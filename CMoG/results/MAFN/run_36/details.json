{
    "run_n":36,
    "run_seed":0,
    "ndims":1000,
    "nsamples":100000,
    "correlation":"corr",
    "nbijectors":10,
    "bijector":"MAFN",
    "spline_knots":8,
    "range_min":-5,
    "hidden_layers":"256-256-256",
    "batch_size":512,
    "activation":"relu",
    "eps_regulariser":0,
    "regulariser":null,
    "dist_seed":0,
    "test_seed":0,
    "kl_divergence":-1,
    "ks_test_mean":0.00265691475182367,
    "ks_test_median":2.8875347838259738e-12,
    "ad_test_mean":0.0010000000000000002,
    "ad_test_median":0.0028380300359105576,
    "Wasserstein_median":0.532119384945887,
    "Wasserstein_mean":0.532119384945887,
    "frob_norm":126.41952064716725,
    "epochs_input":1000,
    "epochs_output":70,
    "time":464.6072750929743,
    "train_loss_history":[
        1954.5999755859375,
        595.3336791992188,
        535.3272705078125,
        517.841796875,
        498.2958984375,
        498.9306945800781,
        487.2156677246094,
        474.24560546875,
        482.8598937988281,
        473.9837646484375,
        469.92620849609375,
        455.2636413574219,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN
    ],
    "val_loss_history":[
        640.8043823242188,
        570.54150390625,
        546.2222290039062,
        497.9167785644531,
        477.8643798828125,
        486.4320373535156,
        483.21002197265625,
        467.1152648925781,
        482.7904357910156,
        453.5700378417969,
        475.6120300292969,
        518.5296630859375,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN
    ],
    "best_train_loss":[],
    "best_val_loss":NaN,
    "best_epoch":[]
}