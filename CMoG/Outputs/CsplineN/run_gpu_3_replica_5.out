2023-09-26 13:23:27.103990: Importing os...
2023-09-26 13:23:27.104050: Importing sys...
2023-09-26 13:23:27.104063: Importing and initializing argparse...
Visible devices: [3]
2023-09-26 13:23:27.119745: Importing timer from timeit...
2023-09-26 13:23:27.120301: Setting env variables for tf import (only device [3] will be available)...
2023-09-26 13:23:27.120344: Importing numpy...
2023-09-26 13:23:27.291961: Importing pandas...
2023-09-26 13:23:27.475306: Importing shutil...
2023-09-26 13:23:27.475331: Importing subprocess...
2023-09-26 13:23:27.475338: Importing tensorflow...
Tensorflow version: 2.12.0
2023-09-26 13:23:29.481265: Importing tensorflow_probability...
Tensorflow probability version: 0.20.1
2023-09-26 13:23:29.818948: Importing textwrap...
2023-09-26 13:23:29.818971: Importing timeit...
2023-09-26 13:23:29.818980: Importing traceback...
2023-09-26 13:23:29.818985: Importing typing...
2023-09-26 13:23:29.818994: Setting tf configs...
2023-09-26 13:23:30.075551: Importing custom module...
Successfully loaded GPU model: NVIDIA A40
2023-09-26 13:23:31.024002: All modues imported successfully.
Directory ../../results/CsplineN_new/ already exists.
Directory ../../results/CsplineN_new/run_1/ already exists.
Skipping it.
===========
Run 1/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_2/ already exists.
Skipping it.
===========
Run 2/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_3/ already exists.
Skipping it.
===========
Run 3/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_4/ already exists.
Skipping it.
===========
Run 4/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_5/ already exists.
Skipping it.
===========
Run 5/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_6/ already exists.
Skipping it.
===========
Run 6/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_7/ already exists.
Skipping it.
===========
Run 7/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_8/ already exists.
Skipping it.
===========
Run 8/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_9/ already exists.
Skipping it.
===========
Run 9/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_10/ already exists.
Skipping it.
===========
Run 10/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_11/ already exists.
Skipping it.
===========
Run 11/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_12/ already exists.
Skipping it.
===========
Run 12/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_13/ already exists.
Skipping it.
===========
Run 13/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_14/ already exists.
Skipping it.
===========
Run 14/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_15/ already exists.
Skipping it.
===========
Run 15/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_16/ already exists.
Skipping it.
===========
Run 16/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_17/ already exists.
Skipping it.
===========
Run 17/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_18/ already exists.
Skipping it.
===========
Run 18/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_19/ already exists.
Skipping it.
===========
Run 19/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_20/ already exists.
Skipping it.
===========
Run 20/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_21/ already exists.
Skipping it.
===========
Run 21/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_22/ already exists.
Skipping it.
===========
Run 22/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_23/ already exists.
Skipping it.
===========
Run 23/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_24/ already exists.
Skipping it.
===========
Run 24/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_25/ already exists.
Skipping it.
===========
Run 25/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_26/ already exists.
Skipping it.
===========
Run 26/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_27/ already exists.
Skipping it.
===========
Run 27/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_28/ already exists.
Skipping it.
===========
Run 28/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_29/ already exists.
Skipping it.
===========
Run 29/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_30/ already exists.
Skipping it.
===========
Run 30/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_31/ already exists.
Skipping it.
===========
Run 31/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_32/ already exists.
Skipping it.
===========
Run 32/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_33/ already exists.
Skipping it.
===========
Run 33/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_34/ already exists.
Skipping it.
===========
Run 34/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_35/ already exists.
Skipping it.
===========
Run 35/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_36/ already exists.
Skipping it.
===========
Run 36/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_37/ already exists.
Skipping it.
===========
Run 37/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_38/ already exists.
Skipping it.
===========
Run 38/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_39/ already exists.
Skipping it.
===========
Run 39/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_40/ already exists.
Skipping it.
===========
Run 40/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_41/ already exists.
Skipping it.
===========
Run 41/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_42/ already exists.
Skipping it.
===========
Run 42/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_43/ already exists.
Skipping it.
===========
Run 43/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_44/ already exists.
Skipping it.
===========
Run 44/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_45/ already exists.
Skipping it.
===========
Run 45/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_46/ already exists.
Skipping it.
===========
Run 46/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_47/ already exists.
Skipping it.
===========
Run 47/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_48/ already exists.
Skipping it.
===========
Run 48/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_49/ already exists.
Skipping it.
===========
Run 49/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_50/ already exists.
Skipping it.
===========
Run 50/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_51/ already exists.
Skipping it.
===========
Run 51/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_52/ already exists.
Skipping it.
===========
Run 52/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_53/ already exists.
Skipping it.
===========
Run 53/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_54/ already exists.
Skipping it.
===========
Run 54/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_55/ already exists.
Skipping it.
===========
Run 55/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_56/ already exists.
Skipping it.
===========
Run 56/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_57/ already exists.
Skipping it.
===========
Run 57/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_58/ already exists.
Skipping it.
===========
Run 58/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_59/ already exists.
Skipping it.
===========
Run 59/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_60/ already exists.
Skipping it.
===========
Run 60/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_61/ already exists.
Skipping it.
===========
Run 61/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_62/ already exists.
Skipping it.
===========
Run 62/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_63/ already exists.
Skipping it.
===========
Run 63/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_64/ already exists.
Skipping it.
===========
Run 64/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_65/ already exists.
Skipping it.
===========
Run 65/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_66/ already exists.
Skipping it.
===========
Run 66/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_67/ already exists.
Skipping it.
===========
Run 67/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_68/ already exists.
Skipping it.
===========
Run 68/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_69/ already exists.
Skipping it.
===========
Run 69/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_70/ already exists.
Skipping it.
===========
Run 70/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_71/ already exists.
Skipping it.
===========
Run 71/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_72/ already exists.
Skipping it.
===========
Run 72/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_73/ already exists.
Skipping it.
===========
Run 73/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_74/ already exists.
Skipping it.
===========
Run 74/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_75/ already exists.
Skipping it.
===========
Run 75/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_76/ already exists.
Skipping it.
===========
Run 76/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_77/ already exists.
Skipping it.
===========
Run 77/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_78/ already exists.
Skipping it.
===========
Run 78/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_79/ already exists.
Skipping it.
===========
Run 79/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_80/ already exists.
Skipping it.
===========
Run 80/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_81/ already exists.
Skipping it.
===========
Run 81/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_82/ already exists.
Skipping it.
===========
Run 82/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_83/ already exists.
Skipping it.
===========
Run 83/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_84/ already exists.
Skipping it.
===========
Run 84/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_85/ already exists.
Skipping it.
===========
Run 85/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_86/ already exists.
Skipping it.
===========
Run 86/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_87/ already exists.
Skipping it.
===========
Run 87/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_88/ already exists.
Skipping it.
===========
Run 88/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_89/ already exists.
Skipping it.
===========
Run 89/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_90/ already exists.
Skipping it.
===========
Run 90/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_91/ already exists.
Skipping it.
===========
Run 91/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_92/ already exists.
Skipping it.
===========
Run 92/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_93/ already exists.
Skipping it.
===========
Run 93/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_94/ already exists.
Skipping it.
===========
Run 94/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_95/ already exists.
Skipping it.
===========
Run 95/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_96/ already exists.
Skipping it.
===========
Run 96/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_97/ already exists.
Skipping it.
===========
Run 97/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_98/ already exists.
Skipping it.
===========
Run 98/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_99/ already exists.
Skipping it.
===========
Run 99/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_100/ already exists.
Skipping it.
===========
Run 100/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_101/ already exists.
Skipping it.
===========
Run 101/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_102/ already exists.
Skipping it.
===========
Run 102/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_103/ already exists.
Skipping it.
===========
Run 103/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_104/ already exists.
Skipping it.
===========
Run 104/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_105/ already exists.
Skipping it.
===========
Run 105/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_106/ already exists.
Skipping it.
===========
Run 106/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_107/ already exists.
Skipping it.
===========
Run 107/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_108/ already exists.
Skipping it.
===========
Run 108/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_109/ already exists.
Skipping it.
===========
Run 109/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_110/ already exists.
Skipping it.
===========
Run 110/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_111/ already exists.
Skipping it.
===========
Run 111/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_112/ already exists.
Skipping it.
===========
Run 112/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_113/ already exists.
Skipping it.
===========
Run 113/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_114/ already exists.
Skipping it.
===========
Run 114/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_115/ already exists.
Skipping it.
===========
Run 115/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_116/ already exists.
Skipping it.
===========
Run 116/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_117/ already exists.
Skipping it.
===========
Run 117/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_118/ already exists.
Skipping it.
===========
Run 118/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_119/ already exists.
Skipping it.
===========
Run 119/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_120/ already exists.
Skipping it.
===========
Run 120/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_121/ already exists.
Skipping it.
===========
Run 121/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_122/ already exists.
Skipping it.
===========
Run 122/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_123/ already exists.
Skipping it.
===========
Run 123/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_124/ already exists.
Skipping it.
===========
Run 124/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_125/ already exists.
Skipping it.
===========
Run 125/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_126/ already exists.
Skipping it.
===========
Run 126/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_127/ already exists.
Skipping it.
===========
Run 127/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_128/ already exists.
Skipping it.
===========
Run 128/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_129/ already exists.
Skipping it.
===========
Run 129/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_130/ already exists.
Skipping it.
===========
Run 130/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_131/ already exists.
Skipping it.
===========
Run 131/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_132/ already exists.
Skipping it.
===========
Run 132/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_133/ already exists.
Skipping it.
===========
Run 133/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_134/ already exists.
Skipping it.
===========
Run 134/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_135/ already exists.
Skipping it.
===========
Run 135/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_136/ already exists.
Skipping it.
===========
Run 136/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_137/ already exists.
Skipping it.
===========
Run 137/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_138/ already exists.
Skipping it.
===========
Run 138/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_139/ already exists.
Skipping it.
===========
Run 139/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_140/ already exists.
Skipping it.
===========
Run 140/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_141/ already exists.
Skipping it.
===========
Run 141/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_142/ already exists.
Skipping it.
===========
Run 142/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_143/ already exists.
Skipping it.
===========
Run 143/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_144/ already exists.
Skipping it.
===========
Run 144/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_145/ already exists.
Skipping it.
===========
Run 145/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_146/ already exists.
Skipping it.
===========
Run 146/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_147/ already exists.
Skipping it.
===========
Run 147/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_148/ already exists.
Skipping it.
===========
Run 148/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_149/ already exists.
Skipping it.
===========
Run 149/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_150/ already exists.
Skipping it.
===========
Run 150/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_151/ already exists.
Skipping it.
===========
Run 151/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_152/ already exists.
Skipping it.
===========
Run 152/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_153/ already exists.
Skipping it.
===========
Run 153/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_154/ already exists.
Skipping it.
===========
Run 154/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_155/ already exists.
Skipping it.
===========
Run 155/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_156/ already exists.
Skipping it.
===========
Run 156/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_157/ already exists.
Skipping it.
===========
Run 157/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_158/ already exists.
Skipping it.
===========
Run 158/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_159/ already exists.
Skipping it.
===========
Run 159/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_160/ already exists.
Skipping it.
===========
Run 160/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_161/ already exists.
Skipping it.
===========
Run 161/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_162/ already exists.
Skipping it.
===========
Run 162/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_163/ already exists.
Skipping it.
===========
Run 163/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_164/ already exists.
Skipping it.
===========
Run 164/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_165/ already exists.
Skipping it.
===========
Run 165/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_166/ already exists.
Skipping it.
===========
Run 166/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_167/ already exists.
Skipping it.
===========
Run 167/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_168/ already exists.
Skipping it.
===========
Run 168/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_169/ already exists.
Skipping it.
===========
Run 169/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_170/ already exists.
Skipping it.
===========
Run 170/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_171/ already exists.
Skipping it.
===========
Run 171/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_172/ already exists.
Skipping it.
===========
Run 172/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_173/ already exists.
Skipping it.
===========
Run 173/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_174/ already exists.
Skipping it.
===========
Run 174/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_175/ already exists.
Skipping it.
===========
Run 175/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_176/ already exists.
Skipping it.
===========
Run 176/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_177/ already exists.
Skipping it.
===========
Run 177/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_178/ already exists.
Skipping it.
===========
Run 178/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_179/ already exists.
Skipping it.
===========
Run 179/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_180/ already exists.
Skipping it.
===========
Run 180/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_181/ already exists.
Skipping it.
===========
Run 181/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_182/ already exists.
Skipping it.
===========
Run 182/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_183/ already exists.
Skipping it.
===========
Run 183/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_184/ already exists.
Skipping it.
===========
Run 184/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_185/ already exists.
Skipping it.
===========
Run 185/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_186/ already exists.
Skipping it.
===========
Run 186/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_187/ already exists.
Skipping it.
===========
Run 187/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_188/ already exists.
Skipping it.
===========
Run 188/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_189/ already exists.
Skipping it.
===========
Run 189/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_190/ already exists.
Skipping it.
===========
Run 190/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_191/ already exists.
Skipping it.
===========
Run 191/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_192/ already exists.
Skipping it.
===========
Run 192/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_193/ already exists.
Skipping it.
===========
Run 193/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_194/ already exists.
Skipping it.
===========
Run 194/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_195/ already exists.
Skipping it.
===========
Run 195/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_196/ already exists.
Skipping it.
===========
Run 196/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_197/ already exists.
Skipping it.
===========
Run 197/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_198/ already exists.
Skipping it.
===========
Run 198/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_199/ already exists.
Skipping it.
===========
Run 199/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_200/ already exists.
Skipping it.
===========
Run 200/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_201/ already exists.
Skipping it.
===========
Run 201/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_202/ already exists.
Skipping it.
===========
Run 202/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_203/ already exists.
Skipping it.
===========
Run 203/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_204/ already exists.
Skipping it.
===========
Run 204/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_205/ already exists.
Skipping it.
===========
Run 205/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_206/ already exists.
Skipping it.
===========
Run 206/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_207/ already exists.
Skipping it.
===========
Run 207/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_208/ already exists.
Skipping it.
===========
Run 208/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_209/ already exists.
Skipping it.
===========
Run 209/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_210/ already exists.
Skipping it.
===========
Run 210/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_211/ already exists.
Skipping it.
===========
Run 211/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_212/ already exists.
Skipping it.
===========
Run 212/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_213/ already exists.
Skipping it.
===========
Run 213/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_214/ already exists.
Skipping it.
===========
Run 214/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_215/ already exists.
Skipping it.
===========
Run 215/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_216/ already exists.
Skipping it.
===========
Run 216/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_217/ already exists.
Skipping it.
===========
Run 217/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_218/ already exists.
Skipping it.
===========
Run 218/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_219/ already exists.
Skipping it.
===========
Run 219/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_220/ already exists.
Skipping it.
===========
Run 220/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_221/ already exists.
Skipping it.
===========
Run 221/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_222/ already exists.
Skipping it.
===========
Run 222/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_223/ already exists.
Skipping it.
===========
Run 223/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_224/ already exists.
Skipping it.
===========
Run 224/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_225/ already exists.
Skipping it.
===========
Run 225/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_226/ already exists.
Skipping it.
===========
Run 226/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_227/ already exists.
Skipping it.
===========
Run 227/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_228/ already exists.
Skipping it.
===========
Run 228/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_229/ already exists.
Skipping it.
===========
Run 229/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_230/ already exists.
Skipping it.
===========
Run 230/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_231/ already exists.
Skipping it.
===========
Run 231/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_232/ already exists.
Skipping it.
===========
Run 232/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_233/ already exists.
Skipping it.
===========
Run 233/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_234/ already exists.
Skipping it.
===========
Run 234/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_235/ already exists.
Skipping it.
===========
Run 235/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_236/ already exists.
Skipping it.
===========
Run 236/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_237/ already exists.
Skipping it.
===========
Run 237/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_238/ already exists.
Skipping it.
===========
Run 238/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_239/ already exists.
Skipping it.
===========
Run 239/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_240/ already exists.
Skipping it.
===========
Run 240/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_241/ already exists.
Skipping it.
===========
Run 241/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_242/ already exists.
Skipping it.
===========
Run 242/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_243/ already exists.
Skipping it.
===========
Run 243/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_244/ already exists.
Skipping it.
===========
Run 244/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_245/ already exists.
Skipping it.
===========
Run 245/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_246/ already exists.
Skipping it.
===========
Run 246/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_247/ already exists.
Skipping it.
===========
Run 247/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_248/ already exists.
Skipping it.
===========
Run 248/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_249/ already exists.
Skipping it.
===========
Run 249/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_250/ already exists.
Skipping it.
===========
Run 250/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_251/ already exists.
Skipping it.
===========
Run 251/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_252/ already exists.
Skipping it.
===========
Run 252/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_253/ already exists.
Skipping it.
===========
Run 253/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_254/ already exists.
Skipping it.
===========
Run 254/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_255/ already exists.
Skipping it.
===========
Run 255/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_256/ already exists.
Skipping it.
===========
Run 256/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_257/ already exists.
Skipping it.
===========
Run 257/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_258/ already exists.
Skipping it.
===========
Run 258/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_259/ already exists.
Skipping it.
===========
Run 259/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_260/ already exists.
Skipping it.
===========
Run 260/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_261/ already exists.
Skipping it.
===========
Run 261/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_262/ already exists.
Skipping it.
===========
Run 262/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_263/ already exists.
Skipping it.
===========
Run 263/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_264/ already exists.
Skipping it.
===========
Run 264/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_265/ already exists.
Skipping it.
===========
Run 265/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_266/ already exists.
Skipping it.
===========
Run 266/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_267/ already exists.
Skipping it.
===========
Run 267/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_268/ already exists.
Skipping it.
===========
Run 268/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_269/ already exists.
Skipping it.
===========
Run 269/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_270/ already exists.
Skipping it.
===========
Run 270/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_271/ already exists.
Skipping it.
===========
Run 271/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_272/ already exists.
Skipping it.
===========
Run 272/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_273/ already exists.
Skipping it.
===========
Run 273/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_274/ already exists.
Skipping it.
===========
Run 274/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_275/ already exists.
Skipping it.
===========
Run 275/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_276/ already exists.
Skipping it.
===========
Run 276/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_277/ already exists.
Skipping it.
===========
Run 277/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_278/ already exists.
Skipping it.
===========
Run 278/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_279/ already exists.
Skipping it.
===========
Run 279/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_280/ already exists.
Skipping it.
===========
Run 280/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_281/ already exists.
Skipping it.
===========
Run 281/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_282/ already exists.
Skipping it.
===========
Run 282/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_283/ already exists.
Skipping it.
===========
Run 283/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_284/ already exists.
Skipping it.
===========
Run 284/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_285/ already exists.
Skipping it.
===========
Run 285/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_286/ already exists.
Skipping it.
===========
Run 286/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_287/ already exists.
Skipping it.
===========
Run 287/720 already exists. Skipping it.
===========

===========
Generating train data for run 288.
===========
Train data generated in 0.11 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_288/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 541}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_288/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 1.4544215 ,  3.75662   ,  8.587604  , ...,  7.2717385 ,
         2.2797804 ,  2.224709  ],
       [ 1.3902065 ,  3.433224  ,  7.9205    , ...,  7.378508  ,
         3.6055362 ,  1.7885203 ],
       [ 2.5590267 ,  3.4328253 ,  7.4715605 , ...,  7.496273  ,
         3.511426  ,  1.7360344 ],
       ...,
       [ 5.120887  ,  6.0070558 , -0.50225353, ...,  0.7586615 ,
         6.522565  ,  1.2877582 ],
       [ 4.695989  ,  6.091708  ,  0.05890873, ...,  1.4941858 ,
         6.0310183 ,  1.5105633 ],
       [ 5.3161554 ,  7.1853566 ,  7.6864433 , ...,  4.199462  ,
         2.6094391 ,  7.597809  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_288/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_288
self.data_kwargs: {'seed': 541}
self.x_data: [[ 3.5424666   4.160326    8.947518   ...  7.3513613   3.2319064
   2.0238907 ]
 [ 1.223466    3.6614168   7.44358    ...  7.1275983   2.889486
   2.1263318 ]
 [ 2.8113456   3.2582755   7.9323573  ...  7.1118317   2.55147
   1.6773428 ]
 ...
 [ 4.8257422   5.760828    0.99088824 ...  1.1221942   6.224573
   1.3870366 ]
 [ 2.8796694   4.5901284   7.9563813  ...  7.221806    3.399475
   1.8678449 ]
 [ 4.724557    5.899211   -0.68043184 ...  1.4107605   6.846419
   1.3825576 ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_10"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_11 (InputLayer)       [(None, 32)]              0         
                                                                 
 log_prob_layer (LogProbLaye  (None,)                  2798560   
 r)                                                              
                                                                 
=================================================================
Total params: 2,798,560
Trainable params: 2,798,560
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer'")
self.model: <keras.engine.functional.Functional object at 0x7fd634486d70>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fd68c7d02b0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fd68c7d02b0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fd634747580>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fd6344bd5a0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fd6344bdb10>, <keras.callbacks.ModelCheckpoint object at 0x7fd6344bdc60>, <keras.callbacks.EarlyStopping object at 0x7fd6344bde70>, <keras.callbacks.ReduceLROnPlateau object at 0x7fd6344bdea0>, <keras.callbacks.TerminateOnNaN object at 0x7fd6344bdbd0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 1.4544215 ,  3.75662   ,  8.587604  , ...,  7.2717385 ,
         2.2797804 ,  2.224709  ],
       [ 1.3902065 ,  3.433224  ,  7.9205    , ...,  7.378508  ,
         3.6055362 ,  1.7885203 ],
       [ 2.5590267 ,  3.4328253 ,  7.4715605 , ...,  7.496273  ,
         3.511426  ,  1.7360344 ],
       ...,
       [ 5.120887  ,  6.0070558 , -0.50225353, ...,  0.7586615 ,
         6.522565  ,  1.2877582 ],
       [ 4.695989  ,  6.091708  ,  0.05890873, ...,  1.4941858 ,
         6.0310183 ,  1.5105633 ],
       [ 5.3161554 ,  7.1853566 ,  7.6864433 , ...,  4.199462  ,
         2.6094391 ,  7.597809  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_288/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 288/720 with hyperparameters:
timestamp = 2023-09-26 13:23:38.059620
ndims = 32
seed_train = 541
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 2798560
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 3.5424666   4.160326    8.947518    1.0939208   7.617727   -0.37824863
  9.755269    4.70193     9.9485855   6.084102    7.916266    0.31372035
  2.6670911   1.177147    2.493954    1.2494209   3.149602    6.587495
  1.3128376   6.9324527   5.4146237   2.7642589   4.1612015   1.0985487
  4.086754    9.263963    3.806251    5.6873355   2.3875675   7.3513613
  3.2319064   2.0238907 ]
Epoch 1/1000
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Batch 22: Invalid loss, terminating training
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
2023-09-26 13:26:19.420 
Epoch 1/1000 
	 loss: nan, MinusLogProbMetric: 1774.7509, val_loss: nan, val_MinusLogProbMetric: nan

Epoch 1: val_loss did not improve from inf
196/196 - 161s - loss: nan - MinusLogProbMetric: 1774.7509 - val_loss: nan - val_MinusLogProbMetric: nan - lr: 0.0010 - 161s/epoch - 823ms/step
The loss history contains NaN values.
Training failed: trying again with seed 810886 and lr 0.0003333333333333333.
===========
Generating train data for run 288.
===========
Train data generated in 0.16 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_288/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 541}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_288/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 1.4544215 ,  3.75662   ,  8.587604  , ...,  7.2717385 ,
         2.2797804 ,  2.224709  ],
       [ 1.3902065 ,  3.433224  ,  7.9205    , ...,  7.378508  ,
         3.6055362 ,  1.7885203 ],
       [ 2.5590267 ,  3.4328253 ,  7.4715605 , ...,  7.496273  ,
         3.511426  ,  1.7360344 ],
       ...,
       [ 5.120887  ,  6.0070558 , -0.50225353, ...,  0.7586615 ,
         6.522565  ,  1.2877582 ],
       [ 4.695989  ,  6.091708  ,  0.05890873, ...,  1.4941858 ,
         6.0310183 ,  1.5105633 ],
       [ 5.3161554 ,  7.1853566 ,  7.6864433 , ...,  4.199462  ,
         2.6094391 ,  7.597809  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_288/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_288
self.data_kwargs: {'seed': 541}
self.x_data: [[ 3.5424666   4.160326    8.947518   ...  7.3513613   3.2319064
   2.0238907 ]
 [ 1.223466    3.6614168   7.44358    ...  7.1275983   2.889486
   2.1263318 ]
 [ 2.8113456   3.2582755   7.9323573  ...  7.1118317   2.55147
   1.6773428 ]
 ...
 [ 4.8257422   5.760828    0.99088824 ...  1.1221942   6.224573
   1.3870366 ]
 [ 2.8796694   4.5901284   7.9563813  ...  7.221806    3.399475
   1.8678449 ]
 [ 4.724557    5.899211   -0.68043184 ...  1.4107605   6.846419
   1.3825576 ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_21"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_22 (InputLayer)       [(None, 32)]              0         
                                                                 
 log_prob_layer_1 (LogProbLa  (None,)                  2798560   
 yer)                                                            
                                                                 
=================================================================
Total params: 2,798,560
Trainable params: 2,798,560
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_1/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_1'")
self.model: <keras.engine.functional.Functional object at 0x7fda4d998d60>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fda5625fdf0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fda5625fdf0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fda56372020>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fda4504cca0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fda4504d210>, <keras.callbacks.ModelCheckpoint object at 0x7fda4504d2d0>, <keras.callbacks.EarlyStopping object at 0x7fda4504d540>, <keras.callbacks.ReduceLROnPlateau object at 0x7fda4504d570>, <keras.callbacks.TerminateOnNaN object at 0x7fda4504d1b0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 1.4544215 ,  3.75662   ,  8.587604  , ...,  7.2717385 ,
         2.2797804 ,  2.224709  ],
       [ 1.3902065 ,  3.433224  ,  7.9205    , ...,  7.378508  ,
         3.6055362 ,  1.7885203 ],
       [ 2.5590267 ,  3.4328253 ,  7.4715605 , ...,  7.496273  ,
         3.511426  ,  1.7360344 ],
       ...,
       [ 5.120887  ,  6.0070558 , -0.50225353, ...,  0.7586615 ,
         6.522565  ,  1.2877582 ],
       [ 4.695989  ,  6.091708  ,  0.05890873, ...,  1.4941858 ,
         6.0310183 ,  1.5105633 ],
       [ 5.3161554 ,  7.1853566 ,  7.6864433 , ...,  4.199462  ,
         2.6094391 ,  7.597809  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_288/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 288/720 with hyperparameters:
timestamp = 2023-09-26 13:26:27.789205
ndims = 32
seed_train = 541
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 2798560
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.0003333333333333333...
Train first sample: [ 3.5424666   4.160326    8.947518    1.0939208   7.617727   -0.37824863
  9.755269    4.70193     9.9485855   6.084102    7.916266    0.31372035
  2.6670911   1.177147    2.493954    1.2494209   3.149602    6.587495
  1.3128376   6.9324527   5.4146237   2.7642589   4.1612015   1.0985487
  4.086754    9.263963    3.806251    5.6873355   2.3875675   7.3513613
  3.2319064   2.0238907 ]
Epoch 1/1000
2023-09-26 13:30:31.598 
Epoch 1/1000 
	 loss: 182.4214, MinusLogProbMetric: 182.4214, val_loss: 42.2772, val_MinusLogProbMetric: 42.2772

Epoch 1: val_loss improved from inf to 42.27718, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 245s - loss: 182.4214 - MinusLogProbMetric: 182.4214 - val_loss: 42.2772 - val_MinusLogProbMetric: 42.2772 - lr: 3.3333e-04 - 245s/epoch - 1s/step
Epoch 2/1000
2023-09-26 13:31:54.438 
Epoch 2/1000 
	 loss: 35.0333, MinusLogProbMetric: 35.0333, val_loss: 31.9529, val_MinusLogProbMetric: 31.9529

Epoch 2: val_loss improved from 42.27718 to 31.95290, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 83s - loss: 35.0333 - MinusLogProbMetric: 35.0333 - val_loss: 31.9529 - val_MinusLogProbMetric: 31.9529 - lr: 3.3333e-04 - 83s/epoch - 421ms/step
Epoch 3/1000
2023-09-26 13:33:19.415 
Epoch 3/1000 
	 loss: 28.6200, MinusLogProbMetric: 28.6200, val_loss: 26.4290, val_MinusLogProbMetric: 26.4290

Epoch 3: val_loss improved from 31.95290 to 26.42899, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 85s - loss: 28.6200 - MinusLogProbMetric: 28.6200 - val_loss: 26.4290 - val_MinusLogProbMetric: 26.4290 - lr: 3.3333e-04 - 85s/epoch - 434ms/step
Epoch 4/1000
2023-09-26 13:34:43.068 
Epoch 4/1000 
	 loss: 25.9022, MinusLogProbMetric: 25.9022, val_loss: 27.0947, val_MinusLogProbMetric: 27.0947

Epoch 4: val_loss did not improve from 26.42899
196/196 - 82s - loss: 25.9022 - MinusLogProbMetric: 25.9022 - val_loss: 27.0947 - val_MinusLogProbMetric: 27.0947 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 5/1000
2023-09-26 13:36:05.102 
Epoch 5/1000 
	 loss: 24.3199, MinusLogProbMetric: 24.3199, val_loss: 23.6482, val_MinusLogProbMetric: 23.6482

Epoch 5: val_loss improved from 26.42899 to 23.64824, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 84s - loss: 24.3199 - MinusLogProbMetric: 24.3199 - val_loss: 23.6482 - val_MinusLogProbMetric: 23.6482 - lr: 3.3333e-04 - 84s/epoch - 426ms/step
Epoch 6/1000
2023-09-26 13:37:29.141 
Epoch 6/1000 
	 loss: 23.4611, MinusLogProbMetric: 23.4611, val_loss: 22.6871, val_MinusLogProbMetric: 22.6871

Epoch 6: val_loss improved from 23.64824 to 22.68710, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 84s - loss: 23.4611 - MinusLogProbMetric: 23.4611 - val_loss: 22.6871 - val_MinusLogProbMetric: 22.6871 - lr: 3.3333e-04 - 84s/epoch - 429ms/step
Epoch 7/1000
2023-09-26 13:38:52.158 
Epoch 7/1000 
	 loss: 22.6429, MinusLogProbMetric: 22.6429, val_loss: 22.8764, val_MinusLogProbMetric: 22.8764

Epoch 7: val_loss did not improve from 22.68710
196/196 - 81s - loss: 22.6429 - MinusLogProbMetric: 22.6429 - val_loss: 22.8764 - val_MinusLogProbMetric: 22.8764 - lr: 3.3333e-04 - 81s/epoch - 416ms/step
Epoch 8/1000
2023-09-26 13:40:14.064 
Epoch 8/1000 
	 loss: 22.1246, MinusLogProbMetric: 22.1246, val_loss: 22.8425, val_MinusLogProbMetric: 22.8425

Epoch 8: val_loss did not improve from 22.68710
196/196 - 82s - loss: 22.1246 - MinusLogProbMetric: 22.1246 - val_loss: 22.8425 - val_MinusLogProbMetric: 22.8425 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 9/1000
2023-09-26 13:41:33.613 
Epoch 9/1000 
	 loss: 21.7849, MinusLogProbMetric: 21.7849, val_loss: 21.5114, val_MinusLogProbMetric: 21.5114

Epoch 9: val_loss improved from 22.68710 to 21.51143, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 81s - loss: 21.7849 - MinusLogProbMetric: 21.7849 - val_loss: 21.5114 - val_MinusLogProbMetric: 21.5114 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 10/1000
2023-09-26 13:42:58.872 
Epoch 10/1000 
	 loss: 21.4326, MinusLogProbMetric: 21.4326, val_loss: 21.6268, val_MinusLogProbMetric: 21.6268

Epoch 10: val_loss did not improve from 21.51143
196/196 - 83s - loss: 21.4326 - MinusLogProbMetric: 21.4326 - val_loss: 21.6268 - val_MinusLogProbMetric: 21.6268 - lr: 3.3333e-04 - 83s/epoch - 426ms/step
Epoch 11/1000
2023-09-26 13:44:20.050 
Epoch 11/1000 
	 loss: 21.0769, MinusLogProbMetric: 21.0769, val_loss: 20.7478, val_MinusLogProbMetric: 20.7478

Epoch 11: val_loss improved from 21.51143 to 20.74779, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 83s - loss: 21.0769 - MinusLogProbMetric: 21.0769 - val_loss: 20.7478 - val_MinusLogProbMetric: 20.7478 - lr: 3.3333e-04 - 83s/epoch - 422ms/step
Epoch 12/1000
2023-09-26 13:45:42.805 
Epoch 12/1000 
	 loss: 20.8443, MinusLogProbMetric: 20.8443, val_loss: 20.5389, val_MinusLogProbMetric: 20.5389

Epoch 12: val_loss improved from 20.74779 to 20.53888, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 83s - loss: 20.8443 - MinusLogProbMetric: 20.8443 - val_loss: 20.5389 - val_MinusLogProbMetric: 20.5389 - lr: 3.3333e-04 - 83s/epoch - 422ms/step
Epoch 13/1000
2023-09-26 13:47:06.204 
Epoch 13/1000 
	 loss: 20.7150, MinusLogProbMetric: 20.7150, val_loss: 20.4962, val_MinusLogProbMetric: 20.4962

Epoch 13: val_loss improved from 20.53888 to 20.49618, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 83s - loss: 20.7150 - MinusLogProbMetric: 20.7150 - val_loss: 20.4962 - val_MinusLogProbMetric: 20.4962 - lr: 3.3333e-04 - 83s/epoch - 426ms/step
Epoch 14/1000
2023-09-26 13:48:28.750 
Epoch 14/1000 
	 loss: 20.5272, MinusLogProbMetric: 20.5272, val_loss: 20.4223, val_MinusLogProbMetric: 20.4223

Epoch 14: val_loss improved from 20.49618 to 20.42230, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 83s - loss: 20.5272 - MinusLogProbMetric: 20.5272 - val_loss: 20.4223 - val_MinusLogProbMetric: 20.4223 - lr: 3.3333e-04 - 83s/epoch - 422ms/step
Epoch 15/1000
2023-09-26 13:49:52.921 
Epoch 15/1000 
	 loss: 20.3083, MinusLogProbMetric: 20.3083, val_loss: 20.4136, val_MinusLogProbMetric: 20.4136

Epoch 15: val_loss improved from 20.42230 to 20.41355, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 84s - loss: 20.3083 - MinusLogProbMetric: 20.3083 - val_loss: 20.4136 - val_MinusLogProbMetric: 20.4136 - lr: 3.3333e-04 - 84s/epoch - 428ms/step
Epoch 16/1000
2023-09-26 13:51:15.880 
Epoch 16/1000 
	 loss: 20.2421, MinusLogProbMetric: 20.2421, val_loss: 20.8493, val_MinusLogProbMetric: 20.8493

Epoch 16: val_loss did not improve from 20.41355
196/196 - 82s - loss: 20.2421 - MinusLogProbMetric: 20.2421 - val_loss: 20.8493 - val_MinusLogProbMetric: 20.8493 - lr: 3.3333e-04 - 82s/epoch - 416ms/step
Epoch 17/1000
2023-09-26 13:52:36.965 
Epoch 17/1000 
	 loss: 20.1076, MinusLogProbMetric: 20.1076, val_loss: 21.6643, val_MinusLogProbMetric: 21.6643

Epoch 17: val_loss did not improve from 20.41355
196/196 - 81s - loss: 20.1076 - MinusLogProbMetric: 20.1076 - val_loss: 21.6643 - val_MinusLogProbMetric: 21.6643 - lr: 3.3333e-04 - 81s/epoch - 414ms/step
Epoch 18/1000
2023-09-26 13:53:57.643 
Epoch 18/1000 
	 loss: 19.9757, MinusLogProbMetric: 19.9757, val_loss: 19.8225, val_MinusLogProbMetric: 19.8225

Epoch 18: val_loss improved from 20.41355 to 19.82253, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 82s - loss: 19.9757 - MinusLogProbMetric: 19.9757 - val_loss: 19.8225 - val_MinusLogProbMetric: 19.8225 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 19/1000
2023-09-26 13:55:20.435 
Epoch 19/1000 
	 loss: 19.8100, MinusLogProbMetric: 19.8100, val_loss: 20.7829, val_MinusLogProbMetric: 20.7829

Epoch 19: val_loss did not improve from 19.82253
196/196 - 81s - loss: 19.8100 - MinusLogProbMetric: 19.8100 - val_loss: 20.7829 - val_MinusLogProbMetric: 20.7829 - lr: 3.3333e-04 - 81s/epoch - 414ms/step
Epoch 20/1000
2023-09-26 13:56:41.270 
Epoch 20/1000 
	 loss: 19.9299, MinusLogProbMetric: 19.9299, val_loss: 21.2504, val_MinusLogProbMetric: 21.2504

Epoch 20: val_loss did not improve from 19.82253
196/196 - 81s - loss: 19.9299 - MinusLogProbMetric: 19.9299 - val_loss: 21.2504 - val_MinusLogProbMetric: 21.2504 - lr: 3.3333e-04 - 81s/epoch - 412ms/step
Epoch 21/1000
2023-09-26 13:58:04.426 
Epoch 21/1000 
	 loss: 19.6754, MinusLogProbMetric: 19.6754, val_loss: 19.6179, val_MinusLogProbMetric: 19.6179

Epoch 21: val_loss improved from 19.82253 to 19.61792, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 85s - loss: 19.6754 - MinusLogProbMetric: 19.6754 - val_loss: 19.6179 - val_MinusLogProbMetric: 19.6179 - lr: 3.3333e-04 - 85s/epoch - 431ms/step
Epoch 22/1000
2023-09-26 13:59:29.198 
Epoch 22/1000 
	 loss: 19.5990, MinusLogProbMetric: 19.5990, val_loss: 20.2764, val_MinusLogProbMetric: 20.2764

Epoch 22: val_loss did not improve from 19.61792
196/196 - 83s - loss: 19.5990 - MinusLogProbMetric: 19.5990 - val_loss: 20.2764 - val_MinusLogProbMetric: 20.2764 - lr: 3.3333e-04 - 83s/epoch - 425ms/step
Epoch 23/1000
2023-09-26 14:00:50.695 
Epoch 23/1000 
	 loss: 19.5285, MinusLogProbMetric: 19.5285, val_loss: 19.5130, val_MinusLogProbMetric: 19.5130

Epoch 23: val_loss improved from 19.61792 to 19.51298, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 83s - loss: 19.5285 - MinusLogProbMetric: 19.5285 - val_loss: 19.5130 - val_MinusLogProbMetric: 19.5130 - lr: 3.3333e-04 - 83s/epoch - 424ms/step
Epoch 24/1000
2023-09-26 14:02:14.620 
Epoch 24/1000 
	 loss: 19.4920, MinusLogProbMetric: 19.4920, val_loss: 20.8858, val_MinusLogProbMetric: 20.8858

Epoch 24: val_loss did not improve from 19.51298
196/196 - 82s - loss: 19.4920 - MinusLogProbMetric: 19.4920 - val_loss: 20.8858 - val_MinusLogProbMetric: 20.8858 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 25/1000
2023-09-26 14:03:37.830 
Epoch 25/1000 
	 loss: 19.4436, MinusLogProbMetric: 19.4436, val_loss: 19.7205, val_MinusLogProbMetric: 19.7205

Epoch 25: val_loss did not improve from 19.51298
196/196 - 83s - loss: 19.4436 - MinusLogProbMetric: 19.4436 - val_loss: 19.7205 - val_MinusLogProbMetric: 19.7205 - lr: 3.3333e-04 - 83s/epoch - 425ms/step
Epoch 26/1000
2023-09-26 14:04:59.531 
Epoch 26/1000 
	 loss: 19.2560, MinusLogProbMetric: 19.2560, val_loss: 18.8542, val_MinusLogProbMetric: 18.8542

Epoch 26: val_loss improved from 19.51298 to 18.85419, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 83s - loss: 19.2560 - MinusLogProbMetric: 19.2560 - val_loss: 18.8542 - val_MinusLogProbMetric: 18.8542 - lr: 3.3333e-04 - 83s/epoch - 424ms/step
Epoch 27/1000
2023-09-26 14:06:24.483 
Epoch 27/1000 
	 loss: 19.2955, MinusLogProbMetric: 19.2955, val_loss: 19.1198, val_MinusLogProbMetric: 19.1198

Epoch 27: val_loss did not improve from 18.85419
196/196 - 84s - loss: 19.2955 - MinusLogProbMetric: 19.2955 - val_loss: 19.1198 - val_MinusLogProbMetric: 19.1198 - lr: 3.3333e-04 - 84s/epoch - 426ms/step
Epoch 28/1000
2023-09-26 14:07:46.654 
Epoch 28/1000 
	 loss: 19.2134, MinusLogProbMetric: 19.2134, val_loss: 19.5287, val_MinusLogProbMetric: 19.5287

Epoch 28: val_loss did not improve from 18.85419
196/196 - 82s - loss: 19.2134 - MinusLogProbMetric: 19.2134 - val_loss: 19.5287 - val_MinusLogProbMetric: 19.5287 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 29/1000
2023-09-26 14:09:08.855 
Epoch 29/1000 
	 loss: 19.2198, MinusLogProbMetric: 19.2198, val_loss: 19.0109, val_MinusLogProbMetric: 19.0109

Epoch 29: val_loss did not improve from 18.85419
196/196 - 82s - loss: 19.2198 - MinusLogProbMetric: 19.2198 - val_loss: 19.0109 - val_MinusLogProbMetric: 19.0109 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 30/1000
2023-09-26 14:10:27.713 
Epoch 30/1000 
	 loss: 19.0255, MinusLogProbMetric: 19.0255, val_loss: 19.3690, val_MinusLogProbMetric: 19.3690

Epoch 30: val_loss did not improve from 18.85419
196/196 - 79s - loss: 19.0255 - MinusLogProbMetric: 19.0255 - val_loss: 19.3690 - val_MinusLogProbMetric: 19.3690 - lr: 3.3333e-04 - 79s/epoch - 402ms/step
Epoch 31/1000
2023-09-26 14:11:47.638 
Epoch 31/1000 
	 loss: 19.1158, MinusLogProbMetric: 19.1158, val_loss: 19.5482, val_MinusLogProbMetric: 19.5482

Epoch 31: val_loss did not improve from 18.85419
196/196 - 80s - loss: 19.1158 - MinusLogProbMetric: 19.1158 - val_loss: 19.5482 - val_MinusLogProbMetric: 19.5482 - lr: 3.3333e-04 - 80s/epoch - 408ms/step
Epoch 32/1000
2023-09-26 14:13:10.199 
Epoch 32/1000 
	 loss: 18.9885, MinusLogProbMetric: 18.9885, val_loss: 19.5117, val_MinusLogProbMetric: 19.5117

Epoch 32: val_loss did not improve from 18.85419
196/196 - 83s - loss: 18.9885 - MinusLogProbMetric: 18.9885 - val_loss: 19.5117 - val_MinusLogProbMetric: 19.5117 - lr: 3.3333e-04 - 83s/epoch - 421ms/step
Epoch 33/1000
2023-09-26 14:14:31.616 
Epoch 33/1000 
	 loss: 18.9860, MinusLogProbMetric: 18.9860, val_loss: 19.3138, val_MinusLogProbMetric: 19.3138

Epoch 33: val_loss did not improve from 18.85419
196/196 - 81s - loss: 18.9860 - MinusLogProbMetric: 18.9860 - val_loss: 19.3138 - val_MinusLogProbMetric: 19.3138 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 34/1000
2023-09-26 14:15:53.522 
Epoch 34/1000 
	 loss: 18.8733, MinusLogProbMetric: 18.8733, val_loss: 19.1128, val_MinusLogProbMetric: 19.1128

Epoch 34: val_loss did not improve from 18.85419
196/196 - 82s - loss: 18.8733 - MinusLogProbMetric: 18.8733 - val_loss: 19.1128 - val_MinusLogProbMetric: 19.1128 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 35/1000
2023-09-26 14:17:14.109 
Epoch 35/1000 
	 loss: 18.9158, MinusLogProbMetric: 18.9158, val_loss: 18.9724, val_MinusLogProbMetric: 18.9724

Epoch 35: val_loss did not improve from 18.85419
196/196 - 81s - loss: 18.9158 - MinusLogProbMetric: 18.9158 - val_loss: 18.9724 - val_MinusLogProbMetric: 18.9724 - lr: 3.3333e-04 - 81s/epoch - 411ms/step
Epoch 36/1000
2023-09-26 14:18:35.909 
Epoch 36/1000 
	 loss: 18.9032, MinusLogProbMetric: 18.9032, val_loss: 19.7632, val_MinusLogProbMetric: 19.7632

Epoch 36: val_loss did not improve from 18.85419
196/196 - 82s - loss: 18.9032 - MinusLogProbMetric: 18.9032 - val_loss: 19.7632 - val_MinusLogProbMetric: 19.7632 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 37/1000
2023-09-26 14:20:01.161 
Epoch 37/1000 
	 loss: 18.8130, MinusLogProbMetric: 18.8130, val_loss: 18.7848, val_MinusLogProbMetric: 18.7848

Epoch 37: val_loss improved from 18.85419 to 18.78477, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 87s - loss: 18.8130 - MinusLogProbMetric: 18.8130 - val_loss: 18.7848 - val_MinusLogProbMetric: 18.7848 - lr: 3.3333e-04 - 87s/epoch - 444ms/step
Epoch 38/1000
2023-09-26 14:21:25.805 
Epoch 38/1000 
	 loss: 18.7985, MinusLogProbMetric: 18.7985, val_loss: 20.0197, val_MinusLogProbMetric: 20.0197

Epoch 38: val_loss did not improve from 18.78477
196/196 - 83s - loss: 18.7985 - MinusLogProbMetric: 18.7985 - val_loss: 20.0197 - val_MinusLogProbMetric: 20.0197 - lr: 3.3333e-04 - 83s/epoch - 423ms/step
Epoch 39/1000
2023-09-26 14:22:49.544 
Epoch 39/1000 
	 loss: 18.6306, MinusLogProbMetric: 18.6306, val_loss: 19.2514, val_MinusLogProbMetric: 19.2514

Epoch 39: val_loss did not improve from 18.78477
196/196 - 84s - loss: 18.6306 - MinusLogProbMetric: 18.6306 - val_loss: 19.2514 - val_MinusLogProbMetric: 19.2514 - lr: 3.3333e-04 - 84s/epoch - 427ms/step
Epoch 40/1000
2023-09-26 14:24:14.150 
Epoch 40/1000 
	 loss: 18.6931, MinusLogProbMetric: 18.6931, val_loss: 18.9509, val_MinusLogProbMetric: 18.9509

Epoch 40: val_loss did not improve from 18.78477
196/196 - 85s - loss: 18.6931 - MinusLogProbMetric: 18.6931 - val_loss: 18.9509 - val_MinusLogProbMetric: 18.9509 - lr: 3.3333e-04 - 85s/epoch - 432ms/step
Epoch 41/1000
2023-09-26 14:25:38.725 
Epoch 41/1000 
	 loss: 18.6157, MinusLogProbMetric: 18.6157, val_loss: 19.2406, val_MinusLogProbMetric: 19.2406

Epoch 41: val_loss did not improve from 18.78477
196/196 - 85s - loss: 18.6157 - MinusLogProbMetric: 18.6157 - val_loss: 19.2406 - val_MinusLogProbMetric: 19.2406 - lr: 3.3333e-04 - 85s/epoch - 431ms/step
Epoch 42/1000
2023-09-26 14:27:02.189 
Epoch 42/1000 
	 loss: 18.6331, MinusLogProbMetric: 18.6331, val_loss: 18.7439, val_MinusLogProbMetric: 18.7439

Epoch 42: val_loss improved from 18.78477 to 18.74392, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 85s - loss: 18.6331 - MinusLogProbMetric: 18.6331 - val_loss: 18.7439 - val_MinusLogProbMetric: 18.7439 - lr: 3.3333e-04 - 85s/epoch - 433ms/step
Epoch 43/1000
2023-09-26 14:28:26.139 
Epoch 43/1000 
	 loss: 18.6113, MinusLogProbMetric: 18.6113, val_loss: 19.0411, val_MinusLogProbMetric: 19.0411

Epoch 43: val_loss did not improve from 18.74392
196/196 - 83s - loss: 18.6113 - MinusLogProbMetric: 18.6113 - val_loss: 19.0411 - val_MinusLogProbMetric: 19.0411 - lr: 3.3333e-04 - 83s/epoch - 421ms/step
Epoch 44/1000
2023-09-26 14:29:52.586 
Epoch 44/1000 
	 loss: 18.7169, MinusLogProbMetric: 18.7169, val_loss: 18.6697, val_MinusLogProbMetric: 18.6697

Epoch 44: val_loss improved from 18.74392 to 18.66968, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 88s - loss: 18.7169 - MinusLogProbMetric: 18.7169 - val_loss: 18.6697 - val_MinusLogProbMetric: 18.6697 - lr: 3.3333e-04 - 88s/epoch - 451ms/step
Epoch 45/1000
2023-09-26 14:31:20.232 
Epoch 45/1000 
	 loss: 18.5481, MinusLogProbMetric: 18.5481, val_loss: 18.4652, val_MinusLogProbMetric: 18.4652

Epoch 45: val_loss improved from 18.66968 to 18.46516, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 88s - loss: 18.5481 - MinusLogProbMetric: 18.5481 - val_loss: 18.4652 - val_MinusLogProbMetric: 18.4652 - lr: 3.3333e-04 - 88s/epoch - 446ms/step
Epoch 46/1000
2023-09-26 14:32:48.441 
Epoch 46/1000 
	 loss: 18.5437, MinusLogProbMetric: 18.5437, val_loss: 18.6496, val_MinusLogProbMetric: 18.6496

Epoch 46: val_loss did not improve from 18.46516
196/196 - 86s - loss: 18.5437 - MinusLogProbMetric: 18.5437 - val_loss: 18.6496 - val_MinusLogProbMetric: 18.6496 - lr: 3.3333e-04 - 86s/epoch - 441ms/step
Epoch 47/1000
2023-09-26 14:34:10.138 
Epoch 47/1000 
	 loss: 18.4798, MinusLogProbMetric: 18.4798, val_loss: 19.4137, val_MinusLogProbMetric: 19.4137

Epoch 47: val_loss did not improve from 18.46516
196/196 - 82s - loss: 18.4798 - MinusLogProbMetric: 18.4798 - val_loss: 19.4137 - val_MinusLogProbMetric: 19.4137 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 48/1000
2023-09-26 14:35:29.502 
Epoch 48/1000 
	 loss: 18.4921, MinusLogProbMetric: 18.4921, val_loss: 18.3342, val_MinusLogProbMetric: 18.3342

Epoch 48: val_loss improved from 18.46516 to 18.33420, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 81s - loss: 18.4921 - MinusLogProbMetric: 18.4921 - val_loss: 18.3342 - val_MinusLogProbMetric: 18.3342 - lr: 3.3333e-04 - 81s/epoch - 413ms/step
Epoch 49/1000
2023-09-26 14:36:52.031 
Epoch 49/1000 
	 loss: 18.4780, MinusLogProbMetric: 18.4780, val_loss: 19.4255, val_MinusLogProbMetric: 19.4255

Epoch 49: val_loss did not improve from 18.33420
196/196 - 81s - loss: 18.4780 - MinusLogProbMetric: 18.4780 - val_loss: 19.4255 - val_MinusLogProbMetric: 19.4255 - lr: 3.3333e-04 - 81s/epoch - 413ms/step
Epoch 50/1000
2023-09-26 14:38:12.658 
Epoch 50/1000 
	 loss: 18.4488, MinusLogProbMetric: 18.4488, val_loss: 19.4574, val_MinusLogProbMetric: 19.4574

Epoch 50: val_loss did not improve from 18.33420
196/196 - 81s - loss: 18.4488 - MinusLogProbMetric: 18.4488 - val_loss: 19.4574 - val_MinusLogProbMetric: 19.4574 - lr: 3.3333e-04 - 81s/epoch - 411ms/step
Epoch 51/1000
2023-09-26 14:39:33.234 
Epoch 51/1000 
	 loss: 18.4201, MinusLogProbMetric: 18.4201, val_loss: 18.8603, val_MinusLogProbMetric: 18.8603

Epoch 51: val_loss did not improve from 18.33420
196/196 - 81s - loss: 18.4201 - MinusLogProbMetric: 18.4201 - val_loss: 18.8603 - val_MinusLogProbMetric: 18.8603 - lr: 3.3333e-04 - 81s/epoch - 411ms/step
Epoch 52/1000
2023-09-26 14:40:53.740 
Epoch 52/1000 
	 loss: 18.4648, MinusLogProbMetric: 18.4648, val_loss: 18.3896, val_MinusLogProbMetric: 18.3896

Epoch 52: val_loss did not improve from 18.33420
196/196 - 81s - loss: 18.4648 - MinusLogProbMetric: 18.4648 - val_loss: 18.3896 - val_MinusLogProbMetric: 18.3896 - lr: 3.3333e-04 - 81s/epoch - 411ms/step
Epoch 53/1000
2023-09-26 14:42:12.896 
Epoch 53/1000 
	 loss: 18.4505, MinusLogProbMetric: 18.4505, val_loss: 19.6454, val_MinusLogProbMetric: 19.6454

Epoch 53: val_loss did not improve from 18.33420
196/196 - 79s - loss: 18.4505 - MinusLogProbMetric: 18.4505 - val_loss: 19.6454 - val_MinusLogProbMetric: 19.6454 - lr: 3.3333e-04 - 79s/epoch - 404ms/step
Epoch 54/1000
2023-09-26 14:43:33.283 
Epoch 54/1000 
	 loss: 18.3638, MinusLogProbMetric: 18.3638, val_loss: 18.6226, val_MinusLogProbMetric: 18.6226

Epoch 54: val_loss did not improve from 18.33420
196/196 - 80s - loss: 18.3638 - MinusLogProbMetric: 18.3638 - val_loss: 18.6226 - val_MinusLogProbMetric: 18.6226 - lr: 3.3333e-04 - 80s/epoch - 410ms/step
Epoch 55/1000
2023-09-26 14:44:53.014 
Epoch 55/1000 
	 loss: 18.3821, MinusLogProbMetric: 18.3821, val_loss: 18.4565, val_MinusLogProbMetric: 18.4565

Epoch 55: val_loss did not improve from 18.33420
196/196 - 80s - loss: 18.3821 - MinusLogProbMetric: 18.3821 - val_loss: 18.4565 - val_MinusLogProbMetric: 18.4565 - lr: 3.3333e-04 - 80s/epoch - 407ms/step
Epoch 56/1000
2023-09-26 14:46:12.384 
Epoch 56/1000 
	 loss: 18.4233, MinusLogProbMetric: 18.4233, val_loss: 18.3267, val_MinusLogProbMetric: 18.3267

Epoch 56: val_loss improved from 18.33420 to 18.32668, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 81s - loss: 18.4233 - MinusLogProbMetric: 18.4233 - val_loss: 18.3267 - val_MinusLogProbMetric: 18.3267 - lr: 3.3333e-04 - 81s/epoch - 413ms/step
Epoch 57/1000
2023-09-26 14:47:35.694 
Epoch 57/1000 
	 loss: 18.3294, MinusLogProbMetric: 18.3294, val_loss: 18.6103, val_MinusLogProbMetric: 18.6103

Epoch 57: val_loss did not improve from 18.32668
196/196 - 82s - loss: 18.3294 - MinusLogProbMetric: 18.3294 - val_loss: 18.6103 - val_MinusLogProbMetric: 18.6103 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 58/1000
2023-09-26 14:48:56.656 
Epoch 58/1000 
	 loss: 18.4631, MinusLogProbMetric: 18.4631, val_loss: 18.8561, val_MinusLogProbMetric: 18.8561

Epoch 58: val_loss did not improve from 18.32668
196/196 - 81s - loss: 18.4631 - MinusLogProbMetric: 18.4631 - val_loss: 18.8561 - val_MinusLogProbMetric: 18.8561 - lr: 3.3333e-04 - 81s/epoch - 413ms/step
Epoch 59/1000
2023-09-26 14:50:15.832 
Epoch 59/1000 
	 loss: 18.3206, MinusLogProbMetric: 18.3206, val_loss: 18.5701, val_MinusLogProbMetric: 18.5701

Epoch 59: val_loss did not improve from 18.32668
196/196 - 79s - loss: 18.3206 - MinusLogProbMetric: 18.3206 - val_loss: 18.5701 - val_MinusLogProbMetric: 18.5701 - lr: 3.3333e-04 - 79s/epoch - 404ms/step
Epoch 60/1000
2023-09-26 14:51:34.188 
Epoch 60/1000 
	 loss: 18.2336, MinusLogProbMetric: 18.2336, val_loss: 19.5039, val_MinusLogProbMetric: 19.5039

Epoch 60: val_loss did not improve from 18.32668
196/196 - 78s - loss: 18.2336 - MinusLogProbMetric: 18.2336 - val_loss: 19.5039 - val_MinusLogProbMetric: 19.5039 - lr: 3.3333e-04 - 78s/epoch - 400ms/step
Epoch 61/1000
2023-09-26 14:52:53.021 
Epoch 61/1000 
	 loss: 18.2614, MinusLogProbMetric: 18.2614, val_loss: 18.5097, val_MinusLogProbMetric: 18.5097

Epoch 61: val_loss did not improve from 18.32668
196/196 - 79s - loss: 18.2614 - MinusLogProbMetric: 18.2614 - val_loss: 18.5097 - val_MinusLogProbMetric: 18.5097 - lr: 3.3333e-04 - 79s/epoch - 402ms/step
Epoch 62/1000
2023-09-26 14:54:15.245 
Epoch 62/1000 
	 loss: 18.2758, MinusLogProbMetric: 18.2758, val_loss: 18.4885, val_MinusLogProbMetric: 18.4885

Epoch 62: val_loss did not improve from 18.32668
196/196 - 82s - loss: 18.2758 - MinusLogProbMetric: 18.2758 - val_loss: 18.4885 - val_MinusLogProbMetric: 18.4885 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 63/1000
2023-09-26 14:55:36.196 
Epoch 63/1000 
	 loss: 18.2255, MinusLogProbMetric: 18.2255, val_loss: 18.5646, val_MinusLogProbMetric: 18.5646

Epoch 63: val_loss did not improve from 18.32668
196/196 - 81s - loss: 18.2255 - MinusLogProbMetric: 18.2255 - val_loss: 18.5646 - val_MinusLogProbMetric: 18.5646 - lr: 3.3333e-04 - 81s/epoch - 413ms/step
Epoch 64/1000
2023-09-26 14:56:57.071 
Epoch 64/1000 
	 loss: 18.2441, MinusLogProbMetric: 18.2441, val_loss: 18.7573, val_MinusLogProbMetric: 18.7573

Epoch 64: val_loss did not improve from 18.32668
196/196 - 81s - loss: 18.2441 - MinusLogProbMetric: 18.2441 - val_loss: 18.7573 - val_MinusLogProbMetric: 18.7573 - lr: 3.3333e-04 - 81s/epoch - 413ms/step
Epoch 65/1000
2023-09-26 14:58:16.807 
Epoch 65/1000 
	 loss: 18.1425, MinusLogProbMetric: 18.1425, val_loss: 18.6238, val_MinusLogProbMetric: 18.6238

Epoch 65: val_loss did not improve from 18.32668
196/196 - 80s - loss: 18.1425 - MinusLogProbMetric: 18.1425 - val_loss: 18.6238 - val_MinusLogProbMetric: 18.6238 - lr: 3.3333e-04 - 80s/epoch - 407ms/step
Epoch 66/1000
2023-09-26 14:59:39.299 
Epoch 66/1000 
	 loss: 18.1684, MinusLogProbMetric: 18.1684, val_loss: 18.2426, val_MinusLogProbMetric: 18.2426

Epoch 66: val_loss improved from 18.32668 to 18.24263, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 84s - loss: 18.1684 - MinusLogProbMetric: 18.1684 - val_loss: 18.2426 - val_MinusLogProbMetric: 18.2426 - lr: 3.3333e-04 - 84s/epoch - 428ms/step
Epoch 67/1000
2023-09-26 15:01:00.352 
Epoch 67/1000 
	 loss: 18.1608, MinusLogProbMetric: 18.1608, val_loss: 18.5736, val_MinusLogProbMetric: 18.5736

Epoch 67: val_loss did not improve from 18.24263
196/196 - 80s - loss: 18.1608 - MinusLogProbMetric: 18.1608 - val_loss: 18.5736 - val_MinusLogProbMetric: 18.5736 - lr: 3.3333e-04 - 80s/epoch - 406ms/step
Epoch 68/1000
2023-09-26 15:02:20.109 
Epoch 68/1000 
	 loss: 18.1967, MinusLogProbMetric: 18.1967, val_loss: 18.4024, val_MinusLogProbMetric: 18.4024

Epoch 68: val_loss did not improve from 18.24263
196/196 - 80s - loss: 18.1967 - MinusLogProbMetric: 18.1967 - val_loss: 18.4024 - val_MinusLogProbMetric: 18.4024 - lr: 3.3333e-04 - 80s/epoch - 407ms/step
Epoch 69/1000
2023-09-26 15:03:39.538 
Epoch 69/1000 
	 loss: 18.0379, MinusLogProbMetric: 18.0379, val_loss: 18.5300, val_MinusLogProbMetric: 18.5300

Epoch 69: val_loss did not improve from 18.24263
196/196 - 79s - loss: 18.0379 - MinusLogProbMetric: 18.0379 - val_loss: 18.5300 - val_MinusLogProbMetric: 18.5300 - lr: 3.3333e-04 - 79s/epoch - 405ms/step
Epoch 70/1000
2023-09-26 15:04:59.202 
Epoch 70/1000 
	 loss: 18.1008, MinusLogProbMetric: 18.1008, val_loss: 18.4446, val_MinusLogProbMetric: 18.4446

Epoch 70: val_loss did not improve from 18.24263
196/196 - 80s - loss: 18.1008 - MinusLogProbMetric: 18.1008 - val_loss: 18.4446 - val_MinusLogProbMetric: 18.4446 - lr: 3.3333e-04 - 80s/epoch - 406ms/step
Epoch 71/1000
2023-09-26 15:06:17.330 
Epoch 71/1000 
	 loss: 18.1331, MinusLogProbMetric: 18.1331, val_loss: 18.7465, val_MinusLogProbMetric: 18.7465

Epoch 71: val_loss did not improve from 18.24263
196/196 - 78s - loss: 18.1331 - MinusLogProbMetric: 18.1331 - val_loss: 18.7465 - val_MinusLogProbMetric: 18.7465 - lr: 3.3333e-04 - 78s/epoch - 399ms/step
Epoch 72/1000
2023-09-26 15:07:37.406 
Epoch 72/1000 
	 loss: 18.1088, MinusLogProbMetric: 18.1088, val_loss: 18.7848, val_MinusLogProbMetric: 18.7848

Epoch 72: val_loss did not improve from 18.24263
196/196 - 80s - loss: 18.1088 - MinusLogProbMetric: 18.1088 - val_loss: 18.7848 - val_MinusLogProbMetric: 18.7848 - lr: 3.3333e-04 - 80s/epoch - 409ms/step
Epoch 73/1000
2023-09-26 15:08:55.258 
Epoch 73/1000 
	 loss: 18.0182, MinusLogProbMetric: 18.0182, val_loss: 18.3604, val_MinusLogProbMetric: 18.3604

Epoch 73: val_loss did not improve from 18.24263
196/196 - 78s - loss: 18.0182 - MinusLogProbMetric: 18.0182 - val_loss: 18.3604 - val_MinusLogProbMetric: 18.3604 - lr: 3.3333e-04 - 78s/epoch - 397ms/step
Epoch 74/1000
2023-09-26 15:10:13.995 
Epoch 74/1000 
	 loss: 18.0794, MinusLogProbMetric: 18.0794, val_loss: 18.3869, val_MinusLogProbMetric: 18.3869

Epoch 74: val_loss did not improve from 18.24263
196/196 - 79s - loss: 18.0794 - MinusLogProbMetric: 18.0794 - val_loss: 18.3869 - val_MinusLogProbMetric: 18.3869 - lr: 3.3333e-04 - 79s/epoch - 402ms/step
Epoch 75/1000
2023-09-26 15:11:32.834 
Epoch 75/1000 
	 loss: 18.1036, MinusLogProbMetric: 18.1036, val_loss: 18.9412, val_MinusLogProbMetric: 18.9412

Epoch 75: val_loss did not improve from 18.24263
196/196 - 79s - loss: 18.1036 - MinusLogProbMetric: 18.1036 - val_loss: 18.9412 - val_MinusLogProbMetric: 18.9412 - lr: 3.3333e-04 - 79s/epoch - 402ms/step
Epoch 76/1000
2023-09-26 15:12:52.723 
Epoch 76/1000 
	 loss: 18.0309, MinusLogProbMetric: 18.0309, val_loss: 18.4670, val_MinusLogProbMetric: 18.4670

Epoch 76: val_loss did not improve from 18.24263
196/196 - 80s - loss: 18.0309 - MinusLogProbMetric: 18.0309 - val_loss: 18.4670 - val_MinusLogProbMetric: 18.4670 - lr: 3.3333e-04 - 80s/epoch - 408ms/step
Epoch 77/1000
2023-09-26 15:14:12.170 
Epoch 77/1000 
	 loss: 18.0244, MinusLogProbMetric: 18.0244, val_loss: 18.5729, val_MinusLogProbMetric: 18.5729

Epoch 77: val_loss did not improve from 18.24263
196/196 - 79s - loss: 18.0244 - MinusLogProbMetric: 18.0244 - val_loss: 18.5729 - val_MinusLogProbMetric: 18.5729 - lr: 3.3333e-04 - 79s/epoch - 405ms/step
Epoch 78/1000
2023-09-26 15:15:32.832 
Epoch 78/1000 
	 loss: 18.0385, MinusLogProbMetric: 18.0385, val_loss: 18.0266, val_MinusLogProbMetric: 18.0266

Epoch 78: val_loss improved from 18.24263 to 18.02663, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 82s - loss: 18.0385 - MinusLogProbMetric: 18.0385 - val_loss: 18.0266 - val_MinusLogProbMetric: 18.0266 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 79/1000
2023-09-26 15:16:53.978 
Epoch 79/1000 
	 loss: 17.9061, MinusLogProbMetric: 17.9061, val_loss: 18.6170, val_MinusLogProbMetric: 18.6170

Epoch 79: val_loss did not improve from 18.02663
196/196 - 80s - loss: 17.9061 - MinusLogProbMetric: 17.9061 - val_loss: 18.6170 - val_MinusLogProbMetric: 18.6170 - lr: 3.3333e-04 - 80s/epoch - 407ms/step
Epoch 80/1000
2023-09-26 15:18:14.283 
Epoch 80/1000 
	 loss: 17.9599, MinusLogProbMetric: 17.9599, val_loss: 18.0816, val_MinusLogProbMetric: 18.0816

Epoch 80: val_loss did not improve from 18.02663
196/196 - 80s - loss: 17.9599 - MinusLogProbMetric: 17.9599 - val_loss: 18.0816 - val_MinusLogProbMetric: 18.0816 - lr: 3.3333e-04 - 80s/epoch - 410ms/step
Epoch 81/1000
2023-09-26 15:19:34.533 
Epoch 81/1000 
	 loss: 17.9867, MinusLogProbMetric: 17.9867, val_loss: 20.3494, val_MinusLogProbMetric: 20.3494

Epoch 81: val_loss did not improve from 18.02663
196/196 - 80s - loss: 17.9867 - MinusLogProbMetric: 17.9867 - val_loss: 20.3494 - val_MinusLogProbMetric: 20.3494 - lr: 3.3333e-04 - 80s/epoch - 409ms/step
Epoch 82/1000
2023-09-26 15:21:02.726 
Epoch 82/1000 
	 loss: 17.9817, MinusLogProbMetric: 17.9817, val_loss: 17.9365, val_MinusLogProbMetric: 17.9365

Epoch 82: val_loss improved from 18.02663 to 17.93653, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 90s - loss: 17.9817 - MinusLogProbMetric: 17.9817 - val_loss: 17.9365 - val_MinusLogProbMetric: 17.9365 - lr: 3.3333e-04 - 90s/epoch - 458ms/step
Epoch 83/1000
2023-09-26 15:22:30.860 
Epoch 83/1000 
	 loss: 17.9392, MinusLogProbMetric: 17.9392, val_loss: 18.2359, val_MinusLogProbMetric: 18.2359

Epoch 83: val_loss did not improve from 17.93653
196/196 - 87s - loss: 17.9392 - MinusLogProbMetric: 17.9392 - val_loss: 18.2359 - val_MinusLogProbMetric: 18.2359 - lr: 3.3333e-04 - 87s/epoch - 442ms/step
Epoch 84/1000
2023-09-26 15:23:55.274 
Epoch 84/1000 
	 loss: 17.9211, MinusLogProbMetric: 17.9211, val_loss: 18.1516, val_MinusLogProbMetric: 18.1516

Epoch 84: val_loss did not improve from 17.93653
196/196 - 84s - loss: 17.9211 - MinusLogProbMetric: 17.9211 - val_loss: 18.1516 - val_MinusLogProbMetric: 18.1516 - lr: 3.3333e-04 - 84s/epoch - 431ms/step
Epoch 85/1000
2023-09-26 15:25:14.158 
Epoch 85/1000 
	 loss: 17.9655, MinusLogProbMetric: 17.9655, val_loss: 17.9738, val_MinusLogProbMetric: 17.9738

Epoch 85: val_loss did not improve from 17.93653
196/196 - 79s - loss: 17.9655 - MinusLogProbMetric: 17.9655 - val_loss: 17.9738 - val_MinusLogProbMetric: 17.9738 - lr: 3.3333e-04 - 79s/epoch - 402ms/step
Epoch 86/1000
2023-09-26 15:26:25.778 
Epoch 86/1000 
	 loss: 17.8710, MinusLogProbMetric: 17.8710, val_loss: 18.0238, val_MinusLogProbMetric: 18.0238

Epoch 86: val_loss did not improve from 17.93653
196/196 - 72s - loss: 17.8710 - MinusLogProbMetric: 17.8710 - val_loss: 18.0238 - val_MinusLogProbMetric: 18.0238 - lr: 3.3333e-04 - 72s/epoch - 365ms/step
Epoch 87/1000
2023-09-26 15:27:34.307 
Epoch 87/1000 
	 loss: 17.8713, MinusLogProbMetric: 17.8713, val_loss: 18.3916, val_MinusLogProbMetric: 18.3916

Epoch 87: val_loss did not improve from 17.93653
196/196 - 69s - loss: 17.8713 - MinusLogProbMetric: 17.8713 - val_loss: 18.3916 - val_MinusLogProbMetric: 18.3916 - lr: 3.3333e-04 - 69s/epoch - 350ms/step
Epoch 88/1000
2023-09-26 15:28:50.355 
Epoch 88/1000 
	 loss: 17.9910, MinusLogProbMetric: 17.9910, val_loss: 17.9818, val_MinusLogProbMetric: 17.9818

Epoch 88: val_loss did not improve from 17.93653
196/196 - 76s - loss: 17.9910 - MinusLogProbMetric: 17.9910 - val_loss: 17.9818 - val_MinusLogProbMetric: 17.9818 - lr: 3.3333e-04 - 76s/epoch - 388ms/step
Epoch 89/1000
2023-09-26 15:29:59.661 
Epoch 89/1000 
	 loss: 17.9393, MinusLogProbMetric: 17.9393, val_loss: 18.2914, val_MinusLogProbMetric: 18.2914

Epoch 89: val_loss did not improve from 17.93653
196/196 - 69s - loss: 17.9393 - MinusLogProbMetric: 17.9393 - val_loss: 18.2914 - val_MinusLogProbMetric: 18.2914 - lr: 3.3333e-04 - 69s/epoch - 354ms/step
Epoch 90/1000
2023-09-26 15:31:15.306 
Epoch 90/1000 
	 loss: 17.8075, MinusLogProbMetric: 17.8075, val_loss: 17.8935, val_MinusLogProbMetric: 17.8935

Epoch 90: val_loss improved from 17.93653 to 17.89348, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 78s - loss: 17.8075 - MinusLogProbMetric: 17.8075 - val_loss: 17.8935 - val_MinusLogProbMetric: 17.8935 - lr: 3.3333e-04 - 78s/epoch - 396ms/step
Epoch 91/1000
2023-09-26 15:32:39.523 
Epoch 91/1000 
	 loss: 17.8330, MinusLogProbMetric: 17.8330, val_loss: 18.0610, val_MinusLogProbMetric: 18.0610

Epoch 91: val_loss did not improve from 17.89348
196/196 - 82s - loss: 17.8330 - MinusLogProbMetric: 17.8330 - val_loss: 18.0610 - val_MinusLogProbMetric: 18.0610 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 92/1000
2023-09-26 15:34:00.565 
Epoch 92/1000 
	 loss: 17.9415, MinusLogProbMetric: 17.9415, val_loss: 18.0306, val_MinusLogProbMetric: 18.0306

Epoch 92: val_loss did not improve from 17.89348
196/196 - 81s - loss: 17.9415 - MinusLogProbMetric: 17.9415 - val_loss: 18.0306 - val_MinusLogProbMetric: 18.0306 - lr: 3.3333e-04 - 81s/epoch - 413ms/step
Epoch 93/1000
2023-09-26 15:35:19.873 
Epoch 93/1000 
	 loss: 17.9157, MinusLogProbMetric: 17.9157, val_loss: 18.2989, val_MinusLogProbMetric: 18.2989

Epoch 93: val_loss did not improve from 17.89348
196/196 - 79s - loss: 17.9157 - MinusLogProbMetric: 17.9157 - val_loss: 18.2989 - val_MinusLogProbMetric: 18.2989 - lr: 3.3333e-04 - 79s/epoch - 405ms/step
Epoch 94/1000
2023-09-26 15:36:36.788 
Epoch 94/1000 
	 loss: 17.8320, MinusLogProbMetric: 17.8320, val_loss: 18.0210, val_MinusLogProbMetric: 18.0210

Epoch 94: val_loss did not improve from 17.89348
196/196 - 77s - loss: 17.8320 - MinusLogProbMetric: 17.8320 - val_loss: 18.0210 - val_MinusLogProbMetric: 18.0210 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 95/1000
2023-09-26 15:37:54.159 
Epoch 95/1000 
	 loss: 17.8436, MinusLogProbMetric: 17.8436, val_loss: 17.9216, val_MinusLogProbMetric: 17.9216

Epoch 95: val_loss did not improve from 17.89348
196/196 - 77s - loss: 17.8436 - MinusLogProbMetric: 17.8436 - val_loss: 17.9216 - val_MinusLogProbMetric: 17.9216 - lr: 3.3333e-04 - 77s/epoch - 395ms/step
Epoch 96/1000
2023-09-26 15:39:11.361 
Epoch 96/1000 
	 loss: 17.7776, MinusLogProbMetric: 17.7776, val_loss: 18.2339, val_MinusLogProbMetric: 18.2339

Epoch 96: val_loss did not improve from 17.89348
196/196 - 77s - loss: 17.7776 - MinusLogProbMetric: 17.7776 - val_loss: 18.2339 - val_MinusLogProbMetric: 18.2339 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 97/1000
2023-09-26 15:40:28.041 
Epoch 97/1000 
	 loss: 17.7823, MinusLogProbMetric: 17.7823, val_loss: 17.9907, val_MinusLogProbMetric: 17.9907

Epoch 97: val_loss did not improve from 17.89348
196/196 - 77s - loss: 17.7823 - MinusLogProbMetric: 17.7823 - val_loss: 17.9907 - val_MinusLogProbMetric: 17.9907 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 98/1000
2023-09-26 15:41:45.326 
Epoch 98/1000 
	 loss: 17.8014, MinusLogProbMetric: 17.8014, val_loss: 17.9716, val_MinusLogProbMetric: 17.9716

Epoch 98: val_loss did not improve from 17.89348
196/196 - 77s - loss: 17.8014 - MinusLogProbMetric: 17.8014 - val_loss: 17.9716 - val_MinusLogProbMetric: 17.9716 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 99/1000
2023-09-26 15:43:06.967 
Epoch 99/1000 
	 loss: 17.7358, MinusLogProbMetric: 17.7358, val_loss: 20.2189, val_MinusLogProbMetric: 20.2189

Epoch 99: val_loss did not improve from 17.89348
196/196 - 82s - loss: 17.7358 - MinusLogProbMetric: 17.7358 - val_loss: 20.2189 - val_MinusLogProbMetric: 20.2189 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 100/1000
2023-09-26 15:44:27.482 
Epoch 100/1000 
	 loss: 17.8822, MinusLogProbMetric: 17.8822, val_loss: 18.1749, val_MinusLogProbMetric: 18.1749

Epoch 100: val_loss did not improve from 17.89348
196/196 - 80s - loss: 17.8822 - MinusLogProbMetric: 17.8822 - val_loss: 18.1749 - val_MinusLogProbMetric: 18.1749 - lr: 3.3333e-04 - 80s/epoch - 411ms/step
Epoch 101/1000
2023-09-26 15:45:44.644 
Epoch 101/1000 
	 loss: 17.7113, MinusLogProbMetric: 17.7113, val_loss: 18.0945, val_MinusLogProbMetric: 18.0945

Epoch 101: val_loss did not improve from 17.89348
196/196 - 77s - loss: 17.7113 - MinusLogProbMetric: 17.7113 - val_loss: 18.0945 - val_MinusLogProbMetric: 18.0945 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 102/1000
2023-09-26 15:47:01.556 
Epoch 102/1000 
	 loss: 17.7805, MinusLogProbMetric: 17.7805, val_loss: 18.1659, val_MinusLogProbMetric: 18.1659

Epoch 102: val_loss did not improve from 17.89348
196/196 - 77s - loss: 17.7805 - MinusLogProbMetric: 17.7805 - val_loss: 18.1659 - val_MinusLogProbMetric: 18.1659 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 103/1000
2023-09-26 15:48:18.810 
Epoch 103/1000 
	 loss: 17.7500, MinusLogProbMetric: 17.7500, val_loss: 19.2787, val_MinusLogProbMetric: 19.2787

Epoch 103: val_loss did not improve from 17.89348
196/196 - 77s - loss: 17.7500 - MinusLogProbMetric: 17.7500 - val_loss: 19.2787 - val_MinusLogProbMetric: 19.2787 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 104/1000
2023-09-26 15:49:34.344 
Epoch 104/1000 
	 loss: 17.7911, MinusLogProbMetric: 17.7911, val_loss: 17.9605, val_MinusLogProbMetric: 17.9605

Epoch 104: val_loss did not improve from 17.89348
196/196 - 76s - loss: 17.7911 - MinusLogProbMetric: 17.7911 - val_loss: 17.9605 - val_MinusLogProbMetric: 17.9605 - lr: 3.3333e-04 - 76s/epoch - 385ms/step
Epoch 105/1000
2023-09-26 15:50:50.609 
Epoch 105/1000 
	 loss: 17.7150, MinusLogProbMetric: 17.7150, val_loss: 18.5943, val_MinusLogProbMetric: 18.5943

Epoch 105: val_loss did not improve from 17.89348
196/196 - 76s - loss: 17.7150 - MinusLogProbMetric: 17.7150 - val_loss: 18.5943 - val_MinusLogProbMetric: 18.5943 - lr: 3.3333e-04 - 76s/epoch - 389ms/step
Epoch 106/1000
2023-09-26 15:52:06.141 
Epoch 106/1000 
	 loss: 17.6384, MinusLogProbMetric: 17.6384, val_loss: 17.9815, val_MinusLogProbMetric: 17.9815

Epoch 106: val_loss did not improve from 17.89348
196/196 - 76s - loss: 17.6384 - MinusLogProbMetric: 17.6384 - val_loss: 17.9815 - val_MinusLogProbMetric: 17.9815 - lr: 3.3333e-04 - 76s/epoch - 385ms/step
Epoch 107/1000
2023-09-26 15:53:22.313 
Epoch 107/1000 
	 loss: 17.6427, MinusLogProbMetric: 17.6427, val_loss: 18.0208, val_MinusLogProbMetric: 18.0208

Epoch 107: val_loss did not improve from 17.89348
196/196 - 76s - loss: 17.6427 - MinusLogProbMetric: 17.6427 - val_loss: 18.0208 - val_MinusLogProbMetric: 18.0208 - lr: 3.3333e-04 - 76s/epoch - 388ms/step
Epoch 108/1000
2023-09-26 15:54:37.944 
Epoch 108/1000 
	 loss: 17.7638, MinusLogProbMetric: 17.7638, val_loss: 18.2385, val_MinusLogProbMetric: 18.2385

Epoch 108: val_loss did not improve from 17.89348
196/196 - 76s - loss: 17.7638 - MinusLogProbMetric: 17.7638 - val_loss: 18.2385 - val_MinusLogProbMetric: 18.2385 - lr: 3.3333e-04 - 76s/epoch - 386ms/step
Epoch 109/1000
2023-09-26 15:55:55.200 
Epoch 109/1000 
	 loss: 17.7037, MinusLogProbMetric: 17.7037, val_loss: 17.9880, val_MinusLogProbMetric: 17.9880

Epoch 109: val_loss did not improve from 17.89348
196/196 - 77s - loss: 17.7037 - MinusLogProbMetric: 17.7037 - val_loss: 17.9880 - val_MinusLogProbMetric: 17.9880 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 110/1000
2023-09-26 15:57:06.611 
Epoch 110/1000 
	 loss: 17.7595, MinusLogProbMetric: 17.7595, val_loss: 18.0382, val_MinusLogProbMetric: 18.0382

Epoch 110: val_loss did not improve from 17.89348
196/196 - 71s - loss: 17.7595 - MinusLogProbMetric: 17.7595 - val_loss: 18.0382 - val_MinusLogProbMetric: 18.0382 - lr: 3.3333e-04 - 71s/epoch - 364ms/step
Epoch 111/1000
2023-09-26 15:58:17.799 
Epoch 111/1000 
	 loss: 17.7738, MinusLogProbMetric: 17.7738, val_loss: 18.1642, val_MinusLogProbMetric: 18.1642

Epoch 111: val_loss did not improve from 17.89348
196/196 - 71s - loss: 17.7738 - MinusLogProbMetric: 17.7738 - val_loss: 18.1642 - val_MinusLogProbMetric: 18.1642 - lr: 3.3333e-04 - 71s/epoch - 363ms/step
Epoch 112/1000
2023-09-26 15:59:33.057 
Epoch 112/1000 
	 loss: 17.7298, MinusLogProbMetric: 17.7298, val_loss: 18.3275, val_MinusLogProbMetric: 18.3275

Epoch 112: val_loss did not improve from 17.89348
196/196 - 75s - loss: 17.7298 - MinusLogProbMetric: 17.7298 - val_loss: 18.3275 - val_MinusLogProbMetric: 18.3275 - lr: 3.3333e-04 - 75s/epoch - 384ms/step
Epoch 113/1000
2023-09-26 16:00:49.315 
Epoch 113/1000 
	 loss: 17.7152, MinusLogProbMetric: 17.7152, val_loss: 17.8515, val_MinusLogProbMetric: 17.8515

Epoch 113: val_loss improved from 17.89348 to 17.85154, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 78s - loss: 17.7152 - MinusLogProbMetric: 17.7152 - val_loss: 17.8515 - val_MinusLogProbMetric: 17.8515 - lr: 3.3333e-04 - 78s/epoch - 397ms/step
Epoch 114/1000
2023-09-26 16:02:07.002 
Epoch 114/1000 
	 loss: 17.7179, MinusLogProbMetric: 17.7179, val_loss: 18.0271, val_MinusLogProbMetric: 18.0271

Epoch 114: val_loss did not improve from 17.85154
196/196 - 76s - loss: 17.7179 - MinusLogProbMetric: 17.7179 - val_loss: 18.0271 - val_MinusLogProbMetric: 18.0271 - lr: 3.3333e-04 - 76s/epoch - 389ms/step
Epoch 115/1000
2023-09-26 16:03:23.096 
Epoch 115/1000 
	 loss: 17.6014, MinusLogProbMetric: 17.6014, val_loss: 18.1271, val_MinusLogProbMetric: 18.1271

Epoch 115: val_loss did not improve from 17.85154
196/196 - 76s - loss: 17.6014 - MinusLogProbMetric: 17.6014 - val_loss: 18.1271 - val_MinusLogProbMetric: 18.1271 - lr: 3.3333e-04 - 76s/epoch - 388ms/step
Epoch 116/1000
2023-09-26 16:04:39.539 
Epoch 116/1000 
	 loss: 17.7014, MinusLogProbMetric: 17.7014, val_loss: 17.9989, val_MinusLogProbMetric: 17.9989

Epoch 116: val_loss did not improve from 17.85154
196/196 - 76s - loss: 17.7014 - MinusLogProbMetric: 17.7014 - val_loss: 17.9989 - val_MinusLogProbMetric: 17.9989 - lr: 3.3333e-04 - 76s/epoch - 390ms/step
Epoch 117/1000
2023-09-26 16:05:55.926 
Epoch 117/1000 
	 loss: 17.6216, MinusLogProbMetric: 17.6216, val_loss: 18.6756, val_MinusLogProbMetric: 18.6756

Epoch 117: val_loss did not improve from 17.85154
196/196 - 76s - loss: 17.6216 - MinusLogProbMetric: 17.6216 - val_loss: 18.6756 - val_MinusLogProbMetric: 18.6756 - lr: 3.3333e-04 - 76s/epoch - 390ms/step
Epoch 118/1000
2023-09-26 16:07:11.667 
Epoch 118/1000 
	 loss: 17.6648, MinusLogProbMetric: 17.6648, val_loss: 17.9680, val_MinusLogProbMetric: 17.9680

Epoch 118: val_loss did not improve from 17.85154
196/196 - 76s - loss: 17.6648 - MinusLogProbMetric: 17.6648 - val_loss: 17.9680 - val_MinusLogProbMetric: 17.9680 - lr: 3.3333e-04 - 76s/epoch - 386ms/step
Epoch 119/1000
2023-09-26 16:08:28.583 
Epoch 119/1000 
	 loss: 17.7236, MinusLogProbMetric: 17.7236, val_loss: 18.4551, val_MinusLogProbMetric: 18.4551

Epoch 119: val_loss did not improve from 17.85154
196/196 - 77s - loss: 17.7236 - MinusLogProbMetric: 17.7236 - val_loss: 18.4551 - val_MinusLogProbMetric: 18.4551 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 120/1000
2023-09-26 16:09:45.518 
Epoch 120/1000 
	 loss: 17.6226, MinusLogProbMetric: 17.6226, val_loss: 17.9638, val_MinusLogProbMetric: 17.9638

Epoch 120: val_loss did not improve from 17.85154
196/196 - 77s - loss: 17.6226 - MinusLogProbMetric: 17.6226 - val_loss: 17.9638 - val_MinusLogProbMetric: 17.9638 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 121/1000
2023-09-26 16:11:02.567 
Epoch 121/1000 
	 loss: 17.6330, MinusLogProbMetric: 17.6330, val_loss: 18.1537, val_MinusLogProbMetric: 18.1537

Epoch 121: val_loss did not improve from 17.85154
196/196 - 77s - loss: 17.6330 - MinusLogProbMetric: 17.6330 - val_loss: 18.1537 - val_MinusLogProbMetric: 18.1537 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 122/1000
2023-09-26 16:12:18.630 
Epoch 122/1000 
	 loss: 17.5706, MinusLogProbMetric: 17.5706, val_loss: 18.0108, val_MinusLogProbMetric: 18.0108

Epoch 122: val_loss did not improve from 17.85154
196/196 - 76s - loss: 17.5706 - MinusLogProbMetric: 17.5706 - val_loss: 18.0108 - val_MinusLogProbMetric: 18.0108 - lr: 3.3333e-04 - 76s/epoch - 388ms/step
Epoch 123/1000
2023-09-26 16:13:34.530 
Epoch 123/1000 
	 loss: 17.5856, MinusLogProbMetric: 17.5856, val_loss: 18.1876, val_MinusLogProbMetric: 18.1876

Epoch 123: val_loss did not improve from 17.85154
196/196 - 76s - loss: 17.5856 - MinusLogProbMetric: 17.5856 - val_loss: 18.1876 - val_MinusLogProbMetric: 18.1876 - lr: 3.3333e-04 - 76s/epoch - 387ms/step
Epoch 124/1000
2023-09-26 16:14:51.656 
Epoch 124/1000 
	 loss: 17.6347, MinusLogProbMetric: 17.6347, val_loss: 19.0543, val_MinusLogProbMetric: 19.0543

Epoch 124: val_loss did not improve from 17.85154
196/196 - 77s - loss: 17.6347 - MinusLogProbMetric: 17.6347 - val_loss: 19.0543 - val_MinusLogProbMetric: 19.0543 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 125/1000
2023-09-26 16:16:09.043 
Epoch 125/1000 
	 loss: 17.5956, MinusLogProbMetric: 17.5956, val_loss: 17.9287, val_MinusLogProbMetric: 17.9287

Epoch 125: val_loss did not improve from 17.85154
196/196 - 77s - loss: 17.5956 - MinusLogProbMetric: 17.5956 - val_loss: 17.9287 - val_MinusLogProbMetric: 17.9287 - lr: 3.3333e-04 - 77s/epoch - 395ms/step
Epoch 126/1000
2023-09-26 16:17:25.171 
Epoch 126/1000 
	 loss: 17.5445, MinusLogProbMetric: 17.5445, val_loss: 18.0537, val_MinusLogProbMetric: 18.0537

Epoch 126: val_loss did not improve from 17.85154
196/196 - 76s - loss: 17.5445 - MinusLogProbMetric: 17.5445 - val_loss: 18.0537 - val_MinusLogProbMetric: 18.0537 - lr: 3.3333e-04 - 76s/epoch - 388ms/step
Epoch 127/1000
2023-09-26 16:18:41.884 
Epoch 127/1000 
	 loss: 17.5185, MinusLogProbMetric: 17.5185, val_loss: 18.2061, val_MinusLogProbMetric: 18.2061

Epoch 127: val_loss did not improve from 17.85154
196/196 - 77s - loss: 17.5185 - MinusLogProbMetric: 17.5185 - val_loss: 18.2061 - val_MinusLogProbMetric: 18.2061 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 128/1000
2023-09-26 16:19:59.043 
Epoch 128/1000 
	 loss: 17.5714, MinusLogProbMetric: 17.5714, val_loss: 18.0815, val_MinusLogProbMetric: 18.0815

Epoch 128: val_loss did not improve from 17.85154
196/196 - 77s - loss: 17.5714 - MinusLogProbMetric: 17.5714 - val_loss: 18.0815 - val_MinusLogProbMetric: 18.0815 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 129/1000
2023-09-26 16:21:16.080 
Epoch 129/1000 
	 loss: 17.5210, MinusLogProbMetric: 17.5210, val_loss: 18.3086, val_MinusLogProbMetric: 18.3086

Epoch 129: val_loss did not improve from 17.85154
196/196 - 77s - loss: 17.5210 - MinusLogProbMetric: 17.5210 - val_loss: 18.3086 - val_MinusLogProbMetric: 18.3086 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 130/1000
2023-09-26 16:22:32.992 
Epoch 130/1000 
	 loss: 17.5182, MinusLogProbMetric: 17.5182, val_loss: 18.5603, val_MinusLogProbMetric: 18.5603

Epoch 130: val_loss did not improve from 17.85154
196/196 - 77s - loss: 17.5182 - MinusLogProbMetric: 17.5182 - val_loss: 18.5603 - val_MinusLogProbMetric: 18.5603 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 131/1000
2023-09-26 16:23:50.180 
Epoch 131/1000 
	 loss: 17.5520, MinusLogProbMetric: 17.5520, val_loss: 17.8898, val_MinusLogProbMetric: 17.8898

Epoch 131: val_loss did not improve from 17.85154
196/196 - 77s - loss: 17.5520 - MinusLogProbMetric: 17.5520 - val_loss: 17.8898 - val_MinusLogProbMetric: 17.8898 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 132/1000
2023-09-26 16:25:06.665 
Epoch 132/1000 
	 loss: 17.5465, MinusLogProbMetric: 17.5465, val_loss: 18.1093, val_MinusLogProbMetric: 18.1093

Epoch 132: val_loss did not improve from 17.85154
196/196 - 76s - loss: 17.5465 - MinusLogProbMetric: 17.5465 - val_loss: 18.1093 - val_MinusLogProbMetric: 18.1093 - lr: 3.3333e-04 - 76s/epoch - 390ms/step
Epoch 133/1000
2023-09-26 16:26:24.502 
Epoch 133/1000 
	 loss: 17.4447, MinusLogProbMetric: 17.4447, val_loss: 18.0438, val_MinusLogProbMetric: 18.0438

Epoch 133: val_loss did not improve from 17.85154
196/196 - 78s - loss: 17.4447 - MinusLogProbMetric: 17.4447 - val_loss: 18.0438 - val_MinusLogProbMetric: 18.0438 - lr: 3.3333e-04 - 78s/epoch - 397ms/step
Epoch 134/1000
2023-09-26 16:27:41.773 
Epoch 134/1000 
	 loss: 17.5070, MinusLogProbMetric: 17.5070, val_loss: 17.8999, val_MinusLogProbMetric: 17.8999

Epoch 134: val_loss did not improve from 17.85154
196/196 - 77s - loss: 17.5070 - MinusLogProbMetric: 17.5070 - val_loss: 17.8999 - val_MinusLogProbMetric: 17.8999 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 135/1000
2023-09-26 16:28:58.573 
Epoch 135/1000 
	 loss: 17.5565, MinusLogProbMetric: 17.5565, val_loss: 17.9067, val_MinusLogProbMetric: 17.9067

Epoch 135: val_loss did not improve from 17.85154
196/196 - 77s - loss: 17.5565 - MinusLogProbMetric: 17.5565 - val_loss: 17.9067 - val_MinusLogProbMetric: 17.9067 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 136/1000
2023-09-26 16:30:14.774 
Epoch 136/1000 
	 loss: 17.5949, MinusLogProbMetric: 17.5949, val_loss: 17.8956, val_MinusLogProbMetric: 17.8956

Epoch 136: val_loss did not improve from 17.85154
196/196 - 76s - loss: 17.5949 - MinusLogProbMetric: 17.5949 - val_loss: 17.8956 - val_MinusLogProbMetric: 17.8956 - lr: 3.3333e-04 - 76s/epoch - 389ms/step
Epoch 137/1000
2023-09-26 16:31:31.984 
Epoch 137/1000 
	 loss: 17.5138, MinusLogProbMetric: 17.5138, val_loss: 18.1758, val_MinusLogProbMetric: 18.1758

Epoch 137: val_loss did not improve from 17.85154
196/196 - 77s - loss: 17.5138 - MinusLogProbMetric: 17.5138 - val_loss: 18.1758 - val_MinusLogProbMetric: 18.1758 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 138/1000
2023-09-26 16:32:48.724 
Epoch 138/1000 
	 loss: 17.4476, MinusLogProbMetric: 17.4476, val_loss: 17.9768, val_MinusLogProbMetric: 17.9768

Epoch 138: val_loss did not improve from 17.85154
196/196 - 77s - loss: 17.4476 - MinusLogProbMetric: 17.4476 - val_loss: 17.9768 - val_MinusLogProbMetric: 17.9768 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 139/1000
2023-09-26 16:34:04.267 
Epoch 139/1000 
	 loss: 17.5948, MinusLogProbMetric: 17.5948, val_loss: 18.4819, val_MinusLogProbMetric: 18.4819

Epoch 139: val_loss did not improve from 17.85154
196/196 - 76s - loss: 17.5948 - MinusLogProbMetric: 17.5948 - val_loss: 18.4819 - val_MinusLogProbMetric: 18.4819 - lr: 3.3333e-04 - 76s/epoch - 385ms/step
Epoch 140/1000
2023-09-26 16:35:21.112 
Epoch 140/1000 
	 loss: 17.4889, MinusLogProbMetric: 17.4889, val_loss: 17.8672, val_MinusLogProbMetric: 17.8672

Epoch 140: val_loss did not improve from 17.85154
196/196 - 77s - loss: 17.4889 - MinusLogProbMetric: 17.4889 - val_loss: 17.8672 - val_MinusLogProbMetric: 17.8672 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 141/1000
2023-09-26 16:36:38.203 
Epoch 141/1000 
	 loss: 17.5677, MinusLogProbMetric: 17.5677, val_loss: 17.8339, val_MinusLogProbMetric: 17.8339

Epoch 141: val_loss improved from 17.85154 to 17.83389, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 78s - loss: 17.5677 - MinusLogProbMetric: 17.5677 - val_loss: 17.8339 - val_MinusLogProbMetric: 17.8339 - lr: 3.3333e-04 - 78s/epoch - 400ms/step
Epoch 142/1000
2023-09-26 16:37:56.019 
Epoch 142/1000 
	 loss: 17.4481, MinusLogProbMetric: 17.4481, val_loss: 18.8435, val_MinusLogProbMetric: 18.8435

Epoch 142: val_loss did not improve from 17.83389
196/196 - 76s - loss: 17.4481 - MinusLogProbMetric: 17.4481 - val_loss: 18.8435 - val_MinusLogProbMetric: 18.8435 - lr: 3.3333e-04 - 76s/epoch - 390ms/step
Epoch 143/1000
2023-09-26 16:39:11.783 
Epoch 143/1000 
	 loss: 17.4225, MinusLogProbMetric: 17.4225, val_loss: 17.6863, val_MinusLogProbMetric: 17.6863

Epoch 143: val_loss improved from 17.83389 to 17.68629, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 77s - loss: 17.4225 - MinusLogProbMetric: 17.4225 - val_loss: 17.6863 - val_MinusLogProbMetric: 17.6863 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 144/1000
2023-09-26 16:40:29.719 
Epoch 144/1000 
	 loss: 17.4472, MinusLogProbMetric: 17.4472, val_loss: 18.7760, val_MinusLogProbMetric: 18.7760

Epoch 144: val_loss did not improve from 17.68629
196/196 - 77s - loss: 17.4472 - MinusLogProbMetric: 17.4472 - val_loss: 18.7760 - val_MinusLogProbMetric: 18.7760 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 145/1000
2023-09-26 16:41:46.428 
Epoch 145/1000 
	 loss: 17.4510, MinusLogProbMetric: 17.4510, val_loss: 17.6813, val_MinusLogProbMetric: 17.6813

Epoch 145: val_loss improved from 17.68629 to 17.68128, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 78s - loss: 17.4510 - MinusLogProbMetric: 17.4510 - val_loss: 17.6813 - val_MinusLogProbMetric: 17.6813 - lr: 3.3333e-04 - 78s/epoch - 399ms/step
Epoch 146/1000
2023-09-26 16:43:03.880 
Epoch 146/1000 
	 loss: 17.4308, MinusLogProbMetric: 17.4308, val_loss: 17.7534, val_MinusLogProbMetric: 17.7534

Epoch 146: val_loss did not improve from 17.68128
196/196 - 76s - loss: 17.4308 - MinusLogProbMetric: 17.4308 - val_loss: 17.7534 - val_MinusLogProbMetric: 17.7534 - lr: 3.3333e-04 - 76s/epoch - 387ms/step
Epoch 147/1000
2023-09-26 16:44:20.815 
Epoch 147/1000 
	 loss: 17.4659, MinusLogProbMetric: 17.4659, val_loss: 18.3569, val_MinusLogProbMetric: 18.3569

Epoch 147: val_loss did not improve from 17.68128
196/196 - 77s - loss: 17.4659 - MinusLogProbMetric: 17.4659 - val_loss: 18.3569 - val_MinusLogProbMetric: 18.3569 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 148/1000
2023-09-26 16:45:37.016 
Epoch 148/1000 
	 loss: 17.4024, MinusLogProbMetric: 17.4024, val_loss: 18.1368, val_MinusLogProbMetric: 18.1368

Epoch 148: val_loss did not improve from 17.68128
196/196 - 76s - loss: 17.4024 - MinusLogProbMetric: 17.4024 - val_loss: 18.1368 - val_MinusLogProbMetric: 18.1368 - lr: 3.3333e-04 - 76s/epoch - 389ms/step
Epoch 149/1000
2023-09-26 16:46:53.487 
Epoch 149/1000 
	 loss: 17.4287, MinusLogProbMetric: 17.4287, val_loss: 19.6547, val_MinusLogProbMetric: 19.6547

Epoch 149: val_loss did not improve from 17.68128
196/196 - 76s - loss: 17.4287 - MinusLogProbMetric: 17.4287 - val_loss: 19.6547 - val_MinusLogProbMetric: 19.6547 - lr: 3.3333e-04 - 76s/epoch - 390ms/step
Epoch 150/1000
2023-09-26 16:48:10.766 
Epoch 150/1000 
	 loss: 17.4779, MinusLogProbMetric: 17.4779, val_loss: 17.9293, val_MinusLogProbMetric: 17.9293

Epoch 150: val_loss did not improve from 17.68128
196/196 - 77s - loss: 17.4779 - MinusLogProbMetric: 17.4779 - val_loss: 17.9293 - val_MinusLogProbMetric: 17.9293 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 151/1000
2023-09-26 16:49:27.586 
Epoch 151/1000 
	 loss: 17.4076, MinusLogProbMetric: 17.4076, val_loss: 18.2277, val_MinusLogProbMetric: 18.2277

Epoch 151: val_loss did not improve from 17.68128
196/196 - 77s - loss: 17.4076 - MinusLogProbMetric: 17.4076 - val_loss: 18.2277 - val_MinusLogProbMetric: 18.2277 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 152/1000
2023-09-26 16:50:44.200 
Epoch 152/1000 
	 loss: 17.3935, MinusLogProbMetric: 17.3935, val_loss: 17.8582, val_MinusLogProbMetric: 17.8582

Epoch 152: val_loss did not improve from 17.68128
196/196 - 77s - loss: 17.3935 - MinusLogProbMetric: 17.3935 - val_loss: 17.8582 - val_MinusLogProbMetric: 17.8582 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 153/1000
2023-09-26 16:52:00.321 
Epoch 153/1000 
	 loss: 17.3622, MinusLogProbMetric: 17.3622, val_loss: 18.0451, val_MinusLogProbMetric: 18.0451

Epoch 153: val_loss did not improve from 17.68128
196/196 - 76s - loss: 17.3622 - MinusLogProbMetric: 17.3622 - val_loss: 18.0451 - val_MinusLogProbMetric: 18.0451 - lr: 3.3333e-04 - 76s/epoch - 388ms/step
Epoch 154/1000
2023-09-26 16:53:17.413 
Epoch 154/1000 
	 loss: 17.4211, MinusLogProbMetric: 17.4211, val_loss: 18.3542, val_MinusLogProbMetric: 18.3542

Epoch 154: val_loss did not improve from 17.68128
196/196 - 77s - loss: 17.4211 - MinusLogProbMetric: 17.4211 - val_loss: 18.3542 - val_MinusLogProbMetric: 18.3542 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 155/1000
2023-09-26 16:54:34.309 
Epoch 155/1000 
	 loss: 17.3922, MinusLogProbMetric: 17.3922, val_loss: 17.9939, val_MinusLogProbMetric: 17.9939

Epoch 155: val_loss did not improve from 17.68128
196/196 - 77s - loss: 17.3922 - MinusLogProbMetric: 17.3922 - val_loss: 17.9939 - val_MinusLogProbMetric: 17.9939 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 156/1000
2023-09-26 16:55:51.055 
Epoch 156/1000 
	 loss: 17.3784, MinusLogProbMetric: 17.3784, val_loss: 18.1325, val_MinusLogProbMetric: 18.1325

Epoch 156: val_loss did not improve from 17.68128
196/196 - 77s - loss: 17.3784 - MinusLogProbMetric: 17.3784 - val_loss: 18.1325 - val_MinusLogProbMetric: 18.1325 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 157/1000
2023-09-26 16:57:07.780 
Epoch 157/1000 
	 loss: 17.3997, MinusLogProbMetric: 17.3997, val_loss: 17.8307, val_MinusLogProbMetric: 17.8307

Epoch 157: val_loss did not improve from 17.68128
196/196 - 77s - loss: 17.3997 - MinusLogProbMetric: 17.3997 - val_loss: 17.8307 - val_MinusLogProbMetric: 17.8307 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 158/1000
2023-09-26 16:58:24.439 
Epoch 158/1000 
	 loss: 17.4937, MinusLogProbMetric: 17.4937, val_loss: 17.8707, val_MinusLogProbMetric: 17.8707

Epoch 158: val_loss did not improve from 17.68128
196/196 - 77s - loss: 17.4937 - MinusLogProbMetric: 17.4937 - val_loss: 17.8707 - val_MinusLogProbMetric: 17.8707 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 159/1000
2023-09-26 16:59:39.939 
Epoch 159/1000 
	 loss: 17.4242, MinusLogProbMetric: 17.4242, val_loss: 17.9885, val_MinusLogProbMetric: 17.9885

Epoch 159: val_loss did not improve from 17.68128
196/196 - 75s - loss: 17.4242 - MinusLogProbMetric: 17.4242 - val_loss: 17.9885 - val_MinusLogProbMetric: 17.9885 - lr: 3.3333e-04 - 75s/epoch - 385ms/step
Epoch 160/1000
2023-09-26 17:00:56.184 
Epoch 160/1000 
	 loss: 17.3554, MinusLogProbMetric: 17.3554, val_loss: 18.3116, val_MinusLogProbMetric: 18.3116

Epoch 160: val_loss did not improve from 17.68128
196/196 - 76s - loss: 17.3554 - MinusLogProbMetric: 17.3554 - val_loss: 18.3116 - val_MinusLogProbMetric: 18.3116 - lr: 3.3333e-04 - 76s/epoch - 389ms/step
Epoch 161/1000
2023-09-26 17:02:12.921 
Epoch 161/1000 
	 loss: 17.4330, MinusLogProbMetric: 17.4330, val_loss: 17.7938, val_MinusLogProbMetric: 17.7938

Epoch 161: val_loss did not improve from 17.68128
196/196 - 77s - loss: 17.4330 - MinusLogProbMetric: 17.4330 - val_loss: 17.7938 - val_MinusLogProbMetric: 17.7938 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 162/1000
2023-09-26 17:03:29.215 
Epoch 162/1000 
	 loss: 17.3723, MinusLogProbMetric: 17.3723, val_loss: 17.9121, val_MinusLogProbMetric: 17.9121

Epoch 162: val_loss did not improve from 17.68128
196/196 - 76s - loss: 17.3723 - MinusLogProbMetric: 17.3723 - val_loss: 17.9121 - val_MinusLogProbMetric: 17.9121 - lr: 3.3333e-04 - 76s/epoch - 389ms/step
Epoch 163/1000
2023-09-26 17:04:46.632 
Epoch 163/1000 
	 loss: 17.3986, MinusLogProbMetric: 17.3986, val_loss: 17.8261, val_MinusLogProbMetric: 17.8261

Epoch 163: val_loss did not improve from 17.68128
196/196 - 77s - loss: 17.3986 - MinusLogProbMetric: 17.3986 - val_loss: 17.8261 - val_MinusLogProbMetric: 17.8261 - lr: 3.3333e-04 - 77s/epoch - 395ms/step
Epoch 164/1000
2023-09-26 17:06:03.293 
Epoch 164/1000 
	 loss: 17.3093, MinusLogProbMetric: 17.3093, val_loss: 17.7402, val_MinusLogProbMetric: 17.7402

Epoch 164: val_loss did not improve from 17.68128
196/196 - 77s - loss: 17.3093 - MinusLogProbMetric: 17.3093 - val_loss: 17.7402 - val_MinusLogProbMetric: 17.7402 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 165/1000
2023-09-26 17:07:19.964 
Epoch 165/1000 
	 loss: 17.3398, MinusLogProbMetric: 17.3398, val_loss: 17.9235, val_MinusLogProbMetric: 17.9235

Epoch 165: val_loss did not improve from 17.68128
196/196 - 77s - loss: 17.3398 - MinusLogProbMetric: 17.3398 - val_loss: 17.9235 - val_MinusLogProbMetric: 17.9235 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 166/1000
2023-09-26 17:08:36.959 
Epoch 166/1000 
	 loss: 17.3145, MinusLogProbMetric: 17.3145, val_loss: 18.4096, val_MinusLogProbMetric: 18.4096

Epoch 166: val_loss did not improve from 17.68128
196/196 - 77s - loss: 17.3145 - MinusLogProbMetric: 17.3145 - val_loss: 18.4096 - val_MinusLogProbMetric: 18.4096 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 167/1000
2023-09-26 17:09:53.668 
Epoch 167/1000 
	 loss: 17.3999, MinusLogProbMetric: 17.3999, val_loss: 19.0909, val_MinusLogProbMetric: 19.0909

Epoch 167: val_loss did not improve from 17.68128
196/196 - 77s - loss: 17.3999 - MinusLogProbMetric: 17.3999 - val_loss: 19.0909 - val_MinusLogProbMetric: 19.0909 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 168/1000
2023-09-26 17:11:09.986 
Epoch 168/1000 
	 loss: 17.3753, MinusLogProbMetric: 17.3753, val_loss: 17.7007, val_MinusLogProbMetric: 17.7007

Epoch 168: val_loss did not improve from 17.68128
196/196 - 76s - loss: 17.3753 - MinusLogProbMetric: 17.3753 - val_loss: 17.7007 - val_MinusLogProbMetric: 17.7007 - lr: 3.3333e-04 - 76s/epoch - 389ms/step
Epoch 169/1000
2023-09-26 17:12:26.711 
Epoch 169/1000 
	 loss: 17.3156, MinusLogProbMetric: 17.3156, val_loss: 18.0670, val_MinusLogProbMetric: 18.0670

Epoch 169: val_loss did not improve from 17.68128
196/196 - 77s - loss: 17.3156 - MinusLogProbMetric: 17.3156 - val_loss: 18.0670 - val_MinusLogProbMetric: 18.0670 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 170/1000
2023-09-26 17:13:43.787 
Epoch 170/1000 
	 loss: 17.2989, MinusLogProbMetric: 17.2989, val_loss: 17.6879, val_MinusLogProbMetric: 17.6879

Epoch 170: val_loss did not improve from 17.68128
196/196 - 77s - loss: 17.2989 - MinusLogProbMetric: 17.2989 - val_loss: 17.6879 - val_MinusLogProbMetric: 17.6879 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 171/1000
2023-09-26 17:14:59.747 
Epoch 171/1000 
	 loss: 17.3142, MinusLogProbMetric: 17.3142, val_loss: 17.7617, val_MinusLogProbMetric: 17.7617

Epoch 171: val_loss did not improve from 17.68128
196/196 - 76s - loss: 17.3142 - MinusLogProbMetric: 17.3142 - val_loss: 17.7617 - val_MinusLogProbMetric: 17.7617 - lr: 3.3333e-04 - 76s/epoch - 388ms/step
Epoch 172/1000
2023-09-26 17:16:16.042 
Epoch 172/1000 
	 loss: 17.3421, MinusLogProbMetric: 17.3421, val_loss: 17.7725, val_MinusLogProbMetric: 17.7725

Epoch 172: val_loss did not improve from 17.68128
196/196 - 76s - loss: 17.3421 - MinusLogProbMetric: 17.3421 - val_loss: 17.7725 - val_MinusLogProbMetric: 17.7725 - lr: 3.3333e-04 - 76s/epoch - 389ms/step
Epoch 173/1000
2023-09-26 17:17:32.988 
Epoch 173/1000 
	 loss: 17.3116, MinusLogProbMetric: 17.3116, val_loss: 17.8652, val_MinusLogProbMetric: 17.8652

Epoch 173: val_loss did not improve from 17.68128
196/196 - 77s - loss: 17.3116 - MinusLogProbMetric: 17.3116 - val_loss: 17.8652 - val_MinusLogProbMetric: 17.8652 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 174/1000
2023-09-26 17:18:49.450 
Epoch 174/1000 
	 loss: 17.2676, MinusLogProbMetric: 17.2676, val_loss: 17.9300, val_MinusLogProbMetric: 17.9300

Epoch 174: val_loss did not improve from 17.68128
196/196 - 76s - loss: 17.2676 - MinusLogProbMetric: 17.2676 - val_loss: 17.9300 - val_MinusLogProbMetric: 17.9300 - lr: 3.3333e-04 - 76s/epoch - 390ms/step
Epoch 175/1000
2023-09-26 17:20:05.810 
Epoch 175/1000 
	 loss: 17.3229, MinusLogProbMetric: 17.3229, val_loss: 17.5500, val_MinusLogProbMetric: 17.5500

Epoch 175: val_loss improved from 17.68128 to 17.54995, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 78s - loss: 17.3229 - MinusLogProbMetric: 17.3229 - val_loss: 17.5500 - val_MinusLogProbMetric: 17.5500 - lr: 3.3333e-04 - 78s/epoch - 397ms/step
Epoch 176/1000
2023-09-26 17:21:24.209 
Epoch 176/1000 
	 loss: 17.3556, MinusLogProbMetric: 17.3556, val_loss: 17.7434, val_MinusLogProbMetric: 17.7434

Epoch 176: val_loss did not improve from 17.54995
196/196 - 77s - loss: 17.3556 - MinusLogProbMetric: 17.3556 - val_loss: 17.7434 - val_MinusLogProbMetric: 17.7434 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 177/1000
2023-09-26 17:22:41.000 
Epoch 177/1000 
	 loss: 17.2974, MinusLogProbMetric: 17.2974, val_loss: 17.7929, val_MinusLogProbMetric: 17.7929

Epoch 177: val_loss did not improve from 17.54995
196/196 - 77s - loss: 17.2974 - MinusLogProbMetric: 17.2974 - val_loss: 17.7929 - val_MinusLogProbMetric: 17.7929 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 178/1000
2023-09-26 17:23:57.934 
Epoch 178/1000 
	 loss: 17.2682, MinusLogProbMetric: 17.2682, val_loss: 17.9035, val_MinusLogProbMetric: 17.9035

Epoch 178: val_loss did not improve from 17.54995
196/196 - 77s - loss: 17.2682 - MinusLogProbMetric: 17.2682 - val_loss: 17.9035 - val_MinusLogProbMetric: 17.9035 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 179/1000
2023-09-26 17:25:14.949 
Epoch 179/1000 
	 loss: 17.3487, MinusLogProbMetric: 17.3487, val_loss: 18.0039, val_MinusLogProbMetric: 18.0039

Epoch 179: val_loss did not improve from 17.54995
196/196 - 77s - loss: 17.3487 - MinusLogProbMetric: 17.3487 - val_loss: 18.0039 - val_MinusLogProbMetric: 18.0039 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 180/1000
2023-09-26 17:26:32.386 
Epoch 180/1000 
	 loss: 17.2470, MinusLogProbMetric: 17.2470, val_loss: 17.6295, val_MinusLogProbMetric: 17.6295

Epoch 180: val_loss did not improve from 17.54995
196/196 - 77s - loss: 17.2470 - MinusLogProbMetric: 17.2470 - val_loss: 17.6295 - val_MinusLogProbMetric: 17.6295 - lr: 3.3333e-04 - 77s/epoch - 395ms/step
Epoch 181/1000
2023-09-26 17:27:48.615 
Epoch 181/1000 
	 loss: 17.2286, MinusLogProbMetric: 17.2286, val_loss: 17.8029, val_MinusLogProbMetric: 17.8029

Epoch 181: val_loss did not improve from 17.54995
196/196 - 76s - loss: 17.2286 - MinusLogProbMetric: 17.2286 - val_loss: 17.8029 - val_MinusLogProbMetric: 17.8029 - lr: 3.3333e-04 - 76s/epoch - 389ms/step
Epoch 182/1000
2023-09-26 17:29:05.654 
Epoch 182/1000 
	 loss: 17.2593, MinusLogProbMetric: 17.2593, val_loss: 18.1834, val_MinusLogProbMetric: 18.1834

Epoch 182: val_loss did not improve from 17.54995
196/196 - 77s - loss: 17.2593 - MinusLogProbMetric: 17.2593 - val_loss: 18.1834 - val_MinusLogProbMetric: 18.1834 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 183/1000
2023-09-26 17:30:22.582 
Epoch 183/1000 
	 loss: 17.3536, MinusLogProbMetric: 17.3536, val_loss: 17.9031, val_MinusLogProbMetric: 17.9031

Epoch 183: val_loss did not improve from 17.54995
196/196 - 77s - loss: 17.3536 - MinusLogProbMetric: 17.3536 - val_loss: 17.9031 - val_MinusLogProbMetric: 17.9031 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 184/1000
2023-09-26 17:31:39.803 
Epoch 184/1000 
	 loss: 17.2745, MinusLogProbMetric: 17.2745, val_loss: 17.8782, val_MinusLogProbMetric: 17.8782

Epoch 184: val_loss did not improve from 17.54995
196/196 - 77s - loss: 17.2745 - MinusLogProbMetric: 17.2745 - val_loss: 17.8782 - val_MinusLogProbMetric: 17.8782 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 185/1000
2023-09-26 17:32:56.815 
Epoch 185/1000 
	 loss: 17.2689, MinusLogProbMetric: 17.2689, val_loss: 17.7252, val_MinusLogProbMetric: 17.7252

Epoch 185: val_loss did not improve from 17.54995
196/196 - 77s - loss: 17.2689 - MinusLogProbMetric: 17.2689 - val_loss: 17.7252 - val_MinusLogProbMetric: 17.7252 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 186/1000
2023-09-26 17:34:14.001 
Epoch 186/1000 
	 loss: 17.2030, MinusLogProbMetric: 17.2030, val_loss: 17.8780, val_MinusLogProbMetric: 17.8780

Epoch 186: val_loss did not improve from 17.54995
196/196 - 77s - loss: 17.2030 - MinusLogProbMetric: 17.2030 - val_loss: 17.8780 - val_MinusLogProbMetric: 17.8780 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 187/1000
2023-09-26 17:35:30.720 
Epoch 187/1000 
	 loss: 17.2501, MinusLogProbMetric: 17.2501, val_loss: 17.6977, val_MinusLogProbMetric: 17.6977

Epoch 187: val_loss did not improve from 17.54995
196/196 - 77s - loss: 17.2501 - MinusLogProbMetric: 17.2501 - val_loss: 17.6977 - val_MinusLogProbMetric: 17.6977 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 188/1000
2023-09-26 17:36:47.128 
Epoch 188/1000 
	 loss: 17.2441, MinusLogProbMetric: 17.2441, val_loss: 18.0901, val_MinusLogProbMetric: 18.0901

Epoch 188: val_loss did not improve from 17.54995
196/196 - 76s - loss: 17.2441 - MinusLogProbMetric: 17.2441 - val_loss: 18.0901 - val_MinusLogProbMetric: 18.0901 - lr: 3.3333e-04 - 76s/epoch - 390ms/step
Epoch 189/1000
2023-09-26 17:38:03.984 
Epoch 189/1000 
	 loss: 17.2537, MinusLogProbMetric: 17.2537, val_loss: 17.7308, val_MinusLogProbMetric: 17.7308

Epoch 189: val_loss did not improve from 17.54995
196/196 - 77s - loss: 17.2537 - MinusLogProbMetric: 17.2537 - val_loss: 17.7308 - val_MinusLogProbMetric: 17.7308 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 190/1000
2023-09-26 17:39:20.570 
Epoch 190/1000 
	 loss: 17.2284, MinusLogProbMetric: 17.2284, val_loss: 17.8991, val_MinusLogProbMetric: 17.8991

Epoch 190: val_loss did not improve from 17.54995
196/196 - 77s - loss: 17.2284 - MinusLogProbMetric: 17.2284 - val_loss: 17.8991 - val_MinusLogProbMetric: 17.8991 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 191/1000
2023-09-26 17:40:37.659 
Epoch 191/1000 
	 loss: 17.2166, MinusLogProbMetric: 17.2166, val_loss: 17.7084, val_MinusLogProbMetric: 17.7084

Epoch 191: val_loss did not improve from 17.54995
196/196 - 77s - loss: 17.2166 - MinusLogProbMetric: 17.2166 - val_loss: 17.7084 - val_MinusLogProbMetric: 17.7084 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 192/1000
2023-09-26 17:41:54.394 
Epoch 192/1000 
	 loss: 17.1808, MinusLogProbMetric: 17.1808, val_loss: 17.8253, val_MinusLogProbMetric: 17.8253

Epoch 192: val_loss did not improve from 17.54995
196/196 - 77s - loss: 17.1808 - MinusLogProbMetric: 17.1808 - val_loss: 17.8253 - val_MinusLogProbMetric: 17.8253 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 193/1000
2023-09-26 17:43:11.394 
Epoch 193/1000 
	 loss: 17.1846, MinusLogProbMetric: 17.1846, val_loss: 19.1673, val_MinusLogProbMetric: 19.1673

Epoch 193: val_loss did not improve from 17.54995
196/196 - 77s - loss: 17.1846 - MinusLogProbMetric: 17.1846 - val_loss: 19.1673 - val_MinusLogProbMetric: 19.1673 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 194/1000
2023-09-26 17:44:27.697 
Epoch 194/1000 
	 loss: 17.1841, MinusLogProbMetric: 17.1841, val_loss: 17.7631, val_MinusLogProbMetric: 17.7631

Epoch 194: val_loss did not improve from 17.54995
196/196 - 76s - loss: 17.1841 - MinusLogProbMetric: 17.1841 - val_loss: 17.7631 - val_MinusLogProbMetric: 17.7631 - lr: 3.3333e-04 - 76s/epoch - 389ms/step
Epoch 195/1000
2023-09-26 17:45:43.876 
Epoch 195/1000 
	 loss: 17.2757, MinusLogProbMetric: 17.2757, val_loss: 17.9185, val_MinusLogProbMetric: 17.9185

Epoch 195: val_loss did not improve from 17.54995
196/196 - 76s - loss: 17.2757 - MinusLogProbMetric: 17.2757 - val_loss: 17.9185 - val_MinusLogProbMetric: 17.9185 - lr: 3.3333e-04 - 76s/epoch - 389ms/step
Epoch 196/1000
2023-09-26 17:46:59.513 
Epoch 196/1000 
	 loss: 17.1598, MinusLogProbMetric: 17.1598, val_loss: 17.8606, val_MinusLogProbMetric: 17.8606

Epoch 196: val_loss did not improve from 17.54995
196/196 - 76s - loss: 17.1598 - MinusLogProbMetric: 17.1598 - val_loss: 17.8606 - val_MinusLogProbMetric: 17.8606 - lr: 3.3333e-04 - 76s/epoch - 386ms/step
Epoch 197/1000
2023-09-26 17:48:16.287 
Epoch 197/1000 
	 loss: 17.1593, MinusLogProbMetric: 17.1593, val_loss: 18.1322, val_MinusLogProbMetric: 18.1322

Epoch 197: val_loss did not improve from 17.54995
196/196 - 77s - loss: 17.1593 - MinusLogProbMetric: 17.1593 - val_loss: 18.1322 - val_MinusLogProbMetric: 18.1322 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 198/1000
2023-09-26 17:49:32.850 
Epoch 198/1000 
	 loss: 17.2000, MinusLogProbMetric: 17.2000, val_loss: 17.8570, val_MinusLogProbMetric: 17.8570

Epoch 198: val_loss did not improve from 17.54995
196/196 - 77s - loss: 17.2000 - MinusLogProbMetric: 17.2000 - val_loss: 17.8570 - val_MinusLogProbMetric: 17.8570 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 199/1000
2023-09-26 17:50:50.323 
Epoch 199/1000 
	 loss: 17.2279, MinusLogProbMetric: 17.2279, val_loss: 18.3035, val_MinusLogProbMetric: 18.3035

Epoch 199: val_loss did not improve from 17.54995
196/196 - 77s - loss: 17.2279 - MinusLogProbMetric: 17.2279 - val_loss: 18.3035 - val_MinusLogProbMetric: 18.3035 - lr: 3.3333e-04 - 77s/epoch - 395ms/step
Epoch 200/1000
2023-09-26 17:52:06.270 
Epoch 200/1000 
	 loss: 17.1442, MinusLogProbMetric: 17.1442, val_loss: 17.9568, val_MinusLogProbMetric: 17.9568

Epoch 200: val_loss did not improve from 17.54995
196/196 - 76s - loss: 17.1442 - MinusLogProbMetric: 17.1442 - val_loss: 17.9568 - val_MinusLogProbMetric: 17.9568 - lr: 3.3333e-04 - 76s/epoch - 387ms/step
Epoch 201/1000
2023-09-26 17:53:22.136 
Epoch 201/1000 
	 loss: 17.1416, MinusLogProbMetric: 17.1416, val_loss: 17.8168, val_MinusLogProbMetric: 17.8168

Epoch 201: val_loss did not improve from 17.54995
196/196 - 76s - loss: 17.1416 - MinusLogProbMetric: 17.1416 - val_loss: 17.8168 - val_MinusLogProbMetric: 17.8168 - lr: 3.3333e-04 - 76s/epoch - 387ms/step
Epoch 202/1000
2023-09-26 17:54:38.036 
Epoch 202/1000 
	 loss: 17.1264, MinusLogProbMetric: 17.1264, val_loss: 17.5244, val_MinusLogProbMetric: 17.5244

Epoch 202: val_loss improved from 17.54995 to 17.52437, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 77s - loss: 17.1264 - MinusLogProbMetric: 17.1264 - val_loss: 17.5244 - val_MinusLogProbMetric: 17.5244 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 203/1000
2023-09-26 17:55:55.076 
Epoch 203/1000 
	 loss: 17.1468, MinusLogProbMetric: 17.1468, val_loss: 17.7236, val_MinusLogProbMetric: 17.7236

Epoch 203: val_loss did not improve from 17.52437
196/196 - 76s - loss: 17.1468 - MinusLogProbMetric: 17.1468 - val_loss: 17.7236 - val_MinusLogProbMetric: 17.7236 - lr: 3.3333e-04 - 76s/epoch - 387ms/step
Epoch 204/1000
2023-09-26 17:57:11.457 
Epoch 204/1000 
	 loss: 17.1492, MinusLogProbMetric: 17.1492, val_loss: 18.0558, val_MinusLogProbMetric: 18.0558

Epoch 204: val_loss did not improve from 17.52437
196/196 - 76s - loss: 17.1492 - MinusLogProbMetric: 17.1492 - val_loss: 18.0558 - val_MinusLogProbMetric: 18.0558 - lr: 3.3333e-04 - 76s/epoch - 390ms/step
Epoch 205/1000
2023-09-26 17:58:28.865 
Epoch 205/1000 
	 loss: 17.1539, MinusLogProbMetric: 17.1539, val_loss: 17.6569, val_MinusLogProbMetric: 17.6569

Epoch 205: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.1539 - MinusLogProbMetric: 17.1539 - val_loss: 17.6569 - val_MinusLogProbMetric: 17.6569 - lr: 3.3333e-04 - 77s/epoch - 395ms/step
Epoch 206/1000
2023-09-26 17:59:46.024 
Epoch 206/1000 
	 loss: 17.1451, MinusLogProbMetric: 17.1451, val_loss: 17.7926, val_MinusLogProbMetric: 17.7926

Epoch 206: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.1451 - MinusLogProbMetric: 17.1451 - val_loss: 17.7926 - val_MinusLogProbMetric: 17.7926 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 207/1000
2023-09-26 18:01:02.553 
Epoch 207/1000 
	 loss: 17.1208, MinusLogProbMetric: 17.1208, val_loss: 17.6764, val_MinusLogProbMetric: 17.6764

Epoch 207: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.1208 - MinusLogProbMetric: 17.1208 - val_loss: 17.6764 - val_MinusLogProbMetric: 17.6764 - lr: 3.3333e-04 - 77s/epoch - 390ms/step
Epoch 208/1000
2023-09-26 18:02:19.042 
Epoch 208/1000 
	 loss: 17.1796, MinusLogProbMetric: 17.1796, val_loss: 18.0819, val_MinusLogProbMetric: 18.0819

Epoch 208: val_loss did not improve from 17.52437
196/196 - 76s - loss: 17.1796 - MinusLogProbMetric: 17.1796 - val_loss: 18.0819 - val_MinusLogProbMetric: 18.0819 - lr: 3.3333e-04 - 76s/epoch - 390ms/step
Epoch 209/1000
2023-09-26 18:03:35.983 
Epoch 209/1000 
	 loss: 17.1792, MinusLogProbMetric: 17.1792, val_loss: 17.6953, val_MinusLogProbMetric: 17.6953

Epoch 209: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.1792 - MinusLogProbMetric: 17.1792 - val_loss: 17.6953 - val_MinusLogProbMetric: 17.6953 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 210/1000
2023-09-26 18:04:51.899 
Epoch 210/1000 
	 loss: 17.1447, MinusLogProbMetric: 17.1447, val_loss: 17.7068, val_MinusLogProbMetric: 17.7068

Epoch 210: val_loss did not improve from 17.52437
196/196 - 76s - loss: 17.1447 - MinusLogProbMetric: 17.1447 - val_loss: 17.7068 - val_MinusLogProbMetric: 17.7068 - lr: 3.3333e-04 - 76s/epoch - 387ms/step
Epoch 211/1000
2023-09-26 18:06:08.398 
Epoch 211/1000 
	 loss: 17.1585, MinusLogProbMetric: 17.1585, val_loss: 17.7865, val_MinusLogProbMetric: 17.7865

Epoch 211: val_loss did not improve from 17.52437
196/196 - 76s - loss: 17.1585 - MinusLogProbMetric: 17.1585 - val_loss: 17.7865 - val_MinusLogProbMetric: 17.7865 - lr: 3.3333e-04 - 76s/epoch - 390ms/step
Epoch 212/1000
2023-09-26 18:07:24.700 
Epoch 212/1000 
	 loss: 17.1105, MinusLogProbMetric: 17.1105, val_loss: 17.6094, val_MinusLogProbMetric: 17.6094

Epoch 212: val_loss did not improve from 17.52437
196/196 - 76s - loss: 17.1105 - MinusLogProbMetric: 17.1105 - val_loss: 17.6094 - val_MinusLogProbMetric: 17.6094 - lr: 3.3333e-04 - 76s/epoch - 389ms/step
Epoch 213/1000
2023-09-26 18:08:41.905 
Epoch 213/1000 
	 loss: 17.0852, MinusLogProbMetric: 17.0852, val_loss: 17.6321, val_MinusLogProbMetric: 17.6321

Epoch 213: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.0852 - MinusLogProbMetric: 17.0852 - val_loss: 17.6321 - val_MinusLogProbMetric: 17.6321 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 214/1000
2023-09-26 18:09:58.199 
Epoch 214/1000 
	 loss: 17.1473, MinusLogProbMetric: 17.1473, val_loss: 18.0826, val_MinusLogProbMetric: 18.0826

Epoch 214: val_loss did not improve from 17.52437
196/196 - 76s - loss: 17.1473 - MinusLogProbMetric: 17.1473 - val_loss: 18.0826 - val_MinusLogProbMetric: 18.0826 - lr: 3.3333e-04 - 76s/epoch - 389ms/step
Epoch 215/1000
2023-09-26 18:11:14.711 
Epoch 215/1000 
	 loss: 17.0740, MinusLogProbMetric: 17.0740, val_loss: 17.5499, val_MinusLogProbMetric: 17.5499

Epoch 215: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.0740 - MinusLogProbMetric: 17.0740 - val_loss: 17.5499 - val_MinusLogProbMetric: 17.5499 - lr: 3.3333e-04 - 77s/epoch - 390ms/step
Epoch 216/1000
2023-09-26 18:12:31.645 
Epoch 216/1000 
	 loss: 17.1125, MinusLogProbMetric: 17.1125, val_loss: 17.8908, val_MinusLogProbMetric: 17.8908

Epoch 216: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.1125 - MinusLogProbMetric: 17.1125 - val_loss: 17.8908 - val_MinusLogProbMetric: 17.8908 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 217/1000
2023-09-26 18:13:48.855 
Epoch 217/1000 
	 loss: 17.1019, MinusLogProbMetric: 17.1019, val_loss: 17.7146, val_MinusLogProbMetric: 17.7146

Epoch 217: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.1019 - MinusLogProbMetric: 17.1019 - val_loss: 17.7146 - val_MinusLogProbMetric: 17.7146 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 218/1000
2023-09-26 18:15:05.597 
Epoch 218/1000 
	 loss: 17.0572, MinusLogProbMetric: 17.0572, val_loss: 17.6315, val_MinusLogProbMetric: 17.6315

Epoch 218: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.0572 - MinusLogProbMetric: 17.0572 - val_loss: 17.6315 - val_MinusLogProbMetric: 17.6315 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 219/1000
2023-09-26 18:16:22.799 
Epoch 219/1000 
	 loss: 17.1257, MinusLogProbMetric: 17.1257, val_loss: 17.8174, val_MinusLogProbMetric: 17.8174

Epoch 219: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.1257 - MinusLogProbMetric: 17.1257 - val_loss: 17.8174 - val_MinusLogProbMetric: 17.8174 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 220/1000
2023-09-26 18:17:39.541 
Epoch 220/1000 
	 loss: 17.0753, MinusLogProbMetric: 17.0753, val_loss: 17.7917, val_MinusLogProbMetric: 17.7917

Epoch 220: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.0753 - MinusLogProbMetric: 17.0753 - val_loss: 17.7917 - val_MinusLogProbMetric: 17.7917 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 221/1000
2023-09-26 18:18:55.878 
Epoch 221/1000 
	 loss: 17.1053, MinusLogProbMetric: 17.1053, val_loss: 17.5245, val_MinusLogProbMetric: 17.5245

Epoch 221: val_loss did not improve from 17.52437
196/196 - 76s - loss: 17.1053 - MinusLogProbMetric: 17.1053 - val_loss: 17.5245 - val_MinusLogProbMetric: 17.5245 - lr: 3.3333e-04 - 76s/epoch - 389ms/step
Epoch 222/1000
2023-09-26 18:20:11.864 
Epoch 222/1000 
	 loss: 16.9964, MinusLogProbMetric: 16.9964, val_loss: 18.6899, val_MinusLogProbMetric: 18.6899

Epoch 222: val_loss did not improve from 17.52437
196/196 - 76s - loss: 16.9964 - MinusLogProbMetric: 16.9964 - val_loss: 18.6899 - val_MinusLogProbMetric: 18.6899 - lr: 3.3333e-04 - 76s/epoch - 388ms/step
Epoch 223/1000
2023-09-26 18:21:29.174 
Epoch 223/1000 
	 loss: 17.0697, MinusLogProbMetric: 17.0697, val_loss: 17.7268, val_MinusLogProbMetric: 17.7268

Epoch 223: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.0697 - MinusLogProbMetric: 17.0697 - val_loss: 17.7268 - val_MinusLogProbMetric: 17.7268 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 224/1000
2023-09-26 18:22:45.756 
Epoch 224/1000 
	 loss: 17.0928, MinusLogProbMetric: 17.0928, val_loss: 17.7176, val_MinusLogProbMetric: 17.7176

Epoch 224: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.0928 - MinusLogProbMetric: 17.0928 - val_loss: 17.7176 - val_MinusLogProbMetric: 17.7176 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 225/1000
2023-09-26 18:24:03.063 
Epoch 225/1000 
	 loss: 17.1107, MinusLogProbMetric: 17.1107, val_loss: 17.7983, val_MinusLogProbMetric: 17.7983

Epoch 225: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.1107 - MinusLogProbMetric: 17.1107 - val_loss: 17.7983 - val_MinusLogProbMetric: 17.7983 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 226/1000
2023-09-26 18:25:20.273 
Epoch 226/1000 
	 loss: 17.1072, MinusLogProbMetric: 17.1072, val_loss: 17.8841, val_MinusLogProbMetric: 17.8841

Epoch 226: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.1072 - MinusLogProbMetric: 17.1072 - val_loss: 17.8841 - val_MinusLogProbMetric: 17.8841 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 227/1000
2023-09-26 18:26:37.324 
Epoch 227/1000 
	 loss: 17.0290, MinusLogProbMetric: 17.0290, val_loss: 17.6587, val_MinusLogProbMetric: 17.6587

Epoch 227: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.0290 - MinusLogProbMetric: 17.0290 - val_loss: 17.6587 - val_MinusLogProbMetric: 17.6587 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 228/1000
2023-09-26 18:27:54.053 
Epoch 228/1000 
	 loss: 17.0664, MinusLogProbMetric: 17.0664, val_loss: 17.9705, val_MinusLogProbMetric: 17.9705

Epoch 228: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.0664 - MinusLogProbMetric: 17.0664 - val_loss: 17.9705 - val_MinusLogProbMetric: 17.9705 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 229/1000
2023-09-26 18:29:10.949 
Epoch 229/1000 
	 loss: 17.0780, MinusLogProbMetric: 17.0780, val_loss: 17.6508, val_MinusLogProbMetric: 17.6508

Epoch 229: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.0780 - MinusLogProbMetric: 17.0780 - val_loss: 17.6508 - val_MinusLogProbMetric: 17.6508 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 230/1000
2023-09-26 18:30:27.922 
Epoch 230/1000 
	 loss: 17.0626, MinusLogProbMetric: 17.0626, val_loss: 18.3234, val_MinusLogProbMetric: 18.3234

Epoch 230: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.0626 - MinusLogProbMetric: 17.0626 - val_loss: 18.3234 - val_MinusLogProbMetric: 18.3234 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 231/1000
2023-09-26 18:31:44.098 
Epoch 231/1000 
	 loss: 16.9987, MinusLogProbMetric: 16.9987, val_loss: 17.7512, val_MinusLogProbMetric: 17.7512

Epoch 231: val_loss did not improve from 17.52437
196/196 - 76s - loss: 16.9987 - MinusLogProbMetric: 16.9987 - val_loss: 17.7512 - val_MinusLogProbMetric: 17.7512 - lr: 3.3333e-04 - 76s/epoch - 389ms/step
Epoch 232/1000
2023-09-26 18:33:01.432 
Epoch 232/1000 
	 loss: 17.0366, MinusLogProbMetric: 17.0366, val_loss: 18.0775, val_MinusLogProbMetric: 18.0775

Epoch 232: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.0366 - MinusLogProbMetric: 17.0366 - val_loss: 18.0775 - val_MinusLogProbMetric: 18.0775 - lr: 3.3333e-04 - 77s/epoch - 395ms/step
Epoch 233/1000
2023-09-26 18:34:18.893 
Epoch 233/1000 
	 loss: 17.0547, MinusLogProbMetric: 17.0547, val_loss: 18.1087, val_MinusLogProbMetric: 18.1087

Epoch 233: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.0547 - MinusLogProbMetric: 17.0547 - val_loss: 18.1087 - val_MinusLogProbMetric: 18.1087 - lr: 3.3333e-04 - 77s/epoch - 395ms/step
Epoch 234/1000
2023-09-26 18:35:36.209 
Epoch 234/1000 
	 loss: 17.0288, MinusLogProbMetric: 17.0288, val_loss: 18.1086, val_MinusLogProbMetric: 18.1086

Epoch 234: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.0288 - MinusLogProbMetric: 17.0288 - val_loss: 18.1086 - val_MinusLogProbMetric: 18.1086 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 235/1000
2023-09-26 18:36:53.626 
Epoch 235/1000 
	 loss: 17.0690, MinusLogProbMetric: 17.0690, val_loss: 18.0410, val_MinusLogProbMetric: 18.0410

Epoch 235: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.0690 - MinusLogProbMetric: 17.0690 - val_loss: 18.0410 - val_MinusLogProbMetric: 18.0410 - lr: 3.3333e-04 - 77s/epoch - 395ms/step
Epoch 236/1000
2023-09-26 18:38:10.721 
Epoch 236/1000 
	 loss: 17.0610, MinusLogProbMetric: 17.0610, val_loss: 18.1768, val_MinusLogProbMetric: 18.1768

Epoch 236: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.0610 - MinusLogProbMetric: 17.0610 - val_loss: 18.1768 - val_MinusLogProbMetric: 18.1768 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 237/1000
2023-09-26 18:39:27.203 
Epoch 237/1000 
	 loss: 17.0606, MinusLogProbMetric: 17.0606, val_loss: 17.5704, val_MinusLogProbMetric: 17.5704

Epoch 237: val_loss did not improve from 17.52437
196/196 - 76s - loss: 17.0606 - MinusLogProbMetric: 17.0606 - val_loss: 17.5704 - val_MinusLogProbMetric: 17.5704 - lr: 3.3333e-04 - 76s/epoch - 390ms/step
Epoch 238/1000
2023-09-26 18:40:44.154 
Epoch 238/1000 
	 loss: 17.0150, MinusLogProbMetric: 17.0150, val_loss: 17.7578, val_MinusLogProbMetric: 17.7578

Epoch 238: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.0150 - MinusLogProbMetric: 17.0150 - val_loss: 17.7578 - val_MinusLogProbMetric: 17.7578 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 239/1000
2023-09-26 18:42:01.811 
Epoch 239/1000 
	 loss: 16.9723, MinusLogProbMetric: 16.9723, val_loss: 17.8879, val_MinusLogProbMetric: 17.8879

Epoch 239: val_loss did not improve from 17.52437
196/196 - 78s - loss: 16.9723 - MinusLogProbMetric: 16.9723 - val_loss: 17.8879 - val_MinusLogProbMetric: 17.8879 - lr: 3.3333e-04 - 78s/epoch - 396ms/step
Epoch 240/1000
2023-09-26 18:43:18.539 
Epoch 240/1000 
	 loss: 16.9908, MinusLogProbMetric: 16.9908, val_loss: 17.5510, val_MinusLogProbMetric: 17.5510

Epoch 240: val_loss did not improve from 17.52437
196/196 - 77s - loss: 16.9908 - MinusLogProbMetric: 16.9908 - val_loss: 17.5510 - val_MinusLogProbMetric: 17.5510 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 241/1000
2023-09-26 18:44:35.955 
Epoch 241/1000 
	 loss: 17.0520, MinusLogProbMetric: 17.0520, val_loss: 17.7756, val_MinusLogProbMetric: 17.7756

Epoch 241: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.0520 - MinusLogProbMetric: 17.0520 - val_loss: 17.7756 - val_MinusLogProbMetric: 17.7756 - lr: 3.3333e-04 - 77s/epoch - 395ms/step
Epoch 242/1000
2023-09-26 18:45:53.308 
Epoch 242/1000 
	 loss: 16.9986, MinusLogProbMetric: 16.9986, val_loss: 17.9911, val_MinusLogProbMetric: 17.9911

Epoch 242: val_loss did not improve from 17.52437
196/196 - 77s - loss: 16.9986 - MinusLogProbMetric: 16.9986 - val_loss: 17.9911 - val_MinusLogProbMetric: 17.9911 - lr: 3.3333e-04 - 77s/epoch - 395ms/step
Epoch 243/1000
2023-09-26 18:47:10.842 
Epoch 243/1000 
	 loss: 16.9642, MinusLogProbMetric: 16.9642, val_loss: 17.7321, val_MinusLogProbMetric: 17.7321

Epoch 243: val_loss did not improve from 17.52437
196/196 - 78s - loss: 16.9642 - MinusLogProbMetric: 16.9642 - val_loss: 17.7321 - val_MinusLogProbMetric: 17.7321 - lr: 3.3333e-04 - 78s/epoch - 396ms/step
Epoch 244/1000
2023-09-26 18:48:27.550 
Epoch 244/1000 
	 loss: 17.0422, MinusLogProbMetric: 17.0422, val_loss: 17.7254, val_MinusLogProbMetric: 17.7254

Epoch 244: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.0422 - MinusLogProbMetric: 17.0422 - val_loss: 17.7254 - val_MinusLogProbMetric: 17.7254 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 245/1000
2023-09-26 18:49:44.297 
Epoch 245/1000 
	 loss: 17.0130, MinusLogProbMetric: 17.0130, val_loss: 18.4645, val_MinusLogProbMetric: 18.4645

Epoch 245: val_loss did not improve from 17.52437
196/196 - 77s - loss: 17.0130 - MinusLogProbMetric: 17.0130 - val_loss: 18.4645 - val_MinusLogProbMetric: 18.4645 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 246/1000
2023-09-26 18:51:01.191 
Epoch 246/1000 
	 loss: 16.9924, MinusLogProbMetric: 16.9924, val_loss: 17.7314, val_MinusLogProbMetric: 17.7314

Epoch 246: val_loss did not improve from 17.52437
196/196 - 77s - loss: 16.9924 - MinusLogProbMetric: 16.9924 - val_loss: 17.7314 - val_MinusLogProbMetric: 17.7314 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 247/1000
2023-09-26 18:52:18.346 
Epoch 247/1000 
	 loss: 16.9710, MinusLogProbMetric: 16.9710, val_loss: 17.5092, val_MinusLogProbMetric: 17.5092

Epoch 247: val_loss improved from 17.52437 to 17.50923, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 78s - loss: 16.9710 - MinusLogProbMetric: 16.9710 - val_loss: 17.5092 - val_MinusLogProbMetric: 17.5092 - lr: 3.3333e-04 - 78s/epoch - 400ms/step
Epoch 248/1000
2023-09-26 18:53:35.967 
Epoch 248/1000 
	 loss: 16.9932, MinusLogProbMetric: 16.9932, val_loss: 17.7306, val_MinusLogProbMetric: 17.7306

Epoch 248: val_loss did not improve from 17.50923
196/196 - 76s - loss: 16.9932 - MinusLogProbMetric: 16.9932 - val_loss: 17.7306 - val_MinusLogProbMetric: 17.7306 - lr: 3.3333e-04 - 76s/epoch - 390ms/step
Epoch 249/1000
2023-09-26 18:54:53.265 
Epoch 249/1000 
	 loss: 16.9997, MinusLogProbMetric: 16.9997, val_loss: 18.0572, val_MinusLogProbMetric: 18.0572

Epoch 249: val_loss did not improve from 17.50923
196/196 - 77s - loss: 16.9997 - MinusLogProbMetric: 16.9997 - val_loss: 18.0572 - val_MinusLogProbMetric: 18.0572 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 250/1000
2023-09-26 18:56:10.108 
Epoch 250/1000 
	 loss: 16.9367, MinusLogProbMetric: 16.9367, val_loss: 18.4558, val_MinusLogProbMetric: 18.4558

Epoch 250: val_loss did not improve from 17.50923
196/196 - 77s - loss: 16.9367 - MinusLogProbMetric: 16.9367 - val_loss: 18.4558 - val_MinusLogProbMetric: 18.4558 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 251/1000
2023-09-26 18:57:26.481 
Epoch 251/1000 
	 loss: 16.9740, MinusLogProbMetric: 16.9740, val_loss: 17.7306, val_MinusLogProbMetric: 17.7306

Epoch 251: val_loss did not improve from 17.50923
196/196 - 76s - loss: 16.9740 - MinusLogProbMetric: 16.9740 - val_loss: 17.7306 - val_MinusLogProbMetric: 17.7306 - lr: 3.3333e-04 - 76s/epoch - 390ms/step
Epoch 252/1000
2023-09-26 18:58:43.001 
Epoch 252/1000 
	 loss: 17.0155, MinusLogProbMetric: 17.0155, val_loss: 18.4758, val_MinusLogProbMetric: 18.4758

Epoch 252: val_loss did not improve from 17.50923
196/196 - 77s - loss: 17.0155 - MinusLogProbMetric: 17.0155 - val_loss: 18.4758 - val_MinusLogProbMetric: 18.4758 - lr: 3.3333e-04 - 77s/epoch - 390ms/step
Epoch 253/1000
2023-09-26 19:00:00.289 
Epoch 253/1000 
	 loss: 16.9829, MinusLogProbMetric: 16.9829, val_loss: 17.8211, val_MinusLogProbMetric: 17.8211

Epoch 253: val_loss did not improve from 17.50923
196/196 - 77s - loss: 16.9829 - MinusLogProbMetric: 16.9829 - val_loss: 17.8211 - val_MinusLogProbMetric: 17.8211 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 254/1000
2023-09-26 19:01:16.130 
Epoch 254/1000 
	 loss: 16.9807, MinusLogProbMetric: 16.9807, val_loss: 17.5562, val_MinusLogProbMetric: 17.5562

Epoch 254: val_loss did not improve from 17.50923
196/196 - 76s - loss: 16.9807 - MinusLogProbMetric: 16.9807 - val_loss: 17.5562 - val_MinusLogProbMetric: 17.5562 - lr: 3.3333e-04 - 76s/epoch - 387ms/step
Epoch 255/1000
2023-09-26 19:02:32.208 
Epoch 255/1000 
	 loss: 17.0605, MinusLogProbMetric: 17.0605, val_loss: 17.7570, val_MinusLogProbMetric: 17.7570

Epoch 255: val_loss did not improve from 17.50923
196/196 - 76s - loss: 17.0605 - MinusLogProbMetric: 17.0605 - val_loss: 17.7570 - val_MinusLogProbMetric: 17.7570 - lr: 3.3333e-04 - 76s/epoch - 388ms/step
Epoch 256/1000
2023-09-26 19:03:48.516 
Epoch 256/1000 
	 loss: 16.9468, MinusLogProbMetric: 16.9468, val_loss: 17.5639, val_MinusLogProbMetric: 17.5639

Epoch 256: val_loss did not improve from 17.50923
196/196 - 76s - loss: 16.9468 - MinusLogProbMetric: 16.9468 - val_loss: 17.5639 - val_MinusLogProbMetric: 17.5639 - lr: 3.3333e-04 - 76s/epoch - 389ms/step
Epoch 257/1000
2023-09-26 19:05:05.431 
Epoch 257/1000 
	 loss: 16.9289, MinusLogProbMetric: 16.9289, val_loss: 17.7720, val_MinusLogProbMetric: 17.7720

Epoch 257: val_loss did not improve from 17.50923
196/196 - 77s - loss: 16.9289 - MinusLogProbMetric: 16.9289 - val_loss: 17.7720 - val_MinusLogProbMetric: 17.7720 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 258/1000
2023-09-26 19:06:21.277 
Epoch 258/1000 
	 loss: 16.9870, MinusLogProbMetric: 16.9870, val_loss: 17.7814, val_MinusLogProbMetric: 17.7814

Epoch 258: val_loss did not improve from 17.50923
196/196 - 76s - loss: 16.9870 - MinusLogProbMetric: 16.9870 - val_loss: 17.7814 - val_MinusLogProbMetric: 17.7814 - lr: 3.3333e-04 - 76s/epoch - 387ms/step
Epoch 259/1000
2023-09-26 19:07:38.149 
Epoch 259/1000 
	 loss: 16.9550, MinusLogProbMetric: 16.9550, val_loss: 17.8287, val_MinusLogProbMetric: 17.8287

Epoch 259: val_loss did not improve from 17.50923
196/196 - 77s - loss: 16.9550 - MinusLogProbMetric: 16.9550 - val_loss: 17.8287 - val_MinusLogProbMetric: 17.8287 - lr: 3.3333e-04 - 77s/epoch - 392ms/step
Epoch 260/1000
2023-09-26 19:08:55.923 
Epoch 260/1000 
	 loss: 16.9823, MinusLogProbMetric: 16.9823, val_loss: 17.7675, val_MinusLogProbMetric: 17.7675

Epoch 260: val_loss did not improve from 17.50923
196/196 - 78s - loss: 16.9823 - MinusLogProbMetric: 16.9823 - val_loss: 17.7675 - val_MinusLogProbMetric: 17.7675 - lr: 3.3333e-04 - 78s/epoch - 397ms/step
Epoch 261/1000
2023-09-26 19:10:12.894 
Epoch 261/1000 
	 loss: 16.9062, MinusLogProbMetric: 16.9062, val_loss: 17.6923, val_MinusLogProbMetric: 17.6923

Epoch 261: val_loss did not improve from 17.50923
196/196 - 77s - loss: 16.9062 - MinusLogProbMetric: 16.9062 - val_loss: 17.6923 - val_MinusLogProbMetric: 17.6923 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 262/1000
2023-09-26 19:11:29.361 
Epoch 262/1000 
	 loss: 16.9188, MinusLogProbMetric: 16.9188, val_loss: 17.5416, val_MinusLogProbMetric: 17.5416

Epoch 262: val_loss did not improve from 17.50923
196/196 - 76s - loss: 16.9188 - MinusLogProbMetric: 16.9188 - val_loss: 17.5416 - val_MinusLogProbMetric: 17.5416 - lr: 3.3333e-04 - 76s/epoch - 390ms/step
Epoch 263/1000
2023-09-26 19:12:45.682 
Epoch 263/1000 
	 loss: 16.9559, MinusLogProbMetric: 16.9559, val_loss: 18.5014, val_MinusLogProbMetric: 18.5014

Epoch 263: val_loss did not improve from 17.50923
196/196 - 76s - loss: 16.9559 - MinusLogProbMetric: 16.9559 - val_loss: 18.5014 - val_MinusLogProbMetric: 18.5014 - lr: 3.3333e-04 - 76s/epoch - 389ms/step
Epoch 264/1000
2023-09-26 19:14:02.350 
Epoch 264/1000 
	 loss: 16.8931, MinusLogProbMetric: 16.8931, val_loss: 18.1416, val_MinusLogProbMetric: 18.1416

Epoch 264: val_loss did not improve from 17.50923
196/196 - 77s - loss: 16.8931 - MinusLogProbMetric: 16.8931 - val_loss: 18.1416 - val_MinusLogProbMetric: 18.1416 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 265/1000
2023-09-26 19:15:19.302 
Epoch 265/1000 
	 loss: 16.9458, MinusLogProbMetric: 16.9458, val_loss: 17.7992, val_MinusLogProbMetric: 17.7992

Epoch 265: val_loss did not improve from 17.50923
196/196 - 77s - loss: 16.9458 - MinusLogProbMetric: 16.9458 - val_loss: 17.7992 - val_MinusLogProbMetric: 17.7992 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 266/1000
2023-09-26 19:16:37.051 
Epoch 266/1000 
	 loss: 16.9344, MinusLogProbMetric: 16.9344, val_loss: 17.8682, val_MinusLogProbMetric: 17.8682

Epoch 266: val_loss did not improve from 17.50923
196/196 - 78s - loss: 16.9344 - MinusLogProbMetric: 16.9344 - val_loss: 17.8682 - val_MinusLogProbMetric: 17.8682 - lr: 3.3333e-04 - 78s/epoch - 397ms/step
Epoch 267/1000
2023-09-26 19:17:51.890 
Epoch 267/1000 
	 loss: 16.9128, MinusLogProbMetric: 16.9128, val_loss: 19.2686, val_MinusLogProbMetric: 19.2686

Epoch 267: val_loss did not improve from 17.50923
196/196 - 75s - loss: 16.9128 - MinusLogProbMetric: 16.9128 - val_loss: 19.2686 - val_MinusLogProbMetric: 19.2686 - lr: 3.3333e-04 - 75s/epoch - 382ms/step
Epoch 268/1000
2023-09-26 19:19:00.755 
Epoch 268/1000 
	 loss: 16.9343, MinusLogProbMetric: 16.9343, val_loss: 17.5493, val_MinusLogProbMetric: 17.5493

Epoch 268: val_loss did not improve from 17.50923
196/196 - 69s - loss: 16.9343 - MinusLogProbMetric: 16.9343 - val_loss: 17.5493 - val_MinusLogProbMetric: 17.5493 - lr: 3.3333e-04 - 69s/epoch - 351ms/step
Epoch 269/1000
2023-09-26 19:20:04.761 
Epoch 269/1000 
	 loss: 16.9251, MinusLogProbMetric: 16.9251, val_loss: 18.0979, val_MinusLogProbMetric: 18.0979

Epoch 269: val_loss did not improve from 17.50923
196/196 - 64s - loss: 16.9251 - MinusLogProbMetric: 16.9251 - val_loss: 18.0979 - val_MinusLogProbMetric: 18.0979 - lr: 3.3333e-04 - 64s/epoch - 327ms/step
Epoch 270/1000
2023-09-26 19:21:19.058 
Epoch 270/1000 
	 loss: 16.9194, MinusLogProbMetric: 16.9194, val_loss: 18.0868, val_MinusLogProbMetric: 18.0868

Epoch 270: val_loss did not improve from 17.50923
196/196 - 74s - loss: 16.9194 - MinusLogProbMetric: 16.9194 - val_loss: 18.0868 - val_MinusLogProbMetric: 18.0868 - lr: 3.3333e-04 - 74s/epoch - 379ms/step
Epoch 271/1000
2023-09-26 19:22:27.496 
Epoch 271/1000 
	 loss: 16.8736, MinusLogProbMetric: 16.8736, val_loss: 18.1226, val_MinusLogProbMetric: 18.1226

Epoch 271: val_loss did not improve from 17.50923
196/196 - 68s - loss: 16.8736 - MinusLogProbMetric: 16.8736 - val_loss: 18.1226 - val_MinusLogProbMetric: 18.1226 - lr: 3.3333e-04 - 68s/epoch - 349ms/step
Epoch 272/1000
2023-09-26 19:23:33.822 
Epoch 272/1000 
	 loss: 16.8435, MinusLogProbMetric: 16.8435, val_loss: 18.0279, val_MinusLogProbMetric: 18.0279

Epoch 272: val_loss did not improve from 17.50923
196/196 - 66s - loss: 16.8435 - MinusLogProbMetric: 16.8435 - val_loss: 18.0279 - val_MinusLogProbMetric: 18.0279 - lr: 3.3333e-04 - 66s/epoch - 338ms/step
Epoch 273/1000
2023-09-26 19:24:49.079 
Epoch 273/1000 
	 loss: 16.8936, MinusLogProbMetric: 16.8936, val_loss: 17.7457, val_MinusLogProbMetric: 17.7457

Epoch 273: val_loss did not improve from 17.50923
196/196 - 75s - loss: 16.8936 - MinusLogProbMetric: 16.8936 - val_loss: 17.7457 - val_MinusLogProbMetric: 17.7457 - lr: 3.3333e-04 - 75s/epoch - 384ms/step
Epoch 274/1000
2023-09-26 19:26:05.309 
Epoch 274/1000 
	 loss: 16.9475, MinusLogProbMetric: 16.9475, val_loss: 17.8313, val_MinusLogProbMetric: 17.8313

Epoch 274: val_loss did not improve from 17.50923
196/196 - 76s - loss: 16.9475 - MinusLogProbMetric: 16.9475 - val_loss: 17.8313 - val_MinusLogProbMetric: 17.8313 - lr: 3.3333e-04 - 76s/epoch - 389ms/step
Epoch 275/1000
2023-09-26 19:27:22.464 
Epoch 275/1000 
	 loss: 16.9191, MinusLogProbMetric: 16.9191, val_loss: 17.8160, val_MinusLogProbMetric: 17.8160

Epoch 275: val_loss did not improve from 17.50923
196/196 - 77s - loss: 16.9191 - MinusLogProbMetric: 16.9191 - val_loss: 17.8160 - val_MinusLogProbMetric: 17.8160 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 276/1000
2023-09-26 19:28:32.128 
Epoch 276/1000 
	 loss: 16.8540, MinusLogProbMetric: 16.8540, val_loss: 17.7186, val_MinusLogProbMetric: 17.7186

Epoch 276: val_loss did not improve from 17.50923
196/196 - 70s - loss: 16.8540 - MinusLogProbMetric: 16.8540 - val_loss: 17.7186 - val_MinusLogProbMetric: 17.7186 - lr: 3.3333e-04 - 70s/epoch - 355ms/step
Epoch 277/1000
2023-09-26 19:29:36.187 
Epoch 277/1000 
	 loss: 16.8668, MinusLogProbMetric: 16.8668, val_loss: 18.1918, val_MinusLogProbMetric: 18.1918

Epoch 277: val_loss did not improve from 17.50923
196/196 - 64s - loss: 16.8668 - MinusLogProbMetric: 16.8668 - val_loss: 18.1918 - val_MinusLogProbMetric: 18.1918 - lr: 3.3333e-04 - 64s/epoch - 327ms/step
Epoch 278/1000
2023-09-26 19:30:54.244 
Epoch 278/1000 
	 loss: 16.9326, MinusLogProbMetric: 16.9326, val_loss: 17.5387, val_MinusLogProbMetric: 17.5387

Epoch 278: val_loss did not improve from 17.50923
196/196 - 78s - loss: 16.9326 - MinusLogProbMetric: 16.9326 - val_loss: 17.5387 - val_MinusLogProbMetric: 17.5387 - lr: 3.3333e-04 - 78s/epoch - 398ms/step
Epoch 279/1000
2023-09-26 19:32:10.241 
Epoch 279/1000 
	 loss: 16.8862, MinusLogProbMetric: 16.8862, val_loss: 17.6779, val_MinusLogProbMetric: 17.6779

Epoch 279: val_loss did not improve from 17.50923
196/196 - 76s - loss: 16.8862 - MinusLogProbMetric: 16.8862 - val_loss: 17.6779 - val_MinusLogProbMetric: 17.6779 - lr: 3.3333e-04 - 76s/epoch - 388ms/step
Epoch 280/1000
2023-09-26 19:33:26.802 
Epoch 280/1000 
	 loss: 16.9089, MinusLogProbMetric: 16.9089, val_loss: 18.0875, val_MinusLogProbMetric: 18.0875

Epoch 280: val_loss did not improve from 17.50923
196/196 - 77s - loss: 16.9089 - MinusLogProbMetric: 16.9089 - val_loss: 18.0875 - val_MinusLogProbMetric: 18.0875 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 281/1000
2023-09-26 19:34:44.258 
Epoch 281/1000 
	 loss: 16.8375, MinusLogProbMetric: 16.8375, val_loss: 17.5214, val_MinusLogProbMetric: 17.5214

Epoch 281: val_loss did not improve from 17.50923
196/196 - 77s - loss: 16.8375 - MinusLogProbMetric: 16.8375 - val_loss: 17.5214 - val_MinusLogProbMetric: 17.5214 - lr: 3.3333e-04 - 77s/epoch - 395ms/step
Epoch 282/1000
2023-09-26 19:36:01.384 
Epoch 282/1000 
	 loss: 16.8747, MinusLogProbMetric: 16.8747, val_loss: 17.8895, val_MinusLogProbMetric: 17.8895

Epoch 282: val_loss did not improve from 17.50923
196/196 - 77s - loss: 16.8747 - MinusLogProbMetric: 16.8747 - val_loss: 17.8895 - val_MinusLogProbMetric: 17.8895 - lr: 3.3333e-04 - 77s/epoch - 393ms/step
Epoch 283/1000
2023-09-26 19:37:18.035 
Epoch 283/1000 
	 loss: 16.9012, MinusLogProbMetric: 16.9012, val_loss: 18.0442, val_MinusLogProbMetric: 18.0442

Epoch 283: val_loss did not improve from 17.50923
196/196 - 77s - loss: 16.9012 - MinusLogProbMetric: 16.9012 - val_loss: 18.0442 - val_MinusLogProbMetric: 18.0442 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 284/1000
2023-09-26 19:38:34.744 
Epoch 284/1000 
	 loss: 16.8326, MinusLogProbMetric: 16.8326, val_loss: 17.6452, val_MinusLogProbMetric: 17.6452

Epoch 284: val_loss did not improve from 17.50923
196/196 - 77s - loss: 16.8326 - MinusLogProbMetric: 16.8326 - val_loss: 17.6452 - val_MinusLogProbMetric: 17.6452 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 285/1000
2023-09-26 19:39:51.359 
Epoch 285/1000 
	 loss: 16.8650, MinusLogProbMetric: 16.8650, val_loss: 18.2410, val_MinusLogProbMetric: 18.2410

Epoch 285: val_loss did not improve from 17.50923
196/196 - 77s - loss: 16.8650 - MinusLogProbMetric: 16.8650 - val_loss: 18.2410 - val_MinusLogProbMetric: 18.2410 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 286/1000
2023-09-26 19:41:07.849 
Epoch 286/1000 
	 loss: 16.8721, MinusLogProbMetric: 16.8721, val_loss: 17.8953, val_MinusLogProbMetric: 17.8953

Epoch 286: val_loss did not improve from 17.50923
196/196 - 76s - loss: 16.8721 - MinusLogProbMetric: 16.8721 - val_loss: 17.8953 - val_MinusLogProbMetric: 17.8953 - lr: 3.3333e-04 - 76s/epoch - 390ms/step
Epoch 287/1000
2023-09-26 19:42:23.314 
Epoch 287/1000 
	 loss: 16.8465, MinusLogProbMetric: 16.8465, val_loss: 17.8962, val_MinusLogProbMetric: 17.8962

Epoch 287: val_loss did not improve from 17.50923
196/196 - 75s - loss: 16.8465 - MinusLogProbMetric: 16.8465 - val_loss: 17.8962 - val_MinusLogProbMetric: 17.8962 - lr: 3.3333e-04 - 75s/epoch - 385ms/step
Epoch 288/1000
2023-09-26 19:43:39.797 
Epoch 288/1000 
	 loss: 16.8518, MinusLogProbMetric: 16.8518, val_loss: 17.8212, val_MinusLogProbMetric: 17.8212

Epoch 288: val_loss did not improve from 17.50923
196/196 - 76s - loss: 16.8518 - MinusLogProbMetric: 16.8518 - val_loss: 17.8212 - val_MinusLogProbMetric: 17.8212 - lr: 3.3333e-04 - 76s/epoch - 390ms/step
Epoch 289/1000
2023-09-26 19:44:55.051 
Epoch 289/1000 
	 loss: 16.8725, MinusLogProbMetric: 16.8725, val_loss: 17.9071, val_MinusLogProbMetric: 17.9071

Epoch 289: val_loss did not improve from 17.50923
196/196 - 75s - loss: 16.8725 - MinusLogProbMetric: 16.8725 - val_loss: 17.9071 - val_MinusLogProbMetric: 17.9071 - lr: 3.3333e-04 - 75s/epoch - 384ms/step
Epoch 290/1000
2023-09-26 19:46:10.297 
Epoch 290/1000 
	 loss: 16.8806, MinusLogProbMetric: 16.8806, val_loss: 17.5651, val_MinusLogProbMetric: 17.5651

Epoch 290: val_loss did not improve from 17.50923
196/196 - 75s - loss: 16.8806 - MinusLogProbMetric: 16.8806 - val_loss: 17.5651 - val_MinusLogProbMetric: 17.5651 - lr: 3.3333e-04 - 75s/epoch - 384ms/step
Epoch 291/1000
2023-09-26 19:47:26.391 
Epoch 291/1000 
	 loss: 16.8241, MinusLogProbMetric: 16.8241, val_loss: 17.7093, val_MinusLogProbMetric: 17.7093

Epoch 291: val_loss did not improve from 17.50923
196/196 - 76s - loss: 16.8241 - MinusLogProbMetric: 16.8241 - val_loss: 17.7093 - val_MinusLogProbMetric: 17.7093 - lr: 3.3333e-04 - 76s/epoch - 388ms/step
Epoch 292/1000
2023-09-26 19:48:41.847 
Epoch 292/1000 
	 loss: 16.8408, MinusLogProbMetric: 16.8408, val_loss: 17.8769, val_MinusLogProbMetric: 17.8769

Epoch 292: val_loss did not improve from 17.50923
196/196 - 75s - loss: 16.8408 - MinusLogProbMetric: 16.8408 - val_loss: 17.8769 - val_MinusLogProbMetric: 17.8769 - lr: 3.3333e-04 - 75s/epoch - 385ms/step
Epoch 293/1000
2023-09-26 19:49:57.660 
Epoch 293/1000 
	 loss: 16.8481, MinusLogProbMetric: 16.8481, val_loss: 18.0824, val_MinusLogProbMetric: 18.0824

Epoch 293: val_loss did not improve from 17.50923
196/196 - 76s - loss: 16.8481 - MinusLogProbMetric: 16.8481 - val_loss: 18.0824 - val_MinusLogProbMetric: 18.0824 - lr: 3.3333e-04 - 76s/epoch - 387ms/step
Epoch 294/1000
2023-09-26 19:51:14.056 
Epoch 294/1000 
	 loss: 16.7663, MinusLogProbMetric: 16.7663, val_loss: 18.0896, val_MinusLogProbMetric: 18.0896

Epoch 294: val_loss did not improve from 17.50923
196/196 - 76s - loss: 16.7663 - MinusLogProbMetric: 16.7663 - val_loss: 18.0896 - val_MinusLogProbMetric: 18.0896 - lr: 3.3333e-04 - 76s/epoch - 390ms/step
Epoch 295/1000
2023-09-26 19:52:30.624 
Epoch 295/1000 
	 loss: 16.8535, MinusLogProbMetric: 16.8535, val_loss: 18.0452, val_MinusLogProbMetric: 18.0452

Epoch 295: val_loss did not improve from 17.50923
196/196 - 77s - loss: 16.8535 - MinusLogProbMetric: 16.8535 - val_loss: 18.0452 - val_MinusLogProbMetric: 18.0452 - lr: 3.3333e-04 - 77s/epoch - 391ms/step
Epoch 296/1000
2023-09-26 19:53:46.500 
Epoch 296/1000 
	 loss: 16.8048, MinusLogProbMetric: 16.8048, val_loss: 17.6898, val_MinusLogProbMetric: 17.6898

Epoch 296: val_loss did not improve from 17.50923
196/196 - 76s - loss: 16.8048 - MinusLogProbMetric: 16.8048 - val_loss: 17.6898 - val_MinusLogProbMetric: 17.6898 - lr: 3.3333e-04 - 76s/epoch - 387ms/step
Epoch 297/1000
2023-09-26 19:55:02.578 
Epoch 297/1000 
	 loss: 16.7598, MinusLogProbMetric: 16.7598, val_loss: 17.6529, val_MinusLogProbMetric: 17.6529

Epoch 297: val_loss did not improve from 17.50923
196/196 - 76s - loss: 16.7598 - MinusLogProbMetric: 16.7598 - val_loss: 17.6529 - val_MinusLogProbMetric: 17.6529 - lr: 3.3333e-04 - 76s/epoch - 388ms/step
Epoch 298/1000
2023-09-26 19:56:18.286 
Epoch 298/1000 
	 loss: 16.3855, MinusLogProbMetric: 16.3855, val_loss: 17.3941, val_MinusLogProbMetric: 17.3941

Epoch 298: val_loss improved from 17.50923 to 17.39408, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 77s - loss: 16.3855 - MinusLogProbMetric: 16.3855 - val_loss: 17.3941 - val_MinusLogProbMetric: 17.3941 - lr: 1.6667e-04 - 77s/epoch - 394ms/step
Epoch 299/1000
2023-09-26 19:57:36.030 
Epoch 299/1000 
	 loss: 16.3973, MinusLogProbMetric: 16.3973, val_loss: 17.4524, val_MinusLogProbMetric: 17.4524

Epoch 299: val_loss did not improve from 17.39408
196/196 - 76s - loss: 16.3973 - MinusLogProbMetric: 16.3973 - val_loss: 17.4524 - val_MinusLogProbMetric: 17.4524 - lr: 1.6667e-04 - 76s/epoch - 389ms/step
Epoch 300/1000
2023-09-26 19:58:51.635 
Epoch 300/1000 
	 loss: 16.3987, MinusLogProbMetric: 16.3987, val_loss: 17.4412, val_MinusLogProbMetric: 17.4412

Epoch 300: val_loss did not improve from 17.39408
196/196 - 76s - loss: 16.3987 - MinusLogProbMetric: 16.3987 - val_loss: 17.4412 - val_MinusLogProbMetric: 17.4412 - lr: 1.6667e-04 - 76s/epoch - 386ms/step
Epoch 301/1000
2023-09-26 20:00:08.053 
Epoch 301/1000 
	 loss: 16.4513, MinusLogProbMetric: 16.4513, val_loss: 17.4414, val_MinusLogProbMetric: 17.4414

Epoch 301: val_loss did not improve from 17.39408
196/196 - 76s - loss: 16.4513 - MinusLogProbMetric: 16.4513 - val_loss: 17.4414 - val_MinusLogProbMetric: 17.4414 - lr: 1.6667e-04 - 76s/epoch - 390ms/step
Epoch 302/1000
2023-09-26 20:01:24.330 
Epoch 302/1000 
	 loss: 16.4087, MinusLogProbMetric: 16.4087, val_loss: 17.3626, val_MinusLogProbMetric: 17.3626

Epoch 302: val_loss improved from 17.39408 to 17.36260, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 77s - loss: 16.4087 - MinusLogProbMetric: 16.4087 - val_loss: 17.3626 - val_MinusLogProbMetric: 17.3626 - lr: 1.6667e-04 - 77s/epoch - 395ms/step
Epoch 303/1000
2023-09-26 20:02:41.264 
Epoch 303/1000 
	 loss: 16.4222, MinusLogProbMetric: 16.4222, val_loss: 17.4970, val_MinusLogProbMetric: 17.4970

Epoch 303: val_loss did not improve from 17.36260
196/196 - 76s - loss: 16.4222 - MinusLogProbMetric: 16.4222 - val_loss: 17.4970 - val_MinusLogProbMetric: 17.4970 - lr: 1.6667e-04 - 76s/epoch - 387ms/step
Epoch 304/1000
2023-09-26 20:03:56.788 
Epoch 304/1000 
	 loss: 16.4288, MinusLogProbMetric: 16.4288, val_loss: 17.4355, val_MinusLogProbMetric: 17.4355

Epoch 304: val_loss did not improve from 17.36260
196/196 - 76s - loss: 16.4288 - MinusLogProbMetric: 16.4288 - val_loss: 17.4355 - val_MinusLogProbMetric: 17.4355 - lr: 1.6667e-04 - 76s/epoch - 385ms/step
Epoch 305/1000
2023-09-26 20:05:11.589 
Epoch 305/1000 
	 loss: 16.4105, MinusLogProbMetric: 16.4105, val_loss: 17.3504, val_MinusLogProbMetric: 17.3504

Epoch 305: val_loss improved from 17.36260 to 17.35037, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 76s - loss: 16.4105 - MinusLogProbMetric: 16.4105 - val_loss: 17.3504 - val_MinusLogProbMetric: 17.3504 - lr: 1.6667e-04 - 76s/epoch - 390ms/step
Epoch 306/1000
2023-09-26 20:06:28.485 
Epoch 306/1000 
	 loss: 16.3940, MinusLogProbMetric: 16.3940, val_loss: 17.4292, val_MinusLogProbMetric: 17.4292

Epoch 306: val_loss did not improve from 17.35037
196/196 - 75s - loss: 16.3940 - MinusLogProbMetric: 16.3940 - val_loss: 17.4292 - val_MinusLogProbMetric: 17.4292 - lr: 1.6667e-04 - 75s/epoch - 384ms/step
Epoch 307/1000
2023-09-26 20:07:44.200 
Epoch 307/1000 
	 loss: 16.3768, MinusLogProbMetric: 16.3768, val_loss: 17.3854, val_MinusLogProbMetric: 17.3854

Epoch 307: val_loss did not improve from 17.35037
196/196 - 76s - loss: 16.3768 - MinusLogProbMetric: 16.3768 - val_loss: 17.3854 - val_MinusLogProbMetric: 17.3854 - lr: 1.6667e-04 - 76s/epoch - 386ms/step
Epoch 308/1000
2023-09-26 20:08:59.229 
Epoch 308/1000 
	 loss: 16.4034, MinusLogProbMetric: 16.4034, val_loss: 17.4820, val_MinusLogProbMetric: 17.4820

Epoch 308: val_loss did not improve from 17.35037
196/196 - 75s - loss: 16.4034 - MinusLogProbMetric: 16.4034 - val_loss: 17.4820 - val_MinusLogProbMetric: 17.4820 - lr: 1.6667e-04 - 75s/epoch - 383ms/step
Epoch 309/1000
2023-09-26 20:10:14.903 
Epoch 309/1000 
	 loss: 16.4143, MinusLogProbMetric: 16.4143, val_loss: 17.4615, val_MinusLogProbMetric: 17.4615

Epoch 309: val_loss did not improve from 17.35037
196/196 - 76s - loss: 16.4143 - MinusLogProbMetric: 16.4143 - val_loss: 17.4615 - val_MinusLogProbMetric: 17.4615 - lr: 1.6667e-04 - 76s/epoch - 386ms/step
Epoch 310/1000
2023-09-26 20:11:29.543 
Epoch 310/1000 
	 loss: 16.3969, MinusLogProbMetric: 16.3969, val_loss: 17.5663, val_MinusLogProbMetric: 17.5663

Epoch 310: val_loss did not improve from 17.35037
196/196 - 75s - loss: 16.3969 - MinusLogProbMetric: 16.3969 - val_loss: 17.5663 - val_MinusLogProbMetric: 17.5663 - lr: 1.6667e-04 - 75s/epoch - 381ms/step
Epoch 311/1000
2023-09-26 20:12:44.463 
Epoch 311/1000 
	 loss: 16.3629, MinusLogProbMetric: 16.3629, val_loss: 17.3842, val_MinusLogProbMetric: 17.3842

Epoch 311: val_loss did not improve from 17.35037
196/196 - 75s - loss: 16.3629 - MinusLogProbMetric: 16.3629 - val_loss: 17.3842 - val_MinusLogProbMetric: 17.3842 - lr: 1.6667e-04 - 75s/epoch - 382ms/step
Epoch 312/1000
2023-09-26 20:13:58.664 
Epoch 312/1000 
	 loss: 16.3780, MinusLogProbMetric: 16.3780, val_loss: 17.3377, val_MinusLogProbMetric: 17.3377

Epoch 312: val_loss improved from 17.35037 to 17.33767, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 75s - loss: 16.3780 - MinusLogProbMetric: 16.3780 - val_loss: 17.3377 - val_MinusLogProbMetric: 17.3377 - lr: 1.6667e-04 - 75s/epoch - 384ms/step
Epoch 313/1000
2023-09-26 20:15:15.171 
Epoch 313/1000 
	 loss: 16.3525, MinusLogProbMetric: 16.3525, val_loss: 17.4285, val_MinusLogProbMetric: 17.4285

Epoch 313: val_loss did not improve from 17.33767
196/196 - 75s - loss: 16.3525 - MinusLogProbMetric: 16.3525 - val_loss: 17.4285 - val_MinusLogProbMetric: 17.4285 - lr: 1.6667e-04 - 75s/epoch - 385ms/step
Epoch 314/1000
2023-09-26 20:16:30.467 
Epoch 314/1000 
	 loss: 16.3764, MinusLogProbMetric: 16.3764, val_loss: 17.5130, val_MinusLogProbMetric: 17.5130

Epoch 314: val_loss did not improve from 17.33767
196/196 - 75s - loss: 16.3764 - MinusLogProbMetric: 16.3764 - val_loss: 17.5130 - val_MinusLogProbMetric: 17.5130 - lr: 1.6667e-04 - 75s/epoch - 384ms/step
Epoch 315/1000
2023-09-26 20:17:45.467 
Epoch 315/1000 
	 loss: 16.3866, MinusLogProbMetric: 16.3866, val_loss: 17.3763, val_MinusLogProbMetric: 17.3763

Epoch 315: val_loss did not improve from 17.33767
196/196 - 75s - loss: 16.3866 - MinusLogProbMetric: 16.3866 - val_loss: 17.3763 - val_MinusLogProbMetric: 17.3763 - lr: 1.6667e-04 - 75s/epoch - 383ms/step
Epoch 316/1000
2023-09-26 20:19:00.213 
Epoch 316/1000 
	 loss: 16.3797, MinusLogProbMetric: 16.3797, val_loss: 17.5416, val_MinusLogProbMetric: 17.5416

Epoch 316: val_loss did not improve from 17.33767
196/196 - 75s - loss: 16.3797 - MinusLogProbMetric: 16.3797 - val_loss: 17.5416 - val_MinusLogProbMetric: 17.5416 - lr: 1.6667e-04 - 75s/epoch - 381ms/step
Epoch 317/1000
2023-09-26 20:20:15.306 
Epoch 317/1000 
	 loss: 16.3684, MinusLogProbMetric: 16.3684, val_loss: 17.6152, val_MinusLogProbMetric: 17.6152

Epoch 317: val_loss did not improve from 17.33767
196/196 - 75s - loss: 16.3684 - MinusLogProbMetric: 16.3684 - val_loss: 17.6152 - val_MinusLogProbMetric: 17.6152 - lr: 1.6667e-04 - 75s/epoch - 383ms/step
Epoch 318/1000
2023-09-26 20:21:30.592 
Epoch 318/1000 
	 loss: 16.4078, MinusLogProbMetric: 16.4078, val_loss: 17.5686, val_MinusLogProbMetric: 17.5686

Epoch 318: val_loss did not improve from 17.33767
196/196 - 75s - loss: 16.4078 - MinusLogProbMetric: 16.4078 - val_loss: 17.5686 - val_MinusLogProbMetric: 17.5686 - lr: 1.6667e-04 - 75s/epoch - 384ms/step
Epoch 319/1000
2023-09-26 20:22:45.767 
Epoch 319/1000 
	 loss: 16.3710, MinusLogProbMetric: 16.3710, val_loss: 17.4760, val_MinusLogProbMetric: 17.4760

Epoch 319: val_loss did not improve from 17.33767
196/196 - 75s - loss: 16.3710 - MinusLogProbMetric: 16.3710 - val_loss: 17.4760 - val_MinusLogProbMetric: 17.4760 - lr: 1.6667e-04 - 75s/epoch - 384ms/step
Epoch 320/1000
2023-09-26 20:24:00.206 
Epoch 320/1000 
	 loss: 16.4282, MinusLogProbMetric: 16.4282, val_loss: 17.7023, val_MinusLogProbMetric: 17.7023

Epoch 320: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.4282 - MinusLogProbMetric: 16.4282 - val_loss: 17.7023 - val_MinusLogProbMetric: 17.7023 - lr: 1.6667e-04 - 74s/epoch - 380ms/step
Epoch 321/1000
2023-09-26 20:25:14.303 
Epoch 321/1000 
	 loss: 16.3800, MinusLogProbMetric: 16.3800, val_loss: 17.6384, val_MinusLogProbMetric: 17.6384

Epoch 321: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3800 - MinusLogProbMetric: 16.3800 - val_loss: 17.6384 - val_MinusLogProbMetric: 17.6384 - lr: 1.6667e-04 - 74s/epoch - 378ms/step
Epoch 322/1000
2023-09-26 20:26:28.462 
Epoch 322/1000 
	 loss: 16.3973, MinusLogProbMetric: 16.3973, val_loss: 17.4601, val_MinusLogProbMetric: 17.4601

Epoch 322: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3973 - MinusLogProbMetric: 16.3973 - val_loss: 17.4601 - val_MinusLogProbMetric: 17.4601 - lr: 1.6667e-04 - 74s/epoch - 378ms/step
Epoch 323/1000
2023-09-26 20:27:43.197 
Epoch 323/1000 
	 loss: 16.3667, MinusLogProbMetric: 16.3667, val_loss: 17.4470, val_MinusLogProbMetric: 17.4470

Epoch 323: val_loss did not improve from 17.33767
196/196 - 75s - loss: 16.3667 - MinusLogProbMetric: 16.3667 - val_loss: 17.4470 - val_MinusLogProbMetric: 17.4470 - lr: 1.6667e-04 - 75s/epoch - 381ms/step
Epoch 324/1000
2023-09-26 20:28:57.816 
Epoch 324/1000 
	 loss: 16.3638, MinusLogProbMetric: 16.3638, val_loss: 17.9096, val_MinusLogProbMetric: 17.9096

Epoch 324: val_loss did not improve from 17.33767
196/196 - 75s - loss: 16.3638 - MinusLogProbMetric: 16.3638 - val_loss: 17.9096 - val_MinusLogProbMetric: 17.9096 - lr: 1.6667e-04 - 75s/epoch - 381ms/step
Epoch 325/1000
2023-09-26 20:30:12.156 
Epoch 325/1000 
	 loss: 16.3801, MinusLogProbMetric: 16.3801, val_loss: 17.3933, val_MinusLogProbMetric: 17.3933

Epoch 325: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3801 - MinusLogProbMetric: 16.3801 - val_loss: 17.3933 - val_MinusLogProbMetric: 17.3933 - lr: 1.6667e-04 - 74s/epoch - 379ms/step
Epoch 326/1000
2023-09-26 20:31:26.808 
Epoch 326/1000 
	 loss: 16.3603, MinusLogProbMetric: 16.3603, val_loss: 17.3860, val_MinusLogProbMetric: 17.3860

Epoch 326: val_loss did not improve from 17.33767
196/196 - 75s - loss: 16.3603 - MinusLogProbMetric: 16.3603 - val_loss: 17.3860 - val_MinusLogProbMetric: 17.3860 - lr: 1.6667e-04 - 75s/epoch - 381ms/step
Epoch 327/1000
2023-09-26 20:32:40.656 
Epoch 327/1000 
	 loss: 16.3433, MinusLogProbMetric: 16.3433, val_loss: 17.4451, val_MinusLogProbMetric: 17.4451

Epoch 327: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3433 - MinusLogProbMetric: 16.3433 - val_loss: 17.4451 - val_MinusLogProbMetric: 17.4451 - lr: 1.6667e-04 - 74s/epoch - 377ms/step
Epoch 328/1000
2023-09-26 20:33:55.075 
Epoch 328/1000 
	 loss: 16.4217, MinusLogProbMetric: 16.4217, val_loss: 17.4213, val_MinusLogProbMetric: 17.4213

Epoch 328: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.4217 - MinusLogProbMetric: 16.4217 - val_loss: 17.4213 - val_MinusLogProbMetric: 17.4213 - lr: 1.6667e-04 - 74s/epoch - 380ms/step
Epoch 329/1000
2023-09-26 20:35:09.476 
Epoch 329/1000 
	 loss: 16.3634, MinusLogProbMetric: 16.3634, val_loss: 17.4178, val_MinusLogProbMetric: 17.4178

Epoch 329: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3634 - MinusLogProbMetric: 16.3634 - val_loss: 17.4178 - val_MinusLogProbMetric: 17.4178 - lr: 1.6667e-04 - 74s/epoch - 380ms/step
Epoch 330/1000
2023-09-26 20:36:23.861 
Epoch 330/1000 
	 loss: 16.3657, MinusLogProbMetric: 16.3657, val_loss: 17.4934, val_MinusLogProbMetric: 17.4934

Epoch 330: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3657 - MinusLogProbMetric: 16.3657 - val_loss: 17.4934 - val_MinusLogProbMetric: 17.4934 - lr: 1.6667e-04 - 74s/epoch - 379ms/step
Epoch 331/1000
2023-09-26 20:37:38.255 
Epoch 331/1000 
	 loss: 16.3487, MinusLogProbMetric: 16.3487, val_loss: 17.4181, val_MinusLogProbMetric: 17.4181

Epoch 331: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3487 - MinusLogProbMetric: 16.3487 - val_loss: 17.4181 - val_MinusLogProbMetric: 17.4181 - lr: 1.6667e-04 - 74s/epoch - 380ms/step
Epoch 332/1000
2023-09-26 20:38:51.770 
Epoch 332/1000 
	 loss: 16.3864, MinusLogProbMetric: 16.3864, val_loss: 17.5761, val_MinusLogProbMetric: 17.5761

Epoch 332: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3864 - MinusLogProbMetric: 16.3864 - val_loss: 17.5761 - val_MinusLogProbMetric: 17.5761 - lr: 1.6667e-04 - 74s/epoch - 375ms/step
Epoch 333/1000
2023-09-26 20:40:05.514 
Epoch 333/1000 
	 loss: 16.3428, MinusLogProbMetric: 16.3428, val_loss: 17.4684, val_MinusLogProbMetric: 17.4684

Epoch 333: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3428 - MinusLogProbMetric: 16.3428 - val_loss: 17.4684 - val_MinusLogProbMetric: 17.4684 - lr: 1.6667e-04 - 74s/epoch - 376ms/step
Epoch 334/1000
2023-09-26 20:41:18.962 
Epoch 334/1000 
	 loss: 16.3254, MinusLogProbMetric: 16.3254, val_loss: 17.4201, val_MinusLogProbMetric: 17.4201

Epoch 334: val_loss did not improve from 17.33767
196/196 - 73s - loss: 16.3254 - MinusLogProbMetric: 16.3254 - val_loss: 17.4201 - val_MinusLogProbMetric: 17.4201 - lr: 1.6667e-04 - 73s/epoch - 375ms/step
Epoch 335/1000
2023-09-26 20:42:32.643 
Epoch 335/1000 
	 loss: 16.3541, MinusLogProbMetric: 16.3541, val_loss: 17.4217, val_MinusLogProbMetric: 17.4217

Epoch 335: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3541 - MinusLogProbMetric: 16.3541 - val_loss: 17.4217 - val_MinusLogProbMetric: 17.4217 - lr: 1.6667e-04 - 74s/epoch - 376ms/step
Epoch 336/1000
2023-09-26 20:43:46.710 
Epoch 336/1000 
	 loss: 16.3539, MinusLogProbMetric: 16.3539, val_loss: 17.9654, val_MinusLogProbMetric: 17.9654

Epoch 336: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3539 - MinusLogProbMetric: 16.3539 - val_loss: 17.9654 - val_MinusLogProbMetric: 17.9654 - lr: 1.6667e-04 - 74s/epoch - 378ms/step
Epoch 337/1000
2023-09-26 20:45:00.593 
Epoch 337/1000 
	 loss: 16.3508, MinusLogProbMetric: 16.3508, val_loss: 17.5257, val_MinusLogProbMetric: 17.5257

Epoch 337: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3508 - MinusLogProbMetric: 16.3508 - val_loss: 17.5257 - val_MinusLogProbMetric: 17.5257 - lr: 1.6667e-04 - 74s/epoch - 377ms/step
Epoch 338/1000
2023-09-26 20:46:14.860 
Epoch 338/1000 
	 loss: 16.3986, MinusLogProbMetric: 16.3986, val_loss: 17.4992, val_MinusLogProbMetric: 17.4992

Epoch 338: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3986 - MinusLogProbMetric: 16.3986 - val_loss: 17.4992 - val_MinusLogProbMetric: 17.4992 - lr: 1.6667e-04 - 74s/epoch - 379ms/step
Epoch 339/1000
2023-09-26 20:47:28.557 
Epoch 339/1000 
	 loss: 16.3142, MinusLogProbMetric: 16.3142, val_loss: 17.4350, val_MinusLogProbMetric: 17.4350

Epoch 339: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3142 - MinusLogProbMetric: 16.3142 - val_loss: 17.4350 - val_MinusLogProbMetric: 17.4350 - lr: 1.6667e-04 - 74s/epoch - 376ms/step
Epoch 340/1000
2023-09-26 20:48:42.194 
Epoch 340/1000 
	 loss: 16.3645, MinusLogProbMetric: 16.3645, val_loss: 17.5251, val_MinusLogProbMetric: 17.5251

Epoch 340: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3645 - MinusLogProbMetric: 16.3645 - val_loss: 17.5251 - val_MinusLogProbMetric: 17.5251 - lr: 1.6667e-04 - 74s/epoch - 376ms/step
Epoch 341/1000
2023-09-26 20:49:56.159 
Epoch 341/1000 
	 loss: 16.3407, MinusLogProbMetric: 16.3407, val_loss: 17.3781, val_MinusLogProbMetric: 17.3781

Epoch 341: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3407 - MinusLogProbMetric: 16.3407 - val_loss: 17.3781 - val_MinusLogProbMetric: 17.3781 - lr: 1.6667e-04 - 74s/epoch - 377ms/step
Epoch 342/1000
2023-09-26 20:51:10.021 
Epoch 342/1000 
	 loss: 16.3895, MinusLogProbMetric: 16.3895, val_loss: 17.3818, val_MinusLogProbMetric: 17.3818

Epoch 342: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3895 - MinusLogProbMetric: 16.3895 - val_loss: 17.3818 - val_MinusLogProbMetric: 17.3818 - lr: 1.6667e-04 - 74s/epoch - 377ms/step
Epoch 343/1000
2023-09-26 20:52:24.064 
Epoch 343/1000 
	 loss: 16.3587, MinusLogProbMetric: 16.3587, val_loss: 17.4210, val_MinusLogProbMetric: 17.4210

Epoch 343: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3587 - MinusLogProbMetric: 16.3587 - val_loss: 17.4210 - val_MinusLogProbMetric: 17.4210 - lr: 1.6667e-04 - 74s/epoch - 378ms/step
Epoch 344/1000
2023-09-26 20:53:38.243 
Epoch 344/1000 
	 loss: 16.3586, MinusLogProbMetric: 16.3586, val_loss: 17.4263, val_MinusLogProbMetric: 17.4263

Epoch 344: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3586 - MinusLogProbMetric: 16.3586 - val_loss: 17.4263 - val_MinusLogProbMetric: 17.4263 - lr: 1.6667e-04 - 74s/epoch - 378ms/step
Epoch 345/1000
2023-09-26 20:54:52.446 
Epoch 345/1000 
	 loss: 16.3588, MinusLogProbMetric: 16.3588, val_loss: 17.4622, val_MinusLogProbMetric: 17.4622

Epoch 345: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3588 - MinusLogProbMetric: 16.3588 - val_loss: 17.4622 - val_MinusLogProbMetric: 17.4622 - lr: 1.6667e-04 - 74s/epoch - 379ms/step
Epoch 346/1000
2023-09-26 20:56:06.753 
Epoch 346/1000 
	 loss: 16.3841, MinusLogProbMetric: 16.3841, val_loss: 17.4350, val_MinusLogProbMetric: 17.4350

Epoch 346: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3841 - MinusLogProbMetric: 16.3841 - val_loss: 17.4350 - val_MinusLogProbMetric: 17.4350 - lr: 1.6667e-04 - 74s/epoch - 379ms/step
Epoch 347/1000
2023-09-26 20:57:19.969 
Epoch 347/1000 
	 loss: 16.3300, MinusLogProbMetric: 16.3300, val_loss: 17.5522, val_MinusLogProbMetric: 17.5522

Epoch 347: val_loss did not improve from 17.33767
196/196 - 73s - loss: 16.3300 - MinusLogProbMetric: 16.3300 - val_loss: 17.5522 - val_MinusLogProbMetric: 17.5522 - lr: 1.6667e-04 - 73s/epoch - 374ms/step
Epoch 348/1000
2023-09-26 20:58:33.781 
Epoch 348/1000 
	 loss: 16.3523, MinusLogProbMetric: 16.3523, val_loss: 17.5505, val_MinusLogProbMetric: 17.5505

Epoch 348: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3523 - MinusLogProbMetric: 16.3523 - val_loss: 17.5505 - val_MinusLogProbMetric: 17.5505 - lr: 1.6667e-04 - 74s/epoch - 377ms/step
Epoch 349/1000
2023-09-26 20:59:47.738 
Epoch 349/1000 
	 loss: 16.3395, MinusLogProbMetric: 16.3395, val_loss: 17.4713, val_MinusLogProbMetric: 17.4713

Epoch 349: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3395 - MinusLogProbMetric: 16.3395 - val_loss: 17.4713 - val_MinusLogProbMetric: 17.4713 - lr: 1.6667e-04 - 74s/epoch - 377ms/step
Epoch 350/1000
2023-09-26 21:01:01.704 
Epoch 350/1000 
	 loss: 16.3167, MinusLogProbMetric: 16.3167, val_loss: 17.4777, val_MinusLogProbMetric: 17.4777

Epoch 350: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3167 - MinusLogProbMetric: 16.3167 - val_loss: 17.4777 - val_MinusLogProbMetric: 17.4777 - lr: 1.6667e-04 - 74s/epoch - 377ms/step
Epoch 351/1000
2023-09-26 21:02:14.942 
Epoch 351/1000 
	 loss: 16.3404, MinusLogProbMetric: 16.3404, val_loss: 17.6377, val_MinusLogProbMetric: 17.6377

Epoch 351: val_loss did not improve from 17.33767
196/196 - 73s - loss: 16.3404 - MinusLogProbMetric: 16.3404 - val_loss: 17.6377 - val_MinusLogProbMetric: 17.6377 - lr: 1.6667e-04 - 73s/epoch - 374ms/step
Epoch 352/1000
2023-09-26 21:03:28.660 
Epoch 352/1000 
	 loss: 16.2956, MinusLogProbMetric: 16.2956, val_loss: 17.4961, val_MinusLogProbMetric: 17.4961

Epoch 352: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.2956 - MinusLogProbMetric: 16.2956 - val_loss: 17.4961 - val_MinusLogProbMetric: 17.4961 - lr: 1.6667e-04 - 74s/epoch - 376ms/step
Epoch 353/1000
2023-09-26 21:04:42.639 
Epoch 353/1000 
	 loss: 16.3369, MinusLogProbMetric: 16.3369, val_loss: 17.4240, val_MinusLogProbMetric: 17.4240

Epoch 353: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3369 - MinusLogProbMetric: 16.3369 - val_loss: 17.4240 - val_MinusLogProbMetric: 17.4240 - lr: 1.6667e-04 - 74s/epoch - 377ms/step
Epoch 354/1000
2023-09-26 21:05:56.958 
Epoch 354/1000 
	 loss: 16.3458, MinusLogProbMetric: 16.3458, val_loss: 17.4403, val_MinusLogProbMetric: 17.4403

Epoch 354: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3458 - MinusLogProbMetric: 16.3458 - val_loss: 17.4403 - val_MinusLogProbMetric: 17.4403 - lr: 1.6667e-04 - 74s/epoch - 379ms/step
Epoch 355/1000
2023-09-26 21:07:10.383 
Epoch 355/1000 
	 loss: 16.3352, MinusLogProbMetric: 16.3352, val_loss: 17.6927, val_MinusLogProbMetric: 17.6927

Epoch 355: val_loss did not improve from 17.33767
196/196 - 73s - loss: 16.3352 - MinusLogProbMetric: 16.3352 - val_loss: 17.6927 - val_MinusLogProbMetric: 17.6927 - lr: 1.6667e-04 - 73s/epoch - 375ms/step
Epoch 356/1000
2023-09-26 21:08:23.581 
Epoch 356/1000 
	 loss: 16.3459, MinusLogProbMetric: 16.3459, val_loss: 17.4554, val_MinusLogProbMetric: 17.4554

Epoch 356: val_loss did not improve from 17.33767
196/196 - 73s - loss: 16.3459 - MinusLogProbMetric: 16.3459 - val_loss: 17.4554 - val_MinusLogProbMetric: 17.4554 - lr: 1.6667e-04 - 73s/epoch - 373ms/step
Epoch 357/1000
2023-09-26 21:09:36.725 
Epoch 357/1000 
	 loss: 16.3266, MinusLogProbMetric: 16.3266, val_loss: 17.4062, val_MinusLogProbMetric: 17.4062

Epoch 357: val_loss did not improve from 17.33767
196/196 - 73s - loss: 16.3266 - MinusLogProbMetric: 16.3266 - val_loss: 17.4062 - val_MinusLogProbMetric: 17.4062 - lr: 1.6667e-04 - 73s/epoch - 373ms/step
Epoch 358/1000
2023-09-26 21:10:50.240 
Epoch 358/1000 
	 loss: 16.3090, MinusLogProbMetric: 16.3090, val_loss: 17.5125, val_MinusLogProbMetric: 17.5125

Epoch 358: val_loss did not improve from 17.33767
196/196 - 74s - loss: 16.3090 - MinusLogProbMetric: 16.3090 - val_loss: 17.5125 - val_MinusLogProbMetric: 17.5125 - lr: 1.6667e-04 - 74s/epoch - 375ms/step
Epoch 359/1000
2023-09-26 21:12:03.525 
Epoch 359/1000 
	 loss: 16.2954, MinusLogProbMetric: 16.2954, val_loss: 17.5124, val_MinusLogProbMetric: 17.5124

Epoch 359: val_loss did not improve from 17.33767
196/196 - 73s - loss: 16.2954 - MinusLogProbMetric: 16.2954 - val_loss: 17.5124 - val_MinusLogProbMetric: 17.5124 - lr: 1.6667e-04 - 73s/epoch - 374ms/step
Epoch 360/1000
2023-09-26 21:13:17.002 
Epoch 360/1000 
	 loss: 16.2969, MinusLogProbMetric: 16.2969, val_loss: 17.5485, val_MinusLogProbMetric: 17.5485

Epoch 360: val_loss did not improve from 17.33767
196/196 - 73s - loss: 16.2969 - MinusLogProbMetric: 16.2969 - val_loss: 17.5485 - val_MinusLogProbMetric: 17.5485 - lr: 1.6667e-04 - 73s/epoch - 375ms/step
Epoch 361/1000
2023-09-26 21:14:30.500 
Epoch 361/1000 
	 loss: 16.3445, MinusLogProbMetric: 16.3445, val_loss: 17.5418, val_MinusLogProbMetric: 17.5418

Epoch 361: val_loss did not improve from 17.33767
196/196 - 73s - loss: 16.3445 - MinusLogProbMetric: 16.3445 - val_loss: 17.5418 - val_MinusLogProbMetric: 17.5418 - lr: 1.6667e-04 - 73s/epoch - 375ms/step
Epoch 362/1000
2023-09-26 21:15:43.256 
Epoch 362/1000 
	 loss: 16.3366, MinusLogProbMetric: 16.3366, val_loss: 17.4685, val_MinusLogProbMetric: 17.4685

Epoch 362: val_loss did not improve from 17.33767
196/196 - 73s - loss: 16.3366 - MinusLogProbMetric: 16.3366 - val_loss: 17.4685 - val_MinusLogProbMetric: 17.4685 - lr: 1.6667e-04 - 73s/epoch - 371ms/step
Epoch 363/1000
2023-09-26 21:16:56.654 
Epoch 363/1000 
	 loss: 16.1578, MinusLogProbMetric: 16.1578, val_loss: 17.3377, val_MinusLogProbMetric: 17.3377

Epoch 363: val_loss did not improve from 17.33767
196/196 - 73s - loss: 16.1578 - MinusLogProbMetric: 16.1578 - val_loss: 17.3377 - val_MinusLogProbMetric: 17.3377 - lr: 8.3333e-05 - 73s/epoch - 374ms/step
Epoch 364/1000
2023-09-26 21:18:10.133 
Epoch 364/1000 
	 loss: 16.1332, MinusLogProbMetric: 16.1332, val_loss: 17.3119, val_MinusLogProbMetric: 17.3119

Epoch 364: val_loss improved from 17.33767 to 17.31186, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 75s - loss: 16.1332 - MinusLogProbMetric: 16.1332 - val_loss: 17.3119 - val_MinusLogProbMetric: 17.3119 - lr: 8.3333e-05 - 75s/epoch - 381ms/step
Epoch 365/1000
2023-09-26 21:19:25.081 
Epoch 365/1000 
	 loss: 16.1304, MinusLogProbMetric: 16.1304, val_loss: 17.4730, val_MinusLogProbMetric: 17.4730

Epoch 365: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1304 - MinusLogProbMetric: 16.1304 - val_loss: 17.4730 - val_MinusLogProbMetric: 17.4730 - lr: 8.3333e-05 - 74s/epoch - 377ms/step
Epoch 366/1000
2023-09-26 21:20:38.231 
Epoch 366/1000 
	 loss: 16.1467, MinusLogProbMetric: 16.1467, val_loss: 17.3498, val_MinusLogProbMetric: 17.3498

Epoch 366: val_loss did not improve from 17.31186
196/196 - 73s - loss: 16.1467 - MinusLogProbMetric: 16.1467 - val_loss: 17.3498 - val_MinusLogProbMetric: 17.3498 - lr: 8.3333e-05 - 73s/epoch - 373ms/step
Epoch 367/1000
2023-09-26 21:21:52.188 
Epoch 367/1000 
	 loss: 16.1350, MinusLogProbMetric: 16.1350, val_loss: 17.3398, val_MinusLogProbMetric: 17.3398

Epoch 367: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1350 - MinusLogProbMetric: 16.1350 - val_loss: 17.3398 - val_MinusLogProbMetric: 17.3398 - lr: 8.3333e-05 - 74s/epoch - 377ms/step
Epoch 368/1000
2023-09-26 21:23:05.590 
Epoch 368/1000 
	 loss: 16.1105, MinusLogProbMetric: 16.1105, val_loss: 17.3762, val_MinusLogProbMetric: 17.3762

Epoch 368: val_loss did not improve from 17.31186
196/196 - 73s - loss: 16.1105 - MinusLogProbMetric: 16.1105 - val_loss: 17.3762 - val_MinusLogProbMetric: 17.3762 - lr: 8.3333e-05 - 73s/epoch - 374ms/step
Epoch 369/1000
2023-09-26 21:24:18.815 
Epoch 369/1000 
	 loss: 16.1240, MinusLogProbMetric: 16.1240, val_loss: 17.3218, val_MinusLogProbMetric: 17.3218

Epoch 369: val_loss did not improve from 17.31186
196/196 - 73s - loss: 16.1240 - MinusLogProbMetric: 16.1240 - val_loss: 17.3218 - val_MinusLogProbMetric: 17.3218 - lr: 8.3333e-05 - 73s/epoch - 374ms/step
Epoch 370/1000
2023-09-26 21:25:32.407 
Epoch 370/1000 
	 loss: 16.1437, MinusLogProbMetric: 16.1437, val_loss: 17.3460, val_MinusLogProbMetric: 17.3460

Epoch 370: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1437 - MinusLogProbMetric: 16.1437 - val_loss: 17.3460 - val_MinusLogProbMetric: 17.3460 - lr: 8.3333e-05 - 74s/epoch - 375ms/step
Epoch 371/1000
2023-09-26 21:26:47.011 
Epoch 371/1000 
	 loss: 16.1272, MinusLogProbMetric: 16.1272, val_loss: 17.3439, val_MinusLogProbMetric: 17.3439

Epoch 371: val_loss did not improve from 17.31186
196/196 - 75s - loss: 16.1272 - MinusLogProbMetric: 16.1272 - val_loss: 17.3439 - val_MinusLogProbMetric: 17.3439 - lr: 8.3333e-05 - 75s/epoch - 381ms/step
Epoch 372/1000
2023-09-26 21:27:59.801 
Epoch 372/1000 
	 loss: 16.1802, MinusLogProbMetric: 16.1802, val_loss: 17.4099, val_MinusLogProbMetric: 17.4099

Epoch 372: val_loss did not improve from 17.31186
196/196 - 73s - loss: 16.1802 - MinusLogProbMetric: 16.1802 - val_loss: 17.4099 - val_MinusLogProbMetric: 17.4099 - lr: 8.3333e-05 - 73s/epoch - 371ms/step
Epoch 373/1000
2023-09-26 21:29:13.506 
Epoch 373/1000 
	 loss: 16.1288, MinusLogProbMetric: 16.1288, val_loss: 17.4543, val_MinusLogProbMetric: 17.4543

Epoch 373: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1288 - MinusLogProbMetric: 16.1288 - val_loss: 17.4543 - val_MinusLogProbMetric: 17.4543 - lr: 8.3333e-05 - 74s/epoch - 376ms/step
Epoch 374/1000
2023-09-26 21:30:27.624 
Epoch 374/1000 
	 loss: 16.1377, MinusLogProbMetric: 16.1377, val_loss: 17.3728, val_MinusLogProbMetric: 17.3728

Epoch 374: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1377 - MinusLogProbMetric: 16.1377 - val_loss: 17.3728 - val_MinusLogProbMetric: 17.3728 - lr: 8.3333e-05 - 74s/epoch - 378ms/step
Epoch 375/1000
2023-09-26 21:31:42.026 
Epoch 375/1000 
	 loss: 16.1199, MinusLogProbMetric: 16.1199, val_loss: 17.3680, val_MinusLogProbMetric: 17.3680

Epoch 375: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1199 - MinusLogProbMetric: 16.1199 - val_loss: 17.3680 - val_MinusLogProbMetric: 17.3680 - lr: 8.3333e-05 - 74s/epoch - 380ms/step
Epoch 376/1000
2023-09-26 21:32:55.736 
Epoch 376/1000 
	 loss: 16.1344, MinusLogProbMetric: 16.1344, val_loss: 17.3141, val_MinusLogProbMetric: 17.3141

Epoch 376: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1344 - MinusLogProbMetric: 16.1344 - val_loss: 17.3141 - val_MinusLogProbMetric: 17.3141 - lr: 8.3333e-05 - 74s/epoch - 376ms/step
Epoch 377/1000
2023-09-26 21:34:09.675 
Epoch 377/1000 
	 loss: 16.1097, MinusLogProbMetric: 16.1097, val_loss: 17.3734, val_MinusLogProbMetric: 17.3734

Epoch 377: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1097 - MinusLogProbMetric: 16.1097 - val_loss: 17.3734 - val_MinusLogProbMetric: 17.3734 - lr: 8.3333e-05 - 74s/epoch - 377ms/step
Epoch 378/1000
2023-09-26 21:35:24.050 
Epoch 378/1000 
	 loss: 16.1403, MinusLogProbMetric: 16.1403, val_loss: 17.3959, val_MinusLogProbMetric: 17.3959

Epoch 378: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1403 - MinusLogProbMetric: 16.1403 - val_loss: 17.3959 - val_MinusLogProbMetric: 17.3959 - lr: 8.3333e-05 - 74s/epoch - 379ms/step
Epoch 379/1000
2023-09-26 21:36:37.007 
Epoch 379/1000 
	 loss: 16.1181, MinusLogProbMetric: 16.1181, val_loss: 17.3779, val_MinusLogProbMetric: 17.3779

Epoch 379: val_loss did not improve from 17.31186
196/196 - 73s - loss: 16.1181 - MinusLogProbMetric: 16.1181 - val_loss: 17.3779 - val_MinusLogProbMetric: 17.3779 - lr: 8.3333e-05 - 73s/epoch - 372ms/step
Epoch 380/1000
2023-09-26 21:37:51.071 
Epoch 380/1000 
	 loss: 16.1189, MinusLogProbMetric: 16.1189, val_loss: 17.4034, val_MinusLogProbMetric: 17.4034

Epoch 380: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1189 - MinusLogProbMetric: 16.1189 - val_loss: 17.4034 - val_MinusLogProbMetric: 17.4034 - lr: 8.3333e-05 - 74s/epoch - 378ms/step
Epoch 381/1000
2023-09-26 21:39:04.922 
Epoch 381/1000 
	 loss: 16.1342, MinusLogProbMetric: 16.1342, val_loss: 17.4852, val_MinusLogProbMetric: 17.4852

Epoch 381: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1342 - MinusLogProbMetric: 16.1342 - val_loss: 17.4852 - val_MinusLogProbMetric: 17.4852 - lr: 8.3333e-05 - 74s/epoch - 377ms/step
Epoch 382/1000
2023-09-26 21:40:18.404 
Epoch 382/1000 
	 loss: 16.1245, MinusLogProbMetric: 16.1245, val_loss: 17.3303, val_MinusLogProbMetric: 17.3303

Epoch 382: val_loss did not improve from 17.31186
196/196 - 73s - loss: 16.1245 - MinusLogProbMetric: 16.1245 - val_loss: 17.3303 - val_MinusLogProbMetric: 17.3303 - lr: 8.3333e-05 - 73s/epoch - 375ms/step
Epoch 383/1000
2023-09-26 21:41:32.003 
Epoch 383/1000 
	 loss: 16.1242, MinusLogProbMetric: 16.1242, val_loss: 17.3667, val_MinusLogProbMetric: 17.3667

Epoch 383: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1242 - MinusLogProbMetric: 16.1242 - val_loss: 17.3667 - val_MinusLogProbMetric: 17.3667 - lr: 8.3333e-05 - 74s/epoch - 375ms/step
Epoch 384/1000
2023-09-26 21:42:45.291 
Epoch 384/1000 
	 loss: 16.1279, MinusLogProbMetric: 16.1279, val_loss: 17.4130, val_MinusLogProbMetric: 17.4130

Epoch 384: val_loss did not improve from 17.31186
196/196 - 73s - loss: 16.1279 - MinusLogProbMetric: 16.1279 - val_loss: 17.4130 - val_MinusLogProbMetric: 17.4130 - lr: 8.3333e-05 - 73s/epoch - 374ms/step
Epoch 385/1000
2023-09-26 21:43:58.118 
Epoch 385/1000 
	 loss: 16.1475, MinusLogProbMetric: 16.1475, val_loss: 17.4364, val_MinusLogProbMetric: 17.4364

Epoch 385: val_loss did not improve from 17.31186
196/196 - 73s - loss: 16.1475 - MinusLogProbMetric: 16.1475 - val_loss: 17.4364 - val_MinusLogProbMetric: 17.4364 - lr: 8.3333e-05 - 73s/epoch - 372ms/step
Epoch 386/1000
2023-09-26 21:45:11.647 
Epoch 386/1000 
	 loss: 16.1206, MinusLogProbMetric: 16.1206, val_loss: 17.4876, val_MinusLogProbMetric: 17.4876

Epoch 386: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1206 - MinusLogProbMetric: 16.1206 - val_loss: 17.4876 - val_MinusLogProbMetric: 17.4876 - lr: 8.3333e-05 - 74s/epoch - 375ms/step
Epoch 387/1000
2023-09-26 21:46:25.016 
Epoch 387/1000 
	 loss: 16.1129, MinusLogProbMetric: 16.1129, val_loss: 17.3563, val_MinusLogProbMetric: 17.3563

Epoch 387: val_loss did not improve from 17.31186
196/196 - 73s - loss: 16.1129 - MinusLogProbMetric: 16.1129 - val_loss: 17.3563 - val_MinusLogProbMetric: 17.3563 - lr: 8.3333e-05 - 73s/epoch - 374ms/step
Epoch 388/1000
2023-09-26 21:47:38.718 
Epoch 388/1000 
	 loss: 16.1137, MinusLogProbMetric: 16.1137, val_loss: 17.3782, val_MinusLogProbMetric: 17.3782

Epoch 388: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1137 - MinusLogProbMetric: 16.1137 - val_loss: 17.3782 - val_MinusLogProbMetric: 17.3782 - lr: 8.3333e-05 - 74s/epoch - 376ms/step
Epoch 389/1000
2023-09-26 21:48:52.304 
Epoch 389/1000 
	 loss: 16.1035, MinusLogProbMetric: 16.1035, val_loss: 17.3274, val_MinusLogProbMetric: 17.3274

Epoch 389: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1035 - MinusLogProbMetric: 16.1035 - val_loss: 17.3274 - val_MinusLogProbMetric: 17.3274 - lr: 8.3333e-05 - 74s/epoch - 375ms/step
Epoch 390/1000
2023-09-26 21:50:06.302 
Epoch 390/1000 
	 loss: 16.1216, MinusLogProbMetric: 16.1216, val_loss: 17.4063, val_MinusLogProbMetric: 17.4063

Epoch 390: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1216 - MinusLogProbMetric: 16.1216 - val_loss: 17.4063 - val_MinusLogProbMetric: 17.4063 - lr: 8.3333e-05 - 74s/epoch - 378ms/step
Epoch 391/1000
2023-09-26 21:51:19.291 
Epoch 391/1000 
	 loss: 16.1045, MinusLogProbMetric: 16.1045, val_loss: 17.3737, val_MinusLogProbMetric: 17.3737

Epoch 391: val_loss did not improve from 17.31186
196/196 - 73s - loss: 16.1045 - MinusLogProbMetric: 16.1045 - val_loss: 17.3737 - val_MinusLogProbMetric: 17.3737 - lr: 8.3333e-05 - 73s/epoch - 372ms/step
Epoch 392/1000
2023-09-26 21:52:33.593 
Epoch 392/1000 
	 loss: 16.1273, MinusLogProbMetric: 16.1273, val_loss: 17.7865, val_MinusLogProbMetric: 17.7865

Epoch 392: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1273 - MinusLogProbMetric: 16.1273 - val_loss: 17.7865 - val_MinusLogProbMetric: 17.7865 - lr: 8.3333e-05 - 74s/epoch - 379ms/step
Epoch 393/1000
2023-09-26 21:53:47.047 
Epoch 393/1000 
	 loss: 16.1145, MinusLogProbMetric: 16.1145, val_loss: 17.3632, val_MinusLogProbMetric: 17.3632

Epoch 393: val_loss did not improve from 17.31186
196/196 - 73s - loss: 16.1145 - MinusLogProbMetric: 16.1145 - val_loss: 17.3632 - val_MinusLogProbMetric: 17.3632 - lr: 8.3333e-05 - 73s/epoch - 375ms/step
Epoch 394/1000
2023-09-26 21:55:00.846 
Epoch 394/1000 
	 loss: 16.1145, MinusLogProbMetric: 16.1145, val_loss: 17.4138, val_MinusLogProbMetric: 17.4138

Epoch 394: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1145 - MinusLogProbMetric: 16.1145 - val_loss: 17.4138 - val_MinusLogProbMetric: 17.4138 - lr: 8.3333e-05 - 74s/epoch - 377ms/step
Epoch 395/1000
2023-09-26 21:56:14.244 
Epoch 395/1000 
	 loss: 16.1160, MinusLogProbMetric: 16.1160, val_loss: 17.3797, val_MinusLogProbMetric: 17.3797

Epoch 395: val_loss did not improve from 17.31186
196/196 - 73s - loss: 16.1160 - MinusLogProbMetric: 16.1160 - val_loss: 17.3797 - val_MinusLogProbMetric: 17.3797 - lr: 8.3333e-05 - 73s/epoch - 374ms/step
Epoch 396/1000
2023-09-26 21:57:27.981 
Epoch 396/1000 
	 loss: 16.1219, MinusLogProbMetric: 16.1219, val_loss: 17.3255, val_MinusLogProbMetric: 17.3255

Epoch 396: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1219 - MinusLogProbMetric: 16.1219 - val_loss: 17.3255 - val_MinusLogProbMetric: 17.3255 - lr: 8.3333e-05 - 74s/epoch - 376ms/step
Epoch 397/1000
2023-09-26 21:58:41.820 
Epoch 397/1000 
	 loss: 16.0999, MinusLogProbMetric: 16.0999, val_loss: 17.3173, val_MinusLogProbMetric: 17.3173

Epoch 397: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.0999 - MinusLogProbMetric: 16.0999 - val_loss: 17.3173 - val_MinusLogProbMetric: 17.3173 - lr: 8.3333e-05 - 74s/epoch - 377ms/step
Epoch 398/1000
2023-09-26 21:59:55.030 
Epoch 398/1000 
	 loss: 16.1634, MinusLogProbMetric: 16.1634, val_loss: 17.3391, val_MinusLogProbMetric: 17.3391

Epoch 398: val_loss did not improve from 17.31186
196/196 - 73s - loss: 16.1634 - MinusLogProbMetric: 16.1634 - val_loss: 17.3391 - val_MinusLogProbMetric: 17.3391 - lr: 8.3333e-05 - 73s/epoch - 373ms/step
Epoch 399/1000
2023-09-26 22:01:09.243 
Epoch 399/1000 
	 loss: 16.1236, MinusLogProbMetric: 16.1236, val_loss: 17.3758, val_MinusLogProbMetric: 17.3758

Epoch 399: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1236 - MinusLogProbMetric: 16.1236 - val_loss: 17.3758 - val_MinusLogProbMetric: 17.3758 - lr: 8.3333e-05 - 74s/epoch - 379ms/step
Epoch 400/1000
2023-09-26 22:02:23.436 
Epoch 400/1000 
	 loss: 16.1193, MinusLogProbMetric: 16.1193, val_loss: 17.4146, val_MinusLogProbMetric: 17.4146

Epoch 400: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1193 - MinusLogProbMetric: 16.1193 - val_loss: 17.4146 - val_MinusLogProbMetric: 17.4146 - lr: 8.3333e-05 - 74s/epoch - 379ms/step
Epoch 401/1000
2023-09-26 22:03:36.802 
Epoch 401/1000 
	 loss: 16.1653, MinusLogProbMetric: 16.1653, val_loss: 17.4418, val_MinusLogProbMetric: 17.4418

Epoch 401: val_loss did not improve from 17.31186
196/196 - 73s - loss: 16.1653 - MinusLogProbMetric: 16.1653 - val_loss: 17.4418 - val_MinusLogProbMetric: 17.4418 - lr: 8.3333e-05 - 73s/epoch - 374ms/step
Epoch 402/1000
2023-09-26 22:04:50.990 
Epoch 402/1000 
	 loss: 16.1010, MinusLogProbMetric: 16.1010, val_loss: 17.4109, val_MinusLogProbMetric: 17.4109

Epoch 402: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1010 - MinusLogProbMetric: 16.1010 - val_loss: 17.4109 - val_MinusLogProbMetric: 17.4109 - lr: 8.3333e-05 - 74s/epoch - 378ms/step
Epoch 403/1000
2023-09-26 22:06:04.685 
Epoch 403/1000 
	 loss: 16.0950, MinusLogProbMetric: 16.0950, val_loss: 17.4174, val_MinusLogProbMetric: 17.4174

Epoch 403: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.0950 - MinusLogProbMetric: 16.0950 - val_loss: 17.4174 - val_MinusLogProbMetric: 17.4174 - lr: 8.3333e-05 - 74s/epoch - 376ms/step
Epoch 404/1000
2023-09-26 22:07:18.558 
Epoch 404/1000 
	 loss: 16.0955, MinusLogProbMetric: 16.0955, val_loss: 17.3445, val_MinusLogProbMetric: 17.3445

Epoch 404: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.0955 - MinusLogProbMetric: 16.0955 - val_loss: 17.3445 - val_MinusLogProbMetric: 17.3445 - lr: 8.3333e-05 - 74s/epoch - 377ms/step
Epoch 405/1000
2023-09-26 22:08:32.208 
Epoch 405/1000 
	 loss: 16.0870, MinusLogProbMetric: 16.0870, val_loss: 17.3672, val_MinusLogProbMetric: 17.3672

Epoch 405: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.0870 - MinusLogProbMetric: 16.0870 - val_loss: 17.3672 - val_MinusLogProbMetric: 17.3672 - lr: 8.3333e-05 - 74s/epoch - 376ms/step
Epoch 406/1000
2023-09-26 22:09:46.370 
Epoch 406/1000 
	 loss: 16.0851, MinusLogProbMetric: 16.0851, val_loss: 17.3600, val_MinusLogProbMetric: 17.3600

Epoch 406: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.0851 - MinusLogProbMetric: 16.0851 - val_loss: 17.3600 - val_MinusLogProbMetric: 17.3600 - lr: 8.3333e-05 - 74s/epoch - 378ms/step
Epoch 407/1000
2023-09-26 22:11:00.208 
Epoch 407/1000 
	 loss: 16.0973, MinusLogProbMetric: 16.0973, val_loss: 17.3807, val_MinusLogProbMetric: 17.3807

Epoch 407: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.0973 - MinusLogProbMetric: 16.0973 - val_loss: 17.3807 - val_MinusLogProbMetric: 17.3807 - lr: 8.3333e-05 - 74s/epoch - 377ms/step
Epoch 408/1000
2023-09-26 22:12:14.375 
Epoch 408/1000 
	 loss: 16.0862, MinusLogProbMetric: 16.0862, val_loss: 17.3937, val_MinusLogProbMetric: 17.3937

Epoch 408: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.0862 - MinusLogProbMetric: 16.0862 - val_loss: 17.3937 - val_MinusLogProbMetric: 17.3937 - lr: 8.3333e-05 - 74s/epoch - 378ms/step
Epoch 409/1000
2023-09-26 22:13:28.090 
Epoch 409/1000 
	 loss: 16.1117, MinusLogProbMetric: 16.1117, val_loss: 17.3512, val_MinusLogProbMetric: 17.3512

Epoch 409: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1117 - MinusLogProbMetric: 16.1117 - val_loss: 17.3512 - val_MinusLogProbMetric: 17.3512 - lr: 8.3333e-05 - 74s/epoch - 376ms/step
Epoch 410/1000
2023-09-26 22:14:41.963 
Epoch 410/1000 
	 loss: 16.0684, MinusLogProbMetric: 16.0684, val_loss: 17.3634, val_MinusLogProbMetric: 17.3634

Epoch 410: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.0684 - MinusLogProbMetric: 16.0684 - val_loss: 17.3634 - val_MinusLogProbMetric: 17.3634 - lr: 8.3333e-05 - 74s/epoch - 377ms/step
Epoch 411/1000
2023-09-26 22:15:56.286 
Epoch 411/1000 
	 loss: 16.1427, MinusLogProbMetric: 16.1427, val_loss: 17.4410, val_MinusLogProbMetric: 17.4410

Epoch 411: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1427 - MinusLogProbMetric: 16.1427 - val_loss: 17.4410 - val_MinusLogProbMetric: 17.4410 - lr: 8.3333e-05 - 74s/epoch - 379ms/step
Epoch 412/1000
2023-09-26 22:17:09.575 
Epoch 412/1000 
	 loss: 16.1122, MinusLogProbMetric: 16.1122, val_loss: 17.4289, val_MinusLogProbMetric: 17.4289

Epoch 412: val_loss did not improve from 17.31186
196/196 - 73s - loss: 16.1122 - MinusLogProbMetric: 16.1122 - val_loss: 17.4289 - val_MinusLogProbMetric: 17.4289 - lr: 8.3333e-05 - 73s/epoch - 374ms/step
Epoch 413/1000
2023-09-26 22:18:23.638 
Epoch 413/1000 
	 loss: 16.1078, MinusLogProbMetric: 16.1078, val_loss: 17.3528, val_MinusLogProbMetric: 17.3528

Epoch 413: val_loss did not improve from 17.31186
196/196 - 74s - loss: 16.1078 - MinusLogProbMetric: 16.1078 - val_loss: 17.3528 - val_MinusLogProbMetric: 17.3528 - lr: 8.3333e-05 - 74s/epoch - 378ms/step
Epoch 414/1000
2023-09-26 22:19:37.107 
Epoch 414/1000 
	 loss: 16.0809, MinusLogProbMetric: 16.0809, val_loss: 17.3998, val_MinusLogProbMetric: 17.3998

Epoch 414: val_loss did not improve from 17.31186
196/196 - 73s - loss: 16.0809 - MinusLogProbMetric: 16.0809 - val_loss: 17.3998 - val_MinusLogProbMetric: 17.3998 - lr: 8.3333e-05 - 73s/epoch - 375ms/step
Epoch 415/1000
2023-09-26 22:20:51.015 
Epoch 415/1000 
	 loss: 16.0135, MinusLogProbMetric: 16.0135, val_loss: 17.3050, val_MinusLogProbMetric: 17.3050

Epoch 415: val_loss improved from 17.31186 to 17.30502, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_288/weights/best_weights.h5
196/196 - 75s - loss: 16.0135 - MinusLogProbMetric: 16.0135 - val_loss: 17.3050 - val_MinusLogProbMetric: 17.3050 - lr: 4.1667e-05 - 75s/epoch - 384ms/step
Epoch 416/1000
2023-09-26 22:22:06.042 
Epoch 416/1000 
	 loss: 16.0065, MinusLogProbMetric: 16.0065, val_loss: 17.3160, val_MinusLogProbMetric: 17.3160

Epoch 416: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0065 - MinusLogProbMetric: 16.0065 - val_loss: 17.3160 - val_MinusLogProbMetric: 17.3160 - lr: 4.1667e-05 - 74s/epoch - 376ms/step
Epoch 417/1000
2023-09-26 22:23:20.064 
Epoch 417/1000 
	 loss: 16.0158, MinusLogProbMetric: 16.0158, val_loss: 17.4075, val_MinusLogProbMetric: 17.4075

Epoch 417: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0158 - MinusLogProbMetric: 16.0158 - val_loss: 17.4075 - val_MinusLogProbMetric: 17.4075 - lr: 4.1667e-05 - 74s/epoch - 378ms/step
Epoch 418/1000
2023-09-26 22:24:33.712 
Epoch 418/1000 
	 loss: 16.0078, MinusLogProbMetric: 16.0078, val_loss: 17.3202, val_MinusLogProbMetric: 17.3202

Epoch 418: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0078 - MinusLogProbMetric: 16.0078 - val_loss: 17.3202 - val_MinusLogProbMetric: 17.3202 - lr: 4.1667e-05 - 74s/epoch - 376ms/step
Epoch 419/1000
2023-09-26 22:25:47.439 
Epoch 419/1000 
	 loss: 16.0038, MinusLogProbMetric: 16.0038, val_loss: 17.3759, val_MinusLogProbMetric: 17.3759

Epoch 419: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0038 - MinusLogProbMetric: 16.0038 - val_loss: 17.3759 - val_MinusLogProbMetric: 17.3759 - lr: 4.1667e-05 - 74s/epoch - 376ms/step
Epoch 420/1000
2023-09-26 22:27:01.138 
Epoch 420/1000 
	 loss: 16.0117, MinusLogProbMetric: 16.0117, val_loss: 17.3298, val_MinusLogProbMetric: 17.3298

Epoch 420: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0117 - MinusLogProbMetric: 16.0117 - val_loss: 17.3298 - val_MinusLogProbMetric: 17.3298 - lr: 4.1667e-05 - 74s/epoch - 376ms/step
Epoch 421/1000
2023-09-26 22:28:15.404 
Epoch 421/1000 
	 loss: 16.0126, MinusLogProbMetric: 16.0126, val_loss: 17.3612, val_MinusLogProbMetric: 17.3612

Epoch 421: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0126 - MinusLogProbMetric: 16.0126 - val_loss: 17.3612 - val_MinusLogProbMetric: 17.3612 - lr: 4.1667e-05 - 74s/epoch - 379ms/step
Epoch 422/1000
2023-09-26 22:29:29.241 
Epoch 422/1000 
	 loss: 16.0120, MinusLogProbMetric: 16.0120, val_loss: 17.3350, val_MinusLogProbMetric: 17.3350

Epoch 422: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0120 - MinusLogProbMetric: 16.0120 - val_loss: 17.3350 - val_MinusLogProbMetric: 17.3350 - lr: 4.1667e-05 - 74s/epoch - 377ms/step
Epoch 423/1000
2023-09-26 22:30:42.889 
Epoch 423/1000 
	 loss: 16.0158, MinusLogProbMetric: 16.0158, val_loss: 17.3327, val_MinusLogProbMetric: 17.3327

Epoch 423: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0158 - MinusLogProbMetric: 16.0158 - val_loss: 17.3327 - val_MinusLogProbMetric: 17.3327 - lr: 4.1667e-05 - 74s/epoch - 376ms/step
Epoch 424/1000
2023-09-26 22:31:56.168 
Epoch 424/1000 
	 loss: 16.0042, MinusLogProbMetric: 16.0042, val_loss: 17.3546, val_MinusLogProbMetric: 17.3546

Epoch 424: val_loss did not improve from 17.30502
196/196 - 73s - loss: 16.0042 - MinusLogProbMetric: 16.0042 - val_loss: 17.3546 - val_MinusLogProbMetric: 17.3546 - lr: 4.1667e-05 - 73s/epoch - 374ms/step
Epoch 425/1000
2023-09-26 22:33:05.189 
Epoch 425/1000 
	 loss: 16.0039, MinusLogProbMetric: 16.0039, val_loss: 17.3213, val_MinusLogProbMetric: 17.3213

Epoch 425: val_loss did not improve from 17.30502
196/196 - 69s - loss: 16.0039 - MinusLogProbMetric: 16.0039 - val_loss: 17.3213 - val_MinusLogProbMetric: 17.3213 - lr: 4.1667e-05 - 69s/epoch - 352ms/step
Epoch 426/1000
2023-09-26 22:34:09.971 
Epoch 426/1000 
	 loss: 16.0024, MinusLogProbMetric: 16.0024, val_loss: 17.3568, val_MinusLogProbMetric: 17.3568

Epoch 426: val_loss did not improve from 17.30502
196/196 - 65s - loss: 16.0024 - MinusLogProbMetric: 16.0024 - val_loss: 17.3568 - val_MinusLogProbMetric: 17.3568 - lr: 4.1667e-05 - 65s/epoch - 331ms/step
Epoch 427/1000
2023-09-26 22:35:22.736 
Epoch 427/1000 
	 loss: 16.0065, MinusLogProbMetric: 16.0065, val_loss: 17.3472, val_MinusLogProbMetric: 17.3472

Epoch 427: val_loss did not improve from 17.30502
196/196 - 73s - loss: 16.0065 - MinusLogProbMetric: 16.0065 - val_loss: 17.3472 - val_MinusLogProbMetric: 17.3472 - lr: 4.1667e-05 - 73s/epoch - 371ms/step
Epoch 428/1000
2023-09-26 22:36:29.373 
Epoch 428/1000 
	 loss: 16.0096, MinusLogProbMetric: 16.0096, val_loss: 17.3288, val_MinusLogProbMetric: 17.3288

Epoch 428: val_loss did not improve from 17.30502
196/196 - 67s - loss: 16.0096 - MinusLogProbMetric: 16.0096 - val_loss: 17.3288 - val_MinusLogProbMetric: 17.3288 - lr: 4.1667e-05 - 67s/epoch - 340ms/step
Epoch 429/1000
2023-09-26 22:37:35.033 
Epoch 429/1000 
	 loss: 16.0029, MinusLogProbMetric: 16.0029, val_loss: 17.4294, val_MinusLogProbMetric: 17.4294

Epoch 429: val_loss did not improve from 17.30502
196/196 - 66s - loss: 16.0029 - MinusLogProbMetric: 16.0029 - val_loss: 17.4294 - val_MinusLogProbMetric: 17.4294 - lr: 4.1667e-05 - 66s/epoch - 335ms/step
Epoch 430/1000
2023-09-26 22:38:48.602 
Epoch 430/1000 
	 loss: 16.0197, MinusLogProbMetric: 16.0197, val_loss: 17.3926, val_MinusLogProbMetric: 17.3926

Epoch 430: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0197 - MinusLogProbMetric: 16.0197 - val_loss: 17.3926 - val_MinusLogProbMetric: 17.3926 - lr: 4.1667e-05 - 74s/epoch - 375ms/step
Epoch 431/1000
2023-09-26 22:40:01.866 
Epoch 431/1000 
	 loss: 16.0103, MinusLogProbMetric: 16.0103, val_loss: 17.4128, val_MinusLogProbMetric: 17.4128

Epoch 431: val_loss did not improve from 17.30502
196/196 - 73s - loss: 16.0103 - MinusLogProbMetric: 16.0103 - val_loss: 17.4128 - val_MinusLogProbMetric: 17.4128 - lr: 4.1667e-05 - 73s/epoch - 374ms/step
Epoch 432/1000
2023-09-26 22:41:15.800 
Epoch 432/1000 
	 loss: 16.0084, MinusLogProbMetric: 16.0084, val_loss: 17.3306, val_MinusLogProbMetric: 17.3306

Epoch 432: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0084 - MinusLogProbMetric: 16.0084 - val_loss: 17.3306 - val_MinusLogProbMetric: 17.3306 - lr: 4.1667e-05 - 74s/epoch - 377ms/step
Epoch 433/1000
2023-09-26 22:42:29.241 
Epoch 433/1000 
	 loss: 16.0086, MinusLogProbMetric: 16.0086, val_loss: 17.3252, val_MinusLogProbMetric: 17.3252

Epoch 433: val_loss did not improve from 17.30502
196/196 - 73s - loss: 16.0086 - MinusLogProbMetric: 16.0086 - val_loss: 17.3252 - val_MinusLogProbMetric: 17.3252 - lr: 4.1667e-05 - 73s/epoch - 375ms/step
Epoch 434/1000
2023-09-26 22:43:43.780 
Epoch 434/1000 
	 loss: 16.0027, MinusLogProbMetric: 16.0027, val_loss: 17.3176, val_MinusLogProbMetric: 17.3176

Epoch 434: val_loss did not improve from 17.30502
196/196 - 75s - loss: 16.0027 - MinusLogProbMetric: 16.0027 - val_loss: 17.3176 - val_MinusLogProbMetric: 17.3176 - lr: 4.1667e-05 - 75s/epoch - 380ms/step
Epoch 435/1000
2023-09-26 22:44:57.181 
Epoch 435/1000 
	 loss: 16.0011, MinusLogProbMetric: 16.0011, val_loss: 17.3435, val_MinusLogProbMetric: 17.3435

Epoch 435: val_loss did not improve from 17.30502
196/196 - 73s - loss: 16.0011 - MinusLogProbMetric: 16.0011 - val_loss: 17.3435 - val_MinusLogProbMetric: 17.3435 - lr: 4.1667e-05 - 73s/epoch - 374ms/step
Epoch 436/1000
2023-09-26 22:46:10.988 
Epoch 436/1000 
	 loss: 16.0074, MinusLogProbMetric: 16.0074, val_loss: 17.3504, val_MinusLogProbMetric: 17.3504

Epoch 436: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0074 - MinusLogProbMetric: 16.0074 - val_loss: 17.3504 - val_MinusLogProbMetric: 17.3504 - lr: 4.1667e-05 - 74s/epoch - 377ms/step
Epoch 437/1000
2023-09-26 22:47:24.897 
Epoch 437/1000 
	 loss: 16.0014, MinusLogProbMetric: 16.0014, val_loss: 17.3581, val_MinusLogProbMetric: 17.3581

Epoch 437: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0014 - MinusLogProbMetric: 16.0014 - val_loss: 17.3581 - val_MinusLogProbMetric: 17.3581 - lr: 4.1667e-05 - 74s/epoch - 377ms/step
Epoch 438/1000
2023-09-26 22:48:38.428 
Epoch 438/1000 
	 loss: 16.0084, MinusLogProbMetric: 16.0084, val_loss: 17.3442, val_MinusLogProbMetric: 17.3442

Epoch 438: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0084 - MinusLogProbMetric: 16.0084 - val_loss: 17.3442 - val_MinusLogProbMetric: 17.3442 - lr: 4.1667e-05 - 74s/epoch - 375ms/step
Epoch 439/1000
2023-09-26 22:49:52.408 
Epoch 439/1000 
	 loss: 15.9962, MinusLogProbMetric: 15.9962, val_loss: 17.3390, val_MinusLogProbMetric: 17.3390

Epoch 439: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9962 - MinusLogProbMetric: 15.9962 - val_loss: 17.3390 - val_MinusLogProbMetric: 17.3390 - lr: 4.1667e-05 - 74s/epoch - 377ms/step
Epoch 440/1000
2023-09-26 22:51:06.334 
Epoch 440/1000 
	 loss: 16.0099, MinusLogProbMetric: 16.0099, val_loss: 17.3483, val_MinusLogProbMetric: 17.3483

Epoch 440: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0099 - MinusLogProbMetric: 16.0099 - val_loss: 17.3483 - val_MinusLogProbMetric: 17.3483 - lr: 4.1667e-05 - 74s/epoch - 377ms/step
Epoch 441/1000
2023-09-26 22:52:19.300 
Epoch 441/1000 
	 loss: 16.0035, MinusLogProbMetric: 16.0035, val_loss: 17.3881, val_MinusLogProbMetric: 17.3881

Epoch 441: val_loss did not improve from 17.30502
196/196 - 73s - loss: 16.0035 - MinusLogProbMetric: 16.0035 - val_loss: 17.3881 - val_MinusLogProbMetric: 17.3881 - lr: 4.1667e-05 - 73s/epoch - 372ms/step
Epoch 442/1000
2023-09-26 22:53:33.298 
Epoch 442/1000 
	 loss: 16.0005, MinusLogProbMetric: 16.0005, val_loss: 17.3343, val_MinusLogProbMetric: 17.3343

Epoch 442: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0005 - MinusLogProbMetric: 16.0005 - val_loss: 17.3343 - val_MinusLogProbMetric: 17.3343 - lr: 4.1667e-05 - 74s/epoch - 378ms/step
Epoch 443/1000
2023-09-26 22:54:46.803 
Epoch 443/1000 
	 loss: 15.9997, MinusLogProbMetric: 15.9997, val_loss: 17.3625, val_MinusLogProbMetric: 17.3625

Epoch 443: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9997 - MinusLogProbMetric: 15.9997 - val_loss: 17.3625 - val_MinusLogProbMetric: 17.3625 - lr: 4.1667e-05 - 74s/epoch - 375ms/step
Epoch 444/1000
2023-09-26 22:56:00.818 
Epoch 444/1000 
	 loss: 16.0048, MinusLogProbMetric: 16.0048, val_loss: 17.3552, val_MinusLogProbMetric: 17.3552

Epoch 444: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0048 - MinusLogProbMetric: 16.0048 - val_loss: 17.3552 - val_MinusLogProbMetric: 17.3552 - lr: 4.1667e-05 - 74s/epoch - 378ms/step
Epoch 445/1000
2023-09-26 22:57:14.585 
Epoch 445/1000 
	 loss: 16.0011, MinusLogProbMetric: 16.0011, val_loss: 17.3457, val_MinusLogProbMetric: 17.3457

Epoch 445: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0011 - MinusLogProbMetric: 16.0011 - val_loss: 17.3457 - val_MinusLogProbMetric: 17.3457 - lr: 4.1667e-05 - 74s/epoch - 376ms/step
Epoch 446/1000
2023-09-26 22:58:28.758 
Epoch 446/1000 
	 loss: 16.0033, MinusLogProbMetric: 16.0033, val_loss: 17.3261, val_MinusLogProbMetric: 17.3261

Epoch 446: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0033 - MinusLogProbMetric: 16.0033 - val_loss: 17.3261 - val_MinusLogProbMetric: 17.3261 - lr: 4.1667e-05 - 74s/epoch - 378ms/step
Epoch 447/1000
2023-09-26 22:59:42.781 
Epoch 447/1000 
	 loss: 16.0014, MinusLogProbMetric: 16.0014, val_loss: 17.3306, val_MinusLogProbMetric: 17.3306

Epoch 447: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0014 - MinusLogProbMetric: 16.0014 - val_loss: 17.3306 - val_MinusLogProbMetric: 17.3306 - lr: 4.1667e-05 - 74s/epoch - 378ms/step
Epoch 448/1000
2023-09-26 23:00:56.778 
Epoch 448/1000 
	 loss: 16.0021, MinusLogProbMetric: 16.0021, val_loss: 17.4005, val_MinusLogProbMetric: 17.4005

Epoch 448: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0021 - MinusLogProbMetric: 16.0021 - val_loss: 17.4005 - val_MinusLogProbMetric: 17.4005 - lr: 4.1667e-05 - 74s/epoch - 378ms/step
Epoch 449/1000
2023-09-26 23:02:10.129 
Epoch 449/1000 
	 loss: 16.0024, MinusLogProbMetric: 16.0024, val_loss: 17.3458, val_MinusLogProbMetric: 17.3458

Epoch 449: val_loss did not improve from 17.30502
196/196 - 73s - loss: 16.0024 - MinusLogProbMetric: 16.0024 - val_loss: 17.3458 - val_MinusLogProbMetric: 17.3458 - lr: 4.1667e-05 - 73s/epoch - 374ms/step
Epoch 450/1000
2023-09-26 23:03:24.715 
Epoch 450/1000 
	 loss: 15.9958, MinusLogProbMetric: 15.9958, val_loss: 17.3768, val_MinusLogProbMetric: 17.3768

Epoch 450: val_loss did not improve from 17.30502
196/196 - 75s - loss: 15.9958 - MinusLogProbMetric: 15.9958 - val_loss: 17.3768 - val_MinusLogProbMetric: 17.3768 - lr: 4.1667e-05 - 75s/epoch - 381ms/step
Epoch 451/1000
2023-09-26 23:04:39.649 
Epoch 451/1000 
	 loss: 15.9985, MinusLogProbMetric: 15.9985, val_loss: 17.3317, val_MinusLogProbMetric: 17.3317

Epoch 451: val_loss did not improve from 17.30502
196/196 - 75s - loss: 15.9985 - MinusLogProbMetric: 15.9985 - val_loss: 17.3317 - val_MinusLogProbMetric: 17.3317 - lr: 4.1667e-05 - 75s/epoch - 382ms/step
Epoch 452/1000
2023-09-26 23:05:53.879 
Epoch 452/1000 
	 loss: 16.0099, MinusLogProbMetric: 16.0099, val_loss: 17.3734, val_MinusLogProbMetric: 17.3734

Epoch 452: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0099 - MinusLogProbMetric: 16.0099 - val_loss: 17.3734 - val_MinusLogProbMetric: 17.3734 - lr: 4.1667e-05 - 74s/epoch - 379ms/step
Epoch 453/1000
2023-09-26 23:07:07.562 
Epoch 453/1000 
	 loss: 15.9987, MinusLogProbMetric: 15.9987, val_loss: 17.3275, val_MinusLogProbMetric: 17.3275

Epoch 453: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9987 - MinusLogProbMetric: 15.9987 - val_loss: 17.3275 - val_MinusLogProbMetric: 17.3275 - lr: 4.1667e-05 - 74s/epoch - 376ms/step
Epoch 454/1000
2023-09-26 23:08:21.617 
Epoch 454/1000 
	 loss: 15.9961, MinusLogProbMetric: 15.9961, val_loss: 17.4386, val_MinusLogProbMetric: 17.4386

Epoch 454: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9961 - MinusLogProbMetric: 15.9961 - val_loss: 17.4386 - val_MinusLogProbMetric: 17.4386 - lr: 4.1667e-05 - 74s/epoch - 378ms/step
Epoch 455/1000
2023-09-26 23:09:35.488 
Epoch 455/1000 
	 loss: 15.9923, MinusLogProbMetric: 15.9923, val_loss: 17.3597, val_MinusLogProbMetric: 17.3597

Epoch 455: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9923 - MinusLogProbMetric: 15.9923 - val_loss: 17.3597 - val_MinusLogProbMetric: 17.3597 - lr: 4.1667e-05 - 74s/epoch - 377ms/step
Epoch 456/1000
2023-09-26 23:10:49.544 
Epoch 456/1000 
	 loss: 16.0146, MinusLogProbMetric: 16.0146, val_loss: 17.3561, val_MinusLogProbMetric: 17.3561

Epoch 456: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0146 - MinusLogProbMetric: 16.0146 - val_loss: 17.3561 - val_MinusLogProbMetric: 17.3561 - lr: 4.1667e-05 - 74s/epoch - 378ms/step
Epoch 457/1000
2023-09-26 23:12:02.972 
Epoch 457/1000 
	 loss: 15.9955, MinusLogProbMetric: 15.9955, val_loss: 17.3309, val_MinusLogProbMetric: 17.3309

Epoch 457: val_loss did not improve from 17.30502
196/196 - 73s - loss: 15.9955 - MinusLogProbMetric: 15.9955 - val_loss: 17.3309 - val_MinusLogProbMetric: 17.3309 - lr: 4.1667e-05 - 73s/epoch - 375ms/step
Epoch 458/1000
2023-09-26 23:13:17.132 
Epoch 458/1000 
	 loss: 16.0062, MinusLogProbMetric: 16.0062, val_loss: 17.3832, val_MinusLogProbMetric: 17.3832

Epoch 458: val_loss did not improve from 17.30502
196/196 - 74s - loss: 16.0062 - MinusLogProbMetric: 16.0062 - val_loss: 17.3832 - val_MinusLogProbMetric: 17.3832 - lr: 4.1667e-05 - 74s/epoch - 378ms/step
Epoch 459/1000
2023-09-26 23:14:30.852 
Epoch 459/1000 
	 loss: 15.9995, MinusLogProbMetric: 15.9995, val_loss: 17.3234, val_MinusLogProbMetric: 17.3234

Epoch 459: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9995 - MinusLogProbMetric: 15.9995 - val_loss: 17.3234 - val_MinusLogProbMetric: 17.3234 - lr: 4.1667e-05 - 74s/epoch - 376ms/step
Epoch 460/1000
2023-09-26 23:15:44.631 
Epoch 460/1000 
	 loss: 15.9939, MinusLogProbMetric: 15.9939, val_loss: 17.3380, val_MinusLogProbMetric: 17.3380

Epoch 460: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9939 - MinusLogProbMetric: 15.9939 - val_loss: 17.3380 - val_MinusLogProbMetric: 17.3380 - lr: 4.1667e-05 - 74s/epoch - 376ms/step
Epoch 461/1000
2023-09-26 23:16:58.351 
Epoch 461/1000 
	 loss: 15.9960, MinusLogProbMetric: 15.9960, val_loss: 17.3215, val_MinusLogProbMetric: 17.3215

Epoch 461: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9960 - MinusLogProbMetric: 15.9960 - val_loss: 17.3215 - val_MinusLogProbMetric: 17.3215 - lr: 4.1667e-05 - 74s/epoch - 376ms/step
Epoch 462/1000
2023-09-26 23:18:12.217 
Epoch 462/1000 
	 loss: 15.9897, MinusLogProbMetric: 15.9897, val_loss: 17.3606, val_MinusLogProbMetric: 17.3606

Epoch 462: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9897 - MinusLogProbMetric: 15.9897 - val_loss: 17.3606 - val_MinusLogProbMetric: 17.3606 - lr: 4.1667e-05 - 74s/epoch - 377ms/step
Epoch 463/1000
2023-09-26 23:19:26.133 
Epoch 463/1000 
	 loss: 15.9935, MinusLogProbMetric: 15.9935, val_loss: 17.3430, val_MinusLogProbMetric: 17.3430

Epoch 463: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9935 - MinusLogProbMetric: 15.9935 - val_loss: 17.3430 - val_MinusLogProbMetric: 17.3430 - lr: 4.1667e-05 - 74s/epoch - 377ms/step
Epoch 464/1000
2023-09-26 23:20:39.310 
Epoch 464/1000 
	 loss: 15.9895, MinusLogProbMetric: 15.9895, val_loss: 17.4393, val_MinusLogProbMetric: 17.4393

Epoch 464: val_loss did not improve from 17.30502
196/196 - 73s - loss: 15.9895 - MinusLogProbMetric: 15.9895 - val_loss: 17.4393 - val_MinusLogProbMetric: 17.4393 - lr: 4.1667e-05 - 73s/epoch - 373ms/step
Epoch 465/1000
2023-09-26 23:21:53.152 
Epoch 465/1000 
	 loss: 15.9841, MinusLogProbMetric: 15.9841, val_loss: 17.3345, val_MinusLogProbMetric: 17.3345

Epoch 465: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9841 - MinusLogProbMetric: 15.9841 - val_loss: 17.3345 - val_MinusLogProbMetric: 17.3345 - lr: 4.1667e-05 - 74s/epoch - 377ms/step
Epoch 466/1000
2023-09-26 23:23:06.394 
Epoch 466/1000 
	 loss: 15.9500, MinusLogProbMetric: 15.9500, val_loss: 17.3221, val_MinusLogProbMetric: 17.3221

Epoch 466: val_loss did not improve from 17.30502
196/196 - 73s - loss: 15.9500 - MinusLogProbMetric: 15.9500 - val_loss: 17.3221 - val_MinusLogProbMetric: 17.3221 - lr: 2.0833e-05 - 73s/epoch - 374ms/step
Epoch 467/1000
2023-09-26 23:24:20.191 
Epoch 467/1000 
	 loss: 15.9487, MinusLogProbMetric: 15.9487, val_loss: 17.3396, val_MinusLogProbMetric: 17.3396

Epoch 467: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9487 - MinusLogProbMetric: 15.9487 - val_loss: 17.3396 - val_MinusLogProbMetric: 17.3396 - lr: 2.0833e-05 - 74s/epoch - 376ms/step
Epoch 468/1000
2023-09-26 23:25:34.039 
Epoch 468/1000 
	 loss: 15.9490, MinusLogProbMetric: 15.9490, val_loss: 17.3289, val_MinusLogProbMetric: 17.3289

Epoch 468: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9490 - MinusLogProbMetric: 15.9490 - val_loss: 17.3289 - val_MinusLogProbMetric: 17.3289 - lr: 2.0833e-05 - 74s/epoch - 377ms/step
Epoch 469/1000
2023-09-26 23:26:47.734 
Epoch 469/1000 
	 loss: 15.9437, MinusLogProbMetric: 15.9437, val_loss: 17.3157, val_MinusLogProbMetric: 17.3157

Epoch 469: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9437 - MinusLogProbMetric: 15.9437 - val_loss: 17.3157 - val_MinusLogProbMetric: 17.3157 - lr: 2.0833e-05 - 74s/epoch - 376ms/step
Epoch 470/1000
2023-09-26 23:28:01.943 
Epoch 470/1000 
	 loss: 15.9476, MinusLogProbMetric: 15.9476, val_loss: 17.3260, val_MinusLogProbMetric: 17.3260

Epoch 470: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9476 - MinusLogProbMetric: 15.9476 - val_loss: 17.3260 - val_MinusLogProbMetric: 17.3260 - lr: 2.0833e-05 - 74s/epoch - 379ms/step
Epoch 471/1000
2023-09-26 23:29:16.036 
Epoch 471/1000 
	 loss: 15.9442, MinusLogProbMetric: 15.9442, val_loss: 17.3298, val_MinusLogProbMetric: 17.3298

Epoch 471: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9442 - MinusLogProbMetric: 15.9442 - val_loss: 17.3298 - val_MinusLogProbMetric: 17.3298 - lr: 2.0833e-05 - 74s/epoch - 378ms/step
Epoch 472/1000
2023-09-26 23:30:29.485 
Epoch 472/1000 
	 loss: 15.9463, MinusLogProbMetric: 15.9463, val_loss: 17.3389, val_MinusLogProbMetric: 17.3389

Epoch 472: val_loss did not improve from 17.30502
196/196 - 73s - loss: 15.9463 - MinusLogProbMetric: 15.9463 - val_loss: 17.3389 - val_MinusLogProbMetric: 17.3389 - lr: 2.0833e-05 - 73s/epoch - 375ms/step
Epoch 473/1000
2023-09-26 23:31:43.025 
Epoch 473/1000 
	 loss: 15.9478, MinusLogProbMetric: 15.9478, val_loss: 17.3296, val_MinusLogProbMetric: 17.3296

Epoch 473: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9478 - MinusLogProbMetric: 15.9478 - val_loss: 17.3296 - val_MinusLogProbMetric: 17.3296 - lr: 2.0833e-05 - 74s/epoch - 375ms/step
Epoch 474/1000
2023-09-26 23:32:56.992 
Epoch 474/1000 
	 loss: 15.9427, MinusLogProbMetric: 15.9427, val_loss: 17.3217, val_MinusLogProbMetric: 17.3217

Epoch 474: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9427 - MinusLogProbMetric: 15.9427 - val_loss: 17.3217 - val_MinusLogProbMetric: 17.3217 - lr: 2.0833e-05 - 74s/epoch - 377ms/step
Epoch 475/1000
2023-09-26 23:34:10.009 
Epoch 475/1000 
	 loss: 15.9420, MinusLogProbMetric: 15.9420, val_loss: 17.3444, val_MinusLogProbMetric: 17.3444

Epoch 475: val_loss did not improve from 17.30502
196/196 - 73s - loss: 15.9420 - MinusLogProbMetric: 15.9420 - val_loss: 17.3444 - val_MinusLogProbMetric: 17.3444 - lr: 2.0833e-05 - 73s/epoch - 373ms/step
Epoch 476/1000
2023-09-26 23:35:23.901 
Epoch 476/1000 
	 loss: 15.9433, MinusLogProbMetric: 15.9433, val_loss: 17.3637, val_MinusLogProbMetric: 17.3637

Epoch 476: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9433 - MinusLogProbMetric: 15.9433 - val_loss: 17.3637 - val_MinusLogProbMetric: 17.3637 - lr: 2.0833e-05 - 74s/epoch - 377ms/step
Epoch 477/1000
2023-09-26 23:36:37.764 
Epoch 477/1000 
	 loss: 15.9489, MinusLogProbMetric: 15.9489, val_loss: 17.3137, val_MinusLogProbMetric: 17.3137

Epoch 477: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9489 - MinusLogProbMetric: 15.9489 - val_loss: 17.3137 - val_MinusLogProbMetric: 17.3137 - lr: 2.0833e-05 - 74s/epoch - 377ms/step
Epoch 478/1000
2023-09-26 23:37:51.146 
Epoch 478/1000 
	 loss: 15.9436, MinusLogProbMetric: 15.9436, val_loss: 17.3275, val_MinusLogProbMetric: 17.3275

Epoch 478: val_loss did not improve from 17.30502
196/196 - 73s - loss: 15.9436 - MinusLogProbMetric: 15.9436 - val_loss: 17.3275 - val_MinusLogProbMetric: 17.3275 - lr: 2.0833e-05 - 73s/epoch - 374ms/step
Epoch 479/1000
2023-09-26 23:39:04.700 
Epoch 479/1000 
	 loss: 15.9434, MinusLogProbMetric: 15.9434, val_loss: 17.3378, val_MinusLogProbMetric: 17.3378

Epoch 479: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9434 - MinusLogProbMetric: 15.9434 - val_loss: 17.3378 - val_MinusLogProbMetric: 17.3378 - lr: 2.0833e-05 - 74s/epoch - 375ms/step
Epoch 480/1000
2023-09-26 23:40:18.019 
Epoch 480/1000 
	 loss: 15.9429, MinusLogProbMetric: 15.9429, val_loss: 17.3243, val_MinusLogProbMetric: 17.3243

Epoch 480: val_loss did not improve from 17.30502
196/196 - 73s - loss: 15.9429 - MinusLogProbMetric: 15.9429 - val_loss: 17.3243 - val_MinusLogProbMetric: 17.3243 - lr: 2.0833e-05 - 73s/epoch - 374ms/step
Epoch 481/1000
2023-09-26 23:41:32.329 
Epoch 481/1000 
	 loss: 15.9441, MinusLogProbMetric: 15.9441, val_loss: 17.3215, val_MinusLogProbMetric: 17.3215

Epoch 481: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9441 - MinusLogProbMetric: 15.9441 - val_loss: 17.3215 - val_MinusLogProbMetric: 17.3215 - lr: 2.0833e-05 - 74s/epoch - 379ms/step
Epoch 482/1000
2023-09-26 23:42:45.667 
Epoch 482/1000 
	 loss: 15.9401, MinusLogProbMetric: 15.9401, val_loss: 17.3250, val_MinusLogProbMetric: 17.3250

Epoch 482: val_loss did not improve from 17.30502
196/196 - 73s - loss: 15.9401 - MinusLogProbMetric: 15.9401 - val_loss: 17.3250 - val_MinusLogProbMetric: 17.3250 - lr: 2.0833e-05 - 73s/epoch - 374ms/step
Epoch 483/1000
2023-09-26 23:43:59.592 
Epoch 483/1000 
	 loss: 15.9441, MinusLogProbMetric: 15.9441, val_loss: 17.3243, val_MinusLogProbMetric: 17.3243

Epoch 483: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9441 - MinusLogProbMetric: 15.9441 - val_loss: 17.3243 - val_MinusLogProbMetric: 17.3243 - lr: 2.0833e-05 - 74s/epoch - 377ms/step
Epoch 484/1000
2023-09-26 23:45:13.160 
Epoch 484/1000 
	 loss: 15.9458, MinusLogProbMetric: 15.9458, val_loss: 17.3296, val_MinusLogProbMetric: 17.3296

Epoch 484: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9458 - MinusLogProbMetric: 15.9458 - val_loss: 17.3296 - val_MinusLogProbMetric: 17.3296 - lr: 2.0833e-05 - 74s/epoch - 375ms/step
Epoch 485/1000
2023-09-26 23:46:26.846 
Epoch 485/1000 
	 loss: 15.9416, MinusLogProbMetric: 15.9416, val_loss: 17.3251, val_MinusLogProbMetric: 17.3251

Epoch 485: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9416 - MinusLogProbMetric: 15.9416 - val_loss: 17.3251 - val_MinusLogProbMetric: 17.3251 - lr: 2.0833e-05 - 74s/epoch - 376ms/step
Epoch 486/1000
2023-09-26 23:47:40.336 
Epoch 486/1000 
	 loss: 15.9434, MinusLogProbMetric: 15.9434, val_loss: 17.3293, val_MinusLogProbMetric: 17.3293

Epoch 486: val_loss did not improve from 17.30502
196/196 - 73s - loss: 15.9434 - MinusLogProbMetric: 15.9434 - val_loss: 17.3293 - val_MinusLogProbMetric: 17.3293 - lr: 2.0833e-05 - 73s/epoch - 375ms/step
Epoch 487/1000
2023-09-26 23:48:54.240 
Epoch 487/1000 
	 loss: 15.9429, MinusLogProbMetric: 15.9429, val_loss: 17.3247, val_MinusLogProbMetric: 17.3247

Epoch 487: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9429 - MinusLogProbMetric: 15.9429 - val_loss: 17.3247 - val_MinusLogProbMetric: 17.3247 - lr: 2.0833e-05 - 74s/epoch - 377ms/step
Epoch 488/1000
2023-09-26 23:50:07.705 
Epoch 488/1000 
	 loss: 15.9436, MinusLogProbMetric: 15.9436, val_loss: 17.3143, val_MinusLogProbMetric: 17.3143

Epoch 488: val_loss did not improve from 17.30502
196/196 - 73s - loss: 15.9436 - MinusLogProbMetric: 15.9436 - val_loss: 17.3143 - val_MinusLogProbMetric: 17.3143 - lr: 2.0833e-05 - 73s/epoch - 375ms/step
Epoch 489/1000
2023-09-26 23:51:21.355 
Epoch 489/1000 
	 loss: 15.9419, MinusLogProbMetric: 15.9419, val_loss: 17.3329, val_MinusLogProbMetric: 17.3329

Epoch 489: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9419 - MinusLogProbMetric: 15.9419 - val_loss: 17.3329 - val_MinusLogProbMetric: 17.3329 - lr: 2.0833e-05 - 74s/epoch - 376ms/step
Epoch 490/1000
2023-09-26 23:52:35.074 
Epoch 490/1000 
	 loss: 15.9415, MinusLogProbMetric: 15.9415, val_loss: 17.3404, val_MinusLogProbMetric: 17.3404

Epoch 490: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9415 - MinusLogProbMetric: 15.9415 - val_loss: 17.3404 - val_MinusLogProbMetric: 17.3404 - lr: 2.0833e-05 - 74s/epoch - 376ms/step
Epoch 491/1000
2023-09-26 23:53:48.287 
Epoch 491/1000 
	 loss: 15.9417, MinusLogProbMetric: 15.9417, val_loss: 17.3432, val_MinusLogProbMetric: 17.3432

Epoch 491: val_loss did not improve from 17.30502
196/196 - 73s - loss: 15.9417 - MinusLogProbMetric: 15.9417 - val_loss: 17.3432 - val_MinusLogProbMetric: 17.3432 - lr: 2.0833e-05 - 73s/epoch - 374ms/step
Epoch 492/1000
2023-09-26 23:55:02.216 
Epoch 492/1000 
	 loss: 15.9349, MinusLogProbMetric: 15.9349, val_loss: 17.3198, val_MinusLogProbMetric: 17.3198

Epoch 492: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9349 - MinusLogProbMetric: 15.9349 - val_loss: 17.3198 - val_MinusLogProbMetric: 17.3198 - lr: 2.0833e-05 - 74s/epoch - 377ms/step
Epoch 493/1000
2023-09-26 23:56:15.968 
Epoch 493/1000 
	 loss: 15.9418, MinusLogProbMetric: 15.9418, val_loss: 17.3268, val_MinusLogProbMetric: 17.3268

Epoch 493: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9418 - MinusLogProbMetric: 15.9418 - val_loss: 17.3268 - val_MinusLogProbMetric: 17.3268 - lr: 2.0833e-05 - 74s/epoch - 376ms/step
Epoch 494/1000
2023-09-26 23:57:29.209 
Epoch 494/1000 
	 loss: 15.9349, MinusLogProbMetric: 15.9349, val_loss: 17.3352, val_MinusLogProbMetric: 17.3352

Epoch 494: val_loss did not improve from 17.30502
196/196 - 73s - loss: 15.9349 - MinusLogProbMetric: 15.9349 - val_loss: 17.3352 - val_MinusLogProbMetric: 17.3352 - lr: 2.0833e-05 - 73s/epoch - 374ms/step
Epoch 495/1000
2023-09-26 23:58:43.503 
Epoch 495/1000 
	 loss: 15.9404, MinusLogProbMetric: 15.9404, val_loss: 17.3256, val_MinusLogProbMetric: 17.3256

Epoch 495: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9404 - MinusLogProbMetric: 15.9404 - val_loss: 17.3256 - val_MinusLogProbMetric: 17.3256 - lr: 2.0833e-05 - 74s/epoch - 379ms/step
Epoch 496/1000
2023-09-26 23:59:57.200 
Epoch 496/1000 
	 loss: 15.9396, MinusLogProbMetric: 15.9396, val_loss: 17.3486, val_MinusLogProbMetric: 17.3486

Epoch 496: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9396 - MinusLogProbMetric: 15.9396 - val_loss: 17.3486 - val_MinusLogProbMetric: 17.3486 - lr: 2.0833e-05 - 74s/epoch - 376ms/step
Epoch 497/1000
2023-09-27 00:01:10.701 
Epoch 497/1000 
	 loss: 15.9369, MinusLogProbMetric: 15.9369, val_loss: 17.4148, val_MinusLogProbMetric: 17.4148

Epoch 497: val_loss did not improve from 17.30502
196/196 - 73s - loss: 15.9369 - MinusLogProbMetric: 15.9369 - val_loss: 17.4148 - val_MinusLogProbMetric: 17.4148 - lr: 2.0833e-05 - 73s/epoch - 375ms/step
Epoch 498/1000
2023-09-27 00:02:24.808 
Epoch 498/1000 
	 loss: 15.9405, MinusLogProbMetric: 15.9405, val_loss: 17.3223, val_MinusLogProbMetric: 17.3223

Epoch 498: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9405 - MinusLogProbMetric: 15.9405 - val_loss: 17.3223 - val_MinusLogProbMetric: 17.3223 - lr: 2.0833e-05 - 74s/epoch - 378ms/step
Epoch 499/1000
2023-09-27 00:03:38.756 
Epoch 499/1000 
	 loss: 15.9527, MinusLogProbMetric: 15.9527, val_loss: 17.3260, val_MinusLogProbMetric: 17.3260

Epoch 499: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9527 - MinusLogProbMetric: 15.9527 - val_loss: 17.3260 - val_MinusLogProbMetric: 17.3260 - lr: 2.0833e-05 - 74s/epoch - 377ms/step
Epoch 500/1000
2023-09-27 00:04:53.173 
Epoch 500/1000 
	 loss: 15.9368, MinusLogProbMetric: 15.9368, val_loss: 17.3285, val_MinusLogProbMetric: 17.3285

Epoch 500: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9368 - MinusLogProbMetric: 15.9368 - val_loss: 17.3285 - val_MinusLogProbMetric: 17.3285 - lr: 2.0833e-05 - 74s/epoch - 380ms/step
Epoch 501/1000
2023-09-27 00:06:07.223 
Epoch 501/1000 
	 loss: 15.9371, MinusLogProbMetric: 15.9371, val_loss: 17.3435, val_MinusLogProbMetric: 17.3435

Epoch 501: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9371 - MinusLogProbMetric: 15.9371 - val_loss: 17.3435 - val_MinusLogProbMetric: 17.3435 - lr: 2.0833e-05 - 74s/epoch - 378ms/step
Epoch 502/1000
2023-09-27 00:07:21.034 
Epoch 502/1000 
	 loss: 15.9434, MinusLogProbMetric: 15.9434, val_loss: 17.3247, val_MinusLogProbMetric: 17.3247

Epoch 502: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9434 - MinusLogProbMetric: 15.9434 - val_loss: 17.3247 - val_MinusLogProbMetric: 17.3247 - lr: 2.0833e-05 - 74s/epoch - 377ms/step
Epoch 503/1000
2023-09-27 00:08:35.182 
Epoch 503/1000 
	 loss: 15.9368, MinusLogProbMetric: 15.9368, val_loss: 17.3513, val_MinusLogProbMetric: 17.3513

Epoch 503: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9368 - MinusLogProbMetric: 15.9368 - val_loss: 17.3513 - val_MinusLogProbMetric: 17.3513 - lr: 2.0833e-05 - 74s/epoch - 378ms/step
Epoch 504/1000
2023-09-27 00:09:48.134 
Epoch 504/1000 
	 loss: 15.9374, MinusLogProbMetric: 15.9374, val_loss: 17.3197, val_MinusLogProbMetric: 17.3197

Epoch 504: val_loss did not improve from 17.30502
196/196 - 73s - loss: 15.9374 - MinusLogProbMetric: 15.9374 - val_loss: 17.3197 - val_MinusLogProbMetric: 17.3197 - lr: 2.0833e-05 - 73s/epoch - 372ms/step
Epoch 505/1000
2023-09-27 00:11:01.635 
Epoch 505/1000 
	 loss: 15.9396, MinusLogProbMetric: 15.9396, val_loss: 17.3320, val_MinusLogProbMetric: 17.3320

Epoch 505: val_loss did not improve from 17.30502
196/196 - 73s - loss: 15.9396 - MinusLogProbMetric: 15.9396 - val_loss: 17.3320 - val_MinusLogProbMetric: 17.3320 - lr: 2.0833e-05 - 73s/epoch - 375ms/step
Epoch 506/1000
2023-09-27 00:12:15.362 
Epoch 506/1000 
	 loss: 15.9439, MinusLogProbMetric: 15.9439, val_loss: 17.3182, val_MinusLogProbMetric: 17.3182

Epoch 506: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9439 - MinusLogProbMetric: 15.9439 - val_loss: 17.3182 - val_MinusLogProbMetric: 17.3182 - lr: 2.0833e-05 - 74s/epoch - 376ms/step
Epoch 507/1000
2023-09-27 00:13:29.077 
Epoch 507/1000 
	 loss: 15.9356, MinusLogProbMetric: 15.9356, val_loss: 17.3300, val_MinusLogProbMetric: 17.3300

Epoch 507: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9356 - MinusLogProbMetric: 15.9356 - val_loss: 17.3300 - val_MinusLogProbMetric: 17.3300 - lr: 2.0833e-05 - 74s/epoch - 376ms/step
Epoch 508/1000
2023-09-27 00:14:42.637 
Epoch 508/1000 
	 loss: 15.9387, MinusLogProbMetric: 15.9387, val_loss: 17.3673, val_MinusLogProbMetric: 17.3673

Epoch 508: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9387 - MinusLogProbMetric: 15.9387 - val_loss: 17.3673 - val_MinusLogProbMetric: 17.3673 - lr: 2.0833e-05 - 74s/epoch - 375ms/step
Epoch 509/1000
2023-09-27 00:15:56.244 
Epoch 509/1000 
	 loss: 15.9403, MinusLogProbMetric: 15.9403, val_loss: 17.3218, val_MinusLogProbMetric: 17.3218

Epoch 509: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9403 - MinusLogProbMetric: 15.9403 - val_loss: 17.3218 - val_MinusLogProbMetric: 17.3218 - lr: 2.0833e-05 - 74s/epoch - 376ms/step
Epoch 510/1000
2023-09-27 00:17:10.325 
Epoch 510/1000 
	 loss: 15.9337, MinusLogProbMetric: 15.9337, val_loss: 17.3310, val_MinusLogProbMetric: 17.3310

Epoch 510: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9337 - MinusLogProbMetric: 15.9337 - val_loss: 17.3310 - val_MinusLogProbMetric: 17.3310 - lr: 2.0833e-05 - 74s/epoch - 378ms/step
Epoch 511/1000
2023-09-27 00:18:24.266 
Epoch 511/1000 
	 loss: 15.9363, MinusLogProbMetric: 15.9363, val_loss: 17.3481, val_MinusLogProbMetric: 17.3481

Epoch 511: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9363 - MinusLogProbMetric: 15.9363 - val_loss: 17.3481 - val_MinusLogProbMetric: 17.3481 - lr: 2.0833e-05 - 74s/epoch - 377ms/step
Epoch 512/1000
2023-09-27 00:19:37.468 
Epoch 512/1000 
	 loss: 15.9352, MinusLogProbMetric: 15.9352, val_loss: 17.3580, val_MinusLogProbMetric: 17.3580

Epoch 512: val_loss did not improve from 17.30502
196/196 - 73s - loss: 15.9352 - MinusLogProbMetric: 15.9352 - val_loss: 17.3580 - val_MinusLogProbMetric: 17.3580 - lr: 2.0833e-05 - 73s/epoch - 373ms/step
Epoch 513/1000
2023-09-27 00:20:51.045 
Epoch 513/1000 
	 loss: 15.9450, MinusLogProbMetric: 15.9450, val_loss: 17.3637, val_MinusLogProbMetric: 17.3637

Epoch 513: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9450 - MinusLogProbMetric: 15.9450 - val_loss: 17.3637 - val_MinusLogProbMetric: 17.3637 - lr: 2.0833e-05 - 74s/epoch - 375ms/step
Epoch 514/1000
2023-09-27 00:22:05.233 
Epoch 514/1000 
	 loss: 15.9378, MinusLogProbMetric: 15.9378, val_loss: 17.3432, val_MinusLogProbMetric: 17.3432

Epoch 514: val_loss did not improve from 17.30502
196/196 - 74s - loss: 15.9378 - MinusLogProbMetric: 15.9378 - val_loss: 17.3432 - val_MinusLogProbMetric: 17.3432 - lr: 2.0833e-05 - 74s/epoch - 378ms/step
Epoch 515/1000
2023-09-27 00:23:19.189 
Epoch 515/1000 
	 loss: 15.9308, MinusLogProbMetric: 15.9308, val_loss: 17.3292, val_MinusLogProbMetric: 17.3292

Epoch 515: val_loss did not improve from 17.30502
Restoring model weights from the end of the best epoch: 415.
196/196 - 75s - loss: 15.9308 - MinusLogProbMetric: 15.9308 - val_loss: 17.3292 - val_MinusLogProbMetric: 17.3292 - lr: 2.0833e-05 - 75s/epoch - 381ms/step
Epoch 515: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
LR metric calculation completed in 29.69541421404574 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 19.96987230400555 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
SWD metric calculation completed in 13.08262979099527 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
FN metric calculation completed in 13.938210684980731 seconds.
Training succeeded with seed 541.
Model trained in 39412.14 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 78.47 s.
                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/c_Main_CsplineN.py , Line : 469, Func.Name : prediction_function, Message : Plotters.cornerplotter(X_data_test.numpy(),X_data_nf.numpy(),path_to_results,ndims,norm=True) # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 78.92 s.
===========
Run 288/720 done in 39666.73 s.
===========

Directory ../../results/CsplineN_new/run_289/ already exists.
Skipping it.
===========
Run 289/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_290/ already exists.
Skipping it.
===========
Run 290/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_291/ already exists.
Skipping it.
===========
Run 291/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_292/ already exists.
Skipping it.
===========
Run 292/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_293/ already exists.
Skipping it.
===========
Run 293/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_294/ already exists.
Skipping it.
===========
Run 294/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_295/ already exists.
Skipping it.
===========
Run 295/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_296/ already exists.
Skipping it.
===========
Run 296/720 already exists. Skipping it.
===========

===========
Generating train data for run 297.
===========
Train data generated in 0.16 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_297/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 869}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_297/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.7724807 ,  3.5952213 ,  8.442487  , ...,  7.3644695 ,
         3.6588435 ,  2.0248146 ],
       [ 6.6242166 ,  7.1665483 ,  6.4277024 , ...,  3.1194153 ,
         2.6248946 ,  8.037665  ],
       [ 4.5211086 ,  5.2663136 , -0.6501303 , ...,  0.17722613,
         6.462096  ,  1.3170475 ],
       ...,
       [ 5.2085795 ,  5.348097  , -0.4658583 , ..., -0.03725696,
         5.9864964 ,  1.2388526 ],
       [ 3.9188156 ,  5.4859467 , -0.29968688, ...,  0.4149692 ,
         6.0867124 ,  1.4174792 ],
       [ 2.283803  ,  2.9701724 ,  8.729265  , ...,  6.0229187 ,
         3.2842712 ,  2.1182036 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_297/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_297
self.data_kwargs: {'seed': 869}
self.x_data: [[ 1.7417877   3.5044646   9.194398   ...  7.377848    2.8874114
   1.7757134 ]
 [ 3.8693519   4.134066    8.323213   ...  7.5259514   3.079576
   1.8540689 ]
 [ 2.7888105   3.5250566   6.8470335  ...  7.0512147   2.9893377
   1.7142482 ]
 ...
 [ 3.8914979   5.948059   -0.25578696 ...  1.7629418   6.8860593
   1.464444  ]
 [ 3.0775785   3.9001913   8.887795   ...  7.2041593   3.5200696
   1.5176823 ]
 [ 1.0419946   3.6002321   7.1163735  ...  7.3799496   3.218665
   1.6207042 ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_27"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_28 (InputLayer)       [(None, 32)]              0         
                                                                 
 log_prob_layer_2 (LogProbLa  (None,)                  413360    
 yer)                                                            
                                                                 
=================================================================
Total params: 413,360
Trainable params: 413,360
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_2/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_2'")
self.model: <keras.engine.functional.Functional object at 0x7fd38c1c2620>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fda12627130>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fda12627130>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fda12801e40>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fd384618d60>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fd3846192d0>, <keras.callbacks.ModelCheckpoint object at 0x7fd384619390>, <keras.callbacks.EarlyStopping object at 0x7fd384619600>, <keras.callbacks.ReduceLROnPlateau object at 0x7fd384619630>, <keras.callbacks.TerminateOnNaN object at 0x7fd384619270>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.7724807 ,  3.5952213 ,  8.442487  , ...,  7.3644695 ,
         3.6588435 ,  2.0248146 ],
       [ 6.6242166 ,  7.1665483 ,  6.4277024 , ...,  3.1194153 ,
         2.6248946 ,  8.037665  ],
       [ 4.5211086 ,  5.2663136 , -0.6501303 , ...,  0.17722613,
         6.462096  ,  1.3170475 ],
       ...,
       [ 5.2085795 ,  5.348097  , -0.4658583 , ..., -0.03725696,
         5.9864964 ,  1.2388526 ],
       [ 3.9188156 ,  5.4859467 , -0.29968688, ...,  0.4149692 ,
         6.0867124 ,  1.4174792 ],
       [ 2.283803  ,  2.9701724 ,  8.729265  , ...,  6.0229187 ,
         3.2842712 ,  2.1182036 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_297/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 297/720 with hyperparameters:
timestamp = 2023-09-27 00:24:42.877010
ndims = 32
seed_train = 869
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 5
spline_knots = 8
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 413360
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 1.7417877   3.5044646   9.194398    1.0621872   8.910313    1.2448134
  9.752992    4.795541   10.214517    5.8200784   7.3571367   0.42017213
  3.0764782   1.1773593   3.1572356   1.3086243   2.6951017   5.712275
  0.4469142   6.9349284   5.5393224   1.8138231   6.1143165   1.1455625
  7.183009    9.098161    3.4021838   5.9704523   0.79392874  7.377848
  2.8874114   1.7757134 ]
Epoch 1/1000
2023-09-27 00:26:13.181 
Epoch 1/1000 
	 loss: 125.3786, MinusLogProbMetric: 125.3786, val_loss: 33.4126, val_MinusLogProbMetric: 33.4126

Epoch 1: val_loss improved from inf to 33.41261, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 91s - loss: 125.3786 - MinusLogProbMetric: 125.3786 - val_loss: 33.4126 - val_MinusLogProbMetric: 33.4126 - lr: 0.0010 - 91s/epoch - 462ms/step
Epoch 2/1000
2023-09-27 00:26:47.135 
Epoch 2/1000 
	 loss: 28.5342, MinusLogProbMetric: 28.5342, val_loss: 25.7858, val_MinusLogProbMetric: 25.7858

Epoch 2: val_loss improved from 33.41261 to 25.78578, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 34s - loss: 28.5342 - MinusLogProbMetric: 28.5342 - val_loss: 25.7858 - val_MinusLogProbMetric: 25.7858 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 3/1000
2023-09-27 00:27:20.468 
Epoch 3/1000 
	 loss: 24.2626, MinusLogProbMetric: 24.2626, val_loss: 23.4645, val_MinusLogProbMetric: 23.4645

Epoch 3: val_loss improved from 25.78578 to 23.46450, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 24.2626 - MinusLogProbMetric: 24.2626 - val_loss: 23.4645 - val_MinusLogProbMetric: 23.4645 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 4/1000
2023-09-27 00:27:53.758 
Epoch 4/1000 
	 loss: 22.5289, MinusLogProbMetric: 22.5289, val_loss: 21.9069, val_MinusLogProbMetric: 21.9069

Epoch 4: val_loss improved from 23.46450 to 21.90690, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 22.5289 - MinusLogProbMetric: 22.5289 - val_loss: 21.9069 - val_MinusLogProbMetric: 21.9069 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 5/1000
2023-09-27 00:28:26.596 
Epoch 5/1000 
	 loss: 21.5465, MinusLogProbMetric: 21.5465, val_loss: 21.1501, val_MinusLogProbMetric: 21.1501

Epoch 5: val_loss improved from 21.90690 to 21.15005, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 21.5465 - MinusLogProbMetric: 21.5465 - val_loss: 21.1501 - val_MinusLogProbMetric: 21.1501 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 6/1000
2023-09-27 00:28:59.173 
Epoch 6/1000 
	 loss: 21.0247, MinusLogProbMetric: 21.0247, val_loss: 22.2256, val_MinusLogProbMetric: 22.2256

Epoch 6: val_loss did not improve from 21.15005
196/196 - 32s - loss: 21.0247 - MinusLogProbMetric: 21.0247 - val_loss: 22.2256 - val_MinusLogProbMetric: 22.2256 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 7/1000
2023-09-27 00:29:31.200 
Epoch 7/1000 
	 loss: 20.5595, MinusLogProbMetric: 20.5595, val_loss: 20.1040, val_MinusLogProbMetric: 20.1040

Epoch 7: val_loss improved from 21.15005 to 20.10398, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 20.5595 - MinusLogProbMetric: 20.5595 - val_loss: 20.1040 - val_MinusLogProbMetric: 20.1040 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 8/1000
2023-09-27 00:30:03.711 
Epoch 8/1000 
	 loss: 20.3415, MinusLogProbMetric: 20.3415, val_loss: 19.8551, val_MinusLogProbMetric: 19.8551

Epoch 8: val_loss improved from 20.10398 to 19.85507, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 20.3415 - MinusLogProbMetric: 20.3415 - val_loss: 19.8551 - val_MinusLogProbMetric: 19.8551 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 9/1000
2023-09-27 00:30:36.566 
Epoch 9/1000 
	 loss: 19.9895, MinusLogProbMetric: 19.9895, val_loss: 19.6670, val_MinusLogProbMetric: 19.6670

Epoch 9: val_loss improved from 19.85507 to 19.66697, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 19.9895 - MinusLogProbMetric: 19.9895 - val_loss: 19.6670 - val_MinusLogProbMetric: 19.6670 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 10/1000
2023-09-27 00:31:09.031 
Epoch 10/1000 
	 loss: 19.7087, MinusLogProbMetric: 19.7087, val_loss: 19.3841, val_MinusLogProbMetric: 19.3841

Epoch 10: val_loss improved from 19.66697 to 19.38407, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 19.7087 - MinusLogProbMetric: 19.7087 - val_loss: 19.3841 - val_MinusLogProbMetric: 19.3841 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 11/1000
2023-09-27 00:31:41.734 
Epoch 11/1000 
	 loss: 19.5712, MinusLogProbMetric: 19.5712, val_loss: 19.5952, val_MinusLogProbMetric: 19.5952

Epoch 11: val_loss did not improve from 19.38407
196/196 - 32s - loss: 19.5712 - MinusLogProbMetric: 19.5712 - val_loss: 19.5952 - val_MinusLogProbMetric: 19.5952 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 12/1000
2023-09-27 00:32:13.392 
Epoch 12/1000 
	 loss: 19.5859, MinusLogProbMetric: 19.5859, val_loss: 19.3114, val_MinusLogProbMetric: 19.3114

Epoch 12: val_loss improved from 19.38407 to 19.31137, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 32s - loss: 19.5859 - MinusLogProbMetric: 19.5859 - val_loss: 19.3114 - val_MinusLogProbMetric: 19.3114 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 13/1000
2023-09-27 00:32:46.190 
Epoch 13/1000 
	 loss: 19.1385, MinusLogProbMetric: 19.1385, val_loss: 19.0163, val_MinusLogProbMetric: 19.0163

Epoch 13: val_loss improved from 19.31137 to 19.01631, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 19.1385 - MinusLogProbMetric: 19.1385 - val_loss: 19.0163 - val_MinusLogProbMetric: 19.0163 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 14/1000
2023-09-27 00:33:18.896 
Epoch 14/1000 
	 loss: 19.2398, MinusLogProbMetric: 19.2398, val_loss: 18.9871, val_MinusLogProbMetric: 18.9871

Epoch 14: val_loss improved from 19.01631 to 18.98709, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 19.2398 - MinusLogProbMetric: 19.2398 - val_loss: 18.9871 - val_MinusLogProbMetric: 18.9871 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 15/1000
2023-09-27 00:33:51.533 
Epoch 15/1000 
	 loss: 18.9550, MinusLogProbMetric: 18.9550, val_loss: 19.9368, val_MinusLogProbMetric: 19.9368

Epoch 15: val_loss did not improve from 18.98709
196/196 - 32s - loss: 18.9550 - MinusLogProbMetric: 18.9550 - val_loss: 19.9368 - val_MinusLogProbMetric: 19.9368 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 16/1000
2023-09-27 00:34:23.994 
Epoch 16/1000 
	 loss: 19.0690, MinusLogProbMetric: 19.0690, val_loss: 19.3019, val_MinusLogProbMetric: 19.3019

Epoch 16: val_loss did not improve from 18.98709
196/196 - 32s - loss: 19.0690 - MinusLogProbMetric: 19.0690 - val_loss: 19.3019 - val_MinusLogProbMetric: 19.3019 - lr: 0.0010 - 32s/epoch - 166ms/step
Epoch 17/1000
2023-09-27 00:34:56.001 
Epoch 17/1000 
	 loss: 18.7341, MinusLogProbMetric: 18.7341, val_loss: 18.7415, val_MinusLogProbMetric: 18.7415

Epoch 17: val_loss improved from 18.98709 to 18.74145, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 18.7341 - MinusLogProbMetric: 18.7341 - val_loss: 18.7415 - val_MinusLogProbMetric: 18.7415 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 18/1000
2023-09-27 00:35:28.917 
Epoch 18/1000 
	 loss: 18.8451, MinusLogProbMetric: 18.8451, val_loss: 18.4204, val_MinusLogProbMetric: 18.4204

Epoch 18: val_loss improved from 18.74145 to 18.42037, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 18.8451 - MinusLogProbMetric: 18.8451 - val_loss: 18.4204 - val_MinusLogProbMetric: 18.4204 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 19/1000
2023-09-27 00:36:01.634 
Epoch 19/1000 
	 loss: 18.7631, MinusLogProbMetric: 18.7631, val_loss: 19.1519, val_MinusLogProbMetric: 19.1519

Epoch 19: val_loss did not improve from 18.42037
196/196 - 32s - loss: 18.7631 - MinusLogProbMetric: 18.7631 - val_loss: 19.1519 - val_MinusLogProbMetric: 19.1519 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 20/1000
2023-09-27 00:36:33.903 
Epoch 20/1000 
	 loss: 18.6896, MinusLogProbMetric: 18.6896, val_loss: 19.1910, val_MinusLogProbMetric: 19.1910

Epoch 20: val_loss did not improve from 18.42037
196/196 - 32s - loss: 18.6896 - MinusLogProbMetric: 18.6896 - val_loss: 19.1910 - val_MinusLogProbMetric: 19.1910 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 21/1000
2023-09-27 00:37:06.118 
Epoch 21/1000 
	 loss: 18.5248, MinusLogProbMetric: 18.5248, val_loss: 26.5376, val_MinusLogProbMetric: 26.5376

Epoch 21: val_loss did not improve from 18.42037
196/196 - 32s - loss: 18.5248 - MinusLogProbMetric: 18.5248 - val_loss: 26.5376 - val_MinusLogProbMetric: 26.5376 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 22/1000
2023-09-27 00:37:38.328 
Epoch 22/1000 
	 loss: 18.7448, MinusLogProbMetric: 18.7448, val_loss: 18.5852, val_MinusLogProbMetric: 18.5852

Epoch 22: val_loss did not improve from 18.42037
196/196 - 32s - loss: 18.7448 - MinusLogProbMetric: 18.7448 - val_loss: 18.5852 - val_MinusLogProbMetric: 18.5852 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 23/1000
2023-09-27 00:38:10.496 
Epoch 23/1000 
	 loss: 18.4493, MinusLogProbMetric: 18.4493, val_loss: 18.6322, val_MinusLogProbMetric: 18.6322

Epoch 23: val_loss did not improve from 18.42037
196/196 - 32s - loss: 18.4493 - MinusLogProbMetric: 18.4493 - val_loss: 18.6322 - val_MinusLogProbMetric: 18.6322 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 24/1000
2023-09-27 00:38:42.447 
Epoch 24/1000 
	 loss: 18.3766, MinusLogProbMetric: 18.3766, val_loss: 18.1973, val_MinusLogProbMetric: 18.1973

Epoch 24: val_loss improved from 18.42037 to 18.19735, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 18.3766 - MinusLogProbMetric: 18.3766 - val_loss: 18.1973 - val_MinusLogProbMetric: 18.1973 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 25/1000
2023-09-27 00:39:15.881 
Epoch 25/1000 
	 loss: 18.4200, MinusLogProbMetric: 18.4200, val_loss: 18.6554, val_MinusLogProbMetric: 18.6554

Epoch 25: val_loss did not improve from 18.19735
196/196 - 32s - loss: 18.4200 - MinusLogProbMetric: 18.4200 - val_loss: 18.6554 - val_MinusLogProbMetric: 18.6554 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 26/1000
2023-09-27 00:39:47.987 
Epoch 26/1000 
	 loss: 18.3929, MinusLogProbMetric: 18.3929, val_loss: 18.3400, val_MinusLogProbMetric: 18.3400

Epoch 26: val_loss did not improve from 18.19735
196/196 - 32s - loss: 18.3929 - MinusLogProbMetric: 18.3929 - val_loss: 18.3400 - val_MinusLogProbMetric: 18.3400 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 27/1000
2023-09-27 00:40:20.221 
Epoch 27/1000 
	 loss: 18.2133, MinusLogProbMetric: 18.2133, val_loss: 19.2657, val_MinusLogProbMetric: 19.2657

Epoch 27: val_loss did not improve from 18.19735
196/196 - 32s - loss: 18.2133 - MinusLogProbMetric: 18.2133 - val_loss: 19.2657 - val_MinusLogProbMetric: 19.2657 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 28/1000
2023-09-27 00:40:52.728 
Epoch 28/1000 
	 loss: 18.2077, MinusLogProbMetric: 18.2077, val_loss: 18.0868, val_MinusLogProbMetric: 18.0868

Epoch 28: val_loss improved from 18.19735 to 18.08684, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 18.2077 - MinusLogProbMetric: 18.2077 - val_loss: 18.0868 - val_MinusLogProbMetric: 18.0868 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 29/1000
2023-09-27 00:41:25.381 
Epoch 29/1000 
	 loss: 18.2113, MinusLogProbMetric: 18.2113, val_loss: 19.1856, val_MinusLogProbMetric: 19.1856

Epoch 29: val_loss did not improve from 18.08684
196/196 - 32s - loss: 18.2113 - MinusLogProbMetric: 18.2113 - val_loss: 19.1856 - val_MinusLogProbMetric: 19.1856 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 30/1000
2023-09-27 00:41:57.670 
Epoch 30/1000 
	 loss: 18.2247, MinusLogProbMetric: 18.2247, val_loss: 18.2294, val_MinusLogProbMetric: 18.2294

Epoch 30: val_loss did not improve from 18.08684
196/196 - 32s - loss: 18.2247 - MinusLogProbMetric: 18.2247 - val_loss: 18.2294 - val_MinusLogProbMetric: 18.2294 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 31/1000
2023-09-27 00:42:29.607 
Epoch 31/1000 
	 loss: 18.1375, MinusLogProbMetric: 18.1375, val_loss: 18.3102, val_MinusLogProbMetric: 18.3102

Epoch 31: val_loss did not improve from 18.08684
196/196 - 32s - loss: 18.1375 - MinusLogProbMetric: 18.1375 - val_loss: 18.3102 - val_MinusLogProbMetric: 18.3102 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 32/1000
2023-09-27 00:43:01.922 
Epoch 32/1000 
	 loss: 18.0635, MinusLogProbMetric: 18.0635, val_loss: 18.4198, val_MinusLogProbMetric: 18.4198

Epoch 32: val_loss did not improve from 18.08684
196/196 - 32s - loss: 18.0635 - MinusLogProbMetric: 18.0635 - val_loss: 18.4198 - val_MinusLogProbMetric: 18.4198 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 33/1000
2023-09-27 00:43:34.165 
Epoch 33/1000 
	 loss: 18.0984, MinusLogProbMetric: 18.0984, val_loss: 17.8798, val_MinusLogProbMetric: 17.8798

Epoch 33: val_loss improved from 18.08684 to 17.87977, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 18.0984 - MinusLogProbMetric: 18.0984 - val_loss: 17.8798 - val_MinusLogProbMetric: 17.8798 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 34/1000
2023-09-27 00:44:06.946 
Epoch 34/1000 
	 loss: 17.9574, MinusLogProbMetric: 17.9574, val_loss: 18.4723, val_MinusLogProbMetric: 18.4723

Epoch 34: val_loss did not improve from 17.87977
196/196 - 32s - loss: 17.9574 - MinusLogProbMetric: 17.9574 - val_loss: 18.4723 - val_MinusLogProbMetric: 18.4723 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 35/1000
2023-09-27 00:44:39.037 
Epoch 35/1000 
	 loss: 18.1225, MinusLogProbMetric: 18.1225, val_loss: 19.4628, val_MinusLogProbMetric: 19.4628

Epoch 35: val_loss did not improve from 17.87977
196/196 - 32s - loss: 18.1225 - MinusLogProbMetric: 18.1225 - val_loss: 19.4628 - val_MinusLogProbMetric: 19.4628 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 36/1000
2023-09-27 00:45:11.455 
Epoch 36/1000 
	 loss: 18.0386, MinusLogProbMetric: 18.0386, val_loss: 18.2445, val_MinusLogProbMetric: 18.2445

Epoch 36: val_loss did not improve from 17.87977
196/196 - 32s - loss: 18.0386 - MinusLogProbMetric: 18.0386 - val_loss: 18.2445 - val_MinusLogProbMetric: 18.2445 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 37/1000
2023-09-27 00:45:43.654 
Epoch 37/1000 
	 loss: 17.9485, MinusLogProbMetric: 17.9485, val_loss: 17.8986, val_MinusLogProbMetric: 17.8986

Epoch 37: val_loss did not improve from 17.87977
196/196 - 32s - loss: 17.9485 - MinusLogProbMetric: 17.9485 - val_loss: 17.8986 - val_MinusLogProbMetric: 17.8986 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 38/1000
2023-09-27 00:46:16.123 
Epoch 38/1000 
	 loss: 17.8975, MinusLogProbMetric: 17.8975, val_loss: 17.8865, val_MinusLogProbMetric: 17.8865

Epoch 38: val_loss did not improve from 17.87977
196/196 - 32s - loss: 17.8975 - MinusLogProbMetric: 17.8975 - val_loss: 17.8865 - val_MinusLogProbMetric: 17.8865 - lr: 0.0010 - 32s/epoch - 166ms/step
Epoch 39/1000
2023-09-27 00:46:48.322 
Epoch 39/1000 
	 loss: 17.9503, MinusLogProbMetric: 17.9503, val_loss: 18.1352, val_MinusLogProbMetric: 18.1352

Epoch 39: val_loss did not improve from 17.87977
196/196 - 32s - loss: 17.9503 - MinusLogProbMetric: 17.9503 - val_loss: 18.1352 - val_MinusLogProbMetric: 18.1352 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 40/1000
2023-09-27 00:47:20.466 
Epoch 40/1000 
	 loss: 17.8121, MinusLogProbMetric: 17.8121, val_loss: 17.7650, val_MinusLogProbMetric: 17.7650

Epoch 40: val_loss improved from 17.87977 to 17.76497, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 17.8121 - MinusLogProbMetric: 17.8121 - val_loss: 17.7650 - val_MinusLogProbMetric: 17.7650 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 41/1000
2023-09-27 00:47:53.173 
Epoch 41/1000 
	 loss: 17.8833, MinusLogProbMetric: 17.8833, val_loss: 18.2953, val_MinusLogProbMetric: 18.2953

Epoch 41: val_loss did not improve from 17.76497
196/196 - 32s - loss: 17.8833 - MinusLogProbMetric: 17.8833 - val_loss: 18.2953 - val_MinusLogProbMetric: 18.2953 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 42/1000
2023-09-27 00:48:24.974 
Epoch 42/1000 
	 loss: 17.9000, MinusLogProbMetric: 17.9000, val_loss: 18.0203, val_MinusLogProbMetric: 18.0203

Epoch 42: val_loss did not improve from 17.76497
196/196 - 32s - loss: 17.9000 - MinusLogProbMetric: 17.9000 - val_loss: 18.0203 - val_MinusLogProbMetric: 18.0203 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 43/1000
2023-09-27 00:48:56.967 
Epoch 43/1000 
	 loss: 17.8451, MinusLogProbMetric: 17.8451, val_loss: 18.3865, val_MinusLogProbMetric: 18.3865

Epoch 43: val_loss did not improve from 17.76497
196/196 - 32s - loss: 17.8451 - MinusLogProbMetric: 17.8451 - val_loss: 18.3865 - val_MinusLogProbMetric: 18.3865 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 44/1000
2023-09-27 00:49:29.285 
Epoch 44/1000 
	 loss: 17.7569, MinusLogProbMetric: 17.7569, val_loss: 18.1499, val_MinusLogProbMetric: 18.1499

Epoch 44: val_loss did not improve from 17.76497
196/196 - 32s - loss: 17.7569 - MinusLogProbMetric: 17.7569 - val_loss: 18.1499 - val_MinusLogProbMetric: 18.1499 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 45/1000
2023-09-27 00:50:01.575 
Epoch 45/1000 
	 loss: 17.7799, MinusLogProbMetric: 17.7799, val_loss: 18.4286, val_MinusLogProbMetric: 18.4286

Epoch 45: val_loss did not improve from 17.76497
196/196 - 32s - loss: 17.7799 - MinusLogProbMetric: 17.7799 - val_loss: 18.4286 - val_MinusLogProbMetric: 18.4286 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 46/1000
2023-09-27 00:50:33.566 
Epoch 46/1000 
	 loss: 17.8595, MinusLogProbMetric: 17.8595, val_loss: 17.9858, val_MinusLogProbMetric: 17.9858

Epoch 46: val_loss did not improve from 17.76497
196/196 - 32s - loss: 17.8595 - MinusLogProbMetric: 17.8595 - val_loss: 17.9858 - val_MinusLogProbMetric: 17.9858 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 47/1000
2023-09-27 00:51:05.480 
Epoch 47/1000 
	 loss: 17.7205, MinusLogProbMetric: 17.7205, val_loss: 17.9829, val_MinusLogProbMetric: 17.9829

Epoch 47: val_loss did not improve from 17.76497
196/196 - 32s - loss: 17.7205 - MinusLogProbMetric: 17.7205 - val_loss: 17.9829 - val_MinusLogProbMetric: 17.9829 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 48/1000
2023-09-27 00:51:37.740 
Epoch 48/1000 
	 loss: 17.7264, MinusLogProbMetric: 17.7264, val_loss: 18.0511, val_MinusLogProbMetric: 18.0511

Epoch 48: val_loss did not improve from 17.76497
196/196 - 32s - loss: 17.7264 - MinusLogProbMetric: 17.7264 - val_loss: 18.0511 - val_MinusLogProbMetric: 18.0511 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 49/1000
2023-09-27 00:52:09.771 
Epoch 49/1000 
	 loss: 17.6831, MinusLogProbMetric: 17.6831, val_loss: 18.2388, val_MinusLogProbMetric: 18.2388

Epoch 49: val_loss did not improve from 17.76497
196/196 - 32s - loss: 17.6831 - MinusLogProbMetric: 17.6831 - val_loss: 18.2388 - val_MinusLogProbMetric: 18.2388 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 50/1000
2023-09-27 00:52:42.013 
Epoch 50/1000 
	 loss: 17.7418, MinusLogProbMetric: 17.7418, val_loss: 18.2022, val_MinusLogProbMetric: 18.2022

Epoch 50: val_loss did not improve from 17.76497
196/196 - 32s - loss: 17.7418 - MinusLogProbMetric: 17.7418 - val_loss: 18.2022 - val_MinusLogProbMetric: 18.2022 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 51/1000
2023-09-27 00:53:14.187 
Epoch 51/1000 
	 loss: 17.6907, MinusLogProbMetric: 17.6907, val_loss: 18.1605, val_MinusLogProbMetric: 18.1605

Epoch 51: val_loss did not improve from 17.76497
196/196 - 32s - loss: 17.6907 - MinusLogProbMetric: 17.6907 - val_loss: 18.1605 - val_MinusLogProbMetric: 18.1605 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 52/1000
2023-09-27 00:53:46.103 
Epoch 52/1000 
	 loss: 17.6295, MinusLogProbMetric: 17.6295, val_loss: 17.8071, val_MinusLogProbMetric: 17.8071

Epoch 52: val_loss did not improve from 17.76497
196/196 - 32s - loss: 17.6295 - MinusLogProbMetric: 17.6295 - val_loss: 17.8071 - val_MinusLogProbMetric: 17.8071 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 53/1000
2023-09-27 00:54:18.180 
Epoch 53/1000 
	 loss: 17.6660, MinusLogProbMetric: 17.6660, val_loss: 17.6122, val_MinusLogProbMetric: 17.6122

Epoch 53: val_loss improved from 17.76497 to 17.61215, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 17.6660 - MinusLogProbMetric: 17.6660 - val_loss: 17.6122 - val_MinusLogProbMetric: 17.6122 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 54/1000
2023-09-27 00:54:50.489 
Epoch 54/1000 
	 loss: 17.6681, MinusLogProbMetric: 17.6681, val_loss: 17.8838, val_MinusLogProbMetric: 17.8838

Epoch 54: val_loss did not improve from 17.61215
196/196 - 32s - loss: 17.6681 - MinusLogProbMetric: 17.6681 - val_loss: 17.8838 - val_MinusLogProbMetric: 17.8838 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 55/1000
2023-09-27 00:55:22.264 
Epoch 55/1000 
	 loss: 17.6056, MinusLogProbMetric: 17.6056, val_loss: 17.8692, val_MinusLogProbMetric: 17.8692

Epoch 55: val_loss did not improve from 17.61215
196/196 - 32s - loss: 17.6056 - MinusLogProbMetric: 17.6056 - val_loss: 17.8692 - val_MinusLogProbMetric: 17.8692 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 56/1000
2023-09-27 00:55:54.236 
Epoch 56/1000 
	 loss: 17.6019, MinusLogProbMetric: 17.6019, val_loss: 17.6554, val_MinusLogProbMetric: 17.6554

Epoch 56: val_loss did not improve from 17.61215
196/196 - 32s - loss: 17.6019 - MinusLogProbMetric: 17.6019 - val_loss: 17.6554 - val_MinusLogProbMetric: 17.6554 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 57/1000
2023-09-27 00:56:26.087 
Epoch 57/1000 
	 loss: 17.5835, MinusLogProbMetric: 17.5835, val_loss: 18.3308, val_MinusLogProbMetric: 18.3308

Epoch 57: val_loss did not improve from 17.61215
196/196 - 32s - loss: 17.5835 - MinusLogProbMetric: 17.5835 - val_loss: 18.3308 - val_MinusLogProbMetric: 18.3308 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 58/1000
2023-09-27 00:56:57.781 
Epoch 58/1000 
	 loss: 17.6086, MinusLogProbMetric: 17.6086, val_loss: 18.0473, val_MinusLogProbMetric: 18.0473

Epoch 58: val_loss did not improve from 17.61215
196/196 - 32s - loss: 17.6086 - MinusLogProbMetric: 17.6086 - val_loss: 18.0473 - val_MinusLogProbMetric: 18.0473 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 59/1000
2023-09-27 00:57:29.436 
Epoch 59/1000 
	 loss: 17.5348, MinusLogProbMetric: 17.5348, val_loss: 17.3684, val_MinusLogProbMetric: 17.3684

Epoch 59: val_loss improved from 17.61215 to 17.36841, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 32s - loss: 17.5348 - MinusLogProbMetric: 17.5348 - val_loss: 17.3684 - val_MinusLogProbMetric: 17.3684 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 60/1000
2023-09-27 00:58:02.214 
Epoch 60/1000 
	 loss: 17.5559, MinusLogProbMetric: 17.5559, val_loss: 17.9653, val_MinusLogProbMetric: 17.9653

Epoch 60: val_loss did not improve from 17.36841
196/196 - 32s - loss: 17.5559 - MinusLogProbMetric: 17.5559 - val_loss: 17.9653 - val_MinusLogProbMetric: 17.9653 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 61/1000
2023-09-27 00:58:34.114 
Epoch 61/1000 
	 loss: 17.5483, MinusLogProbMetric: 17.5483, val_loss: 17.6213, val_MinusLogProbMetric: 17.6213

Epoch 61: val_loss did not improve from 17.36841
196/196 - 32s - loss: 17.5483 - MinusLogProbMetric: 17.5483 - val_loss: 17.6213 - val_MinusLogProbMetric: 17.6213 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 62/1000
2023-09-27 00:59:06.105 
Epoch 62/1000 
	 loss: 17.5111, MinusLogProbMetric: 17.5111, val_loss: 17.9834, val_MinusLogProbMetric: 17.9834

Epoch 62: val_loss did not improve from 17.36841
196/196 - 32s - loss: 17.5111 - MinusLogProbMetric: 17.5111 - val_loss: 17.9834 - val_MinusLogProbMetric: 17.9834 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 63/1000
2023-09-27 00:59:37.706 
Epoch 63/1000 
	 loss: 17.5533, MinusLogProbMetric: 17.5533, val_loss: 17.9674, val_MinusLogProbMetric: 17.9674

Epoch 63: val_loss did not improve from 17.36841
196/196 - 32s - loss: 17.5533 - MinusLogProbMetric: 17.5533 - val_loss: 17.9674 - val_MinusLogProbMetric: 17.9674 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 64/1000
2023-09-27 01:00:09.408 
Epoch 64/1000 
	 loss: 17.5364, MinusLogProbMetric: 17.5364, val_loss: 17.6127, val_MinusLogProbMetric: 17.6127

Epoch 64: val_loss did not improve from 17.36841
196/196 - 32s - loss: 17.5364 - MinusLogProbMetric: 17.5364 - val_loss: 17.6127 - val_MinusLogProbMetric: 17.6127 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 65/1000
2023-09-27 01:00:41.202 
Epoch 65/1000 
	 loss: 17.4654, MinusLogProbMetric: 17.4654, val_loss: 17.6190, val_MinusLogProbMetric: 17.6190

Epoch 65: val_loss did not improve from 17.36841
196/196 - 32s - loss: 17.4654 - MinusLogProbMetric: 17.4654 - val_loss: 17.6190 - val_MinusLogProbMetric: 17.6190 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 66/1000
2023-09-27 01:01:12.808 
Epoch 66/1000 
	 loss: 17.4982, MinusLogProbMetric: 17.4982, val_loss: 18.3587, val_MinusLogProbMetric: 18.3587

Epoch 66: val_loss did not improve from 17.36841
196/196 - 32s - loss: 17.4982 - MinusLogProbMetric: 17.4982 - val_loss: 18.3587 - val_MinusLogProbMetric: 18.3587 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 67/1000
2023-09-27 01:01:44.843 
Epoch 67/1000 
	 loss: 17.5346, MinusLogProbMetric: 17.5346, val_loss: 17.4949, val_MinusLogProbMetric: 17.4949

Epoch 67: val_loss did not improve from 17.36841
196/196 - 32s - loss: 17.5346 - MinusLogProbMetric: 17.5346 - val_loss: 17.4949 - val_MinusLogProbMetric: 17.4949 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 68/1000
2023-09-27 01:02:16.214 
Epoch 68/1000 
	 loss: 17.4764, MinusLogProbMetric: 17.4764, val_loss: 18.0528, val_MinusLogProbMetric: 18.0528

Epoch 68: val_loss did not improve from 17.36841
196/196 - 31s - loss: 17.4764 - MinusLogProbMetric: 17.4764 - val_loss: 18.0528 - val_MinusLogProbMetric: 18.0528 - lr: 0.0010 - 31s/epoch - 160ms/step
Epoch 69/1000
2023-09-27 01:02:48.525 
Epoch 69/1000 
	 loss: 17.5147, MinusLogProbMetric: 17.5147, val_loss: 17.8723, val_MinusLogProbMetric: 17.8723

Epoch 69: val_loss did not improve from 17.36841
196/196 - 32s - loss: 17.5147 - MinusLogProbMetric: 17.5147 - val_loss: 17.8723 - val_MinusLogProbMetric: 17.8723 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 70/1000
2023-09-27 01:03:19.955 
Epoch 70/1000 
	 loss: 17.4924, MinusLogProbMetric: 17.4924, val_loss: 17.8456, val_MinusLogProbMetric: 17.8456

Epoch 70: val_loss did not improve from 17.36841
196/196 - 31s - loss: 17.4924 - MinusLogProbMetric: 17.4924 - val_loss: 17.8456 - val_MinusLogProbMetric: 17.8456 - lr: 0.0010 - 31s/epoch - 160ms/step
Epoch 71/1000
2023-09-27 01:03:52.019 
Epoch 71/1000 
	 loss: 17.4161, MinusLogProbMetric: 17.4161, val_loss: 17.3618, val_MinusLogProbMetric: 17.3618

Epoch 71: val_loss improved from 17.36841 to 17.36184, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 17.4161 - MinusLogProbMetric: 17.4161 - val_loss: 17.3618 - val_MinusLogProbMetric: 17.3618 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 72/1000
2023-09-27 01:04:24.859 
Epoch 72/1000 
	 loss: 17.4199, MinusLogProbMetric: 17.4199, val_loss: 17.7339, val_MinusLogProbMetric: 17.7339

Epoch 72: val_loss did not improve from 17.36184
196/196 - 32s - loss: 17.4199 - MinusLogProbMetric: 17.4199 - val_loss: 17.7339 - val_MinusLogProbMetric: 17.7339 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 73/1000
2023-09-27 01:04:56.760 
Epoch 73/1000 
	 loss: 17.4114, MinusLogProbMetric: 17.4114, val_loss: 17.8742, val_MinusLogProbMetric: 17.8742

Epoch 73: val_loss did not improve from 17.36184
196/196 - 32s - loss: 17.4114 - MinusLogProbMetric: 17.4114 - val_loss: 17.8742 - val_MinusLogProbMetric: 17.8742 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 74/1000
2023-09-27 01:05:28.806 
Epoch 74/1000 
	 loss: 17.4487, MinusLogProbMetric: 17.4487, val_loss: 17.4358, val_MinusLogProbMetric: 17.4358

Epoch 74: val_loss did not improve from 17.36184
196/196 - 32s - loss: 17.4487 - MinusLogProbMetric: 17.4487 - val_loss: 17.4358 - val_MinusLogProbMetric: 17.4358 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 75/1000
2023-09-27 01:06:00.830 
Epoch 75/1000 
	 loss: 17.3224, MinusLogProbMetric: 17.3224, val_loss: 18.2801, val_MinusLogProbMetric: 18.2801

Epoch 75: val_loss did not improve from 17.36184
196/196 - 32s - loss: 17.3224 - MinusLogProbMetric: 17.3224 - val_loss: 18.2801 - val_MinusLogProbMetric: 18.2801 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 76/1000
2023-09-27 01:06:32.853 
Epoch 76/1000 
	 loss: 17.3557, MinusLogProbMetric: 17.3557, val_loss: 18.2797, val_MinusLogProbMetric: 18.2797

Epoch 76: val_loss did not improve from 17.36184
196/196 - 32s - loss: 17.3557 - MinusLogProbMetric: 17.3557 - val_loss: 18.2797 - val_MinusLogProbMetric: 18.2797 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 77/1000
2023-09-27 01:07:04.794 
Epoch 77/1000 
	 loss: 17.3668, MinusLogProbMetric: 17.3668, val_loss: 17.5502, val_MinusLogProbMetric: 17.5502

Epoch 77: val_loss did not improve from 17.36184
196/196 - 32s - loss: 17.3668 - MinusLogProbMetric: 17.3668 - val_loss: 17.5502 - val_MinusLogProbMetric: 17.5502 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 78/1000
2023-09-27 01:07:36.165 
Epoch 78/1000 
	 loss: 17.3294, MinusLogProbMetric: 17.3294, val_loss: 17.5642, val_MinusLogProbMetric: 17.5642

Epoch 78: val_loss did not improve from 17.36184
196/196 - 31s - loss: 17.3294 - MinusLogProbMetric: 17.3294 - val_loss: 17.5642 - val_MinusLogProbMetric: 17.5642 - lr: 0.0010 - 31s/epoch - 160ms/step
Epoch 79/1000
2023-09-27 01:08:07.968 
Epoch 79/1000 
	 loss: 17.4564, MinusLogProbMetric: 17.4564, val_loss: 17.5540, val_MinusLogProbMetric: 17.5540

Epoch 79: val_loss did not improve from 17.36184
196/196 - 32s - loss: 17.4564 - MinusLogProbMetric: 17.4564 - val_loss: 17.5540 - val_MinusLogProbMetric: 17.5540 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 80/1000
2023-09-27 01:08:39.619 
Epoch 80/1000 
	 loss: 17.3412, MinusLogProbMetric: 17.3412, val_loss: 18.1229, val_MinusLogProbMetric: 18.1229

Epoch 80: val_loss did not improve from 17.36184
196/196 - 32s - loss: 17.3412 - MinusLogProbMetric: 17.3412 - val_loss: 18.1229 - val_MinusLogProbMetric: 18.1229 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 81/1000
2023-09-27 01:09:11.374 
Epoch 81/1000 
	 loss: 17.3112, MinusLogProbMetric: 17.3112, val_loss: 17.3940, val_MinusLogProbMetric: 17.3940

Epoch 81: val_loss did not improve from 17.36184
196/196 - 32s - loss: 17.3112 - MinusLogProbMetric: 17.3112 - val_loss: 17.3940 - val_MinusLogProbMetric: 17.3940 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 82/1000
2023-09-27 01:09:43.048 
Epoch 82/1000 
	 loss: 17.3613, MinusLogProbMetric: 17.3613, val_loss: 17.7528, val_MinusLogProbMetric: 17.7528

Epoch 82: val_loss did not improve from 17.36184
196/196 - 32s - loss: 17.3613 - MinusLogProbMetric: 17.3613 - val_loss: 17.7528 - val_MinusLogProbMetric: 17.7528 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 83/1000
2023-09-27 01:10:14.732 
Epoch 83/1000 
	 loss: 17.3059, MinusLogProbMetric: 17.3059, val_loss: 17.6624, val_MinusLogProbMetric: 17.6624

Epoch 83: val_loss did not improve from 17.36184
196/196 - 32s - loss: 17.3059 - MinusLogProbMetric: 17.3059 - val_loss: 17.6624 - val_MinusLogProbMetric: 17.6624 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 84/1000
2023-09-27 01:10:46.842 
Epoch 84/1000 
	 loss: 17.3533, MinusLogProbMetric: 17.3533, val_loss: 17.5571, val_MinusLogProbMetric: 17.5571

Epoch 84: val_loss did not improve from 17.36184
196/196 - 32s - loss: 17.3533 - MinusLogProbMetric: 17.3533 - val_loss: 17.5571 - val_MinusLogProbMetric: 17.5571 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 85/1000
2023-09-27 01:11:18.681 
Epoch 85/1000 
	 loss: 17.3682, MinusLogProbMetric: 17.3682, val_loss: 17.2455, val_MinusLogProbMetric: 17.2455

Epoch 85: val_loss improved from 17.36184 to 17.24552, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 17.3682 - MinusLogProbMetric: 17.3682 - val_loss: 17.2455 - val_MinusLogProbMetric: 17.2455 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 86/1000
2023-09-27 01:11:51.487 
Epoch 86/1000 
	 loss: 17.3149, MinusLogProbMetric: 17.3149, val_loss: 17.4522, val_MinusLogProbMetric: 17.4522

Epoch 86: val_loss did not improve from 17.24552
196/196 - 32s - loss: 17.3149 - MinusLogProbMetric: 17.3149 - val_loss: 17.4522 - val_MinusLogProbMetric: 17.4522 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 87/1000
2023-09-27 01:12:23.388 
Epoch 87/1000 
	 loss: 17.3084, MinusLogProbMetric: 17.3084, val_loss: 17.3092, val_MinusLogProbMetric: 17.3092

Epoch 87: val_loss did not improve from 17.24552
196/196 - 32s - loss: 17.3084 - MinusLogProbMetric: 17.3084 - val_loss: 17.3092 - val_MinusLogProbMetric: 17.3092 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 88/1000
2023-09-27 01:12:55.425 
Epoch 88/1000 
	 loss: 17.3220, MinusLogProbMetric: 17.3220, val_loss: 17.4266, val_MinusLogProbMetric: 17.4266

Epoch 88: val_loss did not improve from 17.24552
196/196 - 32s - loss: 17.3220 - MinusLogProbMetric: 17.3220 - val_loss: 17.4266 - val_MinusLogProbMetric: 17.4266 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 89/1000
2023-09-27 01:13:27.396 
Epoch 89/1000 
	 loss: 17.2638, MinusLogProbMetric: 17.2638, val_loss: 17.4147, val_MinusLogProbMetric: 17.4147

Epoch 89: val_loss did not improve from 17.24552
196/196 - 32s - loss: 17.2638 - MinusLogProbMetric: 17.2638 - val_loss: 17.4147 - val_MinusLogProbMetric: 17.4147 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 90/1000
2023-09-27 01:13:59.102 
Epoch 90/1000 
	 loss: 17.2710, MinusLogProbMetric: 17.2710, val_loss: 17.9372, val_MinusLogProbMetric: 17.9372

Epoch 90: val_loss did not improve from 17.24552
196/196 - 32s - loss: 17.2710 - MinusLogProbMetric: 17.2710 - val_loss: 17.9372 - val_MinusLogProbMetric: 17.9372 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 91/1000
2023-09-27 01:14:30.734 
Epoch 91/1000 
	 loss: 17.2480, MinusLogProbMetric: 17.2480, val_loss: 17.4017, val_MinusLogProbMetric: 17.4017

Epoch 91: val_loss did not improve from 17.24552
196/196 - 32s - loss: 17.2480 - MinusLogProbMetric: 17.2480 - val_loss: 17.4017 - val_MinusLogProbMetric: 17.4017 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 92/1000
2023-09-27 01:15:02.488 
Epoch 92/1000 
	 loss: 17.2560, MinusLogProbMetric: 17.2560, val_loss: 18.1037, val_MinusLogProbMetric: 18.1037

Epoch 92: val_loss did not improve from 17.24552
196/196 - 32s - loss: 17.2560 - MinusLogProbMetric: 17.2560 - val_loss: 18.1037 - val_MinusLogProbMetric: 18.1037 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 93/1000
2023-09-27 01:15:34.215 
Epoch 93/1000 
	 loss: 17.2242, MinusLogProbMetric: 17.2242, val_loss: 18.0797, val_MinusLogProbMetric: 18.0797

Epoch 93: val_loss did not improve from 17.24552
196/196 - 32s - loss: 17.2242 - MinusLogProbMetric: 17.2242 - val_loss: 18.0797 - val_MinusLogProbMetric: 18.0797 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 94/1000
2023-09-27 01:16:06.114 
Epoch 94/1000 
	 loss: 17.2840, MinusLogProbMetric: 17.2840, val_loss: 17.3032, val_MinusLogProbMetric: 17.3032

Epoch 94: val_loss did not improve from 17.24552
196/196 - 32s - loss: 17.2840 - MinusLogProbMetric: 17.2840 - val_loss: 17.3032 - val_MinusLogProbMetric: 17.3032 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 95/1000
2023-09-27 01:16:37.596 
Epoch 95/1000 
	 loss: 17.2478, MinusLogProbMetric: 17.2478, val_loss: 17.7729, val_MinusLogProbMetric: 17.7729

Epoch 95: val_loss did not improve from 17.24552
196/196 - 31s - loss: 17.2478 - MinusLogProbMetric: 17.2478 - val_loss: 17.7729 - val_MinusLogProbMetric: 17.7729 - lr: 0.0010 - 31s/epoch - 161ms/step
Epoch 96/1000
2023-09-27 01:17:09.186 
Epoch 96/1000 
	 loss: 17.2252, MinusLogProbMetric: 17.2252, val_loss: 17.4165, val_MinusLogProbMetric: 17.4165

Epoch 96: val_loss did not improve from 17.24552
196/196 - 32s - loss: 17.2252 - MinusLogProbMetric: 17.2252 - val_loss: 17.4165 - val_MinusLogProbMetric: 17.4165 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 97/1000
2023-09-27 01:17:41.034 
Epoch 97/1000 
	 loss: 17.2183, MinusLogProbMetric: 17.2183, val_loss: 17.2082, val_MinusLogProbMetric: 17.2082

Epoch 97: val_loss improved from 17.24552 to 17.20821, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 17.2183 - MinusLogProbMetric: 17.2183 - val_loss: 17.2082 - val_MinusLogProbMetric: 17.2082 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 98/1000
2023-09-27 01:18:13.617 
Epoch 98/1000 
	 loss: 17.1817, MinusLogProbMetric: 17.1817, val_loss: 18.2122, val_MinusLogProbMetric: 18.2122

Epoch 98: val_loss did not improve from 17.20821
196/196 - 32s - loss: 17.1817 - MinusLogProbMetric: 17.1817 - val_loss: 18.2122 - val_MinusLogProbMetric: 18.2122 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 99/1000
2023-09-27 01:18:45.777 
Epoch 99/1000 
	 loss: 17.1838, MinusLogProbMetric: 17.1838, val_loss: 17.9715, val_MinusLogProbMetric: 17.9715

Epoch 99: val_loss did not improve from 17.20821
196/196 - 32s - loss: 17.1838 - MinusLogProbMetric: 17.1838 - val_loss: 17.9715 - val_MinusLogProbMetric: 17.9715 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 100/1000
2023-09-27 01:19:17.538 
Epoch 100/1000 
	 loss: 17.2275, MinusLogProbMetric: 17.2275, val_loss: 17.4686, val_MinusLogProbMetric: 17.4686

Epoch 100: val_loss did not improve from 17.20821
196/196 - 32s - loss: 17.2275 - MinusLogProbMetric: 17.2275 - val_loss: 17.4686 - val_MinusLogProbMetric: 17.4686 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 101/1000
2023-09-27 01:19:49.498 
Epoch 101/1000 
	 loss: 17.1958, MinusLogProbMetric: 17.1958, val_loss: 17.8377, val_MinusLogProbMetric: 17.8377

Epoch 101: val_loss did not improve from 17.20821
196/196 - 32s - loss: 17.1958 - MinusLogProbMetric: 17.1958 - val_loss: 17.8377 - val_MinusLogProbMetric: 17.8377 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 102/1000
2023-09-27 01:20:21.145 
Epoch 102/1000 
	 loss: 17.2459, MinusLogProbMetric: 17.2459, val_loss: 17.3069, val_MinusLogProbMetric: 17.3069

Epoch 102: val_loss did not improve from 17.20821
196/196 - 32s - loss: 17.2459 - MinusLogProbMetric: 17.2459 - val_loss: 17.3069 - val_MinusLogProbMetric: 17.3069 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 103/1000
2023-09-27 01:20:52.793 
Epoch 103/1000 
	 loss: 17.1659, MinusLogProbMetric: 17.1659, val_loss: 17.5608, val_MinusLogProbMetric: 17.5608

Epoch 103: val_loss did not improve from 17.20821
196/196 - 32s - loss: 17.1659 - MinusLogProbMetric: 17.1659 - val_loss: 17.5608 - val_MinusLogProbMetric: 17.5608 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 104/1000
2023-09-27 01:21:24.751 
Epoch 104/1000 
	 loss: 17.1882, MinusLogProbMetric: 17.1882, val_loss: 17.1840, val_MinusLogProbMetric: 17.1840

Epoch 104: val_loss improved from 17.20821 to 17.18402, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 17.1882 - MinusLogProbMetric: 17.1882 - val_loss: 17.1840 - val_MinusLogProbMetric: 17.1840 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 105/1000
2023-09-27 01:21:57.118 
Epoch 105/1000 
	 loss: 17.1629, MinusLogProbMetric: 17.1629, val_loss: 17.6282, val_MinusLogProbMetric: 17.6282

Epoch 105: val_loss did not improve from 17.18402
196/196 - 32s - loss: 17.1629 - MinusLogProbMetric: 17.1629 - val_loss: 17.6282 - val_MinusLogProbMetric: 17.6282 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 106/1000
2023-09-27 01:22:29.167 
Epoch 106/1000 
	 loss: 17.1064, MinusLogProbMetric: 17.1064, val_loss: 17.1538, val_MinusLogProbMetric: 17.1538

Epoch 106: val_loss improved from 17.18402 to 17.15380, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 17.1064 - MinusLogProbMetric: 17.1064 - val_loss: 17.1538 - val_MinusLogProbMetric: 17.1538 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 107/1000
2023-09-27 01:23:01.848 
Epoch 107/1000 
	 loss: 17.1792, MinusLogProbMetric: 17.1792, val_loss: 17.3030, val_MinusLogProbMetric: 17.3030

Epoch 107: val_loss did not improve from 17.15380
196/196 - 32s - loss: 17.1792 - MinusLogProbMetric: 17.1792 - val_loss: 17.3030 - val_MinusLogProbMetric: 17.3030 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 108/1000
2023-09-27 01:23:33.746 
Epoch 108/1000 
	 loss: 17.1342, MinusLogProbMetric: 17.1342, val_loss: 17.5419, val_MinusLogProbMetric: 17.5419

Epoch 108: val_loss did not improve from 17.15380
196/196 - 32s - loss: 17.1342 - MinusLogProbMetric: 17.1342 - val_loss: 17.5419 - val_MinusLogProbMetric: 17.5419 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 109/1000
2023-09-27 01:24:05.480 
Epoch 109/1000 
	 loss: 17.1550, MinusLogProbMetric: 17.1550, val_loss: 17.3043, val_MinusLogProbMetric: 17.3043

Epoch 109: val_loss did not improve from 17.15380
196/196 - 32s - loss: 17.1550 - MinusLogProbMetric: 17.1550 - val_loss: 17.3043 - val_MinusLogProbMetric: 17.3043 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 110/1000
2023-09-27 01:24:37.377 
Epoch 110/1000 
	 loss: 17.1140, MinusLogProbMetric: 17.1140, val_loss: 17.0975, val_MinusLogProbMetric: 17.0975

Epoch 110: val_loss improved from 17.15380 to 17.09749, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 17.1140 - MinusLogProbMetric: 17.1140 - val_loss: 17.0975 - val_MinusLogProbMetric: 17.0975 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 111/1000
2023-09-27 01:25:09.900 
Epoch 111/1000 
	 loss: 17.1114, MinusLogProbMetric: 17.1114, val_loss: 17.3848, val_MinusLogProbMetric: 17.3848

Epoch 111: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.1114 - MinusLogProbMetric: 17.1114 - val_loss: 17.3848 - val_MinusLogProbMetric: 17.3848 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 112/1000
2023-09-27 01:25:41.662 
Epoch 112/1000 
	 loss: 17.1849, MinusLogProbMetric: 17.1849, val_loss: 17.2427, val_MinusLogProbMetric: 17.2427

Epoch 112: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.1849 - MinusLogProbMetric: 17.1849 - val_loss: 17.2427 - val_MinusLogProbMetric: 17.2427 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 113/1000
2023-09-27 01:26:13.638 
Epoch 113/1000 
	 loss: 17.1333, MinusLogProbMetric: 17.1333, val_loss: 17.2854, val_MinusLogProbMetric: 17.2854

Epoch 113: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.1333 - MinusLogProbMetric: 17.1333 - val_loss: 17.2854 - val_MinusLogProbMetric: 17.2854 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 114/1000
2023-09-27 01:26:45.616 
Epoch 114/1000 
	 loss: 17.0779, MinusLogProbMetric: 17.0779, val_loss: 17.5592, val_MinusLogProbMetric: 17.5592

Epoch 114: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0779 - MinusLogProbMetric: 17.0779 - val_loss: 17.5592 - val_MinusLogProbMetric: 17.5592 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 115/1000
2023-09-27 01:27:17.180 
Epoch 115/1000 
	 loss: 17.1121, MinusLogProbMetric: 17.1121, val_loss: 17.1583, val_MinusLogProbMetric: 17.1583

Epoch 115: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.1121 - MinusLogProbMetric: 17.1121 - val_loss: 17.1583 - val_MinusLogProbMetric: 17.1583 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 116/1000
2023-09-27 01:27:49.168 
Epoch 116/1000 
	 loss: 17.1608, MinusLogProbMetric: 17.1608, val_loss: 17.3143, val_MinusLogProbMetric: 17.3143

Epoch 116: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.1608 - MinusLogProbMetric: 17.1608 - val_loss: 17.3143 - val_MinusLogProbMetric: 17.3143 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 117/1000
2023-09-27 01:28:20.929 
Epoch 117/1000 
	 loss: 17.0920, MinusLogProbMetric: 17.0920, val_loss: 17.3187, val_MinusLogProbMetric: 17.3187

Epoch 117: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0920 - MinusLogProbMetric: 17.0920 - val_loss: 17.3187 - val_MinusLogProbMetric: 17.3187 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 118/1000
2023-09-27 01:28:52.747 
Epoch 118/1000 
	 loss: 17.1134, MinusLogProbMetric: 17.1134, val_loss: 18.0106, val_MinusLogProbMetric: 18.0106

Epoch 118: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.1134 - MinusLogProbMetric: 17.1134 - val_loss: 18.0106 - val_MinusLogProbMetric: 18.0106 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 119/1000
2023-09-27 01:29:24.364 
Epoch 119/1000 
	 loss: 17.1375, MinusLogProbMetric: 17.1375, val_loss: 17.5032, val_MinusLogProbMetric: 17.5032

Epoch 119: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.1375 - MinusLogProbMetric: 17.1375 - val_loss: 17.5032 - val_MinusLogProbMetric: 17.5032 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 120/1000
2023-09-27 01:29:55.948 
Epoch 120/1000 
	 loss: 17.1130, MinusLogProbMetric: 17.1130, val_loss: 17.2583, val_MinusLogProbMetric: 17.2583

Epoch 120: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.1130 - MinusLogProbMetric: 17.1130 - val_loss: 17.2583 - val_MinusLogProbMetric: 17.2583 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 121/1000
2023-09-27 01:30:28.064 
Epoch 121/1000 
	 loss: 17.0455, MinusLogProbMetric: 17.0455, val_loss: 17.3747, val_MinusLogProbMetric: 17.3747

Epoch 121: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0455 - MinusLogProbMetric: 17.0455 - val_loss: 17.3747 - val_MinusLogProbMetric: 17.3747 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 122/1000
2023-09-27 01:31:00.268 
Epoch 122/1000 
	 loss: 17.0684, MinusLogProbMetric: 17.0684, val_loss: 17.3019, val_MinusLogProbMetric: 17.3019

Epoch 122: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0684 - MinusLogProbMetric: 17.0684 - val_loss: 17.3019 - val_MinusLogProbMetric: 17.3019 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 123/1000
2023-09-27 01:31:32.282 
Epoch 123/1000 
	 loss: 17.0866, MinusLogProbMetric: 17.0866, val_loss: 17.2356, val_MinusLogProbMetric: 17.2356

Epoch 123: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0866 - MinusLogProbMetric: 17.0866 - val_loss: 17.2356 - val_MinusLogProbMetric: 17.2356 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 124/1000
2023-09-27 01:32:04.051 
Epoch 124/1000 
	 loss: 17.1007, MinusLogProbMetric: 17.1007, val_loss: 18.2094, val_MinusLogProbMetric: 18.2094

Epoch 124: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.1007 - MinusLogProbMetric: 17.1007 - val_loss: 18.2094 - val_MinusLogProbMetric: 18.2094 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 125/1000
2023-09-27 01:32:35.842 
Epoch 125/1000 
	 loss: 17.0815, MinusLogProbMetric: 17.0815, val_loss: 17.2142, val_MinusLogProbMetric: 17.2142

Epoch 125: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0815 - MinusLogProbMetric: 17.0815 - val_loss: 17.2142 - val_MinusLogProbMetric: 17.2142 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 126/1000
2023-09-27 01:33:07.766 
Epoch 126/1000 
	 loss: 17.0474, MinusLogProbMetric: 17.0474, val_loss: 17.4044, val_MinusLogProbMetric: 17.4044

Epoch 126: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0474 - MinusLogProbMetric: 17.0474 - val_loss: 17.4044 - val_MinusLogProbMetric: 17.4044 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 127/1000
2023-09-27 01:33:39.318 
Epoch 127/1000 
	 loss: 17.0368, MinusLogProbMetric: 17.0368, val_loss: 17.5743, val_MinusLogProbMetric: 17.5743

Epoch 127: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0368 - MinusLogProbMetric: 17.0368 - val_loss: 17.5743 - val_MinusLogProbMetric: 17.5743 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 128/1000
2023-09-27 01:34:11.720 
Epoch 128/1000 
	 loss: 17.0502, MinusLogProbMetric: 17.0502, val_loss: 17.2961, val_MinusLogProbMetric: 17.2961

Epoch 128: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0502 - MinusLogProbMetric: 17.0502 - val_loss: 17.2961 - val_MinusLogProbMetric: 17.2961 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 129/1000
2023-09-27 01:34:43.576 
Epoch 129/1000 
	 loss: 17.0917, MinusLogProbMetric: 17.0917, val_loss: 17.1374, val_MinusLogProbMetric: 17.1374

Epoch 129: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0917 - MinusLogProbMetric: 17.0917 - val_loss: 17.1374 - val_MinusLogProbMetric: 17.1374 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 130/1000
2023-09-27 01:35:15.449 
Epoch 130/1000 
	 loss: 17.0478, MinusLogProbMetric: 17.0478, val_loss: 17.2916, val_MinusLogProbMetric: 17.2916

Epoch 130: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0478 - MinusLogProbMetric: 17.0478 - val_loss: 17.2916 - val_MinusLogProbMetric: 17.2916 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 131/1000
2023-09-27 01:35:47.630 
Epoch 131/1000 
	 loss: 17.0336, MinusLogProbMetric: 17.0336, val_loss: 17.6474, val_MinusLogProbMetric: 17.6474

Epoch 131: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0336 - MinusLogProbMetric: 17.0336 - val_loss: 17.6474 - val_MinusLogProbMetric: 17.6474 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 132/1000
2023-09-27 01:36:19.698 
Epoch 132/1000 
	 loss: 17.0105, MinusLogProbMetric: 17.0105, val_loss: 17.2267, val_MinusLogProbMetric: 17.2267

Epoch 132: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0105 - MinusLogProbMetric: 17.0105 - val_loss: 17.2267 - val_MinusLogProbMetric: 17.2267 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 133/1000
2023-09-27 01:36:51.404 
Epoch 133/1000 
	 loss: 17.0749, MinusLogProbMetric: 17.0749, val_loss: 17.4226, val_MinusLogProbMetric: 17.4226

Epoch 133: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0749 - MinusLogProbMetric: 17.0749 - val_loss: 17.4226 - val_MinusLogProbMetric: 17.4226 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 134/1000
2023-09-27 01:37:23.225 
Epoch 134/1000 
	 loss: 17.0300, MinusLogProbMetric: 17.0300, val_loss: 17.5930, val_MinusLogProbMetric: 17.5930

Epoch 134: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0300 - MinusLogProbMetric: 17.0300 - val_loss: 17.5930 - val_MinusLogProbMetric: 17.5930 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 135/1000
2023-09-27 01:37:55.076 
Epoch 135/1000 
	 loss: 17.0808, MinusLogProbMetric: 17.0808, val_loss: 17.4232, val_MinusLogProbMetric: 17.4232

Epoch 135: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0808 - MinusLogProbMetric: 17.0808 - val_loss: 17.4232 - val_MinusLogProbMetric: 17.4232 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 136/1000
2023-09-27 01:38:26.614 
Epoch 136/1000 
	 loss: 17.0229, MinusLogProbMetric: 17.0229, val_loss: 17.1819, val_MinusLogProbMetric: 17.1819

Epoch 136: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0229 - MinusLogProbMetric: 17.0229 - val_loss: 17.1819 - val_MinusLogProbMetric: 17.1819 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 137/1000
2023-09-27 01:38:58.967 
Epoch 137/1000 
	 loss: 16.9872, MinusLogProbMetric: 16.9872, val_loss: 17.2011, val_MinusLogProbMetric: 17.2011

Epoch 137: val_loss did not improve from 17.09749
196/196 - 32s - loss: 16.9872 - MinusLogProbMetric: 16.9872 - val_loss: 17.2011 - val_MinusLogProbMetric: 17.2011 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 138/1000
2023-09-27 01:39:30.702 
Epoch 138/1000 
	 loss: 17.0006, MinusLogProbMetric: 17.0006, val_loss: 17.1284, val_MinusLogProbMetric: 17.1284

Epoch 138: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0006 - MinusLogProbMetric: 17.0006 - val_loss: 17.1284 - val_MinusLogProbMetric: 17.1284 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 139/1000
2023-09-27 01:40:02.404 
Epoch 139/1000 
	 loss: 17.0021, MinusLogProbMetric: 17.0021, val_loss: 17.3069, val_MinusLogProbMetric: 17.3069

Epoch 139: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0021 - MinusLogProbMetric: 17.0021 - val_loss: 17.3069 - val_MinusLogProbMetric: 17.3069 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 140/1000
2023-09-27 01:40:34.400 
Epoch 140/1000 
	 loss: 17.0086, MinusLogProbMetric: 17.0086, val_loss: 17.1125, val_MinusLogProbMetric: 17.1125

Epoch 140: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0086 - MinusLogProbMetric: 17.0086 - val_loss: 17.1125 - val_MinusLogProbMetric: 17.1125 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 141/1000
2023-09-27 01:41:07.715 
Epoch 141/1000 
	 loss: 16.9981, MinusLogProbMetric: 16.9981, val_loss: 17.5014, val_MinusLogProbMetric: 17.5014

Epoch 141: val_loss did not improve from 17.09749
196/196 - 33s - loss: 16.9981 - MinusLogProbMetric: 16.9981 - val_loss: 17.5014 - val_MinusLogProbMetric: 17.5014 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 142/1000
2023-09-27 01:41:41.110 
Epoch 142/1000 
	 loss: 17.0154, MinusLogProbMetric: 17.0154, val_loss: 17.2318, val_MinusLogProbMetric: 17.2318

Epoch 142: val_loss did not improve from 17.09749
196/196 - 33s - loss: 17.0154 - MinusLogProbMetric: 17.0154 - val_loss: 17.2318 - val_MinusLogProbMetric: 17.2318 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 143/1000
2023-09-27 01:42:14.134 
Epoch 143/1000 
	 loss: 16.9999, MinusLogProbMetric: 16.9999, val_loss: 17.2093, val_MinusLogProbMetric: 17.2093

Epoch 143: val_loss did not improve from 17.09749
196/196 - 33s - loss: 16.9999 - MinusLogProbMetric: 16.9999 - val_loss: 17.2093 - val_MinusLogProbMetric: 17.2093 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 144/1000
2023-09-27 01:42:46.674 
Epoch 144/1000 
	 loss: 16.9819, MinusLogProbMetric: 16.9819, val_loss: 17.3943, val_MinusLogProbMetric: 17.3943

Epoch 144: val_loss did not improve from 17.09749
196/196 - 33s - loss: 16.9819 - MinusLogProbMetric: 16.9819 - val_loss: 17.3943 - val_MinusLogProbMetric: 17.3943 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 145/1000
2023-09-27 01:43:19.425 
Epoch 145/1000 
	 loss: 17.0148, MinusLogProbMetric: 17.0148, val_loss: 17.5747, val_MinusLogProbMetric: 17.5747

Epoch 145: val_loss did not improve from 17.09749
196/196 - 33s - loss: 17.0148 - MinusLogProbMetric: 17.0148 - val_loss: 17.5747 - val_MinusLogProbMetric: 17.5747 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 146/1000
2023-09-27 01:43:51.622 
Epoch 146/1000 
	 loss: 16.9869, MinusLogProbMetric: 16.9869, val_loss: 17.5635, val_MinusLogProbMetric: 17.5635

Epoch 146: val_loss did not improve from 17.09749
196/196 - 32s - loss: 16.9869 - MinusLogProbMetric: 16.9869 - val_loss: 17.5635 - val_MinusLogProbMetric: 17.5635 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 147/1000
2023-09-27 01:44:24.155 
Epoch 147/1000 
	 loss: 16.9840, MinusLogProbMetric: 16.9840, val_loss: 17.3553, val_MinusLogProbMetric: 17.3553

Epoch 147: val_loss did not improve from 17.09749
196/196 - 33s - loss: 16.9840 - MinusLogProbMetric: 16.9840 - val_loss: 17.3553 - val_MinusLogProbMetric: 17.3553 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 148/1000
2023-09-27 01:44:56.081 
Epoch 148/1000 
	 loss: 17.0093, MinusLogProbMetric: 17.0093, val_loss: 17.2563, val_MinusLogProbMetric: 17.2563

Epoch 148: val_loss did not improve from 17.09749
196/196 - 32s - loss: 17.0093 - MinusLogProbMetric: 17.0093 - val_loss: 17.2563 - val_MinusLogProbMetric: 17.2563 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 149/1000
2023-09-27 01:45:28.017 
Epoch 149/1000 
	 loss: 16.9611, MinusLogProbMetric: 16.9611, val_loss: 17.4039, val_MinusLogProbMetric: 17.4039

Epoch 149: val_loss did not improve from 17.09749
196/196 - 32s - loss: 16.9611 - MinusLogProbMetric: 16.9611 - val_loss: 17.4039 - val_MinusLogProbMetric: 17.4039 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 150/1000
2023-09-27 01:46:00.423 
Epoch 150/1000 
	 loss: 16.9434, MinusLogProbMetric: 16.9434, val_loss: 17.0437, val_MinusLogProbMetric: 17.0437

Epoch 150: val_loss improved from 17.09749 to 17.04369, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 16.9434 - MinusLogProbMetric: 16.9434 - val_loss: 17.0437 - val_MinusLogProbMetric: 17.0437 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 151/1000
2023-09-27 01:46:32.980 
Epoch 151/1000 
	 loss: 16.9839, MinusLogProbMetric: 16.9839, val_loss: 17.5409, val_MinusLogProbMetric: 17.5409

Epoch 151: val_loss did not improve from 17.04369
196/196 - 32s - loss: 16.9839 - MinusLogProbMetric: 16.9839 - val_loss: 17.5409 - val_MinusLogProbMetric: 17.5409 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 152/1000
2023-09-27 01:47:04.826 
Epoch 152/1000 
	 loss: 16.9487, MinusLogProbMetric: 16.9487, val_loss: 17.1418, val_MinusLogProbMetric: 17.1418

Epoch 152: val_loss did not improve from 17.04369
196/196 - 32s - loss: 16.9487 - MinusLogProbMetric: 16.9487 - val_loss: 17.1418 - val_MinusLogProbMetric: 17.1418 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 153/1000
2023-09-27 01:47:36.433 
Epoch 153/1000 
	 loss: 16.9419, MinusLogProbMetric: 16.9419, val_loss: 17.7830, val_MinusLogProbMetric: 17.7830

Epoch 153: val_loss did not improve from 17.04369
196/196 - 32s - loss: 16.9419 - MinusLogProbMetric: 16.9419 - val_loss: 17.7830 - val_MinusLogProbMetric: 17.7830 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 154/1000
2023-09-27 01:48:08.212 
Epoch 154/1000 
	 loss: 16.9650, MinusLogProbMetric: 16.9650, val_loss: 17.2707, val_MinusLogProbMetric: 17.2707

Epoch 154: val_loss did not improve from 17.04369
196/196 - 32s - loss: 16.9650 - MinusLogProbMetric: 16.9650 - val_loss: 17.2707 - val_MinusLogProbMetric: 17.2707 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 155/1000
2023-09-27 01:48:40.116 
Epoch 155/1000 
	 loss: 16.9191, MinusLogProbMetric: 16.9191, val_loss: 17.2901, val_MinusLogProbMetric: 17.2901

Epoch 155: val_loss did not improve from 17.04369
196/196 - 32s - loss: 16.9191 - MinusLogProbMetric: 16.9191 - val_loss: 17.2901 - val_MinusLogProbMetric: 17.2901 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 156/1000
2023-09-27 01:49:11.839 
Epoch 156/1000 
	 loss: 16.9559, MinusLogProbMetric: 16.9559, val_loss: 17.1906, val_MinusLogProbMetric: 17.1906

Epoch 156: val_loss did not improve from 17.04369
196/196 - 32s - loss: 16.9559 - MinusLogProbMetric: 16.9559 - val_loss: 17.1906 - val_MinusLogProbMetric: 17.1906 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 157/1000
2023-09-27 01:49:43.875 
Epoch 157/1000 
	 loss: 16.9527, MinusLogProbMetric: 16.9527, val_loss: 17.3515, val_MinusLogProbMetric: 17.3515

Epoch 157: val_loss did not improve from 17.04369
196/196 - 32s - loss: 16.9527 - MinusLogProbMetric: 16.9527 - val_loss: 17.3515 - val_MinusLogProbMetric: 17.3515 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 158/1000
2023-09-27 01:50:15.795 
Epoch 158/1000 
	 loss: 16.9465, MinusLogProbMetric: 16.9465, val_loss: 17.1147, val_MinusLogProbMetric: 17.1147

Epoch 158: val_loss did not improve from 17.04369
196/196 - 32s - loss: 16.9465 - MinusLogProbMetric: 16.9465 - val_loss: 17.1147 - val_MinusLogProbMetric: 17.1147 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 159/1000
2023-09-27 01:50:47.459 
Epoch 159/1000 
	 loss: 16.9711, MinusLogProbMetric: 16.9711, val_loss: 17.1410, val_MinusLogProbMetric: 17.1410

Epoch 159: val_loss did not improve from 17.04369
196/196 - 32s - loss: 16.9711 - MinusLogProbMetric: 16.9711 - val_loss: 17.1410 - val_MinusLogProbMetric: 17.1410 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 160/1000
2023-09-27 01:51:19.407 
Epoch 160/1000 
	 loss: 16.9576, MinusLogProbMetric: 16.9576, val_loss: 17.0500, val_MinusLogProbMetric: 17.0500

Epoch 160: val_loss did not improve from 17.04369
196/196 - 32s - loss: 16.9576 - MinusLogProbMetric: 16.9576 - val_loss: 17.0500 - val_MinusLogProbMetric: 17.0500 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 161/1000
2023-09-27 01:51:51.443 
Epoch 161/1000 
	 loss: 16.9125, MinusLogProbMetric: 16.9125, val_loss: 17.0414, val_MinusLogProbMetric: 17.0414

Epoch 161: val_loss improved from 17.04369 to 17.04139, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 16.9125 - MinusLogProbMetric: 16.9125 - val_loss: 17.0414 - val_MinusLogProbMetric: 17.0414 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 162/1000
2023-09-27 01:52:23.981 
Epoch 162/1000 
	 loss: 16.9145, MinusLogProbMetric: 16.9145, val_loss: 17.1296, val_MinusLogProbMetric: 17.1296

Epoch 162: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.9145 - MinusLogProbMetric: 16.9145 - val_loss: 17.1296 - val_MinusLogProbMetric: 17.1296 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 163/1000
2023-09-27 01:52:55.928 
Epoch 163/1000 
	 loss: 16.9464, MinusLogProbMetric: 16.9464, val_loss: 17.4702, val_MinusLogProbMetric: 17.4702

Epoch 163: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.9464 - MinusLogProbMetric: 16.9464 - val_loss: 17.4702 - val_MinusLogProbMetric: 17.4702 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 164/1000
2023-09-27 01:53:27.931 
Epoch 164/1000 
	 loss: 16.9280, MinusLogProbMetric: 16.9280, val_loss: 17.6224, val_MinusLogProbMetric: 17.6224

Epoch 164: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.9280 - MinusLogProbMetric: 16.9280 - val_loss: 17.6224 - val_MinusLogProbMetric: 17.6224 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 165/1000
2023-09-27 01:53:59.948 
Epoch 165/1000 
	 loss: 16.9304, MinusLogProbMetric: 16.9304, val_loss: 17.1812, val_MinusLogProbMetric: 17.1812

Epoch 165: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.9304 - MinusLogProbMetric: 16.9304 - val_loss: 17.1812 - val_MinusLogProbMetric: 17.1812 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 166/1000
2023-09-27 01:54:31.841 
Epoch 166/1000 
	 loss: 16.9075, MinusLogProbMetric: 16.9075, val_loss: 17.0627, val_MinusLogProbMetric: 17.0627

Epoch 166: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.9075 - MinusLogProbMetric: 16.9075 - val_loss: 17.0627 - val_MinusLogProbMetric: 17.0627 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 167/1000
2023-09-27 01:55:03.667 
Epoch 167/1000 
	 loss: 16.9759, MinusLogProbMetric: 16.9759, val_loss: 17.0693, val_MinusLogProbMetric: 17.0693

Epoch 167: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.9759 - MinusLogProbMetric: 16.9759 - val_loss: 17.0693 - val_MinusLogProbMetric: 17.0693 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 168/1000
2023-09-27 01:55:35.342 
Epoch 168/1000 
	 loss: 16.8583, MinusLogProbMetric: 16.8583, val_loss: 17.2595, val_MinusLogProbMetric: 17.2595

Epoch 168: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.8583 - MinusLogProbMetric: 16.8583 - val_loss: 17.2595 - val_MinusLogProbMetric: 17.2595 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 169/1000
2023-09-27 01:56:07.232 
Epoch 169/1000 
	 loss: 16.9048, MinusLogProbMetric: 16.9048, val_loss: 17.0585, val_MinusLogProbMetric: 17.0585

Epoch 169: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.9048 - MinusLogProbMetric: 16.9048 - val_loss: 17.0585 - val_MinusLogProbMetric: 17.0585 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 170/1000
2023-09-27 01:56:38.933 
Epoch 170/1000 
	 loss: 16.9276, MinusLogProbMetric: 16.9276, val_loss: 17.1814, val_MinusLogProbMetric: 17.1814

Epoch 170: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.9276 - MinusLogProbMetric: 16.9276 - val_loss: 17.1814 - val_MinusLogProbMetric: 17.1814 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 171/1000
2023-09-27 01:57:10.909 
Epoch 171/1000 
	 loss: 16.9089, MinusLogProbMetric: 16.9089, val_loss: 17.1694, val_MinusLogProbMetric: 17.1694

Epoch 171: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.9089 - MinusLogProbMetric: 16.9089 - val_loss: 17.1694 - val_MinusLogProbMetric: 17.1694 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 172/1000
2023-09-27 01:57:42.597 
Epoch 172/1000 
	 loss: 16.9287, MinusLogProbMetric: 16.9287, val_loss: 18.0506, val_MinusLogProbMetric: 18.0506

Epoch 172: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.9287 - MinusLogProbMetric: 16.9287 - val_loss: 18.0506 - val_MinusLogProbMetric: 18.0506 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 173/1000
2023-09-27 01:58:14.248 
Epoch 173/1000 
	 loss: 16.9011, MinusLogProbMetric: 16.9011, val_loss: 17.2315, val_MinusLogProbMetric: 17.2315

Epoch 173: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.9011 - MinusLogProbMetric: 16.9011 - val_loss: 17.2315 - val_MinusLogProbMetric: 17.2315 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 174/1000
2023-09-27 01:58:46.213 
Epoch 174/1000 
	 loss: 16.8606, MinusLogProbMetric: 16.8606, val_loss: 17.0697, val_MinusLogProbMetric: 17.0697

Epoch 174: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.8606 - MinusLogProbMetric: 16.8606 - val_loss: 17.0697 - val_MinusLogProbMetric: 17.0697 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 175/1000
2023-09-27 01:59:18.213 
Epoch 175/1000 
	 loss: 16.9219, MinusLogProbMetric: 16.9219, val_loss: 17.5186, val_MinusLogProbMetric: 17.5186

Epoch 175: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.9219 - MinusLogProbMetric: 16.9219 - val_loss: 17.5186 - val_MinusLogProbMetric: 17.5186 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 176/1000
2023-09-27 01:59:49.977 
Epoch 176/1000 
	 loss: 16.8913, MinusLogProbMetric: 16.8913, val_loss: 17.3507, val_MinusLogProbMetric: 17.3507

Epoch 176: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.8913 - MinusLogProbMetric: 16.8913 - val_loss: 17.3507 - val_MinusLogProbMetric: 17.3507 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 177/1000
2023-09-27 02:00:21.821 
Epoch 177/1000 
	 loss: 16.9161, MinusLogProbMetric: 16.9161, val_loss: 17.1374, val_MinusLogProbMetric: 17.1374

Epoch 177: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.9161 - MinusLogProbMetric: 16.9161 - val_loss: 17.1374 - val_MinusLogProbMetric: 17.1374 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 178/1000
2023-09-27 02:00:53.585 
Epoch 178/1000 
	 loss: 16.9222, MinusLogProbMetric: 16.9222, val_loss: 17.1453, val_MinusLogProbMetric: 17.1453

Epoch 178: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.9222 - MinusLogProbMetric: 16.9222 - val_loss: 17.1453 - val_MinusLogProbMetric: 17.1453 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 179/1000
2023-09-27 02:01:25.599 
Epoch 179/1000 
	 loss: 16.8930, MinusLogProbMetric: 16.8930, val_loss: 17.0986, val_MinusLogProbMetric: 17.0986

Epoch 179: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.8930 - MinusLogProbMetric: 16.8930 - val_loss: 17.0986 - val_MinusLogProbMetric: 17.0986 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 180/1000
2023-09-27 02:01:57.231 
Epoch 180/1000 
	 loss: 16.8799, MinusLogProbMetric: 16.8799, val_loss: 17.1811, val_MinusLogProbMetric: 17.1811

Epoch 180: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.8799 - MinusLogProbMetric: 16.8799 - val_loss: 17.1811 - val_MinusLogProbMetric: 17.1811 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 181/1000
2023-09-27 02:02:29.134 
Epoch 181/1000 
	 loss: 16.8938, MinusLogProbMetric: 16.8938, val_loss: 17.3924, val_MinusLogProbMetric: 17.3924

Epoch 181: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.8938 - MinusLogProbMetric: 16.8938 - val_loss: 17.3924 - val_MinusLogProbMetric: 17.3924 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 182/1000
2023-09-27 02:03:00.847 
Epoch 182/1000 
	 loss: 16.9129, MinusLogProbMetric: 16.9129, val_loss: 17.1344, val_MinusLogProbMetric: 17.1344

Epoch 182: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.9129 - MinusLogProbMetric: 16.9129 - val_loss: 17.1344 - val_MinusLogProbMetric: 17.1344 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 183/1000
2023-09-27 02:03:32.710 
Epoch 183/1000 
	 loss: 16.8546, MinusLogProbMetric: 16.8546, val_loss: 17.3353, val_MinusLogProbMetric: 17.3353

Epoch 183: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.8546 - MinusLogProbMetric: 16.8546 - val_loss: 17.3353 - val_MinusLogProbMetric: 17.3353 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 184/1000
2023-09-27 02:04:04.507 
Epoch 184/1000 
	 loss: 16.8524, MinusLogProbMetric: 16.8524, val_loss: 17.1763, val_MinusLogProbMetric: 17.1763

Epoch 184: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.8524 - MinusLogProbMetric: 16.8524 - val_loss: 17.1763 - val_MinusLogProbMetric: 17.1763 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 185/1000
2023-09-27 02:04:36.245 
Epoch 185/1000 
	 loss: 16.8432, MinusLogProbMetric: 16.8432, val_loss: 17.0961, val_MinusLogProbMetric: 17.0961

Epoch 185: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.8432 - MinusLogProbMetric: 16.8432 - val_loss: 17.0961 - val_MinusLogProbMetric: 17.0961 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 186/1000
2023-09-27 02:05:07.952 
Epoch 186/1000 
	 loss: 16.8660, MinusLogProbMetric: 16.8660, val_loss: 17.3726, val_MinusLogProbMetric: 17.3726

Epoch 186: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.8660 - MinusLogProbMetric: 16.8660 - val_loss: 17.3726 - val_MinusLogProbMetric: 17.3726 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 187/1000
2023-09-27 02:05:39.982 
Epoch 187/1000 
	 loss: 16.8375, MinusLogProbMetric: 16.8375, val_loss: 17.0547, val_MinusLogProbMetric: 17.0547

Epoch 187: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.8375 - MinusLogProbMetric: 16.8375 - val_loss: 17.0547 - val_MinusLogProbMetric: 17.0547 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 188/1000
2023-09-27 02:06:11.859 
Epoch 188/1000 
	 loss: 16.8568, MinusLogProbMetric: 16.8568, val_loss: 17.1647, val_MinusLogProbMetric: 17.1647

Epoch 188: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.8568 - MinusLogProbMetric: 16.8568 - val_loss: 17.1647 - val_MinusLogProbMetric: 17.1647 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 189/1000
2023-09-27 02:06:43.781 
Epoch 189/1000 
	 loss: 16.8376, MinusLogProbMetric: 16.8376, val_loss: 17.0709, val_MinusLogProbMetric: 17.0709

Epoch 189: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.8376 - MinusLogProbMetric: 16.8376 - val_loss: 17.0709 - val_MinusLogProbMetric: 17.0709 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 190/1000
2023-09-27 02:07:15.452 
Epoch 190/1000 
	 loss: 16.8524, MinusLogProbMetric: 16.8524, val_loss: 17.1487, val_MinusLogProbMetric: 17.1487

Epoch 190: val_loss did not improve from 17.04139
196/196 - 32s - loss: 16.8524 - MinusLogProbMetric: 16.8524 - val_loss: 17.1487 - val_MinusLogProbMetric: 17.1487 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 191/1000
2023-09-27 02:07:47.184 
Epoch 191/1000 
	 loss: 16.8322, MinusLogProbMetric: 16.8322, val_loss: 17.0307, val_MinusLogProbMetric: 17.0307

Epoch 191: val_loss improved from 17.04139 to 17.03068, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 32s - loss: 16.8322 - MinusLogProbMetric: 16.8322 - val_loss: 17.0307 - val_MinusLogProbMetric: 17.0307 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 192/1000
2023-09-27 02:08:20.076 
Epoch 192/1000 
	 loss: 16.8430, MinusLogProbMetric: 16.8430, val_loss: 17.1003, val_MinusLogProbMetric: 17.1003

Epoch 192: val_loss did not improve from 17.03068
196/196 - 32s - loss: 16.8430 - MinusLogProbMetric: 16.8430 - val_loss: 17.1003 - val_MinusLogProbMetric: 17.1003 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 193/1000
2023-09-27 02:08:51.901 
Epoch 193/1000 
	 loss: 16.8163, MinusLogProbMetric: 16.8163, val_loss: 17.1692, val_MinusLogProbMetric: 17.1692

Epoch 193: val_loss did not improve from 17.03068
196/196 - 32s - loss: 16.8163 - MinusLogProbMetric: 16.8163 - val_loss: 17.1692 - val_MinusLogProbMetric: 17.1692 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 194/1000
2023-09-27 02:09:23.560 
Epoch 194/1000 
	 loss: 16.8328, MinusLogProbMetric: 16.8328, val_loss: 17.1944, val_MinusLogProbMetric: 17.1944

Epoch 194: val_loss did not improve from 17.03068
196/196 - 32s - loss: 16.8328 - MinusLogProbMetric: 16.8328 - val_loss: 17.1944 - val_MinusLogProbMetric: 17.1944 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 195/1000
2023-09-27 02:09:55.691 
Epoch 195/1000 
	 loss: 16.8246, MinusLogProbMetric: 16.8246, val_loss: 17.1509, val_MinusLogProbMetric: 17.1509

Epoch 195: val_loss did not improve from 17.03068
196/196 - 32s - loss: 16.8246 - MinusLogProbMetric: 16.8246 - val_loss: 17.1509 - val_MinusLogProbMetric: 17.1509 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 196/1000
2023-09-27 02:10:27.538 
Epoch 196/1000 
	 loss: 16.8563, MinusLogProbMetric: 16.8563, val_loss: 17.0287, val_MinusLogProbMetric: 17.0287

Epoch 196: val_loss improved from 17.03068 to 17.02869, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 32s - loss: 16.8563 - MinusLogProbMetric: 16.8563 - val_loss: 17.0287 - val_MinusLogProbMetric: 17.0287 - lr: 0.0010 - 32s/epoch - 166ms/step
Epoch 197/1000
2023-09-27 02:11:00.039 
Epoch 197/1000 
	 loss: 16.8044, MinusLogProbMetric: 16.8044, val_loss: 17.0533, val_MinusLogProbMetric: 17.0533

Epoch 197: val_loss did not improve from 17.02869
196/196 - 32s - loss: 16.8044 - MinusLogProbMetric: 16.8044 - val_loss: 17.0533 - val_MinusLogProbMetric: 17.0533 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 198/1000
2023-09-27 02:11:31.387 
Epoch 198/1000 
	 loss: 16.8361, MinusLogProbMetric: 16.8361, val_loss: 17.3546, val_MinusLogProbMetric: 17.3546

Epoch 198: val_loss did not improve from 17.02869
196/196 - 31s - loss: 16.8361 - MinusLogProbMetric: 16.8361 - val_loss: 17.3546 - val_MinusLogProbMetric: 17.3546 - lr: 0.0010 - 31s/epoch - 160ms/step
Epoch 199/1000
2023-09-27 02:12:03.152 
Epoch 199/1000 
	 loss: 16.8610, MinusLogProbMetric: 16.8610, val_loss: 17.2855, val_MinusLogProbMetric: 17.2855

Epoch 199: val_loss did not improve from 17.02869
196/196 - 32s - loss: 16.8610 - MinusLogProbMetric: 16.8610 - val_loss: 17.2855 - val_MinusLogProbMetric: 17.2855 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 200/1000
2023-09-27 02:12:35.088 
Epoch 200/1000 
	 loss: 16.8351, MinusLogProbMetric: 16.8351, val_loss: 17.0981, val_MinusLogProbMetric: 17.0981

Epoch 200: val_loss did not improve from 17.02869
196/196 - 32s - loss: 16.8351 - MinusLogProbMetric: 16.8351 - val_loss: 17.0981 - val_MinusLogProbMetric: 17.0981 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 201/1000
2023-09-27 02:13:06.928 
Epoch 201/1000 
	 loss: 16.8425, MinusLogProbMetric: 16.8425, val_loss: 17.2915, val_MinusLogProbMetric: 17.2915

Epoch 201: val_loss did not improve from 17.02869
196/196 - 32s - loss: 16.8425 - MinusLogProbMetric: 16.8425 - val_loss: 17.2915 - val_MinusLogProbMetric: 17.2915 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 202/1000
2023-09-27 02:13:38.800 
Epoch 202/1000 
	 loss: 16.8046, MinusLogProbMetric: 16.8046, val_loss: 17.2688, val_MinusLogProbMetric: 17.2688

Epoch 202: val_loss did not improve from 17.02869
196/196 - 32s - loss: 16.8046 - MinusLogProbMetric: 16.8046 - val_loss: 17.2688 - val_MinusLogProbMetric: 17.2688 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 203/1000
2023-09-27 02:14:10.687 
Epoch 203/1000 
	 loss: 16.8067, MinusLogProbMetric: 16.8067, val_loss: 17.1588, val_MinusLogProbMetric: 17.1588

Epoch 203: val_loss did not improve from 17.02869
196/196 - 32s - loss: 16.8067 - MinusLogProbMetric: 16.8067 - val_loss: 17.1588 - val_MinusLogProbMetric: 17.1588 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 204/1000
2023-09-27 02:14:42.681 
Epoch 204/1000 
	 loss: 16.8391, MinusLogProbMetric: 16.8391, val_loss: 17.2077, val_MinusLogProbMetric: 17.2077

Epoch 204: val_loss did not improve from 17.02869
196/196 - 32s - loss: 16.8391 - MinusLogProbMetric: 16.8391 - val_loss: 17.2077 - val_MinusLogProbMetric: 17.2077 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 205/1000
2023-09-27 02:15:14.311 
Epoch 205/1000 
	 loss: 16.8028, MinusLogProbMetric: 16.8028, val_loss: 17.1315, val_MinusLogProbMetric: 17.1315

Epoch 205: val_loss did not improve from 17.02869
196/196 - 32s - loss: 16.8028 - MinusLogProbMetric: 16.8028 - val_loss: 17.1315 - val_MinusLogProbMetric: 17.1315 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 206/1000
2023-09-27 02:15:46.020 
Epoch 206/1000 
	 loss: 16.8069, MinusLogProbMetric: 16.8069, val_loss: 16.9711, val_MinusLogProbMetric: 16.9711

Epoch 206: val_loss improved from 17.02869 to 16.97110, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 32s - loss: 16.8069 - MinusLogProbMetric: 16.8069 - val_loss: 16.9711 - val_MinusLogProbMetric: 16.9711 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 207/1000
2023-09-27 02:16:18.428 
Epoch 207/1000 
	 loss: 16.7839, MinusLogProbMetric: 16.7839, val_loss: 17.0563, val_MinusLogProbMetric: 17.0563

Epoch 207: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7839 - MinusLogProbMetric: 16.7839 - val_loss: 17.0563 - val_MinusLogProbMetric: 17.0563 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 208/1000
2023-09-27 02:16:50.097 
Epoch 208/1000 
	 loss: 16.8372, MinusLogProbMetric: 16.8372, val_loss: 17.1520, val_MinusLogProbMetric: 17.1520

Epoch 208: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.8372 - MinusLogProbMetric: 16.8372 - val_loss: 17.1520 - val_MinusLogProbMetric: 17.1520 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 209/1000
2023-09-27 02:17:22.122 
Epoch 209/1000 
	 loss: 16.7959, MinusLogProbMetric: 16.7959, val_loss: 17.0929, val_MinusLogProbMetric: 17.0929

Epoch 209: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7959 - MinusLogProbMetric: 16.7959 - val_loss: 17.0929 - val_MinusLogProbMetric: 17.0929 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 210/1000
2023-09-27 02:17:53.742 
Epoch 210/1000 
	 loss: 16.8162, MinusLogProbMetric: 16.8162, val_loss: 17.2125, val_MinusLogProbMetric: 17.2125

Epoch 210: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.8162 - MinusLogProbMetric: 16.8162 - val_loss: 17.2125 - val_MinusLogProbMetric: 17.2125 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 211/1000
2023-09-27 02:18:25.904 
Epoch 211/1000 
	 loss: 16.8063, MinusLogProbMetric: 16.8063, val_loss: 17.0191, val_MinusLogProbMetric: 17.0191

Epoch 211: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.8063 - MinusLogProbMetric: 16.8063 - val_loss: 17.0191 - val_MinusLogProbMetric: 17.0191 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 212/1000
2023-09-27 02:18:57.786 
Epoch 212/1000 
	 loss: 16.7729, MinusLogProbMetric: 16.7729, val_loss: 16.9887, val_MinusLogProbMetric: 16.9887

Epoch 212: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7729 - MinusLogProbMetric: 16.7729 - val_loss: 16.9887 - val_MinusLogProbMetric: 16.9887 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 213/1000
2023-09-27 02:19:29.515 
Epoch 213/1000 
	 loss: 16.7687, MinusLogProbMetric: 16.7687, val_loss: 17.1454, val_MinusLogProbMetric: 17.1454

Epoch 213: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7687 - MinusLogProbMetric: 16.7687 - val_loss: 17.1454 - val_MinusLogProbMetric: 17.1454 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 214/1000
2023-09-27 02:20:01.355 
Epoch 214/1000 
	 loss: 16.7819, MinusLogProbMetric: 16.7819, val_loss: 17.0129, val_MinusLogProbMetric: 17.0129

Epoch 214: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7819 - MinusLogProbMetric: 16.7819 - val_loss: 17.0129 - val_MinusLogProbMetric: 17.0129 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 215/1000
2023-09-27 02:20:33.186 
Epoch 215/1000 
	 loss: 16.7843, MinusLogProbMetric: 16.7843, val_loss: 17.5492, val_MinusLogProbMetric: 17.5492

Epoch 215: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7843 - MinusLogProbMetric: 16.7843 - val_loss: 17.5492 - val_MinusLogProbMetric: 17.5492 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 216/1000
2023-09-27 02:21:04.979 
Epoch 216/1000 
	 loss: 16.7905, MinusLogProbMetric: 16.7905, val_loss: 17.0524, val_MinusLogProbMetric: 17.0524

Epoch 216: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7905 - MinusLogProbMetric: 16.7905 - val_loss: 17.0524 - val_MinusLogProbMetric: 17.0524 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 217/1000
2023-09-27 02:21:36.657 
Epoch 217/1000 
	 loss: 16.7860, MinusLogProbMetric: 16.7860, val_loss: 17.1552, val_MinusLogProbMetric: 17.1552

Epoch 217: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7860 - MinusLogProbMetric: 16.7860 - val_loss: 17.1552 - val_MinusLogProbMetric: 17.1552 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 218/1000
2023-09-27 02:22:08.614 
Epoch 218/1000 
	 loss: 16.8117, MinusLogProbMetric: 16.8117, val_loss: 17.5720, val_MinusLogProbMetric: 17.5720

Epoch 218: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.8117 - MinusLogProbMetric: 16.8117 - val_loss: 17.5720 - val_MinusLogProbMetric: 17.5720 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 219/1000
2023-09-27 02:22:40.351 
Epoch 219/1000 
	 loss: 16.7954, MinusLogProbMetric: 16.7954, val_loss: 17.0747, val_MinusLogProbMetric: 17.0747

Epoch 219: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7954 - MinusLogProbMetric: 16.7954 - val_loss: 17.0747 - val_MinusLogProbMetric: 17.0747 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 220/1000
2023-09-27 02:23:12.263 
Epoch 220/1000 
	 loss: 16.7683, MinusLogProbMetric: 16.7683, val_loss: 17.0876, val_MinusLogProbMetric: 17.0876

Epoch 220: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7683 - MinusLogProbMetric: 16.7683 - val_loss: 17.0876 - val_MinusLogProbMetric: 17.0876 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 221/1000
2023-09-27 02:23:44.061 
Epoch 221/1000 
	 loss: 16.7635, MinusLogProbMetric: 16.7635, val_loss: 17.0880, val_MinusLogProbMetric: 17.0880

Epoch 221: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7635 - MinusLogProbMetric: 16.7635 - val_loss: 17.0880 - val_MinusLogProbMetric: 17.0880 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 222/1000
2023-09-27 02:24:15.848 
Epoch 222/1000 
	 loss: 16.8014, MinusLogProbMetric: 16.8014, val_loss: 17.1570, val_MinusLogProbMetric: 17.1570

Epoch 222: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.8014 - MinusLogProbMetric: 16.8014 - val_loss: 17.1570 - val_MinusLogProbMetric: 17.1570 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 223/1000
2023-09-27 02:24:47.692 
Epoch 223/1000 
	 loss: 16.7548, MinusLogProbMetric: 16.7548, val_loss: 17.1291, val_MinusLogProbMetric: 17.1291

Epoch 223: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7548 - MinusLogProbMetric: 16.7548 - val_loss: 17.1291 - val_MinusLogProbMetric: 17.1291 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 224/1000
2023-09-27 02:25:19.492 
Epoch 224/1000 
	 loss: 16.7658, MinusLogProbMetric: 16.7658, val_loss: 17.1389, val_MinusLogProbMetric: 17.1389

Epoch 224: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7658 - MinusLogProbMetric: 16.7658 - val_loss: 17.1389 - val_MinusLogProbMetric: 17.1389 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 225/1000
2023-09-27 02:25:51.496 
Epoch 225/1000 
	 loss: 16.7881, MinusLogProbMetric: 16.7881, val_loss: 17.1357, val_MinusLogProbMetric: 17.1357

Epoch 225: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7881 - MinusLogProbMetric: 16.7881 - val_loss: 17.1357 - val_MinusLogProbMetric: 17.1357 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 226/1000
2023-09-27 02:26:23.575 
Epoch 226/1000 
	 loss: 16.7349, MinusLogProbMetric: 16.7349, val_loss: 17.3217, val_MinusLogProbMetric: 17.3217

Epoch 226: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7349 - MinusLogProbMetric: 16.7349 - val_loss: 17.3217 - val_MinusLogProbMetric: 17.3217 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 227/1000
2023-09-27 02:26:55.371 
Epoch 227/1000 
	 loss: 16.7777, MinusLogProbMetric: 16.7777, val_loss: 17.0696, val_MinusLogProbMetric: 17.0696

Epoch 227: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7777 - MinusLogProbMetric: 16.7777 - val_loss: 17.0696 - val_MinusLogProbMetric: 17.0696 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 228/1000
2023-09-27 02:27:27.274 
Epoch 228/1000 
	 loss: 16.7328, MinusLogProbMetric: 16.7328, val_loss: 17.4199, val_MinusLogProbMetric: 17.4199

Epoch 228: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7328 - MinusLogProbMetric: 16.7328 - val_loss: 17.4199 - val_MinusLogProbMetric: 17.4199 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 229/1000
2023-09-27 02:27:58.748 
Epoch 229/1000 
	 loss: 16.7737, MinusLogProbMetric: 16.7737, val_loss: 17.2328, val_MinusLogProbMetric: 17.2328

Epoch 229: val_loss did not improve from 16.97110
196/196 - 31s - loss: 16.7737 - MinusLogProbMetric: 16.7737 - val_loss: 17.2328 - val_MinusLogProbMetric: 17.2328 - lr: 0.0010 - 31s/epoch - 161ms/step
Epoch 230/1000
2023-09-27 02:28:30.694 
Epoch 230/1000 
	 loss: 16.7544, MinusLogProbMetric: 16.7544, val_loss: 17.0230, val_MinusLogProbMetric: 17.0230

Epoch 230: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7544 - MinusLogProbMetric: 16.7544 - val_loss: 17.0230 - val_MinusLogProbMetric: 17.0230 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 231/1000
2023-09-27 02:29:02.643 
Epoch 231/1000 
	 loss: 16.7270, MinusLogProbMetric: 16.7270, val_loss: 17.1201, val_MinusLogProbMetric: 17.1201

Epoch 231: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7270 - MinusLogProbMetric: 16.7270 - val_loss: 17.1201 - val_MinusLogProbMetric: 17.1201 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 232/1000
2023-09-27 02:29:34.480 
Epoch 232/1000 
	 loss: 16.7663, MinusLogProbMetric: 16.7663, val_loss: 17.1197, val_MinusLogProbMetric: 17.1197

Epoch 232: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7663 - MinusLogProbMetric: 16.7663 - val_loss: 17.1197 - val_MinusLogProbMetric: 17.1197 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 233/1000
2023-09-27 02:30:05.961 
Epoch 233/1000 
	 loss: 16.7174, MinusLogProbMetric: 16.7174, val_loss: 17.0997, val_MinusLogProbMetric: 17.0997

Epoch 233: val_loss did not improve from 16.97110
196/196 - 31s - loss: 16.7174 - MinusLogProbMetric: 16.7174 - val_loss: 17.0997 - val_MinusLogProbMetric: 17.0997 - lr: 0.0010 - 31s/epoch - 161ms/step
Epoch 234/1000
2023-09-27 02:30:37.728 
Epoch 234/1000 
	 loss: 16.7358, MinusLogProbMetric: 16.7358, val_loss: 17.1272, val_MinusLogProbMetric: 17.1272

Epoch 234: val_loss did not improve from 16.97110
196/196 - 32s - loss: 16.7358 - MinusLogProbMetric: 16.7358 - val_loss: 17.1272 - val_MinusLogProbMetric: 17.1272 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 235/1000
2023-09-27 02:31:08.473 
Epoch 235/1000 
	 loss: 16.7611, MinusLogProbMetric: 16.7611, val_loss: 16.9402, val_MinusLogProbMetric: 16.9402

Epoch 235: val_loss improved from 16.97110 to 16.94023, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 31s - loss: 16.7611 - MinusLogProbMetric: 16.7611 - val_loss: 16.9402 - val_MinusLogProbMetric: 16.9402 - lr: 0.0010 - 31s/epoch - 160ms/step
Epoch 236/1000
2023-09-27 02:31:39.983 
Epoch 236/1000 
	 loss: 16.7513, MinusLogProbMetric: 16.7513, val_loss: 16.9819, val_MinusLogProbMetric: 16.9819

Epoch 236: val_loss did not improve from 16.94023
196/196 - 31s - loss: 16.7513 - MinusLogProbMetric: 16.7513 - val_loss: 16.9819 - val_MinusLogProbMetric: 16.9819 - lr: 0.0010 - 31s/epoch - 158ms/step
Epoch 237/1000
2023-09-27 02:32:10.359 
Epoch 237/1000 
	 loss: 16.7278, MinusLogProbMetric: 16.7278, val_loss: 17.0183, val_MinusLogProbMetric: 17.0183

Epoch 237: val_loss did not improve from 16.94023
196/196 - 30s - loss: 16.7278 - MinusLogProbMetric: 16.7278 - val_loss: 17.0183 - val_MinusLogProbMetric: 17.0183 - lr: 0.0010 - 30s/epoch - 155ms/step
Epoch 238/1000
2023-09-27 02:32:38.619 
Epoch 238/1000 
	 loss: 16.7234, MinusLogProbMetric: 16.7234, val_loss: 17.0914, val_MinusLogProbMetric: 17.0914

Epoch 238: val_loss did not improve from 16.94023
196/196 - 28s - loss: 16.7234 - MinusLogProbMetric: 16.7234 - val_loss: 17.0914 - val_MinusLogProbMetric: 17.0914 - lr: 0.0010 - 28s/epoch - 144ms/step
Epoch 239/1000
2023-09-27 02:33:09.390 
Epoch 239/1000 
	 loss: 16.7299, MinusLogProbMetric: 16.7299, val_loss: 17.1480, val_MinusLogProbMetric: 17.1480

Epoch 239: val_loss did not improve from 16.94023
196/196 - 31s - loss: 16.7299 - MinusLogProbMetric: 16.7299 - val_loss: 17.1480 - val_MinusLogProbMetric: 17.1480 - lr: 0.0010 - 31s/epoch - 157ms/step
Epoch 240/1000
2023-09-27 02:33:41.241 
Epoch 240/1000 
	 loss: 16.7522, MinusLogProbMetric: 16.7522, val_loss: 17.1517, val_MinusLogProbMetric: 17.1517

Epoch 240: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.7522 - MinusLogProbMetric: 16.7522 - val_loss: 17.1517 - val_MinusLogProbMetric: 17.1517 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 241/1000
2023-09-27 02:34:12.534 
Epoch 241/1000 
	 loss: 16.7176, MinusLogProbMetric: 16.7176, val_loss: 16.9764, val_MinusLogProbMetric: 16.9764

Epoch 241: val_loss did not improve from 16.94023
196/196 - 31s - loss: 16.7176 - MinusLogProbMetric: 16.7176 - val_loss: 16.9764 - val_MinusLogProbMetric: 16.9764 - lr: 0.0010 - 31s/epoch - 160ms/step
Epoch 242/1000
2023-09-27 02:34:44.323 
Epoch 242/1000 
	 loss: 16.7227, MinusLogProbMetric: 16.7227, val_loss: 16.9985, val_MinusLogProbMetric: 16.9985

Epoch 242: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.7227 - MinusLogProbMetric: 16.7227 - val_loss: 16.9985 - val_MinusLogProbMetric: 16.9985 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 243/1000
2023-09-27 02:35:15.914 
Epoch 243/1000 
	 loss: 16.7213, MinusLogProbMetric: 16.7213, val_loss: 17.0827, val_MinusLogProbMetric: 17.0827

Epoch 243: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.7213 - MinusLogProbMetric: 16.7213 - val_loss: 17.0827 - val_MinusLogProbMetric: 17.0827 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 244/1000
2023-09-27 02:35:47.526 
Epoch 244/1000 
	 loss: 16.7299, MinusLogProbMetric: 16.7299, val_loss: 16.9921, val_MinusLogProbMetric: 16.9921

Epoch 244: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.7299 - MinusLogProbMetric: 16.7299 - val_loss: 16.9921 - val_MinusLogProbMetric: 16.9921 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 245/1000
2023-09-27 02:36:19.601 
Epoch 245/1000 
	 loss: 16.7274, MinusLogProbMetric: 16.7274, val_loss: 17.2955, val_MinusLogProbMetric: 17.2955

Epoch 245: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.7274 - MinusLogProbMetric: 16.7274 - val_loss: 17.2955 - val_MinusLogProbMetric: 17.2955 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 246/1000
2023-09-27 02:36:51.247 
Epoch 246/1000 
	 loss: 16.7348, MinusLogProbMetric: 16.7348, val_loss: 17.1979, val_MinusLogProbMetric: 17.1979

Epoch 246: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.7348 - MinusLogProbMetric: 16.7348 - val_loss: 17.1979 - val_MinusLogProbMetric: 17.1979 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 247/1000
2023-09-27 02:37:23.746 
Epoch 247/1000 
	 loss: 16.7340, MinusLogProbMetric: 16.7340, val_loss: 17.3913, val_MinusLogProbMetric: 17.3913

Epoch 247: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.7340 - MinusLogProbMetric: 16.7340 - val_loss: 17.3913 - val_MinusLogProbMetric: 17.3913 - lr: 0.0010 - 32s/epoch - 166ms/step
Epoch 248/1000
2023-09-27 02:37:55.572 
Epoch 248/1000 
	 loss: 16.7149, MinusLogProbMetric: 16.7149, val_loss: 17.0266, val_MinusLogProbMetric: 17.0266

Epoch 248: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.7149 - MinusLogProbMetric: 16.7149 - val_loss: 17.0266 - val_MinusLogProbMetric: 17.0266 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 249/1000
2023-09-27 02:38:27.526 
Epoch 249/1000 
	 loss: 16.7181, MinusLogProbMetric: 16.7181, val_loss: 17.1709, val_MinusLogProbMetric: 17.1709

Epoch 249: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.7181 - MinusLogProbMetric: 16.7181 - val_loss: 17.1709 - val_MinusLogProbMetric: 17.1709 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 250/1000
2023-09-27 02:38:59.462 
Epoch 250/1000 
	 loss: 16.7460, MinusLogProbMetric: 16.7460, val_loss: 17.0302, val_MinusLogProbMetric: 17.0302

Epoch 250: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.7460 - MinusLogProbMetric: 16.7460 - val_loss: 17.0302 - val_MinusLogProbMetric: 17.0302 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 251/1000
2023-09-27 02:39:31.330 
Epoch 251/1000 
	 loss: 16.6957, MinusLogProbMetric: 16.6957, val_loss: 17.0422, val_MinusLogProbMetric: 17.0422

Epoch 251: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.6957 - MinusLogProbMetric: 16.6957 - val_loss: 17.0422 - val_MinusLogProbMetric: 17.0422 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 252/1000
2023-09-27 02:40:03.647 
Epoch 252/1000 
	 loss: 16.7162, MinusLogProbMetric: 16.7162, val_loss: 17.2837, val_MinusLogProbMetric: 17.2837

Epoch 252: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.7162 - MinusLogProbMetric: 16.7162 - val_loss: 17.2837 - val_MinusLogProbMetric: 17.2837 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 253/1000
2023-09-27 02:40:35.537 
Epoch 253/1000 
	 loss: 16.7281, MinusLogProbMetric: 16.7281, val_loss: 17.0275, val_MinusLogProbMetric: 17.0275

Epoch 253: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.7281 - MinusLogProbMetric: 16.7281 - val_loss: 17.0275 - val_MinusLogProbMetric: 17.0275 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 254/1000
2023-09-27 02:41:07.216 
Epoch 254/1000 
	 loss: 16.7152, MinusLogProbMetric: 16.7152, val_loss: 17.0760, val_MinusLogProbMetric: 17.0760

Epoch 254: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.7152 - MinusLogProbMetric: 16.7152 - val_loss: 17.0760 - val_MinusLogProbMetric: 17.0760 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 255/1000
2023-09-27 02:41:39.231 
Epoch 255/1000 
	 loss: 16.6970, MinusLogProbMetric: 16.6970, val_loss: 17.0206, val_MinusLogProbMetric: 17.0206

Epoch 255: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.6970 - MinusLogProbMetric: 16.6970 - val_loss: 17.0206 - val_MinusLogProbMetric: 17.0206 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 256/1000
2023-09-27 02:42:10.901 
Epoch 256/1000 
	 loss: 16.6752, MinusLogProbMetric: 16.6752, val_loss: 17.3362, val_MinusLogProbMetric: 17.3362

Epoch 256: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.6752 - MinusLogProbMetric: 16.6752 - val_loss: 17.3362 - val_MinusLogProbMetric: 17.3362 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 257/1000
2023-09-27 02:42:43.216 
Epoch 257/1000 
	 loss: 16.7153, MinusLogProbMetric: 16.7153, val_loss: 17.0301, val_MinusLogProbMetric: 17.0301

Epoch 257: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.7153 - MinusLogProbMetric: 16.7153 - val_loss: 17.0301 - val_MinusLogProbMetric: 17.0301 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 258/1000
2023-09-27 02:43:14.960 
Epoch 258/1000 
	 loss: 16.7132, MinusLogProbMetric: 16.7132, val_loss: 17.1082, val_MinusLogProbMetric: 17.1082

Epoch 258: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.7132 - MinusLogProbMetric: 16.7132 - val_loss: 17.1082 - val_MinusLogProbMetric: 17.1082 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 259/1000
2023-09-27 02:43:47.082 
Epoch 259/1000 
	 loss: 16.7101, MinusLogProbMetric: 16.7101, val_loss: 17.1753, val_MinusLogProbMetric: 17.1753

Epoch 259: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.7101 - MinusLogProbMetric: 16.7101 - val_loss: 17.1753 - val_MinusLogProbMetric: 17.1753 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 260/1000
2023-09-27 02:44:19.179 
Epoch 260/1000 
	 loss: 16.7055, MinusLogProbMetric: 16.7055, val_loss: 17.0068, val_MinusLogProbMetric: 17.0068

Epoch 260: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.7055 - MinusLogProbMetric: 16.7055 - val_loss: 17.0068 - val_MinusLogProbMetric: 17.0068 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 261/1000
2023-09-27 02:44:51.111 
Epoch 261/1000 
	 loss: 16.6846, MinusLogProbMetric: 16.6846, val_loss: 17.0570, val_MinusLogProbMetric: 17.0570

Epoch 261: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.6846 - MinusLogProbMetric: 16.6846 - val_loss: 17.0570 - val_MinusLogProbMetric: 17.0570 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 262/1000
2023-09-27 02:45:23.315 
Epoch 262/1000 
	 loss: 16.7267, MinusLogProbMetric: 16.7267, val_loss: 16.9587, val_MinusLogProbMetric: 16.9587

Epoch 262: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.7267 - MinusLogProbMetric: 16.7267 - val_loss: 16.9587 - val_MinusLogProbMetric: 16.9587 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 263/1000
2023-09-27 02:45:55.380 
Epoch 263/1000 
	 loss: 16.6927, MinusLogProbMetric: 16.6927, val_loss: 17.1346, val_MinusLogProbMetric: 17.1346

Epoch 263: val_loss did not improve from 16.94023
196/196 - 32s - loss: 16.6927 - MinusLogProbMetric: 16.6927 - val_loss: 17.1346 - val_MinusLogProbMetric: 17.1346 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 264/1000
2023-09-27 02:46:27.906 
Epoch 264/1000 
	 loss: 16.7091, MinusLogProbMetric: 16.7091, val_loss: 16.9374, val_MinusLogProbMetric: 16.9374

Epoch 264: val_loss improved from 16.94023 to 16.93736, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 16.7091 - MinusLogProbMetric: 16.7091 - val_loss: 16.9374 - val_MinusLogProbMetric: 16.9374 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 265/1000
2023-09-27 02:47:00.544 
Epoch 265/1000 
	 loss: 16.6844, MinusLogProbMetric: 16.6844, val_loss: 17.0692, val_MinusLogProbMetric: 17.0692

Epoch 265: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6844 - MinusLogProbMetric: 16.6844 - val_loss: 17.0692 - val_MinusLogProbMetric: 17.0692 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 266/1000
2023-09-27 02:47:32.557 
Epoch 266/1000 
	 loss: 16.6989, MinusLogProbMetric: 16.6989, val_loss: 17.2288, val_MinusLogProbMetric: 17.2288

Epoch 266: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6989 - MinusLogProbMetric: 16.6989 - val_loss: 17.2288 - val_MinusLogProbMetric: 17.2288 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 267/1000
2023-09-27 02:48:04.597 
Epoch 267/1000 
	 loss: 16.7438, MinusLogProbMetric: 16.7438, val_loss: 17.1619, val_MinusLogProbMetric: 17.1619

Epoch 267: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.7438 - MinusLogProbMetric: 16.7438 - val_loss: 17.1619 - val_MinusLogProbMetric: 17.1619 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 268/1000
2023-09-27 02:48:35.956 
Epoch 268/1000 
	 loss: 16.6841, MinusLogProbMetric: 16.6841, val_loss: 16.9576, val_MinusLogProbMetric: 16.9576

Epoch 268: val_loss did not improve from 16.93736
196/196 - 31s - loss: 16.6841 - MinusLogProbMetric: 16.6841 - val_loss: 16.9576 - val_MinusLogProbMetric: 16.9576 - lr: 0.0010 - 31s/epoch - 160ms/step
Epoch 269/1000
2023-09-27 02:49:07.964 
Epoch 269/1000 
	 loss: 16.6720, MinusLogProbMetric: 16.6720, val_loss: 17.1825, val_MinusLogProbMetric: 17.1825

Epoch 269: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6720 - MinusLogProbMetric: 16.6720 - val_loss: 17.1825 - val_MinusLogProbMetric: 17.1825 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 270/1000
2023-09-27 02:49:39.696 
Epoch 270/1000 
	 loss: 16.6690, MinusLogProbMetric: 16.6690, val_loss: 17.1329, val_MinusLogProbMetric: 17.1329

Epoch 270: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6690 - MinusLogProbMetric: 16.6690 - val_loss: 17.1329 - val_MinusLogProbMetric: 17.1329 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 271/1000
2023-09-27 02:50:11.921 
Epoch 271/1000 
	 loss: 16.6998, MinusLogProbMetric: 16.6998, val_loss: 17.0102, val_MinusLogProbMetric: 17.0102

Epoch 271: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6998 - MinusLogProbMetric: 16.6998 - val_loss: 17.0102 - val_MinusLogProbMetric: 17.0102 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 272/1000
2023-09-27 02:50:43.648 
Epoch 272/1000 
	 loss: 16.6933, MinusLogProbMetric: 16.6933, val_loss: 17.0915, val_MinusLogProbMetric: 17.0915

Epoch 272: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6933 - MinusLogProbMetric: 16.6933 - val_loss: 17.0915 - val_MinusLogProbMetric: 17.0915 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 273/1000
2023-09-27 02:51:15.362 
Epoch 273/1000 
	 loss: 16.6549, MinusLogProbMetric: 16.6549, val_loss: 17.0933, val_MinusLogProbMetric: 17.0933

Epoch 273: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6549 - MinusLogProbMetric: 16.6549 - val_loss: 17.0933 - val_MinusLogProbMetric: 17.0933 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 274/1000
2023-09-27 02:51:47.315 
Epoch 274/1000 
	 loss: 16.6709, MinusLogProbMetric: 16.6709, val_loss: 17.1543, val_MinusLogProbMetric: 17.1543

Epoch 274: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6709 - MinusLogProbMetric: 16.6709 - val_loss: 17.1543 - val_MinusLogProbMetric: 17.1543 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 275/1000
2023-09-27 02:52:19.234 
Epoch 275/1000 
	 loss: 16.7087, MinusLogProbMetric: 16.7087, val_loss: 17.1322, val_MinusLogProbMetric: 17.1322

Epoch 275: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.7087 - MinusLogProbMetric: 16.7087 - val_loss: 17.1322 - val_MinusLogProbMetric: 17.1322 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 276/1000
2023-09-27 02:52:50.917 
Epoch 276/1000 
	 loss: 16.6512, MinusLogProbMetric: 16.6512, val_loss: 17.0707, val_MinusLogProbMetric: 17.0707

Epoch 276: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6512 - MinusLogProbMetric: 16.6512 - val_loss: 17.0707 - val_MinusLogProbMetric: 17.0707 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 277/1000
2023-09-27 02:53:23.097 
Epoch 277/1000 
	 loss: 16.6528, MinusLogProbMetric: 16.6528, val_loss: 17.0584, val_MinusLogProbMetric: 17.0584

Epoch 277: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6528 - MinusLogProbMetric: 16.6528 - val_loss: 17.0584 - val_MinusLogProbMetric: 17.0584 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 278/1000
2023-09-27 02:53:54.936 
Epoch 278/1000 
	 loss: 16.7140, MinusLogProbMetric: 16.7140, val_loss: 17.0687, val_MinusLogProbMetric: 17.0687

Epoch 278: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.7140 - MinusLogProbMetric: 16.7140 - val_loss: 17.0687 - val_MinusLogProbMetric: 17.0687 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 279/1000
2023-09-27 02:54:26.949 
Epoch 279/1000 
	 loss: 16.6503, MinusLogProbMetric: 16.6503, val_loss: 16.9532, val_MinusLogProbMetric: 16.9532

Epoch 279: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6503 - MinusLogProbMetric: 16.6503 - val_loss: 16.9532 - val_MinusLogProbMetric: 16.9532 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 280/1000
2023-09-27 02:54:58.910 
Epoch 280/1000 
	 loss: 16.6551, MinusLogProbMetric: 16.6551, val_loss: 17.2841, val_MinusLogProbMetric: 17.2841

Epoch 280: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6551 - MinusLogProbMetric: 16.6551 - val_loss: 17.2841 - val_MinusLogProbMetric: 17.2841 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 281/1000
2023-09-27 02:55:30.785 
Epoch 281/1000 
	 loss: 16.6612, MinusLogProbMetric: 16.6612, val_loss: 17.0505, val_MinusLogProbMetric: 17.0505

Epoch 281: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6612 - MinusLogProbMetric: 16.6612 - val_loss: 17.0505 - val_MinusLogProbMetric: 17.0505 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 282/1000
2023-09-27 02:56:02.638 
Epoch 282/1000 
	 loss: 16.6882, MinusLogProbMetric: 16.6882, val_loss: 17.0397, val_MinusLogProbMetric: 17.0397

Epoch 282: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6882 - MinusLogProbMetric: 16.6882 - val_loss: 17.0397 - val_MinusLogProbMetric: 17.0397 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 283/1000
2023-09-27 02:56:34.755 
Epoch 283/1000 
	 loss: 16.6919, MinusLogProbMetric: 16.6919, val_loss: 17.1101, val_MinusLogProbMetric: 17.1101

Epoch 283: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6919 - MinusLogProbMetric: 16.6919 - val_loss: 17.1101 - val_MinusLogProbMetric: 17.1101 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 284/1000
2023-09-27 02:57:06.622 
Epoch 284/1000 
	 loss: 16.6458, MinusLogProbMetric: 16.6458, val_loss: 17.1660, val_MinusLogProbMetric: 17.1660

Epoch 284: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6458 - MinusLogProbMetric: 16.6458 - val_loss: 17.1660 - val_MinusLogProbMetric: 17.1660 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 285/1000
2023-09-27 02:57:38.609 
Epoch 285/1000 
	 loss: 16.6966, MinusLogProbMetric: 16.6966, val_loss: 17.2196, val_MinusLogProbMetric: 17.2196

Epoch 285: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6966 - MinusLogProbMetric: 16.6966 - val_loss: 17.2196 - val_MinusLogProbMetric: 17.2196 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 286/1000
2023-09-27 02:58:10.482 
Epoch 286/1000 
	 loss: 16.6548, MinusLogProbMetric: 16.6548, val_loss: 16.9398, val_MinusLogProbMetric: 16.9398

Epoch 286: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6548 - MinusLogProbMetric: 16.6548 - val_loss: 16.9398 - val_MinusLogProbMetric: 16.9398 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 287/1000
2023-09-27 02:58:42.034 
Epoch 287/1000 
	 loss: 16.6707, MinusLogProbMetric: 16.6707, val_loss: 17.3278, val_MinusLogProbMetric: 17.3278

Epoch 287: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6707 - MinusLogProbMetric: 16.6707 - val_loss: 17.3278 - val_MinusLogProbMetric: 17.3278 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 288/1000
2023-09-27 02:59:13.879 
Epoch 288/1000 
	 loss: 16.6419, MinusLogProbMetric: 16.6419, val_loss: 16.9703, val_MinusLogProbMetric: 16.9703

Epoch 288: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6419 - MinusLogProbMetric: 16.6419 - val_loss: 16.9703 - val_MinusLogProbMetric: 16.9703 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 289/1000
2023-09-27 02:59:45.320 
Epoch 289/1000 
	 loss: 16.6748, MinusLogProbMetric: 16.6748, val_loss: 16.9995, val_MinusLogProbMetric: 16.9995

Epoch 289: val_loss did not improve from 16.93736
196/196 - 31s - loss: 16.6748 - MinusLogProbMetric: 16.6748 - val_loss: 16.9995 - val_MinusLogProbMetric: 16.9995 - lr: 0.0010 - 31s/epoch - 160ms/step
Epoch 290/1000
2023-09-27 03:00:17.387 
Epoch 290/1000 
	 loss: 16.6794, MinusLogProbMetric: 16.6794, val_loss: 16.9917, val_MinusLogProbMetric: 16.9917

Epoch 290: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6794 - MinusLogProbMetric: 16.6794 - val_loss: 16.9917 - val_MinusLogProbMetric: 16.9917 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 291/1000
2023-09-27 03:00:49.119 
Epoch 291/1000 
	 loss: 16.6531, MinusLogProbMetric: 16.6531, val_loss: 17.1800, val_MinusLogProbMetric: 17.1800

Epoch 291: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6531 - MinusLogProbMetric: 16.6531 - val_loss: 17.1800 - val_MinusLogProbMetric: 17.1800 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 292/1000
2023-09-27 03:01:21.238 
Epoch 292/1000 
	 loss: 16.6406, MinusLogProbMetric: 16.6406, val_loss: 17.1919, val_MinusLogProbMetric: 17.1919

Epoch 292: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6406 - MinusLogProbMetric: 16.6406 - val_loss: 17.1919 - val_MinusLogProbMetric: 17.1919 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 293/1000
2023-09-27 03:01:52.719 
Epoch 293/1000 
	 loss: 16.6523, MinusLogProbMetric: 16.6523, val_loss: 17.1452, val_MinusLogProbMetric: 17.1452

Epoch 293: val_loss did not improve from 16.93736
196/196 - 31s - loss: 16.6523 - MinusLogProbMetric: 16.6523 - val_loss: 17.1452 - val_MinusLogProbMetric: 17.1452 - lr: 0.0010 - 31s/epoch - 161ms/step
Epoch 294/1000
2023-09-27 03:02:24.811 
Epoch 294/1000 
	 loss: 16.6552, MinusLogProbMetric: 16.6552, val_loss: 17.1555, val_MinusLogProbMetric: 17.1555

Epoch 294: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6552 - MinusLogProbMetric: 16.6552 - val_loss: 17.1555 - val_MinusLogProbMetric: 17.1555 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 295/1000
2023-09-27 03:02:56.851 
Epoch 295/1000 
	 loss: 16.6334, MinusLogProbMetric: 16.6334, val_loss: 17.2332, val_MinusLogProbMetric: 17.2332

Epoch 295: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6334 - MinusLogProbMetric: 16.6334 - val_loss: 17.2332 - val_MinusLogProbMetric: 17.2332 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 296/1000
2023-09-27 03:03:29.262 
Epoch 296/1000 
	 loss: 16.6579, MinusLogProbMetric: 16.6579, val_loss: 17.0415, val_MinusLogProbMetric: 17.0415

Epoch 296: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6579 - MinusLogProbMetric: 16.6579 - val_loss: 17.0415 - val_MinusLogProbMetric: 17.0415 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 297/1000
2023-09-27 03:04:01.305 
Epoch 297/1000 
	 loss: 16.6425, MinusLogProbMetric: 16.6425, val_loss: 17.0270, val_MinusLogProbMetric: 17.0270

Epoch 297: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6425 - MinusLogProbMetric: 16.6425 - val_loss: 17.0270 - val_MinusLogProbMetric: 17.0270 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 298/1000
2023-09-27 03:04:32.838 
Epoch 298/1000 
	 loss: 16.6300, MinusLogProbMetric: 16.6300, val_loss: 17.0267, val_MinusLogProbMetric: 17.0267

Epoch 298: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6300 - MinusLogProbMetric: 16.6300 - val_loss: 17.0267 - val_MinusLogProbMetric: 17.0267 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 299/1000
2023-09-27 03:05:04.593 
Epoch 299/1000 
	 loss: 16.6328, MinusLogProbMetric: 16.6328, val_loss: 16.9428, val_MinusLogProbMetric: 16.9428

Epoch 299: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6328 - MinusLogProbMetric: 16.6328 - val_loss: 16.9428 - val_MinusLogProbMetric: 16.9428 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 300/1000
2023-09-27 03:05:36.324 
Epoch 300/1000 
	 loss: 16.6073, MinusLogProbMetric: 16.6073, val_loss: 17.1103, val_MinusLogProbMetric: 17.1103

Epoch 300: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6073 - MinusLogProbMetric: 16.6073 - val_loss: 17.1103 - val_MinusLogProbMetric: 17.1103 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 301/1000
2023-09-27 03:06:08.118 
Epoch 301/1000 
	 loss: 16.6658, MinusLogProbMetric: 16.6658, val_loss: 16.9851, val_MinusLogProbMetric: 16.9851

Epoch 301: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6658 - MinusLogProbMetric: 16.6658 - val_loss: 16.9851 - val_MinusLogProbMetric: 16.9851 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 302/1000
2023-09-27 03:06:40.136 
Epoch 302/1000 
	 loss: 16.6187, MinusLogProbMetric: 16.6187, val_loss: 16.9547, val_MinusLogProbMetric: 16.9547

Epoch 302: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6187 - MinusLogProbMetric: 16.6187 - val_loss: 16.9547 - val_MinusLogProbMetric: 16.9547 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 303/1000
2023-09-27 03:07:11.810 
Epoch 303/1000 
	 loss: 16.6304, MinusLogProbMetric: 16.6304, val_loss: 16.9664, val_MinusLogProbMetric: 16.9664

Epoch 303: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6304 - MinusLogProbMetric: 16.6304 - val_loss: 16.9664 - val_MinusLogProbMetric: 16.9664 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 304/1000
2023-09-27 03:07:43.820 
Epoch 304/1000 
	 loss: 16.6255, MinusLogProbMetric: 16.6255, val_loss: 16.9660, val_MinusLogProbMetric: 16.9660

Epoch 304: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6255 - MinusLogProbMetric: 16.6255 - val_loss: 16.9660 - val_MinusLogProbMetric: 16.9660 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 305/1000
2023-09-27 03:08:15.543 
Epoch 305/1000 
	 loss: 16.6214, MinusLogProbMetric: 16.6214, val_loss: 17.4783, val_MinusLogProbMetric: 17.4783

Epoch 305: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6214 - MinusLogProbMetric: 16.6214 - val_loss: 17.4783 - val_MinusLogProbMetric: 17.4783 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 306/1000
2023-09-27 03:08:47.672 
Epoch 306/1000 
	 loss: 16.6357, MinusLogProbMetric: 16.6357, val_loss: 16.9990, val_MinusLogProbMetric: 16.9990

Epoch 306: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6357 - MinusLogProbMetric: 16.6357 - val_loss: 16.9990 - val_MinusLogProbMetric: 16.9990 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 307/1000
2023-09-27 03:09:19.318 
Epoch 307/1000 
	 loss: 16.6394, MinusLogProbMetric: 16.6394, val_loss: 17.0574, val_MinusLogProbMetric: 17.0574

Epoch 307: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6394 - MinusLogProbMetric: 16.6394 - val_loss: 17.0574 - val_MinusLogProbMetric: 17.0574 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 308/1000
2023-09-27 03:09:51.191 
Epoch 308/1000 
	 loss: 16.6081, MinusLogProbMetric: 16.6081, val_loss: 17.0330, val_MinusLogProbMetric: 17.0330

Epoch 308: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6081 - MinusLogProbMetric: 16.6081 - val_loss: 17.0330 - val_MinusLogProbMetric: 17.0330 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 309/1000
2023-09-27 03:10:23.529 
Epoch 309/1000 
	 loss: 16.6412, MinusLogProbMetric: 16.6412, val_loss: 17.1031, val_MinusLogProbMetric: 17.1031

Epoch 309: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6412 - MinusLogProbMetric: 16.6412 - val_loss: 17.1031 - val_MinusLogProbMetric: 17.1031 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 310/1000
2023-09-27 03:10:55.295 
Epoch 310/1000 
	 loss: 16.6432, MinusLogProbMetric: 16.6432, val_loss: 17.0534, val_MinusLogProbMetric: 17.0534

Epoch 310: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6432 - MinusLogProbMetric: 16.6432 - val_loss: 17.0534 - val_MinusLogProbMetric: 17.0534 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 311/1000
2023-09-27 03:11:27.142 
Epoch 311/1000 
	 loss: 16.6290, MinusLogProbMetric: 16.6290, val_loss: 17.2721, val_MinusLogProbMetric: 17.2721

Epoch 311: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6290 - MinusLogProbMetric: 16.6290 - val_loss: 17.2721 - val_MinusLogProbMetric: 17.2721 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 312/1000
2023-09-27 03:11:58.727 
Epoch 312/1000 
	 loss: 16.6141, MinusLogProbMetric: 16.6141, val_loss: 17.1667, val_MinusLogProbMetric: 17.1667

Epoch 312: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6141 - MinusLogProbMetric: 16.6141 - val_loss: 17.1667 - val_MinusLogProbMetric: 17.1667 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 313/1000
2023-09-27 03:12:30.766 
Epoch 313/1000 
	 loss: 16.6208, MinusLogProbMetric: 16.6208, val_loss: 16.9962, val_MinusLogProbMetric: 16.9962

Epoch 313: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6208 - MinusLogProbMetric: 16.6208 - val_loss: 16.9962 - val_MinusLogProbMetric: 16.9962 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 314/1000
2023-09-27 03:13:02.531 
Epoch 314/1000 
	 loss: 16.6131, MinusLogProbMetric: 16.6131, val_loss: 17.0495, val_MinusLogProbMetric: 17.0495

Epoch 314: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.6131 - MinusLogProbMetric: 16.6131 - val_loss: 17.0495 - val_MinusLogProbMetric: 17.0495 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 315/1000
2023-09-27 03:13:34.595 
Epoch 315/1000 
	 loss: 16.4713, MinusLogProbMetric: 16.4713, val_loss: 16.9464, val_MinusLogProbMetric: 16.9464

Epoch 315: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.4713 - MinusLogProbMetric: 16.4713 - val_loss: 16.9464 - val_MinusLogProbMetric: 16.9464 - lr: 5.0000e-04 - 32s/epoch - 164ms/step
Epoch 316/1000
2023-09-27 03:14:06.389 
Epoch 316/1000 
	 loss: 16.4555, MinusLogProbMetric: 16.4555, val_loss: 16.9445, val_MinusLogProbMetric: 16.9445

Epoch 316: val_loss did not improve from 16.93736
196/196 - 32s - loss: 16.4555 - MinusLogProbMetric: 16.4555 - val_loss: 16.9445 - val_MinusLogProbMetric: 16.9445 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 317/1000
2023-09-27 03:14:38.141 
Epoch 317/1000 
	 loss: 16.4612, MinusLogProbMetric: 16.4612, val_loss: 16.8960, val_MinusLogProbMetric: 16.8960

Epoch 317: val_loss improved from 16.93736 to 16.89600, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 32s - loss: 16.4612 - MinusLogProbMetric: 16.4612 - val_loss: 16.8960 - val_MinusLogProbMetric: 16.8960 - lr: 5.0000e-04 - 32s/epoch - 165ms/step
Epoch 318/1000
2023-09-27 03:15:10.558 
Epoch 318/1000 
	 loss: 16.4648, MinusLogProbMetric: 16.4648, val_loss: 16.9529, val_MinusLogProbMetric: 16.9529

Epoch 318: val_loss did not improve from 16.89600
196/196 - 32s - loss: 16.4648 - MinusLogProbMetric: 16.4648 - val_loss: 16.9529 - val_MinusLogProbMetric: 16.9529 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 319/1000
2023-09-27 03:15:42.264 
Epoch 319/1000 
	 loss: 16.4721, MinusLogProbMetric: 16.4721, val_loss: 16.9081, val_MinusLogProbMetric: 16.9081

Epoch 319: val_loss did not improve from 16.89600
196/196 - 32s - loss: 16.4721 - MinusLogProbMetric: 16.4721 - val_loss: 16.9081 - val_MinusLogProbMetric: 16.9081 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 320/1000
2023-09-27 03:16:14.269 
Epoch 320/1000 
	 loss: 16.4580, MinusLogProbMetric: 16.4580, val_loss: 16.8822, val_MinusLogProbMetric: 16.8822

Epoch 320: val_loss improved from 16.89600 to 16.88224, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 16.4580 - MinusLogProbMetric: 16.4580 - val_loss: 16.8822 - val_MinusLogProbMetric: 16.8822 - lr: 5.0000e-04 - 33s/epoch - 166ms/step
Epoch 321/1000
2023-09-27 03:16:46.377 
Epoch 321/1000 
	 loss: 16.4554, MinusLogProbMetric: 16.4554, val_loss: 17.1380, val_MinusLogProbMetric: 17.1380

Epoch 321: val_loss did not improve from 16.88224
196/196 - 32s - loss: 16.4554 - MinusLogProbMetric: 16.4554 - val_loss: 17.1380 - val_MinusLogProbMetric: 17.1380 - lr: 5.0000e-04 - 32s/epoch - 161ms/step
Epoch 322/1000
2023-09-27 03:17:18.318 
Epoch 322/1000 
	 loss: 16.4753, MinusLogProbMetric: 16.4753, val_loss: 16.9208, val_MinusLogProbMetric: 16.9208

Epoch 322: val_loss did not improve from 16.88224
196/196 - 32s - loss: 16.4753 - MinusLogProbMetric: 16.4753 - val_loss: 16.9208 - val_MinusLogProbMetric: 16.9208 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 323/1000
2023-09-27 03:17:49.968 
Epoch 323/1000 
	 loss: 16.4673, MinusLogProbMetric: 16.4673, val_loss: 16.9920, val_MinusLogProbMetric: 16.9920

Epoch 323: val_loss did not improve from 16.88224
196/196 - 32s - loss: 16.4673 - MinusLogProbMetric: 16.4673 - val_loss: 16.9920 - val_MinusLogProbMetric: 16.9920 - lr: 5.0000e-04 - 32s/epoch - 161ms/step
Epoch 324/1000
2023-09-27 03:18:21.902 
Epoch 324/1000 
	 loss: 16.4540, MinusLogProbMetric: 16.4540, val_loss: 16.8904, val_MinusLogProbMetric: 16.8904

Epoch 324: val_loss did not improve from 16.88224
196/196 - 32s - loss: 16.4540 - MinusLogProbMetric: 16.4540 - val_loss: 16.8904 - val_MinusLogProbMetric: 16.8904 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 325/1000
2023-09-27 03:18:53.641 
Epoch 325/1000 
	 loss: 16.4613, MinusLogProbMetric: 16.4613, val_loss: 16.9723, val_MinusLogProbMetric: 16.9723

Epoch 325: val_loss did not improve from 16.88224
196/196 - 32s - loss: 16.4613 - MinusLogProbMetric: 16.4613 - val_loss: 16.9723 - val_MinusLogProbMetric: 16.9723 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 326/1000
2023-09-27 03:19:25.876 
Epoch 326/1000 
	 loss: 16.4534, MinusLogProbMetric: 16.4534, val_loss: 16.9263, val_MinusLogProbMetric: 16.9263

Epoch 326: val_loss did not improve from 16.88224
196/196 - 32s - loss: 16.4534 - MinusLogProbMetric: 16.4534 - val_loss: 16.9263 - val_MinusLogProbMetric: 16.9263 - lr: 5.0000e-04 - 32s/epoch - 164ms/step
Epoch 327/1000
2023-09-27 03:19:58.067 
Epoch 327/1000 
	 loss: 16.4684, MinusLogProbMetric: 16.4684, val_loss: 16.9556, val_MinusLogProbMetric: 16.9556

Epoch 327: val_loss did not improve from 16.88224
196/196 - 32s - loss: 16.4684 - MinusLogProbMetric: 16.4684 - val_loss: 16.9556 - val_MinusLogProbMetric: 16.9556 - lr: 5.0000e-04 - 32s/epoch - 164ms/step
Epoch 328/1000
2023-09-27 03:20:29.824 
Epoch 328/1000 
	 loss: 16.4521, MinusLogProbMetric: 16.4521, val_loss: 16.9881, val_MinusLogProbMetric: 16.9881

Epoch 328: val_loss did not improve from 16.88224
196/196 - 32s - loss: 16.4521 - MinusLogProbMetric: 16.4521 - val_loss: 16.9881 - val_MinusLogProbMetric: 16.9881 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 329/1000
2023-09-27 03:21:01.470 
Epoch 329/1000 
	 loss: 16.4572, MinusLogProbMetric: 16.4572, val_loss: 17.0901, val_MinusLogProbMetric: 17.0901

Epoch 329: val_loss did not improve from 16.88224
196/196 - 32s - loss: 16.4572 - MinusLogProbMetric: 16.4572 - val_loss: 17.0901 - val_MinusLogProbMetric: 17.0901 - lr: 5.0000e-04 - 32s/epoch - 161ms/step
Epoch 330/1000
2023-09-27 03:21:33.257 
Epoch 330/1000 
	 loss: 16.4646, MinusLogProbMetric: 16.4646, val_loss: 16.8829, val_MinusLogProbMetric: 16.8829

Epoch 330: val_loss did not improve from 16.88224
196/196 - 32s - loss: 16.4646 - MinusLogProbMetric: 16.4646 - val_loss: 16.8829 - val_MinusLogProbMetric: 16.8829 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 331/1000
2023-09-27 03:22:05.326 
Epoch 331/1000 
	 loss: 16.4597, MinusLogProbMetric: 16.4597, val_loss: 16.8760, val_MinusLogProbMetric: 16.8760

Epoch 331: val_loss improved from 16.88224 to 16.87599, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 16.4597 - MinusLogProbMetric: 16.4597 - val_loss: 16.8760 - val_MinusLogProbMetric: 16.8760 - lr: 5.0000e-04 - 33s/epoch - 166ms/step
Epoch 332/1000
2023-09-27 03:22:37.652 
Epoch 332/1000 
	 loss: 16.4574, MinusLogProbMetric: 16.4574, val_loss: 16.8974, val_MinusLogProbMetric: 16.8974

Epoch 332: val_loss did not improve from 16.87599
196/196 - 32s - loss: 16.4574 - MinusLogProbMetric: 16.4574 - val_loss: 16.8974 - val_MinusLogProbMetric: 16.8974 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 333/1000
2023-09-27 03:23:09.804 
Epoch 333/1000 
	 loss: 16.4429, MinusLogProbMetric: 16.4429, val_loss: 16.9011, val_MinusLogProbMetric: 16.9011

Epoch 333: val_loss did not improve from 16.87599
196/196 - 32s - loss: 16.4429 - MinusLogProbMetric: 16.4429 - val_loss: 16.9011 - val_MinusLogProbMetric: 16.9011 - lr: 5.0000e-04 - 32s/epoch - 164ms/step
Epoch 334/1000
2023-09-27 03:23:41.561 
Epoch 334/1000 
	 loss: 16.4469, MinusLogProbMetric: 16.4469, val_loss: 16.9997, val_MinusLogProbMetric: 16.9997

Epoch 334: val_loss did not improve from 16.87599
196/196 - 32s - loss: 16.4469 - MinusLogProbMetric: 16.4469 - val_loss: 16.9997 - val_MinusLogProbMetric: 16.9997 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 335/1000
2023-09-27 03:24:13.508 
Epoch 335/1000 
	 loss: 16.4671, MinusLogProbMetric: 16.4671, val_loss: 16.9130, val_MinusLogProbMetric: 16.9130

Epoch 335: val_loss did not improve from 16.87599
196/196 - 32s - loss: 16.4671 - MinusLogProbMetric: 16.4671 - val_loss: 16.9130 - val_MinusLogProbMetric: 16.9130 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 336/1000
2023-09-27 03:24:45.577 
Epoch 336/1000 
	 loss: 16.4494, MinusLogProbMetric: 16.4494, val_loss: 16.8704, val_MinusLogProbMetric: 16.8704

Epoch 336: val_loss improved from 16.87599 to 16.87041, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 16.4494 - MinusLogProbMetric: 16.4494 - val_loss: 16.8704 - val_MinusLogProbMetric: 16.8704 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 337/1000
2023-09-27 03:25:17.811 
Epoch 337/1000 
	 loss: 16.4441, MinusLogProbMetric: 16.4441, val_loss: 16.9339, val_MinusLogProbMetric: 16.9339

Epoch 337: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4441 - MinusLogProbMetric: 16.4441 - val_loss: 16.9339 - val_MinusLogProbMetric: 16.9339 - lr: 5.0000e-04 - 32s/epoch - 161ms/step
Epoch 338/1000
2023-09-27 03:25:49.592 
Epoch 338/1000 
	 loss: 16.4493, MinusLogProbMetric: 16.4493, val_loss: 16.9828, val_MinusLogProbMetric: 16.9828

Epoch 338: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4493 - MinusLogProbMetric: 16.4493 - val_loss: 16.9828 - val_MinusLogProbMetric: 16.9828 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 339/1000
2023-09-27 03:26:21.543 
Epoch 339/1000 
	 loss: 16.4645, MinusLogProbMetric: 16.4645, val_loss: 17.0153, val_MinusLogProbMetric: 17.0153

Epoch 339: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4645 - MinusLogProbMetric: 16.4645 - val_loss: 17.0153 - val_MinusLogProbMetric: 17.0153 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 340/1000
2023-09-27 03:26:53.788 
Epoch 340/1000 
	 loss: 16.4639, MinusLogProbMetric: 16.4639, val_loss: 16.9997, val_MinusLogProbMetric: 16.9997

Epoch 340: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4639 - MinusLogProbMetric: 16.4639 - val_loss: 16.9997 - val_MinusLogProbMetric: 16.9997 - lr: 5.0000e-04 - 32s/epoch - 164ms/step
Epoch 341/1000
2023-09-27 03:27:26.172 
Epoch 341/1000 
	 loss: 16.4747, MinusLogProbMetric: 16.4747, val_loss: 16.9409, val_MinusLogProbMetric: 16.9409

Epoch 341: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4747 - MinusLogProbMetric: 16.4747 - val_loss: 16.9409 - val_MinusLogProbMetric: 16.9409 - lr: 5.0000e-04 - 32s/epoch - 165ms/step
Epoch 342/1000
2023-09-27 03:27:57.753 
Epoch 342/1000 
	 loss: 16.4564, MinusLogProbMetric: 16.4564, val_loss: 16.9396, val_MinusLogProbMetric: 16.9396

Epoch 342: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4564 - MinusLogProbMetric: 16.4564 - val_loss: 16.9396 - val_MinusLogProbMetric: 16.9396 - lr: 5.0000e-04 - 32s/epoch - 161ms/step
Epoch 343/1000
2023-09-27 03:28:30.228 
Epoch 343/1000 
	 loss: 16.4388, MinusLogProbMetric: 16.4388, val_loss: 16.8862, val_MinusLogProbMetric: 16.8862

Epoch 343: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4388 - MinusLogProbMetric: 16.4388 - val_loss: 16.8862 - val_MinusLogProbMetric: 16.8862 - lr: 5.0000e-04 - 32s/epoch - 166ms/step
Epoch 344/1000
2023-09-27 03:29:01.753 
Epoch 344/1000 
	 loss: 16.4624, MinusLogProbMetric: 16.4624, val_loss: 16.8870, val_MinusLogProbMetric: 16.8870

Epoch 344: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4624 - MinusLogProbMetric: 16.4624 - val_loss: 16.8870 - val_MinusLogProbMetric: 16.8870 - lr: 5.0000e-04 - 32s/epoch - 161ms/step
Epoch 345/1000
2023-09-27 03:29:33.890 
Epoch 345/1000 
	 loss: 16.4458, MinusLogProbMetric: 16.4458, val_loss: 16.9001, val_MinusLogProbMetric: 16.9001

Epoch 345: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4458 - MinusLogProbMetric: 16.4458 - val_loss: 16.9001 - val_MinusLogProbMetric: 16.9001 - lr: 5.0000e-04 - 32s/epoch - 164ms/step
Epoch 346/1000
2023-09-27 03:30:05.648 
Epoch 346/1000 
	 loss: 16.4597, MinusLogProbMetric: 16.4597, val_loss: 16.8906, val_MinusLogProbMetric: 16.8906

Epoch 346: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4597 - MinusLogProbMetric: 16.4597 - val_loss: 16.8906 - val_MinusLogProbMetric: 16.8906 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 347/1000
2023-09-27 03:30:37.240 
Epoch 347/1000 
	 loss: 16.4375, MinusLogProbMetric: 16.4375, val_loss: 17.0561, val_MinusLogProbMetric: 17.0561

Epoch 347: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4375 - MinusLogProbMetric: 16.4375 - val_loss: 17.0561 - val_MinusLogProbMetric: 17.0561 - lr: 5.0000e-04 - 32s/epoch - 161ms/step
Epoch 348/1000
2023-09-27 03:31:09.335 
Epoch 348/1000 
	 loss: 16.4713, MinusLogProbMetric: 16.4713, val_loss: 16.9141, val_MinusLogProbMetric: 16.9141

Epoch 348: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4713 - MinusLogProbMetric: 16.4713 - val_loss: 16.9141 - val_MinusLogProbMetric: 16.9141 - lr: 5.0000e-04 - 32s/epoch - 164ms/step
Epoch 349/1000
2023-09-27 03:31:40.877 
Epoch 349/1000 
	 loss: 16.4330, MinusLogProbMetric: 16.4330, val_loss: 16.9476, val_MinusLogProbMetric: 16.9476

Epoch 349: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4330 - MinusLogProbMetric: 16.4330 - val_loss: 16.9476 - val_MinusLogProbMetric: 16.9476 - lr: 5.0000e-04 - 32s/epoch - 161ms/step
Epoch 350/1000
2023-09-27 03:32:12.799 
Epoch 350/1000 
	 loss: 16.4369, MinusLogProbMetric: 16.4369, val_loss: 16.8903, val_MinusLogProbMetric: 16.8903

Epoch 350: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4369 - MinusLogProbMetric: 16.4369 - val_loss: 16.8903 - val_MinusLogProbMetric: 16.8903 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 351/1000
2023-09-27 03:32:44.798 
Epoch 351/1000 
	 loss: 16.4588, MinusLogProbMetric: 16.4588, val_loss: 16.8858, val_MinusLogProbMetric: 16.8858

Epoch 351: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4588 - MinusLogProbMetric: 16.4588 - val_loss: 16.8858 - val_MinusLogProbMetric: 16.8858 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 352/1000
2023-09-27 03:33:16.605 
Epoch 352/1000 
	 loss: 16.4421, MinusLogProbMetric: 16.4421, val_loss: 16.9459, val_MinusLogProbMetric: 16.9459

Epoch 352: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4421 - MinusLogProbMetric: 16.4421 - val_loss: 16.9459 - val_MinusLogProbMetric: 16.9459 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 353/1000
2023-09-27 03:33:48.551 
Epoch 353/1000 
	 loss: 16.4401, MinusLogProbMetric: 16.4401, val_loss: 16.8834, val_MinusLogProbMetric: 16.8834

Epoch 353: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4401 - MinusLogProbMetric: 16.4401 - val_loss: 16.8834 - val_MinusLogProbMetric: 16.8834 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 354/1000
2023-09-27 03:34:20.452 
Epoch 354/1000 
	 loss: 16.4320, MinusLogProbMetric: 16.4320, val_loss: 16.9769, val_MinusLogProbMetric: 16.9769

Epoch 354: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4320 - MinusLogProbMetric: 16.4320 - val_loss: 16.9769 - val_MinusLogProbMetric: 16.9769 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 355/1000
2023-09-27 03:34:52.215 
Epoch 355/1000 
	 loss: 16.4424, MinusLogProbMetric: 16.4424, val_loss: 16.9489, val_MinusLogProbMetric: 16.9489

Epoch 355: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4424 - MinusLogProbMetric: 16.4424 - val_loss: 16.9489 - val_MinusLogProbMetric: 16.9489 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 356/1000
2023-09-27 03:35:24.023 
Epoch 356/1000 
	 loss: 16.4426, MinusLogProbMetric: 16.4426, val_loss: 16.9084, val_MinusLogProbMetric: 16.9084

Epoch 356: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4426 - MinusLogProbMetric: 16.4426 - val_loss: 16.9084 - val_MinusLogProbMetric: 16.9084 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 357/1000
2023-09-27 03:35:55.802 
Epoch 357/1000 
	 loss: 16.4293, MinusLogProbMetric: 16.4293, val_loss: 16.9217, val_MinusLogProbMetric: 16.9217

Epoch 357: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4293 - MinusLogProbMetric: 16.4293 - val_loss: 16.9217 - val_MinusLogProbMetric: 16.9217 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 358/1000
2023-09-27 03:36:27.705 
Epoch 358/1000 
	 loss: 16.4363, MinusLogProbMetric: 16.4363, val_loss: 16.9945, val_MinusLogProbMetric: 16.9945

Epoch 358: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4363 - MinusLogProbMetric: 16.4363 - val_loss: 16.9945 - val_MinusLogProbMetric: 16.9945 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 359/1000
2023-09-27 03:36:59.876 
Epoch 359/1000 
	 loss: 16.4505, MinusLogProbMetric: 16.4505, val_loss: 16.8757, val_MinusLogProbMetric: 16.8757

Epoch 359: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4505 - MinusLogProbMetric: 16.4505 - val_loss: 16.8757 - val_MinusLogProbMetric: 16.8757 - lr: 5.0000e-04 - 32s/epoch - 164ms/step
Epoch 360/1000
2023-09-27 03:37:32.086 
Epoch 360/1000 
	 loss: 16.4696, MinusLogProbMetric: 16.4696, val_loss: 16.9465, val_MinusLogProbMetric: 16.9465

Epoch 360: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4696 - MinusLogProbMetric: 16.4696 - val_loss: 16.9465 - val_MinusLogProbMetric: 16.9465 - lr: 5.0000e-04 - 32s/epoch - 164ms/step
Epoch 361/1000
2023-09-27 03:38:04.098 
Epoch 361/1000 
	 loss: 16.4310, MinusLogProbMetric: 16.4310, val_loss: 16.9332, val_MinusLogProbMetric: 16.9332

Epoch 361: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4310 - MinusLogProbMetric: 16.4310 - val_loss: 16.9332 - val_MinusLogProbMetric: 16.9332 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 362/1000
2023-09-27 03:38:35.957 
Epoch 362/1000 
	 loss: 16.4302, MinusLogProbMetric: 16.4302, val_loss: 16.9650, val_MinusLogProbMetric: 16.9650

Epoch 362: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4302 - MinusLogProbMetric: 16.4302 - val_loss: 16.9650 - val_MinusLogProbMetric: 16.9650 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 363/1000
2023-09-27 03:39:07.790 
Epoch 363/1000 
	 loss: 16.4524, MinusLogProbMetric: 16.4524, val_loss: 16.9014, val_MinusLogProbMetric: 16.9014

Epoch 363: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4524 - MinusLogProbMetric: 16.4524 - val_loss: 16.9014 - val_MinusLogProbMetric: 16.9014 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 364/1000
2023-09-27 03:39:39.728 
Epoch 364/1000 
	 loss: 16.4355, MinusLogProbMetric: 16.4355, val_loss: 17.0021, val_MinusLogProbMetric: 17.0021

Epoch 364: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4355 - MinusLogProbMetric: 16.4355 - val_loss: 17.0021 - val_MinusLogProbMetric: 17.0021 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 365/1000
2023-09-27 03:40:11.881 
Epoch 365/1000 
	 loss: 16.4196, MinusLogProbMetric: 16.4196, val_loss: 17.1774, val_MinusLogProbMetric: 17.1774

Epoch 365: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4196 - MinusLogProbMetric: 16.4196 - val_loss: 17.1774 - val_MinusLogProbMetric: 17.1774 - lr: 5.0000e-04 - 32s/epoch - 164ms/step
Epoch 366/1000
2023-09-27 03:40:43.927 
Epoch 366/1000 
	 loss: 16.4444, MinusLogProbMetric: 16.4444, val_loss: 16.9131, val_MinusLogProbMetric: 16.9131

Epoch 366: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4444 - MinusLogProbMetric: 16.4444 - val_loss: 16.9131 - val_MinusLogProbMetric: 16.9131 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 367/1000
2023-09-27 03:41:15.977 
Epoch 367/1000 
	 loss: 16.4370, MinusLogProbMetric: 16.4370, val_loss: 17.0486, val_MinusLogProbMetric: 17.0486

Epoch 367: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4370 - MinusLogProbMetric: 16.4370 - val_loss: 17.0486 - val_MinusLogProbMetric: 17.0486 - lr: 5.0000e-04 - 32s/epoch - 164ms/step
Epoch 368/1000
2023-09-27 03:41:47.812 
Epoch 368/1000 
	 loss: 16.4517, MinusLogProbMetric: 16.4517, val_loss: 16.9662, val_MinusLogProbMetric: 16.9662

Epoch 368: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4517 - MinusLogProbMetric: 16.4517 - val_loss: 16.9662 - val_MinusLogProbMetric: 16.9662 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 369/1000
2023-09-27 03:42:19.902 
Epoch 369/1000 
	 loss: 16.4235, MinusLogProbMetric: 16.4235, val_loss: 17.1066, val_MinusLogProbMetric: 17.1066

Epoch 369: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4235 - MinusLogProbMetric: 16.4235 - val_loss: 17.1066 - val_MinusLogProbMetric: 17.1066 - lr: 5.0000e-04 - 32s/epoch - 164ms/step
Epoch 370/1000
2023-09-27 03:42:51.669 
Epoch 370/1000 
	 loss: 16.4377, MinusLogProbMetric: 16.4377, val_loss: 16.9465, val_MinusLogProbMetric: 16.9465

Epoch 370: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4377 - MinusLogProbMetric: 16.4377 - val_loss: 16.9465 - val_MinusLogProbMetric: 16.9465 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 371/1000
2023-09-27 03:43:23.361 
Epoch 371/1000 
	 loss: 16.4297, MinusLogProbMetric: 16.4297, val_loss: 16.9236, val_MinusLogProbMetric: 16.9236

Epoch 371: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4297 - MinusLogProbMetric: 16.4297 - val_loss: 16.9236 - val_MinusLogProbMetric: 16.9236 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 372/1000
2023-09-27 03:43:55.382 
Epoch 372/1000 
	 loss: 16.4469, MinusLogProbMetric: 16.4469, val_loss: 16.9979, val_MinusLogProbMetric: 16.9979

Epoch 372: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4469 - MinusLogProbMetric: 16.4469 - val_loss: 16.9979 - val_MinusLogProbMetric: 16.9979 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 373/1000
2023-09-27 03:44:27.177 
Epoch 373/1000 
	 loss: 16.4285, MinusLogProbMetric: 16.4285, val_loss: 16.9826, val_MinusLogProbMetric: 16.9826

Epoch 373: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4285 - MinusLogProbMetric: 16.4285 - val_loss: 16.9826 - val_MinusLogProbMetric: 16.9826 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 374/1000
2023-09-27 03:44:58.918 
Epoch 374/1000 
	 loss: 16.4218, MinusLogProbMetric: 16.4218, val_loss: 16.8908, val_MinusLogProbMetric: 16.8908

Epoch 374: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4218 - MinusLogProbMetric: 16.4218 - val_loss: 16.8908 - val_MinusLogProbMetric: 16.8908 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 375/1000
2023-09-27 03:45:30.966 
Epoch 375/1000 
	 loss: 16.4203, MinusLogProbMetric: 16.4203, val_loss: 16.9138, val_MinusLogProbMetric: 16.9138

Epoch 375: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4203 - MinusLogProbMetric: 16.4203 - val_loss: 16.9138 - val_MinusLogProbMetric: 16.9138 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 376/1000
2023-09-27 03:46:02.929 
Epoch 376/1000 
	 loss: 16.4258, MinusLogProbMetric: 16.4258, val_loss: 16.9903, val_MinusLogProbMetric: 16.9903

Epoch 376: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4258 - MinusLogProbMetric: 16.4258 - val_loss: 16.9903 - val_MinusLogProbMetric: 16.9903 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 377/1000
2023-09-27 03:46:34.679 
Epoch 377/1000 
	 loss: 16.4424, MinusLogProbMetric: 16.4424, val_loss: 16.9296, val_MinusLogProbMetric: 16.9296

Epoch 377: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4424 - MinusLogProbMetric: 16.4424 - val_loss: 16.9296 - val_MinusLogProbMetric: 16.9296 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 378/1000
2023-09-27 03:47:06.404 
Epoch 378/1000 
	 loss: 16.4756, MinusLogProbMetric: 16.4756, val_loss: 16.8842, val_MinusLogProbMetric: 16.8842

Epoch 378: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4756 - MinusLogProbMetric: 16.4756 - val_loss: 16.8842 - val_MinusLogProbMetric: 16.8842 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 379/1000
2023-09-27 03:47:39.547 
Epoch 379/1000 
	 loss: 16.4220, MinusLogProbMetric: 16.4220, val_loss: 16.9276, val_MinusLogProbMetric: 16.9276

Epoch 379: val_loss did not improve from 16.87041
196/196 - 33s - loss: 16.4220 - MinusLogProbMetric: 16.4220 - val_loss: 16.9276 - val_MinusLogProbMetric: 16.9276 - lr: 5.0000e-04 - 33s/epoch - 169ms/step
Epoch 380/1000
2023-09-27 03:48:11.780 
Epoch 380/1000 
	 loss: 16.4174, MinusLogProbMetric: 16.4174, val_loss: 16.9932, val_MinusLogProbMetric: 16.9932

Epoch 380: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4174 - MinusLogProbMetric: 16.4174 - val_loss: 16.9932 - val_MinusLogProbMetric: 16.9932 - lr: 5.0000e-04 - 32s/epoch - 164ms/step
Epoch 381/1000
2023-09-27 03:48:43.808 
Epoch 381/1000 
	 loss: 16.4453, MinusLogProbMetric: 16.4453, val_loss: 16.9746, val_MinusLogProbMetric: 16.9746

Epoch 381: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4453 - MinusLogProbMetric: 16.4453 - val_loss: 16.9746 - val_MinusLogProbMetric: 16.9746 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 382/1000
2023-09-27 03:49:15.150 
Epoch 382/1000 
	 loss: 16.4237, MinusLogProbMetric: 16.4237, val_loss: 16.9517, val_MinusLogProbMetric: 16.9517

Epoch 382: val_loss did not improve from 16.87041
196/196 - 31s - loss: 16.4237 - MinusLogProbMetric: 16.4237 - val_loss: 16.9517 - val_MinusLogProbMetric: 16.9517 - lr: 5.0000e-04 - 31s/epoch - 160ms/step
Epoch 383/1000
2023-09-27 03:49:47.037 
Epoch 383/1000 
	 loss: 16.4325, MinusLogProbMetric: 16.4325, val_loss: 16.9516, val_MinusLogProbMetric: 16.9516

Epoch 383: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4325 - MinusLogProbMetric: 16.4325 - val_loss: 16.9516 - val_MinusLogProbMetric: 16.9516 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 384/1000
2023-09-27 03:50:18.831 
Epoch 384/1000 
	 loss: 16.4387, MinusLogProbMetric: 16.4387, val_loss: 16.9305, val_MinusLogProbMetric: 16.9305

Epoch 384: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4387 - MinusLogProbMetric: 16.4387 - val_loss: 16.9305 - val_MinusLogProbMetric: 16.9305 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 385/1000
2023-09-27 03:50:50.732 
Epoch 385/1000 
	 loss: 16.4402, MinusLogProbMetric: 16.4402, val_loss: 16.9706, val_MinusLogProbMetric: 16.9706

Epoch 385: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4402 - MinusLogProbMetric: 16.4402 - val_loss: 16.9706 - val_MinusLogProbMetric: 16.9706 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 386/1000
2023-09-27 03:51:22.318 
Epoch 386/1000 
	 loss: 16.4189, MinusLogProbMetric: 16.4189, val_loss: 16.8784, val_MinusLogProbMetric: 16.8784

Epoch 386: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.4189 - MinusLogProbMetric: 16.4189 - val_loss: 16.8784 - val_MinusLogProbMetric: 16.8784 - lr: 5.0000e-04 - 32s/epoch - 161ms/step
Epoch 387/1000
2023-09-27 03:51:54.076 
Epoch 387/1000 
	 loss: 16.3530, MinusLogProbMetric: 16.3530, val_loss: 16.8830, val_MinusLogProbMetric: 16.8830

Epoch 387: val_loss did not improve from 16.87041
196/196 - 32s - loss: 16.3530 - MinusLogProbMetric: 16.3530 - val_loss: 16.8830 - val_MinusLogProbMetric: 16.8830 - lr: 2.5000e-04 - 32s/epoch - 162ms/step
Epoch 388/1000
2023-09-27 03:52:25.996 
Epoch 388/1000 
	 loss: 16.3533, MinusLogProbMetric: 16.3533, val_loss: 16.8699, val_MinusLogProbMetric: 16.8699

Epoch 388: val_loss improved from 16.87041 to 16.86988, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 16.3533 - MinusLogProbMetric: 16.3533 - val_loss: 16.8699 - val_MinusLogProbMetric: 16.8699 - lr: 2.5000e-04 - 33s/epoch - 166ms/step
Epoch 389/1000
2023-09-27 03:52:58.385 
Epoch 389/1000 
	 loss: 16.3553, MinusLogProbMetric: 16.3553, val_loss: 16.9122, val_MinusLogProbMetric: 16.9122

Epoch 389: val_loss did not improve from 16.86988
196/196 - 32s - loss: 16.3553 - MinusLogProbMetric: 16.3553 - val_loss: 16.9122 - val_MinusLogProbMetric: 16.9122 - lr: 2.5000e-04 - 32s/epoch - 162ms/step
Epoch 390/1000
2023-09-27 03:53:30.314 
Epoch 390/1000 
	 loss: 16.3616, MinusLogProbMetric: 16.3616, val_loss: 16.9106, val_MinusLogProbMetric: 16.9106

Epoch 390: val_loss did not improve from 16.86988
196/196 - 32s - loss: 16.3616 - MinusLogProbMetric: 16.3616 - val_loss: 16.9106 - val_MinusLogProbMetric: 16.9106 - lr: 2.5000e-04 - 32s/epoch - 163ms/step
Epoch 391/1000
2023-09-27 03:54:01.993 
Epoch 391/1000 
	 loss: 16.3475, MinusLogProbMetric: 16.3475, val_loss: 16.9121, val_MinusLogProbMetric: 16.9121

Epoch 391: val_loss did not improve from 16.86988
196/196 - 32s - loss: 16.3475 - MinusLogProbMetric: 16.3475 - val_loss: 16.9121 - val_MinusLogProbMetric: 16.9121 - lr: 2.5000e-04 - 32s/epoch - 162ms/step
Epoch 392/1000
2023-09-27 03:54:34.236 
Epoch 392/1000 
	 loss: 16.3511, MinusLogProbMetric: 16.3511, val_loss: 16.8969, val_MinusLogProbMetric: 16.8969

Epoch 392: val_loss did not improve from 16.86988
196/196 - 32s - loss: 16.3511 - MinusLogProbMetric: 16.3511 - val_loss: 16.8969 - val_MinusLogProbMetric: 16.8969 - lr: 2.5000e-04 - 32s/epoch - 164ms/step
Epoch 393/1000
2023-09-27 03:55:06.155 
Epoch 393/1000 
	 loss: 16.3534, MinusLogProbMetric: 16.3534, val_loss: 16.8839, val_MinusLogProbMetric: 16.8839

Epoch 393: val_loss did not improve from 16.86988
196/196 - 32s - loss: 16.3534 - MinusLogProbMetric: 16.3534 - val_loss: 16.8839 - val_MinusLogProbMetric: 16.8839 - lr: 2.5000e-04 - 32s/epoch - 163ms/step
Epoch 394/1000
2023-09-27 03:55:38.308 
Epoch 394/1000 
	 loss: 16.3489, MinusLogProbMetric: 16.3489, val_loss: 16.8918, val_MinusLogProbMetric: 16.8918

Epoch 394: val_loss did not improve from 16.86988
196/196 - 32s - loss: 16.3489 - MinusLogProbMetric: 16.3489 - val_loss: 16.8918 - val_MinusLogProbMetric: 16.8918 - lr: 2.5000e-04 - 32s/epoch - 164ms/step
Epoch 395/1000
2023-09-27 03:56:09.701 
Epoch 395/1000 
	 loss: 16.3567, MinusLogProbMetric: 16.3567, val_loss: 16.8693, val_MinusLogProbMetric: 16.8693

Epoch 395: val_loss improved from 16.86988 to 16.86929, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 32s - loss: 16.3567 - MinusLogProbMetric: 16.3567 - val_loss: 16.8693 - val_MinusLogProbMetric: 16.8693 - lr: 2.5000e-04 - 32s/epoch - 164ms/step
Epoch 396/1000
2023-09-27 03:56:42.337 
Epoch 396/1000 
	 loss: 16.3526, MinusLogProbMetric: 16.3526, val_loss: 16.8907, val_MinusLogProbMetric: 16.8907

Epoch 396: val_loss did not improve from 16.86929
196/196 - 32s - loss: 16.3526 - MinusLogProbMetric: 16.3526 - val_loss: 16.8907 - val_MinusLogProbMetric: 16.8907 - lr: 2.5000e-04 - 32s/epoch - 163ms/step
Epoch 397/1000
2023-09-27 03:57:14.161 
Epoch 397/1000 
	 loss: 16.3503, MinusLogProbMetric: 16.3503, val_loss: 16.9089, val_MinusLogProbMetric: 16.9089

Epoch 397: val_loss did not improve from 16.86929
196/196 - 32s - loss: 16.3503 - MinusLogProbMetric: 16.3503 - val_loss: 16.9089 - val_MinusLogProbMetric: 16.9089 - lr: 2.5000e-04 - 32s/epoch - 162ms/step
Epoch 398/1000
2023-09-27 03:57:45.906 
Epoch 398/1000 
	 loss: 16.3577, MinusLogProbMetric: 16.3577, val_loss: 16.8763, val_MinusLogProbMetric: 16.8763

Epoch 398: val_loss did not improve from 16.86929
196/196 - 32s - loss: 16.3577 - MinusLogProbMetric: 16.3577 - val_loss: 16.8763 - val_MinusLogProbMetric: 16.8763 - lr: 2.5000e-04 - 32s/epoch - 162ms/step
Epoch 399/1000
2023-09-27 03:58:17.816 
Epoch 399/1000 
	 loss: 16.3548, MinusLogProbMetric: 16.3548, val_loss: 16.8858, val_MinusLogProbMetric: 16.8858

Epoch 399: val_loss did not improve from 16.86929
196/196 - 32s - loss: 16.3548 - MinusLogProbMetric: 16.3548 - val_loss: 16.8858 - val_MinusLogProbMetric: 16.8858 - lr: 2.5000e-04 - 32s/epoch - 163ms/step
Epoch 400/1000
2023-09-27 03:58:49.260 
Epoch 400/1000 
	 loss: 16.3548, MinusLogProbMetric: 16.3548, val_loss: 16.9604, val_MinusLogProbMetric: 16.9604

Epoch 400: val_loss did not improve from 16.86929
196/196 - 31s - loss: 16.3548 - MinusLogProbMetric: 16.3548 - val_loss: 16.9604 - val_MinusLogProbMetric: 16.9604 - lr: 2.5000e-04 - 31s/epoch - 160ms/step
Epoch 401/1000
2023-09-27 03:59:21.105 
Epoch 401/1000 
	 loss: 16.3550, MinusLogProbMetric: 16.3550, val_loss: 16.9168, val_MinusLogProbMetric: 16.9168

Epoch 401: val_loss did not improve from 16.86929
196/196 - 32s - loss: 16.3550 - MinusLogProbMetric: 16.3550 - val_loss: 16.9168 - val_MinusLogProbMetric: 16.9168 - lr: 2.5000e-04 - 32s/epoch - 162ms/step
Epoch 402/1000
2023-09-27 03:59:52.890 
Epoch 402/1000 
	 loss: 16.3565, MinusLogProbMetric: 16.3565, val_loss: 16.9250, val_MinusLogProbMetric: 16.9250

Epoch 402: val_loss did not improve from 16.86929
196/196 - 32s - loss: 16.3565 - MinusLogProbMetric: 16.3565 - val_loss: 16.9250 - val_MinusLogProbMetric: 16.9250 - lr: 2.5000e-04 - 32s/epoch - 162ms/step
Epoch 403/1000
2023-09-27 04:00:24.718 
Epoch 403/1000 
	 loss: 16.3525, MinusLogProbMetric: 16.3525, val_loss: 16.8810, val_MinusLogProbMetric: 16.8810

Epoch 403: val_loss did not improve from 16.86929
196/196 - 32s - loss: 16.3525 - MinusLogProbMetric: 16.3525 - val_loss: 16.8810 - val_MinusLogProbMetric: 16.8810 - lr: 2.5000e-04 - 32s/epoch - 162ms/step
Epoch 404/1000
2023-09-27 04:00:56.609 
Epoch 404/1000 
	 loss: 16.3565, MinusLogProbMetric: 16.3565, val_loss: 16.8782, val_MinusLogProbMetric: 16.8782

Epoch 404: val_loss did not improve from 16.86929
196/196 - 32s - loss: 16.3565 - MinusLogProbMetric: 16.3565 - val_loss: 16.8782 - val_MinusLogProbMetric: 16.8782 - lr: 2.5000e-04 - 32s/epoch - 163ms/step
Epoch 405/1000
2023-09-27 04:01:28.454 
Epoch 405/1000 
	 loss: 16.3555, MinusLogProbMetric: 16.3555, val_loss: 16.8850, val_MinusLogProbMetric: 16.8850

Epoch 405: val_loss did not improve from 16.86929
196/196 - 32s - loss: 16.3555 - MinusLogProbMetric: 16.3555 - val_loss: 16.8850 - val_MinusLogProbMetric: 16.8850 - lr: 2.5000e-04 - 32s/epoch - 162ms/step
Epoch 406/1000
2023-09-27 04:02:00.697 
Epoch 406/1000 
	 loss: 16.3615, MinusLogProbMetric: 16.3615, val_loss: 16.9418, val_MinusLogProbMetric: 16.9418

Epoch 406: val_loss did not improve from 16.86929
196/196 - 32s - loss: 16.3615 - MinusLogProbMetric: 16.3615 - val_loss: 16.9418 - val_MinusLogProbMetric: 16.9418 - lr: 2.5000e-04 - 32s/epoch - 164ms/step
Epoch 407/1000
2023-09-27 04:02:32.533 
Epoch 407/1000 
	 loss: 16.3623, MinusLogProbMetric: 16.3623, val_loss: 16.8992, val_MinusLogProbMetric: 16.8992

Epoch 407: val_loss did not improve from 16.86929
196/196 - 32s - loss: 16.3623 - MinusLogProbMetric: 16.3623 - val_loss: 16.8992 - val_MinusLogProbMetric: 16.8992 - lr: 2.5000e-04 - 32s/epoch - 162ms/step
Epoch 408/1000
2023-09-27 04:03:04.423 
Epoch 408/1000 
	 loss: 16.3472, MinusLogProbMetric: 16.3472, val_loss: 16.8685, val_MinusLogProbMetric: 16.8685

Epoch 408: val_loss improved from 16.86929 to 16.86853, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 32s - loss: 16.3472 - MinusLogProbMetric: 16.3472 - val_loss: 16.8685 - val_MinusLogProbMetric: 16.8685 - lr: 2.5000e-04 - 32s/epoch - 165ms/step
Epoch 409/1000
2023-09-27 04:03:36.827 
Epoch 409/1000 
	 loss: 16.3444, MinusLogProbMetric: 16.3444, val_loss: 16.8873, val_MinusLogProbMetric: 16.8873

Epoch 409: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3444 - MinusLogProbMetric: 16.3444 - val_loss: 16.8873 - val_MinusLogProbMetric: 16.8873 - lr: 2.5000e-04 - 32s/epoch - 163ms/step
Epoch 410/1000
2023-09-27 04:04:08.852 
Epoch 410/1000 
	 loss: 16.3484, MinusLogProbMetric: 16.3484, val_loss: 16.9007, val_MinusLogProbMetric: 16.9007

Epoch 410: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3484 - MinusLogProbMetric: 16.3484 - val_loss: 16.9007 - val_MinusLogProbMetric: 16.9007 - lr: 2.5000e-04 - 32s/epoch - 163ms/step
Epoch 411/1000
2023-09-27 04:04:41.033 
Epoch 411/1000 
	 loss: 16.3483, MinusLogProbMetric: 16.3483, val_loss: 16.9008, val_MinusLogProbMetric: 16.9008

Epoch 411: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3483 - MinusLogProbMetric: 16.3483 - val_loss: 16.9008 - val_MinusLogProbMetric: 16.9008 - lr: 2.5000e-04 - 32s/epoch - 164ms/step
Epoch 412/1000
2023-09-27 04:05:13.063 
Epoch 412/1000 
	 loss: 16.3472, MinusLogProbMetric: 16.3472, val_loss: 16.8769, val_MinusLogProbMetric: 16.8769

Epoch 412: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3472 - MinusLogProbMetric: 16.3472 - val_loss: 16.8769 - val_MinusLogProbMetric: 16.8769 - lr: 2.5000e-04 - 32s/epoch - 163ms/step
Epoch 413/1000
2023-09-27 04:05:45.000 
Epoch 413/1000 
	 loss: 16.3467, MinusLogProbMetric: 16.3467, val_loss: 16.8852, val_MinusLogProbMetric: 16.8852

Epoch 413: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3467 - MinusLogProbMetric: 16.3467 - val_loss: 16.8852 - val_MinusLogProbMetric: 16.8852 - lr: 2.5000e-04 - 32s/epoch - 163ms/step
Epoch 414/1000
2023-09-27 04:06:16.874 
Epoch 414/1000 
	 loss: 16.3509, MinusLogProbMetric: 16.3509, val_loss: 16.8798, val_MinusLogProbMetric: 16.8798

Epoch 414: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3509 - MinusLogProbMetric: 16.3509 - val_loss: 16.8798 - val_MinusLogProbMetric: 16.8798 - lr: 2.5000e-04 - 32s/epoch - 163ms/step
Epoch 415/1000
2023-09-27 04:06:48.714 
Epoch 415/1000 
	 loss: 16.3529, MinusLogProbMetric: 16.3529, val_loss: 16.9700, val_MinusLogProbMetric: 16.9700

Epoch 415: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3529 - MinusLogProbMetric: 16.3529 - val_loss: 16.9700 - val_MinusLogProbMetric: 16.9700 - lr: 2.5000e-04 - 32s/epoch - 162ms/step
Epoch 416/1000
2023-09-27 04:07:20.505 
Epoch 416/1000 
	 loss: 16.3469, MinusLogProbMetric: 16.3469, val_loss: 16.9656, val_MinusLogProbMetric: 16.9656

Epoch 416: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3469 - MinusLogProbMetric: 16.3469 - val_loss: 16.9656 - val_MinusLogProbMetric: 16.9656 - lr: 2.5000e-04 - 32s/epoch - 162ms/step
Epoch 417/1000
2023-09-27 04:07:52.282 
Epoch 417/1000 
	 loss: 16.3421, MinusLogProbMetric: 16.3421, val_loss: 16.9407, val_MinusLogProbMetric: 16.9407

Epoch 417: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3421 - MinusLogProbMetric: 16.3421 - val_loss: 16.9407 - val_MinusLogProbMetric: 16.9407 - lr: 2.5000e-04 - 32s/epoch - 162ms/step
Epoch 418/1000
2023-09-27 04:08:24.387 
Epoch 418/1000 
	 loss: 16.3563, MinusLogProbMetric: 16.3563, val_loss: 16.9005, val_MinusLogProbMetric: 16.9005

Epoch 418: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3563 - MinusLogProbMetric: 16.3563 - val_loss: 16.9005 - val_MinusLogProbMetric: 16.9005 - lr: 2.5000e-04 - 32s/epoch - 164ms/step
Epoch 419/1000
2023-09-27 04:08:56.382 
Epoch 419/1000 
	 loss: 16.3405, MinusLogProbMetric: 16.3405, val_loss: 16.9297, val_MinusLogProbMetric: 16.9297

Epoch 419: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3405 - MinusLogProbMetric: 16.3405 - val_loss: 16.9297 - val_MinusLogProbMetric: 16.9297 - lr: 2.5000e-04 - 32s/epoch - 163ms/step
Epoch 420/1000
2023-09-27 04:09:28.621 
Epoch 420/1000 
	 loss: 16.3505, MinusLogProbMetric: 16.3505, val_loss: 16.8820, val_MinusLogProbMetric: 16.8820

Epoch 420: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3505 - MinusLogProbMetric: 16.3505 - val_loss: 16.8820 - val_MinusLogProbMetric: 16.8820 - lr: 2.5000e-04 - 32s/epoch - 164ms/step
Epoch 421/1000
2023-09-27 04:10:00.559 
Epoch 421/1000 
	 loss: 16.3401, MinusLogProbMetric: 16.3401, val_loss: 16.8790, val_MinusLogProbMetric: 16.8790

Epoch 421: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3401 - MinusLogProbMetric: 16.3401 - val_loss: 16.8790 - val_MinusLogProbMetric: 16.8790 - lr: 2.5000e-04 - 32s/epoch - 163ms/step
Epoch 422/1000
2023-09-27 04:10:32.647 
Epoch 422/1000 
	 loss: 16.3415, MinusLogProbMetric: 16.3415, val_loss: 16.8988, val_MinusLogProbMetric: 16.8988

Epoch 422: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3415 - MinusLogProbMetric: 16.3415 - val_loss: 16.8988 - val_MinusLogProbMetric: 16.8988 - lr: 2.5000e-04 - 32s/epoch - 164ms/step
Epoch 423/1000
2023-09-27 04:11:04.800 
Epoch 423/1000 
	 loss: 16.5898, MinusLogProbMetric: 16.5898, val_loss: 16.8933, val_MinusLogProbMetric: 16.8933

Epoch 423: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.5898 - MinusLogProbMetric: 16.5898 - val_loss: 16.8933 - val_MinusLogProbMetric: 16.8933 - lr: 2.5000e-04 - 32s/epoch - 164ms/step
Epoch 424/1000
2023-09-27 04:11:36.706 
Epoch 424/1000 
	 loss: 16.3583, MinusLogProbMetric: 16.3583, val_loss: 16.9498, val_MinusLogProbMetric: 16.9498

Epoch 424: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3583 - MinusLogProbMetric: 16.3583 - val_loss: 16.9498 - val_MinusLogProbMetric: 16.9498 - lr: 2.5000e-04 - 32s/epoch - 163ms/step
Epoch 425/1000
2023-09-27 04:12:08.322 
Epoch 425/1000 
	 loss: 16.3442, MinusLogProbMetric: 16.3442, val_loss: 16.9233, val_MinusLogProbMetric: 16.9233

Epoch 425: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3442 - MinusLogProbMetric: 16.3442 - val_loss: 16.9233 - val_MinusLogProbMetric: 16.9233 - lr: 2.5000e-04 - 32s/epoch - 161ms/step
Epoch 426/1000
2023-09-27 04:12:40.580 
Epoch 426/1000 
	 loss: 16.3420, MinusLogProbMetric: 16.3420, val_loss: 16.8767, val_MinusLogProbMetric: 16.8767

Epoch 426: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3420 - MinusLogProbMetric: 16.3420 - val_loss: 16.8767 - val_MinusLogProbMetric: 16.8767 - lr: 2.5000e-04 - 32s/epoch - 165ms/step
Epoch 427/1000
2023-09-27 04:13:13.151 
Epoch 427/1000 
	 loss: 16.3510, MinusLogProbMetric: 16.3510, val_loss: 16.8888, val_MinusLogProbMetric: 16.8888

Epoch 427: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3510 - MinusLogProbMetric: 16.3510 - val_loss: 16.8888 - val_MinusLogProbMetric: 16.8888 - lr: 2.5000e-04 - 33s/epoch - 166ms/step
Epoch 428/1000
2023-09-27 04:13:46.015 
Epoch 428/1000 
	 loss: 16.3396, MinusLogProbMetric: 16.3396, val_loss: 16.9237, val_MinusLogProbMetric: 16.9237

Epoch 428: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3396 - MinusLogProbMetric: 16.3396 - val_loss: 16.9237 - val_MinusLogProbMetric: 16.9237 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 429/1000
2023-09-27 04:14:18.974 
Epoch 429/1000 
	 loss: 16.3421, MinusLogProbMetric: 16.3421, val_loss: 16.8942, val_MinusLogProbMetric: 16.8942

Epoch 429: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3421 - MinusLogProbMetric: 16.3421 - val_loss: 16.8942 - val_MinusLogProbMetric: 16.8942 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 430/1000
2023-09-27 04:14:52.168 
Epoch 430/1000 
	 loss: 16.3412, MinusLogProbMetric: 16.3412, val_loss: 16.8887, val_MinusLogProbMetric: 16.8887

Epoch 430: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3412 - MinusLogProbMetric: 16.3412 - val_loss: 16.8887 - val_MinusLogProbMetric: 16.8887 - lr: 2.5000e-04 - 33s/epoch - 169ms/step
Epoch 431/1000
2023-09-27 04:15:24.923 
Epoch 431/1000 
	 loss: 16.3445, MinusLogProbMetric: 16.3445, val_loss: 16.9538, val_MinusLogProbMetric: 16.9538

Epoch 431: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3445 - MinusLogProbMetric: 16.3445 - val_loss: 16.9538 - val_MinusLogProbMetric: 16.9538 - lr: 2.5000e-04 - 33s/epoch - 167ms/step
Epoch 432/1000
2023-09-27 04:15:57.990 
Epoch 432/1000 
	 loss: 16.3446, MinusLogProbMetric: 16.3446, val_loss: 16.8803, val_MinusLogProbMetric: 16.8803

Epoch 432: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3446 - MinusLogProbMetric: 16.3446 - val_loss: 16.8803 - val_MinusLogProbMetric: 16.8803 - lr: 2.5000e-04 - 33s/epoch - 169ms/step
Epoch 433/1000
2023-09-27 04:16:31.160 
Epoch 433/1000 
	 loss: 16.3400, MinusLogProbMetric: 16.3400, val_loss: 16.9123, val_MinusLogProbMetric: 16.9123

Epoch 433: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3400 - MinusLogProbMetric: 16.3400 - val_loss: 16.9123 - val_MinusLogProbMetric: 16.9123 - lr: 2.5000e-04 - 33s/epoch - 169ms/step
Epoch 434/1000
2023-09-27 04:17:04.751 
Epoch 434/1000 
	 loss: 16.3585, MinusLogProbMetric: 16.3585, val_loss: 16.8774, val_MinusLogProbMetric: 16.8774

Epoch 434: val_loss did not improve from 16.86853
196/196 - 34s - loss: 16.3585 - MinusLogProbMetric: 16.3585 - val_loss: 16.8774 - val_MinusLogProbMetric: 16.8774 - lr: 2.5000e-04 - 34s/epoch - 171ms/step
Epoch 435/1000
2023-09-27 04:17:37.822 
Epoch 435/1000 
	 loss: 16.3436, MinusLogProbMetric: 16.3436, val_loss: 16.8839, val_MinusLogProbMetric: 16.8839

Epoch 435: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3436 - MinusLogProbMetric: 16.3436 - val_loss: 16.8839 - val_MinusLogProbMetric: 16.8839 - lr: 2.5000e-04 - 33s/epoch - 169ms/step
Epoch 436/1000
2023-09-27 04:18:11.552 
Epoch 436/1000 
	 loss: 16.3543, MinusLogProbMetric: 16.3543, val_loss: 16.9270, val_MinusLogProbMetric: 16.9270

Epoch 436: val_loss did not improve from 16.86853
196/196 - 34s - loss: 16.3543 - MinusLogProbMetric: 16.3543 - val_loss: 16.9270 - val_MinusLogProbMetric: 16.9270 - lr: 2.5000e-04 - 34s/epoch - 172ms/step
Epoch 437/1000
2023-09-27 04:18:44.560 
Epoch 437/1000 
	 loss: 16.3427, MinusLogProbMetric: 16.3427, val_loss: 16.9402, val_MinusLogProbMetric: 16.9402

Epoch 437: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3427 - MinusLogProbMetric: 16.3427 - val_loss: 16.9402 - val_MinusLogProbMetric: 16.9402 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 438/1000
2023-09-27 04:19:17.637 
Epoch 438/1000 
	 loss: 16.3398, MinusLogProbMetric: 16.3398, val_loss: 16.8796, val_MinusLogProbMetric: 16.8796

Epoch 438: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3398 - MinusLogProbMetric: 16.3398 - val_loss: 16.8796 - val_MinusLogProbMetric: 16.8796 - lr: 2.5000e-04 - 33s/epoch - 169ms/step
Epoch 439/1000
2023-09-27 04:19:50.664 
Epoch 439/1000 
	 loss: 16.3487, MinusLogProbMetric: 16.3487, val_loss: 16.8818, val_MinusLogProbMetric: 16.8818

Epoch 439: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3487 - MinusLogProbMetric: 16.3487 - val_loss: 16.8818 - val_MinusLogProbMetric: 16.8818 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 440/1000
2023-09-27 04:20:24.028 
Epoch 440/1000 
	 loss: 16.3358, MinusLogProbMetric: 16.3358, val_loss: 16.9150, val_MinusLogProbMetric: 16.9150

Epoch 440: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3358 - MinusLogProbMetric: 16.3358 - val_loss: 16.9150 - val_MinusLogProbMetric: 16.9150 - lr: 2.5000e-04 - 33s/epoch - 170ms/step
Epoch 441/1000
2023-09-27 04:20:56.041 
Epoch 441/1000 
	 loss: 16.3438, MinusLogProbMetric: 16.3438, val_loss: 16.9051, val_MinusLogProbMetric: 16.9051

Epoch 441: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3438 - MinusLogProbMetric: 16.3438 - val_loss: 16.9051 - val_MinusLogProbMetric: 16.9051 - lr: 2.5000e-04 - 32s/epoch - 163ms/step
Epoch 442/1000
2023-09-27 04:21:29.501 
Epoch 442/1000 
	 loss: 16.3470, MinusLogProbMetric: 16.3470, val_loss: 16.9045, val_MinusLogProbMetric: 16.9045

Epoch 442: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3470 - MinusLogProbMetric: 16.3470 - val_loss: 16.9045 - val_MinusLogProbMetric: 16.9045 - lr: 2.5000e-04 - 33s/epoch - 171ms/step
Epoch 443/1000
2023-09-27 04:22:02.326 
Epoch 443/1000 
	 loss: 16.3415, MinusLogProbMetric: 16.3415, val_loss: 16.8828, val_MinusLogProbMetric: 16.8828

Epoch 443: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3415 - MinusLogProbMetric: 16.3415 - val_loss: 16.8828 - val_MinusLogProbMetric: 16.8828 - lr: 2.5000e-04 - 33s/epoch - 167ms/step
Epoch 444/1000
2023-09-27 04:22:34.457 
Epoch 444/1000 
	 loss: 16.3463, MinusLogProbMetric: 16.3463, val_loss: 16.8986, val_MinusLogProbMetric: 16.8986

Epoch 444: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3463 - MinusLogProbMetric: 16.3463 - val_loss: 16.8986 - val_MinusLogProbMetric: 16.8986 - lr: 2.5000e-04 - 32s/epoch - 164ms/step
Epoch 445/1000
2023-09-27 04:23:06.346 
Epoch 445/1000 
	 loss: 16.3386, MinusLogProbMetric: 16.3386, val_loss: 16.9384, val_MinusLogProbMetric: 16.9384

Epoch 445: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3386 - MinusLogProbMetric: 16.3386 - val_loss: 16.9384 - val_MinusLogProbMetric: 16.9384 - lr: 2.5000e-04 - 32s/epoch - 163ms/step
Epoch 446/1000
2023-09-27 04:23:38.514 
Epoch 446/1000 
	 loss: 16.3380, MinusLogProbMetric: 16.3380, val_loss: 16.8856, val_MinusLogProbMetric: 16.8856

Epoch 446: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3380 - MinusLogProbMetric: 16.3380 - val_loss: 16.8856 - val_MinusLogProbMetric: 16.8856 - lr: 2.5000e-04 - 32s/epoch - 164ms/step
Epoch 447/1000
2023-09-27 04:24:10.754 
Epoch 447/1000 
	 loss: 16.3437, MinusLogProbMetric: 16.3437, val_loss: 16.9012, val_MinusLogProbMetric: 16.9012

Epoch 447: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3437 - MinusLogProbMetric: 16.3437 - val_loss: 16.9012 - val_MinusLogProbMetric: 16.9012 - lr: 2.5000e-04 - 32s/epoch - 164ms/step
Epoch 448/1000
2023-09-27 04:24:42.833 
Epoch 448/1000 
	 loss: 16.3398, MinusLogProbMetric: 16.3398, val_loss: 16.9161, val_MinusLogProbMetric: 16.9161

Epoch 448: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3398 - MinusLogProbMetric: 16.3398 - val_loss: 16.9161 - val_MinusLogProbMetric: 16.9161 - lr: 2.5000e-04 - 32s/epoch - 164ms/step
Epoch 449/1000
2023-09-27 04:25:14.851 
Epoch 449/1000 
	 loss: 16.3614, MinusLogProbMetric: 16.3614, val_loss: 16.9009, val_MinusLogProbMetric: 16.9009

Epoch 449: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3614 - MinusLogProbMetric: 16.3614 - val_loss: 16.9009 - val_MinusLogProbMetric: 16.9009 - lr: 2.5000e-04 - 32s/epoch - 163ms/step
Epoch 450/1000
2023-09-27 04:25:46.820 
Epoch 450/1000 
	 loss: 16.3425, MinusLogProbMetric: 16.3425, val_loss: 16.9327, val_MinusLogProbMetric: 16.9327

Epoch 450: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3425 - MinusLogProbMetric: 16.3425 - val_loss: 16.9327 - val_MinusLogProbMetric: 16.9327 - lr: 2.5000e-04 - 32s/epoch - 163ms/step
Epoch 451/1000
2023-09-27 04:26:19.417 
Epoch 451/1000 
	 loss: 16.3437, MinusLogProbMetric: 16.3437, val_loss: 16.8863, val_MinusLogProbMetric: 16.8863

Epoch 451: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3437 - MinusLogProbMetric: 16.3437 - val_loss: 16.8863 - val_MinusLogProbMetric: 16.8863 - lr: 2.5000e-04 - 33s/epoch - 166ms/step
Epoch 452/1000
2023-09-27 04:26:52.020 
Epoch 452/1000 
	 loss: 16.3371, MinusLogProbMetric: 16.3371, val_loss: 16.9042, val_MinusLogProbMetric: 16.9042

Epoch 452: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3371 - MinusLogProbMetric: 16.3371 - val_loss: 16.9042 - val_MinusLogProbMetric: 16.9042 - lr: 2.5000e-04 - 33s/epoch - 166ms/step
Epoch 453/1000
2023-09-27 04:27:23.880 
Epoch 453/1000 
	 loss: 16.3367, MinusLogProbMetric: 16.3367, val_loss: 16.9504, val_MinusLogProbMetric: 16.9504

Epoch 453: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3367 - MinusLogProbMetric: 16.3367 - val_loss: 16.9504 - val_MinusLogProbMetric: 16.9504 - lr: 2.5000e-04 - 32s/epoch - 163ms/step
Epoch 454/1000
2023-09-27 04:27:55.771 
Epoch 454/1000 
	 loss: 16.3471, MinusLogProbMetric: 16.3471, val_loss: 16.9114, val_MinusLogProbMetric: 16.9114

Epoch 454: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3471 - MinusLogProbMetric: 16.3471 - val_loss: 16.9114 - val_MinusLogProbMetric: 16.9114 - lr: 2.5000e-04 - 32s/epoch - 163ms/step
Epoch 455/1000
2023-09-27 04:28:27.999 
Epoch 455/1000 
	 loss: 16.3358, MinusLogProbMetric: 16.3358, val_loss: 16.9274, val_MinusLogProbMetric: 16.9274

Epoch 455: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3358 - MinusLogProbMetric: 16.3358 - val_loss: 16.9274 - val_MinusLogProbMetric: 16.9274 - lr: 2.5000e-04 - 32s/epoch - 164ms/step
Epoch 456/1000
2023-09-27 04:28:59.778 
Epoch 456/1000 
	 loss: 16.3398, MinusLogProbMetric: 16.3398, val_loss: 16.8866, val_MinusLogProbMetric: 16.8866

Epoch 456: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3398 - MinusLogProbMetric: 16.3398 - val_loss: 16.8866 - val_MinusLogProbMetric: 16.8866 - lr: 2.5000e-04 - 32s/epoch - 162ms/step
Epoch 457/1000
2023-09-27 04:29:31.907 
Epoch 457/1000 
	 loss: 16.3426, MinusLogProbMetric: 16.3426, val_loss: 16.8871, val_MinusLogProbMetric: 16.8871

Epoch 457: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3426 - MinusLogProbMetric: 16.3426 - val_loss: 16.8871 - val_MinusLogProbMetric: 16.8871 - lr: 2.5000e-04 - 32s/epoch - 164ms/step
Epoch 458/1000
2023-09-27 04:30:03.874 
Epoch 458/1000 
	 loss: 16.3318, MinusLogProbMetric: 16.3318, val_loss: 16.9194, val_MinusLogProbMetric: 16.9194

Epoch 458: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3318 - MinusLogProbMetric: 16.3318 - val_loss: 16.9194 - val_MinusLogProbMetric: 16.9194 - lr: 2.5000e-04 - 32s/epoch - 163ms/step
Epoch 459/1000
2023-09-27 04:30:35.800 
Epoch 459/1000 
	 loss: 16.3018, MinusLogProbMetric: 16.3018, val_loss: 16.8934, val_MinusLogProbMetric: 16.8934

Epoch 459: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3018 - MinusLogProbMetric: 16.3018 - val_loss: 16.8934 - val_MinusLogProbMetric: 16.8934 - lr: 1.2500e-04 - 32s/epoch - 163ms/step
Epoch 460/1000
2023-09-27 04:31:08.048 
Epoch 460/1000 
	 loss: 16.3039, MinusLogProbMetric: 16.3039, val_loss: 16.8936, val_MinusLogProbMetric: 16.8936

Epoch 460: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3039 - MinusLogProbMetric: 16.3039 - val_loss: 16.8936 - val_MinusLogProbMetric: 16.8936 - lr: 1.2500e-04 - 32s/epoch - 165ms/step
Epoch 461/1000
2023-09-27 04:31:39.847 
Epoch 461/1000 
	 loss: 16.3019, MinusLogProbMetric: 16.3019, val_loss: 16.8724, val_MinusLogProbMetric: 16.8724

Epoch 461: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3019 - MinusLogProbMetric: 16.3019 - val_loss: 16.8724 - val_MinusLogProbMetric: 16.8724 - lr: 1.2500e-04 - 32s/epoch - 162ms/step
Epoch 462/1000
2023-09-27 04:32:11.839 
Epoch 462/1000 
	 loss: 16.2998, MinusLogProbMetric: 16.2998, val_loss: 16.8881, val_MinusLogProbMetric: 16.8881

Epoch 462: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.2998 - MinusLogProbMetric: 16.2998 - val_loss: 16.8881 - val_MinusLogProbMetric: 16.8881 - lr: 1.2500e-04 - 32s/epoch - 163ms/step
Epoch 463/1000
2023-09-27 04:32:43.553 
Epoch 463/1000 
	 loss: 16.3044, MinusLogProbMetric: 16.3044, val_loss: 16.8718, val_MinusLogProbMetric: 16.8718

Epoch 463: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3044 - MinusLogProbMetric: 16.3044 - val_loss: 16.8718 - val_MinusLogProbMetric: 16.8718 - lr: 1.2500e-04 - 32s/epoch - 162ms/step
Epoch 464/1000
2023-09-27 04:33:15.338 
Epoch 464/1000 
	 loss: 16.3019, MinusLogProbMetric: 16.3019, val_loss: 16.9080, val_MinusLogProbMetric: 16.9080

Epoch 464: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3019 - MinusLogProbMetric: 16.3019 - val_loss: 16.9080 - val_MinusLogProbMetric: 16.9080 - lr: 1.2500e-04 - 32s/epoch - 162ms/step
Epoch 465/1000
2023-09-27 04:33:47.391 
Epoch 465/1000 
	 loss: 16.3098, MinusLogProbMetric: 16.3098, val_loss: 16.9258, val_MinusLogProbMetric: 16.9258

Epoch 465: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3098 - MinusLogProbMetric: 16.3098 - val_loss: 16.9258 - val_MinusLogProbMetric: 16.9258 - lr: 1.2500e-04 - 32s/epoch - 164ms/step
Epoch 466/1000
2023-09-27 04:34:18.989 
Epoch 466/1000 
	 loss: 16.3084, MinusLogProbMetric: 16.3084, val_loss: 16.8920, val_MinusLogProbMetric: 16.8920

Epoch 466: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3084 - MinusLogProbMetric: 16.3084 - val_loss: 16.8920 - val_MinusLogProbMetric: 16.8920 - lr: 1.2500e-04 - 32s/epoch - 161ms/step
Epoch 467/1000
2023-09-27 04:34:50.711 
Epoch 467/1000 
	 loss: 16.3004, MinusLogProbMetric: 16.3004, val_loss: 16.8924, val_MinusLogProbMetric: 16.8924

Epoch 467: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3004 - MinusLogProbMetric: 16.3004 - val_loss: 16.8924 - val_MinusLogProbMetric: 16.8924 - lr: 1.2500e-04 - 32s/epoch - 162ms/step
Epoch 468/1000
2023-09-27 04:35:22.937 
Epoch 468/1000 
	 loss: 16.3077, MinusLogProbMetric: 16.3077, val_loss: 16.8846, val_MinusLogProbMetric: 16.8846

Epoch 468: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3077 - MinusLogProbMetric: 16.3077 - val_loss: 16.8846 - val_MinusLogProbMetric: 16.8846 - lr: 1.2500e-04 - 32s/epoch - 164ms/step
Epoch 469/1000
2023-09-27 04:35:54.789 
Epoch 469/1000 
	 loss: 16.2993, MinusLogProbMetric: 16.2993, val_loss: 16.8767, val_MinusLogProbMetric: 16.8767

Epoch 469: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.2993 - MinusLogProbMetric: 16.2993 - val_loss: 16.8767 - val_MinusLogProbMetric: 16.8767 - lr: 1.2500e-04 - 32s/epoch - 162ms/step
Epoch 470/1000
2023-09-27 04:36:26.910 
Epoch 470/1000 
	 loss: 16.3042, MinusLogProbMetric: 16.3042, val_loss: 16.9024, val_MinusLogProbMetric: 16.9024

Epoch 470: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3042 - MinusLogProbMetric: 16.3042 - val_loss: 16.9024 - val_MinusLogProbMetric: 16.9024 - lr: 1.2500e-04 - 32s/epoch - 164ms/step
Epoch 471/1000
2023-09-27 04:36:59.061 
Epoch 471/1000 
	 loss: 16.2992, MinusLogProbMetric: 16.2992, val_loss: 16.8875, val_MinusLogProbMetric: 16.8875

Epoch 471: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.2992 - MinusLogProbMetric: 16.2992 - val_loss: 16.8875 - val_MinusLogProbMetric: 16.8875 - lr: 1.2500e-04 - 32s/epoch - 164ms/step
Epoch 472/1000
2023-09-27 04:37:30.885 
Epoch 472/1000 
	 loss: 16.3010, MinusLogProbMetric: 16.3010, val_loss: 16.8811, val_MinusLogProbMetric: 16.8811

Epoch 472: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3010 - MinusLogProbMetric: 16.3010 - val_loss: 16.8811 - val_MinusLogProbMetric: 16.8811 - lr: 1.2500e-04 - 32s/epoch - 162ms/step
Epoch 473/1000
2023-09-27 04:38:03.023 
Epoch 473/1000 
	 loss: 16.3037, MinusLogProbMetric: 16.3037, val_loss: 16.8994, val_MinusLogProbMetric: 16.8994

Epoch 473: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3037 - MinusLogProbMetric: 16.3037 - val_loss: 16.8994 - val_MinusLogProbMetric: 16.8994 - lr: 1.2500e-04 - 32s/epoch - 164ms/step
Epoch 474/1000
2023-09-27 04:38:34.925 
Epoch 474/1000 
	 loss: 16.2980, MinusLogProbMetric: 16.2980, val_loss: 16.8839, val_MinusLogProbMetric: 16.8839

Epoch 474: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.2980 - MinusLogProbMetric: 16.2980 - val_loss: 16.8839 - val_MinusLogProbMetric: 16.8839 - lr: 1.2500e-04 - 32s/epoch - 163ms/step
Epoch 475/1000
2023-09-27 04:39:06.713 
Epoch 475/1000 
	 loss: 16.3059, MinusLogProbMetric: 16.3059, val_loss: 16.8877, val_MinusLogProbMetric: 16.8877

Epoch 475: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3059 - MinusLogProbMetric: 16.3059 - val_loss: 16.8877 - val_MinusLogProbMetric: 16.8877 - lr: 1.2500e-04 - 32s/epoch - 162ms/step
Epoch 476/1000
2023-09-27 04:39:38.957 
Epoch 476/1000 
	 loss: 16.3031, MinusLogProbMetric: 16.3031, val_loss: 16.8838, val_MinusLogProbMetric: 16.8838

Epoch 476: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3031 - MinusLogProbMetric: 16.3031 - val_loss: 16.8838 - val_MinusLogProbMetric: 16.8838 - lr: 1.2500e-04 - 32s/epoch - 164ms/step
Epoch 477/1000
2023-09-27 04:40:11.596 
Epoch 477/1000 
	 loss: 16.2964, MinusLogProbMetric: 16.2964, val_loss: 16.8795, val_MinusLogProbMetric: 16.8795

Epoch 477: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.2964 - MinusLogProbMetric: 16.2964 - val_loss: 16.8795 - val_MinusLogProbMetric: 16.8795 - lr: 1.2500e-04 - 33s/epoch - 167ms/step
Epoch 478/1000
2023-09-27 04:40:43.178 
Epoch 478/1000 
	 loss: 16.2999, MinusLogProbMetric: 16.2999, val_loss: 16.8838, val_MinusLogProbMetric: 16.8838

Epoch 478: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.2999 - MinusLogProbMetric: 16.2999 - val_loss: 16.8838 - val_MinusLogProbMetric: 16.8838 - lr: 1.2500e-04 - 32s/epoch - 161ms/step
Epoch 479/1000
2023-09-27 04:41:15.117 
Epoch 479/1000 
	 loss: 16.3020, MinusLogProbMetric: 16.3020, val_loss: 16.8841, val_MinusLogProbMetric: 16.8841

Epoch 479: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3020 - MinusLogProbMetric: 16.3020 - val_loss: 16.8841 - val_MinusLogProbMetric: 16.8841 - lr: 1.2500e-04 - 32s/epoch - 163ms/step
Epoch 480/1000
2023-09-27 04:41:47.721 
Epoch 480/1000 
	 loss: 16.2979, MinusLogProbMetric: 16.2979, val_loss: 16.9055, val_MinusLogProbMetric: 16.9055

Epoch 480: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.2979 - MinusLogProbMetric: 16.2979 - val_loss: 16.9055 - val_MinusLogProbMetric: 16.9055 - lr: 1.2500e-04 - 33s/epoch - 166ms/step
Epoch 481/1000
2023-09-27 04:42:19.827 
Epoch 481/1000 
	 loss: 16.3006, MinusLogProbMetric: 16.3006, val_loss: 16.9092, val_MinusLogProbMetric: 16.9092

Epoch 481: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3006 - MinusLogProbMetric: 16.3006 - val_loss: 16.9092 - val_MinusLogProbMetric: 16.9092 - lr: 1.2500e-04 - 32s/epoch - 164ms/step
Epoch 482/1000
2023-09-27 04:42:52.553 
Epoch 482/1000 
	 loss: 16.2961, MinusLogProbMetric: 16.2961, val_loss: 16.8923, val_MinusLogProbMetric: 16.8923

Epoch 482: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.2961 - MinusLogProbMetric: 16.2961 - val_loss: 16.8923 - val_MinusLogProbMetric: 16.8923 - lr: 1.2500e-04 - 33s/epoch - 167ms/step
Epoch 483/1000
2023-09-27 04:43:25.367 
Epoch 483/1000 
	 loss: 16.3036, MinusLogProbMetric: 16.3036, val_loss: 16.8831, val_MinusLogProbMetric: 16.8831

Epoch 483: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3036 - MinusLogProbMetric: 16.3036 - val_loss: 16.8831 - val_MinusLogProbMetric: 16.8831 - lr: 1.2500e-04 - 33s/epoch - 167ms/step
Epoch 484/1000
2023-09-27 04:43:58.954 
Epoch 484/1000 
	 loss: 16.2958, MinusLogProbMetric: 16.2958, val_loss: 16.8824, val_MinusLogProbMetric: 16.8824

Epoch 484: val_loss did not improve from 16.86853
196/196 - 34s - loss: 16.2958 - MinusLogProbMetric: 16.2958 - val_loss: 16.8824 - val_MinusLogProbMetric: 16.8824 - lr: 1.2500e-04 - 34s/epoch - 171ms/step
Epoch 485/1000
2023-09-27 04:44:31.977 
Epoch 485/1000 
	 loss: 16.3001, MinusLogProbMetric: 16.3001, val_loss: 16.9028, val_MinusLogProbMetric: 16.9028

Epoch 485: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3001 - MinusLogProbMetric: 16.3001 - val_loss: 16.9028 - val_MinusLogProbMetric: 16.9028 - lr: 1.2500e-04 - 33s/epoch - 168ms/step
Epoch 486/1000
2023-09-27 04:45:05.940 
Epoch 486/1000 
	 loss: 16.3009, MinusLogProbMetric: 16.3009, val_loss: 16.9092, val_MinusLogProbMetric: 16.9092

Epoch 486: val_loss did not improve from 16.86853
196/196 - 34s - loss: 16.3009 - MinusLogProbMetric: 16.3009 - val_loss: 16.9092 - val_MinusLogProbMetric: 16.9092 - lr: 1.2500e-04 - 34s/epoch - 173ms/step
Epoch 487/1000
2023-09-27 04:45:39.260 
Epoch 487/1000 
	 loss: 16.3016, MinusLogProbMetric: 16.3016, val_loss: 16.8833, val_MinusLogProbMetric: 16.8833

Epoch 487: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3016 - MinusLogProbMetric: 16.3016 - val_loss: 16.8833 - val_MinusLogProbMetric: 16.8833 - lr: 1.2500e-04 - 33s/epoch - 170ms/step
Epoch 488/1000
2023-09-27 04:46:12.980 
Epoch 488/1000 
	 loss: 16.3025, MinusLogProbMetric: 16.3025, val_loss: 16.8908, val_MinusLogProbMetric: 16.8908

Epoch 488: val_loss did not improve from 16.86853
196/196 - 34s - loss: 16.3025 - MinusLogProbMetric: 16.3025 - val_loss: 16.8908 - val_MinusLogProbMetric: 16.8908 - lr: 1.2500e-04 - 34s/epoch - 172ms/step
Epoch 489/1000
2023-09-27 04:46:46.008 
Epoch 489/1000 
	 loss: 16.3053, MinusLogProbMetric: 16.3053, val_loss: 16.9827, val_MinusLogProbMetric: 16.9827

Epoch 489: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3053 - MinusLogProbMetric: 16.3053 - val_loss: 16.9827 - val_MinusLogProbMetric: 16.9827 - lr: 1.2500e-04 - 33s/epoch - 168ms/step
Epoch 490/1000
2023-09-27 04:47:18.374 
Epoch 490/1000 
	 loss: 16.2979, MinusLogProbMetric: 16.2979, val_loss: 16.9059, val_MinusLogProbMetric: 16.9059

Epoch 490: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.2979 - MinusLogProbMetric: 16.2979 - val_loss: 16.9059 - val_MinusLogProbMetric: 16.9059 - lr: 1.2500e-04 - 32s/epoch - 165ms/step
Epoch 491/1000
2023-09-27 04:47:51.198 
Epoch 491/1000 
	 loss: 16.2992, MinusLogProbMetric: 16.2992, val_loss: 16.8917, val_MinusLogProbMetric: 16.8917

Epoch 491: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.2992 - MinusLogProbMetric: 16.2992 - val_loss: 16.8917 - val_MinusLogProbMetric: 16.8917 - lr: 1.2500e-04 - 33s/epoch - 167ms/step
Epoch 492/1000
2023-09-27 04:48:23.774 
Epoch 492/1000 
	 loss: 16.2996, MinusLogProbMetric: 16.2996, val_loss: 16.9066, val_MinusLogProbMetric: 16.9066

Epoch 492: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.2996 - MinusLogProbMetric: 16.2996 - val_loss: 16.9066 - val_MinusLogProbMetric: 16.9066 - lr: 1.2500e-04 - 33s/epoch - 166ms/step
Epoch 493/1000
2023-09-27 04:48:55.900 
Epoch 493/1000 
	 loss: 16.3069, MinusLogProbMetric: 16.3069, val_loss: 16.8861, val_MinusLogProbMetric: 16.8861

Epoch 493: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3069 - MinusLogProbMetric: 16.3069 - val_loss: 16.8861 - val_MinusLogProbMetric: 16.8861 - lr: 1.2500e-04 - 32s/epoch - 164ms/step
Epoch 494/1000
2023-09-27 04:49:27.994 
Epoch 494/1000 
	 loss: 16.2994, MinusLogProbMetric: 16.2994, val_loss: 16.8994, val_MinusLogProbMetric: 16.8994

Epoch 494: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.2994 - MinusLogProbMetric: 16.2994 - val_loss: 16.8994 - val_MinusLogProbMetric: 16.8994 - lr: 1.2500e-04 - 32s/epoch - 164ms/step
Epoch 495/1000
2023-09-27 04:50:00.507 
Epoch 495/1000 
	 loss: 16.3006, MinusLogProbMetric: 16.3006, val_loss: 16.8765, val_MinusLogProbMetric: 16.8765

Epoch 495: val_loss did not improve from 16.86853
196/196 - 33s - loss: 16.3006 - MinusLogProbMetric: 16.3006 - val_loss: 16.8765 - val_MinusLogProbMetric: 16.8765 - lr: 1.2500e-04 - 33s/epoch - 166ms/step
Epoch 496/1000
2023-09-27 04:50:32.810 
Epoch 496/1000 
	 loss: 16.2980, MinusLogProbMetric: 16.2980, val_loss: 16.9059, val_MinusLogProbMetric: 16.9059

Epoch 496: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.2980 - MinusLogProbMetric: 16.2980 - val_loss: 16.9059 - val_MinusLogProbMetric: 16.9059 - lr: 1.2500e-04 - 32s/epoch - 165ms/step
Epoch 497/1000
2023-09-27 04:51:04.557 
Epoch 497/1000 
	 loss: 16.2996, MinusLogProbMetric: 16.2996, val_loss: 16.8841, val_MinusLogProbMetric: 16.8841

Epoch 497: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.2996 - MinusLogProbMetric: 16.2996 - val_loss: 16.8841 - val_MinusLogProbMetric: 16.8841 - lr: 1.2500e-04 - 32s/epoch - 162ms/step
Epoch 498/1000
2023-09-27 04:51:36.714 
Epoch 498/1000 
	 loss: 16.3024, MinusLogProbMetric: 16.3024, val_loss: 16.8790, val_MinusLogProbMetric: 16.8790

Epoch 498: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.3024 - MinusLogProbMetric: 16.3024 - val_loss: 16.8790 - val_MinusLogProbMetric: 16.8790 - lr: 1.2500e-04 - 32s/epoch - 164ms/step
Epoch 499/1000
2023-09-27 04:52:08.473 
Epoch 499/1000 
	 loss: 16.2961, MinusLogProbMetric: 16.2961, val_loss: 16.8897, val_MinusLogProbMetric: 16.8897

Epoch 499: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.2961 - MinusLogProbMetric: 16.2961 - val_loss: 16.8897 - val_MinusLogProbMetric: 16.8897 - lr: 1.2500e-04 - 32s/epoch - 162ms/step
Epoch 500/1000
2023-09-27 04:52:40.570 
Epoch 500/1000 
	 loss: 16.2952, MinusLogProbMetric: 16.2952, val_loss: 16.8993, val_MinusLogProbMetric: 16.8993

Epoch 500: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.2952 - MinusLogProbMetric: 16.2952 - val_loss: 16.8993 - val_MinusLogProbMetric: 16.8993 - lr: 1.2500e-04 - 32s/epoch - 164ms/step
Epoch 501/1000
2023-09-27 04:53:12.476 
Epoch 501/1000 
	 loss: 16.2926, MinusLogProbMetric: 16.2926, val_loss: 16.8920, val_MinusLogProbMetric: 16.8920

Epoch 501: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.2926 - MinusLogProbMetric: 16.2926 - val_loss: 16.8920 - val_MinusLogProbMetric: 16.8920 - lr: 1.2500e-04 - 32s/epoch - 163ms/step
Epoch 502/1000
2023-09-27 04:53:44.318 
Epoch 502/1000 
	 loss: 16.2983, MinusLogProbMetric: 16.2983, val_loss: 16.8810, val_MinusLogProbMetric: 16.8810

Epoch 502: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.2983 - MinusLogProbMetric: 16.2983 - val_loss: 16.8810 - val_MinusLogProbMetric: 16.8810 - lr: 1.2500e-04 - 32s/epoch - 162ms/step
Epoch 503/1000
2023-09-27 04:54:15.816 
Epoch 503/1000 
	 loss: 16.3054, MinusLogProbMetric: 16.3054, val_loss: 16.9068, val_MinusLogProbMetric: 16.9068

Epoch 503: val_loss did not improve from 16.86853
196/196 - 31s - loss: 16.3054 - MinusLogProbMetric: 16.3054 - val_loss: 16.9068 - val_MinusLogProbMetric: 16.9068 - lr: 1.2500e-04 - 31s/epoch - 161ms/step
Epoch 504/1000
2023-09-27 04:54:47.685 
Epoch 504/1000 
	 loss: 16.2962, MinusLogProbMetric: 16.2962, val_loss: 16.8809, val_MinusLogProbMetric: 16.8809

Epoch 504: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.2962 - MinusLogProbMetric: 16.2962 - val_loss: 16.8809 - val_MinusLogProbMetric: 16.8809 - lr: 1.2500e-04 - 32s/epoch - 163ms/step
Epoch 505/1000
2023-09-27 04:55:19.411 
Epoch 505/1000 
	 loss: 16.2964, MinusLogProbMetric: 16.2964, val_loss: 16.9011, val_MinusLogProbMetric: 16.9011

Epoch 505: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.2964 - MinusLogProbMetric: 16.2964 - val_loss: 16.9011 - val_MinusLogProbMetric: 16.9011 - lr: 1.2500e-04 - 32s/epoch - 162ms/step
Epoch 506/1000
2023-09-27 04:55:51.627 
Epoch 506/1000 
	 loss: 16.2975, MinusLogProbMetric: 16.2975, val_loss: 16.8802, val_MinusLogProbMetric: 16.8802

Epoch 506: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.2975 - MinusLogProbMetric: 16.2975 - val_loss: 16.8802 - val_MinusLogProbMetric: 16.8802 - lr: 1.2500e-04 - 32s/epoch - 164ms/step
Epoch 507/1000
2023-09-27 04:56:23.706 
Epoch 507/1000 
	 loss: 16.2954, MinusLogProbMetric: 16.2954, val_loss: 16.8940, val_MinusLogProbMetric: 16.8940

Epoch 507: val_loss did not improve from 16.86853
196/196 - 32s - loss: 16.2954 - MinusLogProbMetric: 16.2954 - val_loss: 16.8940 - val_MinusLogProbMetric: 16.8940 - lr: 1.2500e-04 - 32s/epoch - 164ms/step
Epoch 508/1000
2023-09-27 04:56:55.524 
Epoch 508/1000 
	 loss: 16.2969, MinusLogProbMetric: 16.2969, val_loss: 16.9170, val_MinusLogProbMetric: 16.9170

Epoch 508: val_loss did not improve from 16.86853
Restoring model weights from the end of the best epoch: 408.
196/196 - 32s - loss: 16.2969 - MinusLogProbMetric: 16.2969 - val_loss: 16.9170 - val_MinusLogProbMetric: 16.9170 - lr: 1.2500e-04 - 32s/epoch - 164ms/step
Epoch 508: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
LR metric calculation completed in 11.886519577004947 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 7.903634556976613 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
SWD metric calculation completed in 5.244996514986269 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
FN metric calculation completed in 10.371284124033991 seconds.
Training succeeded with seed 869.
Model trained in 16333.07 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 36.54 s.
                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/c_Main_CsplineN.py , Line : 469, Func.Name : prediction_function, Message : Plotters.cornerplotter(X_data_test.numpy(),X_data_nf.numpy(),path_to_results,ndims,norm=True) # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 36.86 s.
===========
Run 297/720 done in 16373.89 s.
===========

Directory ../../results/CsplineN_new/run_298/ already exists.
Skipping it.
===========
Run 298/720 already exists. Skipping it.
===========

===========
Generating train data for run 299.
===========
Train data generated in 0.20 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_299/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 869}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_299/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.7724807 ,  3.5952213 ,  8.442487  , ...,  7.3644695 ,
         3.6588435 ,  2.0248146 ],
       [ 6.6242166 ,  7.1665483 ,  6.4277024 , ...,  3.1194153 ,
         2.6248946 ,  8.037665  ],
       [ 4.5211086 ,  5.2663136 , -0.6501303 , ...,  0.17722613,
         6.462096  ,  1.3170475 ],
       ...,
       [ 5.2085795 ,  5.348097  , -0.4658583 , ..., -0.03725696,
         5.9864964 ,  1.2388526 ],
       [ 3.9188156 ,  5.4859467 , -0.29968688, ...,  0.4149692 ,
         6.0867124 ,  1.4174792 ],
       [ 2.283803  ,  2.9701724 ,  8.729265  , ...,  6.0229187 ,
         3.2842712 ,  2.1182036 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_299/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_299
self.data_kwargs: {'seed': 869}
self.x_data: [[ 1.7417877   3.5044646   9.194398   ...  7.377848    2.8874114
   1.7757134 ]
 [ 3.8693519   4.134066    8.323213   ...  7.5259514   3.079576
   1.8540689 ]
 [ 2.7888105   3.5250566   6.8470335  ...  7.0512147   2.9893377
   1.7142482 ]
 ...
 [ 3.8914979   5.948059   -0.25578696 ...  1.7629418   6.8860593
   1.464444  ]
 [ 3.0775785   3.9001913   8.887795   ...  7.2041593   3.5200696
   1.5176823 ]
 [ 1.0419946   3.6002321   7.1163735  ...  7.3799496   3.218665
   1.6207042 ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_33"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_34 (InputLayer)       [(None, 32)]              0         
                                                                 
 log_prob_layer_3 (LogProbLa  (None,)                  537200    
 yer)                                                            
                                                                 
=================================================================
Total params: 537,200
Trainable params: 537,200
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_3/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_3'")
self.model: <keras.engine.functional.Functional object at 0x7fd9eebf3fa0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fd5d420e380>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fd5d420e380>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fd9f6ffd780>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fd42c1b2260>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fd42c1b37c0>, <keras.callbacks.ModelCheckpoint object at 0x7fd42c1b3a30>, <keras.callbacks.EarlyStopping object at 0x7fd42c1b3430>, <keras.callbacks.ReduceLROnPlateau object at 0x7fd42c1b30a0>, <keras.callbacks.TerminateOnNaN object at 0x7fd42c1b3580>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.7724807 ,  3.5952213 ,  8.442487  , ...,  7.3644695 ,
         3.6588435 ,  2.0248146 ],
       [ 6.6242166 ,  7.1665483 ,  6.4277024 , ...,  3.1194153 ,
         2.6248946 ,  8.037665  ],
       [ 4.5211086 ,  5.2663136 , -0.6501303 , ...,  0.17722613,
         6.462096  ,  1.3170475 ],
       ...,
       [ 5.2085795 ,  5.348097  , -0.4658583 , ..., -0.03725696,
         5.9864964 ,  1.2388526 ],
       [ 3.9188156 ,  5.4859467 , -0.29968688, ...,  0.4149692 ,
         6.0867124 ,  1.4174792 ],
       [ 2.283803  ,  2.9701724 ,  8.729265  , ...,  6.0229187 ,
         3.2842712 ,  2.1182036 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_299/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 299/720 with hyperparameters:
timestamp = 2023-09-27 04:57:38.855904
ndims = 32
seed_train = 869
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 5
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 537200
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 1.7417877   3.5044646   9.194398    1.0621872   8.910313    1.2448134
  9.752992    4.795541   10.214517    5.8200784   7.3571367   0.42017213
  3.0764782   1.1773593   3.1572356   1.3086243   2.6951017   5.712275
  0.4469142   6.9349284   5.5393224   1.8138231   6.1143165   1.1455625
  7.183009    9.098161    3.4021838   5.9704523   0.79392874  7.377848
  2.8874114   1.7757134 ]
Epoch 1/1000
2023-09-27 04:59:35.135 
Epoch 1/1000 
	 loss: 135.7429, MinusLogProbMetric: 135.7429, val_loss: 34.6594, val_MinusLogProbMetric: 34.6594

Epoch 1: val_loss improved from inf to 34.65942, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 117s - loss: 135.7429 - MinusLogProbMetric: 135.7429 - val_loss: 34.6594 - val_MinusLogProbMetric: 34.6594 - lr: 0.0010 - 117s/epoch - 596ms/step
Epoch 2/1000
2023-09-27 05:00:15.252 
Epoch 2/1000 
	 loss: 29.6971, MinusLogProbMetric: 29.6971, val_loss: 26.2540, val_MinusLogProbMetric: 26.2540

Epoch 2: val_loss improved from 34.65942 to 26.25400, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 40s - loss: 29.6971 - MinusLogProbMetric: 29.6971 - val_loss: 26.2540 - val_MinusLogProbMetric: 26.2540 - lr: 0.0010 - 40s/epoch - 203ms/step
Epoch 3/1000
2023-09-27 05:00:55.374 
Epoch 3/1000 
	 loss: 25.3557, MinusLogProbMetric: 25.3557, val_loss: 23.9769, val_MinusLogProbMetric: 23.9769

Epoch 3: val_loss improved from 26.25400 to 23.97689, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 40s - loss: 25.3557 - MinusLogProbMetric: 25.3557 - val_loss: 23.9769 - val_MinusLogProbMetric: 23.9769 - lr: 0.0010 - 40s/epoch - 205ms/step
Epoch 4/1000
2023-09-27 05:01:34.517 
Epoch 4/1000 
	 loss: 23.5142, MinusLogProbMetric: 23.5142, val_loss: 23.2490, val_MinusLogProbMetric: 23.2490

Epoch 4: val_loss improved from 23.97689 to 23.24900, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 39s - loss: 23.5142 - MinusLogProbMetric: 23.5142 - val_loss: 23.2490 - val_MinusLogProbMetric: 23.2490 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 5/1000
2023-09-27 05:02:13.738 
Epoch 5/1000 
	 loss: 22.4863, MinusLogProbMetric: 22.4863, val_loss: 22.4666, val_MinusLogProbMetric: 22.4666

Epoch 5: val_loss improved from 23.24900 to 22.46658, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 39s - loss: 22.4863 - MinusLogProbMetric: 22.4863 - val_loss: 22.4666 - val_MinusLogProbMetric: 22.4666 - lr: 0.0010 - 39s/epoch - 201ms/step
Epoch 6/1000
2023-09-27 05:02:53.189 
Epoch 6/1000 
	 loss: 21.8418, MinusLogProbMetric: 21.8418, val_loss: 21.6063, val_MinusLogProbMetric: 21.6063

Epoch 6: val_loss improved from 22.46658 to 21.60628, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 40s - loss: 21.8418 - MinusLogProbMetric: 21.8418 - val_loss: 21.6063 - val_MinusLogProbMetric: 21.6063 - lr: 0.0010 - 40s/epoch - 202ms/step
Epoch 7/1000
2023-09-27 05:03:32.869 
Epoch 7/1000 
	 loss: 21.2775, MinusLogProbMetric: 21.2775, val_loss: 20.8328, val_MinusLogProbMetric: 20.8328

Epoch 7: val_loss improved from 21.60628 to 20.83276, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 39s - loss: 21.2775 - MinusLogProbMetric: 21.2775 - val_loss: 20.8328 - val_MinusLogProbMetric: 20.8328 - lr: 0.0010 - 39s/epoch - 201ms/step
Epoch 8/1000
2023-09-27 05:04:12.312 
Epoch 8/1000 
	 loss: 21.0457, MinusLogProbMetric: 21.0457, val_loss: 20.7909, val_MinusLogProbMetric: 20.7909

Epoch 8: val_loss improved from 20.83276 to 20.79091, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 39s - loss: 21.0457 - MinusLogProbMetric: 21.0457 - val_loss: 20.7909 - val_MinusLogProbMetric: 20.7909 - lr: 0.0010 - 39s/epoch - 201ms/step
Epoch 9/1000
2023-09-27 05:04:51.870 
Epoch 9/1000 
	 loss: 20.6281, MinusLogProbMetric: 20.6281, val_loss: 20.5628, val_MinusLogProbMetric: 20.5628

Epoch 9: val_loss improved from 20.79091 to 20.56283, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 40s - loss: 20.6281 - MinusLogProbMetric: 20.6281 - val_loss: 20.5628 - val_MinusLogProbMetric: 20.5628 - lr: 0.0010 - 40s/epoch - 202ms/step
Epoch 10/1000
2023-09-27 05:05:31.361 
Epoch 10/1000 
	 loss: 20.4089, MinusLogProbMetric: 20.4089, val_loss: 20.5972, val_MinusLogProbMetric: 20.5972

Epoch 10: val_loss did not improve from 20.56283
196/196 - 39s - loss: 20.4089 - MinusLogProbMetric: 20.4089 - val_loss: 20.5972 - val_MinusLogProbMetric: 20.5972 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 11/1000
2023-09-27 05:06:10.306 
Epoch 11/1000 
	 loss: 20.2586, MinusLogProbMetric: 20.2586, val_loss: 20.3775, val_MinusLogProbMetric: 20.3775

Epoch 11: val_loss improved from 20.56283 to 20.37751, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 40s - loss: 20.2586 - MinusLogProbMetric: 20.2586 - val_loss: 20.3775 - val_MinusLogProbMetric: 20.3775 - lr: 0.0010 - 40s/epoch - 203ms/step
Epoch 12/1000
2023-09-27 05:06:50.018 
Epoch 12/1000 
	 loss: 20.0295, MinusLogProbMetric: 20.0295, val_loss: 19.7711, val_MinusLogProbMetric: 19.7711

Epoch 12: val_loss improved from 20.37751 to 19.77106, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 40s - loss: 20.0295 - MinusLogProbMetric: 20.0295 - val_loss: 19.7711 - val_MinusLogProbMetric: 19.7711 - lr: 0.0010 - 40s/epoch - 202ms/step
Epoch 13/1000
2023-09-27 05:07:29.119 
Epoch 13/1000 
	 loss: 19.8784, MinusLogProbMetric: 19.8784, val_loss: 19.2722, val_MinusLogProbMetric: 19.2722

Epoch 13: val_loss improved from 19.77106 to 19.27218, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 39s - loss: 19.8784 - MinusLogProbMetric: 19.8784 - val_loss: 19.2722 - val_MinusLogProbMetric: 19.2722 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 14/1000
2023-09-27 05:08:08.731 
Epoch 14/1000 
	 loss: 19.5731, MinusLogProbMetric: 19.5731, val_loss: 19.2370, val_MinusLogProbMetric: 19.2370

Epoch 14: val_loss improved from 19.27218 to 19.23701, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 40s - loss: 19.5731 - MinusLogProbMetric: 19.5731 - val_loss: 19.2370 - val_MinusLogProbMetric: 19.2370 - lr: 0.0010 - 40s/epoch - 203ms/step
Epoch 15/1000
2023-09-27 05:08:47.976 
Epoch 15/1000 
	 loss: 19.6023, MinusLogProbMetric: 19.6023, val_loss: 19.3360, val_MinusLogProbMetric: 19.3360

Epoch 15: val_loss did not improve from 19.23701
196/196 - 39s - loss: 19.6023 - MinusLogProbMetric: 19.6023 - val_loss: 19.3360 - val_MinusLogProbMetric: 19.3360 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 16/1000
2023-09-27 05:09:26.918 
Epoch 16/1000 
	 loss: 19.3527, MinusLogProbMetric: 19.3527, val_loss: 19.7149, val_MinusLogProbMetric: 19.7149

Epoch 16: val_loss did not improve from 19.23701
196/196 - 39s - loss: 19.3527 - MinusLogProbMetric: 19.3527 - val_loss: 19.7149 - val_MinusLogProbMetric: 19.7149 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 17/1000
2023-09-27 05:10:05.636 
Epoch 17/1000 
	 loss: 19.2288, MinusLogProbMetric: 19.2288, val_loss: 20.4999, val_MinusLogProbMetric: 20.4999

Epoch 17: val_loss did not improve from 19.23701
196/196 - 39s - loss: 19.2288 - MinusLogProbMetric: 19.2288 - val_loss: 20.4999 - val_MinusLogProbMetric: 20.4999 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 18/1000
2023-09-27 05:10:44.192 
Epoch 18/1000 
	 loss: 19.2021, MinusLogProbMetric: 19.2021, val_loss: 18.4685, val_MinusLogProbMetric: 18.4685

Epoch 18: val_loss improved from 19.23701 to 18.46852, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 39s - loss: 19.2021 - MinusLogProbMetric: 19.2021 - val_loss: 18.4685 - val_MinusLogProbMetric: 18.4685 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 19/1000
2023-09-27 05:11:23.607 
Epoch 19/1000 
	 loss: 19.0982, MinusLogProbMetric: 19.0982, val_loss: 19.5758, val_MinusLogProbMetric: 19.5758

Epoch 19: val_loss did not improve from 18.46852
196/196 - 39s - loss: 19.0982 - MinusLogProbMetric: 19.0982 - val_loss: 19.5758 - val_MinusLogProbMetric: 19.5758 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 20/1000
2023-09-27 05:12:02.447 
Epoch 20/1000 
	 loss: 18.9326, MinusLogProbMetric: 18.9326, val_loss: 19.1313, val_MinusLogProbMetric: 19.1313

Epoch 20: val_loss did not improve from 18.46852
196/196 - 39s - loss: 18.9326 - MinusLogProbMetric: 18.9326 - val_loss: 19.1313 - val_MinusLogProbMetric: 19.1313 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 21/1000
2023-09-27 05:12:41.275 
Epoch 21/1000 
	 loss: 18.9425, MinusLogProbMetric: 18.9425, val_loss: 18.6694, val_MinusLogProbMetric: 18.6694

Epoch 21: val_loss did not improve from 18.46852
196/196 - 39s - loss: 18.9425 - MinusLogProbMetric: 18.9425 - val_loss: 18.6694 - val_MinusLogProbMetric: 18.6694 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 22/1000
2023-09-27 05:13:20.105 
Epoch 22/1000 
	 loss: 18.7702, MinusLogProbMetric: 18.7702, val_loss: 18.6756, val_MinusLogProbMetric: 18.6756

Epoch 22: val_loss did not improve from 18.46852
196/196 - 39s - loss: 18.7702 - MinusLogProbMetric: 18.7702 - val_loss: 18.6756 - val_MinusLogProbMetric: 18.6756 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 23/1000
2023-09-27 05:13:58.822 
Epoch 23/1000 
	 loss: 18.7829, MinusLogProbMetric: 18.7829, val_loss: 18.7045, val_MinusLogProbMetric: 18.7045

Epoch 23: val_loss did not improve from 18.46852
196/196 - 39s - loss: 18.7829 - MinusLogProbMetric: 18.7829 - val_loss: 18.7045 - val_MinusLogProbMetric: 18.7045 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 24/1000
2023-09-27 05:14:37.561 
Epoch 24/1000 
	 loss: 18.6910, MinusLogProbMetric: 18.6910, val_loss: 18.3214, val_MinusLogProbMetric: 18.3214

Epoch 24: val_loss improved from 18.46852 to 18.32140, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 39s - loss: 18.6910 - MinusLogProbMetric: 18.6910 - val_loss: 18.3214 - val_MinusLogProbMetric: 18.3214 - lr: 0.0010 - 39s/epoch - 201ms/step
Epoch 25/1000
2023-09-27 05:15:16.994 
Epoch 25/1000 
	 loss: 18.6234, MinusLogProbMetric: 18.6234, val_loss: 18.4778, val_MinusLogProbMetric: 18.4778

Epoch 25: val_loss did not improve from 18.32140
196/196 - 39s - loss: 18.6234 - MinusLogProbMetric: 18.6234 - val_loss: 18.4778 - val_MinusLogProbMetric: 18.4778 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 26/1000
2023-09-27 05:15:55.851 
Epoch 26/1000 
	 loss: 18.6113, MinusLogProbMetric: 18.6113, val_loss: 19.1484, val_MinusLogProbMetric: 19.1484

Epoch 26: val_loss did not improve from 18.32140
196/196 - 39s - loss: 18.6113 - MinusLogProbMetric: 18.6113 - val_loss: 19.1484 - val_MinusLogProbMetric: 19.1484 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 27/1000
2023-09-27 05:16:34.355 
Epoch 27/1000 
	 loss: 18.5216, MinusLogProbMetric: 18.5216, val_loss: 18.9113, val_MinusLogProbMetric: 18.9113

Epoch 27: val_loss did not improve from 18.32140
196/196 - 39s - loss: 18.5216 - MinusLogProbMetric: 18.5216 - val_loss: 18.9113 - val_MinusLogProbMetric: 18.9113 - lr: 0.0010 - 39s/epoch - 196ms/step
Epoch 28/1000
2023-09-27 05:17:13.218 
Epoch 28/1000 
	 loss: 18.4083, MinusLogProbMetric: 18.4083, val_loss: 18.8511, val_MinusLogProbMetric: 18.8511

Epoch 28: val_loss did not improve from 18.32140
196/196 - 39s - loss: 18.4083 - MinusLogProbMetric: 18.4083 - val_loss: 18.8511 - val_MinusLogProbMetric: 18.8511 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 29/1000
2023-09-27 05:17:51.638 
Epoch 29/1000 
	 loss: 18.4900, MinusLogProbMetric: 18.4900, val_loss: 18.5187, val_MinusLogProbMetric: 18.5187

Epoch 29: val_loss did not improve from 18.32140
196/196 - 38s - loss: 18.4900 - MinusLogProbMetric: 18.4900 - val_loss: 18.5187 - val_MinusLogProbMetric: 18.5187 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 30/1000
2023-09-27 05:18:30.096 
Epoch 30/1000 
	 loss: 18.3482, MinusLogProbMetric: 18.3482, val_loss: 19.3886, val_MinusLogProbMetric: 19.3886

Epoch 30: val_loss did not improve from 18.32140
196/196 - 38s - loss: 18.3482 - MinusLogProbMetric: 18.3482 - val_loss: 19.3886 - val_MinusLogProbMetric: 19.3886 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 31/1000
2023-09-27 05:19:08.628 
Epoch 31/1000 
	 loss: 18.3207, MinusLogProbMetric: 18.3207, val_loss: 18.1486, val_MinusLogProbMetric: 18.1486

Epoch 31: val_loss improved from 18.32140 to 18.14863, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 39s - loss: 18.3207 - MinusLogProbMetric: 18.3207 - val_loss: 18.1486 - val_MinusLogProbMetric: 18.1486 - lr: 0.0010 - 39s/epoch - 201ms/step
Epoch 32/1000
2023-09-27 05:19:48.345 
Epoch 32/1000 
	 loss: 18.2112, MinusLogProbMetric: 18.2112, val_loss: 18.2378, val_MinusLogProbMetric: 18.2378

Epoch 32: val_loss did not improve from 18.14863
196/196 - 39s - loss: 18.2112 - MinusLogProbMetric: 18.2112 - val_loss: 18.2378 - val_MinusLogProbMetric: 18.2378 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 33/1000
2023-09-27 05:20:27.025 
Epoch 33/1000 
	 loss: 18.2350, MinusLogProbMetric: 18.2350, val_loss: 18.0096, val_MinusLogProbMetric: 18.0096

Epoch 33: val_loss improved from 18.14863 to 18.00965, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 39s - loss: 18.2350 - MinusLogProbMetric: 18.2350 - val_loss: 18.0096 - val_MinusLogProbMetric: 18.0096 - lr: 0.0010 - 39s/epoch - 201ms/step
Epoch 34/1000
2023-09-27 05:21:06.303 
Epoch 34/1000 
	 loss: 18.1916, MinusLogProbMetric: 18.1916, val_loss: 18.3142, val_MinusLogProbMetric: 18.3142

Epoch 34: val_loss did not improve from 18.00965
196/196 - 39s - loss: 18.1916 - MinusLogProbMetric: 18.1916 - val_loss: 18.3142 - val_MinusLogProbMetric: 18.3142 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 35/1000
2023-09-27 05:21:43.685 
Epoch 35/1000 
	 loss: 18.1399, MinusLogProbMetric: 18.1399, val_loss: 19.3114, val_MinusLogProbMetric: 19.3114

Epoch 35: val_loss did not improve from 18.00965
196/196 - 37s - loss: 18.1399 - MinusLogProbMetric: 18.1399 - val_loss: 19.3114 - val_MinusLogProbMetric: 19.3114 - lr: 0.0010 - 37s/epoch - 191ms/step
Epoch 36/1000
2023-09-27 05:22:20.902 
Epoch 36/1000 
	 loss: 18.1161, MinusLogProbMetric: 18.1161, val_loss: 17.9900, val_MinusLogProbMetric: 17.9900

Epoch 36: val_loss improved from 18.00965 to 17.98997, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 38s - loss: 18.1161 - MinusLogProbMetric: 18.1161 - val_loss: 17.9900 - val_MinusLogProbMetric: 17.9900 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 37/1000
2023-09-27 05:22:57.085 
Epoch 37/1000 
	 loss: 18.0684, MinusLogProbMetric: 18.0684, val_loss: 18.6436, val_MinusLogProbMetric: 18.6436

Epoch 37: val_loss did not improve from 17.98997
196/196 - 36s - loss: 18.0684 - MinusLogProbMetric: 18.0684 - val_loss: 18.6436 - val_MinusLogProbMetric: 18.6436 - lr: 0.0010 - 36s/epoch - 181ms/step
Epoch 38/1000
2023-09-27 05:23:34.045 
Epoch 38/1000 
	 loss: 18.2231, MinusLogProbMetric: 18.2231, val_loss: 18.1276, val_MinusLogProbMetric: 18.1276

Epoch 38: val_loss did not improve from 17.98997
196/196 - 37s - loss: 18.2231 - MinusLogProbMetric: 18.2231 - val_loss: 18.1276 - val_MinusLogProbMetric: 18.1276 - lr: 0.0010 - 37s/epoch - 189ms/step
Epoch 39/1000
2023-09-27 05:24:11.744 
Epoch 39/1000 
	 loss: 18.0022, MinusLogProbMetric: 18.0022, val_loss: 17.9052, val_MinusLogProbMetric: 17.9052

Epoch 39: val_loss improved from 17.98997 to 17.90516, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 38s - loss: 18.0022 - MinusLogProbMetric: 18.0022 - val_loss: 17.9052 - val_MinusLogProbMetric: 17.9052 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 40/1000
2023-09-27 05:24:50.852 
Epoch 40/1000 
	 loss: 18.0102, MinusLogProbMetric: 18.0102, val_loss: 18.7876, val_MinusLogProbMetric: 18.7876

Epoch 40: val_loss did not improve from 17.90516
196/196 - 38s - loss: 18.0102 - MinusLogProbMetric: 18.0102 - val_loss: 18.7876 - val_MinusLogProbMetric: 18.7876 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 41/1000
2023-09-27 05:25:28.859 
Epoch 41/1000 
	 loss: 17.9506, MinusLogProbMetric: 17.9506, val_loss: 18.2478, val_MinusLogProbMetric: 18.2478

Epoch 41: val_loss did not improve from 17.90516
196/196 - 38s - loss: 17.9506 - MinusLogProbMetric: 17.9506 - val_loss: 18.2478 - val_MinusLogProbMetric: 18.2478 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 42/1000
2023-09-27 05:26:07.413 
Epoch 42/1000 
	 loss: 17.8898, MinusLogProbMetric: 17.8898, val_loss: 18.2956, val_MinusLogProbMetric: 18.2956

Epoch 42: val_loss did not improve from 17.90516
196/196 - 39s - loss: 17.8898 - MinusLogProbMetric: 17.8898 - val_loss: 18.2956 - val_MinusLogProbMetric: 18.2956 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 43/1000
2023-09-27 05:26:45.657 
Epoch 43/1000 
	 loss: 17.8822, MinusLogProbMetric: 17.8822, val_loss: 17.8122, val_MinusLogProbMetric: 17.8122

Epoch 43: val_loss improved from 17.90516 to 17.81221, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 39s - loss: 17.8822 - MinusLogProbMetric: 17.8822 - val_loss: 17.8122 - val_MinusLogProbMetric: 17.8122 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 44/1000
2023-09-27 05:27:24.777 
Epoch 44/1000 
	 loss: 17.9352, MinusLogProbMetric: 17.9352, val_loss: 18.0687, val_MinusLogProbMetric: 18.0687

Epoch 44: val_loss did not improve from 17.81221
196/196 - 38s - loss: 17.9352 - MinusLogProbMetric: 17.9352 - val_loss: 18.0687 - val_MinusLogProbMetric: 18.0687 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 45/1000
2023-09-27 05:28:03.226 
Epoch 45/1000 
	 loss: 17.7808, MinusLogProbMetric: 17.7808, val_loss: 17.8000, val_MinusLogProbMetric: 17.8000

Epoch 45: val_loss improved from 17.81221 to 17.80002, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 39s - loss: 17.7808 - MinusLogProbMetric: 17.7808 - val_loss: 17.8000 - val_MinusLogProbMetric: 17.8000 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 46/1000
2023-09-27 05:28:42.281 
Epoch 46/1000 
	 loss: 17.7840, MinusLogProbMetric: 17.7840, val_loss: 17.8423, val_MinusLogProbMetric: 17.8423

Epoch 46: val_loss did not improve from 17.80002
196/196 - 38s - loss: 17.7840 - MinusLogProbMetric: 17.7840 - val_loss: 17.8423 - val_MinusLogProbMetric: 17.8423 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 47/1000
2023-09-27 05:29:20.988 
Epoch 47/1000 
	 loss: 17.8030, MinusLogProbMetric: 17.8030, val_loss: 18.0093, val_MinusLogProbMetric: 18.0093

Epoch 47: val_loss did not improve from 17.80002
196/196 - 39s - loss: 17.8030 - MinusLogProbMetric: 17.8030 - val_loss: 18.0093 - val_MinusLogProbMetric: 18.0093 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 48/1000
2023-09-27 05:29:59.184 
Epoch 48/1000 
	 loss: 17.7236, MinusLogProbMetric: 17.7236, val_loss: 18.1749, val_MinusLogProbMetric: 18.1749

Epoch 48: val_loss did not improve from 17.80002
196/196 - 38s - loss: 17.7236 - MinusLogProbMetric: 17.7236 - val_loss: 18.1749 - val_MinusLogProbMetric: 18.1749 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 49/1000
2023-09-27 05:30:37.533 
Epoch 49/1000 
	 loss: 17.7353, MinusLogProbMetric: 17.7353, val_loss: 18.3026, val_MinusLogProbMetric: 18.3026

Epoch 49: val_loss did not improve from 17.80002
196/196 - 38s - loss: 17.7353 - MinusLogProbMetric: 17.7353 - val_loss: 18.3026 - val_MinusLogProbMetric: 18.3026 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 50/1000
2023-09-27 05:31:16.110 
Epoch 50/1000 
	 loss: 17.7548, MinusLogProbMetric: 17.7548, val_loss: 17.8834, val_MinusLogProbMetric: 17.8834

Epoch 50: val_loss did not improve from 17.80002
196/196 - 39s - loss: 17.7548 - MinusLogProbMetric: 17.7548 - val_loss: 17.8834 - val_MinusLogProbMetric: 17.8834 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 51/1000
2023-09-27 05:31:54.172 
Epoch 51/1000 
	 loss: 17.7243, MinusLogProbMetric: 17.7243, val_loss: 17.8364, val_MinusLogProbMetric: 17.8364

Epoch 51: val_loss did not improve from 17.80002
196/196 - 38s - loss: 17.7243 - MinusLogProbMetric: 17.7243 - val_loss: 17.8364 - val_MinusLogProbMetric: 17.8364 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 52/1000
2023-09-27 05:32:32.978 
Epoch 52/1000 
	 loss: 17.6495, MinusLogProbMetric: 17.6495, val_loss: 18.0478, val_MinusLogProbMetric: 18.0478

Epoch 52: val_loss did not improve from 17.80002
196/196 - 39s - loss: 17.6495 - MinusLogProbMetric: 17.6495 - val_loss: 18.0478 - val_MinusLogProbMetric: 18.0478 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 53/1000
2023-09-27 05:33:08.037 
Epoch 53/1000 
	 loss: 17.6642, MinusLogProbMetric: 17.6642, val_loss: 17.5982, val_MinusLogProbMetric: 17.5982

Epoch 53: val_loss improved from 17.80002 to 17.59822, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 36s - loss: 17.6642 - MinusLogProbMetric: 17.6642 - val_loss: 17.5982 - val_MinusLogProbMetric: 17.5982 - lr: 0.0010 - 36s/epoch - 182ms/step
Epoch 54/1000
2023-09-27 05:33:43.343 
Epoch 54/1000 
	 loss: 17.6345, MinusLogProbMetric: 17.6345, val_loss: 17.4841, val_MinusLogProbMetric: 17.4841

Epoch 54: val_loss improved from 17.59822 to 17.48411, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 35s - loss: 17.6345 - MinusLogProbMetric: 17.6345 - val_loss: 17.4841 - val_MinusLogProbMetric: 17.4841 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 55/1000
2023-09-27 05:34:21.768 
Epoch 55/1000 
	 loss: 17.6835, MinusLogProbMetric: 17.6835, val_loss: 17.7984, val_MinusLogProbMetric: 17.7984

Epoch 55: val_loss did not improve from 17.48411
196/196 - 38s - loss: 17.6835 - MinusLogProbMetric: 17.6835 - val_loss: 17.7984 - val_MinusLogProbMetric: 17.7984 - lr: 0.0010 - 38s/epoch - 192ms/step
Epoch 56/1000
2023-09-27 05:35:00.180 
Epoch 56/1000 
	 loss: 17.6147, MinusLogProbMetric: 17.6147, val_loss: 18.0167, val_MinusLogProbMetric: 18.0167

Epoch 56: val_loss did not improve from 17.48411
196/196 - 38s - loss: 17.6147 - MinusLogProbMetric: 17.6147 - val_loss: 18.0167 - val_MinusLogProbMetric: 18.0167 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 57/1000
2023-09-27 05:35:35.104 
Epoch 57/1000 
	 loss: 17.6127, MinusLogProbMetric: 17.6127, val_loss: 18.0280, val_MinusLogProbMetric: 18.0280

Epoch 57: val_loss did not improve from 17.48411
196/196 - 35s - loss: 17.6127 - MinusLogProbMetric: 17.6127 - val_loss: 18.0280 - val_MinusLogProbMetric: 18.0280 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 58/1000
2023-09-27 05:36:09.450 
Epoch 58/1000 
	 loss: 17.6298, MinusLogProbMetric: 17.6298, val_loss: 17.5485, val_MinusLogProbMetric: 17.5485

Epoch 58: val_loss did not improve from 17.48411
196/196 - 34s - loss: 17.6298 - MinusLogProbMetric: 17.6298 - val_loss: 17.5485 - val_MinusLogProbMetric: 17.5485 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 59/1000
2023-09-27 05:36:46.197 
Epoch 59/1000 
	 loss: 17.5877, MinusLogProbMetric: 17.5877, val_loss: 19.2847, val_MinusLogProbMetric: 19.2847

Epoch 59: val_loss did not improve from 17.48411
196/196 - 37s - loss: 17.5877 - MinusLogProbMetric: 17.5877 - val_loss: 19.2847 - val_MinusLogProbMetric: 19.2847 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 60/1000
2023-09-27 05:37:24.664 
Epoch 60/1000 
	 loss: 17.6091, MinusLogProbMetric: 17.6091, val_loss: 17.7426, val_MinusLogProbMetric: 17.7426

Epoch 60: val_loss did not improve from 17.48411
196/196 - 38s - loss: 17.6091 - MinusLogProbMetric: 17.6091 - val_loss: 17.7426 - val_MinusLogProbMetric: 17.7426 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 61/1000
2023-09-27 05:38:02.945 
Epoch 61/1000 
	 loss: 17.5320, MinusLogProbMetric: 17.5320, val_loss: 17.9996, val_MinusLogProbMetric: 17.9996

Epoch 61: val_loss did not improve from 17.48411
196/196 - 38s - loss: 17.5320 - MinusLogProbMetric: 17.5320 - val_loss: 17.9996 - val_MinusLogProbMetric: 17.9996 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 62/1000
2023-09-27 05:38:41.652 
Epoch 62/1000 
	 loss: 17.5469, MinusLogProbMetric: 17.5469, val_loss: 17.8462, val_MinusLogProbMetric: 17.8462

Epoch 62: val_loss did not improve from 17.48411
196/196 - 39s - loss: 17.5469 - MinusLogProbMetric: 17.5469 - val_loss: 17.8462 - val_MinusLogProbMetric: 17.8462 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 63/1000
2023-09-27 05:39:20.293 
Epoch 63/1000 
	 loss: 17.5198, MinusLogProbMetric: 17.5198, val_loss: 17.5664, val_MinusLogProbMetric: 17.5664

Epoch 63: val_loss did not improve from 17.48411
196/196 - 39s - loss: 17.5198 - MinusLogProbMetric: 17.5198 - val_loss: 17.5664 - val_MinusLogProbMetric: 17.5664 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 64/1000
2023-09-27 05:39:59.080 
Epoch 64/1000 
	 loss: 17.5598, MinusLogProbMetric: 17.5598, val_loss: 17.3513, val_MinusLogProbMetric: 17.3513

Epoch 64: val_loss improved from 17.48411 to 17.35131, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 39s - loss: 17.5598 - MinusLogProbMetric: 17.5598 - val_loss: 17.3513 - val_MinusLogProbMetric: 17.3513 - lr: 0.0010 - 39s/epoch - 201ms/step
Epoch 65/1000
2023-09-27 05:40:38.535 
Epoch 65/1000 
	 loss: 17.4811, MinusLogProbMetric: 17.4811, val_loss: 18.0036, val_MinusLogProbMetric: 18.0036

Epoch 65: val_loss did not improve from 17.35131
196/196 - 39s - loss: 17.4811 - MinusLogProbMetric: 17.4811 - val_loss: 18.0036 - val_MinusLogProbMetric: 18.0036 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 66/1000
2023-09-27 05:41:17.253 
Epoch 66/1000 
	 loss: 17.4451, MinusLogProbMetric: 17.4451, val_loss: 17.9148, val_MinusLogProbMetric: 17.9148

Epoch 66: val_loss did not improve from 17.35131
196/196 - 39s - loss: 17.4451 - MinusLogProbMetric: 17.4451 - val_loss: 17.9148 - val_MinusLogProbMetric: 17.9148 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 67/1000
2023-09-27 05:41:55.803 
Epoch 67/1000 
	 loss: 17.4778, MinusLogProbMetric: 17.4778, val_loss: 17.6127, val_MinusLogProbMetric: 17.6127

Epoch 67: val_loss did not improve from 17.35131
196/196 - 39s - loss: 17.4778 - MinusLogProbMetric: 17.4778 - val_loss: 17.6127 - val_MinusLogProbMetric: 17.6127 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 68/1000
2023-09-27 05:42:34.478 
Epoch 68/1000 
	 loss: 17.4057, MinusLogProbMetric: 17.4057, val_loss: 17.4871, val_MinusLogProbMetric: 17.4871

Epoch 68: val_loss did not improve from 17.35131
196/196 - 39s - loss: 17.4057 - MinusLogProbMetric: 17.4057 - val_loss: 17.4871 - val_MinusLogProbMetric: 17.4871 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 69/1000
2023-09-27 05:43:13.182 
Epoch 69/1000 
	 loss: 17.4414, MinusLogProbMetric: 17.4414, val_loss: 17.8664, val_MinusLogProbMetric: 17.8664

Epoch 69: val_loss did not improve from 17.35131
196/196 - 39s - loss: 17.4414 - MinusLogProbMetric: 17.4414 - val_loss: 17.8664 - val_MinusLogProbMetric: 17.8664 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 70/1000
2023-09-27 05:43:51.878 
Epoch 70/1000 
	 loss: 17.4890, MinusLogProbMetric: 17.4890, val_loss: 17.8005, val_MinusLogProbMetric: 17.8005

Epoch 70: val_loss did not improve from 17.35131
196/196 - 39s - loss: 17.4890 - MinusLogProbMetric: 17.4890 - val_loss: 17.8005 - val_MinusLogProbMetric: 17.8005 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 71/1000
2023-09-27 05:44:30.557 
Epoch 71/1000 
	 loss: 17.4250, MinusLogProbMetric: 17.4250, val_loss: 17.5074, val_MinusLogProbMetric: 17.5074

Epoch 71: val_loss did not improve from 17.35131
196/196 - 39s - loss: 17.4250 - MinusLogProbMetric: 17.4250 - val_loss: 17.5074 - val_MinusLogProbMetric: 17.5074 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 72/1000
2023-09-27 05:45:09.342 
Epoch 72/1000 
	 loss: 17.4108, MinusLogProbMetric: 17.4108, val_loss: 17.4039, val_MinusLogProbMetric: 17.4039

Epoch 72: val_loss did not improve from 17.35131
196/196 - 39s - loss: 17.4108 - MinusLogProbMetric: 17.4108 - val_loss: 17.4039 - val_MinusLogProbMetric: 17.4039 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 73/1000
2023-09-27 05:45:48.156 
Epoch 73/1000 
	 loss: 17.4308, MinusLogProbMetric: 17.4308, val_loss: 17.9307, val_MinusLogProbMetric: 17.9307

Epoch 73: val_loss did not improve from 17.35131
196/196 - 39s - loss: 17.4308 - MinusLogProbMetric: 17.4308 - val_loss: 17.9307 - val_MinusLogProbMetric: 17.9307 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 74/1000
2023-09-27 05:46:26.888 
Epoch 74/1000 
	 loss: 17.3852, MinusLogProbMetric: 17.3852, val_loss: 17.5723, val_MinusLogProbMetric: 17.5723

Epoch 74: val_loss did not improve from 17.35131
196/196 - 39s - loss: 17.3852 - MinusLogProbMetric: 17.3852 - val_loss: 17.5723 - val_MinusLogProbMetric: 17.5723 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 75/1000
2023-09-27 05:47:05.800 
Epoch 75/1000 
	 loss: 17.4555, MinusLogProbMetric: 17.4555, val_loss: 17.5497, val_MinusLogProbMetric: 17.5497

Epoch 75: val_loss did not improve from 17.35131
196/196 - 39s - loss: 17.4555 - MinusLogProbMetric: 17.4555 - val_loss: 17.5497 - val_MinusLogProbMetric: 17.5497 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 76/1000
2023-09-27 05:47:44.275 
Epoch 76/1000 
	 loss: 17.3944, MinusLogProbMetric: 17.3944, val_loss: 17.5037, val_MinusLogProbMetric: 17.5037

Epoch 76: val_loss did not improve from 17.35131
196/196 - 38s - loss: 17.3944 - MinusLogProbMetric: 17.3944 - val_loss: 17.5037 - val_MinusLogProbMetric: 17.5037 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 77/1000
2023-09-27 05:48:22.934 
Epoch 77/1000 
	 loss: 17.3558, MinusLogProbMetric: 17.3558, val_loss: 17.7313, val_MinusLogProbMetric: 17.7313

Epoch 77: val_loss did not improve from 17.35131
196/196 - 39s - loss: 17.3558 - MinusLogProbMetric: 17.3558 - val_loss: 17.7313 - val_MinusLogProbMetric: 17.7313 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 78/1000
2023-09-27 05:49:01.359 
Epoch 78/1000 
	 loss: 17.3283, MinusLogProbMetric: 17.3283, val_loss: 17.7718, val_MinusLogProbMetric: 17.7718

Epoch 78: val_loss did not improve from 17.35131
196/196 - 38s - loss: 17.3283 - MinusLogProbMetric: 17.3283 - val_loss: 17.7718 - val_MinusLogProbMetric: 17.7718 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 79/1000
2023-09-27 05:49:40.466 
Epoch 79/1000 
	 loss: 17.3951, MinusLogProbMetric: 17.3951, val_loss: 17.7302, val_MinusLogProbMetric: 17.7302

Epoch 79: val_loss did not improve from 17.35131
196/196 - 39s - loss: 17.3951 - MinusLogProbMetric: 17.3951 - val_loss: 17.7302 - val_MinusLogProbMetric: 17.7302 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 80/1000
2023-09-27 05:50:19.029 
Epoch 80/1000 
	 loss: 17.3927, MinusLogProbMetric: 17.3927, val_loss: 17.2270, val_MinusLogProbMetric: 17.2270

Epoch 80: val_loss improved from 17.35131 to 17.22700, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 39s - loss: 17.3927 - MinusLogProbMetric: 17.3927 - val_loss: 17.2270 - val_MinusLogProbMetric: 17.2270 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 81/1000
2023-09-27 05:50:58.203 
Epoch 81/1000 
	 loss: 17.2888, MinusLogProbMetric: 17.2888, val_loss: 17.4830, val_MinusLogProbMetric: 17.4830

Epoch 81: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.2888 - MinusLogProbMetric: 17.2888 - val_loss: 17.4830 - val_MinusLogProbMetric: 17.4830 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 82/1000
2023-09-27 05:51:37.039 
Epoch 82/1000 
	 loss: 17.3187, MinusLogProbMetric: 17.3187, val_loss: 17.3095, val_MinusLogProbMetric: 17.3095

Epoch 82: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.3187 - MinusLogProbMetric: 17.3187 - val_loss: 17.3095 - val_MinusLogProbMetric: 17.3095 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 83/1000
2023-09-27 05:52:15.728 
Epoch 83/1000 
	 loss: 17.3504, MinusLogProbMetric: 17.3504, val_loss: 17.6931, val_MinusLogProbMetric: 17.6931

Epoch 83: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.3504 - MinusLogProbMetric: 17.3504 - val_loss: 17.6931 - val_MinusLogProbMetric: 17.6931 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 84/1000
2023-09-27 05:52:54.106 
Epoch 84/1000 
	 loss: 17.3500, MinusLogProbMetric: 17.3500, val_loss: 17.5134, val_MinusLogProbMetric: 17.5134

Epoch 84: val_loss did not improve from 17.22700
196/196 - 38s - loss: 17.3500 - MinusLogProbMetric: 17.3500 - val_loss: 17.5134 - val_MinusLogProbMetric: 17.5134 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 85/1000
2023-09-27 05:53:32.523 
Epoch 85/1000 
	 loss: 17.3043, MinusLogProbMetric: 17.3043, val_loss: 17.3375, val_MinusLogProbMetric: 17.3375

Epoch 85: val_loss did not improve from 17.22700
196/196 - 38s - loss: 17.3043 - MinusLogProbMetric: 17.3043 - val_loss: 17.3375 - val_MinusLogProbMetric: 17.3375 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 86/1000
2023-09-27 05:54:11.052 
Epoch 86/1000 
	 loss: 17.2755, MinusLogProbMetric: 17.2755, val_loss: 17.7417, val_MinusLogProbMetric: 17.7417

Epoch 86: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.2755 - MinusLogProbMetric: 17.2755 - val_loss: 17.7417 - val_MinusLogProbMetric: 17.7417 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 87/1000
2023-09-27 05:54:50.043 
Epoch 87/1000 
	 loss: 17.2803, MinusLogProbMetric: 17.2803, val_loss: 17.4803, val_MinusLogProbMetric: 17.4803

Epoch 87: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.2803 - MinusLogProbMetric: 17.2803 - val_loss: 17.4803 - val_MinusLogProbMetric: 17.4803 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 88/1000
2023-09-27 05:55:28.437 
Epoch 88/1000 
	 loss: 17.2496, MinusLogProbMetric: 17.2496, val_loss: 17.3124, val_MinusLogProbMetric: 17.3124

Epoch 88: val_loss did not improve from 17.22700
196/196 - 38s - loss: 17.2496 - MinusLogProbMetric: 17.2496 - val_loss: 17.3124 - val_MinusLogProbMetric: 17.3124 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 89/1000
2023-09-27 05:56:06.744 
Epoch 89/1000 
	 loss: 17.2587, MinusLogProbMetric: 17.2587, val_loss: 17.4644, val_MinusLogProbMetric: 17.4644

Epoch 89: val_loss did not improve from 17.22700
196/196 - 38s - loss: 17.2587 - MinusLogProbMetric: 17.2587 - val_loss: 17.4644 - val_MinusLogProbMetric: 17.4644 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 90/1000
2023-09-27 05:56:46.045 
Epoch 90/1000 
	 loss: 17.2489, MinusLogProbMetric: 17.2489, val_loss: 17.4417, val_MinusLogProbMetric: 17.4417

Epoch 90: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.2489 - MinusLogProbMetric: 17.2489 - val_loss: 17.4417 - val_MinusLogProbMetric: 17.4417 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 91/1000
2023-09-27 05:57:24.687 
Epoch 91/1000 
	 loss: 17.2682, MinusLogProbMetric: 17.2682, val_loss: 17.3144, val_MinusLogProbMetric: 17.3144

Epoch 91: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.2682 - MinusLogProbMetric: 17.2682 - val_loss: 17.3144 - val_MinusLogProbMetric: 17.3144 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 92/1000
2023-09-27 05:58:03.752 
Epoch 92/1000 
	 loss: 17.2619, MinusLogProbMetric: 17.2619, val_loss: 17.7614, val_MinusLogProbMetric: 17.7614

Epoch 92: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.2619 - MinusLogProbMetric: 17.2619 - val_loss: 17.7614 - val_MinusLogProbMetric: 17.7614 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 93/1000
2023-09-27 05:58:42.677 
Epoch 93/1000 
	 loss: 17.2156, MinusLogProbMetric: 17.2156, val_loss: 17.3952, val_MinusLogProbMetric: 17.3952

Epoch 93: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.2156 - MinusLogProbMetric: 17.2156 - val_loss: 17.3952 - val_MinusLogProbMetric: 17.3952 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 94/1000
2023-09-27 05:59:21.615 
Epoch 94/1000 
	 loss: 17.1908, MinusLogProbMetric: 17.1908, val_loss: 18.2596, val_MinusLogProbMetric: 18.2596

Epoch 94: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.1908 - MinusLogProbMetric: 17.1908 - val_loss: 18.2596 - val_MinusLogProbMetric: 18.2596 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 95/1000
2023-09-27 06:00:00.156 
Epoch 95/1000 
	 loss: 17.2515, MinusLogProbMetric: 17.2515, val_loss: 17.2911, val_MinusLogProbMetric: 17.2911

Epoch 95: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.2515 - MinusLogProbMetric: 17.2515 - val_loss: 17.2911 - val_MinusLogProbMetric: 17.2911 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 96/1000
2023-09-27 06:00:39.160 
Epoch 96/1000 
	 loss: 17.2294, MinusLogProbMetric: 17.2294, val_loss: 17.3431, val_MinusLogProbMetric: 17.3431

Epoch 96: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.2294 - MinusLogProbMetric: 17.2294 - val_loss: 17.3431 - val_MinusLogProbMetric: 17.3431 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 97/1000
2023-09-27 06:01:17.585 
Epoch 97/1000 
	 loss: 17.2120, MinusLogProbMetric: 17.2120, val_loss: 17.4662, val_MinusLogProbMetric: 17.4662

Epoch 97: val_loss did not improve from 17.22700
196/196 - 38s - loss: 17.2120 - MinusLogProbMetric: 17.2120 - val_loss: 17.4662 - val_MinusLogProbMetric: 17.4662 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 98/1000
2023-09-27 06:01:56.114 
Epoch 98/1000 
	 loss: 17.2289, MinusLogProbMetric: 17.2289, val_loss: 18.0781, val_MinusLogProbMetric: 18.0781

Epoch 98: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.2289 - MinusLogProbMetric: 17.2289 - val_loss: 18.0781 - val_MinusLogProbMetric: 18.0781 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 99/1000
2023-09-27 06:02:34.656 
Epoch 99/1000 
	 loss: 17.1708, MinusLogProbMetric: 17.1708, val_loss: 17.4540, val_MinusLogProbMetric: 17.4540

Epoch 99: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.1708 - MinusLogProbMetric: 17.1708 - val_loss: 17.4540 - val_MinusLogProbMetric: 17.4540 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 100/1000
2023-09-27 06:03:13.477 
Epoch 100/1000 
	 loss: 17.2381, MinusLogProbMetric: 17.2381, val_loss: 17.2978, val_MinusLogProbMetric: 17.2978

Epoch 100: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.2381 - MinusLogProbMetric: 17.2381 - val_loss: 17.2978 - val_MinusLogProbMetric: 17.2978 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 101/1000
2023-09-27 06:03:52.046 
Epoch 101/1000 
	 loss: 17.2140, MinusLogProbMetric: 17.2140, val_loss: 17.4844, val_MinusLogProbMetric: 17.4844

Epoch 101: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.2140 - MinusLogProbMetric: 17.2140 - val_loss: 17.4844 - val_MinusLogProbMetric: 17.4844 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 102/1000
2023-09-27 06:04:31.192 
Epoch 102/1000 
	 loss: 17.1849, MinusLogProbMetric: 17.1849, val_loss: 17.4893, val_MinusLogProbMetric: 17.4893

Epoch 102: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.1849 - MinusLogProbMetric: 17.1849 - val_loss: 17.4893 - val_MinusLogProbMetric: 17.4893 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 103/1000
2023-09-27 06:05:09.735 
Epoch 103/1000 
	 loss: 17.2448, MinusLogProbMetric: 17.2448, val_loss: 17.4535, val_MinusLogProbMetric: 17.4535

Epoch 103: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.2448 - MinusLogProbMetric: 17.2448 - val_loss: 17.4535 - val_MinusLogProbMetric: 17.4535 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 104/1000
2023-09-27 06:05:48.637 
Epoch 104/1000 
	 loss: 17.1636, MinusLogProbMetric: 17.1636, val_loss: 17.2587, val_MinusLogProbMetric: 17.2587

Epoch 104: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.1636 - MinusLogProbMetric: 17.1636 - val_loss: 17.2587 - val_MinusLogProbMetric: 17.2587 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 105/1000
2023-09-27 06:06:27.188 
Epoch 105/1000 
	 loss: 17.1433, MinusLogProbMetric: 17.1433, val_loss: 17.8975, val_MinusLogProbMetric: 17.8975

Epoch 105: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.1433 - MinusLogProbMetric: 17.1433 - val_loss: 17.8975 - val_MinusLogProbMetric: 17.8975 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 106/1000
2023-09-27 06:07:06.110 
Epoch 106/1000 
	 loss: 17.1822, MinusLogProbMetric: 17.1822, val_loss: 17.3419, val_MinusLogProbMetric: 17.3419

Epoch 106: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.1822 - MinusLogProbMetric: 17.1822 - val_loss: 17.3419 - val_MinusLogProbMetric: 17.3419 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 107/1000
2023-09-27 06:07:44.752 
Epoch 107/1000 
	 loss: 17.1671, MinusLogProbMetric: 17.1671, val_loss: 17.2899, val_MinusLogProbMetric: 17.2899

Epoch 107: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.1671 - MinusLogProbMetric: 17.1671 - val_loss: 17.2899 - val_MinusLogProbMetric: 17.2899 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 108/1000
2023-09-27 06:08:23.631 
Epoch 108/1000 
	 loss: 17.1367, MinusLogProbMetric: 17.1367, val_loss: 17.3161, val_MinusLogProbMetric: 17.3161

Epoch 108: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.1367 - MinusLogProbMetric: 17.1367 - val_loss: 17.3161 - val_MinusLogProbMetric: 17.3161 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 109/1000
2023-09-27 06:09:02.637 
Epoch 109/1000 
	 loss: 17.1561, MinusLogProbMetric: 17.1561, val_loss: 17.2627, val_MinusLogProbMetric: 17.2627

Epoch 109: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.1561 - MinusLogProbMetric: 17.1561 - val_loss: 17.2627 - val_MinusLogProbMetric: 17.2627 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 110/1000
2023-09-27 06:09:41.191 
Epoch 110/1000 
	 loss: 17.1228, MinusLogProbMetric: 17.1228, val_loss: 17.6842, val_MinusLogProbMetric: 17.6842

Epoch 110: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.1228 - MinusLogProbMetric: 17.1228 - val_loss: 17.6842 - val_MinusLogProbMetric: 17.6842 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 111/1000
2023-09-27 06:10:20.114 
Epoch 111/1000 
	 loss: 17.1537, MinusLogProbMetric: 17.1537, val_loss: 17.3742, val_MinusLogProbMetric: 17.3742

Epoch 111: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.1537 - MinusLogProbMetric: 17.1537 - val_loss: 17.3742 - val_MinusLogProbMetric: 17.3742 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 112/1000
2023-09-27 06:10:58.654 
Epoch 112/1000 
	 loss: 17.1456, MinusLogProbMetric: 17.1456, val_loss: 17.3325, val_MinusLogProbMetric: 17.3325

Epoch 112: val_loss did not improve from 17.22700
196/196 - 39s - loss: 17.1456 - MinusLogProbMetric: 17.1456 - val_loss: 17.3325 - val_MinusLogProbMetric: 17.3325 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 113/1000
2023-09-27 06:11:37.573 
Epoch 113/1000 
	 loss: 17.1699, MinusLogProbMetric: 17.1699, val_loss: 17.1428, val_MinusLogProbMetric: 17.1428

Epoch 113: val_loss improved from 17.22700 to 17.14277, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 40s - loss: 17.1699 - MinusLogProbMetric: 17.1699 - val_loss: 17.1428 - val_MinusLogProbMetric: 17.1428 - lr: 0.0010 - 40s/epoch - 202ms/step
Epoch 114/1000
2023-09-27 06:12:16.893 
Epoch 114/1000 
	 loss: 17.1003, MinusLogProbMetric: 17.1003, val_loss: 17.5919, val_MinusLogProbMetric: 17.5919

Epoch 114: val_loss did not improve from 17.14277
196/196 - 39s - loss: 17.1003 - MinusLogProbMetric: 17.1003 - val_loss: 17.5919 - val_MinusLogProbMetric: 17.5919 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 115/1000
2023-09-27 06:12:55.773 
Epoch 115/1000 
	 loss: 17.0995, MinusLogProbMetric: 17.0995, val_loss: 17.1004, val_MinusLogProbMetric: 17.1004

Epoch 115: val_loss improved from 17.14277 to 17.10039, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 40s - loss: 17.0995 - MinusLogProbMetric: 17.0995 - val_loss: 17.1004 - val_MinusLogProbMetric: 17.1004 - lr: 0.0010 - 40s/epoch - 203ms/step
Epoch 116/1000
2023-09-27 06:13:35.516 
Epoch 116/1000 
	 loss: 17.0822, MinusLogProbMetric: 17.0822, val_loss: 17.1382, val_MinusLogProbMetric: 17.1382

Epoch 116: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0822 - MinusLogProbMetric: 17.0822 - val_loss: 17.1382 - val_MinusLogProbMetric: 17.1382 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 117/1000
2023-09-27 06:14:14.224 
Epoch 117/1000 
	 loss: 17.1235, MinusLogProbMetric: 17.1235, val_loss: 17.2013, val_MinusLogProbMetric: 17.2013

Epoch 117: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.1235 - MinusLogProbMetric: 17.1235 - val_loss: 17.2013 - val_MinusLogProbMetric: 17.2013 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 118/1000
2023-09-27 06:14:52.861 
Epoch 118/1000 
	 loss: 17.1394, MinusLogProbMetric: 17.1394, val_loss: 17.6859, val_MinusLogProbMetric: 17.6859

Epoch 118: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.1394 - MinusLogProbMetric: 17.1394 - val_loss: 17.6859 - val_MinusLogProbMetric: 17.6859 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 119/1000
2023-09-27 06:15:31.731 
Epoch 119/1000 
	 loss: 17.1062, MinusLogProbMetric: 17.1062, val_loss: 17.3975, val_MinusLogProbMetric: 17.3975

Epoch 119: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.1062 - MinusLogProbMetric: 17.1062 - val_loss: 17.3975 - val_MinusLogProbMetric: 17.3975 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 120/1000
2023-09-27 06:16:10.474 
Epoch 120/1000 
	 loss: 17.0777, MinusLogProbMetric: 17.0777, val_loss: 17.1431, val_MinusLogProbMetric: 17.1431

Epoch 120: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0777 - MinusLogProbMetric: 17.0777 - val_loss: 17.1431 - val_MinusLogProbMetric: 17.1431 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 121/1000
2023-09-27 06:16:49.178 
Epoch 121/1000 
	 loss: 17.1196, MinusLogProbMetric: 17.1196, val_loss: 17.4886, val_MinusLogProbMetric: 17.4886

Epoch 121: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.1196 - MinusLogProbMetric: 17.1196 - val_loss: 17.4886 - val_MinusLogProbMetric: 17.4886 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 122/1000
2023-09-27 06:17:27.938 
Epoch 122/1000 
	 loss: 17.0937, MinusLogProbMetric: 17.0937, val_loss: 17.2751, val_MinusLogProbMetric: 17.2751

Epoch 122: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0937 - MinusLogProbMetric: 17.0937 - val_loss: 17.2751 - val_MinusLogProbMetric: 17.2751 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 123/1000
2023-09-27 06:18:06.575 
Epoch 123/1000 
	 loss: 17.0450, MinusLogProbMetric: 17.0450, val_loss: 18.1036, val_MinusLogProbMetric: 18.1036

Epoch 123: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0450 - MinusLogProbMetric: 17.0450 - val_loss: 18.1036 - val_MinusLogProbMetric: 18.1036 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 124/1000
2023-09-27 06:18:44.982 
Epoch 124/1000 
	 loss: 17.1417, MinusLogProbMetric: 17.1417, val_loss: 17.1987, val_MinusLogProbMetric: 17.1987

Epoch 124: val_loss did not improve from 17.10039
196/196 - 38s - loss: 17.1417 - MinusLogProbMetric: 17.1417 - val_loss: 17.1987 - val_MinusLogProbMetric: 17.1987 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 125/1000
2023-09-27 06:19:23.975 
Epoch 125/1000 
	 loss: 17.0513, MinusLogProbMetric: 17.0513, val_loss: 17.1261, val_MinusLogProbMetric: 17.1261

Epoch 125: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0513 - MinusLogProbMetric: 17.0513 - val_loss: 17.1261 - val_MinusLogProbMetric: 17.1261 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 126/1000
2023-09-27 06:20:02.640 
Epoch 126/1000 
	 loss: 17.0613, MinusLogProbMetric: 17.0613, val_loss: 17.4528, val_MinusLogProbMetric: 17.4528

Epoch 126: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0613 - MinusLogProbMetric: 17.0613 - val_loss: 17.4528 - val_MinusLogProbMetric: 17.4528 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 127/1000
2023-09-27 06:20:41.380 
Epoch 127/1000 
	 loss: 17.0906, MinusLogProbMetric: 17.0906, val_loss: 17.2772, val_MinusLogProbMetric: 17.2772

Epoch 127: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0906 - MinusLogProbMetric: 17.0906 - val_loss: 17.2772 - val_MinusLogProbMetric: 17.2772 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 128/1000
2023-09-27 06:21:20.381 
Epoch 128/1000 
	 loss: 17.0356, MinusLogProbMetric: 17.0356, val_loss: 17.2121, val_MinusLogProbMetric: 17.2121

Epoch 128: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0356 - MinusLogProbMetric: 17.0356 - val_loss: 17.2121 - val_MinusLogProbMetric: 17.2121 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 129/1000
2023-09-27 06:21:59.040 
Epoch 129/1000 
	 loss: 17.0781, MinusLogProbMetric: 17.0781, val_loss: 17.3365, val_MinusLogProbMetric: 17.3365

Epoch 129: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0781 - MinusLogProbMetric: 17.0781 - val_loss: 17.3365 - val_MinusLogProbMetric: 17.3365 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 130/1000
2023-09-27 06:22:37.792 
Epoch 130/1000 
	 loss: 17.0843, MinusLogProbMetric: 17.0843, val_loss: 17.2531, val_MinusLogProbMetric: 17.2531

Epoch 130: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0843 - MinusLogProbMetric: 17.0843 - val_loss: 17.2531 - val_MinusLogProbMetric: 17.2531 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 131/1000
2023-09-27 06:23:16.353 
Epoch 131/1000 
	 loss: 17.0541, MinusLogProbMetric: 17.0541, val_loss: 17.1937, val_MinusLogProbMetric: 17.1937

Epoch 131: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0541 - MinusLogProbMetric: 17.0541 - val_loss: 17.1937 - val_MinusLogProbMetric: 17.1937 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 132/1000
2023-09-27 06:23:55.164 
Epoch 132/1000 
	 loss: 17.0286, MinusLogProbMetric: 17.0286, val_loss: 17.1998, val_MinusLogProbMetric: 17.1998

Epoch 132: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0286 - MinusLogProbMetric: 17.0286 - val_loss: 17.1998 - val_MinusLogProbMetric: 17.1998 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 133/1000
2023-09-27 06:24:33.791 
Epoch 133/1000 
	 loss: 17.0671, MinusLogProbMetric: 17.0671, val_loss: 17.2430, val_MinusLogProbMetric: 17.2430

Epoch 133: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0671 - MinusLogProbMetric: 17.0671 - val_loss: 17.2430 - val_MinusLogProbMetric: 17.2430 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 134/1000
2023-09-27 06:25:12.680 
Epoch 134/1000 
	 loss: 17.0334, MinusLogProbMetric: 17.0334, val_loss: 17.1893, val_MinusLogProbMetric: 17.1893

Epoch 134: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0334 - MinusLogProbMetric: 17.0334 - val_loss: 17.1893 - val_MinusLogProbMetric: 17.1893 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 135/1000
2023-09-27 06:25:51.146 
Epoch 135/1000 
	 loss: 17.0613, MinusLogProbMetric: 17.0613, val_loss: 17.3580, val_MinusLogProbMetric: 17.3580

Epoch 135: val_loss did not improve from 17.10039
196/196 - 38s - loss: 17.0613 - MinusLogProbMetric: 17.0613 - val_loss: 17.3580 - val_MinusLogProbMetric: 17.3580 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 136/1000
2023-09-27 06:26:29.689 
Epoch 136/1000 
	 loss: 16.9979, MinusLogProbMetric: 16.9979, val_loss: 17.3420, val_MinusLogProbMetric: 17.3420

Epoch 136: val_loss did not improve from 17.10039
196/196 - 39s - loss: 16.9979 - MinusLogProbMetric: 16.9979 - val_loss: 17.3420 - val_MinusLogProbMetric: 17.3420 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 137/1000
2023-09-27 06:27:08.299 
Epoch 137/1000 
	 loss: 17.0189, MinusLogProbMetric: 17.0189, val_loss: 17.3400, val_MinusLogProbMetric: 17.3400

Epoch 137: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0189 - MinusLogProbMetric: 17.0189 - val_loss: 17.3400 - val_MinusLogProbMetric: 17.3400 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 138/1000
2023-09-27 06:27:47.224 
Epoch 138/1000 
	 loss: 17.0386, MinusLogProbMetric: 17.0386, val_loss: 17.2895, val_MinusLogProbMetric: 17.2895

Epoch 138: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0386 - MinusLogProbMetric: 17.0386 - val_loss: 17.2895 - val_MinusLogProbMetric: 17.2895 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 139/1000
2023-09-27 06:28:25.895 
Epoch 139/1000 
	 loss: 17.0331, MinusLogProbMetric: 17.0331, val_loss: 17.2491, val_MinusLogProbMetric: 17.2491

Epoch 139: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0331 - MinusLogProbMetric: 17.0331 - val_loss: 17.2491 - val_MinusLogProbMetric: 17.2491 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 140/1000
2023-09-27 06:29:04.926 
Epoch 140/1000 
	 loss: 17.0518, MinusLogProbMetric: 17.0518, val_loss: 17.1880, val_MinusLogProbMetric: 17.1880

Epoch 140: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0518 - MinusLogProbMetric: 17.0518 - val_loss: 17.1880 - val_MinusLogProbMetric: 17.1880 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 141/1000
2023-09-27 06:29:43.647 
Epoch 141/1000 
	 loss: 17.0200, MinusLogProbMetric: 17.0200, val_loss: 17.1988, val_MinusLogProbMetric: 17.1988

Epoch 141: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0200 - MinusLogProbMetric: 17.0200 - val_loss: 17.1988 - val_MinusLogProbMetric: 17.1988 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 142/1000
2023-09-27 06:30:22.868 
Epoch 142/1000 
	 loss: 17.0758, MinusLogProbMetric: 17.0758, val_loss: 17.1285, val_MinusLogProbMetric: 17.1285

Epoch 142: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0758 - MinusLogProbMetric: 17.0758 - val_loss: 17.1285 - val_MinusLogProbMetric: 17.1285 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 143/1000
2023-09-27 06:31:01.454 
Epoch 143/1000 
	 loss: 16.9947, MinusLogProbMetric: 16.9947, val_loss: 17.1771, val_MinusLogProbMetric: 17.1771

Epoch 143: val_loss did not improve from 17.10039
196/196 - 39s - loss: 16.9947 - MinusLogProbMetric: 16.9947 - val_loss: 17.1771 - val_MinusLogProbMetric: 17.1771 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 144/1000
2023-09-27 06:31:40.156 
Epoch 144/1000 
	 loss: 17.0486, MinusLogProbMetric: 17.0486, val_loss: 17.3883, val_MinusLogProbMetric: 17.3883

Epoch 144: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0486 - MinusLogProbMetric: 17.0486 - val_loss: 17.3883 - val_MinusLogProbMetric: 17.3883 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 145/1000
2023-09-27 06:32:18.513 
Epoch 145/1000 
	 loss: 16.9932, MinusLogProbMetric: 16.9932, val_loss: 17.3808, val_MinusLogProbMetric: 17.3808

Epoch 145: val_loss did not improve from 17.10039
196/196 - 38s - loss: 16.9932 - MinusLogProbMetric: 16.9932 - val_loss: 17.3808 - val_MinusLogProbMetric: 17.3808 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 146/1000
2023-09-27 06:32:57.376 
Epoch 146/1000 
	 loss: 17.0330, MinusLogProbMetric: 17.0330, val_loss: 17.4148, val_MinusLogProbMetric: 17.4148

Epoch 146: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0330 - MinusLogProbMetric: 17.0330 - val_loss: 17.4148 - val_MinusLogProbMetric: 17.4148 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 147/1000
2023-09-27 06:33:36.200 
Epoch 147/1000 
	 loss: 17.0340, MinusLogProbMetric: 17.0340, val_loss: 17.2600, val_MinusLogProbMetric: 17.2600

Epoch 147: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0340 - MinusLogProbMetric: 17.0340 - val_loss: 17.2600 - val_MinusLogProbMetric: 17.2600 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 148/1000
2023-09-27 06:34:14.871 
Epoch 148/1000 
	 loss: 16.9726, MinusLogProbMetric: 16.9726, val_loss: 17.2069, val_MinusLogProbMetric: 17.2069

Epoch 148: val_loss did not improve from 17.10039
196/196 - 39s - loss: 16.9726 - MinusLogProbMetric: 16.9726 - val_loss: 17.2069 - val_MinusLogProbMetric: 17.2069 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 149/1000
2023-09-27 06:34:53.875 
Epoch 149/1000 
	 loss: 17.0086, MinusLogProbMetric: 17.0086, val_loss: 17.1033, val_MinusLogProbMetric: 17.1033

Epoch 149: val_loss did not improve from 17.10039
196/196 - 39s - loss: 17.0086 - MinusLogProbMetric: 17.0086 - val_loss: 17.1033 - val_MinusLogProbMetric: 17.1033 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 150/1000
2023-09-27 06:35:32.773 
Epoch 150/1000 
	 loss: 16.9726, MinusLogProbMetric: 16.9726, val_loss: 17.0955, val_MinusLogProbMetric: 17.0955

Epoch 150: val_loss improved from 17.10039 to 17.09546, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 40s - loss: 16.9726 - MinusLogProbMetric: 16.9726 - val_loss: 17.0955 - val_MinusLogProbMetric: 17.0955 - lr: 0.0010 - 40s/epoch - 202ms/step
Epoch 151/1000
2023-09-27 06:36:12.519 
Epoch 151/1000 
	 loss: 17.0018, MinusLogProbMetric: 17.0018, val_loss: 17.3379, val_MinusLogProbMetric: 17.3379

Epoch 151: val_loss did not improve from 17.09546
196/196 - 39s - loss: 17.0018 - MinusLogProbMetric: 17.0018 - val_loss: 17.3379 - val_MinusLogProbMetric: 17.3379 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 152/1000
2023-09-27 06:36:51.566 
Epoch 152/1000 
	 loss: 16.9826, MinusLogProbMetric: 16.9826, val_loss: 17.0616, val_MinusLogProbMetric: 17.0616

Epoch 152: val_loss improved from 17.09546 to 17.06159, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 40s - loss: 16.9826 - MinusLogProbMetric: 16.9826 - val_loss: 17.0616 - val_MinusLogProbMetric: 17.0616 - lr: 0.0010 - 40s/epoch - 203ms/step
Epoch 153/1000
2023-09-27 06:37:31.067 
Epoch 153/1000 
	 loss: 16.9879, MinusLogProbMetric: 16.9879, val_loss: 17.3085, val_MinusLogProbMetric: 17.3085

Epoch 153: val_loss did not improve from 17.06159
196/196 - 39s - loss: 16.9879 - MinusLogProbMetric: 16.9879 - val_loss: 17.3085 - val_MinusLogProbMetric: 17.3085 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 154/1000
2023-09-27 06:38:09.861 
Epoch 154/1000 
	 loss: 16.9431, MinusLogProbMetric: 16.9431, val_loss: 17.1077, val_MinusLogProbMetric: 17.1077

Epoch 154: val_loss did not improve from 17.06159
196/196 - 39s - loss: 16.9431 - MinusLogProbMetric: 16.9431 - val_loss: 17.1077 - val_MinusLogProbMetric: 17.1077 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 155/1000
2023-09-27 06:38:48.575 
Epoch 155/1000 
	 loss: 17.0001, MinusLogProbMetric: 17.0001, val_loss: 17.3905, val_MinusLogProbMetric: 17.3905

Epoch 155: val_loss did not improve from 17.06159
196/196 - 39s - loss: 17.0001 - MinusLogProbMetric: 17.0001 - val_loss: 17.3905 - val_MinusLogProbMetric: 17.3905 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 156/1000
2023-09-27 06:39:27.258 
Epoch 156/1000 
	 loss: 17.0289, MinusLogProbMetric: 17.0289, val_loss: 17.2611, val_MinusLogProbMetric: 17.2611

Epoch 156: val_loss did not improve from 17.06159
196/196 - 39s - loss: 17.0289 - MinusLogProbMetric: 17.0289 - val_loss: 17.2611 - val_MinusLogProbMetric: 17.2611 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 157/1000
2023-09-27 06:40:06.370 
Epoch 157/1000 
	 loss: 16.9867, MinusLogProbMetric: 16.9867, val_loss: 17.3650, val_MinusLogProbMetric: 17.3650

Epoch 157: val_loss did not improve from 17.06159
196/196 - 39s - loss: 16.9867 - MinusLogProbMetric: 16.9867 - val_loss: 17.3650 - val_MinusLogProbMetric: 17.3650 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 158/1000
2023-09-27 06:40:45.206 
Epoch 158/1000 
	 loss: 16.9569, MinusLogProbMetric: 16.9569, val_loss: 17.2038, val_MinusLogProbMetric: 17.2038

Epoch 158: val_loss did not improve from 17.06159
196/196 - 39s - loss: 16.9569 - MinusLogProbMetric: 16.9569 - val_loss: 17.2038 - val_MinusLogProbMetric: 17.2038 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 159/1000
2023-09-27 06:41:23.872 
Epoch 159/1000 
	 loss: 16.9889, MinusLogProbMetric: 16.9889, val_loss: 17.1273, val_MinusLogProbMetric: 17.1273

Epoch 159: val_loss did not improve from 17.06159
196/196 - 39s - loss: 16.9889 - MinusLogProbMetric: 16.9889 - val_loss: 17.1273 - val_MinusLogProbMetric: 17.1273 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 160/1000
2023-09-27 06:42:02.522 
Epoch 160/1000 
	 loss: 16.9819, MinusLogProbMetric: 16.9819, val_loss: 17.0842, val_MinusLogProbMetric: 17.0842

Epoch 160: val_loss did not improve from 17.06159
196/196 - 39s - loss: 16.9819 - MinusLogProbMetric: 16.9819 - val_loss: 17.0842 - val_MinusLogProbMetric: 17.0842 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 161/1000
2023-09-27 06:42:41.094 
Epoch 161/1000 
	 loss: 17.0138, MinusLogProbMetric: 17.0138, val_loss: 17.2544, val_MinusLogProbMetric: 17.2544

Epoch 161: val_loss did not improve from 17.06159
196/196 - 39s - loss: 17.0138 - MinusLogProbMetric: 17.0138 - val_loss: 17.2544 - val_MinusLogProbMetric: 17.2544 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 162/1000
2023-09-27 06:43:19.695 
Epoch 162/1000 
	 loss: 16.9292, MinusLogProbMetric: 16.9292, val_loss: 17.1859, val_MinusLogProbMetric: 17.1859

Epoch 162: val_loss did not improve from 17.06159
196/196 - 39s - loss: 16.9292 - MinusLogProbMetric: 16.9292 - val_loss: 17.1859 - val_MinusLogProbMetric: 17.1859 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 163/1000
2023-09-27 06:43:58.568 
Epoch 163/1000 
	 loss: 17.0045, MinusLogProbMetric: 17.0045, val_loss: 17.0129, val_MinusLogProbMetric: 17.0129

Epoch 163: val_loss improved from 17.06159 to 17.01286, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 40s - loss: 17.0045 - MinusLogProbMetric: 17.0045 - val_loss: 17.0129 - val_MinusLogProbMetric: 17.0129 - lr: 0.0010 - 40s/epoch - 203ms/step
Epoch 164/1000
2023-09-27 06:44:37.856 
Epoch 164/1000 
	 loss: 16.9725, MinusLogProbMetric: 16.9725, val_loss: 17.2958, val_MinusLogProbMetric: 17.2958

Epoch 164: val_loss did not improve from 17.01286
196/196 - 38s - loss: 16.9725 - MinusLogProbMetric: 16.9725 - val_loss: 17.2958 - val_MinusLogProbMetric: 17.2958 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 165/1000
2023-09-27 06:45:16.431 
Epoch 165/1000 
	 loss: 16.9889, MinusLogProbMetric: 16.9889, val_loss: 17.1463, val_MinusLogProbMetric: 17.1463

Epoch 165: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.9889 - MinusLogProbMetric: 16.9889 - val_loss: 17.1463 - val_MinusLogProbMetric: 17.1463 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 166/1000
2023-09-27 06:45:54.833 
Epoch 166/1000 
	 loss: 16.9137, MinusLogProbMetric: 16.9137, val_loss: 17.1071, val_MinusLogProbMetric: 17.1071

Epoch 166: val_loss did not improve from 17.01286
196/196 - 38s - loss: 16.9137 - MinusLogProbMetric: 16.9137 - val_loss: 17.1071 - val_MinusLogProbMetric: 17.1071 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 167/1000
2023-09-27 06:46:33.573 
Epoch 167/1000 
	 loss: 16.9611, MinusLogProbMetric: 16.9611, val_loss: 17.0571, val_MinusLogProbMetric: 17.0571

Epoch 167: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.9611 - MinusLogProbMetric: 16.9611 - val_loss: 17.0571 - val_MinusLogProbMetric: 17.0571 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 168/1000
2023-09-27 06:47:12.247 
Epoch 168/1000 
	 loss: 16.9416, MinusLogProbMetric: 16.9416, val_loss: 17.3015, val_MinusLogProbMetric: 17.3015

Epoch 168: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.9416 - MinusLogProbMetric: 16.9416 - val_loss: 17.3015 - val_MinusLogProbMetric: 17.3015 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 169/1000
2023-09-27 06:47:50.887 
Epoch 169/1000 
	 loss: 16.8975, MinusLogProbMetric: 16.8975, val_loss: 17.0951, val_MinusLogProbMetric: 17.0951

Epoch 169: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.8975 - MinusLogProbMetric: 16.8975 - val_loss: 17.0951 - val_MinusLogProbMetric: 17.0951 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 170/1000
2023-09-27 06:48:29.305 
Epoch 170/1000 
	 loss: 16.9317, MinusLogProbMetric: 16.9317, val_loss: 17.1830, val_MinusLogProbMetric: 17.1830

Epoch 170: val_loss did not improve from 17.01286
196/196 - 38s - loss: 16.9317 - MinusLogProbMetric: 16.9317 - val_loss: 17.1830 - val_MinusLogProbMetric: 17.1830 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 171/1000
2023-09-27 06:49:07.686 
Epoch 171/1000 
	 loss: 16.9161, MinusLogProbMetric: 16.9161, val_loss: 17.8751, val_MinusLogProbMetric: 17.8751

Epoch 171: val_loss did not improve from 17.01286
196/196 - 38s - loss: 16.9161 - MinusLogProbMetric: 16.9161 - val_loss: 17.8751 - val_MinusLogProbMetric: 17.8751 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 172/1000
2023-09-27 06:49:46.192 
Epoch 172/1000 
	 loss: 16.9514, MinusLogProbMetric: 16.9514, val_loss: 17.2057, val_MinusLogProbMetric: 17.2057

Epoch 172: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.9514 - MinusLogProbMetric: 16.9514 - val_loss: 17.2057 - val_MinusLogProbMetric: 17.2057 - lr: 0.0010 - 39s/epoch - 196ms/step
Epoch 173/1000
2023-09-27 06:50:24.727 
Epoch 173/1000 
	 loss: 16.9183, MinusLogProbMetric: 16.9183, val_loss: 17.2054, val_MinusLogProbMetric: 17.2054

Epoch 173: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.9183 - MinusLogProbMetric: 16.9183 - val_loss: 17.2054 - val_MinusLogProbMetric: 17.2054 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 174/1000
2023-09-27 06:51:03.213 
Epoch 174/1000 
	 loss: 16.9295, MinusLogProbMetric: 16.9295, val_loss: 17.2434, val_MinusLogProbMetric: 17.2434

Epoch 174: val_loss did not improve from 17.01286
196/196 - 38s - loss: 16.9295 - MinusLogProbMetric: 16.9295 - val_loss: 17.2434 - val_MinusLogProbMetric: 17.2434 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 175/1000
2023-09-27 06:51:42.129 
Epoch 175/1000 
	 loss: 16.9393, MinusLogProbMetric: 16.9393, val_loss: 17.0282, val_MinusLogProbMetric: 17.0282

Epoch 175: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.9393 - MinusLogProbMetric: 16.9393 - val_loss: 17.0282 - val_MinusLogProbMetric: 17.0282 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 176/1000
2023-09-27 06:52:21.125 
Epoch 176/1000 
	 loss: 16.9684, MinusLogProbMetric: 16.9684, val_loss: 17.3012, val_MinusLogProbMetric: 17.3012

Epoch 176: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.9684 - MinusLogProbMetric: 16.9684 - val_loss: 17.3012 - val_MinusLogProbMetric: 17.3012 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 177/1000
2023-09-27 06:52:59.626 
Epoch 177/1000 
	 loss: 16.8837, MinusLogProbMetric: 16.8837, val_loss: 17.2802, val_MinusLogProbMetric: 17.2802

Epoch 177: val_loss did not improve from 17.01286
196/196 - 38s - loss: 16.8837 - MinusLogProbMetric: 16.8837 - val_loss: 17.2802 - val_MinusLogProbMetric: 17.2802 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 178/1000
2023-09-27 06:53:38.371 
Epoch 178/1000 
	 loss: 16.9339, MinusLogProbMetric: 16.9339, val_loss: 17.0434, val_MinusLogProbMetric: 17.0434

Epoch 178: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.9339 - MinusLogProbMetric: 16.9339 - val_loss: 17.0434 - val_MinusLogProbMetric: 17.0434 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 179/1000
2023-09-27 06:54:17.238 
Epoch 179/1000 
	 loss: 16.9399, MinusLogProbMetric: 16.9399, val_loss: 17.2336, val_MinusLogProbMetric: 17.2336

Epoch 179: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.9399 - MinusLogProbMetric: 16.9399 - val_loss: 17.2336 - val_MinusLogProbMetric: 17.2336 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 180/1000
2023-09-27 06:54:55.960 
Epoch 180/1000 
	 loss: 16.8967, MinusLogProbMetric: 16.8967, val_loss: 17.1026, val_MinusLogProbMetric: 17.1026

Epoch 180: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.8967 - MinusLogProbMetric: 16.8967 - val_loss: 17.1026 - val_MinusLogProbMetric: 17.1026 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 181/1000
2023-09-27 06:55:34.355 
Epoch 181/1000 
	 loss: 16.9121, MinusLogProbMetric: 16.9121, val_loss: 17.1548, val_MinusLogProbMetric: 17.1548

Epoch 181: val_loss did not improve from 17.01286
196/196 - 38s - loss: 16.9121 - MinusLogProbMetric: 16.9121 - val_loss: 17.1548 - val_MinusLogProbMetric: 17.1548 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 182/1000
2023-09-27 06:56:12.927 
Epoch 182/1000 
	 loss: 16.9298, MinusLogProbMetric: 16.9298, val_loss: 17.2369, val_MinusLogProbMetric: 17.2369

Epoch 182: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.9298 - MinusLogProbMetric: 16.9298 - val_loss: 17.2369 - val_MinusLogProbMetric: 17.2369 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 183/1000
2023-09-27 06:56:51.757 
Epoch 183/1000 
	 loss: 16.8958, MinusLogProbMetric: 16.8958, val_loss: 17.3321, val_MinusLogProbMetric: 17.3321

Epoch 183: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.8958 - MinusLogProbMetric: 16.8958 - val_loss: 17.3321 - val_MinusLogProbMetric: 17.3321 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 184/1000
2023-09-27 06:57:30.382 
Epoch 184/1000 
	 loss: 16.8851, MinusLogProbMetric: 16.8851, val_loss: 17.1507, val_MinusLogProbMetric: 17.1507

Epoch 184: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.8851 - MinusLogProbMetric: 16.8851 - val_loss: 17.1507 - val_MinusLogProbMetric: 17.1507 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 185/1000
2023-09-27 06:58:09.148 
Epoch 185/1000 
	 loss: 16.8724, MinusLogProbMetric: 16.8724, val_loss: 17.4147, val_MinusLogProbMetric: 17.4147

Epoch 185: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.8724 - MinusLogProbMetric: 16.8724 - val_loss: 17.4147 - val_MinusLogProbMetric: 17.4147 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 186/1000
2023-09-27 06:58:48.032 
Epoch 186/1000 
	 loss: 16.9394, MinusLogProbMetric: 16.9394, val_loss: 17.1076, val_MinusLogProbMetric: 17.1076

Epoch 186: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.9394 - MinusLogProbMetric: 16.9394 - val_loss: 17.1076 - val_MinusLogProbMetric: 17.1076 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 187/1000
2023-09-27 06:59:26.568 
Epoch 187/1000 
	 loss: 16.8779, MinusLogProbMetric: 16.8779, val_loss: 17.0274, val_MinusLogProbMetric: 17.0274

Epoch 187: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.8779 - MinusLogProbMetric: 16.8779 - val_loss: 17.0274 - val_MinusLogProbMetric: 17.0274 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 188/1000
2023-09-27 07:00:05.568 
Epoch 188/1000 
	 loss: 16.8996, MinusLogProbMetric: 16.8996, val_loss: 17.0968, val_MinusLogProbMetric: 17.0968

Epoch 188: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.8996 - MinusLogProbMetric: 16.8996 - val_loss: 17.0968 - val_MinusLogProbMetric: 17.0968 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 189/1000
2023-09-27 07:00:44.486 
Epoch 189/1000 
	 loss: 16.8607, MinusLogProbMetric: 16.8607, val_loss: 17.1476, val_MinusLogProbMetric: 17.1476

Epoch 189: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.8607 - MinusLogProbMetric: 16.8607 - val_loss: 17.1476 - val_MinusLogProbMetric: 17.1476 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 190/1000
2023-09-27 07:01:23.090 
Epoch 190/1000 
	 loss: 16.9064, MinusLogProbMetric: 16.9064, val_loss: 17.2113, val_MinusLogProbMetric: 17.2113

Epoch 190: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.9064 - MinusLogProbMetric: 16.9064 - val_loss: 17.2113 - val_MinusLogProbMetric: 17.2113 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 191/1000
2023-09-27 07:02:01.696 
Epoch 191/1000 
	 loss: 16.9126, MinusLogProbMetric: 16.9126, val_loss: 17.3823, val_MinusLogProbMetric: 17.3823

Epoch 191: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.9126 - MinusLogProbMetric: 16.9126 - val_loss: 17.3823 - val_MinusLogProbMetric: 17.3823 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 192/1000
2023-09-27 07:02:40.381 
Epoch 192/1000 
	 loss: 16.8779, MinusLogProbMetric: 16.8779, val_loss: 17.1754, val_MinusLogProbMetric: 17.1754

Epoch 192: val_loss did not improve from 17.01286
196/196 - 39s - loss: 16.8779 - MinusLogProbMetric: 16.8779 - val_loss: 17.1754 - val_MinusLogProbMetric: 17.1754 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 193/1000
2023-09-27 07:03:18.581 
Epoch 193/1000 
	 loss: 16.8711, MinusLogProbMetric: 16.8711, val_loss: 16.9918, val_MinusLogProbMetric: 16.9918

Epoch 193: val_loss improved from 17.01286 to 16.99179, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 39s - loss: 16.8711 - MinusLogProbMetric: 16.8711 - val_loss: 16.9918 - val_MinusLogProbMetric: 16.9918 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 194/1000
2023-09-27 07:03:57.620 
Epoch 194/1000 
	 loss: 16.8982, MinusLogProbMetric: 16.8982, val_loss: 17.1129, val_MinusLogProbMetric: 17.1129

Epoch 194: val_loss did not improve from 16.99179
196/196 - 38s - loss: 16.8982 - MinusLogProbMetric: 16.8982 - val_loss: 17.1129 - val_MinusLogProbMetric: 17.1129 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 195/1000
2023-09-27 07:04:36.581 
Epoch 195/1000 
	 loss: 16.8681, MinusLogProbMetric: 16.8681, val_loss: 17.0726, val_MinusLogProbMetric: 17.0726

Epoch 195: val_loss did not improve from 16.99179
196/196 - 39s - loss: 16.8681 - MinusLogProbMetric: 16.8681 - val_loss: 17.0726 - val_MinusLogProbMetric: 17.0726 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 196/1000
2023-09-27 07:05:15.448 
Epoch 196/1000 
	 loss: 16.8996, MinusLogProbMetric: 16.8996, val_loss: 17.2876, val_MinusLogProbMetric: 17.2876

Epoch 196: val_loss did not improve from 16.99179
196/196 - 39s - loss: 16.8996 - MinusLogProbMetric: 16.8996 - val_loss: 17.2876 - val_MinusLogProbMetric: 17.2876 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 197/1000
2023-09-27 07:05:54.043 
Epoch 197/1000 
	 loss: 16.8846, MinusLogProbMetric: 16.8846, val_loss: 17.2110, val_MinusLogProbMetric: 17.2110

Epoch 197: val_loss did not improve from 16.99179
196/196 - 39s - loss: 16.8846 - MinusLogProbMetric: 16.8846 - val_loss: 17.2110 - val_MinusLogProbMetric: 17.2110 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 198/1000
2023-09-27 07:06:32.836 
Epoch 198/1000 
	 loss: 16.9060, MinusLogProbMetric: 16.9060, val_loss: 17.1159, val_MinusLogProbMetric: 17.1159

Epoch 198: val_loss did not improve from 16.99179
196/196 - 39s - loss: 16.9060 - MinusLogProbMetric: 16.9060 - val_loss: 17.1159 - val_MinusLogProbMetric: 17.1159 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 199/1000
2023-09-27 07:07:11.653 
Epoch 199/1000 
	 loss: 16.8747, MinusLogProbMetric: 16.8747, val_loss: 17.3117, val_MinusLogProbMetric: 17.3117

Epoch 199: val_loss did not improve from 16.99179
196/196 - 39s - loss: 16.8747 - MinusLogProbMetric: 16.8747 - val_loss: 17.3117 - val_MinusLogProbMetric: 17.3117 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 200/1000
2023-09-27 07:07:50.103 
Epoch 200/1000 
	 loss: 16.8633, MinusLogProbMetric: 16.8633, val_loss: 17.0763, val_MinusLogProbMetric: 17.0763

Epoch 200: val_loss did not improve from 16.99179
196/196 - 38s - loss: 16.8633 - MinusLogProbMetric: 16.8633 - val_loss: 17.0763 - val_MinusLogProbMetric: 17.0763 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 201/1000
2023-09-27 07:08:28.714 
Epoch 201/1000 
	 loss: 16.8831, MinusLogProbMetric: 16.8831, val_loss: 17.1802, val_MinusLogProbMetric: 17.1802

Epoch 201: val_loss did not improve from 16.99179
196/196 - 39s - loss: 16.8831 - MinusLogProbMetric: 16.8831 - val_loss: 17.1802 - val_MinusLogProbMetric: 17.1802 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 202/1000
2023-09-27 07:09:07.226 
Epoch 202/1000 
	 loss: 16.8975, MinusLogProbMetric: 16.8975, val_loss: 17.1129, val_MinusLogProbMetric: 17.1129

Epoch 202: val_loss did not improve from 16.99179
196/196 - 39s - loss: 16.8975 - MinusLogProbMetric: 16.8975 - val_loss: 17.1129 - val_MinusLogProbMetric: 17.1129 - lr: 0.0010 - 39s/epoch - 196ms/step
Epoch 203/1000
2023-09-27 07:09:45.856 
Epoch 203/1000 
	 loss: 16.8668, MinusLogProbMetric: 16.8668, val_loss: 17.0280, val_MinusLogProbMetric: 17.0280

Epoch 203: val_loss did not improve from 16.99179
196/196 - 39s - loss: 16.8668 - MinusLogProbMetric: 16.8668 - val_loss: 17.0280 - val_MinusLogProbMetric: 17.0280 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 204/1000
2023-09-27 07:10:24.756 
Epoch 204/1000 
	 loss: 16.8374, MinusLogProbMetric: 16.8374, val_loss: 17.0690, val_MinusLogProbMetric: 17.0690

Epoch 204: val_loss did not improve from 16.99179
196/196 - 39s - loss: 16.8374 - MinusLogProbMetric: 16.8374 - val_loss: 17.0690 - val_MinusLogProbMetric: 17.0690 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 205/1000
2023-09-27 07:11:03.433 
Epoch 205/1000 
	 loss: 16.9116, MinusLogProbMetric: 16.9116, val_loss: 17.3152, val_MinusLogProbMetric: 17.3152

Epoch 205: val_loss did not improve from 16.99179
196/196 - 39s - loss: 16.9116 - MinusLogProbMetric: 16.9116 - val_loss: 17.3152 - val_MinusLogProbMetric: 17.3152 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 206/1000
2023-09-27 07:11:42.478 
Epoch 206/1000 
	 loss: 16.8647, MinusLogProbMetric: 16.8647, val_loss: 17.0968, val_MinusLogProbMetric: 17.0968

Epoch 206: val_loss did not improve from 16.99179
196/196 - 39s - loss: 16.8647 - MinusLogProbMetric: 16.8647 - val_loss: 17.0968 - val_MinusLogProbMetric: 17.0968 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 207/1000
2023-09-27 07:12:20.958 
Epoch 207/1000 
	 loss: 16.8841, MinusLogProbMetric: 16.8841, val_loss: 17.0626, val_MinusLogProbMetric: 17.0626

Epoch 207: val_loss did not improve from 16.99179
196/196 - 38s - loss: 16.8841 - MinusLogProbMetric: 16.8841 - val_loss: 17.0626 - val_MinusLogProbMetric: 17.0626 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 208/1000
2023-09-27 07:12:59.655 
Epoch 208/1000 
	 loss: 16.8144, MinusLogProbMetric: 16.8144, val_loss: 17.1300, val_MinusLogProbMetric: 17.1300

Epoch 208: val_loss did not improve from 16.99179
196/196 - 39s - loss: 16.8144 - MinusLogProbMetric: 16.8144 - val_loss: 17.1300 - val_MinusLogProbMetric: 17.1300 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 209/1000
2023-09-27 07:13:38.013 
Epoch 209/1000 
	 loss: 16.8479, MinusLogProbMetric: 16.8479, val_loss: 17.0320, val_MinusLogProbMetric: 17.0320

Epoch 209: val_loss did not improve from 16.99179
196/196 - 38s - loss: 16.8479 - MinusLogProbMetric: 16.8479 - val_loss: 17.0320 - val_MinusLogProbMetric: 17.0320 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 210/1000
2023-09-27 07:14:16.811 
Epoch 210/1000 
	 loss: 16.8624, MinusLogProbMetric: 16.8624, val_loss: 17.0550, val_MinusLogProbMetric: 17.0550

Epoch 210: val_loss did not improve from 16.99179
196/196 - 39s - loss: 16.8624 - MinusLogProbMetric: 16.8624 - val_loss: 17.0550 - val_MinusLogProbMetric: 17.0550 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 211/1000
2023-09-27 07:14:55.642 
Epoch 211/1000 
	 loss: 16.8375, MinusLogProbMetric: 16.8375, val_loss: 17.2317, val_MinusLogProbMetric: 17.2317

Epoch 211: val_loss did not improve from 16.99179
196/196 - 39s - loss: 16.8375 - MinusLogProbMetric: 16.8375 - val_loss: 17.2317 - val_MinusLogProbMetric: 17.2317 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 212/1000
2023-09-27 07:15:34.643 
Epoch 212/1000 
	 loss: 16.8528, MinusLogProbMetric: 16.8528, val_loss: 17.1677, val_MinusLogProbMetric: 17.1677

Epoch 212: val_loss did not improve from 16.99179
196/196 - 39s - loss: 16.8528 - MinusLogProbMetric: 16.8528 - val_loss: 17.1677 - val_MinusLogProbMetric: 17.1677 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 213/1000
2023-09-27 07:16:13.502 
Epoch 213/1000 
	 loss: 16.8380, MinusLogProbMetric: 16.8380, val_loss: 18.0862, val_MinusLogProbMetric: 18.0862

Epoch 213: val_loss did not improve from 16.99179
196/196 - 39s - loss: 16.8380 - MinusLogProbMetric: 16.8380 - val_loss: 18.0862 - val_MinusLogProbMetric: 18.0862 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 214/1000
2023-09-27 07:16:52.523 
Epoch 214/1000 
	 loss: 16.8455, MinusLogProbMetric: 16.8455, val_loss: 17.2529, val_MinusLogProbMetric: 17.2529

Epoch 214: val_loss did not improve from 16.99179
196/196 - 39s - loss: 16.8455 - MinusLogProbMetric: 16.8455 - val_loss: 17.2529 - val_MinusLogProbMetric: 17.2529 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 215/1000
2023-09-27 07:17:30.130 
Epoch 215/1000 
	 loss: 16.8412, MinusLogProbMetric: 16.8412, val_loss: 17.1882, val_MinusLogProbMetric: 17.1882

Epoch 215: val_loss did not improve from 16.99179
196/196 - 38s - loss: 16.8412 - MinusLogProbMetric: 16.8412 - val_loss: 17.1882 - val_MinusLogProbMetric: 17.1882 - lr: 0.0010 - 38s/epoch - 192ms/step
Epoch 216/1000
2023-09-27 07:18:07.012 
Epoch 216/1000 
	 loss: 16.8631, MinusLogProbMetric: 16.8631, val_loss: 17.1333, val_MinusLogProbMetric: 17.1333

Epoch 216: val_loss did not improve from 16.99179
196/196 - 37s - loss: 16.8631 - MinusLogProbMetric: 16.8631 - val_loss: 17.1333 - val_MinusLogProbMetric: 17.1333 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 217/1000
2023-09-27 07:18:41.330 
Epoch 217/1000 
	 loss: 16.8582, MinusLogProbMetric: 16.8582, val_loss: 17.1466, val_MinusLogProbMetric: 17.1466

Epoch 217: val_loss did not improve from 16.99179
196/196 - 34s - loss: 16.8582 - MinusLogProbMetric: 16.8582 - val_loss: 17.1466 - val_MinusLogProbMetric: 17.1466 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 218/1000
2023-09-27 07:19:16.470 
Epoch 218/1000 
	 loss: 16.8160, MinusLogProbMetric: 16.8160, val_loss: 17.0154, val_MinusLogProbMetric: 17.0154

Epoch 218: val_loss did not improve from 16.99179
196/196 - 35s - loss: 16.8160 - MinusLogProbMetric: 16.8160 - val_loss: 17.0154 - val_MinusLogProbMetric: 17.0154 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 219/1000
2023-09-27 07:19:54.945 
Epoch 219/1000 
	 loss: 16.8239, MinusLogProbMetric: 16.8239, val_loss: 16.9227, val_MinusLogProbMetric: 16.9227

Epoch 219: val_loss improved from 16.99179 to 16.92271, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 39s - loss: 16.8239 - MinusLogProbMetric: 16.8239 - val_loss: 16.9227 - val_MinusLogProbMetric: 16.9227 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 220/1000
2023-09-27 07:20:34.147 
Epoch 220/1000 
	 loss: 16.8397, MinusLogProbMetric: 16.8397, val_loss: 17.2211, val_MinusLogProbMetric: 17.2211

Epoch 220: val_loss did not improve from 16.92271
196/196 - 38s - loss: 16.8397 - MinusLogProbMetric: 16.8397 - val_loss: 17.2211 - val_MinusLogProbMetric: 17.2211 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 221/1000
2023-09-27 07:21:08.297 
Epoch 221/1000 
	 loss: 16.8342, MinusLogProbMetric: 16.8342, val_loss: 17.1564, val_MinusLogProbMetric: 17.1564

Epoch 221: val_loss did not improve from 16.92271
196/196 - 34s - loss: 16.8342 - MinusLogProbMetric: 16.8342 - val_loss: 17.1564 - val_MinusLogProbMetric: 17.1564 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 222/1000
2023-09-27 07:21:42.697 
Epoch 222/1000 
	 loss: 16.8481, MinusLogProbMetric: 16.8481, val_loss: 17.0590, val_MinusLogProbMetric: 17.0590

Epoch 222: val_loss did not improve from 16.92271
196/196 - 34s - loss: 16.8481 - MinusLogProbMetric: 16.8481 - val_loss: 17.0590 - val_MinusLogProbMetric: 17.0590 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 223/1000
2023-09-27 07:22:20.178 
Epoch 223/1000 
	 loss: 16.8338, MinusLogProbMetric: 16.8338, val_loss: 17.2979, val_MinusLogProbMetric: 17.2979

Epoch 223: val_loss did not improve from 16.92271
196/196 - 37s - loss: 16.8338 - MinusLogProbMetric: 16.8338 - val_loss: 17.2979 - val_MinusLogProbMetric: 17.2979 - lr: 0.0010 - 37s/epoch - 191ms/step
Epoch 224/1000
2023-09-27 07:22:58.695 
Epoch 224/1000 
	 loss: 16.8621, MinusLogProbMetric: 16.8621, val_loss: 17.1041, val_MinusLogProbMetric: 17.1041

Epoch 224: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.8621 - MinusLogProbMetric: 16.8621 - val_loss: 17.1041 - val_MinusLogProbMetric: 17.1041 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 225/1000
2023-09-27 07:23:36.688 
Epoch 225/1000 
	 loss: 16.8671, MinusLogProbMetric: 16.8671, val_loss: 17.1742, val_MinusLogProbMetric: 17.1742

Epoch 225: val_loss did not improve from 16.92271
196/196 - 38s - loss: 16.8671 - MinusLogProbMetric: 16.8671 - val_loss: 17.1742 - val_MinusLogProbMetric: 17.1742 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 226/1000
2023-09-27 07:24:15.217 
Epoch 226/1000 
	 loss: 16.8214, MinusLogProbMetric: 16.8214, val_loss: 17.0553, val_MinusLogProbMetric: 17.0553

Epoch 226: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.8214 - MinusLogProbMetric: 16.8214 - val_loss: 17.0553 - val_MinusLogProbMetric: 17.0553 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 227/1000
2023-09-27 07:24:53.660 
Epoch 227/1000 
	 loss: 16.8076, MinusLogProbMetric: 16.8076, val_loss: 17.1480, val_MinusLogProbMetric: 17.1480

Epoch 227: val_loss did not improve from 16.92271
196/196 - 38s - loss: 16.8076 - MinusLogProbMetric: 16.8076 - val_loss: 17.1480 - val_MinusLogProbMetric: 17.1480 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 228/1000
2023-09-27 07:25:31.966 
Epoch 228/1000 
	 loss: 16.8482, MinusLogProbMetric: 16.8482, val_loss: 17.3132, val_MinusLogProbMetric: 17.3132

Epoch 228: val_loss did not improve from 16.92271
196/196 - 38s - loss: 16.8482 - MinusLogProbMetric: 16.8482 - val_loss: 17.3132 - val_MinusLogProbMetric: 17.3132 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 229/1000
2023-09-27 07:26:10.132 
Epoch 229/1000 
	 loss: 16.8067, MinusLogProbMetric: 16.8067, val_loss: 17.0779, val_MinusLogProbMetric: 17.0779

Epoch 229: val_loss did not improve from 16.92271
196/196 - 38s - loss: 16.8067 - MinusLogProbMetric: 16.8067 - val_loss: 17.0779 - val_MinusLogProbMetric: 17.0779 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 230/1000
2023-09-27 07:26:48.589 
Epoch 230/1000 
	 loss: 16.8298, MinusLogProbMetric: 16.8298, val_loss: 17.2049, val_MinusLogProbMetric: 17.2049

Epoch 230: val_loss did not improve from 16.92271
196/196 - 38s - loss: 16.8298 - MinusLogProbMetric: 16.8298 - val_loss: 17.2049 - val_MinusLogProbMetric: 17.2049 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 231/1000
2023-09-27 07:27:27.239 
Epoch 231/1000 
	 loss: 16.8522, MinusLogProbMetric: 16.8522, val_loss: 17.0508, val_MinusLogProbMetric: 17.0508

Epoch 231: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.8522 - MinusLogProbMetric: 16.8522 - val_loss: 17.0508 - val_MinusLogProbMetric: 17.0508 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 232/1000
2023-09-27 07:28:06.245 
Epoch 232/1000 
	 loss: 16.8396, MinusLogProbMetric: 16.8396, val_loss: 17.1214, val_MinusLogProbMetric: 17.1214

Epoch 232: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.8396 - MinusLogProbMetric: 16.8396 - val_loss: 17.1214 - val_MinusLogProbMetric: 17.1214 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 233/1000
2023-09-27 07:28:45.054 
Epoch 233/1000 
	 loss: 16.8169, MinusLogProbMetric: 16.8169, val_loss: 17.0579, val_MinusLogProbMetric: 17.0579

Epoch 233: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.8169 - MinusLogProbMetric: 16.8169 - val_loss: 17.0579 - val_MinusLogProbMetric: 17.0579 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 234/1000
2023-09-27 07:29:24.206 
Epoch 234/1000 
	 loss: 16.8323, MinusLogProbMetric: 16.8323, val_loss: 16.9239, val_MinusLogProbMetric: 16.9239

Epoch 234: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.8323 - MinusLogProbMetric: 16.8323 - val_loss: 16.9239 - val_MinusLogProbMetric: 16.9239 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 235/1000
2023-09-27 07:30:02.872 
Epoch 235/1000 
	 loss: 16.8089, MinusLogProbMetric: 16.8089, val_loss: 17.1574, val_MinusLogProbMetric: 17.1574

Epoch 235: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.8089 - MinusLogProbMetric: 16.8089 - val_loss: 17.1574 - val_MinusLogProbMetric: 17.1574 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 236/1000
2023-09-27 07:30:41.761 
Epoch 236/1000 
	 loss: 16.8102, MinusLogProbMetric: 16.8102, val_loss: 17.2308, val_MinusLogProbMetric: 17.2308

Epoch 236: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.8102 - MinusLogProbMetric: 16.8102 - val_loss: 17.2308 - val_MinusLogProbMetric: 17.2308 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 237/1000
2023-09-27 07:31:20.190 
Epoch 237/1000 
	 loss: 16.8102, MinusLogProbMetric: 16.8102, val_loss: 17.1272, val_MinusLogProbMetric: 17.1272

Epoch 237: val_loss did not improve from 16.92271
196/196 - 38s - loss: 16.8102 - MinusLogProbMetric: 16.8102 - val_loss: 17.1272 - val_MinusLogProbMetric: 17.1272 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 238/1000
2023-09-27 07:31:58.749 
Epoch 238/1000 
	 loss: 16.8122, MinusLogProbMetric: 16.8122, val_loss: 17.0569, val_MinusLogProbMetric: 17.0569

Epoch 238: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.8122 - MinusLogProbMetric: 16.8122 - val_loss: 17.0569 - val_MinusLogProbMetric: 17.0569 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 239/1000
2023-09-27 07:32:37.290 
Epoch 239/1000 
	 loss: 16.7990, MinusLogProbMetric: 16.7990, val_loss: 16.9261, val_MinusLogProbMetric: 16.9261

Epoch 239: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.7990 - MinusLogProbMetric: 16.7990 - val_loss: 16.9261 - val_MinusLogProbMetric: 16.9261 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 240/1000
2023-09-27 07:33:16.027 
Epoch 240/1000 
	 loss: 16.7744, MinusLogProbMetric: 16.7744, val_loss: 16.9687, val_MinusLogProbMetric: 16.9687

Epoch 240: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.7744 - MinusLogProbMetric: 16.7744 - val_loss: 16.9687 - val_MinusLogProbMetric: 16.9687 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 241/1000
2023-09-27 07:33:54.813 
Epoch 241/1000 
	 loss: 16.8206, MinusLogProbMetric: 16.8206, val_loss: 17.2195, val_MinusLogProbMetric: 17.2195

Epoch 241: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.8206 - MinusLogProbMetric: 16.8206 - val_loss: 17.2195 - val_MinusLogProbMetric: 17.2195 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 242/1000
2023-09-27 07:34:33.473 
Epoch 242/1000 
	 loss: 16.8405, MinusLogProbMetric: 16.8405, val_loss: 17.0150, val_MinusLogProbMetric: 17.0150

Epoch 242: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.8405 - MinusLogProbMetric: 16.8405 - val_loss: 17.0150 - val_MinusLogProbMetric: 17.0150 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 243/1000
2023-09-27 07:35:12.014 
Epoch 243/1000 
	 loss: 16.7602, MinusLogProbMetric: 16.7602, val_loss: 16.9722, val_MinusLogProbMetric: 16.9722

Epoch 243: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.7602 - MinusLogProbMetric: 16.7602 - val_loss: 16.9722 - val_MinusLogProbMetric: 16.9722 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 244/1000
2023-09-27 07:35:50.605 
Epoch 244/1000 
	 loss: 16.7874, MinusLogProbMetric: 16.7874, val_loss: 17.0596, val_MinusLogProbMetric: 17.0596

Epoch 244: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.7874 - MinusLogProbMetric: 16.7874 - val_loss: 17.0596 - val_MinusLogProbMetric: 17.0596 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 245/1000
2023-09-27 07:36:29.652 
Epoch 245/1000 
	 loss: 16.7886, MinusLogProbMetric: 16.7886, val_loss: 17.0135, val_MinusLogProbMetric: 17.0135

Epoch 245: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.7886 - MinusLogProbMetric: 16.7886 - val_loss: 17.0135 - val_MinusLogProbMetric: 17.0135 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 246/1000
2023-09-27 07:37:08.463 
Epoch 246/1000 
	 loss: 16.7626, MinusLogProbMetric: 16.7626, val_loss: 17.2673, val_MinusLogProbMetric: 17.2673

Epoch 246: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.7626 - MinusLogProbMetric: 16.7626 - val_loss: 17.2673 - val_MinusLogProbMetric: 17.2673 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 247/1000
2023-09-27 07:37:47.274 
Epoch 247/1000 
	 loss: 16.8295, MinusLogProbMetric: 16.8295, val_loss: 16.9853, val_MinusLogProbMetric: 16.9853

Epoch 247: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.8295 - MinusLogProbMetric: 16.8295 - val_loss: 16.9853 - val_MinusLogProbMetric: 16.9853 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 248/1000
2023-09-27 07:38:25.614 
Epoch 248/1000 
	 loss: 16.7711, MinusLogProbMetric: 16.7711, val_loss: 17.0071, val_MinusLogProbMetric: 17.0071

Epoch 248: val_loss did not improve from 16.92271
196/196 - 38s - loss: 16.7711 - MinusLogProbMetric: 16.7711 - val_loss: 17.0071 - val_MinusLogProbMetric: 17.0071 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 249/1000
2023-09-27 07:39:03.993 
Epoch 249/1000 
	 loss: 16.8134, MinusLogProbMetric: 16.8134, val_loss: 17.2380, val_MinusLogProbMetric: 17.2380

Epoch 249: val_loss did not improve from 16.92271
196/196 - 38s - loss: 16.8134 - MinusLogProbMetric: 16.8134 - val_loss: 17.2380 - val_MinusLogProbMetric: 17.2380 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 250/1000
2023-09-27 07:39:43.048 
Epoch 250/1000 
	 loss: 16.8198, MinusLogProbMetric: 16.8198, val_loss: 17.1453, val_MinusLogProbMetric: 17.1453

Epoch 250: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.8198 - MinusLogProbMetric: 16.8198 - val_loss: 17.1453 - val_MinusLogProbMetric: 17.1453 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 251/1000
2023-09-27 07:40:22.211 
Epoch 251/1000 
	 loss: 16.7540, MinusLogProbMetric: 16.7540, val_loss: 17.1110, val_MinusLogProbMetric: 17.1110

Epoch 251: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.7540 - MinusLogProbMetric: 16.7540 - val_loss: 17.1110 - val_MinusLogProbMetric: 17.1110 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 252/1000
2023-09-27 07:41:01.195 
Epoch 252/1000 
	 loss: 16.7832, MinusLogProbMetric: 16.7832, val_loss: 17.2120, val_MinusLogProbMetric: 17.2120

Epoch 252: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.7832 - MinusLogProbMetric: 16.7832 - val_loss: 17.2120 - val_MinusLogProbMetric: 17.2120 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 253/1000
2023-09-27 07:41:39.657 
Epoch 253/1000 
	 loss: 16.7873, MinusLogProbMetric: 16.7873, val_loss: 17.2186, val_MinusLogProbMetric: 17.2186

Epoch 253: val_loss did not improve from 16.92271
196/196 - 38s - loss: 16.7873 - MinusLogProbMetric: 16.7873 - val_loss: 17.2186 - val_MinusLogProbMetric: 17.2186 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 254/1000
2023-09-27 07:42:18.462 
Epoch 254/1000 
	 loss: 16.8021, MinusLogProbMetric: 16.8021, val_loss: 17.2350, val_MinusLogProbMetric: 17.2350

Epoch 254: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.8021 - MinusLogProbMetric: 16.8021 - val_loss: 17.2350 - val_MinusLogProbMetric: 17.2350 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 255/1000
2023-09-27 07:42:57.151 
Epoch 255/1000 
	 loss: 16.8003, MinusLogProbMetric: 16.8003, val_loss: 17.1037, val_MinusLogProbMetric: 17.1037

Epoch 255: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.8003 - MinusLogProbMetric: 16.8003 - val_loss: 17.1037 - val_MinusLogProbMetric: 17.1037 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 256/1000
2023-09-27 07:43:36.026 
Epoch 256/1000 
	 loss: 16.7808, MinusLogProbMetric: 16.7808, val_loss: 17.0314, val_MinusLogProbMetric: 17.0314

Epoch 256: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.7808 - MinusLogProbMetric: 16.7808 - val_loss: 17.0314 - val_MinusLogProbMetric: 17.0314 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 257/1000
2023-09-27 07:44:15.550 
Epoch 257/1000 
	 loss: 16.8188, MinusLogProbMetric: 16.8188, val_loss: 17.1600, val_MinusLogProbMetric: 17.1600

Epoch 257: val_loss did not improve from 16.92271
196/196 - 40s - loss: 16.8188 - MinusLogProbMetric: 16.8188 - val_loss: 17.1600 - val_MinusLogProbMetric: 17.1600 - lr: 0.0010 - 40s/epoch - 202ms/step
Epoch 258/1000
2023-09-27 07:44:54.873 
Epoch 258/1000 
	 loss: 16.8037, MinusLogProbMetric: 16.8037, val_loss: 17.0632, val_MinusLogProbMetric: 17.0632

Epoch 258: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.8037 - MinusLogProbMetric: 16.8037 - val_loss: 17.0632 - val_MinusLogProbMetric: 17.0632 - lr: 0.0010 - 39s/epoch - 201ms/step
Epoch 259/1000
2023-09-27 07:45:33.553 
Epoch 259/1000 
	 loss: 16.7662, MinusLogProbMetric: 16.7662, val_loss: 17.0326, val_MinusLogProbMetric: 17.0326

Epoch 259: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.7662 - MinusLogProbMetric: 16.7662 - val_loss: 17.0326 - val_MinusLogProbMetric: 17.0326 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 260/1000
2023-09-27 07:46:12.849 
Epoch 260/1000 
	 loss: 16.7789, MinusLogProbMetric: 16.7789, val_loss: 17.1138, val_MinusLogProbMetric: 17.1138

Epoch 260: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.7789 - MinusLogProbMetric: 16.7789 - val_loss: 17.1138 - val_MinusLogProbMetric: 17.1138 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 261/1000
2023-09-27 07:46:51.713 
Epoch 261/1000 
	 loss: 16.7858, MinusLogProbMetric: 16.7858, val_loss: 17.1708, val_MinusLogProbMetric: 17.1708

Epoch 261: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.7858 - MinusLogProbMetric: 16.7858 - val_loss: 17.1708 - val_MinusLogProbMetric: 17.1708 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 262/1000
2023-09-27 07:47:30.518 
Epoch 262/1000 
	 loss: 16.8315, MinusLogProbMetric: 16.8315, val_loss: 17.2569, val_MinusLogProbMetric: 17.2569

Epoch 262: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.8315 - MinusLogProbMetric: 16.8315 - val_loss: 17.2569 - val_MinusLogProbMetric: 17.2569 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 263/1000
2023-09-27 07:48:09.793 
Epoch 263/1000 
	 loss: 16.7911, MinusLogProbMetric: 16.7911, val_loss: 17.0722, val_MinusLogProbMetric: 17.0722

Epoch 263: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.7911 - MinusLogProbMetric: 16.7911 - val_loss: 17.0722 - val_MinusLogProbMetric: 17.0722 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 264/1000
2023-09-27 07:48:48.735 
Epoch 264/1000 
	 loss: 16.7653, MinusLogProbMetric: 16.7653, val_loss: 17.1270, val_MinusLogProbMetric: 17.1270

Epoch 264: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.7653 - MinusLogProbMetric: 16.7653 - val_loss: 17.1270 - val_MinusLogProbMetric: 17.1270 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 265/1000
2023-09-27 07:49:28.440 
Epoch 265/1000 
	 loss: 16.8060, MinusLogProbMetric: 16.8060, val_loss: 17.2909, val_MinusLogProbMetric: 17.2909

Epoch 265: val_loss did not improve from 16.92271
196/196 - 40s - loss: 16.8060 - MinusLogProbMetric: 16.8060 - val_loss: 17.2909 - val_MinusLogProbMetric: 17.2909 - lr: 0.0010 - 40s/epoch - 203ms/step
Epoch 266/1000
2023-09-27 07:50:07.316 
Epoch 266/1000 
	 loss: 16.7597, MinusLogProbMetric: 16.7597, val_loss: 17.0423, val_MinusLogProbMetric: 17.0423

Epoch 266: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.7597 - MinusLogProbMetric: 16.7597 - val_loss: 17.0423 - val_MinusLogProbMetric: 17.0423 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 267/1000
2023-09-27 07:50:46.154 
Epoch 267/1000 
	 loss: 16.7692, MinusLogProbMetric: 16.7692, val_loss: 17.0972, val_MinusLogProbMetric: 17.0972

Epoch 267: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.7692 - MinusLogProbMetric: 16.7692 - val_loss: 17.0972 - val_MinusLogProbMetric: 17.0972 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 268/1000
2023-09-27 07:51:24.959 
Epoch 268/1000 
	 loss: 16.7684, MinusLogProbMetric: 16.7684, val_loss: 17.0780, val_MinusLogProbMetric: 17.0780

Epoch 268: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.7684 - MinusLogProbMetric: 16.7684 - val_loss: 17.0780 - val_MinusLogProbMetric: 17.0780 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 269/1000
2023-09-27 07:52:03.992 
Epoch 269/1000 
	 loss: 16.7844, MinusLogProbMetric: 16.7844, val_loss: 17.0595, val_MinusLogProbMetric: 17.0595

Epoch 269: val_loss did not improve from 16.92271
196/196 - 39s - loss: 16.7844 - MinusLogProbMetric: 16.7844 - val_loss: 17.0595 - val_MinusLogProbMetric: 17.0595 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 270/1000
2023-09-27 07:52:42.692 
Epoch 270/1000 
	 loss: 16.6011, MinusLogProbMetric: 16.6011, val_loss: 16.9037, val_MinusLogProbMetric: 16.9037

Epoch 270: val_loss improved from 16.92271 to 16.90370, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 39s - loss: 16.6011 - MinusLogProbMetric: 16.6011 - val_loss: 16.9037 - val_MinusLogProbMetric: 16.9037 - lr: 5.0000e-04 - 39s/epoch - 201ms/step
Epoch 271/1000
2023-09-27 07:53:22.455 
Epoch 271/1000 
	 loss: 16.5971, MinusLogProbMetric: 16.5971, val_loss: 16.8650, val_MinusLogProbMetric: 16.8650

Epoch 271: val_loss improved from 16.90370 to 16.86495, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 40s - loss: 16.5971 - MinusLogProbMetric: 16.5971 - val_loss: 16.8650 - val_MinusLogProbMetric: 16.8650 - lr: 5.0000e-04 - 40s/epoch - 203ms/step
Epoch 272/1000
2023-09-27 07:54:01.970 
Epoch 272/1000 
	 loss: 16.5738, MinusLogProbMetric: 16.5738, val_loss: 16.8871, val_MinusLogProbMetric: 16.8871

Epoch 272: val_loss did not improve from 16.86495
196/196 - 39s - loss: 16.5738 - MinusLogProbMetric: 16.5738 - val_loss: 16.8871 - val_MinusLogProbMetric: 16.8871 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 273/1000
2023-09-27 07:54:41.313 
Epoch 273/1000 
	 loss: 16.5981, MinusLogProbMetric: 16.5981, val_loss: 17.0345, val_MinusLogProbMetric: 17.0345

Epoch 273: val_loss did not improve from 16.86495
196/196 - 39s - loss: 16.5981 - MinusLogProbMetric: 16.5981 - val_loss: 17.0345 - val_MinusLogProbMetric: 17.0345 - lr: 5.0000e-04 - 39s/epoch - 201ms/step
Epoch 274/1000
2023-09-27 07:55:20.431 
Epoch 274/1000 
	 loss: 16.5899, MinusLogProbMetric: 16.5899, val_loss: 16.9365, val_MinusLogProbMetric: 16.9365

Epoch 274: val_loss did not improve from 16.86495
196/196 - 39s - loss: 16.5899 - MinusLogProbMetric: 16.5899 - val_loss: 16.9365 - val_MinusLogProbMetric: 16.9365 - lr: 5.0000e-04 - 39s/epoch - 200ms/step
Epoch 275/1000
2023-09-27 07:55:59.491 
Epoch 275/1000 
	 loss: 16.5997, MinusLogProbMetric: 16.5997, val_loss: 16.9021, val_MinusLogProbMetric: 16.9021

Epoch 275: val_loss did not improve from 16.86495
196/196 - 39s - loss: 16.5997 - MinusLogProbMetric: 16.5997 - val_loss: 16.9021 - val_MinusLogProbMetric: 16.9021 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 276/1000
2023-09-27 07:56:38.681 
Epoch 276/1000 
	 loss: 16.5755, MinusLogProbMetric: 16.5755, val_loss: 16.9088, val_MinusLogProbMetric: 16.9088

Epoch 276: val_loss did not improve from 16.86495
196/196 - 39s - loss: 16.5755 - MinusLogProbMetric: 16.5755 - val_loss: 16.9088 - val_MinusLogProbMetric: 16.9088 - lr: 5.0000e-04 - 39s/epoch - 200ms/step
Epoch 277/1000
2023-09-27 07:57:17.560 
Epoch 277/1000 
	 loss: 16.5931, MinusLogProbMetric: 16.5931, val_loss: 16.8936, val_MinusLogProbMetric: 16.8936

Epoch 277: val_loss did not improve from 16.86495
196/196 - 39s - loss: 16.5931 - MinusLogProbMetric: 16.5931 - val_loss: 16.8936 - val_MinusLogProbMetric: 16.8936 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 278/1000
2023-09-27 07:57:56.699 
Epoch 278/1000 
	 loss: 16.5844, MinusLogProbMetric: 16.5844, val_loss: 17.0241, val_MinusLogProbMetric: 17.0241

Epoch 278: val_loss did not improve from 16.86495
196/196 - 39s - loss: 16.5844 - MinusLogProbMetric: 16.5844 - val_loss: 17.0241 - val_MinusLogProbMetric: 17.0241 - lr: 5.0000e-04 - 39s/epoch - 200ms/step
Epoch 279/1000
2023-09-27 07:58:35.628 
Epoch 279/1000 
	 loss: 16.5958, MinusLogProbMetric: 16.5958, val_loss: 16.9085, val_MinusLogProbMetric: 16.9085

Epoch 279: val_loss did not improve from 16.86495
196/196 - 39s - loss: 16.5958 - MinusLogProbMetric: 16.5958 - val_loss: 16.9085 - val_MinusLogProbMetric: 16.9085 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 280/1000
2023-09-27 07:59:14.829 
Epoch 280/1000 
	 loss: 16.5876, MinusLogProbMetric: 16.5876, val_loss: 16.9927, val_MinusLogProbMetric: 16.9927

Epoch 280: val_loss did not improve from 16.86495
196/196 - 39s - loss: 16.5876 - MinusLogProbMetric: 16.5876 - val_loss: 16.9927 - val_MinusLogProbMetric: 16.9927 - lr: 5.0000e-04 - 39s/epoch - 200ms/step
Epoch 281/1000
2023-09-27 07:59:53.915 
Epoch 281/1000 
	 loss: 16.5833, MinusLogProbMetric: 16.5833, val_loss: 16.9334, val_MinusLogProbMetric: 16.9334

Epoch 281: val_loss did not improve from 16.86495
196/196 - 39s - loss: 16.5833 - MinusLogProbMetric: 16.5833 - val_loss: 16.9334 - val_MinusLogProbMetric: 16.9334 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 282/1000
2023-09-27 08:00:33.682 
Epoch 282/1000 
	 loss: 16.6042, MinusLogProbMetric: 16.6042, val_loss: 16.9144, val_MinusLogProbMetric: 16.9144

Epoch 282: val_loss did not improve from 16.86495
196/196 - 40s - loss: 16.6042 - MinusLogProbMetric: 16.6042 - val_loss: 16.9144 - val_MinusLogProbMetric: 16.9144 - lr: 5.0000e-04 - 40s/epoch - 203ms/step
Epoch 283/1000
2023-09-27 08:01:12.751 
Epoch 283/1000 
	 loss: 16.5960, MinusLogProbMetric: 16.5960, val_loss: 16.9595, val_MinusLogProbMetric: 16.9595

Epoch 283: val_loss did not improve from 16.86495
196/196 - 39s - loss: 16.5960 - MinusLogProbMetric: 16.5960 - val_loss: 16.9595 - val_MinusLogProbMetric: 16.9595 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 284/1000
2023-09-27 08:01:51.736 
Epoch 284/1000 
	 loss: 16.5941, MinusLogProbMetric: 16.5941, val_loss: 16.9481, val_MinusLogProbMetric: 16.9481

Epoch 284: val_loss did not improve from 16.86495
196/196 - 39s - loss: 16.5941 - MinusLogProbMetric: 16.5941 - val_loss: 16.9481 - val_MinusLogProbMetric: 16.9481 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 285/1000
2023-09-27 08:02:30.195 
Epoch 285/1000 
	 loss: 16.5936, MinusLogProbMetric: 16.5936, val_loss: 16.8644, val_MinusLogProbMetric: 16.8644

Epoch 285: val_loss improved from 16.86495 to 16.86435, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 39s - loss: 16.5936 - MinusLogProbMetric: 16.5936 - val_loss: 16.8644 - val_MinusLogProbMetric: 16.8644 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 286/1000
2023-09-27 08:03:09.558 
Epoch 286/1000 
	 loss: 16.5893, MinusLogProbMetric: 16.5893, val_loss: 16.8608, val_MinusLogProbMetric: 16.8608

Epoch 286: val_loss improved from 16.86435 to 16.86081, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 39s - loss: 16.5893 - MinusLogProbMetric: 16.5893 - val_loss: 16.8608 - val_MinusLogProbMetric: 16.8608 - lr: 5.0000e-04 - 39s/epoch - 201ms/step
Epoch 287/1000
2023-09-27 08:03:48.829 
Epoch 287/1000 
	 loss: 16.5770, MinusLogProbMetric: 16.5770, val_loss: 16.9058, val_MinusLogProbMetric: 16.9058

Epoch 287: val_loss did not improve from 16.86081
196/196 - 39s - loss: 16.5770 - MinusLogProbMetric: 16.5770 - val_loss: 16.9058 - val_MinusLogProbMetric: 16.9058 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 288/1000
2023-09-27 08:04:27.864 
Epoch 288/1000 
	 loss: 16.5884, MinusLogProbMetric: 16.5884, val_loss: 16.8677, val_MinusLogProbMetric: 16.8677

Epoch 288: val_loss did not improve from 16.86081
196/196 - 39s - loss: 16.5884 - MinusLogProbMetric: 16.5884 - val_loss: 16.8677 - val_MinusLogProbMetric: 16.8677 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 289/1000
2023-09-27 08:05:06.960 
Epoch 289/1000 
	 loss: 16.5704, MinusLogProbMetric: 16.5704, val_loss: 16.9279, val_MinusLogProbMetric: 16.9279

Epoch 289: val_loss did not improve from 16.86081
196/196 - 39s - loss: 16.5704 - MinusLogProbMetric: 16.5704 - val_loss: 16.9279 - val_MinusLogProbMetric: 16.9279 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 290/1000
2023-09-27 08:05:46.403 
Epoch 290/1000 
	 loss: 16.5770, MinusLogProbMetric: 16.5770, val_loss: 16.9200, val_MinusLogProbMetric: 16.9200

Epoch 290: val_loss did not improve from 16.86081
196/196 - 39s - loss: 16.5770 - MinusLogProbMetric: 16.5770 - val_loss: 16.9200 - val_MinusLogProbMetric: 16.9200 - lr: 5.0000e-04 - 39s/epoch - 201ms/step
Epoch 291/1000
2023-09-27 08:06:25.675 
Epoch 291/1000 
	 loss: 16.5764, MinusLogProbMetric: 16.5764, val_loss: 16.8591, val_MinusLogProbMetric: 16.8591

Epoch 291: val_loss improved from 16.86081 to 16.85906, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 40s - loss: 16.5764 - MinusLogProbMetric: 16.5764 - val_loss: 16.8591 - val_MinusLogProbMetric: 16.8591 - lr: 5.0000e-04 - 40s/epoch - 204ms/step
Epoch 292/1000
2023-09-27 08:07:05.812 
Epoch 292/1000 
	 loss: 16.5753, MinusLogProbMetric: 16.5753, val_loss: 16.8785, val_MinusLogProbMetric: 16.8785

Epoch 292: val_loss did not improve from 16.85906
196/196 - 40s - loss: 16.5753 - MinusLogProbMetric: 16.5753 - val_loss: 16.8785 - val_MinusLogProbMetric: 16.8785 - lr: 5.0000e-04 - 40s/epoch - 202ms/step
Epoch 293/1000
2023-09-27 08:07:44.643 
Epoch 293/1000 
	 loss: 16.5764, MinusLogProbMetric: 16.5764, val_loss: 16.8920, val_MinusLogProbMetric: 16.8920

Epoch 293: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5764 - MinusLogProbMetric: 16.5764 - val_loss: 16.8920 - val_MinusLogProbMetric: 16.8920 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 294/1000
2023-09-27 08:08:23.579 
Epoch 294/1000 
	 loss: 16.5922, MinusLogProbMetric: 16.5922, val_loss: 16.9557, val_MinusLogProbMetric: 16.9557

Epoch 294: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5922 - MinusLogProbMetric: 16.5922 - val_loss: 16.9557 - val_MinusLogProbMetric: 16.9557 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 295/1000
2023-09-27 08:09:02.393 
Epoch 295/1000 
	 loss: 16.5893, MinusLogProbMetric: 16.5893, val_loss: 17.0716, val_MinusLogProbMetric: 17.0716

Epoch 295: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5893 - MinusLogProbMetric: 16.5893 - val_loss: 17.0716 - val_MinusLogProbMetric: 17.0716 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 296/1000
2023-09-27 08:09:41.265 
Epoch 296/1000 
	 loss: 16.5868, MinusLogProbMetric: 16.5868, val_loss: 16.9118, val_MinusLogProbMetric: 16.9118

Epoch 296: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5868 - MinusLogProbMetric: 16.5868 - val_loss: 16.9118 - val_MinusLogProbMetric: 16.9118 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 297/1000
2023-09-27 08:10:20.440 
Epoch 297/1000 
	 loss: 16.5646, MinusLogProbMetric: 16.5646, val_loss: 16.9114, val_MinusLogProbMetric: 16.9114

Epoch 297: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5646 - MinusLogProbMetric: 16.5646 - val_loss: 16.9114 - val_MinusLogProbMetric: 16.9114 - lr: 5.0000e-04 - 39s/epoch - 200ms/step
Epoch 298/1000
2023-09-27 08:10:59.316 
Epoch 298/1000 
	 loss: 16.5853, MinusLogProbMetric: 16.5853, val_loss: 16.9267, val_MinusLogProbMetric: 16.9267

Epoch 298: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5853 - MinusLogProbMetric: 16.5853 - val_loss: 16.9267 - val_MinusLogProbMetric: 16.9267 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 299/1000
2023-09-27 08:11:37.704 
Epoch 299/1000 
	 loss: 16.5963, MinusLogProbMetric: 16.5963, val_loss: 16.9686, val_MinusLogProbMetric: 16.9686

Epoch 299: val_loss did not improve from 16.85906
196/196 - 38s - loss: 16.5963 - MinusLogProbMetric: 16.5963 - val_loss: 16.9686 - val_MinusLogProbMetric: 16.9686 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 300/1000
2023-09-27 08:12:16.596 
Epoch 300/1000 
	 loss: 16.5712, MinusLogProbMetric: 16.5712, val_loss: 16.8593, val_MinusLogProbMetric: 16.8593

Epoch 300: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5712 - MinusLogProbMetric: 16.5712 - val_loss: 16.8593 - val_MinusLogProbMetric: 16.8593 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 301/1000
2023-09-27 08:12:55.367 
Epoch 301/1000 
	 loss: 16.5755, MinusLogProbMetric: 16.5755, val_loss: 16.9497, val_MinusLogProbMetric: 16.9497

Epoch 301: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5755 - MinusLogProbMetric: 16.5755 - val_loss: 16.9497 - val_MinusLogProbMetric: 16.9497 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 302/1000
2023-09-27 08:13:33.961 
Epoch 302/1000 
	 loss: 16.5915, MinusLogProbMetric: 16.5915, val_loss: 16.8933, val_MinusLogProbMetric: 16.8933

Epoch 302: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5915 - MinusLogProbMetric: 16.5915 - val_loss: 16.8933 - val_MinusLogProbMetric: 16.8933 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 303/1000
2023-09-27 08:14:12.854 
Epoch 303/1000 
	 loss: 16.5675, MinusLogProbMetric: 16.5675, val_loss: 16.9252, val_MinusLogProbMetric: 16.9252

Epoch 303: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5675 - MinusLogProbMetric: 16.5675 - val_loss: 16.9252 - val_MinusLogProbMetric: 16.9252 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 304/1000
2023-09-27 08:14:52.061 
Epoch 304/1000 
	 loss: 16.5822, MinusLogProbMetric: 16.5822, val_loss: 16.9837, val_MinusLogProbMetric: 16.9837

Epoch 304: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5822 - MinusLogProbMetric: 16.5822 - val_loss: 16.9837 - val_MinusLogProbMetric: 16.9837 - lr: 5.0000e-04 - 39s/epoch - 200ms/step
Epoch 305/1000
2023-09-27 08:15:30.646 
Epoch 305/1000 
	 loss: 16.5800, MinusLogProbMetric: 16.5800, val_loss: 16.9414, val_MinusLogProbMetric: 16.9414

Epoch 305: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5800 - MinusLogProbMetric: 16.5800 - val_loss: 16.9414 - val_MinusLogProbMetric: 16.9414 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 306/1000
2023-09-27 08:16:09.583 
Epoch 306/1000 
	 loss: 16.5591, MinusLogProbMetric: 16.5591, val_loss: 16.9032, val_MinusLogProbMetric: 16.9032

Epoch 306: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5591 - MinusLogProbMetric: 16.5591 - val_loss: 16.9032 - val_MinusLogProbMetric: 16.9032 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 307/1000
2023-09-27 08:16:48.251 
Epoch 307/1000 
	 loss: 16.5684, MinusLogProbMetric: 16.5684, val_loss: 16.9855, val_MinusLogProbMetric: 16.9855

Epoch 307: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5684 - MinusLogProbMetric: 16.5684 - val_loss: 16.9855 - val_MinusLogProbMetric: 16.9855 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 308/1000
2023-09-27 08:17:27.195 
Epoch 308/1000 
	 loss: 16.5840, MinusLogProbMetric: 16.5840, val_loss: 16.9178, val_MinusLogProbMetric: 16.9178

Epoch 308: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5840 - MinusLogProbMetric: 16.5840 - val_loss: 16.9178 - val_MinusLogProbMetric: 16.9178 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 309/1000
2023-09-27 08:18:06.169 
Epoch 309/1000 
	 loss: 16.5880, MinusLogProbMetric: 16.5880, val_loss: 16.8937, val_MinusLogProbMetric: 16.8937

Epoch 309: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5880 - MinusLogProbMetric: 16.5880 - val_loss: 16.8937 - val_MinusLogProbMetric: 16.8937 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 310/1000
2023-09-27 08:18:45.249 
Epoch 310/1000 
	 loss: 16.5730, MinusLogProbMetric: 16.5730, val_loss: 16.9052, val_MinusLogProbMetric: 16.9052

Epoch 310: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5730 - MinusLogProbMetric: 16.5730 - val_loss: 16.9052 - val_MinusLogProbMetric: 16.9052 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 311/1000
2023-09-27 08:19:23.820 
Epoch 311/1000 
	 loss: 16.5772, MinusLogProbMetric: 16.5772, val_loss: 16.9127, val_MinusLogProbMetric: 16.9127

Epoch 311: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5772 - MinusLogProbMetric: 16.5772 - val_loss: 16.9127 - val_MinusLogProbMetric: 16.9127 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 312/1000
2023-09-27 08:20:02.797 
Epoch 312/1000 
	 loss: 16.5640, MinusLogProbMetric: 16.5640, val_loss: 16.9243, val_MinusLogProbMetric: 16.9243

Epoch 312: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5640 - MinusLogProbMetric: 16.5640 - val_loss: 16.9243 - val_MinusLogProbMetric: 16.9243 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 313/1000
2023-09-27 08:20:41.496 
Epoch 313/1000 
	 loss: 16.5712, MinusLogProbMetric: 16.5712, val_loss: 17.0197, val_MinusLogProbMetric: 17.0197

Epoch 313: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5712 - MinusLogProbMetric: 16.5712 - val_loss: 17.0197 - val_MinusLogProbMetric: 17.0197 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 314/1000
2023-09-27 08:21:20.261 
Epoch 314/1000 
	 loss: 16.5662, MinusLogProbMetric: 16.5662, val_loss: 16.9263, val_MinusLogProbMetric: 16.9263

Epoch 314: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5662 - MinusLogProbMetric: 16.5662 - val_loss: 16.9263 - val_MinusLogProbMetric: 16.9263 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 315/1000
2023-09-27 08:21:58.995 
Epoch 315/1000 
	 loss: 16.5650, MinusLogProbMetric: 16.5650, val_loss: 17.0548, val_MinusLogProbMetric: 17.0548

Epoch 315: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5650 - MinusLogProbMetric: 16.5650 - val_loss: 17.0548 - val_MinusLogProbMetric: 17.0548 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 316/1000
2023-09-27 08:22:37.441 
Epoch 316/1000 
	 loss: 16.5725, MinusLogProbMetric: 16.5725, val_loss: 16.9178, val_MinusLogProbMetric: 16.9178

Epoch 316: val_loss did not improve from 16.85906
196/196 - 38s - loss: 16.5725 - MinusLogProbMetric: 16.5725 - val_loss: 16.9178 - val_MinusLogProbMetric: 16.9178 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 317/1000
2023-09-27 08:23:16.391 
Epoch 317/1000 
	 loss: 16.5979, MinusLogProbMetric: 16.5979, val_loss: 16.8957, val_MinusLogProbMetric: 16.8957

Epoch 317: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5979 - MinusLogProbMetric: 16.5979 - val_loss: 16.8957 - val_MinusLogProbMetric: 16.8957 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 318/1000
2023-09-27 08:23:55.329 
Epoch 318/1000 
	 loss: 16.5645, MinusLogProbMetric: 16.5645, val_loss: 16.8935, val_MinusLogProbMetric: 16.8935

Epoch 318: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5645 - MinusLogProbMetric: 16.5645 - val_loss: 16.8935 - val_MinusLogProbMetric: 16.8935 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 319/1000
2023-09-27 08:24:33.956 
Epoch 319/1000 
	 loss: 16.5775, MinusLogProbMetric: 16.5775, val_loss: 16.9310, val_MinusLogProbMetric: 16.9310

Epoch 319: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5775 - MinusLogProbMetric: 16.5775 - val_loss: 16.9310 - val_MinusLogProbMetric: 16.9310 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 320/1000
2023-09-27 08:25:12.893 
Epoch 320/1000 
	 loss: 16.5716, MinusLogProbMetric: 16.5716, val_loss: 16.8893, val_MinusLogProbMetric: 16.8893

Epoch 320: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5716 - MinusLogProbMetric: 16.5716 - val_loss: 16.8893 - val_MinusLogProbMetric: 16.8893 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 321/1000
2023-09-27 08:25:51.785 
Epoch 321/1000 
	 loss: 16.5622, MinusLogProbMetric: 16.5622, val_loss: 16.9803, val_MinusLogProbMetric: 16.9803

Epoch 321: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5622 - MinusLogProbMetric: 16.5622 - val_loss: 16.9803 - val_MinusLogProbMetric: 16.9803 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 322/1000
2023-09-27 08:26:30.360 
Epoch 322/1000 
	 loss: 16.5682, MinusLogProbMetric: 16.5682, val_loss: 16.9188, val_MinusLogProbMetric: 16.9188

Epoch 322: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5682 - MinusLogProbMetric: 16.5682 - val_loss: 16.9188 - val_MinusLogProbMetric: 16.9188 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 323/1000
2023-09-27 08:27:09.203 
Epoch 323/1000 
	 loss: 16.5646, MinusLogProbMetric: 16.5646, val_loss: 17.0258, val_MinusLogProbMetric: 17.0258

Epoch 323: val_loss did not improve from 16.85906
196/196 - 39s - loss: 16.5646 - MinusLogProbMetric: 16.5646 - val_loss: 17.0258 - val_MinusLogProbMetric: 17.0258 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 324/1000
2023-09-27 08:27:48.431 
Epoch 324/1000 
	 loss: 16.5588, MinusLogProbMetric: 16.5588, val_loss: 16.8367, val_MinusLogProbMetric: 16.8367

Epoch 324: val_loss improved from 16.85906 to 16.83673, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 40s - loss: 16.5588 - MinusLogProbMetric: 16.5588 - val_loss: 16.8367 - val_MinusLogProbMetric: 16.8367 - lr: 5.0000e-04 - 40s/epoch - 203ms/step
Epoch 325/1000
2023-09-27 08:28:27.867 
Epoch 325/1000 
	 loss: 16.5741, MinusLogProbMetric: 16.5741, val_loss: 17.0415, val_MinusLogProbMetric: 17.0415

Epoch 325: val_loss did not improve from 16.83673
196/196 - 39s - loss: 16.5741 - MinusLogProbMetric: 16.5741 - val_loss: 17.0415 - val_MinusLogProbMetric: 17.0415 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 326/1000
2023-09-27 08:29:06.543 
Epoch 326/1000 
	 loss: 16.5873, MinusLogProbMetric: 16.5873, val_loss: 16.9103, val_MinusLogProbMetric: 16.9103

Epoch 326: val_loss did not improve from 16.83673
196/196 - 39s - loss: 16.5873 - MinusLogProbMetric: 16.5873 - val_loss: 16.9103 - val_MinusLogProbMetric: 16.9103 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 327/1000
2023-09-27 08:29:44.955 
Epoch 327/1000 
	 loss: 16.5659, MinusLogProbMetric: 16.5659, val_loss: 17.0133, val_MinusLogProbMetric: 17.0133

Epoch 327: val_loss did not improve from 16.83673
196/196 - 38s - loss: 16.5659 - MinusLogProbMetric: 16.5659 - val_loss: 17.0133 - val_MinusLogProbMetric: 17.0133 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 328/1000
2023-09-27 08:30:23.559 
Epoch 328/1000 
	 loss: 16.5651, MinusLogProbMetric: 16.5651, val_loss: 16.9493, val_MinusLogProbMetric: 16.9493

Epoch 328: val_loss did not improve from 16.83673
196/196 - 39s - loss: 16.5651 - MinusLogProbMetric: 16.5651 - val_loss: 16.9493 - val_MinusLogProbMetric: 16.9493 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 329/1000
2023-09-27 08:31:02.311 
Epoch 329/1000 
	 loss: 16.5721, MinusLogProbMetric: 16.5721, val_loss: 16.8569, val_MinusLogProbMetric: 16.8569

Epoch 329: val_loss did not improve from 16.83673
196/196 - 39s - loss: 16.5721 - MinusLogProbMetric: 16.5721 - val_loss: 16.8569 - val_MinusLogProbMetric: 16.8569 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 330/1000
2023-09-27 08:31:40.980 
Epoch 330/1000 
	 loss: 16.5605, MinusLogProbMetric: 16.5605, val_loss: 16.9599, val_MinusLogProbMetric: 16.9599

Epoch 330: val_loss did not improve from 16.83673
196/196 - 39s - loss: 16.5605 - MinusLogProbMetric: 16.5605 - val_loss: 16.9599 - val_MinusLogProbMetric: 16.9599 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 331/1000
2023-09-27 08:32:19.693 
Epoch 331/1000 
	 loss: 16.5749, MinusLogProbMetric: 16.5749, val_loss: 16.9566, val_MinusLogProbMetric: 16.9566

Epoch 331: val_loss did not improve from 16.83673
196/196 - 39s - loss: 16.5749 - MinusLogProbMetric: 16.5749 - val_loss: 16.9566 - val_MinusLogProbMetric: 16.9566 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 332/1000
2023-09-27 08:32:58.605 
Epoch 332/1000 
	 loss: 16.5663, MinusLogProbMetric: 16.5663, val_loss: 16.9511, val_MinusLogProbMetric: 16.9511

Epoch 332: val_loss did not improve from 16.83673
196/196 - 39s - loss: 16.5663 - MinusLogProbMetric: 16.5663 - val_loss: 16.9511 - val_MinusLogProbMetric: 16.9511 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 333/1000
2023-09-27 08:33:37.121 
Epoch 333/1000 
	 loss: 16.5718, MinusLogProbMetric: 16.5718, val_loss: 16.8914, val_MinusLogProbMetric: 16.8914

Epoch 333: val_loss did not improve from 16.83673
196/196 - 39s - loss: 16.5718 - MinusLogProbMetric: 16.5718 - val_loss: 16.8914 - val_MinusLogProbMetric: 16.8914 - lr: 5.0000e-04 - 39s/epoch - 196ms/step
Epoch 334/1000
2023-09-27 08:34:16.181 
Epoch 334/1000 
	 loss: 16.5541, MinusLogProbMetric: 16.5541, val_loss: 16.9519, val_MinusLogProbMetric: 16.9519

Epoch 334: val_loss did not improve from 16.83673
196/196 - 39s - loss: 16.5541 - MinusLogProbMetric: 16.5541 - val_loss: 16.9519 - val_MinusLogProbMetric: 16.9519 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 335/1000
2023-09-27 08:34:55.120 
Epoch 335/1000 
	 loss: 16.5749, MinusLogProbMetric: 16.5749, val_loss: 16.8733, val_MinusLogProbMetric: 16.8733

Epoch 335: val_loss did not improve from 16.83673
196/196 - 39s - loss: 16.5749 - MinusLogProbMetric: 16.5749 - val_loss: 16.8733 - val_MinusLogProbMetric: 16.8733 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 336/1000
2023-09-27 08:35:33.947 
Epoch 336/1000 
	 loss: 16.5734, MinusLogProbMetric: 16.5734, val_loss: 16.8684, val_MinusLogProbMetric: 16.8684

Epoch 336: val_loss did not improve from 16.83673
196/196 - 39s - loss: 16.5734 - MinusLogProbMetric: 16.5734 - val_loss: 16.8684 - val_MinusLogProbMetric: 16.8684 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 337/1000
2023-09-27 08:36:12.801 
Epoch 337/1000 
	 loss: 16.5607, MinusLogProbMetric: 16.5607, val_loss: 16.8867, val_MinusLogProbMetric: 16.8867

Epoch 337: val_loss did not improve from 16.83673
196/196 - 39s - loss: 16.5607 - MinusLogProbMetric: 16.5607 - val_loss: 16.8867 - val_MinusLogProbMetric: 16.8867 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 338/1000
2023-09-27 08:36:51.540 
Epoch 338/1000 
	 loss: 16.5653, MinusLogProbMetric: 16.5653, val_loss: 16.8891, val_MinusLogProbMetric: 16.8891

Epoch 338: val_loss did not improve from 16.83673
196/196 - 39s - loss: 16.5653 - MinusLogProbMetric: 16.5653 - val_loss: 16.8891 - val_MinusLogProbMetric: 16.8891 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 339/1000
2023-09-27 08:37:30.476 
Epoch 339/1000 
	 loss: 16.5397, MinusLogProbMetric: 16.5397, val_loss: 16.8747, val_MinusLogProbMetric: 16.8747

Epoch 339: val_loss did not improve from 16.83673
196/196 - 39s - loss: 16.5397 - MinusLogProbMetric: 16.5397 - val_loss: 16.8747 - val_MinusLogProbMetric: 16.8747 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 340/1000
2023-09-27 08:38:09.128 
Epoch 340/1000 
	 loss: 16.5561, MinusLogProbMetric: 16.5561, val_loss: 16.8900, val_MinusLogProbMetric: 16.8900

Epoch 340: val_loss did not improve from 16.83673
196/196 - 39s - loss: 16.5561 - MinusLogProbMetric: 16.5561 - val_loss: 16.8900 - val_MinusLogProbMetric: 16.8900 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 341/1000
2023-09-27 08:38:48.318 
Epoch 341/1000 
	 loss: 16.5560, MinusLogProbMetric: 16.5560, val_loss: 16.8762, val_MinusLogProbMetric: 16.8762

Epoch 341: val_loss did not improve from 16.83673
196/196 - 39s - loss: 16.5560 - MinusLogProbMetric: 16.5560 - val_loss: 16.8762 - val_MinusLogProbMetric: 16.8762 - lr: 5.0000e-04 - 39s/epoch - 200ms/step
Epoch 342/1000
2023-09-27 08:39:28.874 
Epoch 342/1000 
	 loss: 16.5525, MinusLogProbMetric: 16.5525, val_loss: 16.8770, val_MinusLogProbMetric: 16.8770

Epoch 342: val_loss did not improve from 16.83673
196/196 - 41s - loss: 16.5525 - MinusLogProbMetric: 16.5525 - val_loss: 16.8770 - val_MinusLogProbMetric: 16.8770 - lr: 5.0000e-04 - 41s/epoch - 207ms/step
Epoch 343/1000
2023-09-27 08:40:10.022 
Epoch 343/1000 
	 loss: 16.5628, MinusLogProbMetric: 16.5628, val_loss: 16.8988, val_MinusLogProbMetric: 16.8988

Epoch 343: val_loss did not improve from 16.83673
196/196 - 41s - loss: 16.5628 - MinusLogProbMetric: 16.5628 - val_loss: 16.8988 - val_MinusLogProbMetric: 16.8988 - lr: 5.0000e-04 - 41s/epoch - 210ms/step
Epoch 344/1000
2023-09-27 08:40:49.506 
Epoch 344/1000 
	 loss: 16.5473, MinusLogProbMetric: 16.5473, val_loss: 16.9635, val_MinusLogProbMetric: 16.9635

Epoch 344: val_loss did not improve from 16.83673
196/196 - 39s - loss: 16.5473 - MinusLogProbMetric: 16.5473 - val_loss: 16.9635 - val_MinusLogProbMetric: 16.9635 - lr: 5.0000e-04 - 39s/epoch - 201ms/step
Epoch 345/1000
2023-09-27 08:41:29.579 
Epoch 345/1000 
	 loss: 16.5672, MinusLogProbMetric: 16.5672, val_loss: 16.9605, val_MinusLogProbMetric: 16.9605

Epoch 345: val_loss did not improve from 16.83673
196/196 - 40s - loss: 16.5672 - MinusLogProbMetric: 16.5672 - val_loss: 16.9605 - val_MinusLogProbMetric: 16.9605 - lr: 5.0000e-04 - 40s/epoch - 204ms/step
Epoch 346/1000
2023-09-27 08:42:09.364 
Epoch 346/1000 
	 loss: 16.5636, MinusLogProbMetric: 16.5636, val_loss: 16.8963, val_MinusLogProbMetric: 16.8963

Epoch 346: val_loss did not improve from 16.83673
196/196 - 40s - loss: 16.5636 - MinusLogProbMetric: 16.5636 - val_loss: 16.8963 - val_MinusLogProbMetric: 16.8963 - lr: 5.0000e-04 - 40s/epoch - 203ms/step
Epoch 347/1000
2023-09-27 08:42:49.960 
Epoch 347/1000 
	 loss: 16.5465, MinusLogProbMetric: 16.5465, val_loss: 17.0137, val_MinusLogProbMetric: 17.0137

Epoch 347: val_loss did not improve from 16.83673
196/196 - 41s - loss: 16.5465 - MinusLogProbMetric: 16.5465 - val_loss: 17.0137 - val_MinusLogProbMetric: 17.0137 - lr: 5.0000e-04 - 41s/epoch - 207ms/step
Epoch 348/1000
2023-09-27 08:43:30.557 
Epoch 348/1000 
	 loss: 16.5761, MinusLogProbMetric: 16.5761, val_loss: 16.8612, val_MinusLogProbMetric: 16.8612

Epoch 348: val_loss did not improve from 16.83673
196/196 - 41s - loss: 16.5761 - MinusLogProbMetric: 16.5761 - val_loss: 16.8612 - val_MinusLogProbMetric: 16.8612 - lr: 5.0000e-04 - 41s/epoch - 207ms/step
Epoch 349/1000
2023-09-27 08:44:10.316 
Epoch 349/1000 
	 loss: 16.5498, MinusLogProbMetric: 16.5498, val_loss: 16.8918, val_MinusLogProbMetric: 16.8918

Epoch 349: val_loss did not improve from 16.83673
196/196 - 40s - loss: 16.5498 - MinusLogProbMetric: 16.5498 - val_loss: 16.8918 - val_MinusLogProbMetric: 16.8918 - lr: 5.0000e-04 - 40s/epoch - 203ms/step
Epoch 350/1000
2023-09-27 08:44:50.284 
Epoch 350/1000 
	 loss: 16.5519, MinusLogProbMetric: 16.5519, val_loss: 16.9848, val_MinusLogProbMetric: 16.9848

Epoch 350: val_loss did not improve from 16.83673
196/196 - 40s - loss: 16.5519 - MinusLogProbMetric: 16.5519 - val_loss: 16.9848 - val_MinusLogProbMetric: 16.9848 - lr: 5.0000e-04 - 40s/epoch - 204ms/step
Epoch 351/1000
2023-09-27 08:45:30.587 
Epoch 351/1000 
	 loss: 16.5656, MinusLogProbMetric: 16.5656, val_loss: 16.9075, val_MinusLogProbMetric: 16.9075

Epoch 351: val_loss did not improve from 16.83673
196/196 - 40s - loss: 16.5656 - MinusLogProbMetric: 16.5656 - val_loss: 16.9075 - val_MinusLogProbMetric: 16.9075 - lr: 5.0000e-04 - 40s/epoch - 206ms/step
Epoch 352/1000
2023-09-27 08:46:11.202 
Epoch 352/1000 
	 loss: 16.5518, MinusLogProbMetric: 16.5518, val_loss: 16.9141, val_MinusLogProbMetric: 16.9141

Epoch 352: val_loss did not improve from 16.83673
196/196 - 41s - loss: 16.5518 - MinusLogProbMetric: 16.5518 - val_loss: 16.9141 - val_MinusLogProbMetric: 16.9141 - lr: 5.0000e-04 - 41s/epoch - 207ms/step
Epoch 353/1000
2023-09-27 08:46:51.590 
Epoch 353/1000 
	 loss: 16.5767, MinusLogProbMetric: 16.5767, val_loss: 16.8626, val_MinusLogProbMetric: 16.8626

Epoch 353: val_loss did not improve from 16.83673
196/196 - 40s - loss: 16.5767 - MinusLogProbMetric: 16.5767 - val_loss: 16.8626 - val_MinusLogProbMetric: 16.8626 - lr: 5.0000e-04 - 40s/epoch - 206ms/step
Epoch 354/1000
2023-09-27 08:47:31.513 
Epoch 354/1000 
	 loss: 16.5594, MinusLogProbMetric: 16.5594, val_loss: 16.8909, val_MinusLogProbMetric: 16.8909

Epoch 354: val_loss did not improve from 16.83673
196/196 - 40s - loss: 16.5594 - MinusLogProbMetric: 16.5594 - val_loss: 16.8909 - val_MinusLogProbMetric: 16.8909 - lr: 5.0000e-04 - 40s/epoch - 204ms/step
Epoch 355/1000
2023-09-27 08:48:11.943 
Epoch 355/1000 
	 loss: 16.5582, MinusLogProbMetric: 16.5582, val_loss: 16.9050, val_MinusLogProbMetric: 16.9050

Epoch 355: val_loss did not improve from 16.83673
196/196 - 40s - loss: 16.5582 - MinusLogProbMetric: 16.5582 - val_loss: 16.9050 - val_MinusLogProbMetric: 16.9050 - lr: 5.0000e-04 - 40s/epoch - 206ms/step
Epoch 356/1000
2023-09-27 08:48:53.450 
Epoch 356/1000 
	 loss: 16.5540, MinusLogProbMetric: 16.5540, val_loss: 16.8896, val_MinusLogProbMetric: 16.8896

Epoch 356: val_loss did not improve from 16.83673
196/196 - 42s - loss: 16.5540 - MinusLogProbMetric: 16.5540 - val_loss: 16.8896 - val_MinusLogProbMetric: 16.8896 - lr: 5.0000e-04 - 42s/epoch - 212ms/step
Epoch 357/1000
2023-09-27 08:49:37.408 
Epoch 357/1000 
	 loss: 16.5459, MinusLogProbMetric: 16.5459, val_loss: 16.8812, val_MinusLogProbMetric: 16.8812

Epoch 357: val_loss did not improve from 16.83673
196/196 - 44s - loss: 16.5459 - MinusLogProbMetric: 16.5459 - val_loss: 16.8812 - val_MinusLogProbMetric: 16.8812 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 358/1000
2023-09-27 08:50:20.796 
Epoch 358/1000 
	 loss: 16.5484, MinusLogProbMetric: 16.5484, val_loss: 16.8899, val_MinusLogProbMetric: 16.8899

Epoch 358: val_loss did not improve from 16.83673
196/196 - 43s - loss: 16.5484 - MinusLogProbMetric: 16.5484 - val_loss: 16.8899 - val_MinusLogProbMetric: 16.8899 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 359/1000
2023-09-27 08:51:04.194 
Epoch 359/1000 
	 loss: 16.5351, MinusLogProbMetric: 16.5351, val_loss: 16.8849, val_MinusLogProbMetric: 16.8849

Epoch 359: val_loss did not improve from 16.83673
196/196 - 43s - loss: 16.5351 - MinusLogProbMetric: 16.5351 - val_loss: 16.8849 - val_MinusLogProbMetric: 16.8849 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 360/1000
2023-09-27 08:51:47.546 
Epoch 360/1000 
	 loss: 16.5697, MinusLogProbMetric: 16.5697, val_loss: 16.9733, val_MinusLogProbMetric: 16.9733

Epoch 360: val_loss did not improve from 16.83673
196/196 - 43s - loss: 16.5697 - MinusLogProbMetric: 16.5697 - val_loss: 16.9733 - val_MinusLogProbMetric: 16.9733 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 361/1000
2023-09-27 08:52:30.936 
Epoch 361/1000 
	 loss: 16.5744, MinusLogProbMetric: 16.5744, val_loss: 16.9219, val_MinusLogProbMetric: 16.9219

Epoch 361: val_loss did not improve from 16.83673
196/196 - 43s - loss: 16.5744 - MinusLogProbMetric: 16.5744 - val_loss: 16.9219 - val_MinusLogProbMetric: 16.9219 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 362/1000
2023-09-27 08:53:14.371 
Epoch 362/1000 
	 loss: 16.5508, MinusLogProbMetric: 16.5508, val_loss: 16.9970, val_MinusLogProbMetric: 16.9970

Epoch 362: val_loss did not improve from 16.83673
196/196 - 43s - loss: 16.5508 - MinusLogProbMetric: 16.5508 - val_loss: 16.9970 - val_MinusLogProbMetric: 16.9970 - lr: 5.0000e-04 - 43s/epoch - 222ms/step
Epoch 363/1000
2023-09-27 08:53:57.683 
Epoch 363/1000 
	 loss: 16.5466, MinusLogProbMetric: 16.5466, val_loss: 16.8809, val_MinusLogProbMetric: 16.8809

Epoch 363: val_loss did not improve from 16.83673
196/196 - 43s - loss: 16.5466 - MinusLogProbMetric: 16.5466 - val_loss: 16.8809 - val_MinusLogProbMetric: 16.8809 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 364/1000
2023-09-27 08:54:41.071 
Epoch 364/1000 
	 loss: 16.5411, MinusLogProbMetric: 16.5411, val_loss: 16.9313, val_MinusLogProbMetric: 16.9313

Epoch 364: val_loss did not improve from 16.83673
196/196 - 43s - loss: 16.5411 - MinusLogProbMetric: 16.5411 - val_loss: 16.9313 - val_MinusLogProbMetric: 16.9313 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 365/1000
2023-09-27 08:55:23.957 
Epoch 365/1000 
	 loss: 16.5633, MinusLogProbMetric: 16.5633, val_loss: 17.0944, val_MinusLogProbMetric: 17.0944

Epoch 365: val_loss did not improve from 16.83673
196/196 - 43s - loss: 16.5633 - MinusLogProbMetric: 16.5633 - val_loss: 17.0944 - val_MinusLogProbMetric: 17.0944 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 366/1000
2023-09-27 08:56:06.801 
Epoch 366/1000 
	 loss: 16.5526, MinusLogProbMetric: 16.5526, val_loss: 16.9155, val_MinusLogProbMetric: 16.9155

Epoch 366: val_loss did not improve from 16.83673
196/196 - 43s - loss: 16.5526 - MinusLogProbMetric: 16.5526 - val_loss: 16.9155 - val_MinusLogProbMetric: 16.9155 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 367/1000
2023-09-27 08:56:46.721 
Epoch 367/1000 
	 loss: 16.5861, MinusLogProbMetric: 16.5861, val_loss: 16.9517, val_MinusLogProbMetric: 16.9517

Epoch 367: val_loss did not improve from 16.83673
196/196 - 40s - loss: 16.5861 - MinusLogProbMetric: 16.5861 - val_loss: 16.9517 - val_MinusLogProbMetric: 16.9517 - lr: 5.0000e-04 - 40s/epoch - 204ms/step
Epoch 368/1000
2023-09-27 08:57:25.880 
Epoch 368/1000 
	 loss: 16.5397, MinusLogProbMetric: 16.5397, val_loss: 16.9591, val_MinusLogProbMetric: 16.9591

Epoch 368: val_loss did not improve from 16.83673
196/196 - 39s - loss: 16.5397 - MinusLogProbMetric: 16.5397 - val_loss: 16.9591 - val_MinusLogProbMetric: 16.9591 - lr: 5.0000e-04 - 39s/epoch - 200ms/step
Epoch 369/1000
2023-09-27 08:58:07.832 
Epoch 369/1000 
	 loss: 16.5497, MinusLogProbMetric: 16.5497, val_loss: 17.1240, val_MinusLogProbMetric: 17.1240

Epoch 369: val_loss did not improve from 16.83673
196/196 - 42s - loss: 16.5497 - MinusLogProbMetric: 16.5497 - val_loss: 17.1240 - val_MinusLogProbMetric: 17.1240 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 370/1000
2023-09-27 08:58:49.312 
Epoch 370/1000 
	 loss: 16.5335, MinusLogProbMetric: 16.5335, val_loss: 16.9416, val_MinusLogProbMetric: 16.9416

Epoch 370: val_loss did not improve from 16.83673
196/196 - 41s - loss: 16.5335 - MinusLogProbMetric: 16.5335 - val_loss: 16.9416 - val_MinusLogProbMetric: 16.9416 - lr: 5.0000e-04 - 41s/epoch - 212ms/step
Epoch 371/1000
2023-09-27 08:59:32.414 
Epoch 371/1000 
	 loss: 16.5347, MinusLogProbMetric: 16.5347, val_loss: 16.9493, val_MinusLogProbMetric: 16.9493

Epoch 371: val_loss did not improve from 16.83673
196/196 - 43s - loss: 16.5347 - MinusLogProbMetric: 16.5347 - val_loss: 16.9493 - val_MinusLogProbMetric: 16.9493 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 372/1000
2023-09-27 09:00:14.857 
Epoch 372/1000 
	 loss: 16.5608, MinusLogProbMetric: 16.5608, val_loss: 17.1028, val_MinusLogProbMetric: 17.1028

Epoch 372: val_loss did not improve from 16.83673
196/196 - 42s - loss: 16.5608 - MinusLogProbMetric: 16.5608 - val_loss: 17.1028 - val_MinusLogProbMetric: 17.1028 - lr: 5.0000e-04 - 42s/epoch - 217ms/step
Epoch 373/1000
2023-09-27 09:00:55.249 
Epoch 373/1000 
	 loss: 16.5434, MinusLogProbMetric: 16.5434, val_loss: 16.9524, val_MinusLogProbMetric: 16.9524

Epoch 373: val_loss did not improve from 16.83673
196/196 - 40s - loss: 16.5434 - MinusLogProbMetric: 16.5434 - val_loss: 16.9524 - val_MinusLogProbMetric: 16.9524 - lr: 5.0000e-04 - 40s/epoch - 206ms/step
Epoch 374/1000
2023-09-27 09:01:34.399 
Epoch 374/1000 
	 loss: 16.5511, MinusLogProbMetric: 16.5511, val_loss: 16.9196, val_MinusLogProbMetric: 16.9196

Epoch 374: val_loss did not improve from 16.83673
196/196 - 39s - loss: 16.5511 - MinusLogProbMetric: 16.5511 - val_loss: 16.9196 - val_MinusLogProbMetric: 16.9196 - lr: 5.0000e-04 - 39s/epoch - 200ms/step
Epoch 375/1000
2023-09-27 09:02:17.425 
Epoch 375/1000 
	 loss: 16.4709, MinusLogProbMetric: 16.4709, val_loss: 16.8985, val_MinusLogProbMetric: 16.8985

Epoch 375: val_loss did not improve from 16.83673
196/196 - 43s - loss: 16.4709 - MinusLogProbMetric: 16.4709 - val_loss: 16.8985 - val_MinusLogProbMetric: 16.8985 - lr: 2.5000e-04 - 43s/epoch - 220ms/step
Epoch 376/1000
2023-09-27 09:02:58.505 
Epoch 376/1000 
	 loss: 16.4728, MinusLogProbMetric: 16.4728, val_loss: 16.8847, val_MinusLogProbMetric: 16.8847

Epoch 376: val_loss did not improve from 16.83673
196/196 - 41s - loss: 16.4728 - MinusLogProbMetric: 16.4728 - val_loss: 16.8847 - val_MinusLogProbMetric: 16.8847 - lr: 2.5000e-04 - 41s/epoch - 210ms/step
Epoch 377/1000
2023-09-27 09:03:40.989 
Epoch 377/1000 
	 loss: 16.4833, MinusLogProbMetric: 16.4833, val_loss: 16.8829, val_MinusLogProbMetric: 16.8829

Epoch 377: val_loss did not improve from 16.83673
196/196 - 42s - loss: 16.4833 - MinusLogProbMetric: 16.4833 - val_loss: 16.8829 - val_MinusLogProbMetric: 16.8829 - lr: 2.5000e-04 - 42s/epoch - 217ms/step
Epoch 378/1000
2023-09-27 09:04:23.360 
Epoch 378/1000 
	 loss: 16.4772, MinusLogProbMetric: 16.4772, val_loss: 16.8529, val_MinusLogProbMetric: 16.8529

Epoch 378: val_loss did not improve from 16.83673
196/196 - 42s - loss: 16.4772 - MinusLogProbMetric: 16.4772 - val_loss: 16.8529 - val_MinusLogProbMetric: 16.8529 - lr: 2.5000e-04 - 42s/epoch - 216ms/step
Epoch 379/1000
2023-09-27 09:05:06.392 
Epoch 379/1000 
	 loss: 16.4708, MinusLogProbMetric: 16.4708, val_loss: 16.8412, val_MinusLogProbMetric: 16.8412

Epoch 379: val_loss did not improve from 16.83673
196/196 - 43s - loss: 16.4708 - MinusLogProbMetric: 16.4708 - val_loss: 16.8412 - val_MinusLogProbMetric: 16.8412 - lr: 2.5000e-04 - 43s/epoch - 220ms/step
Epoch 380/1000
2023-09-27 09:05:48.794 
Epoch 380/1000 
	 loss: 16.4706, MinusLogProbMetric: 16.4706, val_loss: 16.8374, val_MinusLogProbMetric: 16.8374

Epoch 380: val_loss did not improve from 16.83673
196/196 - 42s - loss: 16.4706 - MinusLogProbMetric: 16.4706 - val_loss: 16.8374 - val_MinusLogProbMetric: 16.8374 - lr: 2.5000e-04 - 42s/epoch - 216ms/step
Epoch 381/1000
2023-09-27 09:06:31.610 
Epoch 381/1000 
	 loss: 16.4694, MinusLogProbMetric: 16.4694, val_loss: 16.9295, val_MinusLogProbMetric: 16.9295

Epoch 381: val_loss did not improve from 16.83673
196/196 - 43s - loss: 16.4694 - MinusLogProbMetric: 16.4694 - val_loss: 16.9295 - val_MinusLogProbMetric: 16.9295 - lr: 2.5000e-04 - 43s/epoch - 218ms/step
Epoch 382/1000
2023-09-27 09:07:14.634 
Epoch 382/1000 
	 loss: 16.4806, MinusLogProbMetric: 16.4806, val_loss: 16.8727, val_MinusLogProbMetric: 16.8727

Epoch 382: val_loss did not improve from 16.83673
196/196 - 43s - loss: 16.4806 - MinusLogProbMetric: 16.4806 - val_loss: 16.8727 - val_MinusLogProbMetric: 16.8727 - lr: 2.5000e-04 - 43s/epoch - 219ms/step
Epoch 383/1000
2023-09-27 09:07:57.906 
Epoch 383/1000 
	 loss: 16.4812, MinusLogProbMetric: 16.4812, val_loss: 16.8263, val_MinusLogProbMetric: 16.8263

Epoch 383: val_loss improved from 16.83673 to 16.82627, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 44s - loss: 16.4812 - MinusLogProbMetric: 16.4812 - val_loss: 16.8263 - val_MinusLogProbMetric: 16.8263 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 384/1000
2023-09-27 09:08:41.513 
Epoch 384/1000 
	 loss: 16.4785, MinusLogProbMetric: 16.4785, val_loss: 16.8573, val_MinusLogProbMetric: 16.8573

Epoch 384: val_loss did not improve from 16.82627
196/196 - 43s - loss: 16.4785 - MinusLogProbMetric: 16.4785 - val_loss: 16.8573 - val_MinusLogProbMetric: 16.8573 - lr: 2.5000e-04 - 43s/epoch - 218ms/step
Epoch 385/1000
2023-09-27 09:09:25.072 
Epoch 385/1000 
	 loss: 16.4795, MinusLogProbMetric: 16.4795, val_loss: 16.8636, val_MinusLogProbMetric: 16.8636

Epoch 385: val_loss did not improve from 16.82627
196/196 - 44s - loss: 16.4795 - MinusLogProbMetric: 16.4795 - val_loss: 16.8636 - val_MinusLogProbMetric: 16.8636 - lr: 2.5000e-04 - 44s/epoch - 222ms/step
Epoch 386/1000
2023-09-27 09:10:08.260 
Epoch 386/1000 
	 loss: 16.4751, MinusLogProbMetric: 16.4751, val_loss: 16.8378, val_MinusLogProbMetric: 16.8378

Epoch 386: val_loss did not improve from 16.82627
196/196 - 43s - loss: 16.4751 - MinusLogProbMetric: 16.4751 - val_loss: 16.8378 - val_MinusLogProbMetric: 16.8378 - lr: 2.5000e-04 - 43s/epoch - 220ms/step
Epoch 387/1000
2023-09-27 09:10:51.486 
Epoch 387/1000 
	 loss: 16.4659, MinusLogProbMetric: 16.4659, val_loss: 16.8718, val_MinusLogProbMetric: 16.8718

Epoch 387: val_loss did not improve from 16.82627
196/196 - 43s - loss: 16.4659 - MinusLogProbMetric: 16.4659 - val_loss: 16.8718 - val_MinusLogProbMetric: 16.8718 - lr: 2.5000e-04 - 43s/epoch - 221ms/step
Epoch 388/1000
2023-09-27 09:11:34.798 
Epoch 388/1000 
	 loss: 16.4668, MinusLogProbMetric: 16.4668, val_loss: 16.9098, val_MinusLogProbMetric: 16.9098

Epoch 388: val_loss did not improve from 16.82627
196/196 - 43s - loss: 16.4668 - MinusLogProbMetric: 16.4668 - val_loss: 16.9098 - val_MinusLogProbMetric: 16.9098 - lr: 2.5000e-04 - 43s/epoch - 221ms/step
Epoch 389/1000
2023-09-27 09:12:18.129 
Epoch 389/1000 
	 loss: 16.4710, MinusLogProbMetric: 16.4710, val_loss: 16.8661, val_MinusLogProbMetric: 16.8661

Epoch 389: val_loss did not improve from 16.82627
196/196 - 43s - loss: 16.4710 - MinusLogProbMetric: 16.4710 - val_loss: 16.8661 - val_MinusLogProbMetric: 16.8661 - lr: 2.5000e-04 - 43s/epoch - 221ms/step
Epoch 390/1000
2023-09-27 09:13:01.844 
Epoch 390/1000 
	 loss: 16.4692, MinusLogProbMetric: 16.4692, val_loss: 16.8636, val_MinusLogProbMetric: 16.8636

Epoch 390: val_loss did not improve from 16.82627
196/196 - 44s - loss: 16.4692 - MinusLogProbMetric: 16.4692 - val_loss: 16.8636 - val_MinusLogProbMetric: 16.8636 - lr: 2.5000e-04 - 44s/epoch - 223ms/step
Epoch 391/1000
2023-09-27 09:13:45.023 
Epoch 391/1000 
	 loss: 16.4699, MinusLogProbMetric: 16.4699, val_loss: 16.8588, val_MinusLogProbMetric: 16.8588

Epoch 391: val_loss did not improve from 16.82627
196/196 - 43s - loss: 16.4699 - MinusLogProbMetric: 16.4699 - val_loss: 16.8588 - val_MinusLogProbMetric: 16.8588 - lr: 2.5000e-04 - 43s/epoch - 220ms/step
Epoch 392/1000
2023-09-27 09:14:28.039 
Epoch 392/1000 
	 loss: 16.4713, MinusLogProbMetric: 16.4713, val_loss: 16.8477, val_MinusLogProbMetric: 16.8477

Epoch 392: val_loss did not improve from 16.82627
196/196 - 43s - loss: 16.4713 - MinusLogProbMetric: 16.4713 - val_loss: 16.8477 - val_MinusLogProbMetric: 16.8477 - lr: 2.5000e-04 - 43s/epoch - 219ms/step
Epoch 393/1000
2023-09-27 09:15:11.428 
Epoch 393/1000 
	 loss: 16.4824, MinusLogProbMetric: 16.4824, val_loss: 16.9168, val_MinusLogProbMetric: 16.9168

Epoch 393: val_loss did not improve from 16.82627
196/196 - 43s - loss: 16.4824 - MinusLogProbMetric: 16.4824 - val_loss: 16.9168 - val_MinusLogProbMetric: 16.9168 - lr: 2.5000e-04 - 43s/epoch - 221ms/step
Epoch 394/1000
2023-09-27 09:15:54.877 
Epoch 394/1000 
	 loss: 16.4791, MinusLogProbMetric: 16.4791, val_loss: 16.8447, val_MinusLogProbMetric: 16.8447

Epoch 394: val_loss did not improve from 16.82627
196/196 - 43s - loss: 16.4791 - MinusLogProbMetric: 16.4791 - val_loss: 16.8447 - val_MinusLogProbMetric: 16.8447 - lr: 2.5000e-04 - 43s/epoch - 222ms/step
Epoch 395/1000
2023-09-27 09:16:38.035 
Epoch 395/1000 
	 loss: 16.4680, MinusLogProbMetric: 16.4680, val_loss: 16.8711, val_MinusLogProbMetric: 16.8711

Epoch 395: val_loss did not improve from 16.82627
196/196 - 43s - loss: 16.4680 - MinusLogProbMetric: 16.4680 - val_loss: 16.8711 - val_MinusLogProbMetric: 16.8711 - lr: 2.5000e-04 - 43s/epoch - 220ms/step
Epoch 396/1000
2023-09-27 09:17:19.426 
Epoch 396/1000 
	 loss: 16.4561, MinusLogProbMetric: 16.4561, val_loss: 16.8501, val_MinusLogProbMetric: 16.8501

Epoch 396: val_loss did not improve from 16.82627
196/196 - 41s - loss: 16.4561 - MinusLogProbMetric: 16.4561 - val_loss: 16.8501 - val_MinusLogProbMetric: 16.8501 - lr: 2.5000e-04 - 41s/epoch - 211ms/step
Epoch 397/1000
2023-09-27 09:18:01.338 
Epoch 397/1000 
	 loss: 16.4721, MinusLogProbMetric: 16.4721, val_loss: 16.8463, val_MinusLogProbMetric: 16.8463

Epoch 397: val_loss did not improve from 16.82627
196/196 - 42s - loss: 16.4721 - MinusLogProbMetric: 16.4721 - val_loss: 16.8463 - val_MinusLogProbMetric: 16.8463 - lr: 2.5000e-04 - 42s/epoch - 214ms/step
Epoch 398/1000
2023-09-27 09:18:40.763 
Epoch 398/1000 
	 loss: 16.4619, MinusLogProbMetric: 16.4619, val_loss: 16.8293, val_MinusLogProbMetric: 16.8293

Epoch 398: val_loss did not improve from 16.82627
196/196 - 39s - loss: 16.4619 - MinusLogProbMetric: 16.4619 - val_loss: 16.8293 - val_MinusLogProbMetric: 16.8293 - lr: 2.5000e-04 - 39s/epoch - 201ms/step
Epoch 399/1000
2023-09-27 09:19:20.729 
Epoch 399/1000 
	 loss: 16.4678, MinusLogProbMetric: 16.4678, val_loss: 16.8579, val_MinusLogProbMetric: 16.8579

Epoch 399: val_loss did not improve from 16.82627
196/196 - 40s - loss: 16.4678 - MinusLogProbMetric: 16.4678 - val_loss: 16.8579 - val_MinusLogProbMetric: 16.8579 - lr: 2.5000e-04 - 40s/epoch - 204ms/step
Epoch 400/1000
2023-09-27 09:20:03.703 
Epoch 400/1000 
	 loss: 16.4666, MinusLogProbMetric: 16.4666, val_loss: 16.8594, val_MinusLogProbMetric: 16.8594

Epoch 400: val_loss did not improve from 16.82627
196/196 - 43s - loss: 16.4666 - MinusLogProbMetric: 16.4666 - val_loss: 16.8594 - val_MinusLogProbMetric: 16.8594 - lr: 2.5000e-04 - 43s/epoch - 219ms/step
Epoch 401/1000
2023-09-27 09:20:46.588 
Epoch 401/1000 
	 loss: 16.4651, MinusLogProbMetric: 16.4651, val_loss: 16.8399, val_MinusLogProbMetric: 16.8399

Epoch 401: val_loss did not improve from 16.82627
196/196 - 43s - loss: 16.4651 - MinusLogProbMetric: 16.4651 - val_loss: 16.8399 - val_MinusLogProbMetric: 16.8399 - lr: 2.5000e-04 - 43s/epoch - 219ms/step
Epoch 402/1000
2023-09-27 09:21:29.659 
Epoch 402/1000 
	 loss: 16.4800, MinusLogProbMetric: 16.4800, val_loss: 16.8773, val_MinusLogProbMetric: 16.8773

Epoch 402: val_loss did not improve from 16.82627
196/196 - 43s - loss: 16.4800 - MinusLogProbMetric: 16.4800 - val_loss: 16.8773 - val_MinusLogProbMetric: 16.8773 - lr: 2.5000e-04 - 43s/epoch - 220ms/step
Epoch 403/1000
2023-09-27 09:22:09.454 
Epoch 403/1000 
	 loss: 16.4747, MinusLogProbMetric: 16.4747, val_loss: 16.8447, val_MinusLogProbMetric: 16.8447

Epoch 403: val_loss did not improve from 16.82627
196/196 - 40s - loss: 16.4747 - MinusLogProbMetric: 16.4747 - val_loss: 16.8447 - val_MinusLogProbMetric: 16.8447 - lr: 2.5000e-04 - 40s/epoch - 203ms/step
Epoch 404/1000
2023-09-27 09:22:48.561 
Epoch 404/1000 
	 loss: 16.4791, MinusLogProbMetric: 16.4791, val_loss: 16.8413, val_MinusLogProbMetric: 16.8413

Epoch 404: val_loss did not improve from 16.82627
196/196 - 39s - loss: 16.4791 - MinusLogProbMetric: 16.4791 - val_loss: 16.8413 - val_MinusLogProbMetric: 16.8413 - lr: 2.5000e-04 - 39s/epoch - 200ms/step
Epoch 405/1000
2023-09-27 09:23:24.285 
Epoch 405/1000 
	 loss: 16.4653, MinusLogProbMetric: 16.4653, val_loss: 16.8454, val_MinusLogProbMetric: 16.8454

Epoch 405: val_loss did not improve from 16.82627
196/196 - 36s - loss: 16.4653 - MinusLogProbMetric: 16.4653 - val_loss: 16.8454 - val_MinusLogProbMetric: 16.8454 - lr: 2.5000e-04 - 36s/epoch - 182ms/step
Epoch 406/1000
2023-09-27 09:23:59.169 
Epoch 406/1000 
	 loss: 16.4685, MinusLogProbMetric: 16.4685, val_loss: 16.8687, val_MinusLogProbMetric: 16.8687

Epoch 406: val_loss did not improve from 16.82627
196/196 - 35s - loss: 16.4685 - MinusLogProbMetric: 16.4685 - val_loss: 16.8687 - val_MinusLogProbMetric: 16.8687 - lr: 2.5000e-04 - 35s/epoch - 178ms/step
Epoch 407/1000
2023-09-27 09:24:33.339 
Epoch 407/1000 
	 loss: 16.4802, MinusLogProbMetric: 16.4802, val_loss: 16.8768, val_MinusLogProbMetric: 16.8768

Epoch 407: val_loss did not improve from 16.82627
196/196 - 34s - loss: 16.4802 - MinusLogProbMetric: 16.4802 - val_loss: 16.8768 - val_MinusLogProbMetric: 16.8768 - lr: 2.5000e-04 - 34s/epoch - 174ms/step
Epoch 408/1000
2023-09-27 09:25:13.519 
Epoch 408/1000 
	 loss: 16.4635, MinusLogProbMetric: 16.4635, val_loss: 16.8367, val_MinusLogProbMetric: 16.8367

Epoch 408: val_loss did not improve from 16.82627
196/196 - 40s - loss: 16.4635 - MinusLogProbMetric: 16.4635 - val_loss: 16.8367 - val_MinusLogProbMetric: 16.8367 - lr: 2.5000e-04 - 40s/epoch - 205ms/step
Epoch 409/1000
2023-09-27 09:25:51.545 
Epoch 409/1000 
	 loss: 16.4627, MinusLogProbMetric: 16.4627, val_loss: 16.8619, val_MinusLogProbMetric: 16.8619

Epoch 409: val_loss did not improve from 16.82627
196/196 - 38s - loss: 16.4627 - MinusLogProbMetric: 16.4627 - val_loss: 16.8619 - val_MinusLogProbMetric: 16.8619 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 410/1000
2023-09-27 09:26:24.827 
Epoch 410/1000 
	 loss: 16.4634, MinusLogProbMetric: 16.4634, val_loss: 16.8986, val_MinusLogProbMetric: 16.8986

Epoch 410: val_loss did not improve from 16.82627
196/196 - 33s - loss: 16.4634 - MinusLogProbMetric: 16.4634 - val_loss: 16.8986 - val_MinusLogProbMetric: 16.8986 - lr: 2.5000e-04 - 33s/epoch - 170ms/step
Epoch 411/1000
2023-09-27 09:26:57.751 
Epoch 411/1000 
	 loss: 16.4756, MinusLogProbMetric: 16.4756, val_loss: 16.8477, val_MinusLogProbMetric: 16.8477

Epoch 411: val_loss did not improve from 16.82627
196/196 - 33s - loss: 16.4756 - MinusLogProbMetric: 16.4756 - val_loss: 16.8477 - val_MinusLogProbMetric: 16.8477 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 412/1000
2023-09-27 09:27:31.780 
Epoch 412/1000 
	 loss: 16.4605, MinusLogProbMetric: 16.4605, val_loss: 16.8528, val_MinusLogProbMetric: 16.8528

Epoch 412: val_loss did not improve from 16.82627
196/196 - 34s - loss: 16.4605 - MinusLogProbMetric: 16.4605 - val_loss: 16.8528 - val_MinusLogProbMetric: 16.8528 - lr: 2.5000e-04 - 34s/epoch - 174ms/step
Epoch 413/1000
2023-09-27 09:28:07.526 
Epoch 413/1000 
	 loss: 16.4589, MinusLogProbMetric: 16.4589, val_loss: 16.8409, val_MinusLogProbMetric: 16.8409

Epoch 413: val_loss did not improve from 16.82627
196/196 - 36s - loss: 16.4589 - MinusLogProbMetric: 16.4589 - val_loss: 16.8409 - val_MinusLogProbMetric: 16.8409 - lr: 2.5000e-04 - 36s/epoch - 182ms/step
Epoch 414/1000
2023-09-27 09:28:46.964 
Epoch 414/1000 
	 loss: 16.4689, MinusLogProbMetric: 16.4689, val_loss: 16.8513, val_MinusLogProbMetric: 16.8513

Epoch 414: val_loss did not improve from 16.82627
196/196 - 39s - loss: 16.4689 - MinusLogProbMetric: 16.4689 - val_loss: 16.8513 - val_MinusLogProbMetric: 16.8513 - lr: 2.5000e-04 - 39s/epoch - 201ms/step
Epoch 415/1000
2023-09-27 09:29:27.376 
Epoch 415/1000 
	 loss: 16.4701, MinusLogProbMetric: 16.4701, val_loss: 16.9233, val_MinusLogProbMetric: 16.9233

Epoch 415: val_loss did not improve from 16.82627
196/196 - 40s - loss: 16.4701 - MinusLogProbMetric: 16.4701 - val_loss: 16.9233 - val_MinusLogProbMetric: 16.9233 - lr: 2.5000e-04 - 40s/epoch - 206ms/step
Epoch 416/1000
2023-09-27 09:30:05.761 
Epoch 416/1000 
	 loss: 16.4560, MinusLogProbMetric: 16.4560, val_loss: 16.8606, val_MinusLogProbMetric: 16.8606

Epoch 416: val_loss did not improve from 16.82627
196/196 - 38s - loss: 16.4560 - MinusLogProbMetric: 16.4560 - val_loss: 16.8606 - val_MinusLogProbMetric: 16.8606 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 417/1000
2023-09-27 09:30:45.790 
Epoch 417/1000 
	 loss: 16.4852, MinusLogProbMetric: 16.4852, val_loss: 16.8735, val_MinusLogProbMetric: 16.8735

Epoch 417: val_loss did not improve from 16.82627
196/196 - 40s - loss: 16.4852 - MinusLogProbMetric: 16.4852 - val_loss: 16.8735 - val_MinusLogProbMetric: 16.8735 - lr: 2.5000e-04 - 40s/epoch - 204ms/step
Epoch 418/1000
2023-09-27 09:31:25.617 
Epoch 418/1000 
	 loss: 16.4609, MinusLogProbMetric: 16.4609, val_loss: 16.8415, val_MinusLogProbMetric: 16.8415

Epoch 418: val_loss did not improve from 16.82627
196/196 - 40s - loss: 16.4609 - MinusLogProbMetric: 16.4609 - val_loss: 16.8415 - val_MinusLogProbMetric: 16.8415 - lr: 2.5000e-04 - 40s/epoch - 203ms/step
Epoch 419/1000
2023-09-27 09:32:06.738 
Epoch 419/1000 
	 loss: 16.4599, MinusLogProbMetric: 16.4599, val_loss: 16.8395, val_MinusLogProbMetric: 16.8395

Epoch 419: val_loss did not improve from 16.82627
196/196 - 41s - loss: 16.4599 - MinusLogProbMetric: 16.4599 - val_loss: 16.8395 - val_MinusLogProbMetric: 16.8395 - lr: 2.5000e-04 - 41s/epoch - 210ms/step
Epoch 420/1000
2023-09-27 09:32:46.965 
Epoch 420/1000 
	 loss: 16.4603, MinusLogProbMetric: 16.4603, val_loss: 16.8347, val_MinusLogProbMetric: 16.8347

Epoch 420: val_loss did not improve from 16.82627
196/196 - 40s - loss: 16.4603 - MinusLogProbMetric: 16.4603 - val_loss: 16.8347 - val_MinusLogProbMetric: 16.8347 - lr: 2.5000e-04 - 40s/epoch - 205ms/step
Epoch 421/1000
2023-09-27 09:33:27.620 
Epoch 421/1000 
	 loss: 16.4629, MinusLogProbMetric: 16.4629, val_loss: 16.8637, val_MinusLogProbMetric: 16.8637

Epoch 421: val_loss did not improve from 16.82627
196/196 - 41s - loss: 16.4629 - MinusLogProbMetric: 16.4629 - val_loss: 16.8637 - val_MinusLogProbMetric: 16.8637 - lr: 2.5000e-04 - 41s/epoch - 207ms/step
Epoch 422/1000
2023-09-27 09:34:09.023 
Epoch 422/1000 
	 loss: 16.4684, MinusLogProbMetric: 16.4684, val_loss: 16.8860, val_MinusLogProbMetric: 16.8860

Epoch 422: val_loss did not improve from 16.82627
196/196 - 41s - loss: 16.4684 - MinusLogProbMetric: 16.4684 - val_loss: 16.8860 - val_MinusLogProbMetric: 16.8860 - lr: 2.5000e-04 - 41s/epoch - 211ms/step
Epoch 423/1000
2023-09-27 09:34:50.905 
Epoch 423/1000 
	 loss: 16.4589, MinusLogProbMetric: 16.4589, val_loss: 16.8435, val_MinusLogProbMetric: 16.8435

Epoch 423: val_loss did not improve from 16.82627
196/196 - 42s - loss: 16.4589 - MinusLogProbMetric: 16.4589 - val_loss: 16.8435 - val_MinusLogProbMetric: 16.8435 - lr: 2.5000e-04 - 42s/epoch - 214ms/step
Epoch 424/1000
2023-09-27 09:35:30.996 
Epoch 424/1000 
	 loss: 16.4764, MinusLogProbMetric: 16.4764, val_loss: 16.8548, val_MinusLogProbMetric: 16.8548

Epoch 424: val_loss did not improve from 16.82627
196/196 - 40s - loss: 16.4764 - MinusLogProbMetric: 16.4764 - val_loss: 16.8548 - val_MinusLogProbMetric: 16.8548 - lr: 2.5000e-04 - 40s/epoch - 205ms/step
Epoch 425/1000
2023-09-27 09:36:12.063 
Epoch 425/1000 
	 loss: 16.4572, MinusLogProbMetric: 16.4572, val_loss: 16.8555, val_MinusLogProbMetric: 16.8555

Epoch 425: val_loss did not improve from 16.82627
196/196 - 41s - loss: 16.4572 - MinusLogProbMetric: 16.4572 - val_loss: 16.8555 - val_MinusLogProbMetric: 16.8555 - lr: 2.5000e-04 - 41s/epoch - 209ms/step
Epoch 426/1000
2023-09-27 09:36:52.503 
Epoch 426/1000 
	 loss: 16.4548, MinusLogProbMetric: 16.4548, val_loss: 16.8464, val_MinusLogProbMetric: 16.8464

Epoch 426: val_loss did not improve from 16.82627
196/196 - 40s - loss: 16.4548 - MinusLogProbMetric: 16.4548 - val_loss: 16.8464 - val_MinusLogProbMetric: 16.8464 - lr: 2.5000e-04 - 40s/epoch - 206ms/step
Epoch 427/1000
2023-09-27 09:37:33.007 
Epoch 427/1000 
	 loss: 16.4624, MinusLogProbMetric: 16.4624, val_loss: 16.8488, val_MinusLogProbMetric: 16.8488

Epoch 427: val_loss did not improve from 16.82627
196/196 - 41s - loss: 16.4624 - MinusLogProbMetric: 16.4624 - val_loss: 16.8488 - val_MinusLogProbMetric: 16.8488 - lr: 2.5000e-04 - 41s/epoch - 207ms/step
Epoch 428/1000
2023-09-27 09:38:13.105 
Epoch 428/1000 
	 loss: 16.4550, MinusLogProbMetric: 16.4550, val_loss: 16.8954, val_MinusLogProbMetric: 16.8954

Epoch 428: val_loss did not improve from 16.82627
196/196 - 40s - loss: 16.4550 - MinusLogProbMetric: 16.4550 - val_loss: 16.8954 - val_MinusLogProbMetric: 16.8954 - lr: 2.5000e-04 - 40s/epoch - 205ms/step
Epoch 429/1000
2023-09-27 09:38:54.018 
Epoch 429/1000 
	 loss: 16.4707, MinusLogProbMetric: 16.4707, val_loss: 16.8452, val_MinusLogProbMetric: 16.8452

Epoch 429: val_loss did not improve from 16.82627
196/196 - 41s - loss: 16.4707 - MinusLogProbMetric: 16.4707 - val_loss: 16.8452 - val_MinusLogProbMetric: 16.8452 - lr: 2.5000e-04 - 41s/epoch - 209ms/step
Epoch 430/1000
2023-09-27 09:39:34.169 
Epoch 430/1000 
	 loss: 16.4614, MinusLogProbMetric: 16.4614, val_loss: 16.8569, val_MinusLogProbMetric: 16.8569

Epoch 430: val_loss did not improve from 16.82627
196/196 - 40s - loss: 16.4614 - MinusLogProbMetric: 16.4614 - val_loss: 16.8569 - val_MinusLogProbMetric: 16.8569 - lr: 2.5000e-04 - 40s/epoch - 205ms/step
Epoch 431/1000
2023-09-27 09:40:14.983 
Epoch 431/1000 
	 loss: 16.4670, MinusLogProbMetric: 16.4670, val_loss: 16.8500, val_MinusLogProbMetric: 16.8500

Epoch 431: val_loss did not improve from 16.82627
196/196 - 41s - loss: 16.4670 - MinusLogProbMetric: 16.4670 - val_loss: 16.8500 - val_MinusLogProbMetric: 16.8500 - lr: 2.5000e-04 - 41s/epoch - 208ms/step
Epoch 432/1000
2023-09-27 09:40:55.213 
Epoch 432/1000 
	 loss: 16.4765, MinusLogProbMetric: 16.4765, val_loss: 16.8562, val_MinusLogProbMetric: 16.8562

Epoch 432: val_loss did not improve from 16.82627
196/196 - 40s - loss: 16.4765 - MinusLogProbMetric: 16.4765 - val_loss: 16.8562 - val_MinusLogProbMetric: 16.8562 - lr: 2.5000e-04 - 40s/epoch - 205ms/step
Epoch 433/1000
2023-09-27 09:41:36.382 
Epoch 433/1000 
	 loss: 16.4595, MinusLogProbMetric: 16.4595, val_loss: 16.8548, val_MinusLogProbMetric: 16.8548

Epoch 433: val_loss did not improve from 16.82627
196/196 - 41s - loss: 16.4595 - MinusLogProbMetric: 16.4595 - val_loss: 16.8548 - val_MinusLogProbMetric: 16.8548 - lr: 2.5000e-04 - 41s/epoch - 210ms/step
Epoch 434/1000
2023-09-27 09:42:17.076 
Epoch 434/1000 
	 loss: 16.4219, MinusLogProbMetric: 16.4219, val_loss: 16.8274, val_MinusLogProbMetric: 16.8274

Epoch 434: val_loss did not improve from 16.82627
196/196 - 41s - loss: 16.4219 - MinusLogProbMetric: 16.4219 - val_loss: 16.8274 - val_MinusLogProbMetric: 16.8274 - lr: 1.2500e-04 - 41s/epoch - 208ms/step
Epoch 435/1000
2023-09-27 09:42:58.598 
Epoch 435/1000 
	 loss: 16.4212, MinusLogProbMetric: 16.4212, val_loss: 16.8426, val_MinusLogProbMetric: 16.8426

Epoch 435: val_loss did not improve from 16.82627
196/196 - 42s - loss: 16.4212 - MinusLogProbMetric: 16.4212 - val_loss: 16.8426 - val_MinusLogProbMetric: 16.8426 - lr: 1.2500e-04 - 42s/epoch - 212ms/step
Epoch 436/1000
2023-09-27 09:43:39.588 
Epoch 436/1000 
	 loss: 16.4242, MinusLogProbMetric: 16.4242, val_loss: 16.8154, val_MinusLogProbMetric: 16.8154

Epoch 436: val_loss improved from 16.82627 to 16.81541, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 42s - loss: 16.4242 - MinusLogProbMetric: 16.4242 - val_loss: 16.8154 - val_MinusLogProbMetric: 16.8154 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 437/1000
2023-09-27 09:44:19.917 
Epoch 437/1000 
	 loss: 16.4312, MinusLogProbMetric: 16.4312, val_loss: 16.8152, val_MinusLogProbMetric: 16.8152

Epoch 437: val_loss improved from 16.81541 to 16.81524, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 40s - loss: 16.4312 - MinusLogProbMetric: 16.4312 - val_loss: 16.8152 - val_MinusLogProbMetric: 16.8152 - lr: 1.2500e-04 - 40s/epoch - 206ms/step
Epoch 438/1000
2023-09-27 09:45:01.212 
Epoch 438/1000 
	 loss: 16.4211, MinusLogProbMetric: 16.4211, val_loss: 16.8338, val_MinusLogProbMetric: 16.8338

Epoch 438: val_loss did not improve from 16.81524
196/196 - 41s - loss: 16.4211 - MinusLogProbMetric: 16.4211 - val_loss: 16.8338 - val_MinusLogProbMetric: 16.8338 - lr: 1.2500e-04 - 41s/epoch - 207ms/step
Epoch 439/1000
2023-09-27 09:45:41.522 
Epoch 439/1000 
	 loss: 16.4258, MinusLogProbMetric: 16.4258, val_loss: 16.8618, val_MinusLogProbMetric: 16.8618

Epoch 439: val_loss did not improve from 16.81524
196/196 - 40s - loss: 16.4258 - MinusLogProbMetric: 16.4258 - val_loss: 16.8618 - val_MinusLogProbMetric: 16.8618 - lr: 1.2500e-04 - 40s/epoch - 206ms/step
Epoch 440/1000
2023-09-27 09:46:22.701 
Epoch 440/1000 
	 loss: 16.4259, MinusLogProbMetric: 16.4259, val_loss: 16.8201, val_MinusLogProbMetric: 16.8201

Epoch 440: val_loss did not improve from 16.81524
196/196 - 41s - loss: 16.4259 - MinusLogProbMetric: 16.4259 - val_loss: 16.8201 - val_MinusLogProbMetric: 16.8201 - lr: 1.2500e-04 - 41s/epoch - 210ms/step
Epoch 441/1000
2023-09-27 09:47:02.504 
Epoch 441/1000 
	 loss: 16.4243, MinusLogProbMetric: 16.4243, val_loss: 16.8301, val_MinusLogProbMetric: 16.8301

Epoch 441: val_loss did not improve from 16.81524
196/196 - 40s - loss: 16.4243 - MinusLogProbMetric: 16.4243 - val_loss: 16.8301 - val_MinusLogProbMetric: 16.8301 - lr: 1.2500e-04 - 40s/epoch - 203ms/step
Epoch 442/1000
2023-09-27 09:47:42.700 
Epoch 442/1000 
	 loss: 16.4224, MinusLogProbMetric: 16.4224, val_loss: 16.8235, val_MinusLogProbMetric: 16.8235

Epoch 442: val_loss did not improve from 16.81524
196/196 - 40s - loss: 16.4224 - MinusLogProbMetric: 16.4224 - val_loss: 16.8235 - val_MinusLogProbMetric: 16.8235 - lr: 1.2500e-04 - 40s/epoch - 205ms/step
Epoch 443/1000
2023-09-27 09:48:22.360 
Epoch 443/1000 
	 loss: 16.4239, MinusLogProbMetric: 16.4239, val_loss: 16.8330, val_MinusLogProbMetric: 16.8330

Epoch 443: val_loss did not improve from 16.81524
196/196 - 40s - loss: 16.4239 - MinusLogProbMetric: 16.4239 - val_loss: 16.8330 - val_MinusLogProbMetric: 16.8330 - lr: 1.2500e-04 - 40s/epoch - 202ms/step
Epoch 444/1000
2023-09-27 09:49:02.643 
Epoch 444/1000 
	 loss: 16.4259, MinusLogProbMetric: 16.4259, val_loss: 16.8500, val_MinusLogProbMetric: 16.8500

Epoch 444: val_loss did not improve from 16.81524
196/196 - 40s - loss: 16.4259 - MinusLogProbMetric: 16.4259 - val_loss: 16.8500 - val_MinusLogProbMetric: 16.8500 - lr: 1.2500e-04 - 40s/epoch - 206ms/step
Epoch 445/1000
2023-09-27 09:49:43.577 
Epoch 445/1000 
	 loss: 16.4257, MinusLogProbMetric: 16.4257, val_loss: 16.8313, val_MinusLogProbMetric: 16.8313

Epoch 445: val_loss did not improve from 16.81524
196/196 - 41s - loss: 16.4257 - MinusLogProbMetric: 16.4257 - val_loss: 16.8313 - val_MinusLogProbMetric: 16.8313 - lr: 1.2500e-04 - 41s/epoch - 209ms/step
Epoch 446/1000
2023-09-27 09:50:24.452 
Epoch 446/1000 
	 loss: 16.4214, MinusLogProbMetric: 16.4214, val_loss: 16.8159, val_MinusLogProbMetric: 16.8159

Epoch 446: val_loss did not improve from 16.81524
196/196 - 41s - loss: 16.4214 - MinusLogProbMetric: 16.4214 - val_loss: 16.8159 - val_MinusLogProbMetric: 16.8159 - lr: 1.2500e-04 - 41s/epoch - 209ms/step
Epoch 447/1000
2023-09-27 09:51:05.442 
Epoch 447/1000 
	 loss: 16.4333, MinusLogProbMetric: 16.4333, val_loss: 16.8269, val_MinusLogProbMetric: 16.8269

Epoch 447: val_loss did not improve from 16.81524
196/196 - 41s - loss: 16.4333 - MinusLogProbMetric: 16.4333 - val_loss: 16.8269 - val_MinusLogProbMetric: 16.8269 - lr: 1.2500e-04 - 41s/epoch - 209ms/step
Epoch 448/1000
2023-09-27 09:51:46.021 
Epoch 448/1000 
	 loss: 16.4224, MinusLogProbMetric: 16.4224, val_loss: 16.8349, val_MinusLogProbMetric: 16.8349

Epoch 448: val_loss did not improve from 16.81524
196/196 - 41s - loss: 16.4224 - MinusLogProbMetric: 16.4224 - val_loss: 16.8349 - val_MinusLogProbMetric: 16.8349 - lr: 1.2500e-04 - 41s/epoch - 207ms/step
Epoch 449/1000
2023-09-27 09:52:27.258 
Epoch 449/1000 
	 loss: 16.4243, MinusLogProbMetric: 16.4243, val_loss: 16.8326, val_MinusLogProbMetric: 16.8326

Epoch 449: val_loss did not improve from 16.81524
196/196 - 41s - loss: 16.4243 - MinusLogProbMetric: 16.4243 - val_loss: 16.8326 - val_MinusLogProbMetric: 16.8326 - lr: 1.2500e-04 - 41s/epoch - 210ms/step
Epoch 450/1000
2023-09-27 09:53:06.868 
Epoch 450/1000 
	 loss: 16.4228, MinusLogProbMetric: 16.4228, val_loss: 16.8381, val_MinusLogProbMetric: 16.8381

Epoch 450: val_loss did not improve from 16.81524
196/196 - 40s - loss: 16.4228 - MinusLogProbMetric: 16.4228 - val_loss: 16.8381 - val_MinusLogProbMetric: 16.8381 - lr: 1.2500e-04 - 40s/epoch - 202ms/step
Epoch 451/1000
2023-09-27 09:53:46.684 
Epoch 451/1000 
	 loss: 16.4217, MinusLogProbMetric: 16.4217, val_loss: 16.8140, val_MinusLogProbMetric: 16.8140

Epoch 451: val_loss improved from 16.81524 to 16.81405, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 40s - loss: 16.4217 - MinusLogProbMetric: 16.4217 - val_loss: 16.8140 - val_MinusLogProbMetric: 16.8140 - lr: 1.2500e-04 - 40s/epoch - 206ms/step
Epoch 452/1000
2023-09-27 09:54:28.035 
Epoch 452/1000 
	 loss: 16.4215, MinusLogProbMetric: 16.4215, val_loss: 16.8218, val_MinusLogProbMetric: 16.8218

Epoch 452: val_loss did not improve from 16.81405
196/196 - 41s - loss: 16.4215 - MinusLogProbMetric: 16.4215 - val_loss: 16.8218 - val_MinusLogProbMetric: 16.8218 - lr: 1.2500e-04 - 41s/epoch - 208ms/step
Epoch 453/1000
2023-09-27 09:55:08.592 
Epoch 453/1000 
	 loss: 16.4230, MinusLogProbMetric: 16.4230, val_loss: 16.8459, val_MinusLogProbMetric: 16.8459

Epoch 453: val_loss did not improve from 16.81405
196/196 - 41s - loss: 16.4230 - MinusLogProbMetric: 16.4230 - val_loss: 16.8459 - val_MinusLogProbMetric: 16.8459 - lr: 1.2500e-04 - 41s/epoch - 207ms/step
Epoch 454/1000
2023-09-27 09:55:47.785 
Epoch 454/1000 
	 loss: 16.4208, MinusLogProbMetric: 16.4208, val_loss: 16.8326, val_MinusLogProbMetric: 16.8326

Epoch 454: val_loss did not improve from 16.81405
196/196 - 39s - loss: 16.4208 - MinusLogProbMetric: 16.4208 - val_loss: 16.8326 - val_MinusLogProbMetric: 16.8326 - lr: 1.2500e-04 - 39s/epoch - 200ms/step
Epoch 455/1000
2023-09-27 09:56:28.106 
Epoch 455/1000 
	 loss: 16.4281, MinusLogProbMetric: 16.4281, val_loss: 16.8292, val_MinusLogProbMetric: 16.8292

Epoch 455: val_loss did not improve from 16.81405
196/196 - 40s - loss: 16.4281 - MinusLogProbMetric: 16.4281 - val_loss: 16.8292 - val_MinusLogProbMetric: 16.8292 - lr: 1.2500e-04 - 40s/epoch - 206ms/step
Epoch 456/1000
2023-09-27 09:57:08.528 
Epoch 456/1000 
	 loss: 16.4244, MinusLogProbMetric: 16.4244, val_loss: 16.8227, val_MinusLogProbMetric: 16.8227

Epoch 456: val_loss did not improve from 16.81405
196/196 - 40s - loss: 16.4244 - MinusLogProbMetric: 16.4244 - val_loss: 16.8227 - val_MinusLogProbMetric: 16.8227 - lr: 1.2500e-04 - 40s/epoch - 206ms/step
Epoch 457/1000
2023-09-27 09:57:48.342 
Epoch 457/1000 
	 loss: 16.4209, MinusLogProbMetric: 16.4209, val_loss: 16.8280, val_MinusLogProbMetric: 16.8280

Epoch 457: val_loss did not improve from 16.81405
196/196 - 40s - loss: 16.4209 - MinusLogProbMetric: 16.4209 - val_loss: 16.8280 - val_MinusLogProbMetric: 16.8280 - lr: 1.2500e-04 - 40s/epoch - 203ms/step
Epoch 458/1000
2023-09-27 09:58:29.461 
Epoch 458/1000 
	 loss: 16.4268, MinusLogProbMetric: 16.4268, val_loss: 16.8175, val_MinusLogProbMetric: 16.8175

Epoch 458: val_loss did not improve from 16.81405
196/196 - 41s - loss: 16.4268 - MinusLogProbMetric: 16.4268 - val_loss: 16.8175 - val_MinusLogProbMetric: 16.8175 - lr: 1.2500e-04 - 41s/epoch - 210ms/step
Epoch 459/1000
2023-09-27 09:59:09.497 
Epoch 459/1000 
	 loss: 16.4216, MinusLogProbMetric: 16.4216, val_loss: 16.8230, val_MinusLogProbMetric: 16.8230

Epoch 459: val_loss did not improve from 16.81405
196/196 - 40s - loss: 16.4216 - MinusLogProbMetric: 16.4216 - val_loss: 16.8230 - val_MinusLogProbMetric: 16.8230 - lr: 1.2500e-04 - 40s/epoch - 204ms/step
Epoch 460/1000
2023-09-27 09:59:49.072 
Epoch 460/1000 
	 loss: 16.4217, MinusLogProbMetric: 16.4217, val_loss: 16.8297, val_MinusLogProbMetric: 16.8297

Epoch 460: val_loss did not improve from 16.81405
196/196 - 40s - loss: 16.4217 - MinusLogProbMetric: 16.4217 - val_loss: 16.8297 - val_MinusLogProbMetric: 16.8297 - lr: 1.2500e-04 - 40s/epoch - 202ms/step
Epoch 461/1000
2023-09-27 10:00:28.832 
Epoch 461/1000 
	 loss: 16.4212, MinusLogProbMetric: 16.4212, val_loss: 16.8207, val_MinusLogProbMetric: 16.8207

Epoch 461: val_loss did not improve from 16.81405
196/196 - 40s - loss: 16.4212 - MinusLogProbMetric: 16.4212 - val_loss: 16.8207 - val_MinusLogProbMetric: 16.8207 - lr: 1.2500e-04 - 40s/epoch - 203ms/step
Epoch 462/1000
2023-09-27 10:01:08.537 
Epoch 462/1000 
	 loss: 16.4166, MinusLogProbMetric: 16.4166, val_loss: 16.8252, val_MinusLogProbMetric: 16.8252

Epoch 462: val_loss did not improve from 16.81405
196/196 - 40s - loss: 16.4166 - MinusLogProbMetric: 16.4166 - val_loss: 16.8252 - val_MinusLogProbMetric: 16.8252 - lr: 1.2500e-04 - 40s/epoch - 203ms/step
Epoch 463/1000
2023-09-27 10:01:49.661 
Epoch 463/1000 
	 loss: 16.4235, MinusLogProbMetric: 16.4235, val_loss: 16.8134, val_MinusLogProbMetric: 16.8134

Epoch 463: val_loss improved from 16.81405 to 16.81343, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 42s - loss: 16.4235 - MinusLogProbMetric: 16.4235 - val_loss: 16.8134 - val_MinusLogProbMetric: 16.8134 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 464/1000
2023-09-27 10:02:30.313 
Epoch 464/1000 
	 loss: 16.4228, MinusLogProbMetric: 16.4228, val_loss: 16.8201, val_MinusLogProbMetric: 16.8201

Epoch 464: val_loss did not improve from 16.81343
196/196 - 40s - loss: 16.4228 - MinusLogProbMetric: 16.4228 - val_loss: 16.8201 - val_MinusLogProbMetric: 16.8201 - lr: 1.2500e-04 - 40s/epoch - 204ms/step
Epoch 465/1000
2023-09-27 10:03:10.355 
Epoch 465/1000 
	 loss: 16.4249, MinusLogProbMetric: 16.4249, val_loss: 16.8447, val_MinusLogProbMetric: 16.8447

Epoch 465: val_loss did not improve from 16.81343
196/196 - 40s - loss: 16.4249 - MinusLogProbMetric: 16.4249 - val_loss: 16.8447 - val_MinusLogProbMetric: 16.8447 - lr: 1.2500e-04 - 40s/epoch - 204ms/step
Epoch 466/1000
2023-09-27 10:03:50.531 
Epoch 466/1000 
	 loss: 16.4237, MinusLogProbMetric: 16.4237, val_loss: 16.8666, val_MinusLogProbMetric: 16.8666

Epoch 466: val_loss did not improve from 16.81343
196/196 - 40s - loss: 16.4237 - MinusLogProbMetric: 16.4237 - val_loss: 16.8666 - val_MinusLogProbMetric: 16.8666 - lr: 1.2500e-04 - 40s/epoch - 205ms/step
Epoch 467/1000
2023-09-27 10:04:31.766 
Epoch 467/1000 
	 loss: 16.4270, MinusLogProbMetric: 16.4270, val_loss: 16.8350, val_MinusLogProbMetric: 16.8350

Epoch 467: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4270 - MinusLogProbMetric: 16.4270 - val_loss: 16.8350 - val_MinusLogProbMetric: 16.8350 - lr: 1.2500e-04 - 41s/epoch - 210ms/step
Epoch 468/1000
2023-09-27 10:05:12.252 
Epoch 468/1000 
	 loss: 16.4166, MinusLogProbMetric: 16.4166, val_loss: 16.8315, val_MinusLogProbMetric: 16.8315

Epoch 468: val_loss did not improve from 16.81343
196/196 - 40s - loss: 16.4166 - MinusLogProbMetric: 16.4166 - val_loss: 16.8315 - val_MinusLogProbMetric: 16.8315 - lr: 1.2500e-04 - 40s/epoch - 207ms/step
Epoch 469/1000
2023-09-27 10:05:53.712 
Epoch 469/1000 
	 loss: 16.4226, MinusLogProbMetric: 16.4226, val_loss: 16.8227, val_MinusLogProbMetric: 16.8227

Epoch 469: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4226 - MinusLogProbMetric: 16.4226 - val_loss: 16.8227 - val_MinusLogProbMetric: 16.8227 - lr: 1.2500e-04 - 41s/epoch - 212ms/step
Epoch 470/1000
2023-09-27 10:06:29.956 
Epoch 470/1000 
	 loss: 16.4181, MinusLogProbMetric: 16.4181, val_loss: 16.8335, val_MinusLogProbMetric: 16.8335

Epoch 470: val_loss did not improve from 16.81343
196/196 - 36s - loss: 16.4181 - MinusLogProbMetric: 16.4181 - val_loss: 16.8335 - val_MinusLogProbMetric: 16.8335 - lr: 1.2500e-04 - 36s/epoch - 185ms/step
Epoch 471/1000
2023-09-27 10:07:05.927 
Epoch 471/1000 
	 loss: 16.4167, MinusLogProbMetric: 16.4167, val_loss: 16.8291, val_MinusLogProbMetric: 16.8291

Epoch 471: val_loss did not improve from 16.81343
196/196 - 36s - loss: 16.4167 - MinusLogProbMetric: 16.4167 - val_loss: 16.8291 - val_MinusLogProbMetric: 16.8291 - lr: 1.2500e-04 - 36s/epoch - 183ms/step
Epoch 472/1000
2023-09-27 10:07:40.410 
Epoch 472/1000 
	 loss: 16.4195, MinusLogProbMetric: 16.4195, val_loss: 16.8308, val_MinusLogProbMetric: 16.8308

Epoch 472: val_loss did not improve from 16.81343
196/196 - 34s - loss: 16.4195 - MinusLogProbMetric: 16.4195 - val_loss: 16.8308 - val_MinusLogProbMetric: 16.8308 - lr: 1.2500e-04 - 34s/epoch - 176ms/step
Epoch 473/1000
2023-09-27 10:08:16.236 
Epoch 473/1000 
	 loss: 16.4313, MinusLogProbMetric: 16.4313, val_loss: 16.8398, val_MinusLogProbMetric: 16.8398

Epoch 473: val_loss did not improve from 16.81343
196/196 - 36s - loss: 16.4313 - MinusLogProbMetric: 16.4313 - val_loss: 16.8398 - val_MinusLogProbMetric: 16.8398 - lr: 1.2500e-04 - 36s/epoch - 183ms/step
Epoch 474/1000
2023-09-27 10:08:56.328 
Epoch 474/1000 
	 loss: 16.4211, MinusLogProbMetric: 16.4211, val_loss: 16.8208, val_MinusLogProbMetric: 16.8208

Epoch 474: val_loss did not improve from 16.81343
196/196 - 40s - loss: 16.4211 - MinusLogProbMetric: 16.4211 - val_loss: 16.8208 - val_MinusLogProbMetric: 16.8208 - lr: 1.2500e-04 - 40s/epoch - 205ms/step
Epoch 475/1000
2023-09-27 10:09:36.117 
Epoch 475/1000 
	 loss: 16.4147, MinusLogProbMetric: 16.4147, val_loss: 16.8207, val_MinusLogProbMetric: 16.8207

Epoch 475: val_loss did not improve from 16.81343
196/196 - 40s - loss: 16.4147 - MinusLogProbMetric: 16.4147 - val_loss: 16.8207 - val_MinusLogProbMetric: 16.8207 - lr: 1.2500e-04 - 40s/epoch - 203ms/step
Epoch 476/1000
2023-09-27 10:10:16.376 
Epoch 476/1000 
	 loss: 16.4182, MinusLogProbMetric: 16.4182, val_loss: 16.8341, val_MinusLogProbMetric: 16.8341

Epoch 476: val_loss did not improve from 16.81343
196/196 - 40s - loss: 16.4182 - MinusLogProbMetric: 16.4182 - val_loss: 16.8341 - val_MinusLogProbMetric: 16.8341 - lr: 1.2500e-04 - 40s/epoch - 205ms/step
Epoch 477/1000
2023-09-27 10:10:57.777 
Epoch 477/1000 
	 loss: 16.4194, MinusLogProbMetric: 16.4194, val_loss: 16.8253, val_MinusLogProbMetric: 16.8253

Epoch 477: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4194 - MinusLogProbMetric: 16.4194 - val_loss: 16.8253 - val_MinusLogProbMetric: 16.8253 - lr: 1.2500e-04 - 41s/epoch - 211ms/step
Epoch 478/1000
2023-09-27 10:11:38.675 
Epoch 478/1000 
	 loss: 16.4229, MinusLogProbMetric: 16.4229, val_loss: 16.8230, val_MinusLogProbMetric: 16.8230

Epoch 478: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4229 - MinusLogProbMetric: 16.4229 - val_loss: 16.8230 - val_MinusLogProbMetric: 16.8230 - lr: 1.2500e-04 - 41s/epoch - 209ms/step
Epoch 479/1000
2023-09-27 10:12:19.774 
Epoch 479/1000 
	 loss: 16.4170, MinusLogProbMetric: 16.4170, val_loss: 16.8255, val_MinusLogProbMetric: 16.8255

Epoch 479: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4170 - MinusLogProbMetric: 16.4170 - val_loss: 16.8255 - val_MinusLogProbMetric: 16.8255 - lr: 1.2500e-04 - 41s/epoch - 210ms/step
Epoch 480/1000
2023-09-27 10:13:01.595 
Epoch 480/1000 
	 loss: 16.4211, MinusLogProbMetric: 16.4211, val_loss: 16.8249, val_MinusLogProbMetric: 16.8249

Epoch 480: val_loss did not improve from 16.81343
196/196 - 42s - loss: 16.4211 - MinusLogProbMetric: 16.4211 - val_loss: 16.8249 - val_MinusLogProbMetric: 16.8249 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 481/1000
2023-09-27 10:13:44.732 
Epoch 481/1000 
	 loss: 16.4176, MinusLogProbMetric: 16.4176, val_loss: 16.8401, val_MinusLogProbMetric: 16.8401

Epoch 481: val_loss did not improve from 16.81343
196/196 - 43s - loss: 16.4176 - MinusLogProbMetric: 16.4176 - val_loss: 16.8401 - val_MinusLogProbMetric: 16.8401 - lr: 1.2500e-04 - 43s/epoch - 220ms/step
Epoch 482/1000
2023-09-27 10:14:26.925 
Epoch 482/1000 
	 loss: 16.4181, MinusLogProbMetric: 16.4181, val_loss: 16.8923, val_MinusLogProbMetric: 16.8923

Epoch 482: val_loss did not improve from 16.81343
196/196 - 42s - loss: 16.4181 - MinusLogProbMetric: 16.4181 - val_loss: 16.8923 - val_MinusLogProbMetric: 16.8923 - lr: 1.2500e-04 - 42s/epoch - 215ms/step
Epoch 483/1000
2023-09-27 10:15:08.074 
Epoch 483/1000 
	 loss: 16.4235, MinusLogProbMetric: 16.4235, val_loss: 16.8544, val_MinusLogProbMetric: 16.8544

Epoch 483: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4235 - MinusLogProbMetric: 16.4235 - val_loss: 16.8544 - val_MinusLogProbMetric: 16.8544 - lr: 1.2500e-04 - 41s/epoch - 210ms/step
Epoch 484/1000
2023-09-27 10:15:48.941 
Epoch 484/1000 
	 loss: 16.4167, MinusLogProbMetric: 16.4167, val_loss: 16.8231, val_MinusLogProbMetric: 16.8231

Epoch 484: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4167 - MinusLogProbMetric: 16.4167 - val_loss: 16.8231 - val_MinusLogProbMetric: 16.8231 - lr: 1.2500e-04 - 41s/epoch - 208ms/step
Epoch 485/1000
2023-09-27 10:16:30.532 
Epoch 485/1000 
	 loss: 16.4137, MinusLogProbMetric: 16.4137, val_loss: 16.8300, val_MinusLogProbMetric: 16.8300

Epoch 485: val_loss did not improve from 16.81343
196/196 - 42s - loss: 16.4137 - MinusLogProbMetric: 16.4137 - val_loss: 16.8300 - val_MinusLogProbMetric: 16.8300 - lr: 1.2500e-04 - 42s/epoch - 212ms/step
Epoch 486/1000
2023-09-27 10:17:11.923 
Epoch 486/1000 
	 loss: 16.4185, MinusLogProbMetric: 16.4185, val_loss: 16.8389, val_MinusLogProbMetric: 16.8389

Epoch 486: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4185 - MinusLogProbMetric: 16.4185 - val_loss: 16.8389 - val_MinusLogProbMetric: 16.8389 - lr: 1.2500e-04 - 41s/epoch - 211ms/step
Epoch 487/1000
2023-09-27 10:17:54.094 
Epoch 487/1000 
	 loss: 16.4173, MinusLogProbMetric: 16.4173, val_loss: 16.8272, val_MinusLogProbMetric: 16.8272

Epoch 487: val_loss did not improve from 16.81343
196/196 - 42s - loss: 16.4173 - MinusLogProbMetric: 16.4173 - val_loss: 16.8272 - val_MinusLogProbMetric: 16.8272 - lr: 1.2500e-04 - 42s/epoch - 215ms/step
Epoch 488/1000
2023-09-27 10:18:35.801 
Epoch 488/1000 
	 loss: 16.4164, MinusLogProbMetric: 16.4164, val_loss: 16.8226, val_MinusLogProbMetric: 16.8226

Epoch 488: val_loss did not improve from 16.81343
196/196 - 42s - loss: 16.4164 - MinusLogProbMetric: 16.4164 - val_loss: 16.8226 - val_MinusLogProbMetric: 16.8226 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 489/1000
2023-09-27 10:19:15.917 
Epoch 489/1000 
	 loss: 16.4362, MinusLogProbMetric: 16.4362, val_loss: 16.8285, val_MinusLogProbMetric: 16.8285

Epoch 489: val_loss did not improve from 16.81343
196/196 - 40s - loss: 16.4362 - MinusLogProbMetric: 16.4362 - val_loss: 16.8285 - val_MinusLogProbMetric: 16.8285 - lr: 1.2500e-04 - 40s/epoch - 205ms/step
Epoch 490/1000
2023-09-27 10:19:57.323 
Epoch 490/1000 
	 loss: 16.4187, MinusLogProbMetric: 16.4187, val_loss: 16.8198, val_MinusLogProbMetric: 16.8198

Epoch 490: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4187 - MinusLogProbMetric: 16.4187 - val_loss: 16.8198 - val_MinusLogProbMetric: 16.8198 - lr: 1.2500e-04 - 41s/epoch - 211ms/step
Epoch 491/1000
2023-09-27 10:20:37.916 
Epoch 491/1000 
	 loss: 16.4300, MinusLogProbMetric: 16.4300, val_loss: 16.8255, val_MinusLogProbMetric: 16.8255

Epoch 491: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4300 - MinusLogProbMetric: 16.4300 - val_loss: 16.8255 - val_MinusLogProbMetric: 16.8255 - lr: 1.2500e-04 - 41s/epoch - 207ms/step
Epoch 492/1000
2023-09-27 10:21:19.034 
Epoch 492/1000 
	 loss: 16.4197, MinusLogProbMetric: 16.4197, val_loss: 16.8427, val_MinusLogProbMetric: 16.8427

Epoch 492: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4197 - MinusLogProbMetric: 16.4197 - val_loss: 16.8427 - val_MinusLogProbMetric: 16.8427 - lr: 1.2500e-04 - 41s/epoch - 210ms/step
Epoch 493/1000
2023-09-27 10:22:00.991 
Epoch 493/1000 
	 loss: 16.4236, MinusLogProbMetric: 16.4236, val_loss: 16.8348, val_MinusLogProbMetric: 16.8348

Epoch 493: val_loss did not improve from 16.81343
196/196 - 42s - loss: 16.4236 - MinusLogProbMetric: 16.4236 - val_loss: 16.8348 - val_MinusLogProbMetric: 16.8348 - lr: 1.2500e-04 - 42s/epoch - 214ms/step
Epoch 494/1000
2023-09-27 10:22:43.520 
Epoch 494/1000 
	 loss: 16.4190, MinusLogProbMetric: 16.4190, val_loss: 16.8357, val_MinusLogProbMetric: 16.8357

Epoch 494: val_loss did not improve from 16.81343
196/196 - 43s - loss: 16.4190 - MinusLogProbMetric: 16.4190 - val_loss: 16.8357 - val_MinusLogProbMetric: 16.8357 - lr: 1.2500e-04 - 43s/epoch - 217ms/step
Epoch 495/1000
2023-09-27 10:23:26.426 
Epoch 495/1000 
	 loss: 16.4265, MinusLogProbMetric: 16.4265, val_loss: 16.8271, val_MinusLogProbMetric: 16.8271

Epoch 495: val_loss did not improve from 16.81343
196/196 - 43s - loss: 16.4265 - MinusLogProbMetric: 16.4265 - val_loss: 16.8271 - val_MinusLogProbMetric: 16.8271 - lr: 1.2500e-04 - 43s/epoch - 219ms/step
Epoch 496/1000
2023-09-27 10:24:08.218 
Epoch 496/1000 
	 loss: 16.4170, MinusLogProbMetric: 16.4170, val_loss: 16.8340, val_MinusLogProbMetric: 16.8340

Epoch 496: val_loss did not improve from 16.81343
196/196 - 42s - loss: 16.4170 - MinusLogProbMetric: 16.4170 - val_loss: 16.8340 - val_MinusLogProbMetric: 16.8340 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 497/1000
2023-09-27 10:24:49.771 
Epoch 497/1000 
	 loss: 16.4205, MinusLogProbMetric: 16.4205, val_loss: 16.8331, val_MinusLogProbMetric: 16.8331

Epoch 497: val_loss did not improve from 16.81343
196/196 - 42s - loss: 16.4205 - MinusLogProbMetric: 16.4205 - val_loss: 16.8331 - val_MinusLogProbMetric: 16.8331 - lr: 1.2500e-04 - 42s/epoch - 212ms/step
Epoch 498/1000
2023-09-27 10:25:30.728 
Epoch 498/1000 
	 loss: 16.4307, MinusLogProbMetric: 16.4307, val_loss: 16.8378, val_MinusLogProbMetric: 16.8378

Epoch 498: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4307 - MinusLogProbMetric: 16.4307 - val_loss: 16.8378 - val_MinusLogProbMetric: 16.8378 - lr: 1.2500e-04 - 41s/epoch - 209ms/step
Epoch 499/1000
2023-09-27 10:26:11.227 
Epoch 499/1000 
	 loss: 16.4132, MinusLogProbMetric: 16.4132, val_loss: 16.8419, val_MinusLogProbMetric: 16.8419

Epoch 499: val_loss did not improve from 16.81343
196/196 - 40s - loss: 16.4132 - MinusLogProbMetric: 16.4132 - val_loss: 16.8419 - val_MinusLogProbMetric: 16.8419 - lr: 1.2500e-04 - 40s/epoch - 207ms/step
Epoch 500/1000
2023-09-27 10:26:52.318 
Epoch 500/1000 
	 loss: 16.4193, MinusLogProbMetric: 16.4193, val_loss: 16.8314, val_MinusLogProbMetric: 16.8314

Epoch 500: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4193 - MinusLogProbMetric: 16.4193 - val_loss: 16.8314 - val_MinusLogProbMetric: 16.8314 - lr: 1.2500e-04 - 41s/epoch - 210ms/step
Epoch 501/1000
2023-09-27 10:27:33.621 
Epoch 501/1000 
	 loss: 16.4161, MinusLogProbMetric: 16.4161, val_loss: 16.8262, val_MinusLogProbMetric: 16.8262

Epoch 501: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4161 - MinusLogProbMetric: 16.4161 - val_loss: 16.8262 - val_MinusLogProbMetric: 16.8262 - lr: 1.2500e-04 - 41s/epoch - 211ms/step
Epoch 502/1000
2023-09-27 10:28:14.596 
Epoch 502/1000 
	 loss: 16.4149, MinusLogProbMetric: 16.4149, val_loss: 16.8401, val_MinusLogProbMetric: 16.8401

Epoch 502: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4149 - MinusLogProbMetric: 16.4149 - val_loss: 16.8401 - val_MinusLogProbMetric: 16.8401 - lr: 1.2500e-04 - 41s/epoch - 209ms/step
Epoch 503/1000
2023-09-27 10:28:56.581 
Epoch 503/1000 
	 loss: 16.4173, MinusLogProbMetric: 16.4173, val_loss: 16.8276, val_MinusLogProbMetric: 16.8276

Epoch 503: val_loss did not improve from 16.81343
196/196 - 42s - loss: 16.4173 - MinusLogProbMetric: 16.4173 - val_loss: 16.8276 - val_MinusLogProbMetric: 16.8276 - lr: 1.2500e-04 - 42s/epoch - 214ms/step
Epoch 504/1000
2023-09-27 10:29:37.929 
Epoch 504/1000 
	 loss: 16.4136, MinusLogProbMetric: 16.4136, val_loss: 16.8529, val_MinusLogProbMetric: 16.8529

Epoch 504: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4136 - MinusLogProbMetric: 16.4136 - val_loss: 16.8529 - val_MinusLogProbMetric: 16.8529 - lr: 1.2500e-04 - 41s/epoch - 211ms/step
Epoch 505/1000
2023-09-27 10:30:20.578 
Epoch 505/1000 
	 loss: 16.4221, MinusLogProbMetric: 16.4221, val_loss: 16.8264, val_MinusLogProbMetric: 16.8264

Epoch 505: val_loss did not improve from 16.81343
196/196 - 43s - loss: 16.4221 - MinusLogProbMetric: 16.4221 - val_loss: 16.8264 - val_MinusLogProbMetric: 16.8264 - lr: 1.2500e-04 - 43s/epoch - 218ms/step
Epoch 506/1000
2023-09-27 10:31:02.008 
Epoch 506/1000 
	 loss: 16.4225, MinusLogProbMetric: 16.4225, val_loss: 16.8343, val_MinusLogProbMetric: 16.8343

Epoch 506: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4225 - MinusLogProbMetric: 16.4225 - val_loss: 16.8343 - val_MinusLogProbMetric: 16.8343 - lr: 1.2500e-04 - 41s/epoch - 211ms/step
Epoch 507/1000
2023-09-27 10:31:43.558 
Epoch 507/1000 
	 loss: 16.4144, MinusLogProbMetric: 16.4144, val_loss: 16.8225, val_MinusLogProbMetric: 16.8225

Epoch 507: val_loss did not improve from 16.81343
196/196 - 42s - loss: 16.4144 - MinusLogProbMetric: 16.4144 - val_loss: 16.8225 - val_MinusLogProbMetric: 16.8225 - lr: 1.2500e-04 - 42s/epoch - 212ms/step
Epoch 508/1000
2023-09-27 10:32:24.810 
Epoch 508/1000 
	 loss: 16.4208, MinusLogProbMetric: 16.4208, val_loss: 16.8539, val_MinusLogProbMetric: 16.8539

Epoch 508: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4208 - MinusLogProbMetric: 16.4208 - val_loss: 16.8539 - val_MinusLogProbMetric: 16.8539 - lr: 1.2500e-04 - 41s/epoch - 210ms/step
Epoch 509/1000
2023-09-27 10:33:05.708 
Epoch 509/1000 
	 loss: 16.4245, MinusLogProbMetric: 16.4245, val_loss: 16.8440, val_MinusLogProbMetric: 16.8440

Epoch 509: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4245 - MinusLogProbMetric: 16.4245 - val_loss: 16.8440 - val_MinusLogProbMetric: 16.8440 - lr: 1.2500e-04 - 41s/epoch - 209ms/step
Epoch 510/1000
2023-09-27 10:33:47.039 
Epoch 510/1000 
	 loss: 16.4148, MinusLogProbMetric: 16.4148, val_loss: 16.8467, val_MinusLogProbMetric: 16.8467

Epoch 510: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4148 - MinusLogProbMetric: 16.4148 - val_loss: 16.8467 - val_MinusLogProbMetric: 16.8467 - lr: 1.2500e-04 - 41s/epoch - 211ms/step
Epoch 511/1000
2023-09-27 10:34:28.989 
Epoch 511/1000 
	 loss: 16.4165, MinusLogProbMetric: 16.4165, val_loss: 16.8226, val_MinusLogProbMetric: 16.8226

Epoch 511: val_loss did not improve from 16.81343
196/196 - 42s - loss: 16.4165 - MinusLogProbMetric: 16.4165 - val_loss: 16.8226 - val_MinusLogProbMetric: 16.8226 - lr: 1.2500e-04 - 42s/epoch - 214ms/step
Epoch 512/1000
2023-09-27 10:35:09.324 
Epoch 512/1000 
	 loss: 16.4157, MinusLogProbMetric: 16.4157, val_loss: 16.8211, val_MinusLogProbMetric: 16.8211

Epoch 512: val_loss did not improve from 16.81343
196/196 - 40s - loss: 16.4157 - MinusLogProbMetric: 16.4157 - val_loss: 16.8211 - val_MinusLogProbMetric: 16.8211 - lr: 1.2500e-04 - 40s/epoch - 206ms/step
Epoch 513/1000
2023-09-27 10:35:50.199 
Epoch 513/1000 
	 loss: 16.4106, MinusLogProbMetric: 16.4106, val_loss: 16.8439, val_MinusLogProbMetric: 16.8439

Epoch 513: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4106 - MinusLogProbMetric: 16.4106 - val_loss: 16.8439 - val_MinusLogProbMetric: 16.8439 - lr: 1.2500e-04 - 41s/epoch - 209ms/step
Epoch 514/1000
2023-09-27 10:36:32.655 
Epoch 514/1000 
	 loss: 16.4015, MinusLogProbMetric: 16.4015, val_loss: 16.8271, val_MinusLogProbMetric: 16.8271

Epoch 514: val_loss did not improve from 16.81343
196/196 - 42s - loss: 16.4015 - MinusLogProbMetric: 16.4015 - val_loss: 16.8271 - val_MinusLogProbMetric: 16.8271 - lr: 6.2500e-05 - 42s/epoch - 217ms/step
Epoch 515/1000
2023-09-27 10:37:14.367 
Epoch 515/1000 
	 loss: 16.3976, MinusLogProbMetric: 16.3976, val_loss: 16.8224, val_MinusLogProbMetric: 16.8224

Epoch 515: val_loss did not improve from 16.81343
196/196 - 42s - loss: 16.3976 - MinusLogProbMetric: 16.3976 - val_loss: 16.8224 - val_MinusLogProbMetric: 16.8224 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 516/1000
2023-09-27 10:37:55.885 
Epoch 516/1000 
	 loss: 16.4137, MinusLogProbMetric: 16.4137, val_loss: 16.8381, val_MinusLogProbMetric: 16.8381

Epoch 516: val_loss did not improve from 16.81343
196/196 - 42s - loss: 16.4137 - MinusLogProbMetric: 16.4137 - val_loss: 16.8381 - val_MinusLogProbMetric: 16.8381 - lr: 6.2500e-05 - 42s/epoch - 212ms/step
Epoch 517/1000
2023-09-27 10:38:36.970 
Epoch 517/1000 
	 loss: 16.4014, MinusLogProbMetric: 16.4014, val_loss: 16.8208, val_MinusLogProbMetric: 16.8208

Epoch 517: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.4014 - MinusLogProbMetric: 16.4014 - val_loss: 16.8208 - val_MinusLogProbMetric: 16.8208 - lr: 6.2500e-05 - 41s/epoch - 210ms/step
Epoch 518/1000
2023-09-27 10:39:18.250 
Epoch 518/1000 
	 loss: 16.3976, MinusLogProbMetric: 16.3976, val_loss: 16.8210, val_MinusLogProbMetric: 16.8210

Epoch 518: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.3976 - MinusLogProbMetric: 16.3976 - val_loss: 16.8210 - val_MinusLogProbMetric: 16.8210 - lr: 6.2500e-05 - 41s/epoch - 211ms/step
Epoch 519/1000
2023-09-27 10:39:58.265 
Epoch 519/1000 
	 loss: 16.4004, MinusLogProbMetric: 16.4004, val_loss: 16.8249, val_MinusLogProbMetric: 16.8249

Epoch 519: val_loss did not improve from 16.81343
196/196 - 40s - loss: 16.4004 - MinusLogProbMetric: 16.4004 - val_loss: 16.8249 - val_MinusLogProbMetric: 16.8249 - lr: 6.2500e-05 - 40s/epoch - 204ms/step
Epoch 520/1000
2023-09-27 10:40:39.304 
Epoch 520/1000 
	 loss: 16.3980, MinusLogProbMetric: 16.3980, val_loss: 16.8150, val_MinusLogProbMetric: 16.8150

Epoch 520: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.3980 - MinusLogProbMetric: 16.3980 - val_loss: 16.8150 - val_MinusLogProbMetric: 16.8150 - lr: 6.2500e-05 - 41s/epoch - 209ms/step
Epoch 521/1000
2023-09-27 10:41:20.043 
Epoch 521/1000 
	 loss: 16.3976, MinusLogProbMetric: 16.3976, val_loss: 16.8166, val_MinusLogProbMetric: 16.8166

Epoch 521: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.3976 - MinusLogProbMetric: 16.3976 - val_loss: 16.8166 - val_MinusLogProbMetric: 16.8166 - lr: 6.2500e-05 - 41s/epoch - 208ms/step
Epoch 522/1000
2023-09-27 10:42:01.580 
Epoch 522/1000 
	 loss: 16.4000, MinusLogProbMetric: 16.4000, val_loss: 16.8399, val_MinusLogProbMetric: 16.8399

Epoch 522: val_loss did not improve from 16.81343
196/196 - 42s - loss: 16.4000 - MinusLogProbMetric: 16.4000 - val_loss: 16.8399 - val_MinusLogProbMetric: 16.8399 - lr: 6.2500e-05 - 42s/epoch - 212ms/step
Epoch 523/1000
2023-09-27 10:42:42.666 
Epoch 523/1000 
	 loss: 16.3992, MinusLogProbMetric: 16.3992, val_loss: 16.8193, val_MinusLogProbMetric: 16.8193

Epoch 523: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.3992 - MinusLogProbMetric: 16.3992 - val_loss: 16.8193 - val_MinusLogProbMetric: 16.8193 - lr: 6.2500e-05 - 41s/epoch - 210ms/step
Epoch 524/1000
2023-09-27 10:43:23.956 
Epoch 524/1000 
	 loss: 16.3982, MinusLogProbMetric: 16.3982, val_loss: 16.8424, val_MinusLogProbMetric: 16.8424

Epoch 524: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.3982 - MinusLogProbMetric: 16.3982 - val_loss: 16.8424 - val_MinusLogProbMetric: 16.8424 - lr: 6.2500e-05 - 41s/epoch - 211ms/step
Epoch 525/1000
2023-09-27 10:44:04.221 
Epoch 525/1000 
	 loss: 16.4014, MinusLogProbMetric: 16.4014, val_loss: 16.8140, val_MinusLogProbMetric: 16.8140

Epoch 525: val_loss did not improve from 16.81343
196/196 - 40s - loss: 16.4014 - MinusLogProbMetric: 16.4014 - val_loss: 16.8140 - val_MinusLogProbMetric: 16.8140 - lr: 6.2500e-05 - 40s/epoch - 205ms/step
Epoch 526/1000
2023-09-27 10:44:46.264 
Epoch 526/1000 
	 loss: 16.3974, MinusLogProbMetric: 16.3974, val_loss: 16.8174, val_MinusLogProbMetric: 16.8174

Epoch 526: val_loss did not improve from 16.81343
196/196 - 42s - loss: 16.3974 - MinusLogProbMetric: 16.3974 - val_loss: 16.8174 - val_MinusLogProbMetric: 16.8174 - lr: 6.2500e-05 - 42s/epoch - 214ms/step
Epoch 527/1000
2023-09-27 10:45:27.216 
Epoch 527/1000 
	 loss: 16.3984, MinusLogProbMetric: 16.3984, val_loss: 16.8146, val_MinusLogProbMetric: 16.8146

Epoch 527: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.3984 - MinusLogProbMetric: 16.3984 - val_loss: 16.8146 - val_MinusLogProbMetric: 16.8146 - lr: 6.2500e-05 - 41s/epoch - 209ms/step
Epoch 528/1000
2023-09-27 10:46:08.610 
Epoch 528/1000 
	 loss: 16.3960, MinusLogProbMetric: 16.3960, val_loss: 16.8146, val_MinusLogProbMetric: 16.8146

Epoch 528: val_loss did not improve from 16.81343
196/196 - 41s - loss: 16.3960 - MinusLogProbMetric: 16.3960 - val_loss: 16.8146 - val_MinusLogProbMetric: 16.8146 - lr: 6.2500e-05 - 41s/epoch - 211ms/step
Epoch 529/1000
2023-09-27 10:46:48.975 
Epoch 529/1000 
	 loss: 16.3987, MinusLogProbMetric: 16.3987, val_loss: 16.8227, val_MinusLogProbMetric: 16.8227

Epoch 529: val_loss did not improve from 16.81343
196/196 - 40s - loss: 16.3987 - MinusLogProbMetric: 16.3987 - val_loss: 16.8227 - val_MinusLogProbMetric: 16.8227 - lr: 6.2500e-05 - 40s/epoch - 206ms/step
Epoch 530/1000
2023-09-27 10:47:30.411 
Epoch 530/1000 
	 loss: 16.3966, MinusLogProbMetric: 16.3966, val_loss: 16.8134, val_MinusLogProbMetric: 16.8134

Epoch 530: val_loss improved from 16.81343 to 16.81339, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_299/weights/best_weights.h5
196/196 - 42s - loss: 16.3966 - MinusLogProbMetric: 16.3966 - val_loss: 16.8134 - val_MinusLogProbMetric: 16.8134 - lr: 6.2500e-05 - 42s/epoch - 214ms/step
Epoch 531/1000
2023-09-27 10:48:11.851 
Epoch 531/1000 
	 loss: 16.3975, MinusLogProbMetric: 16.3975, val_loss: 16.8195, val_MinusLogProbMetric: 16.8195

Epoch 531: val_loss did not improve from 16.81339
196/196 - 41s - loss: 16.3975 - MinusLogProbMetric: 16.3975 - val_loss: 16.8195 - val_MinusLogProbMetric: 16.8195 - lr: 6.2500e-05 - 41s/epoch - 209ms/step
Epoch 532/1000
2023-09-27 10:48:52.696 
Epoch 532/1000 
	 loss: 16.3983, MinusLogProbMetric: 16.3983, val_loss: 16.8252, val_MinusLogProbMetric: 16.8252

Epoch 532: val_loss did not improve from 16.81339
196/196 - 41s - loss: 16.3983 - MinusLogProbMetric: 16.3983 - val_loss: 16.8252 - val_MinusLogProbMetric: 16.8252 - lr: 6.2500e-05 - 41s/epoch - 208ms/step
Epoch 533/1000
2023-09-27 10:49:32.731 
Epoch 533/1000 
	 loss: 16.4036, MinusLogProbMetric: 16.4036, val_loss: 16.8186, val_MinusLogProbMetric: 16.8186

Epoch 533: val_loss did not improve from 16.81339
196/196 - 40s - loss: 16.4036 - MinusLogProbMetric: 16.4036 - val_loss: 16.8186 - val_MinusLogProbMetric: 16.8186 - lr: 6.2500e-05 - 40s/epoch - 204ms/step
Epoch 534/1000
2023-09-27 10:50:13.550 
Epoch 534/1000 
	 loss: 16.4001, MinusLogProbMetric: 16.4001, val_loss: 16.8185, val_MinusLogProbMetric: 16.8185

Epoch 534: val_loss did not improve from 16.81339
196/196 - 41s - loss: 16.4001 - MinusLogProbMetric: 16.4001 - val_loss: 16.8185 - val_MinusLogProbMetric: 16.8185 - lr: 6.2500e-05 - 41s/epoch - 208ms/step
Epoch 535/1000
2023-09-27 10:50:55.011 
Epoch 535/1000 
	 loss: 16.3956, MinusLogProbMetric: 16.3956, val_loss: 16.8248, val_MinusLogProbMetric: 16.8248

Epoch 535: val_loss did not improve from 16.81339
196/196 - 41s - loss: 16.3956 - MinusLogProbMetric: 16.3956 - val_loss: 16.8248 - val_MinusLogProbMetric: 16.8248 - lr: 6.2500e-05 - 41s/epoch - 212ms/step
Epoch 536/1000
2023-09-27 10:51:35.557 
Epoch 536/1000 
	 loss: 16.3990, MinusLogProbMetric: 16.3990, val_loss: 16.8167, val_MinusLogProbMetric: 16.8167

Epoch 536: val_loss did not improve from 16.81339
196/196 - 41s - loss: 16.3990 - MinusLogProbMetric: 16.3990 - val_loss: 16.8167 - val_MinusLogProbMetric: 16.8167 - lr: 6.2500e-05 - 41s/epoch - 207ms/step
Epoch 537/1000
2023-09-27 10:52:16.762 
Epoch 537/1000 
	 loss: 16.3998, MinusLogProbMetric: 16.3998, val_loss: 16.8165, val_MinusLogProbMetric: 16.8165

Epoch 537: val_loss did not improve from 16.81339
196/196 - 41s - loss: 16.3998 - MinusLogProbMetric: 16.3998 - val_loss: 16.8165 - val_MinusLogProbMetric: 16.8165 - lr: 6.2500e-05 - 41s/epoch - 210ms/step
Epoch 538/1000
2023-09-27 10:52:58.263 
Epoch 538/1000 
	 loss: 16.3987, MinusLogProbMetric: 16.3987, val_loss: 16.8241, val_MinusLogProbMetric: 16.8241

Epoch 538: val_loss did not improve from 16.81339
196/196 - 41s - loss: 16.3987 - MinusLogProbMetric: 16.3987 - val_loss: 16.8241 - val_MinusLogProbMetric: 16.8241 - lr: 6.2500e-05 - 41s/epoch - 212ms/step
Epoch 539/1000
2023-09-27 10:53:39.990 
Epoch 539/1000 
	 loss: 16.3986, MinusLogProbMetric: 16.3986, val_loss: 16.8295, val_MinusLogProbMetric: 16.8295

Epoch 539: val_loss did not improve from 16.81339
196/196 - 42s - loss: 16.3986 - MinusLogProbMetric: 16.3986 - val_loss: 16.8295 - val_MinusLogProbMetric: 16.8295 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 540/1000
2023-09-27 10:54:20.694 
Epoch 540/1000 
	 loss: 16.3967, MinusLogProbMetric: 16.3967, val_loss: 16.8250, val_MinusLogProbMetric: 16.8250

Epoch 540: val_loss did not improve from 16.81339
196/196 - 41s - loss: 16.3967 - MinusLogProbMetric: 16.3967 - val_loss: 16.8250 - val_MinusLogProbMetric: 16.8250 - lr: 6.2500e-05 - 41s/epoch - 208ms/step
Epoch 541/1000
2023-09-27 10:55:00.900 
Epoch 541/1000 
	 loss: 16.3976, MinusLogProbMetric: 16.3976, val_loss: 16.8175, val_MinusLogProbMetric: 16.8175

Epoch 541: val_loss did not improve from 16.81339
196/196 - 40s - loss: 16.3976 - MinusLogProbMetric: 16.3976 - val_loss: 16.8175 - val_MinusLogProbMetric: 16.8175 - lr: 6.2500e-05 - 40s/epoch - 205ms/step
Epoch 542/1000
2023-09-27 10:55:41.346 
Epoch 542/1000 
	 loss: 16.3963, MinusLogProbMetric: 16.3963, val_loss: 16.8191, val_MinusLogProbMetric: 16.8191

Epoch 542: val_loss did not improve from 16.81339
196/196 - 40s - loss: 16.3963 - MinusLogProbMetric: 16.3963 - val_loss: 16.8191 - val_MinusLogProbMetric: 16.8191 - lr: 6.2500e-05 - 40s/epoch - 206ms/step
Epoch 543/1000
2023-09-27 10:56:22.985 
Epoch 543/1000 
	 loss: 16.3974, MinusLogProbMetric: 16.3974, val_loss: 16.8171, val_MinusLogProbMetric: 16.8171

Epoch 543: val_loss did not improve from 16.81339
196/196 - 42s - loss: 16.3974 - MinusLogProbMetric: 16.3974 - val_loss: 16.8171 - val_MinusLogProbMetric: 16.8171 - lr: 6.2500e-05 - 42s/epoch - 212ms/step
Epoch 544/1000
2023-09-27 10:57:04.253 
Epoch 544/1000 
	 loss: 16.4026, MinusLogProbMetric: 16.4026, val_loss: 16.8216, val_MinusLogProbMetric: 16.8216

Epoch 544: val_loss did not improve from 16.81339
196/196 - 41s - loss: 16.4026 - MinusLogProbMetric: 16.4026 - val_loss: 16.8216 - val_MinusLogProbMetric: 16.8216 - lr: 6.2500e-05 - 41s/epoch - 211ms/step
Epoch 545/1000
2023-09-27 10:57:44.660 
Epoch 545/1000 
	 loss: 16.3964, MinusLogProbMetric: 16.3964, val_loss: 16.8144, val_MinusLogProbMetric: 16.8144

Epoch 545: val_loss did not improve from 16.81339
196/196 - 40s - loss: 16.3964 - MinusLogProbMetric: 16.3964 - val_loss: 16.8144 - val_MinusLogProbMetric: 16.8144 - lr: 6.2500e-05 - 40s/epoch - 206ms/step
Epoch 546/1000
2023-09-27 10:58:25.708 
Epoch 546/1000 
	 loss: 16.3968, MinusLogProbMetric: 16.3968, val_loss: 16.8235, val_MinusLogProbMetric: 16.8235

Epoch 546: val_loss did not improve from 16.81339
196/196 - 41s - loss: 16.3968 - MinusLogProbMetric: 16.3968 - val_loss: 16.8235 - val_MinusLogProbMetric: 16.8235 - lr: 6.2500e-05 - 41s/epoch - 209ms/step
Epoch 547/1000
2023-09-27 10:59:07.279 
Epoch 547/1000 
	 loss: 16.3959, MinusLogProbMetric: 16.3959, val_loss: 16.8213, val_MinusLogProbMetric: 16.8213

Epoch 547: val_loss did not improve from 16.81339
196/196 - 42s - loss: 16.3959 - MinusLogProbMetric: 16.3959 - val_loss: 16.8213 - val_MinusLogProbMetric: 16.8213 - lr: 6.2500e-05 - 42s/epoch - 212ms/step
Epoch 548/1000
2023-09-27 10:59:48.549 
Epoch 548/1000 
	 loss: 16.3982, MinusLogProbMetric: 16.3982, val_loss: 16.8404, val_MinusLogProbMetric: 16.8404

Epoch 548: val_loss did not improve from 16.81339
196/196 - 41s - loss: 16.3982 - MinusLogProbMetric: 16.3982 - val_loss: 16.8404 - val_MinusLogProbMetric: 16.8404 - lr: 6.2500e-05 - 41s/epoch - 211ms/step
Epoch 549/1000
2023-09-27 11:00:29.014 
Epoch 549/1000 
	 loss: 16.3962, MinusLogProbMetric: 16.3962, val_loss: 16.8174, val_MinusLogProbMetric: 16.8174

Epoch 549: val_loss did not improve from 16.81339
196/196 - 40s - loss: 16.3962 - MinusLogProbMetric: 16.3962 - val_loss: 16.8174 - val_MinusLogProbMetric: 16.8174 - lr: 6.2500e-05 - 40s/epoch - 206ms/step
Epoch 550/1000
2023-09-27 11:01:09.553 
Epoch 550/1000 
	 loss: 16.3963, MinusLogProbMetric: 16.3963, val_loss: 16.8171, val_MinusLogProbMetric: 16.8171

Epoch 550: val_loss did not improve from 16.81339
196/196 - 41s - loss: 16.3963 - MinusLogProbMetric: 16.3963 - val_loss: 16.8171 - val_MinusLogProbMetric: 16.8171 - lr: 6.2500e-05 - 41s/epoch - 207ms/step
Epoch 551/1000
2023-09-27 11:01:50.752 
Epoch 551/1000 
	 loss: 16.3963, MinusLogProbMetric: 16.3963, val_loss: 16.8295, val_MinusLogProbMetric: 16.8295

Epoch 551: val_loss did not improve from 16.81339
196/196 - 41s - loss: 16.3963 - MinusLogProbMetric: 16.3963 - val_loss: 16.8295 - val_MinusLogProbMetric: 16.8295 - lr: 6.2500e-05 - 41s/epoch - 210ms/step
Epoch 552/1000
2023-09-27 11:02:31.074 
Epoch 552/1000 
	 loss: 16.3991, MinusLogProbMetric: 16.3991, val_loss: 16.8245, val_MinusLogProbMetric: 16.8245

Epoch 552: val_loss did not improve from 16.81339
196/196 - 40s - loss: 16.3991 - MinusLogProbMetric: 16.3991 - val_loss: 16.8245 - val_MinusLogProbMetric: 16.8245 - lr: 6.2500e-05 - 40s/epoch - 206ms/step
Epoch 553/1000
2023-09-27 11:03:11.817 
Epoch 553/1000 
	 loss: 16.3953, MinusLogProbMetric: 16.3953, val_loss: 16.8177, val_MinusLogProbMetric: 16.8177

Epoch 553: val_loss did not improve from 16.81339
196/196 - 41s - loss: 16.3953 - MinusLogProbMetric: 16.3953 - val_loss: 16.8177 - val_MinusLogProbMetric: 16.8177 - lr: 6.2500e-05 - 41s/epoch - 208ms/step
Epoch 554/1000
2023-09-27 11:03:51.771 
Epoch 554/1000 
	 loss: 16.3974, MinusLogProbMetric: 16.3974, val_loss: 16.8214, val_MinusLogProbMetric: 16.8214

Epoch 554: val_loss did not improve from 16.81339
196/196 - 40s - loss: 16.3974 - MinusLogProbMetric: 16.3974 - val_loss: 16.8214 - val_MinusLogProbMetric: 16.8214 - lr: 6.2500e-05 - 40s/epoch - 204ms/step
Epoch 555/1000
2023-09-27 11:04:32.440 
Epoch 555/1000 
	 loss: 16.3971, MinusLogProbMetric: 16.3971, val_loss: 16.8187, val_MinusLogProbMetric: 16.8187

Epoch 555: val_loss did not improve from 16.81339
196/196 - 41s - loss: 16.3971 - MinusLogProbMetric: 16.3971 - val_loss: 16.8187 - val_MinusLogProbMetric: 16.8187 - lr: 6.2500e-05 - 41s/epoch - 207ms/step
Epoch 556/1000
2023-09-27 11:05:13.232 
Epoch 556/1000 
	 loss: 16.3959, MinusLogProbMetric: 16.3959, val_loss: 16.8270, val_MinusLogProbMetric: 16.8270

Epoch 556: val_loss did not improve from 16.81339
196/196 - 41s - loss: 16.3959 - MinusLogProbMetric: 16.3959 - val_loss: 16.8270 - val_MinusLogProbMetric: 16.8270 - lr: 6.2500e-05 - 41s/epoch - 208ms/step
Epoch 557/1000
2023-09-27 11:05:53.713 
Epoch 557/1000 
	 loss: 16.4010, MinusLogProbMetric: 16.4010, val_loss: 16.8213, val_MinusLogProbMetric: 16.8213

Epoch 557: val_loss did not improve from 16.81339
196/196 - 40s - loss: 16.4010 - MinusLogProbMetric: 16.4010 - val_loss: 16.8213 - val_MinusLogProbMetric: 16.8213 - lr: 6.2500e-05 - 40s/epoch - 207ms/step
Epoch 558/1000
2023-09-27 11:06:34.978 
Epoch 558/1000 
	 loss: 16.3956, MinusLogProbMetric: 16.3956, val_loss: 16.8159, val_MinusLogProbMetric: 16.8159

Epoch 558: val_loss did not improve from 16.81339
196/196 - 41s - loss: 16.3956 - MinusLogProbMetric: 16.3956 - val_loss: 16.8159 - val_MinusLogProbMetric: 16.8159 - lr: 6.2500e-05 - 41s/epoch - 211ms/step
Epoch 559/1000
2023-09-27 11:07:15.241 
Epoch 559/1000 
	 loss: 16.3948, MinusLogProbMetric: 16.3948, val_loss: 16.8169, val_MinusLogProbMetric: 16.8169

Epoch 559: val_loss did not improve from 16.81339
196/196 - 40s - loss: 16.3948 - MinusLogProbMetric: 16.3948 - val_loss: 16.8169 - val_MinusLogProbMetric: 16.8169 - lr: 6.2500e-05 - 40s/epoch - 205ms/step
Epoch 560/1000
2023-09-27 11:07:57.053 
Epoch 560/1000 
	 loss: 16.3946, MinusLogProbMetric: 16.3946, val_loss: 16.8303, val_MinusLogProbMetric: 16.8303

Epoch 560: val_loss did not improve from 16.81339
196/196 - 42s - loss: 16.3946 - MinusLogProbMetric: 16.3946 - val_loss: 16.8303 - val_MinusLogProbMetric: 16.8303 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 561/1000
2023-09-27 11:08:37.225 
Epoch 561/1000 
	 loss: 16.3990, MinusLogProbMetric: 16.3990, val_loss: 16.8244, val_MinusLogProbMetric: 16.8244

Epoch 561: val_loss did not improve from 16.81339
196/196 - 40s - loss: 16.3990 - MinusLogProbMetric: 16.3990 - val_loss: 16.8244 - val_MinusLogProbMetric: 16.8244 - lr: 6.2500e-05 - 40s/epoch - 205ms/step
Epoch 562/1000
2023-09-27 11:09:18.601 
Epoch 562/1000 
	 loss: 16.3972, MinusLogProbMetric: 16.3972, val_loss: 16.8236, val_MinusLogProbMetric: 16.8236

Epoch 562: val_loss did not improve from 16.81339
196/196 - 41s - loss: 16.3972 - MinusLogProbMetric: 16.3972 - val_loss: 16.8236 - val_MinusLogProbMetric: 16.8236 - lr: 6.2500e-05 - 41s/epoch - 211ms/step
Epoch 563/1000
2023-09-27 11:09:58.389 
Epoch 563/1000 
	 loss: 16.3960, MinusLogProbMetric: 16.3960, val_loss: 16.8219, val_MinusLogProbMetric: 16.8219

Epoch 563: val_loss did not improve from 16.81339
Restoring model weights from the end of the best epoch: 463.
196/196 - 40s - loss: 16.3960 - MinusLogProbMetric: 16.3960 - val_loss: 16.8219 - val_MinusLogProbMetric: 16.8219 - lr: 6.2500e-05 - 40s/epoch - 206ms/step
Epoch 563: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
LR metric calculation completed in 16.48250416398514 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 9.21671755897114 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
SWD metric calculation completed in 6.725544077984523 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
FN metric calculation completed in 7.620187089021783 seconds.
Training succeeded with seed 869.
Model trained in 22340.16 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 41.47 s.
                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/c_Main_CsplineN.py , Line : 469, Func.Name : prediction_function, Message : Plotters.cornerplotter(X_data_test.numpy(),X_data_nf.numpy(),path_to_results,ndims,norm=True) # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 41.73 s.
===========
Run 299/720 done in 22388.01 s.
===========

Directory ../../results/CsplineN_new/run_300/ already exists.
Skipping it.
===========
Run 300/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_301/ already exists.
Skipping it.
===========
Run 301/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_302/ already exists.
Skipping it.
===========
Run 302/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_303/ already exists.
Skipping it.
===========
Run 303/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_304/ already exists.
Skipping it.
===========
Run 304/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_305/ already exists.
Skipping it.
===========
Run 305/720 already exists. Skipping it.
===========

===========
Generating train data for run 306.
===========
Train data generated in 0.27 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_306/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 926}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_306/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[1.5383615 , 4.21851   , 9.147865  , ..., 7.328855  , 2.4535477 ,
        2.0265868 ],
       [1.2026695 , 3.5675488 , 8.490738  , ..., 7.486889  , 2.9732862 ,
        1.6526531 ],
       [5.7808385 , 5.6486273 , 0.85161066, ..., 0.44565296, 6.0336885 ,
        1.4597642 ],
       ...,
       [3.869998  , 5.7079043 , 0.7277752 , ..., 1.4709862 , 7.5385275 ,
        1.2852083 ],
       [2.111317  , 3.3553224 , 7.6223764 , ..., 7.4778986 , 3.6354768 ,
        1.7641349 ],
       [0.83836687, 3.4177158 , 7.4230075 , ..., 7.223582  , 3.3779047 ,
        2.0014815 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_306/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_306
self.data_kwargs: {'seed': 926}
self.x_data: [[1.4696891  3.165189   9.115545   ... 7.2440553  3.018408   2.0407877 ]
 [2.9008398  3.8232424  7.129506   ... 7.411926   2.8866556  1.4983263 ]
 [4.669435   5.457821   0.04349925 ... 0.866001   6.611358   1.4323243 ]
 ...
 [4.261785   5.5317554  0.77893746 ... 0.60558414 5.4824862  1.3011014 ]
 [4.4981847  5.716866   0.72522354 ... 0.9913055  5.7512865  1.5265256 ]
 [5.479814   7.150977   6.3064384  ... 3.1490364  2.6668518  8.143393  ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_39"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_40 (InputLayer)       [(None, 32)]              0         
                                                                 
 log_prob_layer_4 (LogProbLa  (None,)                  1152560   
 yer)                                                            
                                                                 
=================================================================
Total params: 1,152,560
Trainable params: 1,152,560
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_4/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_4'")
self.model: <keras.engine.functional.Functional object at 0x7fd38dbc8dc0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fd3a08f7460>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fd3a08f7460>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fd3a078f1c0>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fd38d92c940>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fd38d92ceb0>, <keras.callbacks.ModelCheckpoint object at 0x7fd38d92cf70>, <keras.callbacks.EarlyStopping object at 0x7fd38d92d1e0>, <keras.callbacks.ReduceLROnPlateau object at 0x7fd38d92d210>, <keras.callbacks.TerminateOnNaN object at 0x7fd38d92ce50>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[1.5383615 , 4.21851   , 9.147865  , ..., 7.328855  , 2.4535477 ,
        2.0265868 ],
       [1.2026695 , 3.5675488 , 8.490738  , ..., 7.486889  , 2.9732862 ,
        1.6526531 ],
       [5.7808385 , 5.6486273 , 0.85161066, ..., 0.44565296, 6.0336885 ,
        1.4597642 ],
       ...,
       [3.869998  , 5.7079043 , 0.7277752 , ..., 1.4709862 , 7.5385275 ,
        1.2852083 ],
       [2.111317  , 3.3553224 , 7.6223764 , ..., 7.4778986 , 3.6354768 ,
        1.7641349 ],
       [0.83836687, 3.4177158 , 7.4230075 , ..., 7.223582  , 3.3779047 ,
        2.0014815 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_306/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 306/720 with hyperparameters:
timestamp = 2023-09-27 11:10:45.501632
ndims = 32
seed_train = 926
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 5
spline_knots = 8
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 1152560
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 1.4696891   3.165189    9.115545    1.2257975   9.89761    -0.04518861
  9.761367    5.046433   10.037439    6.270509    6.6800056   0.37080207
  3.2512977   1.1872      2.5658634   0.9389908   3.4711475   5.1744766
  0.38911742  6.94769     5.6341734   2.616604    4.513363    1.4770697
  4.2721643   9.222334    2.548921    6.22901     1.4673232   7.2440553
  3.018408    2.0407877 ]
Epoch 1/1000
2023-09-27 11:12:26.975 
Epoch 1/1000 
	 loss: 53.0505, MinusLogProbMetric: 53.0505, val_loss: 26.3904, val_MinusLogProbMetric: 26.3904

Epoch 1: val_loss improved from inf to 26.39040, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 102s - loss: 53.0505 - MinusLogProbMetric: 53.0505 - val_loss: 26.3904 - val_MinusLogProbMetric: 26.3904 - lr: 0.0010 - 102s/epoch - 520ms/step
Epoch 2/1000
2023-09-27 11:13:02.549 
Epoch 2/1000 
	 loss: 24.4090, MinusLogProbMetric: 24.4090, val_loss: 23.6915, val_MinusLogProbMetric: 23.6915

Epoch 2: val_loss improved from 26.39040 to 23.69153, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 35s - loss: 24.4090 - MinusLogProbMetric: 24.4090 - val_loss: 23.6915 - val_MinusLogProbMetric: 23.6915 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 3/1000
2023-09-27 11:13:36.832 
Epoch 3/1000 
	 loss: 22.5300, MinusLogProbMetric: 22.5300, val_loss: 22.3331, val_MinusLogProbMetric: 22.3331

Epoch 3: val_loss improved from 23.69153 to 22.33307, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 34s - loss: 22.5300 - MinusLogProbMetric: 22.5300 - val_loss: 22.3331 - val_MinusLogProbMetric: 22.3331 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 4/1000
2023-09-27 11:14:12.359 
Epoch 4/1000 
	 loss: 21.7776, MinusLogProbMetric: 21.7776, val_loss: 22.9916, val_MinusLogProbMetric: 22.9916

Epoch 4: val_loss did not improve from 22.33307
196/196 - 35s - loss: 21.7776 - MinusLogProbMetric: 21.7776 - val_loss: 22.9916 - val_MinusLogProbMetric: 22.9916 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 5/1000
2023-09-27 11:14:45.761 
Epoch 5/1000 
	 loss: 21.0752, MinusLogProbMetric: 21.0752, val_loss: 20.7323, val_MinusLogProbMetric: 20.7323

Epoch 5: val_loss improved from 22.33307 to 20.73230, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 34s - loss: 21.0752 - MinusLogProbMetric: 21.0752 - val_loss: 20.7323 - val_MinusLogProbMetric: 20.7323 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 6/1000
2023-09-27 11:15:20.566 
Epoch 6/1000 
	 loss: 20.6478, MinusLogProbMetric: 20.6478, val_loss: 21.4688, val_MinusLogProbMetric: 21.4688

Epoch 6: val_loss did not improve from 20.73230
196/196 - 34s - loss: 20.6478 - MinusLogProbMetric: 20.6478 - val_loss: 21.4688 - val_MinusLogProbMetric: 21.4688 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 7/1000
2023-09-27 11:15:53.794 
Epoch 7/1000 
	 loss: 20.2902, MinusLogProbMetric: 20.2902, val_loss: 19.7637, val_MinusLogProbMetric: 19.7637

Epoch 7: val_loss improved from 20.73230 to 19.76370, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 34s - loss: 20.2902 - MinusLogProbMetric: 20.2902 - val_loss: 19.7637 - val_MinusLogProbMetric: 19.7637 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 8/1000
2023-09-27 11:16:29.201 
Epoch 8/1000 
	 loss: 19.9857, MinusLogProbMetric: 19.9857, val_loss: 19.4794, val_MinusLogProbMetric: 19.4794

Epoch 8: val_loss improved from 19.76370 to 19.47937, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 35s - loss: 19.9857 - MinusLogProbMetric: 19.9857 - val_loss: 19.4794 - val_MinusLogProbMetric: 19.4794 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 9/1000
2023-09-27 11:17:03.064 
Epoch 9/1000 
	 loss: 19.6091, MinusLogProbMetric: 19.6091, val_loss: 19.3216, val_MinusLogProbMetric: 19.3216

Epoch 9: val_loss improved from 19.47937 to 19.32156, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 34s - loss: 19.6091 - MinusLogProbMetric: 19.6091 - val_loss: 19.3216 - val_MinusLogProbMetric: 19.3216 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 10/1000
2023-09-27 11:17:37.287 
Epoch 10/1000 
	 loss: 19.2733, MinusLogProbMetric: 19.2733, val_loss: 19.5090, val_MinusLogProbMetric: 19.5090

Epoch 10: val_loss did not improve from 19.32156
196/196 - 34s - loss: 19.2733 - MinusLogProbMetric: 19.2733 - val_loss: 19.5090 - val_MinusLogProbMetric: 19.5090 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 11/1000
2023-09-27 11:18:11.496 
Epoch 11/1000 
	 loss: 19.1193, MinusLogProbMetric: 19.1193, val_loss: 19.4428, val_MinusLogProbMetric: 19.4428

Epoch 11: val_loss did not improve from 19.32156
196/196 - 34s - loss: 19.1193 - MinusLogProbMetric: 19.1193 - val_loss: 19.4428 - val_MinusLogProbMetric: 19.4428 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 12/1000
2023-09-27 11:18:45.560 
Epoch 12/1000 
	 loss: 18.9438, MinusLogProbMetric: 18.9438, val_loss: 18.6620, val_MinusLogProbMetric: 18.6620

Epoch 12: val_loss improved from 19.32156 to 18.66200, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 35s - loss: 18.9438 - MinusLogProbMetric: 18.9438 - val_loss: 18.6620 - val_MinusLogProbMetric: 18.6620 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 13/1000
2023-09-27 11:19:20.524 
Epoch 13/1000 
	 loss: 18.7891, MinusLogProbMetric: 18.7891, val_loss: 18.4962, val_MinusLogProbMetric: 18.4962

Epoch 13: val_loss improved from 18.66200 to 18.49623, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 35s - loss: 18.7891 - MinusLogProbMetric: 18.7891 - val_loss: 18.4962 - val_MinusLogProbMetric: 18.4962 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 14/1000
2023-09-27 11:19:54.191 
Epoch 14/1000 
	 loss: 19.0114, MinusLogProbMetric: 19.0114, val_loss: 18.7883, val_MinusLogProbMetric: 18.7883

Epoch 14: val_loss did not improve from 18.49623
196/196 - 33s - loss: 19.0114 - MinusLogProbMetric: 19.0114 - val_loss: 18.7883 - val_MinusLogProbMetric: 18.7883 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 15/1000
2023-09-27 11:20:28.906 
Epoch 15/1000 
	 loss: 18.7395, MinusLogProbMetric: 18.7395, val_loss: 18.6831, val_MinusLogProbMetric: 18.6831

Epoch 15: val_loss did not improve from 18.49623
196/196 - 35s - loss: 18.7395 - MinusLogProbMetric: 18.7395 - val_loss: 18.6831 - val_MinusLogProbMetric: 18.6831 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 16/1000
2023-09-27 11:21:01.827 
Epoch 16/1000 
	 loss: 18.5164, MinusLogProbMetric: 18.5164, val_loss: 18.2548, val_MinusLogProbMetric: 18.2548

Epoch 16: val_loss improved from 18.49623 to 18.25484, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 34s - loss: 18.5164 - MinusLogProbMetric: 18.5164 - val_loss: 18.2548 - val_MinusLogProbMetric: 18.2548 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 17/1000
2023-09-27 11:21:36.886 
Epoch 17/1000 
	 loss: 18.5135, MinusLogProbMetric: 18.5135, val_loss: 18.3462, val_MinusLogProbMetric: 18.3462

Epoch 17: val_loss did not improve from 18.25484
196/196 - 34s - loss: 18.5135 - MinusLogProbMetric: 18.5135 - val_loss: 18.3462 - val_MinusLogProbMetric: 18.3462 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 18/1000
2023-09-27 11:22:10.636 
Epoch 18/1000 
	 loss: 18.4292, MinusLogProbMetric: 18.4292, val_loss: 18.7297, val_MinusLogProbMetric: 18.7297

Epoch 18: val_loss did not improve from 18.25484
196/196 - 34s - loss: 18.4292 - MinusLogProbMetric: 18.4292 - val_loss: 18.7297 - val_MinusLogProbMetric: 18.7297 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 19/1000
2023-09-27 11:22:45.263 
Epoch 19/1000 
	 loss: 18.3940, MinusLogProbMetric: 18.3940, val_loss: 18.7859, val_MinusLogProbMetric: 18.7859

Epoch 19: val_loss did not improve from 18.25484
196/196 - 35s - loss: 18.3940 - MinusLogProbMetric: 18.3940 - val_loss: 18.7859 - val_MinusLogProbMetric: 18.7859 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 20/1000
2023-09-27 11:23:19.113 
Epoch 20/1000 
	 loss: 18.2096, MinusLogProbMetric: 18.2096, val_loss: 18.1359, val_MinusLogProbMetric: 18.1359

Epoch 20: val_loss improved from 18.25484 to 18.13594, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 35s - loss: 18.2096 - MinusLogProbMetric: 18.2096 - val_loss: 18.1359 - val_MinusLogProbMetric: 18.1359 - lr: 0.0010 - 35s/epoch - 176ms/step
Epoch 21/1000
2023-09-27 11:23:54.945 
Epoch 21/1000 
	 loss: 18.2069, MinusLogProbMetric: 18.2069, val_loss: 18.0887, val_MinusLogProbMetric: 18.0887

Epoch 21: val_loss improved from 18.13594 to 18.08867, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 36s - loss: 18.2069 - MinusLogProbMetric: 18.2069 - val_loss: 18.0887 - val_MinusLogProbMetric: 18.0887 - lr: 0.0010 - 36s/epoch - 182ms/step
Epoch 22/1000
2023-09-27 11:24:29.802 
Epoch 22/1000 
	 loss: 18.1633, MinusLogProbMetric: 18.1633, val_loss: 19.5811, val_MinusLogProbMetric: 19.5811

Epoch 22: val_loss did not improve from 18.08867
196/196 - 34s - loss: 18.1633 - MinusLogProbMetric: 18.1633 - val_loss: 19.5811 - val_MinusLogProbMetric: 19.5811 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 23/1000
2023-09-27 11:25:03.732 
Epoch 23/1000 
	 loss: 18.0835, MinusLogProbMetric: 18.0835, val_loss: 18.9070, val_MinusLogProbMetric: 18.9070

Epoch 23: val_loss did not improve from 18.08867
196/196 - 34s - loss: 18.0835 - MinusLogProbMetric: 18.0835 - val_loss: 18.9070 - val_MinusLogProbMetric: 18.9070 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 24/1000
2023-09-27 11:25:37.590 
Epoch 24/1000 
	 loss: 17.9755, MinusLogProbMetric: 17.9755, val_loss: 17.8883, val_MinusLogProbMetric: 17.8883

Epoch 24: val_loss improved from 18.08867 to 17.88828, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 34s - loss: 17.9755 - MinusLogProbMetric: 17.9755 - val_loss: 17.8883 - val_MinusLogProbMetric: 17.8883 - lr: 0.0010 - 34s/epoch - 176ms/step
Epoch 25/1000
2023-09-27 11:26:12.624 
Epoch 25/1000 
	 loss: 18.0738, MinusLogProbMetric: 18.0738, val_loss: 18.4917, val_MinusLogProbMetric: 18.4917

Epoch 25: val_loss did not improve from 17.88828
196/196 - 34s - loss: 18.0738 - MinusLogProbMetric: 18.0738 - val_loss: 18.4917 - val_MinusLogProbMetric: 18.4917 - lr: 0.0010 - 34s/epoch - 176ms/step
Epoch 26/1000
2023-09-27 11:26:46.711 
Epoch 26/1000 
	 loss: 17.9641, MinusLogProbMetric: 17.9641, val_loss: 18.8894, val_MinusLogProbMetric: 18.8894

Epoch 26: val_loss did not improve from 17.88828
196/196 - 34s - loss: 17.9641 - MinusLogProbMetric: 17.9641 - val_loss: 18.8894 - val_MinusLogProbMetric: 18.8894 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 27/1000
2023-09-27 11:27:21.499 
Epoch 27/1000 
	 loss: 17.9514, MinusLogProbMetric: 17.9514, val_loss: 19.1065, val_MinusLogProbMetric: 19.1065

Epoch 27: val_loss did not improve from 17.88828
196/196 - 35s - loss: 17.9514 - MinusLogProbMetric: 17.9514 - val_loss: 19.1065 - val_MinusLogProbMetric: 19.1065 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 28/1000
2023-09-27 11:27:56.255 
Epoch 28/1000 
	 loss: 17.8696, MinusLogProbMetric: 17.8696, val_loss: 17.9190, val_MinusLogProbMetric: 17.9190

Epoch 28: val_loss did not improve from 17.88828
196/196 - 35s - loss: 17.8696 - MinusLogProbMetric: 17.8696 - val_loss: 17.9190 - val_MinusLogProbMetric: 17.9190 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 29/1000
2023-09-27 11:28:30.061 
Epoch 29/1000 
	 loss: 17.7715, MinusLogProbMetric: 17.7715, val_loss: 17.7672, val_MinusLogProbMetric: 17.7672

Epoch 29: val_loss improved from 17.88828 to 17.76723, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 35s - loss: 17.7715 - MinusLogProbMetric: 17.7715 - val_loss: 17.7672 - val_MinusLogProbMetric: 17.7672 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 30/1000
2023-09-27 11:29:04.762 
Epoch 30/1000 
	 loss: 17.7968, MinusLogProbMetric: 17.7968, val_loss: 18.6942, val_MinusLogProbMetric: 18.6942

Epoch 30: val_loss did not improve from 17.76723
196/196 - 34s - loss: 17.7968 - MinusLogProbMetric: 17.7968 - val_loss: 18.6942 - val_MinusLogProbMetric: 18.6942 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 31/1000
2023-09-27 11:29:39.599 
Epoch 31/1000 
	 loss: 17.6910, MinusLogProbMetric: 17.6910, val_loss: 17.9141, val_MinusLogProbMetric: 17.9141

Epoch 31: val_loss did not improve from 17.76723
196/196 - 35s - loss: 17.6910 - MinusLogProbMetric: 17.6910 - val_loss: 17.9141 - val_MinusLogProbMetric: 17.9141 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 32/1000
2023-09-27 11:30:15.323 
Epoch 32/1000 
	 loss: 17.6638, MinusLogProbMetric: 17.6638, val_loss: 17.9703, val_MinusLogProbMetric: 17.9703

Epoch 32: val_loss did not improve from 17.76723
196/196 - 36s - loss: 17.6638 - MinusLogProbMetric: 17.6638 - val_loss: 17.9703 - val_MinusLogProbMetric: 17.9703 - lr: 0.0010 - 36s/epoch - 182ms/step
Epoch 33/1000
2023-09-27 11:30:51.603 
Epoch 33/1000 
	 loss: 17.7865, MinusLogProbMetric: 17.7865, val_loss: 17.7690, val_MinusLogProbMetric: 17.7690

Epoch 33: val_loss did not improve from 17.76723
196/196 - 36s - loss: 17.7865 - MinusLogProbMetric: 17.7865 - val_loss: 17.7690 - val_MinusLogProbMetric: 17.7690 - lr: 0.0010 - 36s/epoch - 185ms/step
Epoch 34/1000
2023-09-27 11:31:26.428 
Epoch 34/1000 
	 loss: 17.6051, MinusLogProbMetric: 17.6051, val_loss: 18.1903, val_MinusLogProbMetric: 18.1903

Epoch 34: val_loss did not improve from 17.76723
196/196 - 35s - loss: 17.6051 - MinusLogProbMetric: 17.6051 - val_loss: 18.1903 - val_MinusLogProbMetric: 18.1903 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 35/1000
2023-09-27 11:32:00.619 
Epoch 35/1000 
	 loss: 17.6821, MinusLogProbMetric: 17.6821, val_loss: 17.7670, val_MinusLogProbMetric: 17.7670

Epoch 35: val_loss improved from 17.76723 to 17.76704, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 35s - loss: 17.6821 - MinusLogProbMetric: 17.6821 - val_loss: 17.7670 - val_MinusLogProbMetric: 17.7670 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 36/1000
2023-09-27 11:32:35.356 
Epoch 36/1000 
	 loss: 17.5909, MinusLogProbMetric: 17.5909, val_loss: 17.6073, val_MinusLogProbMetric: 17.6073

Epoch 36: val_loss improved from 17.76704 to 17.60734, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 35s - loss: 17.5909 - MinusLogProbMetric: 17.5909 - val_loss: 17.6073 - val_MinusLogProbMetric: 17.6073 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 37/1000
2023-09-27 11:33:10.154 
Epoch 37/1000 
	 loss: 17.5185, MinusLogProbMetric: 17.5185, val_loss: 17.9820, val_MinusLogProbMetric: 17.9820

Epoch 37: val_loss did not improve from 17.60734
196/196 - 34s - loss: 17.5185 - MinusLogProbMetric: 17.5185 - val_loss: 17.9820 - val_MinusLogProbMetric: 17.9820 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 38/1000
2023-09-27 11:33:43.987 
Epoch 38/1000 
	 loss: 17.4914, MinusLogProbMetric: 17.4914, val_loss: 18.5594, val_MinusLogProbMetric: 18.5594

Epoch 38: val_loss did not improve from 17.60734
196/196 - 34s - loss: 17.4914 - MinusLogProbMetric: 17.4914 - val_loss: 18.5594 - val_MinusLogProbMetric: 18.5594 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 39/1000
2023-09-27 11:34:17.761 
Epoch 39/1000 
	 loss: 17.4984, MinusLogProbMetric: 17.4984, val_loss: 17.6161, val_MinusLogProbMetric: 17.6161

Epoch 39: val_loss did not improve from 17.60734
196/196 - 34s - loss: 17.4984 - MinusLogProbMetric: 17.4984 - val_loss: 17.6161 - val_MinusLogProbMetric: 17.6161 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 40/1000
2023-09-27 11:34:51.107 
Epoch 40/1000 
	 loss: 17.5427, MinusLogProbMetric: 17.5427, val_loss: 17.8135, val_MinusLogProbMetric: 17.8135

Epoch 40: val_loss did not improve from 17.60734
196/196 - 33s - loss: 17.5427 - MinusLogProbMetric: 17.5427 - val_loss: 17.8135 - val_MinusLogProbMetric: 17.8135 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 41/1000
2023-09-27 11:35:25.398 
Epoch 41/1000 
	 loss: 17.4323, MinusLogProbMetric: 17.4323, val_loss: 17.6672, val_MinusLogProbMetric: 17.6672

Epoch 41: val_loss did not improve from 17.60734
196/196 - 34s - loss: 17.4323 - MinusLogProbMetric: 17.4323 - val_loss: 17.6672 - val_MinusLogProbMetric: 17.6672 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 42/1000
2023-09-27 11:35:58.775 
Epoch 42/1000 
	 loss: 17.3942, MinusLogProbMetric: 17.3942, val_loss: 18.3510, val_MinusLogProbMetric: 18.3510

Epoch 42: val_loss did not improve from 17.60734
196/196 - 33s - loss: 17.3942 - MinusLogProbMetric: 17.3942 - val_loss: 18.3510 - val_MinusLogProbMetric: 18.3510 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 43/1000
2023-09-27 11:36:32.338 
Epoch 43/1000 
	 loss: 17.3448, MinusLogProbMetric: 17.3448, val_loss: 17.7942, val_MinusLogProbMetric: 17.7942

Epoch 43: val_loss did not improve from 17.60734
196/196 - 34s - loss: 17.3448 - MinusLogProbMetric: 17.3448 - val_loss: 17.7942 - val_MinusLogProbMetric: 17.7942 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 44/1000
2023-09-27 11:37:06.100 
Epoch 44/1000 
	 loss: 17.3588, MinusLogProbMetric: 17.3588, val_loss: 17.6447, val_MinusLogProbMetric: 17.6447

Epoch 44: val_loss did not improve from 17.60734
196/196 - 34s - loss: 17.3588 - MinusLogProbMetric: 17.3588 - val_loss: 17.6447 - val_MinusLogProbMetric: 17.6447 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 45/1000
2023-09-27 11:37:40.300 
Epoch 45/1000 
	 loss: 17.3123, MinusLogProbMetric: 17.3123, val_loss: 17.6948, val_MinusLogProbMetric: 17.6948

Epoch 45: val_loss did not improve from 17.60734
196/196 - 34s - loss: 17.3123 - MinusLogProbMetric: 17.3123 - val_loss: 17.6948 - val_MinusLogProbMetric: 17.6948 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 46/1000
2023-09-27 11:38:14.059 
Epoch 46/1000 
	 loss: 17.3014, MinusLogProbMetric: 17.3014, val_loss: 18.4709, val_MinusLogProbMetric: 18.4709

Epoch 46: val_loss did not improve from 17.60734
196/196 - 34s - loss: 17.3014 - MinusLogProbMetric: 17.3014 - val_loss: 18.4709 - val_MinusLogProbMetric: 18.4709 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 47/1000
2023-09-27 11:38:48.421 
Epoch 47/1000 
	 loss: 17.2869, MinusLogProbMetric: 17.2869, val_loss: 17.6287, val_MinusLogProbMetric: 17.6287

Epoch 47: val_loss did not improve from 17.60734
196/196 - 34s - loss: 17.2869 - MinusLogProbMetric: 17.2869 - val_loss: 17.6287 - val_MinusLogProbMetric: 17.6287 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 48/1000
2023-09-27 11:39:23.063 
Epoch 48/1000 
	 loss: 17.2867, MinusLogProbMetric: 17.2867, val_loss: 17.3847, val_MinusLogProbMetric: 17.3847

Epoch 48: val_loss improved from 17.60734 to 17.38470, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 35s - loss: 17.2867 - MinusLogProbMetric: 17.2867 - val_loss: 17.3847 - val_MinusLogProbMetric: 17.3847 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 49/1000
2023-09-27 11:39:58.066 
Epoch 49/1000 
	 loss: 17.2646, MinusLogProbMetric: 17.2646, val_loss: 17.8124, val_MinusLogProbMetric: 17.8124

Epoch 49: val_loss did not improve from 17.38470
196/196 - 34s - loss: 17.2646 - MinusLogProbMetric: 17.2646 - val_loss: 17.8124 - val_MinusLogProbMetric: 17.8124 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 50/1000
2023-09-27 11:40:31.827 
Epoch 50/1000 
	 loss: 17.2563, MinusLogProbMetric: 17.2563, val_loss: 17.8279, val_MinusLogProbMetric: 17.8279

Epoch 50: val_loss did not improve from 17.38470
196/196 - 34s - loss: 17.2563 - MinusLogProbMetric: 17.2563 - val_loss: 17.8279 - val_MinusLogProbMetric: 17.8279 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 51/1000
2023-09-27 11:41:05.322 
Epoch 51/1000 
	 loss: 17.2546, MinusLogProbMetric: 17.2546, val_loss: 17.6379, val_MinusLogProbMetric: 17.6379

Epoch 51: val_loss did not improve from 17.38470
196/196 - 33s - loss: 17.2546 - MinusLogProbMetric: 17.2546 - val_loss: 17.6379 - val_MinusLogProbMetric: 17.6379 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 52/1000
2023-09-27 11:41:38.561 
Epoch 52/1000 
	 loss: 17.2581, MinusLogProbMetric: 17.2581, val_loss: 17.3523, val_MinusLogProbMetric: 17.3523

Epoch 52: val_loss improved from 17.38470 to 17.35230, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 34s - loss: 17.2581 - MinusLogProbMetric: 17.2581 - val_loss: 17.3523 - val_MinusLogProbMetric: 17.3523 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 53/1000
2023-09-27 11:42:12.663 
Epoch 53/1000 
	 loss: 17.2068, MinusLogProbMetric: 17.2068, val_loss: 17.6198, val_MinusLogProbMetric: 17.6198

Epoch 53: val_loss did not improve from 17.35230
196/196 - 34s - loss: 17.2068 - MinusLogProbMetric: 17.2068 - val_loss: 17.6198 - val_MinusLogProbMetric: 17.6198 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 54/1000
2023-09-27 11:42:46.699 
Epoch 54/1000 
	 loss: 17.1797, MinusLogProbMetric: 17.1797, val_loss: 17.8239, val_MinusLogProbMetric: 17.8239

Epoch 54: val_loss did not improve from 17.35230
196/196 - 34s - loss: 17.1797 - MinusLogProbMetric: 17.1797 - val_loss: 17.8239 - val_MinusLogProbMetric: 17.8239 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 55/1000
2023-09-27 11:43:20.414 
Epoch 55/1000 
	 loss: 17.1412, MinusLogProbMetric: 17.1412, val_loss: 18.0337, val_MinusLogProbMetric: 18.0337

Epoch 55: val_loss did not improve from 17.35230
196/196 - 34s - loss: 17.1412 - MinusLogProbMetric: 17.1412 - val_loss: 18.0337 - val_MinusLogProbMetric: 18.0337 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 56/1000
2023-09-27 11:43:54.153 
Epoch 56/1000 
	 loss: 17.1100, MinusLogProbMetric: 17.1100, val_loss: 17.6762, val_MinusLogProbMetric: 17.6762

Epoch 56: val_loss did not improve from 17.35230
196/196 - 34s - loss: 17.1100 - MinusLogProbMetric: 17.1100 - val_loss: 17.6762 - val_MinusLogProbMetric: 17.6762 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 57/1000
2023-09-27 11:44:28.015 
Epoch 57/1000 
	 loss: 17.1424, MinusLogProbMetric: 17.1424, val_loss: 17.5267, val_MinusLogProbMetric: 17.5267

Epoch 57: val_loss did not improve from 17.35230
196/196 - 34s - loss: 17.1424 - MinusLogProbMetric: 17.1424 - val_loss: 17.5267 - val_MinusLogProbMetric: 17.5267 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 58/1000
2023-09-27 11:45:01.936 
Epoch 58/1000 
	 loss: 17.1203, MinusLogProbMetric: 17.1203, val_loss: 17.4729, val_MinusLogProbMetric: 17.4729

Epoch 58: val_loss did not improve from 17.35230
196/196 - 34s - loss: 17.1203 - MinusLogProbMetric: 17.1203 - val_loss: 17.4729 - val_MinusLogProbMetric: 17.4729 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 59/1000
2023-09-27 11:45:35.933 
Epoch 59/1000 
	 loss: 17.0938, MinusLogProbMetric: 17.0938, val_loss: 17.7796, val_MinusLogProbMetric: 17.7796

Epoch 59: val_loss did not improve from 17.35230
196/196 - 34s - loss: 17.0938 - MinusLogProbMetric: 17.0938 - val_loss: 17.7796 - val_MinusLogProbMetric: 17.7796 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 60/1000
2023-09-27 11:46:10.364 
Epoch 60/1000 
	 loss: 17.1278, MinusLogProbMetric: 17.1278, val_loss: 17.7786, val_MinusLogProbMetric: 17.7786

Epoch 60: val_loss did not improve from 17.35230
196/196 - 34s - loss: 17.1278 - MinusLogProbMetric: 17.1278 - val_loss: 17.7786 - val_MinusLogProbMetric: 17.7786 - lr: 0.0010 - 34s/epoch - 176ms/step
Epoch 61/1000
2023-09-27 11:46:44.925 
Epoch 61/1000 
	 loss: 17.0302, MinusLogProbMetric: 17.0302, val_loss: 17.4522, val_MinusLogProbMetric: 17.4522

Epoch 61: val_loss did not improve from 17.35230
196/196 - 35s - loss: 17.0302 - MinusLogProbMetric: 17.0302 - val_loss: 17.4522 - val_MinusLogProbMetric: 17.4522 - lr: 0.0010 - 35s/epoch - 176ms/step
Epoch 62/1000
2023-09-27 11:47:19.504 
Epoch 62/1000 
	 loss: 17.0545, MinusLogProbMetric: 17.0545, val_loss: 17.5842, val_MinusLogProbMetric: 17.5842

Epoch 62: val_loss did not improve from 17.35230
196/196 - 35s - loss: 17.0545 - MinusLogProbMetric: 17.0545 - val_loss: 17.5842 - val_MinusLogProbMetric: 17.5842 - lr: 0.0010 - 35s/epoch - 176ms/step
Epoch 63/1000
2023-09-27 11:47:54.327 
Epoch 63/1000 
	 loss: 17.0275, MinusLogProbMetric: 17.0275, val_loss: 17.8817, val_MinusLogProbMetric: 17.8817

Epoch 63: val_loss did not improve from 17.35230
196/196 - 35s - loss: 17.0275 - MinusLogProbMetric: 17.0275 - val_loss: 17.8817 - val_MinusLogProbMetric: 17.8817 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 64/1000
2023-09-27 11:48:27.975 
Epoch 64/1000 
	 loss: 17.0505, MinusLogProbMetric: 17.0505, val_loss: 17.3005, val_MinusLogProbMetric: 17.3005

Epoch 64: val_loss improved from 17.35230 to 17.30046, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 34s - loss: 17.0505 - MinusLogProbMetric: 17.0505 - val_loss: 17.3005 - val_MinusLogProbMetric: 17.3005 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 65/1000
2023-09-27 11:49:03.564 
Epoch 65/1000 
	 loss: 17.0463, MinusLogProbMetric: 17.0463, val_loss: 17.4369, val_MinusLogProbMetric: 17.4369

Epoch 65: val_loss did not improve from 17.30046
196/196 - 35s - loss: 17.0463 - MinusLogProbMetric: 17.0463 - val_loss: 17.4369 - val_MinusLogProbMetric: 17.4369 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 66/1000
2023-09-27 11:49:38.012 
Epoch 66/1000 
	 loss: 17.0115, MinusLogProbMetric: 17.0115, val_loss: 17.5953, val_MinusLogProbMetric: 17.5953

Epoch 66: val_loss did not improve from 17.30046
196/196 - 34s - loss: 17.0115 - MinusLogProbMetric: 17.0115 - val_loss: 17.5953 - val_MinusLogProbMetric: 17.5953 - lr: 0.0010 - 34s/epoch - 176ms/step
Epoch 67/1000
2023-09-27 11:50:11.721 
Epoch 67/1000 
	 loss: 17.0313, MinusLogProbMetric: 17.0313, val_loss: 17.6755, val_MinusLogProbMetric: 17.6755

Epoch 67: val_loss did not improve from 17.30046
196/196 - 34s - loss: 17.0313 - MinusLogProbMetric: 17.0313 - val_loss: 17.6755 - val_MinusLogProbMetric: 17.6755 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 68/1000
2023-09-27 11:50:45.742 
Epoch 68/1000 
	 loss: 16.9984, MinusLogProbMetric: 16.9984, val_loss: 17.6290, val_MinusLogProbMetric: 17.6290

Epoch 68: val_loss did not improve from 17.30046
196/196 - 34s - loss: 16.9984 - MinusLogProbMetric: 16.9984 - val_loss: 17.6290 - val_MinusLogProbMetric: 17.6290 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 69/1000
2023-09-27 11:51:19.466 
Epoch 69/1000 
	 loss: 16.9585, MinusLogProbMetric: 16.9585, val_loss: 17.7013, val_MinusLogProbMetric: 17.7013

Epoch 69: val_loss did not improve from 17.30046
196/196 - 34s - loss: 16.9585 - MinusLogProbMetric: 16.9585 - val_loss: 17.7013 - val_MinusLogProbMetric: 17.7013 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 70/1000
2023-09-27 11:51:53.749 
Epoch 70/1000 
	 loss: 16.9911, MinusLogProbMetric: 16.9911, val_loss: 17.2804, val_MinusLogProbMetric: 17.2804

Epoch 70: val_loss improved from 17.30046 to 17.28036, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 35s - loss: 16.9911 - MinusLogProbMetric: 16.9911 - val_loss: 17.2804 - val_MinusLogProbMetric: 17.2804 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 71/1000
2023-09-27 11:52:29.180 
Epoch 71/1000 
	 loss: 16.9569, MinusLogProbMetric: 16.9569, val_loss: 17.6347, val_MinusLogProbMetric: 17.6347

Epoch 71: val_loss did not improve from 17.28036
196/196 - 35s - loss: 16.9569 - MinusLogProbMetric: 16.9569 - val_loss: 17.6347 - val_MinusLogProbMetric: 17.6347 - lr: 0.0010 - 35s/epoch - 176ms/step
Epoch 72/1000
2023-09-27 11:53:03.446 
Epoch 72/1000 
	 loss: 16.9423, MinusLogProbMetric: 16.9423, val_loss: 17.2329, val_MinusLogProbMetric: 17.2329

Epoch 72: val_loss improved from 17.28036 to 17.23288, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_306/weights/best_weights.h5
196/196 - 35s - loss: 16.9423 - MinusLogProbMetric: 16.9423 - val_loss: 17.2329 - val_MinusLogProbMetric: 17.2329 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 73/1000
2023-09-27 11:53:38.364 
Epoch 73/1000 
	 loss: 16.9111, MinusLogProbMetric: 16.9111, val_loss: 17.6631, val_MinusLogProbMetric: 17.6631

Epoch 73: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.9111 - MinusLogProbMetric: 16.9111 - val_loss: 17.6631 - val_MinusLogProbMetric: 17.6631 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 74/1000
2023-09-27 11:54:11.671 
Epoch 74/1000 
	 loss: 16.8935, MinusLogProbMetric: 16.8935, val_loss: 17.3481, val_MinusLogProbMetric: 17.3481

Epoch 74: val_loss did not improve from 17.23288
196/196 - 33s - loss: 16.8935 - MinusLogProbMetric: 16.8935 - val_loss: 17.3481 - val_MinusLogProbMetric: 17.3481 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 75/1000
2023-09-27 11:54:46.285 
Epoch 75/1000 
	 loss: 16.8966, MinusLogProbMetric: 16.8966, val_loss: 17.5366, val_MinusLogProbMetric: 17.5366

Epoch 75: val_loss did not improve from 17.23288
196/196 - 35s - loss: 16.8966 - MinusLogProbMetric: 16.8966 - val_loss: 17.5366 - val_MinusLogProbMetric: 17.5366 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 76/1000
2023-09-27 11:55:20.056 
Epoch 76/1000 
	 loss: 16.8655, MinusLogProbMetric: 16.8655, val_loss: 17.8522, val_MinusLogProbMetric: 17.8522

Epoch 76: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.8655 - MinusLogProbMetric: 16.8655 - val_loss: 17.8522 - val_MinusLogProbMetric: 17.8522 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 77/1000
2023-09-27 11:55:54.733 
Epoch 77/1000 
	 loss: 16.8892, MinusLogProbMetric: 16.8892, val_loss: 17.2700, val_MinusLogProbMetric: 17.2700

Epoch 77: val_loss did not improve from 17.23288
196/196 - 35s - loss: 16.8892 - MinusLogProbMetric: 16.8892 - val_loss: 17.2700 - val_MinusLogProbMetric: 17.2700 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 78/1000
2023-09-27 11:56:29.194 
Epoch 78/1000 
	 loss: 16.8504, MinusLogProbMetric: 16.8504, val_loss: 17.5565, val_MinusLogProbMetric: 17.5565

Epoch 78: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.8504 - MinusLogProbMetric: 16.8504 - val_loss: 17.5565 - val_MinusLogProbMetric: 17.5565 - lr: 0.0010 - 34s/epoch - 176ms/step
Epoch 79/1000
2023-09-27 11:57:03.481 
Epoch 79/1000 
	 loss: 16.8576, MinusLogProbMetric: 16.8576, val_loss: 17.5777, val_MinusLogProbMetric: 17.5777

Epoch 79: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.8576 - MinusLogProbMetric: 16.8576 - val_loss: 17.5777 - val_MinusLogProbMetric: 17.5777 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 80/1000
2023-09-27 11:57:38.366 
Epoch 80/1000 
	 loss: 16.8236, MinusLogProbMetric: 16.8236, val_loss: 17.3971, val_MinusLogProbMetric: 17.3971

Epoch 80: val_loss did not improve from 17.23288
196/196 - 35s - loss: 16.8236 - MinusLogProbMetric: 16.8236 - val_loss: 17.3971 - val_MinusLogProbMetric: 17.3971 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 81/1000
2023-09-27 11:58:12.179 
Epoch 81/1000 
	 loss: 16.8325, MinusLogProbMetric: 16.8325, val_loss: 17.4023, val_MinusLogProbMetric: 17.4023

Epoch 81: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.8325 - MinusLogProbMetric: 16.8325 - val_loss: 17.4023 - val_MinusLogProbMetric: 17.4023 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 82/1000
2023-09-27 11:58:47.113 
Epoch 82/1000 
	 loss: 16.8380, MinusLogProbMetric: 16.8380, val_loss: 17.5536, val_MinusLogProbMetric: 17.5536

Epoch 82: val_loss did not improve from 17.23288
196/196 - 35s - loss: 16.8380 - MinusLogProbMetric: 16.8380 - val_loss: 17.5536 - val_MinusLogProbMetric: 17.5536 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 83/1000
2023-09-27 11:59:20.473 
Epoch 83/1000 
	 loss: 16.7772, MinusLogProbMetric: 16.7772, val_loss: 17.7748, val_MinusLogProbMetric: 17.7748

Epoch 83: val_loss did not improve from 17.23288
196/196 - 33s - loss: 16.7772 - MinusLogProbMetric: 16.7772 - val_loss: 17.7748 - val_MinusLogProbMetric: 17.7748 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 84/1000
2023-09-27 11:59:54.410 
Epoch 84/1000 
	 loss: 16.8114, MinusLogProbMetric: 16.8114, val_loss: 17.4228, val_MinusLogProbMetric: 17.4228

Epoch 84: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.8114 - MinusLogProbMetric: 16.8114 - val_loss: 17.4228 - val_MinusLogProbMetric: 17.4228 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 85/1000
2023-09-27 12:00:28.355 
Epoch 85/1000 
	 loss: 16.7616, MinusLogProbMetric: 16.7616, val_loss: 17.2812, val_MinusLogProbMetric: 17.2812

Epoch 85: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.7616 - MinusLogProbMetric: 16.7616 - val_loss: 17.2812 - val_MinusLogProbMetric: 17.2812 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 86/1000
2023-09-27 12:01:02.658 
Epoch 86/1000 
	 loss: 16.7864, MinusLogProbMetric: 16.7864, val_loss: 17.3024, val_MinusLogProbMetric: 17.3024

Epoch 86: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.7864 - MinusLogProbMetric: 16.7864 - val_loss: 17.3024 - val_MinusLogProbMetric: 17.3024 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 87/1000
2023-09-27 12:01:36.777 
Epoch 87/1000 
	 loss: 16.8000, MinusLogProbMetric: 16.8000, val_loss: 17.4150, val_MinusLogProbMetric: 17.4150

Epoch 87: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.8000 - MinusLogProbMetric: 16.8000 - val_loss: 17.4150 - val_MinusLogProbMetric: 17.4150 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 88/1000
2023-09-27 12:02:10.683 
Epoch 88/1000 
	 loss: 16.7678, MinusLogProbMetric: 16.7678, val_loss: 17.2845, val_MinusLogProbMetric: 17.2845

Epoch 88: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.7678 - MinusLogProbMetric: 16.7678 - val_loss: 17.2845 - val_MinusLogProbMetric: 17.2845 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 89/1000
2023-09-27 12:02:43.768 
Epoch 89/1000 
	 loss: 16.7049, MinusLogProbMetric: 16.7049, val_loss: 17.5398, val_MinusLogProbMetric: 17.5398

Epoch 89: val_loss did not improve from 17.23288
196/196 - 33s - loss: 16.7049 - MinusLogProbMetric: 16.7049 - val_loss: 17.5398 - val_MinusLogProbMetric: 17.5398 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 90/1000
2023-09-27 12:03:17.547 
Epoch 90/1000 
	 loss: 16.7536, MinusLogProbMetric: 16.7536, val_loss: 17.4259, val_MinusLogProbMetric: 17.4259

Epoch 90: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.7536 - MinusLogProbMetric: 16.7536 - val_loss: 17.4259 - val_MinusLogProbMetric: 17.4259 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 91/1000
2023-09-27 12:03:50.657 
Epoch 91/1000 
	 loss: 16.7716, MinusLogProbMetric: 16.7716, val_loss: 17.2931, val_MinusLogProbMetric: 17.2931

Epoch 91: val_loss did not improve from 17.23288
196/196 - 33s - loss: 16.7716 - MinusLogProbMetric: 16.7716 - val_loss: 17.2931 - val_MinusLogProbMetric: 17.2931 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 92/1000
2023-09-27 12:04:24.482 
Epoch 92/1000 
	 loss: 16.7088, MinusLogProbMetric: 16.7088, val_loss: 17.5677, val_MinusLogProbMetric: 17.5677

Epoch 92: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.7088 - MinusLogProbMetric: 16.7088 - val_loss: 17.5677 - val_MinusLogProbMetric: 17.5677 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 93/1000
2023-09-27 12:04:58.958 
Epoch 93/1000 
	 loss: 16.7138, MinusLogProbMetric: 16.7138, val_loss: 17.5004, val_MinusLogProbMetric: 17.5004

Epoch 93: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.7138 - MinusLogProbMetric: 16.7138 - val_loss: 17.5004 - val_MinusLogProbMetric: 17.5004 - lr: 0.0010 - 34s/epoch - 176ms/step
Epoch 94/1000
2023-09-27 12:05:33.687 
Epoch 94/1000 
	 loss: 16.7166, MinusLogProbMetric: 16.7166, val_loss: 17.5427, val_MinusLogProbMetric: 17.5427

Epoch 94: val_loss did not improve from 17.23288
196/196 - 35s - loss: 16.7166 - MinusLogProbMetric: 16.7166 - val_loss: 17.5427 - val_MinusLogProbMetric: 17.5427 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 95/1000
2023-09-27 12:06:07.839 
Epoch 95/1000 
	 loss: 16.6636, MinusLogProbMetric: 16.6636, val_loss: 17.4979, val_MinusLogProbMetric: 17.4979

Epoch 95: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.6636 - MinusLogProbMetric: 16.6636 - val_loss: 17.4979 - val_MinusLogProbMetric: 17.4979 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 96/1000
2023-09-27 12:06:41.639 
Epoch 96/1000 
	 loss: 16.6605, MinusLogProbMetric: 16.6605, val_loss: 17.3360, val_MinusLogProbMetric: 17.3360

Epoch 96: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.6605 - MinusLogProbMetric: 16.6605 - val_loss: 17.3360 - val_MinusLogProbMetric: 17.3360 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 97/1000
2023-09-27 12:07:15.156 
Epoch 97/1000 
	 loss: 16.6973, MinusLogProbMetric: 16.6973, val_loss: 17.3288, val_MinusLogProbMetric: 17.3288

Epoch 97: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.6973 - MinusLogProbMetric: 16.6973 - val_loss: 17.3288 - val_MinusLogProbMetric: 17.3288 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 98/1000
2023-09-27 12:07:49.504 
Epoch 98/1000 
	 loss: 16.7130, MinusLogProbMetric: 16.7130, val_loss: 17.3742, val_MinusLogProbMetric: 17.3742

Epoch 98: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.7130 - MinusLogProbMetric: 16.7130 - val_loss: 17.3742 - val_MinusLogProbMetric: 17.3742 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 99/1000
2023-09-27 12:08:23.421 
Epoch 99/1000 
	 loss: 16.6155, MinusLogProbMetric: 16.6155, val_loss: 17.7432, val_MinusLogProbMetric: 17.7432

Epoch 99: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.6155 - MinusLogProbMetric: 16.6155 - val_loss: 17.7432 - val_MinusLogProbMetric: 17.7432 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 100/1000
2023-09-27 12:08:58.060 
Epoch 100/1000 
	 loss: 16.6645, MinusLogProbMetric: 16.6645, val_loss: 17.8125, val_MinusLogProbMetric: 17.8125

Epoch 100: val_loss did not improve from 17.23288
196/196 - 35s - loss: 16.6645 - MinusLogProbMetric: 16.6645 - val_loss: 17.8125 - val_MinusLogProbMetric: 17.8125 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 101/1000
2023-09-27 12:09:32.055 
Epoch 101/1000 
	 loss: 16.6275, MinusLogProbMetric: 16.6275, val_loss: 17.9266, val_MinusLogProbMetric: 17.9266

Epoch 101: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.6275 - MinusLogProbMetric: 16.6275 - val_loss: 17.9266 - val_MinusLogProbMetric: 17.9266 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 102/1000
2023-09-27 12:10:05.837 
Epoch 102/1000 
	 loss: 16.6253, MinusLogProbMetric: 16.6253, val_loss: 17.4969, val_MinusLogProbMetric: 17.4969

Epoch 102: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.6253 - MinusLogProbMetric: 16.6253 - val_loss: 17.4969 - val_MinusLogProbMetric: 17.4969 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 103/1000
2023-09-27 12:10:39.459 
Epoch 103/1000 
	 loss: 16.6608, MinusLogProbMetric: 16.6608, val_loss: 17.3104, val_MinusLogProbMetric: 17.3104

Epoch 103: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.6608 - MinusLogProbMetric: 16.6608 - val_loss: 17.3104 - val_MinusLogProbMetric: 17.3104 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 104/1000
2023-09-27 12:11:13.957 
Epoch 104/1000 
	 loss: 16.6094, MinusLogProbMetric: 16.6094, val_loss: 18.1319, val_MinusLogProbMetric: 18.1319

Epoch 104: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.6094 - MinusLogProbMetric: 16.6094 - val_loss: 18.1319 - val_MinusLogProbMetric: 18.1319 - lr: 0.0010 - 34s/epoch - 176ms/step
Epoch 105/1000
2023-09-27 12:11:47.998 
Epoch 105/1000 
	 loss: 16.5903, MinusLogProbMetric: 16.5903, val_loss: 17.6482, val_MinusLogProbMetric: 17.6482

Epoch 105: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.5903 - MinusLogProbMetric: 16.5903 - val_loss: 17.6482 - val_MinusLogProbMetric: 17.6482 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 106/1000
2023-09-27 12:12:20.995 
Epoch 106/1000 
	 loss: 16.5998, MinusLogProbMetric: 16.5998, val_loss: 17.4962, val_MinusLogProbMetric: 17.4962

Epoch 106: val_loss did not improve from 17.23288
196/196 - 33s - loss: 16.5998 - MinusLogProbMetric: 16.5998 - val_loss: 17.4962 - val_MinusLogProbMetric: 17.4962 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 107/1000
2023-09-27 12:12:54.886 
Epoch 107/1000 
	 loss: 16.5381, MinusLogProbMetric: 16.5381, val_loss: 17.4141, val_MinusLogProbMetric: 17.4141

Epoch 107: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.5381 - MinusLogProbMetric: 16.5381 - val_loss: 17.4141 - val_MinusLogProbMetric: 17.4141 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 108/1000
2023-09-27 12:13:28.756 
Epoch 108/1000 
	 loss: 16.5391, MinusLogProbMetric: 16.5391, val_loss: 17.5677, val_MinusLogProbMetric: 17.5677

Epoch 108: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.5391 - MinusLogProbMetric: 16.5391 - val_loss: 17.5677 - val_MinusLogProbMetric: 17.5677 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 109/1000
2023-09-27 12:14:02.607 
Epoch 109/1000 
	 loss: 16.5501, MinusLogProbMetric: 16.5501, val_loss: 17.3751, val_MinusLogProbMetric: 17.3751

Epoch 109: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.5501 - MinusLogProbMetric: 16.5501 - val_loss: 17.3751 - val_MinusLogProbMetric: 17.3751 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 110/1000
2023-09-27 12:14:36.121 
Epoch 110/1000 
	 loss: 16.5895, MinusLogProbMetric: 16.5895, val_loss: 17.4503, val_MinusLogProbMetric: 17.4503

Epoch 110: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.5895 - MinusLogProbMetric: 16.5895 - val_loss: 17.4503 - val_MinusLogProbMetric: 17.4503 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 111/1000
2023-09-27 12:15:09.371 
Epoch 111/1000 
	 loss: 16.5525, MinusLogProbMetric: 16.5525, val_loss: 17.3845, val_MinusLogProbMetric: 17.3845

Epoch 111: val_loss did not improve from 17.23288
196/196 - 33s - loss: 16.5525 - MinusLogProbMetric: 16.5525 - val_loss: 17.3845 - val_MinusLogProbMetric: 17.3845 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 112/1000
2023-09-27 12:15:43.863 
Epoch 112/1000 
	 loss: 16.4918, MinusLogProbMetric: 16.4918, val_loss: 17.4009, val_MinusLogProbMetric: 17.4009

Epoch 112: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.4918 - MinusLogProbMetric: 16.4918 - val_loss: 17.4009 - val_MinusLogProbMetric: 17.4009 - lr: 0.0010 - 34s/epoch - 176ms/step
Epoch 113/1000
2023-09-27 12:16:17.094 
Epoch 113/1000 
	 loss: 16.5398, MinusLogProbMetric: 16.5398, val_loss: 17.5435, val_MinusLogProbMetric: 17.5435

Epoch 113: val_loss did not improve from 17.23288
196/196 - 33s - loss: 16.5398 - MinusLogProbMetric: 16.5398 - val_loss: 17.5435 - val_MinusLogProbMetric: 17.5435 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 114/1000
2023-09-27 12:16:51.031 
Epoch 114/1000 
	 loss: 16.5435, MinusLogProbMetric: 16.5435, val_loss: 17.4297, val_MinusLogProbMetric: 17.4297

Epoch 114: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.5435 - MinusLogProbMetric: 16.5435 - val_loss: 17.4297 - val_MinusLogProbMetric: 17.4297 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 115/1000
2023-09-27 12:17:24.845 
Epoch 115/1000 
	 loss: 16.5021, MinusLogProbMetric: 16.5021, val_loss: 17.4297, val_MinusLogProbMetric: 17.4297

Epoch 115: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.5021 - MinusLogProbMetric: 16.5021 - val_loss: 17.4297 - val_MinusLogProbMetric: 17.4297 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 116/1000
2023-09-27 12:17:58.962 
Epoch 116/1000 
	 loss: 16.4897, MinusLogProbMetric: 16.4897, val_loss: 17.3785, val_MinusLogProbMetric: 17.3785

Epoch 116: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.4897 - MinusLogProbMetric: 16.4897 - val_loss: 17.3785 - val_MinusLogProbMetric: 17.3785 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 117/1000
2023-09-27 12:18:32.771 
Epoch 117/1000 
	 loss: 16.4660, MinusLogProbMetric: 16.4660, val_loss: 17.5807, val_MinusLogProbMetric: 17.5807

Epoch 117: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.4660 - MinusLogProbMetric: 16.4660 - val_loss: 17.5807 - val_MinusLogProbMetric: 17.5807 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 118/1000
2023-09-27 12:19:07.181 
Epoch 118/1000 
	 loss: 16.5184, MinusLogProbMetric: 16.5184, val_loss: 17.4389, val_MinusLogProbMetric: 17.4389

Epoch 118: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.5184 - MinusLogProbMetric: 16.5184 - val_loss: 17.4389 - val_MinusLogProbMetric: 17.4389 - lr: 0.0010 - 34s/epoch - 176ms/step
Epoch 119/1000
2023-09-27 12:19:40.419 
Epoch 119/1000 
	 loss: 16.4566, MinusLogProbMetric: 16.4566, val_loss: 17.4231, val_MinusLogProbMetric: 17.4231

Epoch 119: val_loss did not improve from 17.23288
196/196 - 33s - loss: 16.4566 - MinusLogProbMetric: 16.4566 - val_loss: 17.4231 - val_MinusLogProbMetric: 17.4231 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 120/1000
2023-09-27 12:20:13.959 
Epoch 120/1000 
	 loss: 16.4658, MinusLogProbMetric: 16.4658, val_loss: 17.4783, val_MinusLogProbMetric: 17.4783

Epoch 120: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.4658 - MinusLogProbMetric: 16.4658 - val_loss: 17.4783 - val_MinusLogProbMetric: 17.4783 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 121/1000
2023-09-27 12:20:47.935 
Epoch 121/1000 
	 loss: 16.4848, MinusLogProbMetric: 16.4848, val_loss: 17.4375, val_MinusLogProbMetric: 17.4375

Epoch 121: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.4848 - MinusLogProbMetric: 16.4848 - val_loss: 17.4375 - val_MinusLogProbMetric: 17.4375 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 122/1000
2023-09-27 12:21:21.398 
Epoch 122/1000 
	 loss: 16.4829, MinusLogProbMetric: 16.4829, val_loss: 17.4234, val_MinusLogProbMetric: 17.4234

Epoch 122: val_loss did not improve from 17.23288
196/196 - 33s - loss: 16.4829 - MinusLogProbMetric: 16.4829 - val_loss: 17.4234 - val_MinusLogProbMetric: 17.4234 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 123/1000
2023-09-27 12:21:55.680 
Epoch 123/1000 
	 loss: 16.1576, MinusLogProbMetric: 16.1576, val_loss: 17.3664, val_MinusLogProbMetric: 17.3664

Epoch 123: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.1576 - MinusLogProbMetric: 16.1576 - val_loss: 17.3664 - val_MinusLogProbMetric: 17.3664 - lr: 5.0000e-04 - 34s/epoch - 175ms/step
Epoch 124/1000
2023-09-27 12:22:30.010 
Epoch 124/1000 
	 loss: 16.1631, MinusLogProbMetric: 16.1631, val_loss: 17.5063, val_MinusLogProbMetric: 17.5063

Epoch 124: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.1631 - MinusLogProbMetric: 16.1631 - val_loss: 17.5063 - val_MinusLogProbMetric: 17.5063 - lr: 5.0000e-04 - 34s/epoch - 175ms/step
Epoch 125/1000
2023-09-27 12:23:03.776 
Epoch 125/1000 
	 loss: 16.1362, MinusLogProbMetric: 16.1362, val_loss: 17.4555, val_MinusLogProbMetric: 17.4555

Epoch 125: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.1362 - MinusLogProbMetric: 16.1362 - val_loss: 17.4555 - val_MinusLogProbMetric: 17.4555 - lr: 5.0000e-04 - 34s/epoch - 172ms/step
Epoch 126/1000
2023-09-27 12:23:38.448 
Epoch 126/1000 
	 loss: 16.1774, MinusLogProbMetric: 16.1774, val_loss: 17.3518, val_MinusLogProbMetric: 17.3518

Epoch 126: val_loss did not improve from 17.23288
196/196 - 35s - loss: 16.1774 - MinusLogProbMetric: 16.1774 - val_loss: 17.3518 - val_MinusLogProbMetric: 17.3518 - lr: 5.0000e-04 - 35s/epoch - 177ms/step
Epoch 127/1000
2023-09-27 12:24:13.218 
Epoch 127/1000 
	 loss: 16.1392, MinusLogProbMetric: 16.1392, val_loss: 17.3445, val_MinusLogProbMetric: 17.3445

Epoch 127: val_loss did not improve from 17.23288
196/196 - 35s - loss: 16.1392 - MinusLogProbMetric: 16.1392 - val_loss: 17.3445 - val_MinusLogProbMetric: 17.3445 - lr: 5.0000e-04 - 35s/epoch - 177ms/step
Epoch 128/1000
2023-09-27 12:24:47.347 
Epoch 128/1000 
	 loss: 16.1177, MinusLogProbMetric: 16.1177, val_loss: 17.3959, val_MinusLogProbMetric: 17.3959

Epoch 128: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.1177 - MinusLogProbMetric: 16.1177 - val_loss: 17.3959 - val_MinusLogProbMetric: 17.3959 - lr: 5.0000e-04 - 34s/epoch - 174ms/step
Epoch 129/1000
2023-09-27 12:25:21.233 
Epoch 129/1000 
	 loss: 16.1457, MinusLogProbMetric: 16.1457, val_loss: 17.3387, val_MinusLogProbMetric: 17.3387

Epoch 129: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.1457 - MinusLogProbMetric: 16.1457 - val_loss: 17.3387 - val_MinusLogProbMetric: 17.3387 - lr: 5.0000e-04 - 34s/epoch - 173ms/step
Epoch 130/1000
2023-09-27 12:25:55.813 
Epoch 130/1000 
	 loss: 16.1210, MinusLogProbMetric: 16.1210, val_loss: 17.3610, val_MinusLogProbMetric: 17.3610

Epoch 130: val_loss did not improve from 17.23288
196/196 - 35s - loss: 16.1210 - MinusLogProbMetric: 16.1210 - val_loss: 17.3610 - val_MinusLogProbMetric: 17.3610 - lr: 5.0000e-04 - 35s/epoch - 176ms/step
Epoch 131/1000
2023-09-27 12:26:30.062 
Epoch 131/1000 
	 loss: 16.1290, MinusLogProbMetric: 16.1290, val_loss: 17.4232, val_MinusLogProbMetric: 17.4232

Epoch 131: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.1290 - MinusLogProbMetric: 16.1290 - val_loss: 17.4232 - val_MinusLogProbMetric: 17.4232 - lr: 5.0000e-04 - 34s/epoch - 175ms/step
Epoch 132/1000
2023-09-27 12:27:03.664 
Epoch 132/1000 
	 loss: 16.1063, MinusLogProbMetric: 16.1063, val_loss: 17.3881, val_MinusLogProbMetric: 17.3881

Epoch 132: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.1063 - MinusLogProbMetric: 16.1063 - val_loss: 17.3881 - val_MinusLogProbMetric: 17.3881 - lr: 5.0000e-04 - 34s/epoch - 171ms/step
Epoch 133/1000
2023-09-27 12:27:37.358 
Epoch 133/1000 
	 loss: 16.0970, MinusLogProbMetric: 16.0970, val_loss: 17.7337, val_MinusLogProbMetric: 17.7337

Epoch 133: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.0970 - MinusLogProbMetric: 16.0970 - val_loss: 17.7337 - val_MinusLogProbMetric: 17.7337 - lr: 5.0000e-04 - 34s/epoch - 172ms/step
Epoch 134/1000
2023-09-27 12:28:10.575 
Epoch 134/1000 
	 loss: 16.1373, MinusLogProbMetric: 16.1373, val_loss: 17.3857, val_MinusLogProbMetric: 17.3857

Epoch 134: val_loss did not improve from 17.23288
196/196 - 33s - loss: 16.1373 - MinusLogProbMetric: 16.1373 - val_loss: 17.3857 - val_MinusLogProbMetric: 17.3857 - lr: 5.0000e-04 - 33s/epoch - 169ms/step
Epoch 135/1000
2023-09-27 12:28:44.627 
Epoch 135/1000 
	 loss: 16.1050, MinusLogProbMetric: 16.1050, val_loss: 17.5556, val_MinusLogProbMetric: 17.5556

Epoch 135: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.1050 - MinusLogProbMetric: 16.1050 - val_loss: 17.5556 - val_MinusLogProbMetric: 17.5556 - lr: 5.0000e-04 - 34s/epoch - 174ms/step
Epoch 136/1000
2023-09-27 12:29:18.612 
Epoch 136/1000 
	 loss: 16.1154, MinusLogProbMetric: 16.1154, val_loss: 17.4826, val_MinusLogProbMetric: 17.4826

Epoch 136: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.1154 - MinusLogProbMetric: 16.1154 - val_loss: 17.4826 - val_MinusLogProbMetric: 17.4826 - lr: 5.0000e-04 - 34s/epoch - 173ms/step
Epoch 137/1000
2023-09-27 12:29:52.020 
Epoch 137/1000 
	 loss: 16.1086, MinusLogProbMetric: 16.1086, val_loss: 17.3699, val_MinusLogProbMetric: 17.3699

Epoch 137: val_loss did not improve from 17.23288
196/196 - 33s - loss: 16.1086 - MinusLogProbMetric: 16.1086 - val_loss: 17.3699 - val_MinusLogProbMetric: 17.3699 - lr: 5.0000e-04 - 33s/epoch - 170ms/step
Epoch 138/1000
2023-09-27 12:30:25.784 
Epoch 138/1000 
	 loss: 16.0971, MinusLogProbMetric: 16.0971, val_loss: 17.5113, val_MinusLogProbMetric: 17.5113

Epoch 138: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.0971 - MinusLogProbMetric: 16.0971 - val_loss: 17.5113 - val_MinusLogProbMetric: 17.5113 - lr: 5.0000e-04 - 34s/epoch - 172ms/step
Epoch 139/1000
2023-09-27 12:31:00.494 
Epoch 139/1000 
	 loss: 16.0691, MinusLogProbMetric: 16.0691, val_loss: 17.5058, val_MinusLogProbMetric: 17.5058

Epoch 139: val_loss did not improve from 17.23288
196/196 - 35s - loss: 16.0691 - MinusLogProbMetric: 16.0691 - val_loss: 17.5058 - val_MinusLogProbMetric: 17.5058 - lr: 5.0000e-04 - 35s/epoch - 177ms/step
Epoch 140/1000
2023-09-27 12:31:35.129 
Epoch 140/1000 
	 loss: 16.0914, MinusLogProbMetric: 16.0914, val_loss: 17.4011, val_MinusLogProbMetric: 17.4011

Epoch 140: val_loss did not improve from 17.23288
196/196 - 35s - loss: 16.0914 - MinusLogProbMetric: 16.0914 - val_loss: 17.4011 - val_MinusLogProbMetric: 17.4011 - lr: 5.0000e-04 - 35s/epoch - 177ms/step
Epoch 141/1000
2023-09-27 12:32:08.945 
Epoch 141/1000 
	 loss: 16.0609, MinusLogProbMetric: 16.0609, val_loss: 17.5316, val_MinusLogProbMetric: 17.5316

Epoch 141: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.0609 - MinusLogProbMetric: 16.0609 - val_loss: 17.5316 - val_MinusLogProbMetric: 17.5316 - lr: 5.0000e-04 - 34s/epoch - 173ms/step
Epoch 142/1000
2023-09-27 12:32:43.331 
Epoch 142/1000 
	 loss: 16.0885, MinusLogProbMetric: 16.0885, val_loss: 17.7399, val_MinusLogProbMetric: 17.7399

Epoch 142: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.0885 - MinusLogProbMetric: 16.0885 - val_loss: 17.7399 - val_MinusLogProbMetric: 17.7399 - lr: 5.0000e-04 - 34s/epoch - 175ms/step
Epoch 143/1000
2023-09-27 12:33:16.815 
Epoch 143/1000 
	 loss: 16.0690, MinusLogProbMetric: 16.0690, val_loss: 17.5586, val_MinusLogProbMetric: 17.5586

Epoch 143: val_loss did not improve from 17.23288
196/196 - 33s - loss: 16.0690 - MinusLogProbMetric: 16.0690 - val_loss: 17.5586 - val_MinusLogProbMetric: 17.5586 - lr: 5.0000e-04 - 33s/epoch - 171ms/step
Epoch 144/1000
2023-09-27 12:33:50.377 
Epoch 144/1000 
	 loss: 16.0857, MinusLogProbMetric: 16.0857, val_loss: 17.5984, val_MinusLogProbMetric: 17.5984

Epoch 144: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.0857 - MinusLogProbMetric: 16.0857 - val_loss: 17.5984 - val_MinusLogProbMetric: 17.5984 - lr: 5.0000e-04 - 34s/epoch - 171ms/step
Epoch 145/1000
2023-09-27 12:34:23.759 
Epoch 145/1000 
	 loss: 16.0649, MinusLogProbMetric: 16.0649, val_loss: 17.4372, val_MinusLogProbMetric: 17.4372

Epoch 145: val_loss did not improve from 17.23288
196/196 - 33s - loss: 16.0649 - MinusLogProbMetric: 16.0649 - val_loss: 17.4372 - val_MinusLogProbMetric: 17.4372 - lr: 5.0000e-04 - 33s/epoch - 170ms/step
Epoch 146/1000
2023-09-27 12:34:57.468 
Epoch 146/1000 
	 loss: 16.0517, MinusLogProbMetric: 16.0517, val_loss: 17.5180, val_MinusLogProbMetric: 17.5180

Epoch 146: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.0517 - MinusLogProbMetric: 16.0517 - val_loss: 17.5180 - val_MinusLogProbMetric: 17.5180 - lr: 5.0000e-04 - 34s/epoch - 172ms/step
Epoch 147/1000
2023-09-27 12:35:30.923 
Epoch 147/1000 
	 loss: 16.0584, MinusLogProbMetric: 16.0584, val_loss: 17.4613, val_MinusLogProbMetric: 17.4613

Epoch 147: val_loss did not improve from 17.23288
196/196 - 33s - loss: 16.0584 - MinusLogProbMetric: 16.0584 - val_loss: 17.4613 - val_MinusLogProbMetric: 17.4613 - lr: 5.0000e-04 - 33s/epoch - 171ms/step
Epoch 148/1000
2023-09-27 12:36:05.144 
Epoch 148/1000 
	 loss: 16.0401, MinusLogProbMetric: 16.0401, val_loss: 17.4348, val_MinusLogProbMetric: 17.4348

Epoch 148: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.0401 - MinusLogProbMetric: 16.0401 - val_loss: 17.4348 - val_MinusLogProbMetric: 17.4348 - lr: 5.0000e-04 - 34s/epoch - 175ms/step
Epoch 149/1000
2023-09-27 12:36:39.608 
Epoch 149/1000 
	 loss: 16.0366, MinusLogProbMetric: 16.0366, val_loss: 17.5145, val_MinusLogProbMetric: 17.5145

Epoch 149: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.0366 - MinusLogProbMetric: 16.0366 - val_loss: 17.5145 - val_MinusLogProbMetric: 17.5145 - lr: 5.0000e-04 - 34s/epoch - 176ms/step
Epoch 150/1000
2023-09-27 12:37:13.707 
Epoch 150/1000 
	 loss: 16.0452, MinusLogProbMetric: 16.0452, val_loss: 17.5661, val_MinusLogProbMetric: 17.5661

Epoch 150: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.0452 - MinusLogProbMetric: 16.0452 - val_loss: 17.5661 - val_MinusLogProbMetric: 17.5661 - lr: 5.0000e-04 - 34s/epoch - 174ms/step
Epoch 151/1000
2023-09-27 12:37:47.944 
Epoch 151/1000 
	 loss: 16.0618, MinusLogProbMetric: 16.0618, val_loss: 17.5640, val_MinusLogProbMetric: 17.5640

Epoch 151: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.0618 - MinusLogProbMetric: 16.0618 - val_loss: 17.5640 - val_MinusLogProbMetric: 17.5640 - lr: 5.0000e-04 - 34s/epoch - 175ms/step
Epoch 152/1000
2023-09-27 12:38:21.550 
Epoch 152/1000 
	 loss: 16.0421, MinusLogProbMetric: 16.0421, val_loss: 17.5111, val_MinusLogProbMetric: 17.5111

Epoch 152: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.0421 - MinusLogProbMetric: 16.0421 - val_loss: 17.5111 - val_MinusLogProbMetric: 17.5111 - lr: 5.0000e-04 - 34s/epoch - 171ms/step
Epoch 153/1000
2023-09-27 12:38:55.646 
Epoch 153/1000 
	 loss: 16.0680, MinusLogProbMetric: 16.0680, val_loss: 17.5103, val_MinusLogProbMetric: 17.5103

Epoch 153: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.0680 - MinusLogProbMetric: 16.0680 - val_loss: 17.5103 - val_MinusLogProbMetric: 17.5103 - lr: 5.0000e-04 - 34s/epoch - 174ms/step
Epoch 154/1000
2023-09-27 12:39:29.936 
Epoch 154/1000 
	 loss: 16.0290, MinusLogProbMetric: 16.0290, val_loss: 17.5297, val_MinusLogProbMetric: 17.5297

Epoch 154: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.0290 - MinusLogProbMetric: 16.0290 - val_loss: 17.5297 - val_MinusLogProbMetric: 17.5297 - lr: 5.0000e-04 - 34s/epoch - 175ms/step
Epoch 155/1000
2023-09-27 12:40:04.210 
Epoch 155/1000 
	 loss: 16.0166, MinusLogProbMetric: 16.0166, val_loss: 17.6238, val_MinusLogProbMetric: 17.6238

Epoch 155: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.0166 - MinusLogProbMetric: 16.0166 - val_loss: 17.6238 - val_MinusLogProbMetric: 17.6238 - lr: 5.0000e-04 - 34s/epoch - 175ms/step
Epoch 156/1000
2023-09-27 12:40:37.847 
Epoch 156/1000 
	 loss: 16.0340, MinusLogProbMetric: 16.0340, val_loss: 17.5886, val_MinusLogProbMetric: 17.5886

Epoch 156: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.0340 - MinusLogProbMetric: 16.0340 - val_loss: 17.5886 - val_MinusLogProbMetric: 17.5886 - lr: 5.0000e-04 - 34s/epoch - 172ms/step
Epoch 157/1000
2023-09-27 12:41:11.497 
Epoch 157/1000 
	 loss: 16.0171, MinusLogProbMetric: 16.0171, val_loss: 17.5946, val_MinusLogProbMetric: 17.5946

Epoch 157: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.0171 - MinusLogProbMetric: 16.0171 - val_loss: 17.5946 - val_MinusLogProbMetric: 17.5946 - lr: 5.0000e-04 - 34s/epoch - 172ms/step
Epoch 158/1000
2023-09-27 12:41:46.060 
Epoch 158/1000 
	 loss: 16.0181, MinusLogProbMetric: 16.0181, val_loss: 17.5305, val_MinusLogProbMetric: 17.5305

Epoch 158: val_loss did not improve from 17.23288
196/196 - 35s - loss: 16.0181 - MinusLogProbMetric: 16.0181 - val_loss: 17.5305 - val_MinusLogProbMetric: 17.5305 - lr: 5.0000e-04 - 35s/epoch - 176ms/step
Epoch 159/1000
2023-09-27 12:42:20.072 
Epoch 159/1000 
	 loss: 15.9979, MinusLogProbMetric: 15.9979, val_loss: 17.4971, val_MinusLogProbMetric: 17.4971

Epoch 159: val_loss did not improve from 17.23288
196/196 - 34s - loss: 15.9979 - MinusLogProbMetric: 15.9979 - val_loss: 17.4971 - val_MinusLogProbMetric: 17.4971 - lr: 5.0000e-04 - 34s/epoch - 174ms/step
Epoch 160/1000
2023-09-27 12:42:54.701 
Epoch 160/1000 
	 loss: 16.0051, MinusLogProbMetric: 16.0051, val_loss: 17.6146, val_MinusLogProbMetric: 17.6146

Epoch 160: val_loss did not improve from 17.23288
196/196 - 35s - loss: 16.0051 - MinusLogProbMetric: 16.0051 - val_loss: 17.6146 - val_MinusLogProbMetric: 17.6146 - lr: 5.0000e-04 - 35s/epoch - 177ms/step
Epoch 161/1000
2023-09-27 12:43:28.714 
Epoch 161/1000 
	 loss: 16.0304, MinusLogProbMetric: 16.0304, val_loss: 17.4974, val_MinusLogProbMetric: 17.4974

Epoch 161: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.0304 - MinusLogProbMetric: 16.0304 - val_loss: 17.4974 - val_MinusLogProbMetric: 17.4974 - lr: 5.0000e-04 - 34s/epoch - 174ms/step
Epoch 162/1000
2023-09-27 12:44:02.492 
Epoch 162/1000 
	 loss: 15.9917, MinusLogProbMetric: 15.9917, val_loss: 17.5505, val_MinusLogProbMetric: 17.5505

Epoch 162: val_loss did not improve from 17.23288
196/196 - 34s - loss: 15.9917 - MinusLogProbMetric: 15.9917 - val_loss: 17.5505 - val_MinusLogProbMetric: 17.5505 - lr: 5.0000e-04 - 34s/epoch - 172ms/step
Epoch 163/1000
2023-09-27 12:44:36.219 
Epoch 163/1000 
	 loss: 16.0009, MinusLogProbMetric: 16.0009, val_loss: 17.5297, val_MinusLogProbMetric: 17.5297

Epoch 163: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.0009 - MinusLogProbMetric: 16.0009 - val_loss: 17.5297 - val_MinusLogProbMetric: 17.5297 - lr: 5.0000e-04 - 34s/epoch - 172ms/step
Epoch 164/1000
2023-09-27 12:45:10.153 
Epoch 164/1000 
	 loss: 16.0003, MinusLogProbMetric: 16.0003, val_loss: 17.7423, val_MinusLogProbMetric: 17.7423

Epoch 164: val_loss did not improve from 17.23288
196/196 - 34s - loss: 16.0003 - MinusLogProbMetric: 16.0003 - val_loss: 17.7423 - val_MinusLogProbMetric: 17.7423 - lr: 5.0000e-04 - 34s/epoch - 173ms/step
Epoch 165/1000
2023-09-27 12:45:43.770 
Epoch 165/1000 
	 loss: 15.9776, MinusLogProbMetric: 15.9776, val_loss: 17.5583, val_MinusLogProbMetric: 17.5583

Epoch 165: val_loss did not improve from 17.23288
196/196 - 34s - loss: 15.9776 - MinusLogProbMetric: 15.9776 - val_loss: 17.5583 - val_MinusLogProbMetric: 17.5583 - lr: 5.0000e-04 - 34s/epoch - 171ms/step
Epoch 166/1000
2023-09-27 12:46:17.370 
Epoch 166/1000 
	 loss: 15.9891, MinusLogProbMetric: 15.9891, val_loss: 17.6167, val_MinusLogProbMetric: 17.6167

Epoch 166: val_loss did not improve from 17.23288
196/196 - 34s - loss: 15.9891 - MinusLogProbMetric: 15.9891 - val_loss: 17.6167 - val_MinusLogProbMetric: 17.6167 - lr: 5.0000e-04 - 34s/epoch - 171ms/step
Epoch 167/1000
2023-09-27 12:46:51.310 
Epoch 167/1000 
	 loss: 15.9584, MinusLogProbMetric: 15.9584, val_loss: 17.5520, val_MinusLogProbMetric: 17.5520

Epoch 167: val_loss did not improve from 17.23288
196/196 - 34s - loss: 15.9584 - MinusLogProbMetric: 15.9584 - val_loss: 17.5520 - val_MinusLogProbMetric: 17.5520 - lr: 5.0000e-04 - 34s/epoch - 173ms/step
Epoch 168/1000
2023-09-27 12:47:25.111 
Epoch 168/1000 
	 loss: 15.9608, MinusLogProbMetric: 15.9608, val_loss: 17.5321, val_MinusLogProbMetric: 17.5321

Epoch 168: val_loss did not improve from 17.23288
196/196 - 34s - loss: 15.9608 - MinusLogProbMetric: 15.9608 - val_loss: 17.5321 - val_MinusLogProbMetric: 17.5321 - lr: 5.0000e-04 - 34s/epoch - 172ms/step
Epoch 169/1000
2023-09-27 12:47:58.728 
Epoch 169/1000 
	 loss: 15.9508, MinusLogProbMetric: 15.9508, val_loss: 17.6149, val_MinusLogProbMetric: 17.6149

Epoch 169: val_loss did not improve from 17.23288
196/196 - 34s - loss: 15.9508 - MinusLogProbMetric: 15.9508 - val_loss: 17.6149 - val_MinusLogProbMetric: 17.6149 - lr: 5.0000e-04 - 34s/epoch - 172ms/step
Epoch 170/1000
2023-09-27 12:48:32.384 
Epoch 170/1000 
	 loss: 15.9668, MinusLogProbMetric: 15.9668, val_loss: 17.5830, val_MinusLogProbMetric: 17.5830

Epoch 170: val_loss did not improve from 17.23288
196/196 - 34s - loss: 15.9668 - MinusLogProbMetric: 15.9668 - val_loss: 17.5830 - val_MinusLogProbMetric: 17.5830 - lr: 5.0000e-04 - 34s/epoch - 172ms/step
Epoch 171/1000
2023-09-27 12:49:07.344 
Epoch 171/1000 
	 loss: 15.9752, MinusLogProbMetric: 15.9752, val_loss: 17.7832, val_MinusLogProbMetric: 17.7832

Epoch 171: val_loss did not improve from 17.23288
196/196 - 35s - loss: 15.9752 - MinusLogProbMetric: 15.9752 - val_loss: 17.7832 - val_MinusLogProbMetric: 17.7832 - lr: 5.0000e-04 - 35s/epoch - 178ms/step
Epoch 172/1000
2023-09-27 12:49:41.081 
Epoch 172/1000 
	 loss: 15.9671, MinusLogProbMetric: 15.9671, val_loss: 17.5880, val_MinusLogProbMetric: 17.5880

Epoch 172: val_loss did not improve from 17.23288
Restoring model weights from the end of the best epoch: 72.
196/196 - 34s - loss: 15.9671 - MinusLogProbMetric: 15.9671 - val_loss: 17.5880 - val_MinusLogProbMetric: 17.5880 - lr: 5.0000e-04 - 34s/epoch - 174ms/step
Epoch 172: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
LR metric calculation completed in 14.015485865995288 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 9.053511330974288 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
SWD metric calculation completed in 5.775541144015733 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
FN metric calculation completed in 6.853896806016564 seconds.
Training succeeded with seed 926.
Model trained in 5936.00 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 36.90 s.
                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/c_Main_CsplineN.py , Line : 469, Func.Name : prediction_function, Message : Plotters.cornerplotter(X_data_test.numpy(),X_data_nf.numpy(),path_to_results,ndims,norm=True) # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 37.14 s.
===========
Run 306/720 done in 5977.86 s.
===========

===========
Generating train data for run 307.
===========
Train data generated in 0.32 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_307/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 926}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_307/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[1.5383615 , 4.21851   , 9.147865  , ..., 7.328855  , 2.4535477 ,
        2.0265868 ],
       [1.2026695 , 3.5675488 , 8.490738  , ..., 7.486889  , 2.9732862 ,
        1.6526531 ],
       [5.7808385 , 5.6486273 , 0.85161066, ..., 0.44565296, 6.0336885 ,
        1.4597642 ],
       ...,
       [3.869998  , 5.7079043 , 0.7277752 , ..., 1.4709862 , 7.5385275 ,
        1.2852083 ],
       [2.111317  , 3.3553224 , 7.6223764 , ..., 7.4778986 , 3.6354768 ,
        1.7641349 ],
       [0.83836687, 3.4177158 , 7.4230075 , ..., 7.223582  , 3.3779047 ,
        2.0014815 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_307/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_307
self.data_kwargs: {'seed': 926}
self.x_data: [[1.4696891  3.165189   9.115545   ... 7.2440553  3.018408   2.0407877 ]
 [2.9008398  3.8232424  7.129506   ... 7.411926   2.8866556  1.4983263 ]
 [4.669435   5.457821   0.04349925 ... 0.866001   6.611358   1.4323243 ]
 ...
 [4.261785   5.5317554  0.77893746 ... 0.60558414 5.4824862  1.3011014 ]
 [4.4981847  5.716866   0.72522354 ... 0.9913055  5.7512865  1.5265256 ]
 [5.479814   7.150977   6.3064384  ... 3.1490364  2.6668518  8.143393  ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_45"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_46 (InputLayer)       [(None, 32)]              0         
                                                                 
 log_prob_layer_5 (LogProbLa  (None,)                  537200    
 yer)                                                            
                                                                 
=================================================================
Total params: 537,200
Trainable params: 537,200
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_5/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_5'")
self.model: <keras.engine.functional.Functional object at 0x7fd25477bb80>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fd244751210>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fd244751210>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fd2d84fd210>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fd254752b90>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fd254753100>, <keras.callbacks.ModelCheckpoint object at 0x7fd2547531c0>, <keras.callbacks.EarlyStopping object at 0x7fd254753430>, <keras.callbacks.ReduceLROnPlateau object at 0x7fd254753460>, <keras.callbacks.TerminateOnNaN object at 0x7fd2547530a0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[1.5383615 , 4.21851   , 9.147865  , ..., 7.328855  , 2.4535477 ,
        2.0265868 ],
       [1.2026695 , 3.5675488 , 8.490738  , ..., 7.486889  , 2.9732862 ,
        1.6526531 ],
       [5.7808385 , 5.6486273 , 0.85161066, ..., 0.44565296, 6.0336885 ,
        1.4597642 ],
       ...,
       [3.869998  , 5.7079043 , 0.7277752 , ..., 1.4709862 , 7.5385275 ,
        1.2852083 ],
       [2.111317  , 3.3553224 , 7.6223764 , ..., 7.4778986 , 3.6354768 ,
        1.7641349 ],
       [0.83836687, 3.4177158 , 7.4230075 , ..., 7.223582  , 3.3779047 ,
        2.0014815 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_307/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 307/720 with hyperparameters:
timestamp = 2023-09-27 12:50:23.862802
ndims = 32
seed_train = 926
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 5
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 537200
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 1.4696891   3.165189    9.115545    1.2257975   9.89761    -0.04518861
  9.761367    5.046433   10.037439    6.270509    6.6800056   0.37080207
  3.2512977   1.1872      2.5658634   0.9389908   3.4711475   5.1744766
  0.38911742  6.94769     5.6341734   2.616604    4.513363    1.4770697
  4.2721643   9.222334    2.548921    6.22901     1.4673232   7.2440553
  3.018408    2.0407877 ]
Epoch 1/1000
2023-09-27 12:52:36.328 
Epoch 1/1000 
	 loss: 200.9292, MinusLogProbMetric: 200.9292, val_loss: 43.0933, val_MinusLogProbMetric: 43.0933

Epoch 1: val_loss improved from inf to 43.09328, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 133s - loss: 200.9292 - MinusLogProbMetric: 200.9292 - val_loss: 43.0933 - val_MinusLogProbMetric: 43.0933 - lr: 0.0010 - 133s/epoch - 678ms/step
Epoch 2/1000
2023-09-27 12:53:17.909 
Epoch 2/1000 
	 loss: 36.2091, MinusLogProbMetric: 36.2091, val_loss: 31.8770, val_MinusLogProbMetric: 31.8770

Epoch 2: val_loss improved from 43.09328 to 31.87697, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 42s - loss: 36.2091 - MinusLogProbMetric: 36.2091 - val_loss: 31.8770 - val_MinusLogProbMetric: 31.8770 - lr: 0.0010 - 42s/epoch - 212ms/step
Epoch 3/1000
2023-09-27 12:53:58.655 
Epoch 3/1000 
	 loss: 28.7350, MinusLogProbMetric: 28.7350, val_loss: 26.5773, val_MinusLogProbMetric: 26.5773

Epoch 3: val_loss improved from 31.87697 to 26.57730, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 41s - loss: 28.7350 - MinusLogProbMetric: 28.7350 - val_loss: 26.5773 - val_MinusLogProbMetric: 26.5773 - lr: 0.0010 - 41s/epoch - 208ms/step
Epoch 4/1000
2023-09-27 12:54:40.223 
Epoch 4/1000 
	 loss: 25.6378, MinusLogProbMetric: 25.6378, val_loss: 26.1099, val_MinusLogProbMetric: 26.1099

Epoch 4: val_loss improved from 26.57730 to 26.10992, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 41s - loss: 25.6378 - MinusLogProbMetric: 25.6378 - val_loss: 26.1099 - val_MinusLogProbMetric: 26.1099 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 5/1000
2023-09-27 12:55:21.892 
Epoch 5/1000 
	 loss: 24.1068, MinusLogProbMetric: 24.1068, val_loss: 23.8736, val_MinusLogProbMetric: 23.8736

Epoch 5: val_loss improved from 26.10992 to 23.87364, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 42s - loss: 24.1068 - MinusLogProbMetric: 24.1068 - val_loss: 23.8736 - val_MinusLogProbMetric: 23.8736 - lr: 0.0010 - 42s/epoch - 212ms/step
Epoch 6/1000
2023-09-27 12:56:02.645 
Epoch 6/1000 
	 loss: 23.0688, MinusLogProbMetric: 23.0688, val_loss: 22.9177, val_MinusLogProbMetric: 22.9177

Epoch 6: val_loss improved from 23.87364 to 22.91767, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 41s - loss: 23.0688 - MinusLogProbMetric: 23.0688 - val_loss: 22.9177 - val_MinusLogProbMetric: 22.9177 - lr: 0.0010 - 41s/epoch - 208ms/step
Epoch 7/1000
2023-09-27 12:56:43.899 
Epoch 7/1000 
	 loss: 22.2587, MinusLogProbMetric: 22.2587, val_loss: 22.9790, val_MinusLogProbMetric: 22.9790

Epoch 7: val_loss did not improve from 22.91767
196/196 - 41s - loss: 22.2587 - MinusLogProbMetric: 22.2587 - val_loss: 22.9790 - val_MinusLogProbMetric: 22.9790 - lr: 0.0010 - 41s/epoch - 207ms/step
Epoch 8/1000
2023-09-27 12:57:24.009 
Epoch 8/1000 
	 loss: 21.9608, MinusLogProbMetric: 21.9608, val_loss: 21.4424, val_MinusLogProbMetric: 21.4424

Epoch 8: val_loss improved from 22.91767 to 21.44242, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 41s - loss: 21.9608 - MinusLogProbMetric: 21.9608 - val_loss: 21.4424 - val_MinusLogProbMetric: 21.4424 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 9/1000
2023-09-27 12:58:04.503 
Epoch 9/1000 
	 loss: 21.5650, MinusLogProbMetric: 21.5650, val_loss: 20.8588, val_MinusLogProbMetric: 20.8588

Epoch 9: val_loss improved from 21.44242 to 20.85883, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 40s - loss: 21.5650 - MinusLogProbMetric: 21.5650 - val_loss: 20.8588 - val_MinusLogProbMetric: 20.8588 - lr: 0.0010 - 40s/epoch - 206ms/step
Epoch 10/1000
2023-09-27 12:58:45.919 
Epoch 10/1000 
	 loss: 21.2083, MinusLogProbMetric: 21.2083, val_loss: 20.7123, val_MinusLogProbMetric: 20.7123

Epoch 10: val_loss improved from 20.85883 to 20.71231, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 41s - loss: 21.2083 - MinusLogProbMetric: 21.2083 - val_loss: 20.7123 - val_MinusLogProbMetric: 20.7123 - lr: 0.0010 - 41s/epoch - 212ms/step
Epoch 11/1000
2023-09-27 12:59:25.963 
Epoch 11/1000 
	 loss: 20.8834, MinusLogProbMetric: 20.8834, val_loss: 20.7296, val_MinusLogProbMetric: 20.7296

Epoch 11: val_loss did not improve from 20.71231
196/196 - 39s - loss: 20.8834 - MinusLogProbMetric: 20.8834 - val_loss: 20.7296 - val_MinusLogProbMetric: 20.7296 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 12/1000
2023-09-27 13:00:05.806 
Epoch 12/1000 
	 loss: 20.8381, MinusLogProbMetric: 20.8381, val_loss: 21.4737, val_MinusLogProbMetric: 21.4737

Epoch 12: val_loss did not improve from 20.71231
196/196 - 40s - loss: 20.8381 - MinusLogProbMetric: 20.8381 - val_loss: 21.4737 - val_MinusLogProbMetric: 21.4737 - lr: 0.0010 - 40s/epoch - 203ms/step
Epoch 13/1000
2023-09-27 13:00:46.976 
Epoch 13/1000 
	 loss: 20.5580, MinusLogProbMetric: 20.5580, val_loss: 20.5960, val_MinusLogProbMetric: 20.5960

Epoch 13: val_loss improved from 20.71231 to 20.59603, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 42s - loss: 20.5580 - MinusLogProbMetric: 20.5580 - val_loss: 20.5960 - val_MinusLogProbMetric: 20.5960 - lr: 0.0010 - 42s/epoch - 214ms/step
Epoch 14/1000
2023-09-27 13:01:28.217 
Epoch 14/1000 
	 loss: 20.2715, MinusLogProbMetric: 20.2715, val_loss: 20.4514, val_MinusLogProbMetric: 20.4514

Epoch 14: val_loss improved from 20.59603 to 20.45144, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 41s - loss: 20.2715 - MinusLogProbMetric: 20.2715 - val_loss: 20.4514 - val_MinusLogProbMetric: 20.4514 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 15/1000
2023-09-27 13:02:09.364 
Epoch 15/1000 
	 loss: 20.1317, MinusLogProbMetric: 20.1317, val_loss: 20.7274, val_MinusLogProbMetric: 20.7274

Epoch 15: val_loss did not improve from 20.45144
196/196 - 40s - loss: 20.1317 - MinusLogProbMetric: 20.1317 - val_loss: 20.7274 - val_MinusLogProbMetric: 20.7274 - lr: 0.0010 - 40s/epoch - 206ms/step
Epoch 16/1000
2023-09-27 13:02:49.454 
Epoch 16/1000 
	 loss: 20.0591, MinusLogProbMetric: 20.0591, val_loss: 20.3260, val_MinusLogProbMetric: 20.3260

Epoch 16: val_loss improved from 20.45144 to 20.32597, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 41s - loss: 20.0591 - MinusLogProbMetric: 20.0591 - val_loss: 20.3260 - val_MinusLogProbMetric: 20.3260 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 17/1000
2023-09-27 13:03:30.823 
Epoch 17/1000 
	 loss: 19.9565, MinusLogProbMetric: 19.9565, val_loss: 19.7262, val_MinusLogProbMetric: 19.7262

Epoch 17: val_loss improved from 20.32597 to 19.72618, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 41s - loss: 19.9565 - MinusLogProbMetric: 19.9565 - val_loss: 19.7262 - val_MinusLogProbMetric: 19.7262 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 18/1000
2023-09-27 13:04:11.953 
Epoch 18/1000 
	 loss: 19.8737, MinusLogProbMetric: 19.8737, val_loss: 20.1958, val_MinusLogProbMetric: 20.1958

Epoch 18: val_loss did not improve from 19.72618
196/196 - 40s - loss: 19.8737 - MinusLogProbMetric: 19.8737 - val_loss: 20.1958 - val_MinusLogProbMetric: 20.1958 - lr: 0.0010 - 40s/epoch - 205ms/step
Epoch 19/1000
2023-09-27 13:04:51.145 
Epoch 19/1000 
	 loss: 19.5451, MinusLogProbMetric: 19.5451, val_loss: 19.3509, val_MinusLogProbMetric: 19.3509

Epoch 19: val_loss improved from 19.72618 to 19.35089, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 40s - loss: 19.5451 - MinusLogProbMetric: 19.5451 - val_loss: 19.3509 - val_MinusLogProbMetric: 19.3509 - lr: 0.0010 - 40s/epoch - 205ms/step
Epoch 20/1000
2023-09-27 13:05:31.282 
Epoch 20/1000 
	 loss: 19.6807, MinusLogProbMetric: 19.6807, val_loss: 19.1709, val_MinusLogProbMetric: 19.1709

Epoch 20: val_loss improved from 19.35089 to 19.17086, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 40s - loss: 19.6807 - MinusLogProbMetric: 19.6807 - val_loss: 19.1709 - val_MinusLogProbMetric: 19.1709 - lr: 0.0010 - 40s/epoch - 204ms/step
Epoch 21/1000
2023-09-27 13:06:11.395 
Epoch 21/1000 
	 loss: 19.4500, MinusLogProbMetric: 19.4500, val_loss: 19.2935, val_MinusLogProbMetric: 19.2935

Epoch 21: val_loss did not improve from 19.17086
196/196 - 39s - loss: 19.4500 - MinusLogProbMetric: 19.4500 - val_loss: 19.2935 - val_MinusLogProbMetric: 19.2935 - lr: 0.0010 - 39s/epoch - 201ms/step
Epoch 22/1000
2023-09-27 13:06:50.917 
Epoch 22/1000 
	 loss: 19.4478, MinusLogProbMetric: 19.4478, val_loss: 19.4636, val_MinusLogProbMetric: 19.4636

Epoch 22: val_loss did not improve from 19.17086
196/196 - 40s - loss: 19.4478 - MinusLogProbMetric: 19.4478 - val_loss: 19.4636 - val_MinusLogProbMetric: 19.4636 - lr: 0.0010 - 40s/epoch - 202ms/step
Epoch 23/1000
2023-09-27 13:07:30.628 
Epoch 23/1000 
	 loss: 19.4221, MinusLogProbMetric: 19.4221, val_loss: 19.4966, val_MinusLogProbMetric: 19.4966

Epoch 23: val_loss did not improve from 19.17086
196/196 - 40s - loss: 19.4221 - MinusLogProbMetric: 19.4221 - val_loss: 19.4966 - val_MinusLogProbMetric: 19.4966 - lr: 0.0010 - 40s/epoch - 203ms/step
Epoch 24/1000
2023-09-27 13:08:10.082 
Epoch 24/1000 
	 loss: 19.1965, MinusLogProbMetric: 19.1965, val_loss: 19.1224, val_MinusLogProbMetric: 19.1224

Epoch 24: val_loss improved from 19.17086 to 19.12236, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 40s - loss: 19.1965 - MinusLogProbMetric: 19.1965 - val_loss: 19.1224 - val_MinusLogProbMetric: 19.1224 - lr: 0.0010 - 40s/epoch - 205ms/step
Epoch 25/1000
2023-09-27 13:08:51.311 
Epoch 25/1000 
	 loss: 19.1758, MinusLogProbMetric: 19.1758, val_loss: 19.5234, val_MinusLogProbMetric: 19.5234

Epoch 25: val_loss did not improve from 19.12236
196/196 - 41s - loss: 19.1758 - MinusLogProbMetric: 19.1758 - val_loss: 19.5234 - val_MinusLogProbMetric: 19.5234 - lr: 0.0010 - 41s/epoch - 207ms/step
Epoch 26/1000
2023-09-27 13:09:31.757 
Epoch 26/1000 
	 loss: 19.0874, MinusLogProbMetric: 19.0874, val_loss: 19.0165, val_MinusLogProbMetric: 19.0165

Epoch 26: val_loss improved from 19.12236 to 19.01646, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 41s - loss: 19.0874 - MinusLogProbMetric: 19.0874 - val_loss: 19.0165 - val_MinusLogProbMetric: 19.0165 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 27/1000
2023-09-27 13:10:12.198 
Epoch 27/1000 
	 loss: 18.9886, MinusLogProbMetric: 18.9886, val_loss: 18.9994, val_MinusLogProbMetric: 18.9994

Epoch 27: val_loss improved from 19.01646 to 18.99942, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 40s - loss: 18.9886 - MinusLogProbMetric: 18.9886 - val_loss: 18.9994 - val_MinusLogProbMetric: 18.9994 - lr: 0.0010 - 40s/epoch - 206ms/step
Epoch 28/1000
2023-09-27 13:10:54.000 
Epoch 28/1000 
	 loss: 19.0016, MinusLogProbMetric: 19.0016, val_loss: 18.9841, val_MinusLogProbMetric: 18.9841

Epoch 28: val_loss improved from 18.99942 to 18.98413, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 42s - loss: 19.0016 - MinusLogProbMetric: 19.0016 - val_loss: 18.9841 - val_MinusLogProbMetric: 18.9841 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 29/1000
2023-09-27 13:11:35.080 
Epoch 29/1000 
	 loss: 18.9021, MinusLogProbMetric: 18.9021, val_loss: 18.6611, val_MinusLogProbMetric: 18.6611

Epoch 29: val_loss improved from 18.98413 to 18.66109, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 41s - loss: 18.9021 - MinusLogProbMetric: 18.9021 - val_loss: 18.6611 - val_MinusLogProbMetric: 18.6611 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 30/1000
2023-09-27 13:12:15.948 
Epoch 30/1000 
	 loss: 18.8359, MinusLogProbMetric: 18.8359, val_loss: 18.9474, val_MinusLogProbMetric: 18.9474

Epoch 30: val_loss did not improve from 18.66109
196/196 - 40s - loss: 18.8359 - MinusLogProbMetric: 18.8359 - val_loss: 18.9474 - val_MinusLogProbMetric: 18.9474 - lr: 0.0010 - 40s/epoch - 205ms/step
Epoch 31/1000
2023-09-27 13:12:56.233 
Epoch 31/1000 
	 loss: 19.0027, MinusLogProbMetric: 19.0027, val_loss: 19.2915, val_MinusLogProbMetric: 19.2915

Epoch 31: val_loss did not improve from 18.66109
196/196 - 40s - loss: 19.0027 - MinusLogProbMetric: 19.0027 - val_loss: 19.2915 - val_MinusLogProbMetric: 19.2915 - lr: 0.0010 - 40s/epoch - 206ms/step
Epoch 32/1000
2023-09-27 13:13:36.431 
Epoch 32/1000 
	 loss: 18.7363, MinusLogProbMetric: 18.7363, val_loss: 18.9195, val_MinusLogProbMetric: 18.9195

Epoch 32: val_loss did not improve from 18.66109
196/196 - 40s - loss: 18.7363 - MinusLogProbMetric: 18.7363 - val_loss: 18.9195 - val_MinusLogProbMetric: 18.9195 - lr: 0.0010 - 40s/epoch - 205ms/step
Epoch 33/1000
2023-09-27 13:14:16.456 
Epoch 33/1000 
	 loss: 18.8111, MinusLogProbMetric: 18.8111, val_loss: 19.1578, val_MinusLogProbMetric: 19.1578

Epoch 33: val_loss did not improve from 18.66109
196/196 - 40s - loss: 18.8111 - MinusLogProbMetric: 18.8111 - val_loss: 19.1578 - val_MinusLogProbMetric: 19.1578 - lr: 0.0010 - 40s/epoch - 204ms/step
Epoch 34/1000
2023-09-27 13:14:56.357 
Epoch 34/1000 
	 loss: 18.5949, MinusLogProbMetric: 18.5949, val_loss: 19.4599, val_MinusLogProbMetric: 19.4599

Epoch 34: val_loss did not improve from 18.66109
196/196 - 40s - loss: 18.5949 - MinusLogProbMetric: 18.5949 - val_loss: 19.4599 - val_MinusLogProbMetric: 19.4599 - lr: 0.0010 - 40s/epoch - 204ms/step
Epoch 35/1000
2023-09-27 13:15:37.210 
Epoch 35/1000 
	 loss: 18.6381, MinusLogProbMetric: 18.6381, val_loss: 18.7464, val_MinusLogProbMetric: 18.7464

Epoch 35: val_loss did not improve from 18.66109
196/196 - 41s - loss: 18.6381 - MinusLogProbMetric: 18.6381 - val_loss: 18.7464 - val_MinusLogProbMetric: 18.7464 - lr: 0.0010 - 41s/epoch - 208ms/step
Epoch 36/1000
2023-09-27 13:16:17.959 
Epoch 36/1000 
	 loss: 18.6484, MinusLogProbMetric: 18.6484, val_loss: 19.0011, val_MinusLogProbMetric: 19.0011

Epoch 36: val_loss did not improve from 18.66109
196/196 - 41s - loss: 18.6484 - MinusLogProbMetric: 18.6484 - val_loss: 19.0011 - val_MinusLogProbMetric: 19.0011 - lr: 0.0010 - 41s/epoch - 208ms/step
Epoch 37/1000
2023-09-27 13:16:57.724 
Epoch 37/1000 
	 loss: 18.5080, MinusLogProbMetric: 18.5080, val_loss: 20.9038, val_MinusLogProbMetric: 20.9038

Epoch 37: val_loss did not improve from 18.66109
196/196 - 40s - loss: 18.5080 - MinusLogProbMetric: 18.5080 - val_loss: 20.9038 - val_MinusLogProbMetric: 20.9038 - lr: 0.0010 - 40s/epoch - 203ms/step
Epoch 38/1000
2023-09-27 13:17:36.990 
Epoch 38/1000 
	 loss: 18.6961, MinusLogProbMetric: 18.6961, val_loss: 18.7216, val_MinusLogProbMetric: 18.7216

Epoch 38: val_loss did not improve from 18.66109
196/196 - 39s - loss: 18.6961 - MinusLogProbMetric: 18.6961 - val_loss: 18.7216 - val_MinusLogProbMetric: 18.7216 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 39/1000
2023-09-27 13:18:16.771 
Epoch 39/1000 
	 loss: 18.6175, MinusLogProbMetric: 18.6175, val_loss: 18.5813, val_MinusLogProbMetric: 18.5813

Epoch 39: val_loss improved from 18.66109 to 18.58132, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 41s - loss: 18.6175 - MinusLogProbMetric: 18.6175 - val_loss: 18.5813 - val_MinusLogProbMetric: 18.5813 - lr: 0.0010 - 41s/epoch - 207ms/step
Epoch 40/1000
2023-09-27 13:18:57.651 
Epoch 40/1000 
	 loss: 18.4307, MinusLogProbMetric: 18.4307, val_loss: 18.5206, val_MinusLogProbMetric: 18.5206

Epoch 40: val_loss improved from 18.58132 to 18.52062, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 41s - loss: 18.4307 - MinusLogProbMetric: 18.4307 - val_loss: 18.5206 - val_MinusLogProbMetric: 18.5206 - lr: 0.0010 - 41s/epoch - 208ms/step
Epoch 41/1000
2023-09-27 13:19:38.289 
Epoch 41/1000 
	 loss: 18.4308, MinusLogProbMetric: 18.4308, val_loss: 18.7237, val_MinusLogProbMetric: 18.7237

Epoch 41: val_loss did not improve from 18.52062
196/196 - 40s - loss: 18.4308 - MinusLogProbMetric: 18.4308 - val_loss: 18.7237 - val_MinusLogProbMetric: 18.7237 - lr: 0.0010 - 40s/epoch - 204ms/step
Epoch 42/1000
2023-09-27 13:20:18.444 
Epoch 42/1000 
	 loss: 18.3250, MinusLogProbMetric: 18.3250, val_loss: 18.7866, val_MinusLogProbMetric: 18.7866

Epoch 42: val_loss did not improve from 18.52062
196/196 - 40s - loss: 18.3250 - MinusLogProbMetric: 18.3250 - val_loss: 18.7866 - val_MinusLogProbMetric: 18.7866 - lr: 0.0010 - 40s/epoch - 205ms/step
Epoch 43/1000
2023-09-27 13:20:58.907 
Epoch 43/1000 
	 loss: 18.3860, MinusLogProbMetric: 18.3860, val_loss: 18.6715, val_MinusLogProbMetric: 18.6715

Epoch 43: val_loss did not improve from 18.52062
196/196 - 40s - loss: 18.3860 - MinusLogProbMetric: 18.3860 - val_loss: 18.6715 - val_MinusLogProbMetric: 18.6715 - lr: 0.0010 - 40s/epoch - 206ms/step
Epoch 44/1000
2023-09-27 13:21:39.516 
Epoch 44/1000 
	 loss: 18.3810, MinusLogProbMetric: 18.3810, val_loss: 18.8415, val_MinusLogProbMetric: 18.8415

Epoch 44: val_loss did not improve from 18.52062
196/196 - 41s - loss: 18.3810 - MinusLogProbMetric: 18.3810 - val_loss: 18.8415 - val_MinusLogProbMetric: 18.8415 - lr: 0.0010 - 41s/epoch - 207ms/step
Epoch 45/1000
2023-09-27 13:22:21.123 
Epoch 45/1000 
	 loss: 18.3169, MinusLogProbMetric: 18.3169, val_loss: 18.6534, val_MinusLogProbMetric: 18.6534

Epoch 45: val_loss did not improve from 18.52062
196/196 - 42s - loss: 18.3169 - MinusLogProbMetric: 18.3169 - val_loss: 18.6534 - val_MinusLogProbMetric: 18.6534 - lr: 0.0010 - 42s/epoch - 212ms/step
Epoch 46/1000
2023-09-27 13:23:01.654 
Epoch 46/1000 
	 loss: 18.3843, MinusLogProbMetric: 18.3843, val_loss: 19.0939, val_MinusLogProbMetric: 19.0939

Epoch 46: val_loss did not improve from 18.52062
196/196 - 41s - loss: 18.3843 - MinusLogProbMetric: 18.3843 - val_loss: 19.0939 - val_MinusLogProbMetric: 19.0939 - lr: 0.0010 - 41s/epoch - 207ms/step
Epoch 47/1000
2023-09-27 13:23:42.265 
Epoch 47/1000 
	 loss: 18.3649, MinusLogProbMetric: 18.3649, val_loss: 18.8220, val_MinusLogProbMetric: 18.8220

Epoch 47: val_loss did not improve from 18.52062
196/196 - 41s - loss: 18.3649 - MinusLogProbMetric: 18.3649 - val_loss: 18.8220 - val_MinusLogProbMetric: 18.8220 - lr: 0.0010 - 41s/epoch - 207ms/step
Epoch 48/1000
2023-09-27 13:24:22.513 
Epoch 48/1000 
	 loss: 18.2774, MinusLogProbMetric: 18.2774, val_loss: 19.0197, val_MinusLogProbMetric: 19.0197

Epoch 48: val_loss did not improve from 18.52062
196/196 - 40s - loss: 18.2774 - MinusLogProbMetric: 18.2774 - val_loss: 19.0197 - val_MinusLogProbMetric: 19.0197 - lr: 0.0010 - 40s/epoch - 205ms/step
Epoch 49/1000
2023-09-27 13:25:02.371 
Epoch 49/1000 
	 loss: 18.2246, MinusLogProbMetric: 18.2246, val_loss: 17.9609, val_MinusLogProbMetric: 17.9609

Epoch 49: val_loss improved from 18.52062 to 17.96089, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 41s - loss: 18.2246 - MinusLogProbMetric: 18.2246 - val_loss: 17.9609 - val_MinusLogProbMetric: 17.9609 - lr: 0.0010 - 41s/epoch - 208ms/step
Epoch 50/1000
2023-09-27 13:25:43.104 
Epoch 50/1000 
	 loss: 18.0718, MinusLogProbMetric: 18.0718, val_loss: 18.1524, val_MinusLogProbMetric: 18.1524

Epoch 50: val_loss did not improve from 17.96089
196/196 - 40s - loss: 18.0718 - MinusLogProbMetric: 18.0718 - val_loss: 18.1524 - val_MinusLogProbMetric: 18.1524 - lr: 0.0010 - 40s/epoch - 204ms/step
Epoch 51/1000
2023-09-27 13:26:23.353 
Epoch 51/1000 
	 loss: 18.1649, MinusLogProbMetric: 18.1649, val_loss: 20.3388, val_MinusLogProbMetric: 20.3388

Epoch 51: val_loss did not improve from 17.96089
196/196 - 40s - loss: 18.1649 - MinusLogProbMetric: 18.1649 - val_loss: 20.3388 - val_MinusLogProbMetric: 20.3388 - lr: 0.0010 - 40s/epoch - 205ms/step
Epoch 52/1000
2023-09-27 13:27:03.063 
Epoch 52/1000 
	 loss: 18.3344, MinusLogProbMetric: 18.3344, val_loss: 18.0767, val_MinusLogProbMetric: 18.0767

Epoch 52: val_loss did not improve from 17.96089
196/196 - 40s - loss: 18.3344 - MinusLogProbMetric: 18.3344 - val_loss: 18.0767 - val_MinusLogProbMetric: 18.0767 - lr: 0.0010 - 40s/epoch - 203ms/step
Epoch 53/1000
2023-09-27 13:27:43.648 
Epoch 53/1000 
	 loss: 18.0421, MinusLogProbMetric: 18.0421, val_loss: 19.5049, val_MinusLogProbMetric: 19.5049

Epoch 53: val_loss did not improve from 17.96089
196/196 - 41s - loss: 18.0421 - MinusLogProbMetric: 18.0421 - val_loss: 19.5049 - val_MinusLogProbMetric: 19.5049 - lr: 0.0010 - 41s/epoch - 207ms/step
Epoch 54/1000
2023-09-27 13:28:23.677 
Epoch 54/1000 
	 loss: 18.2235, MinusLogProbMetric: 18.2235, val_loss: 20.1488, val_MinusLogProbMetric: 20.1488

Epoch 54: val_loss did not improve from 17.96089
196/196 - 40s - loss: 18.2235 - MinusLogProbMetric: 18.2235 - val_loss: 20.1488 - val_MinusLogProbMetric: 20.1488 - lr: 0.0010 - 40s/epoch - 204ms/step
Epoch 55/1000
2023-09-27 13:29:03.108 
Epoch 55/1000 
	 loss: 18.0128, MinusLogProbMetric: 18.0128, val_loss: 18.0410, val_MinusLogProbMetric: 18.0410

Epoch 55: val_loss did not improve from 17.96089
196/196 - 39s - loss: 18.0128 - MinusLogProbMetric: 18.0128 - val_loss: 18.0410 - val_MinusLogProbMetric: 18.0410 - lr: 0.0010 - 39s/epoch - 201ms/step
Epoch 56/1000
2023-09-27 13:29:43.713 
Epoch 56/1000 
	 loss: 18.0192, MinusLogProbMetric: 18.0192, val_loss: 18.4198, val_MinusLogProbMetric: 18.4198

Epoch 56: val_loss did not improve from 17.96089
196/196 - 41s - loss: 18.0192 - MinusLogProbMetric: 18.0192 - val_loss: 18.4198 - val_MinusLogProbMetric: 18.4198 - lr: 0.0010 - 41s/epoch - 207ms/step
Epoch 57/1000
2023-09-27 13:30:23.705 
Epoch 57/1000 
	 loss: 18.1316, MinusLogProbMetric: 18.1316, val_loss: 17.9520, val_MinusLogProbMetric: 17.9520

Epoch 57: val_loss improved from 17.96089 to 17.95197, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 41s - loss: 18.1316 - MinusLogProbMetric: 18.1316 - val_loss: 17.9520 - val_MinusLogProbMetric: 17.9520 - lr: 0.0010 - 41s/epoch - 208ms/step
Epoch 58/1000
2023-09-27 13:31:05.125 
Epoch 58/1000 
	 loss: 17.9555, MinusLogProbMetric: 17.9555, val_loss: 18.0978, val_MinusLogProbMetric: 18.0978

Epoch 58: val_loss did not improve from 17.95197
196/196 - 41s - loss: 17.9555 - MinusLogProbMetric: 17.9555 - val_loss: 18.0978 - val_MinusLogProbMetric: 18.0978 - lr: 0.0010 - 41s/epoch - 207ms/step
Epoch 59/1000
2023-09-27 13:31:45.275 
Epoch 59/1000 
	 loss: 17.9849, MinusLogProbMetric: 17.9849, val_loss: 18.2267, val_MinusLogProbMetric: 18.2267

Epoch 59: val_loss did not improve from 17.95197
196/196 - 40s - loss: 17.9849 - MinusLogProbMetric: 17.9849 - val_loss: 18.2267 - val_MinusLogProbMetric: 18.2267 - lr: 0.0010 - 40s/epoch - 205ms/step
Epoch 60/1000
2023-09-27 13:32:25.775 
Epoch 60/1000 
	 loss: 17.8695, MinusLogProbMetric: 17.8695, val_loss: 18.1700, val_MinusLogProbMetric: 18.1700

Epoch 60: val_loss did not improve from 17.95197
196/196 - 40s - loss: 17.8695 - MinusLogProbMetric: 17.8695 - val_loss: 18.1700 - val_MinusLogProbMetric: 18.1700 - lr: 0.0010 - 40s/epoch - 207ms/step
Epoch 61/1000
2023-09-27 13:33:06.064 
Epoch 61/1000 
	 loss: 17.8719, MinusLogProbMetric: 17.8719, val_loss: 17.7858, val_MinusLogProbMetric: 17.7858

Epoch 61: val_loss improved from 17.95197 to 17.78579, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 41s - loss: 17.8719 - MinusLogProbMetric: 17.8719 - val_loss: 17.7858 - val_MinusLogProbMetric: 17.7858 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 62/1000
2023-09-27 13:33:47.159 
Epoch 62/1000 
	 loss: 17.9662, MinusLogProbMetric: 17.9662, val_loss: 18.2902, val_MinusLogProbMetric: 18.2902

Epoch 62: val_loss did not improve from 17.78579
196/196 - 40s - loss: 17.9662 - MinusLogProbMetric: 17.9662 - val_loss: 18.2902 - val_MinusLogProbMetric: 18.2902 - lr: 0.0010 - 40s/epoch - 205ms/step
Epoch 63/1000
2023-09-27 13:34:26.438 
Epoch 63/1000 
	 loss: 18.0849, MinusLogProbMetric: 18.0849, val_loss: 17.8012, val_MinusLogProbMetric: 17.8012

Epoch 63: val_loss did not improve from 17.78579
196/196 - 39s - loss: 18.0849 - MinusLogProbMetric: 18.0849 - val_loss: 17.8012 - val_MinusLogProbMetric: 17.8012 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 64/1000
2023-09-27 13:35:06.508 
Epoch 64/1000 
	 loss: 17.8428, MinusLogProbMetric: 17.8428, val_loss: 18.4997, val_MinusLogProbMetric: 18.4997

Epoch 64: val_loss did not improve from 17.78579
196/196 - 40s - loss: 17.8428 - MinusLogProbMetric: 17.8428 - val_loss: 18.4997 - val_MinusLogProbMetric: 18.4997 - lr: 0.0010 - 40s/epoch - 204ms/step
Epoch 65/1000
2023-09-27 13:35:47.553 
Epoch 65/1000 
	 loss: 17.9602, MinusLogProbMetric: 17.9602, val_loss: 17.9563, val_MinusLogProbMetric: 17.9563

Epoch 65: val_loss did not improve from 17.78579
196/196 - 41s - loss: 17.9602 - MinusLogProbMetric: 17.9602 - val_loss: 17.9563 - val_MinusLogProbMetric: 17.9563 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 66/1000
2023-09-27 13:36:27.606 
Epoch 66/1000 
	 loss: 17.9485, MinusLogProbMetric: 17.9485, val_loss: 17.5533, val_MinusLogProbMetric: 17.5533

Epoch 66: val_loss improved from 17.78579 to 17.55334, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 41s - loss: 17.9485 - MinusLogProbMetric: 17.9485 - val_loss: 17.5533 - val_MinusLogProbMetric: 17.5533 - lr: 0.0010 - 41s/epoch - 208ms/step
Epoch 67/1000
2023-09-27 13:37:09.368 
Epoch 67/1000 
	 loss: 17.8474, MinusLogProbMetric: 17.8474, val_loss: 17.7911, val_MinusLogProbMetric: 17.7911

Epoch 67: val_loss did not improve from 17.55334
196/196 - 41s - loss: 17.8474 - MinusLogProbMetric: 17.8474 - val_loss: 17.7911 - val_MinusLogProbMetric: 17.7911 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 68/1000
2023-09-27 13:37:49.264 
Epoch 68/1000 
	 loss: 17.9567, MinusLogProbMetric: 17.9567, val_loss: 18.1763, val_MinusLogProbMetric: 18.1763

Epoch 68: val_loss did not improve from 17.55334
196/196 - 40s - loss: 17.9567 - MinusLogProbMetric: 17.9567 - val_loss: 18.1763 - val_MinusLogProbMetric: 18.1763 - lr: 0.0010 - 40s/epoch - 204ms/step
Epoch 69/1000
2023-09-27 13:38:29.636 
Epoch 69/1000 
	 loss: 17.8282, MinusLogProbMetric: 17.8282, val_loss: 17.7528, val_MinusLogProbMetric: 17.7528

Epoch 69: val_loss did not improve from 17.55334
196/196 - 40s - loss: 17.8282 - MinusLogProbMetric: 17.8282 - val_loss: 17.7528 - val_MinusLogProbMetric: 17.7528 - lr: 0.0010 - 40s/epoch - 206ms/step
Epoch 70/1000
2023-09-27 13:39:09.917 
Epoch 70/1000 
	 loss: 17.9748, MinusLogProbMetric: 17.9748, val_loss: 17.8644, val_MinusLogProbMetric: 17.8644

Epoch 70: val_loss did not improve from 17.55334
196/196 - 40s - loss: 17.9748 - MinusLogProbMetric: 17.9748 - val_loss: 17.8644 - val_MinusLogProbMetric: 17.8644 - lr: 0.0010 - 40s/epoch - 205ms/step
Epoch 71/1000
2023-09-27 13:39:51.156 
Epoch 71/1000 
	 loss: 17.7747, MinusLogProbMetric: 17.7747, val_loss: 17.9378, val_MinusLogProbMetric: 17.9378

Epoch 71: val_loss did not improve from 17.55334
196/196 - 41s - loss: 17.7747 - MinusLogProbMetric: 17.7747 - val_loss: 17.9378 - val_MinusLogProbMetric: 17.9378 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 72/1000
2023-09-27 13:40:31.316 
Epoch 72/1000 
	 loss: 17.8989, MinusLogProbMetric: 17.8989, val_loss: 18.9461, val_MinusLogProbMetric: 18.9461

Epoch 72: val_loss did not improve from 17.55334
196/196 - 40s - loss: 17.8989 - MinusLogProbMetric: 17.8989 - val_loss: 18.9461 - val_MinusLogProbMetric: 18.9461 - lr: 0.0010 - 40s/epoch - 205ms/step
Epoch 73/1000
2023-09-27 13:41:12.219 
Epoch 73/1000 
	 loss: 17.8329, MinusLogProbMetric: 17.8329, val_loss: 18.0902, val_MinusLogProbMetric: 18.0902

Epoch 73: val_loss did not improve from 17.55334
196/196 - 41s - loss: 17.8329 - MinusLogProbMetric: 17.8329 - val_loss: 18.0902 - val_MinusLogProbMetric: 18.0902 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 74/1000
2023-09-27 13:41:52.124 
Epoch 74/1000 
	 loss: 17.8302, MinusLogProbMetric: 17.8302, val_loss: 18.1719, val_MinusLogProbMetric: 18.1719

Epoch 74: val_loss did not improve from 17.55334
196/196 - 40s - loss: 17.8302 - MinusLogProbMetric: 17.8302 - val_loss: 18.1719 - val_MinusLogProbMetric: 18.1719 - lr: 0.0010 - 40s/epoch - 204ms/step
Epoch 75/1000
2023-09-27 13:42:32.566 
Epoch 75/1000 
	 loss: 17.7810, MinusLogProbMetric: 17.7810, val_loss: 18.0340, val_MinusLogProbMetric: 18.0340

Epoch 75: val_loss did not improve from 17.55334
196/196 - 40s - loss: 17.7810 - MinusLogProbMetric: 17.7810 - val_loss: 18.0340 - val_MinusLogProbMetric: 18.0340 - lr: 0.0010 - 40s/epoch - 206ms/step
Epoch 76/1000
2023-09-27 13:43:12.689 
Epoch 76/1000 
	 loss: 17.8287, MinusLogProbMetric: 17.8287, val_loss: 17.8791, val_MinusLogProbMetric: 17.8791

Epoch 76: val_loss did not improve from 17.55334
196/196 - 40s - loss: 17.8287 - MinusLogProbMetric: 17.8287 - val_loss: 17.8791 - val_MinusLogProbMetric: 17.8791 - lr: 0.0010 - 40s/epoch - 205ms/step
Epoch 77/1000
2023-09-27 13:43:52.731 
Epoch 77/1000 
	 loss: 17.6363, MinusLogProbMetric: 17.6363, val_loss: 17.8178, val_MinusLogProbMetric: 17.8178

Epoch 77: val_loss did not improve from 17.55334
196/196 - 40s - loss: 17.6363 - MinusLogProbMetric: 17.6363 - val_loss: 17.8178 - val_MinusLogProbMetric: 17.8178 - lr: 0.0010 - 40s/epoch - 204ms/step
Epoch 78/1000
2023-09-27 13:44:31.512 
Epoch 78/1000 
	 loss: 17.8017, MinusLogProbMetric: 17.8017, val_loss: 17.8234, val_MinusLogProbMetric: 17.8234

Epoch 78: val_loss did not improve from 17.55334
196/196 - 39s - loss: 17.8017 - MinusLogProbMetric: 17.8017 - val_loss: 17.8234 - val_MinusLogProbMetric: 17.8234 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 79/1000
2023-09-27 13:45:06.162 
Epoch 79/1000 
	 loss: 17.7630, MinusLogProbMetric: 17.7630, val_loss: 17.5400, val_MinusLogProbMetric: 17.5400

Epoch 79: val_loss improved from 17.55334 to 17.54000, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 35s - loss: 17.7630 - MinusLogProbMetric: 17.7630 - val_loss: 17.5400 - val_MinusLogProbMetric: 17.5400 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 80/1000
2023-09-27 13:45:39.396 
Epoch 80/1000 
	 loss: 17.7672, MinusLogProbMetric: 17.7672, val_loss: 18.5658, val_MinusLogProbMetric: 18.5658

Epoch 80: val_loss did not improve from 17.54000
196/196 - 33s - loss: 17.7672 - MinusLogProbMetric: 17.7672 - val_loss: 18.5658 - val_MinusLogProbMetric: 18.5658 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 81/1000
2023-09-27 13:46:14.288 
Epoch 81/1000 
	 loss: 17.7739, MinusLogProbMetric: 17.7739, val_loss: 18.5393, val_MinusLogProbMetric: 18.5393

Epoch 81: val_loss did not improve from 17.54000
196/196 - 35s - loss: 17.7739 - MinusLogProbMetric: 17.7739 - val_loss: 18.5393 - val_MinusLogProbMetric: 18.5393 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 82/1000
2023-09-27 13:46:53.557 
Epoch 82/1000 
	 loss: 17.7596, MinusLogProbMetric: 17.7596, val_loss: 17.9787, val_MinusLogProbMetric: 17.9787

Epoch 82: val_loss did not improve from 17.54000
196/196 - 39s - loss: 17.7596 - MinusLogProbMetric: 17.7596 - val_loss: 17.9787 - val_MinusLogProbMetric: 17.9787 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 83/1000
2023-09-27 13:47:33.152 
Epoch 83/1000 
	 loss: 17.6687, MinusLogProbMetric: 17.6687, val_loss: 18.2701, val_MinusLogProbMetric: 18.2701

Epoch 83: val_loss did not improve from 17.54000
196/196 - 40s - loss: 17.6687 - MinusLogProbMetric: 17.6687 - val_loss: 18.2701 - val_MinusLogProbMetric: 18.2701 - lr: 0.0010 - 40s/epoch - 202ms/step
Epoch 84/1000
2023-09-27 13:48:12.452 
Epoch 84/1000 
	 loss: 17.7187, MinusLogProbMetric: 17.7187, val_loss: 17.6739, val_MinusLogProbMetric: 17.6739

Epoch 84: val_loss did not improve from 17.54000
196/196 - 39s - loss: 17.7187 - MinusLogProbMetric: 17.7187 - val_loss: 17.6739 - val_MinusLogProbMetric: 17.6739 - lr: 0.0010 - 39s/epoch - 201ms/step
Epoch 85/1000
2023-09-27 13:48:52.493 
Epoch 85/1000 
	 loss: 17.6251, MinusLogProbMetric: 17.6251, val_loss: 17.7342, val_MinusLogProbMetric: 17.7342

Epoch 85: val_loss did not improve from 17.54000
196/196 - 40s - loss: 17.6251 - MinusLogProbMetric: 17.6251 - val_loss: 17.7342 - val_MinusLogProbMetric: 17.7342 - lr: 0.0010 - 40s/epoch - 204ms/step
Epoch 86/1000
2023-09-27 13:49:34.490 
Epoch 86/1000 
	 loss: 17.6497, MinusLogProbMetric: 17.6497, val_loss: 17.7399, val_MinusLogProbMetric: 17.7399

Epoch 86: val_loss did not improve from 17.54000
196/196 - 42s - loss: 17.6497 - MinusLogProbMetric: 17.6497 - val_loss: 17.7399 - val_MinusLogProbMetric: 17.7399 - lr: 0.0010 - 42s/epoch - 214ms/step
Epoch 87/1000
2023-09-27 13:50:13.164 
Epoch 87/1000 
	 loss: 17.6322, MinusLogProbMetric: 17.6322, val_loss: 17.8695, val_MinusLogProbMetric: 17.8695

Epoch 87: val_loss did not improve from 17.54000
196/196 - 39s - loss: 17.6322 - MinusLogProbMetric: 17.6322 - val_loss: 17.8695 - val_MinusLogProbMetric: 17.8695 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 88/1000
2023-09-27 13:50:52.137 
Epoch 88/1000 
	 loss: 17.7014, MinusLogProbMetric: 17.7014, val_loss: 18.1023, val_MinusLogProbMetric: 18.1023

Epoch 88: val_loss did not improve from 17.54000
196/196 - 39s - loss: 17.7014 - MinusLogProbMetric: 17.7014 - val_loss: 18.1023 - val_MinusLogProbMetric: 18.1023 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 89/1000
2023-09-27 13:51:31.311 
Epoch 89/1000 
	 loss: 17.5523, MinusLogProbMetric: 17.5523, val_loss: 17.6313, val_MinusLogProbMetric: 17.6313

Epoch 89: val_loss did not improve from 17.54000
196/196 - 39s - loss: 17.5523 - MinusLogProbMetric: 17.5523 - val_loss: 17.6313 - val_MinusLogProbMetric: 17.6313 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 90/1000
2023-09-27 13:52:11.764 
Epoch 90/1000 
	 loss: 17.8172, MinusLogProbMetric: 17.8172, val_loss: 17.4718, val_MinusLogProbMetric: 17.4718

Epoch 90: val_loss improved from 17.54000 to 17.47177, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 41s - loss: 17.8172 - MinusLogProbMetric: 17.8172 - val_loss: 17.4718 - val_MinusLogProbMetric: 17.4718 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 91/1000
2023-09-27 13:52:51.319 
Epoch 91/1000 
	 loss: 17.5290, MinusLogProbMetric: 17.5290, val_loss: 17.3441, val_MinusLogProbMetric: 17.3441

Epoch 91: val_loss improved from 17.47177 to 17.34410, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 39s - loss: 17.5290 - MinusLogProbMetric: 17.5290 - val_loss: 17.3441 - val_MinusLogProbMetric: 17.3441 - lr: 0.0010 - 39s/epoch - 201ms/step
Epoch 92/1000
2023-09-27 13:53:30.601 
Epoch 92/1000 
	 loss: 17.8369, MinusLogProbMetric: 17.8369, val_loss: 17.7348, val_MinusLogProbMetric: 17.7348

Epoch 92: val_loss did not improve from 17.34410
196/196 - 39s - loss: 17.8369 - MinusLogProbMetric: 17.8369 - val_loss: 17.7348 - val_MinusLogProbMetric: 17.7348 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 93/1000
2023-09-27 13:54:09.181 
Epoch 93/1000 
	 loss: 17.5530, MinusLogProbMetric: 17.5530, val_loss: 17.3824, val_MinusLogProbMetric: 17.3824

Epoch 93: val_loss did not improve from 17.34410
196/196 - 39s - loss: 17.5530 - MinusLogProbMetric: 17.5530 - val_loss: 17.3824 - val_MinusLogProbMetric: 17.3824 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 94/1000
2023-09-27 13:54:48.118 
Epoch 94/1000 
	 loss: 17.6432, MinusLogProbMetric: 17.6432, val_loss: 17.6259, val_MinusLogProbMetric: 17.6259

Epoch 94: val_loss did not improve from 17.34410
196/196 - 39s - loss: 17.6432 - MinusLogProbMetric: 17.6432 - val_loss: 17.6259 - val_MinusLogProbMetric: 17.6259 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 95/1000
2023-09-27 13:55:27.107 
Epoch 95/1000 
	 loss: 17.6205, MinusLogProbMetric: 17.6205, val_loss: 17.6226, val_MinusLogProbMetric: 17.6226

Epoch 95: val_loss did not improve from 17.34410
196/196 - 39s - loss: 17.6205 - MinusLogProbMetric: 17.6205 - val_loss: 17.6226 - val_MinusLogProbMetric: 17.6226 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 96/1000
2023-09-27 13:56:06.227 
Epoch 96/1000 
	 loss: 17.5923, MinusLogProbMetric: 17.5923, val_loss: 17.5989, val_MinusLogProbMetric: 17.5989

Epoch 96: val_loss did not improve from 17.34410
196/196 - 39s - loss: 17.5923 - MinusLogProbMetric: 17.5923 - val_loss: 17.5989 - val_MinusLogProbMetric: 17.5989 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 97/1000
2023-09-27 13:56:45.121 
Epoch 97/1000 
	 loss: 17.4703, MinusLogProbMetric: 17.4703, val_loss: 17.8069, val_MinusLogProbMetric: 17.8069

Epoch 97: val_loss did not improve from 17.34410
196/196 - 39s - loss: 17.4703 - MinusLogProbMetric: 17.4703 - val_loss: 17.8069 - val_MinusLogProbMetric: 17.8069 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 98/1000
2023-09-27 13:57:24.110 
Epoch 98/1000 
	 loss: 17.5550, MinusLogProbMetric: 17.5550, val_loss: 17.4374, val_MinusLogProbMetric: 17.4374

Epoch 98: val_loss did not improve from 17.34410
196/196 - 39s - loss: 17.5550 - MinusLogProbMetric: 17.5550 - val_loss: 17.4374 - val_MinusLogProbMetric: 17.4374 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 99/1000
2023-09-27 13:58:03.021 
Epoch 99/1000 
	 loss: 17.4882, MinusLogProbMetric: 17.4882, val_loss: 17.5102, val_MinusLogProbMetric: 17.5102

Epoch 99: val_loss did not improve from 17.34410
196/196 - 39s - loss: 17.4882 - MinusLogProbMetric: 17.4882 - val_loss: 17.5102 - val_MinusLogProbMetric: 17.5102 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 100/1000
2023-09-27 13:58:42.233 
Epoch 100/1000 
	 loss: 17.5278, MinusLogProbMetric: 17.5278, val_loss: 17.4724, val_MinusLogProbMetric: 17.4724

Epoch 100: val_loss did not improve from 17.34410
196/196 - 39s - loss: 17.5278 - MinusLogProbMetric: 17.5278 - val_loss: 17.4724 - val_MinusLogProbMetric: 17.4724 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 101/1000
2023-09-27 13:59:21.203 
Epoch 101/1000 
	 loss: 17.4496, MinusLogProbMetric: 17.4496, val_loss: 17.5496, val_MinusLogProbMetric: 17.5496

Epoch 101: val_loss did not improve from 17.34410
196/196 - 39s - loss: 17.4496 - MinusLogProbMetric: 17.4496 - val_loss: 17.5496 - val_MinusLogProbMetric: 17.5496 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 102/1000
2023-09-27 14:00:00.476 
Epoch 102/1000 
	 loss: 17.4818, MinusLogProbMetric: 17.4818, val_loss: 17.8332, val_MinusLogProbMetric: 17.8332

Epoch 102: val_loss did not improve from 17.34410
196/196 - 39s - loss: 17.4818 - MinusLogProbMetric: 17.4818 - val_loss: 17.8332 - val_MinusLogProbMetric: 17.8332 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 103/1000
2023-09-27 14:00:39.176 
Epoch 103/1000 
	 loss: 17.7142, MinusLogProbMetric: 17.7142, val_loss: 17.6842, val_MinusLogProbMetric: 17.6842

Epoch 103: val_loss did not improve from 17.34410
196/196 - 39s - loss: 17.7142 - MinusLogProbMetric: 17.7142 - val_loss: 17.6842 - val_MinusLogProbMetric: 17.6842 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 104/1000
2023-09-27 14:01:18.425 
Epoch 104/1000 
	 loss: 17.6175, MinusLogProbMetric: 17.6175, val_loss: 17.7321, val_MinusLogProbMetric: 17.7321

Epoch 104: val_loss did not improve from 17.34410
196/196 - 39s - loss: 17.6175 - MinusLogProbMetric: 17.6175 - val_loss: 17.7321 - val_MinusLogProbMetric: 17.7321 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 105/1000
2023-09-27 14:01:57.062 
Epoch 105/1000 
	 loss: 17.4543, MinusLogProbMetric: 17.4543, val_loss: 17.9825, val_MinusLogProbMetric: 17.9825

Epoch 105: val_loss did not improve from 17.34410
196/196 - 39s - loss: 17.4543 - MinusLogProbMetric: 17.4543 - val_loss: 17.9825 - val_MinusLogProbMetric: 17.9825 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 106/1000
2023-09-27 14:02:36.005 
Epoch 106/1000 
	 loss: 17.3986, MinusLogProbMetric: 17.3986, val_loss: 17.4640, val_MinusLogProbMetric: 17.4640

Epoch 106: val_loss did not improve from 17.34410
196/196 - 39s - loss: 17.3986 - MinusLogProbMetric: 17.3986 - val_loss: 17.4640 - val_MinusLogProbMetric: 17.4640 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 107/1000
2023-09-27 14:03:14.471 
Epoch 107/1000 
	 loss: 17.4433, MinusLogProbMetric: 17.4433, val_loss: 17.4781, val_MinusLogProbMetric: 17.4781

Epoch 107: val_loss did not improve from 17.34410
196/196 - 38s - loss: 17.4433 - MinusLogProbMetric: 17.4433 - val_loss: 17.4781 - val_MinusLogProbMetric: 17.4781 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 108/1000
2023-09-27 14:03:53.120 
Epoch 108/1000 
	 loss: 17.4136, MinusLogProbMetric: 17.4136, val_loss: 17.3632, val_MinusLogProbMetric: 17.3632

Epoch 108: val_loss did not improve from 17.34410
196/196 - 39s - loss: 17.4136 - MinusLogProbMetric: 17.4136 - val_loss: 17.3632 - val_MinusLogProbMetric: 17.3632 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 109/1000
2023-09-27 14:04:32.335 
Epoch 109/1000 
	 loss: 17.7414, MinusLogProbMetric: 17.7414, val_loss: 17.5345, val_MinusLogProbMetric: 17.5345

Epoch 109: val_loss did not improve from 17.34410
196/196 - 39s - loss: 17.7414 - MinusLogProbMetric: 17.7414 - val_loss: 17.5345 - val_MinusLogProbMetric: 17.5345 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 110/1000
2023-09-27 14:05:11.119 
Epoch 110/1000 
	 loss: 17.5211, MinusLogProbMetric: 17.5211, val_loss: 17.7247, val_MinusLogProbMetric: 17.7247

Epoch 110: val_loss did not improve from 17.34410
196/196 - 39s - loss: 17.5211 - MinusLogProbMetric: 17.5211 - val_loss: 17.7247 - val_MinusLogProbMetric: 17.7247 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 111/1000
2023-09-27 14:05:49.908 
Epoch 111/1000 
	 loss: 17.3927, MinusLogProbMetric: 17.3927, val_loss: 17.9400, val_MinusLogProbMetric: 17.9400

Epoch 111: val_loss did not improve from 17.34410
196/196 - 39s - loss: 17.3927 - MinusLogProbMetric: 17.3927 - val_loss: 17.9400 - val_MinusLogProbMetric: 17.9400 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 112/1000
2023-09-27 14:06:30.802 
Epoch 112/1000 
	 loss: 17.5131, MinusLogProbMetric: 17.5131, val_loss: 17.3063, val_MinusLogProbMetric: 17.3063

Epoch 112: val_loss improved from 17.34410 to 17.30634, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 42s - loss: 17.5131 - MinusLogProbMetric: 17.5131 - val_loss: 17.3063 - val_MinusLogProbMetric: 17.3063 - lr: 0.0010 - 42s/epoch - 212ms/step
Epoch 113/1000
2023-09-27 14:07:12.022 
Epoch 113/1000 
	 loss: 17.5229, MinusLogProbMetric: 17.5229, val_loss: 17.4284, val_MinusLogProbMetric: 17.4284

Epoch 113: val_loss did not improve from 17.30634
196/196 - 41s - loss: 17.5229 - MinusLogProbMetric: 17.5229 - val_loss: 17.4284 - val_MinusLogProbMetric: 17.4284 - lr: 0.0010 - 41s/epoch - 207ms/step
Epoch 114/1000
2023-09-27 14:07:52.694 
Epoch 114/1000 
	 loss: 17.3302, MinusLogProbMetric: 17.3302, val_loss: 17.2551, val_MinusLogProbMetric: 17.2551

Epoch 114: val_loss improved from 17.30634 to 17.25508, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 41s - loss: 17.3302 - MinusLogProbMetric: 17.3302 - val_loss: 17.2551 - val_MinusLogProbMetric: 17.2551 - lr: 0.0010 - 41s/epoch - 212ms/step
Epoch 115/1000
2023-09-27 14:08:33.676 
Epoch 115/1000 
	 loss: 17.6271, MinusLogProbMetric: 17.6271, val_loss: 17.4760, val_MinusLogProbMetric: 17.4760

Epoch 115: val_loss did not improve from 17.25508
196/196 - 40s - loss: 17.6271 - MinusLogProbMetric: 17.6271 - val_loss: 17.4760 - val_MinusLogProbMetric: 17.4760 - lr: 0.0010 - 40s/epoch - 205ms/step
Epoch 116/1000
2023-09-27 14:09:14.128 
Epoch 116/1000 
	 loss: 17.4474, MinusLogProbMetric: 17.4474, val_loss: 18.1086, val_MinusLogProbMetric: 18.1086

Epoch 116: val_loss did not improve from 17.25508
196/196 - 40s - loss: 17.4474 - MinusLogProbMetric: 17.4474 - val_loss: 18.1086 - val_MinusLogProbMetric: 18.1086 - lr: 0.0010 - 40s/epoch - 206ms/step
Epoch 117/1000
2023-09-27 14:09:54.015 
Epoch 117/1000 
	 loss: 17.3968, MinusLogProbMetric: 17.3968, val_loss: 17.4525, val_MinusLogProbMetric: 17.4525

Epoch 117: val_loss did not improve from 17.25508
196/196 - 40s - loss: 17.3968 - MinusLogProbMetric: 17.3968 - val_loss: 17.4525 - val_MinusLogProbMetric: 17.4525 - lr: 0.0010 - 40s/epoch - 203ms/step
Epoch 118/1000
2023-09-27 14:10:34.293 
Epoch 118/1000 
	 loss: 17.4337, MinusLogProbMetric: 17.4337, val_loss: 17.5883, val_MinusLogProbMetric: 17.5883

Epoch 118: val_loss did not improve from 17.25508
196/196 - 40s - loss: 17.4337 - MinusLogProbMetric: 17.4337 - val_loss: 17.5883 - val_MinusLogProbMetric: 17.5883 - lr: 0.0010 - 40s/epoch - 205ms/step
Epoch 119/1000
2023-09-27 14:11:14.989 
Epoch 119/1000 
	 loss: 17.3915, MinusLogProbMetric: 17.3915, val_loss: 17.8824, val_MinusLogProbMetric: 17.8824

Epoch 119: val_loss did not improve from 17.25508
196/196 - 41s - loss: 17.3915 - MinusLogProbMetric: 17.3915 - val_loss: 17.8824 - val_MinusLogProbMetric: 17.8824 - lr: 0.0010 - 41s/epoch - 208ms/step
Epoch 120/1000
2023-09-27 14:11:55.320 
Epoch 120/1000 
	 loss: 17.3857, MinusLogProbMetric: 17.3857, val_loss: 17.5719, val_MinusLogProbMetric: 17.5719

Epoch 120: val_loss did not improve from 17.25508
196/196 - 40s - loss: 17.3857 - MinusLogProbMetric: 17.3857 - val_loss: 17.5719 - val_MinusLogProbMetric: 17.5719 - lr: 0.0010 - 40s/epoch - 206ms/step
Epoch 121/1000
2023-09-27 14:12:34.999 
Epoch 121/1000 
	 loss: 17.3379, MinusLogProbMetric: 17.3379, val_loss: 18.5056, val_MinusLogProbMetric: 18.5056

Epoch 121: val_loss did not improve from 17.25508
196/196 - 40s - loss: 17.3379 - MinusLogProbMetric: 17.3379 - val_loss: 18.5056 - val_MinusLogProbMetric: 18.5056 - lr: 0.0010 - 40s/epoch - 202ms/step
Epoch 122/1000
2023-09-27 14:13:14.130 
Epoch 122/1000 
	 loss: 17.5206, MinusLogProbMetric: 17.5206, val_loss: 17.4259, val_MinusLogProbMetric: 17.4259

Epoch 122: val_loss did not improve from 17.25508
196/196 - 39s - loss: 17.5206 - MinusLogProbMetric: 17.5206 - val_loss: 17.4259 - val_MinusLogProbMetric: 17.4259 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 123/1000
2023-09-27 14:13:52.758 
Epoch 123/1000 
	 loss: 17.4528, MinusLogProbMetric: 17.4528, val_loss: 17.2417, val_MinusLogProbMetric: 17.2417

Epoch 123: val_loss improved from 17.25508 to 17.24166, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 39s - loss: 17.4528 - MinusLogProbMetric: 17.4528 - val_loss: 17.2417 - val_MinusLogProbMetric: 17.2417 - lr: 0.0010 - 39s/epoch - 201ms/step
Epoch 124/1000
2023-09-27 14:14:32.548 
Epoch 124/1000 
	 loss: 17.3341, MinusLogProbMetric: 17.3341, val_loss: 17.5074, val_MinusLogProbMetric: 17.5074

Epoch 124: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.3341 - MinusLogProbMetric: 17.3341 - val_loss: 17.5074 - val_MinusLogProbMetric: 17.5074 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 125/1000
2023-09-27 14:15:11.648 
Epoch 125/1000 
	 loss: 17.4339, MinusLogProbMetric: 17.4339, val_loss: 17.3276, val_MinusLogProbMetric: 17.3276

Epoch 125: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.4339 - MinusLogProbMetric: 17.4339 - val_loss: 17.3276 - val_MinusLogProbMetric: 17.3276 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 126/1000
2023-09-27 14:15:50.729 
Epoch 126/1000 
	 loss: 17.4468, MinusLogProbMetric: 17.4468, val_loss: 17.4868, val_MinusLogProbMetric: 17.4868

Epoch 126: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.4468 - MinusLogProbMetric: 17.4468 - val_loss: 17.4868 - val_MinusLogProbMetric: 17.4868 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 127/1000
2023-09-27 14:16:29.390 
Epoch 127/1000 
	 loss: 17.4120, MinusLogProbMetric: 17.4120, val_loss: 17.5994, val_MinusLogProbMetric: 17.5994

Epoch 127: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.4120 - MinusLogProbMetric: 17.4120 - val_loss: 17.5994 - val_MinusLogProbMetric: 17.5994 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 128/1000
2023-09-27 14:17:08.667 
Epoch 128/1000 
	 loss: 17.3856, MinusLogProbMetric: 17.3856, val_loss: 17.5882, val_MinusLogProbMetric: 17.5882

Epoch 128: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.3856 - MinusLogProbMetric: 17.3856 - val_loss: 17.5882 - val_MinusLogProbMetric: 17.5882 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 129/1000
2023-09-27 14:17:47.301 
Epoch 129/1000 
	 loss: 17.3432, MinusLogProbMetric: 17.3432, val_loss: 17.4755, val_MinusLogProbMetric: 17.4755

Epoch 129: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.3432 - MinusLogProbMetric: 17.3432 - val_loss: 17.4755 - val_MinusLogProbMetric: 17.4755 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 130/1000
2023-09-27 14:18:26.318 
Epoch 130/1000 
	 loss: 17.4046, MinusLogProbMetric: 17.4046, val_loss: 18.3136, val_MinusLogProbMetric: 18.3136

Epoch 130: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.4046 - MinusLogProbMetric: 17.4046 - val_loss: 18.3136 - val_MinusLogProbMetric: 18.3136 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 131/1000
2023-09-27 14:19:04.723 
Epoch 131/1000 
	 loss: 17.4186, MinusLogProbMetric: 17.4186, val_loss: 17.4467, val_MinusLogProbMetric: 17.4467

Epoch 131: val_loss did not improve from 17.24166
196/196 - 38s - loss: 17.4186 - MinusLogProbMetric: 17.4186 - val_loss: 17.4467 - val_MinusLogProbMetric: 17.4467 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 132/1000
2023-09-27 14:19:43.835 
Epoch 132/1000 
	 loss: 17.2840, MinusLogProbMetric: 17.2840, val_loss: 17.9745, val_MinusLogProbMetric: 17.9745

Epoch 132: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.2840 - MinusLogProbMetric: 17.2840 - val_loss: 17.9745 - val_MinusLogProbMetric: 17.9745 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 133/1000
2023-09-27 14:20:22.581 
Epoch 133/1000 
	 loss: 17.3207, MinusLogProbMetric: 17.3207, val_loss: 17.4110, val_MinusLogProbMetric: 17.4110

Epoch 133: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.3207 - MinusLogProbMetric: 17.3207 - val_loss: 17.4110 - val_MinusLogProbMetric: 17.4110 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 134/1000
2023-09-27 14:21:01.489 
Epoch 134/1000 
	 loss: 17.2709, MinusLogProbMetric: 17.2709, val_loss: 17.2847, val_MinusLogProbMetric: 17.2847

Epoch 134: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.2709 - MinusLogProbMetric: 17.2709 - val_loss: 17.2847 - val_MinusLogProbMetric: 17.2847 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 135/1000
2023-09-27 14:21:40.404 
Epoch 135/1000 
	 loss: 17.4634, MinusLogProbMetric: 17.4634, val_loss: 17.4604, val_MinusLogProbMetric: 17.4604

Epoch 135: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.4634 - MinusLogProbMetric: 17.4634 - val_loss: 17.4604 - val_MinusLogProbMetric: 17.4604 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 136/1000
2023-09-27 14:22:19.065 
Epoch 136/1000 
	 loss: 17.3946, MinusLogProbMetric: 17.3946, val_loss: 17.2853, val_MinusLogProbMetric: 17.2853

Epoch 136: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.3946 - MinusLogProbMetric: 17.3946 - val_loss: 17.2853 - val_MinusLogProbMetric: 17.2853 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 137/1000
2023-09-27 14:22:57.406 
Epoch 137/1000 
	 loss: 17.2537, MinusLogProbMetric: 17.2537, val_loss: 17.9597, val_MinusLogProbMetric: 17.9597

Epoch 137: val_loss did not improve from 17.24166
196/196 - 38s - loss: 17.2537 - MinusLogProbMetric: 17.2537 - val_loss: 17.9597 - val_MinusLogProbMetric: 17.9597 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 138/1000
2023-09-27 14:23:36.257 
Epoch 138/1000 
	 loss: 17.2896, MinusLogProbMetric: 17.2896, val_loss: 17.7107, val_MinusLogProbMetric: 17.7107

Epoch 138: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.2896 - MinusLogProbMetric: 17.2896 - val_loss: 17.7107 - val_MinusLogProbMetric: 17.7107 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 139/1000
2023-09-27 14:24:14.798 
Epoch 139/1000 
	 loss: 17.3271, MinusLogProbMetric: 17.3271, val_loss: 17.3064, val_MinusLogProbMetric: 17.3064

Epoch 139: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.3271 - MinusLogProbMetric: 17.3271 - val_loss: 17.3064 - val_MinusLogProbMetric: 17.3064 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 140/1000
2023-09-27 14:24:54.400 
Epoch 140/1000 
	 loss: 17.2825, MinusLogProbMetric: 17.2825, val_loss: 17.3225, val_MinusLogProbMetric: 17.3225

Epoch 140: val_loss did not improve from 17.24166
196/196 - 40s - loss: 17.2825 - MinusLogProbMetric: 17.2825 - val_loss: 17.3225 - val_MinusLogProbMetric: 17.3225 - lr: 0.0010 - 40s/epoch - 202ms/step
Epoch 141/1000
2023-09-27 14:25:33.542 
Epoch 141/1000 
	 loss: 17.2744, MinusLogProbMetric: 17.2744, val_loss: 17.3407, val_MinusLogProbMetric: 17.3407

Epoch 141: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.2744 - MinusLogProbMetric: 17.2744 - val_loss: 17.3407 - val_MinusLogProbMetric: 17.3407 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 142/1000
2023-09-27 14:26:12.565 
Epoch 142/1000 
	 loss: 17.2267, MinusLogProbMetric: 17.2267, val_loss: 18.0477, val_MinusLogProbMetric: 18.0477

Epoch 142: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.2267 - MinusLogProbMetric: 17.2267 - val_loss: 18.0477 - val_MinusLogProbMetric: 18.0477 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 143/1000
2023-09-27 14:26:50.967 
Epoch 143/1000 
	 loss: 17.4168, MinusLogProbMetric: 17.4168, val_loss: 17.3195, val_MinusLogProbMetric: 17.3195

Epoch 143: val_loss did not improve from 17.24166
196/196 - 38s - loss: 17.4168 - MinusLogProbMetric: 17.4168 - val_loss: 17.3195 - val_MinusLogProbMetric: 17.3195 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 144/1000
2023-09-27 14:27:29.557 
Epoch 144/1000 
	 loss: 17.2373, MinusLogProbMetric: 17.2373, val_loss: 17.8851, val_MinusLogProbMetric: 17.8851

Epoch 144: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.2373 - MinusLogProbMetric: 17.2373 - val_loss: 17.8851 - val_MinusLogProbMetric: 17.8851 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 145/1000
2023-09-27 14:28:08.099 
Epoch 145/1000 
	 loss: 17.4987, MinusLogProbMetric: 17.4987, val_loss: 17.6937, val_MinusLogProbMetric: 17.6937

Epoch 145: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.4987 - MinusLogProbMetric: 17.4987 - val_loss: 17.6937 - val_MinusLogProbMetric: 17.6937 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 146/1000
2023-09-27 14:28:47.056 
Epoch 146/1000 
	 loss: 17.3104, MinusLogProbMetric: 17.3104, val_loss: 17.3853, val_MinusLogProbMetric: 17.3853

Epoch 146: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.3104 - MinusLogProbMetric: 17.3104 - val_loss: 17.3853 - val_MinusLogProbMetric: 17.3853 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 147/1000
2023-09-27 14:29:25.806 
Epoch 147/1000 
	 loss: 17.2488, MinusLogProbMetric: 17.2488, val_loss: 17.4062, val_MinusLogProbMetric: 17.4062

Epoch 147: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.2488 - MinusLogProbMetric: 17.2488 - val_loss: 17.4062 - val_MinusLogProbMetric: 17.4062 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 148/1000
2023-09-27 14:30:04.339 
Epoch 148/1000 
	 loss: 17.2012, MinusLogProbMetric: 17.2012, val_loss: 17.6695, val_MinusLogProbMetric: 17.6695

Epoch 148: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.2012 - MinusLogProbMetric: 17.2012 - val_loss: 17.6695 - val_MinusLogProbMetric: 17.6695 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 149/1000
2023-09-27 14:30:42.772 
Epoch 149/1000 
	 loss: 17.3559, MinusLogProbMetric: 17.3559, val_loss: 17.5342, val_MinusLogProbMetric: 17.5342

Epoch 149: val_loss did not improve from 17.24166
196/196 - 38s - loss: 17.3559 - MinusLogProbMetric: 17.3559 - val_loss: 17.5342 - val_MinusLogProbMetric: 17.5342 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 150/1000
2023-09-27 14:31:21.503 
Epoch 150/1000 
	 loss: 17.1976, MinusLogProbMetric: 17.1976, val_loss: 17.2699, val_MinusLogProbMetric: 17.2699

Epoch 150: val_loss did not improve from 17.24166
196/196 - 39s - loss: 17.1976 - MinusLogProbMetric: 17.1976 - val_loss: 17.2699 - val_MinusLogProbMetric: 17.2699 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 151/1000
2023-09-27 14:32:00.318 
Epoch 151/1000 
	 loss: 17.2440, MinusLogProbMetric: 17.2440, val_loss: 17.1801, val_MinusLogProbMetric: 17.1801

Epoch 151: val_loss improved from 17.24166 to 17.18015, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 39s - loss: 17.2440 - MinusLogProbMetric: 17.2440 - val_loss: 17.1801 - val_MinusLogProbMetric: 17.1801 - lr: 0.0010 - 39s/epoch - 201ms/step
Epoch 152/1000
2023-09-27 14:32:39.957 
Epoch 152/1000 
	 loss: 17.2518, MinusLogProbMetric: 17.2518, val_loss: 17.3163, val_MinusLogProbMetric: 17.3163

Epoch 152: val_loss did not improve from 17.18015
196/196 - 39s - loss: 17.2518 - MinusLogProbMetric: 17.2518 - val_loss: 17.3163 - val_MinusLogProbMetric: 17.3163 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 153/1000
2023-09-27 14:33:18.778 
Epoch 153/1000 
	 loss: 17.3078, MinusLogProbMetric: 17.3078, val_loss: 17.4052, val_MinusLogProbMetric: 17.4052

Epoch 153: val_loss did not improve from 17.18015
196/196 - 39s - loss: 17.3078 - MinusLogProbMetric: 17.3078 - val_loss: 17.4052 - val_MinusLogProbMetric: 17.4052 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 154/1000
2023-09-27 14:33:57.760 
Epoch 154/1000 
	 loss: 17.1640, MinusLogProbMetric: 17.1640, val_loss: 18.0974, val_MinusLogProbMetric: 18.0974

Epoch 154: val_loss did not improve from 17.18015
196/196 - 39s - loss: 17.1640 - MinusLogProbMetric: 17.1640 - val_loss: 18.0974 - val_MinusLogProbMetric: 18.0974 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 155/1000
2023-09-27 14:34:36.928 
Epoch 155/1000 
	 loss: 17.2025, MinusLogProbMetric: 17.2025, val_loss: 17.2921, val_MinusLogProbMetric: 17.2921

Epoch 155: val_loss did not improve from 17.18015
196/196 - 39s - loss: 17.2025 - MinusLogProbMetric: 17.2025 - val_loss: 17.2921 - val_MinusLogProbMetric: 17.2921 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 156/1000
2023-09-27 14:35:15.608 
Epoch 156/1000 
	 loss: 17.2389, MinusLogProbMetric: 17.2389, val_loss: 17.1768, val_MinusLogProbMetric: 17.1768

Epoch 156: val_loss improved from 17.18015 to 17.17681, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 39s - loss: 17.2389 - MinusLogProbMetric: 17.2389 - val_loss: 17.1768 - val_MinusLogProbMetric: 17.1768 - lr: 0.0010 - 39s/epoch - 201ms/step
Epoch 157/1000
2023-09-27 14:35:55.285 
Epoch 157/1000 
	 loss: 17.2674, MinusLogProbMetric: 17.2674, val_loss: 17.4421, val_MinusLogProbMetric: 17.4421

Epoch 157: val_loss did not improve from 17.17681
196/196 - 39s - loss: 17.2674 - MinusLogProbMetric: 17.2674 - val_loss: 17.4421 - val_MinusLogProbMetric: 17.4421 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 158/1000
2023-09-27 14:36:34.371 
Epoch 158/1000 
	 loss: 17.1646, MinusLogProbMetric: 17.1646, val_loss: 17.0708, val_MinusLogProbMetric: 17.0708

Epoch 158: val_loss improved from 17.17681 to 17.07080, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 40s - loss: 17.1646 - MinusLogProbMetric: 17.1646 - val_loss: 17.0708 - val_MinusLogProbMetric: 17.0708 - lr: 0.0010 - 40s/epoch - 202ms/step
Epoch 159/1000
2023-09-27 14:37:14.010 
Epoch 159/1000 
	 loss: 17.4275, MinusLogProbMetric: 17.4275, val_loss: 17.6789, val_MinusLogProbMetric: 17.6789

Epoch 159: val_loss did not improve from 17.07080
196/196 - 39s - loss: 17.4275 - MinusLogProbMetric: 17.4275 - val_loss: 17.6789 - val_MinusLogProbMetric: 17.6789 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 160/1000
2023-09-27 14:37:52.543 
Epoch 160/1000 
	 loss: 17.2180, MinusLogProbMetric: 17.2180, val_loss: 17.1800, val_MinusLogProbMetric: 17.1800

Epoch 160: val_loss did not improve from 17.07080
196/196 - 39s - loss: 17.2180 - MinusLogProbMetric: 17.2180 - val_loss: 17.1800 - val_MinusLogProbMetric: 17.1800 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 161/1000
2023-09-27 14:38:31.437 
Epoch 161/1000 
	 loss: 17.2442, MinusLogProbMetric: 17.2442, val_loss: 17.2839, val_MinusLogProbMetric: 17.2839

Epoch 161: val_loss did not improve from 17.07080
196/196 - 39s - loss: 17.2442 - MinusLogProbMetric: 17.2442 - val_loss: 17.2839 - val_MinusLogProbMetric: 17.2839 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 162/1000
2023-09-27 14:39:10.403 
Epoch 162/1000 
	 loss: 17.2364, MinusLogProbMetric: 17.2364, val_loss: 17.2360, val_MinusLogProbMetric: 17.2360

Epoch 162: val_loss did not improve from 17.07080
196/196 - 39s - loss: 17.2364 - MinusLogProbMetric: 17.2364 - val_loss: 17.2360 - val_MinusLogProbMetric: 17.2360 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 163/1000
2023-09-27 14:39:49.051 
Epoch 163/1000 
	 loss: 17.1220, MinusLogProbMetric: 17.1220, val_loss: 17.3164, val_MinusLogProbMetric: 17.3164

Epoch 163: val_loss did not improve from 17.07080
196/196 - 39s - loss: 17.1220 - MinusLogProbMetric: 17.1220 - val_loss: 17.3164 - val_MinusLogProbMetric: 17.3164 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 164/1000
2023-09-27 14:40:27.542 
Epoch 164/1000 
	 loss: 17.2015, MinusLogProbMetric: 17.2015, val_loss: 17.0485, val_MinusLogProbMetric: 17.0485

Epoch 164: val_loss improved from 17.07080 to 17.04855, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 39s - loss: 17.2015 - MinusLogProbMetric: 17.2015 - val_loss: 17.0485 - val_MinusLogProbMetric: 17.0485 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 165/1000
2023-09-27 14:41:07.418 
Epoch 165/1000 
	 loss: 17.1184, MinusLogProbMetric: 17.1184, val_loss: 17.3362, val_MinusLogProbMetric: 17.3362

Epoch 165: val_loss did not improve from 17.04855
196/196 - 39s - loss: 17.1184 - MinusLogProbMetric: 17.1184 - val_loss: 17.3362 - val_MinusLogProbMetric: 17.3362 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 166/1000
2023-09-27 14:41:45.900 
Epoch 166/1000 
	 loss: 17.2361, MinusLogProbMetric: 17.2361, val_loss: 17.1727, val_MinusLogProbMetric: 17.1727

Epoch 166: val_loss did not improve from 17.04855
196/196 - 38s - loss: 17.2361 - MinusLogProbMetric: 17.2361 - val_loss: 17.1727 - val_MinusLogProbMetric: 17.1727 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 167/1000
2023-09-27 14:42:24.460 
Epoch 167/1000 
	 loss: 17.2235, MinusLogProbMetric: 17.2235, val_loss: 17.4125, val_MinusLogProbMetric: 17.4125

Epoch 167: val_loss did not improve from 17.04855
196/196 - 39s - loss: 17.2235 - MinusLogProbMetric: 17.2235 - val_loss: 17.4125 - val_MinusLogProbMetric: 17.4125 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 168/1000
2023-09-27 14:43:03.190 
Epoch 168/1000 
	 loss: 17.1429, MinusLogProbMetric: 17.1429, val_loss: 17.3436, val_MinusLogProbMetric: 17.3436

Epoch 168: val_loss did not improve from 17.04855
196/196 - 39s - loss: 17.1429 - MinusLogProbMetric: 17.1429 - val_loss: 17.3436 - val_MinusLogProbMetric: 17.3436 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 169/1000
2023-09-27 14:43:42.140 
Epoch 169/1000 
	 loss: 17.1778, MinusLogProbMetric: 17.1778, val_loss: 17.2290, val_MinusLogProbMetric: 17.2290

Epoch 169: val_loss did not improve from 17.04855
196/196 - 39s - loss: 17.1778 - MinusLogProbMetric: 17.1778 - val_loss: 17.2290 - val_MinusLogProbMetric: 17.2290 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 170/1000
2023-09-27 14:44:21.179 
Epoch 170/1000 
	 loss: 17.2749, MinusLogProbMetric: 17.2749, val_loss: 17.1905, val_MinusLogProbMetric: 17.1905

Epoch 170: val_loss did not improve from 17.04855
196/196 - 39s - loss: 17.2749 - MinusLogProbMetric: 17.2749 - val_loss: 17.1905 - val_MinusLogProbMetric: 17.1905 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 171/1000
2023-09-27 14:45:00.248 
Epoch 171/1000 
	 loss: 17.0899, MinusLogProbMetric: 17.0899, val_loss: 17.0361, val_MinusLogProbMetric: 17.0361

Epoch 171: val_loss improved from 17.04855 to 17.03607, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 40s - loss: 17.0899 - MinusLogProbMetric: 17.0899 - val_loss: 17.0361 - val_MinusLogProbMetric: 17.0361 - lr: 0.0010 - 40s/epoch - 203ms/step
Epoch 172/1000
2023-09-27 14:45:39.938 
Epoch 172/1000 
	 loss: 17.1859, MinusLogProbMetric: 17.1859, val_loss: 17.2115, val_MinusLogProbMetric: 17.2115

Epoch 172: val_loss did not improve from 17.03607
196/196 - 39s - loss: 17.1859 - MinusLogProbMetric: 17.1859 - val_loss: 17.2115 - val_MinusLogProbMetric: 17.2115 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 173/1000
2023-09-27 14:46:18.787 
Epoch 173/1000 
	 loss: 17.1126, MinusLogProbMetric: 17.1126, val_loss: 19.5427, val_MinusLogProbMetric: 19.5427

Epoch 173: val_loss did not improve from 17.03607
196/196 - 39s - loss: 17.1126 - MinusLogProbMetric: 17.1126 - val_loss: 19.5427 - val_MinusLogProbMetric: 19.5427 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 174/1000
2023-09-27 14:46:57.589 
Epoch 174/1000 
	 loss: 17.3090, MinusLogProbMetric: 17.3090, val_loss: 17.3114, val_MinusLogProbMetric: 17.3114

Epoch 174: val_loss did not improve from 17.03607
196/196 - 39s - loss: 17.3090 - MinusLogProbMetric: 17.3090 - val_loss: 17.3114 - val_MinusLogProbMetric: 17.3114 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 175/1000
2023-09-27 14:47:36.390 
Epoch 175/1000 
	 loss: 17.1275, MinusLogProbMetric: 17.1275, val_loss: 19.5654, val_MinusLogProbMetric: 19.5654

Epoch 175: val_loss did not improve from 17.03607
196/196 - 39s - loss: 17.1275 - MinusLogProbMetric: 17.1275 - val_loss: 19.5654 - val_MinusLogProbMetric: 19.5654 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 176/1000
2023-09-27 14:48:14.865 
Epoch 176/1000 
	 loss: 17.4481, MinusLogProbMetric: 17.4481, val_loss: 17.1627, val_MinusLogProbMetric: 17.1627

Epoch 176: val_loss did not improve from 17.03607
196/196 - 38s - loss: 17.4481 - MinusLogProbMetric: 17.4481 - val_loss: 17.1627 - val_MinusLogProbMetric: 17.1627 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 177/1000
2023-09-27 14:48:53.307 
Epoch 177/1000 
	 loss: 17.1551, MinusLogProbMetric: 17.1551, val_loss: 17.3418, val_MinusLogProbMetric: 17.3418

Epoch 177: val_loss did not improve from 17.03607
196/196 - 38s - loss: 17.1551 - MinusLogProbMetric: 17.1551 - val_loss: 17.3418 - val_MinusLogProbMetric: 17.3418 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 178/1000
2023-09-27 14:49:32.458 
Epoch 178/1000 
	 loss: 17.1112, MinusLogProbMetric: 17.1112, val_loss: 17.8199, val_MinusLogProbMetric: 17.8199

Epoch 178: val_loss did not improve from 17.03607
196/196 - 39s - loss: 17.1112 - MinusLogProbMetric: 17.1112 - val_loss: 17.8199 - val_MinusLogProbMetric: 17.8199 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 179/1000
2023-09-27 14:50:11.292 
Epoch 179/1000 
	 loss: 17.1334, MinusLogProbMetric: 17.1334, val_loss: 17.5003, val_MinusLogProbMetric: 17.5003

Epoch 179: val_loss did not improve from 17.03607
196/196 - 39s - loss: 17.1334 - MinusLogProbMetric: 17.1334 - val_loss: 17.5003 - val_MinusLogProbMetric: 17.5003 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 180/1000
2023-09-27 14:50:49.904 
Epoch 180/1000 
	 loss: 17.2178, MinusLogProbMetric: 17.2178, val_loss: 17.7478, val_MinusLogProbMetric: 17.7478

Epoch 180: val_loss did not improve from 17.03607
196/196 - 39s - loss: 17.2178 - MinusLogProbMetric: 17.2178 - val_loss: 17.7478 - val_MinusLogProbMetric: 17.7478 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 181/1000
2023-09-27 14:51:28.745 
Epoch 181/1000 
	 loss: 17.1897, MinusLogProbMetric: 17.1897, val_loss: 17.1446, val_MinusLogProbMetric: 17.1446

Epoch 181: val_loss did not improve from 17.03607
196/196 - 39s - loss: 17.1897 - MinusLogProbMetric: 17.1897 - val_loss: 17.1446 - val_MinusLogProbMetric: 17.1446 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 182/1000
2023-09-27 14:52:07.464 
Epoch 182/1000 
	 loss: 17.0648, MinusLogProbMetric: 17.0648, val_loss: 17.2125, val_MinusLogProbMetric: 17.2125

Epoch 182: val_loss did not improve from 17.03607
196/196 - 39s - loss: 17.0648 - MinusLogProbMetric: 17.0648 - val_loss: 17.2125 - val_MinusLogProbMetric: 17.2125 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 183/1000
2023-09-27 14:52:46.172 
Epoch 183/1000 
	 loss: 17.2355, MinusLogProbMetric: 17.2355, val_loss: 17.5570, val_MinusLogProbMetric: 17.5570

Epoch 183: val_loss did not improve from 17.03607
196/196 - 39s - loss: 17.2355 - MinusLogProbMetric: 17.2355 - val_loss: 17.5570 - val_MinusLogProbMetric: 17.5570 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 184/1000
2023-09-27 14:53:24.840 
Epoch 184/1000 
	 loss: 17.0791, MinusLogProbMetric: 17.0791, val_loss: 17.1094, val_MinusLogProbMetric: 17.1094

Epoch 184: val_loss did not improve from 17.03607
196/196 - 39s - loss: 17.0791 - MinusLogProbMetric: 17.0791 - val_loss: 17.1094 - val_MinusLogProbMetric: 17.1094 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 185/1000
2023-09-27 14:54:03.590 
Epoch 185/1000 
	 loss: 17.0742, MinusLogProbMetric: 17.0742, val_loss: 17.1821, val_MinusLogProbMetric: 17.1821

Epoch 185: val_loss did not improve from 17.03607
196/196 - 39s - loss: 17.0742 - MinusLogProbMetric: 17.0742 - val_loss: 17.1821 - val_MinusLogProbMetric: 17.1821 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 186/1000
2023-09-27 14:54:41.766 
Epoch 186/1000 
	 loss: 17.1363, MinusLogProbMetric: 17.1363, val_loss: 17.3150, val_MinusLogProbMetric: 17.3150

Epoch 186: val_loss did not improve from 17.03607
196/196 - 38s - loss: 17.1363 - MinusLogProbMetric: 17.1363 - val_loss: 17.3150 - val_MinusLogProbMetric: 17.3150 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 187/1000
2023-09-27 14:55:20.198 
Epoch 187/1000 
	 loss: 17.2170, MinusLogProbMetric: 17.2170, val_loss: 17.2522, val_MinusLogProbMetric: 17.2522

Epoch 187: val_loss did not improve from 17.03607
196/196 - 38s - loss: 17.2170 - MinusLogProbMetric: 17.2170 - val_loss: 17.2522 - val_MinusLogProbMetric: 17.2522 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 188/1000
2023-09-27 14:55:58.599 
Epoch 188/1000 
	 loss: 17.0626, MinusLogProbMetric: 17.0626, val_loss: 17.2170, val_MinusLogProbMetric: 17.2170

Epoch 188: val_loss did not improve from 17.03607
196/196 - 38s - loss: 17.0626 - MinusLogProbMetric: 17.0626 - val_loss: 17.2170 - val_MinusLogProbMetric: 17.2170 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 189/1000
2023-09-27 14:56:37.276 
Epoch 189/1000 
	 loss: 17.1089, MinusLogProbMetric: 17.1089, val_loss: 17.2231, val_MinusLogProbMetric: 17.2231

Epoch 189: val_loss did not improve from 17.03607
196/196 - 39s - loss: 17.1089 - MinusLogProbMetric: 17.1089 - val_loss: 17.2231 - val_MinusLogProbMetric: 17.2231 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 190/1000
2023-09-27 14:57:16.005 
Epoch 190/1000 
	 loss: 17.1334, MinusLogProbMetric: 17.1334, val_loss: 17.2315, val_MinusLogProbMetric: 17.2315

Epoch 190: val_loss did not improve from 17.03607
196/196 - 39s - loss: 17.1334 - MinusLogProbMetric: 17.1334 - val_loss: 17.2315 - val_MinusLogProbMetric: 17.2315 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 191/1000
2023-09-27 14:57:54.553 
Epoch 191/1000 
	 loss: 17.1378, MinusLogProbMetric: 17.1378, val_loss: 17.3108, val_MinusLogProbMetric: 17.3108

Epoch 191: val_loss did not improve from 17.03607
196/196 - 39s - loss: 17.1378 - MinusLogProbMetric: 17.1378 - val_loss: 17.3108 - val_MinusLogProbMetric: 17.3108 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 192/1000
2023-09-27 14:58:33.600 
Epoch 192/1000 
	 loss: 17.1325, MinusLogProbMetric: 17.1325, val_loss: 17.1812, val_MinusLogProbMetric: 17.1812

Epoch 192: val_loss did not improve from 17.03607
196/196 - 39s - loss: 17.1325 - MinusLogProbMetric: 17.1325 - val_loss: 17.1812 - val_MinusLogProbMetric: 17.1812 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 193/1000
2023-09-27 14:59:11.957 
Epoch 193/1000 
	 loss: 17.0309, MinusLogProbMetric: 17.0309, val_loss: 17.1290, val_MinusLogProbMetric: 17.1290

Epoch 193: val_loss did not improve from 17.03607
196/196 - 38s - loss: 17.0309 - MinusLogProbMetric: 17.0309 - val_loss: 17.1290 - val_MinusLogProbMetric: 17.1290 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 194/1000
2023-09-27 14:59:50.294 
Epoch 194/1000 
	 loss: 17.0444, MinusLogProbMetric: 17.0444, val_loss: 17.2432, val_MinusLogProbMetric: 17.2432

Epoch 194: val_loss did not improve from 17.03607
196/196 - 38s - loss: 17.0444 - MinusLogProbMetric: 17.0444 - val_loss: 17.2432 - val_MinusLogProbMetric: 17.2432 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 195/1000
2023-09-27 15:00:28.600 
Epoch 195/1000 
	 loss: 17.1072, MinusLogProbMetric: 17.1072, val_loss: 17.3885, val_MinusLogProbMetric: 17.3885

Epoch 195: val_loss did not improve from 17.03607
196/196 - 38s - loss: 17.1072 - MinusLogProbMetric: 17.1072 - val_loss: 17.3885 - val_MinusLogProbMetric: 17.3885 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 196/1000
2023-09-27 15:01:07.035 
Epoch 196/1000 
	 loss: 17.0207, MinusLogProbMetric: 17.0207, val_loss: 17.2120, val_MinusLogProbMetric: 17.2120

Epoch 196: val_loss did not improve from 17.03607
196/196 - 38s - loss: 17.0207 - MinusLogProbMetric: 17.0207 - val_loss: 17.2120 - val_MinusLogProbMetric: 17.2120 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 197/1000
2023-09-27 15:01:45.532 
Epoch 197/1000 
	 loss: 17.0877, MinusLogProbMetric: 17.0877, val_loss: 17.2497, val_MinusLogProbMetric: 17.2497

Epoch 197: val_loss did not improve from 17.03607
196/196 - 38s - loss: 17.0877 - MinusLogProbMetric: 17.0877 - val_loss: 17.2497 - val_MinusLogProbMetric: 17.2497 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 198/1000
2023-09-27 15:02:24.106 
Epoch 198/1000 
	 loss: 17.0939, MinusLogProbMetric: 17.0939, val_loss: 17.2446, val_MinusLogProbMetric: 17.2446

Epoch 198: val_loss did not improve from 17.03607
196/196 - 39s - loss: 17.0939 - MinusLogProbMetric: 17.0939 - val_loss: 17.2446 - val_MinusLogProbMetric: 17.2446 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 199/1000
2023-09-27 15:03:02.831 
Epoch 199/1000 
	 loss: 17.0182, MinusLogProbMetric: 17.0182, val_loss: 18.2750, val_MinusLogProbMetric: 18.2750

Epoch 199: val_loss did not improve from 17.03607
196/196 - 39s - loss: 17.0182 - MinusLogProbMetric: 17.0182 - val_loss: 18.2750 - val_MinusLogProbMetric: 18.2750 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 200/1000
2023-09-27 15:03:41.360 
Epoch 200/1000 
	 loss: 17.2250, MinusLogProbMetric: 17.2250, val_loss: 17.1318, val_MinusLogProbMetric: 17.1318

Epoch 200: val_loss did not improve from 17.03607
196/196 - 39s - loss: 17.2250 - MinusLogProbMetric: 17.2250 - val_loss: 17.1318 - val_MinusLogProbMetric: 17.1318 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 201/1000
2023-09-27 15:04:19.531 
Epoch 201/1000 
	 loss: 16.9852, MinusLogProbMetric: 16.9852, val_loss: 17.0814, val_MinusLogProbMetric: 17.0814

Epoch 201: val_loss did not improve from 17.03607
196/196 - 38s - loss: 16.9852 - MinusLogProbMetric: 16.9852 - val_loss: 17.0814 - val_MinusLogProbMetric: 17.0814 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 202/1000
2023-09-27 15:04:58.106 
Epoch 202/1000 
	 loss: 17.0987, MinusLogProbMetric: 17.0987, val_loss: 17.1952, val_MinusLogProbMetric: 17.1952

Epoch 202: val_loss did not improve from 17.03607
196/196 - 39s - loss: 17.0987 - MinusLogProbMetric: 17.0987 - val_loss: 17.1952 - val_MinusLogProbMetric: 17.1952 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 203/1000
2023-09-27 15:05:36.101 
Epoch 203/1000 
	 loss: 17.0512, MinusLogProbMetric: 17.0512, val_loss: 17.7736, val_MinusLogProbMetric: 17.7736

Epoch 203: val_loss did not improve from 17.03607
196/196 - 38s - loss: 17.0512 - MinusLogProbMetric: 17.0512 - val_loss: 17.7736 - val_MinusLogProbMetric: 17.7736 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 204/1000
2023-09-27 15:06:14.472 
Epoch 204/1000 
	 loss: 17.0218, MinusLogProbMetric: 17.0218, val_loss: 17.0187, val_MinusLogProbMetric: 17.0187

Epoch 204: val_loss improved from 17.03607 to 17.01871, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 39s - loss: 17.0218 - MinusLogProbMetric: 17.0218 - val_loss: 17.0187 - val_MinusLogProbMetric: 17.0187 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 205/1000
2023-09-27 15:06:53.437 
Epoch 205/1000 
	 loss: 17.0309, MinusLogProbMetric: 17.0309, val_loss: 17.5721, val_MinusLogProbMetric: 17.5721

Epoch 205: val_loss did not improve from 17.01871
196/196 - 38s - loss: 17.0309 - MinusLogProbMetric: 17.0309 - val_loss: 17.5721 - val_MinusLogProbMetric: 17.5721 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 206/1000
2023-09-27 15:07:31.628 
Epoch 206/1000 
	 loss: 17.1327, MinusLogProbMetric: 17.1327, val_loss: 17.1897, val_MinusLogProbMetric: 17.1897

Epoch 206: val_loss did not improve from 17.01871
196/196 - 38s - loss: 17.1327 - MinusLogProbMetric: 17.1327 - val_loss: 17.1897 - val_MinusLogProbMetric: 17.1897 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 207/1000
2023-09-27 15:08:09.989 
Epoch 207/1000 
	 loss: 16.9640, MinusLogProbMetric: 16.9640, val_loss: 17.4260, val_MinusLogProbMetric: 17.4260

Epoch 207: val_loss did not improve from 17.01871
196/196 - 38s - loss: 16.9640 - MinusLogProbMetric: 16.9640 - val_loss: 17.4260 - val_MinusLogProbMetric: 17.4260 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 208/1000
2023-09-27 15:08:48.406 
Epoch 208/1000 
	 loss: 17.0571, MinusLogProbMetric: 17.0571, val_loss: 17.0565, val_MinusLogProbMetric: 17.0565

Epoch 208: val_loss did not improve from 17.01871
196/196 - 38s - loss: 17.0571 - MinusLogProbMetric: 17.0571 - val_loss: 17.0565 - val_MinusLogProbMetric: 17.0565 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 209/1000
2023-09-27 15:09:27.188 
Epoch 209/1000 
	 loss: 17.0112, MinusLogProbMetric: 17.0112, val_loss: 16.9784, val_MinusLogProbMetric: 16.9784

Epoch 209: val_loss improved from 17.01871 to 16.97837, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 40s - loss: 17.0112 - MinusLogProbMetric: 17.0112 - val_loss: 16.9784 - val_MinusLogProbMetric: 16.9784 - lr: 0.0010 - 40s/epoch - 202ms/step
Epoch 210/1000
2023-09-27 15:10:06.567 
Epoch 210/1000 
	 loss: 17.0727, MinusLogProbMetric: 17.0727, val_loss: 17.4467, val_MinusLogProbMetric: 17.4467

Epoch 210: val_loss did not improve from 16.97837
196/196 - 39s - loss: 17.0727 - MinusLogProbMetric: 17.0727 - val_loss: 17.4467 - val_MinusLogProbMetric: 17.4467 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 211/1000
2023-09-27 15:10:44.795 
Epoch 211/1000 
	 loss: 17.0338, MinusLogProbMetric: 17.0338, val_loss: 17.0765, val_MinusLogProbMetric: 17.0765

Epoch 211: val_loss did not improve from 16.97837
196/196 - 38s - loss: 17.0338 - MinusLogProbMetric: 17.0338 - val_loss: 17.0765 - val_MinusLogProbMetric: 17.0765 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 212/1000
2023-09-27 15:11:23.286 
Epoch 212/1000 
	 loss: 16.9988, MinusLogProbMetric: 16.9988, val_loss: 17.3758, val_MinusLogProbMetric: 17.3758

Epoch 212: val_loss did not improve from 16.97837
196/196 - 38s - loss: 16.9988 - MinusLogProbMetric: 16.9988 - val_loss: 17.3758 - val_MinusLogProbMetric: 17.3758 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 213/1000
2023-09-27 15:12:01.686 
Epoch 213/1000 
	 loss: 17.0888, MinusLogProbMetric: 17.0888, val_loss: 17.0919, val_MinusLogProbMetric: 17.0919

Epoch 213: val_loss did not improve from 16.97837
196/196 - 38s - loss: 17.0888 - MinusLogProbMetric: 17.0888 - val_loss: 17.0919 - val_MinusLogProbMetric: 17.0919 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 214/1000
2023-09-27 15:12:39.725 
Epoch 214/1000 
	 loss: 17.1391, MinusLogProbMetric: 17.1391, val_loss: 17.0358, val_MinusLogProbMetric: 17.0358

Epoch 214: val_loss did not improve from 16.97837
196/196 - 38s - loss: 17.1391 - MinusLogProbMetric: 17.1391 - val_loss: 17.0358 - val_MinusLogProbMetric: 17.0358 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 215/1000
2023-09-27 15:13:18.667 
Epoch 215/1000 
	 loss: 17.0660, MinusLogProbMetric: 17.0660, val_loss: 17.2856, val_MinusLogProbMetric: 17.2856

Epoch 215: val_loss did not improve from 16.97837
196/196 - 39s - loss: 17.0660 - MinusLogProbMetric: 17.0660 - val_loss: 17.2856 - val_MinusLogProbMetric: 17.2856 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 216/1000
2023-09-27 15:13:57.117 
Epoch 216/1000 
	 loss: 16.9689, MinusLogProbMetric: 16.9689, val_loss: 17.1124, val_MinusLogProbMetric: 17.1124

Epoch 216: val_loss did not improve from 16.97837
196/196 - 38s - loss: 16.9689 - MinusLogProbMetric: 16.9689 - val_loss: 17.1124 - val_MinusLogProbMetric: 17.1124 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 217/1000
2023-09-27 15:14:35.588 
Epoch 217/1000 
	 loss: 16.9567, MinusLogProbMetric: 16.9567, val_loss: 17.0221, val_MinusLogProbMetric: 17.0221

Epoch 217: val_loss did not improve from 16.97837
196/196 - 38s - loss: 16.9567 - MinusLogProbMetric: 16.9567 - val_loss: 17.0221 - val_MinusLogProbMetric: 17.0221 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 218/1000
2023-09-27 15:15:14.217 
Epoch 218/1000 
	 loss: 16.9694, MinusLogProbMetric: 16.9694, val_loss: 17.4060, val_MinusLogProbMetric: 17.4060

Epoch 218: val_loss did not improve from 16.97837
196/196 - 39s - loss: 16.9694 - MinusLogProbMetric: 16.9694 - val_loss: 17.4060 - val_MinusLogProbMetric: 17.4060 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 219/1000
2023-09-27 15:15:52.813 
Epoch 219/1000 
	 loss: 17.0291, MinusLogProbMetric: 17.0291, val_loss: 17.3078, val_MinusLogProbMetric: 17.3078

Epoch 219: val_loss did not improve from 16.97837
196/196 - 39s - loss: 17.0291 - MinusLogProbMetric: 17.0291 - val_loss: 17.3078 - val_MinusLogProbMetric: 17.3078 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 220/1000
2023-09-27 15:16:31.289 
Epoch 220/1000 
	 loss: 16.9904, MinusLogProbMetric: 16.9904, val_loss: 17.1796, val_MinusLogProbMetric: 17.1796

Epoch 220: val_loss did not improve from 16.97837
196/196 - 38s - loss: 16.9904 - MinusLogProbMetric: 16.9904 - val_loss: 17.1796 - val_MinusLogProbMetric: 17.1796 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 221/1000
2023-09-27 15:17:09.671 
Epoch 221/1000 
	 loss: 17.0968, MinusLogProbMetric: 17.0968, val_loss: 17.1438, val_MinusLogProbMetric: 17.1438

Epoch 221: val_loss did not improve from 16.97837
196/196 - 38s - loss: 17.0968 - MinusLogProbMetric: 17.0968 - val_loss: 17.1438 - val_MinusLogProbMetric: 17.1438 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 222/1000
2023-09-27 15:17:49.018 
Epoch 222/1000 
	 loss: 17.0753, MinusLogProbMetric: 17.0753, val_loss: 17.0518, val_MinusLogProbMetric: 17.0518

Epoch 222: val_loss did not improve from 16.97837
196/196 - 39s - loss: 17.0753 - MinusLogProbMetric: 17.0753 - val_loss: 17.0518 - val_MinusLogProbMetric: 17.0518 - lr: 0.0010 - 39s/epoch - 201ms/step
Epoch 223/1000
2023-09-27 15:18:28.001 
Epoch 223/1000 
	 loss: 17.0489, MinusLogProbMetric: 17.0489, val_loss: 17.0026, val_MinusLogProbMetric: 17.0026

Epoch 223: val_loss did not improve from 16.97837
196/196 - 39s - loss: 17.0489 - MinusLogProbMetric: 17.0489 - val_loss: 17.0026 - val_MinusLogProbMetric: 17.0026 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 224/1000
2023-09-27 15:19:06.751 
Epoch 224/1000 
	 loss: 16.9468, MinusLogProbMetric: 16.9468, val_loss: 17.2171, val_MinusLogProbMetric: 17.2171

Epoch 224: val_loss did not improve from 16.97837
196/196 - 39s - loss: 16.9468 - MinusLogProbMetric: 16.9468 - val_loss: 17.2171 - val_MinusLogProbMetric: 17.2171 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 225/1000
2023-09-27 15:19:45.278 
Epoch 225/1000 
	 loss: 16.9368, MinusLogProbMetric: 16.9368, val_loss: 18.9921, val_MinusLogProbMetric: 18.9921

Epoch 225: val_loss did not improve from 16.97837
196/196 - 39s - loss: 16.9368 - MinusLogProbMetric: 16.9368 - val_loss: 18.9921 - val_MinusLogProbMetric: 18.9921 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 226/1000
2023-09-27 15:20:23.902 
Epoch 226/1000 
	 loss: 17.0407, MinusLogProbMetric: 17.0407, val_loss: 17.0650, val_MinusLogProbMetric: 17.0650

Epoch 226: val_loss did not improve from 16.97837
196/196 - 39s - loss: 17.0407 - MinusLogProbMetric: 17.0407 - val_loss: 17.0650 - val_MinusLogProbMetric: 17.0650 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 227/1000
2023-09-27 15:21:03.417 
Epoch 227/1000 
	 loss: 16.9990, MinusLogProbMetric: 16.9990, val_loss: 16.9601, val_MinusLogProbMetric: 16.9601

Epoch 227: val_loss improved from 16.97837 to 16.96012, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 40s - loss: 16.9990 - MinusLogProbMetric: 16.9990 - val_loss: 16.9601 - val_MinusLogProbMetric: 16.9601 - lr: 0.0010 - 40s/epoch - 205ms/step
Epoch 228/1000
2023-09-27 15:21:42.669 
Epoch 228/1000 
	 loss: 16.9316, MinusLogProbMetric: 16.9316, val_loss: 17.1654, val_MinusLogProbMetric: 17.1654

Epoch 228: val_loss did not improve from 16.96012
196/196 - 39s - loss: 16.9316 - MinusLogProbMetric: 16.9316 - val_loss: 17.1654 - val_MinusLogProbMetric: 17.1654 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 229/1000
2023-09-27 15:22:21.454 
Epoch 229/1000 
	 loss: 16.9875, MinusLogProbMetric: 16.9875, val_loss: 17.2051, val_MinusLogProbMetric: 17.2051

Epoch 229: val_loss did not improve from 16.96012
196/196 - 39s - loss: 16.9875 - MinusLogProbMetric: 16.9875 - val_loss: 17.2051 - val_MinusLogProbMetric: 17.2051 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 230/1000
2023-09-27 15:23:00.125 
Epoch 230/1000 
	 loss: 16.9655, MinusLogProbMetric: 16.9655, val_loss: 17.2294, val_MinusLogProbMetric: 17.2294

Epoch 230: val_loss did not improve from 16.96012
196/196 - 39s - loss: 16.9655 - MinusLogProbMetric: 16.9655 - val_loss: 17.2294 - val_MinusLogProbMetric: 17.2294 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 231/1000
2023-09-27 15:23:38.727 
Epoch 231/1000 
	 loss: 16.9655, MinusLogProbMetric: 16.9655, val_loss: 17.1823, val_MinusLogProbMetric: 17.1823

Epoch 231: val_loss did not improve from 16.96012
196/196 - 39s - loss: 16.9655 - MinusLogProbMetric: 16.9655 - val_loss: 17.1823 - val_MinusLogProbMetric: 17.1823 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 232/1000
2023-09-27 15:24:17.284 
Epoch 232/1000 
	 loss: 17.0892, MinusLogProbMetric: 17.0892, val_loss: 17.2631, val_MinusLogProbMetric: 17.2631

Epoch 232: val_loss did not improve from 16.96012
196/196 - 39s - loss: 17.0892 - MinusLogProbMetric: 17.0892 - val_loss: 17.2631 - val_MinusLogProbMetric: 17.2631 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 233/1000
2023-09-27 15:24:55.930 
Epoch 233/1000 
	 loss: 16.9704, MinusLogProbMetric: 16.9704, val_loss: 17.0377, val_MinusLogProbMetric: 17.0377

Epoch 233: val_loss did not improve from 16.96012
196/196 - 39s - loss: 16.9704 - MinusLogProbMetric: 16.9704 - val_loss: 17.0377 - val_MinusLogProbMetric: 17.0377 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 234/1000
2023-09-27 15:25:34.673 
Epoch 234/1000 
	 loss: 16.9676, MinusLogProbMetric: 16.9676, val_loss: 17.0608, val_MinusLogProbMetric: 17.0608

Epoch 234: val_loss did not improve from 16.96012
196/196 - 39s - loss: 16.9676 - MinusLogProbMetric: 16.9676 - val_loss: 17.0608 - val_MinusLogProbMetric: 17.0608 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 235/1000
2023-09-27 15:26:13.213 
Epoch 235/1000 
	 loss: 17.0007, MinusLogProbMetric: 17.0007, val_loss: 17.7672, val_MinusLogProbMetric: 17.7672

Epoch 235: val_loss did not improve from 16.96012
196/196 - 39s - loss: 17.0007 - MinusLogProbMetric: 17.0007 - val_loss: 17.7672 - val_MinusLogProbMetric: 17.7672 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 236/1000
2023-09-27 15:26:52.036 
Epoch 236/1000 
	 loss: 16.9854, MinusLogProbMetric: 16.9854, val_loss: 17.2856, val_MinusLogProbMetric: 17.2856

Epoch 236: val_loss did not improve from 16.96012
196/196 - 39s - loss: 16.9854 - MinusLogProbMetric: 16.9854 - val_loss: 17.2856 - val_MinusLogProbMetric: 17.2856 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 237/1000
2023-09-27 15:27:30.544 
Epoch 237/1000 
	 loss: 16.9719, MinusLogProbMetric: 16.9719, val_loss: 17.1915, val_MinusLogProbMetric: 17.1915

Epoch 237: val_loss did not improve from 16.96012
196/196 - 39s - loss: 16.9719 - MinusLogProbMetric: 16.9719 - val_loss: 17.1915 - val_MinusLogProbMetric: 17.1915 - lr: 0.0010 - 39s/epoch - 196ms/step
Epoch 238/1000
2023-09-27 15:28:08.965 
Epoch 238/1000 
	 loss: 17.0527, MinusLogProbMetric: 17.0527, val_loss: 17.1023, val_MinusLogProbMetric: 17.1023

Epoch 238: val_loss did not improve from 16.96012
196/196 - 38s - loss: 17.0527 - MinusLogProbMetric: 17.0527 - val_loss: 17.1023 - val_MinusLogProbMetric: 17.1023 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 239/1000
2023-09-27 15:28:47.992 
Epoch 239/1000 
	 loss: 16.9730, MinusLogProbMetric: 16.9730, val_loss: 17.2233, val_MinusLogProbMetric: 17.2233

Epoch 239: val_loss did not improve from 16.96012
196/196 - 39s - loss: 16.9730 - MinusLogProbMetric: 16.9730 - val_loss: 17.2233 - val_MinusLogProbMetric: 17.2233 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 240/1000
2023-09-27 15:29:26.853 
Epoch 240/1000 
	 loss: 17.0500, MinusLogProbMetric: 17.0500, val_loss: 17.1537, val_MinusLogProbMetric: 17.1537

Epoch 240: val_loss did not improve from 16.96012
196/196 - 39s - loss: 17.0500 - MinusLogProbMetric: 17.0500 - val_loss: 17.1537 - val_MinusLogProbMetric: 17.1537 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 241/1000
2023-09-27 15:30:05.726 
Epoch 241/1000 
	 loss: 16.9475, MinusLogProbMetric: 16.9475, val_loss: 17.6901, val_MinusLogProbMetric: 17.6901

Epoch 241: val_loss did not improve from 16.96012
196/196 - 39s - loss: 16.9475 - MinusLogProbMetric: 16.9475 - val_loss: 17.6901 - val_MinusLogProbMetric: 17.6901 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 242/1000
2023-09-27 15:30:44.191 
Epoch 242/1000 
	 loss: 16.9752, MinusLogProbMetric: 16.9752, val_loss: 17.3648, val_MinusLogProbMetric: 17.3648

Epoch 242: val_loss did not improve from 16.96012
196/196 - 38s - loss: 16.9752 - MinusLogProbMetric: 16.9752 - val_loss: 17.3648 - val_MinusLogProbMetric: 17.3648 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 243/1000
2023-09-27 15:31:22.833 
Epoch 243/1000 
	 loss: 16.9510, MinusLogProbMetric: 16.9510, val_loss: 17.1006, val_MinusLogProbMetric: 17.1006

Epoch 243: val_loss did not improve from 16.96012
196/196 - 39s - loss: 16.9510 - MinusLogProbMetric: 16.9510 - val_loss: 17.1006 - val_MinusLogProbMetric: 17.1006 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 244/1000
2023-09-27 15:32:01.763 
Epoch 244/1000 
	 loss: 17.0223, MinusLogProbMetric: 17.0223, val_loss: 17.1541, val_MinusLogProbMetric: 17.1541

Epoch 244: val_loss did not improve from 16.96012
196/196 - 39s - loss: 17.0223 - MinusLogProbMetric: 17.0223 - val_loss: 17.1541 - val_MinusLogProbMetric: 17.1541 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 245/1000
2023-09-27 15:32:40.296 
Epoch 245/1000 
	 loss: 16.8962, MinusLogProbMetric: 16.8962, val_loss: 17.2396, val_MinusLogProbMetric: 17.2396

Epoch 245: val_loss did not improve from 16.96012
196/196 - 39s - loss: 16.8962 - MinusLogProbMetric: 16.8962 - val_loss: 17.2396 - val_MinusLogProbMetric: 17.2396 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 246/1000
2023-09-27 15:33:18.997 
Epoch 246/1000 
	 loss: 16.9185, MinusLogProbMetric: 16.9185, val_loss: 17.0385, val_MinusLogProbMetric: 17.0385

Epoch 246: val_loss did not improve from 16.96012
196/196 - 39s - loss: 16.9185 - MinusLogProbMetric: 16.9185 - val_loss: 17.0385 - val_MinusLogProbMetric: 17.0385 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 247/1000
2023-09-27 15:33:56.182 
Epoch 247/1000 
	 loss: 16.9587, MinusLogProbMetric: 16.9587, val_loss: 17.2317, val_MinusLogProbMetric: 17.2317

Epoch 247: val_loss did not improve from 16.96012
196/196 - 37s - loss: 16.9587 - MinusLogProbMetric: 16.9587 - val_loss: 17.2317 - val_MinusLogProbMetric: 17.2317 - lr: 0.0010 - 37s/epoch - 190ms/step
Epoch 248/1000
2023-09-27 15:34:32.994 
Epoch 248/1000 
	 loss: 16.9505, MinusLogProbMetric: 16.9505, val_loss: 16.9771, val_MinusLogProbMetric: 16.9771

Epoch 248: val_loss did not improve from 16.96012
196/196 - 37s - loss: 16.9505 - MinusLogProbMetric: 16.9505 - val_loss: 16.9771 - val_MinusLogProbMetric: 16.9771 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 249/1000
2023-09-27 15:35:05.047 
Epoch 249/1000 
	 loss: 16.9356, MinusLogProbMetric: 16.9356, val_loss: 17.9934, val_MinusLogProbMetric: 17.9934

Epoch 249: val_loss did not improve from 16.96012
196/196 - 32s - loss: 16.9356 - MinusLogProbMetric: 16.9356 - val_loss: 17.9934 - val_MinusLogProbMetric: 17.9934 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 250/1000
2023-09-27 15:35:36.913 
Epoch 250/1000 
	 loss: 16.9669, MinusLogProbMetric: 16.9669, val_loss: 17.6231, val_MinusLogProbMetric: 17.6231

Epoch 250: val_loss did not improve from 16.96012
196/196 - 32s - loss: 16.9669 - MinusLogProbMetric: 16.9669 - val_loss: 17.6231 - val_MinusLogProbMetric: 17.6231 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 251/1000
2023-09-27 15:36:12.352 
Epoch 251/1000 
	 loss: 16.9889, MinusLogProbMetric: 16.9889, val_loss: 17.1004, val_MinusLogProbMetric: 17.1004

Epoch 251: val_loss did not improve from 16.96012
196/196 - 35s - loss: 16.9889 - MinusLogProbMetric: 16.9889 - val_loss: 17.1004 - val_MinusLogProbMetric: 17.1004 - lr: 0.0010 - 35s/epoch - 181ms/step
Epoch 252/1000
2023-09-27 15:36:49.509 
Epoch 252/1000 
	 loss: 16.9537, MinusLogProbMetric: 16.9537, val_loss: 17.3329, val_MinusLogProbMetric: 17.3329

Epoch 252: val_loss did not improve from 16.96012
196/196 - 37s - loss: 16.9537 - MinusLogProbMetric: 16.9537 - val_loss: 17.3329 - val_MinusLogProbMetric: 17.3329 - lr: 0.0010 - 37s/epoch - 190ms/step
Epoch 253/1000
2023-09-27 15:37:23.323 
Epoch 253/1000 
	 loss: 16.9875, MinusLogProbMetric: 16.9875, val_loss: 17.2603, val_MinusLogProbMetric: 17.2603

Epoch 253: val_loss did not improve from 16.96012
196/196 - 34s - loss: 16.9875 - MinusLogProbMetric: 16.9875 - val_loss: 17.2603 - val_MinusLogProbMetric: 17.2603 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 254/1000
2023-09-27 15:37:55.246 
Epoch 254/1000 
	 loss: 16.8920, MinusLogProbMetric: 16.8920, val_loss: 16.9761, val_MinusLogProbMetric: 16.9761

Epoch 254: val_loss did not improve from 16.96012
196/196 - 32s - loss: 16.8920 - MinusLogProbMetric: 16.8920 - val_loss: 16.9761 - val_MinusLogProbMetric: 16.9761 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 255/1000
2023-09-27 15:38:29.447 
Epoch 255/1000 
	 loss: 16.9289, MinusLogProbMetric: 16.9289, val_loss: 16.9911, val_MinusLogProbMetric: 16.9911

Epoch 255: val_loss did not improve from 16.96012
196/196 - 34s - loss: 16.9289 - MinusLogProbMetric: 16.9289 - val_loss: 16.9911 - val_MinusLogProbMetric: 16.9911 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 256/1000
2023-09-27 15:39:07.183 
Epoch 256/1000 
	 loss: 16.9320, MinusLogProbMetric: 16.9320, val_loss: 17.0172, val_MinusLogProbMetric: 17.0172

Epoch 256: val_loss did not improve from 16.96012
196/196 - 38s - loss: 16.9320 - MinusLogProbMetric: 16.9320 - val_loss: 17.0172 - val_MinusLogProbMetric: 17.0172 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 257/1000
2023-09-27 15:39:45.641 
Epoch 257/1000 
	 loss: 16.9031, MinusLogProbMetric: 16.9031, val_loss: 17.0720, val_MinusLogProbMetric: 17.0720

Epoch 257: val_loss did not improve from 16.96012
196/196 - 38s - loss: 16.9031 - MinusLogProbMetric: 16.9031 - val_loss: 17.0720 - val_MinusLogProbMetric: 17.0720 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 258/1000
2023-09-27 15:40:22.799 
Epoch 258/1000 
	 loss: 16.9106, MinusLogProbMetric: 16.9106, val_loss: 17.0063, val_MinusLogProbMetric: 17.0063

Epoch 258: val_loss did not improve from 16.96012
196/196 - 37s - loss: 16.9106 - MinusLogProbMetric: 16.9106 - val_loss: 17.0063 - val_MinusLogProbMetric: 17.0063 - lr: 0.0010 - 37s/epoch - 190ms/step
Epoch 259/1000
2023-09-27 15:41:01.342 
Epoch 259/1000 
	 loss: 16.9196, MinusLogProbMetric: 16.9196, val_loss: 16.9568, val_MinusLogProbMetric: 16.9568

Epoch 259: val_loss improved from 16.96012 to 16.95682, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 39s - loss: 16.9196 - MinusLogProbMetric: 16.9196 - val_loss: 16.9568 - val_MinusLogProbMetric: 16.9568 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 260/1000
2023-09-27 15:41:40.248 
Epoch 260/1000 
	 loss: 16.9051, MinusLogProbMetric: 16.9051, val_loss: 17.0515, val_MinusLogProbMetric: 17.0515

Epoch 260: val_loss did not improve from 16.95682
196/196 - 38s - loss: 16.9051 - MinusLogProbMetric: 16.9051 - val_loss: 17.0515 - val_MinusLogProbMetric: 17.0515 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 261/1000
2023-09-27 15:42:19.075 
Epoch 261/1000 
	 loss: 16.9245, MinusLogProbMetric: 16.9245, val_loss: 16.9545, val_MinusLogProbMetric: 16.9545

Epoch 261: val_loss improved from 16.95682 to 16.95449, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 40s - loss: 16.9245 - MinusLogProbMetric: 16.9245 - val_loss: 16.9545 - val_MinusLogProbMetric: 16.9545 - lr: 0.0010 - 40s/epoch - 202ms/step
Epoch 262/1000
2023-09-27 15:42:58.332 
Epoch 262/1000 
	 loss: 16.8700, MinusLogProbMetric: 16.8700, val_loss: 17.1504, val_MinusLogProbMetric: 17.1504

Epoch 262: val_loss did not improve from 16.95449
196/196 - 38s - loss: 16.8700 - MinusLogProbMetric: 16.8700 - val_loss: 17.1504 - val_MinusLogProbMetric: 17.1504 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 263/1000
2023-09-27 15:43:36.665 
Epoch 263/1000 
	 loss: 16.9525, MinusLogProbMetric: 16.9525, val_loss: 17.0652, val_MinusLogProbMetric: 17.0652

Epoch 263: val_loss did not improve from 16.95449
196/196 - 38s - loss: 16.9525 - MinusLogProbMetric: 16.9525 - val_loss: 17.0652 - val_MinusLogProbMetric: 17.0652 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 264/1000
2023-09-27 15:44:15.175 
Epoch 264/1000 
	 loss: 17.0357, MinusLogProbMetric: 17.0357, val_loss: 17.1197, val_MinusLogProbMetric: 17.1197

Epoch 264: val_loss did not improve from 16.95449
196/196 - 39s - loss: 17.0357 - MinusLogProbMetric: 17.0357 - val_loss: 17.1197 - val_MinusLogProbMetric: 17.1197 - lr: 0.0010 - 39s/epoch - 196ms/step
Epoch 265/1000
2023-09-27 15:44:53.617 
Epoch 265/1000 
	 loss: 16.8252, MinusLogProbMetric: 16.8252, val_loss: 16.9678, val_MinusLogProbMetric: 16.9678

Epoch 265: val_loss did not improve from 16.95449
196/196 - 38s - loss: 16.8252 - MinusLogProbMetric: 16.8252 - val_loss: 16.9678 - val_MinusLogProbMetric: 16.9678 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 266/1000
2023-09-27 15:45:32.012 
Epoch 266/1000 
	 loss: 16.9630, MinusLogProbMetric: 16.9630, val_loss: 17.0291, val_MinusLogProbMetric: 17.0291

Epoch 266: val_loss did not improve from 16.95449
196/196 - 38s - loss: 16.9630 - MinusLogProbMetric: 16.9630 - val_loss: 17.0291 - val_MinusLogProbMetric: 17.0291 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 267/1000
2023-09-27 15:46:10.121 
Epoch 267/1000 
	 loss: 16.8948, MinusLogProbMetric: 16.8948, val_loss: 17.2180, val_MinusLogProbMetric: 17.2180

Epoch 267: val_loss did not improve from 16.95449
196/196 - 38s - loss: 16.8948 - MinusLogProbMetric: 16.8948 - val_loss: 17.2180 - val_MinusLogProbMetric: 17.2180 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 268/1000
2023-09-27 15:46:48.736 
Epoch 268/1000 
	 loss: 16.8697, MinusLogProbMetric: 16.8697, val_loss: 17.5468, val_MinusLogProbMetric: 17.5468

Epoch 268: val_loss did not improve from 16.95449
196/196 - 39s - loss: 16.8697 - MinusLogProbMetric: 16.8697 - val_loss: 17.5468 - val_MinusLogProbMetric: 17.5468 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 269/1000
2023-09-27 15:47:27.533 
Epoch 269/1000 
	 loss: 16.8641, MinusLogProbMetric: 16.8641, val_loss: 17.2061, val_MinusLogProbMetric: 17.2061

Epoch 269: val_loss did not improve from 16.95449
196/196 - 39s - loss: 16.8641 - MinusLogProbMetric: 16.8641 - val_loss: 17.2061 - val_MinusLogProbMetric: 17.2061 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 270/1000
2023-09-27 15:48:04.956 
Epoch 270/1000 
	 loss: 16.8909, MinusLogProbMetric: 16.8909, val_loss: 17.1149, val_MinusLogProbMetric: 17.1149

Epoch 270: val_loss did not improve from 16.95449
196/196 - 37s - loss: 16.8909 - MinusLogProbMetric: 16.8909 - val_loss: 17.1149 - val_MinusLogProbMetric: 17.1149 - lr: 0.0010 - 37s/epoch - 191ms/step
Epoch 271/1000
2023-09-27 15:48:37.185 
Epoch 271/1000 
	 loss: 17.0227, MinusLogProbMetric: 17.0227, val_loss: 17.0699, val_MinusLogProbMetric: 17.0699

Epoch 271: val_loss did not improve from 16.95449
196/196 - 32s - loss: 17.0227 - MinusLogProbMetric: 17.0227 - val_loss: 17.0699 - val_MinusLogProbMetric: 17.0699 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 272/1000
2023-09-27 15:49:08.660 
Epoch 272/1000 
	 loss: 16.8666, MinusLogProbMetric: 16.8666, val_loss: 17.0001, val_MinusLogProbMetric: 17.0001

Epoch 272: val_loss did not improve from 16.95449
196/196 - 31s - loss: 16.8666 - MinusLogProbMetric: 16.8666 - val_loss: 17.0001 - val_MinusLogProbMetric: 17.0001 - lr: 0.0010 - 31s/epoch - 161ms/step
Epoch 273/1000
2023-09-27 15:49:43.534 
Epoch 273/1000 
	 loss: 16.9009, MinusLogProbMetric: 16.9009, val_loss: 16.9720, val_MinusLogProbMetric: 16.9720

Epoch 273: val_loss did not improve from 16.95449
196/196 - 35s - loss: 16.9009 - MinusLogProbMetric: 16.9009 - val_loss: 16.9720 - val_MinusLogProbMetric: 16.9720 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 274/1000
2023-09-27 15:50:21.187 
Epoch 274/1000 
	 loss: 16.8460, MinusLogProbMetric: 16.8460, val_loss: 16.9889, val_MinusLogProbMetric: 16.9889

Epoch 274: val_loss did not improve from 16.95449
196/196 - 38s - loss: 16.8460 - MinusLogProbMetric: 16.8460 - val_loss: 16.9889 - val_MinusLogProbMetric: 16.9889 - lr: 0.0010 - 38s/epoch - 192ms/step
Epoch 275/1000
2023-09-27 15:50:54.152 
Epoch 275/1000 
	 loss: 16.8565, MinusLogProbMetric: 16.8565, val_loss: 17.0320, val_MinusLogProbMetric: 17.0320

Epoch 275: val_loss did not improve from 16.95449
196/196 - 33s - loss: 16.8565 - MinusLogProbMetric: 16.8565 - val_loss: 17.0320 - val_MinusLogProbMetric: 17.0320 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 276/1000
2023-09-27 15:51:25.781 
Epoch 276/1000 
	 loss: 16.8964, MinusLogProbMetric: 16.8964, val_loss: 17.2588, val_MinusLogProbMetric: 17.2588

Epoch 276: val_loss did not improve from 16.95449
196/196 - 32s - loss: 16.8964 - MinusLogProbMetric: 16.8964 - val_loss: 17.2588 - val_MinusLogProbMetric: 17.2588 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 277/1000
2023-09-27 15:51:57.890 
Epoch 277/1000 
	 loss: 16.9277, MinusLogProbMetric: 16.9277, val_loss: 17.0245, val_MinusLogProbMetric: 17.0245

Epoch 277: val_loss did not improve from 16.95449
196/196 - 32s - loss: 16.9277 - MinusLogProbMetric: 16.9277 - val_loss: 17.0245 - val_MinusLogProbMetric: 17.0245 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 278/1000
2023-09-27 15:52:34.611 
Epoch 278/1000 
	 loss: 16.8475, MinusLogProbMetric: 16.8475, val_loss: 17.0354, val_MinusLogProbMetric: 17.0354

Epoch 278: val_loss did not improve from 16.95449
196/196 - 37s - loss: 16.8475 - MinusLogProbMetric: 16.8475 - val_loss: 17.0354 - val_MinusLogProbMetric: 17.0354 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 279/1000
2023-09-27 15:53:13.385 
Epoch 279/1000 
	 loss: 16.8808, MinusLogProbMetric: 16.8808, val_loss: 17.1057, val_MinusLogProbMetric: 17.1057

Epoch 279: val_loss did not improve from 16.95449
196/196 - 39s - loss: 16.8808 - MinusLogProbMetric: 16.8808 - val_loss: 17.1057 - val_MinusLogProbMetric: 17.1057 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 280/1000
2023-09-27 15:53:51.806 
Epoch 280/1000 
	 loss: 16.8509, MinusLogProbMetric: 16.8509, val_loss: 17.0314, val_MinusLogProbMetric: 17.0314

Epoch 280: val_loss did not improve from 16.95449
196/196 - 38s - loss: 16.8509 - MinusLogProbMetric: 16.8509 - val_loss: 17.0314 - val_MinusLogProbMetric: 17.0314 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 281/1000
2023-09-27 15:54:27.783 
Epoch 281/1000 
	 loss: 16.8765, MinusLogProbMetric: 16.8765, val_loss: 16.9919, val_MinusLogProbMetric: 16.9919

Epoch 281: val_loss did not improve from 16.95449
196/196 - 36s - loss: 16.8765 - MinusLogProbMetric: 16.8765 - val_loss: 16.9919 - val_MinusLogProbMetric: 16.9919 - lr: 0.0010 - 36s/epoch - 184ms/step
Epoch 282/1000
2023-09-27 15:55:05.246 
Epoch 282/1000 
	 loss: 16.9736, MinusLogProbMetric: 16.9736, val_loss: 16.9486, val_MinusLogProbMetric: 16.9486

Epoch 282: val_loss improved from 16.95449 to 16.94864, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 38s - loss: 16.9736 - MinusLogProbMetric: 16.9736 - val_loss: 16.9486 - val_MinusLogProbMetric: 16.9486 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 283/1000
2023-09-27 15:55:41.973 
Epoch 283/1000 
	 loss: 16.8148, MinusLogProbMetric: 16.8148, val_loss: 16.9461, val_MinusLogProbMetric: 16.9461

Epoch 283: val_loss improved from 16.94864 to 16.94607, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 37s - loss: 16.8148 - MinusLogProbMetric: 16.8148 - val_loss: 16.9461 - val_MinusLogProbMetric: 16.9461 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 284/1000
2023-09-27 15:56:17.974 
Epoch 284/1000 
	 loss: 16.8377, MinusLogProbMetric: 16.8377, val_loss: 16.9872, val_MinusLogProbMetric: 16.9872

Epoch 284: val_loss did not improve from 16.94607
196/196 - 35s - loss: 16.8377 - MinusLogProbMetric: 16.8377 - val_loss: 16.9872 - val_MinusLogProbMetric: 16.9872 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 285/1000
2023-09-27 15:56:57.012 
Epoch 285/1000 
	 loss: 16.8761, MinusLogProbMetric: 16.8761, val_loss: 17.3065, val_MinusLogProbMetric: 17.3065

Epoch 285: val_loss did not improve from 16.94607
196/196 - 39s - loss: 16.8761 - MinusLogProbMetric: 16.8761 - val_loss: 17.3065 - val_MinusLogProbMetric: 17.3065 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 286/1000
2023-09-27 15:57:34.953 
Epoch 286/1000 
	 loss: 16.8348, MinusLogProbMetric: 16.8348, val_loss: 16.9853, val_MinusLogProbMetric: 16.9853

Epoch 286: val_loss did not improve from 16.94607
196/196 - 38s - loss: 16.8348 - MinusLogProbMetric: 16.8348 - val_loss: 16.9853 - val_MinusLogProbMetric: 16.9853 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 287/1000
2023-09-27 15:58:13.699 
Epoch 287/1000 
	 loss: 16.8974, MinusLogProbMetric: 16.8974, val_loss: 17.1826, val_MinusLogProbMetric: 17.1826

Epoch 287: val_loss did not improve from 16.94607
196/196 - 39s - loss: 16.8974 - MinusLogProbMetric: 16.8974 - val_loss: 17.1826 - val_MinusLogProbMetric: 17.1826 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 288/1000
2023-09-27 15:58:51.829 
Epoch 288/1000 
	 loss: 16.8679, MinusLogProbMetric: 16.8679, val_loss: 16.9873, val_MinusLogProbMetric: 16.9873

Epoch 288: val_loss did not improve from 16.94607
196/196 - 38s - loss: 16.8679 - MinusLogProbMetric: 16.8679 - val_loss: 16.9873 - val_MinusLogProbMetric: 16.9873 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 289/1000
2023-09-27 15:59:30.011 
Epoch 289/1000 
	 loss: 16.8331, MinusLogProbMetric: 16.8331, val_loss: 17.0573, val_MinusLogProbMetric: 17.0573

Epoch 289: val_loss did not improve from 16.94607
196/196 - 38s - loss: 16.8331 - MinusLogProbMetric: 16.8331 - val_loss: 17.0573 - val_MinusLogProbMetric: 17.0573 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 290/1000
2023-09-27 16:00:06.916 
Epoch 290/1000 
	 loss: 16.9066, MinusLogProbMetric: 16.9066, val_loss: 16.9772, val_MinusLogProbMetric: 16.9772

Epoch 290: val_loss did not improve from 16.94607
196/196 - 37s - loss: 16.9066 - MinusLogProbMetric: 16.9066 - val_loss: 16.9772 - val_MinusLogProbMetric: 16.9772 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 291/1000
2023-09-27 16:00:42.828 
Epoch 291/1000 
	 loss: 16.8736, MinusLogProbMetric: 16.8736, val_loss: 17.1508, val_MinusLogProbMetric: 17.1508

Epoch 291: val_loss did not improve from 16.94607
196/196 - 36s - loss: 16.8736 - MinusLogProbMetric: 16.8736 - val_loss: 17.1508 - val_MinusLogProbMetric: 17.1508 - lr: 0.0010 - 36s/epoch - 183ms/step
Epoch 292/1000
2023-09-27 16:01:17.467 
Epoch 292/1000 
	 loss: 16.8574, MinusLogProbMetric: 16.8574, val_loss: 17.2388, val_MinusLogProbMetric: 17.2388

Epoch 292: val_loss did not improve from 16.94607
196/196 - 35s - loss: 16.8574 - MinusLogProbMetric: 16.8574 - val_loss: 17.2388 - val_MinusLogProbMetric: 17.2388 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 293/1000
2023-09-27 16:01:55.413 
Epoch 293/1000 
	 loss: 16.8402, MinusLogProbMetric: 16.8402, val_loss: 17.1774, val_MinusLogProbMetric: 17.1774

Epoch 293: val_loss did not improve from 16.94607
196/196 - 38s - loss: 16.8402 - MinusLogProbMetric: 16.8402 - val_loss: 17.1774 - val_MinusLogProbMetric: 17.1774 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 294/1000
2023-09-27 16:02:33.571 
Epoch 294/1000 
	 loss: 16.8588, MinusLogProbMetric: 16.8588, val_loss: 17.3490, val_MinusLogProbMetric: 17.3490

Epoch 294: val_loss did not improve from 16.94607
196/196 - 38s - loss: 16.8588 - MinusLogProbMetric: 16.8588 - val_loss: 17.3490 - val_MinusLogProbMetric: 17.3490 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 295/1000
2023-09-27 16:03:12.332 
Epoch 295/1000 
	 loss: 16.8260, MinusLogProbMetric: 16.8260, val_loss: 17.2065, val_MinusLogProbMetric: 17.2065

Epoch 295: val_loss did not improve from 16.94607
196/196 - 39s - loss: 16.8260 - MinusLogProbMetric: 16.8260 - val_loss: 17.2065 - val_MinusLogProbMetric: 17.2065 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 296/1000
2023-09-27 16:03:50.607 
Epoch 296/1000 
	 loss: 16.8073, MinusLogProbMetric: 16.8073, val_loss: 17.0724, val_MinusLogProbMetric: 17.0724

Epoch 296: val_loss did not improve from 16.94607
196/196 - 38s - loss: 16.8073 - MinusLogProbMetric: 16.8073 - val_loss: 17.0724 - val_MinusLogProbMetric: 17.0724 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 297/1000
2023-09-27 16:04:29.026 
Epoch 297/1000 
	 loss: 16.8247, MinusLogProbMetric: 16.8247, val_loss: 17.0983, val_MinusLogProbMetric: 17.0983

Epoch 297: val_loss did not improve from 16.94607
196/196 - 38s - loss: 16.8247 - MinusLogProbMetric: 16.8247 - val_loss: 17.0983 - val_MinusLogProbMetric: 17.0983 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 298/1000
2023-09-27 16:05:07.733 
Epoch 298/1000 
	 loss: 16.8948, MinusLogProbMetric: 16.8948, val_loss: 17.1324, val_MinusLogProbMetric: 17.1324

Epoch 298: val_loss did not improve from 16.94607
196/196 - 39s - loss: 16.8948 - MinusLogProbMetric: 16.8948 - val_loss: 17.1324 - val_MinusLogProbMetric: 17.1324 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 299/1000
2023-09-27 16:05:46.502 
Epoch 299/1000 
	 loss: 16.9056, MinusLogProbMetric: 16.9056, val_loss: 16.9134, val_MinusLogProbMetric: 16.9134

Epoch 299: val_loss improved from 16.94607 to 16.91337, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 40s - loss: 16.9056 - MinusLogProbMetric: 16.9056 - val_loss: 16.9134 - val_MinusLogProbMetric: 16.9134 - lr: 0.0010 - 40s/epoch - 202ms/step
Epoch 300/1000
2023-09-27 16:06:25.581 
Epoch 300/1000 
	 loss: 16.8253, MinusLogProbMetric: 16.8253, val_loss: 17.1533, val_MinusLogProbMetric: 17.1533

Epoch 300: val_loss did not improve from 16.91337
196/196 - 38s - loss: 16.8253 - MinusLogProbMetric: 16.8253 - val_loss: 17.1533 - val_MinusLogProbMetric: 17.1533 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 301/1000
2023-09-27 16:07:03.260 
Epoch 301/1000 
	 loss: 16.8334, MinusLogProbMetric: 16.8334, val_loss: 16.9387, val_MinusLogProbMetric: 16.9387

Epoch 301: val_loss did not improve from 16.91337
196/196 - 38s - loss: 16.8334 - MinusLogProbMetric: 16.8334 - val_loss: 16.9387 - val_MinusLogProbMetric: 16.9387 - lr: 0.0010 - 38s/epoch - 192ms/step
Epoch 302/1000
2023-09-27 16:07:40.534 
Epoch 302/1000 
	 loss: 16.8164, MinusLogProbMetric: 16.8164, val_loss: 17.3005, val_MinusLogProbMetric: 17.3005

Epoch 302: val_loss did not improve from 16.91337
196/196 - 37s - loss: 16.8164 - MinusLogProbMetric: 16.8164 - val_loss: 17.3005 - val_MinusLogProbMetric: 17.3005 - lr: 0.0010 - 37s/epoch - 190ms/step
Epoch 303/1000
2023-09-27 16:08:15.406 
Epoch 303/1000 
	 loss: 16.8249, MinusLogProbMetric: 16.8249, val_loss: 17.1231, val_MinusLogProbMetric: 17.1231

Epoch 303: val_loss did not improve from 16.91337
196/196 - 35s - loss: 16.8249 - MinusLogProbMetric: 16.8249 - val_loss: 17.1231 - val_MinusLogProbMetric: 17.1231 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 304/1000
2023-09-27 16:08:49.775 
Epoch 304/1000 
	 loss: 16.8053, MinusLogProbMetric: 16.8053, val_loss: 17.1120, val_MinusLogProbMetric: 17.1120

Epoch 304: val_loss did not improve from 16.91337
196/196 - 34s - loss: 16.8053 - MinusLogProbMetric: 16.8053 - val_loss: 17.1120 - val_MinusLogProbMetric: 17.1120 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 305/1000
2023-09-27 16:09:27.126 
Epoch 305/1000 
	 loss: 16.8651, MinusLogProbMetric: 16.8651, val_loss: 17.1228, val_MinusLogProbMetric: 17.1228

Epoch 305: val_loss did not improve from 16.91337
196/196 - 37s - loss: 16.8651 - MinusLogProbMetric: 16.8651 - val_loss: 17.1228 - val_MinusLogProbMetric: 17.1228 - lr: 0.0010 - 37s/epoch - 191ms/step
Epoch 306/1000
2023-09-27 16:10:03.394 
Epoch 306/1000 
	 loss: 16.7871, MinusLogProbMetric: 16.7871, val_loss: 17.7065, val_MinusLogProbMetric: 17.7065

Epoch 306: val_loss did not improve from 16.91337
196/196 - 36s - loss: 16.7871 - MinusLogProbMetric: 16.7871 - val_loss: 17.7065 - val_MinusLogProbMetric: 17.7065 - lr: 0.0010 - 36s/epoch - 185ms/step
Epoch 307/1000
2023-09-27 16:10:40.694 
Epoch 307/1000 
	 loss: 16.8067, MinusLogProbMetric: 16.8067, val_loss: 17.0265, val_MinusLogProbMetric: 17.0265

Epoch 307: val_loss did not improve from 16.91337
196/196 - 37s - loss: 16.8067 - MinusLogProbMetric: 16.8067 - val_loss: 17.0265 - val_MinusLogProbMetric: 17.0265 - lr: 0.0010 - 37s/epoch - 190ms/step
Epoch 308/1000
2023-09-27 16:11:16.564 
Epoch 308/1000 
	 loss: 16.8214, MinusLogProbMetric: 16.8214, val_loss: 17.2904, val_MinusLogProbMetric: 17.2904

Epoch 308: val_loss did not improve from 16.91337
196/196 - 36s - loss: 16.8214 - MinusLogProbMetric: 16.8214 - val_loss: 17.2904 - val_MinusLogProbMetric: 17.2904 - lr: 0.0010 - 36s/epoch - 183ms/step
Epoch 309/1000
2023-09-27 16:11:52.888 
Epoch 309/1000 
	 loss: 16.7913, MinusLogProbMetric: 16.7913, val_loss: 16.9333, val_MinusLogProbMetric: 16.9333

Epoch 309: val_loss did not improve from 16.91337
196/196 - 36s - loss: 16.7913 - MinusLogProbMetric: 16.7913 - val_loss: 16.9333 - val_MinusLogProbMetric: 16.9333 - lr: 0.0010 - 36s/epoch - 185ms/step
Epoch 310/1000
2023-09-27 16:12:31.101 
Epoch 310/1000 
	 loss: 16.8384, MinusLogProbMetric: 16.8384, val_loss: 17.1386, val_MinusLogProbMetric: 17.1386

Epoch 310: val_loss did not improve from 16.91337
196/196 - 38s - loss: 16.8384 - MinusLogProbMetric: 16.8384 - val_loss: 17.1386 - val_MinusLogProbMetric: 17.1386 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 311/1000
2023-09-27 16:13:09.049 
Epoch 311/1000 
	 loss: 16.8057, MinusLogProbMetric: 16.8057, val_loss: 16.9202, val_MinusLogProbMetric: 16.9202

Epoch 311: val_loss did not improve from 16.91337
196/196 - 38s - loss: 16.8057 - MinusLogProbMetric: 16.8057 - val_loss: 16.9202 - val_MinusLogProbMetric: 16.9202 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 312/1000
2023-09-27 16:13:44.722 
Epoch 312/1000 
	 loss: 16.8444, MinusLogProbMetric: 16.8444, val_loss: 16.8908, val_MinusLogProbMetric: 16.8908

Epoch 312: val_loss improved from 16.91337 to 16.89081, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 36s - loss: 16.8444 - MinusLogProbMetric: 16.8444 - val_loss: 16.8908 - val_MinusLogProbMetric: 16.8908 - lr: 0.0010 - 36s/epoch - 185ms/step
Epoch 313/1000
2023-09-27 16:14:20.427 
Epoch 313/1000 
	 loss: 16.8068, MinusLogProbMetric: 16.8068, val_loss: 16.9755, val_MinusLogProbMetric: 16.9755

Epoch 313: val_loss did not improve from 16.89081
196/196 - 35s - loss: 16.8068 - MinusLogProbMetric: 16.8068 - val_loss: 16.9755 - val_MinusLogProbMetric: 16.9755 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 314/1000
2023-09-27 16:14:54.427 
Epoch 314/1000 
	 loss: 16.8403, MinusLogProbMetric: 16.8403, val_loss: 16.9578, val_MinusLogProbMetric: 16.9578

Epoch 314: val_loss did not improve from 16.89081
196/196 - 34s - loss: 16.8403 - MinusLogProbMetric: 16.8403 - val_loss: 16.9578 - val_MinusLogProbMetric: 16.9578 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 315/1000
2023-09-27 16:15:31.936 
Epoch 315/1000 
	 loss: 16.7860, MinusLogProbMetric: 16.7860, val_loss: 17.0262, val_MinusLogProbMetric: 17.0262

Epoch 315: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.7860 - MinusLogProbMetric: 16.7860 - val_loss: 17.0262 - val_MinusLogProbMetric: 17.0262 - lr: 0.0010 - 38s/epoch - 191ms/step
Epoch 316/1000
2023-09-27 16:16:10.460 
Epoch 316/1000 
	 loss: 16.8101, MinusLogProbMetric: 16.8101, val_loss: 17.3360, val_MinusLogProbMetric: 17.3360

Epoch 316: val_loss did not improve from 16.89081
196/196 - 39s - loss: 16.8101 - MinusLogProbMetric: 16.8101 - val_loss: 17.3360 - val_MinusLogProbMetric: 17.3360 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 317/1000
2023-09-27 16:16:48.938 
Epoch 317/1000 
	 loss: 16.7923, MinusLogProbMetric: 16.7923, val_loss: 16.9829, val_MinusLogProbMetric: 16.9829

Epoch 317: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.7923 - MinusLogProbMetric: 16.7923 - val_loss: 16.9829 - val_MinusLogProbMetric: 16.9829 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 318/1000
2023-09-27 16:17:27.277 
Epoch 318/1000 
	 loss: 16.8241, MinusLogProbMetric: 16.8241, val_loss: 17.2837, val_MinusLogProbMetric: 17.2837

Epoch 318: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.8241 - MinusLogProbMetric: 16.8241 - val_loss: 17.2837 - val_MinusLogProbMetric: 17.2837 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 319/1000
2023-09-27 16:18:04.669 
Epoch 319/1000 
	 loss: 16.8364, MinusLogProbMetric: 16.8364, val_loss: 17.1520, val_MinusLogProbMetric: 17.1520

Epoch 319: val_loss did not improve from 16.89081
196/196 - 37s - loss: 16.8364 - MinusLogProbMetric: 16.8364 - val_loss: 17.1520 - val_MinusLogProbMetric: 17.1520 - lr: 0.0010 - 37s/epoch - 191ms/step
Epoch 320/1000
2023-09-27 16:18:39.649 
Epoch 320/1000 
	 loss: 16.8114, MinusLogProbMetric: 16.8114, val_loss: 17.1276, val_MinusLogProbMetric: 17.1276

Epoch 320: val_loss did not improve from 16.89081
196/196 - 35s - loss: 16.8114 - MinusLogProbMetric: 16.8114 - val_loss: 17.1276 - val_MinusLogProbMetric: 17.1276 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 321/1000
2023-09-27 16:19:13.583 
Epoch 321/1000 
	 loss: 16.7912, MinusLogProbMetric: 16.7912, val_loss: 16.9262, val_MinusLogProbMetric: 16.9262

Epoch 321: val_loss did not improve from 16.89081
196/196 - 34s - loss: 16.7912 - MinusLogProbMetric: 16.7912 - val_loss: 16.9262 - val_MinusLogProbMetric: 16.9262 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 322/1000
2023-09-27 16:19:50.632 
Epoch 322/1000 
	 loss: 16.7961, MinusLogProbMetric: 16.7961, val_loss: 17.0318, val_MinusLogProbMetric: 17.0318

Epoch 322: val_loss did not improve from 16.89081
196/196 - 37s - loss: 16.7961 - MinusLogProbMetric: 16.7961 - val_loss: 17.0318 - val_MinusLogProbMetric: 17.0318 - lr: 0.0010 - 37s/epoch - 189ms/step
Epoch 323/1000
2023-09-27 16:20:28.608 
Epoch 323/1000 
	 loss: 16.8270, MinusLogProbMetric: 16.8270, val_loss: 17.1469, val_MinusLogProbMetric: 17.1469

Epoch 323: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.8270 - MinusLogProbMetric: 16.8270 - val_loss: 17.1469 - val_MinusLogProbMetric: 17.1469 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 324/1000
2023-09-27 16:21:06.265 
Epoch 324/1000 
	 loss: 16.8242, MinusLogProbMetric: 16.8242, val_loss: 17.2475, val_MinusLogProbMetric: 17.2475

Epoch 324: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.8242 - MinusLogProbMetric: 16.8242 - val_loss: 17.2475 - val_MinusLogProbMetric: 17.2475 - lr: 0.0010 - 38s/epoch - 192ms/step
Epoch 325/1000
2023-09-27 16:21:43.657 
Epoch 325/1000 
	 loss: 16.7857, MinusLogProbMetric: 16.7857, val_loss: 17.2869, val_MinusLogProbMetric: 17.2869

Epoch 325: val_loss did not improve from 16.89081
196/196 - 37s - loss: 16.7857 - MinusLogProbMetric: 16.7857 - val_loss: 17.2869 - val_MinusLogProbMetric: 17.2869 - lr: 0.0010 - 37s/epoch - 191ms/step
Epoch 326/1000
2023-09-27 16:22:19.423 
Epoch 326/1000 
	 loss: 16.7693, MinusLogProbMetric: 16.7693, val_loss: 16.9725, val_MinusLogProbMetric: 16.9725

Epoch 326: val_loss did not improve from 16.89081
196/196 - 36s - loss: 16.7693 - MinusLogProbMetric: 16.7693 - val_loss: 16.9725 - val_MinusLogProbMetric: 16.9725 - lr: 0.0010 - 36s/epoch - 182ms/step
Epoch 327/1000
2023-09-27 16:22:51.766 
Epoch 327/1000 
	 loss: 16.7930, MinusLogProbMetric: 16.7930, val_loss: 17.4684, val_MinusLogProbMetric: 17.4684

Epoch 327: val_loss did not improve from 16.89081
196/196 - 32s - loss: 16.7930 - MinusLogProbMetric: 16.7930 - val_loss: 17.4684 - val_MinusLogProbMetric: 17.4684 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 328/1000
2023-09-27 16:23:28.564 
Epoch 328/1000 
	 loss: 16.8291, MinusLogProbMetric: 16.8291, val_loss: 17.0079, val_MinusLogProbMetric: 17.0079

Epoch 328: val_loss did not improve from 16.89081
196/196 - 37s - loss: 16.8291 - MinusLogProbMetric: 16.8291 - val_loss: 17.0079 - val_MinusLogProbMetric: 17.0079 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 329/1000
2023-09-27 16:24:07.200 
Epoch 329/1000 
	 loss: 16.7556, MinusLogProbMetric: 16.7556, val_loss: 17.0011, val_MinusLogProbMetric: 17.0011

Epoch 329: val_loss did not improve from 16.89081
196/196 - 39s - loss: 16.7556 - MinusLogProbMetric: 16.7556 - val_loss: 17.0011 - val_MinusLogProbMetric: 17.0011 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 330/1000
2023-09-27 16:24:45.045 
Epoch 330/1000 
	 loss: 16.8417, MinusLogProbMetric: 16.8417, val_loss: 17.0862, val_MinusLogProbMetric: 17.0862

Epoch 330: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.8417 - MinusLogProbMetric: 16.8417 - val_loss: 17.0862 - val_MinusLogProbMetric: 17.0862 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 331/1000
2023-09-27 16:25:23.958 
Epoch 331/1000 
	 loss: 16.7924, MinusLogProbMetric: 16.7924, val_loss: 17.1265, val_MinusLogProbMetric: 17.1265

Epoch 331: val_loss did not improve from 16.89081
196/196 - 39s - loss: 16.7924 - MinusLogProbMetric: 16.7924 - val_loss: 17.1265 - val_MinusLogProbMetric: 17.1265 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 332/1000
2023-09-27 16:26:02.215 
Epoch 332/1000 
	 loss: 16.7438, MinusLogProbMetric: 16.7438, val_loss: 16.9894, val_MinusLogProbMetric: 16.9894

Epoch 332: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.7438 - MinusLogProbMetric: 16.7438 - val_loss: 16.9894 - val_MinusLogProbMetric: 16.9894 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 333/1000
2023-09-27 16:26:40.884 
Epoch 333/1000 
	 loss: 16.8147, MinusLogProbMetric: 16.8147, val_loss: 17.0510, val_MinusLogProbMetric: 17.0510

Epoch 333: val_loss did not improve from 16.89081
196/196 - 39s - loss: 16.8147 - MinusLogProbMetric: 16.8147 - val_loss: 17.0510 - val_MinusLogProbMetric: 17.0510 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 334/1000
2023-09-27 16:27:19.250 
Epoch 334/1000 
	 loss: 16.7670, MinusLogProbMetric: 16.7670, val_loss: 17.0544, val_MinusLogProbMetric: 17.0544

Epoch 334: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.7670 - MinusLogProbMetric: 16.7670 - val_loss: 17.0544 - val_MinusLogProbMetric: 17.0544 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 335/1000
2023-09-27 16:27:57.622 
Epoch 335/1000 
	 loss: 16.8566, MinusLogProbMetric: 16.8566, val_loss: 17.5335, val_MinusLogProbMetric: 17.5335

Epoch 335: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.8566 - MinusLogProbMetric: 16.8566 - val_loss: 17.5335 - val_MinusLogProbMetric: 17.5335 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 336/1000
2023-09-27 16:28:35.912 
Epoch 336/1000 
	 loss: 16.7664, MinusLogProbMetric: 16.7664, val_loss: 17.0892, val_MinusLogProbMetric: 17.0892

Epoch 336: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.7664 - MinusLogProbMetric: 16.7664 - val_loss: 17.0892 - val_MinusLogProbMetric: 17.0892 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 337/1000
2023-09-27 16:29:14.074 
Epoch 337/1000 
	 loss: 16.7504, MinusLogProbMetric: 16.7504, val_loss: 17.4672, val_MinusLogProbMetric: 17.4672

Epoch 337: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.7504 - MinusLogProbMetric: 16.7504 - val_loss: 17.4672 - val_MinusLogProbMetric: 17.4672 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 338/1000
2023-09-27 16:29:52.436 
Epoch 338/1000 
	 loss: 16.7720, MinusLogProbMetric: 16.7720, val_loss: 17.2847, val_MinusLogProbMetric: 17.2847

Epoch 338: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.7720 - MinusLogProbMetric: 16.7720 - val_loss: 17.2847 - val_MinusLogProbMetric: 17.2847 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 339/1000
2023-09-27 16:30:30.668 
Epoch 339/1000 
	 loss: 16.8025, MinusLogProbMetric: 16.8025, val_loss: 17.0819, val_MinusLogProbMetric: 17.0819

Epoch 339: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.8025 - MinusLogProbMetric: 16.8025 - val_loss: 17.0819 - val_MinusLogProbMetric: 17.0819 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 340/1000
2023-09-27 16:31:06.141 
Epoch 340/1000 
	 loss: 16.7952, MinusLogProbMetric: 16.7952, val_loss: 17.0053, val_MinusLogProbMetric: 17.0053

Epoch 340: val_loss did not improve from 16.89081
196/196 - 35s - loss: 16.7952 - MinusLogProbMetric: 16.7952 - val_loss: 17.0053 - val_MinusLogProbMetric: 17.0053 - lr: 0.0010 - 35s/epoch - 181ms/step
Epoch 341/1000
2023-09-27 16:31:40.251 
Epoch 341/1000 
	 loss: 16.8079, MinusLogProbMetric: 16.8079, val_loss: 16.9620, val_MinusLogProbMetric: 16.9620

Epoch 341: val_loss did not improve from 16.89081
196/196 - 34s - loss: 16.8079 - MinusLogProbMetric: 16.8079 - val_loss: 16.9620 - val_MinusLogProbMetric: 16.9620 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 342/1000
2023-09-27 16:32:15.169 
Epoch 342/1000 
	 loss: 16.7730, MinusLogProbMetric: 16.7730, val_loss: 17.0334, val_MinusLogProbMetric: 17.0334

Epoch 342: val_loss did not improve from 16.89081
196/196 - 35s - loss: 16.7730 - MinusLogProbMetric: 16.7730 - val_loss: 17.0334 - val_MinusLogProbMetric: 17.0334 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 343/1000
2023-09-27 16:32:52.724 
Epoch 343/1000 
	 loss: 16.7704, MinusLogProbMetric: 16.7704, val_loss: 17.0709, val_MinusLogProbMetric: 17.0709

Epoch 343: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.7704 - MinusLogProbMetric: 16.7704 - val_loss: 17.0709 - val_MinusLogProbMetric: 17.0709 - lr: 0.0010 - 38s/epoch - 192ms/step
Epoch 344/1000
2023-09-27 16:33:29.294 
Epoch 344/1000 
	 loss: 16.7943, MinusLogProbMetric: 16.7943, val_loss: 16.9905, val_MinusLogProbMetric: 16.9905

Epoch 344: val_loss did not improve from 16.89081
196/196 - 37s - loss: 16.7943 - MinusLogProbMetric: 16.7943 - val_loss: 16.9905 - val_MinusLogProbMetric: 16.9905 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 345/1000
2023-09-27 16:34:04.539 
Epoch 345/1000 
	 loss: 16.7330, MinusLogProbMetric: 16.7330, val_loss: 17.5681, val_MinusLogProbMetric: 17.5681

Epoch 345: val_loss did not improve from 16.89081
196/196 - 35s - loss: 16.7330 - MinusLogProbMetric: 16.7330 - val_loss: 17.5681 - val_MinusLogProbMetric: 17.5681 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 346/1000
2023-09-27 16:34:42.524 
Epoch 346/1000 
	 loss: 16.7918, MinusLogProbMetric: 16.7918, val_loss: 16.9483, val_MinusLogProbMetric: 16.9483

Epoch 346: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.7918 - MinusLogProbMetric: 16.7918 - val_loss: 16.9483 - val_MinusLogProbMetric: 16.9483 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 347/1000
2023-09-27 16:35:20.459 
Epoch 347/1000 
	 loss: 16.7470, MinusLogProbMetric: 16.7470, val_loss: 16.9306, val_MinusLogProbMetric: 16.9306

Epoch 347: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.7470 - MinusLogProbMetric: 16.7470 - val_loss: 16.9306 - val_MinusLogProbMetric: 16.9306 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 348/1000
2023-09-27 16:35:58.211 
Epoch 348/1000 
	 loss: 16.7734, MinusLogProbMetric: 16.7734, val_loss: 17.0125, val_MinusLogProbMetric: 17.0125

Epoch 348: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.7734 - MinusLogProbMetric: 16.7734 - val_loss: 17.0125 - val_MinusLogProbMetric: 17.0125 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 349/1000
2023-09-27 16:36:36.550 
Epoch 349/1000 
	 loss: 16.7285, MinusLogProbMetric: 16.7285, val_loss: 17.2306, val_MinusLogProbMetric: 17.2306

Epoch 349: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.7285 - MinusLogProbMetric: 16.7285 - val_loss: 17.2306 - val_MinusLogProbMetric: 17.2306 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 350/1000
2023-09-27 16:37:15.137 
Epoch 350/1000 
	 loss: 16.7799, MinusLogProbMetric: 16.7799, val_loss: 16.9863, val_MinusLogProbMetric: 16.9863

Epoch 350: val_loss did not improve from 16.89081
196/196 - 39s - loss: 16.7799 - MinusLogProbMetric: 16.7799 - val_loss: 16.9863 - val_MinusLogProbMetric: 16.9863 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 351/1000
2023-09-27 16:37:54.326 
Epoch 351/1000 
	 loss: 16.7624, MinusLogProbMetric: 16.7624, val_loss: 16.9560, val_MinusLogProbMetric: 16.9560

Epoch 351: val_loss did not improve from 16.89081
196/196 - 39s - loss: 16.7624 - MinusLogProbMetric: 16.7624 - val_loss: 16.9560 - val_MinusLogProbMetric: 16.9560 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 352/1000
2023-09-27 16:38:32.869 
Epoch 352/1000 
	 loss: 16.7401, MinusLogProbMetric: 16.7401, val_loss: 17.0175, val_MinusLogProbMetric: 17.0175

Epoch 352: val_loss did not improve from 16.89081
196/196 - 39s - loss: 16.7401 - MinusLogProbMetric: 16.7401 - val_loss: 17.0175 - val_MinusLogProbMetric: 17.0175 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 353/1000
2023-09-27 16:39:11.580 
Epoch 353/1000 
	 loss: 16.7655, MinusLogProbMetric: 16.7655, val_loss: 16.9943, val_MinusLogProbMetric: 16.9943

Epoch 353: val_loss did not improve from 16.89081
196/196 - 39s - loss: 16.7655 - MinusLogProbMetric: 16.7655 - val_loss: 16.9943 - val_MinusLogProbMetric: 16.9943 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 354/1000
2023-09-27 16:39:50.319 
Epoch 354/1000 
	 loss: 16.7414, MinusLogProbMetric: 16.7414, val_loss: 17.9866, val_MinusLogProbMetric: 17.9866

Epoch 354: val_loss did not improve from 16.89081
196/196 - 39s - loss: 16.7414 - MinusLogProbMetric: 16.7414 - val_loss: 17.9866 - val_MinusLogProbMetric: 17.9866 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 355/1000
2023-09-27 16:40:28.641 
Epoch 355/1000 
	 loss: 16.7564, MinusLogProbMetric: 16.7564, val_loss: 17.0649, val_MinusLogProbMetric: 17.0649

Epoch 355: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.7564 - MinusLogProbMetric: 16.7564 - val_loss: 17.0649 - val_MinusLogProbMetric: 17.0649 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 356/1000
2023-09-27 16:41:07.039 
Epoch 356/1000 
	 loss: 16.7466, MinusLogProbMetric: 16.7466, val_loss: 16.9995, val_MinusLogProbMetric: 16.9995

Epoch 356: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.7466 - MinusLogProbMetric: 16.7466 - val_loss: 16.9995 - val_MinusLogProbMetric: 16.9995 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 357/1000
2023-09-27 16:41:45.662 
Epoch 357/1000 
	 loss: 16.7831, MinusLogProbMetric: 16.7831, val_loss: 17.0262, val_MinusLogProbMetric: 17.0262

Epoch 357: val_loss did not improve from 16.89081
196/196 - 39s - loss: 16.7831 - MinusLogProbMetric: 16.7831 - val_loss: 17.0262 - val_MinusLogProbMetric: 17.0262 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 358/1000
2023-09-27 16:42:24.214 
Epoch 358/1000 
	 loss: 16.7258, MinusLogProbMetric: 16.7258, val_loss: 16.9922, val_MinusLogProbMetric: 16.9922

Epoch 358: val_loss did not improve from 16.89081
196/196 - 39s - loss: 16.7258 - MinusLogProbMetric: 16.7258 - val_loss: 16.9922 - val_MinusLogProbMetric: 16.9922 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 359/1000
2023-09-27 16:43:02.887 
Epoch 359/1000 
	 loss: 16.7657, MinusLogProbMetric: 16.7657, val_loss: 16.9885, val_MinusLogProbMetric: 16.9885

Epoch 359: val_loss did not improve from 16.89081
196/196 - 39s - loss: 16.7657 - MinusLogProbMetric: 16.7657 - val_loss: 16.9885 - val_MinusLogProbMetric: 16.9885 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 360/1000
2023-09-27 16:43:41.505 
Epoch 360/1000 
	 loss: 16.7702, MinusLogProbMetric: 16.7702, val_loss: 17.1913, val_MinusLogProbMetric: 17.1913

Epoch 360: val_loss did not improve from 16.89081
196/196 - 39s - loss: 16.7702 - MinusLogProbMetric: 16.7702 - val_loss: 17.1913 - val_MinusLogProbMetric: 17.1913 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 361/1000
2023-09-27 16:44:19.889 
Epoch 361/1000 
	 loss: 16.7304, MinusLogProbMetric: 16.7304, val_loss: 16.9610, val_MinusLogProbMetric: 16.9610

Epoch 361: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.7304 - MinusLogProbMetric: 16.7304 - val_loss: 16.9610 - val_MinusLogProbMetric: 16.9610 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 362/1000
2023-09-27 16:44:58.235 
Epoch 362/1000 
	 loss: 16.7977, MinusLogProbMetric: 16.7977, val_loss: 17.0872, val_MinusLogProbMetric: 17.0872

Epoch 362: val_loss did not improve from 16.89081
196/196 - 38s - loss: 16.7977 - MinusLogProbMetric: 16.7977 - val_loss: 17.0872 - val_MinusLogProbMetric: 17.0872 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 363/1000
2023-09-27 16:45:36.907 
Epoch 363/1000 
	 loss: 16.5501, MinusLogProbMetric: 16.5501, val_loss: 16.7970, val_MinusLogProbMetric: 16.7970

Epoch 363: val_loss improved from 16.89081 to 16.79698, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 39s - loss: 16.5501 - MinusLogProbMetric: 16.5501 - val_loss: 16.7970 - val_MinusLogProbMetric: 16.7970 - lr: 5.0000e-04 - 39s/epoch - 201ms/step
Epoch 364/1000
2023-09-27 16:46:15.995 
Epoch 364/1000 
	 loss: 16.5475, MinusLogProbMetric: 16.5475, val_loss: 16.7903, val_MinusLogProbMetric: 16.7903

Epoch 364: val_loss improved from 16.79698 to 16.79027, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 39s - loss: 16.5475 - MinusLogProbMetric: 16.5475 - val_loss: 16.7903 - val_MinusLogProbMetric: 16.7903 - lr: 5.0000e-04 - 39s/epoch - 199ms/step
Epoch 365/1000
2023-09-27 16:46:55.007 
Epoch 365/1000 
	 loss: 16.5442, MinusLogProbMetric: 16.5442, val_loss: 16.8280, val_MinusLogProbMetric: 16.8280

Epoch 365: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5442 - MinusLogProbMetric: 16.5442 - val_loss: 16.8280 - val_MinusLogProbMetric: 16.8280 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 366/1000
2023-09-27 16:47:33.424 
Epoch 366/1000 
	 loss: 16.5354, MinusLogProbMetric: 16.5354, val_loss: 16.8046, val_MinusLogProbMetric: 16.8046

Epoch 366: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5354 - MinusLogProbMetric: 16.5354 - val_loss: 16.8046 - val_MinusLogProbMetric: 16.8046 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 367/1000
2023-09-27 16:48:11.708 
Epoch 367/1000 
	 loss: 16.5444, MinusLogProbMetric: 16.5444, val_loss: 16.9135, val_MinusLogProbMetric: 16.9135

Epoch 367: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5444 - MinusLogProbMetric: 16.5444 - val_loss: 16.9135 - val_MinusLogProbMetric: 16.9135 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 368/1000
2023-09-27 16:48:49.970 
Epoch 368/1000 
	 loss: 16.5401, MinusLogProbMetric: 16.5401, val_loss: 16.9195, val_MinusLogProbMetric: 16.9195

Epoch 368: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5401 - MinusLogProbMetric: 16.5401 - val_loss: 16.9195 - val_MinusLogProbMetric: 16.9195 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 369/1000
2023-09-27 16:49:28.141 
Epoch 369/1000 
	 loss: 16.5370, MinusLogProbMetric: 16.5370, val_loss: 16.8459, val_MinusLogProbMetric: 16.8459

Epoch 369: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5370 - MinusLogProbMetric: 16.5370 - val_loss: 16.8459 - val_MinusLogProbMetric: 16.8459 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 370/1000
2023-09-27 16:50:06.394 
Epoch 370/1000 
	 loss: 16.5380, MinusLogProbMetric: 16.5380, val_loss: 16.8546, val_MinusLogProbMetric: 16.8546

Epoch 370: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5380 - MinusLogProbMetric: 16.5380 - val_loss: 16.8546 - val_MinusLogProbMetric: 16.8546 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 371/1000
2023-09-27 16:50:44.624 
Epoch 371/1000 
	 loss: 16.5462, MinusLogProbMetric: 16.5462, val_loss: 16.8468, val_MinusLogProbMetric: 16.8468

Epoch 371: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5462 - MinusLogProbMetric: 16.5462 - val_loss: 16.8468 - val_MinusLogProbMetric: 16.8468 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 372/1000
2023-09-27 16:51:22.441 
Epoch 372/1000 
	 loss: 16.5598, MinusLogProbMetric: 16.5598, val_loss: 16.8679, val_MinusLogProbMetric: 16.8679

Epoch 372: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5598 - MinusLogProbMetric: 16.5598 - val_loss: 16.8679 - val_MinusLogProbMetric: 16.8679 - lr: 5.0000e-04 - 38s/epoch - 193ms/step
Epoch 373/1000
2023-09-27 16:52:00.764 
Epoch 373/1000 
	 loss: 16.5502, MinusLogProbMetric: 16.5502, val_loss: 16.8520, val_MinusLogProbMetric: 16.8520

Epoch 373: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5502 - MinusLogProbMetric: 16.5502 - val_loss: 16.8520 - val_MinusLogProbMetric: 16.8520 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 374/1000
2023-09-27 16:52:38.871 
Epoch 374/1000 
	 loss: 16.5417, MinusLogProbMetric: 16.5417, val_loss: 16.8445, val_MinusLogProbMetric: 16.8445

Epoch 374: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5417 - MinusLogProbMetric: 16.5417 - val_loss: 16.8445 - val_MinusLogProbMetric: 16.8445 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 375/1000
2023-09-27 16:53:16.923 
Epoch 375/1000 
	 loss: 16.5310, MinusLogProbMetric: 16.5310, val_loss: 16.8568, val_MinusLogProbMetric: 16.8568

Epoch 375: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5310 - MinusLogProbMetric: 16.5310 - val_loss: 16.8568 - val_MinusLogProbMetric: 16.8568 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 376/1000
2023-09-27 16:53:54.964 
Epoch 376/1000 
	 loss: 16.5379, MinusLogProbMetric: 16.5379, val_loss: 16.8375, val_MinusLogProbMetric: 16.8375

Epoch 376: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5379 - MinusLogProbMetric: 16.5379 - val_loss: 16.8375 - val_MinusLogProbMetric: 16.8375 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 377/1000
2023-09-27 16:54:33.078 
Epoch 377/1000 
	 loss: 16.5408, MinusLogProbMetric: 16.5408, val_loss: 16.9094, val_MinusLogProbMetric: 16.9094

Epoch 377: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5408 - MinusLogProbMetric: 16.5408 - val_loss: 16.9094 - val_MinusLogProbMetric: 16.9094 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 378/1000
2023-09-27 16:55:11.198 
Epoch 378/1000 
	 loss: 16.5507, MinusLogProbMetric: 16.5507, val_loss: 16.9293, val_MinusLogProbMetric: 16.9293

Epoch 378: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5507 - MinusLogProbMetric: 16.5507 - val_loss: 16.9293 - val_MinusLogProbMetric: 16.9293 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 379/1000
2023-09-27 16:55:49.341 
Epoch 379/1000 
	 loss: 16.5379, MinusLogProbMetric: 16.5379, val_loss: 16.8190, val_MinusLogProbMetric: 16.8190

Epoch 379: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5379 - MinusLogProbMetric: 16.5379 - val_loss: 16.8190 - val_MinusLogProbMetric: 16.8190 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 380/1000
2023-09-27 16:56:27.541 
Epoch 380/1000 
	 loss: 16.5231, MinusLogProbMetric: 16.5231, val_loss: 16.7952, val_MinusLogProbMetric: 16.7952

Epoch 380: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5231 - MinusLogProbMetric: 16.5231 - val_loss: 16.7952 - val_MinusLogProbMetric: 16.7952 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 381/1000
2023-09-27 16:57:05.838 
Epoch 381/1000 
	 loss: 16.5271, MinusLogProbMetric: 16.5271, val_loss: 16.8038, val_MinusLogProbMetric: 16.8038

Epoch 381: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5271 - MinusLogProbMetric: 16.5271 - val_loss: 16.8038 - val_MinusLogProbMetric: 16.8038 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 382/1000
2023-09-27 16:57:43.721 
Epoch 382/1000 
	 loss: 16.5516, MinusLogProbMetric: 16.5516, val_loss: 16.8851, val_MinusLogProbMetric: 16.8851

Epoch 382: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5516 - MinusLogProbMetric: 16.5516 - val_loss: 16.8851 - val_MinusLogProbMetric: 16.8851 - lr: 5.0000e-04 - 38s/epoch - 193ms/step
Epoch 383/1000
2023-09-27 16:58:22.034 
Epoch 383/1000 
	 loss: 16.5422, MinusLogProbMetric: 16.5422, val_loss: 16.8406, val_MinusLogProbMetric: 16.8406

Epoch 383: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5422 - MinusLogProbMetric: 16.5422 - val_loss: 16.8406 - val_MinusLogProbMetric: 16.8406 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 384/1000
2023-09-27 16:59:00.163 
Epoch 384/1000 
	 loss: 16.5378, MinusLogProbMetric: 16.5378, val_loss: 16.8283, val_MinusLogProbMetric: 16.8283

Epoch 384: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5378 - MinusLogProbMetric: 16.5378 - val_loss: 16.8283 - val_MinusLogProbMetric: 16.8283 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 385/1000
2023-09-27 16:59:38.897 
Epoch 385/1000 
	 loss: 16.5369, MinusLogProbMetric: 16.5369, val_loss: 16.8066, val_MinusLogProbMetric: 16.8066

Epoch 385: val_loss did not improve from 16.79027
196/196 - 39s - loss: 16.5369 - MinusLogProbMetric: 16.5369 - val_loss: 16.8066 - val_MinusLogProbMetric: 16.8066 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 386/1000
2023-09-27 17:00:16.838 
Epoch 386/1000 
	 loss: 16.5423, MinusLogProbMetric: 16.5423, val_loss: 16.8061, val_MinusLogProbMetric: 16.8061

Epoch 386: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5423 - MinusLogProbMetric: 16.5423 - val_loss: 16.8061 - val_MinusLogProbMetric: 16.8061 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 387/1000
2023-09-27 17:00:54.829 
Epoch 387/1000 
	 loss: 16.5272, MinusLogProbMetric: 16.5272, val_loss: 16.9048, val_MinusLogProbMetric: 16.9048

Epoch 387: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5272 - MinusLogProbMetric: 16.5272 - val_loss: 16.9048 - val_MinusLogProbMetric: 16.9048 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 388/1000
2023-09-27 17:01:32.853 
Epoch 388/1000 
	 loss: 16.5425, MinusLogProbMetric: 16.5425, val_loss: 16.8479, val_MinusLogProbMetric: 16.8479

Epoch 388: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5425 - MinusLogProbMetric: 16.5425 - val_loss: 16.8479 - val_MinusLogProbMetric: 16.8479 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 389/1000
2023-09-27 17:02:10.964 
Epoch 389/1000 
	 loss: 16.5447, MinusLogProbMetric: 16.5447, val_loss: 16.9137, val_MinusLogProbMetric: 16.9137

Epoch 389: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5447 - MinusLogProbMetric: 16.5447 - val_loss: 16.9137 - val_MinusLogProbMetric: 16.9137 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 390/1000
2023-09-27 17:02:49.001 
Epoch 390/1000 
	 loss: 16.5320, MinusLogProbMetric: 16.5320, val_loss: 16.9578, val_MinusLogProbMetric: 16.9578

Epoch 390: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5320 - MinusLogProbMetric: 16.5320 - val_loss: 16.9578 - val_MinusLogProbMetric: 16.9578 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 391/1000
2023-09-27 17:03:26.772 
Epoch 391/1000 
	 loss: 16.5484, MinusLogProbMetric: 16.5484, val_loss: 16.9694, val_MinusLogProbMetric: 16.9694

Epoch 391: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5484 - MinusLogProbMetric: 16.5484 - val_loss: 16.9694 - val_MinusLogProbMetric: 16.9694 - lr: 5.0000e-04 - 38s/epoch - 193ms/step
Epoch 392/1000
2023-09-27 17:04:04.726 
Epoch 392/1000 
	 loss: 16.5293, MinusLogProbMetric: 16.5293, val_loss: 16.9006, val_MinusLogProbMetric: 16.9006

Epoch 392: val_loss did not improve from 16.79027
196/196 - 38s - loss: 16.5293 - MinusLogProbMetric: 16.5293 - val_loss: 16.9006 - val_MinusLogProbMetric: 16.9006 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 393/1000
2023-09-27 17:04:43.174 
Epoch 393/1000 
	 loss: 16.5244, MinusLogProbMetric: 16.5244, val_loss: 16.7879, val_MinusLogProbMetric: 16.7879

Epoch 393: val_loss improved from 16.79027 to 16.78790, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 39s - loss: 16.5244 - MinusLogProbMetric: 16.5244 - val_loss: 16.7879 - val_MinusLogProbMetric: 16.7879 - lr: 5.0000e-04 - 39s/epoch - 201ms/step
Epoch 394/1000
2023-09-27 17:05:22.101 
Epoch 394/1000 
	 loss: 16.5320, MinusLogProbMetric: 16.5320, val_loss: 16.8755, val_MinusLogProbMetric: 16.8755

Epoch 394: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5320 - MinusLogProbMetric: 16.5320 - val_loss: 16.8755 - val_MinusLogProbMetric: 16.8755 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 395/1000
2023-09-27 17:05:56.797 
Epoch 395/1000 
	 loss: 16.5335, MinusLogProbMetric: 16.5335, val_loss: 17.0980, val_MinusLogProbMetric: 17.0980

Epoch 395: val_loss did not improve from 16.78790
196/196 - 35s - loss: 16.5335 - MinusLogProbMetric: 16.5335 - val_loss: 17.0980 - val_MinusLogProbMetric: 17.0980 - lr: 5.0000e-04 - 35s/epoch - 177ms/step
Epoch 396/1000
2023-09-27 17:06:32.657 
Epoch 396/1000 
	 loss: 16.5317, MinusLogProbMetric: 16.5317, val_loss: 16.7925, val_MinusLogProbMetric: 16.7925

Epoch 396: val_loss did not improve from 16.78790
196/196 - 36s - loss: 16.5317 - MinusLogProbMetric: 16.5317 - val_loss: 16.7925 - val_MinusLogProbMetric: 16.7925 - lr: 5.0000e-04 - 36s/epoch - 183ms/step
Epoch 397/1000
2023-09-27 17:07:07.101 
Epoch 397/1000 
	 loss: 16.5363, MinusLogProbMetric: 16.5363, val_loss: 16.8119, val_MinusLogProbMetric: 16.8119

Epoch 397: val_loss did not improve from 16.78790
196/196 - 34s - loss: 16.5363 - MinusLogProbMetric: 16.5363 - val_loss: 16.8119 - val_MinusLogProbMetric: 16.8119 - lr: 5.0000e-04 - 34s/epoch - 176ms/step
Epoch 398/1000
2023-09-27 17:07:39.458 
Epoch 398/1000 
	 loss: 16.5207, MinusLogProbMetric: 16.5207, val_loss: 16.8086, val_MinusLogProbMetric: 16.8086

Epoch 398: val_loss did not improve from 16.78790
196/196 - 32s - loss: 16.5207 - MinusLogProbMetric: 16.5207 - val_loss: 16.8086 - val_MinusLogProbMetric: 16.8086 - lr: 5.0000e-04 - 32s/epoch - 165ms/step
Epoch 399/1000
2023-09-27 17:08:11.472 
Epoch 399/1000 
	 loss: 16.5300, MinusLogProbMetric: 16.5300, val_loss: 16.8765, val_MinusLogProbMetric: 16.8765

Epoch 399: val_loss did not improve from 16.78790
196/196 - 32s - loss: 16.5300 - MinusLogProbMetric: 16.5300 - val_loss: 16.8765 - val_MinusLogProbMetric: 16.8765 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 400/1000
2023-09-27 17:08:44.102 
Epoch 400/1000 
	 loss: 16.5243, MinusLogProbMetric: 16.5243, val_loss: 16.8744, val_MinusLogProbMetric: 16.8744

Epoch 400: val_loss did not improve from 16.78790
196/196 - 33s - loss: 16.5243 - MinusLogProbMetric: 16.5243 - val_loss: 16.8744 - val_MinusLogProbMetric: 16.8744 - lr: 5.0000e-04 - 33s/epoch - 166ms/step
Epoch 401/1000
2023-09-27 17:09:20.396 
Epoch 401/1000 
	 loss: 16.5317, MinusLogProbMetric: 16.5317, val_loss: 16.7947, val_MinusLogProbMetric: 16.7947

Epoch 401: val_loss did not improve from 16.78790
196/196 - 36s - loss: 16.5317 - MinusLogProbMetric: 16.5317 - val_loss: 16.7947 - val_MinusLogProbMetric: 16.7947 - lr: 5.0000e-04 - 36s/epoch - 185ms/step
Epoch 402/1000
2023-09-27 17:09:57.286 
Epoch 402/1000 
	 loss: 16.5444, MinusLogProbMetric: 16.5444, val_loss: 16.8881, val_MinusLogProbMetric: 16.8881

Epoch 402: val_loss did not improve from 16.78790
196/196 - 37s - loss: 16.5444 - MinusLogProbMetric: 16.5444 - val_loss: 16.8881 - val_MinusLogProbMetric: 16.8881 - lr: 5.0000e-04 - 37s/epoch - 188ms/step
Epoch 403/1000
2023-09-27 17:10:29.309 
Epoch 403/1000 
	 loss: 16.5347, MinusLogProbMetric: 16.5347, val_loss: 16.8074, val_MinusLogProbMetric: 16.8074

Epoch 403: val_loss did not improve from 16.78790
196/196 - 32s - loss: 16.5347 - MinusLogProbMetric: 16.5347 - val_loss: 16.8074 - val_MinusLogProbMetric: 16.8074 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 404/1000
2023-09-27 17:11:01.321 
Epoch 404/1000 
	 loss: 16.5262, MinusLogProbMetric: 16.5262, val_loss: 16.8474, val_MinusLogProbMetric: 16.8474

Epoch 404: val_loss did not improve from 16.78790
196/196 - 32s - loss: 16.5262 - MinusLogProbMetric: 16.5262 - val_loss: 16.8474 - val_MinusLogProbMetric: 16.8474 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 405/1000
2023-09-27 17:11:34.030 
Epoch 405/1000 
	 loss: 16.5276, MinusLogProbMetric: 16.5276, val_loss: 16.8444, val_MinusLogProbMetric: 16.8444

Epoch 405: val_loss did not improve from 16.78790
196/196 - 33s - loss: 16.5276 - MinusLogProbMetric: 16.5276 - val_loss: 16.8444 - val_MinusLogProbMetric: 16.8444 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 406/1000
2023-09-27 17:12:09.596 
Epoch 406/1000 
	 loss: 16.5209, MinusLogProbMetric: 16.5209, val_loss: 16.8823, val_MinusLogProbMetric: 16.8823

Epoch 406: val_loss did not improve from 16.78790
196/196 - 36s - loss: 16.5209 - MinusLogProbMetric: 16.5209 - val_loss: 16.8823 - val_MinusLogProbMetric: 16.8823 - lr: 5.0000e-04 - 36s/epoch - 181ms/step
Epoch 407/1000
2023-09-27 17:12:47.192 
Epoch 407/1000 
	 loss: 16.5387, MinusLogProbMetric: 16.5387, val_loss: 16.7996, val_MinusLogProbMetric: 16.7996

Epoch 407: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5387 - MinusLogProbMetric: 16.5387 - val_loss: 16.7996 - val_MinusLogProbMetric: 16.7996 - lr: 5.0000e-04 - 38s/epoch - 192ms/step
Epoch 408/1000
2023-09-27 17:13:25.102 
Epoch 408/1000 
	 loss: 16.5205, MinusLogProbMetric: 16.5205, val_loss: 16.8372, val_MinusLogProbMetric: 16.8372

Epoch 408: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5205 - MinusLogProbMetric: 16.5205 - val_loss: 16.8372 - val_MinusLogProbMetric: 16.8372 - lr: 5.0000e-04 - 38s/epoch - 193ms/step
Epoch 409/1000
2023-09-27 17:14:02.238 
Epoch 409/1000 
	 loss: 16.5174, MinusLogProbMetric: 16.5174, val_loss: 16.8758, val_MinusLogProbMetric: 16.8758

Epoch 409: val_loss did not improve from 16.78790
196/196 - 37s - loss: 16.5174 - MinusLogProbMetric: 16.5174 - val_loss: 16.8758 - val_MinusLogProbMetric: 16.8758 - lr: 5.0000e-04 - 37s/epoch - 189ms/step
Epoch 410/1000
2023-09-27 17:14:40.096 
Epoch 410/1000 
	 loss: 16.5249, MinusLogProbMetric: 16.5249, val_loss: 16.8596, val_MinusLogProbMetric: 16.8596

Epoch 410: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5249 - MinusLogProbMetric: 16.5249 - val_loss: 16.8596 - val_MinusLogProbMetric: 16.8596 - lr: 5.0000e-04 - 38s/epoch - 193ms/step
Epoch 411/1000
2023-09-27 17:15:17.934 
Epoch 411/1000 
	 loss: 16.5233, MinusLogProbMetric: 16.5233, val_loss: 16.9870, val_MinusLogProbMetric: 16.9870

Epoch 411: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5233 - MinusLogProbMetric: 16.5233 - val_loss: 16.9870 - val_MinusLogProbMetric: 16.9870 - lr: 5.0000e-04 - 38s/epoch - 193ms/step
Epoch 412/1000
2023-09-27 17:15:56.434 
Epoch 412/1000 
	 loss: 16.5361, MinusLogProbMetric: 16.5361, val_loss: 16.7968, val_MinusLogProbMetric: 16.7968

Epoch 412: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5361 - MinusLogProbMetric: 16.5361 - val_loss: 16.7968 - val_MinusLogProbMetric: 16.7968 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 413/1000
2023-09-27 17:16:34.463 
Epoch 413/1000 
	 loss: 16.5291, MinusLogProbMetric: 16.5291, val_loss: 17.0911, val_MinusLogProbMetric: 17.0911

Epoch 413: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5291 - MinusLogProbMetric: 16.5291 - val_loss: 17.0911 - val_MinusLogProbMetric: 17.0911 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 414/1000
2023-09-27 17:17:12.587 
Epoch 414/1000 
	 loss: 16.5336, MinusLogProbMetric: 16.5336, val_loss: 16.9221, val_MinusLogProbMetric: 16.9221

Epoch 414: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5336 - MinusLogProbMetric: 16.5336 - val_loss: 16.9221 - val_MinusLogProbMetric: 16.9221 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 415/1000
2023-09-27 17:17:50.768 
Epoch 415/1000 
	 loss: 16.5188, MinusLogProbMetric: 16.5188, val_loss: 16.8594, val_MinusLogProbMetric: 16.8594

Epoch 415: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5188 - MinusLogProbMetric: 16.5188 - val_loss: 16.8594 - val_MinusLogProbMetric: 16.8594 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 416/1000
2023-09-27 17:18:29.066 
Epoch 416/1000 
	 loss: 16.5135, MinusLogProbMetric: 16.5135, val_loss: 16.8163, val_MinusLogProbMetric: 16.8163

Epoch 416: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5135 - MinusLogProbMetric: 16.5135 - val_loss: 16.8163 - val_MinusLogProbMetric: 16.8163 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 417/1000
2023-09-27 17:19:07.058 
Epoch 417/1000 
	 loss: 16.5280, MinusLogProbMetric: 16.5280, val_loss: 16.8682, val_MinusLogProbMetric: 16.8682

Epoch 417: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5280 - MinusLogProbMetric: 16.5280 - val_loss: 16.8682 - val_MinusLogProbMetric: 16.8682 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 418/1000
2023-09-27 17:19:45.083 
Epoch 418/1000 
	 loss: 16.5217, MinusLogProbMetric: 16.5217, val_loss: 16.8288, val_MinusLogProbMetric: 16.8288

Epoch 418: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5217 - MinusLogProbMetric: 16.5217 - val_loss: 16.8288 - val_MinusLogProbMetric: 16.8288 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 419/1000
2023-09-27 17:20:23.208 
Epoch 419/1000 
	 loss: 16.5160, MinusLogProbMetric: 16.5160, val_loss: 16.9293, val_MinusLogProbMetric: 16.9293

Epoch 419: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5160 - MinusLogProbMetric: 16.5160 - val_loss: 16.9293 - val_MinusLogProbMetric: 16.9293 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 420/1000
2023-09-27 17:21:01.018 
Epoch 420/1000 
	 loss: 16.5254, MinusLogProbMetric: 16.5254, val_loss: 16.8166, val_MinusLogProbMetric: 16.8166

Epoch 420: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5254 - MinusLogProbMetric: 16.5254 - val_loss: 16.8166 - val_MinusLogProbMetric: 16.8166 - lr: 5.0000e-04 - 38s/epoch - 193ms/step
Epoch 421/1000
2023-09-27 17:21:39.163 
Epoch 421/1000 
	 loss: 16.5442, MinusLogProbMetric: 16.5442, val_loss: 16.8301, val_MinusLogProbMetric: 16.8301

Epoch 421: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5442 - MinusLogProbMetric: 16.5442 - val_loss: 16.8301 - val_MinusLogProbMetric: 16.8301 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 422/1000
2023-09-27 17:22:16.780 
Epoch 422/1000 
	 loss: 16.5164, MinusLogProbMetric: 16.5164, val_loss: 16.8696, val_MinusLogProbMetric: 16.8696

Epoch 422: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5164 - MinusLogProbMetric: 16.5164 - val_loss: 16.8696 - val_MinusLogProbMetric: 16.8696 - lr: 5.0000e-04 - 38s/epoch - 192ms/step
Epoch 423/1000
2023-09-27 17:22:55.254 
Epoch 423/1000 
	 loss: 16.5157, MinusLogProbMetric: 16.5157, val_loss: 16.8011, val_MinusLogProbMetric: 16.8011

Epoch 423: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5157 - MinusLogProbMetric: 16.5157 - val_loss: 16.8011 - val_MinusLogProbMetric: 16.8011 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 424/1000
2023-09-27 17:23:33.634 
Epoch 424/1000 
	 loss: 16.5299, MinusLogProbMetric: 16.5299, val_loss: 16.8157, val_MinusLogProbMetric: 16.8157

Epoch 424: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5299 - MinusLogProbMetric: 16.5299 - val_loss: 16.8157 - val_MinusLogProbMetric: 16.8157 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 425/1000
2023-09-27 17:24:11.575 
Epoch 425/1000 
	 loss: 16.5208, MinusLogProbMetric: 16.5208, val_loss: 16.8402, val_MinusLogProbMetric: 16.8402

Epoch 425: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5208 - MinusLogProbMetric: 16.5208 - val_loss: 16.8402 - val_MinusLogProbMetric: 16.8402 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 426/1000
2023-09-27 17:24:49.640 
Epoch 426/1000 
	 loss: 16.5133, MinusLogProbMetric: 16.5133, val_loss: 16.8753, val_MinusLogProbMetric: 16.8753

Epoch 426: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5133 - MinusLogProbMetric: 16.5133 - val_loss: 16.8753 - val_MinusLogProbMetric: 16.8753 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 427/1000
2023-09-27 17:25:28.230 
Epoch 427/1000 
	 loss: 16.5226, MinusLogProbMetric: 16.5226, val_loss: 16.8530, val_MinusLogProbMetric: 16.8530

Epoch 427: val_loss did not improve from 16.78790
196/196 - 39s - loss: 16.5226 - MinusLogProbMetric: 16.5226 - val_loss: 16.8530 - val_MinusLogProbMetric: 16.8530 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 428/1000
2023-09-27 17:26:06.093 
Epoch 428/1000 
	 loss: 16.5390, MinusLogProbMetric: 16.5390, val_loss: 16.7991, val_MinusLogProbMetric: 16.7991

Epoch 428: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5390 - MinusLogProbMetric: 16.5390 - val_loss: 16.7991 - val_MinusLogProbMetric: 16.7991 - lr: 5.0000e-04 - 38s/epoch - 193ms/step
Epoch 429/1000
2023-09-27 17:26:44.099 
Epoch 429/1000 
	 loss: 16.5247, MinusLogProbMetric: 16.5247, val_loss: 16.8780, val_MinusLogProbMetric: 16.8780

Epoch 429: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5247 - MinusLogProbMetric: 16.5247 - val_loss: 16.8780 - val_MinusLogProbMetric: 16.8780 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 430/1000
2023-09-27 17:27:22.309 
Epoch 430/1000 
	 loss: 16.5345, MinusLogProbMetric: 16.5345, val_loss: 16.8425, val_MinusLogProbMetric: 16.8425

Epoch 430: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5345 - MinusLogProbMetric: 16.5345 - val_loss: 16.8425 - val_MinusLogProbMetric: 16.8425 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 431/1000
2023-09-27 17:28:00.163 
Epoch 431/1000 
	 loss: 16.5312, MinusLogProbMetric: 16.5312, val_loss: 16.8381, val_MinusLogProbMetric: 16.8381

Epoch 431: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5312 - MinusLogProbMetric: 16.5312 - val_loss: 16.8381 - val_MinusLogProbMetric: 16.8381 - lr: 5.0000e-04 - 38s/epoch - 193ms/step
Epoch 432/1000
2023-09-27 17:28:37.989 
Epoch 432/1000 
	 loss: 16.5233, MinusLogProbMetric: 16.5233, val_loss: 16.8465, val_MinusLogProbMetric: 16.8465

Epoch 432: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5233 - MinusLogProbMetric: 16.5233 - val_loss: 16.8465 - val_MinusLogProbMetric: 16.8465 - lr: 5.0000e-04 - 38s/epoch - 193ms/step
Epoch 433/1000
2023-09-27 17:29:16.129 
Epoch 433/1000 
	 loss: 16.5085, MinusLogProbMetric: 16.5085, val_loss: 16.8761, val_MinusLogProbMetric: 16.8761

Epoch 433: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5085 - MinusLogProbMetric: 16.5085 - val_loss: 16.8761 - val_MinusLogProbMetric: 16.8761 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 434/1000
2023-09-27 17:29:54.812 
Epoch 434/1000 
	 loss: 16.5268, MinusLogProbMetric: 16.5268, val_loss: 16.9776, val_MinusLogProbMetric: 16.9776

Epoch 434: val_loss did not improve from 16.78790
196/196 - 39s - loss: 16.5268 - MinusLogProbMetric: 16.5268 - val_loss: 16.9776 - val_MinusLogProbMetric: 16.9776 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 435/1000
2023-09-27 17:30:33.060 
Epoch 435/1000 
	 loss: 16.5211, MinusLogProbMetric: 16.5211, val_loss: 16.9023, val_MinusLogProbMetric: 16.9023

Epoch 435: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5211 - MinusLogProbMetric: 16.5211 - val_loss: 16.9023 - val_MinusLogProbMetric: 16.9023 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 436/1000
2023-09-27 17:31:11.225 
Epoch 436/1000 
	 loss: 16.5277, MinusLogProbMetric: 16.5277, val_loss: 16.8222, val_MinusLogProbMetric: 16.8222

Epoch 436: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5277 - MinusLogProbMetric: 16.5277 - val_loss: 16.8222 - val_MinusLogProbMetric: 16.8222 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 437/1000
2023-09-27 17:31:49.667 
Epoch 437/1000 
	 loss: 16.5100, MinusLogProbMetric: 16.5100, val_loss: 16.8509, val_MinusLogProbMetric: 16.8509

Epoch 437: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5100 - MinusLogProbMetric: 16.5100 - val_loss: 16.8509 - val_MinusLogProbMetric: 16.8509 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 438/1000
2023-09-27 17:32:27.924 
Epoch 438/1000 
	 loss: 16.5213, MinusLogProbMetric: 16.5213, val_loss: 16.8231, val_MinusLogProbMetric: 16.8231

Epoch 438: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5213 - MinusLogProbMetric: 16.5213 - val_loss: 16.8231 - val_MinusLogProbMetric: 16.8231 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 439/1000
2023-09-27 17:33:05.848 
Epoch 439/1000 
	 loss: 16.5132, MinusLogProbMetric: 16.5132, val_loss: 16.9185, val_MinusLogProbMetric: 16.9185

Epoch 439: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5132 - MinusLogProbMetric: 16.5132 - val_loss: 16.9185 - val_MinusLogProbMetric: 16.9185 - lr: 5.0000e-04 - 38s/epoch - 193ms/step
Epoch 440/1000
2023-09-27 17:33:43.874 
Epoch 440/1000 
	 loss: 16.5194, MinusLogProbMetric: 16.5194, val_loss: 16.8618, val_MinusLogProbMetric: 16.8618

Epoch 440: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5194 - MinusLogProbMetric: 16.5194 - val_loss: 16.8618 - val_MinusLogProbMetric: 16.8618 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 441/1000
2023-09-27 17:34:21.615 
Epoch 441/1000 
	 loss: 16.5111, MinusLogProbMetric: 16.5111, val_loss: 16.8064, val_MinusLogProbMetric: 16.8064

Epoch 441: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5111 - MinusLogProbMetric: 16.5111 - val_loss: 16.8064 - val_MinusLogProbMetric: 16.8064 - lr: 5.0000e-04 - 38s/epoch - 193ms/step
Epoch 442/1000
2023-09-27 17:34:59.972 
Epoch 442/1000 
	 loss: 16.5042, MinusLogProbMetric: 16.5042, val_loss: 16.8469, val_MinusLogProbMetric: 16.8469

Epoch 442: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5042 - MinusLogProbMetric: 16.5042 - val_loss: 16.8469 - val_MinusLogProbMetric: 16.8469 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 443/1000
2023-09-27 17:35:38.440 
Epoch 443/1000 
	 loss: 16.5077, MinusLogProbMetric: 16.5077, val_loss: 16.9154, val_MinusLogProbMetric: 16.9154

Epoch 443: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.5077 - MinusLogProbMetric: 16.5077 - val_loss: 16.9154 - val_MinusLogProbMetric: 16.9154 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 444/1000
2023-09-27 17:36:16.741 
Epoch 444/1000 
	 loss: 16.4473, MinusLogProbMetric: 16.4473, val_loss: 16.8598, val_MinusLogProbMetric: 16.8598

Epoch 444: val_loss did not improve from 16.78790
196/196 - 38s - loss: 16.4473 - MinusLogProbMetric: 16.4473 - val_loss: 16.8598 - val_MinusLogProbMetric: 16.8598 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 445/1000
2023-09-27 17:36:55.186 
Epoch 445/1000 
	 loss: 16.4455, MinusLogProbMetric: 16.4455, val_loss: 16.7695, val_MinusLogProbMetric: 16.7695

Epoch 445: val_loss improved from 16.78790 to 16.76949, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 39s - loss: 16.4455 - MinusLogProbMetric: 16.4455 - val_loss: 16.7695 - val_MinusLogProbMetric: 16.7695 - lr: 2.5000e-04 - 39s/epoch - 200ms/step
Epoch 446/1000
2023-09-27 17:37:34.260 
Epoch 446/1000 
	 loss: 16.4443, MinusLogProbMetric: 16.4443, val_loss: 16.7740, val_MinusLogProbMetric: 16.7740

Epoch 446: val_loss did not improve from 16.76949
196/196 - 38s - loss: 16.4443 - MinusLogProbMetric: 16.4443 - val_loss: 16.7740 - val_MinusLogProbMetric: 16.7740 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 447/1000
2023-09-27 17:38:12.392 
Epoch 447/1000 
	 loss: 16.4451, MinusLogProbMetric: 16.4451, val_loss: 16.7923, val_MinusLogProbMetric: 16.7923

Epoch 447: val_loss did not improve from 16.76949
196/196 - 38s - loss: 16.4451 - MinusLogProbMetric: 16.4451 - val_loss: 16.7923 - val_MinusLogProbMetric: 16.7923 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 448/1000
2023-09-27 17:38:50.516 
Epoch 448/1000 
	 loss: 16.4467, MinusLogProbMetric: 16.4467, val_loss: 16.8031, val_MinusLogProbMetric: 16.8031

Epoch 448: val_loss did not improve from 16.76949
196/196 - 38s - loss: 16.4467 - MinusLogProbMetric: 16.4467 - val_loss: 16.8031 - val_MinusLogProbMetric: 16.8031 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 449/1000
2023-09-27 17:39:29.016 
Epoch 449/1000 
	 loss: 16.4538, MinusLogProbMetric: 16.4538, val_loss: 16.7999, val_MinusLogProbMetric: 16.7999

Epoch 449: val_loss did not improve from 16.76949
196/196 - 38s - loss: 16.4538 - MinusLogProbMetric: 16.4538 - val_loss: 16.7999 - val_MinusLogProbMetric: 16.7999 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 450/1000
2023-09-27 17:40:07.259 
Epoch 450/1000 
	 loss: 16.4419, MinusLogProbMetric: 16.4419, val_loss: 16.7858, val_MinusLogProbMetric: 16.7858

Epoch 450: val_loss did not improve from 16.76949
196/196 - 38s - loss: 16.4419 - MinusLogProbMetric: 16.4419 - val_loss: 16.7858 - val_MinusLogProbMetric: 16.7858 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 451/1000
2023-09-27 17:40:45.730 
Epoch 451/1000 
	 loss: 16.4436, MinusLogProbMetric: 16.4436, val_loss: 16.7881, val_MinusLogProbMetric: 16.7881

Epoch 451: val_loss did not improve from 16.76949
196/196 - 38s - loss: 16.4436 - MinusLogProbMetric: 16.4436 - val_loss: 16.7881 - val_MinusLogProbMetric: 16.7881 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 452/1000
2023-09-27 17:41:23.488 
Epoch 452/1000 
	 loss: 16.4375, MinusLogProbMetric: 16.4375, val_loss: 16.7683, val_MinusLogProbMetric: 16.7683

Epoch 452: val_loss improved from 16.76949 to 16.76835, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 38s - loss: 16.4375 - MinusLogProbMetric: 16.4375 - val_loss: 16.7683 - val_MinusLogProbMetric: 16.7683 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 453/1000
2023-09-27 17:42:02.313 
Epoch 453/1000 
	 loss: 16.4409, MinusLogProbMetric: 16.4409, val_loss: 16.8261, val_MinusLogProbMetric: 16.8261

Epoch 453: val_loss did not improve from 16.76835
196/196 - 38s - loss: 16.4409 - MinusLogProbMetric: 16.4409 - val_loss: 16.8261 - val_MinusLogProbMetric: 16.8261 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 454/1000
2023-09-27 17:42:40.267 
Epoch 454/1000 
	 loss: 16.4529, MinusLogProbMetric: 16.4529, val_loss: 16.7908, val_MinusLogProbMetric: 16.7908

Epoch 454: val_loss did not improve from 16.76835
196/196 - 38s - loss: 16.4529 - MinusLogProbMetric: 16.4529 - val_loss: 16.7908 - val_MinusLogProbMetric: 16.7908 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 455/1000
2023-09-27 17:43:18.633 
Epoch 455/1000 
	 loss: 16.4429, MinusLogProbMetric: 16.4429, val_loss: 16.7700, val_MinusLogProbMetric: 16.7700

Epoch 455: val_loss did not improve from 16.76835
196/196 - 38s - loss: 16.4429 - MinusLogProbMetric: 16.4429 - val_loss: 16.7700 - val_MinusLogProbMetric: 16.7700 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 456/1000
2023-09-27 17:43:56.509 
Epoch 456/1000 
	 loss: 16.4461, MinusLogProbMetric: 16.4461, val_loss: 16.7983, val_MinusLogProbMetric: 16.7983

Epoch 456: val_loss did not improve from 16.76835
196/196 - 38s - loss: 16.4461 - MinusLogProbMetric: 16.4461 - val_loss: 16.7983 - val_MinusLogProbMetric: 16.7983 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 457/1000
2023-09-27 17:44:34.745 
Epoch 457/1000 
	 loss: 16.4448, MinusLogProbMetric: 16.4448, val_loss: 16.7649, val_MinusLogProbMetric: 16.7649

Epoch 457: val_loss improved from 16.76835 to 16.76493, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 39s - loss: 16.4448 - MinusLogProbMetric: 16.4448 - val_loss: 16.7649 - val_MinusLogProbMetric: 16.7649 - lr: 2.5000e-04 - 39s/epoch - 199ms/step
Epoch 458/1000
2023-09-27 17:45:13.276 
Epoch 458/1000 
	 loss: 16.4394, MinusLogProbMetric: 16.4394, val_loss: 16.7976, val_MinusLogProbMetric: 16.7976

Epoch 458: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4394 - MinusLogProbMetric: 16.4394 - val_loss: 16.7976 - val_MinusLogProbMetric: 16.7976 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 459/1000
2023-09-27 17:45:51.759 
Epoch 459/1000 
	 loss: 16.4478, MinusLogProbMetric: 16.4478, val_loss: 16.7861, val_MinusLogProbMetric: 16.7861

Epoch 459: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4478 - MinusLogProbMetric: 16.4478 - val_loss: 16.7861 - val_MinusLogProbMetric: 16.7861 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 460/1000
2023-09-27 17:46:29.966 
Epoch 460/1000 
	 loss: 16.4452, MinusLogProbMetric: 16.4452, val_loss: 16.8181, val_MinusLogProbMetric: 16.8181

Epoch 460: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4452 - MinusLogProbMetric: 16.4452 - val_loss: 16.8181 - val_MinusLogProbMetric: 16.8181 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 461/1000
2023-09-27 17:47:08.214 
Epoch 461/1000 
	 loss: 16.4439, MinusLogProbMetric: 16.4439, val_loss: 16.8227, val_MinusLogProbMetric: 16.8227

Epoch 461: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4439 - MinusLogProbMetric: 16.4439 - val_loss: 16.8227 - val_MinusLogProbMetric: 16.8227 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 462/1000
2023-09-27 17:47:46.546 
Epoch 462/1000 
	 loss: 16.4443, MinusLogProbMetric: 16.4443, val_loss: 16.7747, val_MinusLogProbMetric: 16.7747

Epoch 462: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4443 - MinusLogProbMetric: 16.4443 - val_loss: 16.7747 - val_MinusLogProbMetric: 16.7747 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 463/1000
2023-09-27 17:48:25.358 
Epoch 463/1000 
	 loss: 16.4395, MinusLogProbMetric: 16.4395, val_loss: 16.7744, val_MinusLogProbMetric: 16.7744

Epoch 463: val_loss did not improve from 16.76493
196/196 - 39s - loss: 16.4395 - MinusLogProbMetric: 16.4395 - val_loss: 16.7744 - val_MinusLogProbMetric: 16.7744 - lr: 2.5000e-04 - 39s/epoch - 198ms/step
Epoch 464/1000
2023-09-27 17:49:03.754 
Epoch 464/1000 
	 loss: 16.4373, MinusLogProbMetric: 16.4373, val_loss: 16.7810, val_MinusLogProbMetric: 16.7810

Epoch 464: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4373 - MinusLogProbMetric: 16.4373 - val_loss: 16.7810 - val_MinusLogProbMetric: 16.7810 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 465/1000
2023-09-27 17:49:42.178 
Epoch 465/1000 
	 loss: 16.4435, MinusLogProbMetric: 16.4435, val_loss: 16.7923, val_MinusLogProbMetric: 16.7923

Epoch 465: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4435 - MinusLogProbMetric: 16.4435 - val_loss: 16.7923 - val_MinusLogProbMetric: 16.7923 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 466/1000
2023-09-27 17:50:20.578 
Epoch 466/1000 
	 loss: 16.4446, MinusLogProbMetric: 16.4446, val_loss: 16.7875, val_MinusLogProbMetric: 16.7875

Epoch 466: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4446 - MinusLogProbMetric: 16.4446 - val_loss: 16.7875 - val_MinusLogProbMetric: 16.7875 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 467/1000
2023-09-27 17:50:58.913 
Epoch 467/1000 
	 loss: 16.4416, MinusLogProbMetric: 16.4416, val_loss: 16.8110, val_MinusLogProbMetric: 16.8110

Epoch 467: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4416 - MinusLogProbMetric: 16.4416 - val_loss: 16.8110 - val_MinusLogProbMetric: 16.8110 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 468/1000
2023-09-27 17:51:36.884 
Epoch 468/1000 
	 loss: 16.4443, MinusLogProbMetric: 16.4443, val_loss: 16.8090, val_MinusLogProbMetric: 16.8090

Epoch 468: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4443 - MinusLogProbMetric: 16.4443 - val_loss: 16.8090 - val_MinusLogProbMetric: 16.8090 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 469/1000
2023-09-27 17:52:15.203 
Epoch 469/1000 
	 loss: 16.4355, MinusLogProbMetric: 16.4355, val_loss: 16.7706, val_MinusLogProbMetric: 16.7706

Epoch 469: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4355 - MinusLogProbMetric: 16.4355 - val_loss: 16.7706 - val_MinusLogProbMetric: 16.7706 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 470/1000
2023-09-27 17:52:53.645 
Epoch 470/1000 
	 loss: 16.4538, MinusLogProbMetric: 16.4538, val_loss: 16.7875, val_MinusLogProbMetric: 16.7875

Epoch 470: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4538 - MinusLogProbMetric: 16.4538 - val_loss: 16.7875 - val_MinusLogProbMetric: 16.7875 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 471/1000
2023-09-27 17:53:32.015 
Epoch 471/1000 
	 loss: 16.4422, MinusLogProbMetric: 16.4422, val_loss: 16.8120, val_MinusLogProbMetric: 16.8120

Epoch 471: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4422 - MinusLogProbMetric: 16.4422 - val_loss: 16.8120 - val_MinusLogProbMetric: 16.8120 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 472/1000
2023-09-27 17:54:10.262 
Epoch 472/1000 
	 loss: 16.4413, MinusLogProbMetric: 16.4413, val_loss: 16.7869, val_MinusLogProbMetric: 16.7869

Epoch 472: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4413 - MinusLogProbMetric: 16.4413 - val_loss: 16.7869 - val_MinusLogProbMetric: 16.7869 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 473/1000
2023-09-27 17:54:48.338 
Epoch 473/1000 
	 loss: 16.4393, MinusLogProbMetric: 16.4393, val_loss: 16.7773, val_MinusLogProbMetric: 16.7773

Epoch 473: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4393 - MinusLogProbMetric: 16.4393 - val_loss: 16.7773 - val_MinusLogProbMetric: 16.7773 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 474/1000
2023-09-27 17:55:26.565 
Epoch 474/1000 
	 loss: 16.4408, MinusLogProbMetric: 16.4408, val_loss: 16.8159, val_MinusLogProbMetric: 16.8159

Epoch 474: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4408 - MinusLogProbMetric: 16.4408 - val_loss: 16.8159 - val_MinusLogProbMetric: 16.8159 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 475/1000
2023-09-27 17:56:04.643 
Epoch 475/1000 
	 loss: 16.4361, MinusLogProbMetric: 16.4361, val_loss: 16.7972, val_MinusLogProbMetric: 16.7972

Epoch 475: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4361 - MinusLogProbMetric: 16.4361 - val_loss: 16.7972 - val_MinusLogProbMetric: 16.7972 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 476/1000
2023-09-27 17:56:42.968 
Epoch 476/1000 
	 loss: 16.4399, MinusLogProbMetric: 16.4399, val_loss: 16.8086, val_MinusLogProbMetric: 16.8086

Epoch 476: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4399 - MinusLogProbMetric: 16.4399 - val_loss: 16.8086 - val_MinusLogProbMetric: 16.8086 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 477/1000
2023-09-27 17:57:21.324 
Epoch 477/1000 
	 loss: 16.4425, MinusLogProbMetric: 16.4425, val_loss: 16.7931, val_MinusLogProbMetric: 16.7931

Epoch 477: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4425 - MinusLogProbMetric: 16.4425 - val_loss: 16.7931 - val_MinusLogProbMetric: 16.7931 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 478/1000
2023-09-27 17:57:59.212 
Epoch 478/1000 
	 loss: 16.4441, MinusLogProbMetric: 16.4441, val_loss: 16.7908, val_MinusLogProbMetric: 16.7908

Epoch 478: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4441 - MinusLogProbMetric: 16.4441 - val_loss: 16.7908 - val_MinusLogProbMetric: 16.7908 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 479/1000
2023-09-27 17:58:37.117 
Epoch 479/1000 
	 loss: 16.4377, MinusLogProbMetric: 16.4377, val_loss: 16.8189, val_MinusLogProbMetric: 16.8189

Epoch 479: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4377 - MinusLogProbMetric: 16.4377 - val_loss: 16.8189 - val_MinusLogProbMetric: 16.8189 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 480/1000
2023-09-27 17:59:15.250 
Epoch 480/1000 
	 loss: 16.4422, MinusLogProbMetric: 16.4422, val_loss: 16.7834, val_MinusLogProbMetric: 16.7834

Epoch 480: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4422 - MinusLogProbMetric: 16.4422 - val_loss: 16.7834 - val_MinusLogProbMetric: 16.7834 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 481/1000
2023-09-27 17:59:53.054 
Epoch 481/1000 
	 loss: 16.4401, MinusLogProbMetric: 16.4401, val_loss: 16.7788, val_MinusLogProbMetric: 16.7788

Epoch 481: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4401 - MinusLogProbMetric: 16.4401 - val_loss: 16.7788 - val_MinusLogProbMetric: 16.7788 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 482/1000
2023-09-27 18:00:31.456 
Epoch 482/1000 
	 loss: 16.4348, MinusLogProbMetric: 16.4348, val_loss: 16.7691, val_MinusLogProbMetric: 16.7691

Epoch 482: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4348 - MinusLogProbMetric: 16.4348 - val_loss: 16.7691 - val_MinusLogProbMetric: 16.7691 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 483/1000
2023-09-27 18:01:09.808 
Epoch 483/1000 
	 loss: 16.4382, MinusLogProbMetric: 16.4382, val_loss: 16.8318, val_MinusLogProbMetric: 16.8318

Epoch 483: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4382 - MinusLogProbMetric: 16.4382 - val_loss: 16.8318 - val_MinusLogProbMetric: 16.8318 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 484/1000
2023-09-27 18:01:47.743 
Epoch 484/1000 
	 loss: 16.4451, MinusLogProbMetric: 16.4451, val_loss: 16.7777, val_MinusLogProbMetric: 16.7777

Epoch 484: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4451 - MinusLogProbMetric: 16.4451 - val_loss: 16.7777 - val_MinusLogProbMetric: 16.7777 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 485/1000
2023-09-27 18:02:26.360 
Epoch 485/1000 
	 loss: 16.4353, MinusLogProbMetric: 16.4353, val_loss: 16.7863, val_MinusLogProbMetric: 16.7863

Epoch 485: val_loss did not improve from 16.76493
196/196 - 39s - loss: 16.4353 - MinusLogProbMetric: 16.4353 - val_loss: 16.7863 - val_MinusLogProbMetric: 16.7863 - lr: 2.5000e-04 - 39s/epoch - 197ms/step
Epoch 486/1000
2023-09-27 18:03:04.181 
Epoch 486/1000 
	 loss: 16.4446, MinusLogProbMetric: 16.4446, val_loss: 16.8007, val_MinusLogProbMetric: 16.8007

Epoch 486: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4446 - MinusLogProbMetric: 16.4446 - val_loss: 16.8007 - val_MinusLogProbMetric: 16.8007 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 487/1000
2023-09-27 18:03:42.130 
Epoch 487/1000 
	 loss: 16.4424, MinusLogProbMetric: 16.4424, val_loss: 16.7712, val_MinusLogProbMetric: 16.7712

Epoch 487: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4424 - MinusLogProbMetric: 16.4424 - val_loss: 16.7712 - val_MinusLogProbMetric: 16.7712 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 488/1000
2023-09-27 18:04:20.037 
Epoch 488/1000 
	 loss: 16.4346, MinusLogProbMetric: 16.4346, val_loss: 16.8412, val_MinusLogProbMetric: 16.8412

Epoch 488: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4346 - MinusLogProbMetric: 16.4346 - val_loss: 16.8412 - val_MinusLogProbMetric: 16.8412 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 489/1000
2023-09-27 18:04:58.208 
Epoch 489/1000 
	 loss: 16.4425, MinusLogProbMetric: 16.4425, val_loss: 16.7762, val_MinusLogProbMetric: 16.7762

Epoch 489: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4425 - MinusLogProbMetric: 16.4425 - val_loss: 16.7762 - val_MinusLogProbMetric: 16.7762 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 490/1000
2023-09-27 18:05:36.391 
Epoch 490/1000 
	 loss: 16.4401, MinusLogProbMetric: 16.4401, val_loss: 16.7812, val_MinusLogProbMetric: 16.7812

Epoch 490: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4401 - MinusLogProbMetric: 16.4401 - val_loss: 16.7812 - val_MinusLogProbMetric: 16.7812 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 491/1000
2023-09-27 18:06:14.992 
Epoch 491/1000 
	 loss: 16.4328, MinusLogProbMetric: 16.4328, val_loss: 16.7864, val_MinusLogProbMetric: 16.7864

Epoch 491: val_loss did not improve from 16.76493
196/196 - 39s - loss: 16.4328 - MinusLogProbMetric: 16.4328 - val_loss: 16.7864 - val_MinusLogProbMetric: 16.7864 - lr: 2.5000e-04 - 39s/epoch - 197ms/step
Epoch 492/1000
2023-09-27 18:06:52.913 
Epoch 492/1000 
	 loss: 16.4362, MinusLogProbMetric: 16.4362, val_loss: 16.7926, val_MinusLogProbMetric: 16.7926

Epoch 492: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4362 - MinusLogProbMetric: 16.4362 - val_loss: 16.7926 - val_MinusLogProbMetric: 16.7926 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 493/1000
2023-09-27 18:07:31.287 
Epoch 493/1000 
	 loss: 16.4338, MinusLogProbMetric: 16.4338, val_loss: 16.7954, val_MinusLogProbMetric: 16.7954

Epoch 493: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4338 - MinusLogProbMetric: 16.4338 - val_loss: 16.7954 - val_MinusLogProbMetric: 16.7954 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 494/1000
2023-09-27 18:08:09.464 
Epoch 494/1000 
	 loss: 16.4349, MinusLogProbMetric: 16.4349, val_loss: 16.7821, val_MinusLogProbMetric: 16.7821

Epoch 494: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4349 - MinusLogProbMetric: 16.4349 - val_loss: 16.7821 - val_MinusLogProbMetric: 16.7821 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 495/1000
2023-09-27 18:08:47.564 
Epoch 495/1000 
	 loss: 16.4381, MinusLogProbMetric: 16.4381, val_loss: 16.7857, val_MinusLogProbMetric: 16.7857

Epoch 495: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4381 - MinusLogProbMetric: 16.4381 - val_loss: 16.7857 - val_MinusLogProbMetric: 16.7857 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 496/1000
2023-09-27 18:09:25.633 
Epoch 496/1000 
	 loss: 16.4320, MinusLogProbMetric: 16.4320, val_loss: 16.7827, val_MinusLogProbMetric: 16.7827

Epoch 496: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4320 - MinusLogProbMetric: 16.4320 - val_loss: 16.7827 - val_MinusLogProbMetric: 16.7827 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 497/1000
2023-09-27 18:10:04.057 
Epoch 497/1000 
	 loss: 16.4524, MinusLogProbMetric: 16.4524, val_loss: 16.8225, val_MinusLogProbMetric: 16.8225

Epoch 497: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4524 - MinusLogProbMetric: 16.4524 - val_loss: 16.8225 - val_MinusLogProbMetric: 16.8225 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 498/1000
2023-09-27 18:10:41.945 
Epoch 498/1000 
	 loss: 16.4379, MinusLogProbMetric: 16.4379, val_loss: 16.8030, val_MinusLogProbMetric: 16.8030

Epoch 498: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4379 - MinusLogProbMetric: 16.4379 - val_loss: 16.8030 - val_MinusLogProbMetric: 16.8030 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 499/1000
2023-09-27 18:11:19.753 
Epoch 499/1000 
	 loss: 16.4377, MinusLogProbMetric: 16.4377, val_loss: 16.7817, val_MinusLogProbMetric: 16.7817

Epoch 499: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4377 - MinusLogProbMetric: 16.4377 - val_loss: 16.7817 - val_MinusLogProbMetric: 16.7817 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 500/1000
2023-09-27 18:11:57.557 
Epoch 500/1000 
	 loss: 16.4363, MinusLogProbMetric: 16.4363, val_loss: 16.7899, val_MinusLogProbMetric: 16.7899

Epoch 500: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4363 - MinusLogProbMetric: 16.4363 - val_loss: 16.7899 - val_MinusLogProbMetric: 16.7899 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 501/1000
2023-09-27 18:12:35.570 
Epoch 501/1000 
	 loss: 16.4481, MinusLogProbMetric: 16.4481, val_loss: 16.8104, val_MinusLogProbMetric: 16.8104

Epoch 501: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4481 - MinusLogProbMetric: 16.4481 - val_loss: 16.8104 - val_MinusLogProbMetric: 16.8104 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 502/1000
2023-09-27 18:13:13.858 
Epoch 502/1000 
	 loss: 16.4371, MinusLogProbMetric: 16.4371, val_loss: 16.7923, val_MinusLogProbMetric: 16.7923

Epoch 502: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4371 - MinusLogProbMetric: 16.4371 - val_loss: 16.7923 - val_MinusLogProbMetric: 16.7923 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 503/1000
2023-09-27 18:13:51.931 
Epoch 503/1000 
	 loss: 16.4325, MinusLogProbMetric: 16.4325, val_loss: 16.7712, val_MinusLogProbMetric: 16.7712

Epoch 503: val_loss did not improve from 16.76493
196/196 - 38s - loss: 16.4325 - MinusLogProbMetric: 16.4325 - val_loss: 16.7712 - val_MinusLogProbMetric: 16.7712 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 504/1000
2023-09-27 18:14:30.035 
Epoch 504/1000 
	 loss: 16.4342, MinusLogProbMetric: 16.4342, val_loss: 16.7631, val_MinusLogProbMetric: 16.7631

Epoch 504: val_loss improved from 16.76493 to 16.76312, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 39s - loss: 16.4342 - MinusLogProbMetric: 16.4342 - val_loss: 16.7631 - val_MinusLogProbMetric: 16.7631 - lr: 2.5000e-04 - 39s/epoch - 198ms/step
Epoch 505/1000
2023-09-27 18:15:09.292 
Epoch 505/1000 
	 loss: 16.4339, MinusLogProbMetric: 16.4339, val_loss: 16.8094, val_MinusLogProbMetric: 16.8094

Epoch 505: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4339 - MinusLogProbMetric: 16.4339 - val_loss: 16.8094 - val_MinusLogProbMetric: 16.8094 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 506/1000
2023-09-27 18:15:47.403 
Epoch 506/1000 
	 loss: 16.4336, MinusLogProbMetric: 16.4336, val_loss: 16.7841, val_MinusLogProbMetric: 16.7841

Epoch 506: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4336 - MinusLogProbMetric: 16.4336 - val_loss: 16.7841 - val_MinusLogProbMetric: 16.7841 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 507/1000
2023-09-27 18:16:25.573 
Epoch 507/1000 
	 loss: 16.4391, MinusLogProbMetric: 16.4391, val_loss: 16.8083, val_MinusLogProbMetric: 16.8083

Epoch 507: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4391 - MinusLogProbMetric: 16.4391 - val_loss: 16.8083 - val_MinusLogProbMetric: 16.8083 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 508/1000
2023-09-27 18:17:03.289 
Epoch 508/1000 
	 loss: 16.4322, MinusLogProbMetric: 16.4322, val_loss: 16.8090, val_MinusLogProbMetric: 16.8090

Epoch 508: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4322 - MinusLogProbMetric: 16.4322 - val_loss: 16.8090 - val_MinusLogProbMetric: 16.8090 - lr: 2.5000e-04 - 38s/epoch - 192ms/step
Epoch 509/1000
2023-09-27 18:17:41.223 
Epoch 509/1000 
	 loss: 16.4387, MinusLogProbMetric: 16.4387, val_loss: 16.7759, val_MinusLogProbMetric: 16.7759

Epoch 509: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4387 - MinusLogProbMetric: 16.4387 - val_loss: 16.7759 - val_MinusLogProbMetric: 16.7759 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 510/1000
2023-09-27 18:18:19.490 
Epoch 510/1000 
	 loss: 16.4345, MinusLogProbMetric: 16.4345, val_loss: 16.7763, val_MinusLogProbMetric: 16.7763

Epoch 510: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4345 - MinusLogProbMetric: 16.4345 - val_loss: 16.7763 - val_MinusLogProbMetric: 16.7763 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 511/1000
2023-09-27 18:18:58.028 
Epoch 511/1000 
	 loss: 16.4318, MinusLogProbMetric: 16.4318, val_loss: 16.7809, val_MinusLogProbMetric: 16.7809

Epoch 511: val_loss did not improve from 16.76312
196/196 - 39s - loss: 16.4318 - MinusLogProbMetric: 16.4318 - val_loss: 16.7809 - val_MinusLogProbMetric: 16.7809 - lr: 2.5000e-04 - 39s/epoch - 197ms/step
Epoch 512/1000
2023-09-27 18:19:35.961 
Epoch 512/1000 
	 loss: 16.4365, MinusLogProbMetric: 16.4365, val_loss: 16.7934, val_MinusLogProbMetric: 16.7934

Epoch 512: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4365 - MinusLogProbMetric: 16.4365 - val_loss: 16.7934 - val_MinusLogProbMetric: 16.7934 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 513/1000
2023-09-27 18:20:14.096 
Epoch 513/1000 
	 loss: 16.4323, MinusLogProbMetric: 16.4323, val_loss: 16.7828, val_MinusLogProbMetric: 16.7828

Epoch 513: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4323 - MinusLogProbMetric: 16.4323 - val_loss: 16.7828 - val_MinusLogProbMetric: 16.7828 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 514/1000
2023-09-27 18:20:52.046 
Epoch 514/1000 
	 loss: 16.4326, MinusLogProbMetric: 16.4326, val_loss: 16.7844, val_MinusLogProbMetric: 16.7844

Epoch 514: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4326 - MinusLogProbMetric: 16.4326 - val_loss: 16.7844 - val_MinusLogProbMetric: 16.7844 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 515/1000
2023-09-27 18:21:30.435 
Epoch 515/1000 
	 loss: 16.4330, MinusLogProbMetric: 16.4330, val_loss: 16.7705, val_MinusLogProbMetric: 16.7705

Epoch 515: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4330 - MinusLogProbMetric: 16.4330 - val_loss: 16.7705 - val_MinusLogProbMetric: 16.7705 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 516/1000
2023-09-27 18:22:08.646 
Epoch 516/1000 
	 loss: 16.4364, MinusLogProbMetric: 16.4364, val_loss: 16.7771, val_MinusLogProbMetric: 16.7771

Epoch 516: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4364 - MinusLogProbMetric: 16.4364 - val_loss: 16.7771 - val_MinusLogProbMetric: 16.7771 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 517/1000
2023-09-27 18:22:46.684 
Epoch 517/1000 
	 loss: 16.4360, MinusLogProbMetric: 16.4360, val_loss: 16.7723, val_MinusLogProbMetric: 16.7723

Epoch 517: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4360 - MinusLogProbMetric: 16.4360 - val_loss: 16.7723 - val_MinusLogProbMetric: 16.7723 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 518/1000
2023-09-27 18:23:25.033 
Epoch 518/1000 
	 loss: 16.4328, MinusLogProbMetric: 16.4328, val_loss: 16.7713, val_MinusLogProbMetric: 16.7713

Epoch 518: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4328 - MinusLogProbMetric: 16.4328 - val_loss: 16.7713 - val_MinusLogProbMetric: 16.7713 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 519/1000
2023-09-27 18:24:03.390 
Epoch 519/1000 
	 loss: 16.4382, MinusLogProbMetric: 16.4382, val_loss: 16.7982, val_MinusLogProbMetric: 16.7982

Epoch 519: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4382 - MinusLogProbMetric: 16.4382 - val_loss: 16.7982 - val_MinusLogProbMetric: 16.7982 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 520/1000
2023-09-27 18:24:41.734 
Epoch 520/1000 
	 loss: 16.4355, MinusLogProbMetric: 16.4355, val_loss: 16.7948, val_MinusLogProbMetric: 16.7948

Epoch 520: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4355 - MinusLogProbMetric: 16.4355 - val_loss: 16.7948 - val_MinusLogProbMetric: 16.7948 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 521/1000
2023-09-27 18:25:19.978 
Epoch 521/1000 
	 loss: 16.4355, MinusLogProbMetric: 16.4355, val_loss: 16.7987, val_MinusLogProbMetric: 16.7987

Epoch 521: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4355 - MinusLogProbMetric: 16.4355 - val_loss: 16.7987 - val_MinusLogProbMetric: 16.7987 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 522/1000
2023-09-27 18:25:58.043 
Epoch 522/1000 
	 loss: 16.4304, MinusLogProbMetric: 16.4304, val_loss: 16.7849, val_MinusLogProbMetric: 16.7849

Epoch 522: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4304 - MinusLogProbMetric: 16.4304 - val_loss: 16.7849 - val_MinusLogProbMetric: 16.7849 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 523/1000
2023-09-27 18:26:36.286 
Epoch 523/1000 
	 loss: 16.4287, MinusLogProbMetric: 16.4287, val_loss: 16.7715, val_MinusLogProbMetric: 16.7715

Epoch 523: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4287 - MinusLogProbMetric: 16.4287 - val_loss: 16.7715 - val_MinusLogProbMetric: 16.7715 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 524/1000
2023-09-27 18:27:14.487 
Epoch 524/1000 
	 loss: 16.4330, MinusLogProbMetric: 16.4330, val_loss: 16.7788, val_MinusLogProbMetric: 16.7788

Epoch 524: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4330 - MinusLogProbMetric: 16.4330 - val_loss: 16.7788 - val_MinusLogProbMetric: 16.7788 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 525/1000
2023-09-27 18:27:53.049 
Epoch 525/1000 
	 loss: 16.4296, MinusLogProbMetric: 16.4296, val_loss: 16.8061, val_MinusLogProbMetric: 16.8061

Epoch 525: val_loss did not improve from 16.76312
196/196 - 39s - loss: 16.4296 - MinusLogProbMetric: 16.4296 - val_loss: 16.8061 - val_MinusLogProbMetric: 16.8061 - lr: 2.5000e-04 - 39s/epoch - 197ms/step
Epoch 526/1000
2023-09-27 18:28:31.187 
Epoch 526/1000 
	 loss: 16.4271, MinusLogProbMetric: 16.4271, val_loss: 16.8127, val_MinusLogProbMetric: 16.8127

Epoch 526: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4271 - MinusLogProbMetric: 16.4271 - val_loss: 16.8127 - val_MinusLogProbMetric: 16.8127 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 527/1000
2023-09-27 18:29:09.005 
Epoch 527/1000 
	 loss: 16.4450, MinusLogProbMetric: 16.4450, val_loss: 16.7984, val_MinusLogProbMetric: 16.7984

Epoch 527: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4450 - MinusLogProbMetric: 16.4450 - val_loss: 16.7984 - val_MinusLogProbMetric: 16.7984 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 528/1000
2023-09-27 18:29:46.977 
Epoch 528/1000 
	 loss: 16.4297, MinusLogProbMetric: 16.4297, val_loss: 16.7925, val_MinusLogProbMetric: 16.7925

Epoch 528: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4297 - MinusLogProbMetric: 16.4297 - val_loss: 16.7925 - val_MinusLogProbMetric: 16.7925 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 529/1000
2023-09-27 18:30:24.990 
Epoch 529/1000 
	 loss: 16.4338, MinusLogProbMetric: 16.4338, val_loss: 16.7937, val_MinusLogProbMetric: 16.7937

Epoch 529: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4338 - MinusLogProbMetric: 16.4338 - val_loss: 16.7937 - val_MinusLogProbMetric: 16.7937 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 530/1000
2023-09-27 18:31:03.165 
Epoch 530/1000 
	 loss: 16.4277, MinusLogProbMetric: 16.4277, val_loss: 16.7848, val_MinusLogProbMetric: 16.7848

Epoch 530: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4277 - MinusLogProbMetric: 16.4277 - val_loss: 16.7848 - val_MinusLogProbMetric: 16.7848 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 531/1000
2023-09-27 18:31:41.673 
Epoch 531/1000 
	 loss: 16.4280, MinusLogProbMetric: 16.4280, val_loss: 16.7863, val_MinusLogProbMetric: 16.7863

Epoch 531: val_loss did not improve from 16.76312
196/196 - 39s - loss: 16.4280 - MinusLogProbMetric: 16.4280 - val_loss: 16.7863 - val_MinusLogProbMetric: 16.7863 - lr: 2.5000e-04 - 39s/epoch - 196ms/step
Epoch 532/1000
2023-09-27 18:32:19.719 
Epoch 532/1000 
	 loss: 16.4306, MinusLogProbMetric: 16.4306, val_loss: 16.7782, val_MinusLogProbMetric: 16.7782

Epoch 532: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4306 - MinusLogProbMetric: 16.4306 - val_loss: 16.7782 - val_MinusLogProbMetric: 16.7782 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 533/1000
2023-09-27 18:32:57.814 
Epoch 533/1000 
	 loss: 16.4284, MinusLogProbMetric: 16.4284, val_loss: 16.7838, val_MinusLogProbMetric: 16.7838

Epoch 533: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4284 - MinusLogProbMetric: 16.4284 - val_loss: 16.7838 - val_MinusLogProbMetric: 16.7838 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 534/1000
2023-09-27 18:33:33.952 
Epoch 534/1000 
	 loss: 16.4375, MinusLogProbMetric: 16.4375, val_loss: 16.8320, val_MinusLogProbMetric: 16.8320

Epoch 534: val_loss did not improve from 16.76312
196/196 - 36s - loss: 16.4375 - MinusLogProbMetric: 16.4375 - val_loss: 16.8320 - val_MinusLogProbMetric: 16.8320 - lr: 2.5000e-04 - 36s/epoch - 184ms/step
Epoch 535/1000
2023-09-27 18:34:11.034 
Epoch 535/1000 
	 loss: 16.4281, MinusLogProbMetric: 16.4281, val_loss: 16.7937, val_MinusLogProbMetric: 16.7937

Epoch 535: val_loss did not improve from 16.76312
196/196 - 37s - loss: 16.4281 - MinusLogProbMetric: 16.4281 - val_loss: 16.7937 - val_MinusLogProbMetric: 16.7937 - lr: 2.5000e-04 - 37s/epoch - 189ms/step
Epoch 536/1000
2023-09-27 18:34:46.773 
Epoch 536/1000 
	 loss: 16.4339, MinusLogProbMetric: 16.4339, val_loss: 16.8227, val_MinusLogProbMetric: 16.8227

Epoch 536: val_loss did not improve from 16.76312
196/196 - 36s - loss: 16.4339 - MinusLogProbMetric: 16.4339 - val_loss: 16.8227 - val_MinusLogProbMetric: 16.8227 - lr: 2.5000e-04 - 36s/epoch - 182ms/step
Epoch 537/1000
2023-09-27 18:35:21.087 
Epoch 537/1000 
	 loss: 16.4345, MinusLogProbMetric: 16.4345, val_loss: 16.8165, val_MinusLogProbMetric: 16.8165

Epoch 537: val_loss did not improve from 16.76312
196/196 - 34s - loss: 16.4345 - MinusLogProbMetric: 16.4345 - val_loss: 16.8165 - val_MinusLogProbMetric: 16.8165 - lr: 2.5000e-04 - 34s/epoch - 175ms/step
Epoch 538/1000
2023-09-27 18:35:55.096 
Epoch 538/1000 
	 loss: 16.4315, MinusLogProbMetric: 16.4315, val_loss: 16.8050, val_MinusLogProbMetric: 16.8050

Epoch 538: val_loss did not improve from 16.76312
196/196 - 34s - loss: 16.4315 - MinusLogProbMetric: 16.4315 - val_loss: 16.8050 - val_MinusLogProbMetric: 16.8050 - lr: 2.5000e-04 - 34s/epoch - 173ms/step
Epoch 539/1000
2023-09-27 18:36:32.141 
Epoch 539/1000 
	 loss: 16.4275, MinusLogProbMetric: 16.4275, val_loss: 16.7931, val_MinusLogProbMetric: 16.7931

Epoch 539: val_loss did not improve from 16.76312
196/196 - 37s - loss: 16.4275 - MinusLogProbMetric: 16.4275 - val_loss: 16.7931 - val_MinusLogProbMetric: 16.7931 - lr: 2.5000e-04 - 37s/epoch - 189ms/step
Epoch 540/1000
2023-09-27 18:37:09.650 
Epoch 540/1000 
	 loss: 16.4320, MinusLogProbMetric: 16.4320, val_loss: 16.7764, val_MinusLogProbMetric: 16.7764

Epoch 540: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4320 - MinusLogProbMetric: 16.4320 - val_loss: 16.7764 - val_MinusLogProbMetric: 16.7764 - lr: 2.5000e-04 - 38s/epoch - 191ms/step
Epoch 541/1000
2023-09-27 18:37:44.966 
Epoch 541/1000 
	 loss: 16.4274, MinusLogProbMetric: 16.4274, val_loss: 16.7774, val_MinusLogProbMetric: 16.7774

Epoch 541: val_loss did not improve from 16.76312
196/196 - 35s - loss: 16.4274 - MinusLogProbMetric: 16.4274 - val_loss: 16.7774 - val_MinusLogProbMetric: 16.7774 - lr: 2.5000e-04 - 35s/epoch - 180ms/step
Epoch 542/1000
2023-09-27 18:38:18.625 
Epoch 542/1000 
	 loss: 16.4257, MinusLogProbMetric: 16.4257, val_loss: 16.7721, val_MinusLogProbMetric: 16.7721

Epoch 542: val_loss did not improve from 16.76312
196/196 - 34s - loss: 16.4257 - MinusLogProbMetric: 16.4257 - val_loss: 16.7721 - val_MinusLogProbMetric: 16.7721 - lr: 2.5000e-04 - 34s/epoch - 172ms/step
Epoch 543/1000
2023-09-27 18:38:52.378 
Epoch 543/1000 
	 loss: 16.4327, MinusLogProbMetric: 16.4327, val_loss: 16.7768, val_MinusLogProbMetric: 16.7768

Epoch 543: val_loss did not improve from 16.76312
196/196 - 34s - loss: 16.4327 - MinusLogProbMetric: 16.4327 - val_loss: 16.7768 - val_MinusLogProbMetric: 16.7768 - lr: 2.5000e-04 - 34s/epoch - 172ms/step
Epoch 544/1000
2023-09-27 18:39:27.110 
Epoch 544/1000 
	 loss: 16.4264, MinusLogProbMetric: 16.4264, val_loss: 16.7804, val_MinusLogProbMetric: 16.7804

Epoch 544: val_loss did not improve from 16.76312
196/196 - 35s - loss: 16.4264 - MinusLogProbMetric: 16.4264 - val_loss: 16.7804 - val_MinusLogProbMetric: 16.7804 - lr: 2.5000e-04 - 35s/epoch - 177ms/step
Epoch 545/1000
2023-09-27 18:40:05.667 
Epoch 545/1000 
	 loss: 16.4233, MinusLogProbMetric: 16.4233, val_loss: 16.8185, val_MinusLogProbMetric: 16.8185

Epoch 545: val_loss did not improve from 16.76312
196/196 - 39s - loss: 16.4233 - MinusLogProbMetric: 16.4233 - val_loss: 16.8185 - val_MinusLogProbMetric: 16.8185 - lr: 2.5000e-04 - 39s/epoch - 197ms/step
Epoch 546/1000
2023-09-27 18:40:43.449 
Epoch 546/1000 
	 loss: 16.4279, MinusLogProbMetric: 16.4279, val_loss: 16.7929, val_MinusLogProbMetric: 16.7929

Epoch 546: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4279 - MinusLogProbMetric: 16.4279 - val_loss: 16.7929 - val_MinusLogProbMetric: 16.7929 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 547/1000
2023-09-27 18:41:21.257 
Epoch 547/1000 
	 loss: 16.4271, MinusLogProbMetric: 16.4271, val_loss: 16.7820, val_MinusLogProbMetric: 16.7820

Epoch 547: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4271 - MinusLogProbMetric: 16.4271 - val_loss: 16.7820 - val_MinusLogProbMetric: 16.7820 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 548/1000
2023-09-27 18:41:58.888 
Epoch 548/1000 
	 loss: 16.4277, MinusLogProbMetric: 16.4277, val_loss: 16.7991, val_MinusLogProbMetric: 16.7991

Epoch 548: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4277 - MinusLogProbMetric: 16.4277 - val_loss: 16.7991 - val_MinusLogProbMetric: 16.7991 - lr: 2.5000e-04 - 38s/epoch - 192ms/step
Epoch 549/1000
2023-09-27 18:42:36.585 
Epoch 549/1000 
	 loss: 16.4283, MinusLogProbMetric: 16.4283, val_loss: 16.8330, val_MinusLogProbMetric: 16.8330

Epoch 549: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4283 - MinusLogProbMetric: 16.4283 - val_loss: 16.8330 - val_MinusLogProbMetric: 16.8330 - lr: 2.5000e-04 - 38s/epoch - 192ms/step
Epoch 550/1000
2023-09-27 18:43:14.480 
Epoch 550/1000 
	 loss: 16.4291, MinusLogProbMetric: 16.4291, val_loss: 16.8685, val_MinusLogProbMetric: 16.8685

Epoch 550: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4291 - MinusLogProbMetric: 16.4291 - val_loss: 16.8685 - val_MinusLogProbMetric: 16.8685 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 551/1000
2023-09-27 18:43:52.262 
Epoch 551/1000 
	 loss: 16.4363, MinusLogProbMetric: 16.4363, val_loss: 16.8097, val_MinusLogProbMetric: 16.8097

Epoch 551: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4363 - MinusLogProbMetric: 16.4363 - val_loss: 16.8097 - val_MinusLogProbMetric: 16.8097 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 552/1000
2023-09-27 18:44:30.085 
Epoch 552/1000 
	 loss: 16.4261, MinusLogProbMetric: 16.4261, val_loss: 16.7965, val_MinusLogProbMetric: 16.7965

Epoch 552: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4261 - MinusLogProbMetric: 16.4261 - val_loss: 16.7965 - val_MinusLogProbMetric: 16.7965 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 553/1000
2023-09-27 18:45:08.095 
Epoch 553/1000 
	 loss: 16.4282, MinusLogProbMetric: 16.4282, val_loss: 16.8554, val_MinusLogProbMetric: 16.8554

Epoch 553: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.4282 - MinusLogProbMetric: 16.4282 - val_loss: 16.8554 - val_MinusLogProbMetric: 16.8554 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 554/1000
2023-09-27 18:45:45.592 
Epoch 554/1000 
	 loss: 16.4302, MinusLogProbMetric: 16.4302, val_loss: 16.7884, val_MinusLogProbMetric: 16.7884

Epoch 554: val_loss did not improve from 16.76312
196/196 - 37s - loss: 16.4302 - MinusLogProbMetric: 16.4302 - val_loss: 16.7884 - val_MinusLogProbMetric: 16.7884 - lr: 2.5000e-04 - 37s/epoch - 191ms/step
Epoch 555/1000
2023-09-27 18:46:23.033 
Epoch 555/1000 
	 loss: 16.4003, MinusLogProbMetric: 16.4003, val_loss: 16.7701, val_MinusLogProbMetric: 16.7701

Epoch 555: val_loss did not improve from 16.76312
196/196 - 37s - loss: 16.4003 - MinusLogProbMetric: 16.4003 - val_loss: 16.7701 - val_MinusLogProbMetric: 16.7701 - lr: 1.2500e-04 - 37s/epoch - 191ms/step
Epoch 556/1000
2023-09-27 18:47:00.760 
Epoch 556/1000 
	 loss: 16.3969, MinusLogProbMetric: 16.3969, val_loss: 16.7640, val_MinusLogProbMetric: 16.7640

Epoch 556: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.3969 - MinusLogProbMetric: 16.3969 - val_loss: 16.7640 - val_MinusLogProbMetric: 16.7640 - lr: 1.2500e-04 - 38s/epoch - 192ms/step
Epoch 557/1000
2023-09-27 18:47:38.157 
Epoch 557/1000 
	 loss: 16.3969, MinusLogProbMetric: 16.3969, val_loss: 16.7766, val_MinusLogProbMetric: 16.7766

Epoch 557: val_loss did not improve from 16.76312
196/196 - 37s - loss: 16.3969 - MinusLogProbMetric: 16.3969 - val_loss: 16.7766 - val_MinusLogProbMetric: 16.7766 - lr: 1.2500e-04 - 37s/epoch - 191ms/step
Epoch 558/1000
2023-09-27 18:48:15.604 
Epoch 558/1000 
	 loss: 16.3975, MinusLogProbMetric: 16.3975, val_loss: 16.7728, val_MinusLogProbMetric: 16.7728

Epoch 558: val_loss did not improve from 16.76312
196/196 - 37s - loss: 16.3975 - MinusLogProbMetric: 16.3975 - val_loss: 16.7728 - val_MinusLogProbMetric: 16.7728 - lr: 1.2500e-04 - 37s/epoch - 191ms/step
Epoch 559/1000
2023-09-27 18:48:53.457 
Epoch 559/1000 
	 loss: 16.3953, MinusLogProbMetric: 16.3953, val_loss: 16.7676, val_MinusLogProbMetric: 16.7676

Epoch 559: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.3953 - MinusLogProbMetric: 16.3953 - val_loss: 16.7676 - val_MinusLogProbMetric: 16.7676 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 560/1000
2023-09-27 18:49:31.208 
Epoch 560/1000 
	 loss: 16.3972, MinusLogProbMetric: 16.3972, val_loss: 16.7810, val_MinusLogProbMetric: 16.7810

Epoch 560: val_loss did not improve from 16.76312
196/196 - 38s - loss: 16.3972 - MinusLogProbMetric: 16.3972 - val_loss: 16.7810 - val_MinusLogProbMetric: 16.7810 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 561/1000
2023-09-27 18:50:09.028 
Epoch 561/1000 
	 loss: 16.3996, MinusLogProbMetric: 16.3996, val_loss: 16.7597, val_MinusLogProbMetric: 16.7597

Epoch 561: val_loss improved from 16.76312 to 16.75968, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 38s - loss: 16.3996 - MinusLogProbMetric: 16.3996 - val_loss: 16.7597 - val_MinusLogProbMetric: 16.7597 - lr: 1.2500e-04 - 38s/epoch - 196ms/step
Epoch 562/1000
2023-09-27 18:50:47.524 
Epoch 562/1000 
	 loss: 16.3975, MinusLogProbMetric: 16.3975, val_loss: 16.7774, val_MinusLogProbMetric: 16.7774

Epoch 562: val_loss did not improve from 16.75968
196/196 - 38s - loss: 16.3975 - MinusLogProbMetric: 16.3975 - val_loss: 16.7774 - val_MinusLogProbMetric: 16.7774 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 563/1000
2023-09-27 18:51:24.964 
Epoch 563/1000 
	 loss: 16.3970, MinusLogProbMetric: 16.3970, val_loss: 16.7719, val_MinusLogProbMetric: 16.7719

Epoch 563: val_loss did not improve from 16.75968
196/196 - 37s - loss: 16.3970 - MinusLogProbMetric: 16.3970 - val_loss: 16.7719 - val_MinusLogProbMetric: 16.7719 - lr: 1.2500e-04 - 37s/epoch - 191ms/step
Epoch 564/1000
2023-09-27 18:52:02.802 
Epoch 564/1000 
	 loss: 16.3942, MinusLogProbMetric: 16.3942, val_loss: 16.7661, val_MinusLogProbMetric: 16.7661

Epoch 564: val_loss did not improve from 16.75968
196/196 - 38s - loss: 16.3942 - MinusLogProbMetric: 16.3942 - val_loss: 16.7661 - val_MinusLogProbMetric: 16.7661 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 565/1000
2023-09-27 18:52:39.928 
Epoch 565/1000 
	 loss: 16.3960, MinusLogProbMetric: 16.3960, val_loss: 16.7651, val_MinusLogProbMetric: 16.7651

Epoch 565: val_loss did not improve from 16.75968
196/196 - 37s - loss: 16.3960 - MinusLogProbMetric: 16.3960 - val_loss: 16.7651 - val_MinusLogProbMetric: 16.7651 - lr: 1.2500e-04 - 37s/epoch - 189ms/step
Epoch 566/1000
2023-09-27 18:53:17.580 
Epoch 566/1000 
	 loss: 16.3966, MinusLogProbMetric: 16.3966, val_loss: 16.7583, val_MinusLogProbMetric: 16.7583

Epoch 566: val_loss improved from 16.75968 to 16.75830, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 38s - loss: 16.3966 - MinusLogProbMetric: 16.3966 - val_loss: 16.7583 - val_MinusLogProbMetric: 16.7583 - lr: 1.2500e-04 - 38s/epoch - 196ms/step
Epoch 567/1000
2023-09-27 18:53:56.133 
Epoch 567/1000 
	 loss: 16.3954, MinusLogProbMetric: 16.3954, val_loss: 16.7738, val_MinusLogProbMetric: 16.7738

Epoch 567: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3954 - MinusLogProbMetric: 16.3954 - val_loss: 16.7738 - val_MinusLogProbMetric: 16.7738 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 568/1000
2023-09-27 18:54:33.957 
Epoch 568/1000 
	 loss: 16.3937, MinusLogProbMetric: 16.3937, val_loss: 16.7714, val_MinusLogProbMetric: 16.7714

Epoch 568: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3937 - MinusLogProbMetric: 16.3937 - val_loss: 16.7714 - val_MinusLogProbMetric: 16.7714 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 569/1000
2023-09-27 18:55:11.523 
Epoch 569/1000 
	 loss: 16.3954, MinusLogProbMetric: 16.3954, val_loss: 16.7782, val_MinusLogProbMetric: 16.7782

Epoch 569: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3954 - MinusLogProbMetric: 16.3954 - val_loss: 16.7782 - val_MinusLogProbMetric: 16.7782 - lr: 1.2500e-04 - 38s/epoch - 192ms/step
Epoch 570/1000
2023-09-27 18:55:49.462 
Epoch 570/1000 
	 loss: 16.3950, MinusLogProbMetric: 16.3950, val_loss: 16.7647, val_MinusLogProbMetric: 16.7647

Epoch 570: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3950 - MinusLogProbMetric: 16.3950 - val_loss: 16.7647 - val_MinusLogProbMetric: 16.7647 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 571/1000
2023-09-27 18:56:27.514 
Epoch 571/1000 
	 loss: 16.3990, MinusLogProbMetric: 16.3990, val_loss: 16.7685, val_MinusLogProbMetric: 16.7685

Epoch 571: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3990 - MinusLogProbMetric: 16.3990 - val_loss: 16.7685 - val_MinusLogProbMetric: 16.7685 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 572/1000
2023-09-27 18:57:05.280 
Epoch 572/1000 
	 loss: 16.3952, MinusLogProbMetric: 16.3952, val_loss: 16.7692, val_MinusLogProbMetric: 16.7692

Epoch 572: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3952 - MinusLogProbMetric: 16.3952 - val_loss: 16.7692 - val_MinusLogProbMetric: 16.7692 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 573/1000
2023-09-27 18:57:42.557 
Epoch 573/1000 
	 loss: 16.3967, MinusLogProbMetric: 16.3967, val_loss: 16.7613, val_MinusLogProbMetric: 16.7613

Epoch 573: val_loss did not improve from 16.75830
196/196 - 37s - loss: 16.3967 - MinusLogProbMetric: 16.3967 - val_loss: 16.7613 - val_MinusLogProbMetric: 16.7613 - lr: 1.2500e-04 - 37s/epoch - 190ms/step
Epoch 574/1000
2023-09-27 18:58:20.441 
Epoch 574/1000 
	 loss: 16.3929, MinusLogProbMetric: 16.3929, val_loss: 16.7687, val_MinusLogProbMetric: 16.7687

Epoch 574: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3929 - MinusLogProbMetric: 16.3929 - val_loss: 16.7687 - val_MinusLogProbMetric: 16.7687 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 575/1000
2023-09-27 18:58:58.193 
Epoch 575/1000 
	 loss: 16.3938, MinusLogProbMetric: 16.3938, val_loss: 16.7755, val_MinusLogProbMetric: 16.7755

Epoch 575: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3938 - MinusLogProbMetric: 16.3938 - val_loss: 16.7755 - val_MinusLogProbMetric: 16.7755 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 576/1000
2023-09-27 18:59:35.939 
Epoch 576/1000 
	 loss: 16.3982, MinusLogProbMetric: 16.3982, val_loss: 16.7662, val_MinusLogProbMetric: 16.7662

Epoch 576: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3982 - MinusLogProbMetric: 16.3982 - val_loss: 16.7662 - val_MinusLogProbMetric: 16.7662 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 577/1000
2023-09-27 19:00:13.274 
Epoch 577/1000 
	 loss: 16.3965, MinusLogProbMetric: 16.3965, val_loss: 16.7793, val_MinusLogProbMetric: 16.7793

Epoch 577: val_loss did not improve from 16.75830
196/196 - 37s - loss: 16.3965 - MinusLogProbMetric: 16.3965 - val_loss: 16.7793 - val_MinusLogProbMetric: 16.7793 - lr: 1.2500e-04 - 37s/epoch - 190ms/step
Epoch 578/1000
2023-09-27 19:00:50.998 
Epoch 578/1000 
	 loss: 16.3958, MinusLogProbMetric: 16.3958, val_loss: 16.7790, val_MinusLogProbMetric: 16.7790

Epoch 578: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3958 - MinusLogProbMetric: 16.3958 - val_loss: 16.7790 - val_MinusLogProbMetric: 16.7790 - lr: 1.2500e-04 - 38s/epoch - 192ms/step
Epoch 579/1000
2023-09-27 19:01:28.461 
Epoch 579/1000 
	 loss: 16.3954, MinusLogProbMetric: 16.3954, val_loss: 16.7743, val_MinusLogProbMetric: 16.7743

Epoch 579: val_loss did not improve from 16.75830
196/196 - 37s - loss: 16.3954 - MinusLogProbMetric: 16.3954 - val_loss: 16.7743 - val_MinusLogProbMetric: 16.7743 - lr: 1.2500e-04 - 37s/epoch - 191ms/step
Epoch 580/1000
2023-09-27 19:02:06.183 
Epoch 580/1000 
	 loss: 16.3959, MinusLogProbMetric: 16.3959, val_loss: 16.7774, val_MinusLogProbMetric: 16.7774

Epoch 580: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3959 - MinusLogProbMetric: 16.3959 - val_loss: 16.7774 - val_MinusLogProbMetric: 16.7774 - lr: 1.2500e-04 - 38s/epoch - 192ms/step
Epoch 581/1000
2023-09-27 19:02:44.001 
Epoch 581/1000 
	 loss: 16.3962, MinusLogProbMetric: 16.3962, val_loss: 16.7653, val_MinusLogProbMetric: 16.7653

Epoch 581: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3962 - MinusLogProbMetric: 16.3962 - val_loss: 16.7653 - val_MinusLogProbMetric: 16.7653 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 582/1000
2023-09-27 19:03:22.098 
Epoch 582/1000 
	 loss: 16.3939, MinusLogProbMetric: 16.3939, val_loss: 16.7680, val_MinusLogProbMetric: 16.7680

Epoch 582: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3939 - MinusLogProbMetric: 16.3939 - val_loss: 16.7680 - val_MinusLogProbMetric: 16.7680 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 583/1000
2023-09-27 19:03:59.491 
Epoch 583/1000 
	 loss: 16.3940, MinusLogProbMetric: 16.3940, val_loss: 16.7686, val_MinusLogProbMetric: 16.7686

Epoch 583: val_loss did not improve from 16.75830
196/196 - 37s - loss: 16.3940 - MinusLogProbMetric: 16.3940 - val_loss: 16.7686 - val_MinusLogProbMetric: 16.7686 - lr: 1.2500e-04 - 37s/epoch - 191ms/step
Epoch 584/1000
2023-09-27 19:04:37.125 
Epoch 584/1000 
	 loss: 16.3963, MinusLogProbMetric: 16.3963, val_loss: 16.7745, val_MinusLogProbMetric: 16.7745

Epoch 584: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3963 - MinusLogProbMetric: 16.3963 - val_loss: 16.7745 - val_MinusLogProbMetric: 16.7745 - lr: 1.2500e-04 - 38s/epoch - 192ms/step
Epoch 585/1000
2023-09-27 19:05:14.926 
Epoch 585/1000 
	 loss: 16.3958, MinusLogProbMetric: 16.3958, val_loss: 16.7619, val_MinusLogProbMetric: 16.7619

Epoch 585: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3958 - MinusLogProbMetric: 16.3958 - val_loss: 16.7619 - val_MinusLogProbMetric: 16.7619 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 586/1000
2023-09-27 19:05:52.567 
Epoch 586/1000 
	 loss: 16.3917, MinusLogProbMetric: 16.3917, val_loss: 16.7750, val_MinusLogProbMetric: 16.7750

Epoch 586: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3917 - MinusLogProbMetric: 16.3917 - val_loss: 16.7750 - val_MinusLogProbMetric: 16.7750 - lr: 1.2500e-04 - 38s/epoch - 192ms/step
Epoch 587/1000
2023-09-27 19:06:30.243 
Epoch 587/1000 
	 loss: 16.3930, MinusLogProbMetric: 16.3930, val_loss: 16.7971, val_MinusLogProbMetric: 16.7971

Epoch 587: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3930 - MinusLogProbMetric: 16.3930 - val_loss: 16.7971 - val_MinusLogProbMetric: 16.7971 - lr: 1.2500e-04 - 38s/epoch - 192ms/step
Epoch 588/1000
2023-09-27 19:07:08.141 
Epoch 588/1000 
	 loss: 16.3969, MinusLogProbMetric: 16.3969, val_loss: 16.7758, val_MinusLogProbMetric: 16.7758

Epoch 588: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3969 - MinusLogProbMetric: 16.3969 - val_loss: 16.7758 - val_MinusLogProbMetric: 16.7758 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 589/1000
2023-09-27 19:07:45.889 
Epoch 589/1000 
	 loss: 16.3957, MinusLogProbMetric: 16.3957, val_loss: 16.7607, val_MinusLogProbMetric: 16.7607

Epoch 589: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3957 - MinusLogProbMetric: 16.3957 - val_loss: 16.7607 - val_MinusLogProbMetric: 16.7607 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 590/1000
2023-09-27 19:08:23.411 
Epoch 590/1000 
	 loss: 16.3934, MinusLogProbMetric: 16.3934, val_loss: 16.7737, val_MinusLogProbMetric: 16.7737

Epoch 590: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3934 - MinusLogProbMetric: 16.3934 - val_loss: 16.7737 - val_MinusLogProbMetric: 16.7737 - lr: 1.2500e-04 - 38s/epoch - 191ms/step
Epoch 591/1000
2023-09-27 19:09:01.219 
Epoch 591/1000 
	 loss: 16.3929, MinusLogProbMetric: 16.3929, val_loss: 16.7671, val_MinusLogProbMetric: 16.7671

Epoch 591: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3929 - MinusLogProbMetric: 16.3929 - val_loss: 16.7671 - val_MinusLogProbMetric: 16.7671 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 592/1000
2023-09-27 19:09:39.435 
Epoch 592/1000 
	 loss: 16.3910, MinusLogProbMetric: 16.3910, val_loss: 16.7646, val_MinusLogProbMetric: 16.7646

Epoch 592: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3910 - MinusLogProbMetric: 16.3910 - val_loss: 16.7646 - val_MinusLogProbMetric: 16.7646 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 593/1000
2023-09-27 19:10:17.427 
Epoch 593/1000 
	 loss: 16.3937, MinusLogProbMetric: 16.3937, val_loss: 16.7661, val_MinusLogProbMetric: 16.7661

Epoch 593: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3937 - MinusLogProbMetric: 16.3937 - val_loss: 16.7661 - val_MinusLogProbMetric: 16.7661 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 594/1000
2023-09-27 19:10:55.425 
Epoch 594/1000 
	 loss: 16.3953, MinusLogProbMetric: 16.3953, val_loss: 16.7694, val_MinusLogProbMetric: 16.7694

Epoch 594: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3953 - MinusLogProbMetric: 16.3953 - val_loss: 16.7694 - val_MinusLogProbMetric: 16.7694 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 595/1000
2023-09-27 19:11:33.095 
Epoch 595/1000 
	 loss: 16.3957, MinusLogProbMetric: 16.3957, val_loss: 16.7848, val_MinusLogProbMetric: 16.7848

Epoch 595: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3957 - MinusLogProbMetric: 16.3957 - val_loss: 16.7848 - val_MinusLogProbMetric: 16.7848 - lr: 1.2500e-04 - 38s/epoch - 192ms/step
Epoch 596/1000
2023-09-27 19:12:10.780 
Epoch 596/1000 
	 loss: 16.3945, MinusLogProbMetric: 16.3945, val_loss: 16.7662, val_MinusLogProbMetric: 16.7662

Epoch 596: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3945 - MinusLogProbMetric: 16.3945 - val_loss: 16.7662 - val_MinusLogProbMetric: 16.7662 - lr: 1.2500e-04 - 38s/epoch - 192ms/step
Epoch 597/1000
2023-09-27 19:12:48.180 
Epoch 597/1000 
	 loss: 16.3913, MinusLogProbMetric: 16.3913, val_loss: 16.7731, val_MinusLogProbMetric: 16.7731

Epoch 597: val_loss did not improve from 16.75830
196/196 - 37s - loss: 16.3913 - MinusLogProbMetric: 16.3913 - val_loss: 16.7731 - val_MinusLogProbMetric: 16.7731 - lr: 1.2500e-04 - 37s/epoch - 191ms/step
Epoch 598/1000
2023-09-27 19:13:26.186 
Epoch 598/1000 
	 loss: 16.3963, MinusLogProbMetric: 16.3963, val_loss: 16.7810, val_MinusLogProbMetric: 16.7810

Epoch 598: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3963 - MinusLogProbMetric: 16.3963 - val_loss: 16.7810 - val_MinusLogProbMetric: 16.7810 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 599/1000
2023-09-27 19:14:03.944 
Epoch 599/1000 
	 loss: 16.3932, MinusLogProbMetric: 16.3932, val_loss: 16.7616, val_MinusLogProbMetric: 16.7616

Epoch 599: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3932 - MinusLogProbMetric: 16.3932 - val_loss: 16.7616 - val_MinusLogProbMetric: 16.7616 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 600/1000
2023-09-27 19:14:41.595 
Epoch 600/1000 
	 loss: 16.3922, MinusLogProbMetric: 16.3922, val_loss: 16.7843, val_MinusLogProbMetric: 16.7843

Epoch 600: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3922 - MinusLogProbMetric: 16.3922 - val_loss: 16.7843 - val_MinusLogProbMetric: 16.7843 - lr: 1.2500e-04 - 38s/epoch - 192ms/step
Epoch 601/1000
2023-09-27 19:15:19.160 
Epoch 601/1000 
	 loss: 16.3931, MinusLogProbMetric: 16.3931, val_loss: 16.7705, val_MinusLogProbMetric: 16.7705

Epoch 601: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3931 - MinusLogProbMetric: 16.3931 - val_loss: 16.7705 - val_MinusLogProbMetric: 16.7705 - lr: 1.2500e-04 - 38s/epoch - 192ms/step
Epoch 602/1000
2023-09-27 19:15:57.061 
Epoch 602/1000 
	 loss: 16.3938, MinusLogProbMetric: 16.3938, val_loss: 16.7661, val_MinusLogProbMetric: 16.7661

Epoch 602: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3938 - MinusLogProbMetric: 16.3938 - val_loss: 16.7661 - val_MinusLogProbMetric: 16.7661 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 603/1000
2023-09-27 19:16:35.010 
Epoch 603/1000 
	 loss: 16.3945, MinusLogProbMetric: 16.3945, val_loss: 16.7593, val_MinusLogProbMetric: 16.7593

Epoch 603: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3945 - MinusLogProbMetric: 16.3945 - val_loss: 16.7593 - val_MinusLogProbMetric: 16.7593 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 604/1000
2023-09-27 19:17:12.758 
Epoch 604/1000 
	 loss: 16.3949, MinusLogProbMetric: 16.3949, val_loss: 16.7696, val_MinusLogProbMetric: 16.7696

Epoch 604: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3949 - MinusLogProbMetric: 16.3949 - val_loss: 16.7696 - val_MinusLogProbMetric: 16.7696 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 605/1000
2023-09-27 19:17:50.300 
Epoch 605/1000 
	 loss: 16.3912, MinusLogProbMetric: 16.3912, val_loss: 16.7687, val_MinusLogProbMetric: 16.7687

Epoch 605: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3912 - MinusLogProbMetric: 16.3912 - val_loss: 16.7687 - val_MinusLogProbMetric: 16.7687 - lr: 1.2500e-04 - 38s/epoch - 192ms/step
Epoch 606/1000
2023-09-27 19:18:28.776 
Epoch 606/1000 
	 loss: 16.3913, MinusLogProbMetric: 16.3913, val_loss: 16.7759, val_MinusLogProbMetric: 16.7759

Epoch 606: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3913 - MinusLogProbMetric: 16.3913 - val_loss: 16.7759 - val_MinusLogProbMetric: 16.7759 - lr: 1.2500e-04 - 38s/epoch - 196ms/step
Epoch 607/1000
2023-09-27 19:19:06.582 
Epoch 607/1000 
	 loss: 16.3921, MinusLogProbMetric: 16.3921, val_loss: 16.7847, val_MinusLogProbMetric: 16.7847

Epoch 607: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3921 - MinusLogProbMetric: 16.3921 - val_loss: 16.7847 - val_MinusLogProbMetric: 16.7847 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 608/1000
2023-09-27 19:19:44.354 
Epoch 608/1000 
	 loss: 16.3886, MinusLogProbMetric: 16.3886, val_loss: 16.7679, val_MinusLogProbMetric: 16.7679

Epoch 608: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3886 - MinusLogProbMetric: 16.3886 - val_loss: 16.7679 - val_MinusLogProbMetric: 16.7679 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 609/1000
2023-09-27 19:20:22.167 
Epoch 609/1000 
	 loss: 16.3915, MinusLogProbMetric: 16.3915, val_loss: 16.7987, val_MinusLogProbMetric: 16.7987

Epoch 609: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3915 - MinusLogProbMetric: 16.3915 - val_loss: 16.7987 - val_MinusLogProbMetric: 16.7987 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 610/1000
2023-09-27 19:21:00.069 
Epoch 610/1000 
	 loss: 16.3942, MinusLogProbMetric: 16.3942, val_loss: 16.7760, val_MinusLogProbMetric: 16.7760

Epoch 610: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3942 - MinusLogProbMetric: 16.3942 - val_loss: 16.7760 - val_MinusLogProbMetric: 16.7760 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 611/1000
2023-09-27 19:21:37.727 
Epoch 611/1000 
	 loss: 16.3924, MinusLogProbMetric: 16.3924, val_loss: 16.7813, val_MinusLogProbMetric: 16.7813

Epoch 611: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3924 - MinusLogProbMetric: 16.3924 - val_loss: 16.7813 - val_MinusLogProbMetric: 16.7813 - lr: 1.2500e-04 - 38s/epoch - 192ms/step
Epoch 612/1000
2023-09-27 19:22:15.433 
Epoch 612/1000 
	 loss: 16.3970, MinusLogProbMetric: 16.3970, val_loss: 16.7821, val_MinusLogProbMetric: 16.7821

Epoch 612: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3970 - MinusLogProbMetric: 16.3970 - val_loss: 16.7821 - val_MinusLogProbMetric: 16.7821 - lr: 1.2500e-04 - 38s/epoch - 192ms/step
Epoch 613/1000
2023-09-27 19:22:53.521 
Epoch 613/1000 
	 loss: 16.3910, MinusLogProbMetric: 16.3910, val_loss: 16.7867, val_MinusLogProbMetric: 16.7867

Epoch 613: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3910 - MinusLogProbMetric: 16.3910 - val_loss: 16.7867 - val_MinusLogProbMetric: 16.7867 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 614/1000
2023-09-27 19:23:31.286 
Epoch 614/1000 
	 loss: 16.3959, MinusLogProbMetric: 16.3959, val_loss: 16.7680, val_MinusLogProbMetric: 16.7680

Epoch 614: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3959 - MinusLogProbMetric: 16.3959 - val_loss: 16.7680 - val_MinusLogProbMetric: 16.7680 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 615/1000
2023-09-27 19:24:09.155 
Epoch 615/1000 
	 loss: 16.3934, MinusLogProbMetric: 16.3934, val_loss: 16.7735, val_MinusLogProbMetric: 16.7735

Epoch 615: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3934 - MinusLogProbMetric: 16.3934 - val_loss: 16.7735 - val_MinusLogProbMetric: 16.7735 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 616/1000
2023-09-27 19:24:46.710 
Epoch 616/1000 
	 loss: 16.3940, MinusLogProbMetric: 16.3940, val_loss: 16.7682, val_MinusLogProbMetric: 16.7682

Epoch 616: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3940 - MinusLogProbMetric: 16.3940 - val_loss: 16.7682 - val_MinusLogProbMetric: 16.7682 - lr: 1.2500e-04 - 38s/epoch - 192ms/step
Epoch 617/1000
2023-09-27 19:25:24.279 
Epoch 617/1000 
	 loss: 16.3797, MinusLogProbMetric: 16.3797, val_loss: 16.7591, val_MinusLogProbMetric: 16.7591

Epoch 617: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3797 - MinusLogProbMetric: 16.3797 - val_loss: 16.7591 - val_MinusLogProbMetric: 16.7591 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 618/1000
2023-09-27 19:26:01.172 
Epoch 618/1000 
	 loss: 16.3763, MinusLogProbMetric: 16.3763, val_loss: 16.7661, val_MinusLogProbMetric: 16.7661

Epoch 618: val_loss did not improve from 16.75830
196/196 - 37s - loss: 16.3763 - MinusLogProbMetric: 16.3763 - val_loss: 16.7661 - val_MinusLogProbMetric: 16.7661 - lr: 6.2500e-05 - 37s/epoch - 188ms/step
Epoch 619/1000
2023-09-27 19:26:37.700 
Epoch 619/1000 
	 loss: 16.3772, MinusLogProbMetric: 16.3772, val_loss: 16.7609, val_MinusLogProbMetric: 16.7609

Epoch 619: val_loss did not improve from 16.75830
196/196 - 37s - loss: 16.3772 - MinusLogProbMetric: 16.3772 - val_loss: 16.7609 - val_MinusLogProbMetric: 16.7609 - lr: 6.2500e-05 - 37s/epoch - 186ms/step
Epoch 620/1000
2023-09-27 19:27:14.180 
Epoch 620/1000 
	 loss: 16.3758, MinusLogProbMetric: 16.3758, val_loss: 16.7679, val_MinusLogProbMetric: 16.7679

Epoch 620: val_loss did not improve from 16.75830
196/196 - 36s - loss: 16.3758 - MinusLogProbMetric: 16.3758 - val_loss: 16.7679 - val_MinusLogProbMetric: 16.7679 - lr: 6.2500e-05 - 36s/epoch - 186ms/step
Epoch 621/1000
2023-09-27 19:27:48.843 
Epoch 621/1000 
	 loss: 16.3778, MinusLogProbMetric: 16.3778, val_loss: 16.7673, val_MinusLogProbMetric: 16.7673

Epoch 621: val_loss did not improve from 16.75830
196/196 - 35s - loss: 16.3778 - MinusLogProbMetric: 16.3778 - val_loss: 16.7673 - val_MinusLogProbMetric: 16.7673 - lr: 6.2500e-05 - 35s/epoch - 177ms/step
Epoch 622/1000
2023-09-27 19:28:26.980 
Epoch 622/1000 
	 loss: 16.3780, MinusLogProbMetric: 16.3780, val_loss: 16.7697, val_MinusLogProbMetric: 16.7697

Epoch 622: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3780 - MinusLogProbMetric: 16.3780 - val_loss: 16.7697 - val_MinusLogProbMetric: 16.7697 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 623/1000
2023-09-27 19:29:04.604 
Epoch 623/1000 
	 loss: 16.3791, MinusLogProbMetric: 16.3791, val_loss: 16.7616, val_MinusLogProbMetric: 16.7616

Epoch 623: val_loss did not improve from 16.75830
196/196 - 38s - loss: 16.3791 - MinusLogProbMetric: 16.3791 - val_loss: 16.7616 - val_MinusLogProbMetric: 16.7616 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 624/1000
2023-09-27 19:29:42.374 
Epoch 624/1000 
	 loss: 16.3767, MinusLogProbMetric: 16.3767, val_loss: 16.7566, val_MinusLogProbMetric: 16.7566

Epoch 624: val_loss improved from 16.75830 to 16.75657, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 39s - loss: 16.3767 - MinusLogProbMetric: 16.3767 - val_loss: 16.7566 - val_MinusLogProbMetric: 16.7566 - lr: 6.2500e-05 - 39s/epoch - 196ms/step
Epoch 625/1000
2023-09-27 19:30:20.847 
Epoch 625/1000 
	 loss: 16.3772, MinusLogProbMetric: 16.3772, val_loss: 16.7653, val_MinusLogProbMetric: 16.7653

Epoch 625: val_loss did not improve from 16.75657
196/196 - 38s - loss: 16.3772 - MinusLogProbMetric: 16.3772 - val_loss: 16.7653 - val_MinusLogProbMetric: 16.7653 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 626/1000
2023-09-27 19:30:58.556 
Epoch 626/1000 
	 loss: 16.3767, MinusLogProbMetric: 16.3767, val_loss: 16.7629, val_MinusLogProbMetric: 16.7629

Epoch 626: val_loss did not improve from 16.75657
196/196 - 38s - loss: 16.3767 - MinusLogProbMetric: 16.3767 - val_loss: 16.7629 - val_MinusLogProbMetric: 16.7629 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 627/1000
2023-09-27 19:31:36.646 
Epoch 627/1000 
	 loss: 16.3763, MinusLogProbMetric: 16.3763, val_loss: 16.7706, val_MinusLogProbMetric: 16.7706

Epoch 627: val_loss did not improve from 16.75657
196/196 - 38s - loss: 16.3763 - MinusLogProbMetric: 16.3763 - val_loss: 16.7706 - val_MinusLogProbMetric: 16.7706 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 628/1000
2023-09-27 19:32:14.328 
Epoch 628/1000 
	 loss: 16.3756, MinusLogProbMetric: 16.3756, val_loss: 16.7640, val_MinusLogProbMetric: 16.7640

Epoch 628: val_loss did not improve from 16.75657
196/196 - 38s - loss: 16.3756 - MinusLogProbMetric: 16.3756 - val_loss: 16.7640 - val_MinusLogProbMetric: 16.7640 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 629/1000
2023-09-27 19:32:52.093 
Epoch 629/1000 
	 loss: 16.3766, MinusLogProbMetric: 16.3766, val_loss: 16.7599, val_MinusLogProbMetric: 16.7599

Epoch 629: val_loss did not improve from 16.75657
196/196 - 38s - loss: 16.3766 - MinusLogProbMetric: 16.3766 - val_loss: 16.7599 - val_MinusLogProbMetric: 16.7599 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 630/1000
2023-09-27 19:33:29.692 
Epoch 630/1000 
	 loss: 16.3784, MinusLogProbMetric: 16.3784, val_loss: 16.7646, val_MinusLogProbMetric: 16.7646

Epoch 630: val_loss did not improve from 16.75657
196/196 - 38s - loss: 16.3784 - MinusLogProbMetric: 16.3784 - val_loss: 16.7646 - val_MinusLogProbMetric: 16.7646 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 631/1000
2023-09-27 19:34:07.574 
Epoch 631/1000 
	 loss: 16.3756, MinusLogProbMetric: 16.3756, val_loss: 16.7588, val_MinusLogProbMetric: 16.7588

Epoch 631: val_loss did not improve from 16.75657
196/196 - 38s - loss: 16.3756 - MinusLogProbMetric: 16.3756 - val_loss: 16.7588 - val_MinusLogProbMetric: 16.7588 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 632/1000
2023-09-27 19:34:45.507 
Epoch 632/1000 
	 loss: 16.3776, MinusLogProbMetric: 16.3776, val_loss: 16.7689, val_MinusLogProbMetric: 16.7689

Epoch 632: val_loss did not improve from 16.75657
196/196 - 38s - loss: 16.3776 - MinusLogProbMetric: 16.3776 - val_loss: 16.7689 - val_MinusLogProbMetric: 16.7689 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 633/1000
2023-09-27 19:35:23.337 
Epoch 633/1000 
	 loss: 16.3761, MinusLogProbMetric: 16.3761, val_loss: 16.7601, val_MinusLogProbMetric: 16.7601

Epoch 633: val_loss did not improve from 16.75657
196/196 - 38s - loss: 16.3761 - MinusLogProbMetric: 16.3761 - val_loss: 16.7601 - val_MinusLogProbMetric: 16.7601 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 634/1000
2023-09-27 19:36:01.041 
Epoch 634/1000 
	 loss: 16.3772, MinusLogProbMetric: 16.3772, val_loss: 16.7599, val_MinusLogProbMetric: 16.7599

Epoch 634: val_loss did not improve from 16.75657
196/196 - 38s - loss: 16.3772 - MinusLogProbMetric: 16.3772 - val_loss: 16.7599 - val_MinusLogProbMetric: 16.7599 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 635/1000
2023-09-27 19:36:38.725 
Epoch 635/1000 
	 loss: 16.3765, MinusLogProbMetric: 16.3765, val_loss: 16.7632, val_MinusLogProbMetric: 16.7632

Epoch 635: val_loss did not improve from 16.75657
196/196 - 38s - loss: 16.3765 - MinusLogProbMetric: 16.3765 - val_loss: 16.7632 - val_MinusLogProbMetric: 16.7632 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 636/1000
2023-09-27 19:37:16.767 
Epoch 636/1000 
	 loss: 16.3761, MinusLogProbMetric: 16.3761, val_loss: 16.7594, val_MinusLogProbMetric: 16.7594

Epoch 636: val_loss did not improve from 16.75657
196/196 - 38s - loss: 16.3761 - MinusLogProbMetric: 16.3761 - val_loss: 16.7594 - val_MinusLogProbMetric: 16.7594 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 637/1000
2023-09-27 19:37:54.423 
Epoch 637/1000 
	 loss: 16.3753, MinusLogProbMetric: 16.3753, val_loss: 16.7562, val_MinusLogProbMetric: 16.7562

Epoch 637: val_loss improved from 16.75657 to 16.75624, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 38s - loss: 16.3753 - MinusLogProbMetric: 16.3753 - val_loss: 16.7562 - val_MinusLogProbMetric: 16.7562 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 638/1000
2023-09-27 19:38:33.170 
Epoch 638/1000 
	 loss: 16.3772, MinusLogProbMetric: 16.3772, val_loss: 16.7653, val_MinusLogProbMetric: 16.7653

Epoch 638: val_loss did not improve from 16.75624
196/196 - 38s - loss: 16.3772 - MinusLogProbMetric: 16.3772 - val_loss: 16.7653 - val_MinusLogProbMetric: 16.7653 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 639/1000
2023-09-27 19:39:11.122 
Epoch 639/1000 
	 loss: 16.3762, MinusLogProbMetric: 16.3762, val_loss: 16.7560, val_MinusLogProbMetric: 16.7560

Epoch 639: val_loss improved from 16.75624 to 16.75604, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_307/weights/best_weights.h5
196/196 - 39s - loss: 16.3762 - MinusLogProbMetric: 16.3762 - val_loss: 16.7560 - val_MinusLogProbMetric: 16.7560 - lr: 6.2500e-05 - 39s/epoch - 197ms/step
Epoch 640/1000
2023-09-27 19:39:49.843 
Epoch 640/1000 
	 loss: 16.3751, MinusLogProbMetric: 16.3751, val_loss: 16.7615, val_MinusLogProbMetric: 16.7615

Epoch 640: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3751 - MinusLogProbMetric: 16.3751 - val_loss: 16.7615 - val_MinusLogProbMetric: 16.7615 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 641/1000
2023-09-27 19:40:27.577 
Epoch 641/1000 
	 loss: 16.3768, MinusLogProbMetric: 16.3768, val_loss: 16.7690, val_MinusLogProbMetric: 16.7690

Epoch 641: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3768 - MinusLogProbMetric: 16.3768 - val_loss: 16.7690 - val_MinusLogProbMetric: 16.7690 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 642/1000
2023-09-27 19:41:05.144 
Epoch 642/1000 
	 loss: 16.3759, MinusLogProbMetric: 16.3759, val_loss: 16.7748, val_MinusLogProbMetric: 16.7748

Epoch 642: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3759 - MinusLogProbMetric: 16.3759 - val_loss: 16.7748 - val_MinusLogProbMetric: 16.7748 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 643/1000
2023-09-27 19:41:42.827 
Epoch 643/1000 
	 loss: 16.3774, MinusLogProbMetric: 16.3774, val_loss: 16.7631, val_MinusLogProbMetric: 16.7631

Epoch 643: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3774 - MinusLogProbMetric: 16.3774 - val_loss: 16.7631 - val_MinusLogProbMetric: 16.7631 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 644/1000
2023-09-27 19:42:20.460 
Epoch 644/1000 
	 loss: 16.3778, MinusLogProbMetric: 16.3778, val_loss: 16.7613, val_MinusLogProbMetric: 16.7613

Epoch 644: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3778 - MinusLogProbMetric: 16.3778 - val_loss: 16.7613 - val_MinusLogProbMetric: 16.7613 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 645/1000
2023-09-27 19:42:58.347 
Epoch 645/1000 
	 loss: 16.3769, MinusLogProbMetric: 16.3769, val_loss: 16.7605, val_MinusLogProbMetric: 16.7605

Epoch 645: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3769 - MinusLogProbMetric: 16.3769 - val_loss: 16.7605 - val_MinusLogProbMetric: 16.7605 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 646/1000
2023-09-27 19:43:36.196 
Epoch 646/1000 
	 loss: 16.3769, MinusLogProbMetric: 16.3769, val_loss: 16.7629, val_MinusLogProbMetric: 16.7629

Epoch 646: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3769 - MinusLogProbMetric: 16.3769 - val_loss: 16.7629 - val_MinusLogProbMetric: 16.7629 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 647/1000
2023-09-27 19:44:14.006 
Epoch 647/1000 
	 loss: 16.3753, MinusLogProbMetric: 16.3753, val_loss: 16.7603, val_MinusLogProbMetric: 16.7603

Epoch 647: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3753 - MinusLogProbMetric: 16.3753 - val_loss: 16.7603 - val_MinusLogProbMetric: 16.7603 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 648/1000
2023-09-27 19:44:51.933 
Epoch 648/1000 
	 loss: 16.3752, MinusLogProbMetric: 16.3752, val_loss: 16.7673, val_MinusLogProbMetric: 16.7673

Epoch 648: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3752 - MinusLogProbMetric: 16.3752 - val_loss: 16.7673 - val_MinusLogProbMetric: 16.7673 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 649/1000
2023-09-27 19:45:29.530 
Epoch 649/1000 
	 loss: 16.3770, MinusLogProbMetric: 16.3770, val_loss: 16.7621, val_MinusLogProbMetric: 16.7621

Epoch 649: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3770 - MinusLogProbMetric: 16.3770 - val_loss: 16.7621 - val_MinusLogProbMetric: 16.7621 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 650/1000
2023-09-27 19:46:07.197 
Epoch 650/1000 
	 loss: 16.3760, MinusLogProbMetric: 16.3760, val_loss: 16.7621, val_MinusLogProbMetric: 16.7621

Epoch 650: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3760 - MinusLogProbMetric: 16.3760 - val_loss: 16.7621 - val_MinusLogProbMetric: 16.7621 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 651/1000
2023-09-27 19:46:45.131 
Epoch 651/1000 
	 loss: 16.3779, MinusLogProbMetric: 16.3779, val_loss: 16.7606, val_MinusLogProbMetric: 16.7606

Epoch 651: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3779 - MinusLogProbMetric: 16.3779 - val_loss: 16.7606 - val_MinusLogProbMetric: 16.7606 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 652/1000
2023-09-27 19:47:23.005 
Epoch 652/1000 
	 loss: 16.3745, MinusLogProbMetric: 16.3745, val_loss: 16.7600, val_MinusLogProbMetric: 16.7600

Epoch 652: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3745 - MinusLogProbMetric: 16.3745 - val_loss: 16.7600 - val_MinusLogProbMetric: 16.7600 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 653/1000
2023-09-27 19:48:01.298 
Epoch 653/1000 
	 loss: 16.3749, MinusLogProbMetric: 16.3749, val_loss: 16.7651, val_MinusLogProbMetric: 16.7651

Epoch 653: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3749 - MinusLogProbMetric: 16.3749 - val_loss: 16.7651 - val_MinusLogProbMetric: 16.7651 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 654/1000
2023-09-27 19:48:39.033 
Epoch 654/1000 
	 loss: 16.3758, MinusLogProbMetric: 16.3758, val_loss: 16.7593, val_MinusLogProbMetric: 16.7593

Epoch 654: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3758 - MinusLogProbMetric: 16.3758 - val_loss: 16.7593 - val_MinusLogProbMetric: 16.7593 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 655/1000
2023-09-27 19:49:16.766 
Epoch 655/1000 
	 loss: 16.3755, MinusLogProbMetric: 16.3755, val_loss: 16.7623, val_MinusLogProbMetric: 16.7623

Epoch 655: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3755 - MinusLogProbMetric: 16.3755 - val_loss: 16.7623 - val_MinusLogProbMetric: 16.7623 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 656/1000
2023-09-27 19:49:54.803 
Epoch 656/1000 
	 loss: 16.3757, MinusLogProbMetric: 16.3757, val_loss: 16.7620, val_MinusLogProbMetric: 16.7620

Epoch 656: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3757 - MinusLogProbMetric: 16.3757 - val_loss: 16.7620 - val_MinusLogProbMetric: 16.7620 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 657/1000
2023-09-27 19:50:32.484 
Epoch 657/1000 
	 loss: 16.3752, MinusLogProbMetric: 16.3752, val_loss: 16.7586, val_MinusLogProbMetric: 16.7586

Epoch 657: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3752 - MinusLogProbMetric: 16.3752 - val_loss: 16.7586 - val_MinusLogProbMetric: 16.7586 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 658/1000
2023-09-27 19:51:10.040 
Epoch 658/1000 
	 loss: 16.3748, MinusLogProbMetric: 16.3748, val_loss: 16.7668, val_MinusLogProbMetric: 16.7668

Epoch 658: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3748 - MinusLogProbMetric: 16.3748 - val_loss: 16.7668 - val_MinusLogProbMetric: 16.7668 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 659/1000
2023-09-27 19:51:47.687 
Epoch 659/1000 
	 loss: 16.3765, MinusLogProbMetric: 16.3765, val_loss: 16.7687, val_MinusLogProbMetric: 16.7687

Epoch 659: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3765 - MinusLogProbMetric: 16.3765 - val_loss: 16.7687 - val_MinusLogProbMetric: 16.7687 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 660/1000
2023-09-27 19:52:25.183 
Epoch 660/1000 
	 loss: 16.3752, MinusLogProbMetric: 16.3752, val_loss: 16.7614, val_MinusLogProbMetric: 16.7614

Epoch 660: val_loss did not improve from 16.75604
196/196 - 37s - loss: 16.3752 - MinusLogProbMetric: 16.3752 - val_loss: 16.7614 - val_MinusLogProbMetric: 16.7614 - lr: 6.2500e-05 - 37s/epoch - 191ms/step
Epoch 661/1000
2023-09-27 19:53:03.058 
Epoch 661/1000 
	 loss: 16.3758, MinusLogProbMetric: 16.3758, val_loss: 16.7622, val_MinusLogProbMetric: 16.7622

Epoch 661: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3758 - MinusLogProbMetric: 16.3758 - val_loss: 16.7622 - val_MinusLogProbMetric: 16.7622 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 662/1000
2023-09-27 19:53:40.768 
Epoch 662/1000 
	 loss: 16.3758, MinusLogProbMetric: 16.3758, val_loss: 16.7675, val_MinusLogProbMetric: 16.7675

Epoch 662: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3758 - MinusLogProbMetric: 16.3758 - val_loss: 16.7675 - val_MinusLogProbMetric: 16.7675 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 663/1000
2023-09-27 19:54:18.781 
Epoch 663/1000 
	 loss: 16.3751, MinusLogProbMetric: 16.3751, val_loss: 16.7636, val_MinusLogProbMetric: 16.7636

Epoch 663: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3751 - MinusLogProbMetric: 16.3751 - val_loss: 16.7636 - val_MinusLogProbMetric: 16.7636 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 664/1000
2023-09-27 19:54:56.870 
Epoch 664/1000 
	 loss: 16.3737, MinusLogProbMetric: 16.3737, val_loss: 16.7679, val_MinusLogProbMetric: 16.7679

Epoch 664: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3737 - MinusLogProbMetric: 16.3737 - val_loss: 16.7679 - val_MinusLogProbMetric: 16.7679 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 665/1000
2023-09-27 19:55:34.731 
Epoch 665/1000 
	 loss: 16.3756, MinusLogProbMetric: 16.3756, val_loss: 16.7642, val_MinusLogProbMetric: 16.7642

Epoch 665: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3756 - MinusLogProbMetric: 16.3756 - val_loss: 16.7642 - val_MinusLogProbMetric: 16.7642 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 666/1000
2023-09-27 19:56:12.510 
Epoch 666/1000 
	 loss: 16.3746, MinusLogProbMetric: 16.3746, val_loss: 16.7638, val_MinusLogProbMetric: 16.7638

Epoch 666: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3746 - MinusLogProbMetric: 16.3746 - val_loss: 16.7638 - val_MinusLogProbMetric: 16.7638 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 667/1000
2023-09-27 19:56:50.687 
Epoch 667/1000 
	 loss: 16.3746, MinusLogProbMetric: 16.3746, val_loss: 16.7641, val_MinusLogProbMetric: 16.7641

Epoch 667: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3746 - MinusLogProbMetric: 16.3746 - val_loss: 16.7641 - val_MinusLogProbMetric: 16.7641 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 668/1000
2023-09-27 19:57:27.980 
Epoch 668/1000 
	 loss: 16.3781, MinusLogProbMetric: 16.3781, val_loss: 16.7617, val_MinusLogProbMetric: 16.7617

Epoch 668: val_loss did not improve from 16.75604
196/196 - 37s - loss: 16.3781 - MinusLogProbMetric: 16.3781 - val_loss: 16.7617 - val_MinusLogProbMetric: 16.7617 - lr: 6.2500e-05 - 37s/epoch - 190ms/step
Epoch 669/1000
2023-09-27 19:58:05.707 
Epoch 669/1000 
	 loss: 16.3763, MinusLogProbMetric: 16.3763, val_loss: 16.7647, val_MinusLogProbMetric: 16.7647

Epoch 669: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3763 - MinusLogProbMetric: 16.3763 - val_loss: 16.7647 - val_MinusLogProbMetric: 16.7647 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 670/1000
2023-09-27 19:58:43.434 
Epoch 670/1000 
	 loss: 16.3771, MinusLogProbMetric: 16.3771, val_loss: 16.7618, val_MinusLogProbMetric: 16.7618

Epoch 670: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3771 - MinusLogProbMetric: 16.3771 - val_loss: 16.7618 - val_MinusLogProbMetric: 16.7618 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 671/1000
2023-09-27 19:59:21.431 
Epoch 671/1000 
	 loss: 16.3768, MinusLogProbMetric: 16.3768, val_loss: 16.7640, val_MinusLogProbMetric: 16.7640

Epoch 671: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3768 - MinusLogProbMetric: 16.3768 - val_loss: 16.7640 - val_MinusLogProbMetric: 16.7640 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 672/1000
2023-09-27 19:59:59.515 
Epoch 672/1000 
	 loss: 16.3756, MinusLogProbMetric: 16.3756, val_loss: 16.7748, val_MinusLogProbMetric: 16.7748

Epoch 672: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3756 - MinusLogProbMetric: 16.3756 - val_loss: 16.7748 - val_MinusLogProbMetric: 16.7748 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 673/1000
2023-09-27 20:00:37.395 
Epoch 673/1000 
	 loss: 16.3756, MinusLogProbMetric: 16.3756, val_loss: 16.7599, val_MinusLogProbMetric: 16.7599

Epoch 673: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3756 - MinusLogProbMetric: 16.3756 - val_loss: 16.7599 - val_MinusLogProbMetric: 16.7599 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 674/1000
2023-09-27 20:01:15.251 
Epoch 674/1000 
	 loss: 16.3739, MinusLogProbMetric: 16.3739, val_loss: 16.7625, val_MinusLogProbMetric: 16.7625

Epoch 674: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3739 - MinusLogProbMetric: 16.3739 - val_loss: 16.7625 - val_MinusLogProbMetric: 16.7625 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 675/1000
2023-09-27 20:01:52.954 
Epoch 675/1000 
	 loss: 16.3755, MinusLogProbMetric: 16.3755, val_loss: 16.7602, val_MinusLogProbMetric: 16.7602

Epoch 675: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3755 - MinusLogProbMetric: 16.3755 - val_loss: 16.7602 - val_MinusLogProbMetric: 16.7602 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 676/1000
2023-09-27 20:02:30.595 
Epoch 676/1000 
	 loss: 16.3750, MinusLogProbMetric: 16.3750, val_loss: 16.7652, val_MinusLogProbMetric: 16.7652

Epoch 676: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3750 - MinusLogProbMetric: 16.3750 - val_loss: 16.7652 - val_MinusLogProbMetric: 16.7652 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 677/1000
2023-09-27 20:03:08.572 
Epoch 677/1000 
	 loss: 16.3764, MinusLogProbMetric: 16.3764, val_loss: 16.7561, val_MinusLogProbMetric: 16.7561

Epoch 677: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3764 - MinusLogProbMetric: 16.3764 - val_loss: 16.7561 - val_MinusLogProbMetric: 16.7561 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 678/1000
2023-09-27 20:03:46.443 
Epoch 678/1000 
	 loss: 16.3749, MinusLogProbMetric: 16.3749, val_loss: 16.7682, val_MinusLogProbMetric: 16.7682

Epoch 678: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3749 - MinusLogProbMetric: 16.3749 - val_loss: 16.7682 - val_MinusLogProbMetric: 16.7682 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 679/1000
2023-09-27 20:04:24.346 
Epoch 679/1000 
	 loss: 16.3742, MinusLogProbMetric: 16.3742, val_loss: 16.7601, val_MinusLogProbMetric: 16.7601

Epoch 679: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3742 - MinusLogProbMetric: 16.3742 - val_loss: 16.7601 - val_MinusLogProbMetric: 16.7601 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 680/1000
2023-09-27 20:05:02.194 
Epoch 680/1000 
	 loss: 16.3754, MinusLogProbMetric: 16.3754, val_loss: 16.7625, val_MinusLogProbMetric: 16.7625

Epoch 680: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3754 - MinusLogProbMetric: 16.3754 - val_loss: 16.7625 - val_MinusLogProbMetric: 16.7625 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 681/1000
2023-09-27 20:05:40.221 
Epoch 681/1000 
	 loss: 16.3745, MinusLogProbMetric: 16.3745, val_loss: 16.7683, val_MinusLogProbMetric: 16.7683

Epoch 681: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3745 - MinusLogProbMetric: 16.3745 - val_loss: 16.7683 - val_MinusLogProbMetric: 16.7683 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 682/1000
2023-09-27 20:06:17.812 
Epoch 682/1000 
	 loss: 16.3761, MinusLogProbMetric: 16.3761, val_loss: 16.7618, val_MinusLogProbMetric: 16.7618

Epoch 682: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3761 - MinusLogProbMetric: 16.3761 - val_loss: 16.7618 - val_MinusLogProbMetric: 16.7618 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 683/1000
2023-09-27 20:06:55.290 
Epoch 683/1000 
	 loss: 16.3742, MinusLogProbMetric: 16.3742, val_loss: 16.7620, val_MinusLogProbMetric: 16.7620

Epoch 683: val_loss did not improve from 16.75604
196/196 - 37s - loss: 16.3742 - MinusLogProbMetric: 16.3742 - val_loss: 16.7620 - val_MinusLogProbMetric: 16.7620 - lr: 6.2500e-05 - 37s/epoch - 191ms/step
Epoch 684/1000
2023-09-27 20:07:33.130 
Epoch 684/1000 
	 loss: 16.3752, MinusLogProbMetric: 16.3752, val_loss: 16.7639, val_MinusLogProbMetric: 16.7639

Epoch 684: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3752 - MinusLogProbMetric: 16.3752 - val_loss: 16.7639 - val_MinusLogProbMetric: 16.7639 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 685/1000
2023-09-27 20:08:11.224 
Epoch 685/1000 
	 loss: 16.3741, MinusLogProbMetric: 16.3741, val_loss: 16.7604, val_MinusLogProbMetric: 16.7604

Epoch 685: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3741 - MinusLogProbMetric: 16.3741 - val_loss: 16.7604 - val_MinusLogProbMetric: 16.7604 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 686/1000
2023-09-27 20:08:49.215 
Epoch 686/1000 
	 loss: 16.3734, MinusLogProbMetric: 16.3734, val_loss: 16.7649, val_MinusLogProbMetric: 16.7649

Epoch 686: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3734 - MinusLogProbMetric: 16.3734 - val_loss: 16.7649 - val_MinusLogProbMetric: 16.7649 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 687/1000
2023-09-27 20:09:26.881 
Epoch 687/1000 
	 loss: 16.3743, MinusLogProbMetric: 16.3743, val_loss: 16.7597, val_MinusLogProbMetric: 16.7597

Epoch 687: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3743 - MinusLogProbMetric: 16.3743 - val_loss: 16.7597 - val_MinusLogProbMetric: 16.7597 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 688/1000
2023-09-27 20:10:04.833 
Epoch 688/1000 
	 loss: 16.3740, MinusLogProbMetric: 16.3740, val_loss: 16.7654, val_MinusLogProbMetric: 16.7654

Epoch 688: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3740 - MinusLogProbMetric: 16.3740 - val_loss: 16.7654 - val_MinusLogProbMetric: 16.7654 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 689/1000
2023-09-27 20:10:42.732 
Epoch 689/1000 
	 loss: 16.3757, MinusLogProbMetric: 16.3757, val_loss: 16.7580, val_MinusLogProbMetric: 16.7580

Epoch 689: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3757 - MinusLogProbMetric: 16.3757 - val_loss: 16.7580 - val_MinusLogProbMetric: 16.7580 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 690/1000
2023-09-27 20:11:20.704 
Epoch 690/1000 
	 loss: 16.3673, MinusLogProbMetric: 16.3673, val_loss: 16.7566, val_MinusLogProbMetric: 16.7566

Epoch 690: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3673 - MinusLogProbMetric: 16.3673 - val_loss: 16.7566 - val_MinusLogProbMetric: 16.7566 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 691/1000
2023-09-27 20:11:58.445 
Epoch 691/1000 
	 loss: 16.3663, MinusLogProbMetric: 16.3663, val_loss: 16.7589, val_MinusLogProbMetric: 16.7589

Epoch 691: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3663 - MinusLogProbMetric: 16.3663 - val_loss: 16.7589 - val_MinusLogProbMetric: 16.7589 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 692/1000
2023-09-27 20:12:36.492 
Epoch 692/1000 
	 loss: 16.3668, MinusLogProbMetric: 16.3668, val_loss: 16.7590, val_MinusLogProbMetric: 16.7590

Epoch 692: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3668 - MinusLogProbMetric: 16.3668 - val_loss: 16.7590 - val_MinusLogProbMetric: 16.7590 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 693/1000
2023-09-27 20:13:13.837 
Epoch 693/1000 
	 loss: 16.3672, MinusLogProbMetric: 16.3672, val_loss: 16.7574, val_MinusLogProbMetric: 16.7574

Epoch 693: val_loss did not improve from 16.75604
196/196 - 37s - loss: 16.3672 - MinusLogProbMetric: 16.3672 - val_loss: 16.7574 - val_MinusLogProbMetric: 16.7574 - lr: 3.1250e-05 - 37s/epoch - 191ms/step
Epoch 694/1000
2023-09-27 20:13:51.851 
Epoch 694/1000 
	 loss: 16.3671, MinusLogProbMetric: 16.3671, val_loss: 16.7580, val_MinusLogProbMetric: 16.7580

Epoch 694: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3671 - MinusLogProbMetric: 16.3671 - val_loss: 16.7580 - val_MinusLogProbMetric: 16.7580 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 695/1000
2023-09-27 20:14:29.697 
Epoch 695/1000 
	 loss: 16.3677, MinusLogProbMetric: 16.3677, val_loss: 16.7588, val_MinusLogProbMetric: 16.7588

Epoch 695: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3677 - MinusLogProbMetric: 16.3677 - val_loss: 16.7588 - val_MinusLogProbMetric: 16.7588 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 696/1000
2023-09-27 20:15:07.565 
Epoch 696/1000 
	 loss: 16.3675, MinusLogProbMetric: 16.3675, val_loss: 16.7571, val_MinusLogProbMetric: 16.7571

Epoch 696: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3675 - MinusLogProbMetric: 16.3675 - val_loss: 16.7571 - val_MinusLogProbMetric: 16.7571 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 697/1000
2023-09-27 20:15:45.396 
Epoch 697/1000 
	 loss: 16.3682, MinusLogProbMetric: 16.3682, val_loss: 16.7612, val_MinusLogProbMetric: 16.7612

Epoch 697: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3682 - MinusLogProbMetric: 16.3682 - val_loss: 16.7612 - val_MinusLogProbMetric: 16.7612 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 698/1000
2023-09-27 20:16:23.106 
Epoch 698/1000 
	 loss: 16.3665, MinusLogProbMetric: 16.3665, val_loss: 16.7573, val_MinusLogProbMetric: 16.7573

Epoch 698: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3665 - MinusLogProbMetric: 16.3665 - val_loss: 16.7573 - val_MinusLogProbMetric: 16.7573 - lr: 3.1250e-05 - 38s/epoch - 192ms/step
Epoch 699/1000
2023-09-27 20:17:01.181 
Epoch 699/1000 
	 loss: 16.3670, MinusLogProbMetric: 16.3670, val_loss: 16.7598, val_MinusLogProbMetric: 16.7598

Epoch 699: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3670 - MinusLogProbMetric: 16.3670 - val_loss: 16.7598 - val_MinusLogProbMetric: 16.7598 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 700/1000
2023-09-27 20:17:38.987 
Epoch 700/1000 
	 loss: 16.3672, MinusLogProbMetric: 16.3672, val_loss: 16.7569, val_MinusLogProbMetric: 16.7569

Epoch 700: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3672 - MinusLogProbMetric: 16.3672 - val_loss: 16.7569 - val_MinusLogProbMetric: 16.7569 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 701/1000
2023-09-27 20:18:16.932 
Epoch 701/1000 
	 loss: 16.3674, MinusLogProbMetric: 16.3674, val_loss: 16.7575, val_MinusLogProbMetric: 16.7575

Epoch 701: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3674 - MinusLogProbMetric: 16.3674 - val_loss: 16.7575 - val_MinusLogProbMetric: 16.7575 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 702/1000
2023-09-27 20:18:54.463 
Epoch 702/1000 
	 loss: 16.3661, MinusLogProbMetric: 16.3661, val_loss: 16.7598, val_MinusLogProbMetric: 16.7598

Epoch 702: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3661 - MinusLogProbMetric: 16.3661 - val_loss: 16.7598 - val_MinusLogProbMetric: 16.7598 - lr: 3.1250e-05 - 38s/epoch - 191ms/step
Epoch 703/1000
2023-09-27 20:19:32.304 
Epoch 703/1000 
	 loss: 16.3674, MinusLogProbMetric: 16.3674, val_loss: 16.7563, val_MinusLogProbMetric: 16.7563

Epoch 703: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3674 - MinusLogProbMetric: 16.3674 - val_loss: 16.7563 - val_MinusLogProbMetric: 16.7563 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 704/1000
2023-09-27 20:20:09.837 
Epoch 704/1000 
	 loss: 16.3670, MinusLogProbMetric: 16.3670, val_loss: 16.7610, val_MinusLogProbMetric: 16.7610

Epoch 704: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3670 - MinusLogProbMetric: 16.3670 - val_loss: 16.7610 - val_MinusLogProbMetric: 16.7610 - lr: 3.1250e-05 - 38s/epoch - 191ms/step
Epoch 705/1000
2023-09-27 20:20:47.668 
Epoch 705/1000 
	 loss: 16.3666, MinusLogProbMetric: 16.3666, val_loss: 16.7612, val_MinusLogProbMetric: 16.7612

Epoch 705: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3666 - MinusLogProbMetric: 16.3666 - val_loss: 16.7612 - val_MinusLogProbMetric: 16.7612 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 706/1000
2023-09-27 20:21:25.421 
Epoch 706/1000 
	 loss: 16.3666, MinusLogProbMetric: 16.3666, val_loss: 16.7570, val_MinusLogProbMetric: 16.7570

Epoch 706: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3666 - MinusLogProbMetric: 16.3666 - val_loss: 16.7570 - val_MinusLogProbMetric: 16.7570 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 707/1000
2023-09-27 20:22:03.417 
Epoch 707/1000 
	 loss: 16.3667, MinusLogProbMetric: 16.3667, val_loss: 16.7588, val_MinusLogProbMetric: 16.7588

Epoch 707: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3667 - MinusLogProbMetric: 16.3667 - val_loss: 16.7588 - val_MinusLogProbMetric: 16.7588 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 708/1000
2023-09-27 20:22:40.968 
Epoch 708/1000 
	 loss: 16.3670, MinusLogProbMetric: 16.3670, val_loss: 16.7590, val_MinusLogProbMetric: 16.7590

Epoch 708: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3670 - MinusLogProbMetric: 16.3670 - val_loss: 16.7590 - val_MinusLogProbMetric: 16.7590 - lr: 3.1250e-05 - 38s/epoch - 192ms/step
Epoch 709/1000
2023-09-27 20:23:18.931 
Epoch 709/1000 
	 loss: 16.3665, MinusLogProbMetric: 16.3665, val_loss: 16.7634, val_MinusLogProbMetric: 16.7634

Epoch 709: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3665 - MinusLogProbMetric: 16.3665 - val_loss: 16.7634 - val_MinusLogProbMetric: 16.7634 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 710/1000
2023-09-27 20:23:56.872 
Epoch 710/1000 
	 loss: 16.3666, MinusLogProbMetric: 16.3666, val_loss: 16.7593, val_MinusLogProbMetric: 16.7593

Epoch 710: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3666 - MinusLogProbMetric: 16.3666 - val_loss: 16.7593 - val_MinusLogProbMetric: 16.7593 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 711/1000
2023-09-27 20:24:34.555 
Epoch 711/1000 
	 loss: 16.3664, MinusLogProbMetric: 16.3664, val_loss: 16.7596, val_MinusLogProbMetric: 16.7596

Epoch 711: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3664 - MinusLogProbMetric: 16.3664 - val_loss: 16.7596 - val_MinusLogProbMetric: 16.7596 - lr: 3.1250e-05 - 38s/epoch - 192ms/step
Epoch 712/1000
2023-09-27 20:25:12.213 
Epoch 712/1000 
	 loss: 16.3661, MinusLogProbMetric: 16.3661, val_loss: 16.7604, val_MinusLogProbMetric: 16.7604

Epoch 712: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3661 - MinusLogProbMetric: 16.3661 - val_loss: 16.7604 - val_MinusLogProbMetric: 16.7604 - lr: 3.1250e-05 - 38s/epoch - 192ms/step
Epoch 713/1000
2023-09-27 20:25:49.905 
Epoch 713/1000 
	 loss: 16.3664, MinusLogProbMetric: 16.3664, val_loss: 16.7571, val_MinusLogProbMetric: 16.7571

Epoch 713: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3664 - MinusLogProbMetric: 16.3664 - val_loss: 16.7571 - val_MinusLogProbMetric: 16.7571 - lr: 3.1250e-05 - 38s/epoch - 192ms/step
Epoch 714/1000
2023-09-27 20:26:27.553 
Epoch 714/1000 
	 loss: 16.3672, MinusLogProbMetric: 16.3672, val_loss: 16.7579, val_MinusLogProbMetric: 16.7579

Epoch 714: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3672 - MinusLogProbMetric: 16.3672 - val_loss: 16.7579 - val_MinusLogProbMetric: 16.7579 - lr: 3.1250e-05 - 38s/epoch - 192ms/step
Epoch 715/1000
2023-09-27 20:27:05.409 
Epoch 715/1000 
	 loss: 16.3674, MinusLogProbMetric: 16.3674, val_loss: 16.7604, val_MinusLogProbMetric: 16.7604

Epoch 715: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3674 - MinusLogProbMetric: 16.3674 - val_loss: 16.7604 - val_MinusLogProbMetric: 16.7604 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 716/1000
2023-09-27 20:27:43.350 
Epoch 716/1000 
	 loss: 16.3666, MinusLogProbMetric: 16.3666, val_loss: 16.7567, val_MinusLogProbMetric: 16.7567

Epoch 716: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3666 - MinusLogProbMetric: 16.3666 - val_loss: 16.7567 - val_MinusLogProbMetric: 16.7567 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 717/1000
2023-09-27 20:28:20.873 
Epoch 717/1000 
	 loss: 16.3672, MinusLogProbMetric: 16.3672, val_loss: 16.7602, val_MinusLogProbMetric: 16.7602

Epoch 717: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3672 - MinusLogProbMetric: 16.3672 - val_loss: 16.7602 - val_MinusLogProbMetric: 16.7602 - lr: 3.1250e-05 - 38s/epoch - 191ms/step
Epoch 718/1000
2023-09-27 20:28:59.088 
Epoch 718/1000 
	 loss: 16.3666, MinusLogProbMetric: 16.3666, val_loss: 16.7566, val_MinusLogProbMetric: 16.7566

Epoch 718: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3666 - MinusLogProbMetric: 16.3666 - val_loss: 16.7566 - val_MinusLogProbMetric: 16.7566 - lr: 3.1250e-05 - 38s/epoch - 195ms/step
Epoch 719/1000
2023-09-27 20:29:36.857 
Epoch 719/1000 
	 loss: 16.3661, MinusLogProbMetric: 16.3661, val_loss: 16.7604, val_MinusLogProbMetric: 16.7604

Epoch 719: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3661 - MinusLogProbMetric: 16.3661 - val_loss: 16.7604 - val_MinusLogProbMetric: 16.7604 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 720/1000
2023-09-27 20:30:14.462 
Epoch 720/1000 
	 loss: 16.3668, MinusLogProbMetric: 16.3668, val_loss: 16.7594, val_MinusLogProbMetric: 16.7594

Epoch 720: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3668 - MinusLogProbMetric: 16.3668 - val_loss: 16.7594 - val_MinusLogProbMetric: 16.7594 - lr: 3.1250e-05 - 38s/epoch - 192ms/step
Epoch 721/1000
2023-09-27 20:30:52.396 
Epoch 721/1000 
	 loss: 16.3663, MinusLogProbMetric: 16.3663, val_loss: 16.7612, val_MinusLogProbMetric: 16.7612

Epoch 721: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3663 - MinusLogProbMetric: 16.3663 - val_loss: 16.7612 - val_MinusLogProbMetric: 16.7612 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 722/1000
2023-09-27 20:31:30.209 
Epoch 722/1000 
	 loss: 16.3669, MinusLogProbMetric: 16.3669, val_loss: 16.7593, val_MinusLogProbMetric: 16.7593

Epoch 722: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3669 - MinusLogProbMetric: 16.3669 - val_loss: 16.7593 - val_MinusLogProbMetric: 16.7593 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 723/1000
2023-09-27 20:32:08.310 
Epoch 723/1000 
	 loss: 16.3664, MinusLogProbMetric: 16.3664, val_loss: 16.7572, val_MinusLogProbMetric: 16.7572

Epoch 723: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3664 - MinusLogProbMetric: 16.3664 - val_loss: 16.7572 - val_MinusLogProbMetric: 16.7572 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 724/1000
2023-09-27 20:32:46.055 
Epoch 724/1000 
	 loss: 16.3659, MinusLogProbMetric: 16.3659, val_loss: 16.7597, val_MinusLogProbMetric: 16.7597

Epoch 724: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3659 - MinusLogProbMetric: 16.3659 - val_loss: 16.7597 - val_MinusLogProbMetric: 16.7597 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 725/1000
2023-09-27 20:33:23.963 
Epoch 725/1000 
	 loss: 16.3660, MinusLogProbMetric: 16.3660, val_loss: 16.7588, val_MinusLogProbMetric: 16.7588

Epoch 725: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3660 - MinusLogProbMetric: 16.3660 - val_loss: 16.7588 - val_MinusLogProbMetric: 16.7588 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 726/1000
2023-09-27 20:34:01.732 
Epoch 726/1000 
	 loss: 16.3665, MinusLogProbMetric: 16.3665, val_loss: 16.7582, val_MinusLogProbMetric: 16.7582

Epoch 726: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3665 - MinusLogProbMetric: 16.3665 - val_loss: 16.7582 - val_MinusLogProbMetric: 16.7582 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 727/1000
2023-09-27 20:34:39.506 
Epoch 727/1000 
	 loss: 16.3669, MinusLogProbMetric: 16.3669, val_loss: 16.7624, val_MinusLogProbMetric: 16.7624

Epoch 727: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3669 - MinusLogProbMetric: 16.3669 - val_loss: 16.7624 - val_MinusLogProbMetric: 16.7624 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 728/1000
2023-09-27 20:35:17.157 
Epoch 728/1000 
	 loss: 16.3665, MinusLogProbMetric: 16.3665, val_loss: 16.7604, val_MinusLogProbMetric: 16.7604

Epoch 728: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3665 - MinusLogProbMetric: 16.3665 - val_loss: 16.7604 - val_MinusLogProbMetric: 16.7604 - lr: 3.1250e-05 - 38s/epoch - 192ms/step
Epoch 729/1000
2023-09-27 20:35:55.020 
Epoch 729/1000 
	 loss: 16.3668, MinusLogProbMetric: 16.3668, val_loss: 16.7590, val_MinusLogProbMetric: 16.7590

Epoch 729: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3668 - MinusLogProbMetric: 16.3668 - val_loss: 16.7590 - val_MinusLogProbMetric: 16.7590 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 730/1000
2023-09-27 20:36:32.960 
Epoch 730/1000 
	 loss: 16.3665, MinusLogProbMetric: 16.3665, val_loss: 16.7588, val_MinusLogProbMetric: 16.7588

Epoch 730: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3665 - MinusLogProbMetric: 16.3665 - val_loss: 16.7588 - val_MinusLogProbMetric: 16.7588 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 731/1000
2023-09-27 20:37:10.742 
Epoch 731/1000 
	 loss: 16.3657, MinusLogProbMetric: 16.3657, val_loss: 16.7590, val_MinusLogProbMetric: 16.7590

Epoch 731: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3657 - MinusLogProbMetric: 16.3657 - val_loss: 16.7590 - val_MinusLogProbMetric: 16.7590 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 732/1000
2023-09-27 20:37:48.706 
Epoch 732/1000 
	 loss: 16.3662, MinusLogProbMetric: 16.3662, val_loss: 16.7611, val_MinusLogProbMetric: 16.7611

Epoch 732: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3662 - MinusLogProbMetric: 16.3662 - val_loss: 16.7611 - val_MinusLogProbMetric: 16.7611 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 733/1000
2023-09-27 20:38:26.417 
Epoch 733/1000 
	 loss: 16.3662, MinusLogProbMetric: 16.3662, val_loss: 16.7609, val_MinusLogProbMetric: 16.7609

Epoch 733: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3662 - MinusLogProbMetric: 16.3662 - val_loss: 16.7609 - val_MinusLogProbMetric: 16.7609 - lr: 3.1250e-05 - 38s/epoch - 192ms/step
Epoch 734/1000
2023-09-27 20:39:04.375 
Epoch 734/1000 
	 loss: 16.3661, MinusLogProbMetric: 16.3661, val_loss: 16.7588, val_MinusLogProbMetric: 16.7588

Epoch 734: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3661 - MinusLogProbMetric: 16.3661 - val_loss: 16.7588 - val_MinusLogProbMetric: 16.7588 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 735/1000
2023-09-27 20:39:42.277 
Epoch 735/1000 
	 loss: 16.3658, MinusLogProbMetric: 16.3658, val_loss: 16.7600, val_MinusLogProbMetric: 16.7600

Epoch 735: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3658 - MinusLogProbMetric: 16.3658 - val_loss: 16.7600 - val_MinusLogProbMetric: 16.7600 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 736/1000
2023-09-27 20:40:20.266 
Epoch 736/1000 
	 loss: 16.3657, MinusLogProbMetric: 16.3657, val_loss: 16.7565, val_MinusLogProbMetric: 16.7565

Epoch 736: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3657 - MinusLogProbMetric: 16.3657 - val_loss: 16.7565 - val_MinusLogProbMetric: 16.7565 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 737/1000
2023-09-27 20:40:57.803 
Epoch 737/1000 
	 loss: 16.3664, MinusLogProbMetric: 16.3664, val_loss: 16.7586, val_MinusLogProbMetric: 16.7586

Epoch 737: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3664 - MinusLogProbMetric: 16.3664 - val_loss: 16.7586 - val_MinusLogProbMetric: 16.7586 - lr: 3.1250e-05 - 38s/epoch - 192ms/step
Epoch 738/1000
2023-09-27 20:41:35.568 
Epoch 738/1000 
	 loss: 16.3663, MinusLogProbMetric: 16.3663, val_loss: 16.7648, val_MinusLogProbMetric: 16.7648

Epoch 738: val_loss did not improve from 16.75604
196/196 - 38s - loss: 16.3663 - MinusLogProbMetric: 16.3663 - val_loss: 16.7648 - val_MinusLogProbMetric: 16.7648 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 739/1000
2023-09-27 20:42:13.162 
Epoch 739/1000 
	 loss: 16.3660, MinusLogProbMetric: 16.3660, val_loss: 16.7591, val_MinusLogProbMetric: 16.7591

Epoch 739: val_loss did not improve from 16.75604
Restoring model weights from the end of the best epoch: 639.
196/196 - 38s - loss: 16.3660 - MinusLogProbMetric: 16.3660 - val_loss: 16.7591 - val_MinusLogProbMetric: 16.7591 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 739: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
WARNING:tensorflow:5 out of the last 5 calls to <function LRMetric.Test_tf.<locals>.compute_test at 0x7fd29440d1b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
LR metric calculation completed in 13.962603689986281 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
WARNING:tensorflow:5 out of the last 5 calls to <function KSTest.Test_tf.<locals>.compute_test at 0x7fd29440d240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
KS tests calculation completed in 8.819287794991396 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
WARNING:tensorflow:5 out of the last 5 calls to <function SWDMetric.Test_tf.<locals>.compute_test at 0x7fd29440d900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
SWD metric calculation completed in 6.345706219028216 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
WARNING:tensorflow:5 out of the last 5 calls to <function FNMetric.Test_tf.<locals>.compute_test at 0x7fd29440c430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
FN metric calculation completed in 7.379250171012245 seconds.
Training succeeded with seed 926.
Model trained in 28309.88 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 37.66 s.
                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/c_Main_CsplineN.py , Line : 469, Func.Name : prediction_function, Message : Plotters.cornerplotter(X_data_test.numpy(),X_data_nf.numpy(),path_to_results,ndims,norm=True) # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 37.88 s.
===========
Run 307/720 done in 28352.93 s.
===========

Directory ../../results/CsplineN_new/run_308/ already exists.
Skipping it.
===========
Run 308/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_309/ already exists.
Skipping it.
===========
Run 309/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_310/ already exists.
Skipping it.
===========
Run 310/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_311/ already exists.
Skipping it.
===========
Run 311/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_312/ already exists.
Skipping it.
===========
Run 312/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_313/ already exists.
Skipping it.
===========
Run 313/720 already exists. Skipping it.
===========

===========
Generating train data for run 314.
===========
Train data generated in 0.27 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_314/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 933}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_314/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[2.7429588 , 2.5700626 , 7.723717  , ..., 7.7501717 , 2.9186718 ,
        1.775845  ],
       [4.728784  , 6.065677  , 0.9645814 , ..., 1.2628946 , 6.7253027 ,
        1.4381479 ],
       [3.8513129 , 6.1744533 , 0.2601294 , ..., 1.1662469 , 6.572044  ,
        1.3500103 ],
       ...,
       [2.8332918 , 4.2526407 , 9.701975  , ..., 7.0738525 , 2.5952196 ,
        1.8190176 ],
       [3.118363  , 5.4312434 , 0.32481733, ..., 1.9350358 , 6.6219816 ,
        1.3230293 ],
       [1.792576  , 4.9344916 , 9.207544  , ..., 7.378074  , 2.857349  ,
        1.56005   ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_314/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_314
self.data_kwargs: {'seed': 933}
self.x_data: [[4.6118093  6.294248   0.6753535  ... 1.3966799  6.5528636  1.404321  ]
 [5.0913153  7.181254   5.302016   ... 4.927679   2.6276157  7.5562596 ]
 [2.3468595  3.6813745  8.449473   ... 7.5625257  2.3049273  1.7164713 ]
 ...
 [1.7774892  4.58926    7.003348   ... 7.297376   3.211844   1.3889377 ]
 [5.1396513  5.5684643  1.4578001  ... 0.69219434 6.9603205  1.3834548 ]
 [3.2499232  3.5331872  8.207085   ... 6.760554   3.3946218  2.0297966 ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_51"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_52 (InputLayer)       [(None, 32)]              0         
                                                                 
 log_prob_layer_6 (LogProbLa  (None,)                  1152560   
 yer)                                                            
                                                                 
=================================================================
Total params: 1,152,560
Trainable params: 1,152,560
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_6/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_6'")
self.model: <keras.engine.functional.Functional object at 0x7fd2f45cb460>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fda0a376980>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fda0a376980>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fda1b2f9450>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fda1b2f81f0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_314/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fd42c441e40>, <keras.callbacks.ModelCheckpoint object at 0x7fd2d856d420>, <keras.callbacks.EarlyStopping object at 0x7fd2d856f430>, <keras.callbacks.ReduceLROnPlateau object at 0x7fd3a0211600>, <keras.callbacks.TerminateOnNaN object at 0x7fd3a0210f70>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[2.7429588 , 2.5700626 , 7.723717  , ..., 7.7501717 , 2.9186718 ,
        1.775845  ],
       [4.728784  , 6.065677  , 0.9645814 , ..., 1.2628946 , 6.7253027 ,
        1.4381479 ],
       [3.8513129 , 6.1744533 , 0.2601294 , ..., 1.1662469 , 6.572044  ,
        1.3500103 ],
       ...,
       [2.8332918 , 4.2526407 , 9.701975  , ..., 7.0738525 , 2.5952196 ,
        1.8190176 ],
       [3.118363  , 5.4312434 , 0.32481733, ..., 1.9350358 , 6.6219816 ,
        1.3230293 ],
       [1.792576  , 4.9344916 , 9.207544  , ..., 7.378074  , 2.857349  ,
        1.56005   ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_314/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 314/720 with hyperparameters:
timestamp = 2023-09-27 20:42:59.680514
ndims = 32
seed_train = 933
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 5
spline_knots = 8
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 1152560
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 4.6118093   6.294248    0.6753535   5.561676    6.128757    6.145322
  9.785121    7.1052794   3.7474928   5.3494825   6.3791265   0.5788075
  5.683702    6.3188157   1.6447939   1.0492666   3.6812766   3.7191741
  5.81123     3.2186081  10.359394    0.68370855  2.036205    1.0944312
  6.489696    3.6441135   4.6169076   1.7655768   1.5199437   1.3966799
  6.5528636   1.404321  ]
Epoch 1/1000
2023-09-27 20:44:27.879 
Epoch 1/1000 
	 loss: 54.3047, MinusLogProbMetric: 54.3047, val_loss: 26.6583, val_MinusLogProbMetric: 26.6583

Epoch 1: val_loss improved from inf to 26.65828, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_314/weights/best_weights.h5
196/196 - 88s - loss: 54.3047 - MinusLogProbMetric: 54.3047 - val_loss: 26.6583 - val_MinusLogProbMetric: 26.6583 - lr: 0.0010 - 88s/epoch - 451ms/step
Epoch 2/1000
2023-09-27 20:44:59.942 
Epoch 2/1000 
	 loss: 24.5661, MinusLogProbMetric: 24.5661, val_loss: 24.4411, val_MinusLogProbMetric: 24.4411

Epoch 2: val_loss improved from 26.65828 to 24.44108, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_314/weights/best_weights.h5
196/196 - 32s - loss: 24.5661 - MinusLogProbMetric: 24.5661 - val_loss: 24.4411 - val_MinusLogProbMetric: 24.4411 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 3/1000
2023-09-27 20:45:32.302 
Epoch 3/1000 
	 loss: 22.3809, MinusLogProbMetric: 22.3809, val_loss: 21.0329, val_MinusLogProbMetric: 21.0329

Epoch 3: val_loss improved from 24.44108 to 21.03292, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_314/weights/best_weights.h5
196/196 - 32s - loss: 22.3809 - MinusLogProbMetric: 22.3809 - val_loss: 21.0329 - val_MinusLogProbMetric: 21.0329 - lr: 0.0010 - 32s/epoch - 166ms/step
Epoch 4/1000
2023-09-27 20:46:04.493 
Epoch 4/1000 
	 loss: 21.1290, MinusLogProbMetric: 21.1290, val_loss: 22.3556, val_MinusLogProbMetric: 22.3556

Epoch 4: val_loss did not improve from 21.03292
196/196 - 32s - loss: 21.1290 - MinusLogProbMetric: 21.1290 - val_loss: 22.3556 - val_MinusLogProbMetric: 22.3556 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 5/1000
2023-09-27 20:46:36.329 
Epoch 5/1000 
	 loss: 20.8109, MinusLogProbMetric: 20.8109, val_loss: 20.3203, val_MinusLogProbMetric: 20.3203

Epoch 5: val_loss improved from 21.03292 to 20.32030, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_314/weights/best_weights.h5
196/196 - 32s - loss: 20.8109 - MinusLogProbMetric: 20.8109 - val_loss: 20.3203 - val_MinusLogProbMetric: 20.3203 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 6/1000
2023-09-27 20:47:08.848 
Epoch 6/1000 
	 loss: 20.1373, MinusLogProbMetric: 20.1373, val_loss: 20.3290, val_MinusLogProbMetric: 20.3290

Epoch 6: val_loss did not improve from 20.32030
196/196 - 32s - loss: 20.1373 - MinusLogProbMetric: 20.1373 - val_loss: 20.3290 - val_MinusLogProbMetric: 20.3290 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 7/1000
2023-09-27 20:47:40.938 
Epoch 7/1000 
	 loss: 19.9027, MinusLogProbMetric: 19.9027, val_loss: 19.0849, val_MinusLogProbMetric: 19.0849

Epoch 7: val_loss improved from 20.32030 to 19.08491, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_314/weights/best_weights.h5
196/196 - 33s - loss: 19.9027 - MinusLogProbMetric: 19.9027 - val_loss: 19.0849 - val_MinusLogProbMetric: 19.0849 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 8/1000
2023-09-27 20:48:13.359 
Epoch 8/1000 
	 loss: 19.6489, MinusLogProbMetric: 19.6489, val_loss: 19.8659, val_MinusLogProbMetric: 19.8659

Epoch 8: val_loss did not improve from 19.08491
196/196 - 32s - loss: 19.6489 - MinusLogProbMetric: 19.6489 - val_loss: 19.8659 - val_MinusLogProbMetric: 19.8659 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 9/1000
2023-09-27 20:48:45.255 
Epoch 9/1000 
	 loss: 19.4224, MinusLogProbMetric: 19.4224, val_loss: 20.0724, val_MinusLogProbMetric: 20.0724

Epoch 9: val_loss did not improve from 19.08491
196/196 - 32s - loss: 19.4224 - MinusLogProbMetric: 19.4224 - val_loss: 20.0724 - val_MinusLogProbMetric: 20.0724 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 10/1000
2023-09-27 20:49:17.269 
Epoch 10/1000 
	 loss: 19.1704, MinusLogProbMetric: 19.1704, val_loss: 19.3404, val_MinusLogProbMetric: 19.3404

Epoch 10: val_loss did not improve from 19.08491
196/196 - 32s - loss: 19.1704 - MinusLogProbMetric: 19.1704 - val_loss: 19.3404 - val_MinusLogProbMetric: 19.3404 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 11/1000
2023-09-27 20:49:48.935 
Epoch 11/1000 
	 loss: 18.9844, MinusLogProbMetric: 18.9844, val_loss: 19.3597, val_MinusLogProbMetric: 19.3597

Epoch 11: val_loss did not improve from 19.08491
196/196 - 32s - loss: 18.9844 - MinusLogProbMetric: 18.9844 - val_loss: 19.3597 - val_MinusLogProbMetric: 19.3597 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 12/1000
2023-09-27 20:50:20.630 
Epoch 12/1000 
	 loss: 18.7945, MinusLogProbMetric: 18.7945, val_loss: 18.8416, val_MinusLogProbMetric: 18.8416

Epoch 12: val_loss improved from 19.08491 to 18.84163, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_314/weights/best_weights.h5
196/196 - 32s - loss: 18.7945 - MinusLogProbMetric: 18.7945 - val_loss: 18.8416 - val_MinusLogProbMetric: 18.8416 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 13/1000
2023-09-27 20:50:52.997 
Epoch 13/1000 
	 loss: 18.8434, MinusLogProbMetric: 18.8434, val_loss: 18.5928, val_MinusLogProbMetric: 18.5928

Epoch 13: val_loss improved from 18.84163 to 18.59280, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_314/weights/best_weights.h5
196/196 - 32s - loss: 18.8434 - MinusLogProbMetric: 18.8434 - val_loss: 18.5928 - val_MinusLogProbMetric: 18.5928 - lr: 0.0010 - 32s/epoch - 166ms/step
Epoch 14/1000
2023-09-27 20:51:25.539 
Epoch 14/1000 
	 loss: 18.5665, MinusLogProbMetric: 18.5665, val_loss: 18.3059, val_MinusLogProbMetric: 18.3059

Epoch 14: val_loss improved from 18.59280 to 18.30594, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_314/weights/best_weights.h5
196/196 - 32s - loss: 18.5665 - MinusLogProbMetric: 18.5665 - val_loss: 18.3059 - val_MinusLogProbMetric: 18.3059 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 15/1000
2023-09-27 20:51:57.703 
Epoch 15/1000 
	 loss: 18.6142, MinusLogProbMetric: 18.6142, val_loss: 18.8409, val_MinusLogProbMetric: 18.8409

Epoch 15: val_loss did not improve from 18.30594
196/196 - 32s - loss: 18.6142 - MinusLogProbMetric: 18.6142 - val_loss: 18.8409 - val_MinusLogProbMetric: 18.8409 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 16/1000
2023-09-27 20:52:29.531 
Epoch 16/1000 
	 loss: 18.8632, MinusLogProbMetric: 18.8632, val_loss: 18.8366, val_MinusLogProbMetric: 18.8366

Epoch 16: val_loss did not improve from 18.30594
196/196 - 32s - loss: 18.8632 - MinusLogProbMetric: 18.8632 - val_loss: 18.8366 - val_MinusLogProbMetric: 18.8366 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 17/1000
2023-09-27 20:53:01.365 
Epoch 17/1000 
	 loss: 18.3098, MinusLogProbMetric: 18.3098, val_loss: 19.2847, val_MinusLogProbMetric: 19.2847

Epoch 17: val_loss did not improve from 18.30594
196/196 - 32s - loss: 18.3098 - MinusLogProbMetric: 18.3098 - val_loss: 19.2847 - val_MinusLogProbMetric: 19.2847 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 18/1000
2023-09-27 20:53:33.177 
Epoch 18/1000 
	 loss: 18.2875, MinusLogProbMetric: 18.2875, val_loss: 18.7915, val_MinusLogProbMetric: 18.7915

Epoch 18: val_loss did not improve from 18.30594
196/196 - 32s - loss: 18.2875 - MinusLogProbMetric: 18.2875 - val_loss: 18.7915 - val_MinusLogProbMetric: 18.7915 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 19/1000
2023-09-27 20:54:05.080 
Epoch 19/1000 
	 loss: 18.2182, MinusLogProbMetric: 18.2182, val_loss: 18.3550, val_MinusLogProbMetric: 18.3550

Epoch 19: val_loss did not improve from 18.30594
196/196 - 32s - loss: 18.2182 - MinusLogProbMetric: 18.2182 - val_loss: 18.3550 - val_MinusLogProbMetric: 18.3550 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 20/1000
2023-09-27 20:54:36.978 
Epoch 20/1000 
	 loss: 18.2752, MinusLogProbMetric: 18.2752, val_loss: 19.3669, val_MinusLogProbMetric: 19.3669

Epoch 20: val_loss did not improve from 18.30594
196/196 - 32s - loss: 18.2752 - MinusLogProbMetric: 18.2752 - val_loss: 19.3669 - val_MinusLogProbMetric: 19.3669 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 21/1000
2023-09-27 20:55:08.726 
Epoch 21/1000 
	 loss: 18.0931, MinusLogProbMetric: 18.0931, val_loss: 18.5529, val_MinusLogProbMetric: 18.5529

Epoch 21: val_loss did not improve from 18.30594
196/196 - 32s - loss: 18.0931 - MinusLogProbMetric: 18.0931 - val_loss: 18.5529 - val_MinusLogProbMetric: 18.5529 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 22/1000
2023-09-27 20:55:40.479 
Epoch 22/1000 
	 loss: 18.2000, MinusLogProbMetric: 18.2000, val_loss: 18.0593, val_MinusLogProbMetric: 18.0593

Epoch 22: val_loss improved from 18.30594 to 18.05931, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_314/weights/best_weights.h5
196/196 - 32s - loss: 18.2000 - MinusLogProbMetric: 18.2000 - val_loss: 18.0593 - val_MinusLogProbMetric: 18.0593 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 23/1000
2023-09-27 20:56:12.876 
Epoch 23/1000 
	 loss: 18.2740, MinusLogProbMetric: 18.2740, val_loss: 20.8954, val_MinusLogProbMetric: 20.8954

Epoch 23: val_loss did not improve from 18.05931
196/196 - 32s - loss: 18.2740 - MinusLogProbMetric: 18.2740 - val_loss: 20.8954 - val_MinusLogProbMetric: 20.8954 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 24/1000
2023-09-27 20:56:44.807 
Epoch 24/1000 
	 loss: 18.0014, MinusLogProbMetric: 18.0014, val_loss: 18.1018, val_MinusLogProbMetric: 18.1018

Epoch 24: val_loss did not improve from 18.05931
196/196 - 32s - loss: 18.0014 - MinusLogProbMetric: 18.0014 - val_loss: 18.1018 - val_MinusLogProbMetric: 18.1018 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 25/1000
2023-09-27 20:57:16.520 
Epoch 25/1000 
	 loss: 18.1159, MinusLogProbMetric: 18.1159, val_loss: 17.8220, val_MinusLogProbMetric: 17.8220

Epoch 25: val_loss improved from 18.05931 to 17.82204, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_314/weights/best_weights.h5
196/196 - 32s - loss: 18.1159 - MinusLogProbMetric: 18.1159 - val_loss: 17.8220 - val_MinusLogProbMetric: 17.8220 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 26/1000
2023-09-27 20:57:48.764 
Epoch 26/1000 
	 loss: 18.0306, MinusLogProbMetric: 18.0306, val_loss: 18.5121, val_MinusLogProbMetric: 18.5121

Epoch 26: val_loss did not improve from 17.82204
196/196 - 32s - loss: 18.0306 - MinusLogProbMetric: 18.0306 - val_loss: 18.5121 - val_MinusLogProbMetric: 18.5121 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 27/1000
2023-09-27 20:58:20.476 
Epoch 27/1000 
	 loss: 18.0121, MinusLogProbMetric: 18.0121, val_loss: 18.0101, val_MinusLogProbMetric: 18.0101

Epoch 27: val_loss did not improve from 17.82204
196/196 - 32s - loss: 18.0121 - MinusLogProbMetric: 18.0121 - val_loss: 18.0101 - val_MinusLogProbMetric: 18.0101 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 28/1000
2023-09-27 20:58:52.197 
Epoch 28/1000 
	 loss: 17.9200, MinusLogProbMetric: 17.9200, val_loss: 17.9937, val_MinusLogProbMetric: 17.9937

Epoch 28: val_loss did not improve from 17.82204
196/196 - 32s - loss: 17.9200 - MinusLogProbMetric: 17.9200 - val_loss: 17.9937 - val_MinusLogProbMetric: 17.9937 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 29/1000
2023-09-27 20:59:23.908 
Epoch 29/1000 
	 loss: 17.9995, MinusLogProbMetric: 17.9995, val_loss: 18.8633, val_MinusLogProbMetric: 18.8633

Epoch 29: val_loss did not improve from 17.82204
196/196 - 32s - loss: 17.9995 - MinusLogProbMetric: 17.9995 - val_loss: 18.8633 - val_MinusLogProbMetric: 18.8633 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 30/1000
2023-09-27 20:59:55.760 
Epoch 30/1000 
	 loss: 17.8399, MinusLogProbMetric: 17.8399, val_loss: 17.9408, val_MinusLogProbMetric: 17.9408

Epoch 30: val_loss did not improve from 17.82204
196/196 - 32s - loss: 17.8399 - MinusLogProbMetric: 17.8399 - val_loss: 17.9408 - val_MinusLogProbMetric: 17.9408 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 31/1000
2023-09-27 21:00:27.763 
Epoch 31/1000 
	 loss: 17.8424, MinusLogProbMetric: 17.8424, val_loss: 18.5639, val_MinusLogProbMetric: 18.5639

Epoch 31: val_loss did not improve from 17.82204
196/196 - 32s - loss: 17.8424 - MinusLogProbMetric: 17.8424 - val_loss: 18.5639 - val_MinusLogProbMetric: 18.5639 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 32/1000
2023-09-27 21:00:59.479 
Epoch 32/1000 
	 loss: 17.7099, MinusLogProbMetric: 17.7099, val_loss: 17.6677, val_MinusLogProbMetric: 17.6677

Epoch 32: val_loss improved from 17.82204 to 17.66766, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_314/weights/best_weights.h5
196/196 - 32s - loss: 17.7099 - MinusLogProbMetric: 17.7099 - val_loss: 17.6677 - val_MinusLogProbMetric: 17.6677 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 33/1000
2023-09-27 21:01:32.134 
Epoch 33/1000 
	 loss: 17.7137, MinusLogProbMetric: 17.7137, val_loss: 17.8133, val_MinusLogProbMetric: 17.8133

Epoch 33: val_loss did not improve from 17.66766
196/196 - 32s - loss: 17.7137 - MinusLogProbMetric: 17.7137 - val_loss: 17.8133 - val_MinusLogProbMetric: 17.8133 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 34/1000
2023-09-27 21:02:03.959 
Epoch 34/1000 
	 loss: 17.6511, MinusLogProbMetric: 17.6511, val_loss: 18.4741, val_MinusLogProbMetric: 18.4741

Epoch 34: val_loss did not improve from 17.66766
196/196 - 32s - loss: 17.6511 - MinusLogProbMetric: 17.6511 - val_loss: 18.4741 - val_MinusLogProbMetric: 18.4741 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 35/1000
2023-09-27 21:02:35.966 
Epoch 35/1000 
	 loss: 17.7371, MinusLogProbMetric: 17.7371, val_loss: 17.8568, val_MinusLogProbMetric: 17.8568

Epoch 35: val_loss did not improve from 17.66766
196/196 - 32s - loss: 17.7371 - MinusLogProbMetric: 17.7371 - val_loss: 17.8568 - val_MinusLogProbMetric: 17.8568 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 36/1000
2023-09-27 21:03:08.014 
Epoch 36/1000 
	 loss: 17.7093, MinusLogProbMetric: 17.7093, val_loss: 18.2442, val_MinusLogProbMetric: 18.2442

Epoch 36: val_loss did not improve from 17.66766
196/196 - 32s - loss: 17.7093 - MinusLogProbMetric: 17.7093 - val_loss: 18.2442 - val_MinusLogProbMetric: 18.2442 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 37/1000
2023-09-27 21:03:39.925 
Epoch 37/1000 
	 loss: 17.6054, MinusLogProbMetric: 17.6054, val_loss: 19.1162, val_MinusLogProbMetric: 19.1162

Epoch 37: val_loss did not improve from 17.66766
196/196 - 32s - loss: 17.6054 - MinusLogProbMetric: 17.6054 - val_loss: 19.1162 - val_MinusLogProbMetric: 19.1162 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 38/1000
2023-09-27 21:04:12.091 
Epoch 38/1000 
	 loss: 17.5567, MinusLogProbMetric: 17.5567, val_loss: 19.1032, val_MinusLogProbMetric: 19.1032

Epoch 38: val_loss did not improve from 17.66766
196/196 - 32s - loss: 17.5567 - MinusLogProbMetric: 17.5567 - val_loss: 19.1032 - val_MinusLogProbMetric: 19.1032 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 39/1000
2023-09-27 21:04:43.728 
Epoch 39/1000 
	 loss: 17.7887, MinusLogProbMetric: 17.7887, val_loss: 17.7098, val_MinusLogProbMetric: 17.7098

Epoch 39: val_loss did not improve from 17.66766
196/196 - 32s - loss: 17.7887 - MinusLogProbMetric: 17.7887 - val_loss: 17.7098 - val_MinusLogProbMetric: 17.7098 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 40/1000
2023-09-27 21:05:15.650 
Epoch 40/1000 
	 loss: 17.5277, MinusLogProbMetric: 17.5277, val_loss: 18.2193, val_MinusLogProbMetric: 18.2193

Epoch 40: val_loss did not improve from 17.66766
196/196 - 32s - loss: 17.5277 - MinusLogProbMetric: 17.5277 - val_loss: 18.2193 - val_MinusLogProbMetric: 18.2193 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 41/1000
2023-09-27 21:05:47.759 
Epoch 41/1000 
	 loss: 17.5139, MinusLogProbMetric: 17.5139, val_loss: 17.6381, val_MinusLogProbMetric: 17.6381

Epoch 41: val_loss improved from 17.66766 to 17.63811, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_314/weights/best_weights.h5
196/196 - 33s - loss: 17.5139 - MinusLogProbMetric: 17.5139 - val_loss: 17.6381 - val_MinusLogProbMetric: 17.6381 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 42/1000
2023-09-27 21:06:20.274 
Epoch 42/1000 
	 loss: 17.5269, MinusLogProbMetric: 17.5269, val_loss: 18.4520, val_MinusLogProbMetric: 18.4520

Epoch 42: val_loss did not improve from 17.63811
196/196 - 32s - loss: 17.5269 - MinusLogProbMetric: 17.5269 - val_loss: 18.4520 - val_MinusLogProbMetric: 18.4520 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 43/1000
2023-09-27 21:06:52.262 
Epoch 43/1000 
	 loss: 17.4626, MinusLogProbMetric: 17.4626, val_loss: 18.2153, val_MinusLogProbMetric: 18.2153

Epoch 43: val_loss did not improve from 17.63811
196/196 - 32s - loss: 17.4626 - MinusLogProbMetric: 17.4626 - val_loss: 18.2153 - val_MinusLogProbMetric: 18.2153 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 44/1000
2023-09-27 21:07:23.995 
Epoch 44/1000 
	 loss: 17.4429, MinusLogProbMetric: 17.4429, val_loss: 18.0013, val_MinusLogProbMetric: 18.0013

Epoch 44: val_loss did not improve from 17.63811
196/196 - 32s - loss: 17.4429 - MinusLogProbMetric: 17.4429 - val_loss: 18.0013 - val_MinusLogProbMetric: 18.0013 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 45/1000
2023-09-27 21:07:55.727 
Epoch 45/1000 
	 loss: 17.5654, MinusLogProbMetric: 17.5654, val_loss: 17.9408, val_MinusLogProbMetric: 17.9408

Epoch 45: val_loss did not improve from 17.63811
196/196 - 32s - loss: 17.5654 - MinusLogProbMetric: 17.5654 - val_loss: 17.9408 - val_MinusLogProbMetric: 17.9408 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 46/1000
2023-09-27 21:08:27.776 
Epoch 46/1000 
	 loss: 17.4058, MinusLogProbMetric: 17.4058, val_loss: 17.5841, val_MinusLogProbMetric: 17.5841

Epoch 46: val_loss improved from 17.63811 to 17.58408, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_314/weights/best_weights.h5
196/196 - 33s - loss: 17.4058 - MinusLogProbMetric: 17.4058 - val_loss: 17.5841 - val_MinusLogProbMetric: 17.5841 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 47/1000
2023-09-27 21:09:00.331 
Epoch 47/1000 
	 loss: 17.4033, MinusLogProbMetric: 17.4033, val_loss: 17.7986, val_MinusLogProbMetric: 17.7986

Epoch 47: val_loss did not improve from 17.58408
196/196 - 32s - loss: 17.4033 - MinusLogProbMetric: 17.4033 - val_loss: 17.7986 - val_MinusLogProbMetric: 17.7986 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 48/1000
2023-09-27 21:09:32.242 
Epoch 48/1000 
	 loss: 17.3797, MinusLogProbMetric: 17.3797, val_loss: 17.7110, val_MinusLogProbMetric: 17.7110

Epoch 48: val_loss did not improve from 17.58408
196/196 - 32s - loss: 17.3797 - MinusLogProbMetric: 17.3797 - val_loss: 17.7110 - val_MinusLogProbMetric: 17.7110 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 49/1000
2023-09-27 21:10:03.993 
Epoch 49/1000 
	 loss: 17.3581, MinusLogProbMetric: 17.3581, val_loss: 17.7720, val_MinusLogProbMetric: 17.7720

Epoch 49: val_loss did not improve from 17.58408
196/196 - 32s - loss: 17.3581 - MinusLogProbMetric: 17.3581 - val_loss: 17.7720 - val_MinusLogProbMetric: 17.7720 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 50/1000
2023-09-27 21:10:35.855 
Epoch 50/1000 
	 loss: 17.3619, MinusLogProbMetric: 17.3619, val_loss: 17.9010, val_MinusLogProbMetric: 17.9010

Epoch 50: val_loss did not improve from 17.58408
196/196 - 32s - loss: 17.3619 - MinusLogProbMetric: 17.3619 - val_loss: 17.9010 - val_MinusLogProbMetric: 17.9010 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 51/1000
2023-09-27 21:11:07.900 
Epoch 51/1000 
	 loss: 17.4446, MinusLogProbMetric: 17.4446, val_loss: 19.0905, val_MinusLogProbMetric: 19.0905

Epoch 51: val_loss did not improve from 17.58408
196/196 - 32s - loss: 17.4446 - MinusLogProbMetric: 17.4446 - val_loss: 19.0905 - val_MinusLogProbMetric: 19.0905 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 52/1000
2023-09-27 21:11:39.754 
Epoch 52/1000 
	 loss: 17.3426, MinusLogProbMetric: 17.3426, val_loss: 17.5586, val_MinusLogProbMetric: 17.5586

Epoch 52: val_loss improved from 17.58408 to 17.55857, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_314/weights/best_weights.h5
196/196 - 32s - loss: 17.3426 - MinusLogProbMetric: 17.3426 - val_loss: 17.5586 - val_MinusLogProbMetric: 17.5586 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 53/1000
2023-09-27 21:12:12.243 
Epoch 53/1000 
	 loss: 17.3147, MinusLogProbMetric: 17.3147, val_loss: 18.8741, val_MinusLogProbMetric: 18.8741

Epoch 53: val_loss did not improve from 17.55857
196/196 - 32s - loss: 17.3147 - MinusLogProbMetric: 17.3147 - val_loss: 18.8741 - val_MinusLogProbMetric: 18.8741 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 54/1000
2023-09-27 21:12:43.960 
Epoch 54/1000 
	 loss: 17.2923, MinusLogProbMetric: 17.2923, val_loss: 17.9768, val_MinusLogProbMetric: 17.9768

Epoch 54: val_loss did not improve from 17.55857
196/196 - 32s - loss: 17.2923 - MinusLogProbMetric: 17.2923 - val_loss: 17.9768 - val_MinusLogProbMetric: 17.9768 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 55/1000
2023-09-27 21:13:15.701 
Epoch 55/1000 
	 loss: 17.2782, MinusLogProbMetric: 17.2782, val_loss: 17.5901, val_MinusLogProbMetric: 17.5901

Epoch 55: val_loss did not improve from 17.55857
196/196 - 32s - loss: 17.2782 - MinusLogProbMetric: 17.2782 - val_loss: 17.5901 - val_MinusLogProbMetric: 17.5901 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 56/1000
2023-09-27 21:13:47.421 
Epoch 56/1000 
	 loss: 17.2160, MinusLogProbMetric: 17.2160, val_loss: 17.5300, val_MinusLogProbMetric: 17.5300

Epoch 56: val_loss improved from 17.55857 to 17.53004, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_314/weights/best_weights.h5
196/196 - 32s - loss: 17.2160 - MinusLogProbMetric: 17.2160 - val_loss: 17.5300 - val_MinusLogProbMetric: 17.5300 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 57/1000
2023-09-27 21:14:20.015 
Epoch 57/1000 
	 loss: 17.2643, MinusLogProbMetric: 17.2643, val_loss: 17.7311, val_MinusLogProbMetric: 17.7311

Epoch 57: val_loss did not improve from 17.53004
196/196 - 32s - loss: 17.2643 - MinusLogProbMetric: 17.2643 - val_loss: 17.7311 - val_MinusLogProbMetric: 17.7311 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 58/1000
2023-09-27 21:14:51.877 
Epoch 58/1000 
	 loss: 17.2149, MinusLogProbMetric: 17.2149, val_loss: 17.5400, val_MinusLogProbMetric: 17.5400

Epoch 58: val_loss did not improve from 17.53004
196/196 - 32s - loss: 17.2149 - MinusLogProbMetric: 17.2149 - val_loss: 17.5400 - val_MinusLogProbMetric: 17.5400 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 59/1000
2023-09-27 21:15:23.590 
Epoch 59/1000 
	 loss: 17.2198, MinusLogProbMetric: 17.2198, val_loss: 17.4917, val_MinusLogProbMetric: 17.4917

Epoch 59: val_loss improved from 17.53004 to 17.49169, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_314/weights/best_weights.h5
196/196 - 32s - loss: 17.2198 - MinusLogProbMetric: 17.2198 - val_loss: 17.4917 - val_MinusLogProbMetric: 17.4917 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 60/1000
2023-09-27 21:15:55.934 
Epoch 60/1000 
	 loss: 17.2137, MinusLogProbMetric: 17.2137, val_loss: 17.7208, val_MinusLogProbMetric: 17.7208

Epoch 60: val_loss did not improve from 17.49169
196/196 - 32s - loss: 17.2137 - MinusLogProbMetric: 17.2137 - val_loss: 17.7208 - val_MinusLogProbMetric: 17.7208 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 61/1000
2023-09-27 21:16:27.779 
Epoch 61/1000 
	 loss: 17.1801, MinusLogProbMetric: 17.1801, val_loss: 18.2408, val_MinusLogProbMetric: 18.2408

Epoch 61: val_loss did not improve from 17.49169
196/196 - 32s - loss: 17.1801 - MinusLogProbMetric: 17.1801 - val_loss: 18.2408 - val_MinusLogProbMetric: 18.2408 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 62/1000
2023-09-27 21:16:59.713 
Epoch 62/1000 
	 loss: 17.1640, MinusLogProbMetric: 17.1640, val_loss: 17.8513, val_MinusLogProbMetric: 17.8513

Epoch 62: val_loss did not improve from 17.49169
196/196 - 32s - loss: 17.1640 - MinusLogProbMetric: 17.1640 - val_loss: 17.8513 - val_MinusLogProbMetric: 17.8513 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 63/1000
2023-09-27 21:17:31.710 
Epoch 63/1000 
	 loss: 17.1398, MinusLogProbMetric: 17.1398, val_loss: 17.6127, val_MinusLogProbMetric: 17.6127

Epoch 63: val_loss did not improve from 17.49169
196/196 - 32s - loss: 17.1398 - MinusLogProbMetric: 17.1398 - val_loss: 17.6127 - val_MinusLogProbMetric: 17.6127 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 64/1000
2023-09-27 21:18:03.419 
Epoch 64/1000 
	 loss: 17.1623, MinusLogProbMetric: 17.1623, val_loss: 17.8087, val_MinusLogProbMetric: 17.8087

Epoch 64: val_loss did not improve from 17.49169
196/196 - 32s - loss: 17.1623 - MinusLogProbMetric: 17.1623 - val_loss: 17.8087 - val_MinusLogProbMetric: 17.8087 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 65/1000
2023-09-27 21:18:35.371 
Epoch 65/1000 
	 loss: 17.1290, MinusLogProbMetric: 17.1290, val_loss: 17.6944, val_MinusLogProbMetric: 17.6944

Epoch 65: val_loss did not improve from 17.49169
196/196 - 32s - loss: 17.1290 - MinusLogProbMetric: 17.1290 - val_loss: 17.6944 - val_MinusLogProbMetric: 17.6944 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 66/1000
2023-09-27 21:19:07.240 
Epoch 66/1000 
	 loss: 17.1330, MinusLogProbMetric: 17.1330, val_loss: 17.9786, val_MinusLogProbMetric: 17.9786

Epoch 66: val_loss did not improve from 17.49169
196/196 - 32s - loss: 17.1330 - MinusLogProbMetric: 17.1330 - val_loss: 17.9786 - val_MinusLogProbMetric: 17.9786 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 67/1000
2023-09-27 21:19:39.036 
Epoch 67/1000 
	 loss: 17.1272, MinusLogProbMetric: 17.1272, val_loss: 17.8810, val_MinusLogProbMetric: 17.8810

Epoch 67: val_loss did not improve from 17.49169
196/196 - 32s - loss: 17.1272 - MinusLogProbMetric: 17.1272 - val_loss: 17.8810 - val_MinusLogProbMetric: 17.8810 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 68/1000
2023-09-27 21:20:10.916 
Epoch 68/1000 
	 loss: 17.1009, MinusLogProbMetric: 17.1009, val_loss: 17.6168, val_MinusLogProbMetric: 17.6168

Epoch 68: val_loss did not improve from 17.49169
196/196 - 32s - loss: 17.1009 - MinusLogProbMetric: 17.1009 - val_loss: 17.6168 - val_MinusLogProbMetric: 17.6168 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 69/1000
2023-09-27 21:20:42.862 
Epoch 69/1000 
	 loss: 17.1648, MinusLogProbMetric: 17.1648, val_loss: 18.2242, val_MinusLogProbMetric: 18.2242

Epoch 69: val_loss did not improve from 17.49169
196/196 - 32s - loss: 17.1648 - MinusLogProbMetric: 17.1648 - val_loss: 18.2242 - val_MinusLogProbMetric: 18.2242 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 70/1000
2023-09-27 21:21:15.053 
Epoch 70/1000 
	 loss: 17.0736, MinusLogProbMetric: 17.0736, val_loss: 17.6493, val_MinusLogProbMetric: 17.6493

Epoch 70: val_loss did not improve from 17.49169
196/196 - 32s - loss: 17.0736 - MinusLogProbMetric: 17.0736 - val_loss: 17.6493 - val_MinusLogProbMetric: 17.6493 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 71/1000
2023-09-27 21:21:47.204 
Epoch 71/1000 
	 loss: 17.0380, MinusLogProbMetric: 17.0380, val_loss: 17.6005, val_MinusLogProbMetric: 17.6005

Epoch 71: val_loss did not improve from 17.49169
196/196 - 32s - loss: 17.0380 - MinusLogProbMetric: 17.0380 - val_loss: 17.6005 - val_MinusLogProbMetric: 17.6005 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 72/1000
2023-09-27 21:22:18.993 
Epoch 72/1000 
	 loss: 17.0310, MinusLogProbMetric: 17.0310, val_loss: 17.9095, val_MinusLogProbMetric: 17.9095

Epoch 72: val_loss did not improve from 17.49169
196/196 - 32s - loss: 17.0310 - MinusLogProbMetric: 17.0310 - val_loss: 17.9095 - val_MinusLogProbMetric: 17.9095 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 73/1000
2023-09-27 21:22:50.787 
Epoch 73/1000 
	 loss: 17.0487, MinusLogProbMetric: 17.0487, val_loss: 17.5342, val_MinusLogProbMetric: 17.5342

Epoch 73: val_loss did not improve from 17.49169
196/196 - 32s - loss: 17.0487 - MinusLogProbMetric: 17.0487 - val_loss: 17.5342 - val_MinusLogProbMetric: 17.5342 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 74/1000
2023-09-27 21:23:22.683 
Epoch 74/1000 
	 loss: 17.0590, MinusLogProbMetric: 17.0590, val_loss: 17.5453, val_MinusLogProbMetric: 17.5453

Epoch 74: val_loss did not improve from 17.49169
196/196 - 32s - loss: 17.0590 - MinusLogProbMetric: 17.0590 - val_loss: 17.5453 - val_MinusLogProbMetric: 17.5453 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 75/1000
2023-09-27 21:23:54.219 
Epoch 75/1000 
	 loss: 17.0051, MinusLogProbMetric: 17.0051, val_loss: 17.5774, val_MinusLogProbMetric: 17.5774

Epoch 75: val_loss did not improve from 17.49169
196/196 - 32s - loss: 17.0051 - MinusLogProbMetric: 17.0051 - val_loss: 17.5774 - val_MinusLogProbMetric: 17.5774 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 76/1000
2023-09-27 21:24:26.278 
Epoch 76/1000 
	 loss: 17.0018, MinusLogProbMetric: 17.0018, val_loss: 17.6170, val_MinusLogProbMetric: 17.6170

Epoch 76: val_loss did not improve from 17.49169
196/196 - 32s - loss: 17.0018 - MinusLogProbMetric: 17.0018 - val_loss: 17.6170 - val_MinusLogProbMetric: 17.6170 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 77/1000
2023-09-27 21:24:58.064 
Epoch 77/1000 
	 loss: 17.0041, MinusLogProbMetric: 17.0041, val_loss: 17.6978, val_MinusLogProbMetric: 17.6978

Epoch 77: val_loss did not improve from 17.49169
196/196 - 32s - loss: 17.0041 - MinusLogProbMetric: 17.0041 - val_loss: 17.6978 - val_MinusLogProbMetric: 17.6978 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 78/1000
2023-09-27 21:25:30.056 
Epoch 78/1000 
	 loss: 16.9414, MinusLogProbMetric: 16.9414, val_loss: 18.0253, val_MinusLogProbMetric: 18.0253

Epoch 78: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.9414 - MinusLogProbMetric: 16.9414 - val_loss: 18.0253 - val_MinusLogProbMetric: 18.0253 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 79/1000
2023-09-27 21:26:01.947 
Epoch 79/1000 
	 loss: 16.9514, MinusLogProbMetric: 16.9514, val_loss: 17.5966, val_MinusLogProbMetric: 17.5966

Epoch 79: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.9514 - MinusLogProbMetric: 16.9514 - val_loss: 17.5966 - val_MinusLogProbMetric: 17.5966 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 80/1000
2023-09-27 21:26:33.817 
Epoch 80/1000 
	 loss: 16.9228, MinusLogProbMetric: 16.9228, val_loss: 17.6943, val_MinusLogProbMetric: 17.6943

Epoch 80: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.9228 - MinusLogProbMetric: 16.9228 - val_loss: 17.6943 - val_MinusLogProbMetric: 17.6943 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 81/1000
2023-09-27 21:27:05.958 
Epoch 81/1000 
	 loss: 16.9498, MinusLogProbMetric: 16.9498, val_loss: 17.7633, val_MinusLogProbMetric: 17.7633

Epoch 81: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.9498 - MinusLogProbMetric: 16.9498 - val_loss: 17.7633 - val_MinusLogProbMetric: 17.7633 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 82/1000
2023-09-27 21:27:37.960 
Epoch 82/1000 
	 loss: 16.9394, MinusLogProbMetric: 16.9394, val_loss: 17.9283, val_MinusLogProbMetric: 17.9283

Epoch 82: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.9394 - MinusLogProbMetric: 16.9394 - val_loss: 17.9283 - val_MinusLogProbMetric: 17.9283 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 83/1000
2023-09-27 21:28:09.958 
Epoch 83/1000 
	 loss: 16.9177, MinusLogProbMetric: 16.9177, val_loss: 18.3234, val_MinusLogProbMetric: 18.3234

Epoch 83: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.9177 - MinusLogProbMetric: 16.9177 - val_loss: 18.3234 - val_MinusLogProbMetric: 18.3234 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 84/1000
2023-09-27 21:28:41.742 
Epoch 84/1000 
	 loss: 16.9374, MinusLogProbMetric: 16.9374, val_loss: 17.6532, val_MinusLogProbMetric: 17.6532

Epoch 84: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.9374 - MinusLogProbMetric: 16.9374 - val_loss: 17.6532 - val_MinusLogProbMetric: 17.6532 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 85/1000
2023-09-27 21:29:13.575 
Epoch 85/1000 
	 loss: 16.8750, MinusLogProbMetric: 16.8750, val_loss: 17.6482, val_MinusLogProbMetric: 17.6482

Epoch 85: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.8750 - MinusLogProbMetric: 16.8750 - val_loss: 17.6482 - val_MinusLogProbMetric: 17.6482 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 86/1000
2023-09-27 21:29:45.145 
Epoch 86/1000 
	 loss: 16.8965, MinusLogProbMetric: 16.8965, val_loss: 18.0607, val_MinusLogProbMetric: 18.0607

Epoch 86: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.8965 - MinusLogProbMetric: 16.8965 - val_loss: 18.0607 - val_MinusLogProbMetric: 18.0607 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 87/1000
2023-09-27 21:30:17.194 
Epoch 87/1000 
	 loss: 16.8239, MinusLogProbMetric: 16.8239, val_loss: 17.5143, val_MinusLogProbMetric: 17.5143

Epoch 87: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.8239 - MinusLogProbMetric: 16.8239 - val_loss: 17.5143 - val_MinusLogProbMetric: 17.5143 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 88/1000
2023-09-27 21:30:49.163 
Epoch 88/1000 
	 loss: 16.8781, MinusLogProbMetric: 16.8781, val_loss: 17.6418, val_MinusLogProbMetric: 17.6418

Epoch 88: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.8781 - MinusLogProbMetric: 16.8781 - val_loss: 17.6418 - val_MinusLogProbMetric: 17.6418 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 89/1000
2023-09-27 21:31:20.981 
Epoch 89/1000 
	 loss: 16.8040, MinusLogProbMetric: 16.8040, val_loss: 18.1567, val_MinusLogProbMetric: 18.1567

Epoch 89: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.8040 - MinusLogProbMetric: 16.8040 - val_loss: 18.1567 - val_MinusLogProbMetric: 18.1567 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 90/1000
2023-09-27 21:31:52.611 
Epoch 90/1000 
	 loss: 16.7745, MinusLogProbMetric: 16.7745, val_loss: 17.5168, val_MinusLogProbMetric: 17.5168

Epoch 90: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.7745 - MinusLogProbMetric: 16.7745 - val_loss: 17.5168 - val_MinusLogProbMetric: 17.5168 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 91/1000
2023-09-27 21:32:24.427 
Epoch 91/1000 
	 loss: 16.9211, MinusLogProbMetric: 16.9211, val_loss: 17.8180, val_MinusLogProbMetric: 17.8180

Epoch 91: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.9211 - MinusLogProbMetric: 16.9211 - val_loss: 17.8180 - val_MinusLogProbMetric: 17.8180 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 92/1000
2023-09-27 21:32:56.433 
Epoch 92/1000 
	 loss: 16.8429, MinusLogProbMetric: 16.8429, val_loss: 17.5747, val_MinusLogProbMetric: 17.5747

Epoch 92: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.8429 - MinusLogProbMetric: 16.8429 - val_loss: 17.5747 - val_MinusLogProbMetric: 17.5747 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 93/1000
2023-09-27 21:33:28.203 
Epoch 93/1000 
	 loss: 16.8167, MinusLogProbMetric: 16.8167, val_loss: 17.9400, val_MinusLogProbMetric: 17.9400

Epoch 93: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.8167 - MinusLogProbMetric: 16.8167 - val_loss: 17.9400 - val_MinusLogProbMetric: 17.9400 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 94/1000
2023-09-27 21:34:00.052 
Epoch 94/1000 
	 loss: 16.8474, MinusLogProbMetric: 16.8474, val_loss: 17.6954, val_MinusLogProbMetric: 17.6954

Epoch 94: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.8474 - MinusLogProbMetric: 16.8474 - val_loss: 17.6954 - val_MinusLogProbMetric: 17.6954 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 95/1000
2023-09-27 21:34:31.919 
Epoch 95/1000 
	 loss: 16.7858, MinusLogProbMetric: 16.7858, val_loss: 17.9216, val_MinusLogProbMetric: 17.9216

Epoch 95: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.7858 - MinusLogProbMetric: 16.7858 - val_loss: 17.9216 - val_MinusLogProbMetric: 17.9216 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 96/1000
2023-09-27 21:35:04.045 
Epoch 96/1000 
	 loss: 16.7794, MinusLogProbMetric: 16.7794, val_loss: 18.0424, val_MinusLogProbMetric: 18.0424

Epoch 96: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.7794 - MinusLogProbMetric: 16.7794 - val_loss: 18.0424 - val_MinusLogProbMetric: 18.0424 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 97/1000
2023-09-27 21:35:35.876 
Epoch 97/1000 
	 loss: 16.7405, MinusLogProbMetric: 16.7405, val_loss: 17.5683, val_MinusLogProbMetric: 17.5683

Epoch 97: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.7405 - MinusLogProbMetric: 16.7405 - val_loss: 17.5683 - val_MinusLogProbMetric: 17.5683 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 98/1000
2023-09-27 21:36:07.806 
Epoch 98/1000 
	 loss: 16.7266, MinusLogProbMetric: 16.7266, val_loss: 17.5615, val_MinusLogProbMetric: 17.5615

Epoch 98: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.7266 - MinusLogProbMetric: 16.7266 - val_loss: 17.5615 - val_MinusLogProbMetric: 17.5615 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 99/1000
2023-09-27 21:36:39.594 
Epoch 99/1000 
	 loss: 16.7443, MinusLogProbMetric: 16.7443, val_loss: 18.1558, val_MinusLogProbMetric: 18.1558

Epoch 99: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.7443 - MinusLogProbMetric: 16.7443 - val_loss: 18.1558 - val_MinusLogProbMetric: 18.1558 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 100/1000
2023-09-27 21:37:11.265 
Epoch 100/1000 
	 loss: 16.9048, MinusLogProbMetric: 16.9048, val_loss: 17.6936, val_MinusLogProbMetric: 17.6936

Epoch 100: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.9048 - MinusLogProbMetric: 16.9048 - val_loss: 17.6936 - val_MinusLogProbMetric: 17.6936 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 101/1000
2023-09-27 21:37:43.447 
Epoch 101/1000 
	 loss: 16.6730, MinusLogProbMetric: 16.6730, val_loss: 17.5858, val_MinusLogProbMetric: 17.5858

Epoch 101: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.6730 - MinusLogProbMetric: 16.6730 - val_loss: 17.5858 - val_MinusLogProbMetric: 17.5858 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 102/1000
2023-09-27 21:38:15.356 
Epoch 102/1000 
	 loss: 16.7037, MinusLogProbMetric: 16.7037, val_loss: 17.6588, val_MinusLogProbMetric: 17.6588

Epoch 102: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.7037 - MinusLogProbMetric: 16.7037 - val_loss: 17.6588 - val_MinusLogProbMetric: 17.6588 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 103/1000
2023-09-27 21:38:47.378 
Epoch 103/1000 
	 loss: 16.6929, MinusLogProbMetric: 16.6929, val_loss: 18.0407, val_MinusLogProbMetric: 18.0407

Epoch 103: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.6929 - MinusLogProbMetric: 16.6929 - val_loss: 18.0407 - val_MinusLogProbMetric: 18.0407 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 104/1000
2023-09-27 21:39:19.313 
Epoch 104/1000 
	 loss: 16.7406, MinusLogProbMetric: 16.7406, val_loss: 17.8652, val_MinusLogProbMetric: 17.8652

Epoch 104: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.7406 - MinusLogProbMetric: 16.7406 - val_loss: 17.8652 - val_MinusLogProbMetric: 17.8652 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 105/1000
2023-09-27 21:39:51.230 
Epoch 105/1000 
	 loss: 16.6470, MinusLogProbMetric: 16.6470, val_loss: 17.6201, val_MinusLogProbMetric: 17.6201

Epoch 105: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.6470 - MinusLogProbMetric: 16.6470 - val_loss: 17.6201 - val_MinusLogProbMetric: 17.6201 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 106/1000
2023-09-27 21:40:23.129 
Epoch 106/1000 
	 loss: 16.6545, MinusLogProbMetric: 16.6545, val_loss: 17.8673, val_MinusLogProbMetric: 17.8673

Epoch 106: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.6545 - MinusLogProbMetric: 16.6545 - val_loss: 17.8673 - val_MinusLogProbMetric: 17.8673 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 107/1000
2023-09-27 21:40:55.282 
Epoch 107/1000 
	 loss: 16.6139, MinusLogProbMetric: 16.6139, val_loss: 18.8352, val_MinusLogProbMetric: 18.8352

Epoch 107: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.6139 - MinusLogProbMetric: 16.6139 - val_loss: 18.8352 - val_MinusLogProbMetric: 18.8352 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 108/1000
2023-09-27 21:41:27.149 
Epoch 108/1000 
	 loss: 16.6394, MinusLogProbMetric: 16.6394, val_loss: 17.7038, val_MinusLogProbMetric: 17.7038

Epoch 108: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.6394 - MinusLogProbMetric: 16.6394 - val_loss: 17.7038 - val_MinusLogProbMetric: 17.7038 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 109/1000
2023-09-27 21:41:58.969 
Epoch 109/1000 
	 loss: 16.6207, MinusLogProbMetric: 16.6207, val_loss: 17.7525, val_MinusLogProbMetric: 17.7525

Epoch 109: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.6207 - MinusLogProbMetric: 16.6207 - val_loss: 17.7525 - val_MinusLogProbMetric: 17.7525 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 110/1000
2023-09-27 21:42:30.747 
Epoch 110/1000 
	 loss: 16.2688, MinusLogProbMetric: 16.2688, val_loss: 17.6362, val_MinusLogProbMetric: 17.6362

Epoch 110: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.2688 - MinusLogProbMetric: 16.2688 - val_loss: 17.6362 - val_MinusLogProbMetric: 17.6362 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 111/1000
2023-09-27 21:43:02.872 
Epoch 111/1000 
	 loss: 16.2311, MinusLogProbMetric: 16.2311, val_loss: 17.5840, val_MinusLogProbMetric: 17.5840

Epoch 111: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.2311 - MinusLogProbMetric: 16.2311 - val_loss: 17.5840 - val_MinusLogProbMetric: 17.5840 - lr: 5.0000e-04 - 32s/epoch - 164ms/step
Epoch 112/1000
2023-09-27 21:43:34.536 
Epoch 112/1000 
	 loss: 16.2530, MinusLogProbMetric: 16.2530, val_loss: 17.4976, val_MinusLogProbMetric: 17.4976

Epoch 112: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.2530 - MinusLogProbMetric: 16.2530 - val_loss: 17.4976 - val_MinusLogProbMetric: 17.4976 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 113/1000
2023-09-27 21:44:06.529 
Epoch 113/1000 
	 loss: 16.1933, MinusLogProbMetric: 16.1933, val_loss: 17.5002, val_MinusLogProbMetric: 17.5002

Epoch 113: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.1933 - MinusLogProbMetric: 16.1933 - val_loss: 17.5002 - val_MinusLogProbMetric: 17.5002 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 114/1000
2023-09-27 21:44:38.384 
Epoch 114/1000 
	 loss: 16.2473, MinusLogProbMetric: 16.2473, val_loss: 17.6154, val_MinusLogProbMetric: 17.6154

Epoch 114: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.2473 - MinusLogProbMetric: 16.2473 - val_loss: 17.6154 - val_MinusLogProbMetric: 17.6154 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 115/1000
2023-09-27 21:45:10.082 
Epoch 115/1000 
	 loss: 16.1549, MinusLogProbMetric: 16.1549, val_loss: 18.3407, val_MinusLogProbMetric: 18.3407

Epoch 115: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.1549 - MinusLogProbMetric: 16.1549 - val_loss: 18.3407 - val_MinusLogProbMetric: 18.3407 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 116/1000
2023-09-27 21:45:41.866 
Epoch 116/1000 
	 loss: 16.2366, MinusLogProbMetric: 16.2366, val_loss: 18.1720, val_MinusLogProbMetric: 18.1720

Epoch 116: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.2366 - MinusLogProbMetric: 16.2366 - val_loss: 18.1720 - val_MinusLogProbMetric: 18.1720 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 117/1000
2023-09-27 21:46:13.895 
Epoch 117/1000 
	 loss: 16.2493, MinusLogProbMetric: 16.2493, val_loss: 17.5116, val_MinusLogProbMetric: 17.5116

Epoch 117: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.2493 - MinusLogProbMetric: 16.2493 - val_loss: 17.5116 - val_MinusLogProbMetric: 17.5116 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 118/1000
2023-09-27 21:46:45.817 
Epoch 118/1000 
	 loss: 16.2037, MinusLogProbMetric: 16.2037, val_loss: 17.5424, val_MinusLogProbMetric: 17.5424

Epoch 118: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.2037 - MinusLogProbMetric: 16.2037 - val_loss: 17.5424 - val_MinusLogProbMetric: 17.5424 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 119/1000
2023-09-27 21:47:17.676 
Epoch 119/1000 
	 loss: 16.1586, MinusLogProbMetric: 16.1586, val_loss: 17.5397, val_MinusLogProbMetric: 17.5397

Epoch 119: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.1586 - MinusLogProbMetric: 16.1586 - val_loss: 17.5397 - val_MinusLogProbMetric: 17.5397 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 120/1000
2023-09-27 21:47:49.203 
Epoch 120/1000 
	 loss: 16.1828, MinusLogProbMetric: 16.1828, val_loss: 17.6179, val_MinusLogProbMetric: 17.6179

Epoch 120: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.1828 - MinusLogProbMetric: 16.1828 - val_loss: 17.6179 - val_MinusLogProbMetric: 17.6179 - lr: 5.0000e-04 - 32s/epoch - 161ms/step
Epoch 121/1000
2023-09-27 21:48:20.908 
Epoch 121/1000 
	 loss: 16.1422, MinusLogProbMetric: 16.1422, val_loss: 18.3306, val_MinusLogProbMetric: 18.3306

Epoch 121: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.1422 - MinusLogProbMetric: 16.1422 - val_loss: 18.3306 - val_MinusLogProbMetric: 18.3306 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 122/1000
2023-09-27 21:48:52.822 
Epoch 122/1000 
	 loss: 16.1732, MinusLogProbMetric: 16.1732, val_loss: 17.6424, val_MinusLogProbMetric: 17.6424

Epoch 122: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.1732 - MinusLogProbMetric: 16.1732 - val_loss: 17.6424 - val_MinusLogProbMetric: 17.6424 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 123/1000
2023-09-27 21:49:24.603 
Epoch 123/1000 
	 loss: 16.1677, MinusLogProbMetric: 16.1677, val_loss: 17.5580, val_MinusLogProbMetric: 17.5580

Epoch 123: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.1677 - MinusLogProbMetric: 16.1677 - val_loss: 17.5580 - val_MinusLogProbMetric: 17.5580 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 124/1000
2023-09-27 21:49:56.453 
Epoch 124/1000 
	 loss: 16.1270, MinusLogProbMetric: 16.1270, val_loss: 17.6823, val_MinusLogProbMetric: 17.6823

Epoch 124: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.1270 - MinusLogProbMetric: 16.1270 - val_loss: 17.6823 - val_MinusLogProbMetric: 17.6823 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 125/1000
2023-09-27 21:50:28.251 
Epoch 125/1000 
	 loss: 16.1944, MinusLogProbMetric: 16.1944, val_loss: 17.5990, val_MinusLogProbMetric: 17.5990

Epoch 125: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.1944 - MinusLogProbMetric: 16.1944 - val_loss: 17.5990 - val_MinusLogProbMetric: 17.5990 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 126/1000
2023-09-27 21:51:00.131 
Epoch 126/1000 
	 loss: 16.1310, MinusLogProbMetric: 16.1310, val_loss: 17.5162, val_MinusLogProbMetric: 17.5162

Epoch 126: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.1310 - MinusLogProbMetric: 16.1310 - val_loss: 17.5162 - val_MinusLogProbMetric: 17.5162 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 127/1000
2023-09-27 21:51:31.834 
Epoch 127/1000 
	 loss: 16.1131, MinusLogProbMetric: 16.1131, val_loss: 17.5657, val_MinusLogProbMetric: 17.5657

Epoch 127: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.1131 - MinusLogProbMetric: 16.1131 - val_loss: 17.5657 - val_MinusLogProbMetric: 17.5657 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 128/1000
2023-09-27 21:52:03.668 
Epoch 128/1000 
	 loss: 16.1178, MinusLogProbMetric: 16.1178, val_loss: 18.0381, val_MinusLogProbMetric: 18.0381

Epoch 128: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.1178 - MinusLogProbMetric: 16.1178 - val_loss: 18.0381 - val_MinusLogProbMetric: 18.0381 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 129/1000
2023-09-27 21:52:35.654 
Epoch 129/1000 
	 loss: 16.0933, MinusLogProbMetric: 16.0933, val_loss: 17.5742, val_MinusLogProbMetric: 17.5742

Epoch 129: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.0933 - MinusLogProbMetric: 16.0933 - val_loss: 17.5742 - val_MinusLogProbMetric: 17.5742 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 130/1000
2023-09-27 21:53:07.496 
Epoch 130/1000 
	 loss: 16.0789, MinusLogProbMetric: 16.0789, val_loss: 17.5469, val_MinusLogProbMetric: 17.5469

Epoch 130: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.0789 - MinusLogProbMetric: 16.0789 - val_loss: 17.5469 - val_MinusLogProbMetric: 17.5469 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 131/1000
2023-09-27 21:53:39.312 
Epoch 131/1000 
	 loss: 16.1004, MinusLogProbMetric: 16.1004, val_loss: 17.6719, val_MinusLogProbMetric: 17.6719

Epoch 131: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.1004 - MinusLogProbMetric: 16.1004 - val_loss: 17.6719 - val_MinusLogProbMetric: 17.6719 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 132/1000
2023-09-27 21:54:11.061 
Epoch 132/1000 
	 loss: 16.1215, MinusLogProbMetric: 16.1215, val_loss: 17.6124, val_MinusLogProbMetric: 17.6124

Epoch 132: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.1215 - MinusLogProbMetric: 16.1215 - val_loss: 17.6124 - val_MinusLogProbMetric: 17.6124 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 133/1000
2023-09-27 21:54:42.941 
Epoch 133/1000 
	 loss: 16.0770, MinusLogProbMetric: 16.0770, val_loss: 17.7196, val_MinusLogProbMetric: 17.7196

Epoch 133: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.0770 - MinusLogProbMetric: 16.0770 - val_loss: 17.7196 - val_MinusLogProbMetric: 17.7196 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 134/1000
2023-09-27 21:55:14.855 
Epoch 134/1000 
	 loss: 16.0646, MinusLogProbMetric: 16.0646, val_loss: 17.6182, val_MinusLogProbMetric: 17.6182

Epoch 134: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.0646 - MinusLogProbMetric: 16.0646 - val_loss: 17.6182 - val_MinusLogProbMetric: 17.6182 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 135/1000
2023-09-27 21:55:46.586 
Epoch 135/1000 
	 loss: 16.0649, MinusLogProbMetric: 16.0649, val_loss: 17.6459, val_MinusLogProbMetric: 17.6459

Epoch 135: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.0649 - MinusLogProbMetric: 16.0649 - val_loss: 17.6459 - val_MinusLogProbMetric: 17.6459 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 136/1000
2023-09-27 21:56:18.619 
Epoch 136/1000 
	 loss: 16.0610, MinusLogProbMetric: 16.0610, val_loss: 17.8621, val_MinusLogProbMetric: 17.8621

Epoch 136: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.0610 - MinusLogProbMetric: 16.0610 - val_loss: 17.8621 - val_MinusLogProbMetric: 17.8621 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 137/1000
2023-09-27 21:56:50.770 
Epoch 137/1000 
	 loss: 16.0448, MinusLogProbMetric: 16.0448, val_loss: 17.9344, val_MinusLogProbMetric: 17.9344

Epoch 137: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.0448 - MinusLogProbMetric: 16.0448 - val_loss: 17.9344 - val_MinusLogProbMetric: 17.9344 - lr: 5.0000e-04 - 32s/epoch - 164ms/step
Epoch 138/1000
2023-09-27 21:57:22.606 
Epoch 138/1000 
	 loss: 16.0793, MinusLogProbMetric: 16.0793, val_loss: 17.8451, val_MinusLogProbMetric: 17.8451

Epoch 138: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.0793 - MinusLogProbMetric: 16.0793 - val_loss: 17.8451 - val_MinusLogProbMetric: 17.8451 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 139/1000
2023-09-27 21:57:54.575 
Epoch 139/1000 
	 loss: 16.0765, MinusLogProbMetric: 16.0765, val_loss: 17.7286, val_MinusLogProbMetric: 17.7286

Epoch 139: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.0765 - MinusLogProbMetric: 16.0765 - val_loss: 17.7286 - val_MinusLogProbMetric: 17.7286 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 140/1000
2023-09-27 21:58:26.209 
Epoch 140/1000 
	 loss: 16.0900, MinusLogProbMetric: 16.0900, val_loss: 17.6573, val_MinusLogProbMetric: 17.6573

Epoch 140: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.0900 - MinusLogProbMetric: 16.0900 - val_loss: 17.6573 - val_MinusLogProbMetric: 17.6573 - lr: 5.0000e-04 - 32s/epoch - 161ms/step
Epoch 141/1000
2023-09-27 21:58:58.194 
Epoch 141/1000 
	 loss: 15.9929, MinusLogProbMetric: 15.9929, val_loss: 17.6921, val_MinusLogProbMetric: 17.6921

Epoch 141: val_loss did not improve from 17.49169
196/196 - 32s - loss: 15.9929 - MinusLogProbMetric: 15.9929 - val_loss: 17.6921 - val_MinusLogProbMetric: 17.6921 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 142/1000
2023-09-27 21:59:30.021 
Epoch 142/1000 
	 loss: 16.0232, MinusLogProbMetric: 16.0232, val_loss: 17.6617, val_MinusLogProbMetric: 17.6617

Epoch 142: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.0232 - MinusLogProbMetric: 16.0232 - val_loss: 17.6617 - val_MinusLogProbMetric: 17.6617 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 143/1000
2023-09-27 22:00:02.039 
Epoch 143/1000 
	 loss: 16.0268, MinusLogProbMetric: 16.0268, val_loss: 17.7295, val_MinusLogProbMetric: 17.7295

Epoch 143: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.0268 - MinusLogProbMetric: 16.0268 - val_loss: 17.7295 - val_MinusLogProbMetric: 17.7295 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 144/1000
2023-09-27 22:00:33.945 
Epoch 144/1000 
	 loss: 16.0090, MinusLogProbMetric: 16.0090, val_loss: 17.7092, val_MinusLogProbMetric: 17.7092

Epoch 144: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.0090 - MinusLogProbMetric: 16.0090 - val_loss: 17.7092 - val_MinusLogProbMetric: 17.7092 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 145/1000
2023-09-27 22:01:05.754 
Epoch 145/1000 
	 loss: 16.0317, MinusLogProbMetric: 16.0317, val_loss: 17.7408, val_MinusLogProbMetric: 17.7408

Epoch 145: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.0317 - MinusLogProbMetric: 16.0317 - val_loss: 17.7408 - val_MinusLogProbMetric: 17.7408 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 146/1000
2023-09-27 22:01:37.755 
Epoch 146/1000 
	 loss: 16.0262, MinusLogProbMetric: 16.0262, val_loss: 17.9719, val_MinusLogProbMetric: 17.9719

Epoch 146: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.0262 - MinusLogProbMetric: 16.0262 - val_loss: 17.9719 - val_MinusLogProbMetric: 17.9719 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 147/1000
2023-09-27 22:02:09.559 
Epoch 147/1000 
	 loss: 15.9963, MinusLogProbMetric: 15.9963, val_loss: 18.1025, val_MinusLogProbMetric: 18.1025

Epoch 147: val_loss did not improve from 17.49169
196/196 - 32s - loss: 15.9963 - MinusLogProbMetric: 15.9963 - val_loss: 18.1025 - val_MinusLogProbMetric: 18.1025 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 148/1000
2023-09-27 22:02:41.786 
Epoch 148/1000 
	 loss: 16.0249, MinusLogProbMetric: 16.0249, val_loss: 17.8352, val_MinusLogProbMetric: 17.8352

Epoch 148: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.0249 - MinusLogProbMetric: 16.0249 - val_loss: 17.8352 - val_MinusLogProbMetric: 17.8352 - lr: 5.0000e-04 - 32s/epoch - 164ms/step
Epoch 149/1000
2023-09-27 22:03:13.558 
Epoch 149/1000 
	 loss: 15.9903, MinusLogProbMetric: 15.9903, val_loss: 17.7717, val_MinusLogProbMetric: 17.7717

Epoch 149: val_loss did not improve from 17.49169
196/196 - 32s - loss: 15.9903 - MinusLogProbMetric: 15.9903 - val_loss: 17.7717 - val_MinusLogProbMetric: 17.7717 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 150/1000
2023-09-27 22:03:45.267 
Epoch 150/1000 
	 loss: 15.9887, MinusLogProbMetric: 15.9887, val_loss: 17.7626, val_MinusLogProbMetric: 17.7626

Epoch 150: val_loss did not improve from 17.49169
196/196 - 32s - loss: 15.9887 - MinusLogProbMetric: 15.9887 - val_loss: 17.7626 - val_MinusLogProbMetric: 17.7626 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 151/1000
2023-09-27 22:04:17.179 
Epoch 151/1000 
	 loss: 15.9885, MinusLogProbMetric: 15.9885, val_loss: 17.7468, val_MinusLogProbMetric: 17.7468

Epoch 151: val_loss did not improve from 17.49169
196/196 - 32s - loss: 15.9885 - MinusLogProbMetric: 15.9885 - val_loss: 17.7468 - val_MinusLogProbMetric: 17.7468 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 152/1000
2023-09-27 22:04:48.938 
Epoch 152/1000 
	 loss: 15.9973, MinusLogProbMetric: 15.9973, val_loss: 17.7242, val_MinusLogProbMetric: 17.7242

Epoch 152: val_loss did not improve from 17.49169
196/196 - 32s - loss: 15.9973 - MinusLogProbMetric: 15.9973 - val_loss: 17.7242 - val_MinusLogProbMetric: 17.7242 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 153/1000
2023-09-27 22:05:20.718 
Epoch 153/1000 
	 loss: 15.9542, MinusLogProbMetric: 15.9542, val_loss: 17.7698, val_MinusLogProbMetric: 17.7698

Epoch 153: val_loss did not improve from 17.49169
196/196 - 32s - loss: 15.9542 - MinusLogProbMetric: 15.9542 - val_loss: 17.7698 - val_MinusLogProbMetric: 17.7698 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 154/1000
2023-09-27 22:05:52.490 
Epoch 154/1000 
	 loss: 15.9433, MinusLogProbMetric: 15.9433, val_loss: 17.8888, val_MinusLogProbMetric: 17.8888

Epoch 154: val_loss did not improve from 17.49169
196/196 - 32s - loss: 15.9433 - MinusLogProbMetric: 15.9433 - val_loss: 17.8888 - val_MinusLogProbMetric: 17.8888 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 155/1000
2023-09-27 22:06:24.142 
Epoch 155/1000 
	 loss: 16.0020, MinusLogProbMetric: 16.0020, val_loss: 17.7538, val_MinusLogProbMetric: 17.7538

Epoch 155: val_loss did not improve from 17.49169
196/196 - 32s - loss: 16.0020 - MinusLogProbMetric: 16.0020 - val_loss: 17.7538 - val_MinusLogProbMetric: 17.7538 - lr: 5.0000e-04 - 32s/epoch - 161ms/step
Epoch 156/1000
2023-09-27 22:06:56.112 
Epoch 156/1000 
	 loss: 15.9803, MinusLogProbMetric: 15.9803, val_loss: 17.7979, val_MinusLogProbMetric: 17.7979

Epoch 156: val_loss did not improve from 17.49169
196/196 - 32s - loss: 15.9803 - MinusLogProbMetric: 15.9803 - val_loss: 17.7979 - val_MinusLogProbMetric: 17.7979 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 157/1000
2023-09-27 22:07:27.839 
Epoch 157/1000 
	 loss: 15.9103, MinusLogProbMetric: 15.9103, val_loss: 17.8455, val_MinusLogProbMetric: 17.8455

Epoch 157: val_loss did not improve from 17.49169
196/196 - 32s - loss: 15.9103 - MinusLogProbMetric: 15.9103 - val_loss: 17.8455 - val_MinusLogProbMetric: 17.8455 - lr: 5.0000e-04 - 32s/epoch - 162ms/step
Epoch 158/1000
2023-09-27 22:07:59.436 
Epoch 158/1000 
	 loss: 15.9829, MinusLogProbMetric: 15.9829, val_loss: 17.8127, val_MinusLogProbMetric: 17.8127

Epoch 158: val_loss did not improve from 17.49169
196/196 - 32s - loss: 15.9829 - MinusLogProbMetric: 15.9829 - val_loss: 17.8127 - val_MinusLogProbMetric: 17.8127 - lr: 5.0000e-04 - 32s/epoch - 161ms/step
Epoch 159/1000
2023-09-27 22:08:31.149 
Epoch 159/1000 
	 loss: 15.9268, MinusLogProbMetric: 15.9268, val_loss: 17.8940, val_MinusLogProbMetric: 17.8940

Epoch 159: val_loss did not improve from 17.49169
Restoring model weights from the end of the best epoch: 59.
196/196 - 32s - loss: 15.9268 - MinusLogProbMetric: 15.9268 - val_loss: 17.8940 - val_MinusLogProbMetric: 17.8940 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 159: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
WARNING:tensorflow:6 out of the last 6 calls to <function LRMetric.Test_tf.<locals>.compute_test at 0x7fda44b251b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
LR metric calculation completed in 12.390669999993406 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
WARNING:tensorflow:6 out of the last 6 calls to <function KSTest.Test_tf.<locals>.compute_test at 0x7fda44b25bd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
KS tests calculation completed in 7.464720015996136 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
WARNING:tensorflow:6 out of the last 6 calls to <function SWDMetric.Test_tf.<locals>.compute_test at 0x7fda44b260e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
SWD metric calculation completed in 4.924370839027688 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
WARNING:tensorflow:6 out of the last 6 calls to <function FNMetric.Test_tf.<locals>.compute_test at 0x7fda44b25750> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
FN metric calculation completed in 9.561478941992391 seconds.
Training succeeded with seed 933.
Model trained in 5131.82 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 35.50 s.
                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/c_Main_CsplineN.py , Line : 469, Func.Name : prediction_function, Message : Plotters.cornerplotter(X_data_test.numpy(),X_data_nf.numpy(),path_to_results,ndims,norm=True) # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 35.75 s.
===========
Run 314/720 done in 5175.64 s.
===========

===========
Generating train data for run 315.
===========
Train data generated in 0.18 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_315/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 933}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_315/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[2.7429588 , 2.5700626 , 7.723717  , ..., 7.7501717 , 2.9186718 ,
        1.775845  ],
       [4.728784  , 6.065677  , 0.9645814 , ..., 1.2628946 , 6.7253027 ,
        1.4381479 ],
       [3.8513129 , 6.1744533 , 0.2601294 , ..., 1.1662469 , 6.572044  ,
        1.3500103 ],
       ...,
       [2.8332918 , 4.2526407 , 9.701975  , ..., 7.0738525 , 2.5952196 ,
        1.8190176 ],
       [3.118363  , 5.4312434 , 0.32481733, ..., 1.9350358 , 6.6219816 ,
        1.3230293 ],
       [1.792576  , 4.9344916 , 9.207544  , ..., 7.378074  , 2.857349  ,
        1.56005   ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_315/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_315
self.data_kwargs: {'seed': 933}
self.x_data: [[4.6118093  6.294248   0.6753535  ... 1.3966799  6.5528636  1.404321  ]
 [5.0913153  7.181254   5.302016   ... 4.927679   2.6276157  7.5562596 ]
 [2.3468595  3.6813745  8.449473   ... 7.5625257  2.3049273  1.7164713 ]
 ...
 [1.7774892  4.58926    7.003348   ... 7.297376   3.211844   1.3889377 ]
 [5.1396513  5.5684643  1.4578001  ... 0.69219434 6.9603205  1.3834548 ]
 [3.2499232  3.5331872  8.207085   ... 6.760554   3.3946218  2.0297966 ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_57"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_58 (InputLayer)       [(None, 32)]              0         
                                                                 
 log_prob_layer_7 (LogProbLa  (None,)                  537200    
 yer)                                                            
                                                                 
=================================================================
Total params: 537,200
Trainable params: 537,200
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_7/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_7'")
self.model: <keras.engine.functional.Functional object at 0x7fd4d46ad570>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fd48c60ca90>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fd48c60ca90>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fd42c573b80>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fd42c584400>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fd42c586380>, <keras.callbacks.ModelCheckpoint object at 0x7fd42c587250>, <keras.callbacks.EarlyStopping object at 0x7fd42c585060>, <keras.callbacks.ReduceLROnPlateau object at 0x7fd42c587dc0>, <keras.callbacks.TerminateOnNaN object at 0x7fd42c5848b0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[2.7429588 , 2.5700626 , 7.723717  , ..., 7.7501717 , 2.9186718 ,
        1.775845  ],
       [4.728784  , 6.065677  , 0.9645814 , ..., 1.2628946 , 6.7253027 ,
        1.4381479 ],
       [3.8513129 , 6.1744533 , 0.2601294 , ..., 1.1662469 , 6.572044  ,
        1.3500103 ],
       ...,
       [2.8332918 , 4.2526407 , 9.701975  , ..., 7.0738525 , 2.5952196 ,
        1.8190176 ],
       [3.118363  , 5.4312434 , 0.32481733, ..., 1.9350358 , 6.6219816 ,
        1.3230293 ],
       [1.792576  , 4.9344916 , 9.207544  , ..., 7.378074  , 2.857349  ,
        1.56005   ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_315/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 315/720 with hyperparameters:
timestamp = 2023-09-27 22:09:13.014192
ndims = 32
seed_train = 933
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 5
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 537200
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 4.6118093   6.294248    0.6753535   5.561676    6.128757    6.145322
  9.785121    7.1052794   3.7474928   5.3494825   6.3791265   0.5788075
  5.683702    6.3188157   1.6447939   1.0492666   3.6812766   3.7191741
  5.81123     3.2186081  10.359394    0.68370855  2.036205    1.0944312
  6.489696    3.6441135   4.6169076   1.7655768   1.5199437   1.3966799
  6.5528636   1.404321  ]
Epoch 1/1000
2023-09-27 22:11:03.158 
Epoch 1/1000 
	 loss: 123.2271, MinusLogProbMetric: 123.2271, val_loss: 36.3231, val_MinusLogProbMetric: 36.3231

Epoch 1: val_loss improved from inf to 36.32306, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 110s - loss: 123.2271 - MinusLogProbMetric: 123.2271 - val_loss: 36.3231 - val_MinusLogProbMetric: 36.3231 - lr: 0.0010 - 110s/epoch - 564ms/step
Epoch 2/1000
2023-09-27 22:11:42.230 
Epoch 2/1000 
	 loss: 30.7912, MinusLogProbMetric: 30.7912, val_loss: 28.8667, val_MinusLogProbMetric: 28.8667

Epoch 2: val_loss improved from 36.32306 to 28.86668, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 30.7912 - MinusLogProbMetric: 30.7912 - val_loss: 28.8667 - val_MinusLogProbMetric: 28.8667 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 3/1000
2023-09-27 22:12:21.506 
Epoch 3/1000 
	 loss: 26.0542, MinusLogProbMetric: 26.0542, val_loss: 25.8587, val_MinusLogProbMetric: 25.8587

Epoch 3: val_loss improved from 28.86668 to 25.85869, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 26.0542 - MinusLogProbMetric: 26.0542 - val_loss: 25.8587 - val_MinusLogProbMetric: 25.8587 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 4/1000
2023-09-27 22:13:00.274 
Epoch 4/1000 
	 loss: 24.0021, MinusLogProbMetric: 24.0021, val_loss: 23.2164, val_MinusLogProbMetric: 23.2164

Epoch 4: val_loss improved from 25.85869 to 23.21642, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 24.0021 - MinusLogProbMetric: 24.0021 - val_loss: 23.2164 - val_MinusLogProbMetric: 23.2164 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 5/1000
2023-09-27 22:13:39.518 
Epoch 5/1000 
	 loss: 23.0256, MinusLogProbMetric: 23.0256, val_loss: 22.7767, val_MinusLogProbMetric: 22.7767

Epoch 5: val_loss improved from 23.21642 to 22.77675, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 23.0256 - MinusLogProbMetric: 23.0256 - val_loss: 22.7767 - val_MinusLogProbMetric: 22.7767 - lr: 0.0010 - 39s/epoch - 201ms/step
Epoch 6/1000
2023-09-27 22:14:18.621 
Epoch 6/1000 
	 loss: 22.4346, MinusLogProbMetric: 22.4346, val_loss: 23.4820, val_MinusLogProbMetric: 23.4820

Epoch 6: val_loss did not improve from 22.77675
196/196 - 38s - loss: 22.4346 - MinusLogProbMetric: 22.4346 - val_loss: 23.4820 - val_MinusLogProbMetric: 23.4820 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 7/1000
2023-09-27 22:14:57.012 
Epoch 7/1000 
	 loss: 21.8547, MinusLogProbMetric: 21.8547, val_loss: 21.6008, val_MinusLogProbMetric: 21.6008

Epoch 7: val_loss improved from 22.77675 to 21.60082, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 21.8547 - MinusLogProbMetric: 21.8547 - val_loss: 21.6008 - val_MinusLogProbMetric: 21.6008 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 8/1000
2023-09-27 22:15:35.775 
Epoch 8/1000 
	 loss: 21.3044, MinusLogProbMetric: 21.3044, val_loss: 21.0636, val_MinusLogProbMetric: 21.0636

Epoch 8: val_loss improved from 21.60082 to 21.06356, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 21.3044 - MinusLogProbMetric: 21.3044 - val_loss: 21.0636 - val_MinusLogProbMetric: 21.0636 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 9/1000
2023-09-27 22:16:14.606 
Epoch 9/1000 
	 loss: 21.1448, MinusLogProbMetric: 21.1448, val_loss: 20.7650, val_MinusLogProbMetric: 20.7650

Epoch 9: val_loss improved from 21.06356 to 20.76504, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 21.1448 - MinusLogProbMetric: 21.1448 - val_loss: 20.7650 - val_MinusLogProbMetric: 20.7650 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 10/1000
2023-09-27 22:16:53.661 
Epoch 10/1000 
	 loss: 20.6721, MinusLogProbMetric: 20.6721, val_loss: 21.0066, val_MinusLogProbMetric: 21.0066

Epoch 10: val_loss did not improve from 20.76504
196/196 - 38s - loss: 20.6721 - MinusLogProbMetric: 20.6721 - val_loss: 21.0066 - val_MinusLogProbMetric: 21.0066 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 11/1000
2023-09-27 22:17:31.986 
Epoch 11/1000 
	 loss: 20.5980, MinusLogProbMetric: 20.5980, val_loss: 20.1329, val_MinusLogProbMetric: 20.1329

Epoch 11: val_loss improved from 20.76504 to 20.13295, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 20.5980 - MinusLogProbMetric: 20.5980 - val_loss: 20.1329 - val_MinusLogProbMetric: 20.1329 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 12/1000
2023-09-27 22:18:12.281 
Epoch 12/1000 
	 loss: 20.5654, MinusLogProbMetric: 20.5654, val_loss: 19.7587, val_MinusLogProbMetric: 19.7587

Epoch 12: val_loss improved from 20.13295 to 19.75871, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 40s - loss: 20.5654 - MinusLogProbMetric: 20.5654 - val_loss: 19.7587 - val_MinusLogProbMetric: 19.7587 - lr: 0.0010 - 40s/epoch - 206ms/step
Epoch 13/1000
2023-09-27 22:18:52.094 
Epoch 13/1000 
	 loss: 20.3021, MinusLogProbMetric: 20.3021, val_loss: 20.2213, val_MinusLogProbMetric: 20.2213

Epoch 13: val_loss did not improve from 19.75871
196/196 - 39s - loss: 20.3021 - MinusLogProbMetric: 20.3021 - val_loss: 20.2213 - val_MinusLogProbMetric: 20.2213 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 14/1000
2023-09-27 22:19:30.766 
Epoch 14/1000 
	 loss: 20.1349, MinusLogProbMetric: 20.1349, val_loss: 20.6164, val_MinusLogProbMetric: 20.6164

Epoch 14: val_loss did not improve from 19.75871
196/196 - 39s - loss: 20.1349 - MinusLogProbMetric: 20.1349 - val_loss: 20.6164 - val_MinusLogProbMetric: 20.6164 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 15/1000
2023-09-27 22:20:09.126 
Epoch 15/1000 
	 loss: 19.9627, MinusLogProbMetric: 19.9627, val_loss: 19.8634, val_MinusLogProbMetric: 19.8634

Epoch 15: val_loss did not improve from 19.75871
196/196 - 38s - loss: 19.9627 - MinusLogProbMetric: 19.9627 - val_loss: 19.8634 - val_MinusLogProbMetric: 19.8634 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 16/1000
2023-09-27 22:20:47.340 
Epoch 16/1000 
	 loss: 19.7323, MinusLogProbMetric: 19.7323, val_loss: 19.3820, val_MinusLogProbMetric: 19.3820

Epoch 16: val_loss improved from 19.75871 to 19.38200, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 19.7323 - MinusLogProbMetric: 19.7323 - val_loss: 19.3820 - val_MinusLogProbMetric: 19.3820 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 17/1000
2023-09-27 22:21:26.660 
Epoch 17/1000 
	 loss: 19.8068, MinusLogProbMetric: 19.8068, val_loss: 19.3203, val_MinusLogProbMetric: 19.3203

Epoch 17: val_loss improved from 19.38200 to 19.32032, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 19.8068 - MinusLogProbMetric: 19.8068 - val_loss: 19.3203 - val_MinusLogProbMetric: 19.3203 - lr: 0.0010 - 39s/epoch - 201ms/step
Epoch 18/1000
2023-09-27 22:22:05.921 
Epoch 18/1000 
	 loss: 19.6468, MinusLogProbMetric: 19.6468, val_loss: 19.3069, val_MinusLogProbMetric: 19.3069

Epoch 18: val_loss improved from 19.32032 to 19.30688, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 19.6468 - MinusLogProbMetric: 19.6468 - val_loss: 19.3069 - val_MinusLogProbMetric: 19.3069 - lr: 0.0010 - 39s/epoch - 201ms/step
Epoch 19/1000
2023-09-27 22:22:45.368 
Epoch 19/1000 
	 loss: 19.5183, MinusLogProbMetric: 19.5183, val_loss: 20.9017, val_MinusLogProbMetric: 20.9017

Epoch 19: val_loss did not improve from 19.30688
196/196 - 39s - loss: 19.5183 - MinusLogProbMetric: 19.5183 - val_loss: 20.9017 - val_MinusLogProbMetric: 20.9017 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 20/1000
2023-09-27 22:23:24.162 
Epoch 20/1000 
	 loss: 19.5287, MinusLogProbMetric: 19.5287, val_loss: 19.8125, val_MinusLogProbMetric: 19.8125

Epoch 20: val_loss did not improve from 19.30688
196/196 - 39s - loss: 19.5287 - MinusLogProbMetric: 19.5287 - val_loss: 19.8125 - val_MinusLogProbMetric: 19.8125 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 21/1000
2023-09-27 22:24:02.435 
Epoch 21/1000 
	 loss: 19.3486, MinusLogProbMetric: 19.3486, val_loss: 19.0225, val_MinusLogProbMetric: 19.0225

Epoch 21: val_loss improved from 19.30688 to 19.02255, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 19.3486 - MinusLogProbMetric: 19.3486 - val_loss: 19.0225 - val_MinusLogProbMetric: 19.0225 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 22/1000
2023-09-27 22:24:41.279 
Epoch 22/1000 
	 loss: 19.3301, MinusLogProbMetric: 19.3301, val_loss: 19.1336, val_MinusLogProbMetric: 19.1336

Epoch 22: val_loss did not improve from 19.02255
196/196 - 38s - loss: 19.3301 - MinusLogProbMetric: 19.3301 - val_loss: 19.1336 - val_MinusLogProbMetric: 19.1336 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 23/1000
2023-09-27 22:25:19.534 
Epoch 23/1000 
	 loss: 19.1170, MinusLogProbMetric: 19.1170, val_loss: 19.3391, val_MinusLogProbMetric: 19.3391

Epoch 23: val_loss did not improve from 19.02255
196/196 - 38s - loss: 19.1170 - MinusLogProbMetric: 19.1170 - val_loss: 19.3391 - val_MinusLogProbMetric: 19.3391 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 24/1000
2023-09-27 22:25:58.121 
Epoch 24/1000 
	 loss: 19.3771, MinusLogProbMetric: 19.3771, val_loss: 19.7638, val_MinusLogProbMetric: 19.7638

Epoch 24: val_loss did not improve from 19.02255
196/196 - 39s - loss: 19.3771 - MinusLogProbMetric: 19.3771 - val_loss: 19.7638 - val_MinusLogProbMetric: 19.7638 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 25/1000
2023-09-27 22:26:36.382 
Epoch 25/1000 
	 loss: 19.1243, MinusLogProbMetric: 19.1243, val_loss: 20.2252, val_MinusLogProbMetric: 20.2252

Epoch 25: val_loss did not improve from 19.02255
196/196 - 38s - loss: 19.1243 - MinusLogProbMetric: 19.1243 - val_loss: 20.2252 - val_MinusLogProbMetric: 20.2252 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 26/1000
2023-09-27 22:27:14.499 
Epoch 26/1000 
	 loss: 19.1572, MinusLogProbMetric: 19.1572, val_loss: 18.6359, val_MinusLogProbMetric: 18.6359

Epoch 26: val_loss improved from 19.02255 to 18.63590, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 19.1572 - MinusLogProbMetric: 19.1572 - val_loss: 18.6359 - val_MinusLogProbMetric: 18.6359 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 27/1000
2023-09-27 22:27:53.580 
Epoch 27/1000 
	 loss: 18.9272, MinusLogProbMetric: 18.9272, val_loss: 19.0117, val_MinusLogProbMetric: 19.0117

Epoch 27: val_loss did not improve from 18.63590
196/196 - 39s - loss: 18.9272 - MinusLogProbMetric: 18.9272 - val_loss: 19.0117 - val_MinusLogProbMetric: 19.0117 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 28/1000
2023-09-27 22:28:31.476 
Epoch 28/1000 
	 loss: 19.0379, MinusLogProbMetric: 19.0379, val_loss: 19.0851, val_MinusLogProbMetric: 19.0851

Epoch 28: val_loss did not improve from 18.63590
196/196 - 38s - loss: 19.0379 - MinusLogProbMetric: 19.0379 - val_loss: 19.0851 - val_MinusLogProbMetric: 19.0851 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 29/1000
2023-09-27 22:29:09.629 
Epoch 29/1000 
	 loss: 18.8158, MinusLogProbMetric: 18.8158, val_loss: 18.6669, val_MinusLogProbMetric: 18.6669

Epoch 29: val_loss did not improve from 18.63590
196/196 - 38s - loss: 18.8158 - MinusLogProbMetric: 18.8158 - val_loss: 18.6669 - val_MinusLogProbMetric: 18.6669 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 30/1000
2023-09-27 22:29:47.763 
Epoch 30/1000 
	 loss: 18.6998, MinusLogProbMetric: 18.6998, val_loss: 18.7899, val_MinusLogProbMetric: 18.7899

Epoch 30: val_loss did not improve from 18.63590
196/196 - 38s - loss: 18.6998 - MinusLogProbMetric: 18.6998 - val_loss: 18.7899 - val_MinusLogProbMetric: 18.7899 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 31/1000
2023-09-27 22:30:26.110 
Epoch 31/1000 
	 loss: 18.7957, MinusLogProbMetric: 18.7957, val_loss: 19.2966, val_MinusLogProbMetric: 19.2966

Epoch 31: val_loss did not improve from 18.63590
196/196 - 38s - loss: 18.7957 - MinusLogProbMetric: 18.7957 - val_loss: 19.2966 - val_MinusLogProbMetric: 19.2966 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 32/1000
2023-09-27 22:31:04.025 
Epoch 32/1000 
	 loss: 18.9412, MinusLogProbMetric: 18.9412, val_loss: 18.5598, val_MinusLogProbMetric: 18.5598

Epoch 32: val_loss improved from 18.63590 to 18.55981, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 18.9412 - MinusLogProbMetric: 18.9412 - val_loss: 18.5598 - val_MinusLogProbMetric: 18.5598 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 33/1000
2023-09-27 22:31:42.408 
Epoch 33/1000 
	 loss: 18.5922, MinusLogProbMetric: 18.5922, val_loss: 19.0070, val_MinusLogProbMetric: 19.0070

Epoch 33: val_loss did not improve from 18.55981
196/196 - 38s - loss: 18.5922 - MinusLogProbMetric: 18.5922 - val_loss: 19.0070 - val_MinusLogProbMetric: 19.0070 - lr: 0.0010 - 38s/epoch - 192ms/step
Epoch 34/1000
2023-09-27 22:32:20.476 
Epoch 34/1000 
	 loss: 18.5569, MinusLogProbMetric: 18.5569, val_loss: 18.4673, val_MinusLogProbMetric: 18.4673

Epoch 34: val_loss improved from 18.55981 to 18.46729, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 18.5569 - MinusLogProbMetric: 18.5569 - val_loss: 18.4673 - val_MinusLogProbMetric: 18.4673 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 35/1000
2023-09-27 22:32:59.498 
Epoch 35/1000 
	 loss: 18.4351, MinusLogProbMetric: 18.4351, val_loss: 18.2779, val_MinusLogProbMetric: 18.2779

Epoch 35: val_loss improved from 18.46729 to 18.27790, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 18.4351 - MinusLogProbMetric: 18.4351 - val_loss: 18.2779 - val_MinusLogProbMetric: 18.2779 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 36/1000
2023-09-27 22:33:38.057 
Epoch 36/1000 
	 loss: 18.4432, MinusLogProbMetric: 18.4432, val_loss: 18.7815, val_MinusLogProbMetric: 18.7815

Epoch 36: val_loss did not improve from 18.27790
196/196 - 38s - loss: 18.4432 - MinusLogProbMetric: 18.4432 - val_loss: 18.7815 - val_MinusLogProbMetric: 18.7815 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 37/1000
2023-09-27 22:34:16.167 
Epoch 37/1000 
	 loss: 18.5286, MinusLogProbMetric: 18.5286, val_loss: 18.8508, val_MinusLogProbMetric: 18.8508

Epoch 37: val_loss did not improve from 18.27790
196/196 - 38s - loss: 18.5286 - MinusLogProbMetric: 18.5286 - val_loss: 18.8508 - val_MinusLogProbMetric: 18.8508 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 38/1000
2023-09-27 22:34:54.301 
Epoch 38/1000 
	 loss: 18.4754, MinusLogProbMetric: 18.4754, val_loss: 19.6280, val_MinusLogProbMetric: 19.6280

Epoch 38: val_loss did not improve from 18.27790
196/196 - 38s - loss: 18.4754 - MinusLogProbMetric: 18.4754 - val_loss: 19.6280 - val_MinusLogProbMetric: 19.6280 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 39/1000
2023-09-27 22:35:32.463 
Epoch 39/1000 
	 loss: 18.3359, MinusLogProbMetric: 18.3359, val_loss: 18.3241, val_MinusLogProbMetric: 18.3241

Epoch 39: val_loss did not improve from 18.27790
196/196 - 38s - loss: 18.3359 - MinusLogProbMetric: 18.3359 - val_loss: 18.3241 - val_MinusLogProbMetric: 18.3241 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 40/1000
2023-09-27 22:36:10.601 
Epoch 40/1000 
	 loss: 18.3758, MinusLogProbMetric: 18.3758, val_loss: 18.2397, val_MinusLogProbMetric: 18.2397

Epoch 40: val_loss improved from 18.27790 to 18.23969, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 18.3758 - MinusLogProbMetric: 18.3758 - val_loss: 18.2397 - val_MinusLogProbMetric: 18.2397 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 41/1000
2023-09-27 22:36:49.178 
Epoch 41/1000 
	 loss: 18.3383, MinusLogProbMetric: 18.3383, val_loss: 18.3350, val_MinusLogProbMetric: 18.3350

Epoch 41: val_loss did not improve from 18.23969
196/196 - 38s - loss: 18.3383 - MinusLogProbMetric: 18.3383 - val_loss: 18.3350 - val_MinusLogProbMetric: 18.3350 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 42/1000
2023-09-27 22:37:27.521 
Epoch 42/1000 
	 loss: 18.4167, MinusLogProbMetric: 18.4167, val_loss: 19.2341, val_MinusLogProbMetric: 19.2341

Epoch 42: val_loss did not improve from 18.23969
196/196 - 38s - loss: 18.4167 - MinusLogProbMetric: 18.4167 - val_loss: 19.2341 - val_MinusLogProbMetric: 19.2341 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 43/1000
2023-09-27 22:38:05.759 
Epoch 43/1000 
	 loss: 18.3072, MinusLogProbMetric: 18.3072, val_loss: 18.4667, val_MinusLogProbMetric: 18.4667

Epoch 43: val_loss did not improve from 18.23969
196/196 - 38s - loss: 18.3072 - MinusLogProbMetric: 18.3072 - val_loss: 18.4667 - val_MinusLogProbMetric: 18.4667 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 44/1000
2023-09-27 22:38:44.296 
Epoch 44/1000 
	 loss: 18.3280, MinusLogProbMetric: 18.3280, val_loss: 18.6240, val_MinusLogProbMetric: 18.6240

Epoch 44: val_loss did not improve from 18.23969
196/196 - 39s - loss: 18.3280 - MinusLogProbMetric: 18.3280 - val_loss: 18.6240 - val_MinusLogProbMetric: 18.6240 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 45/1000
2023-09-27 22:39:22.455 
Epoch 45/1000 
	 loss: 18.2328, MinusLogProbMetric: 18.2328, val_loss: 18.8854, val_MinusLogProbMetric: 18.8854

Epoch 45: val_loss did not improve from 18.23969
196/196 - 38s - loss: 18.2328 - MinusLogProbMetric: 18.2328 - val_loss: 18.8854 - val_MinusLogProbMetric: 18.8854 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 46/1000
2023-09-27 22:40:00.766 
Epoch 46/1000 
	 loss: 18.2928, MinusLogProbMetric: 18.2928, val_loss: 18.2548, val_MinusLogProbMetric: 18.2548

Epoch 46: val_loss did not improve from 18.23969
196/196 - 38s - loss: 18.2928 - MinusLogProbMetric: 18.2928 - val_loss: 18.2548 - val_MinusLogProbMetric: 18.2548 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 47/1000
2023-09-27 22:40:38.699 
Epoch 47/1000 
	 loss: 18.1803, MinusLogProbMetric: 18.1803, val_loss: 18.5095, val_MinusLogProbMetric: 18.5095

Epoch 47: val_loss did not improve from 18.23969
196/196 - 38s - loss: 18.1803 - MinusLogProbMetric: 18.1803 - val_loss: 18.5095 - val_MinusLogProbMetric: 18.5095 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 48/1000
2023-09-27 22:41:16.850 
Epoch 48/1000 
	 loss: 18.1241, MinusLogProbMetric: 18.1241, val_loss: 18.4358, val_MinusLogProbMetric: 18.4358

Epoch 48: val_loss did not improve from 18.23969
196/196 - 38s - loss: 18.1241 - MinusLogProbMetric: 18.1241 - val_loss: 18.4358 - val_MinusLogProbMetric: 18.4358 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 49/1000
2023-09-27 22:41:54.795 
Epoch 49/1000 
	 loss: 18.2289, MinusLogProbMetric: 18.2289, val_loss: 18.0745, val_MinusLogProbMetric: 18.0745

Epoch 49: val_loss improved from 18.23969 to 18.07446, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 18.2289 - MinusLogProbMetric: 18.2289 - val_loss: 18.0745 - val_MinusLogProbMetric: 18.0745 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 50/1000
2023-09-27 22:42:33.760 
Epoch 50/1000 
	 loss: 18.1896, MinusLogProbMetric: 18.1896, val_loss: 18.5799, val_MinusLogProbMetric: 18.5799

Epoch 50: val_loss did not improve from 18.07446
196/196 - 38s - loss: 18.1896 - MinusLogProbMetric: 18.1896 - val_loss: 18.5799 - val_MinusLogProbMetric: 18.5799 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 51/1000
2023-09-27 22:43:11.667 
Epoch 51/1000 
	 loss: 18.1404, MinusLogProbMetric: 18.1404, val_loss: 18.3713, val_MinusLogProbMetric: 18.3713

Epoch 51: val_loss did not improve from 18.07446
196/196 - 38s - loss: 18.1404 - MinusLogProbMetric: 18.1404 - val_loss: 18.3713 - val_MinusLogProbMetric: 18.3713 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 52/1000
2023-09-27 22:43:49.862 
Epoch 52/1000 
	 loss: 18.0291, MinusLogProbMetric: 18.0291, val_loss: 18.3517, val_MinusLogProbMetric: 18.3517

Epoch 52: val_loss did not improve from 18.07446
196/196 - 38s - loss: 18.0291 - MinusLogProbMetric: 18.0291 - val_loss: 18.3517 - val_MinusLogProbMetric: 18.3517 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 53/1000
2023-09-27 22:44:27.961 
Epoch 53/1000 
	 loss: 17.9847, MinusLogProbMetric: 17.9847, val_loss: 18.7586, val_MinusLogProbMetric: 18.7586

Epoch 53: val_loss did not improve from 18.07446
196/196 - 38s - loss: 17.9847 - MinusLogProbMetric: 17.9847 - val_loss: 18.7586 - val_MinusLogProbMetric: 18.7586 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 54/1000
2023-09-27 22:45:06.112 
Epoch 54/1000 
	 loss: 17.9776, MinusLogProbMetric: 17.9776, val_loss: 17.8801, val_MinusLogProbMetric: 17.8801

Epoch 54: val_loss improved from 18.07446 to 17.88009, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 17.9776 - MinusLogProbMetric: 17.9776 - val_loss: 17.8801 - val_MinusLogProbMetric: 17.8801 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 55/1000
2023-09-27 22:45:45.224 
Epoch 55/1000 
	 loss: 18.2544, MinusLogProbMetric: 18.2544, val_loss: 19.5962, val_MinusLogProbMetric: 19.5962

Epoch 55: val_loss did not improve from 17.88009
196/196 - 38s - loss: 18.2544 - MinusLogProbMetric: 18.2544 - val_loss: 19.5962 - val_MinusLogProbMetric: 19.5962 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 56/1000
2023-09-27 22:46:23.420 
Epoch 56/1000 
	 loss: 17.9657, MinusLogProbMetric: 17.9657, val_loss: 17.7411, val_MinusLogProbMetric: 17.7411

Epoch 56: val_loss improved from 17.88009 to 17.74112, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 17.9657 - MinusLogProbMetric: 17.9657 - val_loss: 17.7411 - val_MinusLogProbMetric: 17.7411 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 57/1000
2023-09-27 22:47:02.546 
Epoch 57/1000 
	 loss: 17.9933, MinusLogProbMetric: 17.9933, val_loss: 18.0455, val_MinusLogProbMetric: 18.0455

Epoch 57: val_loss did not improve from 17.74112
196/196 - 38s - loss: 17.9933 - MinusLogProbMetric: 17.9933 - val_loss: 18.0455 - val_MinusLogProbMetric: 18.0455 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 58/1000
2023-09-27 22:47:40.697 
Epoch 58/1000 
	 loss: 17.9525, MinusLogProbMetric: 17.9525, val_loss: 19.0082, val_MinusLogProbMetric: 19.0082

Epoch 58: val_loss did not improve from 17.74112
196/196 - 38s - loss: 17.9525 - MinusLogProbMetric: 17.9525 - val_loss: 19.0082 - val_MinusLogProbMetric: 19.0082 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 59/1000
2023-09-27 22:48:18.810 
Epoch 59/1000 
	 loss: 18.0686, MinusLogProbMetric: 18.0686, val_loss: 18.2547, val_MinusLogProbMetric: 18.2547

Epoch 59: val_loss did not improve from 17.74112
196/196 - 38s - loss: 18.0686 - MinusLogProbMetric: 18.0686 - val_loss: 18.2547 - val_MinusLogProbMetric: 18.2547 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 60/1000
2023-09-27 22:48:57.139 
Epoch 60/1000 
	 loss: 17.9271, MinusLogProbMetric: 17.9271, val_loss: 19.0304, val_MinusLogProbMetric: 19.0304

Epoch 60: val_loss did not improve from 17.74112
196/196 - 38s - loss: 17.9271 - MinusLogProbMetric: 17.9271 - val_loss: 19.0304 - val_MinusLogProbMetric: 19.0304 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 61/1000
2023-09-27 22:49:35.277 
Epoch 61/1000 
	 loss: 17.8403, MinusLogProbMetric: 17.8403, val_loss: 17.8714, val_MinusLogProbMetric: 17.8714

Epoch 61: val_loss did not improve from 17.74112
196/196 - 38s - loss: 17.8403 - MinusLogProbMetric: 17.8403 - val_loss: 17.8714 - val_MinusLogProbMetric: 17.8714 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 62/1000
2023-09-27 22:50:13.654 
Epoch 62/1000 
	 loss: 17.8968, MinusLogProbMetric: 17.8968, val_loss: 18.0463, val_MinusLogProbMetric: 18.0463

Epoch 62: val_loss did not improve from 17.74112
196/196 - 38s - loss: 17.8968 - MinusLogProbMetric: 17.8968 - val_loss: 18.0463 - val_MinusLogProbMetric: 18.0463 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 63/1000
2023-09-27 22:50:51.547 
Epoch 63/1000 
	 loss: 17.8401, MinusLogProbMetric: 17.8401, val_loss: 17.8007, val_MinusLogProbMetric: 17.8007

Epoch 63: val_loss did not improve from 17.74112
196/196 - 38s - loss: 17.8401 - MinusLogProbMetric: 17.8401 - val_loss: 17.8007 - val_MinusLogProbMetric: 17.8007 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 64/1000
2023-09-27 22:51:29.318 
Epoch 64/1000 
	 loss: 17.8338, MinusLogProbMetric: 17.8338, val_loss: 18.0382, val_MinusLogProbMetric: 18.0382

Epoch 64: val_loss did not improve from 17.74112
196/196 - 38s - loss: 17.8338 - MinusLogProbMetric: 17.8338 - val_loss: 18.0382 - val_MinusLogProbMetric: 18.0382 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 65/1000
2023-09-27 22:52:07.411 
Epoch 65/1000 
	 loss: 17.8033, MinusLogProbMetric: 17.8033, val_loss: 18.4171, val_MinusLogProbMetric: 18.4171

Epoch 65: val_loss did not improve from 17.74112
196/196 - 38s - loss: 17.8033 - MinusLogProbMetric: 17.8033 - val_loss: 18.4171 - val_MinusLogProbMetric: 18.4171 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 66/1000
2023-09-27 22:52:45.524 
Epoch 66/1000 
	 loss: 17.9106, MinusLogProbMetric: 17.9106, val_loss: 17.6949, val_MinusLogProbMetric: 17.6949

Epoch 66: val_loss improved from 17.74112 to 17.69493, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 17.9106 - MinusLogProbMetric: 17.9106 - val_loss: 17.6949 - val_MinusLogProbMetric: 17.6949 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 67/1000
2023-09-27 22:53:24.401 
Epoch 67/1000 
	 loss: 17.8225, MinusLogProbMetric: 17.8225, val_loss: 18.7178, val_MinusLogProbMetric: 18.7178

Epoch 67: val_loss did not improve from 17.69493
196/196 - 38s - loss: 17.8225 - MinusLogProbMetric: 17.8225 - val_loss: 18.7178 - val_MinusLogProbMetric: 18.7178 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 68/1000
2023-09-27 22:54:02.404 
Epoch 68/1000 
	 loss: 17.8339, MinusLogProbMetric: 17.8339, val_loss: 17.7988, val_MinusLogProbMetric: 17.7988

Epoch 68: val_loss did not improve from 17.69493
196/196 - 38s - loss: 17.8339 - MinusLogProbMetric: 17.8339 - val_loss: 17.7988 - val_MinusLogProbMetric: 17.7988 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 69/1000
2023-09-27 22:54:40.352 
Epoch 69/1000 
	 loss: 17.7309, MinusLogProbMetric: 17.7309, val_loss: 18.1358, val_MinusLogProbMetric: 18.1358

Epoch 69: val_loss did not improve from 17.69493
196/196 - 38s - loss: 17.7309 - MinusLogProbMetric: 17.7309 - val_loss: 18.1358 - val_MinusLogProbMetric: 18.1358 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 70/1000
2023-09-27 22:55:18.710 
Epoch 70/1000 
	 loss: 17.7719, MinusLogProbMetric: 17.7719, val_loss: 17.8255, val_MinusLogProbMetric: 17.8255

Epoch 70: val_loss did not improve from 17.69493
196/196 - 38s - loss: 17.7719 - MinusLogProbMetric: 17.7719 - val_loss: 17.8255 - val_MinusLogProbMetric: 17.8255 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 71/1000
2023-09-27 22:55:57.056 
Epoch 71/1000 
	 loss: 17.8279, MinusLogProbMetric: 17.8279, val_loss: 18.3057, val_MinusLogProbMetric: 18.3057

Epoch 71: val_loss did not improve from 17.69493
196/196 - 38s - loss: 17.8279 - MinusLogProbMetric: 17.8279 - val_loss: 18.3057 - val_MinusLogProbMetric: 18.3057 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 72/1000
2023-09-27 22:56:35.380 
Epoch 72/1000 
	 loss: 17.8326, MinusLogProbMetric: 17.8326, val_loss: 17.6308, val_MinusLogProbMetric: 17.6308

Epoch 72: val_loss improved from 17.69493 to 17.63082, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 17.8326 - MinusLogProbMetric: 17.8326 - val_loss: 17.6308 - val_MinusLogProbMetric: 17.6308 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 73/1000
2023-09-27 22:57:14.074 
Epoch 73/1000 
	 loss: 17.8189, MinusLogProbMetric: 17.8189, val_loss: 17.9186, val_MinusLogProbMetric: 17.9186

Epoch 73: val_loss did not improve from 17.63082
196/196 - 38s - loss: 17.8189 - MinusLogProbMetric: 17.8189 - val_loss: 17.9186 - val_MinusLogProbMetric: 17.9186 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 74/1000
2023-09-27 22:57:52.269 
Epoch 74/1000 
	 loss: 17.6890, MinusLogProbMetric: 17.6890, val_loss: 17.8286, val_MinusLogProbMetric: 17.8286

Epoch 74: val_loss did not improve from 17.63082
196/196 - 38s - loss: 17.6890 - MinusLogProbMetric: 17.6890 - val_loss: 17.8286 - val_MinusLogProbMetric: 17.8286 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 75/1000
2023-09-27 22:58:30.206 
Epoch 75/1000 
	 loss: 17.7145, MinusLogProbMetric: 17.7145, val_loss: 18.0698, val_MinusLogProbMetric: 18.0698

Epoch 75: val_loss did not improve from 17.63082
196/196 - 38s - loss: 17.7145 - MinusLogProbMetric: 17.7145 - val_loss: 18.0698 - val_MinusLogProbMetric: 18.0698 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 76/1000
2023-09-27 22:59:08.147 
Epoch 76/1000 
	 loss: 17.6748, MinusLogProbMetric: 17.6748, val_loss: 17.5537, val_MinusLogProbMetric: 17.5537

Epoch 76: val_loss improved from 17.63082 to 17.55368, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 17.6748 - MinusLogProbMetric: 17.6748 - val_loss: 17.5537 - val_MinusLogProbMetric: 17.5537 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 77/1000
2023-09-27 22:59:47.207 
Epoch 77/1000 
	 loss: 17.6049, MinusLogProbMetric: 17.6049, val_loss: 17.7038, val_MinusLogProbMetric: 17.7038

Epoch 77: val_loss did not improve from 17.55368
196/196 - 38s - loss: 17.6049 - MinusLogProbMetric: 17.6049 - val_loss: 17.7038 - val_MinusLogProbMetric: 17.7038 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 78/1000
2023-09-27 23:00:25.172 
Epoch 78/1000 
	 loss: 17.6428, MinusLogProbMetric: 17.6428, val_loss: 17.5936, val_MinusLogProbMetric: 17.5936

Epoch 78: val_loss did not improve from 17.55368
196/196 - 38s - loss: 17.6428 - MinusLogProbMetric: 17.6428 - val_loss: 17.5936 - val_MinusLogProbMetric: 17.5936 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 79/1000
2023-09-27 23:01:03.295 
Epoch 79/1000 
	 loss: 17.6514, MinusLogProbMetric: 17.6514, val_loss: 17.8275, val_MinusLogProbMetric: 17.8275

Epoch 79: val_loss did not improve from 17.55368
196/196 - 38s - loss: 17.6514 - MinusLogProbMetric: 17.6514 - val_loss: 17.8275 - val_MinusLogProbMetric: 17.8275 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 80/1000
2023-09-27 23:01:41.778 
Epoch 80/1000 
	 loss: 17.6768, MinusLogProbMetric: 17.6768, val_loss: 17.4998, val_MinusLogProbMetric: 17.4998

Epoch 80: val_loss improved from 17.55368 to 17.49981, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 17.6768 - MinusLogProbMetric: 17.6768 - val_loss: 17.4998 - val_MinusLogProbMetric: 17.4998 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 81/1000
2023-09-27 23:02:21.181 
Epoch 81/1000 
	 loss: 17.6824, MinusLogProbMetric: 17.6824, val_loss: 17.7172, val_MinusLogProbMetric: 17.7172

Epoch 81: val_loss did not improve from 17.49981
196/196 - 39s - loss: 17.6824 - MinusLogProbMetric: 17.6824 - val_loss: 17.7172 - val_MinusLogProbMetric: 17.7172 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 82/1000
2023-09-27 23:02:59.768 
Epoch 82/1000 
	 loss: 17.6978, MinusLogProbMetric: 17.6978, val_loss: 17.7666, val_MinusLogProbMetric: 17.7666

Epoch 82: val_loss did not improve from 17.49981
196/196 - 39s - loss: 17.6978 - MinusLogProbMetric: 17.6978 - val_loss: 17.7666 - val_MinusLogProbMetric: 17.7666 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 83/1000
2023-09-27 23:03:38.469 
Epoch 83/1000 
	 loss: 17.5992, MinusLogProbMetric: 17.5992, val_loss: 18.0072, val_MinusLogProbMetric: 18.0072

Epoch 83: val_loss did not improve from 17.49981
196/196 - 39s - loss: 17.5992 - MinusLogProbMetric: 17.5992 - val_loss: 18.0072 - val_MinusLogProbMetric: 18.0072 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 84/1000
2023-09-27 23:04:17.511 
Epoch 84/1000 
	 loss: 17.6194, MinusLogProbMetric: 17.6194, val_loss: 17.6334, val_MinusLogProbMetric: 17.6334

Epoch 84: val_loss did not improve from 17.49981
196/196 - 39s - loss: 17.6194 - MinusLogProbMetric: 17.6194 - val_loss: 17.6334 - val_MinusLogProbMetric: 17.6334 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 85/1000
2023-09-27 23:04:55.809 
Epoch 85/1000 
	 loss: 17.5564, MinusLogProbMetric: 17.5564, val_loss: 17.6500, val_MinusLogProbMetric: 17.6500

Epoch 85: val_loss did not improve from 17.49981
196/196 - 38s - loss: 17.5564 - MinusLogProbMetric: 17.5564 - val_loss: 17.6500 - val_MinusLogProbMetric: 17.6500 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 86/1000
2023-09-27 23:05:34.008 
Epoch 86/1000 
	 loss: 17.6804, MinusLogProbMetric: 17.6804, val_loss: 17.9475, val_MinusLogProbMetric: 17.9475

Epoch 86: val_loss did not improve from 17.49981
196/196 - 38s - loss: 17.6804 - MinusLogProbMetric: 17.6804 - val_loss: 17.9475 - val_MinusLogProbMetric: 17.9475 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 87/1000
2023-09-27 23:06:12.363 
Epoch 87/1000 
	 loss: 17.5958, MinusLogProbMetric: 17.5958, val_loss: 17.4970, val_MinusLogProbMetric: 17.4970

Epoch 87: val_loss improved from 17.49981 to 17.49705, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 17.5958 - MinusLogProbMetric: 17.5958 - val_loss: 17.4970 - val_MinusLogProbMetric: 17.4970 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 88/1000
2023-09-27 23:06:51.468 
Epoch 88/1000 
	 loss: 17.5954, MinusLogProbMetric: 17.5954, val_loss: 17.8237, val_MinusLogProbMetric: 17.8237

Epoch 88: val_loss did not improve from 17.49705
196/196 - 38s - loss: 17.5954 - MinusLogProbMetric: 17.5954 - val_loss: 17.8237 - val_MinusLogProbMetric: 17.8237 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 89/1000
2023-09-27 23:07:30.090 
Epoch 89/1000 
	 loss: 17.5635, MinusLogProbMetric: 17.5635, val_loss: 17.9568, val_MinusLogProbMetric: 17.9568

Epoch 89: val_loss did not improve from 17.49705
196/196 - 39s - loss: 17.5635 - MinusLogProbMetric: 17.5635 - val_loss: 17.9568 - val_MinusLogProbMetric: 17.9568 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 90/1000
2023-09-27 23:08:09.058 
Epoch 90/1000 
	 loss: 17.6009, MinusLogProbMetric: 17.6009, val_loss: 17.7717, val_MinusLogProbMetric: 17.7717

Epoch 90: val_loss did not improve from 17.49705
196/196 - 39s - loss: 17.6009 - MinusLogProbMetric: 17.6009 - val_loss: 17.7717 - val_MinusLogProbMetric: 17.7717 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 91/1000
2023-09-27 23:08:47.360 
Epoch 91/1000 
	 loss: 17.6664, MinusLogProbMetric: 17.6664, val_loss: 18.0028, val_MinusLogProbMetric: 18.0028

Epoch 91: val_loss did not improve from 17.49705
196/196 - 38s - loss: 17.6664 - MinusLogProbMetric: 17.6664 - val_loss: 18.0028 - val_MinusLogProbMetric: 18.0028 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 92/1000
2023-09-27 23:09:25.614 
Epoch 92/1000 
	 loss: 17.5415, MinusLogProbMetric: 17.5415, val_loss: 17.5683, val_MinusLogProbMetric: 17.5683

Epoch 92: val_loss did not improve from 17.49705
196/196 - 38s - loss: 17.5415 - MinusLogProbMetric: 17.5415 - val_loss: 17.5683 - val_MinusLogProbMetric: 17.5683 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 93/1000
2023-09-27 23:10:04.200 
Epoch 93/1000 
	 loss: 17.5878, MinusLogProbMetric: 17.5878, val_loss: 17.5880, val_MinusLogProbMetric: 17.5880

Epoch 93: val_loss did not improve from 17.49705
196/196 - 39s - loss: 17.5878 - MinusLogProbMetric: 17.5878 - val_loss: 17.5880 - val_MinusLogProbMetric: 17.5880 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 94/1000
2023-09-27 23:10:42.722 
Epoch 94/1000 
	 loss: 17.5570, MinusLogProbMetric: 17.5570, val_loss: 17.5187, val_MinusLogProbMetric: 17.5187

Epoch 94: val_loss did not improve from 17.49705
196/196 - 39s - loss: 17.5570 - MinusLogProbMetric: 17.5570 - val_loss: 17.5187 - val_MinusLogProbMetric: 17.5187 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 95/1000
2023-09-27 23:11:21.072 
Epoch 95/1000 
	 loss: 17.5268, MinusLogProbMetric: 17.5268, val_loss: 17.9205, val_MinusLogProbMetric: 17.9205

Epoch 95: val_loss did not improve from 17.49705
196/196 - 38s - loss: 17.5268 - MinusLogProbMetric: 17.5268 - val_loss: 17.9205 - val_MinusLogProbMetric: 17.9205 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 96/1000
2023-09-27 23:11:59.144 
Epoch 96/1000 
	 loss: 17.5361, MinusLogProbMetric: 17.5361, val_loss: 17.5918, val_MinusLogProbMetric: 17.5918

Epoch 96: val_loss did not improve from 17.49705
196/196 - 38s - loss: 17.5361 - MinusLogProbMetric: 17.5361 - val_loss: 17.5918 - val_MinusLogProbMetric: 17.5918 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 97/1000
2023-09-27 23:12:37.634 
Epoch 97/1000 
	 loss: 17.4492, MinusLogProbMetric: 17.4492, val_loss: 18.9408, val_MinusLogProbMetric: 18.9408

Epoch 97: val_loss did not improve from 17.49705
196/196 - 38s - loss: 17.4492 - MinusLogProbMetric: 17.4492 - val_loss: 18.9408 - val_MinusLogProbMetric: 18.9408 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 98/1000
2023-09-27 23:13:16.265 
Epoch 98/1000 
	 loss: 17.5039, MinusLogProbMetric: 17.5039, val_loss: 17.8724, val_MinusLogProbMetric: 17.8724

Epoch 98: val_loss did not improve from 17.49705
196/196 - 39s - loss: 17.5039 - MinusLogProbMetric: 17.5039 - val_loss: 17.8724 - val_MinusLogProbMetric: 17.8724 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 99/1000
2023-09-27 23:13:55.224 
Epoch 99/1000 
	 loss: 17.4377, MinusLogProbMetric: 17.4377, val_loss: 18.2141, val_MinusLogProbMetric: 18.2141

Epoch 99: val_loss did not improve from 17.49705
196/196 - 39s - loss: 17.4377 - MinusLogProbMetric: 17.4377 - val_loss: 18.2141 - val_MinusLogProbMetric: 18.2141 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 100/1000
2023-09-27 23:14:33.780 
Epoch 100/1000 
	 loss: 17.5692, MinusLogProbMetric: 17.5692, val_loss: 17.5542, val_MinusLogProbMetric: 17.5542

Epoch 100: val_loss did not improve from 17.49705
196/196 - 39s - loss: 17.5692 - MinusLogProbMetric: 17.5692 - val_loss: 17.5542 - val_MinusLogProbMetric: 17.5542 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 101/1000
2023-09-27 23:15:12.301 
Epoch 101/1000 
	 loss: 17.5078, MinusLogProbMetric: 17.5078, val_loss: 17.5958, val_MinusLogProbMetric: 17.5958

Epoch 101: val_loss did not improve from 17.49705
196/196 - 39s - loss: 17.5078 - MinusLogProbMetric: 17.5078 - val_loss: 17.5958 - val_MinusLogProbMetric: 17.5958 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 102/1000
2023-09-27 23:15:50.591 
Epoch 102/1000 
	 loss: 17.4896, MinusLogProbMetric: 17.4896, val_loss: 17.5892, val_MinusLogProbMetric: 17.5892

Epoch 102: val_loss did not improve from 17.49705
196/196 - 38s - loss: 17.4896 - MinusLogProbMetric: 17.4896 - val_loss: 17.5892 - val_MinusLogProbMetric: 17.5892 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 103/1000
2023-09-27 23:16:28.889 
Epoch 103/1000 
	 loss: 17.4918, MinusLogProbMetric: 17.4918, val_loss: 17.6834, val_MinusLogProbMetric: 17.6834

Epoch 103: val_loss did not improve from 17.49705
196/196 - 38s - loss: 17.4918 - MinusLogProbMetric: 17.4918 - val_loss: 17.6834 - val_MinusLogProbMetric: 17.6834 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 104/1000
2023-09-27 23:17:07.589 
Epoch 104/1000 
	 loss: 17.4646, MinusLogProbMetric: 17.4646, val_loss: 17.7578, val_MinusLogProbMetric: 17.7578

Epoch 104: val_loss did not improve from 17.49705
196/196 - 39s - loss: 17.4646 - MinusLogProbMetric: 17.4646 - val_loss: 17.7578 - val_MinusLogProbMetric: 17.7578 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 105/1000
2023-09-27 23:17:46.071 
Epoch 105/1000 
	 loss: 17.4445, MinusLogProbMetric: 17.4445, val_loss: 17.4890, val_MinusLogProbMetric: 17.4890

Epoch 105: val_loss improved from 17.49705 to 17.48899, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 17.4445 - MinusLogProbMetric: 17.4445 - val_loss: 17.4890 - val_MinusLogProbMetric: 17.4890 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 106/1000
2023-09-27 23:18:24.905 
Epoch 106/1000 
	 loss: 17.4603, MinusLogProbMetric: 17.4603, val_loss: 17.6296, val_MinusLogProbMetric: 17.6296

Epoch 106: val_loss did not improve from 17.48899
196/196 - 38s - loss: 17.4603 - MinusLogProbMetric: 17.4603 - val_loss: 17.6296 - val_MinusLogProbMetric: 17.6296 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 107/1000
2023-09-27 23:19:03.300 
Epoch 107/1000 
	 loss: 17.4405, MinusLogProbMetric: 17.4405, val_loss: 17.7597, val_MinusLogProbMetric: 17.7597

Epoch 107: val_loss did not improve from 17.48899
196/196 - 38s - loss: 17.4405 - MinusLogProbMetric: 17.4405 - val_loss: 17.7597 - val_MinusLogProbMetric: 17.7597 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 108/1000
2023-09-27 23:19:41.787 
Epoch 108/1000 
	 loss: 17.4627, MinusLogProbMetric: 17.4627, val_loss: 17.7712, val_MinusLogProbMetric: 17.7712

Epoch 108: val_loss did not improve from 17.48899
196/196 - 38s - loss: 17.4627 - MinusLogProbMetric: 17.4627 - val_loss: 17.7712 - val_MinusLogProbMetric: 17.7712 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 109/1000
2023-09-27 23:20:20.131 
Epoch 109/1000 
	 loss: 17.4117, MinusLogProbMetric: 17.4117, val_loss: 17.9379, val_MinusLogProbMetric: 17.9379

Epoch 109: val_loss did not improve from 17.48899
196/196 - 38s - loss: 17.4117 - MinusLogProbMetric: 17.4117 - val_loss: 17.9379 - val_MinusLogProbMetric: 17.9379 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 110/1000
2023-09-27 23:20:58.345 
Epoch 110/1000 
	 loss: 17.4445, MinusLogProbMetric: 17.4445, val_loss: 18.2656, val_MinusLogProbMetric: 18.2656

Epoch 110: val_loss did not improve from 17.48899
196/196 - 38s - loss: 17.4445 - MinusLogProbMetric: 17.4445 - val_loss: 18.2656 - val_MinusLogProbMetric: 18.2656 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 111/1000
2023-09-27 23:21:36.844 
Epoch 111/1000 
	 loss: 17.4514, MinusLogProbMetric: 17.4514, val_loss: 17.4550, val_MinusLogProbMetric: 17.4550

Epoch 111: val_loss improved from 17.48899 to 17.45500, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 17.4514 - MinusLogProbMetric: 17.4514 - val_loss: 17.4550 - val_MinusLogProbMetric: 17.4550 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 112/1000
2023-09-27 23:22:15.637 
Epoch 112/1000 
	 loss: 17.4374, MinusLogProbMetric: 17.4374, val_loss: 17.4463, val_MinusLogProbMetric: 17.4463

Epoch 112: val_loss improved from 17.45500 to 17.44633, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 17.4374 - MinusLogProbMetric: 17.4374 - val_loss: 17.4463 - val_MinusLogProbMetric: 17.4463 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 113/1000
2023-09-27 23:22:54.961 
Epoch 113/1000 
	 loss: 17.4800, MinusLogProbMetric: 17.4800, val_loss: 17.4312, val_MinusLogProbMetric: 17.4312

Epoch 113: val_loss improved from 17.44633 to 17.43120, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 17.4800 - MinusLogProbMetric: 17.4800 - val_loss: 17.4312 - val_MinusLogProbMetric: 17.4312 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 114/1000
2023-09-27 23:23:33.692 
Epoch 114/1000 
	 loss: 17.4060, MinusLogProbMetric: 17.4060, val_loss: 17.7319, val_MinusLogProbMetric: 17.7319

Epoch 114: val_loss did not improve from 17.43120
196/196 - 38s - loss: 17.4060 - MinusLogProbMetric: 17.4060 - val_loss: 17.7319 - val_MinusLogProbMetric: 17.7319 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 115/1000
2023-09-27 23:24:12.105 
Epoch 115/1000 
	 loss: 17.3792, MinusLogProbMetric: 17.3792, val_loss: 17.8406, val_MinusLogProbMetric: 17.8406

Epoch 115: val_loss did not improve from 17.43120
196/196 - 38s - loss: 17.3792 - MinusLogProbMetric: 17.3792 - val_loss: 17.8406 - val_MinusLogProbMetric: 17.8406 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 116/1000
2023-09-27 23:24:50.153 
Epoch 116/1000 
	 loss: 17.4374, MinusLogProbMetric: 17.4374, val_loss: 18.1046, val_MinusLogProbMetric: 18.1046

Epoch 116: val_loss did not improve from 17.43120
196/196 - 38s - loss: 17.4374 - MinusLogProbMetric: 17.4374 - val_loss: 18.1046 - val_MinusLogProbMetric: 18.1046 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 117/1000
2023-09-27 23:25:26.653 
Epoch 117/1000 
	 loss: 17.4055, MinusLogProbMetric: 17.4055, val_loss: 17.4803, val_MinusLogProbMetric: 17.4803

Epoch 117: val_loss did not improve from 17.43120
196/196 - 36s - loss: 17.4055 - MinusLogProbMetric: 17.4055 - val_loss: 17.4803 - val_MinusLogProbMetric: 17.4803 - lr: 0.0010 - 36s/epoch - 186ms/step
Epoch 118/1000
2023-09-27 23:26:03.678 
Epoch 118/1000 
	 loss: 17.3630, MinusLogProbMetric: 17.3630, val_loss: 17.6987, val_MinusLogProbMetric: 17.6987

Epoch 118: val_loss did not improve from 17.43120
196/196 - 37s - loss: 17.3630 - MinusLogProbMetric: 17.3630 - val_loss: 17.6987 - val_MinusLogProbMetric: 17.6987 - lr: 0.0010 - 37s/epoch - 189ms/step
Epoch 119/1000
2023-09-27 23:26:38.294 
Epoch 119/1000 
	 loss: 17.3427, MinusLogProbMetric: 17.3427, val_loss: 17.5627, val_MinusLogProbMetric: 17.5627

Epoch 119: val_loss did not improve from 17.43120
196/196 - 35s - loss: 17.3427 - MinusLogProbMetric: 17.3427 - val_loss: 17.5627 - val_MinusLogProbMetric: 17.5627 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 120/1000
2023-09-27 23:27:16.240 
Epoch 120/1000 
	 loss: 17.4085, MinusLogProbMetric: 17.4085, val_loss: 17.4408, val_MinusLogProbMetric: 17.4408

Epoch 120: val_loss did not improve from 17.43120
196/196 - 38s - loss: 17.4085 - MinusLogProbMetric: 17.4085 - val_loss: 17.4408 - val_MinusLogProbMetric: 17.4408 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 121/1000
2023-09-27 23:27:53.984 
Epoch 121/1000 
	 loss: 17.3627, MinusLogProbMetric: 17.3627, val_loss: 17.5083, val_MinusLogProbMetric: 17.5083

Epoch 121: val_loss did not improve from 17.43120
196/196 - 38s - loss: 17.3627 - MinusLogProbMetric: 17.3627 - val_loss: 17.5083 - val_MinusLogProbMetric: 17.5083 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 122/1000
2023-09-27 23:28:32.145 
Epoch 122/1000 
	 loss: 17.3475, MinusLogProbMetric: 17.3475, val_loss: 17.3300, val_MinusLogProbMetric: 17.3300

Epoch 122: val_loss improved from 17.43120 to 17.32995, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 17.3475 - MinusLogProbMetric: 17.3475 - val_loss: 17.3300 - val_MinusLogProbMetric: 17.3300 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 123/1000
2023-09-27 23:29:10.909 
Epoch 123/1000 
	 loss: 17.3852, MinusLogProbMetric: 17.3852, val_loss: 17.8528, val_MinusLogProbMetric: 17.8528

Epoch 123: val_loss did not improve from 17.32995
196/196 - 38s - loss: 17.3852 - MinusLogProbMetric: 17.3852 - val_loss: 17.8528 - val_MinusLogProbMetric: 17.8528 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 124/1000
2023-09-27 23:29:48.957 
Epoch 124/1000 
	 loss: 17.3741, MinusLogProbMetric: 17.3741, val_loss: 17.6376, val_MinusLogProbMetric: 17.6376

Epoch 124: val_loss did not improve from 17.32995
196/196 - 38s - loss: 17.3741 - MinusLogProbMetric: 17.3741 - val_loss: 17.6376 - val_MinusLogProbMetric: 17.6376 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 125/1000
2023-09-27 23:30:27.070 
Epoch 125/1000 
	 loss: 17.3543, MinusLogProbMetric: 17.3543, val_loss: 17.4419, val_MinusLogProbMetric: 17.4419

Epoch 125: val_loss did not improve from 17.32995
196/196 - 38s - loss: 17.3543 - MinusLogProbMetric: 17.3543 - val_loss: 17.4419 - val_MinusLogProbMetric: 17.4419 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 126/1000
2023-09-27 23:31:05.300 
Epoch 126/1000 
	 loss: 17.3076, MinusLogProbMetric: 17.3076, val_loss: 17.3732, val_MinusLogProbMetric: 17.3732

Epoch 126: val_loss did not improve from 17.32995
196/196 - 38s - loss: 17.3076 - MinusLogProbMetric: 17.3076 - val_loss: 17.3732 - val_MinusLogProbMetric: 17.3732 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 127/1000
2023-09-27 23:31:43.755 
Epoch 127/1000 
	 loss: 17.4188, MinusLogProbMetric: 17.4188, val_loss: 17.4821, val_MinusLogProbMetric: 17.4821

Epoch 127: val_loss did not improve from 17.32995
196/196 - 38s - loss: 17.4188 - MinusLogProbMetric: 17.4188 - val_loss: 17.4821 - val_MinusLogProbMetric: 17.4821 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 128/1000
2023-09-27 23:32:21.882 
Epoch 128/1000 
	 loss: 17.3975, MinusLogProbMetric: 17.3975, val_loss: 17.3732, val_MinusLogProbMetric: 17.3732

Epoch 128: val_loss did not improve from 17.32995
196/196 - 38s - loss: 17.3975 - MinusLogProbMetric: 17.3975 - val_loss: 17.3732 - val_MinusLogProbMetric: 17.3732 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 129/1000
2023-09-27 23:32:59.946 
Epoch 129/1000 
	 loss: 17.3662, MinusLogProbMetric: 17.3662, val_loss: 17.6643, val_MinusLogProbMetric: 17.6643

Epoch 129: val_loss did not improve from 17.32995
196/196 - 38s - loss: 17.3662 - MinusLogProbMetric: 17.3662 - val_loss: 17.6643 - val_MinusLogProbMetric: 17.6643 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 130/1000
2023-09-27 23:33:38.190 
Epoch 130/1000 
	 loss: 17.2700, MinusLogProbMetric: 17.2700, val_loss: 17.6742, val_MinusLogProbMetric: 17.6742

Epoch 130: val_loss did not improve from 17.32995
196/196 - 38s - loss: 17.2700 - MinusLogProbMetric: 17.2700 - val_loss: 17.6742 - val_MinusLogProbMetric: 17.6742 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 131/1000
2023-09-27 23:34:16.394 
Epoch 131/1000 
	 loss: 17.3588, MinusLogProbMetric: 17.3588, val_loss: 18.0654, val_MinusLogProbMetric: 18.0654

Epoch 131: val_loss did not improve from 17.32995
196/196 - 38s - loss: 17.3588 - MinusLogProbMetric: 17.3588 - val_loss: 18.0654 - val_MinusLogProbMetric: 18.0654 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 132/1000
2023-09-27 23:34:54.637 
Epoch 132/1000 
	 loss: 17.3182, MinusLogProbMetric: 17.3182, val_loss: 17.3605, val_MinusLogProbMetric: 17.3605

Epoch 132: val_loss did not improve from 17.32995
196/196 - 38s - loss: 17.3182 - MinusLogProbMetric: 17.3182 - val_loss: 17.3605 - val_MinusLogProbMetric: 17.3605 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 133/1000
2023-09-27 23:35:32.564 
Epoch 133/1000 
	 loss: 17.2924, MinusLogProbMetric: 17.2924, val_loss: 17.9330, val_MinusLogProbMetric: 17.9330

Epoch 133: val_loss did not improve from 17.32995
196/196 - 38s - loss: 17.2924 - MinusLogProbMetric: 17.2924 - val_loss: 17.9330 - val_MinusLogProbMetric: 17.9330 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 134/1000
2023-09-27 23:36:11.058 
Epoch 134/1000 
	 loss: 17.2846, MinusLogProbMetric: 17.2846, val_loss: 17.7394, val_MinusLogProbMetric: 17.7394

Epoch 134: val_loss did not improve from 17.32995
196/196 - 38s - loss: 17.2846 - MinusLogProbMetric: 17.2846 - val_loss: 17.7394 - val_MinusLogProbMetric: 17.7394 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 135/1000
2023-09-27 23:36:49.037 
Epoch 135/1000 
	 loss: 17.3246, MinusLogProbMetric: 17.3246, val_loss: 17.5911, val_MinusLogProbMetric: 17.5911

Epoch 135: val_loss did not improve from 17.32995
196/196 - 38s - loss: 17.3246 - MinusLogProbMetric: 17.3246 - val_loss: 17.5911 - val_MinusLogProbMetric: 17.5911 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 136/1000
2023-09-27 23:37:27.257 
Epoch 136/1000 
	 loss: 17.3418, MinusLogProbMetric: 17.3418, val_loss: 17.4223, val_MinusLogProbMetric: 17.4223

Epoch 136: val_loss did not improve from 17.32995
196/196 - 38s - loss: 17.3418 - MinusLogProbMetric: 17.3418 - val_loss: 17.4223 - val_MinusLogProbMetric: 17.4223 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 137/1000
2023-09-27 23:38:05.472 
Epoch 137/1000 
	 loss: 17.2636, MinusLogProbMetric: 17.2636, val_loss: 17.3191, val_MinusLogProbMetric: 17.3191

Epoch 137: val_loss improved from 17.32995 to 17.31909, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 17.2636 - MinusLogProbMetric: 17.2636 - val_loss: 17.3191 - val_MinusLogProbMetric: 17.3191 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 138/1000
2023-09-27 23:38:44.368 
Epoch 138/1000 
	 loss: 17.3237, MinusLogProbMetric: 17.3237, val_loss: 18.8370, val_MinusLogProbMetric: 18.8370

Epoch 138: val_loss did not improve from 17.31909
196/196 - 38s - loss: 17.3237 - MinusLogProbMetric: 17.3237 - val_loss: 18.8370 - val_MinusLogProbMetric: 18.8370 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 139/1000
2023-09-27 23:39:22.154 
Epoch 139/1000 
	 loss: 17.2503, MinusLogProbMetric: 17.2503, val_loss: 17.5100, val_MinusLogProbMetric: 17.5100

Epoch 139: val_loss did not improve from 17.31909
196/196 - 38s - loss: 17.2503 - MinusLogProbMetric: 17.2503 - val_loss: 17.5100 - val_MinusLogProbMetric: 17.5100 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 140/1000
2023-09-27 23:40:00.519 
Epoch 140/1000 
	 loss: 17.2836, MinusLogProbMetric: 17.2836, val_loss: 18.4338, val_MinusLogProbMetric: 18.4338

Epoch 140: val_loss did not improve from 17.31909
196/196 - 38s - loss: 17.2836 - MinusLogProbMetric: 17.2836 - val_loss: 18.4338 - val_MinusLogProbMetric: 18.4338 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 141/1000
2023-09-27 23:40:38.284 
Epoch 141/1000 
	 loss: 17.2602, MinusLogProbMetric: 17.2602, val_loss: 17.8433, val_MinusLogProbMetric: 17.8433

Epoch 141: val_loss did not improve from 17.31909
196/196 - 38s - loss: 17.2602 - MinusLogProbMetric: 17.2602 - val_loss: 17.8433 - val_MinusLogProbMetric: 17.8433 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 142/1000
2023-09-27 23:41:16.688 
Epoch 142/1000 
	 loss: 17.2893, MinusLogProbMetric: 17.2893, val_loss: 18.0516, val_MinusLogProbMetric: 18.0516

Epoch 142: val_loss did not improve from 17.31909
196/196 - 38s - loss: 17.2893 - MinusLogProbMetric: 17.2893 - val_loss: 18.0516 - val_MinusLogProbMetric: 18.0516 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 143/1000
2023-09-27 23:41:54.834 
Epoch 143/1000 
	 loss: 17.3024, MinusLogProbMetric: 17.3024, val_loss: 17.7712, val_MinusLogProbMetric: 17.7712

Epoch 143: val_loss did not improve from 17.31909
196/196 - 38s - loss: 17.3024 - MinusLogProbMetric: 17.3024 - val_loss: 17.7712 - val_MinusLogProbMetric: 17.7712 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 144/1000
2023-09-27 23:42:33.377 
Epoch 144/1000 
	 loss: 17.2834, MinusLogProbMetric: 17.2834, val_loss: 17.6356, val_MinusLogProbMetric: 17.6356

Epoch 144: val_loss did not improve from 17.31909
196/196 - 39s - loss: 17.2834 - MinusLogProbMetric: 17.2834 - val_loss: 17.6356 - val_MinusLogProbMetric: 17.6356 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 145/1000
2023-09-27 23:43:11.586 
Epoch 145/1000 
	 loss: 17.2903, MinusLogProbMetric: 17.2903, val_loss: 17.8043, val_MinusLogProbMetric: 17.8043

Epoch 145: val_loss did not improve from 17.31909
196/196 - 38s - loss: 17.2903 - MinusLogProbMetric: 17.2903 - val_loss: 17.8043 - val_MinusLogProbMetric: 17.8043 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 146/1000
2023-09-27 23:43:49.927 
Epoch 146/1000 
	 loss: 17.2635, MinusLogProbMetric: 17.2635, val_loss: 17.4967, val_MinusLogProbMetric: 17.4967

Epoch 146: val_loss did not improve from 17.31909
196/196 - 38s - loss: 17.2635 - MinusLogProbMetric: 17.2635 - val_loss: 17.4967 - val_MinusLogProbMetric: 17.4967 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 147/1000
2023-09-27 23:44:28.147 
Epoch 147/1000 
	 loss: 17.2497, MinusLogProbMetric: 17.2497, val_loss: 17.6985, val_MinusLogProbMetric: 17.6985

Epoch 147: val_loss did not improve from 17.31909
196/196 - 38s - loss: 17.2497 - MinusLogProbMetric: 17.2497 - val_loss: 17.6985 - val_MinusLogProbMetric: 17.6985 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 148/1000
2023-09-27 23:45:06.278 
Epoch 148/1000 
	 loss: 17.2507, MinusLogProbMetric: 17.2507, val_loss: 17.4424, val_MinusLogProbMetric: 17.4424

Epoch 148: val_loss did not improve from 17.31909
196/196 - 38s - loss: 17.2507 - MinusLogProbMetric: 17.2507 - val_loss: 17.4424 - val_MinusLogProbMetric: 17.4424 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 149/1000
2023-09-27 23:45:44.340 
Epoch 149/1000 
	 loss: 17.2927, MinusLogProbMetric: 17.2927, val_loss: 17.3420, val_MinusLogProbMetric: 17.3420

Epoch 149: val_loss did not improve from 17.31909
196/196 - 38s - loss: 17.2927 - MinusLogProbMetric: 17.2927 - val_loss: 17.3420 - val_MinusLogProbMetric: 17.3420 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 150/1000
2023-09-27 23:46:22.625 
Epoch 150/1000 
	 loss: 17.2065, MinusLogProbMetric: 17.2065, val_loss: 17.5992, val_MinusLogProbMetric: 17.5992

Epoch 150: val_loss did not improve from 17.31909
196/196 - 38s - loss: 17.2065 - MinusLogProbMetric: 17.2065 - val_loss: 17.5992 - val_MinusLogProbMetric: 17.5992 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 151/1000
2023-09-27 23:47:00.948 
Epoch 151/1000 
	 loss: 17.2665, MinusLogProbMetric: 17.2665, val_loss: 17.5961, val_MinusLogProbMetric: 17.5961

Epoch 151: val_loss did not improve from 17.31909
196/196 - 38s - loss: 17.2665 - MinusLogProbMetric: 17.2665 - val_loss: 17.5961 - val_MinusLogProbMetric: 17.5961 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 152/1000
2023-09-27 23:47:39.226 
Epoch 152/1000 
	 loss: 17.2183, MinusLogProbMetric: 17.2183, val_loss: 17.6674, val_MinusLogProbMetric: 17.6674

Epoch 152: val_loss did not improve from 17.31909
196/196 - 38s - loss: 17.2183 - MinusLogProbMetric: 17.2183 - val_loss: 17.6674 - val_MinusLogProbMetric: 17.6674 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 153/1000
2023-09-27 23:48:17.837 
Epoch 153/1000 
	 loss: 17.2409, MinusLogProbMetric: 17.2409, val_loss: 17.5046, val_MinusLogProbMetric: 17.5046

Epoch 153: val_loss did not improve from 17.31909
196/196 - 39s - loss: 17.2409 - MinusLogProbMetric: 17.2409 - val_loss: 17.5046 - val_MinusLogProbMetric: 17.5046 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 154/1000
2023-09-27 23:48:55.962 
Epoch 154/1000 
	 loss: 17.2916, MinusLogProbMetric: 17.2916, val_loss: 17.6104, val_MinusLogProbMetric: 17.6104

Epoch 154: val_loss did not improve from 17.31909
196/196 - 38s - loss: 17.2916 - MinusLogProbMetric: 17.2916 - val_loss: 17.6104 - val_MinusLogProbMetric: 17.6104 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 155/1000
2023-09-27 23:49:34.469 
Epoch 155/1000 
	 loss: 17.2077, MinusLogProbMetric: 17.2077, val_loss: 17.8625, val_MinusLogProbMetric: 17.8625

Epoch 155: val_loss did not improve from 17.31909
196/196 - 39s - loss: 17.2077 - MinusLogProbMetric: 17.2077 - val_loss: 17.8625 - val_MinusLogProbMetric: 17.8625 - lr: 0.0010 - 39s/epoch - 196ms/step
Epoch 156/1000
2023-09-27 23:50:12.382 
Epoch 156/1000 
	 loss: 17.2561, MinusLogProbMetric: 17.2561, val_loss: 17.3418, val_MinusLogProbMetric: 17.3418

Epoch 156: val_loss did not improve from 17.31909
196/196 - 38s - loss: 17.2561 - MinusLogProbMetric: 17.2561 - val_loss: 17.3418 - val_MinusLogProbMetric: 17.3418 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 157/1000
2023-09-27 23:50:50.368 
Epoch 157/1000 
	 loss: 17.1882, MinusLogProbMetric: 17.1882, val_loss: 17.4574, val_MinusLogProbMetric: 17.4574

Epoch 157: val_loss did not improve from 17.31909
196/196 - 38s - loss: 17.1882 - MinusLogProbMetric: 17.1882 - val_loss: 17.4574 - val_MinusLogProbMetric: 17.4574 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 158/1000
2023-09-27 23:51:28.429 
Epoch 158/1000 
	 loss: 17.2917, MinusLogProbMetric: 17.2917, val_loss: 17.2834, val_MinusLogProbMetric: 17.2834

Epoch 158: val_loss improved from 17.31909 to 17.28336, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 17.2917 - MinusLogProbMetric: 17.2917 - val_loss: 17.2834 - val_MinusLogProbMetric: 17.2834 - lr: 0.0010 - 39s/epoch - 199ms/step
Epoch 159/1000
2023-09-27 23:52:07.602 
Epoch 159/1000 
	 loss: 17.2041, MinusLogProbMetric: 17.2041, val_loss: 17.4446, val_MinusLogProbMetric: 17.4446

Epoch 159: val_loss did not improve from 17.28336
196/196 - 38s - loss: 17.2041 - MinusLogProbMetric: 17.2041 - val_loss: 17.4446 - val_MinusLogProbMetric: 17.4446 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 160/1000
2023-09-27 23:52:45.895 
Epoch 160/1000 
	 loss: 17.1931, MinusLogProbMetric: 17.1931, val_loss: 17.8571, val_MinusLogProbMetric: 17.8571

Epoch 160: val_loss did not improve from 17.28336
196/196 - 38s - loss: 17.1931 - MinusLogProbMetric: 17.1931 - val_loss: 17.8571 - val_MinusLogProbMetric: 17.8571 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 161/1000
2023-09-27 23:53:23.906 
Epoch 161/1000 
	 loss: 17.1883, MinusLogProbMetric: 17.1883, val_loss: 17.4218, val_MinusLogProbMetric: 17.4218

Epoch 161: val_loss did not improve from 17.28336
196/196 - 38s - loss: 17.1883 - MinusLogProbMetric: 17.1883 - val_loss: 17.4218 - val_MinusLogProbMetric: 17.4218 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 162/1000
2023-09-27 23:54:01.733 
Epoch 162/1000 
	 loss: 17.2165, MinusLogProbMetric: 17.2165, val_loss: 17.3968, val_MinusLogProbMetric: 17.3968

Epoch 162: val_loss did not improve from 17.28336
196/196 - 38s - loss: 17.2165 - MinusLogProbMetric: 17.2165 - val_loss: 17.3968 - val_MinusLogProbMetric: 17.3968 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 163/1000
2023-09-27 23:54:40.007 
Epoch 163/1000 
	 loss: 17.1757, MinusLogProbMetric: 17.1757, val_loss: 17.4001, val_MinusLogProbMetric: 17.4001

Epoch 163: val_loss did not improve from 17.28336
196/196 - 38s - loss: 17.1757 - MinusLogProbMetric: 17.1757 - val_loss: 17.4001 - val_MinusLogProbMetric: 17.4001 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 164/1000
2023-09-27 23:55:18.537 
Epoch 164/1000 
	 loss: 17.1836, MinusLogProbMetric: 17.1836, val_loss: 17.7767, val_MinusLogProbMetric: 17.7767

Epoch 164: val_loss did not improve from 17.28336
196/196 - 39s - loss: 17.1836 - MinusLogProbMetric: 17.1836 - val_loss: 17.7767 - val_MinusLogProbMetric: 17.7767 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 165/1000
2023-09-27 23:55:56.637 
Epoch 165/1000 
	 loss: 17.1880, MinusLogProbMetric: 17.1880, val_loss: 17.3713, val_MinusLogProbMetric: 17.3713

Epoch 165: val_loss did not improve from 17.28336
196/196 - 38s - loss: 17.1880 - MinusLogProbMetric: 17.1880 - val_loss: 17.3713 - val_MinusLogProbMetric: 17.3713 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 166/1000
2023-09-27 23:56:34.609 
Epoch 166/1000 
	 loss: 17.1943, MinusLogProbMetric: 17.1943, val_loss: 17.2478, val_MinusLogProbMetric: 17.2478

Epoch 166: val_loss improved from 17.28336 to 17.24781, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 17.1943 - MinusLogProbMetric: 17.1943 - val_loss: 17.2478 - val_MinusLogProbMetric: 17.2478 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 167/1000
2023-09-27 23:57:13.811 
Epoch 167/1000 
	 loss: 17.2096, MinusLogProbMetric: 17.2096, val_loss: 17.4883, val_MinusLogProbMetric: 17.4883

Epoch 167: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.2096 - MinusLogProbMetric: 17.2096 - val_loss: 17.4883 - val_MinusLogProbMetric: 17.4883 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 168/1000
2023-09-27 23:57:52.002 
Epoch 168/1000 
	 loss: 17.2104, MinusLogProbMetric: 17.2104, val_loss: 17.4351, val_MinusLogProbMetric: 17.4351

Epoch 168: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.2104 - MinusLogProbMetric: 17.2104 - val_loss: 17.4351 - val_MinusLogProbMetric: 17.4351 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 169/1000
2023-09-27 23:58:30.338 
Epoch 169/1000 
	 loss: 17.1419, MinusLogProbMetric: 17.1419, val_loss: 17.4844, val_MinusLogProbMetric: 17.4844

Epoch 169: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1419 - MinusLogProbMetric: 17.1419 - val_loss: 17.4844 - val_MinusLogProbMetric: 17.4844 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 170/1000
2023-09-27 23:59:08.388 
Epoch 170/1000 
	 loss: 17.1425, MinusLogProbMetric: 17.1425, val_loss: 17.4093, val_MinusLogProbMetric: 17.4093

Epoch 170: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1425 - MinusLogProbMetric: 17.1425 - val_loss: 17.4093 - val_MinusLogProbMetric: 17.4093 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 171/1000
2023-09-27 23:59:46.435 
Epoch 171/1000 
	 loss: 17.2494, MinusLogProbMetric: 17.2494, val_loss: 17.4091, val_MinusLogProbMetric: 17.4091

Epoch 171: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.2494 - MinusLogProbMetric: 17.2494 - val_loss: 17.4091 - val_MinusLogProbMetric: 17.4091 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 172/1000
2023-09-28 00:00:24.506 
Epoch 172/1000 
	 loss: 17.2226, MinusLogProbMetric: 17.2226, val_loss: 17.4627, val_MinusLogProbMetric: 17.4627

Epoch 172: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.2226 - MinusLogProbMetric: 17.2226 - val_loss: 17.4627 - val_MinusLogProbMetric: 17.4627 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 173/1000
2023-09-28 00:01:03.172 
Epoch 173/1000 
	 loss: 17.1505, MinusLogProbMetric: 17.1505, val_loss: 17.6911, val_MinusLogProbMetric: 17.6911

Epoch 173: val_loss did not improve from 17.24781
196/196 - 39s - loss: 17.1505 - MinusLogProbMetric: 17.1505 - val_loss: 17.6911 - val_MinusLogProbMetric: 17.6911 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 174/1000
2023-09-28 00:01:41.301 
Epoch 174/1000 
	 loss: 17.1591, MinusLogProbMetric: 17.1591, val_loss: 17.4647, val_MinusLogProbMetric: 17.4647

Epoch 174: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1591 - MinusLogProbMetric: 17.1591 - val_loss: 17.4647 - val_MinusLogProbMetric: 17.4647 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 175/1000
2023-09-28 00:02:19.452 
Epoch 175/1000 
	 loss: 17.1509, MinusLogProbMetric: 17.1509, val_loss: 17.9589, val_MinusLogProbMetric: 17.9589

Epoch 175: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1509 - MinusLogProbMetric: 17.1509 - val_loss: 17.9589 - val_MinusLogProbMetric: 17.9589 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 176/1000
2023-09-28 00:02:57.547 
Epoch 176/1000 
	 loss: 17.1873, MinusLogProbMetric: 17.1873, val_loss: 18.5180, val_MinusLogProbMetric: 18.5180

Epoch 176: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1873 - MinusLogProbMetric: 17.1873 - val_loss: 18.5180 - val_MinusLogProbMetric: 18.5180 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 177/1000
2023-09-28 00:03:35.951 
Epoch 177/1000 
	 loss: 17.1881, MinusLogProbMetric: 17.1881, val_loss: 17.4178, val_MinusLogProbMetric: 17.4178

Epoch 177: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1881 - MinusLogProbMetric: 17.1881 - val_loss: 17.4178 - val_MinusLogProbMetric: 17.4178 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 178/1000
2023-09-28 00:04:14.096 
Epoch 178/1000 
	 loss: 17.1904, MinusLogProbMetric: 17.1904, val_loss: 17.8888, val_MinusLogProbMetric: 17.8888

Epoch 178: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1904 - MinusLogProbMetric: 17.1904 - val_loss: 17.8888 - val_MinusLogProbMetric: 17.8888 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 179/1000
2023-09-28 00:04:52.563 
Epoch 179/1000 
	 loss: 17.1960, MinusLogProbMetric: 17.1960, val_loss: 17.2947, val_MinusLogProbMetric: 17.2947

Epoch 179: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1960 - MinusLogProbMetric: 17.1960 - val_loss: 17.2947 - val_MinusLogProbMetric: 17.2947 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 180/1000
2023-09-28 00:05:30.348 
Epoch 180/1000 
	 loss: 17.1409, MinusLogProbMetric: 17.1409, val_loss: 17.2883, val_MinusLogProbMetric: 17.2883

Epoch 180: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1409 - MinusLogProbMetric: 17.1409 - val_loss: 17.2883 - val_MinusLogProbMetric: 17.2883 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 181/1000
2023-09-28 00:06:08.610 
Epoch 181/1000 
	 loss: 17.1351, MinusLogProbMetric: 17.1351, val_loss: 18.0207, val_MinusLogProbMetric: 18.0207

Epoch 181: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1351 - MinusLogProbMetric: 17.1351 - val_loss: 18.0207 - val_MinusLogProbMetric: 18.0207 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 182/1000
2023-09-28 00:06:47.035 
Epoch 182/1000 
	 loss: 17.1373, MinusLogProbMetric: 17.1373, val_loss: 17.2765, val_MinusLogProbMetric: 17.2765

Epoch 182: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1373 - MinusLogProbMetric: 17.1373 - val_loss: 17.2765 - val_MinusLogProbMetric: 17.2765 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 183/1000
2023-09-28 00:07:25.029 
Epoch 183/1000 
	 loss: 17.1021, MinusLogProbMetric: 17.1021, val_loss: 17.3437, val_MinusLogProbMetric: 17.3437

Epoch 183: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1021 - MinusLogProbMetric: 17.1021 - val_loss: 17.3437 - val_MinusLogProbMetric: 17.3437 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 184/1000
2023-09-28 00:08:02.937 
Epoch 184/1000 
	 loss: 17.1086, MinusLogProbMetric: 17.1086, val_loss: 17.4378, val_MinusLogProbMetric: 17.4378

Epoch 184: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1086 - MinusLogProbMetric: 17.1086 - val_loss: 17.4378 - val_MinusLogProbMetric: 17.4378 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 185/1000
2023-09-28 00:08:41.193 
Epoch 185/1000 
	 loss: 17.1069, MinusLogProbMetric: 17.1069, val_loss: 17.6519, val_MinusLogProbMetric: 17.6519

Epoch 185: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1069 - MinusLogProbMetric: 17.1069 - val_loss: 17.6519 - val_MinusLogProbMetric: 17.6519 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 186/1000
2023-09-28 00:09:19.138 
Epoch 186/1000 
	 loss: 17.1005, MinusLogProbMetric: 17.1005, val_loss: 17.5552, val_MinusLogProbMetric: 17.5552

Epoch 186: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1005 - MinusLogProbMetric: 17.1005 - val_loss: 17.5552 - val_MinusLogProbMetric: 17.5552 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 187/1000
2023-09-28 00:09:56.873 
Epoch 187/1000 
	 loss: 17.1371, MinusLogProbMetric: 17.1371, val_loss: 17.7144, val_MinusLogProbMetric: 17.7144

Epoch 187: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1371 - MinusLogProbMetric: 17.1371 - val_loss: 17.7144 - val_MinusLogProbMetric: 17.7144 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 188/1000
2023-09-28 00:10:34.930 
Epoch 188/1000 
	 loss: 17.1068, MinusLogProbMetric: 17.1068, val_loss: 17.3048, val_MinusLogProbMetric: 17.3048

Epoch 188: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1068 - MinusLogProbMetric: 17.1068 - val_loss: 17.3048 - val_MinusLogProbMetric: 17.3048 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 189/1000
2023-09-28 00:11:13.091 
Epoch 189/1000 
	 loss: 17.0913, MinusLogProbMetric: 17.0913, val_loss: 17.4484, val_MinusLogProbMetric: 17.4484

Epoch 189: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.0913 - MinusLogProbMetric: 17.0913 - val_loss: 17.4484 - val_MinusLogProbMetric: 17.4484 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 190/1000
2023-09-28 00:11:51.296 
Epoch 190/1000 
	 loss: 17.1303, MinusLogProbMetric: 17.1303, val_loss: 17.3881, val_MinusLogProbMetric: 17.3881

Epoch 190: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1303 - MinusLogProbMetric: 17.1303 - val_loss: 17.3881 - val_MinusLogProbMetric: 17.3881 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 191/1000
2023-09-28 00:12:29.032 
Epoch 191/1000 
	 loss: 17.1251, MinusLogProbMetric: 17.1251, val_loss: 17.3865, val_MinusLogProbMetric: 17.3865

Epoch 191: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1251 - MinusLogProbMetric: 17.1251 - val_loss: 17.3865 - val_MinusLogProbMetric: 17.3865 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 192/1000
2023-09-28 00:13:07.320 
Epoch 192/1000 
	 loss: 17.1011, MinusLogProbMetric: 17.1011, val_loss: 17.9861, val_MinusLogProbMetric: 17.9861

Epoch 192: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1011 - MinusLogProbMetric: 17.1011 - val_loss: 17.9861 - val_MinusLogProbMetric: 17.9861 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 193/1000
2023-09-28 00:13:45.634 
Epoch 193/1000 
	 loss: 17.0915, MinusLogProbMetric: 17.0915, val_loss: 17.4402, val_MinusLogProbMetric: 17.4402

Epoch 193: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.0915 - MinusLogProbMetric: 17.0915 - val_loss: 17.4402 - val_MinusLogProbMetric: 17.4402 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 194/1000
2023-09-28 00:14:23.630 
Epoch 194/1000 
	 loss: 17.1321, MinusLogProbMetric: 17.1321, val_loss: 17.5322, val_MinusLogProbMetric: 17.5322

Epoch 194: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1321 - MinusLogProbMetric: 17.1321 - val_loss: 17.5322 - val_MinusLogProbMetric: 17.5322 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 195/1000
2023-09-28 00:15:01.911 
Epoch 195/1000 
	 loss: 17.1083, MinusLogProbMetric: 17.1083, val_loss: 17.6371, val_MinusLogProbMetric: 17.6371

Epoch 195: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1083 - MinusLogProbMetric: 17.1083 - val_loss: 17.6371 - val_MinusLogProbMetric: 17.6371 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 196/1000
2023-09-28 00:15:40.527 
Epoch 196/1000 
	 loss: 17.1221, MinusLogProbMetric: 17.1221, val_loss: 18.1650, val_MinusLogProbMetric: 18.1650

Epoch 196: val_loss did not improve from 17.24781
196/196 - 39s - loss: 17.1221 - MinusLogProbMetric: 17.1221 - val_loss: 18.1650 - val_MinusLogProbMetric: 18.1650 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 197/1000
2023-09-28 00:16:18.855 
Epoch 197/1000 
	 loss: 17.1110, MinusLogProbMetric: 17.1110, val_loss: 17.6343, val_MinusLogProbMetric: 17.6343

Epoch 197: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1110 - MinusLogProbMetric: 17.1110 - val_loss: 17.6343 - val_MinusLogProbMetric: 17.6343 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 198/1000
2023-09-28 00:16:56.999 
Epoch 198/1000 
	 loss: 17.0837, MinusLogProbMetric: 17.0837, val_loss: 17.3531, val_MinusLogProbMetric: 17.3531

Epoch 198: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.0837 - MinusLogProbMetric: 17.0837 - val_loss: 17.3531 - val_MinusLogProbMetric: 17.3531 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 199/1000
2023-09-28 00:17:34.942 
Epoch 199/1000 
	 loss: 17.0915, MinusLogProbMetric: 17.0915, val_loss: 17.2726, val_MinusLogProbMetric: 17.2726

Epoch 199: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.0915 - MinusLogProbMetric: 17.0915 - val_loss: 17.2726 - val_MinusLogProbMetric: 17.2726 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 200/1000
2023-09-28 00:18:13.169 
Epoch 200/1000 
	 loss: 17.1162, MinusLogProbMetric: 17.1162, val_loss: 17.2711, val_MinusLogProbMetric: 17.2711

Epoch 200: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1162 - MinusLogProbMetric: 17.1162 - val_loss: 17.2711 - val_MinusLogProbMetric: 17.2711 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 201/1000
2023-09-28 00:18:51.281 
Epoch 201/1000 
	 loss: 17.0588, MinusLogProbMetric: 17.0588, val_loss: 17.5853, val_MinusLogProbMetric: 17.5853

Epoch 201: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.0588 - MinusLogProbMetric: 17.0588 - val_loss: 17.5853 - val_MinusLogProbMetric: 17.5853 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 202/1000
2023-09-28 00:19:29.344 
Epoch 202/1000 
	 loss: 17.1149, MinusLogProbMetric: 17.1149, val_loss: 17.2677, val_MinusLogProbMetric: 17.2677

Epoch 202: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.1149 - MinusLogProbMetric: 17.1149 - val_loss: 17.2677 - val_MinusLogProbMetric: 17.2677 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 203/1000
2023-09-28 00:20:07.632 
Epoch 203/1000 
	 loss: 17.0694, MinusLogProbMetric: 17.0694, val_loss: 17.7771, val_MinusLogProbMetric: 17.7771

Epoch 203: val_loss did not improve from 17.24781
196/196 - 38s - loss: 17.0694 - MinusLogProbMetric: 17.0694 - val_loss: 17.7771 - val_MinusLogProbMetric: 17.7771 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 204/1000
2023-09-28 00:20:45.741 
Epoch 204/1000 
	 loss: 17.0978, MinusLogProbMetric: 17.0978, val_loss: 17.1925, val_MinusLogProbMetric: 17.1925

Epoch 204: val_loss improved from 17.24781 to 17.19248, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 17.0978 - MinusLogProbMetric: 17.0978 - val_loss: 17.1925 - val_MinusLogProbMetric: 17.1925 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 205/1000
2023-09-28 00:21:24.460 
Epoch 205/1000 
	 loss: 17.0665, MinusLogProbMetric: 17.0665, val_loss: 17.2266, val_MinusLogProbMetric: 17.2266

Epoch 205: val_loss did not improve from 17.19248
196/196 - 38s - loss: 17.0665 - MinusLogProbMetric: 17.0665 - val_loss: 17.2266 - val_MinusLogProbMetric: 17.2266 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 206/1000
2023-09-28 00:22:02.853 
Epoch 206/1000 
	 loss: 17.0819, MinusLogProbMetric: 17.0819, val_loss: 17.5762, val_MinusLogProbMetric: 17.5762

Epoch 206: val_loss did not improve from 17.19248
196/196 - 38s - loss: 17.0819 - MinusLogProbMetric: 17.0819 - val_loss: 17.5762 - val_MinusLogProbMetric: 17.5762 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 207/1000
2023-09-28 00:22:40.876 
Epoch 207/1000 
	 loss: 17.0788, MinusLogProbMetric: 17.0788, val_loss: 17.8338, val_MinusLogProbMetric: 17.8338

Epoch 207: val_loss did not improve from 17.19248
196/196 - 38s - loss: 17.0788 - MinusLogProbMetric: 17.0788 - val_loss: 17.8338 - val_MinusLogProbMetric: 17.8338 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 208/1000
2023-09-28 00:23:19.139 
Epoch 208/1000 
	 loss: 17.0681, MinusLogProbMetric: 17.0681, val_loss: 17.3800, val_MinusLogProbMetric: 17.3800

Epoch 208: val_loss did not improve from 17.19248
196/196 - 38s - loss: 17.0681 - MinusLogProbMetric: 17.0681 - val_loss: 17.3800 - val_MinusLogProbMetric: 17.3800 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 209/1000
2023-09-28 00:23:57.281 
Epoch 209/1000 
	 loss: 17.0447, MinusLogProbMetric: 17.0447, val_loss: 17.6782, val_MinusLogProbMetric: 17.6782

Epoch 209: val_loss did not improve from 17.19248
196/196 - 38s - loss: 17.0447 - MinusLogProbMetric: 17.0447 - val_loss: 17.6782 - val_MinusLogProbMetric: 17.6782 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 210/1000
2023-09-28 00:24:35.614 
Epoch 210/1000 
	 loss: 17.0542, MinusLogProbMetric: 17.0542, val_loss: 17.4947, val_MinusLogProbMetric: 17.4947

Epoch 210: val_loss did not improve from 17.19248
196/196 - 38s - loss: 17.0542 - MinusLogProbMetric: 17.0542 - val_loss: 17.4947 - val_MinusLogProbMetric: 17.4947 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 211/1000
2023-09-28 00:25:13.730 
Epoch 211/1000 
	 loss: 17.1440, MinusLogProbMetric: 17.1440, val_loss: 17.5586, val_MinusLogProbMetric: 17.5586

Epoch 211: val_loss did not improve from 17.19248
196/196 - 38s - loss: 17.1440 - MinusLogProbMetric: 17.1440 - val_loss: 17.5586 - val_MinusLogProbMetric: 17.5586 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 212/1000
2023-09-28 00:25:51.665 
Epoch 212/1000 
	 loss: 17.1115, MinusLogProbMetric: 17.1115, val_loss: 17.3217, val_MinusLogProbMetric: 17.3217

Epoch 212: val_loss did not improve from 17.19248
196/196 - 38s - loss: 17.1115 - MinusLogProbMetric: 17.1115 - val_loss: 17.3217 - val_MinusLogProbMetric: 17.3217 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 213/1000
2023-09-28 00:26:29.709 
Epoch 213/1000 
	 loss: 17.0512, MinusLogProbMetric: 17.0512, val_loss: 17.1823, val_MinusLogProbMetric: 17.1823

Epoch 213: val_loss improved from 17.19248 to 17.18229, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 17.0512 - MinusLogProbMetric: 17.0512 - val_loss: 17.1823 - val_MinusLogProbMetric: 17.1823 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 214/1000
2023-09-28 00:27:08.519 
Epoch 214/1000 
	 loss: 17.0787, MinusLogProbMetric: 17.0787, val_loss: 17.5358, val_MinusLogProbMetric: 17.5358

Epoch 214: val_loss did not improve from 17.18229
196/196 - 38s - loss: 17.0787 - MinusLogProbMetric: 17.0787 - val_loss: 17.5358 - val_MinusLogProbMetric: 17.5358 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 215/1000
2023-09-28 00:27:46.797 
Epoch 215/1000 
	 loss: 17.0981, MinusLogProbMetric: 17.0981, val_loss: 17.3304, val_MinusLogProbMetric: 17.3304

Epoch 215: val_loss did not improve from 17.18229
196/196 - 38s - loss: 17.0981 - MinusLogProbMetric: 17.0981 - val_loss: 17.3304 - val_MinusLogProbMetric: 17.3304 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 216/1000
2023-09-28 00:28:24.940 
Epoch 216/1000 
	 loss: 17.0637, MinusLogProbMetric: 17.0637, val_loss: 17.1751, val_MinusLogProbMetric: 17.1751

Epoch 216: val_loss improved from 17.18229 to 17.17515, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 17.0637 - MinusLogProbMetric: 17.0637 - val_loss: 17.1751 - val_MinusLogProbMetric: 17.1751 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 217/1000
2023-09-28 00:29:03.860 
Epoch 217/1000 
	 loss: 17.0285, MinusLogProbMetric: 17.0285, val_loss: 17.2669, val_MinusLogProbMetric: 17.2669

Epoch 217: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0285 - MinusLogProbMetric: 17.0285 - val_loss: 17.2669 - val_MinusLogProbMetric: 17.2669 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 218/1000
2023-09-28 00:29:42.244 
Epoch 218/1000 
	 loss: 17.0468, MinusLogProbMetric: 17.0468, val_loss: 17.3267, val_MinusLogProbMetric: 17.3267

Epoch 218: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0468 - MinusLogProbMetric: 17.0468 - val_loss: 17.3267 - val_MinusLogProbMetric: 17.3267 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 219/1000
2023-09-28 00:30:20.565 
Epoch 219/1000 
	 loss: 17.0252, MinusLogProbMetric: 17.0252, val_loss: 17.3096, val_MinusLogProbMetric: 17.3096

Epoch 219: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0252 - MinusLogProbMetric: 17.0252 - val_loss: 17.3096 - val_MinusLogProbMetric: 17.3096 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 220/1000
2023-09-28 00:30:58.230 
Epoch 220/1000 
	 loss: 17.0881, MinusLogProbMetric: 17.0881, val_loss: 17.3521, val_MinusLogProbMetric: 17.3521

Epoch 220: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0881 - MinusLogProbMetric: 17.0881 - val_loss: 17.3521 - val_MinusLogProbMetric: 17.3521 - lr: 0.0010 - 38s/epoch - 192ms/step
Epoch 221/1000
2023-09-28 00:31:36.502 
Epoch 221/1000 
	 loss: 17.0682, MinusLogProbMetric: 17.0682, val_loss: 17.3487, val_MinusLogProbMetric: 17.3487

Epoch 221: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0682 - MinusLogProbMetric: 17.0682 - val_loss: 17.3487 - val_MinusLogProbMetric: 17.3487 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 222/1000
2023-09-28 00:32:14.837 
Epoch 222/1000 
	 loss: 17.0189, MinusLogProbMetric: 17.0189, val_loss: 17.2023, val_MinusLogProbMetric: 17.2023

Epoch 222: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0189 - MinusLogProbMetric: 17.0189 - val_loss: 17.2023 - val_MinusLogProbMetric: 17.2023 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 223/1000
2023-09-28 00:32:53.094 
Epoch 223/1000 
	 loss: 17.0609, MinusLogProbMetric: 17.0609, val_loss: 17.2571, val_MinusLogProbMetric: 17.2571

Epoch 223: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0609 - MinusLogProbMetric: 17.0609 - val_loss: 17.2571 - val_MinusLogProbMetric: 17.2571 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 224/1000
2023-09-28 00:33:30.694 
Epoch 224/1000 
	 loss: 17.0404, MinusLogProbMetric: 17.0404, val_loss: 17.2931, val_MinusLogProbMetric: 17.2931

Epoch 224: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0404 - MinusLogProbMetric: 17.0404 - val_loss: 17.2931 - val_MinusLogProbMetric: 17.2931 - lr: 0.0010 - 38s/epoch - 192ms/step
Epoch 225/1000
2023-09-28 00:34:08.975 
Epoch 225/1000 
	 loss: 17.0508, MinusLogProbMetric: 17.0508, val_loss: 17.5594, val_MinusLogProbMetric: 17.5594

Epoch 225: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0508 - MinusLogProbMetric: 17.0508 - val_loss: 17.5594 - val_MinusLogProbMetric: 17.5594 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 226/1000
2023-09-28 00:34:47.309 
Epoch 226/1000 
	 loss: 17.0231, MinusLogProbMetric: 17.0231, val_loss: 19.0650, val_MinusLogProbMetric: 19.0650

Epoch 226: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0231 - MinusLogProbMetric: 17.0231 - val_loss: 19.0650 - val_MinusLogProbMetric: 19.0650 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 227/1000
2023-09-28 00:35:25.477 
Epoch 227/1000 
	 loss: 17.0537, MinusLogProbMetric: 17.0537, val_loss: 17.4561, val_MinusLogProbMetric: 17.4561

Epoch 227: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0537 - MinusLogProbMetric: 17.0537 - val_loss: 17.4561 - val_MinusLogProbMetric: 17.4561 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 228/1000
2023-09-28 00:36:03.758 
Epoch 228/1000 
	 loss: 17.0644, MinusLogProbMetric: 17.0644, val_loss: 17.4784, val_MinusLogProbMetric: 17.4784

Epoch 228: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0644 - MinusLogProbMetric: 17.0644 - val_loss: 17.4784 - val_MinusLogProbMetric: 17.4784 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 229/1000
2023-09-28 00:36:41.587 
Epoch 229/1000 
	 loss: 17.0395, MinusLogProbMetric: 17.0395, val_loss: 17.2344, val_MinusLogProbMetric: 17.2344

Epoch 229: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0395 - MinusLogProbMetric: 17.0395 - val_loss: 17.2344 - val_MinusLogProbMetric: 17.2344 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 230/1000
2023-09-28 00:37:17.939 
Epoch 230/1000 
	 loss: 17.0363, MinusLogProbMetric: 17.0363, val_loss: 17.2465, val_MinusLogProbMetric: 17.2465

Epoch 230: val_loss did not improve from 17.17515
196/196 - 36s - loss: 17.0363 - MinusLogProbMetric: 17.0363 - val_loss: 17.2465 - val_MinusLogProbMetric: 17.2465 - lr: 0.0010 - 36s/epoch - 185ms/step
Epoch 231/1000
2023-09-28 00:37:53.072 
Epoch 231/1000 
	 loss: 17.0343, MinusLogProbMetric: 17.0343, val_loss: 17.2624, val_MinusLogProbMetric: 17.2624

Epoch 231: val_loss did not improve from 17.17515
196/196 - 35s - loss: 17.0343 - MinusLogProbMetric: 17.0343 - val_loss: 17.2624 - val_MinusLogProbMetric: 17.2624 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 232/1000
2023-09-28 00:38:27.680 
Epoch 232/1000 
	 loss: 16.9850, MinusLogProbMetric: 16.9850, val_loss: 17.2838, val_MinusLogProbMetric: 17.2838

Epoch 232: val_loss did not improve from 17.17515
196/196 - 35s - loss: 16.9850 - MinusLogProbMetric: 16.9850 - val_loss: 17.2838 - val_MinusLogProbMetric: 17.2838 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 233/1000
2023-09-28 00:39:05.560 
Epoch 233/1000 
	 loss: 17.0291, MinusLogProbMetric: 17.0291, val_loss: 17.7090, val_MinusLogProbMetric: 17.7090

Epoch 233: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0291 - MinusLogProbMetric: 17.0291 - val_loss: 17.7090 - val_MinusLogProbMetric: 17.7090 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 234/1000
2023-09-28 00:39:41.421 
Epoch 234/1000 
	 loss: 17.0146, MinusLogProbMetric: 17.0146, val_loss: 17.4178, val_MinusLogProbMetric: 17.4178

Epoch 234: val_loss did not improve from 17.17515
196/196 - 36s - loss: 17.0146 - MinusLogProbMetric: 17.0146 - val_loss: 17.4178 - val_MinusLogProbMetric: 17.4178 - lr: 0.0010 - 36s/epoch - 183ms/step
Epoch 235/1000
2023-09-28 00:40:15.270 
Epoch 235/1000 
	 loss: 17.0473, MinusLogProbMetric: 17.0473, val_loss: 17.1881, val_MinusLogProbMetric: 17.1881

Epoch 235: val_loss did not improve from 17.17515
196/196 - 34s - loss: 17.0473 - MinusLogProbMetric: 17.0473 - val_loss: 17.1881 - val_MinusLogProbMetric: 17.1881 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 236/1000
2023-09-28 00:40:49.562 
Epoch 236/1000 
	 loss: 17.0031, MinusLogProbMetric: 17.0031, val_loss: 17.5912, val_MinusLogProbMetric: 17.5912

Epoch 236: val_loss did not improve from 17.17515
196/196 - 34s - loss: 17.0031 - MinusLogProbMetric: 17.0031 - val_loss: 17.5912 - val_MinusLogProbMetric: 17.5912 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 237/1000
2023-09-28 00:41:27.388 
Epoch 237/1000 
	 loss: 17.0282, MinusLogProbMetric: 17.0282, val_loss: 17.3375, val_MinusLogProbMetric: 17.3375

Epoch 237: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0282 - MinusLogProbMetric: 17.0282 - val_loss: 17.3375 - val_MinusLogProbMetric: 17.3375 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 238/1000
2023-09-28 00:42:05.805 
Epoch 238/1000 
	 loss: 16.9913, MinusLogProbMetric: 16.9913, val_loss: 17.3359, val_MinusLogProbMetric: 17.3359

Epoch 238: val_loss did not improve from 17.17515
196/196 - 38s - loss: 16.9913 - MinusLogProbMetric: 16.9913 - val_loss: 17.3359 - val_MinusLogProbMetric: 17.3359 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 239/1000
2023-09-28 00:42:43.539 
Epoch 239/1000 
	 loss: 17.0146, MinusLogProbMetric: 17.0146, val_loss: 17.2650, val_MinusLogProbMetric: 17.2650

Epoch 239: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0146 - MinusLogProbMetric: 17.0146 - val_loss: 17.2650 - val_MinusLogProbMetric: 17.2650 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 240/1000
2023-09-28 00:43:21.634 
Epoch 240/1000 
	 loss: 16.9969, MinusLogProbMetric: 16.9969, val_loss: 17.2627, val_MinusLogProbMetric: 17.2627

Epoch 240: val_loss did not improve from 17.17515
196/196 - 38s - loss: 16.9969 - MinusLogProbMetric: 16.9969 - val_loss: 17.2627 - val_MinusLogProbMetric: 17.2627 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 241/1000
2023-09-28 00:43:59.701 
Epoch 241/1000 
	 loss: 17.0197, MinusLogProbMetric: 17.0197, val_loss: 17.2310, val_MinusLogProbMetric: 17.2310

Epoch 241: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0197 - MinusLogProbMetric: 17.0197 - val_loss: 17.2310 - val_MinusLogProbMetric: 17.2310 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 242/1000
2023-09-28 00:44:37.738 
Epoch 242/1000 
	 loss: 17.0103, MinusLogProbMetric: 17.0103, val_loss: 17.4471, val_MinusLogProbMetric: 17.4471

Epoch 242: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0103 - MinusLogProbMetric: 17.0103 - val_loss: 17.4471 - val_MinusLogProbMetric: 17.4471 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 243/1000
2023-09-28 00:45:15.974 
Epoch 243/1000 
	 loss: 16.9985, MinusLogProbMetric: 16.9985, val_loss: 17.8893, val_MinusLogProbMetric: 17.8893

Epoch 243: val_loss did not improve from 17.17515
196/196 - 38s - loss: 16.9985 - MinusLogProbMetric: 16.9985 - val_loss: 17.8893 - val_MinusLogProbMetric: 17.8893 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 244/1000
2023-09-28 00:45:54.058 
Epoch 244/1000 
	 loss: 17.0681, MinusLogProbMetric: 17.0681, val_loss: 17.7252, val_MinusLogProbMetric: 17.7252

Epoch 244: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0681 - MinusLogProbMetric: 17.0681 - val_loss: 17.7252 - val_MinusLogProbMetric: 17.7252 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 245/1000
2023-09-28 00:46:32.287 
Epoch 245/1000 
	 loss: 17.0042, MinusLogProbMetric: 17.0042, val_loss: 17.5463, val_MinusLogProbMetric: 17.5463

Epoch 245: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0042 - MinusLogProbMetric: 17.0042 - val_loss: 17.5463 - val_MinusLogProbMetric: 17.5463 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 246/1000
2023-09-28 00:47:10.369 
Epoch 246/1000 
	 loss: 17.0059, MinusLogProbMetric: 17.0059, val_loss: 17.2304, val_MinusLogProbMetric: 17.2304

Epoch 246: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0059 - MinusLogProbMetric: 17.0059 - val_loss: 17.2304 - val_MinusLogProbMetric: 17.2304 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 247/1000
2023-09-28 00:47:48.713 
Epoch 247/1000 
	 loss: 16.9902, MinusLogProbMetric: 16.9902, val_loss: 17.5323, val_MinusLogProbMetric: 17.5323

Epoch 247: val_loss did not improve from 17.17515
196/196 - 38s - loss: 16.9902 - MinusLogProbMetric: 16.9902 - val_loss: 17.5323 - val_MinusLogProbMetric: 17.5323 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 248/1000
2023-09-28 00:48:26.923 
Epoch 248/1000 
	 loss: 16.9953, MinusLogProbMetric: 16.9953, val_loss: 17.2826, val_MinusLogProbMetric: 17.2826

Epoch 248: val_loss did not improve from 17.17515
196/196 - 38s - loss: 16.9953 - MinusLogProbMetric: 16.9953 - val_loss: 17.2826 - val_MinusLogProbMetric: 17.2826 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 249/1000
2023-09-28 00:49:04.969 
Epoch 249/1000 
	 loss: 16.9971, MinusLogProbMetric: 16.9971, val_loss: 17.5000, val_MinusLogProbMetric: 17.5000

Epoch 249: val_loss did not improve from 17.17515
196/196 - 38s - loss: 16.9971 - MinusLogProbMetric: 16.9971 - val_loss: 17.5000 - val_MinusLogProbMetric: 17.5000 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 250/1000
2023-09-28 00:49:43.063 
Epoch 250/1000 
	 loss: 16.9907, MinusLogProbMetric: 16.9907, val_loss: 17.2221, val_MinusLogProbMetric: 17.2221

Epoch 250: val_loss did not improve from 17.17515
196/196 - 38s - loss: 16.9907 - MinusLogProbMetric: 16.9907 - val_loss: 17.2221 - val_MinusLogProbMetric: 17.2221 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 251/1000
2023-09-28 00:50:21.369 
Epoch 251/1000 
	 loss: 16.9837, MinusLogProbMetric: 16.9837, val_loss: 17.2947, val_MinusLogProbMetric: 17.2947

Epoch 251: val_loss did not improve from 17.17515
196/196 - 38s - loss: 16.9837 - MinusLogProbMetric: 16.9837 - val_loss: 17.2947 - val_MinusLogProbMetric: 17.2947 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 252/1000
2023-09-28 00:50:59.230 
Epoch 252/1000 
	 loss: 16.9619, MinusLogProbMetric: 16.9619, val_loss: 17.4865, val_MinusLogProbMetric: 17.4865

Epoch 252: val_loss did not improve from 17.17515
196/196 - 38s - loss: 16.9619 - MinusLogProbMetric: 16.9619 - val_loss: 17.4865 - val_MinusLogProbMetric: 17.4865 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 253/1000
2023-09-28 00:51:37.174 
Epoch 253/1000 
	 loss: 16.9551, MinusLogProbMetric: 16.9551, val_loss: 17.2044, val_MinusLogProbMetric: 17.2044

Epoch 253: val_loss did not improve from 17.17515
196/196 - 38s - loss: 16.9551 - MinusLogProbMetric: 16.9551 - val_loss: 17.2044 - val_MinusLogProbMetric: 17.2044 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 254/1000
2023-09-28 00:52:15.395 
Epoch 254/1000 
	 loss: 17.0314, MinusLogProbMetric: 17.0314, val_loss: 17.4313, val_MinusLogProbMetric: 17.4313

Epoch 254: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0314 - MinusLogProbMetric: 17.0314 - val_loss: 17.4313 - val_MinusLogProbMetric: 17.4313 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 255/1000
2023-09-28 00:52:53.212 
Epoch 255/1000 
	 loss: 16.9854, MinusLogProbMetric: 16.9854, val_loss: 17.3504, val_MinusLogProbMetric: 17.3504

Epoch 255: val_loss did not improve from 17.17515
196/196 - 38s - loss: 16.9854 - MinusLogProbMetric: 16.9854 - val_loss: 17.3504 - val_MinusLogProbMetric: 17.3504 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 256/1000
2023-09-28 00:53:31.347 
Epoch 256/1000 
	 loss: 16.9742, MinusLogProbMetric: 16.9742, val_loss: 17.6739, val_MinusLogProbMetric: 17.6739

Epoch 256: val_loss did not improve from 17.17515
196/196 - 38s - loss: 16.9742 - MinusLogProbMetric: 16.9742 - val_loss: 17.6739 - val_MinusLogProbMetric: 17.6739 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 257/1000
2023-09-28 00:54:09.342 
Epoch 257/1000 
	 loss: 16.9660, MinusLogProbMetric: 16.9660, val_loss: 17.3073, val_MinusLogProbMetric: 17.3073

Epoch 257: val_loss did not improve from 17.17515
196/196 - 38s - loss: 16.9660 - MinusLogProbMetric: 16.9660 - val_loss: 17.3073 - val_MinusLogProbMetric: 17.3073 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 258/1000
2023-09-28 00:54:47.660 
Epoch 258/1000 
	 loss: 17.0049, MinusLogProbMetric: 17.0049, val_loss: 17.5197, val_MinusLogProbMetric: 17.5197

Epoch 258: val_loss did not improve from 17.17515
196/196 - 38s - loss: 17.0049 - MinusLogProbMetric: 17.0049 - val_loss: 17.5197 - val_MinusLogProbMetric: 17.5197 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 259/1000
2023-09-28 00:55:25.925 
Epoch 259/1000 
	 loss: 16.9932, MinusLogProbMetric: 16.9932, val_loss: 18.1551, val_MinusLogProbMetric: 18.1551

Epoch 259: val_loss did not improve from 17.17515
196/196 - 38s - loss: 16.9932 - MinusLogProbMetric: 16.9932 - val_loss: 18.1551 - val_MinusLogProbMetric: 18.1551 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 260/1000
2023-09-28 00:56:03.973 
Epoch 260/1000 
	 loss: 16.9531, MinusLogProbMetric: 16.9531, val_loss: 17.4070, val_MinusLogProbMetric: 17.4070

Epoch 260: val_loss did not improve from 17.17515
196/196 - 38s - loss: 16.9531 - MinusLogProbMetric: 16.9531 - val_loss: 17.4070 - val_MinusLogProbMetric: 17.4070 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 261/1000
2023-09-28 00:56:42.169 
Epoch 261/1000 
	 loss: 16.9818, MinusLogProbMetric: 16.9818, val_loss: 17.4341, val_MinusLogProbMetric: 17.4341

Epoch 261: val_loss did not improve from 17.17515
196/196 - 38s - loss: 16.9818 - MinusLogProbMetric: 16.9818 - val_loss: 17.4341 - val_MinusLogProbMetric: 17.4341 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 262/1000
2023-09-28 00:57:20.757 
Epoch 262/1000 
	 loss: 17.0138, MinusLogProbMetric: 17.0138, val_loss: 17.2127, val_MinusLogProbMetric: 17.2127

Epoch 262: val_loss did not improve from 17.17515
196/196 - 39s - loss: 17.0138 - MinusLogProbMetric: 17.0138 - val_loss: 17.2127 - val_MinusLogProbMetric: 17.2127 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 263/1000
2023-09-28 00:57:58.818 
Epoch 263/1000 
	 loss: 16.9366, MinusLogProbMetric: 16.9366, val_loss: 17.2577, val_MinusLogProbMetric: 17.2577

Epoch 263: val_loss did not improve from 17.17515
196/196 - 38s - loss: 16.9366 - MinusLogProbMetric: 16.9366 - val_loss: 17.2577 - val_MinusLogProbMetric: 17.2577 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 264/1000
2023-09-28 00:58:37.039 
Epoch 264/1000 
	 loss: 16.9799, MinusLogProbMetric: 16.9799, val_loss: 17.3279, val_MinusLogProbMetric: 17.3279

Epoch 264: val_loss did not improve from 17.17515
196/196 - 38s - loss: 16.9799 - MinusLogProbMetric: 16.9799 - val_loss: 17.3279 - val_MinusLogProbMetric: 17.3279 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 265/1000
2023-09-28 00:59:15.221 
Epoch 265/1000 
	 loss: 16.9412, MinusLogProbMetric: 16.9412, val_loss: 17.4396, val_MinusLogProbMetric: 17.4396

Epoch 265: val_loss did not improve from 17.17515
196/196 - 38s - loss: 16.9412 - MinusLogProbMetric: 16.9412 - val_loss: 17.4396 - val_MinusLogProbMetric: 17.4396 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 266/1000
2023-09-28 00:59:53.823 
Epoch 266/1000 
	 loss: 16.9778, MinusLogProbMetric: 16.9778, val_loss: 17.3210, val_MinusLogProbMetric: 17.3210

Epoch 266: val_loss did not improve from 17.17515
196/196 - 39s - loss: 16.9778 - MinusLogProbMetric: 16.9778 - val_loss: 17.3210 - val_MinusLogProbMetric: 17.3210 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 267/1000
2023-09-28 01:00:32.215 
Epoch 267/1000 
	 loss: 16.7098, MinusLogProbMetric: 16.7098, val_loss: 17.0835, val_MinusLogProbMetric: 17.0835

Epoch 267: val_loss improved from 17.17515 to 17.08347, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.7098 - MinusLogProbMetric: 16.7098 - val_loss: 17.0835 - val_MinusLogProbMetric: 17.0835 - lr: 5.0000e-04 - 39s/epoch - 200ms/step
Epoch 268/1000
2023-09-28 01:01:10.981 
Epoch 268/1000 
	 loss: 16.7102, MinusLogProbMetric: 16.7102, val_loss: 17.1504, val_MinusLogProbMetric: 17.1504

Epoch 268: val_loss did not improve from 17.08347
196/196 - 38s - loss: 16.7102 - MinusLogProbMetric: 16.7102 - val_loss: 17.1504 - val_MinusLogProbMetric: 17.1504 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 269/1000
2023-09-28 01:01:49.033 
Epoch 269/1000 
	 loss: 16.7244, MinusLogProbMetric: 16.7244, val_loss: 17.1394, val_MinusLogProbMetric: 17.1394

Epoch 269: val_loss did not improve from 17.08347
196/196 - 38s - loss: 16.7244 - MinusLogProbMetric: 16.7244 - val_loss: 17.1394 - val_MinusLogProbMetric: 17.1394 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 270/1000
2023-09-28 01:02:27.004 
Epoch 270/1000 
	 loss: 16.7338, MinusLogProbMetric: 16.7338, val_loss: 17.0816, val_MinusLogProbMetric: 17.0816

Epoch 270: val_loss improved from 17.08347 to 17.08162, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.7338 - MinusLogProbMetric: 16.7338 - val_loss: 17.0816 - val_MinusLogProbMetric: 17.0816 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 271/1000
2023-09-28 01:03:05.915 
Epoch 271/1000 
	 loss: 16.7421, MinusLogProbMetric: 16.7421, val_loss: 17.0608, val_MinusLogProbMetric: 17.0608

Epoch 271: val_loss improved from 17.08162 to 17.06082, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.7421 - MinusLogProbMetric: 16.7421 - val_loss: 17.0608 - val_MinusLogProbMetric: 17.0608 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 272/1000
2023-09-28 01:03:44.824 
Epoch 272/1000 
	 loss: 16.7355, MinusLogProbMetric: 16.7355, val_loss: 17.1392, val_MinusLogProbMetric: 17.1392

Epoch 272: val_loss did not improve from 17.06082
196/196 - 38s - loss: 16.7355 - MinusLogProbMetric: 16.7355 - val_loss: 17.1392 - val_MinusLogProbMetric: 17.1392 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 273/1000
2023-09-28 01:04:23.225 
Epoch 273/1000 
	 loss: 16.7260, MinusLogProbMetric: 16.7260, val_loss: 17.0945, val_MinusLogProbMetric: 17.0945

Epoch 273: val_loss did not improve from 17.06082
196/196 - 38s - loss: 16.7260 - MinusLogProbMetric: 16.7260 - val_loss: 17.0945 - val_MinusLogProbMetric: 17.0945 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 274/1000
2023-09-28 01:05:01.159 
Epoch 274/1000 
	 loss: 16.7177, MinusLogProbMetric: 16.7177, val_loss: 17.0578, val_MinusLogProbMetric: 17.0578

Epoch 274: val_loss improved from 17.06082 to 17.05779, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.7177 - MinusLogProbMetric: 16.7177 - val_loss: 17.0578 - val_MinusLogProbMetric: 17.0578 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 275/1000
2023-09-28 01:05:40.135 
Epoch 275/1000 
	 loss: 16.7331, MinusLogProbMetric: 16.7331, val_loss: 17.2126, val_MinusLogProbMetric: 17.2126

Epoch 275: val_loss did not improve from 17.05779
196/196 - 38s - loss: 16.7331 - MinusLogProbMetric: 16.7331 - val_loss: 17.2126 - val_MinusLogProbMetric: 17.2126 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 276/1000
2023-09-28 01:06:18.349 
Epoch 276/1000 
	 loss: 16.7603, MinusLogProbMetric: 16.7603, val_loss: 17.0688, val_MinusLogProbMetric: 17.0688

Epoch 276: val_loss did not improve from 17.05779
196/196 - 38s - loss: 16.7603 - MinusLogProbMetric: 16.7603 - val_loss: 17.0688 - val_MinusLogProbMetric: 17.0688 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 277/1000
2023-09-28 01:06:56.713 
Epoch 277/1000 
	 loss: 16.7320, MinusLogProbMetric: 16.7320, val_loss: 17.1141, val_MinusLogProbMetric: 17.1141

Epoch 277: val_loss did not improve from 17.05779
196/196 - 38s - loss: 16.7320 - MinusLogProbMetric: 16.7320 - val_loss: 17.1141 - val_MinusLogProbMetric: 17.1141 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 278/1000
2023-09-28 01:07:35.154 
Epoch 278/1000 
	 loss: 16.7000, MinusLogProbMetric: 16.7000, val_loss: 17.1029, val_MinusLogProbMetric: 17.1029

Epoch 278: val_loss did not improve from 17.05779
196/196 - 38s - loss: 16.7000 - MinusLogProbMetric: 16.7000 - val_loss: 17.1029 - val_MinusLogProbMetric: 17.1029 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 279/1000
2023-09-28 01:08:13.554 
Epoch 279/1000 
	 loss: 16.7117, MinusLogProbMetric: 16.7117, val_loss: 17.0896, val_MinusLogProbMetric: 17.0896

Epoch 279: val_loss did not improve from 17.05779
196/196 - 38s - loss: 16.7117 - MinusLogProbMetric: 16.7117 - val_loss: 17.0896 - val_MinusLogProbMetric: 17.0896 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 280/1000
2023-09-28 01:08:51.756 
Epoch 280/1000 
	 loss: 16.7259, MinusLogProbMetric: 16.7259, val_loss: 17.4775, val_MinusLogProbMetric: 17.4775

Epoch 280: val_loss did not improve from 17.05779
196/196 - 38s - loss: 16.7259 - MinusLogProbMetric: 16.7259 - val_loss: 17.4775 - val_MinusLogProbMetric: 17.4775 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 281/1000
2023-09-28 01:09:30.196 
Epoch 281/1000 
	 loss: 16.7183, MinusLogProbMetric: 16.7183, val_loss: 17.0587, val_MinusLogProbMetric: 17.0587

Epoch 281: val_loss did not improve from 17.05779
196/196 - 38s - loss: 16.7183 - MinusLogProbMetric: 16.7183 - val_loss: 17.0587 - val_MinusLogProbMetric: 17.0587 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 282/1000
2023-09-28 01:10:08.372 
Epoch 282/1000 
	 loss: 16.7310, MinusLogProbMetric: 16.7310, val_loss: 17.0403, val_MinusLogProbMetric: 17.0403

Epoch 282: val_loss improved from 17.05779 to 17.04032, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.7310 - MinusLogProbMetric: 16.7310 - val_loss: 17.0403 - val_MinusLogProbMetric: 17.0403 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 283/1000
2023-09-28 01:10:47.480 
Epoch 283/1000 
	 loss: 16.7012, MinusLogProbMetric: 16.7012, val_loss: 17.1691, val_MinusLogProbMetric: 17.1691

Epoch 283: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7012 - MinusLogProbMetric: 16.7012 - val_loss: 17.1691 - val_MinusLogProbMetric: 17.1691 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 284/1000
2023-09-28 01:11:25.503 
Epoch 284/1000 
	 loss: 16.7440, MinusLogProbMetric: 16.7440, val_loss: 17.0626, val_MinusLogProbMetric: 17.0626

Epoch 284: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7440 - MinusLogProbMetric: 16.7440 - val_loss: 17.0626 - val_MinusLogProbMetric: 17.0626 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 285/1000
2023-09-28 01:12:03.613 
Epoch 285/1000 
	 loss: 16.7210, MinusLogProbMetric: 16.7210, val_loss: 17.0433, val_MinusLogProbMetric: 17.0433

Epoch 285: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7210 - MinusLogProbMetric: 16.7210 - val_loss: 17.0433 - val_MinusLogProbMetric: 17.0433 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 286/1000
2023-09-28 01:12:41.637 
Epoch 286/1000 
	 loss: 16.7517, MinusLogProbMetric: 16.7517, val_loss: 17.0587, val_MinusLogProbMetric: 17.0587

Epoch 286: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7517 - MinusLogProbMetric: 16.7517 - val_loss: 17.0587 - val_MinusLogProbMetric: 17.0587 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 287/1000
2023-09-28 01:13:20.229 
Epoch 287/1000 
	 loss: 16.7040, MinusLogProbMetric: 16.7040, val_loss: 17.1238, val_MinusLogProbMetric: 17.1238

Epoch 287: val_loss did not improve from 17.04032
196/196 - 39s - loss: 16.7040 - MinusLogProbMetric: 16.7040 - val_loss: 17.1238 - val_MinusLogProbMetric: 17.1238 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 288/1000
2023-09-28 01:13:58.324 
Epoch 288/1000 
	 loss: 16.7243, MinusLogProbMetric: 16.7243, val_loss: 17.0618, val_MinusLogProbMetric: 17.0618

Epoch 288: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7243 - MinusLogProbMetric: 16.7243 - val_loss: 17.0618 - val_MinusLogProbMetric: 17.0618 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 289/1000
2023-09-28 01:14:36.674 
Epoch 289/1000 
	 loss: 16.7346, MinusLogProbMetric: 16.7346, val_loss: 17.2073, val_MinusLogProbMetric: 17.2073

Epoch 289: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7346 - MinusLogProbMetric: 16.7346 - val_loss: 17.2073 - val_MinusLogProbMetric: 17.2073 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 290/1000
2023-09-28 01:15:14.811 
Epoch 290/1000 
	 loss: 16.7542, MinusLogProbMetric: 16.7542, val_loss: 17.2932, val_MinusLogProbMetric: 17.2932

Epoch 290: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7542 - MinusLogProbMetric: 16.7542 - val_loss: 17.2932 - val_MinusLogProbMetric: 17.2932 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 291/1000
2023-09-28 01:15:53.144 
Epoch 291/1000 
	 loss: 16.7028, MinusLogProbMetric: 16.7028, val_loss: 17.0470, val_MinusLogProbMetric: 17.0470

Epoch 291: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7028 - MinusLogProbMetric: 16.7028 - val_loss: 17.0470 - val_MinusLogProbMetric: 17.0470 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 292/1000
2023-09-28 01:16:31.271 
Epoch 292/1000 
	 loss: 16.7415, MinusLogProbMetric: 16.7415, val_loss: 17.3133, val_MinusLogProbMetric: 17.3133

Epoch 292: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7415 - MinusLogProbMetric: 16.7415 - val_loss: 17.3133 - val_MinusLogProbMetric: 17.3133 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 293/1000
2023-09-28 01:17:09.571 
Epoch 293/1000 
	 loss: 16.7031, MinusLogProbMetric: 16.7031, val_loss: 17.1007, val_MinusLogProbMetric: 17.1007

Epoch 293: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7031 - MinusLogProbMetric: 16.7031 - val_loss: 17.1007 - val_MinusLogProbMetric: 17.1007 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 294/1000
2023-09-28 01:17:47.979 
Epoch 294/1000 
	 loss: 16.7117, MinusLogProbMetric: 16.7117, val_loss: 17.0653, val_MinusLogProbMetric: 17.0653

Epoch 294: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7117 - MinusLogProbMetric: 16.7117 - val_loss: 17.0653 - val_MinusLogProbMetric: 17.0653 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 295/1000
2023-09-28 01:18:26.145 
Epoch 295/1000 
	 loss: 16.7414, MinusLogProbMetric: 16.7414, val_loss: 17.1185, val_MinusLogProbMetric: 17.1185

Epoch 295: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7414 - MinusLogProbMetric: 16.7414 - val_loss: 17.1185 - val_MinusLogProbMetric: 17.1185 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 296/1000
2023-09-28 01:19:04.322 
Epoch 296/1000 
	 loss: 16.7275, MinusLogProbMetric: 16.7275, val_loss: 17.1595, val_MinusLogProbMetric: 17.1595

Epoch 296: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7275 - MinusLogProbMetric: 16.7275 - val_loss: 17.1595 - val_MinusLogProbMetric: 17.1595 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 297/1000
2023-09-28 01:19:42.463 
Epoch 297/1000 
	 loss: 16.7910, MinusLogProbMetric: 16.7910, val_loss: 17.1617, val_MinusLogProbMetric: 17.1617

Epoch 297: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7910 - MinusLogProbMetric: 16.7910 - val_loss: 17.1617 - val_MinusLogProbMetric: 17.1617 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 298/1000
2023-09-28 01:20:20.581 
Epoch 298/1000 
	 loss: 16.6810, MinusLogProbMetric: 16.6810, val_loss: 17.6879, val_MinusLogProbMetric: 17.6879

Epoch 298: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.6810 - MinusLogProbMetric: 16.6810 - val_loss: 17.6879 - val_MinusLogProbMetric: 17.6879 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 299/1000
2023-09-28 01:20:58.704 
Epoch 299/1000 
	 loss: 16.7481, MinusLogProbMetric: 16.7481, val_loss: 17.1124, val_MinusLogProbMetric: 17.1124

Epoch 299: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7481 - MinusLogProbMetric: 16.7481 - val_loss: 17.1124 - val_MinusLogProbMetric: 17.1124 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 300/1000
2023-09-28 01:21:36.936 
Epoch 300/1000 
	 loss: 16.7072, MinusLogProbMetric: 16.7072, val_loss: 17.5354, val_MinusLogProbMetric: 17.5354

Epoch 300: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7072 - MinusLogProbMetric: 16.7072 - val_loss: 17.5354 - val_MinusLogProbMetric: 17.5354 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 301/1000
2023-09-28 01:22:15.404 
Epoch 301/1000 
	 loss: 16.7821, MinusLogProbMetric: 16.7821, val_loss: 17.1338, val_MinusLogProbMetric: 17.1338

Epoch 301: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7821 - MinusLogProbMetric: 16.7821 - val_loss: 17.1338 - val_MinusLogProbMetric: 17.1338 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 302/1000
2023-09-28 01:22:53.905 
Epoch 302/1000 
	 loss: 16.6997, MinusLogProbMetric: 16.6997, val_loss: 17.4912, val_MinusLogProbMetric: 17.4912

Epoch 302: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.6997 - MinusLogProbMetric: 16.6997 - val_loss: 17.4912 - val_MinusLogProbMetric: 17.4912 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 303/1000
2023-09-28 01:23:31.877 
Epoch 303/1000 
	 loss: 16.6981, MinusLogProbMetric: 16.6981, val_loss: 17.0982, val_MinusLogProbMetric: 17.0982

Epoch 303: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.6981 - MinusLogProbMetric: 16.6981 - val_loss: 17.0982 - val_MinusLogProbMetric: 17.0982 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 304/1000
2023-09-28 01:24:09.765 
Epoch 304/1000 
	 loss: 16.7152, MinusLogProbMetric: 16.7152, val_loss: 17.0557, val_MinusLogProbMetric: 17.0557

Epoch 304: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7152 - MinusLogProbMetric: 16.7152 - val_loss: 17.0557 - val_MinusLogProbMetric: 17.0557 - lr: 5.0000e-04 - 38s/epoch - 193ms/step
Epoch 305/1000
2023-09-28 01:24:47.854 
Epoch 305/1000 
	 loss: 16.6970, MinusLogProbMetric: 16.6970, val_loss: 17.1199, val_MinusLogProbMetric: 17.1199

Epoch 305: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.6970 - MinusLogProbMetric: 16.6970 - val_loss: 17.1199 - val_MinusLogProbMetric: 17.1199 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 306/1000
2023-09-28 01:25:25.863 
Epoch 306/1000 
	 loss: 16.7271, MinusLogProbMetric: 16.7271, val_loss: 17.1542, val_MinusLogProbMetric: 17.1542

Epoch 306: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7271 - MinusLogProbMetric: 16.7271 - val_loss: 17.1542 - val_MinusLogProbMetric: 17.1542 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 307/1000
2023-09-28 01:26:03.863 
Epoch 307/1000 
	 loss: 16.6961, MinusLogProbMetric: 16.6961, val_loss: 17.4473, val_MinusLogProbMetric: 17.4473

Epoch 307: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.6961 - MinusLogProbMetric: 16.6961 - val_loss: 17.4473 - val_MinusLogProbMetric: 17.4473 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 308/1000
2023-09-28 01:26:41.710 
Epoch 308/1000 
	 loss: 16.6979, MinusLogProbMetric: 16.6979, val_loss: 17.2406, val_MinusLogProbMetric: 17.2406

Epoch 308: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.6979 - MinusLogProbMetric: 16.6979 - val_loss: 17.2406 - val_MinusLogProbMetric: 17.2406 - lr: 5.0000e-04 - 38s/epoch - 193ms/step
Epoch 309/1000
2023-09-28 01:27:19.950 
Epoch 309/1000 
	 loss: 16.7152, MinusLogProbMetric: 16.7152, val_loss: 17.1159, val_MinusLogProbMetric: 17.1159

Epoch 309: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7152 - MinusLogProbMetric: 16.7152 - val_loss: 17.1159 - val_MinusLogProbMetric: 17.1159 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 310/1000
2023-09-28 01:27:58.412 
Epoch 310/1000 
	 loss: 16.7305, MinusLogProbMetric: 16.7305, val_loss: 17.1076, val_MinusLogProbMetric: 17.1076

Epoch 310: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7305 - MinusLogProbMetric: 16.7305 - val_loss: 17.1076 - val_MinusLogProbMetric: 17.1076 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 311/1000
2023-09-28 01:28:36.282 
Epoch 311/1000 
	 loss: 16.6893, MinusLogProbMetric: 16.6893, val_loss: 17.1473, val_MinusLogProbMetric: 17.1473

Epoch 311: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.6893 - MinusLogProbMetric: 16.6893 - val_loss: 17.1473 - val_MinusLogProbMetric: 17.1473 - lr: 5.0000e-04 - 38s/epoch - 193ms/step
Epoch 312/1000
2023-09-28 01:29:14.827 
Epoch 312/1000 
	 loss: 16.6771, MinusLogProbMetric: 16.6771, val_loss: 17.2447, val_MinusLogProbMetric: 17.2447

Epoch 312: val_loss did not improve from 17.04032
196/196 - 39s - loss: 16.6771 - MinusLogProbMetric: 16.6771 - val_loss: 17.2447 - val_MinusLogProbMetric: 17.2447 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 313/1000
2023-09-28 01:29:52.837 
Epoch 313/1000 
	 loss: 16.7404, MinusLogProbMetric: 16.7404, val_loss: 17.1612, val_MinusLogProbMetric: 17.1612

Epoch 313: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7404 - MinusLogProbMetric: 16.7404 - val_loss: 17.1612 - val_MinusLogProbMetric: 17.1612 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 314/1000
2023-09-28 01:30:31.218 
Epoch 314/1000 
	 loss: 16.6918, MinusLogProbMetric: 16.6918, val_loss: 17.1158, val_MinusLogProbMetric: 17.1158

Epoch 314: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.6918 - MinusLogProbMetric: 16.6918 - val_loss: 17.1158 - val_MinusLogProbMetric: 17.1158 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 315/1000
2023-09-28 01:31:09.451 
Epoch 315/1000 
	 loss: 16.7049, MinusLogProbMetric: 16.7049, val_loss: 17.1169, val_MinusLogProbMetric: 17.1169

Epoch 315: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7049 - MinusLogProbMetric: 16.7049 - val_loss: 17.1169 - val_MinusLogProbMetric: 17.1169 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 316/1000
2023-09-28 01:31:47.620 
Epoch 316/1000 
	 loss: 16.7140, MinusLogProbMetric: 16.7140, val_loss: 17.2226, val_MinusLogProbMetric: 17.2226

Epoch 316: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7140 - MinusLogProbMetric: 16.7140 - val_loss: 17.2226 - val_MinusLogProbMetric: 17.2226 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 317/1000
2023-09-28 01:32:25.184 
Epoch 317/1000 
	 loss: 16.7127, MinusLogProbMetric: 16.7127, val_loss: 17.1637, val_MinusLogProbMetric: 17.1637

Epoch 317: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7127 - MinusLogProbMetric: 16.7127 - val_loss: 17.1637 - val_MinusLogProbMetric: 17.1637 - lr: 5.0000e-04 - 38s/epoch - 192ms/step
Epoch 318/1000
2023-09-28 01:33:03.493 
Epoch 318/1000 
	 loss: 16.7077, MinusLogProbMetric: 16.7077, val_loss: 17.3130, val_MinusLogProbMetric: 17.3130

Epoch 318: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7077 - MinusLogProbMetric: 16.7077 - val_loss: 17.3130 - val_MinusLogProbMetric: 17.3130 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 319/1000
2023-09-28 01:33:41.514 
Epoch 319/1000 
	 loss: 16.6959, MinusLogProbMetric: 16.6959, val_loss: 17.1208, val_MinusLogProbMetric: 17.1208

Epoch 319: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.6959 - MinusLogProbMetric: 16.6959 - val_loss: 17.1208 - val_MinusLogProbMetric: 17.1208 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 320/1000
2023-09-28 01:34:19.944 
Epoch 320/1000 
	 loss: 16.6979, MinusLogProbMetric: 16.6979, val_loss: 17.1619, val_MinusLogProbMetric: 17.1619

Epoch 320: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.6979 - MinusLogProbMetric: 16.6979 - val_loss: 17.1619 - val_MinusLogProbMetric: 17.1619 - lr: 5.0000e-04 - 38s/epoch - 196ms/step
Epoch 321/1000
2023-09-28 01:34:58.129 
Epoch 321/1000 
	 loss: 16.6859, MinusLogProbMetric: 16.6859, val_loss: 17.0743, val_MinusLogProbMetric: 17.0743

Epoch 321: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.6859 - MinusLogProbMetric: 16.6859 - val_loss: 17.0743 - val_MinusLogProbMetric: 17.0743 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 322/1000
2023-09-28 01:35:36.337 
Epoch 322/1000 
	 loss: 16.6920, MinusLogProbMetric: 16.6920, val_loss: 17.1057, val_MinusLogProbMetric: 17.1057

Epoch 322: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.6920 - MinusLogProbMetric: 16.6920 - val_loss: 17.1057 - val_MinusLogProbMetric: 17.1057 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 323/1000
2023-09-28 01:36:14.494 
Epoch 323/1000 
	 loss: 16.6987, MinusLogProbMetric: 16.6987, val_loss: 17.1449, val_MinusLogProbMetric: 17.1449

Epoch 323: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.6987 - MinusLogProbMetric: 16.6987 - val_loss: 17.1449 - val_MinusLogProbMetric: 17.1449 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 324/1000
2023-09-28 01:36:52.102 
Epoch 324/1000 
	 loss: 16.7026, MinusLogProbMetric: 16.7026, val_loss: 17.4039, val_MinusLogProbMetric: 17.4039

Epoch 324: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7026 - MinusLogProbMetric: 16.7026 - val_loss: 17.4039 - val_MinusLogProbMetric: 17.4039 - lr: 5.0000e-04 - 38s/epoch - 192ms/step
Epoch 325/1000
2023-09-28 01:37:30.358 
Epoch 325/1000 
	 loss: 16.7155, MinusLogProbMetric: 16.7155, val_loss: 17.0615, val_MinusLogProbMetric: 17.0615

Epoch 325: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7155 - MinusLogProbMetric: 16.7155 - val_loss: 17.0615 - val_MinusLogProbMetric: 17.0615 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 326/1000
2023-09-28 01:38:08.530 
Epoch 326/1000 
	 loss: 16.7006, MinusLogProbMetric: 16.7006, val_loss: 17.1537, val_MinusLogProbMetric: 17.1537

Epoch 326: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7006 - MinusLogProbMetric: 16.7006 - val_loss: 17.1537 - val_MinusLogProbMetric: 17.1537 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 327/1000
2023-09-28 01:38:47.214 
Epoch 327/1000 
	 loss: 16.6804, MinusLogProbMetric: 16.6804, val_loss: 17.0655, val_MinusLogProbMetric: 17.0655

Epoch 327: val_loss did not improve from 17.04032
196/196 - 39s - loss: 16.6804 - MinusLogProbMetric: 16.6804 - val_loss: 17.0655 - val_MinusLogProbMetric: 17.0655 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 328/1000
2023-09-28 01:39:25.268 
Epoch 328/1000 
	 loss: 16.6969, MinusLogProbMetric: 16.6969, val_loss: 17.1927, val_MinusLogProbMetric: 17.1927

Epoch 328: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.6969 - MinusLogProbMetric: 16.6969 - val_loss: 17.1927 - val_MinusLogProbMetric: 17.1927 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 329/1000
2023-09-28 01:40:02.835 
Epoch 329/1000 
	 loss: 16.7106, MinusLogProbMetric: 16.7106, val_loss: 17.0809, val_MinusLogProbMetric: 17.0809

Epoch 329: val_loss did not improve from 17.04032
196/196 - 38s - loss: 16.7106 - MinusLogProbMetric: 16.7106 - val_loss: 17.0809 - val_MinusLogProbMetric: 17.0809 - lr: 5.0000e-04 - 38s/epoch - 192ms/step
Epoch 330/1000
2023-09-28 01:40:38.064 
Epoch 330/1000 
	 loss: 16.6979, MinusLogProbMetric: 16.6979, val_loss: 17.1254, val_MinusLogProbMetric: 17.1254

Epoch 330: val_loss did not improve from 17.04032
196/196 - 35s - loss: 16.6979 - MinusLogProbMetric: 16.6979 - val_loss: 17.1254 - val_MinusLogProbMetric: 17.1254 - lr: 5.0000e-04 - 35s/epoch - 180ms/step
Epoch 331/1000
2023-09-28 01:41:12.217 
Epoch 331/1000 
	 loss: 16.7245, MinusLogProbMetric: 16.7245, val_loss: 17.0747, val_MinusLogProbMetric: 17.0747

Epoch 331: val_loss did not improve from 17.04032
196/196 - 34s - loss: 16.7245 - MinusLogProbMetric: 16.7245 - val_loss: 17.0747 - val_MinusLogProbMetric: 17.0747 - lr: 5.0000e-04 - 34s/epoch - 174ms/step
Epoch 332/1000
2023-09-28 01:41:46.472 
Epoch 332/1000 
	 loss: 16.6965, MinusLogProbMetric: 16.6965, val_loss: 17.1109, val_MinusLogProbMetric: 17.1109

Epoch 332: val_loss did not improve from 17.04032
196/196 - 34s - loss: 16.6965 - MinusLogProbMetric: 16.6965 - val_loss: 17.1109 - val_MinusLogProbMetric: 17.1109 - lr: 5.0000e-04 - 34s/epoch - 175ms/step
Epoch 333/1000
2023-09-28 01:42:24.988 
Epoch 333/1000 
	 loss: 16.5743, MinusLogProbMetric: 16.5743, val_loss: 17.0541, val_MinusLogProbMetric: 17.0541

Epoch 333: val_loss did not improve from 17.04032
196/196 - 39s - loss: 16.5743 - MinusLogProbMetric: 16.5743 - val_loss: 17.0541 - val_MinusLogProbMetric: 17.0541 - lr: 2.5000e-04 - 39s/epoch - 196ms/step
Epoch 334/1000
2023-09-28 01:43:00.289 
Epoch 334/1000 
	 loss: 16.5782, MinusLogProbMetric: 16.5782, val_loss: 16.9974, val_MinusLogProbMetric: 16.9974

Epoch 334: val_loss improved from 17.04032 to 16.99743, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 36s - loss: 16.5782 - MinusLogProbMetric: 16.5782 - val_loss: 16.9974 - val_MinusLogProbMetric: 16.9974 - lr: 2.5000e-04 - 36s/epoch - 183ms/step
Epoch 335/1000
2023-09-28 01:43:34.749 
Epoch 335/1000 
	 loss: 16.5738, MinusLogProbMetric: 16.5738, val_loss: 17.0457, val_MinusLogProbMetric: 17.0457

Epoch 335: val_loss did not improve from 16.99743
196/196 - 34s - loss: 16.5738 - MinusLogProbMetric: 16.5738 - val_loss: 17.0457 - val_MinusLogProbMetric: 17.0457 - lr: 2.5000e-04 - 34s/epoch - 173ms/step
Epoch 336/1000
2023-09-28 01:44:09.121 
Epoch 336/1000 
	 loss: 16.6005, MinusLogProbMetric: 16.6005, val_loss: 17.0185, val_MinusLogProbMetric: 17.0185

Epoch 336: val_loss did not improve from 16.99743
196/196 - 34s - loss: 16.6005 - MinusLogProbMetric: 16.6005 - val_loss: 17.0185 - val_MinusLogProbMetric: 17.0185 - lr: 2.5000e-04 - 34s/epoch - 175ms/step
Epoch 337/1000
2023-09-28 01:44:47.254 
Epoch 337/1000 
	 loss: 16.5705, MinusLogProbMetric: 16.5705, val_loss: 17.0256, val_MinusLogProbMetric: 17.0256

Epoch 337: val_loss did not improve from 16.99743
196/196 - 38s - loss: 16.5705 - MinusLogProbMetric: 16.5705 - val_loss: 17.0256 - val_MinusLogProbMetric: 17.0256 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 338/1000
2023-09-28 01:45:25.314 
Epoch 338/1000 
	 loss: 16.5646, MinusLogProbMetric: 16.5646, val_loss: 17.0110, val_MinusLogProbMetric: 17.0110

Epoch 338: val_loss did not improve from 16.99743
196/196 - 38s - loss: 16.5646 - MinusLogProbMetric: 16.5646 - val_loss: 17.0110 - val_MinusLogProbMetric: 17.0110 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 339/1000
2023-09-28 01:46:03.132 
Epoch 339/1000 
	 loss: 16.5739, MinusLogProbMetric: 16.5739, val_loss: 17.0505, val_MinusLogProbMetric: 17.0505

Epoch 339: val_loss did not improve from 16.99743
196/196 - 38s - loss: 16.5739 - MinusLogProbMetric: 16.5739 - val_loss: 17.0505 - val_MinusLogProbMetric: 17.0505 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 340/1000
2023-09-28 01:46:41.081 
Epoch 340/1000 
	 loss: 16.5829, MinusLogProbMetric: 16.5829, val_loss: 17.0617, val_MinusLogProbMetric: 17.0617

Epoch 340: val_loss did not improve from 16.99743
196/196 - 38s - loss: 16.5829 - MinusLogProbMetric: 16.5829 - val_loss: 17.0617 - val_MinusLogProbMetric: 17.0617 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 341/1000
2023-09-28 01:47:19.370 
Epoch 341/1000 
	 loss: 16.6016, MinusLogProbMetric: 16.6016, val_loss: 17.0072, val_MinusLogProbMetric: 17.0072

Epoch 341: val_loss did not improve from 16.99743
196/196 - 38s - loss: 16.6016 - MinusLogProbMetric: 16.6016 - val_loss: 17.0072 - val_MinusLogProbMetric: 17.0072 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 342/1000
2023-09-28 01:47:57.478 
Epoch 342/1000 
	 loss: 16.5691, MinusLogProbMetric: 16.5691, val_loss: 17.0176, val_MinusLogProbMetric: 17.0176

Epoch 342: val_loss did not improve from 16.99743
196/196 - 38s - loss: 16.5691 - MinusLogProbMetric: 16.5691 - val_loss: 17.0176 - val_MinusLogProbMetric: 17.0176 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 343/1000
2023-09-28 01:48:35.567 
Epoch 343/1000 
	 loss: 16.5692, MinusLogProbMetric: 16.5692, val_loss: 17.0256, val_MinusLogProbMetric: 17.0256

Epoch 343: val_loss did not improve from 16.99743
196/196 - 38s - loss: 16.5692 - MinusLogProbMetric: 16.5692 - val_loss: 17.0256 - val_MinusLogProbMetric: 17.0256 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 344/1000
2023-09-28 01:49:13.454 
Epoch 344/1000 
	 loss: 16.5989, MinusLogProbMetric: 16.5989, val_loss: 17.1161, val_MinusLogProbMetric: 17.1161

Epoch 344: val_loss did not improve from 16.99743
196/196 - 38s - loss: 16.5989 - MinusLogProbMetric: 16.5989 - val_loss: 17.1161 - val_MinusLogProbMetric: 17.1161 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 345/1000
2023-09-28 01:49:51.755 
Epoch 345/1000 
	 loss: 16.5840, MinusLogProbMetric: 16.5840, val_loss: 17.0169, val_MinusLogProbMetric: 17.0169

Epoch 345: val_loss did not improve from 16.99743
196/196 - 38s - loss: 16.5840 - MinusLogProbMetric: 16.5840 - val_loss: 17.0169 - val_MinusLogProbMetric: 17.0169 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 346/1000
2023-09-28 01:50:29.900 
Epoch 346/1000 
	 loss: 16.5777, MinusLogProbMetric: 16.5777, val_loss: 17.0455, val_MinusLogProbMetric: 17.0455

Epoch 346: val_loss did not improve from 16.99743
196/196 - 38s - loss: 16.5777 - MinusLogProbMetric: 16.5777 - val_loss: 17.0455 - val_MinusLogProbMetric: 17.0455 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 347/1000
2023-09-28 01:51:08.313 
Epoch 347/1000 
	 loss: 16.6004, MinusLogProbMetric: 16.6004, val_loss: 16.9924, val_MinusLogProbMetric: 16.9924

Epoch 347: val_loss improved from 16.99743 to 16.99240, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.6004 - MinusLogProbMetric: 16.6004 - val_loss: 16.9924 - val_MinusLogProbMetric: 16.9924 - lr: 2.5000e-04 - 39s/epoch - 200ms/step
Epoch 348/1000
2023-09-28 01:51:47.310 
Epoch 348/1000 
	 loss: 16.5668, MinusLogProbMetric: 16.5668, val_loss: 17.0011, val_MinusLogProbMetric: 17.0011

Epoch 348: val_loss did not improve from 16.99240
196/196 - 38s - loss: 16.5668 - MinusLogProbMetric: 16.5668 - val_loss: 17.0011 - val_MinusLogProbMetric: 17.0011 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 349/1000
2023-09-28 01:52:25.850 
Epoch 349/1000 
	 loss: 16.6102, MinusLogProbMetric: 16.6102, val_loss: 17.1099, val_MinusLogProbMetric: 17.1099

Epoch 349: val_loss did not improve from 16.99240
196/196 - 39s - loss: 16.6102 - MinusLogProbMetric: 16.6102 - val_loss: 17.1099 - val_MinusLogProbMetric: 17.1099 - lr: 2.5000e-04 - 39s/epoch - 197ms/step
Epoch 350/1000
2023-09-28 01:53:04.171 
Epoch 350/1000 
	 loss: 16.5632, MinusLogProbMetric: 16.5632, val_loss: 17.0349, val_MinusLogProbMetric: 17.0349

Epoch 350: val_loss did not improve from 16.99240
196/196 - 38s - loss: 16.5632 - MinusLogProbMetric: 16.5632 - val_loss: 17.0349 - val_MinusLogProbMetric: 17.0349 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 351/1000
2023-09-28 01:53:42.290 
Epoch 351/1000 
	 loss: 16.5861, MinusLogProbMetric: 16.5861, val_loss: 17.0351, val_MinusLogProbMetric: 17.0351

Epoch 351: val_loss did not improve from 16.99240
196/196 - 38s - loss: 16.5861 - MinusLogProbMetric: 16.5861 - val_loss: 17.0351 - val_MinusLogProbMetric: 17.0351 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 352/1000
2023-09-28 01:54:20.536 
Epoch 352/1000 
	 loss: 16.5777, MinusLogProbMetric: 16.5777, val_loss: 16.9880, val_MinusLogProbMetric: 16.9880

Epoch 352: val_loss improved from 16.99240 to 16.98802, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.5777 - MinusLogProbMetric: 16.5777 - val_loss: 16.9880 - val_MinusLogProbMetric: 16.9880 - lr: 2.5000e-04 - 39s/epoch - 198ms/step
Epoch 353/1000
2023-09-28 01:54:59.581 
Epoch 353/1000 
	 loss: 16.5665, MinusLogProbMetric: 16.5665, val_loss: 17.0185, val_MinusLogProbMetric: 17.0185

Epoch 353: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5665 - MinusLogProbMetric: 16.5665 - val_loss: 17.0185 - val_MinusLogProbMetric: 17.0185 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 354/1000
2023-09-28 01:55:37.586 
Epoch 354/1000 
	 loss: 16.5710, MinusLogProbMetric: 16.5710, val_loss: 17.0009, val_MinusLogProbMetric: 17.0009

Epoch 354: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5710 - MinusLogProbMetric: 16.5710 - val_loss: 17.0009 - val_MinusLogProbMetric: 17.0009 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 355/1000
2023-09-28 01:56:15.873 
Epoch 355/1000 
	 loss: 16.5785, MinusLogProbMetric: 16.5785, val_loss: 17.0473, val_MinusLogProbMetric: 17.0473

Epoch 355: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5785 - MinusLogProbMetric: 16.5785 - val_loss: 17.0473 - val_MinusLogProbMetric: 17.0473 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 356/1000
2023-09-28 01:56:53.707 
Epoch 356/1000 
	 loss: 16.5653, MinusLogProbMetric: 16.5653, val_loss: 16.9935, val_MinusLogProbMetric: 16.9935

Epoch 356: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5653 - MinusLogProbMetric: 16.5653 - val_loss: 16.9935 - val_MinusLogProbMetric: 16.9935 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 357/1000
2023-09-28 01:57:31.958 
Epoch 357/1000 
	 loss: 16.5798, MinusLogProbMetric: 16.5798, val_loss: 17.0877, val_MinusLogProbMetric: 17.0877

Epoch 357: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5798 - MinusLogProbMetric: 16.5798 - val_loss: 17.0877 - val_MinusLogProbMetric: 17.0877 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 358/1000
2023-09-28 01:58:10.307 
Epoch 358/1000 
	 loss: 16.5744, MinusLogProbMetric: 16.5744, val_loss: 17.0152, val_MinusLogProbMetric: 17.0152

Epoch 358: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5744 - MinusLogProbMetric: 16.5744 - val_loss: 17.0152 - val_MinusLogProbMetric: 17.0152 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 359/1000
2023-09-28 01:58:48.276 
Epoch 359/1000 
	 loss: 16.5701, MinusLogProbMetric: 16.5701, val_loss: 17.0197, val_MinusLogProbMetric: 17.0197

Epoch 359: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5701 - MinusLogProbMetric: 16.5701 - val_loss: 17.0197 - val_MinusLogProbMetric: 17.0197 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 360/1000
2023-09-28 01:59:26.278 
Epoch 360/1000 
	 loss: 16.5919, MinusLogProbMetric: 16.5919, val_loss: 17.0251, val_MinusLogProbMetric: 17.0251

Epoch 360: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5919 - MinusLogProbMetric: 16.5919 - val_loss: 17.0251 - val_MinusLogProbMetric: 17.0251 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 361/1000
2023-09-28 02:00:04.686 
Epoch 361/1000 
	 loss: 16.5664, MinusLogProbMetric: 16.5664, val_loss: 17.0132, val_MinusLogProbMetric: 17.0132

Epoch 361: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5664 - MinusLogProbMetric: 16.5664 - val_loss: 17.0132 - val_MinusLogProbMetric: 17.0132 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 362/1000
2023-09-28 02:00:42.646 
Epoch 362/1000 
	 loss: 16.5860, MinusLogProbMetric: 16.5860, val_loss: 17.0023, val_MinusLogProbMetric: 17.0023

Epoch 362: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5860 - MinusLogProbMetric: 16.5860 - val_loss: 17.0023 - val_MinusLogProbMetric: 17.0023 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 363/1000
2023-09-28 02:01:20.883 
Epoch 363/1000 
	 loss: 16.5561, MinusLogProbMetric: 16.5561, val_loss: 17.0359, val_MinusLogProbMetric: 17.0359

Epoch 363: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5561 - MinusLogProbMetric: 16.5561 - val_loss: 17.0359 - val_MinusLogProbMetric: 17.0359 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 364/1000
2023-09-28 02:01:59.182 
Epoch 364/1000 
	 loss: 16.5830, MinusLogProbMetric: 16.5830, val_loss: 17.0285, val_MinusLogProbMetric: 17.0285

Epoch 364: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5830 - MinusLogProbMetric: 16.5830 - val_loss: 17.0285 - val_MinusLogProbMetric: 17.0285 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 365/1000
2023-09-28 02:02:37.317 
Epoch 365/1000 
	 loss: 16.5730, MinusLogProbMetric: 16.5730, val_loss: 17.1075, val_MinusLogProbMetric: 17.1075

Epoch 365: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5730 - MinusLogProbMetric: 16.5730 - val_loss: 17.1075 - val_MinusLogProbMetric: 17.1075 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 366/1000
2023-09-28 02:03:15.389 
Epoch 366/1000 
	 loss: 16.5782, MinusLogProbMetric: 16.5782, val_loss: 16.9948, val_MinusLogProbMetric: 16.9948

Epoch 366: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5782 - MinusLogProbMetric: 16.5782 - val_loss: 16.9948 - val_MinusLogProbMetric: 16.9948 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 367/1000
2023-09-28 02:03:53.314 
Epoch 367/1000 
	 loss: 16.5814, MinusLogProbMetric: 16.5814, val_loss: 17.0165, val_MinusLogProbMetric: 17.0165

Epoch 367: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5814 - MinusLogProbMetric: 16.5814 - val_loss: 17.0165 - val_MinusLogProbMetric: 17.0165 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 368/1000
2023-09-28 02:04:31.737 
Epoch 368/1000 
	 loss: 16.5781, MinusLogProbMetric: 16.5781, val_loss: 17.1130, val_MinusLogProbMetric: 17.1130

Epoch 368: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5781 - MinusLogProbMetric: 16.5781 - val_loss: 17.1130 - val_MinusLogProbMetric: 17.1130 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 369/1000
2023-09-28 02:05:10.038 
Epoch 369/1000 
	 loss: 16.5546, MinusLogProbMetric: 16.5546, val_loss: 17.1066, val_MinusLogProbMetric: 17.1066

Epoch 369: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5546 - MinusLogProbMetric: 16.5546 - val_loss: 17.1066 - val_MinusLogProbMetric: 17.1066 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 370/1000
2023-09-28 02:05:48.651 
Epoch 370/1000 
	 loss: 16.5766, MinusLogProbMetric: 16.5766, val_loss: 17.0837, val_MinusLogProbMetric: 17.0837

Epoch 370: val_loss did not improve from 16.98802
196/196 - 39s - loss: 16.5766 - MinusLogProbMetric: 16.5766 - val_loss: 17.0837 - val_MinusLogProbMetric: 17.0837 - lr: 2.5000e-04 - 39s/epoch - 197ms/step
Epoch 371/1000
2023-09-28 02:06:26.630 
Epoch 371/1000 
	 loss: 16.5407, MinusLogProbMetric: 16.5407, val_loss: 17.1517, val_MinusLogProbMetric: 17.1517

Epoch 371: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5407 - MinusLogProbMetric: 16.5407 - val_loss: 17.1517 - val_MinusLogProbMetric: 17.1517 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 372/1000
2023-09-28 02:07:05.286 
Epoch 372/1000 
	 loss: 16.5845, MinusLogProbMetric: 16.5845, val_loss: 17.3043, val_MinusLogProbMetric: 17.3043

Epoch 372: val_loss did not improve from 16.98802
196/196 - 39s - loss: 16.5845 - MinusLogProbMetric: 16.5845 - val_loss: 17.3043 - val_MinusLogProbMetric: 17.3043 - lr: 2.5000e-04 - 39s/epoch - 197ms/step
Epoch 373/1000
2023-09-28 02:07:43.280 
Epoch 373/1000 
	 loss: 16.5748, MinusLogProbMetric: 16.5748, val_loss: 17.0585, val_MinusLogProbMetric: 17.0585

Epoch 373: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5748 - MinusLogProbMetric: 16.5748 - val_loss: 17.0585 - val_MinusLogProbMetric: 17.0585 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 374/1000
2023-09-28 02:08:21.276 
Epoch 374/1000 
	 loss: 16.5634, MinusLogProbMetric: 16.5634, val_loss: 17.0099, val_MinusLogProbMetric: 17.0099

Epoch 374: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5634 - MinusLogProbMetric: 16.5634 - val_loss: 17.0099 - val_MinusLogProbMetric: 17.0099 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 375/1000
2023-09-28 02:08:59.465 
Epoch 375/1000 
	 loss: 16.6029, MinusLogProbMetric: 16.6029, val_loss: 16.9959, val_MinusLogProbMetric: 16.9959

Epoch 375: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.6029 - MinusLogProbMetric: 16.6029 - val_loss: 16.9959 - val_MinusLogProbMetric: 16.9959 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 376/1000
2023-09-28 02:09:37.695 
Epoch 376/1000 
	 loss: 16.5715, MinusLogProbMetric: 16.5715, val_loss: 17.0375, val_MinusLogProbMetric: 17.0375

Epoch 376: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5715 - MinusLogProbMetric: 16.5715 - val_loss: 17.0375 - val_MinusLogProbMetric: 17.0375 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 377/1000
2023-09-28 02:10:15.678 
Epoch 377/1000 
	 loss: 16.5691, MinusLogProbMetric: 16.5691, val_loss: 17.0183, val_MinusLogProbMetric: 17.0183

Epoch 377: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5691 - MinusLogProbMetric: 16.5691 - val_loss: 17.0183 - val_MinusLogProbMetric: 17.0183 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 378/1000
2023-09-28 02:10:53.669 
Epoch 378/1000 
	 loss: 16.5782, MinusLogProbMetric: 16.5782, val_loss: 17.0191, val_MinusLogProbMetric: 17.0191

Epoch 378: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5782 - MinusLogProbMetric: 16.5782 - val_loss: 17.0191 - val_MinusLogProbMetric: 17.0191 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 379/1000
2023-09-28 02:11:31.957 
Epoch 379/1000 
	 loss: 16.5629, MinusLogProbMetric: 16.5629, val_loss: 16.9996, val_MinusLogProbMetric: 16.9996

Epoch 379: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5629 - MinusLogProbMetric: 16.5629 - val_loss: 16.9996 - val_MinusLogProbMetric: 16.9996 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 380/1000
2023-09-28 02:12:09.909 
Epoch 380/1000 
	 loss: 16.5582, MinusLogProbMetric: 16.5582, val_loss: 17.0591, val_MinusLogProbMetric: 17.0591

Epoch 380: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5582 - MinusLogProbMetric: 16.5582 - val_loss: 17.0591 - val_MinusLogProbMetric: 17.0591 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 381/1000
2023-09-28 02:12:47.993 
Epoch 381/1000 
	 loss: 16.5843, MinusLogProbMetric: 16.5843, val_loss: 17.0303, val_MinusLogProbMetric: 17.0303

Epoch 381: val_loss did not improve from 16.98802
196/196 - 38s - loss: 16.5843 - MinusLogProbMetric: 16.5843 - val_loss: 17.0303 - val_MinusLogProbMetric: 17.0303 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 382/1000
2023-09-28 02:13:26.202 
Epoch 382/1000 
	 loss: 16.5554, MinusLogProbMetric: 16.5554, val_loss: 16.9860, val_MinusLogProbMetric: 16.9860

Epoch 382: val_loss improved from 16.98802 to 16.98596, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.5554 - MinusLogProbMetric: 16.5554 - val_loss: 16.9860 - val_MinusLogProbMetric: 16.9860 - lr: 2.5000e-04 - 39s/epoch - 199ms/step
Epoch 383/1000
2023-09-28 02:14:04.997 
Epoch 383/1000 
	 loss: 16.5867, MinusLogProbMetric: 16.5867, val_loss: 17.1352, val_MinusLogProbMetric: 17.1352

Epoch 383: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5867 - MinusLogProbMetric: 16.5867 - val_loss: 17.1352 - val_MinusLogProbMetric: 17.1352 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 384/1000
2023-09-28 02:14:43.337 
Epoch 384/1000 
	 loss: 16.5690, MinusLogProbMetric: 16.5690, val_loss: 17.0378, val_MinusLogProbMetric: 17.0378

Epoch 384: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5690 - MinusLogProbMetric: 16.5690 - val_loss: 17.0378 - val_MinusLogProbMetric: 17.0378 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 385/1000
2023-09-28 02:15:21.451 
Epoch 385/1000 
	 loss: 16.5596, MinusLogProbMetric: 16.5596, val_loss: 17.0308, val_MinusLogProbMetric: 17.0308

Epoch 385: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5596 - MinusLogProbMetric: 16.5596 - val_loss: 17.0308 - val_MinusLogProbMetric: 17.0308 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 386/1000
2023-09-28 02:15:59.750 
Epoch 386/1000 
	 loss: 16.5779, MinusLogProbMetric: 16.5779, val_loss: 17.1111, val_MinusLogProbMetric: 17.1111

Epoch 386: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5779 - MinusLogProbMetric: 16.5779 - val_loss: 17.1111 - val_MinusLogProbMetric: 17.1111 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 387/1000
2023-09-28 02:16:38.026 
Epoch 387/1000 
	 loss: 16.5626, MinusLogProbMetric: 16.5626, val_loss: 17.0622, val_MinusLogProbMetric: 17.0622

Epoch 387: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5626 - MinusLogProbMetric: 16.5626 - val_loss: 17.0622 - val_MinusLogProbMetric: 17.0622 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 388/1000
2023-09-28 02:17:16.133 
Epoch 388/1000 
	 loss: 16.6540, MinusLogProbMetric: 16.6540, val_loss: 17.0482, val_MinusLogProbMetric: 17.0482

Epoch 388: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.6540 - MinusLogProbMetric: 16.6540 - val_loss: 17.0482 - val_MinusLogProbMetric: 17.0482 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 389/1000
2023-09-28 02:17:54.329 
Epoch 389/1000 
	 loss: 16.5504, MinusLogProbMetric: 16.5504, val_loss: 17.0153, val_MinusLogProbMetric: 17.0153

Epoch 389: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5504 - MinusLogProbMetric: 16.5504 - val_loss: 17.0153 - val_MinusLogProbMetric: 17.0153 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 390/1000
2023-09-28 02:18:32.518 
Epoch 390/1000 
	 loss: 16.5618, MinusLogProbMetric: 16.5618, val_loss: 17.1021, val_MinusLogProbMetric: 17.1021

Epoch 390: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5618 - MinusLogProbMetric: 16.5618 - val_loss: 17.1021 - val_MinusLogProbMetric: 17.1021 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 391/1000
2023-09-28 02:19:10.645 
Epoch 391/1000 
	 loss: 16.5651, MinusLogProbMetric: 16.5651, val_loss: 17.0057, val_MinusLogProbMetric: 17.0057

Epoch 391: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5651 - MinusLogProbMetric: 16.5651 - val_loss: 17.0057 - val_MinusLogProbMetric: 17.0057 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 392/1000
2023-09-28 02:19:48.678 
Epoch 392/1000 
	 loss: 16.5745, MinusLogProbMetric: 16.5745, val_loss: 17.0289, val_MinusLogProbMetric: 17.0289

Epoch 392: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5745 - MinusLogProbMetric: 16.5745 - val_loss: 17.0289 - val_MinusLogProbMetric: 17.0289 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 393/1000
2023-09-28 02:20:26.923 
Epoch 393/1000 
	 loss: 16.5723, MinusLogProbMetric: 16.5723, val_loss: 17.0620, val_MinusLogProbMetric: 17.0620

Epoch 393: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5723 - MinusLogProbMetric: 16.5723 - val_loss: 17.0620 - val_MinusLogProbMetric: 17.0620 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 394/1000
2023-09-28 02:21:04.494 
Epoch 394/1000 
	 loss: 16.5571, MinusLogProbMetric: 16.5571, val_loss: 17.0557, val_MinusLogProbMetric: 17.0557

Epoch 394: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5571 - MinusLogProbMetric: 16.5571 - val_loss: 17.0557 - val_MinusLogProbMetric: 17.0557 - lr: 2.5000e-04 - 38s/epoch - 192ms/step
Epoch 395/1000
2023-09-28 02:21:42.813 
Epoch 395/1000 
	 loss: 16.5610, MinusLogProbMetric: 16.5610, val_loss: 16.9891, val_MinusLogProbMetric: 16.9891

Epoch 395: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5610 - MinusLogProbMetric: 16.5610 - val_loss: 16.9891 - val_MinusLogProbMetric: 16.9891 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 396/1000
2023-09-28 02:22:20.872 
Epoch 396/1000 
	 loss: 16.5753, MinusLogProbMetric: 16.5753, val_loss: 17.1153, val_MinusLogProbMetric: 17.1153

Epoch 396: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5753 - MinusLogProbMetric: 16.5753 - val_loss: 17.1153 - val_MinusLogProbMetric: 17.1153 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 397/1000
2023-09-28 02:22:58.790 
Epoch 397/1000 
	 loss: 16.5644, MinusLogProbMetric: 16.5644, val_loss: 16.9871, val_MinusLogProbMetric: 16.9871

Epoch 397: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5644 - MinusLogProbMetric: 16.5644 - val_loss: 16.9871 - val_MinusLogProbMetric: 16.9871 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 398/1000
2023-09-28 02:23:36.890 
Epoch 398/1000 
	 loss: 16.5600, MinusLogProbMetric: 16.5600, val_loss: 16.9951, val_MinusLogProbMetric: 16.9951

Epoch 398: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5600 - MinusLogProbMetric: 16.5600 - val_loss: 16.9951 - val_MinusLogProbMetric: 16.9951 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 399/1000
2023-09-28 02:24:15.225 
Epoch 399/1000 
	 loss: 16.5526, MinusLogProbMetric: 16.5526, val_loss: 17.0552, val_MinusLogProbMetric: 17.0552

Epoch 399: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5526 - MinusLogProbMetric: 16.5526 - val_loss: 17.0552 - val_MinusLogProbMetric: 17.0552 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 400/1000
2023-09-28 02:24:52.999 
Epoch 400/1000 
	 loss: 16.5623, MinusLogProbMetric: 16.5623, val_loss: 17.0170, val_MinusLogProbMetric: 17.0170

Epoch 400: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5623 - MinusLogProbMetric: 16.5623 - val_loss: 17.0170 - val_MinusLogProbMetric: 17.0170 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 401/1000
2023-09-28 02:25:31.184 
Epoch 401/1000 
	 loss: 16.5681, MinusLogProbMetric: 16.5681, val_loss: 17.0286, val_MinusLogProbMetric: 17.0286

Epoch 401: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5681 - MinusLogProbMetric: 16.5681 - val_loss: 17.0286 - val_MinusLogProbMetric: 17.0286 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 402/1000
2023-09-28 02:26:09.135 
Epoch 402/1000 
	 loss: 16.5654, MinusLogProbMetric: 16.5654, val_loss: 17.0038, val_MinusLogProbMetric: 17.0038

Epoch 402: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5654 - MinusLogProbMetric: 16.5654 - val_loss: 17.0038 - val_MinusLogProbMetric: 17.0038 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 403/1000
2023-09-28 02:26:47.217 
Epoch 403/1000 
	 loss: 16.5523, MinusLogProbMetric: 16.5523, val_loss: 17.0387, val_MinusLogProbMetric: 17.0387

Epoch 403: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5523 - MinusLogProbMetric: 16.5523 - val_loss: 17.0387 - val_MinusLogProbMetric: 17.0387 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 404/1000
2023-09-28 02:27:25.526 
Epoch 404/1000 
	 loss: 16.5874, MinusLogProbMetric: 16.5874, val_loss: 17.0178, val_MinusLogProbMetric: 17.0178

Epoch 404: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5874 - MinusLogProbMetric: 16.5874 - val_loss: 17.0178 - val_MinusLogProbMetric: 17.0178 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 405/1000
2023-09-28 02:28:03.555 
Epoch 405/1000 
	 loss: 16.5494, MinusLogProbMetric: 16.5494, val_loss: 17.0192, val_MinusLogProbMetric: 17.0192

Epoch 405: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5494 - MinusLogProbMetric: 16.5494 - val_loss: 17.0192 - val_MinusLogProbMetric: 17.0192 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 406/1000
2023-09-28 02:28:41.956 
Epoch 406/1000 
	 loss: 16.5537, MinusLogProbMetric: 16.5537, val_loss: 16.9968, val_MinusLogProbMetric: 16.9968

Epoch 406: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5537 - MinusLogProbMetric: 16.5537 - val_loss: 16.9968 - val_MinusLogProbMetric: 16.9968 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 407/1000
2023-09-28 02:29:20.147 
Epoch 407/1000 
	 loss: 16.5605, MinusLogProbMetric: 16.5605, val_loss: 16.9967, val_MinusLogProbMetric: 16.9967

Epoch 407: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5605 - MinusLogProbMetric: 16.5605 - val_loss: 16.9967 - val_MinusLogProbMetric: 16.9967 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 408/1000
2023-09-28 02:29:58.497 
Epoch 408/1000 
	 loss: 16.5669, MinusLogProbMetric: 16.5669, val_loss: 17.2061, val_MinusLogProbMetric: 17.2061

Epoch 408: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5669 - MinusLogProbMetric: 16.5669 - val_loss: 17.2061 - val_MinusLogProbMetric: 17.2061 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 409/1000
2023-09-28 02:30:36.610 
Epoch 409/1000 
	 loss: 16.5589, MinusLogProbMetric: 16.5589, val_loss: 17.2793, val_MinusLogProbMetric: 17.2793

Epoch 409: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5589 - MinusLogProbMetric: 16.5589 - val_loss: 17.2793 - val_MinusLogProbMetric: 17.2793 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 410/1000
2023-09-28 02:31:14.791 
Epoch 410/1000 
	 loss: 16.5596, MinusLogProbMetric: 16.5596, val_loss: 18.0977, val_MinusLogProbMetric: 18.0977

Epoch 410: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5596 - MinusLogProbMetric: 16.5596 - val_loss: 18.0977 - val_MinusLogProbMetric: 18.0977 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 411/1000
2023-09-28 02:31:52.772 
Epoch 411/1000 
	 loss: 16.6301, MinusLogProbMetric: 16.6301, val_loss: 17.0275, val_MinusLogProbMetric: 17.0275

Epoch 411: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.6301 - MinusLogProbMetric: 16.6301 - val_loss: 17.0275 - val_MinusLogProbMetric: 17.0275 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 412/1000
2023-09-28 02:32:31.170 
Epoch 412/1000 
	 loss: 16.5604, MinusLogProbMetric: 16.5604, val_loss: 17.0190, val_MinusLogProbMetric: 17.0190

Epoch 412: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5604 - MinusLogProbMetric: 16.5604 - val_loss: 17.0190 - val_MinusLogProbMetric: 17.0190 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 413/1000
2023-09-28 02:33:09.242 
Epoch 413/1000 
	 loss: 16.5575, MinusLogProbMetric: 16.5575, val_loss: 17.0011, val_MinusLogProbMetric: 17.0011

Epoch 413: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5575 - MinusLogProbMetric: 16.5575 - val_loss: 17.0011 - val_MinusLogProbMetric: 17.0011 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 414/1000
2023-09-28 02:33:47.655 
Epoch 414/1000 
	 loss: 16.5472, MinusLogProbMetric: 16.5472, val_loss: 17.0118, val_MinusLogProbMetric: 17.0118

Epoch 414: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5472 - MinusLogProbMetric: 16.5472 - val_loss: 17.0118 - val_MinusLogProbMetric: 17.0118 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 415/1000
2023-09-28 02:34:25.856 
Epoch 415/1000 
	 loss: 16.5595, MinusLogProbMetric: 16.5595, val_loss: 17.0089, val_MinusLogProbMetric: 17.0089

Epoch 415: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5595 - MinusLogProbMetric: 16.5595 - val_loss: 17.0089 - val_MinusLogProbMetric: 17.0089 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 416/1000
2023-09-28 02:35:04.163 
Epoch 416/1000 
	 loss: 16.6092, MinusLogProbMetric: 16.6092, val_loss: 17.0341, val_MinusLogProbMetric: 17.0341

Epoch 416: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.6092 - MinusLogProbMetric: 16.6092 - val_loss: 17.0341 - val_MinusLogProbMetric: 17.0341 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 417/1000
2023-09-28 02:35:42.261 
Epoch 417/1000 
	 loss: 16.5475, MinusLogProbMetric: 16.5475, val_loss: 17.0980, val_MinusLogProbMetric: 17.0980

Epoch 417: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5475 - MinusLogProbMetric: 16.5475 - val_loss: 17.0980 - val_MinusLogProbMetric: 17.0980 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 418/1000
2023-09-28 02:36:20.374 
Epoch 418/1000 
	 loss: 16.5474, MinusLogProbMetric: 16.5474, val_loss: 17.0506, val_MinusLogProbMetric: 17.0506

Epoch 418: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5474 - MinusLogProbMetric: 16.5474 - val_loss: 17.0506 - val_MinusLogProbMetric: 17.0506 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 419/1000
2023-09-28 02:36:58.487 
Epoch 419/1000 
	 loss: 16.5556, MinusLogProbMetric: 16.5556, val_loss: 17.0649, val_MinusLogProbMetric: 17.0649

Epoch 419: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5556 - MinusLogProbMetric: 16.5556 - val_loss: 17.0649 - val_MinusLogProbMetric: 17.0649 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 420/1000
2023-09-28 02:37:36.842 
Epoch 420/1000 
	 loss: 16.5660, MinusLogProbMetric: 16.5660, val_loss: 17.0138, val_MinusLogProbMetric: 17.0138

Epoch 420: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5660 - MinusLogProbMetric: 16.5660 - val_loss: 17.0138 - val_MinusLogProbMetric: 17.0138 - lr: 2.5000e-04 - 38s/epoch - 196ms/step
Epoch 421/1000
2023-09-28 02:38:15.144 
Epoch 421/1000 
	 loss: 16.5563, MinusLogProbMetric: 16.5563, val_loss: 17.1032, val_MinusLogProbMetric: 17.1032

Epoch 421: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5563 - MinusLogProbMetric: 16.5563 - val_loss: 17.1032 - val_MinusLogProbMetric: 17.1032 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 422/1000
2023-09-28 02:38:53.398 
Epoch 422/1000 
	 loss: 16.5679, MinusLogProbMetric: 16.5679, val_loss: 17.0802, val_MinusLogProbMetric: 17.0802

Epoch 422: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5679 - MinusLogProbMetric: 16.5679 - val_loss: 17.0802 - val_MinusLogProbMetric: 17.0802 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 423/1000
2023-09-28 02:39:31.563 
Epoch 423/1000 
	 loss: 16.5603, MinusLogProbMetric: 16.5603, val_loss: 17.1668, val_MinusLogProbMetric: 17.1668

Epoch 423: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5603 - MinusLogProbMetric: 16.5603 - val_loss: 17.1668 - val_MinusLogProbMetric: 17.1668 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 424/1000
2023-09-28 02:40:09.686 
Epoch 424/1000 
	 loss: 16.5568, MinusLogProbMetric: 16.5568, val_loss: 17.0380, val_MinusLogProbMetric: 17.0380

Epoch 424: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5568 - MinusLogProbMetric: 16.5568 - val_loss: 17.0380 - val_MinusLogProbMetric: 17.0380 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 425/1000
2023-09-28 02:40:47.513 
Epoch 425/1000 
	 loss: 16.5579, MinusLogProbMetric: 16.5579, val_loss: 16.9925, val_MinusLogProbMetric: 16.9925

Epoch 425: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5579 - MinusLogProbMetric: 16.5579 - val_loss: 16.9925 - val_MinusLogProbMetric: 16.9925 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 426/1000
2023-09-28 02:41:25.438 
Epoch 426/1000 
	 loss: 16.5370, MinusLogProbMetric: 16.5370, val_loss: 17.0081, val_MinusLogProbMetric: 17.0081

Epoch 426: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5370 - MinusLogProbMetric: 16.5370 - val_loss: 17.0081 - val_MinusLogProbMetric: 17.0081 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 427/1000
2023-09-28 02:42:03.193 
Epoch 427/1000 
	 loss: 16.5565, MinusLogProbMetric: 16.5565, val_loss: 17.0670, val_MinusLogProbMetric: 17.0670

Epoch 427: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5565 - MinusLogProbMetric: 16.5565 - val_loss: 17.0670 - val_MinusLogProbMetric: 17.0670 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 428/1000
2023-09-28 02:42:41.443 
Epoch 428/1000 
	 loss: 16.5831, MinusLogProbMetric: 16.5831, val_loss: 17.1278, val_MinusLogProbMetric: 17.1278

Epoch 428: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5831 - MinusLogProbMetric: 16.5831 - val_loss: 17.1278 - val_MinusLogProbMetric: 17.1278 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 429/1000
2023-09-28 02:43:19.374 
Epoch 429/1000 
	 loss: 16.5528, MinusLogProbMetric: 16.5528, val_loss: 17.0893, val_MinusLogProbMetric: 17.0893

Epoch 429: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5528 - MinusLogProbMetric: 16.5528 - val_loss: 17.0893 - val_MinusLogProbMetric: 17.0893 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 430/1000
2023-09-28 02:43:57.592 
Epoch 430/1000 
	 loss: 16.5547, MinusLogProbMetric: 16.5547, val_loss: 16.9977, val_MinusLogProbMetric: 16.9977

Epoch 430: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5547 - MinusLogProbMetric: 16.5547 - val_loss: 16.9977 - val_MinusLogProbMetric: 16.9977 - lr: 2.5000e-04 - 38s/epoch - 195ms/step
Epoch 431/1000
2023-09-28 02:44:35.365 
Epoch 431/1000 
	 loss: 16.5632, MinusLogProbMetric: 16.5632, val_loss: 17.0262, val_MinusLogProbMetric: 17.0262

Epoch 431: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5632 - MinusLogProbMetric: 16.5632 - val_loss: 17.0262 - val_MinusLogProbMetric: 17.0262 - lr: 2.5000e-04 - 38s/epoch - 193ms/step
Epoch 432/1000
2023-09-28 02:45:13.482 
Epoch 432/1000 
	 loss: 16.5591, MinusLogProbMetric: 16.5591, val_loss: 17.0067, val_MinusLogProbMetric: 17.0067

Epoch 432: val_loss did not improve from 16.98596
196/196 - 38s - loss: 16.5591 - MinusLogProbMetric: 16.5591 - val_loss: 17.0067 - val_MinusLogProbMetric: 17.0067 - lr: 2.5000e-04 - 38s/epoch - 194ms/step
Epoch 433/1000
2023-09-28 02:45:51.543 
Epoch 433/1000 
	 loss: 16.4900, MinusLogProbMetric: 16.4900, val_loss: 16.9752, val_MinusLogProbMetric: 16.9752

Epoch 433: val_loss improved from 16.98596 to 16.97524, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.4900 - MinusLogProbMetric: 16.4900 - val_loss: 16.9752 - val_MinusLogProbMetric: 16.9752 - lr: 1.2500e-04 - 39s/epoch - 198ms/step
Epoch 434/1000
2023-09-28 02:46:30.140 
Epoch 434/1000 
	 loss: 16.4911, MinusLogProbMetric: 16.4911, val_loss: 16.9937, val_MinusLogProbMetric: 16.9937

Epoch 434: val_loss did not improve from 16.97524
196/196 - 38s - loss: 16.4911 - MinusLogProbMetric: 16.4911 - val_loss: 16.9937 - val_MinusLogProbMetric: 16.9937 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 435/1000
2023-09-28 02:47:08.844 
Epoch 435/1000 
	 loss: 16.4846, MinusLogProbMetric: 16.4846, val_loss: 16.9866, val_MinusLogProbMetric: 16.9866

Epoch 435: val_loss did not improve from 16.97524
196/196 - 39s - loss: 16.4846 - MinusLogProbMetric: 16.4846 - val_loss: 16.9866 - val_MinusLogProbMetric: 16.9866 - lr: 1.2500e-04 - 39s/epoch - 197ms/step
Epoch 436/1000
2023-09-28 02:47:47.108 
Epoch 436/1000 
	 loss: 16.4825, MinusLogProbMetric: 16.4825, val_loss: 17.0397, val_MinusLogProbMetric: 17.0397

Epoch 436: val_loss did not improve from 16.97524
196/196 - 38s - loss: 16.4825 - MinusLogProbMetric: 16.4825 - val_loss: 17.0397 - val_MinusLogProbMetric: 17.0397 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 437/1000
2023-09-28 02:48:25.555 
Epoch 437/1000 
	 loss: 16.4927, MinusLogProbMetric: 16.4927, val_loss: 17.0401, val_MinusLogProbMetric: 17.0401

Epoch 437: val_loss did not improve from 16.97524
196/196 - 38s - loss: 16.4927 - MinusLogProbMetric: 16.4927 - val_loss: 17.0401 - val_MinusLogProbMetric: 17.0401 - lr: 1.2500e-04 - 38s/epoch - 196ms/step
Epoch 438/1000
2023-09-28 02:49:03.737 
Epoch 438/1000 
	 loss: 16.4842, MinusLogProbMetric: 16.4842, val_loss: 16.9923, val_MinusLogProbMetric: 16.9923

Epoch 438: val_loss did not improve from 16.97524
196/196 - 38s - loss: 16.4842 - MinusLogProbMetric: 16.4842 - val_loss: 16.9923 - val_MinusLogProbMetric: 16.9923 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 439/1000
2023-09-28 02:49:41.903 
Epoch 439/1000 
	 loss: 16.4822, MinusLogProbMetric: 16.4822, val_loss: 16.9834, val_MinusLogProbMetric: 16.9834

Epoch 439: val_loss did not improve from 16.97524
196/196 - 38s - loss: 16.4822 - MinusLogProbMetric: 16.4822 - val_loss: 16.9834 - val_MinusLogProbMetric: 16.9834 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 440/1000
2023-09-28 02:50:19.798 
Epoch 440/1000 
	 loss: 16.4921, MinusLogProbMetric: 16.4921, val_loss: 16.9705, val_MinusLogProbMetric: 16.9705

Epoch 440: val_loss improved from 16.97524 to 16.97048, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.4921 - MinusLogProbMetric: 16.4921 - val_loss: 16.9705 - val_MinusLogProbMetric: 16.9705 - lr: 1.2500e-04 - 39s/epoch - 197ms/step
Epoch 441/1000
2023-09-28 02:50:58.408 
Epoch 441/1000 
	 loss: 16.4827, MinusLogProbMetric: 16.4827, val_loss: 17.0033, val_MinusLogProbMetric: 17.0033

Epoch 441: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4827 - MinusLogProbMetric: 16.4827 - val_loss: 17.0033 - val_MinusLogProbMetric: 17.0033 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 442/1000
2023-09-28 02:51:36.440 
Epoch 442/1000 
	 loss: 16.4842, MinusLogProbMetric: 16.4842, val_loss: 16.9809, val_MinusLogProbMetric: 16.9809

Epoch 442: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4842 - MinusLogProbMetric: 16.4842 - val_loss: 16.9809 - val_MinusLogProbMetric: 16.9809 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 443/1000
2023-09-28 02:52:14.429 
Epoch 443/1000 
	 loss: 16.4864, MinusLogProbMetric: 16.4864, val_loss: 16.9724, val_MinusLogProbMetric: 16.9724

Epoch 443: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4864 - MinusLogProbMetric: 16.4864 - val_loss: 16.9724 - val_MinusLogProbMetric: 16.9724 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 444/1000
2023-09-28 02:52:52.380 
Epoch 444/1000 
	 loss: 16.4814, MinusLogProbMetric: 16.4814, val_loss: 16.9945, val_MinusLogProbMetric: 16.9945

Epoch 444: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4814 - MinusLogProbMetric: 16.4814 - val_loss: 16.9945 - val_MinusLogProbMetric: 16.9945 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 445/1000
2023-09-28 02:53:30.431 
Epoch 445/1000 
	 loss: 16.4837, MinusLogProbMetric: 16.4837, val_loss: 16.9773, val_MinusLogProbMetric: 16.9773

Epoch 445: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4837 - MinusLogProbMetric: 16.4837 - val_loss: 16.9773 - val_MinusLogProbMetric: 16.9773 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 446/1000
2023-09-28 02:54:08.600 
Epoch 446/1000 
	 loss: 16.4778, MinusLogProbMetric: 16.4778, val_loss: 17.0545, val_MinusLogProbMetric: 17.0545

Epoch 446: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4778 - MinusLogProbMetric: 16.4778 - val_loss: 17.0545 - val_MinusLogProbMetric: 17.0545 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 447/1000
2023-09-28 02:54:46.663 
Epoch 447/1000 
	 loss: 16.4871, MinusLogProbMetric: 16.4871, val_loss: 16.9840, val_MinusLogProbMetric: 16.9840

Epoch 447: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4871 - MinusLogProbMetric: 16.4871 - val_loss: 16.9840 - val_MinusLogProbMetric: 16.9840 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 448/1000
2023-09-28 02:55:24.662 
Epoch 448/1000 
	 loss: 16.4789, MinusLogProbMetric: 16.4789, val_loss: 16.9750, val_MinusLogProbMetric: 16.9750

Epoch 448: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4789 - MinusLogProbMetric: 16.4789 - val_loss: 16.9750 - val_MinusLogProbMetric: 16.9750 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 449/1000
2023-09-28 02:56:02.964 
Epoch 449/1000 
	 loss: 16.4837, MinusLogProbMetric: 16.4837, val_loss: 16.9760, val_MinusLogProbMetric: 16.9760

Epoch 449: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4837 - MinusLogProbMetric: 16.4837 - val_loss: 16.9760 - val_MinusLogProbMetric: 16.9760 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 450/1000
2023-09-28 02:56:40.856 
Epoch 450/1000 
	 loss: 16.4856, MinusLogProbMetric: 16.4856, val_loss: 16.9917, val_MinusLogProbMetric: 16.9917

Epoch 450: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4856 - MinusLogProbMetric: 16.4856 - val_loss: 16.9917 - val_MinusLogProbMetric: 16.9917 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 451/1000
2023-09-28 02:57:18.859 
Epoch 451/1000 
	 loss: 16.4810, MinusLogProbMetric: 16.4810, val_loss: 17.1934, val_MinusLogProbMetric: 17.1934

Epoch 451: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4810 - MinusLogProbMetric: 16.4810 - val_loss: 17.1934 - val_MinusLogProbMetric: 17.1934 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 452/1000
2023-09-28 02:57:56.795 
Epoch 452/1000 
	 loss: 16.5031, MinusLogProbMetric: 16.5031, val_loss: 16.9871, val_MinusLogProbMetric: 16.9871

Epoch 452: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.5031 - MinusLogProbMetric: 16.5031 - val_loss: 16.9871 - val_MinusLogProbMetric: 16.9871 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 453/1000
2023-09-28 02:58:35.166 
Epoch 453/1000 
	 loss: 16.4842, MinusLogProbMetric: 16.4842, val_loss: 16.9737, val_MinusLogProbMetric: 16.9737

Epoch 453: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4842 - MinusLogProbMetric: 16.4842 - val_loss: 16.9737 - val_MinusLogProbMetric: 16.9737 - lr: 1.2500e-04 - 38s/epoch - 196ms/step
Epoch 454/1000
2023-09-28 02:59:12.865 
Epoch 454/1000 
	 loss: 16.4764, MinusLogProbMetric: 16.4764, val_loss: 16.9783, val_MinusLogProbMetric: 16.9783

Epoch 454: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4764 - MinusLogProbMetric: 16.4764 - val_loss: 16.9783 - val_MinusLogProbMetric: 16.9783 - lr: 1.2500e-04 - 38s/epoch - 192ms/step
Epoch 455/1000
2023-09-28 02:59:51.129 
Epoch 455/1000 
	 loss: 16.4823, MinusLogProbMetric: 16.4823, val_loss: 16.9753, val_MinusLogProbMetric: 16.9753

Epoch 455: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4823 - MinusLogProbMetric: 16.4823 - val_loss: 16.9753 - val_MinusLogProbMetric: 16.9753 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 456/1000
2023-09-28 03:00:29.244 
Epoch 456/1000 
	 loss: 16.4967, MinusLogProbMetric: 16.4967, val_loss: 17.0187, val_MinusLogProbMetric: 17.0187

Epoch 456: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4967 - MinusLogProbMetric: 16.4967 - val_loss: 17.0187 - val_MinusLogProbMetric: 17.0187 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 457/1000
2023-09-28 03:01:07.567 
Epoch 457/1000 
	 loss: 16.4762, MinusLogProbMetric: 16.4762, val_loss: 16.9963, val_MinusLogProbMetric: 16.9963

Epoch 457: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4762 - MinusLogProbMetric: 16.4762 - val_loss: 16.9963 - val_MinusLogProbMetric: 16.9963 - lr: 1.2500e-04 - 38s/epoch - 196ms/step
Epoch 458/1000
2023-09-28 03:01:45.613 
Epoch 458/1000 
	 loss: 16.5034, MinusLogProbMetric: 16.5034, val_loss: 17.0269, val_MinusLogProbMetric: 17.0269

Epoch 458: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.5034 - MinusLogProbMetric: 16.5034 - val_loss: 17.0269 - val_MinusLogProbMetric: 17.0269 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 459/1000
2023-09-28 03:02:23.670 
Epoch 459/1000 
	 loss: 16.4812, MinusLogProbMetric: 16.4812, val_loss: 16.9952, val_MinusLogProbMetric: 16.9952

Epoch 459: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4812 - MinusLogProbMetric: 16.4812 - val_loss: 16.9952 - val_MinusLogProbMetric: 16.9952 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 460/1000
2023-09-28 03:03:01.751 
Epoch 460/1000 
	 loss: 16.4771, MinusLogProbMetric: 16.4771, val_loss: 17.0091, val_MinusLogProbMetric: 17.0091

Epoch 460: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4771 - MinusLogProbMetric: 16.4771 - val_loss: 17.0091 - val_MinusLogProbMetric: 17.0091 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 461/1000
2023-09-28 03:03:39.564 
Epoch 461/1000 
	 loss: 16.4955, MinusLogProbMetric: 16.4955, val_loss: 17.0125, val_MinusLogProbMetric: 17.0125

Epoch 461: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4955 - MinusLogProbMetric: 16.4955 - val_loss: 17.0125 - val_MinusLogProbMetric: 17.0125 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 462/1000
2023-09-28 03:04:17.746 
Epoch 462/1000 
	 loss: 16.4797, MinusLogProbMetric: 16.4797, val_loss: 16.9773, val_MinusLogProbMetric: 16.9773

Epoch 462: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4797 - MinusLogProbMetric: 16.4797 - val_loss: 16.9773 - val_MinusLogProbMetric: 16.9773 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 463/1000
2023-09-28 03:04:55.708 
Epoch 463/1000 
	 loss: 16.4792, MinusLogProbMetric: 16.4792, val_loss: 16.9833, val_MinusLogProbMetric: 16.9833

Epoch 463: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4792 - MinusLogProbMetric: 16.4792 - val_loss: 16.9833 - val_MinusLogProbMetric: 16.9833 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 464/1000
2023-09-28 03:05:33.739 
Epoch 464/1000 
	 loss: 16.4904, MinusLogProbMetric: 16.4904, val_loss: 17.0107, val_MinusLogProbMetric: 17.0107

Epoch 464: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4904 - MinusLogProbMetric: 16.4904 - val_loss: 17.0107 - val_MinusLogProbMetric: 17.0107 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 465/1000
2023-09-28 03:06:11.689 
Epoch 465/1000 
	 loss: 16.4876, MinusLogProbMetric: 16.4876, val_loss: 17.0055, val_MinusLogProbMetric: 17.0055

Epoch 465: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4876 - MinusLogProbMetric: 16.4876 - val_loss: 17.0055 - val_MinusLogProbMetric: 17.0055 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 466/1000
2023-09-28 03:06:49.976 
Epoch 466/1000 
	 loss: 16.4825, MinusLogProbMetric: 16.4825, val_loss: 17.0061, val_MinusLogProbMetric: 17.0061

Epoch 466: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4825 - MinusLogProbMetric: 16.4825 - val_loss: 17.0061 - val_MinusLogProbMetric: 17.0061 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 467/1000
2023-09-28 03:07:28.040 
Epoch 467/1000 
	 loss: 16.4829, MinusLogProbMetric: 16.4829, val_loss: 16.9885, val_MinusLogProbMetric: 16.9885

Epoch 467: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4829 - MinusLogProbMetric: 16.4829 - val_loss: 16.9885 - val_MinusLogProbMetric: 16.9885 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 468/1000
2023-09-28 03:08:06.360 
Epoch 468/1000 
	 loss: 16.4687, MinusLogProbMetric: 16.4687, val_loss: 16.9801, val_MinusLogProbMetric: 16.9801

Epoch 468: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4687 - MinusLogProbMetric: 16.4687 - val_loss: 16.9801 - val_MinusLogProbMetric: 16.9801 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 469/1000
2023-09-28 03:08:44.392 
Epoch 469/1000 
	 loss: 16.4808, MinusLogProbMetric: 16.4808, val_loss: 17.0246, val_MinusLogProbMetric: 17.0246

Epoch 469: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4808 - MinusLogProbMetric: 16.4808 - val_loss: 17.0246 - val_MinusLogProbMetric: 17.0246 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 470/1000
2023-09-28 03:09:22.603 
Epoch 470/1000 
	 loss: 16.5297, MinusLogProbMetric: 16.5297, val_loss: 17.0281, val_MinusLogProbMetric: 17.0281

Epoch 470: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.5297 - MinusLogProbMetric: 16.5297 - val_loss: 17.0281 - val_MinusLogProbMetric: 17.0281 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 471/1000
2023-09-28 03:10:00.825 
Epoch 471/1000 
	 loss: 16.4835, MinusLogProbMetric: 16.4835, val_loss: 16.9931, val_MinusLogProbMetric: 16.9931

Epoch 471: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4835 - MinusLogProbMetric: 16.4835 - val_loss: 16.9931 - val_MinusLogProbMetric: 16.9931 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 472/1000
2023-09-28 03:10:38.753 
Epoch 472/1000 
	 loss: 16.4799, MinusLogProbMetric: 16.4799, val_loss: 16.9979, val_MinusLogProbMetric: 16.9979

Epoch 472: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4799 - MinusLogProbMetric: 16.4799 - val_loss: 16.9979 - val_MinusLogProbMetric: 16.9979 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 473/1000
2023-09-28 03:11:17.038 
Epoch 473/1000 
	 loss: 16.4673, MinusLogProbMetric: 16.4673, val_loss: 17.0896, val_MinusLogProbMetric: 17.0896

Epoch 473: val_loss did not improve from 16.97048
196/196 - 38s - loss: 16.4673 - MinusLogProbMetric: 16.4673 - val_loss: 17.0896 - val_MinusLogProbMetric: 17.0896 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 474/1000
2023-09-28 03:11:54.925 
Epoch 474/1000 
	 loss: 16.5151, MinusLogProbMetric: 16.5151, val_loss: 16.9701, val_MinusLogProbMetric: 16.9701

Epoch 474: val_loss improved from 16.97048 to 16.97012, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.5151 - MinusLogProbMetric: 16.5151 - val_loss: 16.9701 - val_MinusLogProbMetric: 16.9701 - lr: 1.2500e-04 - 39s/epoch - 197ms/step
Epoch 475/1000
2023-09-28 03:12:33.650 
Epoch 475/1000 
	 loss: 16.4725, MinusLogProbMetric: 16.4725, val_loss: 16.9649, val_MinusLogProbMetric: 16.9649

Epoch 475: val_loss improved from 16.97012 to 16.96488, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.4725 - MinusLogProbMetric: 16.4725 - val_loss: 16.9649 - val_MinusLogProbMetric: 16.9649 - lr: 1.2500e-04 - 39s/epoch - 198ms/step
Epoch 476/1000
2023-09-28 03:13:12.655 
Epoch 476/1000 
	 loss: 16.4789, MinusLogProbMetric: 16.4789, val_loss: 17.0300, val_MinusLogProbMetric: 17.0300

Epoch 476: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4789 - MinusLogProbMetric: 16.4789 - val_loss: 17.0300 - val_MinusLogProbMetric: 17.0300 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 477/1000
2023-09-28 03:13:50.790 
Epoch 477/1000 
	 loss: 16.4820, MinusLogProbMetric: 16.4820, val_loss: 16.9917, val_MinusLogProbMetric: 16.9917

Epoch 477: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4820 - MinusLogProbMetric: 16.4820 - val_loss: 16.9917 - val_MinusLogProbMetric: 16.9917 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 478/1000
2023-09-28 03:14:29.042 
Epoch 478/1000 
	 loss: 16.4847, MinusLogProbMetric: 16.4847, val_loss: 17.0429, val_MinusLogProbMetric: 17.0429

Epoch 478: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4847 - MinusLogProbMetric: 16.4847 - val_loss: 17.0429 - val_MinusLogProbMetric: 17.0429 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 479/1000
2023-09-28 03:15:06.965 
Epoch 479/1000 
	 loss: 16.4770, MinusLogProbMetric: 16.4770, val_loss: 17.0329, val_MinusLogProbMetric: 17.0329

Epoch 479: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4770 - MinusLogProbMetric: 16.4770 - val_loss: 17.0329 - val_MinusLogProbMetric: 17.0329 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 480/1000
2023-09-28 03:15:44.951 
Epoch 480/1000 
	 loss: 16.4991, MinusLogProbMetric: 16.4991, val_loss: 16.9668, val_MinusLogProbMetric: 16.9668

Epoch 480: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4991 - MinusLogProbMetric: 16.4991 - val_loss: 16.9668 - val_MinusLogProbMetric: 16.9668 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 481/1000
2023-09-28 03:16:23.317 
Epoch 481/1000 
	 loss: 16.4671, MinusLogProbMetric: 16.4671, val_loss: 16.9883, val_MinusLogProbMetric: 16.9883

Epoch 481: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4671 - MinusLogProbMetric: 16.4671 - val_loss: 16.9883 - val_MinusLogProbMetric: 16.9883 - lr: 1.2500e-04 - 38s/epoch - 196ms/step
Epoch 482/1000
2023-09-28 03:17:01.067 
Epoch 482/1000 
	 loss: 16.4887, MinusLogProbMetric: 16.4887, val_loss: 16.9691, val_MinusLogProbMetric: 16.9691

Epoch 482: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4887 - MinusLogProbMetric: 16.4887 - val_loss: 16.9691 - val_MinusLogProbMetric: 16.9691 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 483/1000
2023-09-28 03:17:39.245 
Epoch 483/1000 
	 loss: 16.4957, MinusLogProbMetric: 16.4957, val_loss: 17.0018, val_MinusLogProbMetric: 17.0018

Epoch 483: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4957 - MinusLogProbMetric: 16.4957 - val_loss: 17.0018 - val_MinusLogProbMetric: 17.0018 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 484/1000
2023-09-28 03:18:17.341 
Epoch 484/1000 
	 loss: 16.4804, MinusLogProbMetric: 16.4804, val_loss: 16.9780, val_MinusLogProbMetric: 16.9780

Epoch 484: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4804 - MinusLogProbMetric: 16.4804 - val_loss: 16.9780 - val_MinusLogProbMetric: 16.9780 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 485/1000
2023-09-28 03:18:55.377 
Epoch 485/1000 
	 loss: 16.4769, MinusLogProbMetric: 16.4769, val_loss: 17.0120, val_MinusLogProbMetric: 17.0120

Epoch 485: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4769 - MinusLogProbMetric: 16.4769 - val_loss: 17.0120 - val_MinusLogProbMetric: 17.0120 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 486/1000
2023-09-28 03:19:33.638 
Epoch 486/1000 
	 loss: 16.4763, MinusLogProbMetric: 16.4763, val_loss: 16.9711, val_MinusLogProbMetric: 16.9711

Epoch 486: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4763 - MinusLogProbMetric: 16.4763 - val_loss: 16.9711 - val_MinusLogProbMetric: 16.9711 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 487/1000
2023-09-28 03:20:12.057 
Epoch 487/1000 
	 loss: 16.4818, MinusLogProbMetric: 16.4818, val_loss: 17.0009, val_MinusLogProbMetric: 17.0009

Epoch 487: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4818 - MinusLogProbMetric: 16.4818 - val_loss: 17.0009 - val_MinusLogProbMetric: 17.0009 - lr: 1.2500e-04 - 38s/epoch - 196ms/step
Epoch 488/1000
2023-09-28 03:20:50.054 
Epoch 488/1000 
	 loss: 16.4782, MinusLogProbMetric: 16.4782, val_loss: 16.9995, val_MinusLogProbMetric: 16.9995

Epoch 488: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4782 - MinusLogProbMetric: 16.4782 - val_loss: 16.9995 - val_MinusLogProbMetric: 16.9995 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 489/1000
2023-09-28 03:21:28.331 
Epoch 489/1000 
	 loss: 16.4872, MinusLogProbMetric: 16.4872, val_loss: 17.0189, val_MinusLogProbMetric: 17.0189

Epoch 489: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4872 - MinusLogProbMetric: 16.4872 - val_loss: 17.0189 - val_MinusLogProbMetric: 17.0189 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 490/1000
2023-09-28 03:22:06.213 
Epoch 490/1000 
	 loss: 16.4825, MinusLogProbMetric: 16.4825, val_loss: 16.9987, val_MinusLogProbMetric: 16.9987

Epoch 490: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4825 - MinusLogProbMetric: 16.4825 - val_loss: 16.9987 - val_MinusLogProbMetric: 16.9987 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 491/1000
2023-09-28 03:22:44.009 
Epoch 491/1000 
	 loss: 16.4841, MinusLogProbMetric: 16.4841, val_loss: 17.0000, val_MinusLogProbMetric: 17.0000

Epoch 491: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4841 - MinusLogProbMetric: 16.4841 - val_loss: 17.0000 - val_MinusLogProbMetric: 17.0000 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 492/1000
2023-09-28 03:23:22.304 
Epoch 492/1000 
	 loss: 16.4859, MinusLogProbMetric: 16.4859, val_loss: 16.9757, val_MinusLogProbMetric: 16.9757

Epoch 492: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4859 - MinusLogProbMetric: 16.4859 - val_loss: 16.9757 - val_MinusLogProbMetric: 16.9757 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 493/1000
2023-09-28 03:24:00.735 
Epoch 493/1000 
	 loss: 16.4661, MinusLogProbMetric: 16.4661, val_loss: 16.9862, val_MinusLogProbMetric: 16.9862

Epoch 493: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4661 - MinusLogProbMetric: 16.4661 - val_loss: 16.9862 - val_MinusLogProbMetric: 16.9862 - lr: 1.2500e-04 - 38s/epoch - 196ms/step
Epoch 494/1000
2023-09-28 03:24:38.713 
Epoch 494/1000 
	 loss: 16.4924, MinusLogProbMetric: 16.4924, val_loss: 17.0142, val_MinusLogProbMetric: 17.0142

Epoch 494: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4924 - MinusLogProbMetric: 16.4924 - val_loss: 17.0142 - val_MinusLogProbMetric: 17.0142 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 495/1000
2023-09-28 03:25:17.171 
Epoch 495/1000 
	 loss: 16.4950, MinusLogProbMetric: 16.4950, val_loss: 17.0294, val_MinusLogProbMetric: 17.0294

Epoch 495: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4950 - MinusLogProbMetric: 16.4950 - val_loss: 17.0294 - val_MinusLogProbMetric: 17.0294 - lr: 1.2500e-04 - 38s/epoch - 196ms/step
Epoch 496/1000
2023-09-28 03:25:55.218 
Epoch 496/1000 
	 loss: 16.4728, MinusLogProbMetric: 16.4728, val_loss: 16.9822, val_MinusLogProbMetric: 16.9822

Epoch 496: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4728 - MinusLogProbMetric: 16.4728 - val_loss: 16.9822 - val_MinusLogProbMetric: 16.9822 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 497/1000
2023-09-28 03:26:33.506 
Epoch 497/1000 
	 loss: 16.4851, MinusLogProbMetric: 16.4851, val_loss: 16.9757, val_MinusLogProbMetric: 16.9757

Epoch 497: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4851 - MinusLogProbMetric: 16.4851 - val_loss: 16.9757 - val_MinusLogProbMetric: 16.9757 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 498/1000
2023-09-28 03:27:11.545 
Epoch 498/1000 
	 loss: 16.4823, MinusLogProbMetric: 16.4823, val_loss: 17.0366, val_MinusLogProbMetric: 17.0366

Epoch 498: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4823 - MinusLogProbMetric: 16.4823 - val_loss: 17.0366 - val_MinusLogProbMetric: 17.0366 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 499/1000
2023-09-28 03:27:49.841 
Epoch 499/1000 
	 loss: 16.4778, MinusLogProbMetric: 16.4778, val_loss: 16.9816, val_MinusLogProbMetric: 16.9816

Epoch 499: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4778 - MinusLogProbMetric: 16.4778 - val_loss: 16.9816 - val_MinusLogProbMetric: 16.9816 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 500/1000
2023-09-28 03:28:27.718 
Epoch 500/1000 
	 loss: 16.4811, MinusLogProbMetric: 16.4811, val_loss: 17.0121, val_MinusLogProbMetric: 17.0121

Epoch 500: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4811 - MinusLogProbMetric: 16.4811 - val_loss: 17.0121 - val_MinusLogProbMetric: 17.0121 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 501/1000
2023-09-28 03:29:05.547 
Epoch 501/1000 
	 loss: 16.4794, MinusLogProbMetric: 16.4794, val_loss: 16.9771, val_MinusLogProbMetric: 16.9771

Epoch 501: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4794 - MinusLogProbMetric: 16.4794 - val_loss: 16.9771 - val_MinusLogProbMetric: 16.9771 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 502/1000
2023-09-28 03:29:43.692 
Epoch 502/1000 
	 loss: 16.4688, MinusLogProbMetric: 16.4688, val_loss: 16.9691, val_MinusLogProbMetric: 16.9691

Epoch 502: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4688 - MinusLogProbMetric: 16.4688 - val_loss: 16.9691 - val_MinusLogProbMetric: 16.9691 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 503/1000
2023-09-28 03:30:21.930 
Epoch 503/1000 
	 loss: 16.4861, MinusLogProbMetric: 16.4861, val_loss: 16.9714, val_MinusLogProbMetric: 16.9714

Epoch 503: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4861 - MinusLogProbMetric: 16.4861 - val_loss: 16.9714 - val_MinusLogProbMetric: 16.9714 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 504/1000
2023-09-28 03:30:59.905 
Epoch 504/1000 
	 loss: 16.4816, MinusLogProbMetric: 16.4816, val_loss: 16.9695, val_MinusLogProbMetric: 16.9695

Epoch 504: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4816 - MinusLogProbMetric: 16.4816 - val_loss: 16.9695 - val_MinusLogProbMetric: 16.9695 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 505/1000
2023-09-28 03:31:38.397 
Epoch 505/1000 
	 loss: 16.4861, MinusLogProbMetric: 16.4861, val_loss: 16.9741, val_MinusLogProbMetric: 16.9741

Epoch 505: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4861 - MinusLogProbMetric: 16.4861 - val_loss: 16.9741 - val_MinusLogProbMetric: 16.9741 - lr: 1.2500e-04 - 38s/epoch - 196ms/step
Epoch 506/1000
2023-09-28 03:32:16.877 
Epoch 506/1000 
	 loss: 16.4684, MinusLogProbMetric: 16.4684, val_loss: 17.0068, val_MinusLogProbMetric: 17.0068

Epoch 506: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4684 - MinusLogProbMetric: 16.4684 - val_loss: 17.0068 - val_MinusLogProbMetric: 17.0068 - lr: 1.2500e-04 - 38s/epoch - 196ms/step
Epoch 507/1000
2023-09-28 03:32:55.218 
Epoch 507/1000 
	 loss: 16.5068, MinusLogProbMetric: 16.5068, val_loss: 16.9814, val_MinusLogProbMetric: 16.9814

Epoch 507: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.5068 - MinusLogProbMetric: 16.5068 - val_loss: 16.9814 - val_MinusLogProbMetric: 16.9814 - lr: 1.2500e-04 - 38s/epoch - 196ms/step
Epoch 508/1000
2023-09-28 03:33:33.391 
Epoch 508/1000 
	 loss: 16.4688, MinusLogProbMetric: 16.4688, val_loss: 16.9731, val_MinusLogProbMetric: 16.9731

Epoch 508: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4688 - MinusLogProbMetric: 16.4688 - val_loss: 16.9731 - val_MinusLogProbMetric: 16.9731 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 509/1000
2023-09-28 03:34:11.593 
Epoch 509/1000 
	 loss: 16.4828, MinusLogProbMetric: 16.4828, val_loss: 16.9875, val_MinusLogProbMetric: 16.9875

Epoch 509: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4828 - MinusLogProbMetric: 16.4828 - val_loss: 16.9875 - val_MinusLogProbMetric: 16.9875 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 510/1000
2023-09-28 03:34:50.043 
Epoch 510/1000 
	 loss: 16.4816, MinusLogProbMetric: 16.4816, val_loss: 17.0008, val_MinusLogProbMetric: 17.0008

Epoch 510: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4816 - MinusLogProbMetric: 16.4816 - val_loss: 17.0008 - val_MinusLogProbMetric: 17.0008 - lr: 1.2500e-04 - 38s/epoch - 196ms/step
Epoch 511/1000
2023-09-28 03:35:28.688 
Epoch 511/1000 
	 loss: 16.4904, MinusLogProbMetric: 16.4904, val_loss: 16.9770, val_MinusLogProbMetric: 16.9770

Epoch 511: val_loss did not improve from 16.96488
196/196 - 39s - loss: 16.4904 - MinusLogProbMetric: 16.4904 - val_loss: 16.9770 - val_MinusLogProbMetric: 16.9770 - lr: 1.2500e-04 - 39s/epoch - 197ms/step
Epoch 512/1000
2023-09-28 03:36:06.766 
Epoch 512/1000 
	 loss: 16.4612, MinusLogProbMetric: 16.4612, val_loss: 16.9940, val_MinusLogProbMetric: 16.9940

Epoch 512: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4612 - MinusLogProbMetric: 16.4612 - val_loss: 16.9940 - val_MinusLogProbMetric: 16.9940 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 513/1000
2023-09-28 03:36:44.689 
Epoch 513/1000 
	 loss: 16.4696, MinusLogProbMetric: 16.4696, val_loss: 16.9703, val_MinusLogProbMetric: 16.9703

Epoch 513: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4696 - MinusLogProbMetric: 16.4696 - val_loss: 16.9703 - val_MinusLogProbMetric: 16.9703 - lr: 1.2500e-04 - 38s/epoch - 193ms/step
Epoch 514/1000
2023-09-28 03:37:22.957 
Epoch 514/1000 
	 loss: 16.4634, MinusLogProbMetric: 16.4634, val_loss: 16.9990, val_MinusLogProbMetric: 16.9990

Epoch 514: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4634 - MinusLogProbMetric: 16.4634 - val_loss: 16.9990 - val_MinusLogProbMetric: 16.9990 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 515/1000
2023-09-28 03:38:01.053 
Epoch 515/1000 
	 loss: 16.4699, MinusLogProbMetric: 16.4699, val_loss: 17.0191, val_MinusLogProbMetric: 17.0191

Epoch 515: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4699 - MinusLogProbMetric: 16.4699 - val_loss: 17.0191 - val_MinusLogProbMetric: 17.0191 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 516/1000
2023-09-28 03:38:39.415 
Epoch 516/1000 
	 loss: 16.4734, MinusLogProbMetric: 16.4734, val_loss: 16.9783, val_MinusLogProbMetric: 16.9783

Epoch 516: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4734 - MinusLogProbMetric: 16.4734 - val_loss: 16.9783 - val_MinusLogProbMetric: 16.9783 - lr: 1.2500e-04 - 38s/epoch - 196ms/step
Epoch 517/1000
2023-09-28 03:39:17.115 
Epoch 517/1000 
	 loss: 16.4665, MinusLogProbMetric: 16.4665, val_loss: 16.9811, val_MinusLogProbMetric: 16.9811

Epoch 517: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4665 - MinusLogProbMetric: 16.4665 - val_loss: 16.9811 - val_MinusLogProbMetric: 16.9811 - lr: 1.2500e-04 - 38s/epoch - 192ms/step
Epoch 518/1000
2023-09-28 03:39:55.083 
Epoch 518/1000 
	 loss: 16.4923, MinusLogProbMetric: 16.4923, val_loss: 16.9912, val_MinusLogProbMetric: 16.9912

Epoch 518: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4923 - MinusLogProbMetric: 16.4923 - val_loss: 16.9912 - val_MinusLogProbMetric: 16.9912 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 519/1000
2023-09-28 03:40:33.129 
Epoch 519/1000 
	 loss: 16.4676, MinusLogProbMetric: 16.4676, val_loss: 17.1006, val_MinusLogProbMetric: 17.1006

Epoch 519: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4676 - MinusLogProbMetric: 16.4676 - val_loss: 17.1006 - val_MinusLogProbMetric: 17.1006 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 520/1000
2023-09-28 03:41:11.097 
Epoch 520/1000 
	 loss: 16.4767, MinusLogProbMetric: 16.4767, val_loss: 17.0319, val_MinusLogProbMetric: 17.0319

Epoch 520: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4767 - MinusLogProbMetric: 16.4767 - val_loss: 17.0319 - val_MinusLogProbMetric: 17.0319 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 521/1000
2023-09-28 03:41:49.065 
Epoch 521/1000 
	 loss: 16.4757, MinusLogProbMetric: 16.4757, val_loss: 17.0042, val_MinusLogProbMetric: 17.0042

Epoch 521: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4757 - MinusLogProbMetric: 16.4757 - val_loss: 17.0042 - val_MinusLogProbMetric: 17.0042 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 522/1000
2023-09-28 03:42:27.275 
Epoch 522/1000 
	 loss: 16.4904, MinusLogProbMetric: 16.4904, val_loss: 16.9779, val_MinusLogProbMetric: 16.9779

Epoch 522: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4904 - MinusLogProbMetric: 16.4904 - val_loss: 16.9779 - val_MinusLogProbMetric: 16.9779 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 523/1000
2023-09-28 03:43:05.594 
Epoch 523/1000 
	 loss: 16.4721, MinusLogProbMetric: 16.4721, val_loss: 16.9707, val_MinusLogProbMetric: 16.9707

Epoch 523: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4721 - MinusLogProbMetric: 16.4721 - val_loss: 16.9707 - val_MinusLogProbMetric: 16.9707 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 524/1000
2023-09-28 03:43:43.530 
Epoch 524/1000 
	 loss: 16.4637, MinusLogProbMetric: 16.4637, val_loss: 16.9704, val_MinusLogProbMetric: 16.9704

Epoch 524: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4637 - MinusLogProbMetric: 16.4637 - val_loss: 16.9704 - val_MinusLogProbMetric: 16.9704 - lr: 1.2500e-04 - 38s/epoch - 194ms/step
Epoch 525/1000
2023-09-28 03:44:21.827 
Epoch 525/1000 
	 loss: 16.4731, MinusLogProbMetric: 16.4731, val_loss: 17.0576, val_MinusLogProbMetric: 17.0576

Epoch 525: val_loss did not improve from 16.96488
196/196 - 38s - loss: 16.4731 - MinusLogProbMetric: 16.4731 - val_loss: 17.0576 - val_MinusLogProbMetric: 17.0576 - lr: 1.2500e-04 - 38s/epoch - 195ms/step
Epoch 526/1000
2023-09-28 03:45:00.180 
Epoch 526/1000 
	 loss: 16.4397, MinusLogProbMetric: 16.4397, val_loss: 16.9617, val_MinusLogProbMetric: 16.9617

Epoch 526: val_loss improved from 16.96488 to 16.96166, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.4397 - MinusLogProbMetric: 16.4397 - val_loss: 16.9617 - val_MinusLogProbMetric: 16.9617 - lr: 6.2500e-05 - 39s/epoch - 200ms/step
Epoch 527/1000
2023-09-28 03:45:38.865 
Epoch 527/1000 
	 loss: 16.4355, MinusLogProbMetric: 16.4355, val_loss: 16.9580, val_MinusLogProbMetric: 16.9580

Epoch 527: val_loss improved from 16.96166 to 16.95801, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.4355 - MinusLogProbMetric: 16.4355 - val_loss: 16.9580 - val_MinusLogProbMetric: 16.9580 - lr: 6.2500e-05 - 39s/epoch - 197ms/step
Epoch 528/1000
2023-09-28 03:46:17.721 
Epoch 528/1000 
	 loss: 16.4401, MinusLogProbMetric: 16.4401, val_loss: 16.9636, val_MinusLogProbMetric: 16.9636

Epoch 528: val_loss did not improve from 16.95801
196/196 - 38s - loss: 16.4401 - MinusLogProbMetric: 16.4401 - val_loss: 16.9636 - val_MinusLogProbMetric: 16.9636 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 529/1000
2023-09-28 03:46:55.470 
Epoch 529/1000 
	 loss: 16.4346, MinusLogProbMetric: 16.4346, val_loss: 16.9690, val_MinusLogProbMetric: 16.9690

Epoch 529: val_loss did not improve from 16.95801
196/196 - 38s - loss: 16.4346 - MinusLogProbMetric: 16.4346 - val_loss: 16.9690 - val_MinusLogProbMetric: 16.9690 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 530/1000
2023-09-28 03:47:33.453 
Epoch 530/1000 
	 loss: 16.4345, MinusLogProbMetric: 16.4345, val_loss: 16.9917, val_MinusLogProbMetric: 16.9917

Epoch 530: val_loss did not improve from 16.95801
196/196 - 38s - loss: 16.4345 - MinusLogProbMetric: 16.4345 - val_loss: 16.9917 - val_MinusLogProbMetric: 16.9917 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 531/1000
2023-09-28 03:48:11.623 
Epoch 531/1000 
	 loss: 16.4378, MinusLogProbMetric: 16.4378, val_loss: 16.9778, val_MinusLogProbMetric: 16.9778

Epoch 531: val_loss did not improve from 16.95801
196/196 - 38s - loss: 16.4378 - MinusLogProbMetric: 16.4378 - val_loss: 16.9778 - val_MinusLogProbMetric: 16.9778 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 532/1000
2023-09-28 03:48:49.754 
Epoch 532/1000 
	 loss: 16.4382, MinusLogProbMetric: 16.4382, val_loss: 16.9601, val_MinusLogProbMetric: 16.9601

Epoch 532: val_loss did not improve from 16.95801
196/196 - 38s - loss: 16.4382 - MinusLogProbMetric: 16.4382 - val_loss: 16.9601 - val_MinusLogProbMetric: 16.9601 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 533/1000
2023-09-28 03:49:27.815 
Epoch 533/1000 
	 loss: 16.4321, MinusLogProbMetric: 16.4321, val_loss: 16.9648, val_MinusLogProbMetric: 16.9648

Epoch 533: val_loss did not improve from 16.95801
196/196 - 38s - loss: 16.4321 - MinusLogProbMetric: 16.4321 - val_loss: 16.9648 - val_MinusLogProbMetric: 16.9648 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 534/1000
2023-09-28 03:50:06.165 
Epoch 534/1000 
	 loss: 16.4325, MinusLogProbMetric: 16.4325, val_loss: 16.9800, val_MinusLogProbMetric: 16.9800

Epoch 534: val_loss did not improve from 16.95801
196/196 - 38s - loss: 16.4325 - MinusLogProbMetric: 16.4325 - val_loss: 16.9800 - val_MinusLogProbMetric: 16.9800 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 535/1000
2023-09-28 03:50:44.109 
Epoch 535/1000 
	 loss: 16.4350, MinusLogProbMetric: 16.4350, val_loss: 17.0190, val_MinusLogProbMetric: 17.0190

Epoch 535: val_loss did not improve from 16.95801
196/196 - 38s - loss: 16.4350 - MinusLogProbMetric: 16.4350 - val_loss: 17.0190 - val_MinusLogProbMetric: 17.0190 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 536/1000
2023-09-28 03:51:21.692 
Epoch 536/1000 
	 loss: 16.4369, MinusLogProbMetric: 16.4369, val_loss: 16.9949, val_MinusLogProbMetric: 16.9949

Epoch 536: val_loss did not improve from 16.95801
196/196 - 38s - loss: 16.4369 - MinusLogProbMetric: 16.4369 - val_loss: 16.9949 - val_MinusLogProbMetric: 16.9949 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 537/1000
2023-09-28 03:51:59.685 
Epoch 537/1000 
	 loss: 16.4375, MinusLogProbMetric: 16.4375, val_loss: 16.9663, val_MinusLogProbMetric: 16.9663

Epoch 537: val_loss did not improve from 16.95801
196/196 - 38s - loss: 16.4375 - MinusLogProbMetric: 16.4375 - val_loss: 16.9663 - val_MinusLogProbMetric: 16.9663 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 538/1000
2023-09-28 03:52:37.992 
Epoch 538/1000 
	 loss: 16.4318, MinusLogProbMetric: 16.4318, val_loss: 17.0014, val_MinusLogProbMetric: 17.0014

Epoch 538: val_loss did not improve from 16.95801
196/196 - 38s - loss: 16.4318 - MinusLogProbMetric: 16.4318 - val_loss: 17.0014 - val_MinusLogProbMetric: 17.0014 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 539/1000
2023-09-28 03:53:16.083 
Epoch 539/1000 
	 loss: 16.4396, MinusLogProbMetric: 16.4396, val_loss: 16.9563, val_MinusLogProbMetric: 16.9563

Epoch 539: val_loss improved from 16.95801 to 16.95635, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.4396 - MinusLogProbMetric: 16.4396 - val_loss: 16.9563 - val_MinusLogProbMetric: 16.9563 - lr: 6.2500e-05 - 39s/epoch - 198ms/step
Epoch 540/1000
2023-09-28 03:53:54.901 
Epoch 540/1000 
	 loss: 16.4370, MinusLogProbMetric: 16.4370, val_loss: 16.9702, val_MinusLogProbMetric: 16.9702

Epoch 540: val_loss did not improve from 16.95635
196/196 - 38s - loss: 16.4370 - MinusLogProbMetric: 16.4370 - val_loss: 16.9702 - val_MinusLogProbMetric: 16.9702 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 541/1000
2023-09-28 03:54:32.882 
Epoch 541/1000 
	 loss: 16.4367, MinusLogProbMetric: 16.4367, val_loss: 16.9609, val_MinusLogProbMetric: 16.9609

Epoch 541: val_loss did not improve from 16.95635
196/196 - 38s - loss: 16.4367 - MinusLogProbMetric: 16.4367 - val_loss: 16.9609 - val_MinusLogProbMetric: 16.9609 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 542/1000
2023-09-28 03:55:11.130 
Epoch 542/1000 
	 loss: 16.4331, MinusLogProbMetric: 16.4331, val_loss: 16.9668, val_MinusLogProbMetric: 16.9668

Epoch 542: val_loss did not improve from 16.95635
196/196 - 38s - loss: 16.4331 - MinusLogProbMetric: 16.4331 - val_loss: 16.9668 - val_MinusLogProbMetric: 16.9668 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 543/1000
2023-09-28 03:55:48.737 
Epoch 543/1000 
	 loss: 16.4361, MinusLogProbMetric: 16.4361, val_loss: 16.9605, val_MinusLogProbMetric: 16.9605

Epoch 543: val_loss did not improve from 16.95635
196/196 - 38s - loss: 16.4361 - MinusLogProbMetric: 16.4361 - val_loss: 16.9605 - val_MinusLogProbMetric: 16.9605 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 544/1000
2023-09-28 03:56:27.229 
Epoch 544/1000 
	 loss: 16.4359, MinusLogProbMetric: 16.4359, val_loss: 16.9598, val_MinusLogProbMetric: 16.9598

Epoch 544: val_loss did not improve from 16.95635
196/196 - 38s - loss: 16.4359 - MinusLogProbMetric: 16.4359 - val_loss: 16.9598 - val_MinusLogProbMetric: 16.9598 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 545/1000
2023-09-28 03:57:05.476 
Epoch 545/1000 
	 loss: 16.4319, MinusLogProbMetric: 16.4319, val_loss: 16.9707, val_MinusLogProbMetric: 16.9707

Epoch 545: val_loss did not improve from 16.95635
196/196 - 38s - loss: 16.4319 - MinusLogProbMetric: 16.4319 - val_loss: 16.9707 - val_MinusLogProbMetric: 16.9707 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 546/1000
2023-09-28 03:57:43.764 
Epoch 546/1000 
	 loss: 16.4338, MinusLogProbMetric: 16.4338, val_loss: 16.9714, val_MinusLogProbMetric: 16.9714

Epoch 546: val_loss did not improve from 16.95635
196/196 - 38s - loss: 16.4338 - MinusLogProbMetric: 16.4338 - val_loss: 16.9714 - val_MinusLogProbMetric: 16.9714 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 547/1000
2023-09-28 03:58:22.092 
Epoch 547/1000 
	 loss: 16.4324, MinusLogProbMetric: 16.4324, val_loss: 16.9829, val_MinusLogProbMetric: 16.9829

Epoch 547: val_loss did not improve from 16.95635
196/196 - 38s - loss: 16.4324 - MinusLogProbMetric: 16.4324 - val_loss: 16.9829 - val_MinusLogProbMetric: 16.9829 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 548/1000
2023-09-28 03:59:00.221 
Epoch 548/1000 
	 loss: 16.4353, MinusLogProbMetric: 16.4353, val_loss: 16.9584, val_MinusLogProbMetric: 16.9584

Epoch 548: val_loss did not improve from 16.95635
196/196 - 38s - loss: 16.4353 - MinusLogProbMetric: 16.4353 - val_loss: 16.9584 - val_MinusLogProbMetric: 16.9584 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 549/1000
2023-09-28 03:59:38.438 
Epoch 549/1000 
	 loss: 16.4331, MinusLogProbMetric: 16.4331, val_loss: 16.9601, val_MinusLogProbMetric: 16.9601

Epoch 549: val_loss did not improve from 16.95635
196/196 - 38s - loss: 16.4331 - MinusLogProbMetric: 16.4331 - val_loss: 16.9601 - val_MinusLogProbMetric: 16.9601 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 550/1000
2023-09-28 04:00:16.695 
Epoch 550/1000 
	 loss: 16.4342, MinusLogProbMetric: 16.4342, val_loss: 16.9609, val_MinusLogProbMetric: 16.9609

Epoch 550: val_loss did not improve from 16.95635
196/196 - 38s - loss: 16.4342 - MinusLogProbMetric: 16.4342 - val_loss: 16.9609 - val_MinusLogProbMetric: 16.9609 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 551/1000
2023-09-28 04:00:55.084 
Epoch 551/1000 
	 loss: 16.4294, MinusLogProbMetric: 16.4294, val_loss: 17.0161, val_MinusLogProbMetric: 17.0161

Epoch 551: val_loss did not improve from 16.95635
196/196 - 38s - loss: 16.4294 - MinusLogProbMetric: 16.4294 - val_loss: 17.0161 - val_MinusLogProbMetric: 17.0161 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 552/1000
2023-09-28 04:01:33.369 
Epoch 552/1000 
	 loss: 16.4329, MinusLogProbMetric: 16.4329, val_loss: 16.9680, val_MinusLogProbMetric: 16.9680

Epoch 552: val_loss did not improve from 16.95635
196/196 - 38s - loss: 16.4329 - MinusLogProbMetric: 16.4329 - val_loss: 16.9680 - val_MinusLogProbMetric: 16.9680 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 553/1000
2023-09-28 04:02:11.741 
Epoch 553/1000 
	 loss: 16.4400, MinusLogProbMetric: 16.4400, val_loss: 16.9557, val_MinusLogProbMetric: 16.9557

Epoch 553: val_loss improved from 16.95635 to 16.95567, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.4400 - MinusLogProbMetric: 16.4400 - val_loss: 16.9557 - val_MinusLogProbMetric: 16.9557 - lr: 6.2500e-05 - 39s/epoch - 200ms/step
Epoch 554/1000
2023-09-28 04:02:50.675 
Epoch 554/1000 
	 loss: 16.4367, MinusLogProbMetric: 16.4367, val_loss: 16.9684, val_MinusLogProbMetric: 16.9684

Epoch 554: val_loss did not improve from 16.95567
196/196 - 38s - loss: 16.4367 - MinusLogProbMetric: 16.4367 - val_loss: 16.9684 - val_MinusLogProbMetric: 16.9684 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 555/1000
2023-09-28 04:03:28.859 
Epoch 555/1000 
	 loss: 16.4279, MinusLogProbMetric: 16.4279, val_loss: 16.9574, val_MinusLogProbMetric: 16.9574

Epoch 555: val_loss did not improve from 16.95567
196/196 - 38s - loss: 16.4279 - MinusLogProbMetric: 16.4279 - val_loss: 16.9574 - val_MinusLogProbMetric: 16.9574 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 556/1000
2023-09-28 04:04:07.262 
Epoch 556/1000 
	 loss: 16.4333, MinusLogProbMetric: 16.4333, val_loss: 16.9628, val_MinusLogProbMetric: 16.9628

Epoch 556: val_loss did not improve from 16.95567
196/196 - 38s - loss: 16.4333 - MinusLogProbMetric: 16.4333 - val_loss: 16.9628 - val_MinusLogProbMetric: 16.9628 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 557/1000
2023-09-28 04:04:45.798 
Epoch 557/1000 
	 loss: 16.4299, MinusLogProbMetric: 16.4299, val_loss: 16.9585, val_MinusLogProbMetric: 16.9585

Epoch 557: val_loss did not improve from 16.95567
196/196 - 39s - loss: 16.4299 - MinusLogProbMetric: 16.4299 - val_loss: 16.9585 - val_MinusLogProbMetric: 16.9585 - lr: 6.2500e-05 - 39s/epoch - 197ms/step
Epoch 558/1000
2023-09-28 04:05:24.202 
Epoch 558/1000 
	 loss: 16.4318, MinusLogProbMetric: 16.4318, val_loss: 16.9576, val_MinusLogProbMetric: 16.9576

Epoch 558: val_loss did not improve from 16.95567
196/196 - 38s - loss: 16.4318 - MinusLogProbMetric: 16.4318 - val_loss: 16.9576 - val_MinusLogProbMetric: 16.9576 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 559/1000
2023-09-28 04:06:02.422 
Epoch 559/1000 
	 loss: 16.4296, MinusLogProbMetric: 16.4296, val_loss: 16.9776, val_MinusLogProbMetric: 16.9776

Epoch 559: val_loss did not improve from 16.95567
196/196 - 38s - loss: 16.4296 - MinusLogProbMetric: 16.4296 - val_loss: 16.9776 - val_MinusLogProbMetric: 16.9776 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 560/1000
2023-09-28 04:06:40.629 
Epoch 560/1000 
	 loss: 16.4382, MinusLogProbMetric: 16.4382, val_loss: 16.9991, val_MinusLogProbMetric: 16.9991

Epoch 560: val_loss did not improve from 16.95567
196/196 - 38s - loss: 16.4382 - MinusLogProbMetric: 16.4382 - val_loss: 16.9991 - val_MinusLogProbMetric: 16.9991 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 561/1000
2023-09-28 04:07:18.831 
Epoch 561/1000 
	 loss: 16.4398, MinusLogProbMetric: 16.4398, val_loss: 16.9604, val_MinusLogProbMetric: 16.9604

Epoch 561: val_loss did not improve from 16.95567
196/196 - 38s - loss: 16.4398 - MinusLogProbMetric: 16.4398 - val_loss: 16.9604 - val_MinusLogProbMetric: 16.9604 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 562/1000
2023-09-28 04:07:56.876 
Epoch 562/1000 
	 loss: 16.4342, MinusLogProbMetric: 16.4342, val_loss: 16.9555, val_MinusLogProbMetric: 16.9555

Epoch 562: val_loss improved from 16.95567 to 16.95553, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.4342 - MinusLogProbMetric: 16.4342 - val_loss: 16.9555 - val_MinusLogProbMetric: 16.9555 - lr: 6.2500e-05 - 39s/epoch - 198ms/step
Epoch 563/1000
2023-09-28 04:08:35.751 
Epoch 563/1000 
	 loss: 16.4282, MinusLogProbMetric: 16.4282, val_loss: 16.9672, val_MinusLogProbMetric: 16.9672

Epoch 563: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4282 - MinusLogProbMetric: 16.4282 - val_loss: 16.9672 - val_MinusLogProbMetric: 16.9672 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 564/1000
2023-09-28 04:09:14.023 
Epoch 564/1000 
	 loss: 16.4303, MinusLogProbMetric: 16.4303, val_loss: 16.9631, val_MinusLogProbMetric: 16.9631

Epoch 564: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4303 - MinusLogProbMetric: 16.4303 - val_loss: 16.9631 - val_MinusLogProbMetric: 16.9631 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 565/1000
2023-09-28 04:09:51.977 
Epoch 565/1000 
	 loss: 16.4329, MinusLogProbMetric: 16.4329, val_loss: 17.0282, val_MinusLogProbMetric: 17.0282

Epoch 565: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4329 - MinusLogProbMetric: 16.4329 - val_loss: 17.0282 - val_MinusLogProbMetric: 17.0282 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 566/1000
2023-09-28 04:10:30.572 
Epoch 566/1000 
	 loss: 16.4298, MinusLogProbMetric: 16.4298, val_loss: 16.9672, val_MinusLogProbMetric: 16.9672

Epoch 566: val_loss did not improve from 16.95553
196/196 - 39s - loss: 16.4298 - MinusLogProbMetric: 16.4298 - val_loss: 16.9672 - val_MinusLogProbMetric: 16.9672 - lr: 6.2500e-05 - 39s/epoch - 197ms/step
Epoch 567/1000
2023-09-28 04:11:08.671 
Epoch 567/1000 
	 loss: 16.4282, MinusLogProbMetric: 16.4282, val_loss: 16.9641, val_MinusLogProbMetric: 16.9641

Epoch 567: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4282 - MinusLogProbMetric: 16.4282 - val_loss: 16.9641 - val_MinusLogProbMetric: 16.9641 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 568/1000
2023-09-28 04:11:46.721 
Epoch 568/1000 
	 loss: 16.4298, MinusLogProbMetric: 16.4298, val_loss: 16.9618, val_MinusLogProbMetric: 16.9618

Epoch 568: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4298 - MinusLogProbMetric: 16.4298 - val_loss: 16.9618 - val_MinusLogProbMetric: 16.9618 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 569/1000
2023-09-28 04:12:24.652 
Epoch 569/1000 
	 loss: 16.4309, MinusLogProbMetric: 16.4309, val_loss: 16.9636, val_MinusLogProbMetric: 16.9636

Epoch 569: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4309 - MinusLogProbMetric: 16.4309 - val_loss: 16.9636 - val_MinusLogProbMetric: 16.9636 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 570/1000
2023-09-28 04:13:02.955 
Epoch 570/1000 
	 loss: 16.4315, MinusLogProbMetric: 16.4315, val_loss: 16.9643, val_MinusLogProbMetric: 16.9643

Epoch 570: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4315 - MinusLogProbMetric: 16.4315 - val_loss: 16.9643 - val_MinusLogProbMetric: 16.9643 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 571/1000
2023-09-28 04:13:41.420 
Epoch 571/1000 
	 loss: 16.4287, MinusLogProbMetric: 16.4287, val_loss: 16.9602, val_MinusLogProbMetric: 16.9602

Epoch 571: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4287 - MinusLogProbMetric: 16.4287 - val_loss: 16.9602 - val_MinusLogProbMetric: 16.9602 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 572/1000
2023-09-28 04:14:19.713 
Epoch 572/1000 
	 loss: 16.4388, MinusLogProbMetric: 16.4388, val_loss: 16.9631, val_MinusLogProbMetric: 16.9631

Epoch 572: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4388 - MinusLogProbMetric: 16.4388 - val_loss: 16.9631 - val_MinusLogProbMetric: 16.9631 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 573/1000
2023-09-28 04:14:57.641 
Epoch 573/1000 
	 loss: 16.4267, MinusLogProbMetric: 16.4267, val_loss: 16.9821, val_MinusLogProbMetric: 16.9821

Epoch 573: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4267 - MinusLogProbMetric: 16.4267 - val_loss: 16.9821 - val_MinusLogProbMetric: 16.9821 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 574/1000
2023-09-28 04:15:35.599 
Epoch 574/1000 
	 loss: 16.4363, MinusLogProbMetric: 16.4363, val_loss: 16.9760, val_MinusLogProbMetric: 16.9760

Epoch 574: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4363 - MinusLogProbMetric: 16.4363 - val_loss: 16.9760 - val_MinusLogProbMetric: 16.9760 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 575/1000
2023-09-28 04:16:13.941 
Epoch 575/1000 
	 loss: 16.4315, MinusLogProbMetric: 16.4315, val_loss: 16.9802, val_MinusLogProbMetric: 16.9802

Epoch 575: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4315 - MinusLogProbMetric: 16.4315 - val_loss: 16.9802 - val_MinusLogProbMetric: 16.9802 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 576/1000
2023-09-28 04:16:52.119 
Epoch 576/1000 
	 loss: 16.4262, MinusLogProbMetric: 16.4262, val_loss: 17.0348, val_MinusLogProbMetric: 17.0348

Epoch 576: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4262 - MinusLogProbMetric: 16.4262 - val_loss: 17.0348 - val_MinusLogProbMetric: 17.0348 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 577/1000
2023-09-28 04:17:30.310 
Epoch 577/1000 
	 loss: 16.4316, MinusLogProbMetric: 16.4316, val_loss: 16.9923, val_MinusLogProbMetric: 16.9923

Epoch 577: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4316 - MinusLogProbMetric: 16.4316 - val_loss: 16.9923 - val_MinusLogProbMetric: 16.9923 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 578/1000
2023-09-28 04:18:08.652 
Epoch 578/1000 
	 loss: 16.4366, MinusLogProbMetric: 16.4366, val_loss: 16.9759, val_MinusLogProbMetric: 16.9759

Epoch 578: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4366 - MinusLogProbMetric: 16.4366 - val_loss: 16.9759 - val_MinusLogProbMetric: 16.9759 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 579/1000
2023-09-28 04:18:47.003 
Epoch 579/1000 
	 loss: 16.4326, MinusLogProbMetric: 16.4326, val_loss: 16.9650, val_MinusLogProbMetric: 16.9650

Epoch 579: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4326 - MinusLogProbMetric: 16.4326 - val_loss: 16.9650 - val_MinusLogProbMetric: 16.9650 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 580/1000
2023-09-28 04:19:24.675 
Epoch 580/1000 
	 loss: 16.4288, MinusLogProbMetric: 16.4288, val_loss: 16.9778, val_MinusLogProbMetric: 16.9778

Epoch 580: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4288 - MinusLogProbMetric: 16.4288 - val_loss: 16.9778 - val_MinusLogProbMetric: 16.9778 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 581/1000
2023-09-28 04:20:02.512 
Epoch 581/1000 
	 loss: 16.4320, MinusLogProbMetric: 16.4320, val_loss: 16.9592, val_MinusLogProbMetric: 16.9592

Epoch 581: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4320 - MinusLogProbMetric: 16.4320 - val_loss: 16.9592 - val_MinusLogProbMetric: 16.9592 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 582/1000
2023-09-28 04:20:40.931 
Epoch 582/1000 
	 loss: 16.4359, MinusLogProbMetric: 16.4359, val_loss: 16.9639, val_MinusLogProbMetric: 16.9639

Epoch 582: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4359 - MinusLogProbMetric: 16.4359 - val_loss: 16.9639 - val_MinusLogProbMetric: 16.9639 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 583/1000
2023-09-28 04:21:18.760 
Epoch 583/1000 
	 loss: 16.4280, MinusLogProbMetric: 16.4280, val_loss: 16.9937, val_MinusLogProbMetric: 16.9937

Epoch 583: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4280 - MinusLogProbMetric: 16.4280 - val_loss: 16.9937 - val_MinusLogProbMetric: 16.9937 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 584/1000
2023-09-28 04:21:56.967 
Epoch 584/1000 
	 loss: 16.4390, MinusLogProbMetric: 16.4390, val_loss: 16.9611, val_MinusLogProbMetric: 16.9611

Epoch 584: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4390 - MinusLogProbMetric: 16.4390 - val_loss: 16.9611 - val_MinusLogProbMetric: 16.9611 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 585/1000
2023-09-28 04:22:34.981 
Epoch 585/1000 
	 loss: 16.4290, MinusLogProbMetric: 16.4290, val_loss: 16.9744, val_MinusLogProbMetric: 16.9744

Epoch 585: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4290 - MinusLogProbMetric: 16.4290 - val_loss: 16.9744 - val_MinusLogProbMetric: 16.9744 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 586/1000
2023-09-28 04:23:13.328 
Epoch 586/1000 
	 loss: 16.4381, MinusLogProbMetric: 16.4381, val_loss: 17.0243, val_MinusLogProbMetric: 17.0243

Epoch 586: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4381 - MinusLogProbMetric: 16.4381 - val_loss: 17.0243 - val_MinusLogProbMetric: 17.0243 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 587/1000
2023-09-28 04:23:51.384 
Epoch 587/1000 
	 loss: 16.4406, MinusLogProbMetric: 16.4406, val_loss: 16.9585, val_MinusLogProbMetric: 16.9585

Epoch 587: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4406 - MinusLogProbMetric: 16.4406 - val_loss: 16.9585 - val_MinusLogProbMetric: 16.9585 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 588/1000
2023-09-28 04:24:29.718 
Epoch 588/1000 
	 loss: 16.4316, MinusLogProbMetric: 16.4316, val_loss: 17.0440, val_MinusLogProbMetric: 17.0440

Epoch 588: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4316 - MinusLogProbMetric: 16.4316 - val_loss: 17.0440 - val_MinusLogProbMetric: 17.0440 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 589/1000
2023-09-28 04:25:07.768 
Epoch 589/1000 
	 loss: 16.4336, MinusLogProbMetric: 16.4336, val_loss: 16.9906, val_MinusLogProbMetric: 16.9906

Epoch 589: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4336 - MinusLogProbMetric: 16.4336 - val_loss: 16.9906 - val_MinusLogProbMetric: 16.9906 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 590/1000
2023-09-28 04:25:45.976 
Epoch 590/1000 
	 loss: 16.4282, MinusLogProbMetric: 16.4282, val_loss: 16.9648, val_MinusLogProbMetric: 16.9648

Epoch 590: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4282 - MinusLogProbMetric: 16.4282 - val_loss: 16.9648 - val_MinusLogProbMetric: 16.9648 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 591/1000
2023-09-28 04:26:24.249 
Epoch 591/1000 
	 loss: 16.4295, MinusLogProbMetric: 16.4295, val_loss: 16.9759, val_MinusLogProbMetric: 16.9759

Epoch 591: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4295 - MinusLogProbMetric: 16.4295 - val_loss: 16.9759 - val_MinusLogProbMetric: 16.9759 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 592/1000
2023-09-28 04:27:02.239 
Epoch 592/1000 
	 loss: 16.4269, MinusLogProbMetric: 16.4269, val_loss: 17.0483, val_MinusLogProbMetric: 17.0483

Epoch 592: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4269 - MinusLogProbMetric: 16.4269 - val_loss: 17.0483 - val_MinusLogProbMetric: 17.0483 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 593/1000
2023-09-28 04:27:40.408 
Epoch 593/1000 
	 loss: 16.4415, MinusLogProbMetric: 16.4415, val_loss: 16.9664, val_MinusLogProbMetric: 16.9664

Epoch 593: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4415 - MinusLogProbMetric: 16.4415 - val_loss: 16.9664 - val_MinusLogProbMetric: 16.9664 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 594/1000
2023-09-28 04:28:18.390 
Epoch 594/1000 
	 loss: 16.4226, MinusLogProbMetric: 16.4226, val_loss: 16.9794, val_MinusLogProbMetric: 16.9794

Epoch 594: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4226 - MinusLogProbMetric: 16.4226 - val_loss: 16.9794 - val_MinusLogProbMetric: 16.9794 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 595/1000
2023-09-28 04:28:56.591 
Epoch 595/1000 
	 loss: 16.4303, MinusLogProbMetric: 16.4303, val_loss: 16.9879, val_MinusLogProbMetric: 16.9879

Epoch 595: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4303 - MinusLogProbMetric: 16.4303 - val_loss: 16.9879 - val_MinusLogProbMetric: 16.9879 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 596/1000
2023-09-28 04:29:34.711 
Epoch 596/1000 
	 loss: 16.4221, MinusLogProbMetric: 16.4221, val_loss: 16.9635, val_MinusLogProbMetric: 16.9635

Epoch 596: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4221 - MinusLogProbMetric: 16.4221 - val_loss: 16.9635 - val_MinusLogProbMetric: 16.9635 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 597/1000
2023-09-28 04:30:13.007 
Epoch 597/1000 
	 loss: 16.4280, MinusLogProbMetric: 16.4280, val_loss: 16.9820, val_MinusLogProbMetric: 16.9820

Epoch 597: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4280 - MinusLogProbMetric: 16.4280 - val_loss: 16.9820 - val_MinusLogProbMetric: 16.9820 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 598/1000
2023-09-28 04:30:50.930 
Epoch 598/1000 
	 loss: 16.4282, MinusLogProbMetric: 16.4282, val_loss: 16.9912, val_MinusLogProbMetric: 16.9912

Epoch 598: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4282 - MinusLogProbMetric: 16.4282 - val_loss: 16.9912 - val_MinusLogProbMetric: 16.9912 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 599/1000
2023-09-28 04:31:29.114 
Epoch 599/1000 
	 loss: 16.4281, MinusLogProbMetric: 16.4281, val_loss: 16.9819, val_MinusLogProbMetric: 16.9819

Epoch 599: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4281 - MinusLogProbMetric: 16.4281 - val_loss: 16.9819 - val_MinusLogProbMetric: 16.9819 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 600/1000
2023-09-28 04:32:07.196 
Epoch 600/1000 
	 loss: 16.4265, MinusLogProbMetric: 16.4265, val_loss: 17.0287, val_MinusLogProbMetric: 17.0287

Epoch 600: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4265 - MinusLogProbMetric: 16.4265 - val_loss: 17.0287 - val_MinusLogProbMetric: 17.0287 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 601/1000
2023-09-28 04:32:44.893 
Epoch 601/1000 
	 loss: 16.4338, MinusLogProbMetric: 16.4338, val_loss: 17.0158, val_MinusLogProbMetric: 17.0158

Epoch 601: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4338 - MinusLogProbMetric: 16.4338 - val_loss: 17.0158 - val_MinusLogProbMetric: 17.0158 - lr: 6.2500e-05 - 38s/epoch - 192ms/step
Epoch 602/1000
2023-09-28 04:33:22.722 
Epoch 602/1000 
	 loss: 16.4321, MinusLogProbMetric: 16.4321, val_loss: 16.9660, val_MinusLogProbMetric: 16.9660

Epoch 602: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4321 - MinusLogProbMetric: 16.4321 - val_loss: 16.9660 - val_MinusLogProbMetric: 16.9660 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 603/1000
2023-09-28 04:34:00.593 
Epoch 603/1000 
	 loss: 16.4272, MinusLogProbMetric: 16.4272, val_loss: 17.0572, val_MinusLogProbMetric: 17.0572

Epoch 603: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4272 - MinusLogProbMetric: 16.4272 - val_loss: 17.0572 - val_MinusLogProbMetric: 17.0572 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 604/1000
2023-09-28 04:34:38.761 
Epoch 604/1000 
	 loss: 16.4341, MinusLogProbMetric: 16.4341, val_loss: 16.9732, val_MinusLogProbMetric: 16.9732

Epoch 604: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4341 - MinusLogProbMetric: 16.4341 - val_loss: 16.9732 - val_MinusLogProbMetric: 16.9732 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 605/1000
2023-09-28 04:35:16.824 
Epoch 605/1000 
	 loss: 16.4341, MinusLogProbMetric: 16.4341, val_loss: 16.9627, val_MinusLogProbMetric: 16.9627

Epoch 605: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4341 - MinusLogProbMetric: 16.4341 - val_loss: 16.9627 - val_MinusLogProbMetric: 16.9627 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 606/1000
2023-09-28 04:35:54.837 
Epoch 606/1000 
	 loss: 16.4237, MinusLogProbMetric: 16.4237, val_loss: 16.9599, val_MinusLogProbMetric: 16.9599

Epoch 606: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4237 - MinusLogProbMetric: 16.4237 - val_loss: 16.9599 - val_MinusLogProbMetric: 16.9599 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 607/1000
2023-09-28 04:36:33.213 
Epoch 607/1000 
	 loss: 16.4253, MinusLogProbMetric: 16.4253, val_loss: 16.9629, val_MinusLogProbMetric: 16.9629

Epoch 607: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4253 - MinusLogProbMetric: 16.4253 - val_loss: 16.9629 - val_MinusLogProbMetric: 16.9629 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 608/1000
2023-09-28 04:37:11.571 
Epoch 608/1000 
	 loss: 16.4352, MinusLogProbMetric: 16.4352, val_loss: 16.9651, val_MinusLogProbMetric: 16.9651

Epoch 608: val_loss did not improve from 16.95553
196/196 - 38s - loss: 16.4352 - MinusLogProbMetric: 16.4352 - val_loss: 16.9651 - val_MinusLogProbMetric: 16.9651 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 609/1000
2023-09-28 04:37:49.771 
Epoch 609/1000 
	 loss: 16.4271, MinusLogProbMetric: 16.4271, val_loss: 16.9538, val_MinusLogProbMetric: 16.9538

Epoch 609: val_loss improved from 16.95553 to 16.95384, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.4271 - MinusLogProbMetric: 16.4271 - val_loss: 16.9538 - val_MinusLogProbMetric: 16.9538 - lr: 6.2500e-05 - 39s/epoch - 198ms/step
Epoch 610/1000
2023-09-28 04:38:28.625 
Epoch 610/1000 
	 loss: 16.4211, MinusLogProbMetric: 16.4211, val_loss: 16.9574, val_MinusLogProbMetric: 16.9574

Epoch 610: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4211 - MinusLogProbMetric: 16.4211 - val_loss: 16.9574 - val_MinusLogProbMetric: 16.9574 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 611/1000
2023-09-28 04:39:06.621 
Epoch 611/1000 
	 loss: 16.4206, MinusLogProbMetric: 16.4206, val_loss: 17.0238, val_MinusLogProbMetric: 17.0238

Epoch 611: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4206 - MinusLogProbMetric: 16.4206 - val_loss: 17.0238 - val_MinusLogProbMetric: 17.0238 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 612/1000
2023-09-28 04:39:44.895 
Epoch 612/1000 
	 loss: 16.4311, MinusLogProbMetric: 16.4311, val_loss: 16.9627, val_MinusLogProbMetric: 16.9627

Epoch 612: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4311 - MinusLogProbMetric: 16.4311 - val_loss: 16.9627 - val_MinusLogProbMetric: 16.9627 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 613/1000
2023-09-28 04:40:23.000 
Epoch 613/1000 
	 loss: 16.4256, MinusLogProbMetric: 16.4256, val_loss: 16.9582, val_MinusLogProbMetric: 16.9582

Epoch 613: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4256 - MinusLogProbMetric: 16.4256 - val_loss: 16.9582 - val_MinusLogProbMetric: 16.9582 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 614/1000
2023-09-28 04:41:01.361 
Epoch 614/1000 
	 loss: 16.4244, MinusLogProbMetric: 16.4244, val_loss: 16.9610, val_MinusLogProbMetric: 16.9610

Epoch 614: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4244 - MinusLogProbMetric: 16.4244 - val_loss: 16.9610 - val_MinusLogProbMetric: 16.9610 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 615/1000
2023-09-28 04:41:39.576 
Epoch 615/1000 
	 loss: 16.4257, MinusLogProbMetric: 16.4257, val_loss: 16.9804, val_MinusLogProbMetric: 16.9804

Epoch 615: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4257 - MinusLogProbMetric: 16.4257 - val_loss: 16.9804 - val_MinusLogProbMetric: 16.9804 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 616/1000
2023-09-28 04:42:17.999 
Epoch 616/1000 
	 loss: 16.4270, MinusLogProbMetric: 16.4270, val_loss: 16.9594, val_MinusLogProbMetric: 16.9594

Epoch 616: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4270 - MinusLogProbMetric: 16.4270 - val_loss: 16.9594 - val_MinusLogProbMetric: 16.9594 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 617/1000
2023-09-28 04:42:55.771 
Epoch 617/1000 
	 loss: 16.4267, MinusLogProbMetric: 16.4267, val_loss: 16.9702, val_MinusLogProbMetric: 16.9702

Epoch 617: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4267 - MinusLogProbMetric: 16.4267 - val_loss: 16.9702 - val_MinusLogProbMetric: 16.9702 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 618/1000
2023-09-28 04:43:33.788 
Epoch 618/1000 
	 loss: 16.4310, MinusLogProbMetric: 16.4310, val_loss: 16.9566, val_MinusLogProbMetric: 16.9566

Epoch 618: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4310 - MinusLogProbMetric: 16.4310 - val_loss: 16.9566 - val_MinusLogProbMetric: 16.9566 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 619/1000
2023-09-28 04:44:12.158 
Epoch 619/1000 
	 loss: 16.4213, MinusLogProbMetric: 16.4213, val_loss: 16.9640, val_MinusLogProbMetric: 16.9640

Epoch 619: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4213 - MinusLogProbMetric: 16.4213 - val_loss: 16.9640 - val_MinusLogProbMetric: 16.9640 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 620/1000
2023-09-28 04:44:50.218 
Epoch 620/1000 
	 loss: 16.4337, MinusLogProbMetric: 16.4337, val_loss: 16.9922, val_MinusLogProbMetric: 16.9922

Epoch 620: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4337 - MinusLogProbMetric: 16.4337 - val_loss: 16.9922 - val_MinusLogProbMetric: 16.9922 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 621/1000
2023-09-28 04:45:28.498 
Epoch 621/1000 
	 loss: 16.4287, MinusLogProbMetric: 16.4287, val_loss: 16.9557, val_MinusLogProbMetric: 16.9557

Epoch 621: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4287 - MinusLogProbMetric: 16.4287 - val_loss: 16.9557 - val_MinusLogProbMetric: 16.9557 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 622/1000
2023-09-28 04:46:06.603 
Epoch 622/1000 
	 loss: 16.4453, MinusLogProbMetric: 16.4453, val_loss: 16.9649, val_MinusLogProbMetric: 16.9649

Epoch 622: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4453 - MinusLogProbMetric: 16.4453 - val_loss: 16.9649 - val_MinusLogProbMetric: 16.9649 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 623/1000
2023-09-28 04:46:44.638 
Epoch 623/1000 
	 loss: 16.4218, MinusLogProbMetric: 16.4218, val_loss: 16.9562, val_MinusLogProbMetric: 16.9562

Epoch 623: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4218 - MinusLogProbMetric: 16.4218 - val_loss: 16.9562 - val_MinusLogProbMetric: 16.9562 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 624/1000
2023-09-28 04:47:22.980 
Epoch 624/1000 
	 loss: 16.4245, MinusLogProbMetric: 16.4245, val_loss: 16.9756, val_MinusLogProbMetric: 16.9756

Epoch 624: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4245 - MinusLogProbMetric: 16.4245 - val_loss: 16.9756 - val_MinusLogProbMetric: 16.9756 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 625/1000
2023-09-28 04:48:00.723 
Epoch 625/1000 
	 loss: 16.4217, MinusLogProbMetric: 16.4217, val_loss: 16.9932, val_MinusLogProbMetric: 16.9932

Epoch 625: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4217 - MinusLogProbMetric: 16.4217 - val_loss: 16.9932 - val_MinusLogProbMetric: 16.9932 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 626/1000
2023-09-28 04:48:38.766 
Epoch 626/1000 
	 loss: 16.4294, MinusLogProbMetric: 16.4294, val_loss: 16.9792, val_MinusLogProbMetric: 16.9792

Epoch 626: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4294 - MinusLogProbMetric: 16.4294 - val_loss: 16.9792 - val_MinusLogProbMetric: 16.9792 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 627/1000
2023-09-28 04:49:16.925 
Epoch 627/1000 
	 loss: 16.4200, MinusLogProbMetric: 16.4200, val_loss: 16.9797, val_MinusLogProbMetric: 16.9797

Epoch 627: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4200 - MinusLogProbMetric: 16.4200 - val_loss: 16.9797 - val_MinusLogProbMetric: 16.9797 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 628/1000
2023-09-28 04:49:55.041 
Epoch 628/1000 
	 loss: 16.4254, MinusLogProbMetric: 16.4254, val_loss: 16.9850, val_MinusLogProbMetric: 16.9850

Epoch 628: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4254 - MinusLogProbMetric: 16.4254 - val_loss: 16.9850 - val_MinusLogProbMetric: 16.9850 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 629/1000
2023-09-28 04:50:33.198 
Epoch 629/1000 
	 loss: 16.4303, MinusLogProbMetric: 16.4303, val_loss: 16.9543, val_MinusLogProbMetric: 16.9543

Epoch 629: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4303 - MinusLogProbMetric: 16.4303 - val_loss: 16.9543 - val_MinusLogProbMetric: 16.9543 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 630/1000
2023-09-28 04:51:11.447 
Epoch 630/1000 
	 loss: 16.4271, MinusLogProbMetric: 16.4271, val_loss: 16.9752, val_MinusLogProbMetric: 16.9752

Epoch 630: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4271 - MinusLogProbMetric: 16.4271 - val_loss: 16.9752 - val_MinusLogProbMetric: 16.9752 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 631/1000
2023-09-28 04:51:49.752 
Epoch 631/1000 
	 loss: 16.4242, MinusLogProbMetric: 16.4242, val_loss: 16.9664, val_MinusLogProbMetric: 16.9664

Epoch 631: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4242 - MinusLogProbMetric: 16.4242 - val_loss: 16.9664 - val_MinusLogProbMetric: 16.9664 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 632/1000
2023-09-28 04:52:27.934 
Epoch 632/1000 
	 loss: 16.4296, MinusLogProbMetric: 16.4296, val_loss: 17.0342, val_MinusLogProbMetric: 17.0342

Epoch 632: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4296 - MinusLogProbMetric: 16.4296 - val_loss: 17.0342 - val_MinusLogProbMetric: 17.0342 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 633/1000
2023-09-28 04:53:05.995 
Epoch 633/1000 
	 loss: 16.4308, MinusLogProbMetric: 16.4308, val_loss: 16.9644, val_MinusLogProbMetric: 16.9644

Epoch 633: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4308 - MinusLogProbMetric: 16.4308 - val_loss: 16.9644 - val_MinusLogProbMetric: 16.9644 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 634/1000
2023-09-28 04:53:44.381 
Epoch 634/1000 
	 loss: 16.4322, MinusLogProbMetric: 16.4322, val_loss: 16.9906, val_MinusLogProbMetric: 16.9906

Epoch 634: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4322 - MinusLogProbMetric: 16.4322 - val_loss: 16.9906 - val_MinusLogProbMetric: 16.9906 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 635/1000
2023-09-28 04:54:22.728 
Epoch 635/1000 
	 loss: 16.4223, MinusLogProbMetric: 16.4223, val_loss: 16.9677, val_MinusLogProbMetric: 16.9677

Epoch 635: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4223 - MinusLogProbMetric: 16.4223 - val_loss: 16.9677 - val_MinusLogProbMetric: 16.9677 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 636/1000
2023-09-28 04:55:00.934 
Epoch 636/1000 
	 loss: 16.4215, MinusLogProbMetric: 16.4215, val_loss: 17.0261, val_MinusLogProbMetric: 17.0261

Epoch 636: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4215 - MinusLogProbMetric: 16.4215 - val_loss: 17.0261 - val_MinusLogProbMetric: 17.0261 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 637/1000
2023-09-28 04:55:39.387 
Epoch 637/1000 
	 loss: 16.4234, MinusLogProbMetric: 16.4234, val_loss: 16.9666, val_MinusLogProbMetric: 16.9666

Epoch 637: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4234 - MinusLogProbMetric: 16.4234 - val_loss: 16.9666 - val_MinusLogProbMetric: 16.9666 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 638/1000
2023-09-28 04:56:17.857 
Epoch 638/1000 
	 loss: 16.4329, MinusLogProbMetric: 16.4329, val_loss: 17.0069, val_MinusLogProbMetric: 17.0069

Epoch 638: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4329 - MinusLogProbMetric: 16.4329 - val_loss: 17.0069 - val_MinusLogProbMetric: 17.0069 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 639/1000
2023-09-28 04:56:56.014 
Epoch 639/1000 
	 loss: 16.4273, MinusLogProbMetric: 16.4273, val_loss: 16.9577, val_MinusLogProbMetric: 16.9577

Epoch 639: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4273 - MinusLogProbMetric: 16.4273 - val_loss: 16.9577 - val_MinusLogProbMetric: 16.9577 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 640/1000
2023-09-28 04:57:34.090 
Epoch 640/1000 
	 loss: 16.4157, MinusLogProbMetric: 16.4157, val_loss: 16.9755, val_MinusLogProbMetric: 16.9755

Epoch 640: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4157 - MinusLogProbMetric: 16.4157 - val_loss: 16.9755 - val_MinusLogProbMetric: 16.9755 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 641/1000
2023-09-28 04:58:12.092 
Epoch 641/1000 
	 loss: 16.4238, MinusLogProbMetric: 16.4238, val_loss: 16.9654, val_MinusLogProbMetric: 16.9654

Epoch 641: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4238 - MinusLogProbMetric: 16.4238 - val_loss: 16.9654 - val_MinusLogProbMetric: 16.9654 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 642/1000
2023-09-28 04:58:50.197 
Epoch 642/1000 
	 loss: 16.4202, MinusLogProbMetric: 16.4202, val_loss: 16.9646, val_MinusLogProbMetric: 16.9646

Epoch 642: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4202 - MinusLogProbMetric: 16.4202 - val_loss: 16.9646 - val_MinusLogProbMetric: 16.9646 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 643/1000
2023-09-28 04:59:28.244 
Epoch 643/1000 
	 loss: 16.4241, MinusLogProbMetric: 16.4241, val_loss: 16.9624, val_MinusLogProbMetric: 16.9624

Epoch 643: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4241 - MinusLogProbMetric: 16.4241 - val_loss: 16.9624 - val_MinusLogProbMetric: 16.9624 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 644/1000
2023-09-28 05:00:06.595 
Epoch 644/1000 
	 loss: 16.4270, MinusLogProbMetric: 16.4270, val_loss: 17.0496, val_MinusLogProbMetric: 17.0496

Epoch 644: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4270 - MinusLogProbMetric: 16.4270 - val_loss: 17.0496 - val_MinusLogProbMetric: 17.0496 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 645/1000
2023-09-28 05:00:44.927 
Epoch 645/1000 
	 loss: 16.4266, MinusLogProbMetric: 16.4266, val_loss: 16.9914, val_MinusLogProbMetric: 16.9914

Epoch 645: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4266 - MinusLogProbMetric: 16.4266 - val_loss: 16.9914 - val_MinusLogProbMetric: 16.9914 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 646/1000
2023-09-28 05:01:23.405 
Epoch 646/1000 
	 loss: 16.4256, MinusLogProbMetric: 16.4256, val_loss: 16.9911, val_MinusLogProbMetric: 16.9911

Epoch 646: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4256 - MinusLogProbMetric: 16.4256 - val_loss: 16.9911 - val_MinusLogProbMetric: 16.9911 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 647/1000
2023-09-28 05:02:01.683 
Epoch 647/1000 
	 loss: 16.4293, MinusLogProbMetric: 16.4293, val_loss: 16.9565, val_MinusLogProbMetric: 16.9565

Epoch 647: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4293 - MinusLogProbMetric: 16.4293 - val_loss: 16.9565 - val_MinusLogProbMetric: 16.9565 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 648/1000
2023-09-28 05:02:39.829 
Epoch 648/1000 
	 loss: 16.4212, MinusLogProbMetric: 16.4212, val_loss: 16.9806, val_MinusLogProbMetric: 16.9806

Epoch 648: val_loss did not improve from 16.95384
196/196 - 38s - loss: 16.4212 - MinusLogProbMetric: 16.4212 - val_loss: 16.9806 - val_MinusLogProbMetric: 16.9806 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 649/1000
2023-09-28 05:03:17.668 
Epoch 649/1000 
	 loss: 16.4339, MinusLogProbMetric: 16.4339, val_loss: 16.9535, val_MinusLogProbMetric: 16.9535

Epoch 649: val_loss improved from 16.95384 to 16.95352, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.4339 - MinusLogProbMetric: 16.4339 - val_loss: 16.9535 - val_MinusLogProbMetric: 16.9535 - lr: 6.2500e-05 - 39s/epoch - 197ms/step
Epoch 650/1000
2023-09-28 05:03:56.650 
Epoch 650/1000 
	 loss: 16.4171, MinusLogProbMetric: 16.4171, val_loss: 16.9597, val_MinusLogProbMetric: 16.9597

Epoch 650: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4171 - MinusLogProbMetric: 16.4171 - val_loss: 16.9597 - val_MinusLogProbMetric: 16.9597 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 651/1000
2023-09-28 05:04:34.484 
Epoch 651/1000 
	 loss: 16.4215, MinusLogProbMetric: 16.4215, val_loss: 17.0144, val_MinusLogProbMetric: 17.0144

Epoch 651: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4215 - MinusLogProbMetric: 16.4215 - val_loss: 17.0144 - val_MinusLogProbMetric: 17.0144 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 652/1000
2023-09-28 05:05:12.462 
Epoch 652/1000 
	 loss: 16.4279, MinusLogProbMetric: 16.4279, val_loss: 16.9969, val_MinusLogProbMetric: 16.9969

Epoch 652: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4279 - MinusLogProbMetric: 16.4279 - val_loss: 16.9969 - val_MinusLogProbMetric: 16.9969 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 653/1000
2023-09-28 05:05:51.076 
Epoch 653/1000 
	 loss: 16.4215, MinusLogProbMetric: 16.4215, val_loss: 16.9853, val_MinusLogProbMetric: 16.9853

Epoch 653: val_loss did not improve from 16.95352
196/196 - 39s - loss: 16.4215 - MinusLogProbMetric: 16.4215 - val_loss: 16.9853 - val_MinusLogProbMetric: 16.9853 - lr: 6.2500e-05 - 39s/epoch - 197ms/step
Epoch 654/1000
2023-09-28 05:06:29.075 
Epoch 654/1000 
	 loss: 16.4233, MinusLogProbMetric: 16.4233, val_loss: 16.9806, val_MinusLogProbMetric: 16.9806

Epoch 654: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4233 - MinusLogProbMetric: 16.4233 - val_loss: 16.9806 - val_MinusLogProbMetric: 16.9806 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 655/1000
2023-09-28 05:07:07.325 
Epoch 655/1000 
	 loss: 16.4386, MinusLogProbMetric: 16.4386, val_loss: 16.9687, val_MinusLogProbMetric: 16.9687

Epoch 655: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4386 - MinusLogProbMetric: 16.4386 - val_loss: 16.9687 - val_MinusLogProbMetric: 16.9687 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 656/1000
2023-09-28 05:07:45.250 
Epoch 656/1000 
	 loss: 16.4204, MinusLogProbMetric: 16.4204, val_loss: 16.9621, val_MinusLogProbMetric: 16.9621

Epoch 656: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4204 - MinusLogProbMetric: 16.4204 - val_loss: 16.9621 - val_MinusLogProbMetric: 16.9621 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 657/1000
2023-09-28 05:08:23.074 
Epoch 657/1000 
	 loss: 16.4406, MinusLogProbMetric: 16.4406, val_loss: 16.9580, val_MinusLogProbMetric: 16.9580

Epoch 657: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4406 - MinusLogProbMetric: 16.4406 - val_loss: 16.9580 - val_MinusLogProbMetric: 16.9580 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 658/1000
2023-09-28 05:09:01.028 
Epoch 658/1000 
	 loss: 16.4207, MinusLogProbMetric: 16.4207, val_loss: 16.9623, val_MinusLogProbMetric: 16.9623

Epoch 658: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4207 - MinusLogProbMetric: 16.4207 - val_loss: 16.9623 - val_MinusLogProbMetric: 16.9623 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 659/1000
2023-09-28 05:09:39.181 
Epoch 659/1000 
	 loss: 16.4322, MinusLogProbMetric: 16.4322, val_loss: 16.9802, val_MinusLogProbMetric: 16.9802

Epoch 659: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4322 - MinusLogProbMetric: 16.4322 - val_loss: 16.9802 - val_MinusLogProbMetric: 16.9802 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 660/1000
2023-09-28 05:10:17.400 
Epoch 660/1000 
	 loss: 16.4200, MinusLogProbMetric: 16.4200, val_loss: 16.9649, val_MinusLogProbMetric: 16.9649

Epoch 660: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4200 - MinusLogProbMetric: 16.4200 - val_loss: 16.9649 - val_MinusLogProbMetric: 16.9649 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 661/1000
2023-09-28 05:10:55.718 
Epoch 661/1000 
	 loss: 16.4169, MinusLogProbMetric: 16.4169, val_loss: 16.9593, val_MinusLogProbMetric: 16.9593

Epoch 661: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4169 - MinusLogProbMetric: 16.4169 - val_loss: 16.9593 - val_MinusLogProbMetric: 16.9593 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 662/1000
2023-09-28 05:11:33.697 
Epoch 662/1000 
	 loss: 16.4146, MinusLogProbMetric: 16.4146, val_loss: 16.9895, val_MinusLogProbMetric: 16.9895

Epoch 662: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4146 - MinusLogProbMetric: 16.4146 - val_loss: 16.9895 - val_MinusLogProbMetric: 16.9895 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 663/1000
2023-09-28 05:12:11.788 
Epoch 663/1000 
	 loss: 16.4232, MinusLogProbMetric: 16.4232, val_loss: 16.9706, val_MinusLogProbMetric: 16.9706

Epoch 663: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4232 - MinusLogProbMetric: 16.4232 - val_loss: 16.9706 - val_MinusLogProbMetric: 16.9706 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 664/1000
2023-09-28 05:12:50.038 
Epoch 664/1000 
	 loss: 16.4244, MinusLogProbMetric: 16.4244, val_loss: 16.9727, val_MinusLogProbMetric: 16.9727

Epoch 664: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4244 - MinusLogProbMetric: 16.4244 - val_loss: 16.9727 - val_MinusLogProbMetric: 16.9727 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 665/1000
2023-09-28 05:13:28.302 
Epoch 665/1000 
	 loss: 16.4233, MinusLogProbMetric: 16.4233, val_loss: 17.0677, val_MinusLogProbMetric: 17.0677

Epoch 665: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4233 - MinusLogProbMetric: 16.4233 - val_loss: 17.0677 - val_MinusLogProbMetric: 17.0677 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 666/1000
2023-09-28 05:14:06.154 
Epoch 666/1000 
	 loss: 16.4231, MinusLogProbMetric: 16.4231, val_loss: 16.9742, val_MinusLogProbMetric: 16.9742

Epoch 666: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4231 - MinusLogProbMetric: 16.4231 - val_loss: 16.9742 - val_MinusLogProbMetric: 16.9742 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 667/1000
2023-09-28 05:14:44.526 
Epoch 667/1000 
	 loss: 16.4300, MinusLogProbMetric: 16.4300, val_loss: 16.9615, val_MinusLogProbMetric: 16.9615

Epoch 667: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4300 - MinusLogProbMetric: 16.4300 - val_loss: 16.9615 - val_MinusLogProbMetric: 16.9615 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 668/1000
2023-09-28 05:15:22.997 
Epoch 668/1000 
	 loss: 16.4220, MinusLogProbMetric: 16.4220, val_loss: 16.9646, val_MinusLogProbMetric: 16.9646

Epoch 668: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4220 - MinusLogProbMetric: 16.4220 - val_loss: 16.9646 - val_MinusLogProbMetric: 16.9646 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 669/1000
2023-09-28 05:16:01.185 
Epoch 669/1000 
	 loss: 16.4159, MinusLogProbMetric: 16.4159, val_loss: 16.9716, val_MinusLogProbMetric: 16.9716

Epoch 669: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4159 - MinusLogProbMetric: 16.4159 - val_loss: 16.9716 - val_MinusLogProbMetric: 16.9716 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 670/1000
2023-09-28 05:16:39.072 
Epoch 670/1000 
	 loss: 16.4262, MinusLogProbMetric: 16.4262, val_loss: 16.9624, val_MinusLogProbMetric: 16.9624

Epoch 670: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4262 - MinusLogProbMetric: 16.4262 - val_loss: 16.9624 - val_MinusLogProbMetric: 16.9624 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 671/1000
2023-09-28 05:17:17.202 
Epoch 671/1000 
	 loss: 16.4326, MinusLogProbMetric: 16.4326, val_loss: 16.9939, val_MinusLogProbMetric: 16.9939

Epoch 671: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4326 - MinusLogProbMetric: 16.4326 - val_loss: 16.9939 - val_MinusLogProbMetric: 16.9939 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 672/1000
2023-09-28 05:17:55.221 
Epoch 672/1000 
	 loss: 16.4244, MinusLogProbMetric: 16.4244, val_loss: 16.9758, val_MinusLogProbMetric: 16.9758

Epoch 672: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4244 - MinusLogProbMetric: 16.4244 - val_loss: 16.9758 - val_MinusLogProbMetric: 16.9758 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 673/1000
2023-09-28 05:18:33.254 
Epoch 673/1000 
	 loss: 16.4185, MinusLogProbMetric: 16.4185, val_loss: 17.0191, val_MinusLogProbMetric: 17.0191

Epoch 673: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4185 - MinusLogProbMetric: 16.4185 - val_loss: 17.0191 - val_MinusLogProbMetric: 17.0191 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 674/1000
2023-09-28 05:19:11.279 
Epoch 674/1000 
	 loss: 16.4435, MinusLogProbMetric: 16.4435, val_loss: 17.0161, val_MinusLogProbMetric: 17.0161

Epoch 674: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4435 - MinusLogProbMetric: 16.4435 - val_loss: 17.0161 - val_MinusLogProbMetric: 17.0161 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 675/1000
2023-09-28 05:19:49.270 
Epoch 675/1000 
	 loss: 16.4170, MinusLogProbMetric: 16.4170, val_loss: 16.9725, val_MinusLogProbMetric: 16.9725

Epoch 675: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4170 - MinusLogProbMetric: 16.4170 - val_loss: 16.9725 - val_MinusLogProbMetric: 16.9725 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 676/1000
2023-09-28 05:20:27.586 
Epoch 676/1000 
	 loss: 16.4248, MinusLogProbMetric: 16.4248, val_loss: 16.9624, val_MinusLogProbMetric: 16.9624

Epoch 676: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4248 - MinusLogProbMetric: 16.4248 - val_loss: 16.9624 - val_MinusLogProbMetric: 16.9624 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 677/1000
2023-09-28 05:21:05.904 
Epoch 677/1000 
	 loss: 16.4405, MinusLogProbMetric: 16.4405, val_loss: 17.0254, val_MinusLogProbMetric: 17.0254

Epoch 677: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4405 - MinusLogProbMetric: 16.4405 - val_loss: 17.0254 - val_MinusLogProbMetric: 17.0254 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 678/1000
2023-09-28 05:21:44.112 
Epoch 678/1000 
	 loss: 16.4238, MinusLogProbMetric: 16.4238, val_loss: 16.9862, val_MinusLogProbMetric: 16.9862

Epoch 678: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4238 - MinusLogProbMetric: 16.4238 - val_loss: 16.9862 - val_MinusLogProbMetric: 16.9862 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 679/1000
2023-09-28 05:22:21.944 
Epoch 679/1000 
	 loss: 16.4287, MinusLogProbMetric: 16.4287, val_loss: 16.9606, val_MinusLogProbMetric: 16.9606

Epoch 679: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4287 - MinusLogProbMetric: 16.4287 - val_loss: 16.9606 - val_MinusLogProbMetric: 16.9606 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 680/1000
2023-09-28 05:23:00.090 
Epoch 680/1000 
	 loss: 16.4160, MinusLogProbMetric: 16.4160, val_loss: 16.9597, val_MinusLogProbMetric: 16.9597

Epoch 680: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4160 - MinusLogProbMetric: 16.4160 - val_loss: 16.9597 - val_MinusLogProbMetric: 16.9597 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 681/1000
2023-09-28 05:23:38.138 
Epoch 681/1000 
	 loss: 16.4227, MinusLogProbMetric: 16.4227, val_loss: 16.9592, val_MinusLogProbMetric: 16.9592

Epoch 681: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4227 - MinusLogProbMetric: 16.4227 - val_loss: 16.9592 - val_MinusLogProbMetric: 16.9592 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 682/1000
2023-09-28 05:24:16.040 
Epoch 682/1000 
	 loss: 16.4169, MinusLogProbMetric: 16.4169, val_loss: 17.0113, val_MinusLogProbMetric: 17.0113

Epoch 682: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4169 - MinusLogProbMetric: 16.4169 - val_loss: 17.0113 - val_MinusLogProbMetric: 17.0113 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 683/1000
2023-09-28 05:24:54.035 
Epoch 683/1000 
	 loss: 16.4247, MinusLogProbMetric: 16.4247, val_loss: 16.9616, val_MinusLogProbMetric: 16.9616

Epoch 683: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4247 - MinusLogProbMetric: 16.4247 - val_loss: 16.9616 - val_MinusLogProbMetric: 16.9616 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 684/1000
2023-09-28 05:25:31.843 
Epoch 684/1000 
	 loss: 16.4191, MinusLogProbMetric: 16.4191, val_loss: 16.9620, val_MinusLogProbMetric: 16.9620

Epoch 684: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4191 - MinusLogProbMetric: 16.4191 - val_loss: 16.9620 - val_MinusLogProbMetric: 16.9620 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 685/1000
2023-09-28 05:26:09.957 
Epoch 685/1000 
	 loss: 16.4169, MinusLogProbMetric: 16.4169, val_loss: 16.9758, val_MinusLogProbMetric: 16.9758

Epoch 685: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4169 - MinusLogProbMetric: 16.4169 - val_loss: 16.9758 - val_MinusLogProbMetric: 16.9758 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 686/1000
2023-09-28 05:26:48.202 
Epoch 686/1000 
	 loss: 16.4130, MinusLogProbMetric: 16.4130, val_loss: 16.9540, val_MinusLogProbMetric: 16.9540

Epoch 686: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4130 - MinusLogProbMetric: 16.4130 - val_loss: 16.9540 - val_MinusLogProbMetric: 16.9540 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 687/1000
2023-09-28 05:27:26.306 
Epoch 687/1000 
	 loss: 16.4139, MinusLogProbMetric: 16.4139, val_loss: 17.0062, val_MinusLogProbMetric: 17.0062

Epoch 687: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4139 - MinusLogProbMetric: 16.4139 - val_loss: 17.0062 - val_MinusLogProbMetric: 17.0062 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 688/1000
2023-09-28 05:28:04.697 
Epoch 688/1000 
	 loss: 16.4180, MinusLogProbMetric: 16.4180, val_loss: 16.9596, val_MinusLogProbMetric: 16.9596

Epoch 688: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4180 - MinusLogProbMetric: 16.4180 - val_loss: 16.9596 - val_MinusLogProbMetric: 16.9596 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 689/1000
2023-09-28 05:28:42.782 
Epoch 689/1000 
	 loss: 16.4231, MinusLogProbMetric: 16.4231, val_loss: 16.9874, val_MinusLogProbMetric: 16.9874

Epoch 689: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4231 - MinusLogProbMetric: 16.4231 - val_loss: 16.9874 - val_MinusLogProbMetric: 16.9874 - lr: 6.2500e-05 - 38s/epoch - 194ms/step
Epoch 690/1000
2023-09-28 05:29:20.560 
Epoch 690/1000 
	 loss: 16.4192, MinusLogProbMetric: 16.4192, val_loss: 17.0786, val_MinusLogProbMetric: 17.0786

Epoch 690: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4192 - MinusLogProbMetric: 16.4192 - val_loss: 17.0786 - val_MinusLogProbMetric: 17.0786 - lr: 6.2500e-05 - 38s/epoch - 193ms/step
Epoch 691/1000
2023-09-28 05:29:58.909 
Epoch 691/1000 
	 loss: 16.4220, MinusLogProbMetric: 16.4220, val_loss: 16.9632, val_MinusLogProbMetric: 16.9632

Epoch 691: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4220 - MinusLogProbMetric: 16.4220 - val_loss: 16.9632 - val_MinusLogProbMetric: 16.9632 - lr: 6.2500e-05 - 38s/epoch - 196ms/step
Epoch 692/1000
2023-09-28 05:30:37.522 
Epoch 692/1000 
	 loss: 16.4237, MinusLogProbMetric: 16.4237, val_loss: 16.9788, val_MinusLogProbMetric: 16.9788

Epoch 692: val_loss did not improve from 16.95352
196/196 - 39s - loss: 16.4237 - MinusLogProbMetric: 16.4237 - val_loss: 16.9788 - val_MinusLogProbMetric: 16.9788 - lr: 6.2500e-05 - 39s/epoch - 197ms/step
Epoch 693/1000
2023-09-28 05:31:15.713 
Epoch 693/1000 
	 loss: 16.4170, MinusLogProbMetric: 16.4170, val_loss: 16.9649, val_MinusLogProbMetric: 16.9649

Epoch 693: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4170 - MinusLogProbMetric: 16.4170 - val_loss: 16.9649 - val_MinusLogProbMetric: 16.9649 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 694/1000
2023-09-28 05:31:53.961 
Epoch 694/1000 
	 loss: 16.4144, MinusLogProbMetric: 16.4144, val_loss: 17.0337, val_MinusLogProbMetric: 17.0337

Epoch 694: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4144 - MinusLogProbMetric: 16.4144 - val_loss: 17.0337 - val_MinusLogProbMetric: 17.0337 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 695/1000
2023-09-28 05:32:32.132 
Epoch 695/1000 
	 loss: 16.4183, MinusLogProbMetric: 16.4183, val_loss: 16.9560, val_MinusLogProbMetric: 16.9560

Epoch 695: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4183 - MinusLogProbMetric: 16.4183 - val_loss: 16.9560 - val_MinusLogProbMetric: 16.9560 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 696/1000
2023-09-28 05:33:10.407 
Epoch 696/1000 
	 loss: 16.4204, MinusLogProbMetric: 16.4204, val_loss: 16.9805, val_MinusLogProbMetric: 16.9805

Epoch 696: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4204 - MinusLogProbMetric: 16.4204 - val_loss: 16.9805 - val_MinusLogProbMetric: 16.9805 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 697/1000
2023-09-28 05:33:48.711 
Epoch 697/1000 
	 loss: 16.4178, MinusLogProbMetric: 16.4178, val_loss: 16.9924, val_MinusLogProbMetric: 16.9924

Epoch 697: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4178 - MinusLogProbMetric: 16.4178 - val_loss: 16.9924 - val_MinusLogProbMetric: 16.9924 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 698/1000
2023-09-28 05:34:27.004 
Epoch 698/1000 
	 loss: 16.4342, MinusLogProbMetric: 16.4342, val_loss: 16.9651, val_MinusLogProbMetric: 16.9651

Epoch 698: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4342 - MinusLogProbMetric: 16.4342 - val_loss: 16.9651 - val_MinusLogProbMetric: 16.9651 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 699/1000
2023-09-28 05:35:05.181 
Epoch 699/1000 
	 loss: 16.4169, MinusLogProbMetric: 16.4169, val_loss: 16.9616, val_MinusLogProbMetric: 16.9616

Epoch 699: val_loss did not improve from 16.95352
196/196 - 38s - loss: 16.4169 - MinusLogProbMetric: 16.4169 - val_loss: 16.9616 - val_MinusLogProbMetric: 16.9616 - lr: 6.2500e-05 - 38s/epoch - 195ms/step
Epoch 700/1000
2023-09-28 05:35:43.343 
Epoch 700/1000 
	 loss: 16.3984, MinusLogProbMetric: 16.3984, val_loss: 16.9519, val_MinusLogProbMetric: 16.9519

Epoch 700: val_loss improved from 16.95352 to 16.95193, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.3984 - MinusLogProbMetric: 16.3984 - val_loss: 16.9519 - val_MinusLogProbMetric: 16.9519 - lr: 3.1250e-05 - 39s/epoch - 199ms/step
Epoch 701/1000
2023-09-28 05:36:22.627 
Epoch 701/1000 
	 loss: 16.3987, MinusLogProbMetric: 16.3987, val_loss: 16.9547, val_MinusLogProbMetric: 16.9547

Epoch 701: val_loss did not improve from 16.95193
196/196 - 39s - loss: 16.3987 - MinusLogProbMetric: 16.3987 - val_loss: 16.9547 - val_MinusLogProbMetric: 16.9547 - lr: 3.1250e-05 - 39s/epoch - 197ms/step
Epoch 702/1000
2023-09-28 05:37:00.983 
Epoch 702/1000 
	 loss: 16.3989, MinusLogProbMetric: 16.3989, val_loss: 16.9503, val_MinusLogProbMetric: 16.9503

Epoch 702: val_loss improved from 16.95193 to 16.95027, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.3989 - MinusLogProbMetric: 16.3989 - val_loss: 16.9503 - val_MinusLogProbMetric: 16.9503 - lr: 3.1250e-05 - 39s/epoch - 199ms/step
Epoch 703/1000
2023-09-28 05:37:40.093 
Epoch 703/1000 
	 loss: 16.3978, MinusLogProbMetric: 16.3978, val_loss: 16.9737, val_MinusLogProbMetric: 16.9737

Epoch 703: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3978 - MinusLogProbMetric: 16.3978 - val_loss: 16.9737 - val_MinusLogProbMetric: 16.9737 - lr: 3.1250e-05 - 38s/epoch - 196ms/step
Epoch 704/1000
2023-09-28 05:38:18.110 
Epoch 704/1000 
	 loss: 16.4010, MinusLogProbMetric: 16.4010, val_loss: 16.9573, val_MinusLogProbMetric: 16.9573

Epoch 704: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.4010 - MinusLogProbMetric: 16.4010 - val_loss: 16.9573 - val_MinusLogProbMetric: 16.9573 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 705/1000
2023-09-28 05:38:56.274 
Epoch 705/1000 
	 loss: 16.3987, MinusLogProbMetric: 16.3987, val_loss: 16.9746, val_MinusLogProbMetric: 16.9746

Epoch 705: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3987 - MinusLogProbMetric: 16.3987 - val_loss: 16.9746 - val_MinusLogProbMetric: 16.9746 - lr: 3.1250e-05 - 38s/epoch - 195ms/step
Epoch 706/1000
2023-09-28 05:39:34.573 
Epoch 706/1000 
	 loss: 16.4007, MinusLogProbMetric: 16.4007, val_loss: 16.9668, val_MinusLogProbMetric: 16.9668

Epoch 706: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.4007 - MinusLogProbMetric: 16.4007 - val_loss: 16.9668 - val_MinusLogProbMetric: 16.9668 - lr: 3.1250e-05 - 38s/epoch - 195ms/step
Epoch 707/1000
2023-09-28 05:40:12.934 
Epoch 707/1000 
	 loss: 16.4019, MinusLogProbMetric: 16.4019, val_loss: 16.9545, val_MinusLogProbMetric: 16.9545

Epoch 707: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.4019 - MinusLogProbMetric: 16.4019 - val_loss: 16.9545 - val_MinusLogProbMetric: 16.9545 - lr: 3.1250e-05 - 38s/epoch - 196ms/step
Epoch 708/1000
2023-09-28 05:40:51.223 
Epoch 708/1000 
	 loss: 16.3991, MinusLogProbMetric: 16.3991, val_loss: 16.9522, val_MinusLogProbMetric: 16.9522

Epoch 708: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3991 - MinusLogProbMetric: 16.3991 - val_loss: 16.9522 - val_MinusLogProbMetric: 16.9522 - lr: 3.1250e-05 - 38s/epoch - 195ms/step
Epoch 709/1000
2023-09-28 05:41:29.193 
Epoch 709/1000 
	 loss: 16.3997, MinusLogProbMetric: 16.3997, val_loss: 16.9814, val_MinusLogProbMetric: 16.9814

Epoch 709: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3997 - MinusLogProbMetric: 16.3997 - val_loss: 16.9814 - val_MinusLogProbMetric: 16.9814 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 710/1000
2023-09-28 05:42:07.685 
Epoch 710/1000 
	 loss: 16.3995, MinusLogProbMetric: 16.3995, val_loss: 16.9575, val_MinusLogProbMetric: 16.9575

Epoch 710: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3995 - MinusLogProbMetric: 16.3995 - val_loss: 16.9575 - val_MinusLogProbMetric: 16.9575 - lr: 3.1250e-05 - 38s/epoch - 196ms/step
Epoch 711/1000
2023-09-28 05:42:45.876 
Epoch 711/1000 
	 loss: 16.3977, MinusLogProbMetric: 16.3977, val_loss: 16.9600, val_MinusLogProbMetric: 16.9600

Epoch 711: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3977 - MinusLogProbMetric: 16.3977 - val_loss: 16.9600 - val_MinusLogProbMetric: 16.9600 - lr: 3.1250e-05 - 38s/epoch - 195ms/step
Epoch 712/1000
2023-09-28 05:43:24.084 
Epoch 712/1000 
	 loss: 16.4024, MinusLogProbMetric: 16.4024, val_loss: 16.9729, val_MinusLogProbMetric: 16.9729

Epoch 712: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.4024 - MinusLogProbMetric: 16.4024 - val_loss: 16.9729 - val_MinusLogProbMetric: 16.9729 - lr: 3.1250e-05 - 38s/epoch - 195ms/step
Epoch 713/1000
2023-09-28 05:44:02.449 
Epoch 713/1000 
	 loss: 16.4008, MinusLogProbMetric: 16.4008, val_loss: 16.9533, val_MinusLogProbMetric: 16.9533

Epoch 713: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.4008 - MinusLogProbMetric: 16.4008 - val_loss: 16.9533 - val_MinusLogProbMetric: 16.9533 - lr: 3.1250e-05 - 38s/epoch - 196ms/step
Epoch 714/1000
2023-09-28 05:44:40.354 
Epoch 714/1000 
	 loss: 16.4012, MinusLogProbMetric: 16.4012, val_loss: 16.9545, val_MinusLogProbMetric: 16.9545

Epoch 714: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.4012 - MinusLogProbMetric: 16.4012 - val_loss: 16.9545 - val_MinusLogProbMetric: 16.9545 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 715/1000
2023-09-28 05:45:18.311 
Epoch 715/1000 
	 loss: 16.3979, MinusLogProbMetric: 16.3979, val_loss: 16.9578, val_MinusLogProbMetric: 16.9578

Epoch 715: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3979 - MinusLogProbMetric: 16.3979 - val_loss: 16.9578 - val_MinusLogProbMetric: 16.9578 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 716/1000
2023-09-28 05:45:56.578 
Epoch 716/1000 
	 loss: 16.3976, MinusLogProbMetric: 16.3976, val_loss: 16.9755, val_MinusLogProbMetric: 16.9755

Epoch 716: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3976 - MinusLogProbMetric: 16.3976 - val_loss: 16.9755 - val_MinusLogProbMetric: 16.9755 - lr: 3.1250e-05 - 38s/epoch - 195ms/step
Epoch 717/1000
2023-09-28 05:46:34.804 
Epoch 717/1000 
	 loss: 16.4005, MinusLogProbMetric: 16.4005, val_loss: 16.9574, val_MinusLogProbMetric: 16.9574

Epoch 717: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.4005 - MinusLogProbMetric: 16.4005 - val_loss: 16.9574 - val_MinusLogProbMetric: 16.9574 - lr: 3.1250e-05 - 38s/epoch - 195ms/step
Epoch 718/1000
2023-09-28 05:47:12.856 
Epoch 718/1000 
	 loss: 16.3974, MinusLogProbMetric: 16.3974, val_loss: 16.9725, val_MinusLogProbMetric: 16.9725

Epoch 718: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3974 - MinusLogProbMetric: 16.3974 - val_loss: 16.9725 - val_MinusLogProbMetric: 16.9725 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 719/1000
2023-09-28 05:47:51.053 
Epoch 719/1000 
	 loss: 16.3987, MinusLogProbMetric: 16.3987, val_loss: 16.9541, val_MinusLogProbMetric: 16.9541

Epoch 719: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3987 - MinusLogProbMetric: 16.3987 - val_loss: 16.9541 - val_MinusLogProbMetric: 16.9541 - lr: 3.1250e-05 - 38s/epoch - 195ms/step
Epoch 720/1000
2023-09-28 05:48:29.228 
Epoch 720/1000 
	 loss: 16.4000, MinusLogProbMetric: 16.4000, val_loss: 16.9849, val_MinusLogProbMetric: 16.9849

Epoch 720: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.4000 - MinusLogProbMetric: 16.4000 - val_loss: 16.9849 - val_MinusLogProbMetric: 16.9849 - lr: 3.1250e-05 - 38s/epoch - 195ms/step
Epoch 721/1000
2023-09-28 05:49:07.357 
Epoch 721/1000 
	 loss: 16.4007, MinusLogProbMetric: 16.4007, val_loss: 16.9530, val_MinusLogProbMetric: 16.9530

Epoch 721: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.4007 - MinusLogProbMetric: 16.4007 - val_loss: 16.9530 - val_MinusLogProbMetric: 16.9530 - lr: 3.1250e-05 - 38s/epoch - 195ms/step
Epoch 722/1000
2023-09-28 05:49:45.204 
Epoch 722/1000 
	 loss: 16.4050, MinusLogProbMetric: 16.4050, val_loss: 16.9627, val_MinusLogProbMetric: 16.9627

Epoch 722: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.4050 - MinusLogProbMetric: 16.4050 - val_loss: 16.9627 - val_MinusLogProbMetric: 16.9627 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 723/1000
2023-09-28 05:50:22.996 
Epoch 723/1000 
	 loss: 16.3971, MinusLogProbMetric: 16.3971, val_loss: 16.9678, val_MinusLogProbMetric: 16.9678

Epoch 723: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3971 - MinusLogProbMetric: 16.3971 - val_loss: 16.9678 - val_MinusLogProbMetric: 16.9678 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 724/1000
2023-09-28 05:51:01.524 
Epoch 724/1000 
	 loss: 16.3983, MinusLogProbMetric: 16.3983, val_loss: 16.9598, val_MinusLogProbMetric: 16.9598

Epoch 724: val_loss did not improve from 16.95027
196/196 - 39s - loss: 16.3983 - MinusLogProbMetric: 16.3983 - val_loss: 16.9598 - val_MinusLogProbMetric: 16.9598 - lr: 3.1250e-05 - 39s/epoch - 197ms/step
Epoch 725/1000
2023-09-28 05:51:39.517 
Epoch 725/1000 
	 loss: 16.3982, MinusLogProbMetric: 16.3982, val_loss: 16.9560, val_MinusLogProbMetric: 16.9560

Epoch 725: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3982 - MinusLogProbMetric: 16.3982 - val_loss: 16.9560 - val_MinusLogProbMetric: 16.9560 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 726/1000
2023-09-28 05:52:17.692 
Epoch 726/1000 
	 loss: 16.3989, MinusLogProbMetric: 16.3989, val_loss: 16.9574, val_MinusLogProbMetric: 16.9574

Epoch 726: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3989 - MinusLogProbMetric: 16.3989 - val_loss: 16.9574 - val_MinusLogProbMetric: 16.9574 - lr: 3.1250e-05 - 38s/epoch - 195ms/step
Epoch 727/1000
2023-09-28 05:52:55.723 
Epoch 727/1000 
	 loss: 16.3959, MinusLogProbMetric: 16.3959, val_loss: 16.9584, val_MinusLogProbMetric: 16.9584

Epoch 727: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3959 - MinusLogProbMetric: 16.3959 - val_loss: 16.9584 - val_MinusLogProbMetric: 16.9584 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 728/1000
2023-09-28 05:53:33.838 
Epoch 728/1000 
	 loss: 16.3975, MinusLogProbMetric: 16.3975, val_loss: 16.9562, val_MinusLogProbMetric: 16.9562

Epoch 728: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3975 - MinusLogProbMetric: 16.3975 - val_loss: 16.9562 - val_MinusLogProbMetric: 16.9562 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 729/1000
2023-09-28 05:54:11.982 
Epoch 729/1000 
	 loss: 16.3991, MinusLogProbMetric: 16.3991, val_loss: 16.9580, val_MinusLogProbMetric: 16.9580

Epoch 729: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3991 - MinusLogProbMetric: 16.3991 - val_loss: 16.9580 - val_MinusLogProbMetric: 16.9580 - lr: 3.1250e-05 - 38s/epoch - 195ms/step
Epoch 730/1000
2023-09-28 05:54:50.312 
Epoch 730/1000 
	 loss: 16.3962, MinusLogProbMetric: 16.3962, val_loss: 16.9548, val_MinusLogProbMetric: 16.9548

Epoch 730: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3962 - MinusLogProbMetric: 16.3962 - val_loss: 16.9548 - val_MinusLogProbMetric: 16.9548 - lr: 3.1250e-05 - 38s/epoch - 196ms/step
Epoch 731/1000
2023-09-28 05:55:28.192 
Epoch 731/1000 
	 loss: 16.4014, MinusLogProbMetric: 16.4014, val_loss: 16.9619, val_MinusLogProbMetric: 16.9619

Epoch 731: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.4014 - MinusLogProbMetric: 16.4014 - val_loss: 16.9619 - val_MinusLogProbMetric: 16.9619 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 732/1000
2023-09-28 05:56:06.241 
Epoch 732/1000 
	 loss: 16.3939, MinusLogProbMetric: 16.3939, val_loss: 16.9537, val_MinusLogProbMetric: 16.9537

Epoch 732: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3939 - MinusLogProbMetric: 16.3939 - val_loss: 16.9537 - val_MinusLogProbMetric: 16.9537 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 733/1000
2023-09-28 05:56:44.302 
Epoch 733/1000 
	 loss: 16.3976, MinusLogProbMetric: 16.3976, val_loss: 16.9918, val_MinusLogProbMetric: 16.9918

Epoch 733: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3976 - MinusLogProbMetric: 16.3976 - val_loss: 16.9918 - val_MinusLogProbMetric: 16.9918 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 734/1000
2023-09-28 05:57:22.420 
Epoch 734/1000 
	 loss: 16.3960, MinusLogProbMetric: 16.3960, val_loss: 16.9706, val_MinusLogProbMetric: 16.9706

Epoch 734: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3960 - MinusLogProbMetric: 16.3960 - val_loss: 16.9706 - val_MinusLogProbMetric: 16.9706 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 735/1000
2023-09-28 05:58:00.337 
Epoch 735/1000 
	 loss: 16.3997, MinusLogProbMetric: 16.3997, val_loss: 16.9620, val_MinusLogProbMetric: 16.9620

Epoch 735: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3997 - MinusLogProbMetric: 16.3997 - val_loss: 16.9620 - val_MinusLogProbMetric: 16.9620 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 736/1000
2023-09-28 05:58:38.416 
Epoch 736/1000 
	 loss: 16.3979, MinusLogProbMetric: 16.3979, val_loss: 16.9556, val_MinusLogProbMetric: 16.9556

Epoch 736: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3979 - MinusLogProbMetric: 16.3979 - val_loss: 16.9556 - val_MinusLogProbMetric: 16.9556 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 737/1000
2023-09-28 05:59:16.731 
Epoch 737/1000 
	 loss: 16.3977, MinusLogProbMetric: 16.3977, val_loss: 16.9720, val_MinusLogProbMetric: 16.9720

Epoch 737: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3977 - MinusLogProbMetric: 16.3977 - val_loss: 16.9720 - val_MinusLogProbMetric: 16.9720 - lr: 3.1250e-05 - 38s/epoch - 195ms/step
Epoch 738/1000
2023-09-28 05:59:55.183 
Epoch 738/1000 
	 loss: 16.3989, MinusLogProbMetric: 16.3989, val_loss: 16.9559, val_MinusLogProbMetric: 16.9559

Epoch 738: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3989 - MinusLogProbMetric: 16.3989 - val_loss: 16.9559 - val_MinusLogProbMetric: 16.9559 - lr: 3.1250e-05 - 38s/epoch - 196ms/step
Epoch 739/1000
2023-09-28 06:00:33.531 
Epoch 739/1000 
	 loss: 16.3961, MinusLogProbMetric: 16.3961, val_loss: 16.9528, val_MinusLogProbMetric: 16.9528

Epoch 739: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3961 - MinusLogProbMetric: 16.3961 - val_loss: 16.9528 - val_MinusLogProbMetric: 16.9528 - lr: 3.1250e-05 - 38s/epoch - 196ms/step
Epoch 740/1000
2023-09-28 06:01:11.425 
Epoch 740/1000 
	 loss: 16.4009, MinusLogProbMetric: 16.4009, val_loss: 16.9764, val_MinusLogProbMetric: 16.9764

Epoch 740: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.4009 - MinusLogProbMetric: 16.4009 - val_loss: 16.9764 - val_MinusLogProbMetric: 16.9764 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 741/1000
2023-09-28 06:01:49.581 
Epoch 741/1000 
	 loss: 16.3964, MinusLogProbMetric: 16.3964, val_loss: 16.9559, val_MinusLogProbMetric: 16.9559

Epoch 741: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3964 - MinusLogProbMetric: 16.3964 - val_loss: 16.9559 - val_MinusLogProbMetric: 16.9559 - lr: 3.1250e-05 - 38s/epoch - 195ms/step
Epoch 742/1000
2023-09-28 06:02:27.787 
Epoch 742/1000 
	 loss: 16.3996, MinusLogProbMetric: 16.3996, val_loss: 16.9600, val_MinusLogProbMetric: 16.9600

Epoch 742: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3996 - MinusLogProbMetric: 16.3996 - val_loss: 16.9600 - val_MinusLogProbMetric: 16.9600 - lr: 3.1250e-05 - 38s/epoch - 195ms/step
Epoch 743/1000
2023-09-28 06:03:05.545 
Epoch 743/1000 
	 loss: 16.3987, MinusLogProbMetric: 16.3987, val_loss: 16.9648, val_MinusLogProbMetric: 16.9648

Epoch 743: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3987 - MinusLogProbMetric: 16.3987 - val_loss: 16.9648 - val_MinusLogProbMetric: 16.9648 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 744/1000
2023-09-28 06:03:43.893 
Epoch 744/1000 
	 loss: 16.3958, MinusLogProbMetric: 16.3958, val_loss: 16.9539, val_MinusLogProbMetric: 16.9539

Epoch 744: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3958 - MinusLogProbMetric: 16.3958 - val_loss: 16.9539 - val_MinusLogProbMetric: 16.9539 - lr: 3.1250e-05 - 38s/epoch - 196ms/step
Epoch 745/1000
2023-09-28 06:04:21.696 
Epoch 745/1000 
	 loss: 16.3961, MinusLogProbMetric: 16.3961, val_loss: 16.9641, val_MinusLogProbMetric: 16.9641

Epoch 745: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3961 - MinusLogProbMetric: 16.3961 - val_loss: 16.9641 - val_MinusLogProbMetric: 16.9641 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 746/1000
2023-09-28 06:04:59.568 
Epoch 746/1000 
	 loss: 16.3976, MinusLogProbMetric: 16.3976, val_loss: 16.9669, val_MinusLogProbMetric: 16.9669

Epoch 746: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3976 - MinusLogProbMetric: 16.3976 - val_loss: 16.9669 - val_MinusLogProbMetric: 16.9669 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 747/1000
2023-09-28 06:05:37.429 
Epoch 747/1000 
	 loss: 16.3974, MinusLogProbMetric: 16.3974, val_loss: 16.9552, val_MinusLogProbMetric: 16.9552

Epoch 747: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3974 - MinusLogProbMetric: 16.3974 - val_loss: 16.9552 - val_MinusLogProbMetric: 16.9552 - lr: 3.1250e-05 - 38s/epoch - 193ms/step
Epoch 748/1000
2023-09-28 06:06:15.630 
Epoch 748/1000 
	 loss: 16.3938, MinusLogProbMetric: 16.3938, val_loss: 16.9540, val_MinusLogProbMetric: 16.9540

Epoch 748: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3938 - MinusLogProbMetric: 16.3938 - val_loss: 16.9540 - val_MinusLogProbMetric: 16.9540 - lr: 3.1250e-05 - 38s/epoch - 195ms/step
Epoch 749/1000
2023-09-28 06:06:54.109 
Epoch 749/1000 
	 loss: 16.3943, MinusLogProbMetric: 16.3943, val_loss: 16.9576, val_MinusLogProbMetric: 16.9576

Epoch 749: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3943 - MinusLogProbMetric: 16.3943 - val_loss: 16.9576 - val_MinusLogProbMetric: 16.9576 - lr: 3.1250e-05 - 38s/epoch - 196ms/step
Epoch 750/1000
2023-09-28 06:07:32.136 
Epoch 750/1000 
	 loss: 16.3953, MinusLogProbMetric: 16.3953, val_loss: 16.9538, val_MinusLogProbMetric: 16.9538

Epoch 750: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3953 - MinusLogProbMetric: 16.3953 - val_loss: 16.9538 - val_MinusLogProbMetric: 16.9538 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 751/1000
2023-09-28 06:08:10.256 
Epoch 751/1000 
	 loss: 16.3986, MinusLogProbMetric: 16.3986, val_loss: 16.9598, val_MinusLogProbMetric: 16.9598

Epoch 751: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3986 - MinusLogProbMetric: 16.3986 - val_loss: 16.9598 - val_MinusLogProbMetric: 16.9598 - lr: 3.1250e-05 - 38s/epoch - 194ms/step
Epoch 752/1000
2023-09-28 06:08:48.563 
Epoch 752/1000 
	 loss: 16.3957, MinusLogProbMetric: 16.3957, val_loss: 16.9737, val_MinusLogProbMetric: 16.9737

Epoch 752: val_loss did not improve from 16.95027
196/196 - 38s - loss: 16.3957 - MinusLogProbMetric: 16.3957 - val_loss: 16.9737 - val_MinusLogProbMetric: 16.9737 - lr: 3.1250e-05 - 38s/epoch - 195ms/step
Epoch 753/1000
2023-09-28 06:09:26.691 
Epoch 753/1000 
	 loss: 16.3877, MinusLogProbMetric: 16.3877, val_loss: 16.9494, val_MinusLogProbMetric: 16.9494

Epoch 753: val_loss improved from 16.95027 to 16.94937, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_315/weights/best_weights.h5
196/196 - 39s - loss: 16.3877 - MinusLogProbMetric: 16.3877 - val_loss: 16.9494 - val_MinusLogProbMetric: 16.9494 - lr: 1.5625e-05 - 39s/epoch - 198ms/step
Epoch 754/1000
2023-09-28 06:10:05.476 
Epoch 754/1000 
	 loss: 16.3870, MinusLogProbMetric: 16.3870, val_loss: 16.9517, val_MinusLogProbMetric: 16.9517

Epoch 754: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3870 - MinusLogProbMetric: 16.3870 - val_loss: 16.9517 - val_MinusLogProbMetric: 16.9517 - lr: 1.5625e-05 - 38s/epoch - 194ms/step
Epoch 755/1000
2023-09-28 06:10:43.369 
Epoch 755/1000 
	 loss: 16.3869, MinusLogProbMetric: 16.3869, val_loss: 16.9501, val_MinusLogProbMetric: 16.9501

Epoch 755: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3869 - MinusLogProbMetric: 16.3869 - val_loss: 16.9501 - val_MinusLogProbMetric: 16.9501 - lr: 1.5625e-05 - 38s/epoch - 193ms/step
Epoch 756/1000
2023-09-28 06:11:21.473 
Epoch 756/1000 
	 loss: 16.3875, MinusLogProbMetric: 16.3875, val_loss: 16.9546, val_MinusLogProbMetric: 16.9546

Epoch 756: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3875 - MinusLogProbMetric: 16.3875 - val_loss: 16.9546 - val_MinusLogProbMetric: 16.9546 - lr: 1.5625e-05 - 38s/epoch - 194ms/step
Epoch 757/1000
2023-09-28 06:11:59.861 
Epoch 757/1000 
	 loss: 16.3865, MinusLogProbMetric: 16.3865, val_loss: 16.9532, val_MinusLogProbMetric: 16.9532

Epoch 757: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3865 - MinusLogProbMetric: 16.3865 - val_loss: 16.9532 - val_MinusLogProbMetric: 16.9532 - lr: 1.5625e-05 - 38s/epoch - 196ms/step
Epoch 758/1000
2023-09-28 06:12:37.775 
Epoch 758/1000 
	 loss: 16.3874, MinusLogProbMetric: 16.3874, val_loss: 16.9574, val_MinusLogProbMetric: 16.9574

Epoch 758: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3874 - MinusLogProbMetric: 16.3874 - val_loss: 16.9574 - val_MinusLogProbMetric: 16.9574 - lr: 1.5625e-05 - 38s/epoch - 193ms/step
Epoch 759/1000
2023-09-28 06:13:15.750 
Epoch 759/1000 
	 loss: 16.3870, MinusLogProbMetric: 16.3870, val_loss: 16.9598, val_MinusLogProbMetric: 16.9598

Epoch 759: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3870 - MinusLogProbMetric: 16.3870 - val_loss: 16.9598 - val_MinusLogProbMetric: 16.9598 - lr: 1.5625e-05 - 38s/epoch - 194ms/step
Epoch 760/1000
2023-09-28 06:13:54.013 
Epoch 760/1000 
	 loss: 16.3880, MinusLogProbMetric: 16.3880, val_loss: 16.9541, val_MinusLogProbMetric: 16.9541

Epoch 760: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3880 - MinusLogProbMetric: 16.3880 - val_loss: 16.9541 - val_MinusLogProbMetric: 16.9541 - lr: 1.5625e-05 - 38s/epoch - 195ms/step
Epoch 761/1000
2023-09-28 06:14:32.192 
Epoch 761/1000 
	 loss: 16.3871, MinusLogProbMetric: 16.3871, val_loss: 16.9609, val_MinusLogProbMetric: 16.9609

Epoch 761: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3871 - MinusLogProbMetric: 16.3871 - val_loss: 16.9609 - val_MinusLogProbMetric: 16.9609 - lr: 1.5625e-05 - 38s/epoch - 195ms/step
Epoch 762/1000
2023-09-28 06:15:10.116 
Epoch 762/1000 
	 loss: 16.3872, MinusLogProbMetric: 16.3872, val_loss: 16.9510, val_MinusLogProbMetric: 16.9510

Epoch 762: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3872 - MinusLogProbMetric: 16.3872 - val_loss: 16.9510 - val_MinusLogProbMetric: 16.9510 - lr: 1.5625e-05 - 38s/epoch - 193ms/step
Epoch 763/1000
2023-09-28 06:15:48.533 
Epoch 763/1000 
	 loss: 16.3866, MinusLogProbMetric: 16.3866, val_loss: 16.9503, val_MinusLogProbMetric: 16.9503

Epoch 763: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3866 - MinusLogProbMetric: 16.3866 - val_loss: 16.9503 - val_MinusLogProbMetric: 16.9503 - lr: 1.5625e-05 - 38s/epoch - 196ms/step
Epoch 764/1000
2023-09-28 06:16:26.568 
Epoch 764/1000 
	 loss: 16.3862, MinusLogProbMetric: 16.3862, val_loss: 16.9617, val_MinusLogProbMetric: 16.9617

Epoch 764: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3862 - MinusLogProbMetric: 16.3862 - val_loss: 16.9617 - val_MinusLogProbMetric: 16.9617 - lr: 1.5625e-05 - 38s/epoch - 194ms/step
Epoch 765/1000
2023-09-28 06:17:04.931 
Epoch 765/1000 
	 loss: 16.3863, MinusLogProbMetric: 16.3863, val_loss: 16.9504, val_MinusLogProbMetric: 16.9504

Epoch 765: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3863 - MinusLogProbMetric: 16.3863 - val_loss: 16.9504 - val_MinusLogProbMetric: 16.9504 - lr: 1.5625e-05 - 38s/epoch - 196ms/step
Epoch 766/1000
2023-09-28 06:17:43.360 
Epoch 766/1000 
	 loss: 16.3860, MinusLogProbMetric: 16.3860, val_loss: 16.9509, val_MinusLogProbMetric: 16.9509

Epoch 766: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3860 - MinusLogProbMetric: 16.3860 - val_loss: 16.9509 - val_MinusLogProbMetric: 16.9509 - lr: 1.5625e-05 - 38s/epoch - 196ms/step
Epoch 767/1000
2023-09-28 06:18:21.987 
Epoch 767/1000 
	 loss: 16.3873, MinusLogProbMetric: 16.3873, val_loss: 16.9545, val_MinusLogProbMetric: 16.9545

Epoch 767: val_loss did not improve from 16.94937
196/196 - 39s - loss: 16.3873 - MinusLogProbMetric: 16.3873 - val_loss: 16.9545 - val_MinusLogProbMetric: 16.9545 - lr: 1.5625e-05 - 39s/epoch - 197ms/step
Epoch 768/1000
2023-09-28 06:19:00.175 
Epoch 768/1000 
	 loss: 16.3868, MinusLogProbMetric: 16.3868, val_loss: 16.9520, val_MinusLogProbMetric: 16.9520

Epoch 768: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3868 - MinusLogProbMetric: 16.3868 - val_loss: 16.9520 - val_MinusLogProbMetric: 16.9520 - lr: 1.5625e-05 - 38s/epoch - 195ms/step
Epoch 769/1000
2023-09-28 06:19:38.247 
Epoch 769/1000 
	 loss: 16.3882, MinusLogProbMetric: 16.3882, val_loss: 16.9526, val_MinusLogProbMetric: 16.9526

Epoch 769: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3882 - MinusLogProbMetric: 16.3882 - val_loss: 16.9526 - val_MinusLogProbMetric: 16.9526 - lr: 1.5625e-05 - 38s/epoch - 194ms/step
Epoch 770/1000
2023-09-28 06:20:16.314 
Epoch 770/1000 
	 loss: 16.3875, MinusLogProbMetric: 16.3875, val_loss: 16.9511, val_MinusLogProbMetric: 16.9511

Epoch 770: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3875 - MinusLogProbMetric: 16.3875 - val_loss: 16.9511 - val_MinusLogProbMetric: 16.9511 - lr: 1.5625e-05 - 38s/epoch - 194ms/step
Epoch 771/1000
2023-09-28 06:20:54.723 
Epoch 771/1000 
	 loss: 16.3867, MinusLogProbMetric: 16.3867, val_loss: 16.9525, val_MinusLogProbMetric: 16.9525

Epoch 771: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3867 - MinusLogProbMetric: 16.3867 - val_loss: 16.9525 - val_MinusLogProbMetric: 16.9525 - lr: 1.5625e-05 - 38s/epoch - 196ms/step
Epoch 772/1000
2023-09-28 06:21:33.153 
Epoch 772/1000 
	 loss: 16.3862, MinusLogProbMetric: 16.3862, val_loss: 16.9522, val_MinusLogProbMetric: 16.9522

Epoch 772: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3862 - MinusLogProbMetric: 16.3862 - val_loss: 16.9522 - val_MinusLogProbMetric: 16.9522 - lr: 1.5625e-05 - 38s/epoch - 196ms/step
Epoch 773/1000
2023-09-28 06:22:11.155 
Epoch 773/1000 
	 loss: 16.3861, MinusLogProbMetric: 16.3861, val_loss: 16.9520, val_MinusLogProbMetric: 16.9520

Epoch 773: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3861 - MinusLogProbMetric: 16.3861 - val_loss: 16.9520 - val_MinusLogProbMetric: 16.9520 - lr: 1.5625e-05 - 38s/epoch - 194ms/step
Epoch 774/1000
2023-09-28 06:22:49.472 
Epoch 774/1000 
	 loss: 16.3860, MinusLogProbMetric: 16.3860, val_loss: 16.9543, val_MinusLogProbMetric: 16.9543

Epoch 774: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3860 - MinusLogProbMetric: 16.3860 - val_loss: 16.9543 - val_MinusLogProbMetric: 16.9543 - lr: 1.5625e-05 - 38s/epoch - 195ms/step
Epoch 775/1000
2023-09-28 06:23:27.597 
Epoch 775/1000 
	 loss: 16.3874, MinusLogProbMetric: 16.3874, val_loss: 16.9524, val_MinusLogProbMetric: 16.9524

Epoch 775: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3874 - MinusLogProbMetric: 16.3874 - val_loss: 16.9524 - val_MinusLogProbMetric: 16.9524 - lr: 1.5625e-05 - 38s/epoch - 194ms/step
Epoch 776/1000
2023-09-28 06:24:05.437 
Epoch 776/1000 
	 loss: 16.3863, MinusLogProbMetric: 16.3863, val_loss: 16.9513, val_MinusLogProbMetric: 16.9513

Epoch 776: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3863 - MinusLogProbMetric: 16.3863 - val_loss: 16.9513 - val_MinusLogProbMetric: 16.9513 - lr: 1.5625e-05 - 38s/epoch - 193ms/step
Epoch 777/1000
2023-09-28 06:24:43.567 
Epoch 777/1000 
	 loss: 16.3857, MinusLogProbMetric: 16.3857, val_loss: 16.9530, val_MinusLogProbMetric: 16.9530

Epoch 777: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3857 - MinusLogProbMetric: 16.3857 - val_loss: 16.9530 - val_MinusLogProbMetric: 16.9530 - lr: 1.5625e-05 - 38s/epoch - 195ms/step
Epoch 778/1000
2023-09-28 06:25:21.681 
Epoch 778/1000 
	 loss: 16.3881, MinusLogProbMetric: 16.3881, val_loss: 16.9542, val_MinusLogProbMetric: 16.9542

Epoch 778: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3881 - MinusLogProbMetric: 16.3881 - val_loss: 16.9542 - val_MinusLogProbMetric: 16.9542 - lr: 1.5625e-05 - 38s/epoch - 194ms/step
Epoch 779/1000
2023-09-28 06:26:00.180 
Epoch 779/1000 
	 loss: 16.3860, MinusLogProbMetric: 16.3860, val_loss: 16.9501, val_MinusLogProbMetric: 16.9501

Epoch 779: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3860 - MinusLogProbMetric: 16.3860 - val_loss: 16.9501 - val_MinusLogProbMetric: 16.9501 - lr: 1.5625e-05 - 38s/epoch - 196ms/step
Epoch 780/1000
2023-09-28 06:26:36.913 
Epoch 780/1000 
	 loss: 16.3866, MinusLogProbMetric: 16.3866, val_loss: 16.9501, val_MinusLogProbMetric: 16.9501

Epoch 780: val_loss did not improve from 16.94937
196/196 - 37s - loss: 16.3866 - MinusLogProbMetric: 16.3866 - val_loss: 16.9501 - val_MinusLogProbMetric: 16.9501 - lr: 1.5625e-05 - 37s/epoch - 187ms/step
Epoch 781/1000
2023-09-28 06:27:14.339 
Epoch 781/1000 
	 loss: 16.3858, MinusLogProbMetric: 16.3858, val_loss: 16.9513, val_MinusLogProbMetric: 16.9513

Epoch 781: val_loss did not improve from 16.94937
196/196 - 37s - loss: 16.3858 - MinusLogProbMetric: 16.3858 - val_loss: 16.9513 - val_MinusLogProbMetric: 16.9513 - lr: 1.5625e-05 - 37s/epoch - 191ms/step
Epoch 782/1000
2023-09-28 06:27:46.066 
Epoch 782/1000 
	 loss: 16.3879, MinusLogProbMetric: 16.3879, val_loss: 16.9533, val_MinusLogProbMetric: 16.9533

Epoch 782: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3879 - MinusLogProbMetric: 16.3879 - val_loss: 16.9533 - val_MinusLogProbMetric: 16.9533 - lr: 1.5625e-05 - 32s/epoch - 162ms/step
Epoch 783/1000
2023-09-28 06:28:18.761 
Epoch 783/1000 
	 loss: 16.3882, MinusLogProbMetric: 16.3882, val_loss: 16.9535, val_MinusLogProbMetric: 16.9535

Epoch 783: val_loss did not improve from 16.94937
196/196 - 33s - loss: 16.3882 - MinusLogProbMetric: 16.3882 - val_loss: 16.9535 - val_MinusLogProbMetric: 16.9535 - lr: 1.5625e-05 - 33s/epoch - 167ms/step
Epoch 784/1000
2023-09-28 06:28:51.084 
Epoch 784/1000 
	 loss: 16.3858, MinusLogProbMetric: 16.3858, val_loss: 16.9697, val_MinusLogProbMetric: 16.9697

Epoch 784: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3858 - MinusLogProbMetric: 16.3858 - val_loss: 16.9697 - val_MinusLogProbMetric: 16.9697 - lr: 1.5625e-05 - 32s/epoch - 165ms/step
Epoch 785/1000
2023-09-28 06:29:26.180 
Epoch 785/1000 
	 loss: 16.3896, MinusLogProbMetric: 16.3896, val_loss: 16.9514, val_MinusLogProbMetric: 16.9514

Epoch 785: val_loss did not improve from 16.94937
196/196 - 35s - loss: 16.3896 - MinusLogProbMetric: 16.3896 - val_loss: 16.9514 - val_MinusLogProbMetric: 16.9514 - lr: 1.5625e-05 - 35s/epoch - 179ms/step
Epoch 786/1000
2023-09-28 06:30:03.486 
Epoch 786/1000 
	 loss: 16.3906, MinusLogProbMetric: 16.3906, val_loss: 16.9521, val_MinusLogProbMetric: 16.9521

Epoch 786: val_loss did not improve from 16.94937
196/196 - 37s - loss: 16.3906 - MinusLogProbMetric: 16.3906 - val_loss: 16.9521 - val_MinusLogProbMetric: 16.9521 - lr: 1.5625e-05 - 37s/epoch - 190ms/step
Epoch 787/1000
2023-09-28 06:30:38.995 
Epoch 787/1000 
	 loss: 16.3854, MinusLogProbMetric: 16.3854, val_loss: 16.9530, val_MinusLogProbMetric: 16.9530

Epoch 787: val_loss did not improve from 16.94937
196/196 - 36s - loss: 16.3854 - MinusLogProbMetric: 16.3854 - val_loss: 16.9530 - val_MinusLogProbMetric: 16.9530 - lr: 1.5625e-05 - 36s/epoch - 181ms/step
Epoch 788/1000
2023-09-28 06:31:10.892 
Epoch 788/1000 
	 loss: 16.3875, MinusLogProbMetric: 16.3875, val_loss: 16.9559, val_MinusLogProbMetric: 16.9559

Epoch 788: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3875 - MinusLogProbMetric: 16.3875 - val_loss: 16.9559 - val_MinusLogProbMetric: 16.9559 - lr: 1.5625e-05 - 32s/epoch - 163ms/step
Epoch 789/1000
2023-09-28 06:31:43.043 
Epoch 789/1000 
	 loss: 16.3881, MinusLogProbMetric: 16.3881, val_loss: 16.9506, val_MinusLogProbMetric: 16.9506

Epoch 789: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3881 - MinusLogProbMetric: 16.3881 - val_loss: 16.9506 - val_MinusLogProbMetric: 16.9506 - lr: 1.5625e-05 - 32s/epoch - 164ms/step
Epoch 790/1000
2023-09-28 06:32:16.077 
Epoch 790/1000 
	 loss: 16.3858, MinusLogProbMetric: 16.3858, val_loss: 16.9526, val_MinusLogProbMetric: 16.9526

Epoch 790: val_loss did not improve from 16.94937
196/196 - 33s - loss: 16.3858 - MinusLogProbMetric: 16.3858 - val_loss: 16.9526 - val_MinusLogProbMetric: 16.9526 - lr: 1.5625e-05 - 33s/epoch - 169ms/step
Epoch 791/1000
2023-09-28 06:32:52.910 
Epoch 791/1000 
	 loss: 16.3857, MinusLogProbMetric: 16.3857, val_loss: 16.9512, val_MinusLogProbMetric: 16.9512

Epoch 791: val_loss did not improve from 16.94937
196/196 - 37s - loss: 16.3857 - MinusLogProbMetric: 16.3857 - val_loss: 16.9512 - val_MinusLogProbMetric: 16.9512 - lr: 1.5625e-05 - 37s/epoch - 188ms/step
Epoch 792/1000
2023-09-28 06:33:29.895 
Epoch 792/1000 
	 loss: 16.3873, MinusLogProbMetric: 16.3873, val_loss: 16.9516, val_MinusLogProbMetric: 16.9516

Epoch 792: val_loss did not improve from 16.94937
196/196 - 37s - loss: 16.3873 - MinusLogProbMetric: 16.3873 - val_loss: 16.9516 - val_MinusLogProbMetric: 16.9516 - lr: 1.5625e-05 - 37s/epoch - 189ms/step
Epoch 793/1000
2023-09-28 06:34:04.249 
Epoch 793/1000 
	 loss: 16.3848, MinusLogProbMetric: 16.3848, val_loss: 16.9505, val_MinusLogProbMetric: 16.9505

Epoch 793: val_loss did not improve from 16.94937
196/196 - 34s - loss: 16.3848 - MinusLogProbMetric: 16.3848 - val_loss: 16.9505 - val_MinusLogProbMetric: 16.9505 - lr: 1.5625e-05 - 34s/epoch - 175ms/step
Epoch 794/1000
2023-09-28 06:34:36.303 
Epoch 794/1000 
	 loss: 16.3865, MinusLogProbMetric: 16.3865, val_loss: 16.9523, val_MinusLogProbMetric: 16.9523

Epoch 794: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3865 - MinusLogProbMetric: 16.3865 - val_loss: 16.9523 - val_MinusLogProbMetric: 16.9523 - lr: 1.5625e-05 - 32s/epoch - 164ms/step
Epoch 795/1000
2023-09-28 06:35:09.080 
Epoch 795/1000 
	 loss: 16.3869, MinusLogProbMetric: 16.3869, val_loss: 16.9513, val_MinusLogProbMetric: 16.9513

Epoch 795: val_loss did not improve from 16.94937
196/196 - 33s - loss: 16.3869 - MinusLogProbMetric: 16.3869 - val_loss: 16.9513 - val_MinusLogProbMetric: 16.9513 - lr: 1.5625e-05 - 33s/epoch - 167ms/step
Epoch 796/1000
2023-09-28 06:35:43.085 
Epoch 796/1000 
	 loss: 16.3842, MinusLogProbMetric: 16.3842, val_loss: 16.9505, val_MinusLogProbMetric: 16.9505

Epoch 796: val_loss did not improve from 16.94937
196/196 - 34s - loss: 16.3842 - MinusLogProbMetric: 16.3842 - val_loss: 16.9505 - val_MinusLogProbMetric: 16.9505 - lr: 1.5625e-05 - 34s/epoch - 174ms/step
Epoch 797/1000
2023-09-28 06:36:20.095 
Epoch 797/1000 
	 loss: 16.3860, MinusLogProbMetric: 16.3860, val_loss: 16.9537, val_MinusLogProbMetric: 16.9537

Epoch 797: val_loss did not improve from 16.94937
196/196 - 37s - loss: 16.3860 - MinusLogProbMetric: 16.3860 - val_loss: 16.9537 - val_MinusLogProbMetric: 16.9537 - lr: 1.5625e-05 - 37s/epoch - 189ms/step
Epoch 798/1000
2023-09-28 06:36:55.702 
Epoch 798/1000 
	 loss: 16.3868, MinusLogProbMetric: 16.3868, val_loss: 16.9510, val_MinusLogProbMetric: 16.9510

Epoch 798: val_loss did not improve from 16.94937
196/196 - 36s - loss: 16.3868 - MinusLogProbMetric: 16.3868 - val_loss: 16.9510 - val_MinusLogProbMetric: 16.9510 - lr: 1.5625e-05 - 36s/epoch - 182ms/step
Epoch 799/1000
2023-09-28 06:37:28.485 
Epoch 799/1000 
	 loss: 16.3847, MinusLogProbMetric: 16.3847, val_loss: 16.9531, val_MinusLogProbMetric: 16.9531

Epoch 799: val_loss did not improve from 16.94937
196/196 - 33s - loss: 16.3847 - MinusLogProbMetric: 16.3847 - val_loss: 16.9531 - val_MinusLogProbMetric: 16.9531 - lr: 1.5625e-05 - 33s/epoch - 167ms/step
Epoch 800/1000
2023-09-28 06:38:00.974 
Epoch 800/1000 
	 loss: 16.3845, MinusLogProbMetric: 16.3845, val_loss: 16.9534, val_MinusLogProbMetric: 16.9534

Epoch 800: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3845 - MinusLogProbMetric: 16.3845 - val_loss: 16.9534 - val_MinusLogProbMetric: 16.9534 - lr: 1.5625e-05 - 32s/epoch - 166ms/step
Epoch 801/1000
2023-09-28 06:38:33.617 
Epoch 801/1000 
	 loss: 16.3867, MinusLogProbMetric: 16.3867, val_loss: 16.9875, val_MinusLogProbMetric: 16.9875

Epoch 801: val_loss did not improve from 16.94937
196/196 - 33s - loss: 16.3867 - MinusLogProbMetric: 16.3867 - val_loss: 16.9875 - val_MinusLogProbMetric: 16.9875 - lr: 1.5625e-05 - 33s/epoch - 167ms/step
Epoch 802/1000
2023-09-28 06:39:10.992 
Epoch 802/1000 
	 loss: 16.3916, MinusLogProbMetric: 16.3916, val_loss: 16.9523, val_MinusLogProbMetric: 16.9523

Epoch 802: val_loss did not improve from 16.94937
196/196 - 37s - loss: 16.3916 - MinusLogProbMetric: 16.3916 - val_loss: 16.9523 - val_MinusLogProbMetric: 16.9523 - lr: 1.5625e-05 - 37s/epoch - 191ms/step
Epoch 803/1000
2023-09-28 06:39:47.957 
Epoch 803/1000 
	 loss: 16.3869, MinusLogProbMetric: 16.3869, val_loss: 16.9538, val_MinusLogProbMetric: 16.9538

Epoch 803: val_loss did not improve from 16.94937
196/196 - 37s - loss: 16.3869 - MinusLogProbMetric: 16.3869 - val_loss: 16.9538 - val_MinusLogProbMetric: 16.9538 - lr: 1.5625e-05 - 37s/epoch - 189ms/step
Epoch 804/1000
2023-09-28 06:40:19.664 
Epoch 804/1000 
	 loss: 16.3823, MinusLogProbMetric: 16.3823, val_loss: 16.9507, val_MinusLogProbMetric: 16.9507

Epoch 804: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3823 - MinusLogProbMetric: 16.3823 - val_loss: 16.9507 - val_MinusLogProbMetric: 16.9507 - lr: 7.8125e-06 - 32s/epoch - 162ms/step
Epoch 805/1000
2023-09-28 06:40:51.861 
Epoch 805/1000 
	 loss: 16.3823, MinusLogProbMetric: 16.3823, val_loss: 16.9504, val_MinusLogProbMetric: 16.9504

Epoch 805: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3823 - MinusLogProbMetric: 16.3823 - val_loss: 16.9504 - val_MinusLogProbMetric: 16.9504 - lr: 7.8125e-06 - 32s/epoch - 164ms/step
Epoch 806/1000
2023-09-28 06:41:24.604 
Epoch 806/1000 
	 loss: 16.3823, MinusLogProbMetric: 16.3823, val_loss: 16.9513, val_MinusLogProbMetric: 16.9513

Epoch 806: val_loss did not improve from 16.94937
196/196 - 33s - loss: 16.3823 - MinusLogProbMetric: 16.3823 - val_loss: 16.9513 - val_MinusLogProbMetric: 16.9513 - lr: 7.8125e-06 - 33s/epoch - 167ms/step
Epoch 807/1000
2023-09-28 06:41:59.591 
Epoch 807/1000 
	 loss: 16.3821, MinusLogProbMetric: 16.3821, val_loss: 16.9498, val_MinusLogProbMetric: 16.9498

Epoch 807: val_loss did not improve from 16.94937
196/196 - 35s - loss: 16.3821 - MinusLogProbMetric: 16.3821 - val_loss: 16.9498 - val_MinusLogProbMetric: 16.9498 - lr: 7.8125e-06 - 35s/epoch - 178ms/step
Epoch 808/1000
2023-09-28 06:42:35.606 
Epoch 808/1000 
	 loss: 16.3816, MinusLogProbMetric: 16.3816, val_loss: 16.9506, val_MinusLogProbMetric: 16.9506

Epoch 808: val_loss did not improve from 16.94937
196/196 - 36s - loss: 16.3816 - MinusLogProbMetric: 16.3816 - val_loss: 16.9506 - val_MinusLogProbMetric: 16.9506 - lr: 7.8125e-06 - 36s/epoch - 184ms/step
Epoch 809/1000
2023-09-28 06:43:09.899 
Epoch 809/1000 
	 loss: 16.3819, MinusLogProbMetric: 16.3819, val_loss: 16.9517, val_MinusLogProbMetric: 16.9517

Epoch 809: val_loss did not improve from 16.94937
196/196 - 34s - loss: 16.3819 - MinusLogProbMetric: 16.3819 - val_loss: 16.9517 - val_MinusLogProbMetric: 16.9517 - lr: 7.8125e-06 - 34s/epoch - 175ms/step
Epoch 810/1000
2023-09-28 06:43:42.529 
Epoch 810/1000 
	 loss: 16.3821, MinusLogProbMetric: 16.3821, val_loss: 16.9498, val_MinusLogProbMetric: 16.9498

Epoch 810: val_loss did not improve from 16.94937
196/196 - 33s - loss: 16.3821 - MinusLogProbMetric: 16.3821 - val_loss: 16.9498 - val_MinusLogProbMetric: 16.9498 - lr: 7.8125e-06 - 33s/epoch - 166ms/step
Epoch 811/1000
2023-09-28 06:44:14.688 
Epoch 811/1000 
	 loss: 16.3823, MinusLogProbMetric: 16.3823, val_loss: 16.9505, val_MinusLogProbMetric: 16.9505

Epoch 811: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3823 - MinusLogProbMetric: 16.3823 - val_loss: 16.9505 - val_MinusLogProbMetric: 16.9505 - lr: 7.8125e-06 - 32s/epoch - 164ms/step
Epoch 812/1000
2023-09-28 06:44:49.291 
Epoch 812/1000 
	 loss: 16.3815, MinusLogProbMetric: 16.3815, val_loss: 16.9521, val_MinusLogProbMetric: 16.9521

Epoch 812: val_loss did not improve from 16.94937
196/196 - 35s - loss: 16.3815 - MinusLogProbMetric: 16.3815 - val_loss: 16.9521 - val_MinusLogProbMetric: 16.9521 - lr: 7.8125e-06 - 35s/epoch - 177ms/step
Epoch 813/1000
2023-09-28 06:45:25.458 
Epoch 813/1000 
	 loss: 16.3813, MinusLogProbMetric: 16.3813, val_loss: 16.9516, val_MinusLogProbMetric: 16.9516

Epoch 813: val_loss did not improve from 16.94937
196/196 - 36s - loss: 16.3813 - MinusLogProbMetric: 16.3813 - val_loss: 16.9516 - val_MinusLogProbMetric: 16.9516 - lr: 7.8125e-06 - 36s/epoch - 185ms/step
Epoch 814/1000
2023-09-28 06:46:02.710 
Epoch 814/1000 
	 loss: 16.3812, MinusLogProbMetric: 16.3812, val_loss: 16.9518, val_MinusLogProbMetric: 16.9518

Epoch 814: val_loss did not improve from 16.94937
196/196 - 37s - loss: 16.3812 - MinusLogProbMetric: 16.3812 - val_loss: 16.9518 - val_MinusLogProbMetric: 16.9518 - lr: 7.8125e-06 - 37s/epoch - 190ms/step
Epoch 815/1000
2023-09-28 06:46:34.961 
Epoch 815/1000 
	 loss: 16.3813, MinusLogProbMetric: 16.3813, val_loss: 16.9510, val_MinusLogProbMetric: 16.9510

Epoch 815: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3813 - MinusLogProbMetric: 16.3813 - val_loss: 16.9510 - val_MinusLogProbMetric: 16.9510 - lr: 7.8125e-06 - 32s/epoch - 165ms/step
Epoch 816/1000
2023-09-28 06:47:06.166 
Epoch 816/1000 
	 loss: 16.3821, MinusLogProbMetric: 16.3821, val_loss: 16.9507, val_MinusLogProbMetric: 16.9507

Epoch 816: val_loss did not improve from 16.94937
196/196 - 31s - loss: 16.3821 - MinusLogProbMetric: 16.3821 - val_loss: 16.9507 - val_MinusLogProbMetric: 16.9507 - lr: 7.8125e-06 - 31s/epoch - 159ms/step
Epoch 817/1000
2023-09-28 06:47:37.678 
Epoch 817/1000 
	 loss: 16.3819, MinusLogProbMetric: 16.3819, val_loss: 16.9508, val_MinusLogProbMetric: 16.9508

Epoch 817: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3819 - MinusLogProbMetric: 16.3819 - val_loss: 16.9508 - val_MinusLogProbMetric: 16.9508 - lr: 7.8125e-06 - 32s/epoch - 161ms/step
Epoch 818/1000
2023-09-28 06:48:11.492 
Epoch 818/1000 
	 loss: 16.3808, MinusLogProbMetric: 16.3808, val_loss: 16.9514, val_MinusLogProbMetric: 16.9514

Epoch 818: val_loss did not improve from 16.94937
196/196 - 34s - loss: 16.3808 - MinusLogProbMetric: 16.3808 - val_loss: 16.9514 - val_MinusLogProbMetric: 16.9514 - lr: 7.8125e-06 - 34s/epoch - 173ms/step
Epoch 819/1000
2023-09-28 06:48:49.173 
Epoch 819/1000 
	 loss: 16.3814, MinusLogProbMetric: 16.3814, val_loss: 16.9511, val_MinusLogProbMetric: 16.9511

Epoch 819: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3814 - MinusLogProbMetric: 16.3814 - val_loss: 16.9511 - val_MinusLogProbMetric: 16.9511 - lr: 7.8125e-06 - 38s/epoch - 192ms/step
Epoch 820/1000
2023-09-28 06:49:23.547 
Epoch 820/1000 
	 loss: 16.3811, MinusLogProbMetric: 16.3811, val_loss: 16.9504, val_MinusLogProbMetric: 16.9504

Epoch 820: val_loss did not improve from 16.94937
196/196 - 34s - loss: 16.3811 - MinusLogProbMetric: 16.3811 - val_loss: 16.9504 - val_MinusLogProbMetric: 16.9504 - lr: 7.8125e-06 - 34s/epoch - 175ms/step
Epoch 821/1000
2023-09-28 06:49:55.182 
Epoch 821/1000 
	 loss: 16.3814, MinusLogProbMetric: 16.3814, val_loss: 16.9506, val_MinusLogProbMetric: 16.9506

Epoch 821: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3814 - MinusLogProbMetric: 16.3814 - val_loss: 16.9506 - val_MinusLogProbMetric: 16.9506 - lr: 7.8125e-06 - 32s/epoch - 161ms/step
Epoch 822/1000
2023-09-28 06:50:27.022 
Epoch 822/1000 
	 loss: 16.3821, MinusLogProbMetric: 16.3821, val_loss: 16.9521, val_MinusLogProbMetric: 16.9521

Epoch 822: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3821 - MinusLogProbMetric: 16.3821 - val_loss: 16.9521 - val_MinusLogProbMetric: 16.9521 - lr: 7.8125e-06 - 32s/epoch - 162ms/step
Epoch 823/1000
2023-09-28 06:50:58.699 
Epoch 823/1000 
	 loss: 16.3817, MinusLogProbMetric: 16.3817, val_loss: 16.9528, val_MinusLogProbMetric: 16.9528

Epoch 823: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3817 - MinusLogProbMetric: 16.3817 - val_loss: 16.9528 - val_MinusLogProbMetric: 16.9528 - lr: 7.8125e-06 - 32s/epoch - 162ms/step
Epoch 824/1000
2023-09-28 06:51:32.662 
Epoch 824/1000 
	 loss: 16.3809, MinusLogProbMetric: 16.3809, val_loss: 16.9494, val_MinusLogProbMetric: 16.9494

Epoch 824: val_loss did not improve from 16.94937
196/196 - 34s - loss: 16.3809 - MinusLogProbMetric: 16.3809 - val_loss: 16.9494 - val_MinusLogProbMetric: 16.9494 - lr: 7.8125e-06 - 34s/epoch - 173ms/step
Epoch 825/1000
2023-09-28 06:52:10.348 
Epoch 825/1000 
	 loss: 16.3812, MinusLogProbMetric: 16.3812, val_loss: 16.9505, val_MinusLogProbMetric: 16.9505

Epoch 825: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3812 - MinusLogProbMetric: 16.3812 - val_loss: 16.9505 - val_MinusLogProbMetric: 16.9505 - lr: 7.8125e-06 - 38s/epoch - 192ms/step
Epoch 826/1000
2023-09-28 06:52:46.779 
Epoch 826/1000 
	 loss: 16.3809, MinusLogProbMetric: 16.3809, val_loss: 16.9511, val_MinusLogProbMetric: 16.9511

Epoch 826: val_loss did not improve from 16.94937
196/196 - 36s - loss: 16.3809 - MinusLogProbMetric: 16.3809 - val_loss: 16.9511 - val_MinusLogProbMetric: 16.9511 - lr: 7.8125e-06 - 36s/epoch - 186ms/step
Epoch 827/1000
2023-09-28 06:53:18.420 
Epoch 827/1000 
	 loss: 16.3814, MinusLogProbMetric: 16.3814, val_loss: 16.9530, val_MinusLogProbMetric: 16.9530

Epoch 827: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3814 - MinusLogProbMetric: 16.3814 - val_loss: 16.9530 - val_MinusLogProbMetric: 16.9530 - lr: 7.8125e-06 - 32s/epoch - 161ms/step
Epoch 828/1000
2023-09-28 06:53:50.213 
Epoch 828/1000 
	 loss: 16.3816, MinusLogProbMetric: 16.3816, val_loss: 16.9536, val_MinusLogProbMetric: 16.9536

Epoch 828: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3816 - MinusLogProbMetric: 16.3816 - val_loss: 16.9536 - val_MinusLogProbMetric: 16.9536 - lr: 7.8125e-06 - 32s/epoch - 162ms/step
Epoch 829/1000
2023-09-28 06:54:22.237 
Epoch 829/1000 
	 loss: 16.3813, MinusLogProbMetric: 16.3813, val_loss: 16.9505, val_MinusLogProbMetric: 16.9505

Epoch 829: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3813 - MinusLogProbMetric: 16.3813 - val_loss: 16.9505 - val_MinusLogProbMetric: 16.9505 - lr: 7.8125e-06 - 32s/epoch - 163ms/step
Epoch 830/1000
2023-09-28 06:54:56.114 
Epoch 830/1000 
	 loss: 16.3805, MinusLogProbMetric: 16.3805, val_loss: 16.9513, val_MinusLogProbMetric: 16.9513

Epoch 830: val_loss did not improve from 16.94937
196/196 - 34s - loss: 16.3805 - MinusLogProbMetric: 16.3805 - val_loss: 16.9513 - val_MinusLogProbMetric: 16.9513 - lr: 7.8125e-06 - 34s/epoch - 173ms/step
Epoch 831/1000
2023-09-28 06:55:33.035 
Epoch 831/1000 
	 loss: 16.3807, MinusLogProbMetric: 16.3807, val_loss: 16.9529, val_MinusLogProbMetric: 16.9529

Epoch 831: val_loss did not improve from 16.94937
196/196 - 37s - loss: 16.3807 - MinusLogProbMetric: 16.3807 - val_loss: 16.9529 - val_MinusLogProbMetric: 16.9529 - lr: 7.8125e-06 - 37s/epoch - 188ms/step
Epoch 832/1000
2023-09-28 06:56:08.642 
Epoch 832/1000 
	 loss: 16.3814, MinusLogProbMetric: 16.3814, val_loss: 16.9501, val_MinusLogProbMetric: 16.9501

Epoch 832: val_loss did not improve from 16.94937
196/196 - 36s - loss: 16.3814 - MinusLogProbMetric: 16.3814 - val_loss: 16.9501 - val_MinusLogProbMetric: 16.9501 - lr: 7.8125e-06 - 36s/epoch - 182ms/step
Epoch 833/1000
2023-09-28 06:56:40.518 
Epoch 833/1000 
	 loss: 16.3807, MinusLogProbMetric: 16.3807, val_loss: 16.9521, val_MinusLogProbMetric: 16.9521

Epoch 833: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3807 - MinusLogProbMetric: 16.3807 - val_loss: 16.9521 - val_MinusLogProbMetric: 16.9521 - lr: 7.8125e-06 - 32s/epoch - 163ms/step
Epoch 834/1000
2023-09-28 06:57:12.489 
Epoch 834/1000 
	 loss: 16.3810, MinusLogProbMetric: 16.3810, val_loss: 16.9519, val_MinusLogProbMetric: 16.9519

Epoch 834: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3810 - MinusLogProbMetric: 16.3810 - val_loss: 16.9519 - val_MinusLogProbMetric: 16.9519 - lr: 7.8125e-06 - 32s/epoch - 163ms/step
Epoch 835/1000
2023-09-28 06:57:45.769 
Epoch 835/1000 
	 loss: 16.3817, MinusLogProbMetric: 16.3817, val_loss: 16.9517, val_MinusLogProbMetric: 16.9517

Epoch 835: val_loss did not improve from 16.94937
196/196 - 33s - loss: 16.3817 - MinusLogProbMetric: 16.3817 - val_loss: 16.9517 - val_MinusLogProbMetric: 16.9517 - lr: 7.8125e-06 - 33s/epoch - 170ms/step
Epoch 836/1000
2023-09-28 06:58:21.131 
Epoch 836/1000 
	 loss: 16.3810, MinusLogProbMetric: 16.3810, val_loss: 16.9505, val_MinusLogProbMetric: 16.9505

Epoch 836: val_loss did not improve from 16.94937
196/196 - 35s - loss: 16.3810 - MinusLogProbMetric: 16.3810 - val_loss: 16.9505 - val_MinusLogProbMetric: 16.9505 - lr: 7.8125e-06 - 35s/epoch - 180ms/step
Epoch 837/1000
2023-09-28 06:58:57.772 
Epoch 837/1000 
	 loss: 16.3803, MinusLogProbMetric: 16.3803, val_loss: 16.9504, val_MinusLogProbMetric: 16.9504

Epoch 837: val_loss did not improve from 16.94937
196/196 - 37s - loss: 16.3803 - MinusLogProbMetric: 16.3803 - val_loss: 16.9504 - val_MinusLogProbMetric: 16.9504 - lr: 7.8125e-06 - 37s/epoch - 187ms/step
Epoch 838/1000
2023-09-28 06:59:32.446 
Epoch 838/1000 
	 loss: 16.3817, MinusLogProbMetric: 16.3817, val_loss: 16.9500, val_MinusLogProbMetric: 16.9500

Epoch 838: val_loss did not improve from 16.94937
196/196 - 35s - loss: 16.3817 - MinusLogProbMetric: 16.3817 - val_loss: 16.9500 - val_MinusLogProbMetric: 16.9500 - lr: 7.8125e-06 - 35s/epoch - 177ms/step
Epoch 839/1000
2023-09-28 07:00:03.959 
Epoch 839/1000 
	 loss: 16.3806, MinusLogProbMetric: 16.3806, val_loss: 16.9518, val_MinusLogProbMetric: 16.9518

Epoch 839: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3806 - MinusLogProbMetric: 16.3806 - val_loss: 16.9518 - val_MinusLogProbMetric: 16.9518 - lr: 7.8125e-06 - 32s/epoch - 161ms/step
Epoch 840/1000
2023-09-28 07:00:36.076 
Epoch 840/1000 
	 loss: 16.3803, MinusLogProbMetric: 16.3803, val_loss: 16.9515, val_MinusLogProbMetric: 16.9515

Epoch 840: val_loss did not improve from 16.94937
196/196 - 32s - loss: 16.3803 - MinusLogProbMetric: 16.3803 - val_loss: 16.9515 - val_MinusLogProbMetric: 16.9515 - lr: 7.8125e-06 - 32s/epoch - 164ms/step
Epoch 841/1000
2023-09-28 07:01:08.643 
Epoch 841/1000 
	 loss: 16.3810, MinusLogProbMetric: 16.3810, val_loss: 16.9510, val_MinusLogProbMetric: 16.9510

Epoch 841: val_loss did not improve from 16.94937
196/196 - 33s - loss: 16.3810 - MinusLogProbMetric: 16.3810 - val_loss: 16.9510 - val_MinusLogProbMetric: 16.9510 - lr: 7.8125e-06 - 33s/epoch - 166ms/step
Epoch 842/1000
2023-09-28 07:01:45.545 
Epoch 842/1000 
	 loss: 16.3812, MinusLogProbMetric: 16.3812, val_loss: 16.9502, val_MinusLogProbMetric: 16.9502

Epoch 842: val_loss did not improve from 16.94937
196/196 - 37s - loss: 16.3812 - MinusLogProbMetric: 16.3812 - val_loss: 16.9502 - val_MinusLogProbMetric: 16.9502 - lr: 7.8125e-06 - 37s/epoch - 188ms/step
Epoch 843/1000
2023-09-28 07:02:23.829 
Epoch 843/1000 
	 loss: 16.3811, MinusLogProbMetric: 16.3811, val_loss: 16.9507, val_MinusLogProbMetric: 16.9507

Epoch 843: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3811 - MinusLogProbMetric: 16.3811 - val_loss: 16.9507 - val_MinusLogProbMetric: 16.9507 - lr: 7.8125e-06 - 38s/epoch - 195ms/step
Epoch 844/1000
2023-09-28 07:03:01.148 
Epoch 844/1000 
	 loss: 16.3807, MinusLogProbMetric: 16.3807, val_loss: 16.9507, val_MinusLogProbMetric: 16.9507

Epoch 844: val_loss did not improve from 16.94937
196/196 - 37s - loss: 16.3807 - MinusLogProbMetric: 16.3807 - val_loss: 16.9507 - val_MinusLogProbMetric: 16.9507 - lr: 7.8125e-06 - 37s/epoch - 190ms/step
Epoch 845/1000
2023-09-28 07:03:33.835 
Epoch 845/1000 
	 loss: 16.3804, MinusLogProbMetric: 16.3804, val_loss: 16.9506, val_MinusLogProbMetric: 16.9506

Epoch 845: val_loss did not improve from 16.94937
196/196 - 33s - loss: 16.3804 - MinusLogProbMetric: 16.3804 - val_loss: 16.9506 - val_MinusLogProbMetric: 16.9506 - lr: 7.8125e-06 - 33s/epoch - 167ms/step
Epoch 846/1000
2023-09-28 07:04:10.581 
Epoch 846/1000 
	 loss: 16.3801, MinusLogProbMetric: 16.3801, val_loss: 16.9508, val_MinusLogProbMetric: 16.9508

Epoch 846: val_loss did not improve from 16.94937
196/196 - 37s - loss: 16.3801 - MinusLogProbMetric: 16.3801 - val_loss: 16.9508 - val_MinusLogProbMetric: 16.9508 - lr: 7.8125e-06 - 37s/epoch - 187ms/step
Epoch 847/1000
2023-09-28 07:04:48.462 
Epoch 847/1000 
	 loss: 16.3812, MinusLogProbMetric: 16.3812, val_loss: 16.9509, val_MinusLogProbMetric: 16.9509

Epoch 847: val_loss did not improve from 16.94937
196/196 - 38s - loss: 16.3812 - MinusLogProbMetric: 16.3812 - val_loss: 16.9509 - val_MinusLogProbMetric: 16.9509 - lr: 7.8125e-06 - 38s/epoch - 193ms/step
Epoch 848/1000
2023-09-28 07:05:27.252 
Epoch 848/1000 
	 loss: 16.3812, MinusLogProbMetric: 16.3812, val_loss: 16.9512, val_MinusLogProbMetric: 16.9512

Epoch 848: val_loss did not improve from 16.94937
196/196 - 39s - loss: 16.3812 - MinusLogProbMetric: 16.3812 - val_loss: 16.9512 - val_MinusLogProbMetric: 16.9512 - lr: 7.8125e-06 - 39s/epoch - 198ms/step
Epoch 849/1000
2023-09-28 07:06:05.941 
Epoch 849/1000 
	 loss: 16.3806, MinusLogProbMetric: 16.3806, val_loss: 16.9508, val_MinusLogProbMetric: 16.9508

Epoch 849: val_loss did not improve from 16.94937
196/196 - 39s - loss: 16.3806 - MinusLogProbMetric: 16.3806 - val_loss: 16.9508 - val_MinusLogProbMetric: 16.9508 - lr: 7.8125e-06 - 39s/epoch - 197ms/step
Epoch 850/1000
2023-09-28 07:06:44.785 
Epoch 850/1000 
	 loss: 16.3813, MinusLogProbMetric: 16.3813, val_loss: 16.9524, val_MinusLogProbMetric: 16.9524

Epoch 850: val_loss did not improve from 16.94937
196/196 - 39s - loss: 16.3813 - MinusLogProbMetric: 16.3813 - val_loss: 16.9524 - val_MinusLogProbMetric: 16.9524 - lr: 7.8125e-06 - 39s/epoch - 198ms/step
Epoch 851/1000
2023-09-28 07:07:23.298 
Epoch 851/1000 
	 loss: 16.3814, MinusLogProbMetric: 16.3814, val_loss: 16.9503, val_MinusLogProbMetric: 16.9503

Epoch 851: val_loss did not improve from 16.94937
196/196 - 39s - loss: 16.3814 - MinusLogProbMetric: 16.3814 - val_loss: 16.9503 - val_MinusLogProbMetric: 16.9503 - lr: 7.8125e-06 - 39s/epoch - 196ms/step
Epoch 852/1000
2023-09-28 07:08:02.278 
Epoch 852/1000 
	 loss: 16.3803, MinusLogProbMetric: 16.3803, val_loss: 16.9499, val_MinusLogProbMetric: 16.9499

Epoch 852: val_loss did not improve from 16.94937
196/196 - 39s - loss: 16.3803 - MinusLogProbMetric: 16.3803 - val_loss: 16.9499 - val_MinusLogProbMetric: 16.9499 - lr: 7.8125e-06 - 39s/epoch - 199ms/step
Epoch 853/1000
2023-09-28 07:08:40.831 
Epoch 853/1000 
	 loss: 16.3808, MinusLogProbMetric: 16.3808, val_loss: 16.9501, val_MinusLogProbMetric: 16.9501

Epoch 853: val_loss did not improve from 16.94937
Restoring model weights from the end of the best epoch: 753.
196/196 - 39s - loss: 16.3808 - MinusLogProbMetric: 16.3808 - val_loss: 16.9501 - val_MinusLogProbMetric: 16.9501 - lr: 7.8125e-06 - 39s/epoch - 199ms/step
Epoch 853: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
LR metric calculation completed in 16.7108022380271 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 9.161649340006988 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
SWD metric calculation completed in 6.563968959031627 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
FN metric calculation completed in 7.755588366999291 seconds.
Training succeeded with seed 933.
Model trained in 32368.45 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 41.51 s.
                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/c_Main_CsplineN.py , Line : 469, Func.Name : prediction_function, Message : Plotters.cornerplotter(X_data_test.numpy(),X_data_nf.numpy(),path_to_results,ndims,norm=True) # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 41.78 s.
===========
Run 315/720 done in 32415.98 s.
===========

Directory ../../results/CsplineN_new/run_316/ already exists.
Skipping it.
===========
Run 316/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_317/ already exists.
Skipping it.
===========
Run 317/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_318/ already exists.
Skipping it.
===========
Run 318/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_319/ already exists.
Skipping it.
===========
Run 319/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_320/ already exists.
Skipping it.
===========
Run 320/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_321/ already exists.
Skipping it.
===========
Run 321/720 already exists. Skipping it.
===========

===========
Generating train data for run 322.
===========
Train data generated in 0.20 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 64)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_322/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 0}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_322/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[5.843066  , 6.885543  , 5.4616323 , ..., 0.60136265, 7.6057563 ,
        1.4468012 ],
       [6.941901  , 2.9639573 , 6.1196294 , ..., 3.4089205 , 5.0531244 ,
        1.7321708 ],
       [6.6497912 , 2.6758661 , 6.1924143 , ..., 2.4044154 , 3.5041332 ,
        2.3901901 ],
       ...,
       [5.4960246 , 7.681503  , 5.4965014 , ..., 1.6430786 , 5.8353615 ,
        1.3267541 ],
       [5.6652064 , 7.894577  , 5.7936563 , ..., 1.3511211 , 6.9882894 ,
        1.2434273 ],
       [5.24072   , 7.783675  , 5.8090463 , ..., 1.1913109 , 5.8178825 ,
        1.3373194 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_322/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_322
self.data_kwargs: {'seed': 0}
self.x_data: [[ 6.6721983   2.7232099   6.150583   ...  3.6440284   4.565682
   2.645935  ]
 [ 1.86333     2.9602146   9.095053   ...  6.366897   -0.51058275
   3.6708503 ]
 [ 5.5981846   7.771953    4.990416   ...  1.6793485   6.8585963
   1.4719678 ]
 ...
 [ 1.690249    4.096276    8.408299   ...  5.907632    0.7324666
   3.17104   ]
 [ 1.5949699   2.976067    6.189886   ...  6.072563    1.3667407
   3.7841148 ]
 [ 6.6605377   2.9536047   6.141097   ...  3.8587723   3.7946694
   1.5606189 ]]
self.y_data: []
self.ndims: 64
Model defined.
Model: "model_63"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_64 (InputLayer)       [(None, 64)]              0         
                                                                 
 log_prob_layer_8 (LogProbLa  (None,)                  1645920   
 yer)                                                            
                                                                 
=================================================================
Total params: 1,645,920
Trainable params: 1,645,920
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_8/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_8'")
self.model: <keras.engine.functional.Functional object at 0x7fd1dc431240>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fd1dc427a00>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fd1dc427a00>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fd314211c90>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fda09e01ae0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fda09e02050>, <keras.callbacks.ModelCheckpoint object at 0x7fda09e02110>, <keras.callbacks.EarlyStopping object at 0x7fda09e02380>, <keras.callbacks.ReduceLROnPlateau object at 0x7fda09e023b0>, <keras.callbacks.TerminateOnNaN object at 0x7fda09e01ff0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[5.843066  , 6.885543  , 5.4616323 , ..., 0.60136265, 7.6057563 ,
        1.4468012 ],
       [6.941901  , 2.9639573 , 6.1196294 , ..., 3.4089205 , 5.0531244 ,
        1.7321708 ],
       [6.6497912 , 2.6758661 , 6.1924143 , ..., 2.4044154 , 3.5041332 ,
        2.3901901 ],
       ...,
       [5.4960246 , 7.681503  , 5.4965014 , ..., 1.6430786 , 5.8353615 ,
        1.3267541 ],
       [5.6652064 , 7.894577  , 5.7936563 , ..., 1.3511211 , 6.9882894 ,
        1.2434273 ],
       [5.24072   , 7.783675  , 5.8090463 , ..., 1.1913109 , 5.8178825 ,
        1.3373194 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_322/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 322/720 with hyperparameters:
timestamp = 2023-09-28 07:09:27.854748
ndims = 64
seed_train = 0
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 5
spline_knots = 8
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 1645920
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 6.6721983   2.7232099   6.150583    4.580923    1.5652926   2.6565456
  7.1790314   4.9339914   5.7110434   6.7498174   6.386396    3.9689803
  8.906224    3.806384    4.1225185   9.359665    7.9177184   7.261933
  0.1027934   9.199222    7.196588   10.08044     2.3912797   8.714102
  2.4626331   6.1591697   1.6348177   8.815128    7.787716    5.5076594
  3.3412566   0.7007286   7.2919664   4.3464866   6.6338673   7.1474853
  9.7648      8.511822   -0.5374965   5.0141335   7.365311    0.6638582
  5.9037857   0.7669884   1.383983    0.33108917  8.1157875   2.689867
  4.5051117   9.846115    7.6886387   0.35349095  2.5627694   4.5428576
  5.8595724   2.7118683   9.446846    6.2642756   4.7844443   6.0548897
  8.103386    3.6440284   4.565682    2.645935  ]
Epoch 1/1000
2023-09-28 07:11:00.607 
Epoch 1/1000 
	 loss: 650.4288, MinusLogProbMetric: 650.4288, val_loss: 119.0785, val_MinusLogProbMetric: 119.0785

Epoch 1: val_loss improved from inf to 119.07849, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 93s - loss: 650.4288 - MinusLogProbMetric: 650.4288 - val_loss: 119.0785 - val_MinusLogProbMetric: 119.0785 - lr: 0.0010 - 93s/epoch - 475ms/step
Epoch 2/1000
2023-09-28 07:11:34.157 
Epoch 2/1000 
	 loss: 103.4249, MinusLogProbMetric: 103.4249, val_loss: 105.8087, val_MinusLogProbMetric: 105.8087

Epoch 2: val_loss improved from 119.07849 to 105.80865, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 103.4249 - MinusLogProbMetric: 103.4249 - val_loss: 105.8087 - val_MinusLogProbMetric: 105.8087 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 3/1000
2023-09-28 07:12:07.045 
Epoch 3/1000 
	 loss: 71.0438, MinusLogProbMetric: 71.0438, val_loss: 60.3834, val_MinusLogProbMetric: 60.3834

Epoch 3: val_loss improved from 105.80865 to 60.38340, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 71.0438 - MinusLogProbMetric: 71.0438 - val_loss: 60.3834 - val_MinusLogProbMetric: 60.3834 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 4/1000
2023-09-28 07:12:40.170 
Epoch 4/1000 
	 loss: 55.8328, MinusLogProbMetric: 55.8328, val_loss: 51.8794, val_MinusLogProbMetric: 51.8794

Epoch 4: val_loss improved from 60.38340 to 51.87937, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 55.8328 - MinusLogProbMetric: 55.8328 - val_loss: 51.8794 - val_MinusLogProbMetric: 51.8794 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 5/1000
2023-09-28 07:13:13.072 
Epoch 5/1000 
	 loss: 49.4727, MinusLogProbMetric: 49.4727, val_loss: 47.6162, val_MinusLogProbMetric: 47.6162

Epoch 5: val_loss improved from 51.87937 to 47.61623, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 49.4727 - MinusLogProbMetric: 49.4727 - val_loss: 47.6162 - val_MinusLogProbMetric: 47.6162 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 6/1000
2023-09-28 07:13:46.222 
Epoch 6/1000 
	 loss: 45.4958, MinusLogProbMetric: 45.4958, val_loss: 44.2386, val_MinusLogProbMetric: 44.2386

Epoch 6: val_loss improved from 47.61623 to 44.23859, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 45.4958 - MinusLogProbMetric: 45.4958 - val_loss: 44.2386 - val_MinusLogProbMetric: 44.2386 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 7/1000
2023-09-28 07:14:19.103 
Epoch 7/1000 
	 loss: 43.0499, MinusLogProbMetric: 43.0499, val_loss: 41.5102, val_MinusLogProbMetric: 41.5102

Epoch 7: val_loss improved from 44.23859 to 41.51022, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 43.0499 - MinusLogProbMetric: 43.0499 - val_loss: 41.5102 - val_MinusLogProbMetric: 41.5102 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 8/1000
2023-09-28 07:14:52.083 
Epoch 8/1000 
	 loss: 41.8274, MinusLogProbMetric: 41.8274, val_loss: 40.2193, val_MinusLogProbMetric: 40.2193

Epoch 8: val_loss improved from 41.51022 to 40.21926, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 41.8274 - MinusLogProbMetric: 41.8274 - val_loss: 40.2193 - val_MinusLogProbMetric: 40.2193 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 9/1000
2023-09-28 07:15:24.938 
Epoch 9/1000 
	 loss: 39.6031, MinusLogProbMetric: 39.6031, val_loss: 39.5248, val_MinusLogProbMetric: 39.5248

Epoch 9: val_loss improved from 40.21926 to 39.52485, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 39.6031 - MinusLogProbMetric: 39.6031 - val_loss: 39.5248 - val_MinusLogProbMetric: 39.5248 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 10/1000
2023-09-28 07:15:57.863 
Epoch 10/1000 
	 loss: 38.7724, MinusLogProbMetric: 38.7724, val_loss: 38.4214, val_MinusLogProbMetric: 38.4214

Epoch 10: val_loss improved from 39.52485 to 38.42144, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 38.7724 - MinusLogProbMetric: 38.7724 - val_loss: 38.4214 - val_MinusLogProbMetric: 38.4214 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 11/1000
2023-09-28 07:16:30.614 
Epoch 11/1000 
	 loss: 37.7360, MinusLogProbMetric: 37.7360, val_loss: 37.4452, val_MinusLogProbMetric: 37.4452

Epoch 11: val_loss improved from 38.42144 to 37.44516, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 37.7360 - MinusLogProbMetric: 37.7360 - val_loss: 37.4452 - val_MinusLogProbMetric: 37.4452 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 12/1000
2023-09-28 07:17:03.590 
Epoch 12/1000 
	 loss: 37.0362, MinusLogProbMetric: 37.0362, val_loss: 38.7262, val_MinusLogProbMetric: 38.7262

Epoch 12: val_loss did not improve from 37.44516
196/196 - 32s - loss: 37.0362 - MinusLogProbMetric: 37.0362 - val_loss: 38.7262 - val_MinusLogProbMetric: 38.7262 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 13/1000
2023-09-28 07:17:35.802 
Epoch 13/1000 
	 loss: 36.4390, MinusLogProbMetric: 36.4390, val_loss: 36.1328, val_MinusLogProbMetric: 36.1328

Epoch 13: val_loss improved from 37.44516 to 36.13275, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 36.4390 - MinusLogProbMetric: 36.4390 - val_loss: 36.1328 - val_MinusLogProbMetric: 36.1328 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 14/1000
2023-09-28 07:18:08.482 
Epoch 14/1000 
	 loss: 35.5943, MinusLogProbMetric: 35.5943, val_loss: 36.7627, val_MinusLogProbMetric: 36.7627

Epoch 14: val_loss did not improve from 36.13275
196/196 - 32s - loss: 35.5943 - MinusLogProbMetric: 35.5943 - val_loss: 36.7627 - val_MinusLogProbMetric: 36.7627 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 15/1000
2023-09-28 07:18:40.602 
Epoch 15/1000 
	 loss: 35.7364, MinusLogProbMetric: 35.7364, val_loss: 34.3267, val_MinusLogProbMetric: 34.3267

Epoch 15: val_loss improved from 36.13275 to 34.32666, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 35.7364 - MinusLogProbMetric: 35.7364 - val_loss: 34.3267 - val_MinusLogProbMetric: 34.3267 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 16/1000
2023-09-28 07:19:13.348 
Epoch 16/1000 
	 loss: 35.3340, MinusLogProbMetric: 35.3340, val_loss: 36.9702, val_MinusLogProbMetric: 36.9702

Epoch 16: val_loss did not improve from 34.32666
196/196 - 32s - loss: 35.3340 - MinusLogProbMetric: 35.3340 - val_loss: 36.9702 - val_MinusLogProbMetric: 36.9702 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 17/1000
2023-09-28 07:19:45.813 
Epoch 17/1000 
	 loss: 34.9309, MinusLogProbMetric: 34.9309, val_loss: 34.6942, val_MinusLogProbMetric: 34.6942

Epoch 17: val_loss did not improve from 34.32666
196/196 - 32s - loss: 34.9309 - MinusLogProbMetric: 34.9309 - val_loss: 34.6942 - val_MinusLogProbMetric: 34.6942 - lr: 0.0010 - 32s/epoch - 166ms/step
Epoch 18/1000
2023-09-28 07:20:18.088 
Epoch 18/1000 
	 loss: 34.5008, MinusLogProbMetric: 34.5008, val_loss: 35.4606, val_MinusLogProbMetric: 35.4606

Epoch 18: val_loss did not improve from 34.32666
196/196 - 32s - loss: 34.5008 - MinusLogProbMetric: 34.5008 - val_loss: 35.4606 - val_MinusLogProbMetric: 35.4606 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 19/1000
2023-09-28 07:20:50.154 
Epoch 19/1000 
	 loss: 34.0880, MinusLogProbMetric: 34.0880, val_loss: 33.8885, val_MinusLogProbMetric: 33.8885

Epoch 19: val_loss improved from 34.32666 to 33.88853, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 34.0880 - MinusLogProbMetric: 34.0880 - val_loss: 33.8885 - val_MinusLogProbMetric: 33.8885 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 20/1000
2023-09-28 07:21:23.141 
Epoch 20/1000 
	 loss: 34.3214, MinusLogProbMetric: 34.3214, val_loss: 33.9527, val_MinusLogProbMetric: 33.9527

Epoch 20: val_loss did not improve from 33.88853
196/196 - 32s - loss: 34.3214 - MinusLogProbMetric: 34.3214 - val_loss: 33.9527 - val_MinusLogProbMetric: 33.9527 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 21/1000
2023-09-28 07:21:55.278 
Epoch 21/1000 
	 loss: 33.9170, MinusLogProbMetric: 33.9170, val_loss: 35.6270, val_MinusLogProbMetric: 35.6270

Epoch 21: val_loss did not improve from 33.88853
196/196 - 32s - loss: 33.9170 - MinusLogProbMetric: 33.9170 - val_loss: 35.6270 - val_MinusLogProbMetric: 35.6270 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 22/1000
2023-09-28 07:22:27.432 
Epoch 22/1000 
	 loss: 33.5619, MinusLogProbMetric: 33.5619, val_loss: 34.9495, val_MinusLogProbMetric: 34.9495

Epoch 22: val_loss did not improve from 33.88853
196/196 - 32s - loss: 33.5619 - MinusLogProbMetric: 33.5619 - val_loss: 34.9495 - val_MinusLogProbMetric: 34.9495 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 23/1000
2023-09-28 07:22:59.484 
Epoch 23/1000 
	 loss: 33.4106, MinusLogProbMetric: 33.4106, val_loss: 33.7169, val_MinusLogProbMetric: 33.7169

Epoch 23: val_loss improved from 33.88853 to 33.71692, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 33.4106 - MinusLogProbMetric: 33.4106 - val_loss: 33.7169 - val_MinusLogProbMetric: 33.7169 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 24/1000
2023-09-28 07:23:32.479 
Epoch 24/1000 
	 loss: 33.3897, MinusLogProbMetric: 33.3897, val_loss: 32.6779, val_MinusLogProbMetric: 32.6779

Epoch 24: val_loss improved from 33.71692 to 32.67786, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 33.3897 - MinusLogProbMetric: 33.3897 - val_loss: 32.6779 - val_MinusLogProbMetric: 32.6779 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 25/1000
2023-09-28 07:24:05.419 
Epoch 25/1000 
	 loss: 33.0107, MinusLogProbMetric: 33.0107, val_loss: 33.7233, val_MinusLogProbMetric: 33.7233

Epoch 25: val_loss did not improve from 32.67786
196/196 - 32s - loss: 33.0107 - MinusLogProbMetric: 33.0107 - val_loss: 33.7233 - val_MinusLogProbMetric: 33.7233 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 26/1000
2023-09-28 07:24:37.782 
Epoch 26/1000 
	 loss: 32.8962, MinusLogProbMetric: 32.8962, val_loss: 32.5387, val_MinusLogProbMetric: 32.5387

Epoch 26: val_loss improved from 32.67786 to 32.53870, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 32.8962 - MinusLogProbMetric: 32.8962 - val_loss: 32.5387 - val_MinusLogProbMetric: 32.5387 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 27/1000
2023-09-28 07:25:10.760 
Epoch 27/1000 
	 loss: 32.7978, MinusLogProbMetric: 32.7978, val_loss: 35.0713, val_MinusLogProbMetric: 35.0713

Epoch 27: val_loss did not improve from 32.53870
196/196 - 32s - loss: 32.7978 - MinusLogProbMetric: 32.7978 - val_loss: 35.0713 - val_MinusLogProbMetric: 35.0713 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 28/1000
2023-09-28 07:25:42.916 
Epoch 28/1000 
	 loss: 32.5592, MinusLogProbMetric: 32.5592, val_loss: 32.8357, val_MinusLogProbMetric: 32.8357

Epoch 28: val_loss did not improve from 32.53870
196/196 - 32s - loss: 32.5592 - MinusLogProbMetric: 32.5592 - val_loss: 32.8357 - val_MinusLogProbMetric: 32.8357 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 29/1000
2023-09-28 07:26:15.064 
Epoch 29/1000 
	 loss: 32.7168, MinusLogProbMetric: 32.7168, val_loss: 33.0440, val_MinusLogProbMetric: 33.0440

Epoch 29: val_loss did not improve from 32.53870
196/196 - 32s - loss: 32.7168 - MinusLogProbMetric: 32.7168 - val_loss: 33.0440 - val_MinusLogProbMetric: 33.0440 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 30/1000
2023-09-28 07:26:47.527 
Epoch 30/1000 
	 loss: 32.6099, MinusLogProbMetric: 32.6099, val_loss: 31.9070, val_MinusLogProbMetric: 31.9070

Epoch 30: val_loss improved from 32.53870 to 31.90700, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 32.6099 - MinusLogProbMetric: 32.6099 - val_loss: 31.9070 - val_MinusLogProbMetric: 31.9070 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 31/1000
2023-09-28 07:27:20.508 
Epoch 31/1000 
	 loss: 32.1840, MinusLogProbMetric: 32.1840, val_loss: 32.5263, val_MinusLogProbMetric: 32.5263

Epoch 31: val_loss did not improve from 31.90700
196/196 - 32s - loss: 32.1840 - MinusLogProbMetric: 32.1840 - val_loss: 32.5263 - val_MinusLogProbMetric: 32.5263 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 32/1000
2023-09-28 07:27:52.931 
Epoch 32/1000 
	 loss: 32.2373, MinusLogProbMetric: 32.2373, val_loss: 32.6166, val_MinusLogProbMetric: 32.6166

Epoch 32: val_loss did not improve from 31.90700
196/196 - 32s - loss: 32.2373 - MinusLogProbMetric: 32.2373 - val_loss: 32.6166 - val_MinusLogProbMetric: 32.6166 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 33/1000
2023-09-28 07:28:25.480 
Epoch 33/1000 
	 loss: 32.3355, MinusLogProbMetric: 32.3355, val_loss: 31.6489, val_MinusLogProbMetric: 31.6489

Epoch 33: val_loss improved from 31.90700 to 31.64887, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 32.3355 - MinusLogProbMetric: 32.3355 - val_loss: 31.6489 - val_MinusLogProbMetric: 31.6489 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 34/1000
2023-09-28 07:28:58.325 
Epoch 34/1000 
	 loss: 31.8914, MinusLogProbMetric: 31.8914, val_loss: 32.6365, val_MinusLogProbMetric: 32.6365

Epoch 34: val_loss did not improve from 31.64887
196/196 - 32s - loss: 31.8914 - MinusLogProbMetric: 31.8914 - val_loss: 32.6365 - val_MinusLogProbMetric: 32.6365 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 35/1000
2023-09-28 07:29:30.563 
Epoch 35/1000 
	 loss: 31.7845, MinusLogProbMetric: 31.7845, val_loss: 31.4125, val_MinusLogProbMetric: 31.4125

Epoch 35: val_loss improved from 31.64887 to 31.41255, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 31.7845 - MinusLogProbMetric: 31.7845 - val_loss: 31.4125 - val_MinusLogProbMetric: 31.4125 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 36/1000
2023-09-28 07:30:03.400 
Epoch 36/1000 
	 loss: 31.8159, MinusLogProbMetric: 31.8159, val_loss: 30.9468, val_MinusLogProbMetric: 30.9468

Epoch 36: val_loss improved from 31.41255 to 30.94684, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 31.8159 - MinusLogProbMetric: 31.8159 - val_loss: 30.9468 - val_MinusLogProbMetric: 30.9468 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 37/1000
2023-09-28 07:30:36.155 
Epoch 37/1000 
	 loss: 31.6125, MinusLogProbMetric: 31.6125, val_loss: 32.3194, val_MinusLogProbMetric: 32.3194

Epoch 37: val_loss did not improve from 30.94684
196/196 - 32s - loss: 31.6125 - MinusLogProbMetric: 31.6125 - val_loss: 32.3194 - val_MinusLogProbMetric: 32.3194 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 38/1000
2023-09-28 07:31:08.521 
Epoch 38/1000 
	 loss: 31.5843, MinusLogProbMetric: 31.5843, val_loss: 31.6392, val_MinusLogProbMetric: 31.6392

Epoch 38: val_loss did not improve from 30.94684
196/196 - 32s - loss: 31.5843 - MinusLogProbMetric: 31.5843 - val_loss: 31.6392 - val_MinusLogProbMetric: 31.6392 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 39/1000
2023-09-28 07:31:40.949 
Epoch 39/1000 
	 loss: 31.4740, MinusLogProbMetric: 31.4740, val_loss: 32.7458, val_MinusLogProbMetric: 32.7458

Epoch 39: val_loss did not improve from 30.94684
196/196 - 32s - loss: 31.4740 - MinusLogProbMetric: 31.4740 - val_loss: 32.7458 - val_MinusLogProbMetric: 32.7458 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 40/1000
2023-09-28 07:32:13.233 
Epoch 40/1000 
	 loss: 31.5506, MinusLogProbMetric: 31.5506, val_loss: 31.8174, val_MinusLogProbMetric: 31.8174

Epoch 40: val_loss did not improve from 30.94684
196/196 - 32s - loss: 31.5506 - MinusLogProbMetric: 31.5506 - val_loss: 31.8174 - val_MinusLogProbMetric: 31.8174 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 41/1000
2023-09-28 07:32:45.626 
Epoch 41/1000 
	 loss: 31.5880, MinusLogProbMetric: 31.5880, val_loss: 31.5422, val_MinusLogProbMetric: 31.5422

Epoch 41: val_loss did not improve from 30.94684
196/196 - 32s - loss: 31.5880 - MinusLogProbMetric: 31.5880 - val_loss: 31.5422 - val_MinusLogProbMetric: 31.5422 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 42/1000
2023-09-28 07:33:17.721 
Epoch 42/1000 
	 loss: 31.5974, MinusLogProbMetric: 31.5974, val_loss: 31.8948, val_MinusLogProbMetric: 31.8948

Epoch 42: val_loss did not improve from 30.94684
196/196 - 32s - loss: 31.5974 - MinusLogProbMetric: 31.5974 - val_loss: 31.8948 - val_MinusLogProbMetric: 31.8948 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 43/1000
2023-09-28 07:33:50.269 
Epoch 43/1000 
	 loss: 31.3792, MinusLogProbMetric: 31.3792, val_loss: 32.4350, val_MinusLogProbMetric: 32.4350

Epoch 43: val_loss did not improve from 30.94684
196/196 - 33s - loss: 31.3792 - MinusLogProbMetric: 31.3792 - val_loss: 32.4350 - val_MinusLogProbMetric: 32.4350 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 44/1000
2023-09-28 07:34:22.360 
Epoch 44/1000 
	 loss: 31.2423, MinusLogProbMetric: 31.2423, val_loss: 31.2823, val_MinusLogProbMetric: 31.2823

Epoch 44: val_loss did not improve from 30.94684
196/196 - 32s - loss: 31.2423 - MinusLogProbMetric: 31.2423 - val_loss: 31.2823 - val_MinusLogProbMetric: 31.2823 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 45/1000
2023-09-28 07:34:54.856 
Epoch 45/1000 
	 loss: 31.4208, MinusLogProbMetric: 31.4208, val_loss: 30.9511, val_MinusLogProbMetric: 30.9511

Epoch 45: val_loss did not improve from 30.94684
196/196 - 32s - loss: 31.4208 - MinusLogProbMetric: 31.4208 - val_loss: 30.9511 - val_MinusLogProbMetric: 30.9511 - lr: 0.0010 - 32s/epoch - 166ms/step
Epoch 46/1000
2023-09-28 07:35:27.293 
Epoch 46/1000 
	 loss: 31.0395, MinusLogProbMetric: 31.0395, val_loss: 30.4620, val_MinusLogProbMetric: 30.4620

Epoch 46: val_loss improved from 30.94684 to 30.46205, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 31.0395 - MinusLogProbMetric: 31.0395 - val_loss: 30.4620 - val_MinusLogProbMetric: 30.4620 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 47/1000
2023-09-28 07:36:00.377 
Epoch 47/1000 
	 loss: 31.2457, MinusLogProbMetric: 31.2457, val_loss: 31.2323, val_MinusLogProbMetric: 31.2323

Epoch 47: val_loss did not improve from 30.46205
196/196 - 32s - loss: 31.2457 - MinusLogProbMetric: 31.2457 - val_loss: 31.2323 - val_MinusLogProbMetric: 31.2323 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 48/1000
2023-09-28 07:36:32.606 
Epoch 48/1000 
	 loss: 30.8561, MinusLogProbMetric: 30.8561, val_loss: 34.8468, val_MinusLogProbMetric: 34.8468

Epoch 48: val_loss did not improve from 30.46205
196/196 - 32s - loss: 30.8561 - MinusLogProbMetric: 30.8561 - val_loss: 34.8468 - val_MinusLogProbMetric: 34.8468 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 49/1000
2023-09-28 07:37:04.970 
Epoch 49/1000 
	 loss: 31.1584, MinusLogProbMetric: 31.1584, val_loss: 31.5943, val_MinusLogProbMetric: 31.5943

Epoch 49: val_loss did not improve from 30.46205
196/196 - 32s - loss: 31.1584 - MinusLogProbMetric: 31.1584 - val_loss: 31.5943 - val_MinusLogProbMetric: 31.5943 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 50/1000
2023-09-28 07:37:37.238 
Epoch 50/1000 
	 loss: 31.0061, MinusLogProbMetric: 31.0061, val_loss: 31.2379, val_MinusLogProbMetric: 31.2379

Epoch 50: val_loss did not improve from 30.46205
196/196 - 32s - loss: 31.0061 - MinusLogProbMetric: 31.0061 - val_loss: 31.2379 - val_MinusLogProbMetric: 31.2379 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 51/1000
2023-09-28 07:38:09.719 
Epoch 51/1000 
	 loss: 30.9565, MinusLogProbMetric: 30.9565, val_loss: 30.6156, val_MinusLogProbMetric: 30.6156

Epoch 51: val_loss did not improve from 30.46205
196/196 - 32s - loss: 30.9565 - MinusLogProbMetric: 30.9565 - val_loss: 30.6156 - val_MinusLogProbMetric: 30.6156 - lr: 0.0010 - 32s/epoch - 166ms/step
Epoch 52/1000
2023-09-28 07:38:42.244 
Epoch 52/1000 
	 loss: 30.9638, MinusLogProbMetric: 30.9638, val_loss: 32.0860, val_MinusLogProbMetric: 32.0860

Epoch 52: val_loss did not improve from 30.46205
196/196 - 33s - loss: 30.9638 - MinusLogProbMetric: 30.9638 - val_loss: 32.0860 - val_MinusLogProbMetric: 32.0860 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 53/1000
2023-09-28 07:39:14.607 
Epoch 53/1000 
	 loss: 30.7574, MinusLogProbMetric: 30.7574, val_loss: 30.5992, val_MinusLogProbMetric: 30.5992

Epoch 53: val_loss did not improve from 30.46205
196/196 - 32s - loss: 30.7574 - MinusLogProbMetric: 30.7574 - val_loss: 30.5992 - val_MinusLogProbMetric: 30.5992 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 54/1000
2023-09-28 07:39:47.072 
Epoch 54/1000 
	 loss: 30.9699, MinusLogProbMetric: 30.9699, val_loss: 30.2062, val_MinusLogProbMetric: 30.2062

Epoch 54: val_loss improved from 30.46205 to 30.20622, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 30.9699 - MinusLogProbMetric: 30.9699 - val_loss: 30.2062 - val_MinusLogProbMetric: 30.2062 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 55/1000
2023-09-28 07:40:20.089 
Epoch 55/1000 
	 loss: 30.8682, MinusLogProbMetric: 30.8682, val_loss: 30.8540, val_MinusLogProbMetric: 30.8540

Epoch 55: val_loss did not improve from 30.20622
196/196 - 33s - loss: 30.8682 - MinusLogProbMetric: 30.8682 - val_loss: 30.8540 - val_MinusLogProbMetric: 30.8540 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 56/1000
2023-09-28 07:40:52.606 
Epoch 56/1000 
	 loss: 30.9683, MinusLogProbMetric: 30.9683, val_loss: 31.3587, val_MinusLogProbMetric: 31.3587

Epoch 56: val_loss did not improve from 30.20622
196/196 - 33s - loss: 30.9683 - MinusLogProbMetric: 30.9683 - val_loss: 31.3587 - val_MinusLogProbMetric: 31.3587 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 57/1000
2023-09-28 07:41:25.040 
Epoch 57/1000 
	 loss: 30.4833, MinusLogProbMetric: 30.4833, val_loss: 30.8940, val_MinusLogProbMetric: 30.8940

Epoch 57: val_loss did not improve from 30.20622
196/196 - 32s - loss: 30.4833 - MinusLogProbMetric: 30.4833 - val_loss: 30.8940 - val_MinusLogProbMetric: 30.8940 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 58/1000
2023-09-28 07:41:57.163 
Epoch 58/1000 
	 loss: 30.5910, MinusLogProbMetric: 30.5910, val_loss: 30.5820, val_MinusLogProbMetric: 30.5820

Epoch 58: val_loss did not improve from 30.20622
196/196 - 32s - loss: 30.5910 - MinusLogProbMetric: 30.5910 - val_loss: 30.5820 - val_MinusLogProbMetric: 30.5820 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 59/1000
2023-09-28 07:42:29.581 
Epoch 59/1000 
	 loss: 30.8227, MinusLogProbMetric: 30.8227, val_loss: 31.3843, val_MinusLogProbMetric: 31.3843

Epoch 59: val_loss did not improve from 30.20622
196/196 - 32s - loss: 30.8227 - MinusLogProbMetric: 30.8227 - val_loss: 31.3843 - val_MinusLogProbMetric: 31.3843 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 60/1000
2023-09-28 07:43:02.026 
Epoch 60/1000 
	 loss: 30.6747, MinusLogProbMetric: 30.6747, val_loss: 32.5238, val_MinusLogProbMetric: 32.5238

Epoch 60: val_loss did not improve from 30.20622
196/196 - 32s - loss: 30.6747 - MinusLogProbMetric: 30.6747 - val_loss: 32.5238 - val_MinusLogProbMetric: 32.5238 - lr: 0.0010 - 32s/epoch - 166ms/step
Epoch 61/1000
2023-09-28 07:43:34.232 
Epoch 61/1000 
	 loss: 30.4246, MinusLogProbMetric: 30.4246, val_loss: 30.2271, val_MinusLogProbMetric: 30.2271

Epoch 61: val_loss did not improve from 30.20622
196/196 - 32s - loss: 30.4246 - MinusLogProbMetric: 30.4246 - val_loss: 30.2271 - val_MinusLogProbMetric: 30.2271 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 62/1000
2023-09-28 07:44:06.545 
Epoch 62/1000 
	 loss: 30.5276, MinusLogProbMetric: 30.5276, val_loss: 31.3546, val_MinusLogProbMetric: 31.3546

Epoch 62: val_loss did not improve from 30.20622
196/196 - 32s - loss: 30.5276 - MinusLogProbMetric: 30.5276 - val_loss: 31.3546 - val_MinusLogProbMetric: 31.3546 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 63/1000
2023-09-28 07:44:38.753 
Epoch 63/1000 
	 loss: 30.4500, MinusLogProbMetric: 30.4500, val_loss: 30.3536, val_MinusLogProbMetric: 30.3536

Epoch 63: val_loss did not improve from 30.20622
196/196 - 32s - loss: 30.4500 - MinusLogProbMetric: 30.4500 - val_loss: 30.3536 - val_MinusLogProbMetric: 30.3536 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 64/1000
2023-09-28 07:45:10.917 
Epoch 64/1000 
	 loss: 30.4014, MinusLogProbMetric: 30.4014, val_loss: 30.5592, val_MinusLogProbMetric: 30.5592

Epoch 64: val_loss did not improve from 30.20622
196/196 - 32s - loss: 30.4014 - MinusLogProbMetric: 30.4014 - val_loss: 30.5592 - val_MinusLogProbMetric: 30.5592 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 65/1000
2023-09-28 07:45:43.189 
Epoch 65/1000 
	 loss: 30.4180, MinusLogProbMetric: 30.4180, val_loss: 29.8528, val_MinusLogProbMetric: 29.8528

Epoch 65: val_loss improved from 30.20622 to 29.85277, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 30.4180 - MinusLogProbMetric: 30.4180 - val_loss: 29.8528 - val_MinusLogProbMetric: 29.8528 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 66/1000
2023-09-28 07:46:16.362 
Epoch 66/1000 
	 loss: 30.1591, MinusLogProbMetric: 30.1591, val_loss: 29.8486, val_MinusLogProbMetric: 29.8486

Epoch 66: val_loss improved from 29.85277 to 29.84860, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 30.1591 - MinusLogProbMetric: 30.1591 - val_loss: 29.8486 - val_MinusLogProbMetric: 29.8486 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 67/1000
2023-09-28 07:46:49.399 
Epoch 67/1000 
	 loss: 30.5033, MinusLogProbMetric: 30.5033, val_loss: 30.1377, val_MinusLogProbMetric: 30.1377

Epoch 67: val_loss did not improve from 29.84860
196/196 - 32s - loss: 30.5033 - MinusLogProbMetric: 30.5033 - val_loss: 30.1377 - val_MinusLogProbMetric: 30.1377 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 68/1000
2023-09-28 07:47:21.769 
Epoch 68/1000 
	 loss: 30.3828, MinusLogProbMetric: 30.3828, val_loss: 30.0090, val_MinusLogProbMetric: 30.0090

Epoch 68: val_loss did not improve from 29.84860
196/196 - 32s - loss: 30.3828 - MinusLogProbMetric: 30.3828 - val_loss: 30.0090 - val_MinusLogProbMetric: 30.0090 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 69/1000
2023-09-28 07:47:53.685 
Epoch 69/1000 
	 loss: 30.1937, MinusLogProbMetric: 30.1937, val_loss: 30.5919, val_MinusLogProbMetric: 30.5919

Epoch 69: val_loss did not improve from 29.84860
196/196 - 32s - loss: 30.1937 - MinusLogProbMetric: 30.1937 - val_loss: 30.5919 - val_MinusLogProbMetric: 30.5919 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 70/1000
2023-09-28 07:48:25.992 
Epoch 70/1000 
	 loss: 30.0966, MinusLogProbMetric: 30.0966, val_loss: 30.3123, val_MinusLogProbMetric: 30.3123

Epoch 70: val_loss did not improve from 29.84860
196/196 - 32s - loss: 30.0966 - MinusLogProbMetric: 30.0966 - val_loss: 30.3123 - val_MinusLogProbMetric: 30.3123 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 71/1000
2023-09-28 07:48:58.123 
Epoch 71/1000 
	 loss: 30.3266, MinusLogProbMetric: 30.3266, val_loss: 30.9587, val_MinusLogProbMetric: 30.9587

Epoch 71: val_loss did not improve from 29.84860
196/196 - 32s - loss: 30.3266 - MinusLogProbMetric: 30.3266 - val_loss: 30.9587 - val_MinusLogProbMetric: 30.9587 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 72/1000
2023-09-28 07:49:30.298 
Epoch 72/1000 
	 loss: 30.2560, MinusLogProbMetric: 30.2560, val_loss: 30.5807, val_MinusLogProbMetric: 30.5807

Epoch 72: val_loss did not improve from 29.84860
196/196 - 32s - loss: 30.2560 - MinusLogProbMetric: 30.2560 - val_loss: 30.5807 - val_MinusLogProbMetric: 30.5807 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 73/1000
2023-09-28 07:50:02.608 
Epoch 73/1000 
	 loss: 30.2139, MinusLogProbMetric: 30.2139, val_loss: 30.3051, val_MinusLogProbMetric: 30.3051

Epoch 73: val_loss did not improve from 29.84860
196/196 - 32s - loss: 30.2139 - MinusLogProbMetric: 30.2139 - val_loss: 30.3051 - val_MinusLogProbMetric: 30.3051 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 74/1000
2023-09-28 07:50:34.927 
Epoch 74/1000 
	 loss: 30.0546, MinusLogProbMetric: 30.0546, val_loss: 30.0135, val_MinusLogProbMetric: 30.0135

Epoch 74: val_loss did not improve from 29.84860
196/196 - 32s - loss: 30.0546 - MinusLogProbMetric: 30.0546 - val_loss: 30.0135 - val_MinusLogProbMetric: 30.0135 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 75/1000
2023-09-28 07:51:07.127 
Epoch 75/1000 
	 loss: 29.9729, MinusLogProbMetric: 29.9729, val_loss: 30.4548, val_MinusLogProbMetric: 30.4548

Epoch 75: val_loss did not improve from 29.84860
196/196 - 32s - loss: 29.9729 - MinusLogProbMetric: 29.9729 - val_loss: 30.4548 - val_MinusLogProbMetric: 30.4548 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 76/1000
2023-09-28 07:51:39.174 
Epoch 76/1000 
	 loss: 30.1592, MinusLogProbMetric: 30.1592, val_loss: 31.0113, val_MinusLogProbMetric: 31.0113

Epoch 76: val_loss did not improve from 29.84860
196/196 - 32s - loss: 30.1592 - MinusLogProbMetric: 30.1592 - val_loss: 31.0113 - val_MinusLogProbMetric: 31.0113 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 77/1000
2023-09-28 07:52:11.480 
Epoch 77/1000 
	 loss: 30.3322, MinusLogProbMetric: 30.3322, val_loss: 29.9660, val_MinusLogProbMetric: 29.9660

Epoch 77: val_loss did not improve from 29.84860
196/196 - 32s - loss: 30.3322 - MinusLogProbMetric: 30.3322 - val_loss: 29.9660 - val_MinusLogProbMetric: 29.9660 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 78/1000
2023-09-28 07:52:43.794 
Epoch 78/1000 
	 loss: 30.0271, MinusLogProbMetric: 30.0271, val_loss: 30.7482, val_MinusLogProbMetric: 30.7482

Epoch 78: val_loss did not improve from 29.84860
196/196 - 32s - loss: 30.0271 - MinusLogProbMetric: 30.0271 - val_loss: 30.7482 - val_MinusLogProbMetric: 30.7482 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 79/1000
2023-09-28 07:53:16.040 
Epoch 79/1000 
	 loss: 29.8108, MinusLogProbMetric: 29.8108, val_loss: 29.9901, val_MinusLogProbMetric: 29.9901

Epoch 79: val_loss did not improve from 29.84860
196/196 - 32s - loss: 29.8108 - MinusLogProbMetric: 29.8108 - val_loss: 29.9901 - val_MinusLogProbMetric: 29.9901 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 80/1000
2023-09-28 07:53:48.243 
Epoch 80/1000 
	 loss: 30.3336, MinusLogProbMetric: 30.3336, val_loss: 30.7040, val_MinusLogProbMetric: 30.7040

Epoch 80: val_loss did not improve from 29.84860
196/196 - 32s - loss: 30.3336 - MinusLogProbMetric: 30.3336 - val_loss: 30.7040 - val_MinusLogProbMetric: 30.7040 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 81/1000
2023-09-28 07:54:20.635 
Epoch 81/1000 
	 loss: 29.8510, MinusLogProbMetric: 29.8510, val_loss: 30.9501, val_MinusLogProbMetric: 30.9501

Epoch 81: val_loss did not improve from 29.84860
196/196 - 32s - loss: 29.8510 - MinusLogProbMetric: 29.8510 - val_loss: 30.9501 - val_MinusLogProbMetric: 30.9501 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 82/1000
2023-09-28 07:54:52.874 
Epoch 82/1000 
	 loss: 29.8680, MinusLogProbMetric: 29.8680, val_loss: 30.1973, val_MinusLogProbMetric: 30.1973

Epoch 82: val_loss did not improve from 29.84860
196/196 - 32s - loss: 29.8680 - MinusLogProbMetric: 29.8680 - val_loss: 30.1973 - val_MinusLogProbMetric: 30.1973 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 83/1000
2023-09-28 07:55:25.257 
Epoch 83/1000 
	 loss: 30.0208, MinusLogProbMetric: 30.0208, val_loss: 30.6690, val_MinusLogProbMetric: 30.6690

Epoch 83: val_loss did not improve from 29.84860
196/196 - 32s - loss: 30.0208 - MinusLogProbMetric: 30.0208 - val_loss: 30.6690 - val_MinusLogProbMetric: 30.6690 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 84/1000
2023-09-28 07:55:57.589 
Epoch 84/1000 
	 loss: 29.7701, MinusLogProbMetric: 29.7701, val_loss: 30.0412, val_MinusLogProbMetric: 30.0412

Epoch 84: val_loss did not improve from 29.84860
196/196 - 32s - loss: 29.7701 - MinusLogProbMetric: 29.7701 - val_loss: 30.0412 - val_MinusLogProbMetric: 30.0412 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 85/1000
2023-09-28 07:56:29.773 
Epoch 85/1000 
	 loss: 29.9712, MinusLogProbMetric: 29.9712, val_loss: 30.2407, val_MinusLogProbMetric: 30.2407

Epoch 85: val_loss did not improve from 29.84860
196/196 - 32s - loss: 29.9712 - MinusLogProbMetric: 29.9712 - val_loss: 30.2407 - val_MinusLogProbMetric: 30.2407 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 86/1000
2023-09-28 07:57:02.065 
Epoch 86/1000 
	 loss: 29.7733, MinusLogProbMetric: 29.7733, val_loss: 30.1591, val_MinusLogProbMetric: 30.1591

Epoch 86: val_loss did not improve from 29.84860
196/196 - 32s - loss: 29.7733 - MinusLogProbMetric: 29.7733 - val_loss: 30.1591 - val_MinusLogProbMetric: 30.1591 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 87/1000
2023-09-28 07:57:34.422 
Epoch 87/1000 
	 loss: 29.8028, MinusLogProbMetric: 29.8028, val_loss: 30.6013, val_MinusLogProbMetric: 30.6013

Epoch 87: val_loss did not improve from 29.84860
196/196 - 32s - loss: 29.8028 - MinusLogProbMetric: 29.8028 - val_loss: 30.6013 - val_MinusLogProbMetric: 30.6013 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 88/1000
2023-09-28 07:58:06.799 
Epoch 88/1000 
	 loss: 29.8667, MinusLogProbMetric: 29.8667, val_loss: 29.5033, val_MinusLogProbMetric: 29.5033

Epoch 88: val_loss improved from 29.84860 to 29.50329, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 29.8667 - MinusLogProbMetric: 29.8667 - val_loss: 29.5033 - val_MinusLogProbMetric: 29.5033 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 89/1000
2023-09-28 07:58:39.727 
Epoch 89/1000 
	 loss: 29.7661, MinusLogProbMetric: 29.7661, val_loss: 29.9431, val_MinusLogProbMetric: 29.9431

Epoch 89: val_loss did not improve from 29.50329
196/196 - 32s - loss: 29.7661 - MinusLogProbMetric: 29.7661 - val_loss: 29.9431 - val_MinusLogProbMetric: 29.9431 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 90/1000
2023-09-28 07:59:12.205 
Epoch 90/1000 
	 loss: 29.7495, MinusLogProbMetric: 29.7495, val_loss: 30.4314, val_MinusLogProbMetric: 30.4314

Epoch 90: val_loss did not improve from 29.50329
196/196 - 32s - loss: 29.7495 - MinusLogProbMetric: 29.7495 - val_loss: 30.4314 - val_MinusLogProbMetric: 30.4314 - lr: 0.0010 - 32s/epoch - 166ms/step
Epoch 91/1000
2023-09-28 07:59:44.491 
Epoch 91/1000 
	 loss: 29.6507, MinusLogProbMetric: 29.6507, val_loss: 29.7204, val_MinusLogProbMetric: 29.7204

Epoch 91: val_loss did not improve from 29.50329
196/196 - 32s - loss: 29.6507 - MinusLogProbMetric: 29.6507 - val_loss: 29.7204 - val_MinusLogProbMetric: 29.7204 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 92/1000
2023-09-28 08:00:16.934 
Epoch 92/1000 
	 loss: 29.9319, MinusLogProbMetric: 29.9319, val_loss: 29.5808, val_MinusLogProbMetric: 29.5808

Epoch 92: val_loss did not improve from 29.50329
196/196 - 32s - loss: 29.9319 - MinusLogProbMetric: 29.9319 - val_loss: 29.5808 - val_MinusLogProbMetric: 29.5808 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 93/1000
2023-09-28 08:00:49.201 
Epoch 93/1000 
	 loss: 29.7391, MinusLogProbMetric: 29.7391, val_loss: 30.1108, val_MinusLogProbMetric: 30.1108

Epoch 93: val_loss did not improve from 29.50329
196/196 - 32s - loss: 29.7391 - MinusLogProbMetric: 29.7391 - val_loss: 30.1108 - val_MinusLogProbMetric: 30.1108 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 94/1000
2023-09-28 08:01:21.864 
Epoch 94/1000 
	 loss: 29.7127, MinusLogProbMetric: 29.7127, val_loss: 30.3312, val_MinusLogProbMetric: 30.3312

Epoch 94: val_loss did not improve from 29.50329
196/196 - 33s - loss: 29.7127 - MinusLogProbMetric: 29.7127 - val_loss: 30.3312 - val_MinusLogProbMetric: 30.3312 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 95/1000
2023-09-28 08:01:54.041 
Epoch 95/1000 
	 loss: 29.6699, MinusLogProbMetric: 29.6699, val_loss: 29.6456, val_MinusLogProbMetric: 29.6456

Epoch 95: val_loss did not improve from 29.50329
196/196 - 32s - loss: 29.6699 - MinusLogProbMetric: 29.6699 - val_loss: 29.6456 - val_MinusLogProbMetric: 29.6456 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 96/1000
2023-09-28 08:02:26.328 
Epoch 96/1000 
	 loss: 29.6983, MinusLogProbMetric: 29.6983, val_loss: 29.8832, val_MinusLogProbMetric: 29.8832

Epoch 96: val_loss did not improve from 29.50329
196/196 - 32s - loss: 29.6983 - MinusLogProbMetric: 29.6983 - val_loss: 29.8832 - val_MinusLogProbMetric: 29.8832 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 97/1000
2023-09-28 08:02:58.642 
Epoch 97/1000 
	 loss: 29.5821, MinusLogProbMetric: 29.5821, val_loss: 30.2391, val_MinusLogProbMetric: 30.2391

Epoch 97: val_loss did not improve from 29.50329
196/196 - 32s - loss: 29.5821 - MinusLogProbMetric: 29.5821 - val_loss: 30.2391 - val_MinusLogProbMetric: 30.2391 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 98/1000
2023-09-28 08:03:30.891 
Epoch 98/1000 
	 loss: 29.5719, MinusLogProbMetric: 29.5719, val_loss: 29.9148, val_MinusLogProbMetric: 29.9148

Epoch 98: val_loss did not improve from 29.50329
196/196 - 32s - loss: 29.5719 - MinusLogProbMetric: 29.5719 - val_loss: 29.9148 - val_MinusLogProbMetric: 29.9148 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 99/1000
2023-09-28 08:04:02.992 
Epoch 99/1000 
	 loss: 29.7176, MinusLogProbMetric: 29.7176, val_loss: 30.0941, val_MinusLogProbMetric: 30.0941

Epoch 99: val_loss did not improve from 29.50329
196/196 - 32s - loss: 29.7176 - MinusLogProbMetric: 29.7176 - val_loss: 30.0941 - val_MinusLogProbMetric: 30.0941 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 100/1000
2023-09-28 08:04:35.287 
Epoch 100/1000 
	 loss: 29.4941, MinusLogProbMetric: 29.4941, val_loss: 30.3184, val_MinusLogProbMetric: 30.3184

Epoch 100: val_loss did not improve from 29.50329
196/196 - 32s - loss: 29.4941 - MinusLogProbMetric: 29.4941 - val_loss: 30.3184 - val_MinusLogProbMetric: 30.3184 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 101/1000
2023-09-28 08:05:07.567 
Epoch 101/1000 
	 loss: 29.6152, MinusLogProbMetric: 29.6152, val_loss: 29.8531, val_MinusLogProbMetric: 29.8531

Epoch 101: val_loss did not improve from 29.50329
196/196 - 32s - loss: 29.6152 - MinusLogProbMetric: 29.6152 - val_loss: 29.8531 - val_MinusLogProbMetric: 29.8531 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 102/1000
2023-09-28 08:05:39.987 
Epoch 102/1000 
	 loss: 29.6577, MinusLogProbMetric: 29.6577, val_loss: 29.9942, val_MinusLogProbMetric: 29.9942

Epoch 102: val_loss did not improve from 29.50329
196/196 - 32s - loss: 29.6577 - MinusLogProbMetric: 29.6577 - val_loss: 29.9942 - val_MinusLogProbMetric: 29.9942 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 103/1000
2023-09-28 08:06:12.234 
Epoch 103/1000 
	 loss: 29.6849, MinusLogProbMetric: 29.6849, val_loss: 29.4368, val_MinusLogProbMetric: 29.4368

Epoch 103: val_loss improved from 29.50329 to 29.43675, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 29.6849 - MinusLogProbMetric: 29.6849 - val_loss: 29.4368 - val_MinusLogProbMetric: 29.4368 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 104/1000
2023-09-28 08:06:45.112 
Epoch 104/1000 
	 loss: 29.6671, MinusLogProbMetric: 29.6671, val_loss: 29.8700, val_MinusLogProbMetric: 29.8700

Epoch 104: val_loss did not improve from 29.43675
196/196 - 32s - loss: 29.6671 - MinusLogProbMetric: 29.6671 - val_loss: 29.8700 - val_MinusLogProbMetric: 29.8700 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 105/1000
2023-09-28 08:07:17.412 
Epoch 105/1000 
	 loss: 29.4596, MinusLogProbMetric: 29.4596, val_loss: 29.7299, val_MinusLogProbMetric: 29.7299

Epoch 105: val_loss did not improve from 29.43675
196/196 - 32s - loss: 29.4596 - MinusLogProbMetric: 29.4596 - val_loss: 29.7299 - val_MinusLogProbMetric: 29.7299 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 106/1000
2023-09-28 08:07:49.543 
Epoch 106/1000 
	 loss: 29.5884, MinusLogProbMetric: 29.5884, val_loss: 29.6921, val_MinusLogProbMetric: 29.6921

Epoch 106: val_loss did not improve from 29.43675
196/196 - 32s - loss: 29.5884 - MinusLogProbMetric: 29.5884 - val_loss: 29.6921 - val_MinusLogProbMetric: 29.6921 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 107/1000
2023-09-28 08:08:22.079 
Epoch 107/1000 
	 loss: 29.4094, MinusLogProbMetric: 29.4094, val_loss: 29.7515, val_MinusLogProbMetric: 29.7515

Epoch 107: val_loss did not improve from 29.43675
196/196 - 33s - loss: 29.4094 - MinusLogProbMetric: 29.4094 - val_loss: 29.7515 - val_MinusLogProbMetric: 29.7515 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 108/1000
2023-09-28 08:08:54.506 
Epoch 108/1000 
	 loss: 29.4724, MinusLogProbMetric: 29.4724, val_loss: 29.8723, val_MinusLogProbMetric: 29.8723

Epoch 108: val_loss did not improve from 29.43675
196/196 - 32s - loss: 29.4724 - MinusLogProbMetric: 29.4724 - val_loss: 29.8723 - val_MinusLogProbMetric: 29.8723 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 109/1000
2023-09-28 08:09:27.062 
Epoch 109/1000 
	 loss: 29.3337, MinusLogProbMetric: 29.3337, val_loss: 30.5651, val_MinusLogProbMetric: 30.5651

Epoch 109: val_loss did not improve from 29.43675
196/196 - 33s - loss: 29.3337 - MinusLogProbMetric: 29.3337 - val_loss: 30.5651 - val_MinusLogProbMetric: 30.5651 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 110/1000
2023-09-28 08:09:59.541 
Epoch 110/1000 
	 loss: 29.4308, MinusLogProbMetric: 29.4308, val_loss: 29.4252, val_MinusLogProbMetric: 29.4252

Epoch 110: val_loss improved from 29.43675 to 29.42523, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 29.4308 - MinusLogProbMetric: 29.4308 - val_loss: 29.4252 - val_MinusLogProbMetric: 29.4252 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 111/1000
2023-09-28 08:10:32.155 
Epoch 111/1000 
	 loss: 29.4143, MinusLogProbMetric: 29.4143, val_loss: 29.4398, val_MinusLogProbMetric: 29.4398

Epoch 111: val_loss did not improve from 29.42523
196/196 - 32s - loss: 29.4143 - MinusLogProbMetric: 29.4143 - val_loss: 29.4398 - val_MinusLogProbMetric: 29.4398 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 112/1000
2023-09-28 08:11:04.375 
Epoch 112/1000 
	 loss: 29.5332, MinusLogProbMetric: 29.5332, val_loss: 29.7906, val_MinusLogProbMetric: 29.7906

Epoch 112: val_loss did not improve from 29.42523
196/196 - 32s - loss: 29.5332 - MinusLogProbMetric: 29.5332 - val_loss: 29.7906 - val_MinusLogProbMetric: 29.7906 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 113/1000
2023-09-28 08:11:36.807 
Epoch 113/1000 
	 loss: 29.4238, MinusLogProbMetric: 29.4238, val_loss: 30.1273, val_MinusLogProbMetric: 30.1273

Epoch 113: val_loss did not improve from 29.42523
196/196 - 32s - loss: 29.4238 - MinusLogProbMetric: 29.4238 - val_loss: 30.1273 - val_MinusLogProbMetric: 30.1273 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 114/1000
2023-09-28 08:12:09.017 
Epoch 114/1000 
	 loss: 29.2706, MinusLogProbMetric: 29.2706, val_loss: 29.3289, val_MinusLogProbMetric: 29.3289

Epoch 114: val_loss improved from 29.42523 to 29.32888, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 29.2706 - MinusLogProbMetric: 29.2706 - val_loss: 29.3289 - val_MinusLogProbMetric: 29.3289 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 115/1000
2023-09-28 08:12:41.901 
Epoch 115/1000 
	 loss: 29.4077, MinusLogProbMetric: 29.4077, val_loss: 31.4041, val_MinusLogProbMetric: 31.4041

Epoch 115: val_loss did not improve from 29.32888
196/196 - 32s - loss: 29.4077 - MinusLogProbMetric: 29.4077 - val_loss: 31.4041 - val_MinusLogProbMetric: 31.4041 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 116/1000
2023-09-28 08:13:14.201 
Epoch 116/1000 
	 loss: 29.3431, MinusLogProbMetric: 29.3431, val_loss: 30.0780, val_MinusLogProbMetric: 30.0780

Epoch 116: val_loss did not improve from 29.32888
196/196 - 32s - loss: 29.3431 - MinusLogProbMetric: 29.3431 - val_loss: 30.0780 - val_MinusLogProbMetric: 30.0780 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 117/1000
2023-09-28 08:13:46.317 
Epoch 117/1000 
	 loss: 29.3536, MinusLogProbMetric: 29.3536, val_loss: 29.7245, val_MinusLogProbMetric: 29.7245

Epoch 117: val_loss did not improve from 29.32888
196/196 - 32s - loss: 29.3536 - MinusLogProbMetric: 29.3536 - val_loss: 29.7245 - val_MinusLogProbMetric: 29.7245 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 118/1000
2023-09-28 08:14:18.603 
Epoch 118/1000 
	 loss: 29.3739, MinusLogProbMetric: 29.3739, val_loss: 29.9288, val_MinusLogProbMetric: 29.9288

Epoch 118: val_loss did not improve from 29.32888
196/196 - 32s - loss: 29.3739 - MinusLogProbMetric: 29.3739 - val_loss: 29.9288 - val_MinusLogProbMetric: 29.9288 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 119/1000
2023-09-28 08:14:50.888 
Epoch 119/1000 
	 loss: 29.3597, MinusLogProbMetric: 29.3597, val_loss: 29.4270, val_MinusLogProbMetric: 29.4270

Epoch 119: val_loss did not improve from 29.32888
196/196 - 32s - loss: 29.3597 - MinusLogProbMetric: 29.3597 - val_loss: 29.4270 - val_MinusLogProbMetric: 29.4270 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 120/1000
2023-09-28 08:15:23.304 
Epoch 120/1000 
	 loss: 29.1405, MinusLogProbMetric: 29.1405, val_loss: 29.1807, val_MinusLogProbMetric: 29.1807

Epoch 120: val_loss improved from 29.32888 to 29.18066, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 29.1405 - MinusLogProbMetric: 29.1405 - val_loss: 29.1807 - val_MinusLogProbMetric: 29.1807 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 121/1000
2023-09-28 08:15:56.172 
Epoch 121/1000 
	 loss: 29.2181, MinusLogProbMetric: 29.2181, val_loss: 30.7451, val_MinusLogProbMetric: 30.7451

Epoch 121: val_loss did not improve from 29.18066
196/196 - 32s - loss: 29.2181 - MinusLogProbMetric: 29.2181 - val_loss: 30.7451 - val_MinusLogProbMetric: 30.7451 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 122/1000
2023-09-28 08:16:28.408 
Epoch 122/1000 
	 loss: 29.2845, MinusLogProbMetric: 29.2845, val_loss: 29.3665, val_MinusLogProbMetric: 29.3665

Epoch 122: val_loss did not improve from 29.18066
196/196 - 32s - loss: 29.2845 - MinusLogProbMetric: 29.2845 - val_loss: 29.3665 - val_MinusLogProbMetric: 29.3665 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 123/1000
2023-09-28 08:17:00.608 
Epoch 123/1000 
	 loss: 29.2652, MinusLogProbMetric: 29.2652, val_loss: 29.8612, val_MinusLogProbMetric: 29.8612

Epoch 123: val_loss did not improve from 29.18066
196/196 - 32s - loss: 29.2652 - MinusLogProbMetric: 29.2652 - val_loss: 29.8612 - val_MinusLogProbMetric: 29.8612 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 124/1000
2023-09-28 08:17:32.929 
Epoch 124/1000 
	 loss: 29.3238, MinusLogProbMetric: 29.3238, val_loss: 29.9726, val_MinusLogProbMetric: 29.9726

Epoch 124: val_loss did not improve from 29.18066
196/196 - 32s - loss: 29.3238 - MinusLogProbMetric: 29.3238 - val_loss: 29.9726 - val_MinusLogProbMetric: 29.9726 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 125/1000
2023-09-28 08:18:04.974 
Epoch 125/1000 
	 loss: 29.2784, MinusLogProbMetric: 29.2784, val_loss: 29.6723, val_MinusLogProbMetric: 29.6723

Epoch 125: val_loss did not improve from 29.18066
196/196 - 32s - loss: 29.2784 - MinusLogProbMetric: 29.2784 - val_loss: 29.6723 - val_MinusLogProbMetric: 29.6723 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 126/1000
2023-09-28 08:18:37.122 
Epoch 126/1000 
	 loss: 29.2192, MinusLogProbMetric: 29.2192, val_loss: 29.5087, val_MinusLogProbMetric: 29.5087

Epoch 126: val_loss did not improve from 29.18066
196/196 - 32s - loss: 29.2192 - MinusLogProbMetric: 29.2192 - val_loss: 29.5087 - val_MinusLogProbMetric: 29.5087 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 127/1000
2023-09-28 08:19:09.564 
Epoch 127/1000 
	 loss: 29.3262, MinusLogProbMetric: 29.3262, val_loss: 30.8451, val_MinusLogProbMetric: 30.8451

Epoch 127: val_loss did not improve from 29.18066
196/196 - 32s - loss: 29.3262 - MinusLogProbMetric: 29.3262 - val_loss: 30.8451 - val_MinusLogProbMetric: 30.8451 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 128/1000
2023-09-28 08:19:41.703 
Epoch 128/1000 
	 loss: 29.2908, MinusLogProbMetric: 29.2908, val_loss: 29.1950, val_MinusLogProbMetric: 29.1950

Epoch 128: val_loss did not improve from 29.18066
196/196 - 32s - loss: 29.2908 - MinusLogProbMetric: 29.2908 - val_loss: 29.1950 - val_MinusLogProbMetric: 29.1950 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 129/1000
2023-09-28 08:20:13.974 
Epoch 129/1000 
	 loss: 29.1978, MinusLogProbMetric: 29.1978, val_loss: 29.5725, val_MinusLogProbMetric: 29.5725

Epoch 129: val_loss did not improve from 29.18066
196/196 - 32s - loss: 29.1978 - MinusLogProbMetric: 29.1978 - val_loss: 29.5725 - val_MinusLogProbMetric: 29.5725 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 130/1000
2023-09-28 08:20:46.189 
Epoch 130/1000 
	 loss: 29.1178, MinusLogProbMetric: 29.1178, val_loss: 29.6113, val_MinusLogProbMetric: 29.6113

Epoch 130: val_loss did not improve from 29.18066
196/196 - 32s - loss: 29.1178 - MinusLogProbMetric: 29.1178 - val_loss: 29.6113 - val_MinusLogProbMetric: 29.6113 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 131/1000
2023-09-28 08:21:18.667 
Epoch 131/1000 
	 loss: 29.2243, MinusLogProbMetric: 29.2243, val_loss: 29.3978, val_MinusLogProbMetric: 29.3978

Epoch 131: val_loss did not improve from 29.18066
196/196 - 32s - loss: 29.2243 - MinusLogProbMetric: 29.2243 - val_loss: 29.3978 - val_MinusLogProbMetric: 29.3978 - lr: 0.0010 - 32s/epoch - 166ms/step
Epoch 132/1000
2023-09-28 08:21:50.952 
Epoch 132/1000 
	 loss: 29.1200, MinusLogProbMetric: 29.1200, val_loss: 29.2838, val_MinusLogProbMetric: 29.2838

Epoch 132: val_loss did not improve from 29.18066
196/196 - 32s - loss: 29.1200 - MinusLogProbMetric: 29.1200 - val_loss: 29.2838 - val_MinusLogProbMetric: 29.2838 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 133/1000
2023-09-28 08:22:23.335 
Epoch 133/1000 
	 loss: 29.0448, MinusLogProbMetric: 29.0448, val_loss: 29.3474, val_MinusLogProbMetric: 29.3474

Epoch 133: val_loss did not improve from 29.18066
196/196 - 32s - loss: 29.0448 - MinusLogProbMetric: 29.0448 - val_loss: 29.3474 - val_MinusLogProbMetric: 29.3474 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 134/1000
2023-09-28 08:22:55.557 
Epoch 134/1000 
	 loss: 29.1064, MinusLogProbMetric: 29.1064, val_loss: 29.3122, val_MinusLogProbMetric: 29.3122

Epoch 134: val_loss did not improve from 29.18066
196/196 - 32s - loss: 29.1064 - MinusLogProbMetric: 29.1064 - val_loss: 29.3122 - val_MinusLogProbMetric: 29.3122 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 135/1000
2023-09-28 08:23:28.227 
Epoch 135/1000 
	 loss: 29.3529, MinusLogProbMetric: 29.3529, val_loss: 29.5560, val_MinusLogProbMetric: 29.5560

Epoch 135: val_loss did not improve from 29.18066
196/196 - 33s - loss: 29.3529 - MinusLogProbMetric: 29.3529 - val_loss: 29.5560 - val_MinusLogProbMetric: 29.5560 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 136/1000
2023-09-28 08:24:00.956 
Epoch 136/1000 
	 loss: 29.2270, MinusLogProbMetric: 29.2270, val_loss: 29.4954, val_MinusLogProbMetric: 29.4954

Epoch 136: val_loss did not improve from 29.18066
196/196 - 33s - loss: 29.2270 - MinusLogProbMetric: 29.2270 - val_loss: 29.4954 - val_MinusLogProbMetric: 29.4954 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 137/1000
2023-09-28 08:24:33.146 
Epoch 137/1000 
	 loss: 29.0098, MinusLogProbMetric: 29.0098, val_loss: 29.3551, val_MinusLogProbMetric: 29.3551

Epoch 137: val_loss did not improve from 29.18066
196/196 - 32s - loss: 29.0098 - MinusLogProbMetric: 29.0098 - val_loss: 29.3551 - val_MinusLogProbMetric: 29.3551 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 138/1000
2023-09-28 08:25:05.167 
Epoch 138/1000 
	 loss: 29.1139, MinusLogProbMetric: 29.1139, val_loss: 29.6466, val_MinusLogProbMetric: 29.6466

Epoch 138: val_loss did not improve from 29.18066
196/196 - 32s - loss: 29.1139 - MinusLogProbMetric: 29.1139 - val_loss: 29.6466 - val_MinusLogProbMetric: 29.6466 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 139/1000
2023-09-28 08:25:37.586 
Epoch 139/1000 
	 loss: 29.1605, MinusLogProbMetric: 29.1605, val_loss: 29.1167, val_MinusLogProbMetric: 29.1167

Epoch 139: val_loss improved from 29.18066 to 29.11670, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 29.1605 - MinusLogProbMetric: 29.1605 - val_loss: 29.1167 - val_MinusLogProbMetric: 29.1167 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 140/1000
2023-09-28 08:26:10.038 
Epoch 140/1000 
	 loss: 29.1242, MinusLogProbMetric: 29.1242, val_loss: 29.3765, val_MinusLogProbMetric: 29.3765

Epoch 140: val_loss did not improve from 29.11670
196/196 - 32s - loss: 29.1242 - MinusLogProbMetric: 29.1242 - val_loss: 29.3765 - val_MinusLogProbMetric: 29.3765 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 141/1000
2023-09-28 08:26:42.235 
Epoch 141/1000 
	 loss: 29.1563, MinusLogProbMetric: 29.1563, val_loss: 29.1598, val_MinusLogProbMetric: 29.1598

Epoch 141: val_loss did not improve from 29.11670
196/196 - 32s - loss: 29.1563 - MinusLogProbMetric: 29.1563 - val_loss: 29.1598 - val_MinusLogProbMetric: 29.1598 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 142/1000
2023-09-28 08:27:14.550 
Epoch 142/1000 
	 loss: 28.9270, MinusLogProbMetric: 28.9270, val_loss: 29.4338, val_MinusLogProbMetric: 29.4338

Epoch 142: val_loss did not improve from 29.11670
196/196 - 32s - loss: 28.9270 - MinusLogProbMetric: 28.9270 - val_loss: 29.4338 - val_MinusLogProbMetric: 29.4338 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 143/1000
2023-09-28 08:27:46.953 
Epoch 143/1000 
	 loss: 29.0317, MinusLogProbMetric: 29.0317, val_loss: 29.9745, val_MinusLogProbMetric: 29.9745

Epoch 143: val_loss did not improve from 29.11670
196/196 - 32s - loss: 29.0317 - MinusLogProbMetric: 29.0317 - val_loss: 29.9745 - val_MinusLogProbMetric: 29.9745 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 144/1000
2023-09-28 08:28:19.195 
Epoch 144/1000 
	 loss: 29.0456, MinusLogProbMetric: 29.0456, val_loss: 29.1151, val_MinusLogProbMetric: 29.1151

Epoch 144: val_loss improved from 29.11670 to 29.11512, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 29.0456 - MinusLogProbMetric: 29.0456 - val_loss: 29.1151 - val_MinusLogProbMetric: 29.1151 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 145/1000
2023-09-28 08:28:51.666 
Epoch 145/1000 
	 loss: 29.1578, MinusLogProbMetric: 29.1578, val_loss: 29.2013, val_MinusLogProbMetric: 29.2013

Epoch 145: val_loss did not improve from 29.11512
196/196 - 32s - loss: 29.1578 - MinusLogProbMetric: 29.1578 - val_loss: 29.2013 - val_MinusLogProbMetric: 29.2013 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 146/1000
2023-09-28 08:29:23.962 
Epoch 146/1000 
	 loss: 29.1873, MinusLogProbMetric: 29.1873, val_loss: 31.7240, val_MinusLogProbMetric: 31.7240

Epoch 146: val_loss did not improve from 29.11512
196/196 - 32s - loss: 29.1873 - MinusLogProbMetric: 29.1873 - val_loss: 31.7240 - val_MinusLogProbMetric: 31.7240 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 147/1000
2023-09-28 08:29:56.139 
Epoch 147/1000 
	 loss: 29.1172, MinusLogProbMetric: 29.1172, val_loss: 30.0209, val_MinusLogProbMetric: 30.0209

Epoch 147: val_loss did not improve from 29.11512
196/196 - 32s - loss: 29.1172 - MinusLogProbMetric: 29.1172 - val_loss: 30.0209 - val_MinusLogProbMetric: 30.0209 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 148/1000
2023-09-28 08:30:28.154 
Epoch 148/1000 
	 loss: 28.9727, MinusLogProbMetric: 28.9727, val_loss: 29.2846, val_MinusLogProbMetric: 29.2846

Epoch 148: val_loss did not improve from 29.11512
196/196 - 32s - loss: 28.9727 - MinusLogProbMetric: 28.9727 - val_loss: 29.2846 - val_MinusLogProbMetric: 29.2846 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 149/1000
2023-09-28 08:31:00.485 
Epoch 149/1000 
	 loss: 28.9329, MinusLogProbMetric: 28.9329, val_loss: 29.2002, val_MinusLogProbMetric: 29.2002

Epoch 149: val_loss did not improve from 29.11512
196/196 - 32s - loss: 28.9329 - MinusLogProbMetric: 28.9329 - val_loss: 29.2002 - val_MinusLogProbMetric: 29.2002 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 150/1000
2023-09-28 08:31:32.586 
Epoch 150/1000 
	 loss: 29.2205, MinusLogProbMetric: 29.2205, val_loss: 28.9046, val_MinusLogProbMetric: 28.9046

Epoch 150: val_loss improved from 29.11512 to 28.90456, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_322/weights/best_weights.h5
196/196 - 33s - loss: 29.2205 - MinusLogProbMetric: 29.2205 - val_loss: 28.9046 - val_MinusLogProbMetric: 28.9046 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 151/1000
2023-09-28 08:32:05.451 
Epoch 151/1000 
	 loss: 28.9479, MinusLogProbMetric: 28.9479, val_loss: 29.3554, val_MinusLogProbMetric: 29.3554

Epoch 151: val_loss did not improve from 28.90456
196/196 - 32s - loss: 28.9479 - MinusLogProbMetric: 28.9479 - val_loss: 29.3554 - val_MinusLogProbMetric: 29.3554 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 152/1000
2023-09-28 08:32:37.666 
Epoch 152/1000 
	 loss: 28.9862, MinusLogProbMetric: 28.9862, val_loss: 29.3114, val_MinusLogProbMetric: 29.3114

Epoch 152: val_loss did not improve from 28.90456
196/196 - 32s - loss: 28.9862 - MinusLogProbMetric: 28.9862 - val_loss: 29.3114 - val_MinusLogProbMetric: 29.3114 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 153/1000
2023-09-28 08:33:10.133 
Epoch 153/1000 
	 loss: 28.9183, MinusLogProbMetric: 28.9183, val_loss: 28.9627, val_MinusLogProbMetric: 28.9627

Epoch 153: val_loss did not improve from 28.90456
196/196 - 32s - loss: 28.9183 - MinusLogProbMetric: 28.9183 - val_loss: 28.9627 - val_MinusLogProbMetric: 28.9627 - lr: 0.0010 - 32s/epoch - 166ms/step
Epoch 154/1000
2023-09-28 08:33:42.618 
Epoch 154/1000 
	 loss: 28.8644, MinusLogProbMetric: 28.8644, val_loss: 29.3542, val_MinusLogProbMetric: 29.3542

Epoch 154: val_loss did not improve from 28.90456
196/196 - 32s - loss: 28.8644 - MinusLogProbMetric: 28.8644 - val_loss: 29.3542 - val_MinusLogProbMetric: 29.3542 - lr: 0.0010 - 32s/epoch - 166ms/step
Epoch 155/1000
2023-09-28 08:34:14.918 
Epoch 155/1000 
	 loss: 28.9516, MinusLogProbMetric: 28.9516, val_loss: 29.0740, val_MinusLogProbMetric: 29.0740

Epoch 155: val_loss did not improve from 28.90456
196/196 - 32s - loss: 28.9516 - MinusLogProbMetric: 28.9516 - val_loss: 29.0740 - val_MinusLogProbMetric: 29.0740 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 156/1000
2023-09-28 08:34:47.196 
Epoch 156/1000 
	 loss: 28.9700, MinusLogProbMetric: 28.9700, val_loss: 29.1071, val_MinusLogProbMetric: 29.1071

Epoch 156: val_loss did not improve from 28.90456
196/196 - 32s - loss: 28.9700 - MinusLogProbMetric: 28.9700 - val_loss: 29.1071 - val_MinusLogProbMetric: 29.1071 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 157/1000
2023-09-28 08:35:19.356 
Epoch 157/1000 
	 loss: 28.8715, MinusLogProbMetric: 28.8715, val_loss: 29.0677, val_MinusLogProbMetric: 29.0677

Epoch 157: val_loss did not improve from 28.90456
196/196 - 32s - loss: 28.8715 - MinusLogProbMetric: 28.8715 - val_loss: 29.0677 - val_MinusLogProbMetric: 29.0677 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 158/1000
2023-09-28 08:35:51.527 
Epoch 158/1000 
	 loss: 28.9912, MinusLogProbMetric: 28.9912, val_loss: 28.9949, val_MinusLogProbMetric: 28.9949

Epoch 158: val_loss did not improve from 28.90456
196/196 - 32s - loss: 28.9912 - MinusLogProbMetric: 28.9912 - val_loss: 28.9949 - val_MinusLogProbMetric: 28.9949 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 159/1000
2023-09-28 08:36:23.907 
Epoch 159/1000 
	 loss: 28.9659, MinusLogProbMetric: 28.9659, val_loss: 29.2561, val_MinusLogProbMetric: 29.2561

Epoch 159: val_loss did not improve from 28.90456
196/196 - 32s - loss: 28.9659 - MinusLogProbMetric: 28.9659 - val_loss: 29.2561 - val_MinusLogProbMetric: 29.2561 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 160/1000
2023-09-28 08:36:56.242 
Epoch 160/1000 
	 loss: 28.8697, MinusLogProbMetric: 28.8697, val_loss: 29.4356, val_MinusLogProbMetric: 29.4356

Epoch 160: val_loss did not improve from 28.90456
196/196 - 32s - loss: 28.8697 - MinusLogProbMetric: 28.8697 - val_loss: 29.4356 - val_MinusLogProbMetric: 29.4356 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 161/1000
2023-09-28 08:37:28.421 
Epoch 161/1000 
	 loss: 28.8101, MinusLogProbMetric: 28.8101, val_loss: 29.1143, val_MinusLogProbMetric: 29.1143

Epoch 161: val_loss did not improve from 28.90456
196/196 - 32s - loss: 28.8101 - MinusLogProbMetric: 28.8101 - val_loss: 29.1143 - val_MinusLogProbMetric: 29.1143 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 162/1000
2023-09-28 08:38:00.735 
Epoch 162/1000 
	 loss: 28.9917, MinusLogProbMetric: 28.9917, val_loss: 29.2625, val_MinusLogProbMetric: 29.2625

Epoch 162: val_loss did not improve from 28.90456
196/196 - 32s - loss: 28.9917 - MinusLogProbMetric: 28.9917 - val_loss: 29.2625 - val_MinusLogProbMetric: 29.2625 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 163/1000
2023-09-28 08:38:33.123 
Epoch 163/1000 
	 loss: 28.8895, MinusLogProbMetric: 28.8895, val_loss: 29.8620, val_MinusLogProbMetric: 29.8620

Epoch 163: val_loss did not improve from 28.90456
196/196 - 32s - loss: 28.8895 - MinusLogProbMetric: 28.8895 - val_loss: 29.8620 - val_MinusLogProbMetric: 29.8620 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 164/1000
2023-09-28 08:39:05.676 
Epoch 164/1000 
	 loss: 28.9679, MinusLogProbMetric: 28.9679, val_loss: 29.5612, val_MinusLogProbMetric: 29.5612

Epoch 164: val_loss did not improve from 28.90456
196/196 - 33s - loss: 28.9679 - MinusLogProbMetric: 28.9679 - val_loss: 29.5612 - val_MinusLogProbMetric: 29.5612 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 165/1000
2023-09-28 08:39:37.909 
Epoch 165/1000 
	 loss: 28.8118, MinusLogProbMetric: 28.8118, val_loss: 29.4221, val_MinusLogProbMetric: 29.4221

Epoch 165: val_loss did not improve from 28.90456
196/196 - 32s - loss: 28.8118 - MinusLogProbMetric: 28.8118 - val_loss: 29.4221 - val_MinusLogProbMetric: 29.4221 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 166/1000
2023-09-28 08:40:10.060 
Epoch 166/1000 
	 loss: 28.8414, MinusLogProbMetric: 28.8414, val_loss: 29.0038, val_MinusLogProbMetric: 29.0038

Epoch 166: val_loss did not improve from 28.90456
196/196 - 32s - loss: 28.8414 - MinusLogProbMetric: 28.8414 - val_loss: 29.0038 - val_MinusLogProbMetric: 29.0038 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 167/1000
2023-09-28 08:40:42.336 
Epoch 167/1000 
	 loss: 28.9242, MinusLogProbMetric: 28.9242, val_loss: 29.6801, val_MinusLogProbMetric: 29.6801

Epoch 167: val_loss did not improve from 28.90456
196/196 - 32s - loss: 28.9242 - MinusLogProbMetric: 28.9242 - val_loss: 29.6801 - val_MinusLogProbMetric: 29.6801 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 168/1000
2023-09-28 08:41:14.781 
Epoch 168/1000 
	 loss: 28.9296, MinusLogProbMetric: 28.9296, val_loss: 29.9140, val_MinusLogProbMetric: 29.9140

Epoch 168: val_loss did not improve from 28.90456
196/196 - 32s - loss: 28.9296 - MinusLogProbMetric: 28.9296 - val_loss: 29.9140 - val_MinusLogProbMetric: 29.9140 - lr: 0.0010 - 32s/epoch - 166ms/step
Epoch 169/1000
2023-09-28 08:41:47.254 
Epoch 169/1000 
	 loss: 28.9106, MinusLogProbMetric: 28.9106, val_loss: 29.6746, val_MinusLogProbMetric: 29.6746

Epoch 169: val_loss did not improve from 28.90456
196/196 - 32s - loss: 28.9106 - MinusLogProbMetric: 28.9106 - val_loss: 29.6746 - val_MinusLogProbMetric: 29.6746 - lr: 0.0010 - 32s/epoch - 166ms/step
Epoch 170/1000
2023-09-28 08:42:19.759 
Epoch 170/1000 
	 loss: 28.7516, MinusLogProbMetric: 28.7516, val_loss: 29.1206, val_MinusLogProbMetric: 29.1206

Epoch 170: val_loss did not improve from 28.90456
196/196 - 33s - loss: 28.7516 - MinusLogProbMetric: 28.7516 - val_loss: 29.1206 - val_MinusLogProbMetric: 29.1206 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 171/1000
2023-09-28 08:42:51.877 
Epoch 171/1000 
	 loss: 28.7788, MinusLogProbMetric: 28.7788, val_loss: 29.3099, val_MinusLogProbMetric: 29.3099

Epoch 171: val_loss did not improve from 28.90456
196/196 - 32s - loss: 28.7788 - MinusLogProbMetric: 28.7788 - val_loss: 29.3099 - val_MinusLogProbMetric: 29.3099 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 172/1000
2023-09-28 08:43:24.111 
Epoch 172/1000 
	 loss: 28.7733, MinusLogProbMetric: 28.7733, val_loss: 29.6396, val_MinusLogProbMetric: 29.6396

Epoch 172: val_loss did not improve from 28.90456
196/196 - 32s - loss: 28.7733 - MinusLogProbMetric: 28.7733 - val_loss: 29.6396 - val_MinusLogProbMetric: 29.6396 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 173/1000
2023-09-28 08:43:57.085 
Epoch 173/1000 
	 loss: 28.6851, MinusLogProbMetric: 28.6851, val_loss: 29.1176, val_MinusLogProbMetric: 29.1176

Epoch 173: val_loss did not improve from 28.90456
196/196 - 33s - loss: 28.6851 - MinusLogProbMetric: 28.6851 - val_loss: 29.1176 - val_MinusLogProbMetric: 29.1176 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 174/1000
2023-09-28 08:44:30.513 
Epoch 174/1000 
	 loss: 28.8183, MinusLogProbMetric: 28.8183, val_loss: 29.3257, val_MinusLogProbMetric: 29.3257

Epoch 174: val_loss did not improve from 28.90456
196/196 - 33s - loss: 28.8183 - MinusLogProbMetric: 28.8183 - val_loss: 29.3257 - val_MinusLogProbMetric: 29.3257 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 175/1000
2023-09-28 08:45:04.052 
Epoch 175/1000 
	 loss: 28.7011, MinusLogProbMetric: 28.7011, val_loss: 29.2794, val_MinusLogProbMetric: 29.2794

Epoch 175: val_loss did not improve from 28.90456
196/196 - 34s - loss: 28.7011 - MinusLogProbMetric: 28.7011 - val_loss: 29.2794 - val_MinusLogProbMetric: 29.2794 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 176/1000
2023-09-28 08:45:37.763 
Epoch 176/1000 
	 loss: 28.8195, MinusLogProbMetric: 28.8195, val_loss: 29.3357, val_MinusLogProbMetric: 29.3357

Epoch 176: val_loss did not improve from 28.90456
196/196 - 34s - loss: 28.8195 - MinusLogProbMetric: 28.8195 - val_loss: 29.3357 - val_MinusLogProbMetric: 29.3357 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 177/1000
2023-09-28 08:46:11.295 
Epoch 177/1000 
	 loss: 28.7888, MinusLogProbMetric: 28.7888, val_loss: 29.9551, val_MinusLogProbMetric: 29.9551

Epoch 177: val_loss did not improve from 28.90456
196/196 - 34s - loss: 28.7888 - MinusLogProbMetric: 28.7888 - val_loss: 29.9551 - val_MinusLogProbMetric: 29.9551 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 178/1000
2023-09-28 08:46:44.926 
Epoch 178/1000 
	 loss: 28.6737, MinusLogProbMetric: 28.6737, val_loss: 29.5874, val_MinusLogProbMetric: 29.5874

Epoch 178: val_loss did not improve from 28.90456
196/196 - 34s - loss: 28.6737 - MinusLogProbMetric: 28.6737 - val_loss: 29.5874 - val_MinusLogProbMetric: 29.5874 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 179/1000
