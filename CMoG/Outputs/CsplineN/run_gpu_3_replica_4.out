2023-09-23 15:06:53.220059: Importing os...
2023-09-23 15:06:53.220141: Importing sys...
2023-09-23 15:06:53.220159: Importing and initializing argparse...
Visible devices: [3]
2023-09-23 15:06:53.238470: Importing timer from timeit...
2023-09-23 15:06:53.239040: Setting env variables for tf import (only device [3] will be available)...
2023-09-23 15:06:53.239086: Importing numpy...
2023-09-23 15:06:53.385611: Importing pandas...
2023-09-23 15:06:53.559793: Importing shutil...
2023-09-23 15:06:53.559817: Importing subprocess...
2023-09-23 15:06:53.559823: Importing tensorflow...
Tensorflow version: 2.12.0
2023-09-23 15:06:55.309284: Importing tensorflow_probability...
Tensorflow probability version: 0.20.1
2023-09-23 15:06:55.601536: Importing textwrap...
2023-09-23 15:06:55.601558: Importing timeit...
2023-09-23 15:06:55.601566: Importing traceback...
2023-09-23 15:06:55.601571: Importing typing...
2023-09-23 15:06:55.601579: Setting tf configs...
2023-09-23 15:06:55.692225: Importing custom module...
Successfully loaded GPU model: NVIDIA A40
2023-09-23 15:06:56.625989: All modues imported successfully.
Directory ../../results/CsplineN_new/ already exists.
Directory ../../results/CsplineN_new/run_1/ already exists.
Skipping it.
===========
Run 1/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_2/ already exists.
Skipping it.
===========
Run 2/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_3/ already exists.
Skipping it.
===========
Run 3/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_4/ already exists.
Skipping it.
===========
Run 4/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_5/ already exists.
Skipping it.
===========
Run 5/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_6/ already exists.
Skipping it.
===========
Run 6/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_7/ already exists.
Skipping it.
===========
Run 7/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_8/ already exists.
Skipping it.
===========
Run 8/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_9/ already exists.
Skipping it.
===========
Run 9/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_10/ already exists.
Skipping it.
===========
Run 10/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_11/ already exists.
Skipping it.
===========
Run 11/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_12/ already exists.
Skipping it.
===========
Run 12/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_13/ already exists.
Skipping it.
===========
Run 13/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_14/ already exists.
Skipping it.
===========
Run 14/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_15/ already exists.
Skipping it.
===========
Run 15/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_16/ already exists.
Skipping it.
===========
Run 16/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_17/ already exists.
Skipping it.
===========
Run 17/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_18/ already exists.
Skipping it.
===========
Run 18/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_19/ already exists.
Skipping it.
===========
Run 19/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_20/ already exists.
Skipping it.
===========
Run 20/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_21/ already exists.
Skipping it.
===========
Run 21/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_22/ already exists.
Skipping it.
===========
Run 22/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_23/ already exists.
Skipping it.
===========
Run 23/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_24/ already exists.
Skipping it.
===========
Run 24/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_25/ already exists.
Skipping it.
===========
Run 25/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_26/ already exists.
Skipping it.
===========
Run 26/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_27/ already exists.
Skipping it.
===========
Run 27/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_28/ already exists.
Skipping it.
===========
Run 28/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_29/ already exists.
Skipping it.
===========
Run 29/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_30/ already exists.
Skipping it.
===========
Run 30/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_31/ already exists.
Skipping it.
===========
Run 31/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_32/ already exists.
Skipping it.
===========
Run 32/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_33/ already exists.
Skipping it.
===========
Run 33/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_34/ already exists.
Skipping it.
===========
Run 34/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_35/ already exists.
Skipping it.
===========
Run 35/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_36/ already exists.
Skipping it.
===========
Run 36/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_37/ already exists.
Skipping it.
===========
Run 37/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_38/ already exists.
Skipping it.
===========
Run 38/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_39/ already exists.
Skipping it.
===========
Run 39/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_40/ already exists.
Skipping it.
===========
Run 40/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_41/ already exists.
Skipping it.
===========
Run 41/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_42/ already exists.
Skipping it.
===========
Run 42/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_43/ already exists.
Skipping it.
===========
Run 43/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_44/ already exists.
Skipping it.
===========
Run 44/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_45/ already exists.
Skipping it.
===========
Run 45/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_46/ already exists.
Skipping it.
===========
Run 46/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_47/ already exists.
Skipping it.
===========
Run 47/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_48/ already exists.
Skipping it.
===========
Run 48/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_49/ already exists.
Skipping it.
===========
Run 49/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_50/ already exists.
Skipping it.
===========
Run 50/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_51/ already exists.
Skipping it.
===========
Run 51/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_52/ already exists.
Skipping it.
===========
Run 52/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_53/ already exists.
Skipping it.
===========
Run 53/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_54/ already exists.
Skipping it.
===========
Run 54/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_55/ already exists.
Skipping it.
===========
Run 55/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_56/ already exists.
Skipping it.
===========
Run 56/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_57/ already exists.
Skipping it.
===========
Run 57/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_58/ already exists.
Skipping it.
===========
Run 58/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_59/ already exists.
Skipping it.
===========
Run 59/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_60/ already exists.
Skipping it.
===========
Run 60/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_61/ already exists.
Skipping it.
===========
Run 61/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_62/ already exists.
Skipping it.
===========
Run 62/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_63/ already exists.
Skipping it.
===========
Run 63/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_64/ already exists.
Skipping it.
===========
Run 64/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_65/ already exists.
Skipping it.
===========
Run 65/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_66/ already exists.
Skipping it.
===========
Run 66/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_67/ already exists.
Skipping it.
===========
Run 67/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_68/ already exists.
Skipping it.
===========
Run 68/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_69/ already exists.
Skipping it.
===========
Run 69/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_70/ already exists.
Skipping it.
===========
Run 70/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_71/ already exists.
Skipping it.
===========
Run 71/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_72/ already exists.
Skipping it.
===========
Run 72/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_73/ already exists.
Skipping it.
===========
Run 73/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_74/ already exists.
Skipping it.
===========
Run 74/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_75/ already exists.
Skipping it.
===========
Run 75/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_76/ already exists.
Skipping it.
===========
Run 76/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_77/ already exists.
Skipping it.
===========
Run 77/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_78/ already exists.
Skipping it.
===========
Run 78/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_79/ already exists.
Skipping it.
===========
Run 79/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_80/ already exists.
Skipping it.
===========
Run 80/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_81/ already exists.
Skipping it.
===========
Run 81/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_82/ already exists.
Skipping it.
===========
Run 82/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_83/ already exists.
Skipping it.
===========
Run 83/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_84/ already exists.
Skipping it.
===========
Run 84/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_85/ already exists.
Skipping it.
===========
Run 85/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_86/ already exists.
Skipping it.
===========
Run 86/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_87/ already exists.
Skipping it.
===========
Run 87/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_88/ already exists.
Skipping it.
===========
Run 88/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_89/ already exists.
Skipping it.
===========
Run 89/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_90/ already exists.
Skipping it.
===========
Run 90/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_91/ already exists.
Skipping it.
===========
Run 91/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_92/ already exists.
Skipping it.
===========
Run 92/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_93/ already exists.
Skipping it.
===========
Run 93/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_94/ already exists.
Skipping it.
===========
Run 94/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_95/ already exists.
Skipping it.
===========
Run 95/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_96/ already exists.
Skipping it.
===========
Run 96/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_97/ already exists.
Skipping it.
===========
Run 97/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_98/ already exists.
Skipping it.
===========
Run 98/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_99/ already exists.
Skipping it.
===========
Run 99/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_100/ already exists.
Skipping it.
===========
Run 100/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_101/ already exists.
Skipping it.
===========
Run 101/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_102/ already exists.
Skipping it.
===========
Run 102/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_103/ already exists.
Skipping it.
===========
Run 103/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_104/ already exists.
Skipping it.
===========
Run 104/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_105/ already exists.
Skipping it.
===========
Run 105/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_106/ already exists.
Skipping it.
===========
Run 106/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_107/ already exists.
Skipping it.
===========
Run 107/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_108/ already exists.
Skipping it.
===========
Run 108/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_109/ already exists.
Skipping it.
===========
Run 109/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_110/ already exists.
Skipping it.
===========
Run 110/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_111/ already exists.
Skipping it.
===========
Run 111/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_112/ already exists.
Skipping it.
===========
Run 112/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_113/ already exists.
Skipping it.
===========
Run 113/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_114/ already exists.
Skipping it.
===========
Run 114/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_115/ already exists.
Skipping it.
===========
Run 115/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_116/ already exists.
Skipping it.
===========
Run 116/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_117/ already exists.
Skipping it.
===========
Run 117/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_118/ already exists.
Skipping it.
===========
Run 118/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_119/ already exists.
Skipping it.
===========
Run 119/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_120/ already exists.
Skipping it.
===========
Run 120/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_121/ already exists.
Skipping it.
===========
Run 121/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_122/ already exists.
Skipping it.
===========
Run 122/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_123/ already exists.
Skipping it.
===========
Run 123/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_124/ already exists.
Skipping it.
===========
Run 124/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_125/ already exists.
Skipping it.
===========
Run 125/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_126/ already exists.
Skipping it.
===========
Run 126/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_127/ already exists.
Skipping it.
===========
Run 127/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_128/ already exists.
Skipping it.
===========
Run 128/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_129/ already exists.
Skipping it.
===========
Run 129/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_130/ already exists.
Skipping it.
===========
Run 130/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_131/ already exists.
Skipping it.
===========
Run 131/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_132/ already exists.
Skipping it.
===========
Run 132/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_133/ already exists.
Skipping it.
===========
Run 133/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_134/ already exists.
Skipping it.
===========
Run 134/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_135/ already exists.
Skipping it.
===========
Run 135/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_136/ already exists.
Skipping it.
===========
Run 136/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_137/ already exists.
Skipping it.
===========
Run 137/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_138/ already exists.
Skipping it.
===========
Run 138/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_139/ already exists.
Skipping it.
===========
Run 139/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_140/ already exists.
Skipping it.
===========
Run 140/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_141/ already exists.
Skipping it.
===========
Run 141/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_142/ already exists.
Skipping it.
===========
Run 142/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_143/ already exists.
Skipping it.
===========
Run 143/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_144/ already exists.
Skipping it.
===========
Run 144/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_145/ already exists.
Skipping it.
===========
Run 145/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_146/ already exists.
Skipping it.
===========
Run 146/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_147/ already exists.
Skipping it.
===========
Run 147/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_148/ already exists.
Skipping it.
===========
Run 148/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_149/ already exists.
Skipping it.
===========
Run 149/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_150/ already exists.
Skipping it.
===========
Run 150/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_151/ already exists.
Skipping it.
===========
Run 151/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_152/ already exists.
Skipping it.
===========
Run 152/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_153/ already exists.
Skipping it.
===========
Run 153/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_154/ already exists.
Skipping it.
===========
Run 154/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_155/ already exists.
Skipping it.
===========
Run 155/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_156/ already exists.
Skipping it.
===========
Run 156/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_157/ already exists.
Skipping it.
===========
Run 157/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_158/ already exists.
Skipping it.
===========
Run 158/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_159/ already exists.
Skipping it.
===========
Run 159/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_160/ already exists.
Skipping it.
===========
Run 160/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_161/ already exists.
Skipping it.
===========
Run 161/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_162/ already exists.
Skipping it.
===========
Run 162/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_163/ already exists.
Skipping it.
===========
Run 163/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_164/ already exists.
Skipping it.
===========
Run 164/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_165/ already exists.
Skipping it.
===========
Run 165/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_166/ already exists.
Skipping it.
===========
Run 166/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_167/ already exists.
Skipping it.
===========
Run 167/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_168/ already exists.
Skipping it.
===========
Run 168/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_169/ already exists.
Skipping it.
===========
Run 169/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_170/ already exists.
Skipping it.
===========
Run 170/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_171/ already exists.
Skipping it.
===========
Run 171/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_172/ already exists.
Skipping it.
===========
Run 172/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_173/ already exists.
Skipping it.
===========
Run 173/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_174/ already exists.
Skipping it.
===========
Run 174/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_175/ already exists.
Skipping it.
===========
Run 175/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_176/ already exists.
Skipping it.
===========
Run 176/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_177/ already exists.
Skipping it.
===========
Run 177/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_178/ already exists.
Skipping it.
===========
Run 178/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_179/ already exists.
Skipping it.
===========
Run 179/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_180/ already exists.
Skipping it.
===========
Run 180/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_181/ already exists.
Skipping it.
===========
Run 181/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_182/ already exists.
Skipping it.
===========
Run 182/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_183/ already exists.
Skipping it.
===========
Run 183/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_184/ already exists.
Skipping it.
===========
Run 184/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_185/ already exists.
Skipping it.
===========
Run 185/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_186/ already exists.
Skipping it.
===========
Run 186/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_187/ already exists.
Skipping it.
===========
Run 187/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_188/ already exists.
Skipping it.
===========
Run 188/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_189/ already exists.
Skipping it.
===========
Run 189/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_190/ already exists.
Skipping it.
===========
Run 190/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_191/ already exists.
Skipping it.
===========
Run 191/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_192/ already exists.
Skipping it.
===========
Run 192/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_193/ already exists.
Skipping it.
===========
Run 193/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_194/ already exists.
Skipping it.
===========
Run 194/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_195/ already exists.
Skipping it.
===========
Run 195/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_196/ already exists.
Skipping it.
===========
Run 196/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_197/ already exists.
Skipping it.
===========
Run 197/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_198/ already exists.
Skipping it.
===========
Run 198/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_199/ already exists.
Skipping it.
===========
Run 199/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_200/ already exists.
Skipping it.
===========
Run 200/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_201/ already exists.
Skipping it.
===========
Run 201/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_202/ already exists.
Skipping it.
===========
Run 202/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_203/ already exists.
Skipping it.
===========
Run 203/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_204/ already exists.
Skipping it.
===========
Run 204/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_205/ already exists.
Skipping it.
===========
Run 205/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_206/ already exists.
Skipping it.
===========
Run 206/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_207/ already exists.
Skipping it.
===========
Run 207/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_208/ already exists.
Skipping it.
===========
Run 208/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_209/ already exists.
Skipping it.
===========
Run 209/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_210/ already exists.
Skipping it.
===========
Run 210/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_211/ already exists.
Skipping it.
===========
Run 211/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_212/ already exists.
Skipping it.
===========
Run 212/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_213/ already exists.
Skipping it.
===========
Run 213/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_214/ already exists.
Skipping it.
===========
Run 214/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_215/ already exists.
Skipping it.
===========
Run 215/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_216/ already exists.
Skipping it.
===========
Run 216/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_217/ already exists.
Skipping it.
===========
Run 217/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_218/ already exists.
Skipping it.
===========
Run 218/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_219/ already exists.
Skipping it.
===========
Run 219/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_220/ already exists.
Skipping it.
===========
Run 220/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_221/ already exists.
Skipping it.
===========
Run 221/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_222/ already exists.
Skipping it.
===========
Run 222/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_223/ already exists.
Skipping it.
===========
Run 223/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_224/ already exists.
Skipping it.
===========
Run 224/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_225/ already exists.
Skipping it.
===========
Run 225/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_226/ already exists.
Skipping it.
===========
Run 226/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_227/ already exists.
Skipping it.
===========
Run 227/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_228/ already exists.
Skipping it.
===========
Run 228/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_229/ already exists.
Skipping it.
===========
Run 229/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_230/ already exists.
Skipping it.
===========
Run 230/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_231/ already exists.
Skipping it.
===========
Run 231/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_232/ already exists.
Skipping it.
===========
Run 232/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_233/ already exists.
Skipping it.
===========
Run 233/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_234/ already exists.
Skipping it.
===========
Run 234/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_235/ already exists.
Skipping it.
===========
Run 235/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_236/ already exists.
Skipping it.
===========
Run 236/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_237/ already exists.
Skipping it.
===========
Run 237/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_238/ already exists.
Skipping it.
===========
Run 238/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_239/ already exists.
Skipping it.
===========
Run 239/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_240/ already exists.
Skipping it.
===========
Run 240/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_241/ already exists.
Skipping it.
===========
Run 241/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_242/ already exists.
Skipping it.
===========
Run 242/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_243/ already exists.
Skipping it.
===========
Run 243/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_244/ already exists.
Skipping it.
===========
Run 244/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_245/ already exists.
Skipping it.
===========
Run 245/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_246/ already exists.
Skipping it.
===========
Run 246/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_247/ already exists.
Skipping it.
===========
Run 247/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_248/ already exists.
Skipping it.
===========
Run 248/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_249/ already exists.
Skipping it.
===========
Run 249/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_250/ already exists.
Skipping it.
===========
Run 250/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_251/ already exists.
Skipping it.
===========
Run 251/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_252/ already exists.
Skipping it.
===========
Run 252/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_253/ already exists.
Skipping it.
===========
Run 253/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_254/ already exists.
Skipping it.
===========
Run 254/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_255/ already exists.
Skipping it.
===========
Run 255/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_256/ already exists.
Skipping it.
===========
Run 256/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_257/ already exists.
Skipping it.
===========
Run 257/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_258/ already exists.
Skipping it.
===========
Run 258/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_259/ already exists.
Skipping it.
===========
Run 259/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_260/ already exists.
Skipping it.
===========
Run 260/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_261/ already exists.
Skipping it.
===========
Run 261/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_262/ already exists.
Skipping it.
===========
Run 262/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_263/ already exists.
Skipping it.
===========
Run 263/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_264/ already exists.
Skipping it.
===========
Run 264/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_265/ already exists.
Skipping it.
===========
Run 265/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_266/ already exists.
Skipping it.
===========
Run 266/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_267/ already exists.
Skipping it.
===========
Run 267/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_268/ already exists.
Skipping it.
===========
Run 268/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_269/ already exists.
Skipping it.
===========
Run 269/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_270/ already exists.
Skipping it.
===========
Run 270/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_271/ already exists.
Skipping it.
===========
Run 271/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_272/ already exists.
Skipping it.
===========
Run 272/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_273/ already exists.
Skipping it.
===========
Run 273/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_274/ already exists.
Skipping it.
===========
Run 274/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_275/ already exists.
Skipping it.
===========
Run 275/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_276/ already exists.
Skipping it.
===========
Run 276/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_277/ already exists.
Skipping it.
===========
Run 277/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_278/ already exists.
Skipping it.
===========
Run 278/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_279/ already exists.
Skipping it.
===========
Run 279/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_280/ already exists.
Skipping it.
===========
Run 280/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_281/ already exists.
Skipping it.
===========
Run 281/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_282/ already exists.
Skipping it.
===========
Run 282/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_283/ already exists.
Skipping it.
===========
Run 283/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_284/ already exists.
Skipping it.
===========
Run 284/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_285/ already exists.
Skipping it.
===========
Run 285/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_286/ already exists.
Skipping it.
===========
Run 286/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_287/ already exists.
Skipping it.
===========
Run 287/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_288/ already exists.
Skipping it.
===========
Run 288/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_289/ already exists.
Skipping it.
===========
Run 289/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_290/ already exists.
Skipping it.
===========
Run 290/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_291/ already exists.
Skipping it.
===========
Run 291/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_292/ already exists.
Skipping it.
===========
Run 292/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_293/ already exists.
Skipping it.
===========
Run 293/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_294/ already exists.
Skipping it.
===========
Run 294/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_295/ already exists.
Skipping it.
===========
Run 295/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_296/ already exists.
Skipping it.
===========
Run 296/720 already exists. Skipping it.
===========

===========
Generating train data for run 297.
===========
Train data generated in 0.12 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_297/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 869}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_297/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.7724807 ,  3.5952213 ,  8.442487  , ...,  7.3644695 ,
         3.6588435 ,  2.0248146 ],
       [ 6.6242166 ,  7.1665483 ,  6.4277024 , ...,  3.1194153 ,
         2.6248946 ,  8.037665  ],
       [ 4.5211086 ,  5.2663136 , -0.6501303 , ...,  0.17722613,
         6.462096  ,  1.3170475 ],
       ...,
       [ 5.2085795 ,  5.348097  , -0.4658583 , ..., -0.03725696,
         5.9864964 ,  1.2388526 ],
       [ 3.9188156 ,  5.4859467 , -0.29968688, ...,  0.4149692 ,
         6.0867124 ,  1.4174792 ],
       [ 2.283803  ,  2.9701724 ,  8.729265  , ...,  6.0229187 ,
         3.2842712 ,  2.1182036 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_297/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_297
self.data_kwargs: {'seed': 869}
self.x_data: [[ 1.7417877   3.5044646   9.194398   ...  7.377848    2.8874114
   1.7757134 ]
 [ 3.8693519   4.134066    8.323213   ...  7.5259514   3.079576
   1.8540689 ]
 [ 2.7888105   3.5250566   6.8470335  ...  7.0512147   2.9893377
   1.7142482 ]
 ...
 [ 3.8914979   5.948059   -0.25578696 ...  1.7629418   6.8860593
   1.464444  ]
 [ 3.0775785   3.9001913   8.887795   ...  7.2041593   3.5200696
   1.5176823 ]
 [ 1.0419946   3.6002321   7.1163735  ...  7.3799496   3.218665
   1.6207042 ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_6 (InputLayer)        [(None, 32)]              0         
                                                                 
 log_prob_layer (LogProbLaye  (None,)                  413360    
 r)                                                              
                                                                 
=================================================================
Total params: 413,360
Trainable params: 413,360
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer'")
self.model: <keras.engine.functional.Functional object at 0x7fd7644f7970>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fd7645fc790>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fd7645fc790>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fd78c1e6980>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fd78c341480>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fd78c343760>, <keras.callbacks.ModelCheckpoint object at 0x7fd78c343310>, <keras.callbacks.EarlyStopping object at 0x7fd78c343a00>, <keras.callbacks.ReduceLROnPlateau object at 0x7fd78c341b10>, <keras.callbacks.TerminateOnNaN object at 0x7fd78c343e20>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.7724807 ,  3.5952213 ,  8.442487  , ...,  7.3644695 ,
         3.6588435 ,  2.0248146 ],
       [ 6.6242166 ,  7.1665483 ,  6.4277024 , ...,  3.1194153 ,
         2.6248946 ,  8.037665  ],
       [ 4.5211086 ,  5.2663136 , -0.6501303 , ...,  0.17722613,
         6.462096  ,  1.3170475 ],
       ...,
       [ 5.2085795 ,  5.348097  , -0.4658583 , ..., -0.03725696,
         5.9864964 ,  1.2388526 ],
       [ 3.9188156 ,  5.4859467 , -0.29968688, ...,  0.4149692 ,
         6.0867124 ,  1.4174792 ],
       [ 2.283803  ,  2.9701724 ,  8.729265  , ...,  6.0229187 ,
         3.2842712 ,  2.1182036 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_297/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 297/720 with hyperparameters:
timestamp = 2023-09-23 15:07:00.456779
ndims = 32
seed_train = 869
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 5
spline_knots = 8
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 413360
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 1.7417877   3.5044646   9.194398    1.0621872   8.910313    1.2448134
  9.752992    4.795541   10.214517    5.8200784   7.3571367   0.42017213
  3.0764782   1.1773593   3.1572356   1.3086243   2.6951017   5.712275
  0.4469142   6.9349284   5.5393224   1.8138231   6.1143165   1.1455625
  7.183009    9.098161    3.4021838   5.9704523   0.79392874  7.377848
  2.8874114   1.7757134 ]
Epoch 1/1000
2023-09-23 15:08:22.784 
Epoch 1/1000 
	 loss: 128.0094, MinusLogProbMetric: 128.0094, val_loss: 33.4145, val_MinusLogProbMetric: 33.4145

Epoch 1: val_loss improved from inf to 33.41455, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 83s - loss: 128.0094 - MinusLogProbMetric: 128.0094 - val_loss: 33.4145 - val_MinusLogProbMetric: 33.4145 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 2/1000
2023-09-23 15:08:43.649 
Epoch 2/1000 
	 loss: 28.6698, MinusLogProbMetric: 28.6698, val_loss: 27.0316, val_MinusLogProbMetric: 27.0316

Epoch 2: val_loss improved from 33.41455 to 27.03162, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 21s - loss: 28.6698 - MinusLogProbMetric: 28.6698 - val_loss: 27.0316 - val_MinusLogProbMetric: 27.0316 - lr: 0.0010 - 21s/epoch - 105ms/step
Epoch 3/1000
2023-09-23 15:09:09.575 
Epoch 3/1000 
	 loss: 24.4239, MinusLogProbMetric: 24.4239, val_loss: 23.9531, val_MinusLogProbMetric: 23.9531

Epoch 3: val_loss improved from 27.03162 to 23.95312, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 26s - loss: 24.4239 - MinusLogProbMetric: 24.4239 - val_loss: 23.9531 - val_MinusLogProbMetric: 23.9531 - lr: 0.0010 - 26s/epoch - 132ms/step
Epoch 4/1000
2023-09-23 15:09:31.395 
Epoch 4/1000 
	 loss: 22.6922, MinusLogProbMetric: 22.6922, val_loss: 23.2160, val_MinusLogProbMetric: 23.2160

Epoch 4: val_loss improved from 23.95312 to 23.21596, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 22s - loss: 22.6922 - MinusLogProbMetric: 22.6922 - val_loss: 23.2160 - val_MinusLogProbMetric: 23.2160 - lr: 0.0010 - 22s/epoch - 112ms/step
Epoch 5/1000
2023-09-23 15:09:57.945 
Epoch 5/1000 
	 loss: 21.8879, MinusLogProbMetric: 21.8879, val_loss: 21.7966, val_MinusLogProbMetric: 21.7966

Epoch 5: val_loss improved from 23.21596 to 21.79664, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 27s - loss: 21.8879 - MinusLogProbMetric: 21.8879 - val_loss: 21.7966 - val_MinusLogProbMetric: 21.7966 - lr: 0.0010 - 27s/epoch - 136ms/step
Epoch 6/1000
2023-09-23 15:10:25.356 
Epoch 6/1000 
	 loss: 21.1860, MinusLogProbMetric: 21.1860, val_loss: 24.0436, val_MinusLogProbMetric: 24.0436

Epoch 6: val_loss did not improve from 21.79664
196/196 - 27s - loss: 21.1860 - MinusLogProbMetric: 21.1860 - val_loss: 24.0436 - val_MinusLogProbMetric: 24.0436 - lr: 0.0010 - 27s/epoch - 137ms/step
Epoch 7/1000
2023-09-23 15:10:51.257 
Epoch 7/1000 
	 loss: 20.8057, MinusLogProbMetric: 20.8057, val_loss: 21.1410, val_MinusLogProbMetric: 21.1410

Epoch 7: val_loss improved from 21.79664 to 21.14101, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 26s - loss: 20.8057 - MinusLogProbMetric: 20.8057 - val_loss: 21.1410 - val_MinusLogProbMetric: 21.1410 - lr: 0.0010 - 26s/epoch - 134ms/step
Epoch 8/1000
2023-09-23 15:11:20.366 
Epoch 8/1000 
	 loss: 20.7118, MinusLogProbMetric: 20.7118, val_loss: 20.3043, val_MinusLogProbMetric: 20.3043

Epoch 8: val_loss improved from 21.14101 to 20.30425, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 29s - loss: 20.7118 - MinusLogProbMetric: 20.7118 - val_loss: 20.3043 - val_MinusLogProbMetric: 20.3043 - lr: 0.0010 - 29s/epoch - 150ms/step
Epoch 9/1000
2023-09-23 15:11:49.369 
Epoch 9/1000 
	 loss: 20.2900, MinusLogProbMetric: 20.2900, val_loss: 20.4459, val_MinusLogProbMetric: 20.4459

Epoch 9: val_loss did not improve from 20.30425
196/196 - 28s - loss: 20.2900 - MinusLogProbMetric: 20.2900 - val_loss: 20.4459 - val_MinusLogProbMetric: 20.4459 - lr: 0.0010 - 28s/epoch - 144ms/step
Epoch 10/1000
2023-09-23 15:12:17.385 
Epoch 10/1000 
	 loss: 20.0116, MinusLogProbMetric: 20.0116, val_loss: 20.0727, val_MinusLogProbMetric: 20.0727

Epoch 10: val_loss improved from 20.30425 to 20.07270, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 29s - loss: 20.0116 - MinusLogProbMetric: 20.0116 - val_loss: 20.0727 - val_MinusLogProbMetric: 20.0727 - lr: 0.0010 - 29s/epoch - 146ms/step
Epoch 11/1000
2023-09-23 15:12:44.621 
Epoch 11/1000 
	 loss: 19.9043, MinusLogProbMetric: 19.9043, val_loss: 19.9722, val_MinusLogProbMetric: 19.9722

Epoch 11: val_loss improved from 20.07270 to 19.97218, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 27s - loss: 19.9043 - MinusLogProbMetric: 19.9043 - val_loss: 19.9722 - val_MinusLogProbMetric: 19.9722 - lr: 0.0010 - 27s/epoch - 139ms/step
Epoch 12/1000
2023-09-23 15:13:14.023 
Epoch 12/1000 
	 loss: 19.7369, MinusLogProbMetric: 19.7369, val_loss: 19.9618, val_MinusLogProbMetric: 19.9618

Epoch 12: val_loss improved from 19.97218 to 19.96176, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 29s - loss: 19.7369 - MinusLogProbMetric: 19.7369 - val_loss: 19.9618 - val_MinusLogProbMetric: 19.9618 - lr: 0.0010 - 29s/epoch - 150ms/step
Epoch 13/1000
2023-09-23 15:13:46.390 
Epoch 13/1000 
	 loss: 19.3970, MinusLogProbMetric: 19.3970, val_loss: 19.1628, val_MinusLogProbMetric: 19.1628

Epoch 13: val_loss improved from 19.96176 to 19.16277, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 32s - loss: 19.3970 - MinusLogProbMetric: 19.3970 - val_loss: 19.1628 - val_MinusLogProbMetric: 19.1628 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 14/1000
2023-09-23 15:14:19.212 
Epoch 14/1000 
	 loss: 19.3456, MinusLogProbMetric: 19.3456, val_loss: 19.4065, val_MinusLogProbMetric: 19.4065

Epoch 14: val_loss did not improve from 19.16277
196/196 - 32s - loss: 19.3456 - MinusLogProbMetric: 19.3456 - val_loss: 19.4065 - val_MinusLogProbMetric: 19.4065 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 15/1000
2023-09-23 15:14:49.542 
Epoch 15/1000 
	 loss: 19.2526, MinusLogProbMetric: 19.2526, val_loss: 19.0166, val_MinusLogProbMetric: 19.0166

Epoch 15: val_loss improved from 19.16277 to 19.01664, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 31s - loss: 19.2526 - MinusLogProbMetric: 19.2526 - val_loss: 19.0166 - val_MinusLogProbMetric: 19.0166 - lr: 0.0010 - 31s/epoch - 157ms/step
Epoch 16/1000
2023-09-23 15:15:20.886 
Epoch 16/1000 
	 loss: 19.3089, MinusLogProbMetric: 19.3089, val_loss: 18.8236, val_MinusLogProbMetric: 18.8236

Epoch 16: val_loss improved from 19.01664 to 18.82359, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 31s - loss: 19.3089 - MinusLogProbMetric: 19.3089 - val_loss: 18.8236 - val_MinusLogProbMetric: 18.8236 - lr: 0.0010 - 31s/epoch - 160ms/step
Epoch 17/1000
2023-09-23 15:15:49.510 
Epoch 17/1000 
	 loss: 19.0710, MinusLogProbMetric: 19.0710, val_loss: 19.1399, val_MinusLogProbMetric: 19.1399

Epoch 17: val_loss did not improve from 18.82359
196/196 - 28s - loss: 19.0710 - MinusLogProbMetric: 19.0710 - val_loss: 19.1399 - val_MinusLogProbMetric: 19.1399 - lr: 0.0010 - 28s/epoch - 144ms/step
Epoch 18/1000
2023-09-23 15:16:19.118 
Epoch 18/1000 
	 loss: 18.9441, MinusLogProbMetric: 18.9441, val_loss: 18.7305, val_MinusLogProbMetric: 18.7305

Epoch 18: val_loss improved from 18.82359 to 18.73050, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 30s - loss: 18.9441 - MinusLogProbMetric: 18.9441 - val_loss: 18.7305 - val_MinusLogProbMetric: 18.7305 - lr: 0.0010 - 30s/epoch - 154ms/step
Epoch 19/1000
2023-09-23 15:16:50.754 
Epoch 19/1000 
	 loss: 18.8228, MinusLogProbMetric: 18.8228, val_loss: 18.8205, val_MinusLogProbMetric: 18.8205

Epoch 19: val_loss did not improve from 18.73050
196/196 - 31s - loss: 18.8228 - MinusLogProbMetric: 18.8228 - val_loss: 18.8205 - val_MinusLogProbMetric: 18.8205 - lr: 0.0010 - 31s/epoch - 159ms/step
Epoch 20/1000
2023-09-23 15:17:20.517 
Epoch 20/1000 
	 loss: 18.7613, MinusLogProbMetric: 18.7613, val_loss: 19.1465, val_MinusLogProbMetric: 19.1465

Epoch 20: val_loss did not improve from 18.73050
196/196 - 30s - loss: 18.7613 - MinusLogProbMetric: 18.7613 - val_loss: 19.1465 - val_MinusLogProbMetric: 19.1465 - lr: 0.0010 - 30s/epoch - 152ms/step
Epoch 21/1000
2023-09-23 15:17:53.081 
Epoch 21/1000 
	 loss: 18.6561, MinusLogProbMetric: 18.6561, val_loss: 23.5441, val_MinusLogProbMetric: 23.5441

Epoch 21: val_loss did not improve from 18.73050
196/196 - 33s - loss: 18.6561 - MinusLogProbMetric: 18.6561 - val_loss: 23.5441 - val_MinusLogProbMetric: 23.5441 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 22/1000
2023-09-23 15:18:25.601 
Epoch 22/1000 
	 loss: 18.7580, MinusLogProbMetric: 18.7580, val_loss: 18.6198, val_MinusLogProbMetric: 18.6198

Epoch 22: val_loss improved from 18.73050 to 18.61982, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 18.7580 - MinusLogProbMetric: 18.7580 - val_loss: 18.6198 - val_MinusLogProbMetric: 18.6198 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 23/1000
2023-09-23 15:18:58.185 
Epoch 23/1000 
	 loss: 18.6319, MinusLogProbMetric: 18.6319, val_loss: 18.4450, val_MinusLogProbMetric: 18.4450

Epoch 23: val_loss improved from 18.61982 to 18.44502, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 18.6319 - MinusLogProbMetric: 18.6319 - val_loss: 18.4450 - val_MinusLogProbMetric: 18.4450 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 24/1000
2023-09-23 15:19:30.893 
Epoch 24/1000 
	 loss: 18.5208, MinusLogProbMetric: 18.5208, val_loss: 18.6306, val_MinusLogProbMetric: 18.6306

Epoch 24: val_loss did not improve from 18.44502
196/196 - 32s - loss: 18.5208 - MinusLogProbMetric: 18.5208 - val_loss: 18.6306 - val_MinusLogProbMetric: 18.6306 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 25/1000
2023-09-23 15:20:03.763 
Epoch 25/1000 
	 loss: 19.1320, MinusLogProbMetric: 19.1320, val_loss: 18.5670, val_MinusLogProbMetric: 18.5670

Epoch 25: val_loss did not improve from 18.44502
196/196 - 33s - loss: 19.1320 - MinusLogProbMetric: 19.1320 - val_loss: 18.5670 - val_MinusLogProbMetric: 18.5670 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 26/1000
2023-09-23 15:20:38.369 
Epoch 26/1000 
	 loss: 18.4969, MinusLogProbMetric: 18.4969, val_loss: 18.7464, val_MinusLogProbMetric: 18.7464

Epoch 26: val_loss did not improve from 18.44502
196/196 - 35s - loss: 18.4969 - MinusLogProbMetric: 18.4969 - val_loss: 18.7464 - val_MinusLogProbMetric: 18.7464 - lr: 0.0010 - 35s/epoch - 176ms/step
Epoch 27/1000
2023-09-23 15:21:12.498 
Epoch 27/1000 
	 loss: 18.3510, MinusLogProbMetric: 18.3510, val_loss: 18.0580, val_MinusLogProbMetric: 18.0580

Epoch 27: val_loss improved from 18.44502 to 18.05795, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 35s - loss: 18.3510 - MinusLogProbMetric: 18.3510 - val_loss: 18.0580 - val_MinusLogProbMetric: 18.0580 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 28/1000
2023-09-23 15:21:48.999 
Epoch 28/1000 
	 loss: 18.3566, MinusLogProbMetric: 18.3566, val_loss: 18.9835, val_MinusLogProbMetric: 18.9835

Epoch 28: val_loss did not improve from 18.05795
196/196 - 36s - loss: 18.3566 - MinusLogProbMetric: 18.3566 - val_loss: 18.9835 - val_MinusLogProbMetric: 18.9835 - lr: 0.0010 - 36s/epoch - 183ms/step
Epoch 29/1000
2023-09-23 15:22:23.159 
Epoch 29/1000 
	 loss: 18.2036, MinusLogProbMetric: 18.2036, val_loss: 19.0440, val_MinusLogProbMetric: 19.0440

Epoch 29: val_loss did not improve from 18.05795
196/196 - 34s - loss: 18.2036 - MinusLogProbMetric: 18.2036 - val_loss: 19.0440 - val_MinusLogProbMetric: 19.0440 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 30/1000
2023-09-23 15:22:56.908 
Epoch 30/1000 
	 loss: 18.2635, MinusLogProbMetric: 18.2635, val_loss: 20.8247, val_MinusLogProbMetric: 20.8247

Epoch 30: val_loss did not improve from 18.05795
196/196 - 34s - loss: 18.2635 - MinusLogProbMetric: 18.2635 - val_loss: 20.8247 - val_MinusLogProbMetric: 20.8247 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 31/1000
2023-09-23 15:23:30.688 
Epoch 31/1000 
	 loss: 18.2409, MinusLogProbMetric: 18.2409, val_loss: 18.4026, val_MinusLogProbMetric: 18.4026

Epoch 31: val_loss did not improve from 18.05795
196/196 - 34s - loss: 18.2409 - MinusLogProbMetric: 18.2409 - val_loss: 18.4026 - val_MinusLogProbMetric: 18.4026 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 32/1000
2023-09-23 15:24:03.600 
Epoch 32/1000 
	 loss: 18.0902, MinusLogProbMetric: 18.0902, val_loss: 18.4813, val_MinusLogProbMetric: 18.4813

Epoch 32: val_loss did not improve from 18.05795
196/196 - 33s - loss: 18.0902 - MinusLogProbMetric: 18.0902 - val_loss: 18.4813 - val_MinusLogProbMetric: 18.4813 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 33/1000
2023-09-23 15:24:38.615 
Epoch 33/1000 
	 loss: 18.1761, MinusLogProbMetric: 18.1761, val_loss: 18.3184, val_MinusLogProbMetric: 18.3184

Epoch 33: val_loss did not improve from 18.05795
196/196 - 35s - loss: 18.1761 - MinusLogProbMetric: 18.1761 - val_loss: 18.3184 - val_MinusLogProbMetric: 18.3184 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 34/1000
2023-09-23 15:25:15.218 
Epoch 34/1000 
	 loss: 18.0183, MinusLogProbMetric: 18.0183, val_loss: 18.2216, val_MinusLogProbMetric: 18.2216

Epoch 34: val_loss did not improve from 18.05795
196/196 - 37s - loss: 18.0183 - MinusLogProbMetric: 18.0183 - val_loss: 18.2216 - val_MinusLogProbMetric: 18.2216 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 35/1000
2023-09-23 15:25:51.428 
Epoch 35/1000 
	 loss: 18.0969, MinusLogProbMetric: 18.0969, val_loss: 18.4741, val_MinusLogProbMetric: 18.4741

Epoch 35: val_loss did not improve from 18.05795
196/196 - 36s - loss: 18.0969 - MinusLogProbMetric: 18.0969 - val_loss: 18.4741 - val_MinusLogProbMetric: 18.4741 - lr: 0.0010 - 36s/epoch - 185ms/step
Epoch 36/1000
2023-09-23 15:26:27.214 
Epoch 36/1000 
	 loss: 17.9794, MinusLogProbMetric: 17.9794, val_loss: 18.0439, val_MinusLogProbMetric: 18.0439

Epoch 36: val_loss improved from 18.05795 to 18.04392, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 36s - loss: 17.9794 - MinusLogProbMetric: 17.9794 - val_loss: 18.0439 - val_MinusLogProbMetric: 18.0439 - lr: 0.0010 - 36s/epoch - 186ms/step
Epoch 37/1000
2023-09-23 15:27:02.075 
Epoch 37/1000 
	 loss: 17.9631, MinusLogProbMetric: 17.9631, val_loss: 17.9733, val_MinusLogProbMetric: 17.9733

Epoch 37: val_loss improved from 18.04392 to 17.97328, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 35s - loss: 17.9631 - MinusLogProbMetric: 17.9631 - val_loss: 17.9733 - val_MinusLogProbMetric: 17.9733 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 38/1000
2023-09-23 15:27:38.648 
Epoch 38/1000 
	 loss: 17.9470, MinusLogProbMetric: 17.9470, val_loss: 17.8256, val_MinusLogProbMetric: 17.8256

Epoch 38: val_loss improved from 17.97328 to 17.82563, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 37s - loss: 17.9470 - MinusLogProbMetric: 17.9470 - val_loss: 17.8256 - val_MinusLogProbMetric: 17.8256 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 39/1000
2023-09-23 15:28:15.536 
Epoch 39/1000 
	 loss: 17.8947, MinusLogProbMetric: 17.8947, val_loss: 17.7880, val_MinusLogProbMetric: 17.7880

Epoch 39: val_loss improved from 17.82563 to 17.78798, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 37s - loss: 17.8947 - MinusLogProbMetric: 17.8947 - val_loss: 17.7880 - val_MinusLogProbMetric: 17.7880 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 40/1000
2023-09-23 15:28:47.476 
Epoch 40/1000 
	 loss: 17.9864, MinusLogProbMetric: 17.9864, val_loss: 17.9000, val_MinusLogProbMetric: 17.9000

Epoch 40: val_loss did not improve from 17.78798
196/196 - 31s - loss: 17.9864 - MinusLogProbMetric: 17.9864 - val_loss: 17.9000 - val_MinusLogProbMetric: 17.9000 - lr: 0.0010 - 31s/epoch - 160ms/step
Epoch 41/1000
2023-09-23 15:29:17.943 
Epoch 41/1000 
	 loss: 17.8195, MinusLogProbMetric: 17.8195, val_loss: 17.7933, val_MinusLogProbMetric: 17.7933

Epoch 41: val_loss did not improve from 17.78798
196/196 - 30s - loss: 17.8195 - MinusLogProbMetric: 17.8195 - val_loss: 17.7933 - val_MinusLogProbMetric: 17.7933 - lr: 0.0010 - 30s/epoch - 155ms/step
Epoch 42/1000
2023-09-23 15:29:47.580 
Epoch 42/1000 
	 loss: 17.7988, MinusLogProbMetric: 17.7988, val_loss: 18.4300, val_MinusLogProbMetric: 18.4300

Epoch 42: val_loss did not improve from 17.78798
196/196 - 30s - loss: 17.7988 - MinusLogProbMetric: 17.7988 - val_loss: 18.4300 - val_MinusLogProbMetric: 18.4300 - lr: 0.0010 - 30s/epoch - 151ms/step
Epoch 43/1000
2023-09-23 15:30:17.133 
Epoch 43/1000 
	 loss: 17.8032, MinusLogProbMetric: 17.8032, val_loss: 17.8192, val_MinusLogProbMetric: 17.8192

Epoch 43: val_loss did not improve from 17.78798
196/196 - 30s - loss: 17.8032 - MinusLogProbMetric: 17.8032 - val_loss: 17.8192 - val_MinusLogProbMetric: 17.8192 - lr: 0.0010 - 30s/epoch - 151ms/step
Epoch 44/1000
2023-09-23 15:30:48.983 
Epoch 44/1000 
	 loss: 17.8412, MinusLogProbMetric: 17.8412, val_loss: 18.8166, val_MinusLogProbMetric: 18.8166

Epoch 44: val_loss did not improve from 17.78798
196/196 - 32s - loss: 17.8412 - MinusLogProbMetric: 17.8412 - val_loss: 18.8166 - val_MinusLogProbMetric: 18.8166 - lr: 0.0010 - 32s/epoch - 162ms/step
Epoch 45/1000
2023-09-23 15:31:21.969 
Epoch 45/1000 
	 loss: 17.8049, MinusLogProbMetric: 17.8049, val_loss: 18.0907, val_MinusLogProbMetric: 18.0907

Epoch 45: val_loss did not improve from 17.78798
196/196 - 33s - loss: 17.8049 - MinusLogProbMetric: 17.8049 - val_loss: 18.0907 - val_MinusLogProbMetric: 18.0907 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 46/1000
2023-09-23 15:31:56.775 
Epoch 46/1000 
	 loss: 17.7504, MinusLogProbMetric: 17.7504, val_loss: 17.8574, val_MinusLogProbMetric: 17.8574

Epoch 46: val_loss did not improve from 17.78798
196/196 - 35s - loss: 17.7504 - MinusLogProbMetric: 17.7504 - val_loss: 17.8574 - val_MinusLogProbMetric: 17.8574 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 47/1000
2023-09-23 15:32:31.526 
Epoch 47/1000 
	 loss: 17.7377, MinusLogProbMetric: 17.7377, val_loss: 17.6827, val_MinusLogProbMetric: 17.6827

Epoch 47: val_loss improved from 17.78798 to 17.68267, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 35s - loss: 17.7377 - MinusLogProbMetric: 17.7377 - val_loss: 17.6827 - val_MinusLogProbMetric: 17.6827 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 48/1000
2023-09-23 15:33:07.062 
Epoch 48/1000 
	 loss: 17.7101, MinusLogProbMetric: 17.7101, val_loss: 17.6769, val_MinusLogProbMetric: 17.6769

Epoch 48: val_loss improved from 17.68267 to 17.67687, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 35s - loss: 17.7101 - MinusLogProbMetric: 17.7101 - val_loss: 17.6769 - val_MinusLogProbMetric: 17.6769 - lr: 0.0010 - 35s/epoch - 181ms/step
Epoch 49/1000
2023-09-23 15:33:41.083 
Epoch 49/1000 
	 loss: 17.6955, MinusLogProbMetric: 17.6955, val_loss: 18.2177, val_MinusLogProbMetric: 18.2177

Epoch 49: val_loss did not improve from 17.67687
196/196 - 34s - loss: 17.6955 - MinusLogProbMetric: 17.6955 - val_loss: 18.2177 - val_MinusLogProbMetric: 18.2177 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 50/1000
2023-09-23 15:34:14.398 
Epoch 50/1000 
	 loss: 17.6814, MinusLogProbMetric: 17.6814, val_loss: 19.0092, val_MinusLogProbMetric: 19.0092

Epoch 50: val_loss did not improve from 17.67687
196/196 - 33s - loss: 17.6814 - MinusLogProbMetric: 17.6814 - val_loss: 19.0092 - val_MinusLogProbMetric: 19.0092 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 51/1000
2023-09-23 15:34:47.635 
Epoch 51/1000 
	 loss: 17.6755, MinusLogProbMetric: 17.6755, val_loss: 19.3647, val_MinusLogProbMetric: 19.3647

Epoch 51: val_loss did not improve from 17.67687
196/196 - 33s - loss: 17.6755 - MinusLogProbMetric: 17.6755 - val_loss: 19.3647 - val_MinusLogProbMetric: 19.3647 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 52/1000
2023-09-23 15:35:20.417 
Epoch 52/1000 
	 loss: 17.6667, MinusLogProbMetric: 17.6667, val_loss: 17.9150, val_MinusLogProbMetric: 17.9150

Epoch 52: val_loss did not improve from 17.67687
196/196 - 33s - loss: 17.6667 - MinusLogProbMetric: 17.6667 - val_loss: 17.9150 - val_MinusLogProbMetric: 17.9150 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 53/1000
2023-09-23 15:35:53.385 
Epoch 53/1000 
	 loss: 17.6862, MinusLogProbMetric: 17.6862, val_loss: 17.9945, val_MinusLogProbMetric: 17.9945

Epoch 53: val_loss did not improve from 17.67687
196/196 - 33s - loss: 17.6862 - MinusLogProbMetric: 17.6862 - val_loss: 17.9945 - val_MinusLogProbMetric: 17.9945 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 54/1000
2023-09-23 15:36:26.808 
Epoch 54/1000 
	 loss: 17.6429, MinusLogProbMetric: 17.6429, val_loss: 17.7272, val_MinusLogProbMetric: 17.7272

Epoch 54: val_loss did not improve from 17.67687
196/196 - 33s - loss: 17.6429 - MinusLogProbMetric: 17.6429 - val_loss: 17.7272 - val_MinusLogProbMetric: 17.7272 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 55/1000
2023-09-23 15:36:59.784 
Epoch 55/1000 
	 loss: 17.5699, MinusLogProbMetric: 17.5699, val_loss: 17.5101, val_MinusLogProbMetric: 17.5101

Epoch 55: val_loss improved from 17.67687 to 17.51009, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 34s - loss: 17.5699 - MinusLogProbMetric: 17.5699 - val_loss: 17.5101 - val_MinusLogProbMetric: 17.5101 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 56/1000
2023-09-23 15:37:33.450 
Epoch 56/1000 
	 loss: 17.5901, MinusLogProbMetric: 17.5901, val_loss: 18.0786, val_MinusLogProbMetric: 18.0786

Epoch 56: val_loss did not improve from 17.51009
196/196 - 33s - loss: 17.5901 - MinusLogProbMetric: 17.5901 - val_loss: 18.0786 - val_MinusLogProbMetric: 18.0786 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 57/1000
2023-09-23 15:38:06.742 
Epoch 57/1000 
	 loss: 17.5681, MinusLogProbMetric: 17.5681, val_loss: 17.9212, val_MinusLogProbMetric: 17.9212

Epoch 57: val_loss did not improve from 17.51009
196/196 - 33s - loss: 17.5681 - MinusLogProbMetric: 17.5681 - val_loss: 17.9212 - val_MinusLogProbMetric: 17.9212 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 58/1000
2023-09-23 15:38:39.523 
Epoch 58/1000 
	 loss: 17.5442, MinusLogProbMetric: 17.5442, val_loss: 17.8254, val_MinusLogProbMetric: 17.8254

Epoch 58: val_loss did not improve from 17.51009
196/196 - 33s - loss: 17.5442 - MinusLogProbMetric: 17.5442 - val_loss: 17.8254 - val_MinusLogProbMetric: 17.8254 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 59/1000
2023-09-23 15:39:12.358 
Epoch 59/1000 
	 loss: 17.5514, MinusLogProbMetric: 17.5514, val_loss: 17.5546, val_MinusLogProbMetric: 17.5546

Epoch 59: val_loss did not improve from 17.51009
196/196 - 33s - loss: 17.5514 - MinusLogProbMetric: 17.5514 - val_loss: 17.5546 - val_MinusLogProbMetric: 17.5546 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 60/1000
2023-09-23 15:39:45.517 
Epoch 60/1000 
	 loss: 17.6556, MinusLogProbMetric: 17.6556, val_loss: 17.6594, val_MinusLogProbMetric: 17.6594

Epoch 60: val_loss did not improve from 17.51009
196/196 - 33s - loss: 17.6556 - MinusLogProbMetric: 17.6556 - val_loss: 17.6594 - val_MinusLogProbMetric: 17.6594 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 61/1000
2023-09-23 15:40:18.461 
Epoch 61/1000 
	 loss: 17.4788, MinusLogProbMetric: 17.4788, val_loss: 17.3794, val_MinusLogProbMetric: 17.3794

Epoch 61: val_loss improved from 17.51009 to 17.37937, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 17.4788 - MinusLogProbMetric: 17.4788 - val_loss: 17.3794 - val_MinusLogProbMetric: 17.3794 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 62/1000
2023-09-23 15:40:51.680 
Epoch 62/1000 
	 loss: 17.5155, MinusLogProbMetric: 17.5155, val_loss: 18.5310, val_MinusLogProbMetric: 18.5310

Epoch 62: val_loss did not improve from 17.37937
196/196 - 33s - loss: 17.5155 - MinusLogProbMetric: 17.5155 - val_loss: 18.5310 - val_MinusLogProbMetric: 18.5310 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 63/1000
2023-09-23 15:41:24.869 
Epoch 63/1000 
	 loss: 17.5517, MinusLogProbMetric: 17.5517, val_loss: 17.9717, val_MinusLogProbMetric: 17.9717

Epoch 63: val_loss did not improve from 17.37937
196/196 - 33s - loss: 17.5517 - MinusLogProbMetric: 17.5517 - val_loss: 17.9717 - val_MinusLogProbMetric: 17.9717 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 64/1000
2023-09-23 15:41:57.889 
Epoch 64/1000 
	 loss: 17.4706, MinusLogProbMetric: 17.4706, val_loss: 17.6371, val_MinusLogProbMetric: 17.6371

Epoch 64: val_loss did not improve from 17.37937
196/196 - 33s - loss: 17.4706 - MinusLogProbMetric: 17.4706 - val_loss: 17.6371 - val_MinusLogProbMetric: 17.6371 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 65/1000
2023-09-23 15:42:30.777 
Epoch 65/1000 
	 loss: 17.5355, MinusLogProbMetric: 17.5355, val_loss: 17.5644, val_MinusLogProbMetric: 17.5644

Epoch 65: val_loss did not improve from 17.37937
196/196 - 33s - loss: 17.5355 - MinusLogProbMetric: 17.5355 - val_loss: 17.5644 - val_MinusLogProbMetric: 17.5644 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 66/1000
2023-09-23 15:43:03.903 
Epoch 66/1000 
	 loss: 17.5092, MinusLogProbMetric: 17.5092, val_loss: 17.6927, val_MinusLogProbMetric: 17.6927

Epoch 66: val_loss did not improve from 17.37937
196/196 - 33s - loss: 17.5092 - MinusLogProbMetric: 17.5092 - val_loss: 17.6927 - val_MinusLogProbMetric: 17.6927 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 67/1000
2023-09-23 15:43:36.841 
Epoch 67/1000 
	 loss: 17.4776, MinusLogProbMetric: 17.4776, val_loss: 17.3256, val_MinusLogProbMetric: 17.3256

Epoch 67: val_loss improved from 17.37937 to 17.32565, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 17.4776 - MinusLogProbMetric: 17.4776 - val_loss: 17.3256 - val_MinusLogProbMetric: 17.3256 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 68/1000
2023-09-23 15:44:10.707 
Epoch 68/1000 
	 loss: 17.4821, MinusLogProbMetric: 17.4821, val_loss: 17.7152, val_MinusLogProbMetric: 17.7152

Epoch 68: val_loss did not improve from 17.32565
196/196 - 33s - loss: 17.4821 - MinusLogProbMetric: 17.4821 - val_loss: 17.7152 - val_MinusLogProbMetric: 17.7152 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 69/1000
2023-09-23 15:44:43.768 
Epoch 69/1000 
	 loss: 17.4243, MinusLogProbMetric: 17.4243, val_loss: 18.2372, val_MinusLogProbMetric: 18.2372

Epoch 69: val_loss did not improve from 17.32565
196/196 - 33s - loss: 17.4243 - MinusLogProbMetric: 17.4243 - val_loss: 18.2372 - val_MinusLogProbMetric: 18.2372 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 70/1000
2023-09-23 15:45:16.697 
Epoch 70/1000 
	 loss: 17.4118, MinusLogProbMetric: 17.4118, val_loss: 17.6691, val_MinusLogProbMetric: 17.6691

Epoch 70: val_loss did not improve from 17.32565
196/196 - 33s - loss: 17.4118 - MinusLogProbMetric: 17.4118 - val_loss: 17.6691 - val_MinusLogProbMetric: 17.6691 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 71/1000
2023-09-23 15:45:49.677 
Epoch 71/1000 
	 loss: 17.3554, MinusLogProbMetric: 17.3554, val_loss: 17.5858, val_MinusLogProbMetric: 17.5858

Epoch 71: val_loss did not improve from 17.32565
196/196 - 33s - loss: 17.3554 - MinusLogProbMetric: 17.3554 - val_loss: 17.5858 - val_MinusLogProbMetric: 17.5858 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 72/1000
2023-09-23 15:46:22.999 
Epoch 72/1000 
	 loss: 17.4941, MinusLogProbMetric: 17.4941, val_loss: 17.4537, val_MinusLogProbMetric: 17.4537

Epoch 72: val_loss did not improve from 17.32565
196/196 - 33s - loss: 17.4941 - MinusLogProbMetric: 17.4941 - val_loss: 17.4537 - val_MinusLogProbMetric: 17.4537 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 73/1000
2023-09-23 15:46:56.108 
Epoch 73/1000 
	 loss: 17.3965, MinusLogProbMetric: 17.3965, val_loss: 17.8140, val_MinusLogProbMetric: 17.8140

Epoch 73: val_loss did not improve from 17.32565
196/196 - 33s - loss: 17.3965 - MinusLogProbMetric: 17.3965 - val_loss: 17.8140 - val_MinusLogProbMetric: 17.8140 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 74/1000
2023-09-23 15:47:29.268 
Epoch 74/1000 
	 loss: 17.3694, MinusLogProbMetric: 17.3694, val_loss: 17.3386, val_MinusLogProbMetric: 17.3386

Epoch 74: val_loss did not improve from 17.32565
196/196 - 33s - loss: 17.3694 - MinusLogProbMetric: 17.3694 - val_loss: 17.3386 - val_MinusLogProbMetric: 17.3386 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 75/1000
2023-09-23 15:48:02.412 
Epoch 75/1000 
	 loss: 17.3581, MinusLogProbMetric: 17.3581, val_loss: 17.7373, val_MinusLogProbMetric: 17.7373

Epoch 75: val_loss did not improve from 17.32565
196/196 - 33s - loss: 17.3581 - MinusLogProbMetric: 17.3581 - val_loss: 17.7373 - val_MinusLogProbMetric: 17.7373 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 76/1000
2023-09-23 15:48:35.372 
Epoch 76/1000 
	 loss: 17.3675, MinusLogProbMetric: 17.3675, val_loss: 18.2849, val_MinusLogProbMetric: 18.2849

Epoch 76: val_loss did not improve from 17.32565
196/196 - 33s - loss: 17.3675 - MinusLogProbMetric: 17.3675 - val_loss: 18.2849 - val_MinusLogProbMetric: 18.2849 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 77/1000
2023-09-23 15:49:08.300 
Epoch 77/1000 
	 loss: 17.3272, MinusLogProbMetric: 17.3272, val_loss: 17.4695, val_MinusLogProbMetric: 17.4695

Epoch 77: val_loss did not improve from 17.32565
196/196 - 33s - loss: 17.3272 - MinusLogProbMetric: 17.3272 - val_loss: 17.4695 - val_MinusLogProbMetric: 17.4695 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 78/1000
2023-09-23 15:49:40.867 
Epoch 78/1000 
	 loss: 17.3317, MinusLogProbMetric: 17.3317, val_loss: 17.4849, val_MinusLogProbMetric: 17.4849

Epoch 78: val_loss did not improve from 17.32565
196/196 - 33s - loss: 17.3317 - MinusLogProbMetric: 17.3317 - val_loss: 17.4849 - val_MinusLogProbMetric: 17.4849 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 79/1000
2023-09-23 15:50:13.699 
Epoch 79/1000 
	 loss: 17.3421, MinusLogProbMetric: 17.3421, val_loss: 17.6407, val_MinusLogProbMetric: 17.6407

Epoch 79: val_loss did not improve from 17.32565
196/196 - 33s - loss: 17.3421 - MinusLogProbMetric: 17.3421 - val_loss: 17.6407 - val_MinusLogProbMetric: 17.6407 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 80/1000
2023-09-23 15:50:46.579 
Epoch 80/1000 
	 loss: 17.7426, MinusLogProbMetric: 17.7426, val_loss: 17.4765, val_MinusLogProbMetric: 17.4765

Epoch 80: val_loss did not improve from 17.32565
196/196 - 33s - loss: 17.7426 - MinusLogProbMetric: 17.7426 - val_loss: 17.4765 - val_MinusLogProbMetric: 17.4765 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 81/1000
2023-09-23 15:51:19.527 
Epoch 81/1000 
	 loss: 17.3330, MinusLogProbMetric: 17.3330, val_loss: 17.2450, val_MinusLogProbMetric: 17.2450

Epoch 81: val_loss improved from 17.32565 to 17.24500, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 17.3330 - MinusLogProbMetric: 17.3330 - val_loss: 17.2450 - val_MinusLogProbMetric: 17.2450 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 82/1000
2023-09-23 15:51:53.288 
Epoch 82/1000 
	 loss: 17.2322, MinusLogProbMetric: 17.2322, val_loss: 17.5644, val_MinusLogProbMetric: 17.5644

Epoch 82: val_loss did not improve from 17.24500
196/196 - 33s - loss: 17.2322 - MinusLogProbMetric: 17.2322 - val_loss: 17.5644 - val_MinusLogProbMetric: 17.5644 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 83/1000
2023-09-23 15:52:26.484 
Epoch 83/1000 
	 loss: 17.2359, MinusLogProbMetric: 17.2359, val_loss: 17.8446, val_MinusLogProbMetric: 17.8446

Epoch 83: val_loss did not improve from 17.24500
196/196 - 33s - loss: 17.2359 - MinusLogProbMetric: 17.2359 - val_loss: 17.8446 - val_MinusLogProbMetric: 17.8446 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 84/1000
2023-09-23 15:52:59.444 
Epoch 84/1000 
	 loss: 17.2610, MinusLogProbMetric: 17.2610, val_loss: 17.5939, val_MinusLogProbMetric: 17.5939

Epoch 84: val_loss did not improve from 17.24500
196/196 - 33s - loss: 17.2610 - MinusLogProbMetric: 17.2610 - val_loss: 17.5939 - val_MinusLogProbMetric: 17.5939 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 85/1000
2023-09-23 15:53:32.761 
Epoch 85/1000 
	 loss: 17.2538, MinusLogProbMetric: 17.2538, val_loss: 17.8679, val_MinusLogProbMetric: 17.8679

Epoch 85: val_loss did not improve from 17.24500
196/196 - 33s - loss: 17.2538 - MinusLogProbMetric: 17.2538 - val_loss: 17.8679 - val_MinusLogProbMetric: 17.8679 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 86/1000
2023-09-23 15:54:05.749 
Epoch 86/1000 
	 loss: 17.2594, MinusLogProbMetric: 17.2594, val_loss: 17.4859, val_MinusLogProbMetric: 17.4859

Epoch 86: val_loss did not improve from 17.24500
196/196 - 33s - loss: 17.2594 - MinusLogProbMetric: 17.2594 - val_loss: 17.4859 - val_MinusLogProbMetric: 17.4859 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 87/1000
2023-09-23 15:54:38.590 
Epoch 87/1000 
	 loss: 17.2917, MinusLogProbMetric: 17.2917, val_loss: 17.5685, val_MinusLogProbMetric: 17.5685

Epoch 87: val_loss did not improve from 17.24500
196/196 - 33s - loss: 17.2917 - MinusLogProbMetric: 17.2917 - val_loss: 17.5685 - val_MinusLogProbMetric: 17.5685 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 88/1000
2023-09-23 15:55:11.747 
Epoch 88/1000 
	 loss: 17.2000, MinusLogProbMetric: 17.2000, val_loss: 17.4962, val_MinusLogProbMetric: 17.4962

Epoch 88: val_loss did not improve from 17.24500
196/196 - 33s - loss: 17.2000 - MinusLogProbMetric: 17.2000 - val_loss: 17.4962 - val_MinusLogProbMetric: 17.4962 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 89/1000
2023-09-23 15:55:44.308 
Epoch 89/1000 
	 loss: 17.2441, MinusLogProbMetric: 17.2441, val_loss: 17.3109, val_MinusLogProbMetric: 17.3109

Epoch 89: val_loss did not improve from 17.24500
196/196 - 33s - loss: 17.2441 - MinusLogProbMetric: 17.2441 - val_loss: 17.3109 - val_MinusLogProbMetric: 17.3109 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 90/1000
2023-09-23 15:56:17.169 
Epoch 90/1000 
	 loss: 17.2239, MinusLogProbMetric: 17.2239, val_loss: 17.5074, val_MinusLogProbMetric: 17.5074

Epoch 90: val_loss did not improve from 17.24500
196/196 - 33s - loss: 17.2239 - MinusLogProbMetric: 17.2239 - val_loss: 17.5074 - val_MinusLogProbMetric: 17.5074 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 91/1000
2023-09-23 15:56:50.169 
Epoch 91/1000 
	 loss: 17.1981, MinusLogProbMetric: 17.1981, val_loss: 17.2533, val_MinusLogProbMetric: 17.2533

Epoch 91: val_loss did not improve from 17.24500
196/196 - 33s - loss: 17.1981 - MinusLogProbMetric: 17.1981 - val_loss: 17.2533 - val_MinusLogProbMetric: 17.2533 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 92/1000
2023-09-23 15:57:22.989 
Epoch 92/1000 
	 loss: 17.2502, MinusLogProbMetric: 17.2502, val_loss: 17.3995, val_MinusLogProbMetric: 17.3995

Epoch 92: val_loss did not improve from 17.24500
196/196 - 33s - loss: 17.2502 - MinusLogProbMetric: 17.2502 - val_loss: 17.3995 - val_MinusLogProbMetric: 17.3995 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 93/1000
2023-09-23 15:57:55.717 
Epoch 93/1000 
	 loss: 17.1895, MinusLogProbMetric: 17.1895, val_loss: 17.3961, val_MinusLogProbMetric: 17.3961

Epoch 93: val_loss did not improve from 17.24500
196/196 - 33s - loss: 17.1895 - MinusLogProbMetric: 17.1895 - val_loss: 17.3961 - val_MinusLogProbMetric: 17.3961 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 94/1000
2023-09-23 15:58:28.965 
Epoch 94/1000 
	 loss: 17.1575, MinusLogProbMetric: 17.1575, val_loss: 17.3661, val_MinusLogProbMetric: 17.3661

Epoch 94: val_loss did not improve from 17.24500
196/196 - 33s - loss: 17.1575 - MinusLogProbMetric: 17.1575 - val_loss: 17.3661 - val_MinusLogProbMetric: 17.3661 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 95/1000
2023-09-23 15:59:01.896 
Epoch 95/1000 
	 loss: 17.1543, MinusLogProbMetric: 17.1543, val_loss: 17.2561, val_MinusLogProbMetric: 17.2561

Epoch 95: val_loss did not improve from 17.24500
196/196 - 33s - loss: 17.1543 - MinusLogProbMetric: 17.1543 - val_loss: 17.2561 - val_MinusLogProbMetric: 17.2561 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 96/1000
2023-09-23 15:59:34.933 
Epoch 96/1000 
	 loss: 17.1499, MinusLogProbMetric: 17.1499, val_loss: 17.2570, val_MinusLogProbMetric: 17.2570

Epoch 96: val_loss did not improve from 17.24500
196/196 - 33s - loss: 17.1499 - MinusLogProbMetric: 17.1499 - val_loss: 17.2570 - val_MinusLogProbMetric: 17.2570 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 97/1000
2023-09-23 16:00:07.691 
Epoch 97/1000 
	 loss: 17.1367, MinusLogProbMetric: 17.1367, val_loss: 17.4693, val_MinusLogProbMetric: 17.4693

Epoch 97: val_loss did not improve from 17.24500
196/196 - 33s - loss: 17.1367 - MinusLogProbMetric: 17.1367 - val_loss: 17.4693 - val_MinusLogProbMetric: 17.4693 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 98/1000
2023-09-23 16:00:40.453 
Epoch 98/1000 
	 loss: 17.1179, MinusLogProbMetric: 17.1179, val_loss: 17.7382, val_MinusLogProbMetric: 17.7382

Epoch 98: val_loss did not improve from 17.24500
196/196 - 33s - loss: 17.1179 - MinusLogProbMetric: 17.1179 - val_loss: 17.7382 - val_MinusLogProbMetric: 17.7382 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 99/1000
2023-09-23 16:01:13.110 
Epoch 99/1000 
	 loss: 17.1106, MinusLogProbMetric: 17.1106, val_loss: 17.5874, val_MinusLogProbMetric: 17.5874

Epoch 99: val_loss did not improve from 17.24500
196/196 - 33s - loss: 17.1106 - MinusLogProbMetric: 17.1106 - val_loss: 17.5874 - val_MinusLogProbMetric: 17.5874 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 100/1000
2023-09-23 16:01:46.217 
Epoch 100/1000 
	 loss: 17.1529, MinusLogProbMetric: 17.1529, val_loss: 17.1190, val_MinusLogProbMetric: 17.1190

Epoch 100: val_loss improved from 17.24500 to 17.11903, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 34s - loss: 17.1529 - MinusLogProbMetric: 17.1529 - val_loss: 17.1190 - val_MinusLogProbMetric: 17.1190 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 101/1000
2023-09-23 16:02:19.596 
Epoch 101/1000 
	 loss: 17.2182, MinusLogProbMetric: 17.2182, val_loss: 17.4304, val_MinusLogProbMetric: 17.4304

Epoch 101: val_loss did not improve from 17.11903
196/196 - 33s - loss: 17.2182 - MinusLogProbMetric: 17.2182 - val_loss: 17.4304 - val_MinusLogProbMetric: 17.4304 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 102/1000
2023-09-23 16:02:52.617 
Epoch 102/1000 
	 loss: 17.0918, MinusLogProbMetric: 17.0918, val_loss: 17.3965, val_MinusLogProbMetric: 17.3965

Epoch 102: val_loss did not improve from 17.11903
196/196 - 33s - loss: 17.0918 - MinusLogProbMetric: 17.0918 - val_loss: 17.3965 - val_MinusLogProbMetric: 17.3965 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 103/1000
2023-09-23 16:03:25.333 
Epoch 103/1000 
	 loss: 17.1613, MinusLogProbMetric: 17.1613, val_loss: 17.4273, val_MinusLogProbMetric: 17.4273

Epoch 103: val_loss did not improve from 17.11903
196/196 - 33s - loss: 17.1613 - MinusLogProbMetric: 17.1613 - val_loss: 17.4273 - val_MinusLogProbMetric: 17.4273 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 104/1000
2023-09-23 16:03:58.402 
Epoch 104/1000 
	 loss: 17.0993, MinusLogProbMetric: 17.0993, val_loss: 17.1538, val_MinusLogProbMetric: 17.1538

Epoch 104: val_loss did not improve from 17.11903
196/196 - 33s - loss: 17.0993 - MinusLogProbMetric: 17.0993 - val_loss: 17.1538 - val_MinusLogProbMetric: 17.1538 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 105/1000
2023-09-23 16:04:31.624 
Epoch 105/1000 
	 loss: 17.0779, MinusLogProbMetric: 17.0779, val_loss: 18.2611, val_MinusLogProbMetric: 18.2611

Epoch 105: val_loss did not improve from 17.11903
196/196 - 33s - loss: 17.0779 - MinusLogProbMetric: 17.0779 - val_loss: 18.2611 - val_MinusLogProbMetric: 18.2611 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 106/1000
2023-09-23 16:05:04.595 
Epoch 106/1000 
	 loss: 17.1196, MinusLogProbMetric: 17.1196, val_loss: 17.7682, val_MinusLogProbMetric: 17.7682

Epoch 106: val_loss did not improve from 17.11903
196/196 - 33s - loss: 17.1196 - MinusLogProbMetric: 17.1196 - val_loss: 17.7682 - val_MinusLogProbMetric: 17.7682 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 107/1000
2023-09-23 16:05:37.425 
Epoch 107/1000 
	 loss: 17.0699, MinusLogProbMetric: 17.0699, val_loss: 17.1602, val_MinusLogProbMetric: 17.1602

Epoch 107: val_loss did not improve from 17.11903
196/196 - 33s - loss: 17.0699 - MinusLogProbMetric: 17.0699 - val_loss: 17.1602 - val_MinusLogProbMetric: 17.1602 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 108/1000
2023-09-23 16:06:10.550 
Epoch 108/1000 
	 loss: 17.0877, MinusLogProbMetric: 17.0877, val_loss: 17.1736, val_MinusLogProbMetric: 17.1736

Epoch 108: val_loss did not improve from 17.11903
196/196 - 33s - loss: 17.0877 - MinusLogProbMetric: 17.0877 - val_loss: 17.1736 - val_MinusLogProbMetric: 17.1736 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 109/1000
2023-09-23 16:06:43.433 
Epoch 109/1000 
	 loss: 17.0867, MinusLogProbMetric: 17.0867, val_loss: 17.1075, val_MinusLogProbMetric: 17.1075

Epoch 109: val_loss improved from 17.11903 to 17.10752, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 17.0867 - MinusLogProbMetric: 17.0867 - val_loss: 17.1075 - val_MinusLogProbMetric: 17.1075 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 110/1000
2023-09-23 16:07:16.928 
Epoch 110/1000 
	 loss: 17.0261, MinusLogProbMetric: 17.0261, val_loss: 17.7448, val_MinusLogProbMetric: 17.7448

Epoch 110: val_loss did not improve from 17.10752
196/196 - 33s - loss: 17.0261 - MinusLogProbMetric: 17.0261 - val_loss: 17.7448 - val_MinusLogProbMetric: 17.7448 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 111/1000
2023-09-23 16:07:49.861 
Epoch 111/1000 
	 loss: 17.0456, MinusLogProbMetric: 17.0456, val_loss: 17.2285, val_MinusLogProbMetric: 17.2285

Epoch 111: val_loss did not improve from 17.10752
196/196 - 33s - loss: 17.0456 - MinusLogProbMetric: 17.0456 - val_loss: 17.2285 - val_MinusLogProbMetric: 17.2285 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 112/1000
2023-09-23 16:08:22.617 
Epoch 112/1000 
	 loss: 17.0745, MinusLogProbMetric: 17.0745, val_loss: 17.2052, val_MinusLogProbMetric: 17.2052

Epoch 112: val_loss did not improve from 17.10752
196/196 - 33s - loss: 17.0745 - MinusLogProbMetric: 17.0745 - val_loss: 17.2052 - val_MinusLogProbMetric: 17.2052 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 113/1000
2023-09-23 16:08:55.675 
Epoch 113/1000 
	 loss: 17.0072, MinusLogProbMetric: 17.0072, val_loss: 17.1865, val_MinusLogProbMetric: 17.1865

Epoch 113: val_loss did not improve from 17.10752
196/196 - 33s - loss: 17.0072 - MinusLogProbMetric: 17.0072 - val_loss: 17.1865 - val_MinusLogProbMetric: 17.1865 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 114/1000
2023-09-23 16:09:28.660 
Epoch 114/1000 
	 loss: 17.0477, MinusLogProbMetric: 17.0477, val_loss: 17.2847, val_MinusLogProbMetric: 17.2847

Epoch 114: val_loss did not improve from 17.10752
196/196 - 33s - loss: 17.0477 - MinusLogProbMetric: 17.0477 - val_loss: 17.2847 - val_MinusLogProbMetric: 17.2847 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 115/1000
2023-09-23 16:10:01.753 
Epoch 115/1000 
	 loss: 17.0381, MinusLogProbMetric: 17.0381, val_loss: 17.2006, val_MinusLogProbMetric: 17.2006

Epoch 115: val_loss did not improve from 17.10752
196/196 - 33s - loss: 17.0381 - MinusLogProbMetric: 17.0381 - val_loss: 17.2006 - val_MinusLogProbMetric: 17.2006 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 116/1000
2023-09-23 16:10:34.566 
Epoch 116/1000 
	 loss: 17.0010, MinusLogProbMetric: 17.0010, val_loss: 17.4138, val_MinusLogProbMetric: 17.4138

Epoch 116: val_loss did not improve from 17.10752
196/196 - 33s - loss: 17.0010 - MinusLogProbMetric: 17.0010 - val_loss: 17.4138 - val_MinusLogProbMetric: 17.4138 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 117/1000
2023-09-23 16:11:07.275 
Epoch 117/1000 
	 loss: 17.1149, MinusLogProbMetric: 17.1149, val_loss: 17.2279, val_MinusLogProbMetric: 17.2279

Epoch 117: val_loss did not improve from 17.10752
196/196 - 33s - loss: 17.1149 - MinusLogProbMetric: 17.1149 - val_loss: 17.2279 - val_MinusLogProbMetric: 17.2279 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 118/1000
2023-09-23 16:11:40.002 
Epoch 118/1000 
	 loss: 17.0249, MinusLogProbMetric: 17.0249, val_loss: 17.2270, val_MinusLogProbMetric: 17.2270

Epoch 118: val_loss did not improve from 17.10752
196/196 - 33s - loss: 17.0249 - MinusLogProbMetric: 17.0249 - val_loss: 17.2270 - val_MinusLogProbMetric: 17.2270 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 119/1000
2023-09-23 16:12:13.001 
Epoch 119/1000 
	 loss: 16.9964, MinusLogProbMetric: 16.9964, val_loss: 17.0559, val_MinusLogProbMetric: 17.0559

Epoch 119: val_loss improved from 17.10752 to 17.05590, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 16.9964 - MinusLogProbMetric: 16.9964 - val_loss: 17.0559 - val_MinusLogProbMetric: 17.0559 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 120/1000
2023-09-23 16:12:46.221 
Epoch 120/1000 
	 loss: 16.9895, MinusLogProbMetric: 16.9895, val_loss: 17.3274, val_MinusLogProbMetric: 17.3274

Epoch 120: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9895 - MinusLogProbMetric: 16.9895 - val_loss: 17.3274 - val_MinusLogProbMetric: 17.3274 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 121/1000
2023-09-23 16:13:19.200 
Epoch 121/1000 
	 loss: 17.0070, MinusLogProbMetric: 17.0070, val_loss: 17.2840, val_MinusLogProbMetric: 17.2840

Epoch 121: val_loss did not improve from 17.05590
196/196 - 33s - loss: 17.0070 - MinusLogProbMetric: 17.0070 - val_loss: 17.2840 - val_MinusLogProbMetric: 17.2840 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 122/1000
2023-09-23 16:13:52.339 
Epoch 122/1000 
	 loss: 16.9916, MinusLogProbMetric: 16.9916, val_loss: 17.1842, val_MinusLogProbMetric: 17.1842

Epoch 122: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9916 - MinusLogProbMetric: 16.9916 - val_loss: 17.1842 - val_MinusLogProbMetric: 17.1842 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 123/1000
2023-09-23 16:14:25.352 
Epoch 123/1000 
	 loss: 17.0137, MinusLogProbMetric: 17.0137, val_loss: 17.0680, val_MinusLogProbMetric: 17.0680

Epoch 123: val_loss did not improve from 17.05590
196/196 - 33s - loss: 17.0137 - MinusLogProbMetric: 17.0137 - val_loss: 17.0680 - val_MinusLogProbMetric: 17.0680 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 124/1000
2023-09-23 16:14:58.258 
Epoch 124/1000 
	 loss: 17.0544, MinusLogProbMetric: 17.0544, val_loss: 17.1025, val_MinusLogProbMetric: 17.1025

Epoch 124: val_loss did not improve from 17.05590
196/196 - 33s - loss: 17.0544 - MinusLogProbMetric: 17.0544 - val_loss: 17.1025 - val_MinusLogProbMetric: 17.1025 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 125/1000
2023-09-23 16:15:31.389 
Epoch 125/1000 
	 loss: 16.9877, MinusLogProbMetric: 16.9877, val_loss: 17.1827, val_MinusLogProbMetric: 17.1827

Epoch 125: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9877 - MinusLogProbMetric: 16.9877 - val_loss: 17.1827 - val_MinusLogProbMetric: 17.1827 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 126/1000
2023-09-23 16:16:04.425 
Epoch 126/1000 
	 loss: 16.9458, MinusLogProbMetric: 16.9458, val_loss: 17.3609, val_MinusLogProbMetric: 17.3609

Epoch 126: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9458 - MinusLogProbMetric: 16.9458 - val_loss: 17.3609 - val_MinusLogProbMetric: 17.3609 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 127/1000
2023-09-23 16:16:37.536 
Epoch 127/1000 
	 loss: 16.9955, MinusLogProbMetric: 16.9955, val_loss: 17.2288, val_MinusLogProbMetric: 17.2288

Epoch 127: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9955 - MinusLogProbMetric: 16.9955 - val_loss: 17.2288 - val_MinusLogProbMetric: 17.2288 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 128/1000
2023-09-23 16:17:10.719 
Epoch 128/1000 
	 loss: 16.9366, MinusLogProbMetric: 16.9366, val_loss: 17.2518, val_MinusLogProbMetric: 17.2518

Epoch 128: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9366 - MinusLogProbMetric: 16.9366 - val_loss: 17.2518 - val_MinusLogProbMetric: 17.2518 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 129/1000
2023-09-23 16:17:43.613 
Epoch 129/1000 
	 loss: 16.9690, MinusLogProbMetric: 16.9690, val_loss: 17.1687, val_MinusLogProbMetric: 17.1687

Epoch 129: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9690 - MinusLogProbMetric: 16.9690 - val_loss: 17.1687 - val_MinusLogProbMetric: 17.1687 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 130/1000
2023-09-23 16:18:16.399 
Epoch 130/1000 
	 loss: 16.9660, MinusLogProbMetric: 16.9660, val_loss: 17.2851, val_MinusLogProbMetric: 17.2851

Epoch 130: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9660 - MinusLogProbMetric: 16.9660 - val_loss: 17.2851 - val_MinusLogProbMetric: 17.2851 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 131/1000
2023-09-23 16:18:49.293 
Epoch 131/1000 
	 loss: 16.9603, MinusLogProbMetric: 16.9603, val_loss: 17.2310, val_MinusLogProbMetric: 17.2310

Epoch 131: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9603 - MinusLogProbMetric: 16.9603 - val_loss: 17.2310 - val_MinusLogProbMetric: 17.2310 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 132/1000
2023-09-23 16:19:22.335 
Epoch 132/1000 
	 loss: 16.9809, MinusLogProbMetric: 16.9809, val_loss: 17.6954, val_MinusLogProbMetric: 17.6954

Epoch 132: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9809 - MinusLogProbMetric: 16.9809 - val_loss: 17.6954 - val_MinusLogProbMetric: 17.6954 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 133/1000
2023-09-23 16:19:55.492 
Epoch 133/1000 
	 loss: 16.9422, MinusLogProbMetric: 16.9422, val_loss: 17.4526, val_MinusLogProbMetric: 17.4526

Epoch 133: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9422 - MinusLogProbMetric: 16.9422 - val_loss: 17.4526 - val_MinusLogProbMetric: 17.4526 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 134/1000
2023-09-23 16:20:28.608 
Epoch 134/1000 
	 loss: 16.9372, MinusLogProbMetric: 16.9372, val_loss: 17.1258, val_MinusLogProbMetric: 17.1258

Epoch 134: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9372 - MinusLogProbMetric: 16.9372 - val_loss: 17.1258 - val_MinusLogProbMetric: 17.1258 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 135/1000
2023-09-23 16:21:01.799 
Epoch 135/1000 
	 loss: 16.9614, MinusLogProbMetric: 16.9614, val_loss: 17.2934, val_MinusLogProbMetric: 17.2934

Epoch 135: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9614 - MinusLogProbMetric: 16.9614 - val_loss: 17.2934 - val_MinusLogProbMetric: 17.2934 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 136/1000
2023-09-23 16:21:35.021 
Epoch 136/1000 
	 loss: 16.9129, MinusLogProbMetric: 16.9129, val_loss: 17.0807, val_MinusLogProbMetric: 17.0807

Epoch 136: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9129 - MinusLogProbMetric: 16.9129 - val_loss: 17.0807 - val_MinusLogProbMetric: 17.0807 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 137/1000
2023-09-23 16:22:07.795 
Epoch 137/1000 
	 loss: 16.9398, MinusLogProbMetric: 16.9398, val_loss: 17.1624, val_MinusLogProbMetric: 17.1624

Epoch 137: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9398 - MinusLogProbMetric: 16.9398 - val_loss: 17.1624 - val_MinusLogProbMetric: 17.1624 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 138/1000
2023-09-23 16:22:40.602 
Epoch 138/1000 
	 loss: 16.9379, MinusLogProbMetric: 16.9379, val_loss: 17.2269, val_MinusLogProbMetric: 17.2269

Epoch 138: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9379 - MinusLogProbMetric: 16.9379 - val_loss: 17.2269 - val_MinusLogProbMetric: 17.2269 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 139/1000
2023-09-23 16:23:13.537 
Epoch 139/1000 
	 loss: 16.9299, MinusLogProbMetric: 16.9299, val_loss: 17.0879, val_MinusLogProbMetric: 17.0879

Epoch 139: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9299 - MinusLogProbMetric: 16.9299 - val_loss: 17.0879 - val_MinusLogProbMetric: 17.0879 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 140/1000
2023-09-23 16:23:46.000 
Epoch 140/1000 
	 loss: 16.9456, MinusLogProbMetric: 16.9456, val_loss: 17.0756, val_MinusLogProbMetric: 17.0756

Epoch 140: val_loss did not improve from 17.05590
196/196 - 32s - loss: 16.9456 - MinusLogProbMetric: 16.9456 - val_loss: 17.0756 - val_MinusLogProbMetric: 17.0756 - lr: 0.0010 - 32s/epoch - 166ms/step
Epoch 141/1000
2023-09-23 16:24:18.890 
Epoch 141/1000 
	 loss: 16.9522, MinusLogProbMetric: 16.9522, val_loss: 17.1141, val_MinusLogProbMetric: 17.1141

Epoch 141: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9522 - MinusLogProbMetric: 16.9522 - val_loss: 17.1141 - val_MinusLogProbMetric: 17.1141 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 142/1000
2023-09-23 16:24:51.804 
Epoch 142/1000 
	 loss: 16.8983, MinusLogProbMetric: 16.8983, val_loss: 17.6336, val_MinusLogProbMetric: 17.6336

Epoch 142: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.8983 - MinusLogProbMetric: 16.8983 - val_loss: 17.6336 - val_MinusLogProbMetric: 17.6336 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 143/1000
2023-09-23 16:25:24.858 
Epoch 143/1000 
	 loss: 16.9412, MinusLogProbMetric: 16.9412, val_loss: 17.1125, val_MinusLogProbMetric: 17.1125

Epoch 143: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9412 - MinusLogProbMetric: 16.9412 - val_loss: 17.1125 - val_MinusLogProbMetric: 17.1125 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 144/1000
2023-09-23 16:25:57.642 
Epoch 144/1000 
	 loss: 16.9122, MinusLogProbMetric: 16.9122, val_loss: 17.0564, val_MinusLogProbMetric: 17.0564

Epoch 144: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9122 - MinusLogProbMetric: 16.9122 - val_loss: 17.0564 - val_MinusLogProbMetric: 17.0564 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 145/1000
2023-09-23 16:26:30.350 
Epoch 145/1000 
	 loss: 16.9556, MinusLogProbMetric: 16.9556, val_loss: 17.4507, val_MinusLogProbMetric: 17.4507

Epoch 145: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.9556 - MinusLogProbMetric: 16.9556 - val_loss: 17.4507 - val_MinusLogProbMetric: 17.4507 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 146/1000
2023-09-23 16:27:03.135 
Epoch 146/1000 
	 loss: 16.8959, MinusLogProbMetric: 16.8959, val_loss: 17.2335, val_MinusLogProbMetric: 17.2335

Epoch 146: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.8959 - MinusLogProbMetric: 16.8959 - val_loss: 17.2335 - val_MinusLogProbMetric: 17.2335 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 147/1000
2023-09-23 16:27:36.078 
Epoch 147/1000 
	 loss: 16.8775, MinusLogProbMetric: 16.8775, val_loss: 17.1391, val_MinusLogProbMetric: 17.1391

Epoch 147: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.8775 - MinusLogProbMetric: 16.8775 - val_loss: 17.1391 - val_MinusLogProbMetric: 17.1391 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 148/1000
2023-09-23 16:28:08.827 
Epoch 148/1000 
	 loss: 16.8963, MinusLogProbMetric: 16.8963, val_loss: 17.2476, val_MinusLogProbMetric: 17.2476

Epoch 148: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.8963 - MinusLogProbMetric: 16.8963 - val_loss: 17.2476 - val_MinusLogProbMetric: 17.2476 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 149/1000
2023-09-23 16:28:41.868 
Epoch 149/1000 
	 loss: 16.8798, MinusLogProbMetric: 16.8798, val_loss: 18.2060, val_MinusLogProbMetric: 18.2060

Epoch 149: val_loss did not improve from 17.05590
196/196 - 33s - loss: 16.8798 - MinusLogProbMetric: 16.8798 - val_loss: 18.2060 - val_MinusLogProbMetric: 18.2060 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 150/1000
2023-09-23 16:29:14.856 
Epoch 150/1000 
	 loss: 16.9168, MinusLogProbMetric: 16.9168, val_loss: 16.9899, val_MinusLogProbMetric: 16.9899

Epoch 150: val_loss improved from 17.05590 to 16.98988, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 16.9168 - MinusLogProbMetric: 16.9168 - val_loss: 16.9899 - val_MinusLogProbMetric: 16.9899 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 151/1000
2023-09-23 16:29:48.294 
Epoch 151/1000 
	 loss: 16.8926, MinusLogProbMetric: 16.8926, val_loss: 17.3045, val_MinusLogProbMetric: 17.3045

Epoch 151: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.8926 - MinusLogProbMetric: 16.8926 - val_loss: 17.3045 - val_MinusLogProbMetric: 17.3045 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 152/1000
2023-09-23 16:30:21.439 
Epoch 152/1000 
	 loss: 16.9780, MinusLogProbMetric: 16.9780, val_loss: 17.0589, val_MinusLogProbMetric: 17.0589

Epoch 152: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.9780 - MinusLogProbMetric: 16.9780 - val_loss: 17.0589 - val_MinusLogProbMetric: 17.0589 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 153/1000
2023-09-23 16:30:54.213 
Epoch 153/1000 
	 loss: 16.8423, MinusLogProbMetric: 16.8423, val_loss: 17.6480, val_MinusLogProbMetric: 17.6480

Epoch 153: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.8423 - MinusLogProbMetric: 16.8423 - val_loss: 17.6480 - val_MinusLogProbMetric: 17.6480 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 154/1000
2023-09-23 16:31:27.097 
Epoch 154/1000 
	 loss: 16.8711, MinusLogProbMetric: 16.8711, val_loss: 17.0584, val_MinusLogProbMetric: 17.0584

Epoch 154: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.8711 - MinusLogProbMetric: 16.8711 - val_loss: 17.0584 - val_MinusLogProbMetric: 17.0584 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 155/1000
2023-09-23 16:31:59.931 
Epoch 155/1000 
	 loss: 16.9013, MinusLogProbMetric: 16.9013, val_loss: 17.1043, val_MinusLogProbMetric: 17.1043

Epoch 155: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.9013 - MinusLogProbMetric: 16.9013 - val_loss: 17.1043 - val_MinusLogProbMetric: 17.1043 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 156/1000
2023-09-23 16:32:32.703 
Epoch 156/1000 
	 loss: 16.8663, MinusLogProbMetric: 16.8663, val_loss: 17.1916, val_MinusLogProbMetric: 17.1916

Epoch 156: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.8663 - MinusLogProbMetric: 16.8663 - val_loss: 17.1916 - val_MinusLogProbMetric: 17.1916 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 157/1000
2023-09-23 16:33:05.563 
Epoch 157/1000 
	 loss: 16.9247, MinusLogProbMetric: 16.9247, val_loss: 17.0524, val_MinusLogProbMetric: 17.0524

Epoch 157: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.9247 - MinusLogProbMetric: 16.9247 - val_loss: 17.0524 - val_MinusLogProbMetric: 17.0524 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 158/1000
2023-09-23 16:33:38.274 
Epoch 158/1000 
	 loss: 16.8599, MinusLogProbMetric: 16.8599, val_loss: 17.1368, val_MinusLogProbMetric: 17.1368

Epoch 158: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.8599 - MinusLogProbMetric: 16.8599 - val_loss: 17.1368 - val_MinusLogProbMetric: 17.1368 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 159/1000
2023-09-23 16:34:11.400 
Epoch 159/1000 
	 loss: 16.8395, MinusLogProbMetric: 16.8395, val_loss: 17.0617, val_MinusLogProbMetric: 17.0617

Epoch 159: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.8395 - MinusLogProbMetric: 16.8395 - val_loss: 17.0617 - val_MinusLogProbMetric: 17.0617 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 160/1000
2023-09-23 16:34:44.423 
Epoch 160/1000 
	 loss: 16.8780, MinusLogProbMetric: 16.8780, val_loss: 17.0015, val_MinusLogProbMetric: 17.0015

Epoch 160: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.8780 - MinusLogProbMetric: 16.8780 - val_loss: 17.0015 - val_MinusLogProbMetric: 17.0015 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 161/1000
2023-09-23 16:35:15.422 
Epoch 161/1000 
	 loss: 16.8553, MinusLogProbMetric: 16.8553, val_loss: 17.0874, val_MinusLogProbMetric: 17.0874

Epoch 161: val_loss did not improve from 16.98988
196/196 - 31s - loss: 16.8553 - MinusLogProbMetric: 16.8553 - val_loss: 17.0874 - val_MinusLogProbMetric: 17.0874 - lr: 0.0010 - 31s/epoch - 158ms/step
Epoch 162/1000
2023-09-23 16:35:45.167 
Epoch 162/1000 
	 loss: 16.8200, MinusLogProbMetric: 16.8200, val_loss: 17.0079, val_MinusLogProbMetric: 17.0079

Epoch 162: val_loss did not improve from 16.98988
196/196 - 30s - loss: 16.8200 - MinusLogProbMetric: 16.8200 - val_loss: 17.0079 - val_MinusLogProbMetric: 17.0079 - lr: 0.0010 - 30s/epoch - 152ms/step
Epoch 163/1000
2023-09-23 16:36:14.993 
Epoch 163/1000 
	 loss: 16.8271, MinusLogProbMetric: 16.8271, val_loss: 17.1942, val_MinusLogProbMetric: 17.1942

Epoch 163: val_loss did not improve from 16.98988
196/196 - 30s - loss: 16.8271 - MinusLogProbMetric: 16.8271 - val_loss: 17.1942 - val_MinusLogProbMetric: 17.1942 - lr: 0.0010 - 30s/epoch - 152ms/step
Epoch 164/1000
2023-09-23 16:36:46.580 
Epoch 164/1000 
	 loss: 16.8543, MinusLogProbMetric: 16.8543, val_loss: 17.5413, val_MinusLogProbMetric: 17.5413

Epoch 164: val_loss did not improve from 16.98988
196/196 - 32s - loss: 16.8543 - MinusLogProbMetric: 16.8543 - val_loss: 17.5413 - val_MinusLogProbMetric: 17.5413 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 165/1000
2023-09-23 16:37:18.860 
Epoch 165/1000 
	 loss: 16.8396, MinusLogProbMetric: 16.8396, val_loss: 17.0858, val_MinusLogProbMetric: 17.0858

Epoch 165: val_loss did not improve from 16.98988
196/196 - 32s - loss: 16.8396 - MinusLogProbMetric: 16.8396 - val_loss: 17.0858 - val_MinusLogProbMetric: 17.0858 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 166/1000
2023-09-23 16:37:51.833 
Epoch 166/1000 
	 loss: 16.8629, MinusLogProbMetric: 16.8629, val_loss: 17.4999, val_MinusLogProbMetric: 17.4999

Epoch 166: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.8629 - MinusLogProbMetric: 16.8629 - val_loss: 17.4999 - val_MinusLogProbMetric: 17.4999 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 167/1000
2023-09-23 16:38:24.584 
Epoch 167/1000 
	 loss: 16.8232, MinusLogProbMetric: 16.8232, val_loss: 17.0695, val_MinusLogProbMetric: 17.0695

Epoch 167: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.8232 - MinusLogProbMetric: 16.8232 - val_loss: 17.0695 - val_MinusLogProbMetric: 17.0695 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 168/1000
2023-09-23 16:38:57.212 
Epoch 168/1000 
	 loss: 16.7990, MinusLogProbMetric: 16.7990, val_loss: 17.8149, val_MinusLogProbMetric: 17.8149

Epoch 168: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.7990 - MinusLogProbMetric: 16.7990 - val_loss: 17.8149 - val_MinusLogProbMetric: 17.8149 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 169/1000
2023-09-23 16:39:29.950 
Epoch 169/1000 
	 loss: 16.8478, MinusLogProbMetric: 16.8478, val_loss: 17.0066, val_MinusLogProbMetric: 17.0066

Epoch 169: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.8478 - MinusLogProbMetric: 16.8478 - val_loss: 17.0066 - val_MinusLogProbMetric: 17.0066 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 170/1000
2023-09-23 16:40:03.400 
Epoch 170/1000 
	 loss: 16.8173, MinusLogProbMetric: 16.8173, val_loss: 17.0318, val_MinusLogProbMetric: 17.0318

Epoch 170: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.8173 - MinusLogProbMetric: 16.8173 - val_loss: 17.0318 - val_MinusLogProbMetric: 17.0318 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 171/1000
2023-09-23 16:40:36.458 
Epoch 171/1000 
	 loss: 16.8523, MinusLogProbMetric: 16.8523, val_loss: 17.2684, val_MinusLogProbMetric: 17.2684

Epoch 171: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.8523 - MinusLogProbMetric: 16.8523 - val_loss: 17.2684 - val_MinusLogProbMetric: 17.2684 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 172/1000
2023-09-23 16:41:09.939 
Epoch 172/1000 
	 loss: 16.8044, MinusLogProbMetric: 16.8044, val_loss: 17.1857, val_MinusLogProbMetric: 17.1857

Epoch 172: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.8044 - MinusLogProbMetric: 16.8044 - val_loss: 17.1857 - val_MinusLogProbMetric: 17.1857 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 173/1000
2023-09-23 16:41:43.188 
Epoch 173/1000 
	 loss: 16.8733, MinusLogProbMetric: 16.8733, val_loss: 17.0635, val_MinusLogProbMetric: 17.0635

Epoch 173: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.8733 - MinusLogProbMetric: 16.8733 - val_loss: 17.0635 - val_MinusLogProbMetric: 17.0635 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 174/1000
2023-09-23 16:42:16.420 
Epoch 174/1000 
	 loss: 16.8166, MinusLogProbMetric: 16.8166, val_loss: 17.1068, val_MinusLogProbMetric: 17.1068

Epoch 174: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.8166 - MinusLogProbMetric: 16.8166 - val_loss: 17.1068 - val_MinusLogProbMetric: 17.1068 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 175/1000
2023-09-23 16:42:49.436 
Epoch 175/1000 
	 loss: 16.8105, MinusLogProbMetric: 16.8105, val_loss: 17.0835, val_MinusLogProbMetric: 17.0835

Epoch 175: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.8105 - MinusLogProbMetric: 16.8105 - val_loss: 17.0835 - val_MinusLogProbMetric: 17.0835 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 176/1000
2023-09-23 16:43:22.431 
Epoch 176/1000 
	 loss: 16.8270, MinusLogProbMetric: 16.8270, val_loss: 17.5576, val_MinusLogProbMetric: 17.5576

Epoch 176: val_loss did not improve from 16.98988
196/196 - 33s - loss: 16.8270 - MinusLogProbMetric: 16.8270 - val_loss: 17.5576 - val_MinusLogProbMetric: 17.5576 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 177/1000
2023-09-23 16:43:55.287 
Epoch 177/1000 
	 loss: 16.8140, MinusLogProbMetric: 16.8140, val_loss: 16.9715, val_MinusLogProbMetric: 16.9715

Epoch 177: val_loss improved from 16.98988 to 16.97145, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 16.8140 - MinusLogProbMetric: 16.8140 - val_loss: 16.9715 - val_MinusLogProbMetric: 16.9715 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 178/1000
2023-09-23 16:44:29.066 
Epoch 178/1000 
	 loss: 16.8103, MinusLogProbMetric: 16.8103, val_loss: 16.9602, val_MinusLogProbMetric: 16.9602

Epoch 178: val_loss improved from 16.97145 to 16.96016, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 34s - loss: 16.8103 - MinusLogProbMetric: 16.8103 - val_loss: 16.9602 - val_MinusLogProbMetric: 16.9602 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 179/1000
2023-09-23 16:45:02.348 
Epoch 179/1000 
	 loss: 16.8004, MinusLogProbMetric: 16.8004, val_loss: 17.1327, val_MinusLogProbMetric: 17.1327

Epoch 179: val_loss did not improve from 16.96016
196/196 - 33s - loss: 16.8004 - MinusLogProbMetric: 16.8004 - val_loss: 17.1327 - val_MinusLogProbMetric: 17.1327 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 180/1000
2023-09-23 16:45:35.649 
Epoch 180/1000 
	 loss: 16.8371, MinusLogProbMetric: 16.8371, val_loss: 17.3390, val_MinusLogProbMetric: 17.3390

Epoch 180: val_loss did not improve from 16.96016
196/196 - 33s - loss: 16.8371 - MinusLogProbMetric: 16.8371 - val_loss: 17.3390 - val_MinusLogProbMetric: 17.3390 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 181/1000
2023-09-23 16:46:08.533 
Epoch 181/1000 
	 loss: 16.8109, MinusLogProbMetric: 16.8109, val_loss: 17.1953, val_MinusLogProbMetric: 17.1953

Epoch 181: val_loss did not improve from 16.96016
196/196 - 33s - loss: 16.8109 - MinusLogProbMetric: 16.8109 - val_loss: 17.1953 - val_MinusLogProbMetric: 17.1953 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 182/1000
2023-09-23 16:46:41.690 
Epoch 182/1000 
	 loss: 16.8355, MinusLogProbMetric: 16.8355, val_loss: 17.0340, val_MinusLogProbMetric: 17.0340

Epoch 182: val_loss did not improve from 16.96016
196/196 - 33s - loss: 16.8355 - MinusLogProbMetric: 16.8355 - val_loss: 17.0340 - val_MinusLogProbMetric: 17.0340 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 183/1000
2023-09-23 16:47:14.600 
Epoch 183/1000 
	 loss: 16.7924, MinusLogProbMetric: 16.7924, val_loss: 17.0078, val_MinusLogProbMetric: 17.0078

Epoch 183: val_loss did not improve from 16.96016
196/196 - 33s - loss: 16.7924 - MinusLogProbMetric: 16.7924 - val_loss: 17.0078 - val_MinusLogProbMetric: 17.0078 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 184/1000
2023-09-23 16:47:47.616 
Epoch 184/1000 
	 loss: 16.7646, MinusLogProbMetric: 16.7646, val_loss: 17.0612, val_MinusLogProbMetric: 17.0612

Epoch 184: val_loss did not improve from 16.96016
196/196 - 33s - loss: 16.7646 - MinusLogProbMetric: 16.7646 - val_loss: 17.0612 - val_MinusLogProbMetric: 17.0612 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 185/1000
2023-09-23 16:48:20.368 
Epoch 185/1000 
	 loss: 16.7438, MinusLogProbMetric: 16.7438, val_loss: 17.1092, val_MinusLogProbMetric: 17.1092

Epoch 185: val_loss did not improve from 16.96016
196/196 - 33s - loss: 16.7438 - MinusLogProbMetric: 16.7438 - val_loss: 17.1092 - val_MinusLogProbMetric: 17.1092 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 186/1000
2023-09-23 16:48:53.305 
Epoch 186/1000 
	 loss: 16.7845, MinusLogProbMetric: 16.7845, val_loss: 16.9807, val_MinusLogProbMetric: 16.9807

Epoch 186: val_loss did not improve from 16.96016
196/196 - 33s - loss: 16.7845 - MinusLogProbMetric: 16.7845 - val_loss: 16.9807 - val_MinusLogProbMetric: 16.9807 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 187/1000
2023-09-23 16:49:26.032 
Epoch 187/1000 
	 loss: 16.7728, MinusLogProbMetric: 16.7728, val_loss: 17.0232, val_MinusLogProbMetric: 17.0232

Epoch 187: val_loss did not improve from 16.96016
196/196 - 33s - loss: 16.7728 - MinusLogProbMetric: 16.7728 - val_loss: 17.0232 - val_MinusLogProbMetric: 17.0232 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 188/1000
2023-09-23 16:49:59.297 
Epoch 188/1000 
	 loss: 16.8121, MinusLogProbMetric: 16.8121, val_loss: 17.0639, val_MinusLogProbMetric: 17.0639

Epoch 188: val_loss did not improve from 16.96016
196/196 - 33s - loss: 16.8121 - MinusLogProbMetric: 16.8121 - val_loss: 17.0639 - val_MinusLogProbMetric: 17.0639 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 189/1000
2023-09-23 16:50:32.581 
Epoch 189/1000 
	 loss: 16.7635, MinusLogProbMetric: 16.7635, val_loss: 16.9844, val_MinusLogProbMetric: 16.9844

Epoch 189: val_loss did not improve from 16.96016
196/196 - 33s - loss: 16.7635 - MinusLogProbMetric: 16.7635 - val_loss: 16.9844 - val_MinusLogProbMetric: 16.9844 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 190/1000
2023-09-23 16:51:05.577 
Epoch 190/1000 
	 loss: 16.7771, MinusLogProbMetric: 16.7771, val_loss: 16.9482, val_MinusLogProbMetric: 16.9482

Epoch 190: val_loss improved from 16.96016 to 16.94816, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 34s - loss: 16.7771 - MinusLogProbMetric: 16.7771 - val_loss: 16.9482 - val_MinusLogProbMetric: 16.9482 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 191/1000
2023-09-23 16:51:39.112 
Epoch 191/1000 
	 loss: 16.7716, MinusLogProbMetric: 16.7716, val_loss: 17.0030, val_MinusLogProbMetric: 17.0030

Epoch 191: val_loss did not improve from 16.94816
196/196 - 33s - loss: 16.7716 - MinusLogProbMetric: 16.7716 - val_loss: 17.0030 - val_MinusLogProbMetric: 17.0030 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 192/1000
2023-09-23 16:52:12.374 
Epoch 192/1000 
	 loss: 16.7705, MinusLogProbMetric: 16.7705, val_loss: 17.0031, val_MinusLogProbMetric: 17.0031

Epoch 192: val_loss did not improve from 16.94816
196/196 - 33s - loss: 16.7705 - MinusLogProbMetric: 16.7705 - val_loss: 17.0031 - val_MinusLogProbMetric: 17.0031 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 193/1000
2023-09-23 16:52:45.512 
Epoch 193/1000 
	 loss: 16.7809, MinusLogProbMetric: 16.7809, val_loss: 17.1197, val_MinusLogProbMetric: 17.1197

Epoch 193: val_loss did not improve from 16.94816
196/196 - 33s - loss: 16.7809 - MinusLogProbMetric: 16.7809 - val_loss: 17.1197 - val_MinusLogProbMetric: 17.1197 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 194/1000
2023-09-23 16:53:18.687 
Epoch 194/1000 
	 loss: 16.7788, MinusLogProbMetric: 16.7788, val_loss: 17.0488, val_MinusLogProbMetric: 17.0488

Epoch 194: val_loss did not improve from 16.94816
196/196 - 33s - loss: 16.7788 - MinusLogProbMetric: 16.7788 - val_loss: 17.0488 - val_MinusLogProbMetric: 17.0488 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 195/1000
2023-09-23 16:53:51.696 
Epoch 195/1000 
	 loss: 16.7469, MinusLogProbMetric: 16.7469, val_loss: 17.1056, val_MinusLogProbMetric: 17.1056

Epoch 195: val_loss did not improve from 16.94816
196/196 - 33s - loss: 16.7469 - MinusLogProbMetric: 16.7469 - val_loss: 17.1056 - val_MinusLogProbMetric: 17.1056 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 196/1000
2023-09-23 16:54:24.636 
Epoch 196/1000 
	 loss: 16.7362, MinusLogProbMetric: 16.7362, val_loss: 17.0442, val_MinusLogProbMetric: 17.0442

Epoch 196: val_loss did not improve from 16.94816
196/196 - 33s - loss: 16.7362 - MinusLogProbMetric: 16.7362 - val_loss: 17.0442 - val_MinusLogProbMetric: 17.0442 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 197/1000
2023-09-23 16:54:57.941 
Epoch 197/1000 
	 loss: 16.7416, MinusLogProbMetric: 16.7416, val_loss: 17.0092, val_MinusLogProbMetric: 17.0092

Epoch 197: val_loss did not improve from 16.94816
196/196 - 33s - loss: 16.7416 - MinusLogProbMetric: 16.7416 - val_loss: 17.0092 - val_MinusLogProbMetric: 17.0092 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 198/1000
2023-09-23 16:55:31.275 
Epoch 198/1000 
	 loss: 16.7553, MinusLogProbMetric: 16.7553, val_loss: 17.0083, val_MinusLogProbMetric: 17.0083

Epoch 198: val_loss did not improve from 16.94816
196/196 - 33s - loss: 16.7553 - MinusLogProbMetric: 16.7553 - val_loss: 17.0083 - val_MinusLogProbMetric: 17.0083 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 199/1000
2023-09-23 16:56:04.649 
Epoch 199/1000 
	 loss: 16.7750, MinusLogProbMetric: 16.7750, val_loss: 16.9563, val_MinusLogProbMetric: 16.9563

Epoch 199: val_loss did not improve from 16.94816
196/196 - 33s - loss: 16.7750 - MinusLogProbMetric: 16.7750 - val_loss: 16.9563 - val_MinusLogProbMetric: 16.9563 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 200/1000
2023-09-23 16:56:38.044 
Epoch 200/1000 
	 loss: 16.7473, MinusLogProbMetric: 16.7473, val_loss: 16.9312, val_MinusLogProbMetric: 16.9312

Epoch 200: val_loss improved from 16.94816 to 16.93117, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 34s - loss: 16.7473 - MinusLogProbMetric: 16.7473 - val_loss: 16.9312 - val_MinusLogProbMetric: 16.9312 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 201/1000
2023-09-23 16:57:11.448 
Epoch 201/1000 
	 loss: 16.7430, MinusLogProbMetric: 16.7430, val_loss: 17.1654, val_MinusLogProbMetric: 17.1654

Epoch 201: val_loss did not improve from 16.93117
196/196 - 33s - loss: 16.7430 - MinusLogProbMetric: 16.7430 - val_loss: 17.1654 - val_MinusLogProbMetric: 17.1654 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 202/1000
2023-09-23 16:57:44.913 
Epoch 202/1000 
	 loss: 16.7800, MinusLogProbMetric: 16.7800, val_loss: 17.1609, val_MinusLogProbMetric: 17.1609

Epoch 202: val_loss did not improve from 16.93117
196/196 - 33s - loss: 16.7800 - MinusLogProbMetric: 16.7800 - val_loss: 17.1609 - val_MinusLogProbMetric: 17.1609 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 203/1000
2023-09-23 16:58:18.017 
Epoch 203/1000 
	 loss: 16.7610, MinusLogProbMetric: 16.7610, val_loss: 16.9629, val_MinusLogProbMetric: 16.9629

Epoch 203: val_loss did not improve from 16.93117
196/196 - 33s - loss: 16.7610 - MinusLogProbMetric: 16.7610 - val_loss: 16.9629 - val_MinusLogProbMetric: 16.9629 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 204/1000
2023-09-23 16:58:51.366 
Epoch 204/1000 
	 loss: 16.7562, MinusLogProbMetric: 16.7562, val_loss: 17.2509, val_MinusLogProbMetric: 17.2509

Epoch 204: val_loss did not improve from 16.93117
196/196 - 33s - loss: 16.7562 - MinusLogProbMetric: 16.7562 - val_loss: 17.2509 - val_MinusLogProbMetric: 17.2509 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 205/1000
2023-09-23 16:59:24.396 
Epoch 205/1000 
	 loss: 16.7181, MinusLogProbMetric: 16.7181, val_loss: 17.0825, val_MinusLogProbMetric: 17.0825

Epoch 205: val_loss did not improve from 16.93117
196/196 - 33s - loss: 16.7181 - MinusLogProbMetric: 16.7181 - val_loss: 17.0825 - val_MinusLogProbMetric: 17.0825 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 206/1000
2023-09-23 16:59:57.565 
Epoch 206/1000 
	 loss: 16.8196, MinusLogProbMetric: 16.8196, val_loss: 17.1213, val_MinusLogProbMetric: 17.1213

Epoch 206: val_loss did not improve from 16.93117
196/196 - 33s - loss: 16.8196 - MinusLogProbMetric: 16.8196 - val_loss: 17.1213 - val_MinusLogProbMetric: 17.1213 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 207/1000
2023-09-23 17:00:30.840 
Epoch 207/1000 
	 loss: 16.7248, MinusLogProbMetric: 16.7248, val_loss: 17.1135, val_MinusLogProbMetric: 17.1135

Epoch 207: val_loss did not improve from 16.93117
196/196 - 33s - loss: 16.7248 - MinusLogProbMetric: 16.7248 - val_loss: 17.1135 - val_MinusLogProbMetric: 17.1135 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 208/1000
2023-09-23 17:01:04.207 
Epoch 208/1000 
	 loss: 16.7559, MinusLogProbMetric: 16.7559, val_loss: 16.9400, val_MinusLogProbMetric: 16.9400

Epoch 208: val_loss did not improve from 16.93117
196/196 - 33s - loss: 16.7559 - MinusLogProbMetric: 16.7559 - val_loss: 16.9400 - val_MinusLogProbMetric: 16.9400 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 209/1000
2023-09-23 17:01:37.247 
Epoch 209/1000 
	 loss: 16.7291, MinusLogProbMetric: 16.7291, val_loss: 17.0148, val_MinusLogProbMetric: 17.0148

Epoch 209: val_loss did not improve from 16.93117
196/196 - 33s - loss: 16.7291 - MinusLogProbMetric: 16.7291 - val_loss: 17.0148 - val_MinusLogProbMetric: 17.0148 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 210/1000
2023-09-23 17:02:10.512 
Epoch 210/1000 
	 loss: 16.7481, MinusLogProbMetric: 16.7481, val_loss: 17.2635, val_MinusLogProbMetric: 17.2635

Epoch 210: val_loss did not improve from 16.93117
196/196 - 33s - loss: 16.7481 - MinusLogProbMetric: 16.7481 - val_loss: 17.2635 - val_MinusLogProbMetric: 17.2635 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 211/1000
2023-09-23 17:02:43.956 
Epoch 211/1000 
	 loss: 16.7449, MinusLogProbMetric: 16.7449, val_loss: 17.1130, val_MinusLogProbMetric: 17.1130

Epoch 211: val_loss did not improve from 16.93117
196/196 - 33s - loss: 16.7449 - MinusLogProbMetric: 16.7449 - val_loss: 17.1130 - val_MinusLogProbMetric: 17.1130 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 212/1000
2023-09-23 17:03:17.146 
Epoch 212/1000 
	 loss: 16.7306, MinusLogProbMetric: 16.7306, val_loss: 17.0368, val_MinusLogProbMetric: 17.0368

Epoch 212: val_loss did not improve from 16.93117
196/196 - 33s - loss: 16.7306 - MinusLogProbMetric: 16.7306 - val_loss: 17.0368 - val_MinusLogProbMetric: 17.0368 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 213/1000
2023-09-23 17:03:50.249 
Epoch 213/1000 
	 loss: 16.7046, MinusLogProbMetric: 16.7046, val_loss: 17.1063, val_MinusLogProbMetric: 17.1063

Epoch 213: val_loss did not improve from 16.93117
196/196 - 33s - loss: 16.7046 - MinusLogProbMetric: 16.7046 - val_loss: 17.1063 - val_MinusLogProbMetric: 17.1063 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 214/1000
2023-09-23 17:04:23.377 
Epoch 214/1000 
	 loss: 16.7325, MinusLogProbMetric: 16.7325, val_loss: 17.0105, val_MinusLogProbMetric: 17.0105

Epoch 214: val_loss did not improve from 16.93117
196/196 - 33s - loss: 16.7325 - MinusLogProbMetric: 16.7325 - val_loss: 17.0105 - val_MinusLogProbMetric: 17.0105 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 215/1000
2023-09-23 17:04:56.540 
Epoch 215/1000 
	 loss: 16.7358, MinusLogProbMetric: 16.7358, val_loss: 17.0723, val_MinusLogProbMetric: 17.0723

Epoch 215: val_loss did not improve from 16.93117
196/196 - 33s - loss: 16.7358 - MinusLogProbMetric: 16.7358 - val_loss: 17.0723 - val_MinusLogProbMetric: 17.0723 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 216/1000
2023-09-23 17:05:29.538 
Epoch 216/1000 
	 loss: 16.7071, MinusLogProbMetric: 16.7071, val_loss: 16.9651, val_MinusLogProbMetric: 16.9651

Epoch 216: val_loss did not improve from 16.93117
196/196 - 33s - loss: 16.7071 - MinusLogProbMetric: 16.7071 - val_loss: 16.9651 - val_MinusLogProbMetric: 16.9651 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 217/1000
2023-09-23 17:06:02.330 
Epoch 217/1000 
	 loss: 16.7041, MinusLogProbMetric: 16.7041, val_loss: 16.9435, val_MinusLogProbMetric: 16.9435

Epoch 217: val_loss did not improve from 16.93117
196/196 - 33s - loss: 16.7041 - MinusLogProbMetric: 16.7041 - val_loss: 16.9435 - val_MinusLogProbMetric: 16.9435 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 218/1000
2023-09-23 17:06:35.428 
Epoch 218/1000 
	 loss: 16.7044, MinusLogProbMetric: 16.7044, val_loss: 17.0714, val_MinusLogProbMetric: 17.0714

Epoch 218: val_loss did not improve from 16.93117
196/196 - 33s - loss: 16.7044 - MinusLogProbMetric: 16.7044 - val_loss: 17.0714 - val_MinusLogProbMetric: 17.0714 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 219/1000
2023-09-23 17:07:08.465 
Epoch 219/1000 
	 loss: 16.7318, MinusLogProbMetric: 16.7318, val_loss: 17.2262, val_MinusLogProbMetric: 17.2262

Epoch 219: val_loss did not improve from 16.93117
196/196 - 33s - loss: 16.7318 - MinusLogProbMetric: 16.7318 - val_loss: 17.2262 - val_MinusLogProbMetric: 17.2262 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 220/1000
2023-09-23 17:07:41.814 
Epoch 220/1000 
	 loss: 16.7166, MinusLogProbMetric: 16.7166, val_loss: 17.1079, val_MinusLogProbMetric: 17.1079

Epoch 220: val_loss did not improve from 16.93117
196/196 - 33s - loss: 16.7166 - MinusLogProbMetric: 16.7166 - val_loss: 17.1079 - val_MinusLogProbMetric: 17.1079 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 221/1000
2023-09-23 17:08:14.568 
Epoch 221/1000 
	 loss: 16.6883, MinusLogProbMetric: 16.6883, val_loss: 16.9232, val_MinusLogProbMetric: 16.9232

Epoch 221: val_loss improved from 16.93117 to 16.92324, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 16.6883 - MinusLogProbMetric: 16.6883 - val_loss: 16.9232 - val_MinusLogProbMetric: 16.9232 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 222/1000
2023-09-23 17:08:47.858 
Epoch 222/1000 
	 loss: 16.7180, MinusLogProbMetric: 16.7180, val_loss: 16.9723, val_MinusLogProbMetric: 16.9723

Epoch 222: val_loss did not improve from 16.92324
196/196 - 33s - loss: 16.7180 - MinusLogProbMetric: 16.7180 - val_loss: 16.9723 - val_MinusLogProbMetric: 16.9723 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 223/1000
2023-09-23 17:09:21.260 
Epoch 223/1000 
	 loss: 16.6986, MinusLogProbMetric: 16.6986, val_loss: 17.4249, val_MinusLogProbMetric: 17.4249

Epoch 223: val_loss did not improve from 16.92324
196/196 - 33s - loss: 16.6986 - MinusLogProbMetric: 16.6986 - val_loss: 17.4249 - val_MinusLogProbMetric: 17.4249 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 224/1000
2023-09-23 17:09:54.593 
Epoch 224/1000 
	 loss: 16.7270, MinusLogProbMetric: 16.7270, val_loss: 17.1428, val_MinusLogProbMetric: 17.1428

Epoch 224: val_loss did not improve from 16.92324
196/196 - 33s - loss: 16.7270 - MinusLogProbMetric: 16.7270 - val_loss: 17.1428 - val_MinusLogProbMetric: 17.1428 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 225/1000
2023-09-23 17:10:27.950 
Epoch 225/1000 
	 loss: 16.6775, MinusLogProbMetric: 16.6775, val_loss: 17.0527, val_MinusLogProbMetric: 17.0527

Epoch 225: val_loss did not improve from 16.92324
196/196 - 33s - loss: 16.6775 - MinusLogProbMetric: 16.6775 - val_loss: 17.0527 - val_MinusLogProbMetric: 17.0527 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 226/1000
2023-09-23 17:11:01.001 
Epoch 226/1000 
	 loss: 16.7222, MinusLogProbMetric: 16.7222, val_loss: 16.9488, val_MinusLogProbMetric: 16.9488

Epoch 226: val_loss did not improve from 16.92324
196/196 - 33s - loss: 16.7222 - MinusLogProbMetric: 16.7222 - val_loss: 16.9488 - val_MinusLogProbMetric: 16.9488 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 227/1000
2023-09-23 17:11:34.263 
Epoch 227/1000 
	 loss: 16.6875, MinusLogProbMetric: 16.6875, val_loss: 16.9564, val_MinusLogProbMetric: 16.9564

Epoch 227: val_loss did not improve from 16.92324
196/196 - 33s - loss: 16.6875 - MinusLogProbMetric: 16.6875 - val_loss: 16.9564 - val_MinusLogProbMetric: 16.9564 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 228/1000
2023-09-23 17:12:07.508 
Epoch 228/1000 
	 loss: 16.7002, MinusLogProbMetric: 16.7002, val_loss: 17.0371, val_MinusLogProbMetric: 17.0371

Epoch 228: val_loss did not improve from 16.92324
196/196 - 33s - loss: 16.7002 - MinusLogProbMetric: 16.7002 - val_loss: 17.0371 - val_MinusLogProbMetric: 17.0371 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 229/1000
2023-09-23 17:12:40.798 
Epoch 229/1000 
	 loss: 16.6818, MinusLogProbMetric: 16.6818, val_loss: 16.9323, val_MinusLogProbMetric: 16.9323

Epoch 229: val_loss did not improve from 16.92324
196/196 - 33s - loss: 16.6818 - MinusLogProbMetric: 16.6818 - val_loss: 16.9323 - val_MinusLogProbMetric: 16.9323 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 230/1000
2023-09-23 17:13:14.094 
Epoch 230/1000 
	 loss: 16.6785, MinusLogProbMetric: 16.6785, val_loss: 16.9145, val_MinusLogProbMetric: 16.9145

Epoch 230: val_loss improved from 16.92324 to 16.91454, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 34s - loss: 16.6785 - MinusLogProbMetric: 16.6785 - val_loss: 16.9145 - val_MinusLogProbMetric: 16.9145 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 231/1000
2023-09-23 17:13:47.822 
Epoch 231/1000 
	 loss: 16.7033, MinusLogProbMetric: 16.7033, val_loss: 16.9383, val_MinusLogProbMetric: 16.9383

Epoch 231: val_loss did not improve from 16.91454
196/196 - 33s - loss: 16.7033 - MinusLogProbMetric: 16.7033 - val_loss: 16.9383 - val_MinusLogProbMetric: 16.9383 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 232/1000
2023-09-23 17:14:20.739 
Epoch 232/1000 
	 loss: 16.7308, MinusLogProbMetric: 16.7308, val_loss: 17.1761, val_MinusLogProbMetric: 17.1761

Epoch 232: val_loss did not improve from 16.91454
196/196 - 33s - loss: 16.7308 - MinusLogProbMetric: 16.7308 - val_loss: 17.1761 - val_MinusLogProbMetric: 17.1761 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 233/1000
2023-09-23 17:14:53.876 
Epoch 233/1000 
	 loss: 16.7135, MinusLogProbMetric: 16.7135, val_loss: 17.0140, val_MinusLogProbMetric: 17.0140

Epoch 233: val_loss did not improve from 16.91454
196/196 - 33s - loss: 16.7135 - MinusLogProbMetric: 16.7135 - val_loss: 17.0140 - val_MinusLogProbMetric: 17.0140 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 234/1000
2023-09-23 17:15:27.102 
Epoch 234/1000 
	 loss: 16.6866, MinusLogProbMetric: 16.6866, val_loss: 16.9762, val_MinusLogProbMetric: 16.9762

Epoch 234: val_loss did not improve from 16.91454
196/196 - 33s - loss: 16.6866 - MinusLogProbMetric: 16.6866 - val_loss: 16.9762 - val_MinusLogProbMetric: 16.9762 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 235/1000
2023-09-23 17:16:00.321 
Epoch 235/1000 
	 loss: 16.6898, MinusLogProbMetric: 16.6898, val_loss: 16.9581, val_MinusLogProbMetric: 16.9581

Epoch 235: val_loss did not improve from 16.91454
196/196 - 33s - loss: 16.6898 - MinusLogProbMetric: 16.6898 - val_loss: 16.9581 - val_MinusLogProbMetric: 16.9581 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 236/1000
2023-09-23 17:16:33.479 
Epoch 236/1000 
	 loss: 16.6717, MinusLogProbMetric: 16.6717, val_loss: 16.9946, val_MinusLogProbMetric: 16.9946

Epoch 236: val_loss did not improve from 16.91454
196/196 - 33s - loss: 16.6717 - MinusLogProbMetric: 16.6717 - val_loss: 16.9946 - val_MinusLogProbMetric: 16.9946 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 237/1000
2023-09-23 17:17:06.648 
Epoch 237/1000 
	 loss: 16.6980, MinusLogProbMetric: 16.6980, val_loss: 16.9600, val_MinusLogProbMetric: 16.9600

Epoch 237: val_loss did not improve from 16.91454
196/196 - 33s - loss: 16.6980 - MinusLogProbMetric: 16.6980 - val_loss: 16.9600 - val_MinusLogProbMetric: 16.9600 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 238/1000
2023-09-23 17:17:39.954 
Epoch 238/1000 
	 loss: 16.6670, MinusLogProbMetric: 16.6670, val_loss: 17.1911, val_MinusLogProbMetric: 17.1911

Epoch 238: val_loss did not improve from 16.91454
196/196 - 33s - loss: 16.6670 - MinusLogProbMetric: 16.6670 - val_loss: 17.1911 - val_MinusLogProbMetric: 17.1911 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 239/1000
2023-09-23 17:18:13.349 
Epoch 239/1000 
	 loss: 16.6911, MinusLogProbMetric: 16.6911, val_loss: 17.0100, val_MinusLogProbMetric: 17.0100

Epoch 239: val_loss did not improve from 16.91454
196/196 - 33s - loss: 16.6911 - MinusLogProbMetric: 16.6911 - val_loss: 17.0100 - val_MinusLogProbMetric: 17.0100 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 240/1000
2023-09-23 17:18:46.716 
Epoch 240/1000 
	 loss: 16.6820, MinusLogProbMetric: 16.6820, val_loss: 17.1510, val_MinusLogProbMetric: 17.1510

Epoch 240: val_loss did not improve from 16.91454
196/196 - 33s - loss: 16.6820 - MinusLogProbMetric: 16.6820 - val_loss: 17.1510 - val_MinusLogProbMetric: 17.1510 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 241/1000
2023-09-23 17:19:19.792 
Epoch 241/1000 
	 loss: 16.6957, MinusLogProbMetric: 16.6957, val_loss: 17.0038, val_MinusLogProbMetric: 17.0038

Epoch 241: val_loss did not improve from 16.91454
196/196 - 33s - loss: 16.6957 - MinusLogProbMetric: 16.6957 - val_loss: 17.0038 - val_MinusLogProbMetric: 17.0038 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 242/1000
2023-09-23 17:19:53.066 
Epoch 242/1000 
	 loss: 16.6745, MinusLogProbMetric: 16.6745, val_loss: 16.9640, val_MinusLogProbMetric: 16.9640

Epoch 242: val_loss did not improve from 16.91454
196/196 - 33s - loss: 16.6745 - MinusLogProbMetric: 16.6745 - val_loss: 16.9640 - val_MinusLogProbMetric: 16.9640 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 243/1000
2023-09-23 17:20:25.971 
Epoch 243/1000 
	 loss: 16.6611, MinusLogProbMetric: 16.6611, val_loss: 16.9160, val_MinusLogProbMetric: 16.9160

Epoch 243: val_loss did not improve from 16.91454
196/196 - 33s - loss: 16.6611 - MinusLogProbMetric: 16.6611 - val_loss: 16.9160 - val_MinusLogProbMetric: 16.9160 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 244/1000
2023-09-23 17:20:58.813 
Epoch 244/1000 
	 loss: 16.6671, MinusLogProbMetric: 16.6671, val_loss: 16.9374, val_MinusLogProbMetric: 16.9374

Epoch 244: val_loss did not improve from 16.91454
196/196 - 33s - loss: 16.6671 - MinusLogProbMetric: 16.6671 - val_loss: 16.9374 - val_MinusLogProbMetric: 16.9374 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 245/1000
2023-09-23 17:21:31.863 
Epoch 245/1000 
	 loss: 16.6517, MinusLogProbMetric: 16.6517, val_loss: 17.1424, val_MinusLogProbMetric: 17.1424

Epoch 245: val_loss did not improve from 16.91454
196/196 - 33s - loss: 16.6517 - MinusLogProbMetric: 16.6517 - val_loss: 17.1424 - val_MinusLogProbMetric: 17.1424 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 246/1000
2023-09-23 17:22:04.783 
Epoch 246/1000 
	 loss: 16.6802, MinusLogProbMetric: 16.6802, val_loss: 17.2697, val_MinusLogProbMetric: 17.2697

Epoch 246: val_loss did not improve from 16.91454
196/196 - 33s - loss: 16.6802 - MinusLogProbMetric: 16.6802 - val_loss: 17.2697 - val_MinusLogProbMetric: 17.2697 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 247/1000
2023-09-23 17:22:37.637 
Epoch 247/1000 
	 loss: 16.6951, MinusLogProbMetric: 16.6951, val_loss: 17.1196, val_MinusLogProbMetric: 17.1196

Epoch 247: val_loss did not improve from 16.91454
196/196 - 33s - loss: 16.6951 - MinusLogProbMetric: 16.6951 - val_loss: 17.1196 - val_MinusLogProbMetric: 17.1196 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 248/1000
2023-09-23 17:23:10.278 
Epoch 248/1000 
	 loss: 16.6582, MinusLogProbMetric: 16.6582, val_loss: 17.4138, val_MinusLogProbMetric: 17.4138

Epoch 248: val_loss did not improve from 16.91454
196/196 - 33s - loss: 16.6582 - MinusLogProbMetric: 16.6582 - val_loss: 17.4138 - val_MinusLogProbMetric: 17.4138 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 249/1000
2023-09-23 17:23:43.051 
Epoch 249/1000 
	 loss: 16.6475, MinusLogProbMetric: 16.6475, val_loss: 16.9026, val_MinusLogProbMetric: 16.9026

Epoch 249: val_loss improved from 16.91454 to 16.90260, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 16.6475 - MinusLogProbMetric: 16.6475 - val_loss: 16.9026 - val_MinusLogProbMetric: 16.9026 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 250/1000
2023-09-23 17:24:16.852 
Epoch 250/1000 
	 loss: 16.6628, MinusLogProbMetric: 16.6628, val_loss: 17.0683, val_MinusLogProbMetric: 17.0683

Epoch 250: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6628 - MinusLogProbMetric: 16.6628 - val_loss: 17.0683 - val_MinusLogProbMetric: 17.0683 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 251/1000
2023-09-23 17:24:49.997 
Epoch 251/1000 
	 loss: 16.6341, MinusLogProbMetric: 16.6341, val_loss: 17.1145, val_MinusLogProbMetric: 17.1145

Epoch 251: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6341 - MinusLogProbMetric: 16.6341 - val_loss: 17.1145 - val_MinusLogProbMetric: 17.1145 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 252/1000
2023-09-23 17:25:23.149 
Epoch 252/1000 
	 loss: 16.6669, MinusLogProbMetric: 16.6669, val_loss: 17.0743, val_MinusLogProbMetric: 17.0743

Epoch 252: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6669 - MinusLogProbMetric: 16.6669 - val_loss: 17.0743 - val_MinusLogProbMetric: 17.0743 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 253/1000
2023-09-23 17:25:56.033 
Epoch 253/1000 
	 loss: 16.6652, MinusLogProbMetric: 16.6652, val_loss: 17.0390, val_MinusLogProbMetric: 17.0390

Epoch 253: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6652 - MinusLogProbMetric: 16.6652 - val_loss: 17.0390 - val_MinusLogProbMetric: 17.0390 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 254/1000
2023-09-23 17:26:28.126 
Epoch 254/1000 
	 loss: 16.6732, MinusLogProbMetric: 16.6732, val_loss: 16.9937, val_MinusLogProbMetric: 16.9937

Epoch 254: val_loss did not improve from 16.90260
196/196 - 32s - loss: 16.6732 - MinusLogProbMetric: 16.6732 - val_loss: 16.9937 - val_MinusLogProbMetric: 16.9937 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 255/1000
2023-09-23 17:27:05.214 
Epoch 255/1000 
	 loss: 16.6460, MinusLogProbMetric: 16.6460, val_loss: 17.0645, val_MinusLogProbMetric: 17.0645

Epoch 255: val_loss did not improve from 16.90260
196/196 - 37s - loss: 16.6460 - MinusLogProbMetric: 16.6460 - val_loss: 17.0645 - val_MinusLogProbMetric: 17.0645 - lr: 0.0010 - 37s/epoch - 189ms/step
Epoch 256/1000
2023-09-23 17:27:37.237 
Epoch 256/1000 
	 loss: 16.6216, MinusLogProbMetric: 16.6216, val_loss: 17.3766, val_MinusLogProbMetric: 17.3766

Epoch 256: val_loss did not improve from 16.90260
196/196 - 32s - loss: 16.6216 - MinusLogProbMetric: 16.6216 - val_loss: 17.3766 - val_MinusLogProbMetric: 17.3766 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 257/1000
2023-09-23 17:28:09.946 
Epoch 257/1000 
	 loss: 16.6561, MinusLogProbMetric: 16.6561, val_loss: 16.9894, val_MinusLogProbMetric: 16.9894

Epoch 257: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6561 - MinusLogProbMetric: 16.6561 - val_loss: 16.9894 - val_MinusLogProbMetric: 16.9894 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 258/1000
2023-09-23 17:28:42.983 
Epoch 258/1000 
	 loss: 16.6411, MinusLogProbMetric: 16.6411, val_loss: 17.0957, val_MinusLogProbMetric: 17.0957

Epoch 258: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6411 - MinusLogProbMetric: 16.6411 - val_loss: 17.0957 - val_MinusLogProbMetric: 17.0957 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 259/1000
2023-09-23 17:29:15.676 
Epoch 259/1000 
	 loss: 16.6451, MinusLogProbMetric: 16.6451, val_loss: 17.0084, val_MinusLogProbMetric: 17.0084

Epoch 259: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6451 - MinusLogProbMetric: 16.6451 - val_loss: 17.0084 - val_MinusLogProbMetric: 17.0084 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 260/1000
2023-09-23 17:29:48.466 
Epoch 260/1000 
	 loss: 16.6390, MinusLogProbMetric: 16.6390, val_loss: 16.9550, val_MinusLogProbMetric: 16.9550

Epoch 260: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6390 - MinusLogProbMetric: 16.6390 - val_loss: 16.9550 - val_MinusLogProbMetric: 16.9550 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 261/1000
2023-09-23 17:30:21.039 
Epoch 261/1000 
	 loss: 16.6172, MinusLogProbMetric: 16.6172, val_loss: 17.0627, val_MinusLogProbMetric: 17.0627

Epoch 261: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6172 - MinusLogProbMetric: 16.6172 - val_loss: 17.0627 - val_MinusLogProbMetric: 17.0627 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 262/1000
2023-09-23 17:30:53.675 
Epoch 262/1000 
	 loss: 16.6740, MinusLogProbMetric: 16.6740, val_loss: 17.1717, val_MinusLogProbMetric: 17.1717

Epoch 262: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6740 - MinusLogProbMetric: 16.6740 - val_loss: 17.1717 - val_MinusLogProbMetric: 17.1717 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 263/1000
2023-09-23 17:31:26.519 
Epoch 263/1000 
	 loss: 16.6488, MinusLogProbMetric: 16.6488, val_loss: 17.0024, val_MinusLogProbMetric: 17.0024

Epoch 263: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6488 - MinusLogProbMetric: 16.6488 - val_loss: 17.0024 - val_MinusLogProbMetric: 17.0024 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 264/1000
2023-09-23 17:31:58.892 
Epoch 264/1000 
	 loss: 16.6471, MinusLogProbMetric: 16.6471, val_loss: 16.9530, val_MinusLogProbMetric: 16.9530

Epoch 264: val_loss did not improve from 16.90260
196/196 - 32s - loss: 16.6471 - MinusLogProbMetric: 16.6471 - val_loss: 16.9530 - val_MinusLogProbMetric: 16.9530 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 265/1000
2023-09-23 17:32:31.652 
Epoch 265/1000 
	 loss: 16.6497, MinusLogProbMetric: 16.6497, val_loss: 16.9841, val_MinusLogProbMetric: 16.9841

Epoch 265: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6497 - MinusLogProbMetric: 16.6497 - val_loss: 16.9841 - val_MinusLogProbMetric: 16.9841 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 266/1000
2023-09-23 17:33:04.682 
Epoch 266/1000 
	 loss: 16.6608, MinusLogProbMetric: 16.6608, val_loss: 17.0752, val_MinusLogProbMetric: 17.0752

Epoch 266: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6608 - MinusLogProbMetric: 16.6608 - val_loss: 17.0752 - val_MinusLogProbMetric: 17.0752 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 267/1000
2023-09-23 17:33:37.664 
Epoch 267/1000 
	 loss: 16.6420, MinusLogProbMetric: 16.6420, val_loss: 17.0102, val_MinusLogProbMetric: 17.0102

Epoch 267: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6420 - MinusLogProbMetric: 16.6420 - val_loss: 17.0102 - val_MinusLogProbMetric: 17.0102 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 268/1000
2023-09-23 17:34:10.371 
Epoch 268/1000 
	 loss: 16.6515, MinusLogProbMetric: 16.6515, val_loss: 17.0159, val_MinusLogProbMetric: 17.0159

Epoch 268: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6515 - MinusLogProbMetric: 16.6515 - val_loss: 17.0159 - val_MinusLogProbMetric: 17.0159 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 269/1000
2023-09-23 17:34:43.207 
Epoch 269/1000 
	 loss: 16.6231, MinusLogProbMetric: 16.6231, val_loss: 16.9178, val_MinusLogProbMetric: 16.9178

Epoch 269: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6231 - MinusLogProbMetric: 16.6231 - val_loss: 16.9178 - val_MinusLogProbMetric: 16.9178 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 270/1000
2023-09-23 17:35:15.973 
Epoch 270/1000 
	 loss: 16.6430, MinusLogProbMetric: 16.6430, val_loss: 16.9408, val_MinusLogProbMetric: 16.9408

Epoch 270: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6430 - MinusLogProbMetric: 16.6430 - val_loss: 16.9408 - val_MinusLogProbMetric: 16.9408 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 271/1000
2023-09-23 17:35:48.668 
Epoch 271/1000 
	 loss: 16.6114, MinusLogProbMetric: 16.6114, val_loss: 17.0750, val_MinusLogProbMetric: 17.0750

Epoch 271: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6114 - MinusLogProbMetric: 16.6114 - val_loss: 17.0750 - val_MinusLogProbMetric: 17.0750 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 272/1000
2023-09-23 17:36:21.462 
Epoch 272/1000 
	 loss: 16.6750, MinusLogProbMetric: 16.6750, val_loss: 16.9402, val_MinusLogProbMetric: 16.9402

Epoch 272: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6750 - MinusLogProbMetric: 16.6750 - val_loss: 16.9402 - val_MinusLogProbMetric: 16.9402 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 273/1000
2023-09-23 17:36:54.448 
Epoch 273/1000 
	 loss: 16.6156, MinusLogProbMetric: 16.6156, val_loss: 16.9906, val_MinusLogProbMetric: 16.9906

Epoch 273: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6156 - MinusLogProbMetric: 16.6156 - val_loss: 16.9906 - val_MinusLogProbMetric: 16.9906 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 274/1000
2023-09-23 17:37:27.598 
Epoch 274/1000 
	 loss: 16.6446, MinusLogProbMetric: 16.6446, val_loss: 17.0483, val_MinusLogProbMetric: 17.0483

Epoch 274: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6446 - MinusLogProbMetric: 16.6446 - val_loss: 17.0483 - val_MinusLogProbMetric: 17.0483 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 275/1000
2023-09-23 17:38:00.779 
Epoch 275/1000 
	 loss: 16.6348, MinusLogProbMetric: 16.6348, val_loss: 17.0374, val_MinusLogProbMetric: 17.0374

Epoch 275: val_loss did not improve from 16.90260
196/196 - 33s - loss: 16.6348 - MinusLogProbMetric: 16.6348 - val_loss: 17.0374 - val_MinusLogProbMetric: 17.0374 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 276/1000
2023-09-23 17:38:33.795 
Epoch 276/1000 
	 loss: 16.6139, MinusLogProbMetric: 16.6139, val_loss: 16.8933, val_MinusLogProbMetric: 16.8933

Epoch 276: val_loss improved from 16.90260 to 16.89331, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 34s - loss: 16.6139 - MinusLogProbMetric: 16.6139 - val_loss: 16.8933 - val_MinusLogProbMetric: 16.8933 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 277/1000
2023-09-23 17:39:07.432 
Epoch 277/1000 
	 loss: 16.6005, MinusLogProbMetric: 16.6005, val_loss: 16.9219, val_MinusLogProbMetric: 16.9219

Epoch 277: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.6005 - MinusLogProbMetric: 16.6005 - val_loss: 16.9219 - val_MinusLogProbMetric: 16.9219 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 278/1000
2023-09-23 17:39:40.422 
Epoch 278/1000 
	 loss: 16.6266, MinusLogProbMetric: 16.6266, val_loss: 17.0426, val_MinusLogProbMetric: 17.0426

Epoch 278: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.6266 - MinusLogProbMetric: 16.6266 - val_loss: 17.0426 - val_MinusLogProbMetric: 17.0426 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 279/1000
2023-09-23 17:40:13.540 
Epoch 279/1000 
	 loss: 16.6117, MinusLogProbMetric: 16.6117, val_loss: 16.9582, val_MinusLogProbMetric: 16.9582

Epoch 279: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.6117 - MinusLogProbMetric: 16.6117 - val_loss: 16.9582 - val_MinusLogProbMetric: 16.9582 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 280/1000
2023-09-23 17:40:47.004 
Epoch 280/1000 
	 loss: 16.6448, MinusLogProbMetric: 16.6448, val_loss: 17.0372, val_MinusLogProbMetric: 17.0372

Epoch 280: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.6448 - MinusLogProbMetric: 16.6448 - val_loss: 17.0372 - val_MinusLogProbMetric: 17.0372 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 281/1000
2023-09-23 17:41:19.855 
Epoch 281/1000 
	 loss: 16.5901, MinusLogProbMetric: 16.5901, val_loss: 17.0730, val_MinusLogProbMetric: 17.0730

Epoch 281: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5901 - MinusLogProbMetric: 16.5901 - val_loss: 17.0730 - val_MinusLogProbMetric: 17.0730 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 282/1000
2023-09-23 17:41:53.250 
Epoch 282/1000 
	 loss: 16.6376, MinusLogProbMetric: 16.6376, val_loss: 16.9125, val_MinusLogProbMetric: 16.9125

Epoch 282: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.6376 - MinusLogProbMetric: 16.6376 - val_loss: 16.9125 - val_MinusLogProbMetric: 16.9125 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 283/1000
2023-09-23 17:42:26.419 
Epoch 283/1000 
	 loss: 16.6069, MinusLogProbMetric: 16.6069, val_loss: 16.9849, val_MinusLogProbMetric: 16.9849

Epoch 283: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.6069 - MinusLogProbMetric: 16.6069 - val_loss: 16.9849 - val_MinusLogProbMetric: 16.9849 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 284/1000
2023-09-23 17:42:59.825 
Epoch 284/1000 
	 loss: 16.6183, MinusLogProbMetric: 16.6183, val_loss: 17.0821, val_MinusLogProbMetric: 17.0821

Epoch 284: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.6183 - MinusLogProbMetric: 16.6183 - val_loss: 17.0821 - val_MinusLogProbMetric: 17.0821 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 285/1000
2023-09-23 17:43:32.909 
Epoch 285/1000 
	 loss: 16.6218, MinusLogProbMetric: 16.6218, val_loss: 17.0527, val_MinusLogProbMetric: 17.0527

Epoch 285: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.6218 - MinusLogProbMetric: 16.6218 - val_loss: 17.0527 - val_MinusLogProbMetric: 17.0527 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 286/1000
2023-09-23 17:44:06.267 
Epoch 286/1000 
	 loss: 16.6174, MinusLogProbMetric: 16.6174, val_loss: 16.9126, val_MinusLogProbMetric: 16.9126

Epoch 286: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.6174 - MinusLogProbMetric: 16.6174 - val_loss: 16.9126 - val_MinusLogProbMetric: 16.9126 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 287/1000
2023-09-23 17:44:39.283 
Epoch 287/1000 
	 loss: 16.6255, MinusLogProbMetric: 16.6255, val_loss: 16.9760, val_MinusLogProbMetric: 16.9760

Epoch 287: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.6255 - MinusLogProbMetric: 16.6255 - val_loss: 16.9760 - val_MinusLogProbMetric: 16.9760 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 288/1000
2023-09-23 17:45:12.302 
Epoch 288/1000 
	 loss: 16.6062, MinusLogProbMetric: 16.6062, val_loss: 16.9541, val_MinusLogProbMetric: 16.9541

Epoch 288: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.6062 - MinusLogProbMetric: 16.6062 - val_loss: 16.9541 - val_MinusLogProbMetric: 16.9541 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 289/1000
2023-09-23 17:45:45.293 
Epoch 289/1000 
	 loss: 16.5856, MinusLogProbMetric: 16.5856, val_loss: 16.9956, val_MinusLogProbMetric: 16.9956

Epoch 289: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5856 - MinusLogProbMetric: 16.5856 - val_loss: 16.9956 - val_MinusLogProbMetric: 16.9956 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 290/1000
2023-09-23 17:46:18.300 
Epoch 290/1000 
	 loss: 16.6567, MinusLogProbMetric: 16.6567, val_loss: 16.9472, val_MinusLogProbMetric: 16.9472

Epoch 290: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.6567 - MinusLogProbMetric: 16.6567 - val_loss: 16.9472 - val_MinusLogProbMetric: 16.9472 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 291/1000
2023-09-23 17:46:51.581 
Epoch 291/1000 
	 loss: 16.6103, MinusLogProbMetric: 16.6103, val_loss: 17.0227, val_MinusLogProbMetric: 17.0227

Epoch 291: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.6103 - MinusLogProbMetric: 16.6103 - val_loss: 17.0227 - val_MinusLogProbMetric: 17.0227 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 292/1000
2023-09-23 17:47:25.421 
Epoch 292/1000 
	 loss: 16.6185, MinusLogProbMetric: 16.6185, val_loss: 17.1418, val_MinusLogProbMetric: 17.1418

Epoch 292: val_loss did not improve from 16.89331
196/196 - 34s - loss: 16.6185 - MinusLogProbMetric: 16.6185 - val_loss: 17.1418 - val_MinusLogProbMetric: 17.1418 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 293/1000
2023-09-23 17:47:58.283 
Epoch 293/1000 
	 loss: 16.6131, MinusLogProbMetric: 16.6131, val_loss: 17.0786, val_MinusLogProbMetric: 17.0786

Epoch 293: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.6131 - MinusLogProbMetric: 16.6131 - val_loss: 17.0786 - val_MinusLogProbMetric: 17.0786 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 294/1000
2023-09-23 17:48:30.860 
Epoch 294/1000 
	 loss: 16.6036, MinusLogProbMetric: 16.6036, val_loss: 17.1338, val_MinusLogProbMetric: 17.1338

Epoch 294: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.6036 - MinusLogProbMetric: 16.6036 - val_loss: 17.1338 - val_MinusLogProbMetric: 17.1338 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 295/1000
2023-09-23 17:49:04.940 
Epoch 295/1000 
	 loss: 16.6059, MinusLogProbMetric: 16.6059, val_loss: 17.0930, val_MinusLogProbMetric: 17.0930

Epoch 295: val_loss did not improve from 16.89331
196/196 - 34s - loss: 16.6059 - MinusLogProbMetric: 16.6059 - val_loss: 17.0930 - val_MinusLogProbMetric: 17.0930 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 296/1000
2023-09-23 17:49:38.480 
Epoch 296/1000 
	 loss: 16.6214, MinusLogProbMetric: 16.6214, val_loss: 16.9313, val_MinusLogProbMetric: 16.9313

Epoch 296: val_loss did not improve from 16.89331
196/196 - 34s - loss: 16.6214 - MinusLogProbMetric: 16.6214 - val_loss: 16.9313 - val_MinusLogProbMetric: 16.9313 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 297/1000
2023-09-23 17:50:11.868 
Epoch 297/1000 
	 loss: 16.6027, MinusLogProbMetric: 16.6027, val_loss: 17.0582, val_MinusLogProbMetric: 17.0582

Epoch 297: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.6027 - MinusLogProbMetric: 16.6027 - val_loss: 17.0582 - val_MinusLogProbMetric: 17.0582 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 298/1000
2023-09-23 17:50:44.997 
Epoch 298/1000 
	 loss: 16.5909, MinusLogProbMetric: 16.5909, val_loss: 16.9293, val_MinusLogProbMetric: 16.9293

Epoch 298: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5909 - MinusLogProbMetric: 16.5909 - val_loss: 16.9293 - val_MinusLogProbMetric: 16.9293 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 299/1000
2023-09-23 17:51:17.792 
Epoch 299/1000 
	 loss: 16.5878, MinusLogProbMetric: 16.5878, val_loss: 17.0704, val_MinusLogProbMetric: 17.0704

Epoch 299: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5878 - MinusLogProbMetric: 16.5878 - val_loss: 17.0704 - val_MinusLogProbMetric: 17.0704 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 300/1000
2023-09-23 17:51:50.580 
Epoch 300/1000 
	 loss: 16.5816, MinusLogProbMetric: 16.5816, val_loss: 17.0030, val_MinusLogProbMetric: 17.0030

Epoch 300: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5816 - MinusLogProbMetric: 16.5816 - val_loss: 17.0030 - val_MinusLogProbMetric: 17.0030 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 301/1000
2023-09-23 17:52:23.607 
Epoch 301/1000 
	 loss: 16.5866, MinusLogProbMetric: 16.5866, val_loss: 16.9648, val_MinusLogProbMetric: 16.9648

Epoch 301: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5866 - MinusLogProbMetric: 16.5866 - val_loss: 16.9648 - val_MinusLogProbMetric: 16.9648 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 302/1000
2023-09-23 17:52:56.454 
Epoch 302/1000 
	 loss: 16.6231, MinusLogProbMetric: 16.6231, val_loss: 16.9506, val_MinusLogProbMetric: 16.9506

Epoch 302: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.6231 - MinusLogProbMetric: 16.6231 - val_loss: 16.9506 - val_MinusLogProbMetric: 16.9506 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 303/1000
2023-09-23 17:53:29.080 
Epoch 303/1000 
	 loss: 16.6018, MinusLogProbMetric: 16.6018, val_loss: 17.0333, val_MinusLogProbMetric: 17.0333

Epoch 303: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.6018 - MinusLogProbMetric: 16.6018 - val_loss: 17.0333 - val_MinusLogProbMetric: 17.0333 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 304/1000
2023-09-23 17:54:01.456 
Epoch 304/1000 
	 loss: 16.5919, MinusLogProbMetric: 16.5919, val_loss: 16.9655, val_MinusLogProbMetric: 16.9655

Epoch 304: val_loss did not improve from 16.89331
196/196 - 32s - loss: 16.5919 - MinusLogProbMetric: 16.5919 - val_loss: 16.9655 - val_MinusLogProbMetric: 16.9655 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 305/1000
2023-09-23 17:54:33.790 
Epoch 305/1000 
	 loss: 16.5881, MinusLogProbMetric: 16.5881, val_loss: 17.0747, val_MinusLogProbMetric: 17.0747

Epoch 305: val_loss did not improve from 16.89331
196/196 - 32s - loss: 16.5881 - MinusLogProbMetric: 16.5881 - val_loss: 17.0747 - val_MinusLogProbMetric: 17.0747 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 306/1000
2023-09-23 17:55:06.505 
Epoch 306/1000 
	 loss: 16.5925, MinusLogProbMetric: 16.5925, val_loss: 16.9369, val_MinusLogProbMetric: 16.9369

Epoch 306: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5925 - MinusLogProbMetric: 16.5925 - val_loss: 16.9369 - val_MinusLogProbMetric: 16.9369 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 307/1000
2023-09-23 17:55:39.039 
Epoch 307/1000 
	 loss: 16.5932, MinusLogProbMetric: 16.5932, val_loss: 17.0423, val_MinusLogProbMetric: 17.0423

Epoch 307: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5932 - MinusLogProbMetric: 16.5932 - val_loss: 17.0423 - val_MinusLogProbMetric: 17.0423 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 308/1000
2023-09-23 17:56:11.486 
Epoch 308/1000 
	 loss: 16.5956, MinusLogProbMetric: 16.5956, val_loss: 17.0595, val_MinusLogProbMetric: 17.0595

Epoch 308: val_loss did not improve from 16.89331
196/196 - 32s - loss: 16.5956 - MinusLogProbMetric: 16.5956 - val_loss: 17.0595 - val_MinusLogProbMetric: 17.0595 - lr: 0.0010 - 32s/epoch - 166ms/step
Epoch 309/1000
2023-09-23 17:56:44.225 
Epoch 309/1000 
	 loss: 16.5809, MinusLogProbMetric: 16.5809, val_loss: 17.0028, val_MinusLogProbMetric: 17.0028

Epoch 309: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5809 - MinusLogProbMetric: 16.5809 - val_loss: 17.0028 - val_MinusLogProbMetric: 17.0028 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 310/1000
2023-09-23 17:57:16.785 
Epoch 310/1000 
	 loss: 16.5754, MinusLogProbMetric: 16.5754, val_loss: 17.0084, val_MinusLogProbMetric: 17.0084

Epoch 310: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5754 - MinusLogProbMetric: 16.5754 - val_loss: 17.0084 - val_MinusLogProbMetric: 17.0084 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 311/1000
2023-09-23 17:57:49.634 
Epoch 311/1000 
	 loss: 16.5728, MinusLogProbMetric: 16.5728, val_loss: 16.9412, val_MinusLogProbMetric: 16.9412

Epoch 311: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5728 - MinusLogProbMetric: 16.5728 - val_loss: 16.9412 - val_MinusLogProbMetric: 16.9412 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 312/1000
2023-09-23 17:58:22.337 
Epoch 312/1000 
	 loss: 16.5722, MinusLogProbMetric: 16.5722, val_loss: 16.9580, val_MinusLogProbMetric: 16.9580

Epoch 312: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5722 - MinusLogProbMetric: 16.5722 - val_loss: 16.9580 - val_MinusLogProbMetric: 16.9580 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 313/1000
2023-09-23 17:58:54.782 
Epoch 313/1000 
	 loss: 16.5730, MinusLogProbMetric: 16.5730, val_loss: 16.9149, val_MinusLogProbMetric: 16.9149

Epoch 313: val_loss did not improve from 16.89331
196/196 - 32s - loss: 16.5730 - MinusLogProbMetric: 16.5730 - val_loss: 16.9149 - val_MinusLogProbMetric: 16.9149 - lr: 0.0010 - 32s/epoch - 166ms/step
Epoch 314/1000
2023-09-23 17:59:27.692 
Epoch 314/1000 
	 loss: 16.5724, MinusLogProbMetric: 16.5724, val_loss: 16.9035, val_MinusLogProbMetric: 16.9035

Epoch 314: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5724 - MinusLogProbMetric: 16.5724 - val_loss: 16.9035 - val_MinusLogProbMetric: 16.9035 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 315/1000
2023-09-23 18:00:00.881 
Epoch 315/1000 
	 loss: 16.5818, MinusLogProbMetric: 16.5818, val_loss: 16.9345, val_MinusLogProbMetric: 16.9345

Epoch 315: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5818 - MinusLogProbMetric: 16.5818 - val_loss: 16.9345 - val_MinusLogProbMetric: 16.9345 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 316/1000
2023-09-23 18:00:33.587 
Epoch 316/1000 
	 loss: 16.5845, MinusLogProbMetric: 16.5845, val_loss: 16.9540, val_MinusLogProbMetric: 16.9540

Epoch 316: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5845 - MinusLogProbMetric: 16.5845 - val_loss: 16.9540 - val_MinusLogProbMetric: 16.9540 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 317/1000
2023-09-23 18:01:06.203 
Epoch 317/1000 
	 loss: 16.5668, MinusLogProbMetric: 16.5668, val_loss: 17.1631, val_MinusLogProbMetric: 17.1631

Epoch 317: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5668 - MinusLogProbMetric: 16.5668 - val_loss: 17.1631 - val_MinusLogProbMetric: 17.1631 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 318/1000
2023-09-23 18:01:38.999 
Epoch 318/1000 
	 loss: 16.5953, MinusLogProbMetric: 16.5953, val_loss: 16.9450, val_MinusLogProbMetric: 16.9450

Epoch 318: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5953 - MinusLogProbMetric: 16.5953 - val_loss: 16.9450 - val_MinusLogProbMetric: 16.9450 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 319/1000
2023-09-23 18:02:11.845 
Epoch 319/1000 
	 loss: 16.5622, MinusLogProbMetric: 16.5622, val_loss: 17.4219, val_MinusLogProbMetric: 17.4219

Epoch 319: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5622 - MinusLogProbMetric: 16.5622 - val_loss: 17.4219 - val_MinusLogProbMetric: 17.4219 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 320/1000
2023-09-23 18:02:44.684 
Epoch 320/1000 
	 loss: 16.5883, MinusLogProbMetric: 16.5883, val_loss: 16.9313, val_MinusLogProbMetric: 16.9313

Epoch 320: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5883 - MinusLogProbMetric: 16.5883 - val_loss: 16.9313 - val_MinusLogProbMetric: 16.9313 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 321/1000
2023-09-23 18:03:17.780 
Epoch 321/1000 
	 loss: 16.5522, MinusLogProbMetric: 16.5522, val_loss: 17.0971, val_MinusLogProbMetric: 17.0971

Epoch 321: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5522 - MinusLogProbMetric: 16.5522 - val_loss: 17.0971 - val_MinusLogProbMetric: 17.0971 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 322/1000
2023-09-23 18:03:50.431 
Epoch 322/1000 
	 loss: 16.5629, MinusLogProbMetric: 16.5629, val_loss: 16.9011, val_MinusLogProbMetric: 16.9011

Epoch 322: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5629 - MinusLogProbMetric: 16.5629 - val_loss: 16.9011 - val_MinusLogProbMetric: 16.9011 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 323/1000
2023-09-23 18:04:23.064 
Epoch 323/1000 
	 loss: 16.5630, MinusLogProbMetric: 16.5630, val_loss: 16.9606, val_MinusLogProbMetric: 16.9606

Epoch 323: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5630 - MinusLogProbMetric: 16.5630 - val_loss: 16.9606 - val_MinusLogProbMetric: 16.9606 - lr: 0.0010 - 33s/epoch - 166ms/step
Epoch 324/1000
2023-09-23 18:04:55.811 
Epoch 324/1000 
	 loss: 16.5718, MinusLogProbMetric: 16.5718, val_loss: 17.0769, val_MinusLogProbMetric: 17.0769

Epoch 324: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5718 - MinusLogProbMetric: 16.5718 - val_loss: 17.0769 - val_MinusLogProbMetric: 17.0769 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 325/1000
2023-09-23 18:05:28.594 
Epoch 325/1000 
	 loss: 16.5745, MinusLogProbMetric: 16.5745, val_loss: 16.9480, val_MinusLogProbMetric: 16.9480

Epoch 325: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5745 - MinusLogProbMetric: 16.5745 - val_loss: 16.9480 - val_MinusLogProbMetric: 16.9480 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 326/1000
2023-09-23 18:06:01.636 
Epoch 326/1000 
	 loss: 16.5916, MinusLogProbMetric: 16.5916, val_loss: 16.9566, val_MinusLogProbMetric: 16.9566

Epoch 326: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.5916 - MinusLogProbMetric: 16.5916 - val_loss: 16.9566 - val_MinusLogProbMetric: 16.9566 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 327/1000
2023-09-23 18:06:34.356 
Epoch 327/1000 
	 loss: 16.4477, MinusLogProbMetric: 16.4477, val_loss: 16.8946, val_MinusLogProbMetric: 16.8946

Epoch 327: val_loss did not improve from 16.89331
196/196 - 33s - loss: 16.4477 - MinusLogProbMetric: 16.4477 - val_loss: 16.8946 - val_MinusLogProbMetric: 16.8946 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 328/1000
2023-09-23 18:07:07.010 
Epoch 328/1000 
	 loss: 16.4436, MinusLogProbMetric: 16.4436, val_loss: 16.8775, val_MinusLogProbMetric: 16.8775

Epoch 328: val_loss improved from 16.89331 to 16.87749, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 16.4436 - MinusLogProbMetric: 16.4436 - val_loss: 16.8775 - val_MinusLogProbMetric: 16.8775 - lr: 5.0000e-04 - 33s/epoch - 169ms/step
Epoch 329/1000
2023-09-23 18:07:40.250 
Epoch 329/1000 
	 loss: 16.4510, MinusLogProbMetric: 16.4510, val_loss: 16.8939, val_MinusLogProbMetric: 16.8939

Epoch 329: val_loss did not improve from 16.87749
196/196 - 33s - loss: 16.4510 - MinusLogProbMetric: 16.4510 - val_loss: 16.8939 - val_MinusLogProbMetric: 16.8939 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 330/1000
2023-09-23 18:08:12.975 
Epoch 330/1000 
	 loss: 16.4469, MinusLogProbMetric: 16.4469, val_loss: 16.8411, val_MinusLogProbMetric: 16.8411

Epoch 330: val_loss improved from 16.87749 to 16.84108, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_297/weights/best_weights.h5
196/196 - 33s - loss: 16.4469 - MinusLogProbMetric: 16.4469 - val_loss: 16.8411 - val_MinusLogProbMetric: 16.8411 - lr: 5.0000e-04 - 33s/epoch - 170ms/step
Epoch 331/1000
2023-09-23 18:08:46.333 
Epoch 331/1000 
	 loss: 16.4414, MinusLogProbMetric: 16.4414, val_loss: 16.8723, val_MinusLogProbMetric: 16.8723

Epoch 331: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4414 - MinusLogProbMetric: 16.4414 - val_loss: 16.8723 - val_MinusLogProbMetric: 16.8723 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 332/1000
2023-09-23 18:09:19.182 
Epoch 332/1000 
	 loss: 16.4340, MinusLogProbMetric: 16.4340, val_loss: 16.8782, val_MinusLogProbMetric: 16.8782

Epoch 332: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4340 - MinusLogProbMetric: 16.4340 - val_loss: 16.8782 - val_MinusLogProbMetric: 16.8782 - lr: 5.0000e-04 - 33s/epoch - 168ms/step
Epoch 333/1000
2023-09-23 18:09:51.959 
Epoch 333/1000 
	 loss: 16.4303, MinusLogProbMetric: 16.4303, val_loss: 16.8567, val_MinusLogProbMetric: 16.8567

Epoch 333: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4303 - MinusLogProbMetric: 16.4303 - val_loss: 16.8567 - val_MinusLogProbMetric: 16.8567 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 334/1000
2023-09-23 18:10:24.391 
Epoch 334/1000 
	 loss: 16.4318, MinusLogProbMetric: 16.4318, val_loss: 16.8818, val_MinusLogProbMetric: 16.8818

Epoch 334: val_loss did not improve from 16.84108
196/196 - 32s - loss: 16.4318 - MinusLogProbMetric: 16.4318 - val_loss: 16.8818 - val_MinusLogProbMetric: 16.8818 - lr: 5.0000e-04 - 32s/epoch - 165ms/step
Epoch 335/1000
2023-09-23 18:10:57.342 
Epoch 335/1000 
	 loss: 16.4361, MinusLogProbMetric: 16.4361, val_loss: 16.9303, val_MinusLogProbMetric: 16.9303

Epoch 335: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4361 - MinusLogProbMetric: 16.4361 - val_loss: 16.9303 - val_MinusLogProbMetric: 16.9303 - lr: 5.0000e-04 - 33s/epoch - 168ms/step
Epoch 336/1000
2023-09-23 18:11:29.958 
Epoch 336/1000 
	 loss: 16.4410, MinusLogProbMetric: 16.4410, val_loss: 16.8550, val_MinusLogProbMetric: 16.8550

Epoch 336: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4410 - MinusLogProbMetric: 16.4410 - val_loss: 16.8550 - val_MinusLogProbMetric: 16.8550 - lr: 5.0000e-04 - 33s/epoch - 166ms/step
Epoch 337/1000
2023-09-23 18:12:02.442 
Epoch 337/1000 
	 loss: 16.4250, MinusLogProbMetric: 16.4250, val_loss: 16.8914, val_MinusLogProbMetric: 16.8914

Epoch 337: val_loss did not improve from 16.84108
196/196 - 32s - loss: 16.4250 - MinusLogProbMetric: 16.4250 - val_loss: 16.8914 - val_MinusLogProbMetric: 16.8914 - lr: 5.0000e-04 - 32s/epoch - 166ms/step
Epoch 338/1000
2023-09-23 18:12:35.005 
Epoch 338/1000 
	 loss: 16.4255, MinusLogProbMetric: 16.4255, val_loss: 16.9160, val_MinusLogProbMetric: 16.9160

Epoch 338: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4255 - MinusLogProbMetric: 16.4255 - val_loss: 16.9160 - val_MinusLogProbMetric: 16.9160 - lr: 5.0000e-04 - 33s/epoch - 166ms/step
Epoch 339/1000
2023-09-23 18:13:07.718 
Epoch 339/1000 
	 loss: 16.4292, MinusLogProbMetric: 16.4292, val_loss: 16.9599, val_MinusLogProbMetric: 16.9599

Epoch 339: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4292 - MinusLogProbMetric: 16.4292 - val_loss: 16.9599 - val_MinusLogProbMetric: 16.9599 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 340/1000
2023-09-23 18:13:40.512 
Epoch 340/1000 
	 loss: 16.4337, MinusLogProbMetric: 16.4337, val_loss: 16.8901, val_MinusLogProbMetric: 16.8901

Epoch 340: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4337 - MinusLogProbMetric: 16.4337 - val_loss: 16.8901 - val_MinusLogProbMetric: 16.8901 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 341/1000
2023-09-23 18:14:13.225 
Epoch 341/1000 
	 loss: 16.4273, MinusLogProbMetric: 16.4273, val_loss: 16.8877, val_MinusLogProbMetric: 16.8877

Epoch 341: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4273 - MinusLogProbMetric: 16.4273 - val_loss: 16.8877 - val_MinusLogProbMetric: 16.8877 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 342/1000
2023-09-23 18:14:46.025 
Epoch 342/1000 
	 loss: 16.4344, MinusLogProbMetric: 16.4344, val_loss: 16.8648, val_MinusLogProbMetric: 16.8648

Epoch 342: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4344 - MinusLogProbMetric: 16.4344 - val_loss: 16.8648 - val_MinusLogProbMetric: 16.8648 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 343/1000
2023-09-23 18:15:18.633 
Epoch 343/1000 
	 loss: 16.4282, MinusLogProbMetric: 16.4282, val_loss: 16.8910, val_MinusLogProbMetric: 16.8910

Epoch 343: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4282 - MinusLogProbMetric: 16.4282 - val_loss: 16.8910 - val_MinusLogProbMetric: 16.8910 - lr: 5.0000e-04 - 33s/epoch - 166ms/step
Epoch 344/1000
2023-09-23 18:15:51.277 
Epoch 344/1000 
	 loss: 16.4458, MinusLogProbMetric: 16.4458, val_loss: 16.8533, val_MinusLogProbMetric: 16.8533

Epoch 344: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4458 - MinusLogProbMetric: 16.4458 - val_loss: 16.8533 - val_MinusLogProbMetric: 16.8533 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 345/1000
2023-09-23 18:16:24.106 
Epoch 345/1000 
	 loss: 16.4280, MinusLogProbMetric: 16.4280, val_loss: 16.8573, val_MinusLogProbMetric: 16.8573

Epoch 345: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4280 - MinusLogProbMetric: 16.4280 - val_loss: 16.8573 - val_MinusLogProbMetric: 16.8573 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 346/1000
2023-09-23 18:16:57.102 
Epoch 346/1000 
	 loss: 16.4165, MinusLogProbMetric: 16.4165, val_loss: 16.8702, val_MinusLogProbMetric: 16.8702

Epoch 346: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4165 - MinusLogProbMetric: 16.4165 - val_loss: 16.8702 - val_MinusLogProbMetric: 16.8702 - lr: 5.0000e-04 - 33s/epoch - 168ms/step
Epoch 347/1000
2023-09-23 18:17:29.743 
Epoch 347/1000 
	 loss: 16.4290, MinusLogProbMetric: 16.4290, val_loss: 16.8776, val_MinusLogProbMetric: 16.8776

Epoch 347: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4290 - MinusLogProbMetric: 16.4290 - val_loss: 16.8776 - val_MinusLogProbMetric: 16.8776 - lr: 5.0000e-04 - 33s/epoch - 166ms/step
Epoch 348/1000
2023-09-23 18:18:02.426 
Epoch 348/1000 
	 loss: 16.4255, MinusLogProbMetric: 16.4255, val_loss: 16.9007, val_MinusLogProbMetric: 16.9007

Epoch 348: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4255 - MinusLogProbMetric: 16.4255 - val_loss: 16.9007 - val_MinusLogProbMetric: 16.9007 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 349/1000
2023-09-23 18:18:35.515 
Epoch 349/1000 
	 loss: 16.4294, MinusLogProbMetric: 16.4294, val_loss: 16.9000, val_MinusLogProbMetric: 16.9000

Epoch 349: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4294 - MinusLogProbMetric: 16.4294 - val_loss: 16.9000 - val_MinusLogProbMetric: 16.9000 - lr: 5.0000e-04 - 33s/epoch - 169ms/step
Epoch 350/1000
2023-09-23 18:19:08.079 
Epoch 350/1000 
	 loss: 16.4206, MinusLogProbMetric: 16.4206, val_loss: 16.8744, val_MinusLogProbMetric: 16.8744

Epoch 350: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4206 - MinusLogProbMetric: 16.4206 - val_loss: 16.8744 - val_MinusLogProbMetric: 16.8744 - lr: 5.0000e-04 - 33s/epoch - 166ms/step
Epoch 351/1000
2023-09-23 18:19:40.865 
Epoch 351/1000 
	 loss: 16.4241, MinusLogProbMetric: 16.4241, val_loss: 16.8896, val_MinusLogProbMetric: 16.8896

Epoch 351: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4241 - MinusLogProbMetric: 16.4241 - val_loss: 16.8896 - val_MinusLogProbMetric: 16.8896 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 352/1000
2023-09-23 18:20:13.501 
Epoch 352/1000 
	 loss: 16.4348, MinusLogProbMetric: 16.4348, val_loss: 16.8922, val_MinusLogProbMetric: 16.8922

Epoch 352: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4348 - MinusLogProbMetric: 16.4348 - val_loss: 16.8922 - val_MinusLogProbMetric: 16.8922 - lr: 5.0000e-04 - 33s/epoch - 166ms/step
Epoch 353/1000
2023-09-23 18:20:46.366 
Epoch 353/1000 
	 loss: 16.4263, MinusLogProbMetric: 16.4263, val_loss: 16.8801, val_MinusLogProbMetric: 16.8801

Epoch 353: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4263 - MinusLogProbMetric: 16.4263 - val_loss: 16.8801 - val_MinusLogProbMetric: 16.8801 - lr: 5.0000e-04 - 33s/epoch - 168ms/step
Epoch 354/1000
2023-09-23 18:21:19.255 
Epoch 354/1000 
	 loss: 16.4169, MinusLogProbMetric: 16.4169, val_loss: 16.8993, val_MinusLogProbMetric: 16.8993

Epoch 354: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4169 - MinusLogProbMetric: 16.4169 - val_loss: 16.8993 - val_MinusLogProbMetric: 16.8993 - lr: 5.0000e-04 - 33s/epoch - 168ms/step
Epoch 355/1000
2023-09-23 18:21:52.026 
Epoch 355/1000 
	 loss: 16.4197, MinusLogProbMetric: 16.4197, val_loss: 16.9004, val_MinusLogProbMetric: 16.9004

Epoch 355: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4197 - MinusLogProbMetric: 16.4197 - val_loss: 16.9004 - val_MinusLogProbMetric: 16.9004 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 356/1000
2023-09-23 18:22:24.846 
Epoch 356/1000 
	 loss: 16.4196, MinusLogProbMetric: 16.4196, val_loss: 16.9054, val_MinusLogProbMetric: 16.9054

Epoch 356: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4196 - MinusLogProbMetric: 16.4196 - val_loss: 16.9054 - val_MinusLogProbMetric: 16.9054 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 357/1000
2023-09-23 18:22:57.626 
Epoch 357/1000 
	 loss: 16.4171, MinusLogProbMetric: 16.4171, val_loss: 16.8884, val_MinusLogProbMetric: 16.8884

Epoch 357: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4171 - MinusLogProbMetric: 16.4171 - val_loss: 16.8884 - val_MinusLogProbMetric: 16.8884 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 358/1000
2023-09-23 18:23:30.288 
Epoch 358/1000 
	 loss: 16.4220, MinusLogProbMetric: 16.4220, val_loss: 16.8744, val_MinusLogProbMetric: 16.8744

Epoch 358: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4220 - MinusLogProbMetric: 16.4220 - val_loss: 16.8744 - val_MinusLogProbMetric: 16.8744 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 359/1000
2023-09-23 18:24:03.241 
Epoch 359/1000 
	 loss: 16.4206, MinusLogProbMetric: 16.4206, val_loss: 16.8510, val_MinusLogProbMetric: 16.8510

Epoch 359: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4206 - MinusLogProbMetric: 16.4206 - val_loss: 16.8510 - val_MinusLogProbMetric: 16.8510 - lr: 5.0000e-04 - 33s/epoch - 168ms/step
Epoch 360/1000
2023-09-23 18:24:36.022 
Epoch 360/1000 
	 loss: 16.4207, MinusLogProbMetric: 16.4207, val_loss: 16.8969, val_MinusLogProbMetric: 16.8969

Epoch 360: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4207 - MinusLogProbMetric: 16.4207 - val_loss: 16.8969 - val_MinusLogProbMetric: 16.8969 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 361/1000
2023-09-23 18:25:08.921 
Epoch 361/1000 
	 loss: 16.4255, MinusLogProbMetric: 16.4255, val_loss: 16.8926, val_MinusLogProbMetric: 16.8926

Epoch 361: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4255 - MinusLogProbMetric: 16.4255 - val_loss: 16.8926 - val_MinusLogProbMetric: 16.8926 - lr: 5.0000e-04 - 33s/epoch - 168ms/step
Epoch 362/1000
2023-09-23 18:25:41.567 
Epoch 362/1000 
	 loss: 16.4228, MinusLogProbMetric: 16.4228, val_loss: 16.8949, val_MinusLogProbMetric: 16.8949

Epoch 362: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4228 - MinusLogProbMetric: 16.4228 - val_loss: 16.8949 - val_MinusLogProbMetric: 16.8949 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 363/1000
2023-09-23 18:26:14.499 
Epoch 363/1000 
	 loss: 16.4124, MinusLogProbMetric: 16.4124, val_loss: 16.9333, val_MinusLogProbMetric: 16.9333

Epoch 363: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4124 - MinusLogProbMetric: 16.4124 - val_loss: 16.9333 - val_MinusLogProbMetric: 16.9333 - lr: 5.0000e-04 - 33s/epoch - 168ms/step
Epoch 364/1000
2023-09-23 18:26:47.034 
Epoch 364/1000 
	 loss: 16.4178, MinusLogProbMetric: 16.4178, val_loss: 16.8850, val_MinusLogProbMetric: 16.8850

Epoch 364: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4178 - MinusLogProbMetric: 16.4178 - val_loss: 16.8850 - val_MinusLogProbMetric: 16.8850 - lr: 5.0000e-04 - 33s/epoch - 166ms/step
Epoch 365/1000
2023-09-23 18:27:19.561 
Epoch 365/1000 
	 loss: 16.4114, MinusLogProbMetric: 16.4114, val_loss: 16.8957, val_MinusLogProbMetric: 16.8957

Epoch 365: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4114 - MinusLogProbMetric: 16.4114 - val_loss: 16.8957 - val_MinusLogProbMetric: 16.8957 - lr: 5.0000e-04 - 33s/epoch - 166ms/step
Epoch 366/1000
2023-09-23 18:27:52.483 
Epoch 366/1000 
	 loss: 16.4093, MinusLogProbMetric: 16.4093, val_loss: 16.8852, val_MinusLogProbMetric: 16.8852

Epoch 366: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4093 - MinusLogProbMetric: 16.4093 - val_loss: 16.8852 - val_MinusLogProbMetric: 16.8852 - lr: 5.0000e-04 - 33s/epoch - 168ms/step
Epoch 367/1000
2023-09-23 18:28:25.193 
Epoch 367/1000 
	 loss: 16.4178, MinusLogProbMetric: 16.4178, val_loss: 16.9030, val_MinusLogProbMetric: 16.9030

Epoch 367: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4178 - MinusLogProbMetric: 16.4178 - val_loss: 16.9030 - val_MinusLogProbMetric: 16.9030 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 368/1000
2023-09-23 18:28:58.120 
Epoch 368/1000 
	 loss: 16.4284, MinusLogProbMetric: 16.4284, val_loss: 16.8824, val_MinusLogProbMetric: 16.8824

Epoch 368: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4284 - MinusLogProbMetric: 16.4284 - val_loss: 16.8824 - val_MinusLogProbMetric: 16.8824 - lr: 5.0000e-04 - 33s/epoch - 168ms/step
Epoch 369/1000
2023-09-23 18:29:30.681 
Epoch 369/1000 
	 loss: 16.4105, MinusLogProbMetric: 16.4105, val_loss: 16.8820, val_MinusLogProbMetric: 16.8820

Epoch 369: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4105 - MinusLogProbMetric: 16.4105 - val_loss: 16.8820 - val_MinusLogProbMetric: 16.8820 - lr: 5.0000e-04 - 33s/epoch - 166ms/step
Epoch 370/1000
2023-09-23 18:30:03.674 
Epoch 370/1000 
	 loss: 16.4118, MinusLogProbMetric: 16.4118, val_loss: 16.8787, val_MinusLogProbMetric: 16.8787

Epoch 370: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4118 - MinusLogProbMetric: 16.4118 - val_loss: 16.8787 - val_MinusLogProbMetric: 16.8787 - lr: 5.0000e-04 - 33s/epoch - 168ms/step
Epoch 371/1000
2023-09-23 18:30:36.499 
Epoch 371/1000 
	 loss: 16.4111, MinusLogProbMetric: 16.4111, val_loss: 16.9143, val_MinusLogProbMetric: 16.9143

Epoch 371: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4111 - MinusLogProbMetric: 16.4111 - val_loss: 16.9143 - val_MinusLogProbMetric: 16.9143 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 372/1000
2023-09-23 18:31:09.068 
Epoch 372/1000 
	 loss: 16.4183, MinusLogProbMetric: 16.4183, val_loss: 16.9054, val_MinusLogProbMetric: 16.9054

Epoch 372: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4183 - MinusLogProbMetric: 16.4183 - val_loss: 16.9054 - val_MinusLogProbMetric: 16.9054 - lr: 5.0000e-04 - 33s/epoch - 166ms/step
Epoch 373/1000
2023-09-23 18:31:41.721 
Epoch 373/1000 
	 loss: 16.4212, MinusLogProbMetric: 16.4212, val_loss: 16.9309, val_MinusLogProbMetric: 16.9309

Epoch 373: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4212 - MinusLogProbMetric: 16.4212 - val_loss: 16.9309 - val_MinusLogProbMetric: 16.9309 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 374/1000
2023-09-23 18:32:14.631 
Epoch 374/1000 
	 loss: 16.4173, MinusLogProbMetric: 16.4173, val_loss: 16.8741, val_MinusLogProbMetric: 16.8741

Epoch 374: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4173 - MinusLogProbMetric: 16.4173 - val_loss: 16.8741 - val_MinusLogProbMetric: 16.8741 - lr: 5.0000e-04 - 33s/epoch - 168ms/step
Epoch 375/1000
2023-09-23 18:32:47.524 
Epoch 375/1000 
	 loss: 16.4149, MinusLogProbMetric: 16.4149, val_loss: 16.8677, val_MinusLogProbMetric: 16.8677

Epoch 375: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4149 - MinusLogProbMetric: 16.4149 - val_loss: 16.8677 - val_MinusLogProbMetric: 16.8677 - lr: 5.0000e-04 - 33s/epoch - 168ms/step
Epoch 376/1000
2023-09-23 18:33:20.288 
Epoch 376/1000 
	 loss: 16.3995, MinusLogProbMetric: 16.3995, val_loss: 16.9139, val_MinusLogProbMetric: 16.9139

Epoch 376: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3995 - MinusLogProbMetric: 16.3995 - val_loss: 16.9139 - val_MinusLogProbMetric: 16.9139 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 377/1000
2023-09-23 18:33:53.243 
Epoch 377/1000 
	 loss: 16.4182, MinusLogProbMetric: 16.4182, val_loss: 16.8763, val_MinusLogProbMetric: 16.8763

Epoch 377: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4182 - MinusLogProbMetric: 16.4182 - val_loss: 16.8763 - val_MinusLogProbMetric: 16.8763 - lr: 5.0000e-04 - 33s/epoch - 168ms/step
Epoch 378/1000
2023-09-23 18:34:26.200 
Epoch 378/1000 
	 loss: 16.4141, MinusLogProbMetric: 16.4141, val_loss: 16.8638, val_MinusLogProbMetric: 16.8638

Epoch 378: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4141 - MinusLogProbMetric: 16.4141 - val_loss: 16.8638 - val_MinusLogProbMetric: 16.8638 - lr: 5.0000e-04 - 33s/epoch - 168ms/step
Epoch 379/1000
2023-09-23 18:34:58.602 
Epoch 379/1000 
	 loss: 16.4112, MinusLogProbMetric: 16.4112, val_loss: 16.9076, val_MinusLogProbMetric: 16.9076

Epoch 379: val_loss did not improve from 16.84108
196/196 - 32s - loss: 16.4112 - MinusLogProbMetric: 16.4112 - val_loss: 16.9076 - val_MinusLogProbMetric: 16.9076 - lr: 5.0000e-04 - 32s/epoch - 165ms/step
Epoch 380/1000
2023-09-23 18:35:31.330 
Epoch 380/1000 
	 loss: 16.4170, MinusLogProbMetric: 16.4170, val_loss: 16.9426, val_MinusLogProbMetric: 16.9426

Epoch 380: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.4170 - MinusLogProbMetric: 16.4170 - val_loss: 16.9426 - val_MinusLogProbMetric: 16.9426 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 381/1000
2023-09-23 18:36:04.262 
Epoch 381/1000 
	 loss: 16.3696, MinusLogProbMetric: 16.3696, val_loss: 16.8662, val_MinusLogProbMetric: 16.8662

Epoch 381: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3696 - MinusLogProbMetric: 16.3696 - val_loss: 16.8662 - val_MinusLogProbMetric: 16.8662 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 382/1000
2023-09-23 18:36:37.227 
Epoch 382/1000 
	 loss: 16.3538, MinusLogProbMetric: 16.3538, val_loss: 16.8452, val_MinusLogProbMetric: 16.8452

Epoch 382: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3538 - MinusLogProbMetric: 16.3538 - val_loss: 16.8452 - val_MinusLogProbMetric: 16.8452 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 383/1000
2023-09-23 18:37:09.912 
Epoch 383/1000 
	 loss: 16.3576, MinusLogProbMetric: 16.3576, val_loss: 16.8578, val_MinusLogProbMetric: 16.8578

Epoch 383: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3576 - MinusLogProbMetric: 16.3576 - val_loss: 16.8578 - val_MinusLogProbMetric: 16.8578 - lr: 2.5000e-04 - 33s/epoch - 167ms/step
Epoch 384/1000
2023-09-23 18:37:42.635 
Epoch 384/1000 
	 loss: 16.3634, MinusLogProbMetric: 16.3634, val_loss: 16.8640, val_MinusLogProbMetric: 16.8640

Epoch 384: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3634 - MinusLogProbMetric: 16.3634 - val_loss: 16.8640 - val_MinusLogProbMetric: 16.8640 - lr: 2.5000e-04 - 33s/epoch - 167ms/step
Epoch 385/1000
2023-09-23 18:38:15.591 
Epoch 385/1000 
	 loss: 16.3551, MinusLogProbMetric: 16.3551, val_loss: 16.8653, val_MinusLogProbMetric: 16.8653

Epoch 385: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3551 - MinusLogProbMetric: 16.3551 - val_loss: 16.8653 - val_MinusLogProbMetric: 16.8653 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 386/1000
2023-09-23 18:38:48.297 
Epoch 386/1000 
	 loss: 16.3585, MinusLogProbMetric: 16.3585, val_loss: 16.8615, val_MinusLogProbMetric: 16.8615

Epoch 386: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3585 - MinusLogProbMetric: 16.3585 - val_loss: 16.8615 - val_MinusLogProbMetric: 16.8615 - lr: 2.5000e-04 - 33s/epoch - 167ms/step
Epoch 387/1000
2023-09-23 18:39:21.028 
Epoch 387/1000 
	 loss: 16.3543, MinusLogProbMetric: 16.3543, val_loss: 16.8426, val_MinusLogProbMetric: 16.8426

Epoch 387: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3543 - MinusLogProbMetric: 16.3543 - val_loss: 16.8426 - val_MinusLogProbMetric: 16.8426 - lr: 2.5000e-04 - 33s/epoch - 167ms/step
Epoch 388/1000
2023-09-23 18:39:54.173 
Epoch 388/1000 
	 loss: 16.3568, MinusLogProbMetric: 16.3568, val_loss: 16.8590, val_MinusLogProbMetric: 16.8590

Epoch 388: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3568 - MinusLogProbMetric: 16.3568 - val_loss: 16.8590 - val_MinusLogProbMetric: 16.8590 - lr: 2.5000e-04 - 33s/epoch - 169ms/step
Epoch 389/1000
2023-09-23 18:40:27.038 
Epoch 389/1000 
	 loss: 16.3575, MinusLogProbMetric: 16.3575, val_loss: 16.8897, val_MinusLogProbMetric: 16.8897

Epoch 389: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3575 - MinusLogProbMetric: 16.3575 - val_loss: 16.8897 - val_MinusLogProbMetric: 16.8897 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 390/1000
2023-09-23 18:41:00.725 
Epoch 390/1000 
	 loss: 16.3582, MinusLogProbMetric: 16.3582, val_loss: 16.8880, val_MinusLogProbMetric: 16.8880

Epoch 390: val_loss did not improve from 16.84108
196/196 - 34s - loss: 16.3582 - MinusLogProbMetric: 16.3582 - val_loss: 16.8880 - val_MinusLogProbMetric: 16.8880 - lr: 2.5000e-04 - 34s/epoch - 172ms/step
Epoch 391/1000
2023-09-23 18:41:35.081 
Epoch 391/1000 
	 loss: 16.3589, MinusLogProbMetric: 16.3589, val_loss: 16.8622, val_MinusLogProbMetric: 16.8622

Epoch 391: val_loss did not improve from 16.84108
196/196 - 34s - loss: 16.3589 - MinusLogProbMetric: 16.3589 - val_loss: 16.8622 - val_MinusLogProbMetric: 16.8622 - lr: 2.5000e-04 - 34s/epoch - 175ms/step
Epoch 392/1000
2023-09-23 18:42:09.142 
Epoch 392/1000 
	 loss: 16.3571, MinusLogProbMetric: 16.3571, val_loss: 16.8574, val_MinusLogProbMetric: 16.8574

Epoch 392: val_loss did not improve from 16.84108
196/196 - 34s - loss: 16.3571 - MinusLogProbMetric: 16.3571 - val_loss: 16.8574 - val_MinusLogProbMetric: 16.8574 - lr: 2.5000e-04 - 34s/epoch - 174ms/step
Epoch 393/1000
2023-09-23 18:42:43.262 
Epoch 393/1000 
	 loss: 16.3575, MinusLogProbMetric: 16.3575, val_loss: 16.8463, val_MinusLogProbMetric: 16.8463

Epoch 393: val_loss did not improve from 16.84108
196/196 - 34s - loss: 16.3575 - MinusLogProbMetric: 16.3575 - val_loss: 16.8463 - val_MinusLogProbMetric: 16.8463 - lr: 2.5000e-04 - 34s/epoch - 174ms/step
Epoch 394/1000
2023-09-23 18:43:17.386 
Epoch 394/1000 
	 loss: 16.3558, MinusLogProbMetric: 16.3558, val_loss: 16.8630, val_MinusLogProbMetric: 16.8630

Epoch 394: val_loss did not improve from 16.84108
196/196 - 34s - loss: 16.3558 - MinusLogProbMetric: 16.3558 - val_loss: 16.8630 - val_MinusLogProbMetric: 16.8630 - lr: 2.5000e-04 - 34s/epoch - 174ms/step
Epoch 395/1000
2023-09-23 18:43:51.114 
Epoch 395/1000 
	 loss: 16.3514, MinusLogProbMetric: 16.3514, val_loss: 16.8638, val_MinusLogProbMetric: 16.8638

Epoch 395: val_loss did not improve from 16.84108
196/196 - 34s - loss: 16.3514 - MinusLogProbMetric: 16.3514 - val_loss: 16.8638 - val_MinusLogProbMetric: 16.8638 - lr: 2.5000e-04 - 34s/epoch - 172ms/step
Epoch 396/1000
2023-09-23 18:44:23.958 
Epoch 396/1000 
	 loss: 16.3535, MinusLogProbMetric: 16.3535, val_loss: 16.8644, val_MinusLogProbMetric: 16.8644

Epoch 396: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3535 - MinusLogProbMetric: 16.3535 - val_loss: 16.8644 - val_MinusLogProbMetric: 16.8644 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 397/1000
2023-09-23 18:44:56.948 
Epoch 397/1000 
	 loss: 16.3611, MinusLogProbMetric: 16.3611, val_loss: 16.8979, val_MinusLogProbMetric: 16.8979

Epoch 397: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3611 - MinusLogProbMetric: 16.3611 - val_loss: 16.8979 - val_MinusLogProbMetric: 16.8979 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 398/1000
2023-09-23 18:45:29.880 
Epoch 398/1000 
	 loss: 16.3580, MinusLogProbMetric: 16.3580, val_loss: 16.8493, val_MinusLogProbMetric: 16.8493

Epoch 398: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3580 - MinusLogProbMetric: 16.3580 - val_loss: 16.8493 - val_MinusLogProbMetric: 16.8493 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 399/1000
2023-09-23 18:46:03.035 
Epoch 399/1000 
	 loss: 16.3563, MinusLogProbMetric: 16.3563, val_loss: 16.8553, val_MinusLogProbMetric: 16.8553

Epoch 399: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3563 - MinusLogProbMetric: 16.3563 - val_loss: 16.8553 - val_MinusLogProbMetric: 16.8553 - lr: 2.5000e-04 - 33s/epoch - 169ms/step
Epoch 400/1000
2023-09-23 18:46:35.936 
Epoch 400/1000 
	 loss: 16.3512, MinusLogProbMetric: 16.3512, val_loss: 16.8732, val_MinusLogProbMetric: 16.8732

Epoch 400: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3512 - MinusLogProbMetric: 16.3512 - val_loss: 16.8732 - val_MinusLogProbMetric: 16.8732 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 401/1000
2023-09-23 18:47:08.905 
Epoch 401/1000 
	 loss: 16.3558, MinusLogProbMetric: 16.3558, val_loss: 16.8720, val_MinusLogProbMetric: 16.8720

Epoch 401: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3558 - MinusLogProbMetric: 16.3558 - val_loss: 16.8720 - val_MinusLogProbMetric: 16.8720 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 402/1000
2023-09-23 18:47:41.930 
Epoch 402/1000 
	 loss: 16.3536, MinusLogProbMetric: 16.3536, val_loss: 16.8698, val_MinusLogProbMetric: 16.8698

Epoch 402: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3536 - MinusLogProbMetric: 16.3536 - val_loss: 16.8698 - val_MinusLogProbMetric: 16.8698 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 403/1000
2023-09-23 18:48:15.434 
Epoch 403/1000 
	 loss: 16.3527, MinusLogProbMetric: 16.3527, val_loss: 16.8785, val_MinusLogProbMetric: 16.8785

Epoch 403: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3527 - MinusLogProbMetric: 16.3527 - val_loss: 16.8785 - val_MinusLogProbMetric: 16.8785 - lr: 2.5000e-04 - 33s/epoch - 171ms/step
Epoch 404/1000
2023-09-23 18:48:48.167 
Epoch 404/1000 
	 loss: 16.3524, MinusLogProbMetric: 16.3524, val_loss: 16.8537, val_MinusLogProbMetric: 16.8537

Epoch 404: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3524 - MinusLogProbMetric: 16.3524 - val_loss: 16.8537 - val_MinusLogProbMetric: 16.8537 - lr: 2.5000e-04 - 33s/epoch - 167ms/step
Epoch 405/1000
2023-09-23 18:49:20.953 
Epoch 405/1000 
	 loss: 16.3522, MinusLogProbMetric: 16.3522, val_loss: 16.8507, val_MinusLogProbMetric: 16.8507

Epoch 405: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3522 - MinusLogProbMetric: 16.3522 - val_loss: 16.8507 - val_MinusLogProbMetric: 16.8507 - lr: 2.5000e-04 - 33s/epoch - 167ms/step
Epoch 406/1000
2023-09-23 18:49:53.753 
Epoch 406/1000 
	 loss: 16.3518, MinusLogProbMetric: 16.3518, val_loss: 16.8642, val_MinusLogProbMetric: 16.8642

Epoch 406: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3518 - MinusLogProbMetric: 16.3518 - val_loss: 16.8642 - val_MinusLogProbMetric: 16.8642 - lr: 2.5000e-04 - 33s/epoch - 167ms/step
Epoch 407/1000
2023-09-23 18:50:26.721 
Epoch 407/1000 
	 loss: 16.3560, MinusLogProbMetric: 16.3560, val_loss: 16.8686, val_MinusLogProbMetric: 16.8686

Epoch 407: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3560 - MinusLogProbMetric: 16.3560 - val_loss: 16.8686 - val_MinusLogProbMetric: 16.8686 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 408/1000
2023-09-23 18:50:59.609 
Epoch 408/1000 
	 loss: 16.3488, MinusLogProbMetric: 16.3488, val_loss: 16.8768, val_MinusLogProbMetric: 16.8768

Epoch 408: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3488 - MinusLogProbMetric: 16.3488 - val_loss: 16.8768 - val_MinusLogProbMetric: 16.8768 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 409/1000
2023-09-23 18:51:32.727 
Epoch 409/1000 
	 loss: 16.3547, MinusLogProbMetric: 16.3547, val_loss: 16.8690, val_MinusLogProbMetric: 16.8690

Epoch 409: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3547 - MinusLogProbMetric: 16.3547 - val_loss: 16.8690 - val_MinusLogProbMetric: 16.8690 - lr: 2.5000e-04 - 33s/epoch - 169ms/step
Epoch 410/1000
2023-09-23 18:52:05.745 
Epoch 410/1000 
	 loss: 16.3515, MinusLogProbMetric: 16.3515, val_loss: 16.8566, val_MinusLogProbMetric: 16.8566

Epoch 410: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3515 - MinusLogProbMetric: 16.3515 - val_loss: 16.8566 - val_MinusLogProbMetric: 16.8566 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 411/1000
2023-09-23 18:52:38.858 
Epoch 411/1000 
	 loss: 16.3584, MinusLogProbMetric: 16.3584, val_loss: 16.8676, val_MinusLogProbMetric: 16.8676

Epoch 411: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3584 - MinusLogProbMetric: 16.3584 - val_loss: 16.8676 - val_MinusLogProbMetric: 16.8676 - lr: 2.5000e-04 - 33s/epoch - 169ms/step
Epoch 412/1000
2023-09-23 18:53:11.977 
Epoch 412/1000 
	 loss: 16.3508, MinusLogProbMetric: 16.3508, val_loss: 16.8807, val_MinusLogProbMetric: 16.8807

Epoch 412: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3508 - MinusLogProbMetric: 16.3508 - val_loss: 16.8807 - val_MinusLogProbMetric: 16.8807 - lr: 2.5000e-04 - 33s/epoch - 169ms/step
Epoch 413/1000
2023-09-23 18:53:44.806 
Epoch 413/1000 
	 loss: 16.3540, MinusLogProbMetric: 16.3540, val_loss: 16.8488, val_MinusLogProbMetric: 16.8488

Epoch 413: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3540 - MinusLogProbMetric: 16.3540 - val_loss: 16.8488 - val_MinusLogProbMetric: 16.8488 - lr: 2.5000e-04 - 33s/epoch - 167ms/step
Epoch 414/1000
2023-09-23 18:54:17.709 
Epoch 414/1000 
	 loss: 16.3493, MinusLogProbMetric: 16.3493, val_loss: 16.8512, val_MinusLogProbMetric: 16.8512

Epoch 414: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3493 - MinusLogProbMetric: 16.3493 - val_loss: 16.8512 - val_MinusLogProbMetric: 16.8512 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 415/1000
2023-09-23 18:54:50.509 
Epoch 415/1000 
	 loss: 16.3576, MinusLogProbMetric: 16.3576, val_loss: 16.8504, val_MinusLogProbMetric: 16.8504

Epoch 415: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3576 - MinusLogProbMetric: 16.3576 - val_loss: 16.8504 - val_MinusLogProbMetric: 16.8504 - lr: 2.5000e-04 - 33s/epoch - 167ms/step
Epoch 416/1000
2023-09-23 18:55:23.548 
Epoch 416/1000 
	 loss: 16.3509, MinusLogProbMetric: 16.3509, val_loss: 16.8530, val_MinusLogProbMetric: 16.8530

Epoch 416: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3509 - MinusLogProbMetric: 16.3509 - val_loss: 16.8530 - val_MinusLogProbMetric: 16.8530 - lr: 2.5000e-04 - 33s/epoch - 169ms/step
Epoch 417/1000
2023-09-23 18:55:56.296 
Epoch 417/1000 
	 loss: 16.3505, MinusLogProbMetric: 16.3505, val_loss: 16.8685, val_MinusLogProbMetric: 16.8685

Epoch 417: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3505 - MinusLogProbMetric: 16.3505 - val_loss: 16.8685 - val_MinusLogProbMetric: 16.8685 - lr: 2.5000e-04 - 33s/epoch - 167ms/step
Epoch 418/1000
2023-09-23 18:56:29.088 
Epoch 418/1000 
	 loss: 16.3544, MinusLogProbMetric: 16.3544, val_loss: 16.8494, val_MinusLogProbMetric: 16.8494

Epoch 418: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3544 - MinusLogProbMetric: 16.3544 - val_loss: 16.8494 - val_MinusLogProbMetric: 16.8494 - lr: 2.5000e-04 - 33s/epoch - 167ms/step
Epoch 419/1000
2023-09-23 18:57:01.453 
Epoch 419/1000 
	 loss: 16.3504, MinusLogProbMetric: 16.3504, val_loss: 16.8439, val_MinusLogProbMetric: 16.8439

Epoch 419: val_loss did not improve from 16.84108
196/196 - 32s - loss: 16.3504 - MinusLogProbMetric: 16.3504 - val_loss: 16.8439 - val_MinusLogProbMetric: 16.8439 - lr: 2.5000e-04 - 32s/epoch - 165ms/step
Epoch 420/1000
2023-09-23 18:57:33.919 
Epoch 420/1000 
	 loss: 16.3504, MinusLogProbMetric: 16.3504, val_loss: 16.8771, val_MinusLogProbMetric: 16.8771

Epoch 420: val_loss did not improve from 16.84108
196/196 - 32s - loss: 16.3504 - MinusLogProbMetric: 16.3504 - val_loss: 16.8771 - val_MinusLogProbMetric: 16.8771 - lr: 2.5000e-04 - 32s/epoch - 166ms/step
Epoch 421/1000
2023-09-23 18:58:06.923 
Epoch 421/1000 
	 loss: 16.3548, MinusLogProbMetric: 16.3548, val_loss: 16.8579, val_MinusLogProbMetric: 16.8579

Epoch 421: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3548 - MinusLogProbMetric: 16.3548 - val_loss: 16.8579 - val_MinusLogProbMetric: 16.8579 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 422/1000
2023-09-23 18:58:39.905 
Epoch 422/1000 
	 loss: 16.3483, MinusLogProbMetric: 16.3483, val_loss: 16.8625, val_MinusLogProbMetric: 16.8625

Epoch 422: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3483 - MinusLogProbMetric: 16.3483 - val_loss: 16.8625 - val_MinusLogProbMetric: 16.8625 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 423/1000
2023-09-23 18:59:12.424 
Epoch 423/1000 
	 loss: 16.3475, MinusLogProbMetric: 16.3475, val_loss: 16.8558, val_MinusLogProbMetric: 16.8558

Epoch 423: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3475 - MinusLogProbMetric: 16.3475 - val_loss: 16.8558 - val_MinusLogProbMetric: 16.8558 - lr: 2.5000e-04 - 33s/epoch - 166ms/step
Epoch 424/1000
2023-09-23 18:59:45.218 
Epoch 424/1000 
	 loss: 16.3523, MinusLogProbMetric: 16.3523, val_loss: 16.8538, val_MinusLogProbMetric: 16.8538

Epoch 424: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3523 - MinusLogProbMetric: 16.3523 - val_loss: 16.8538 - val_MinusLogProbMetric: 16.8538 - lr: 2.5000e-04 - 33s/epoch - 167ms/step
Epoch 425/1000
2023-09-23 19:00:18.258 
Epoch 425/1000 
	 loss: 16.3482, MinusLogProbMetric: 16.3482, val_loss: 16.8469, val_MinusLogProbMetric: 16.8469

Epoch 425: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3482 - MinusLogProbMetric: 16.3482 - val_loss: 16.8469 - val_MinusLogProbMetric: 16.8469 - lr: 2.5000e-04 - 33s/epoch - 169ms/step
Epoch 426/1000
2023-09-23 19:00:51.161 
Epoch 426/1000 
	 loss: 16.3482, MinusLogProbMetric: 16.3482, val_loss: 16.8503, val_MinusLogProbMetric: 16.8503

Epoch 426: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3482 - MinusLogProbMetric: 16.3482 - val_loss: 16.8503 - val_MinusLogProbMetric: 16.8503 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 427/1000
2023-09-23 19:01:23.995 
Epoch 427/1000 
	 loss: 16.3561, MinusLogProbMetric: 16.3561, val_loss: 16.8663, val_MinusLogProbMetric: 16.8663

Epoch 427: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3561 - MinusLogProbMetric: 16.3561 - val_loss: 16.8663 - val_MinusLogProbMetric: 16.8663 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 428/1000
2023-09-23 19:01:56.597 
Epoch 428/1000 
	 loss: 16.3450, MinusLogProbMetric: 16.3450, val_loss: 16.8477, val_MinusLogProbMetric: 16.8477

Epoch 428: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3450 - MinusLogProbMetric: 16.3450 - val_loss: 16.8477 - val_MinusLogProbMetric: 16.8477 - lr: 2.5000e-04 - 33s/epoch - 166ms/step
Epoch 429/1000
2023-09-23 19:02:29.264 
Epoch 429/1000 
	 loss: 16.3447, MinusLogProbMetric: 16.3447, val_loss: 16.8547, val_MinusLogProbMetric: 16.8547

Epoch 429: val_loss did not improve from 16.84108
196/196 - 33s - loss: 16.3447 - MinusLogProbMetric: 16.3447 - val_loss: 16.8547 - val_MinusLogProbMetric: 16.8547 - lr: 2.5000e-04 - 33s/epoch - 167ms/step
Epoch 430/1000
2023-09-23 19:03:01.966 
Epoch 430/1000 
	 loss: 16.3460, MinusLogProbMetric: 16.3460, val_loss: 16.8558, val_MinusLogProbMetric: 16.8558

Epoch 430: val_loss did not improve from 16.84108
Restoring model weights from the end of the best epoch: 330.
196/196 - 33s - loss: 16.3460 - MinusLogProbMetric: 16.3460 - val_loss: 16.8558 - val_MinusLogProbMetric: 16.8558 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 430: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
LR metric calculation completed in 12.447531968999101 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
LR metric calculation completed in 26.267643537998083 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
