2023-09-15 13:48:55.897942: Importing os...
2023-09-15 13:48:55.898018: Importing sys...
2023-09-15 13:48:55.898032: Importing and initializing argparse...
Visible devices: [0]
2023-09-15 13:48:55.917263: Importing timer from timeit...
2023-09-15 13:48:55.918051: Setting env variables for tf import (only device [0] will be available)...
2023-09-15 13:48:55.918116: Importing numpy...
2023-09-15 13:48:56.085504: Importing pandas...
2023-09-15 13:48:56.317636: Importing shutil...
2023-09-15 13:48:56.317674: Importing subprocess...
2023-09-15 13:48:56.317682: Importing tensorflow...
Tensorflow version: 2.12.0
2023-09-15 13:48:59.010899: Importing tensorflow_probability...
Tensorflow probability version: 0.20.1
2023-09-15 13:48:59.459183: Importing textwrap...
2023-09-15 13:48:59.459221: Importing timeit...
2023-09-15 13:48:59.459232: Importing traceback...
2023-09-15 13:48:59.459239: Importing typing...
2023-09-15 13:48:59.459250: Setting tf configs...
2023-09-15 13:48:59.646978: Importing custom module...
Successfully loaded GPU model: NVIDIA A40
2023-09-15 13:49:01.460499: All modues imported successfully.
Directory ../../results/CsplineN_new/ already exists.
Directory ../../results/CsplineN_new/run_1/ already exists.
Skipping it.
===========
Run 1/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_2/ already exists.
Skipping it.
===========
Run 2/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_3/ already exists.
Skipping it.
===========
Run 3/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_4/ already exists.
Skipping it.
===========
Run 4/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_5/ already exists.
Skipping it.
===========
Run 5/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_6/ already exists.
Skipping it.
===========
Run 6/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_7/ already exists.
Skipping it.
===========
Run 7/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_8/ already exists.
Skipping it.
===========
Run 8/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_9/ already exists.
Skipping it.
===========
Run 9/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_10/ already exists.
Skipping it.
===========
Run 10/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_11/ already exists.
Skipping it.
===========
Run 11/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_12/ already exists.
Skipping it.
===========
Run 12/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_13/ already exists.
Skipping it.
===========
Run 13/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_14/ already exists.
Skipping it.
===========
Run 14/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_15/ already exists.
Skipping it.
===========
Run 15/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_16/ already exists.
Skipping it.
===========
Run 16/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_17/ already exists.
Skipping it.
===========
Run 17/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_18/ already exists.
Skipping it.
===========
Run 18/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_19/ already exists.
Skipping it.
===========
Run 19/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_20/ already exists.
Skipping it.
===========
Run 20/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_21/ already exists.
Skipping it.
===========
Run 21/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_22/ already exists.
Skipping it.
===========
Run 22/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_23/ already exists.
Skipping it.
===========
Run 23/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_24/ already exists.
Skipping it.
===========
Run 24/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_25/ already exists.
Skipping it.
===========
Run 25/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_26/ already exists.
Skipping it.
===========
Run 26/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_27/ already exists.
Skipping it.
===========
Run 27/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_28/ already exists.
Skipping it.
===========
Run 28/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_29/ already exists.
Skipping it.
===========
Run 29/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_30/ already exists.
Skipping it.
===========
Run 30/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_31/ already exists.
Skipping it.
===========
Run 31/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_32/ already exists.
Skipping it.
===========
Run 32/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_33/ already exists.
Skipping it.
===========
Run 33/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_34/ already exists.
Skipping it.
===========
Run 34/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_35/ already exists.
Skipping it.
===========
Run 35/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_36/ already exists.
Skipping it.
===========
Run 36/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_37/ already exists.
Skipping it.
===========
Run 37/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_38/ already exists.
Skipping it.
===========
Run 38/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_39/ already exists.
Skipping it.
===========
Run 39/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_40/ already exists.
Skipping it.
===========
Run 40/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_41/ already exists.
Skipping it.
===========
Run 41/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_42/ already exists.
Skipping it.
===========
Run 42/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_43/ already exists.
Skipping it.
===========
Run 43/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_44/ already exists.
Skipping it.
===========
Run 44/720 already exists. Skipping it.
===========

===========
Generating train data for run 45.
===========
Train data generated in 0.39 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 4)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_45/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 541}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_45/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[6.0499196, 7.735244 , 5.962891 , 5.4972267],
       [4.240278 , 7.408592 , 4.430731 , 9.144769 ],
       [8.997333 , 4.4441915, 8.158195 , 5.415612 ],
       ...,
       [4.242811 , 5.565524 , 3.7138436, 8.535822 ],
       [4.239969 , 5.642732 , 3.372448 , 9.072292 ],
       [5.397499 , 7.2973785, 6.0447845, 5.3691936]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_45/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_45
self.data_kwargs: {'seed': 541}
self.x_data: [[4.240572  7.7052617 4.508904  9.582846 ]
 [8.872487  2.583825  7.5498557 5.3223796]
 [9.87924   4.0003986 8.381026  4.1662674]
 ...
 [4.220218  7.3281665 4.7764745 9.373516 ]
 [4.2115626 5.1675367 5.4861526 8.757507 ]
 [4.206221  6.5791492 4.0544195 9.789848 ]]
self.y_data: []
self.ndims: 4
Model defined.
Model: "model_10"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_11 (InputLayer)       [(None, 4)]               0         
                                                                 
 log_prob_layer (LogProbLaye  (None,)                  393420    
 r)                                                              
                                                                 
=================================================================
Total params: 393,420
Trainable params: 393,420
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer'")
self.model: <keras.engine.functional.Functional object at 0x7fb3604abe20>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fb3604d9c90>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fb3604d9c90>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fb318209b70>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fb318209f60>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fb31820a4d0>, <keras.callbacks.ModelCheckpoint object at 0x7fb31820a620>, <keras.callbacks.EarlyStopping object at 0x7fb31820a830>, <keras.callbacks.ReduceLROnPlateau object at 0x7fb31820a860>, <keras.callbacks.TerminateOnNaN object at 0x7fb31820a590>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[6.0499196, 7.735244 , 5.962891 , 5.4972267],
       [4.240278 , 7.408592 , 4.430731 , 9.144769 ],
       [8.997333 , 4.4441915, 8.158195 , 5.415612 ],
       ...,
       [4.242811 , 5.565524 , 3.7138436, 8.535822 ],
       [4.239969 , 5.642732 , 3.372448 , 9.072292 ],
       [5.397499 , 7.2973785, 6.0447845, 5.3691936]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_45/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 45/720 with hyperparameters:
timestamp = 2023-09-15 13:49:11.495411
ndims = 4
seed_train = 541
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 8
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 393420
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [4.240572  7.7052617 4.508904  9.582846 ]
Epoch 1/1000
2023-09-15 13:52:19.812 
Epoch 1/1000 
	 loss: 7.0412, MinusLogProbMetric: 7.0412, val_loss: 4.8958, val_MinusLogProbMetric: 4.8958

Epoch 1: val_loss improved from inf to 4.89578, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 189s - loss: 7.0412 - MinusLogProbMetric: 7.0412 - val_loss: 4.8958 - val_MinusLogProbMetric: 4.8958 - lr: 0.0010 - 189s/epoch - 964ms/step
Epoch 2/1000
2023-09-15 13:53:19.480 
Epoch 2/1000 
	 loss: 4.0528, MinusLogProbMetric: 4.0528, val_loss: 3.1917, val_MinusLogProbMetric: 3.1917

Epoch 2: val_loss improved from 4.89578 to 3.19169, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 60s - loss: 4.0528 - MinusLogProbMetric: 4.0528 - val_loss: 3.1917 - val_MinusLogProbMetric: 3.1917 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 3/1000
2023-09-15 13:54:19.660 
Epoch 3/1000 
	 loss: 3.0938, MinusLogProbMetric: 3.0938, val_loss: 3.0973, val_MinusLogProbMetric: 3.0973

Epoch 3: val_loss improved from 3.19169 to 3.09733, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 60s - loss: 3.0938 - MinusLogProbMetric: 3.0938 - val_loss: 3.0973 - val_MinusLogProbMetric: 3.0973 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 4/1000
2023-09-15 13:55:20.643 
Epoch 4/1000 
	 loss: 2.8459, MinusLogProbMetric: 2.8459, val_loss: 2.9827, val_MinusLogProbMetric: 2.9827

Epoch 4: val_loss improved from 3.09733 to 2.98268, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 61s - loss: 2.8459 - MinusLogProbMetric: 2.8459 - val_loss: 2.9827 - val_MinusLogProbMetric: 2.9827 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 5/1000
2023-09-15 13:56:20.640 
Epoch 5/1000 
	 loss: 2.7720, MinusLogProbMetric: 2.7720, val_loss: 2.9562, val_MinusLogProbMetric: 2.9562

Epoch 5: val_loss improved from 2.98268 to 2.95615, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 60s - loss: 2.7720 - MinusLogProbMetric: 2.7720 - val_loss: 2.9562 - val_MinusLogProbMetric: 2.9562 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 6/1000
2023-09-15 13:57:22.025 
Epoch 6/1000 
	 loss: 2.7170, MinusLogProbMetric: 2.7170, val_loss: 2.7381, val_MinusLogProbMetric: 2.7381

Epoch 6: val_loss improved from 2.95615 to 2.73811, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 61s - loss: 2.7170 - MinusLogProbMetric: 2.7170 - val_loss: 2.7381 - val_MinusLogProbMetric: 2.7381 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 7/1000
2023-09-15 13:58:22.178 
Epoch 7/1000 
	 loss: 2.6347, MinusLogProbMetric: 2.6347, val_loss: 2.8605, val_MinusLogProbMetric: 2.8605

Epoch 7: val_loss did not improve from 2.73811
196/196 - 59s - loss: 2.6347 - MinusLogProbMetric: 2.6347 - val_loss: 2.8605 - val_MinusLogProbMetric: 2.8605 - lr: 0.0010 - 59s/epoch - 303ms/step
Epoch 8/1000
2023-09-15 13:59:21.595 
Epoch 8/1000 
	 loss: 2.6033, MinusLogProbMetric: 2.6033, val_loss: 2.8599, val_MinusLogProbMetric: 2.8599

Epoch 8: val_loss did not improve from 2.73811
196/196 - 59s - loss: 2.6033 - MinusLogProbMetric: 2.6033 - val_loss: 2.8599 - val_MinusLogProbMetric: 2.8599 - lr: 0.0010 - 59s/epoch - 303ms/step
Epoch 9/1000
2023-09-15 14:00:20.550 
Epoch 9/1000 
	 loss: 2.6106, MinusLogProbMetric: 2.6106, val_loss: 2.6209, val_MinusLogProbMetric: 2.6209

Epoch 9: val_loss improved from 2.73811 to 2.62092, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 60s - loss: 2.6106 - MinusLogProbMetric: 2.6106 - val_loss: 2.6209 - val_MinusLogProbMetric: 2.6209 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 10/1000
2023-09-15 14:01:20.487 
Epoch 10/1000 
	 loss: 2.5837, MinusLogProbMetric: 2.5837, val_loss: 2.5886, val_MinusLogProbMetric: 2.5886

Epoch 10: val_loss improved from 2.62092 to 2.58856, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 60s - loss: 2.5837 - MinusLogProbMetric: 2.5837 - val_loss: 2.5886 - val_MinusLogProbMetric: 2.5886 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 11/1000
2023-09-15 14:02:21.542 
Epoch 11/1000 
	 loss: 2.5501, MinusLogProbMetric: 2.5501, val_loss: 2.5158, val_MinusLogProbMetric: 2.5158

Epoch 11: val_loss improved from 2.58856 to 2.51580, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 61s - loss: 2.5501 - MinusLogProbMetric: 2.5501 - val_loss: 2.5158 - val_MinusLogProbMetric: 2.5158 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 12/1000
2023-09-15 14:03:22.392 
Epoch 12/1000 
	 loss: 2.5368, MinusLogProbMetric: 2.5368, val_loss: 2.6489, val_MinusLogProbMetric: 2.6489

Epoch 12: val_loss did not improve from 2.51580
196/196 - 60s - loss: 2.5368 - MinusLogProbMetric: 2.5368 - val_loss: 2.6489 - val_MinusLogProbMetric: 2.6489 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 13/1000
2023-09-15 14:04:22.263 
Epoch 13/1000 
	 loss: 2.5374, MinusLogProbMetric: 2.5374, val_loss: 2.5501, val_MinusLogProbMetric: 2.5501

Epoch 13: val_loss did not improve from 2.51580
196/196 - 60s - loss: 2.5374 - MinusLogProbMetric: 2.5374 - val_loss: 2.5501 - val_MinusLogProbMetric: 2.5501 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 14/1000
2023-09-15 14:05:22.617 
Epoch 14/1000 
	 loss: 2.5510, MinusLogProbMetric: 2.5510, val_loss: 2.4983, val_MinusLogProbMetric: 2.4983

Epoch 14: val_loss improved from 2.51580 to 2.49833, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 61s - loss: 2.5510 - MinusLogProbMetric: 2.5510 - val_loss: 2.4983 - val_MinusLogProbMetric: 2.4983 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 15/1000
2023-09-15 14:06:23.076 
Epoch 15/1000 
	 loss: 2.4981, MinusLogProbMetric: 2.4981, val_loss: 2.5120, val_MinusLogProbMetric: 2.5120

Epoch 15: val_loss did not improve from 2.49833
196/196 - 60s - loss: 2.4981 - MinusLogProbMetric: 2.4981 - val_loss: 2.5120 - val_MinusLogProbMetric: 2.5120 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 16/1000
2023-09-15 14:07:23.144 
Epoch 16/1000 
	 loss: 2.5222, MinusLogProbMetric: 2.5222, val_loss: 2.5257, val_MinusLogProbMetric: 2.5257

Epoch 16: val_loss did not improve from 2.49833
196/196 - 60s - loss: 2.5222 - MinusLogProbMetric: 2.5222 - val_loss: 2.5257 - val_MinusLogProbMetric: 2.5257 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 17/1000
2023-09-15 14:08:23.576 
Epoch 17/1000 
	 loss: 2.4955, MinusLogProbMetric: 2.4955, val_loss: 2.4932, val_MinusLogProbMetric: 2.4932

Epoch 17: val_loss improved from 2.49833 to 2.49317, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 61s - loss: 2.4955 - MinusLogProbMetric: 2.4955 - val_loss: 2.4932 - val_MinusLogProbMetric: 2.4932 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 18/1000
2023-09-15 14:09:24.331 
Epoch 18/1000 
	 loss: 2.4906, MinusLogProbMetric: 2.4906, val_loss: 2.4417, val_MinusLogProbMetric: 2.4417

Epoch 18: val_loss improved from 2.49317 to 2.44172, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 61s - loss: 2.4906 - MinusLogProbMetric: 2.4906 - val_loss: 2.4417 - val_MinusLogProbMetric: 2.4417 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 19/1000
2023-09-15 14:10:25.265 
Epoch 19/1000 
	 loss: 2.4902, MinusLogProbMetric: 2.4902, val_loss: 2.5529, val_MinusLogProbMetric: 2.5529

Epoch 19: val_loss did not improve from 2.44172
196/196 - 60s - loss: 2.4902 - MinusLogProbMetric: 2.4902 - val_loss: 2.5529 - val_MinusLogProbMetric: 2.5529 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 20/1000
2023-09-15 14:11:24.926 
Epoch 20/1000 
	 loss: 2.4829, MinusLogProbMetric: 2.4829, val_loss: 2.5774, val_MinusLogProbMetric: 2.5774

Epoch 20: val_loss did not improve from 2.44172
196/196 - 60s - loss: 2.4829 - MinusLogProbMetric: 2.4829 - val_loss: 2.5774 - val_MinusLogProbMetric: 2.5774 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 21/1000
2023-09-15 14:12:24.569 
Epoch 21/1000 
	 loss: 2.4799, MinusLogProbMetric: 2.4799, val_loss: 2.4420, val_MinusLogProbMetric: 2.4420

Epoch 21: val_loss did not improve from 2.44172
196/196 - 60s - loss: 2.4799 - MinusLogProbMetric: 2.4799 - val_loss: 2.4420 - val_MinusLogProbMetric: 2.4420 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 22/1000
2023-09-15 14:13:24.971 
Epoch 22/1000 
	 loss: 2.4876, MinusLogProbMetric: 2.4876, val_loss: 2.5200, val_MinusLogProbMetric: 2.5200

Epoch 22: val_loss did not improve from 2.44172
196/196 - 60s - loss: 2.4876 - MinusLogProbMetric: 2.4876 - val_loss: 2.5200 - val_MinusLogProbMetric: 2.5200 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 23/1000
2023-09-15 14:14:24.551 
Epoch 23/1000 
	 loss: 2.4649, MinusLogProbMetric: 2.4649, val_loss: 2.5078, val_MinusLogProbMetric: 2.5078

Epoch 23: val_loss did not improve from 2.44172
196/196 - 60s - loss: 2.4649 - MinusLogProbMetric: 2.4649 - val_loss: 2.5078 - val_MinusLogProbMetric: 2.5078 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 24/1000
2023-09-15 14:15:25.392 
Epoch 24/1000 
	 loss: 2.4704, MinusLogProbMetric: 2.4704, val_loss: 2.4759, val_MinusLogProbMetric: 2.4759

Epoch 24: val_loss did not improve from 2.44172
196/196 - 61s - loss: 2.4704 - MinusLogProbMetric: 2.4704 - val_loss: 2.4759 - val_MinusLogProbMetric: 2.4759 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 25/1000
2023-09-15 14:16:25.255 
Epoch 25/1000 
	 loss: 2.4736, MinusLogProbMetric: 2.4736, val_loss: 2.4885, val_MinusLogProbMetric: 2.4885

Epoch 25: val_loss did not improve from 2.44172
196/196 - 60s - loss: 2.4736 - MinusLogProbMetric: 2.4736 - val_loss: 2.4885 - val_MinusLogProbMetric: 2.4885 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 26/1000
2023-09-15 14:17:25.659 
Epoch 26/1000 
	 loss: 2.4618, MinusLogProbMetric: 2.4618, val_loss: 2.4797, val_MinusLogProbMetric: 2.4797

Epoch 26: val_loss did not improve from 2.44172
196/196 - 60s - loss: 2.4618 - MinusLogProbMetric: 2.4618 - val_loss: 2.4797 - val_MinusLogProbMetric: 2.4797 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 27/1000
2023-09-15 14:18:25.527 
Epoch 27/1000 
	 loss: 2.4678, MinusLogProbMetric: 2.4678, val_loss: 2.4539, val_MinusLogProbMetric: 2.4539

Epoch 27: val_loss did not improve from 2.44172
196/196 - 60s - loss: 2.4678 - MinusLogProbMetric: 2.4678 - val_loss: 2.4539 - val_MinusLogProbMetric: 2.4539 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 28/1000
2023-09-15 14:19:25.405 
Epoch 28/1000 
	 loss: 2.4583, MinusLogProbMetric: 2.4583, val_loss: 2.4912, val_MinusLogProbMetric: 2.4912

Epoch 28: val_loss did not improve from 2.44172
196/196 - 60s - loss: 2.4583 - MinusLogProbMetric: 2.4583 - val_loss: 2.4912 - val_MinusLogProbMetric: 2.4912 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 29/1000
2023-09-15 14:20:25.117 
Epoch 29/1000 
	 loss: 2.4529, MinusLogProbMetric: 2.4529, val_loss: 2.4785, val_MinusLogProbMetric: 2.4785

Epoch 29: val_loss did not improve from 2.44172
196/196 - 60s - loss: 2.4529 - MinusLogProbMetric: 2.4529 - val_loss: 2.4785 - val_MinusLogProbMetric: 2.4785 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 30/1000
2023-09-15 14:21:25.470 
Epoch 30/1000 
	 loss: 2.4692, MinusLogProbMetric: 2.4692, val_loss: 2.4843, val_MinusLogProbMetric: 2.4843

Epoch 30: val_loss did not improve from 2.44172
196/196 - 60s - loss: 2.4692 - MinusLogProbMetric: 2.4692 - val_loss: 2.4843 - val_MinusLogProbMetric: 2.4843 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 31/1000
2023-09-15 14:22:25.293 
Epoch 31/1000 
	 loss: 2.4576, MinusLogProbMetric: 2.4576, val_loss: 2.4189, val_MinusLogProbMetric: 2.4189

Epoch 31: val_loss improved from 2.44172 to 2.41889, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 61s - loss: 2.4576 - MinusLogProbMetric: 2.4576 - val_loss: 2.4189 - val_MinusLogProbMetric: 2.4189 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 32/1000
2023-09-15 14:23:26.193 
Epoch 32/1000 
	 loss: 2.4501, MinusLogProbMetric: 2.4501, val_loss: 2.4126, val_MinusLogProbMetric: 2.4126

Epoch 32: val_loss improved from 2.41889 to 2.41259, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 61s - loss: 2.4501 - MinusLogProbMetric: 2.4501 - val_loss: 2.4126 - val_MinusLogProbMetric: 2.4126 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 33/1000
2023-09-15 14:24:27.220 
Epoch 33/1000 
	 loss: 2.4418, MinusLogProbMetric: 2.4418, val_loss: 2.4920, val_MinusLogProbMetric: 2.4920

Epoch 33: val_loss did not improve from 2.41259
196/196 - 60s - loss: 2.4418 - MinusLogProbMetric: 2.4418 - val_loss: 2.4920 - val_MinusLogProbMetric: 2.4920 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 34/1000
2023-09-15 14:25:26.855 
Epoch 34/1000 
	 loss: 2.4573, MinusLogProbMetric: 2.4573, val_loss: 2.4521, val_MinusLogProbMetric: 2.4521

Epoch 34: val_loss did not improve from 2.41259
196/196 - 60s - loss: 2.4573 - MinusLogProbMetric: 2.4573 - val_loss: 2.4521 - val_MinusLogProbMetric: 2.4521 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 35/1000
2023-09-15 14:26:26.945 
Epoch 35/1000 
	 loss: 2.4390, MinusLogProbMetric: 2.4390, val_loss: 2.5461, val_MinusLogProbMetric: 2.5461

Epoch 35: val_loss did not improve from 2.41259
196/196 - 60s - loss: 2.4390 - MinusLogProbMetric: 2.4390 - val_loss: 2.5461 - val_MinusLogProbMetric: 2.5461 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 36/1000
2023-09-15 14:27:27.537 
Epoch 36/1000 
	 loss: 2.4452, MinusLogProbMetric: 2.4452, val_loss: 2.4204, val_MinusLogProbMetric: 2.4204

Epoch 36: val_loss did not improve from 2.41259
196/196 - 61s - loss: 2.4452 - MinusLogProbMetric: 2.4452 - val_loss: 2.4204 - val_MinusLogProbMetric: 2.4204 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 37/1000
2023-09-15 14:28:27.252 
Epoch 37/1000 
	 loss: 2.4494, MinusLogProbMetric: 2.4494, val_loss: 2.4689, val_MinusLogProbMetric: 2.4689

Epoch 37: val_loss did not improve from 2.41259
196/196 - 60s - loss: 2.4494 - MinusLogProbMetric: 2.4494 - val_loss: 2.4689 - val_MinusLogProbMetric: 2.4689 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 38/1000
2023-09-15 14:29:27.915 
Epoch 38/1000 
	 loss: 2.4363, MinusLogProbMetric: 2.4363, val_loss: 2.5789, val_MinusLogProbMetric: 2.5789

Epoch 38: val_loss did not improve from 2.41259
196/196 - 61s - loss: 2.4363 - MinusLogProbMetric: 2.4363 - val_loss: 2.5789 - val_MinusLogProbMetric: 2.5789 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 39/1000
2023-09-15 14:30:28.124 
Epoch 39/1000 
	 loss: 2.4404, MinusLogProbMetric: 2.4404, val_loss: 2.4204, val_MinusLogProbMetric: 2.4204

Epoch 39: val_loss did not improve from 2.41259
196/196 - 60s - loss: 2.4404 - MinusLogProbMetric: 2.4404 - val_loss: 2.4204 - val_MinusLogProbMetric: 2.4204 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 40/1000
2023-09-15 14:31:28.118 
Epoch 40/1000 
	 loss: 2.4328, MinusLogProbMetric: 2.4328, val_loss: 2.4608, val_MinusLogProbMetric: 2.4608

Epoch 40: val_loss did not improve from 2.41259
196/196 - 60s - loss: 2.4328 - MinusLogProbMetric: 2.4328 - val_loss: 2.4608 - val_MinusLogProbMetric: 2.4608 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 41/1000
2023-09-15 14:32:28.336 
Epoch 41/1000 
	 loss: 2.4417, MinusLogProbMetric: 2.4417, val_loss: 2.5185, val_MinusLogProbMetric: 2.5185

Epoch 41: val_loss did not improve from 2.41259
196/196 - 60s - loss: 2.4417 - MinusLogProbMetric: 2.4417 - val_loss: 2.5185 - val_MinusLogProbMetric: 2.5185 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 42/1000
2023-09-15 14:33:27.949 
Epoch 42/1000 
	 loss: 2.4365, MinusLogProbMetric: 2.4365, val_loss: 2.4138, val_MinusLogProbMetric: 2.4138

Epoch 42: val_loss did not improve from 2.41259
196/196 - 60s - loss: 2.4365 - MinusLogProbMetric: 2.4365 - val_loss: 2.4138 - val_MinusLogProbMetric: 2.4138 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 43/1000
2023-09-15 14:34:28.779 
Epoch 43/1000 
	 loss: 2.4382, MinusLogProbMetric: 2.4382, val_loss: 2.5202, val_MinusLogProbMetric: 2.5202

Epoch 43: val_loss did not improve from 2.41259
196/196 - 61s - loss: 2.4382 - MinusLogProbMetric: 2.4382 - val_loss: 2.5202 - val_MinusLogProbMetric: 2.5202 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 44/1000
2023-09-15 14:35:28.750 
Epoch 44/1000 
	 loss: 2.4345, MinusLogProbMetric: 2.4345, val_loss: 2.4297, val_MinusLogProbMetric: 2.4297

Epoch 44: val_loss did not improve from 2.41259
196/196 - 60s - loss: 2.4345 - MinusLogProbMetric: 2.4345 - val_loss: 2.4297 - val_MinusLogProbMetric: 2.4297 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 45/1000
2023-09-15 14:36:28.851 
Epoch 45/1000 
	 loss: 2.4316, MinusLogProbMetric: 2.4316, val_loss: 2.4229, val_MinusLogProbMetric: 2.4229

Epoch 45: val_loss did not improve from 2.41259
196/196 - 60s - loss: 2.4316 - MinusLogProbMetric: 2.4316 - val_loss: 2.4229 - val_MinusLogProbMetric: 2.4229 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 46/1000
2023-09-15 14:37:29.067 
Epoch 46/1000 
	 loss: 2.4317, MinusLogProbMetric: 2.4317, val_loss: 2.4113, val_MinusLogProbMetric: 2.4113

Epoch 46: val_loss improved from 2.41259 to 2.41125, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 61s - loss: 2.4317 - MinusLogProbMetric: 2.4317 - val_loss: 2.4113 - val_MinusLogProbMetric: 2.4113 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 47/1000
2023-09-15 14:38:30.064 
Epoch 47/1000 
	 loss: 2.4246, MinusLogProbMetric: 2.4246, val_loss: 2.4122, val_MinusLogProbMetric: 2.4122

Epoch 47: val_loss did not improve from 2.41125
196/196 - 60s - loss: 2.4246 - MinusLogProbMetric: 2.4246 - val_loss: 2.4122 - val_MinusLogProbMetric: 2.4122 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 48/1000
2023-09-15 14:39:30.166 
Epoch 48/1000 
	 loss: 2.4282, MinusLogProbMetric: 2.4282, val_loss: 2.4379, val_MinusLogProbMetric: 2.4379

Epoch 48: val_loss did not improve from 2.41125
196/196 - 60s - loss: 2.4282 - MinusLogProbMetric: 2.4282 - val_loss: 2.4379 - val_MinusLogProbMetric: 2.4379 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 49/1000
2023-09-15 14:40:30.527 
Epoch 49/1000 
	 loss: 2.4289, MinusLogProbMetric: 2.4289, val_loss: 2.4673, val_MinusLogProbMetric: 2.4673

Epoch 49: val_loss did not improve from 2.41125
196/196 - 60s - loss: 2.4289 - MinusLogProbMetric: 2.4289 - val_loss: 2.4673 - val_MinusLogProbMetric: 2.4673 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 50/1000
2023-09-15 14:41:30.289 
Epoch 50/1000 
	 loss: 2.4334, MinusLogProbMetric: 2.4334, val_loss: 2.4676, val_MinusLogProbMetric: 2.4676

Epoch 50: val_loss did not improve from 2.41125
196/196 - 60s - loss: 2.4334 - MinusLogProbMetric: 2.4334 - val_loss: 2.4676 - val_MinusLogProbMetric: 2.4676 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 51/1000
2023-09-15 14:42:30.334 
Epoch 51/1000 
	 loss: 2.4315, MinusLogProbMetric: 2.4315, val_loss: 2.4108, val_MinusLogProbMetric: 2.4108

Epoch 51: val_loss improved from 2.41125 to 2.41078, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 61s - loss: 2.4315 - MinusLogProbMetric: 2.4315 - val_loss: 2.4108 - val_MinusLogProbMetric: 2.4108 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 52/1000
2023-09-15 14:43:31.459 
Epoch 52/1000 
	 loss: 2.4288, MinusLogProbMetric: 2.4288, val_loss: 2.4528, val_MinusLogProbMetric: 2.4528

Epoch 52: val_loss did not improve from 2.41078
196/196 - 60s - loss: 2.4288 - MinusLogProbMetric: 2.4288 - val_loss: 2.4528 - val_MinusLogProbMetric: 2.4528 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 53/1000
2023-09-15 14:44:31.747 
Epoch 53/1000 
	 loss: 2.4189, MinusLogProbMetric: 2.4189, val_loss: 2.4942, val_MinusLogProbMetric: 2.4942

Epoch 53: val_loss did not improve from 2.41078
196/196 - 60s - loss: 2.4189 - MinusLogProbMetric: 2.4189 - val_loss: 2.4942 - val_MinusLogProbMetric: 2.4942 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 54/1000
2023-09-15 14:45:31.920 
Epoch 54/1000 
	 loss: 2.4207, MinusLogProbMetric: 2.4207, val_loss: 2.4357, val_MinusLogProbMetric: 2.4357

Epoch 54: val_loss did not improve from 2.41078
196/196 - 60s - loss: 2.4207 - MinusLogProbMetric: 2.4207 - val_loss: 2.4357 - val_MinusLogProbMetric: 2.4357 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 55/1000
2023-09-15 14:46:32.105 
Epoch 55/1000 
	 loss: 2.4246, MinusLogProbMetric: 2.4246, val_loss: 2.4610, val_MinusLogProbMetric: 2.4610

Epoch 55: val_loss did not improve from 2.41078
196/196 - 60s - loss: 2.4246 - MinusLogProbMetric: 2.4246 - val_loss: 2.4610 - val_MinusLogProbMetric: 2.4610 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 56/1000
2023-09-15 14:47:32.595 
Epoch 56/1000 
	 loss: 2.4223, MinusLogProbMetric: 2.4223, val_loss: 2.4593, val_MinusLogProbMetric: 2.4593

Epoch 56: val_loss did not improve from 2.41078
196/196 - 60s - loss: 2.4223 - MinusLogProbMetric: 2.4223 - val_loss: 2.4593 - val_MinusLogProbMetric: 2.4593 - lr: 0.0010 - 60s/epoch - 309ms/step
Epoch 57/1000
2023-09-15 14:48:32.821 
Epoch 57/1000 
	 loss: 2.4212, MinusLogProbMetric: 2.4212, val_loss: 2.4920, val_MinusLogProbMetric: 2.4920

Epoch 57: val_loss did not improve from 2.41078
196/196 - 60s - loss: 2.4212 - MinusLogProbMetric: 2.4212 - val_loss: 2.4920 - val_MinusLogProbMetric: 2.4920 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 58/1000
2023-09-15 14:49:33.303 
Epoch 58/1000 
	 loss: 2.4162, MinusLogProbMetric: 2.4162, val_loss: 2.4120, val_MinusLogProbMetric: 2.4120

Epoch 58: val_loss did not improve from 2.41078
196/196 - 60s - loss: 2.4162 - MinusLogProbMetric: 2.4162 - val_loss: 2.4120 - val_MinusLogProbMetric: 2.4120 - lr: 0.0010 - 60s/epoch - 309ms/step
Epoch 59/1000
2023-09-15 14:50:33.857 
Epoch 59/1000 
	 loss: 2.4229, MinusLogProbMetric: 2.4229, val_loss: 2.3957, val_MinusLogProbMetric: 2.3957

Epoch 59: val_loss improved from 2.41078 to 2.39574, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 61s - loss: 2.4229 - MinusLogProbMetric: 2.4229 - val_loss: 2.3957 - val_MinusLogProbMetric: 2.3957 - lr: 0.0010 - 61s/epoch - 314ms/step
Epoch 60/1000
2023-09-15 14:51:34.760 
Epoch 60/1000 
	 loss: 2.4178, MinusLogProbMetric: 2.4178, val_loss: 2.4190, val_MinusLogProbMetric: 2.4190

Epoch 60: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4178 - MinusLogProbMetric: 2.4178 - val_loss: 2.4190 - val_MinusLogProbMetric: 2.4190 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 61/1000
2023-09-15 14:52:32.658 
Epoch 61/1000 
	 loss: 2.4166, MinusLogProbMetric: 2.4166, val_loss: 2.4129, val_MinusLogProbMetric: 2.4129

Epoch 61: val_loss did not improve from 2.39574
196/196 - 58s - loss: 2.4166 - MinusLogProbMetric: 2.4166 - val_loss: 2.4129 - val_MinusLogProbMetric: 2.4129 - lr: 0.0010 - 58s/epoch - 295ms/step
Epoch 62/1000
2023-09-15 14:53:25.543 
Epoch 62/1000 
	 loss: 2.4185, MinusLogProbMetric: 2.4185, val_loss: 2.4557, val_MinusLogProbMetric: 2.4557

Epoch 62: val_loss did not improve from 2.39574
196/196 - 53s - loss: 2.4185 - MinusLogProbMetric: 2.4185 - val_loss: 2.4557 - val_MinusLogProbMetric: 2.4557 - lr: 0.0010 - 53s/epoch - 270ms/step
Epoch 63/1000
2023-09-15 14:54:19.737 
Epoch 63/1000 
	 loss: 2.4167, MinusLogProbMetric: 2.4167, val_loss: 2.4486, val_MinusLogProbMetric: 2.4486

Epoch 63: val_loss did not improve from 2.39574
196/196 - 54s - loss: 2.4167 - MinusLogProbMetric: 2.4167 - val_loss: 2.4486 - val_MinusLogProbMetric: 2.4486 - lr: 0.0010 - 54s/epoch - 276ms/step
Epoch 64/1000
2023-09-15 14:55:19.198 
Epoch 64/1000 
	 loss: 2.4227, MinusLogProbMetric: 2.4227, val_loss: 2.4241, val_MinusLogProbMetric: 2.4241

Epoch 64: val_loss did not improve from 2.39574
196/196 - 59s - loss: 2.4227 - MinusLogProbMetric: 2.4227 - val_loss: 2.4241 - val_MinusLogProbMetric: 2.4241 - lr: 0.0010 - 59s/epoch - 303ms/step
Epoch 65/1000
2023-09-15 14:56:18.383 
Epoch 65/1000 
	 loss: 2.4170, MinusLogProbMetric: 2.4170, val_loss: 2.4143, val_MinusLogProbMetric: 2.4143

Epoch 65: val_loss did not improve from 2.39574
196/196 - 59s - loss: 2.4170 - MinusLogProbMetric: 2.4170 - val_loss: 2.4143 - val_MinusLogProbMetric: 2.4143 - lr: 0.0010 - 59s/epoch - 302ms/step
Epoch 66/1000
2023-09-15 14:57:17.579 
Epoch 66/1000 
	 loss: 2.4151, MinusLogProbMetric: 2.4151, val_loss: 2.4296, val_MinusLogProbMetric: 2.4296

Epoch 66: val_loss did not improve from 2.39574
196/196 - 59s - loss: 2.4151 - MinusLogProbMetric: 2.4151 - val_loss: 2.4296 - val_MinusLogProbMetric: 2.4296 - lr: 0.0010 - 59s/epoch - 302ms/step
Epoch 67/1000
2023-09-15 14:58:17.578 
Epoch 67/1000 
	 loss: 2.4135, MinusLogProbMetric: 2.4135, val_loss: 2.3970, val_MinusLogProbMetric: 2.3970

Epoch 67: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4135 - MinusLogProbMetric: 2.4135 - val_loss: 2.3970 - val_MinusLogProbMetric: 2.3970 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 68/1000
2023-09-15 14:59:17.604 
Epoch 68/1000 
	 loss: 2.4148, MinusLogProbMetric: 2.4148, val_loss: 2.4016, val_MinusLogProbMetric: 2.4016

Epoch 68: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4148 - MinusLogProbMetric: 2.4148 - val_loss: 2.4016 - val_MinusLogProbMetric: 2.4016 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 69/1000
2023-09-15 15:00:17.074 
Epoch 69/1000 
	 loss: 2.4178, MinusLogProbMetric: 2.4178, val_loss: 2.4064, val_MinusLogProbMetric: 2.4064

Epoch 69: val_loss did not improve from 2.39574
196/196 - 59s - loss: 2.4178 - MinusLogProbMetric: 2.4178 - val_loss: 2.4064 - val_MinusLogProbMetric: 2.4064 - lr: 0.0010 - 59s/epoch - 303ms/step
Epoch 70/1000
2023-09-15 15:01:17.262 
Epoch 70/1000 
	 loss: 2.4148, MinusLogProbMetric: 2.4148, val_loss: 2.4184, val_MinusLogProbMetric: 2.4184

Epoch 70: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4148 - MinusLogProbMetric: 2.4148 - val_loss: 2.4184 - val_MinusLogProbMetric: 2.4184 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 71/1000
2023-09-15 15:02:16.772 
Epoch 71/1000 
	 loss: 2.4158, MinusLogProbMetric: 2.4158, val_loss: 2.4025, val_MinusLogProbMetric: 2.4025

Epoch 71: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4158 - MinusLogProbMetric: 2.4158 - val_loss: 2.4025 - val_MinusLogProbMetric: 2.4025 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 72/1000
2023-09-15 15:03:16.869 
Epoch 72/1000 
	 loss: 2.4195, MinusLogProbMetric: 2.4195, val_loss: 2.4070, val_MinusLogProbMetric: 2.4070

Epoch 72: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4195 - MinusLogProbMetric: 2.4195 - val_loss: 2.4070 - val_MinusLogProbMetric: 2.4070 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 73/1000
2023-09-15 15:04:16.634 
Epoch 73/1000 
	 loss: 2.4143, MinusLogProbMetric: 2.4143, val_loss: 2.4362, val_MinusLogProbMetric: 2.4362

Epoch 73: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4143 - MinusLogProbMetric: 2.4143 - val_loss: 2.4362 - val_MinusLogProbMetric: 2.4362 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 74/1000
2023-09-15 15:05:16.662 
Epoch 74/1000 
	 loss: 2.4167, MinusLogProbMetric: 2.4167, val_loss: 2.4056, val_MinusLogProbMetric: 2.4056

Epoch 74: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4167 - MinusLogProbMetric: 2.4167 - val_loss: 2.4056 - val_MinusLogProbMetric: 2.4056 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 75/1000
2023-09-15 15:06:16.791 
Epoch 75/1000 
	 loss: 2.4156, MinusLogProbMetric: 2.4156, val_loss: 2.4296, val_MinusLogProbMetric: 2.4296

Epoch 75: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4156 - MinusLogProbMetric: 2.4156 - val_loss: 2.4296 - val_MinusLogProbMetric: 2.4296 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 76/1000
2023-09-15 15:07:16.806 
Epoch 76/1000 
	 loss: 2.4205, MinusLogProbMetric: 2.4205, val_loss: 2.4343, val_MinusLogProbMetric: 2.4343

Epoch 76: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4205 - MinusLogProbMetric: 2.4205 - val_loss: 2.4343 - val_MinusLogProbMetric: 2.4343 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 77/1000
2023-09-15 15:08:17.282 
Epoch 77/1000 
	 loss: 2.4131, MinusLogProbMetric: 2.4131, val_loss: 2.4387, val_MinusLogProbMetric: 2.4387

Epoch 77: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4131 - MinusLogProbMetric: 2.4131 - val_loss: 2.4387 - val_MinusLogProbMetric: 2.4387 - lr: 0.0010 - 60s/epoch - 309ms/step
Epoch 78/1000
2023-09-15 15:09:17.571 
Epoch 78/1000 
	 loss: 2.4121, MinusLogProbMetric: 2.4121, val_loss: 2.4117, val_MinusLogProbMetric: 2.4117

Epoch 78: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4121 - MinusLogProbMetric: 2.4121 - val_loss: 2.4117 - val_MinusLogProbMetric: 2.4117 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 79/1000
2023-09-15 15:10:17.681 
Epoch 79/1000 
	 loss: 2.4173, MinusLogProbMetric: 2.4173, val_loss: 2.4202, val_MinusLogProbMetric: 2.4202

Epoch 79: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4173 - MinusLogProbMetric: 2.4173 - val_loss: 2.4202 - val_MinusLogProbMetric: 2.4202 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 80/1000
2023-09-15 15:11:17.420 
Epoch 80/1000 
	 loss: 2.4073, MinusLogProbMetric: 2.4073, val_loss: 2.4333, val_MinusLogProbMetric: 2.4333

Epoch 80: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4073 - MinusLogProbMetric: 2.4073 - val_loss: 2.4333 - val_MinusLogProbMetric: 2.4333 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 81/1000
2023-09-15 15:12:17.835 
Epoch 81/1000 
	 loss: 2.4027, MinusLogProbMetric: 2.4027, val_loss: 2.3992, val_MinusLogProbMetric: 2.3992

Epoch 81: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4027 - MinusLogProbMetric: 2.4027 - val_loss: 2.3992 - val_MinusLogProbMetric: 2.3992 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 82/1000
2023-09-15 15:13:18.129 
Epoch 82/1000 
	 loss: 2.4071, MinusLogProbMetric: 2.4071, val_loss: 2.4198, val_MinusLogProbMetric: 2.4198

Epoch 82: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4071 - MinusLogProbMetric: 2.4071 - val_loss: 2.4198 - val_MinusLogProbMetric: 2.4198 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 83/1000
2023-09-15 15:14:18.408 
Epoch 83/1000 
	 loss: 2.4057, MinusLogProbMetric: 2.4057, val_loss: 2.4163, val_MinusLogProbMetric: 2.4163

Epoch 83: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4057 - MinusLogProbMetric: 2.4057 - val_loss: 2.4163 - val_MinusLogProbMetric: 2.4163 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 84/1000
2023-09-15 15:15:17.959 
Epoch 84/1000 
	 loss: 2.4083, MinusLogProbMetric: 2.4083, val_loss: 2.4082, val_MinusLogProbMetric: 2.4082

Epoch 84: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4083 - MinusLogProbMetric: 2.4083 - val_loss: 2.4082 - val_MinusLogProbMetric: 2.4082 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 85/1000
2023-09-15 15:16:18.164 
Epoch 85/1000 
	 loss: 2.4064, MinusLogProbMetric: 2.4064, val_loss: 2.4162, val_MinusLogProbMetric: 2.4162

Epoch 85: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4064 - MinusLogProbMetric: 2.4064 - val_loss: 2.4162 - val_MinusLogProbMetric: 2.4162 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 86/1000
2023-09-15 15:17:18.107 
Epoch 86/1000 
	 loss: 2.4052, MinusLogProbMetric: 2.4052, val_loss: 2.4877, val_MinusLogProbMetric: 2.4877

Epoch 86: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4052 - MinusLogProbMetric: 2.4052 - val_loss: 2.4877 - val_MinusLogProbMetric: 2.4877 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 87/1000
2023-09-15 15:18:18.092 
Epoch 87/1000 
	 loss: 2.4121, MinusLogProbMetric: 2.4121, val_loss: 2.4643, val_MinusLogProbMetric: 2.4643

Epoch 87: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4121 - MinusLogProbMetric: 2.4121 - val_loss: 2.4643 - val_MinusLogProbMetric: 2.4643 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 88/1000
2023-09-15 15:19:18.033 
Epoch 88/1000 
	 loss: 2.4119, MinusLogProbMetric: 2.4119, val_loss: 2.4105, val_MinusLogProbMetric: 2.4105

Epoch 88: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4119 - MinusLogProbMetric: 2.4119 - val_loss: 2.4105 - val_MinusLogProbMetric: 2.4105 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 89/1000
2023-09-15 15:20:17.569 
Epoch 89/1000 
	 loss: 2.4139, MinusLogProbMetric: 2.4139, val_loss: 2.4274, val_MinusLogProbMetric: 2.4274

Epoch 89: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4139 - MinusLogProbMetric: 2.4139 - val_loss: 2.4274 - val_MinusLogProbMetric: 2.4274 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 90/1000
2023-09-15 15:21:17.357 
Epoch 90/1000 
	 loss: 2.4093, MinusLogProbMetric: 2.4093, val_loss: 2.4191, val_MinusLogProbMetric: 2.4191

Epoch 90: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4093 - MinusLogProbMetric: 2.4093 - val_loss: 2.4191 - val_MinusLogProbMetric: 2.4191 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 91/1000
2023-09-15 15:22:17.633 
Epoch 91/1000 
	 loss: 2.4027, MinusLogProbMetric: 2.4027, val_loss: 2.4344, val_MinusLogProbMetric: 2.4344

Epoch 91: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4027 - MinusLogProbMetric: 2.4027 - val_loss: 2.4344 - val_MinusLogProbMetric: 2.4344 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 92/1000
2023-09-15 15:23:17.457 
Epoch 92/1000 
	 loss: 2.4090, MinusLogProbMetric: 2.4090, val_loss: 2.4228, val_MinusLogProbMetric: 2.4228

Epoch 92: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4090 - MinusLogProbMetric: 2.4090 - val_loss: 2.4228 - val_MinusLogProbMetric: 2.4228 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 93/1000
2023-09-15 15:24:17.866 
Epoch 93/1000 
	 loss: 2.4081, MinusLogProbMetric: 2.4081, val_loss: 2.4146, val_MinusLogProbMetric: 2.4146

Epoch 93: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4081 - MinusLogProbMetric: 2.4081 - val_loss: 2.4146 - val_MinusLogProbMetric: 2.4146 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 94/1000
2023-09-15 15:25:17.996 
Epoch 94/1000 
	 loss: 2.4018, MinusLogProbMetric: 2.4018, val_loss: 2.4135, val_MinusLogProbMetric: 2.4135

Epoch 94: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4018 - MinusLogProbMetric: 2.4018 - val_loss: 2.4135 - val_MinusLogProbMetric: 2.4135 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 95/1000
2023-09-15 15:26:18.086 
Epoch 95/1000 
	 loss: 2.4031, MinusLogProbMetric: 2.4031, val_loss: 2.4204, val_MinusLogProbMetric: 2.4204

Epoch 95: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4031 - MinusLogProbMetric: 2.4031 - val_loss: 2.4204 - val_MinusLogProbMetric: 2.4204 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 96/1000
2023-09-15 15:27:18.076 
Epoch 96/1000 
	 loss: 2.4073, MinusLogProbMetric: 2.4073, val_loss: 2.4109, val_MinusLogProbMetric: 2.4109

Epoch 96: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4073 - MinusLogProbMetric: 2.4073 - val_loss: 2.4109 - val_MinusLogProbMetric: 2.4109 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 97/1000
2023-09-15 15:28:18.331 
Epoch 97/1000 
	 loss: 2.4085, MinusLogProbMetric: 2.4085, val_loss: 2.4730, val_MinusLogProbMetric: 2.4730

Epoch 97: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4085 - MinusLogProbMetric: 2.4085 - val_loss: 2.4730 - val_MinusLogProbMetric: 2.4730 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 98/1000
2023-09-15 15:29:18.454 
Epoch 98/1000 
	 loss: 2.4132, MinusLogProbMetric: 2.4132, val_loss: 2.4616, val_MinusLogProbMetric: 2.4616

Epoch 98: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4132 - MinusLogProbMetric: 2.4132 - val_loss: 2.4616 - val_MinusLogProbMetric: 2.4616 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 99/1000
2023-09-15 15:30:18.356 
Epoch 99/1000 
	 loss: 2.4040, MinusLogProbMetric: 2.4040, val_loss: 2.4051, val_MinusLogProbMetric: 2.4051

Epoch 99: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4040 - MinusLogProbMetric: 2.4040 - val_loss: 2.4051 - val_MinusLogProbMetric: 2.4051 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 100/1000
2023-09-15 15:31:19.039 
Epoch 100/1000 
	 loss: 2.4006, MinusLogProbMetric: 2.4006, val_loss: 2.4813, val_MinusLogProbMetric: 2.4813

Epoch 100: val_loss did not improve from 2.39574
196/196 - 61s - loss: 2.4006 - MinusLogProbMetric: 2.4006 - val_loss: 2.4813 - val_MinusLogProbMetric: 2.4813 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 101/1000
2023-09-15 15:32:19.184 
Epoch 101/1000 
	 loss: 2.4117, MinusLogProbMetric: 2.4117, val_loss: 2.4197, val_MinusLogProbMetric: 2.4197

Epoch 101: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4117 - MinusLogProbMetric: 2.4117 - val_loss: 2.4197 - val_MinusLogProbMetric: 2.4197 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 102/1000
2023-09-15 15:33:19.615 
Epoch 102/1000 
	 loss: 2.4012, MinusLogProbMetric: 2.4012, val_loss: 2.4084, val_MinusLogProbMetric: 2.4084

Epoch 102: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4012 - MinusLogProbMetric: 2.4012 - val_loss: 2.4084 - val_MinusLogProbMetric: 2.4084 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 103/1000
2023-09-15 15:34:19.814 
Epoch 103/1000 
	 loss: 2.4043, MinusLogProbMetric: 2.4043, val_loss: 2.4199, val_MinusLogProbMetric: 2.4199

Epoch 103: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4043 - MinusLogProbMetric: 2.4043 - val_loss: 2.4199 - val_MinusLogProbMetric: 2.4199 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 104/1000
2023-09-15 15:35:19.119 
Epoch 104/1000 
	 loss: 2.4045, MinusLogProbMetric: 2.4045, val_loss: 2.4367, val_MinusLogProbMetric: 2.4367

Epoch 104: val_loss did not improve from 2.39574
196/196 - 59s - loss: 2.4045 - MinusLogProbMetric: 2.4045 - val_loss: 2.4367 - val_MinusLogProbMetric: 2.4367 - lr: 0.0010 - 59s/epoch - 303ms/step
Epoch 105/1000
2023-09-15 15:36:19.271 
Epoch 105/1000 
	 loss: 2.4010, MinusLogProbMetric: 2.4010, val_loss: 2.4295, val_MinusLogProbMetric: 2.4295

Epoch 105: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4010 - MinusLogProbMetric: 2.4010 - val_loss: 2.4295 - val_MinusLogProbMetric: 2.4295 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 106/1000
2023-09-15 15:37:18.818 
Epoch 106/1000 
	 loss: 2.4005, MinusLogProbMetric: 2.4005, val_loss: 2.4563, val_MinusLogProbMetric: 2.4563

Epoch 106: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4005 - MinusLogProbMetric: 2.4005 - val_loss: 2.4563 - val_MinusLogProbMetric: 2.4563 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 107/1000
2023-09-15 15:38:19.189 
Epoch 107/1000 
	 loss: 2.4027, MinusLogProbMetric: 2.4027, val_loss: 2.3989, val_MinusLogProbMetric: 2.3989

Epoch 107: val_loss did not improve from 2.39574
196/196 - 60s - loss: 2.4027 - MinusLogProbMetric: 2.4027 - val_loss: 2.3989 - val_MinusLogProbMetric: 2.3989 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 108/1000
2023-09-15 15:39:16.641 
Epoch 108/1000 
	 loss: 2.4039, MinusLogProbMetric: 2.4039, val_loss: 2.4242, val_MinusLogProbMetric: 2.4242

Epoch 108: val_loss did not improve from 2.39574
196/196 - 57s - loss: 2.4039 - MinusLogProbMetric: 2.4039 - val_loss: 2.4242 - val_MinusLogProbMetric: 2.4242 - lr: 0.0010 - 57s/epoch - 293ms/step
Epoch 109/1000
2023-09-15 15:40:09.860 
Epoch 109/1000 
	 loss: 2.4056, MinusLogProbMetric: 2.4056, val_loss: 2.4209, val_MinusLogProbMetric: 2.4209

Epoch 109: val_loss did not improve from 2.39574
196/196 - 53s - loss: 2.4056 - MinusLogProbMetric: 2.4056 - val_loss: 2.4209 - val_MinusLogProbMetric: 2.4209 - lr: 0.0010 - 53s/epoch - 272ms/step
Epoch 110/1000
2023-09-15 15:41:03.241 
Epoch 110/1000 
	 loss: 2.3829, MinusLogProbMetric: 2.3829, val_loss: 2.3858, val_MinusLogProbMetric: 2.3858

Epoch 110: val_loss improved from 2.39574 to 2.38582, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 54s - loss: 2.3829 - MinusLogProbMetric: 2.3829 - val_loss: 2.3858 - val_MinusLogProbMetric: 2.3858 - lr: 5.0000e-04 - 54s/epoch - 277ms/step
Epoch 111/1000
2023-09-15 15:42:03.800 
Epoch 111/1000 
	 loss: 2.3829, MinusLogProbMetric: 2.3829, val_loss: 2.4014, val_MinusLogProbMetric: 2.4014

Epoch 111: val_loss did not improve from 2.38582
196/196 - 60s - loss: 2.3829 - MinusLogProbMetric: 2.3829 - val_loss: 2.4014 - val_MinusLogProbMetric: 2.4014 - lr: 5.0000e-04 - 60s/epoch - 304ms/step
Epoch 112/1000
2023-09-15 15:43:02.720 
Epoch 112/1000 
	 loss: 2.3804, MinusLogProbMetric: 2.3804, val_loss: 2.3936, val_MinusLogProbMetric: 2.3936

Epoch 112: val_loss did not improve from 2.38582
196/196 - 59s - loss: 2.3804 - MinusLogProbMetric: 2.3804 - val_loss: 2.3936 - val_MinusLogProbMetric: 2.3936 - lr: 5.0000e-04 - 59s/epoch - 301ms/step
Epoch 113/1000
2023-09-15 15:44:02.107 
Epoch 113/1000 
	 loss: 2.3816, MinusLogProbMetric: 2.3816, val_loss: 2.4144, val_MinusLogProbMetric: 2.4144

Epoch 113: val_loss did not improve from 2.38582
196/196 - 59s - loss: 2.3816 - MinusLogProbMetric: 2.3816 - val_loss: 2.4144 - val_MinusLogProbMetric: 2.4144 - lr: 5.0000e-04 - 59s/epoch - 303ms/step
Epoch 114/1000
2023-09-15 15:45:01.314 
Epoch 114/1000 
	 loss: 2.3805, MinusLogProbMetric: 2.3805, val_loss: 2.3936, val_MinusLogProbMetric: 2.3936

Epoch 114: val_loss did not improve from 2.38582
196/196 - 59s - loss: 2.3805 - MinusLogProbMetric: 2.3805 - val_loss: 2.3936 - val_MinusLogProbMetric: 2.3936 - lr: 5.0000e-04 - 59s/epoch - 302ms/step
Epoch 115/1000
2023-09-15 15:46:02.052 
Epoch 115/1000 
	 loss: 2.3791, MinusLogProbMetric: 2.3791, val_loss: 2.3888, val_MinusLogProbMetric: 2.3888

Epoch 115: val_loss did not improve from 2.38582
196/196 - 61s - loss: 2.3791 - MinusLogProbMetric: 2.3791 - val_loss: 2.3888 - val_MinusLogProbMetric: 2.3888 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 116/1000
2023-09-15 15:47:02.578 
Epoch 116/1000 
	 loss: 2.3799, MinusLogProbMetric: 2.3799, val_loss: 2.3900, val_MinusLogProbMetric: 2.3900

Epoch 116: val_loss did not improve from 2.38582
196/196 - 61s - loss: 2.3799 - MinusLogProbMetric: 2.3799 - val_loss: 2.3900 - val_MinusLogProbMetric: 2.3900 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 117/1000
2023-09-15 15:48:02.763 
Epoch 117/1000 
	 loss: 2.3789, MinusLogProbMetric: 2.3789, val_loss: 2.3924, val_MinusLogProbMetric: 2.3924

Epoch 117: val_loss did not improve from 2.38582
196/196 - 60s - loss: 2.3789 - MinusLogProbMetric: 2.3789 - val_loss: 2.3924 - val_MinusLogProbMetric: 2.3924 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 118/1000
2023-09-15 15:49:02.821 
Epoch 118/1000 
	 loss: 2.3769, MinusLogProbMetric: 2.3769, val_loss: 2.3983, val_MinusLogProbMetric: 2.3983

Epoch 118: val_loss did not improve from 2.38582
196/196 - 60s - loss: 2.3769 - MinusLogProbMetric: 2.3769 - val_loss: 2.3983 - val_MinusLogProbMetric: 2.3983 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 119/1000
2023-09-15 15:50:02.809 
Epoch 119/1000 
	 loss: 2.3812, MinusLogProbMetric: 2.3812, val_loss: 2.4067, val_MinusLogProbMetric: 2.4067

Epoch 119: val_loss did not improve from 2.38582
196/196 - 60s - loss: 2.3812 - MinusLogProbMetric: 2.3812 - val_loss: 2.4067 - val_MinusLogProbMetric: 2.4067 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 120/1000
2023-09-15 15:51:02.701 
Epoch 120/1000 
	 loss: 2.3840, MinusLogProbMetric: 2.3840, val_loss: 2.3928, val_MinusLogProbMetric: 2.3928

Epoch 120: val_loss did not improve from 2.38582
196/196 - 60s - loss: 2.3840 - MinusLogProbMetric: 2.3840 - val_loss: 2.3928 - val_MinusLogProbMetric: 2.3928 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 121/1000
2023-09-15 15:52:03.544 
Epoch 121/1000 
	 loss: 2.3811, MinusLogProbMetric: 2.3811, val_loss: 2.4008, val_MinusLogProbMetric: 2.4008

Epoch 121: val_loss did not improve from 2.38582
196/196 - 61s - loss: 2.3811 - MinusLogProbMetric: 2.3811 - val_loss: 2.4008 - val_MinusLogProbMetric: 2.4008 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 122/1000
2023-09-15 15:53:03.970 
Epoch 122/1000 
	 loss: 2.3795, MinusLogProbMetric: 2.3795, val_loss: 2.3867, val_MinusLogProbMetric: 2.3867

Epoch 122: val_loss did not improve from 2.38582
196/196 - 60s - loss: 2.3795 - MinusLogProbMetric: 2.3795 - val_loss: 2.3867 - val_MinusLogProbMetric: 2.3867 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 123/1000
2023-09-15 15:54:04.535 
Epoch 123/1000 
	 loss: 2.3767, MinusLogProbMetric: 2.3767, val_loss: 2.4000, val_MinusLogProbMetric: 2.4000

Epoch 123: val_loss did not improve from 2.38582
196/196 - 61s - loss: 2.3767 - MinusLogProbMetric: 2.3767 - val_loss: 2.4000 - val_MinusLogProbMetric: 2.4000 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 124/1000
2023-09-15 15:55:05.906 
Epoch 124/1000 
	 loss: 2.3781, MinusLogProbMetric: 2.3781, val_loss: 2.4012, val_MinusLogProbMetric: 2.4012

Epoch 124: val_loss did not improve from 2.38582
196/196 - 61s - loss: 2.3781 - MinusLogProbMetric: 2.3781 - val_loss: 2.4012 - val_MinusLogProbMetric: 2.4012 - lr: 5.0000e-04 - 61s/epoch - 313ms/step
Epoch 125/1000
2023-09-15 15:56:06.989 
Epoch 125/1000 
	 loss: 2.3799, MinusLogProbMetric: 2.3799, val_loss: 2.3973, val_MinusLogProbMetric: 2.3973

Epoch 125: val_loss did not improve from 2.38582
196/196 - 61s - loss: 2.3799 - MinusLogProbMetric: 2.3799 - val_loss: 2.3973 - val_MinusLogProbMetric: 2.3973 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 126/1000
2023-09-15 15:57:07.611 
Epoch 126/1000 
	 loss: 2.3776, MinusLogProbMetric: 2.3776, val_loss: 2.4020, val_MinusLogProbMetric: 2.4020

Epoch 126: val_loss did not improve from 2.38582
196/196 - 61s - loss: 2.3776 - MinusLogProbMetric: 2.3776 - val_loss: 2.4020 - val_MinusLogProbMetric: 2.4020 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 127/1000
2023-09-15 15:58:08.453 
Epoch 127/1000 
	 loss: 2.3809, MinusLogProbMetric: 2.3809, val_loss: 2.3935, val_MinusLogProbMetric: 2.3935

Epoch 127: val_loss did not improve from 2.38582
196/196 - 61s - loss: 2.3809 - MinusLogProbMetric: 2.3809 - val_loss: 2.3935 - val_MinusLogProbMetric: 2.3935 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 128/1000
2023-09-15 15:59:08.832 
Epoch 128/1000 
	 loss: 2.3778, MinusLogProbMetric: 2.3778, val_loss: 2.3850, val_MinusLogProbMetric: 2.3850

Epoch 128: val_loss improved from 2.38582 to 2.38503, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 61s - loss: 2.3778 - MinusLogProbMetric: 2.3778 - val_loss: 2.3850 - val_MinusLogProbMetric: 2.3850 - lr: 5.0000e-04 - 61s/epoch - 313ms/step
Epoch 129/1000
2023-09-15 16:00:10.328 
Epoch 129/1000 
	 loss: 2.3782, MinusLogProbMetric: 2.3782, val_loss: 2.3969, val_MinusLogProbMetric: 2.3969

Epoch 129: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3782 - MinusLogProbMetric: 2.3782 - val_loss: 2.3969 - val_MinusLogProbMetric: 2.3969 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 130/1000
2023-09-15 16:01:10.779 
Epoch 130/1000 
	 loss: 2.3808, MinusLogProbMetric: 2.3808, val_loss: 2.3888, val_MinusLogProbMetric: 2.3888

Epoch 130: val_loss did not improve from 2.38503
196/196 - 60s - loss: 2.3808 - MinusLogProbMetric: 2.3808 - val_loss: 2.3888 - val_MinusLogProbMetric: 2.3888 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 131/1000
2023-09-15 16:02:12.383 
Epoch 131/1000 
	 loss: 2.3769, MinusLogProbMetric: 2.3769, val_loss: 2.3922, val_MinusLogProbMetric: 2.3922

Epoch 131: val_loss did not improve from 2.38503
196/196 - 62s - loss: 2.3769 - MinusLogProbMetric: 2.3769 - val_loss: 2.3922 - val_MinusLogProbMetric: 2.3922 - lr: 5.0000e-04 - 62s/epoch - 314ms/step
Epoch 132/1000
2023-09-15 16:03:13.134 
Epoch 132/1000 
	 loss: 2.3774, MinusLogProbMetric: 2.3774, val_loss: 2.3961, val_MinusLogProbMetric: 2.3961

Epoch 132: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3774 - MinusLogProbMetric: 2.3774 - val_loss: 2.3961 - val_MinusLogProbMetric: 2.3961 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 133/1000
2023-09-15 16:04:13.560 
Epoch 133/1000 
	 loss: 2.3791, MinusLogProbMetric: 2.3791, val_loss: 2.3874, val_MinusLogProbMetric: 2.3874

Epoch 133: val_loss did not improve from 2.38503
196/196 - 60s - loss: 2.3791 - MinusLogProbMetric: 2.3791 - val_loss: 2.3874 - val_MinusLogProbMetric: 2.3874 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 134/1000
2023-09-15 16:05:14.820 
Epoch 134/1000 
	 loss: 2.3809, MinusLogProbMetric: 2.3809, val_loss: 2.3995, val_MinusLogProbMetric: 2.3995

Epoch 134: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3809 - MinusLogProbMetric: 2.3809 - val_loss: 2.3995 - val_MinusLogProbMetric: 2.3995 - lr: 5.0000e-04 - 61s/epoch - 313ms/step
Epoch 135/1000
2023-09-15 16:06:15.796 
Epoch 135/1000 
	 loss: 2.3784, MinusLogProbMetric: 2.3784, val_loss: 2.3851, val_MinusLogProbMetric: 2.3851

Epoch 135: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3784 - MinusLogProbMetric: 2.3784 - val_loss: 2.3851 - val_MinusLogProbMetric: 2.3851 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 136/1000
2023-09-15 16:07:15.508 
Epoch 136/1000 
	 loss: 2.3766, MinusLogProbMetric: 2.3766, val_loss: 2.3859, val_MinusLogProbMetric: 2.3859

Epoch 136: val_loss did not improve from 2.38503
196/196 - 60s - loss: 2.3766 - MinusLogProbMetric: 2.3766 - val_loss: 2.3859 - val_MinusLogProbMetric: 2.3859 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 137/1000
2023-09-15 16:08:16.509 
Epoch 137/1000 
	 loss: 2.3790, MinusLogProbMetric: 2.3790, val_loss: 2.3931, val_MinusLogProbMetric: 2.3931

Epoch 137: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3790 - MinusLogProbMetric: 2.3790 - val_loss: 2.3931 - val_MinusLogProbMetric: 2.3931 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 138/1000
2023-09-15 16:09:17.088 
Epoch 138/1000 
	 loss: 2.3810, MinusLogProbMetric: 2.3810, val_loss: 2.4020, val_MinusLogProbMetric: 2.4020

Epoch 138: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3810 - MinusLogProbMetric: 2.3810 - val_loss: 2.4020 - val_MinusLogProbMetric: 2.4020 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 139/1000
2023-09-15 16:10:18.513 
Epoch 139/1000 
	 loss: 2.3770, MinusLogProbMetric: 2.3770, val_loss: 2.3931, val_MinusLogProbMetric: 2.3931

Epoch 139: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3770 - MinusLogProbMetric: 2.3770 - val_loss: 2.3931 - val_MinusLogProbMetric: 2.3931 - lr: 5.0000e-04 - 61s/epoch - 313ms/step
Epoch 140/1000
2023-09-15 16:11:19.577 
Epoch 140/1000 
	 loss: 2.3774, MinusLogProbMetric: 2.3774, val_loss: 2.3932, val_MinusLogProbMetric: 2.3932

Epoch 140: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3774 - MinusLogProbMetric: 2.3774 - val_loss: 2.3932 - val_MinusLogProbMetric: 2.3932 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 141/1000
2023-09-15 16:12:20.528 
Epoch 141/1000 
	 loss: 2.3775, MinusLogProbMetric: 2.3775, val_loss: 2.3852, val_MinusLogProbMetric: 2.3852

Epoch 141: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3775 - MinusLogProbMetric: 2.3775 - val_loss: 2.3852 - val_MinusLogProbMetric: 2.3852 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 142/1000
2023-09-15 16:13:21.092 
Epoch 142/1000 
	 loss: 2.3790, MinusLogProbMetric: 2.3790, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 142: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3790 - MinusLogProbMetric: 2.3790 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 143/1000
2023-09-15 16:14:23.383 
Epoch 143/1000 
	 loss: 2.3786, MinusLogProbMetric: 2.3786, val_loss: 2.3954, val_MinusLogProbMetric: 2.3954

Epoch 143: val_loss did not improve from 2.38503
196/196 - 62s - loss: 2.3786 - MinusLogProbMetric: 2.3786 - val_loss: 2.3954 - val_MinusLogProbMetric: 2.3954 - lr: 5.0000e-04 - 62s/epoch - 318ms/step
Epoch 144/1000
2023-09-15 16:15:24.072 
Epoch 144/1000 
	 loss: 2.3785, MinusLogProbMetric: 2.3785, val_loss: 2.4035, val_MinusLogProbMetric: 2.4035

Epoch 144: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3785 - MinusLogProbMetric: 2.3785 - val_loss: 2.4035 - val_MinusLogProbMetric: 2.4035 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 145/1000
2023-09-15 16:16:24.217 
Epoch 145/1000 
	 loss: 2.3780, MinusLogProbMetric: 2.3780, val_loss: 2.3979, val_MinusLogProbMetric: 2.3979

Epoch 145: val_loss did not improve from 2.38503
196/196 - 60s - loss: 2.3780 - MinusLogProbMetric: 2.3780 - val_loss: 2.3979 - val_MinusLogProbMetric: 2.3979 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 146/1000
2023-09-15 16:17:25.678 
Epoch 146/1000 
	 loss: 2.3807, MinusLogProbMetric: 2.3807, val_loss: 2.4040, val_MinusLogProbMetric: 2.4040

Epoch 146: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3807 - MinusLogProbMetric: 2.3807 - val_loss: 2.4040 - val_MinusLogProbMetric: 2.4040 - lr: 5.0000e-04 - 61s/epoch - 314ms/step
Epoch 147/1000
2023-09-15 16:18:25.655 
Epoch 147/1000 
	 loss: 2.3780, MinusLogProbMetric: 2.3780, val_loss: 2.3991, val_MinusLogProbMetric: 2.3991

Epoch 147: val_loss did not improve from 2.38503
196/196 - 60s - loss: 2.3780 - MinusLogProbMetric: 2.3780 - val_loss: 2.3991 - val_MinusLogProbMetric: 2.3991 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 148/1000
2023-09-15 16:19:25.762 
Epoch 148/1000 
	 loss: 2.3789, MinusLogProbMetric: 2.3789, val_loss: 2.4049, val_MinusLogProbMetric: 2.4049

Epoch 148: val_loss did not improve from 2.38503
196/196 - 60s - loss: 2.3789 - MinusLogProbMetric: 2.3789 - val_loss: 2.4049 - val_MinusLogProbMetric: 2.4049 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 149/1000
2023-09-15 16:20:26.721 
Epoch 149/1000 
	 loss: 2.3758, MinusLogProbMetric: 2.3758, val_loss: 2.3953, val_MinusLogProbMetric: 2.3953

Epoch 149: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3758 - MinusLogProbMetric: 2.3758 - val_loss: 2.3953 - val_MinusLogProbMetric: 2.3953 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 150/1000
2023-09-15 16:21:26.384 
Epoch 150/1000 
	 loss: 2.3778, MinusLogProbMetric: 2.3778, val_loss: 2.3887, val_MinusLogProbMetric: 2.3887

Epoch 150: val_loss did not improve from 2.38503
196/196 - 60s - loss: 2.3778 - MinusLogProbMetric: 2.3778 - val_loss: 2.3887 - val_MinusLogProbMetric: 2.3887 - lr: 5.0000e-04 - 60s/epoch - 304ms/step
Epoch 151/1000
2023-09-15 16:22:18.298 
Epoch 151/1000 
	 loss: 2.3771, MinusLogProbMetric: 2.3771, val_loss: 2.3900, val_MinusLogProbMetric: 2.3900

Epoch 151: val_loss did not improve from 2.38503
196/196 - 52s - loss: 2.3771 - MinusLogProbMetric: 2.3771 - val_loss: 2.3900 - val_MinusLogProbMetric: 2.3900 - lr: 5.0000e-04 - 52s/epoch - 265ms/step
Epoch 152/1000
2023-09-15 16:23:11.316 
Epoch 152/1000 
	 loss: 2.3772, MinusLogProbMetric: 2.3772, val_loss: 2.3917, val_MinusLogProbMetric: 2.3917

Epoch 152: val_loss did not improve from 2.38503
196/196 - 53s - loss: 2.3772 - MinusLogProbMetric: 2.3772 - val_loss: 2.3917 - val_MinusLogProbMetric: 2.3917 - lr: 5.0000e-04 - 53s/epoch - 270ms/step
Epoch 153/1000
2023-09-15 16:24:08.482 
Epoch 153/1000 
	 loss: 2.3755, MinusLogProbMetric: 2.3755, val_loss: 2.3906, val_MinusLogProbMetric: 2.3906

Epoch 153: val_loss did not improve from 2.38503
196/196 - 57s - loss: 2.3755 - MinusLogProbMetric: 2.3755 - val_loss: 2.3906 - val_MinusLogProbMetric: 2.3906 - lr: 5.0000e-04 - 57s/epoch - 292ms/step
Epoch 154/1000
2023-09-15 16:25:08.273 
Epoch 154/1000 
	 loss: 2.3756, MinusLogProbMetric: 2.3756, val_loss: 2.3973, val_MinusLogProbMetric: 2.3973

Epoch 154: val_loss did not improve from 2.38503
196/196 - 60s - loss: 2.3756 - MinusLogProbMetric: 2.3756 - val_loss: 2.3973 - val_MinusLogProbMetric: 2.3973 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 155/1000
2023-09-15 16:26:09.205 
Epoch 155/1000 
	 loss: 2.3791, MinusLogProbMetric: 2.3791, val_loss: 2.3912, val_MinusLogProbMetric: 2.3912

Epoch 155: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3791 - MinusLogProbMetric: 2.3791 - val_loss: 2.3912 - val_MinusLogProbMetric: 2.3912 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 156/1000
2023-09-15 16:27:10.163 
Epoch 156/1000 
	 loss: 2.3789, MinusLogProbMetric: 2.3789, val_loss: 2.3964, val_MinusLogProbMetric: 2.3964

Epoch 156: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3789 - MinusLogProbMetric: 2.3789 - val_loss: 2.3964 - val_MinusLogProbMetric: 2.3964 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 157/1000
2023-09-15 16:28:10.859 
Epoch 157/1000 
	 loss: 2.3776, MinusLogProbMetric: 2.3776, val_loss: 2.3989, val_MinusLogProbMetric: 2.3989

Epoch 157: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3776 - MinusLogProbMetric: 2.3776 - val_loss: 2.3989 - val_MinusLogProbMetric: 2.3989 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 158/1000
2023-09-15 16:29:12.313 
Epoch 158/1000 
	 loss: 2.3756, MinusLogProbMetric: 2.3756, val_loss: 2.3968, val_MinusLogProbMetric: 2.3968

Epoch 158: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3756 - MinusLogProbMetric: 2.3756 - val_loss: 2.3968 - val_MinusLogProbMetric: 2.3968 - lr: 5.0000e-04 - 61s/epoch - 314ms/step
Epoch 159/1000
2023-09-15 16:30:13.282 
Epoch 159/1000 
	 loss: 2.3757, MinusLogProbMetric: 2.3757, val_loss: 2.3872, val_MinusLogProbMetric: 2.3872

Epoch 159: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3757 - MinusLogProbMetric: 2.3757 - val_loss: 2.3872 - val_MinusLogProbMetric: 2.3872 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 160/1000
2023-09-15 16:31:14.598 
Epoch 160/1000 
	 loss: 2.3756, MinusLogProbMetric: 2.3756, val_loss: 2.3898, val_MinusLogProbMetric: 2.3898

Epoch 160: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3756 - MinusLogProbMetric: 2.3756 - val_loss: 2.3898 - val_MinusLogProbMetric: 2.3898 - lr: 5.0000e-04 - 61s/epoch - 313ms/step
Epoch 161/1000
2023-09-15 16:32:15.721 
Epoch 161/1000 
	 loss: 2.3784, MinusLogProbMetric: 2.3784, val_loss: 2.4013, val_MinusLogProbMetric: 2.4013

Epoch 161: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3784 - MinusLogProbMetric: 2.3784 - val_loss: 2.4013 - val_MinusLogProbMetric: 2.4013 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 162/1000
2023-09-15 16:33:16.256 
Epoch 162/1000 
	 loss: 2.3806, MinusLogProbMetric: 2.3806, val_loss: 2.3936, val_MinusLogProbMetric: 2.3936

Epoch 162: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3806 - MinusLogProbMetric: 2.3806 - val_loss: 2.3936 - val_MinusLogProbMetric: 2.3936 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 163/1000
2023-09-15 16:34:16.355 
Epoch 163/1000 
	 loss: 2.3773, MinusLogProbMetric: 2.3773, val_loss: 2.3911, val_MinusLogProbMetric: 2.3911

Epoch 163: val_loss did not improve from 2.38503
196/196 - 60s - loss: 2.3773 - MinusLogProbMetric: 2.3773 - val_loss: 2.3911 - val_MinusLogProbMetric: 2.3911 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 164/1000
2023-09-15 16:35:17.197 
Epoch 164/1000 
	 loss: 2.3769, MinusLogProbMetric: 2.3769, val_loss: 2.3947, val_MinusLogProbMetric: 2.3947

Epoch 164: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3769 - MinusLogProbMetric: 2.3769 - val_loss: 2.3947 - val_MinusLogProbMetric: 2.3947 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 165/1000
2023-09-15 16:36:16.913 
Epoch 165/1000 
	 loss: 2.3777, MinusLogProbMetric: 2.3777, val_loss: 2.4035, val_MinusLogProbMetric: 2.4035

Epoch 165: val_loss did not improve from 2.38503
196/196 - 60s - loss: 2.3777 - MinusLogProbMetric: 2.3777 - val_loss: 2.4035 - val_MinusLogProbMetric: 2.4035 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 166/1000
2023-09-15 16:37:16.666 
Epoch 166/1000 
	 loss: 2.3754, MinusLogProbMetric: 2.3754, val_loss: 2.3951, val_MinusLogProbMetric: 2.3951

Epoch 166: val_loss did not improve from 2.38503
196/196 - 60s - loss: 2.3754 - MinusLogProbMetric: 2.3754 - val_loss: 2.3951 - val_MinusLogProbMetric: 2.3951 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 167/1000
2023-09-15 16:38:17.771 
Epoch 167/1000 
	 loss: 2.3737, MinusLogProbMetric: 2.3737, val_loss: 2.3861, val_MinusLogProbMetric: 2.3861

Epoch 167: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3737 - MinusLogProbMetric: 2.3737 - val_loss: 2.3861 - val_MinusLogProbMetric: 2.3861 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 168/1000
2023-09-15 16:39:16.497 
Epoch 168/1000 
	 loss: 2.3738, MinusLogProbMetric: 2.3738, val_loss: 2.3901, val_MinusLogProbMetric: 2.3901

Epoch 168: val_loss did not improve from 2.38503
196/196 - 59s - loss: 2.3738 - MinusLogProbMetric: 2.3738 - val_loss: 2.3901 - val_MinusLogProbMetric: 2.3901 - lr: 5.0000e-04 - 59s/epoch - 300ms/step
Epoch 169/1000
2023-09-15 16:40:17.107 
Epoch 169/1000 
	 loss: 2.3765, MinusLogProbMetric: 2.3765, val_loss: 2.3928, val_MinusLogProbMetric: 2.3928

Epoch 169: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3765 - MinusLogProbMetric: 2.3765 - val_loss: 2.3928 - val_MinusLogProbMetric: 2.3928 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 170/1000
2023-09-15 16:41:17.302 
Epoch 170/1000 
	 loss: 2.3776, MinusLogProbMetric: 2.3776, val_loss: 2.3868, val_MinusLogProbMetric: 2.3868

Epoch 170: val_loss did not improve from 2.38503
196/196 - 60s - loss: 2.3776 - MinusLogProbMetric: 2.3776 - val_loss: 2.3868 - val_MinusLogProbMetric: 2.3868 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 171/1000
2023-09-15 16:42:17.719 
Epoch 171/1000 
	 loss: 2.3750, MinusLogProbMetric: 2.3750, val_loss: 2.3865, val_MinusLogProbMetric: 2.3865

Epoch 171: val_loss did not improve from 2.38503
196/196 - 60s - loss: 2.3750 - MinusLogProbMetric: 2.3750 - val_loss: 2.3865 - val_MinusLogProbMetric: 2.3865 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 172/1000
2023-09-15 16:43:18.772 
Epoch 172/1000 
	 loss: 2.3773, MinusLogProbMetric: 2.3773, val_loss: 2.3911, val_MinusLogProbMetric: 2.3911

Epoch 172: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3773 - MinusLogProbMetric: 2.3773 - val_loss: 2.3911 - val_MinusLogProbMetric: 2.3911 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 173/1000
2023-09-15 16:44:19.162 
Epoch 173/1000 
	 loss: 2.3744, MinusLogProbMetric: 2.3744, val_loss: 2.3889, val_MinusLogProbMetric: 2.3889

Epoch 173: val_loss did not improve from 2.38503
196/196 - 60s - loss: 2.3744 - MinusLogProbMetric: 2.3744 - val_loss: 2.3889 - val_MinusLogProbMetric: 2.3889 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 174/1000
2023-09-15 16:45:19.599 
Epoch 174/1000 
	 loss: 2.3779, MinusLogProbMetric: 2.3779, val_loss: 2.4022, val_MinusLogProbMetric: 2.4022

Epoch 174: val_loss did not improve from 2.38503
196/196 - 60s - loss: 2.3779 - MinusLogProbMetric: 2.3779 - val_loss: 2.4022 - val_MinusLogProbMetric: 2.4022 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 175/1000
2023-09-15 16:46:20.210 
Epoch 175/1000 
	 loss: 2.3751, MinusLogProbMetric: 2.3751, val_loss: 2.3905, val_MinusLogProbMetric: 2.3905

Epoch 175: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3751 - MinusLogProbMetric: 2.3751 - val_loss: 2.3905 - val_MinusLogProbMetric: 2.3905 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 176/1000
2023-09-15 16:47:19.180 
Epoch 176/1000 
	 loss: 2.3766, MinusLogProbMetric: 2.3766, val_loss: 2.3900, val_MinusLogProbMetric: 2.3900

Epoch 176: val_loss did not improve from 2.38503
196/196 - 59s - loss: 2.3766 - MinusLogProbMetric: 2.3766 - val_loss: 2.3900 - val_MinusLogProbMetric: 2.3900 - lr: 5.0000e-04 - 59s/epoch - 301ms/step
Epoch 177/1000
2023-09-15 16:48:17.832 
Epoch 177/1000 
	 loss: 2.3751, MinusLogProbMetric: 2.3751, val_loss: 2.3989, val_MinusLogProbMetric: 2.3989

Epoch 177: val_loss did not improve from 2.38503
196/196 - 59s - loss: 2.3751 - MinusLogProbMetric: 2.3751 - val_loss: 2.3989 - val_MinusLogProbMetric: 2.3989 - lr: 5.0000e-04 - 59s/epoch - 299ms/step
Epoch 178/1000
2023-09-15 16:49:17.602 
Epoch 178/1000 
	 loss: 2.3739, MinusLogProbMetric: 2.3739, val_loss: 2.4017, val_MinusLogProbMetric: 2.4017

Epoch 178: val_loss did not improve from 2.38503
196/196 - 60s - loss: 2.3739 - MinusLogProbMetric: 2.3739 - val_loss: 2.4017 - val_MinusLogProbMetric: 2.4017 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 179/1000
2023-09-15 16:50:18.591 
Epoch 179/1000 
	 loss: 2.3671, MinusLogProbMetric: 2.3671, val_loss: 2.3905, val_MinusLogProbMetric: 2.3905

Epoch 179: val_loss did not improve from 2.38503
196/196 - 61s - loss: 2.3671 - MinusLogProbMetric: 2.3671 - val_loss: 2.3905 - val_MinusLogProbMetric: 2.3905 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 180/1000
2023-09-15 16:51:19.193 
Epoch 180/1000 
	 loss: 2.3653, MinusLogProbMetric: 2.3653, val_loss: 2.3832, val_MinusLogProbMetric: 2.3832

Epoch 180: val_loss improved from 2.38503 to 2.38320, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 61s - loss: 2.3653 - MinusLogProbMetric: 2.3653 - val_loss: 2.3832 - val_MinusLogProbMetric: 2.3832 - lr: 2.5000e-04 - 61s/epoch - 313ms/step
Epoch 181/1000
2023-09-15 16:52:20.116 
Epoch 181/1000 
	 loss: 2.3653, MinusLogProbMetric: 2.3653, val_loss: 2.3829, val_MinusLogProbMetric: 2.3829

Epoch 181: val_loss improved from 2.38320 to 2.38285, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 61s - loss: 2.3653 - MinusLogProbMetric: 2.3653 - val_loss: 2.3829 - val_MinusLogProbMetric: 2.3829 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 182/1000
2023-09-15 16:53:21.793 
Epoch 182/1000 
	 loss: 2.3643, MinusLogProbMetric: 2.3643, val_loss: 2.3830, val_MinusLogProbMetric: 2.3830

Epoch 182: val_loss did not improve from 2.38285
196/196 - 61s - loss: 2.3643 - MinusLogProbMetric: 2.3643 - val_loss: 2.3830 - val_MinusLogProbMetric: 2.3830 - lr: 2.5000e-04 - 61s/epoch - 310ms/step
Epoch 183/1000
2023-09-15 16:54:21.957 
Epoch 183/1000 
	 loss: 2.3660, MinusLogProbMetric: 2.3660, val_loss: 2.3890, val_MinusLogProbMetric: 2.3890

Epoch 183: val_loss did not improve from 2.38285
196/196 - 60s - loss: 2.3660 - MinusLogProbMetric: 2.3660 - val_loss: 2.3890 - val_MinusLogProbMetric: 2.3890 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 184/1000
2023-09-15 16:55:22.555 
Epoch 184/1000 
	 loss: 2.3644, MinusLogProbMetric: 2.3644, val_loss: 2.3904, val_MinusLogProbMetric: 2.3904

Epoch 184: val_loss did not improve from 2.38285
196/196 - 61s - loss: 2.3644 - MinusLogProbMetric: 2.3644 - val_loss: 2.3904 - val_MinusLogProbMetric: 2.3904 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 185/1000
2023-09-15 16:56:23.427 
Epoch 185/1000 
	 loss: 2.3651, MinusLogProbMetric: 2.3651, val_loss: 2.3839, val_MinusLogProbMetric: 2.3839

Epoch 185: val_loss did not improve from 2.38285
196/196 - 61s - loss: 2.3651 - MinusLogProbMetric: 2.3651 - val_loss: 2.3839 - val_MinusLogProbMetric: 2.3839 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 186/1000
2023-09-15 16:57:23.545 
Epoch 186/1000 
	 loss: 2.3658, MinusLogProbMetric: 2.3658, val_loss: 2.3844, val_MinusLogProbMetric: 2.3844

Epoch 186: val_loss did not improve from 2.38285
196/196 - 60s - loss: 2.3658 - MinusLogProbMetric: 2.3658 - val_loss: 2.3844 - val_MinusLogProbMetric: 2.3844 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 187/1000
2023-09-15 16:58:24.346 
Epoch 187/1000 
	 loss: 2.3639, MinusLogProbMetric: 2.3639, val_loss: 2.3861, val_MinusLogProbMetric: 2.3861

Epoch 187: val_loss did not improve from 2.38285
196/196 - 61s - loss: 2.3639 - MinusLogProbMetric: 2.3639 - val_loss: 2.3861 - val_MinusLogProbMetric: 2.3861 - lr: 2.5000e-04 - 61s/epoch - 310ms/step
Epoch 188/1000
2023-09-15 16:59:25.843 
Epoch 188/1000 
	 loss: 2.3644, MinusLogProbMetric: 2.3644, val_loss: 2.3980, val_MinusLogProbMetric: 2.3980

Epoch 188: val_loss did not improve from 2.38285
196/196 - 61s - loss: 2.3644 - MinusLogProbMetric: 2.3644 - val_loss: 2.3980 - val_MinusLogProbMetric: 2.3980 - lr: 2.5000e-04 - 61s/epoch - 314ms/step
Epoch 189/1000
2023-09-15 17:00:29.130 
Epoch 189/1000 
	 loss: 2.3650, MinusLogProbMetric: 2.3650, val_loss: 2.3871, val_MinusLogProbMetric: 2.3871

Epoch 189: val_loss did not improve from 2.38285
196/196 - 63s - loss: 2.3650 - MinusLogProbMetric: 2.3650 - val_loss: 2.3871 - val_MinusLogProbMetric: 2.3871 - lr: 2.5000e-04 - 63s/epoch - 323ms/step
Epoch 190/1000
2023-09-15 17:01:31.601 
Epoch 190/1000 
	 loss: 2.3640, MinusLogProbMetric: 2.3640, val_loss: 2.3829, val_MinusLogProbMetric: 2.3829

Epoch 190: val_loss did not improve from 2.38285
196/196 - 62s - loss: 2.3640 - MinusLogProbMetric: 2.3640 - val_loss: 2.3829 - val_MinusLogProbMetric: 2.3829 - lr: 2.5000e-04 - 62s/epoch - 319ms/step
Epoch 191/1000
2023-09-15 17:02:34.305 
Epoch 191/1000 
	 loss: 2.3651, MinusLogProbMetric: 2.3651, val_loss: 2.3866, val_MinusLogProbMetric: 2.3866

Epoch 191: val_loss did not improve from 2.38285
196/196 - 63s - loss: 2.3651 - MinusLogProbMetric: 2.3651 - val_loss: 2.3866 - val_MinusLogProbMetric: 2.3866 - lr: 2.5000e-04 - 63s/epoch - 320ms/step
Epoch 192/1000
2023-09-15 17:03:37.369 
Epoch 192/1000 
	 loss: 2.3653, MinusLogProbMetric: 2.3653, val_loss: 2.3944, val_MinusLogProbMetric: 2.3944

Epoch 192: val_loss did not improve from 2.38285
196/196 - 63s - loss: 2.3653 - MinusLogProbMetric: 2.3653 - val_loss: 2.3944 - val_MinusLogProbMetric: 2.3944 - lr: 2.5000e-04 - 63s/epoch - 322ms/step
Epoch 193/1000
2023-09-15 17:04:40.516 
Epoch 193/1000 
	 loss: 2.3642, MinusLogProbMetric: 2.3642, val_loss: 2.3852, val_MinusLogProbMetric: 2.3852

Epoch 193: val_loss did not improve from 2.38285
196/196 - 63s - loss: 2.3642 - MinusLogProbMetric: 2.3642 - val_loss: 2.3852 - val_MinusLogProbMetric: 2.3852 - lr: 2.5000e-04 - 63s/epoch - 322ms/step
Epoch 194/1000
2023-09-15 17:05:46.839 
Epoch 194/1000 
	 loss: 2.3635, MinusLogProbMetric: 2.3635, val_loss: 2.3922, val_MinusLogProbMetric: 2.3922

Epoch 194: val_loss did not improve from 2.38285
196/196 - 66s - loss: 2.3635 - MinusLogProbMetric: 2.3635 - val_loss: 2.3922 - val_MinusLogProbMetric: 2.3922 - lr: 2.5000e-04 - 66s/epoch - 338ms/step
Epoch 195/1000
2023-09-15 17:06:50.098 
Epoch 195/1000 
	 loss: 2.3651, MinusLogProbMetric: 2.3651, val_loss: 2.3841, val_MinusLogProbMetric: 2.3841

Epoch 195: val_loss did not improve from 2.38285
196/196 - 63s - loss: 2.3651 - MinusLogProbMetric: 2.3651 - val_loss: 2.3841 - val_MinusLogProbMetric: 2.3841 - lr: 2.5000e-04 - 63s/epoch - 323ms/step
Epoch 196/1000
2023-09-15 17:07:52.452 
Epoch 196/1000 
	 loss: 2.3636, MinusLogProbMetric: 2.3636, val_loss: 2.3897, val_MinusLogProbMetric: 2.3897

Epoch 196: val_loss did not improve from 2.38285
196/196 - 62s - loss: 2.3636 - MinusLogProbMetric: 2.3636 - val_loss: 2.3897 - val_MinusLogProbMetric: 2.3897 - lr: 2.5000e-04 - 62s/epoch - 318ms/step
Epoch 197/1000
2023-09-15 17:08:53.172 
Epoch 197/1000 
	 loss: 2.3644, MinusLogProbMetric: 2.3644, val_loss: 2.3888, val_MinusLogProbMetric: 2.3888

Epoch 197: val_loss did not improve from 2.38285
196/196 - 61s - loss: 2.3644 - MinusLogProbMetric: 2.3644 - val_loss: 2.3888 - val_MinusLogProbMetric: 2.3888 - lr: 2.5000e-04 - 61s/epoch - 310ms/step
Epoch 198/1000
2023-09-15 17:09:53.429 
Epoch 198/1000 
	 loss: 2.3645, MinusLogProbMetric: 2.3645, val_loss: 2.3848, val_MinusLogProbMetric: 2.3848

Epoch 198: val_loss did not improve from 2.38285
196/196 - 60s - loss: 2.3645 - MinusLogProbMetric: 2.3645 - val_loss: 2.3848 - val_MinusLogProbMetric: 2.3848 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 199/1000
2023-09-15 17:10:54.157 
Epoch 199/1000 
	 loss: 2.3634, MinusLogProbMetric: 2.3634, val_loss: 2.3836, val_MinusLogProbMetric: 2.3836

Epoch 199: val_loss did not improve from 2.38285
196/196 - 61s - loss: 2.3634 - MinusLogProbMetric: 2.3634 - val_loss: 2.3836 - val_MinusLogProbMetric: 2.3836 - lr: 2.5000e-04 - 61s/epoch - 310ms/step
Epoch 200/1000
2023-09-15 17:11:54.654 
Epoch 200/1000 
	 loss: 2.3653, MinusLogProbMetric: 2.3653, val_loss: 2.3882, val_MinusLogProbMetric: 2.3882

Epoch 200: val_loss did not improve from 2.38285
196/196 - 60s - loss: 2.3653 - MinusLogProbMetric: 2.3653 - val_loss: 2.3882 - val_MinusLogProbMetric: 2.3882 - lr: 2.5000e-04 - 60s/epoch - 309ms/step
Epoch 201/1000
2023-09-15 17:12:55.436 
Epoch 201/1000 
	 loss: 2.3640, MinusLogProbMetric: 2.3640, val_loss: 2.3835, val_MinusLogProbMetric: 2.3835

Epoch 201: val_loss did not improve from 2.38285
196/196 - 61s - loss: 2.3640 - MinusLogProbMetric: 2.3640 - val_loss: 2.3835 - val_MinusLogProbMetric: 2.3835 - lr: 2.5000e-04 - 61s/epoch - 310ms/step
Epoch 202/1000
2023-09-15 17:13:55.883 
Epoch 202/1000 
	 loss: 2.3634, MinusLogProbMetric: 2.3634, val_loss: 2.3876, val_MinusLogProbMetric: 2.3876

Epoch 202: val_loss did not improve from 2.38285
196/196 - 60s - loss: 2.3634 - MinusLogProbMetric: 2.3634 - val_loss: 2.3876 - val_MinusLogProbMetric: 2.3876 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 203/1000
2023-09-15 17:14:56.890 
Epoch 203/1000 
	 loss: 2.3637, MinusLogProbMetric: 2.3637, val_loss: 2.3875, val_MinusLogProbMetric: 2.3875

Epoch 203: val_loss did not improve from 2.38285
196/196 - 61s - loss: 2.3637 - MinusLogProbMetric: 2.3637 - val_loss: 2.3875 - val_MinusLogProbMetric: 2.3875 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 204/1000
2023-09-15 17:15:57.714 
Epoch 204/1000 
	 loss: 2.3646, MinusLogProbMetric: 2.3646, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 204: val_loss did not improve from 2.38285
196/196 - 61s - loss: 2.3646 - MinusLogProbMetric: 2.3646 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 2.5000e-04 - 61s/epoch - 310ms/step
Epoch 205/1000
2023-09-15 17:16:59.054 
Epoch 205/1000 
	 loss: 2.3640, MinusLogProbMetric: 2.3640, val_loss: 2.3916, val_MinusLogProbMetric: 2.3916

Epoch 205: val_loss did not improve from 2.38285
196/196 - 61s - loss: 2.3640 - MinusLogProbMetric: 2.3640 - val_loss: 2.3916 - val_MinusLogProbMetric: 2.3916 - lr: 2.5000e-04 - 61s/epoch - 313ms/step
Epoch 206/1000
2023-09-15 17:17:59.495 
Epoch 206/1000 
	 loss: 2.3644, MinusLogProbMetric: 2.3644, val_loss: 2.3935, val_MinusLogProbMetric: 2.3935

Epoch 206: val_loss did not improve from 2.38285
196/196 - 60s - loss: 2.3644 - MinusLogProbMetric: 2.3644 - val_loss: 2.3935 - val_MinusLogProbMetric: 2.3935 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 207/1000
2023-09-15 17:19:00.190 
Epoch 207/1000 
	 loss: 2.3637, MinusLogProbMetric: 2.3637, val_loss: 2.3912, val_MinusLogProbMetric: 2.3912

Epoch 207: val_loss did not improve from 2.38285
196/196 - 61s - loss: 2.3637 - MinusLogProbMetric: 2.3637 - val_loss: 2.3912 - val_MinusLogProbMetric: 2.3912 - lr: 2.5000e-04 - 61s/epoch - 310ms/step
Epoch 208/1000
2023-09-15 17:19:59.424 
Epoch 208/1000 
	 loss: 2.3625, MinusLogProbMetric: 2.3625, val_loss: 2.3890, val_MinusLogProbMetric: 2.3890

Epoch 208: val_loss did not improve from 2.38285
196/196 - 59s - loss: 2.3625 - MinusLogProbMetric: 2.3625 - val_loss: 2.3890 - val_MinusLogProbMetric: 2.3890 - lr: 2.5000e-04 - 59s/epoch - 302ms/step
Epoch 209/1000
2023-09-15 17:20:59.998 
Epoch 209/1000 
	 loss: 2.3636, MinusLogProbMetric: 2.3636, val_loss: 2.3850, val_MinusLogProbMetric: 2.3850

Epoch 209: val_loss did not improve from 2.38285
196/196 - 61s - loss: 2.3636 - MinusLogProbMetric: 2.3636 - val_loss: 2.3850 - val_MinusLogProbMetric: 2.3850 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 210/1000
2023-09-15 17:22:01.022 
Epoch 210/1000 
	 loss: 2.3658, MinusLogProbMetric: 2.3658, val_loss: 2.3965, val_MinusLogProbMetric: 2.3965

Epoch 210: val_loss did not improve from 2.38285
196/196 - 61s - loss: 2.3658 - MinusLogProbMetric: 2.3658 - val_loss: 2.3965 - val_MinusLogProbMetric: 2.3965 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 211/1000
2023-09-15 17:23:02.851 
Epoch 211/1000 
	 loss: 2.3641, MinusLogProbMetric: 2.3641, val_loss: 2.3828, val_MinusLogProbMetric: 2.3828

Epoch 211: val_loss improved from 2.38285 to 2.38283, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 63s - loss: 2.3641 - MinusLogProbMetric: 2.3641 - val_loss: 2.3828 - val_MinusLogProbMetric: 2.3828 - lr: 2.5000e-04 - 63s/epoch - 319ms/step
Epoch 212/1000
2023-09-15 17:24:07.377 
Epoch 212/1000 
	 loss: 2.3630, MinusLogProbMetric: 2.3630, val_loss: 2.3877, val_MinusLogProbMetric: 2.3877

Epoch 212: val_loss did not improve from 2.38283
196/196 - 64s - loss: 2.3630 - MinusLogProbMetric: 2.3630 - val_loss: 2.3877 - val_MinusLogProbMetric: 2.3877 - lr: 2.5000e-04 - 64s/epoch - 326ms/step
Epoch 213/1000
2023-09-15 17:25:12.890 
Epoch 213/1000 
	 loss: 2.3630, MinusLogProbMetric: 2.3630, val_loss: 2.3868, val_MinusLogProbMetric: 2.3868

Epoch 213: val_loss did not improve from 2.38283
196/196 - 66s - loss: 2.3630 - MinusLogProbMetric: 2.3630 - val_loss: 2.3868 - val_MinusLogProbMetric: 2.3868 - lr: 2.5000e-04 - 66s/epoch - 334ms/step
Epoch 214/1000
2023-09-15 17:26:13.704 
Epoch 214/1000 
	 loss: 2.3633, MinusLogProbMetric: 2.3633, val_loss: 2.3973, val_MinusLogProbMetric: 2.3973

Epoch 214: val_loss did not improve from 2.38283
196/196 - 61s - loss: 2.3633 - MinusLogProbMetric: 2.3633 - val_loss: 2.3973 - val_MinusLogProbMetric: 2.3973 - lr: 2.5000e-04 - 61s/epoch - 310ms/step
Epoch 215/1000
2023-09-15 17:27:14.479 
Epoch 215/1000 
	 loss: 2.3653, MinusLogProbMetric: 2.3653, val_loss: 2.3889, val_MinusLogProbMetric: 2.3889

Epoch 215: val_loss did not improve from 2.38283
196/196 - 61s - loss: 2.3653 - MinusLogProbMetric: 2.3653 - val_loss: 2.3889 - val_MinusLogProbMetric: 2.3889 - lr: 2.5000e-04 - 61s/epoch - 310ms/step
Epoch 216/1000
2023-09-15 17:28:13.420 
Epoch 216/1000 
	 loss: 2.3633, MinusLogProbMetric: 2.3633, val_loss: 2.3841, val_MinusLogProbMetric: 2.3841

Epoch 216: val_loss did not improve from 2.38283
196/196 - 59s - loss: 2.3633 - MinusLogProbMetric: 2.3633 - val_loss: 2.3841 - val_MinusLogProbMetric: 2.3841 - lr: 2.5000e-04 - 59s/epoch - 301ms/step
Epoch 217/1000
2023-09-15 17:29:11.409 
Epoch 217/1000 
	 loss: 2.3629, MinusLogProbMetric: 2.3629, val_loss: 2.3908, val_MinusLogProbMetric: 2.3908

Epoch 217: val_loss did not improve from 2.38283
196/196 - 58s - loss: 2.3629 - MinusLogProbMetric: 2.3629 - val_loss: 2.3908 - val_MinusLogProbMetric: 2.3908 - lr: 2.5000e-04 - 58s/epoch - 296ms/step
Epoch 218/1000
2023-09-15 17:30:14.047 
Epoch 218/1000 
	 loss: 2.3630, MinusLogProbMetric: 2.3630, val_loss: 2.3940, val_MinusLogProbMetric: 2.3940

Epoch 218: val_loss did not improve from 2.38283
196/196 - 63s - loss: 2.3630 - MinusLogProbMetric: 2.3630 - val_loss: 2.3940 - val_MinusLogProbMetric: 2.3940 - lr: 2.5000e-04 - 63s/epoch - 319ms/step
Epoch 219/1000
2023-09-15 17:31:14.697 
Epoch 219/1000 
	 loss: 2.3637, MinusLogProbMetric: 2.3637, val_loss: 2.3853, val_MinusLogProbMetric: 2.3853

Epoch 219: val_loss did not improve from 2.38283
196/196 - 61s - loss: 2.3637 - MinusLogProbMetric: 2.3637 - val_loss: 2.3853 - val_MinusLogProbMetric: 2.3853 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 220/1000
2023-09-15 17:32:15.224 
Epoch 220/1000 
	 loss: 2.3626, MinusLogProbMetric: 2.3626, val_loss: 2.3864, val_MinusLogProbMetric: 2.3864

Epoch 220: val_loss did not improve from 2.38283
196/196 - 61s - loss: 2.3626 - MinusLogProbMetric: 2.3626 - val_loss: 2.3864 - val_MinusLogProbMetric: 2.3864 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 221/1000
2023-09-15 17:33:16.281 
Epoch 221/1000 
	 loss: 2.3630, MinusLogProbMetric: 2.3630, val_loss: 2.3919, val_MinusLogProbMetric: 2.3919

Epoch 221: val_loss did not improve from 2.38283
196/196 - 61s - loss: 2.3630 - MinusLogProbMetric: 2.3630 - val_loss: 2.3919 - val_MinusLogProbMetric: 2.3919 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 222/1000
2023-09-15 17:34:17.209 
Epoch 222/1000 
	 loss: 2.3625, MinusLogProbMetric: 2.3625, val_loss: 2.3828, val_MinusLogProbMetric: 2.3828

Epoch 222: val_loss improved from 2.38283 to 2.38281, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 62s - loss: 2.3625 - MinusLogProbMetric: 2.3625 - val_loss: 2.3828 - val_MinusLogProbMetric: 2.3828 - lr: 2.5000e-04 - 62s/epoch - 314ms/step
Epoch 223/1000
2023-09-15 17:35:18.172 
Epoch 223/1000 
	 loss: 2.3635, MinusLogProbMetric: 2.3635, val_loss: 2.3933, val_MinusLogProbMetric: 2.3933

Epoch 223: val_loss did not improve from 2.38281
196/196 - 60s - loss: 2.3635 - MinusLogProbMetric: 2.3635 - val_loss: 2.3933 - val_MinusLogProbMetric: 2.3933 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 224/1000
2023-09-15 17:36:18.979 
Epoch 224/1000 
	 loss: 2.3626, MinusLogProbMetric: 2.3626, val_loss: 2.3862, val_MinusLogProbMetric: 2.3862

Epoch 224: val_loss did not improve from 2.38281
196/196 - 61s - loss: 2.3626 - MinusLogProbMetric: 2.3626 - val_loss: 2.3862 - val_MinusLogProbMetric: 2.3862 - lr: 2.5000e-04 - 61s/epoch - 310ms/step
Epoch 225/1000
2023-09-15 17:37:19.343 
Epoch 225/1000 
	 loss: 2.3628, MinusLogProbMetric: 2.3628, val_loss: 2.3858, val_MinusLogProbMetric: 2.3858

Epoch 225: val_loss did not improve from 2.38281
196/196 - 60s - loss: 2.3628 - MinusLogProbMetric: 2.3628 - val_loss: 2.3858 - val_MinusLogProbMetric: 2.3858 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 226/1000
2023-09-15 17:38:19.407 
Epoch 226/1000 
	 loss: 2.3652, MinusLogProbMetric: 2.3652, val_loss: 2.3855, val_MinusLogProbMetric: 2.3855

Epoch 226: val_loss did not improve from 2.38281
196/196 - 60s - loss: 2.3652 - MinusLogProbMetric: 2.3652 - val_loss: 2.3855 - val_MinusLogProbMetric: 2.3855 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 227/1000
2023-09-15 17:39:19.306 
Epoch 227/1000 
	 loss: 2.3620, MinusLogProbMetric: 2.3620, val_loss: 2.3933, val_MinusLogProbMetric: 2.3933

Epoch 227: val_loss did not improve from 2.38281
196/196 - 60s - loss: 2.3620 - MinusLogProbMetric: 2.3620 - val_loss: 2.3933 - val_MinusLogProbMetric: 2.3933 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 228/1000
2023-09-15 17:40:19.964 
Epoch 228/1000 
	 loss: 2.3635, MinusLogProbMetric: 2.3635, val_loss: 2.3875, val_MinusLogProbMetric: 2.3875

Epoch 228: val_loss did not improve from 2.38281
196/196 - 61s - loss: 2.3635 - MinusLogProbMetric: 2.3635 - val_loss: 2.3875 - val_MinusLogProbMetric: 2.3875 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 229/1000
2023-09-15 17:41:20.101 
Epoch 229/1000 
	 loss: 2.3631, MinusLogProbMetric: 2.3631, val_loss: 2.3861, val_MinusLogProbMetric: 2.3861

Epoch 229: val_loss did not improve from 2.38281
196/196 - 60s - loss: 2.3631 - MinusLogProbMetric: 2.3631 - val_loss: 2.3861 - val_MinusLogProbMetric: 2.3861 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 230/1000
2023-09-15 17:42:20.976 
Epoch 230/1000 
	 loss: 2.3632, MinusLogProbMetric: 2.3632, val_loss: 2.3871, val_MinusLogProbMetric: 2.3871

Epoch 230: val_loss did not improve from 2.38281
196/196 - 61s - loss: 2.3632 - MinusLogProbMetric: 2.3632 - val_loss: 2.3871 - val_MinusLogProbMetric: 2.3871 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 231/1000
2023-09-15 17:43:21.768 
Epoch 231/1000 
	 loss: 2.3628, MinusLogProbMetric: 2.3628, val_loss: 2.3847, val_MinusLogProbMetric: 2.3847

Epoch 231: val_loss did not improve from 2.38281
196/196 - 61s - loss: 2.3628 - MinusLogProbMetric: 2.3628 - val_loss: 2.3847 - val_MinusLogProbMetric: 2.3847 - lr: 2.5000e-04 - 61s/epoch - 310ms/step
Epoch 232/1000
2023-09-15 17:44:23.024 
Epoch 232/1000 
	 loss: 2.3573, MinusLogProbMetric: 2.3573, val_loss: 2.3841, val_MinusLogProbMetric: 2.3841

Epoch 232: val_loss did not improve from 2.38281
196/196 - 61s - loss: 2.3573 - MinusLogProbMetric: 2.3573 - val_loss: 2.3841 - val_MinusLogProbMetric: 2.3841 - lr: 1.2500e-04 - 61s/epoch - 312ms/step
Epoch 233/1000
2023-09-15 17:45:23.265 
Epoch 233/1000 
	 loss: 2.3573, MinusLogProbMetric: 2.3573, val_loss: 2.3868, val_MinusLogProbMetric: 2.3868

Epoch 233: val_loss did not improve from 2.38281
196/196 - 60s - loss: 2.3573 - MinusLogProbMetric: 2.3573 - val_loss: 2.3868 - val_MinusLogProbMetric: 2.3868 - lr: 1.2500e-04 - 60s/epoch - 308ms/step
Epoch 234/1000
2023-09-15 17:46:24.031 
Epoch 234/1000 
	 loss: 2.3578, MinusLogProbMetric: 2.3578, val_loss: 2.3862, val_MinusLogProbMetric: 2.3862

Epoch 234: val_loss did not improve from 2.38281
196/196 - 61s - loss: 2.3578 - MinusLogProbMetric: 2.3578 - val_loss: 2.3862 - val_MinusLogProbMetric: 2.3862 - lr: 1.2500e-04 - 61s/epoch - 310ms/step
Epoch 235/1000
2023-09-15 17:47:25.307 
Epoch 235/1000 
	 loss: 2.3569, MinusLogProbMetric: 2.3569, val_loss: 2.3832, val_MinusLogProbMetric: 2.3832

Epoch 235: val_loss did not improve from 2.38281
196/196 - 61s - loss: 2.3569 - MinusLogProbMetric: 2.3569 - val_loss: 2.3832 - val_MinusLogProbMetric: 2.3832 - lr: 1.2500e-04 - 61s/epoch - 313ms/step
Epoch 236/1000
2023-09-15 17:48:25.804 
Epoch 236/1000 
	 loss: 2.3576, MinusLogProbMetric: 2.3576, val_loss: 2.3837, val_MinusLogProbMetric: 2.3837

Epoch 236: val_loss did not improve from 2.38281
196/196 - 61s - loss: 2.3576 - MinusLogProbMetric: 2.3576 - val_loss: 2.3837 - val_MinusLogProbMetric: 2.3837 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 237/1000
2023-09-15 17:49:26.108 
Epoch 237/1000 
	 loss: 2.3567, MinusLogProbMetric: 2.3567, val_loss: 2.3836, val_MinusLogProbMetric: 2.3836

Epoch 237: val_loss did not improve from 2.38281
196/196 - 60s - loss: 2.3567 - MinusLogProbMetric: 2.3567 - val_loss: 2.3836 - val_MinusLogProbMetric: 2.3836 - lr: 1.2500e-04 - 60s/epoch - 308ms/step
Epoch 238/1000
2023-09-15 17:50:26.924 
Epoch 238/1000 
	 loss: 2.3571, MinusLogProbMetric: 2.3571, val_loss: 2.3868, val_MinusLogProbMetric: 2.3868

Epoch 238: val_loss did not improve from 2.38281
196/196 - 61s - loss: 2.3571 - MinusLogProbMetric: 2.3571 - val_loss: 2.3868 - val_MinusLogProbMetric: 2.3868 - lr: 1.2500e-04 - 61s/epoch - 310ms/step
Epoch 239/1000
2023-09-15 17:51:28.284 
Epoch 239/1000 
	 loss: 2.3567, MinusLogProbMetric: 2.3567, val_loss: 2.3844, val_MinusLogProbMetric: 2.3844

Epoch 239: val_loss did not improve from 2.38281
196/196 - 61s - loss: 2.3567 - MinusLogProbMetric: 2.3567 - val_loss: 2.3844 - val_MinusLogProbMetric: 2.3844 - lr: 1.2500e-04 - 61s/epoch - 313ms/step
Epoch 240/1000
2023-09-15 17:52:33.368 
Epoch 240/1000 
	 loss: 2.3568, MinusLogProbMetric: 2.3568, val_loss: 2.3832, val_MinusLogProbMetric: 2.3832

Epoch 240: val_loss did not improve from 2.38281
196/196 - 65s - loss: 2.3568 - MinusLogProbMetric: 2.3568 - val_loss: 2.3832 - val_MinusLogProbMetric: 2.3832 - lr: 1.2500e-04 - 65s/epoch - 332ms/step
Epoch 241/1000
2023-09-15 17:53:33.736 
Epoch 241/1000 
	 loss: 2.3575, MinusLogProbMetric: 2.3575, val_loss: 2.3830, val_MinusLogProbMetric: 2.3830

Epoch 241: val_loss did not improve from 2.38281
196/196 - 60s - loss: 2.3575 - MinusLogProbMetric: 2.3575 - val_loss: 2.3830 - val_MinusLogProbMetric: 2.3830 - lr: 1.2500e-04 - 60s/epoch - 308ms/step
Epoch 242/1000
2023-09-15 17:54:32.429 
Epoch 242/1000 
	 loss: 2.3573, MinusLogProbMetric: 2.3573, val_loss: 2.3812, val_MinusLogProbMetric: 2.3812

Epoch 242: val_loss improved from 2.38281 to 2.38116, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_45/weights/best_weights.h5
196/196 - 60s - loss: 2.3573 - MinusLogProbMetric: 2.3573 - val_loss: 2.3812 - val_MinusLogProbMetric: 2.3812 - lr: 1.2500e-04 - 60s/epoch - 304ms/step
Epoch 243/1000
2023-09-15 17:55:28.614 
Epoch 243/1000 
	 loss: 2.3574, MinusLogProbMetric: 2.3574, val_loss: 2.3834, val_MinusLogProbMetric: 2.3834

Epoch 243: val_loss did not improve from 2.38116
196/196 - 55s - loss: 2.3574 - MinusLogProbMetric: 2.3574 - val_loss: 2.3834 - val_MinusLogProbMetric: 2.3834 - lr: 1.2500e-04 - 55s/epoch - 282ms/step
Epoch 244/1000
2023-09-15 17:56:27.852 
Epoch 244/1000 
	 loss: 2.3573, MinusLogProbMetric: 2.3573, val_loss: 2.3833, val_MinusLogProbMetric: 2.3833

Epoch 244: val_loss did not improve from 2.38116
196/196 - 59s - loss: 2.3573 - MinusLogProbMetric: 2.3573 - val_loss: 2.3833 - val_MinusLogProbMetric: 2.3833 - lr: 1.2500e-04 - 59s/epoch - 302ms/step
Epoch 245/1000
2023-09-15 17:57:32.116 
Epoch 245/1000 
	 loss: 2.3573, MinusLogProbMetric: 2.3573, val_loss: 2.3832, val_MinusLogProbMetric: 2.3832

Epoch 245: val_loss did not improve from 2.38116
196/196 - 64s - loss: 2.3573 - MinusLogProbMetric: 2.3573 - val_loss: 2.3832 - val_MinusLogProbMetric: 2.3832 - lr: 1.2500e-04 - 64s/epoch - 328ms/step
Epoch 246/1000
2023-09-15 17:58:34.609 
Epoch 246/1000 
	 loss: 2.3576, MinusLogProbMetric: 2.3576, val_loss: 2.3856, val_MinusLogProbMetric: 2.3856

Epoch 246: val_loss did not improve from 2.38116
196/196 - 62s - loss: 2.3576 - MinusLogProbMetric: 2.3576 - val_loss: 2.3856 - val_MinusLogProbMetric: 2.3856 - lr: 1.2500e-04 - 62s/epoch - 319ms/step
Epoch 247/1000
2023-09-15 17:59:35.378 
Epoch 247/1000 
	 loss: 2.3566, MinusLogProbMetric: 2.3566, val_loss: 2.3863, val_MinusLogProbMetric: 2.3863

Epoch 247: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3566 - MinusLogProbMetric: 2.3566 - val_loss: 2.3863 - val_MinusLogProbMetric: 2.3863 - lr: 1.2500e-04 - 61s/epoch - 310ms/step
Epoch 248/1000
2023-09-15 18:00:35.633 
Epoch 248/1000 
	 loss: 2.3574, MinusLogProbMetric: 2.3574, val_loss: 2.3834, val_MinusLogProbMetric: 2.3834

Epoch 248: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3574 - MinusLogProbMetric: 2.3574 - val_loss: 2.3834 - val_MinusLogProbMetric: 2.3834 - lr: 1.2500e-04 - 60s/epoch - 307ms/step
Epoch 249/1000
2023-09-15 18:01:34.954 
Epoch 249/1000 
	 loss: 2.3573, MinusLogProbMetric: 2.3573, val_loss: 2.3844, val_MinusLogProbMetric: 2.3844

Epoch 249: val_loss did not improve from 2.38116
196/196 - 59s - loss: 2.3573 - MinusLogProbMetric: 2.3573 - val_loss: 2.3844 - val_MinusLogProbMetric: 2.3844 - lr: 1.2500e-04 - 59s/epoch - 303ms/step
Epoch 250/1000
2023-09-15 18:02:36.167 
Epoch 250/1000 
	 loss: 2.3571, MinusLogProbMetric: 2.3571, val_loss: 2.3829, val_MinusLogProbMetric: 2.3829

Epoch 250: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3571 - MinusLogProbMetric: 2.3571 - val_loss: 2.3829 - val_MinusLogProbMetric: 2.3829 - lr: 1.2500e-04 - 61s/epoch - 312ms/step
Epoch 251/1000
2023-09-15 18:03:37.232 
Epoch 251/1000 
	 loss: 2.3573, MinusLogProbMetric: 2.3573, val_loss: 2.3819, val_MinusLogProbMetric: 2.3819

Epoch 251: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3573 - MinusLogProbMetric: 2.3573 - val_loss: 2.3819 - val_MinusLogProbMetric: 2.3819 - lr: 1.2500e-04 - 61s/epoch - 312ms/step
Epoch 252/1000
2023-09-15 18:04:38.280 
Epoch 252/1000 
	 loss: 2.3571, MinusLogProbMetric: 2.3571, val_loss: 2.3826, val_MinusLogProbMetric: 2.3826

Epoch 252: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3571 - MinusLogProbMetric: 2.3571 - val_loss: 2.3826 - val_MinusLogProbMetric: 2.3826 - lr: 1.2500e-04 - 61s/epoch - 311ms/step
Epoch 253/1000
2023-09-15 18:05:39.424 
Epoch 253/1000 
	 loss: 2.3566, MinusLogProbMetric: 2.3566, val_loss: 2.3824, val_MinusLogProbMetric: 2.3824

Epoch 253: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3566 - MinusLogProbMetric: 2.3566 - val_loss: 2.3824 - val_MinusLogProbMetric: 2.3824 - lr: 1.2500e-04 - 61s/epoch - 312ms/step
Epoch 254/1000
2023-09-15 18:06:40.372 
Epoch 254/1000 
	 loss: 2.3571, MinusLogProbMetric: 2.3571, val_loss: 2.3822, val_MinusLogProbMetric: 2.3822

Epoch 254: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3571 - MinusLogProbMetric: 2.3571 - val_loss: 2.3822 - val_MinusLogProbMetric: 2.3822 - lr: 1.2500e-04 - 61s/epoch - 311ms/step
Epoch 255/1000
2023-09-15 18:07:40.341 
Epoch 255/1000 
	 loss: 2.3568, MinusLogProbMetric: 2.3568, val_loss: 2.3825, val_MinusLogProbMetric: 2.3825

Epoch 255: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3568 - MinusLogProbMetric: 2.3568 - val_loss: 2.3825 - val_MinusLogProbMetric: 2.3825 - lr: 1.2500e-04 - 60s/epoch - 306ms/step
Epoch 256/1000
2023-09-15 18:08:41.598 
Epoch 256/1000 
	 loss: 2.3574, MinusLogProbMetric: 2.3574, val_loss: 2.3815, val_MinusLogProbMetric: 2.3815

Epoch 256: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3574 - MinusLogProbMetric: 2.3574 - val_loss: 2.3815 - val_MinusLogProbMetric: 2.3815 - lr: 1.2500e-04 - 61s/epoch - 313ms/step
Epoch 257/1000
2023-09-15 18:09:41.955 
Epoch 257/1000 
	 loss: 2.3564, MinusLogProbMetric: 2.3564, val_loss: 2.3832, val_MinusLogProbMetric: 2.3832

Epoch 257: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3564 - MinusLogProbMetric: 2.3564 - val_loss: 2.3832 - val_MinusLogProbMetric: 2.3832 - lr: 1.2500e-04 - 60s/epoch - 308ms/step
Epoch 258/1000
2023-09-15 18:10:42.704 
Epoch 258/1000 
	 loss: 2.3568, MinusLogProbMetric: 2.3568, val_loss: 2.3824, val_MinusLogProbMetric: 2.3824

Epoch 258: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3568 - MinusLogProbMetric: 2.3568 - val_loss: 2.3824 - val_MinusLogProbMetric: 2.3824 - lr: 1.2500e-04 - 61s/epoch - 310ms/step
Epoch 259/1000
2023-09-15 18:11:44.213 
Epoch 259/1000 
	 loss: 2.3566, MinusLogProbMetric: 2.3566, val_loss: 2.3835, val_MinusLogProbMetric: 2.3835

Epoch 259: val_loss did not improve from 2.38116
196/196 - 62s - loss: 2.3566 - MinusLogProbMetric: 2.3566 - val_loss: 2.3835 - val_MinusLogProbMetric: 2.3835 - lr: 1.2500e-04 - 62s/epoch - 314ms/step
Epoch 260/1000
2023-09-15 18:12:44.783 
Epoch 260/1000 
	 loss: 2.3568, MinusLogProbMetric: 2.3568, val_loss: 2.3827, val_MinusLogProbMetric: 2.3827

Epoch 260: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3568 - MinusLogProbMetric: 2.3568 - val_loss: 2.3827 - val_MinusLogProbMetric: 2.3827 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 261/1000
2023-09-15 18:13:44.969 
Epoch 261/1000 
	 loss: 2.3565, MinusLogProbMetric: 2.3565, val_loss: 2.3866, val_MinusLogProbMetric: 2.3866

Epoch 261: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3565 - MinusLogProbMetric: 2.3565 - val_loss: 2.3866 - val_MinusLogProbMetric: 2.3866 - lr: 1.2500e-04 - 60s/epoch - 307ms/step
Epoch 262/1000
2023-09-15 18:14:45.072 
Epoch 262/1000 
	 loss: 2.3572, MinusLogProbMetric: 2.3572, val_loss: 2.3830, val_MinusLogProbMetric: 2.3830

Epoch 262: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3572 - MinusLogProbMetric: 2.3572 - val_loss: 2.3830 - val_MinusLogProbMetric: 2.3830 - lr: 1.2500e-04 - 60s/epoch - 307ms/step
Epoch 263/1000
2023-09-15 18:15:43.887 
Epoch 263/1000 
	 loss: 2.3567, MinusLogProbMetric: 2.3567, val_loss: 2.3831, val_MinusLogProbMetric: 2.3831

Epoch 263: val_loss did not improve from 2.38116
196/196 - 59s - loss: 2.3567 - MinusLogProbMetric: 2.3567 - val_loss: 2.3831 - val_MinusLogProbMetric: 2.3831 - lr: 1.2500e-04 - 59s/epoch - 300ms/step
Epoch 264/1000
2023-09-15 18:16:43.376 
Epoch 264/1000 
	 loss: 2.3576, MinusLogProbMetric: 2.3576, val_loss: 2.3839, val_MinusLogProbMetric: 2.3839

Epoch 264: val_loss did not improve from 2.38116
196/196 - 59s - loss: 2.3576 - MinusLogProbMetric: 2.3576 - val_loss: 2.3839 - val_MinusLogProbMetric: 2.3839 - lr: 1.2500e-04 - 59s/epoch - 303ms/step
Epoch 265/1000
2023-09-15 18:17:44.281 
Epoch 265/1000 
	 loss: 2.3569, MinusLogProbMetric: 2.3569, val_loss: 2.3819, val_MinusLogProbMetric: 2.3819

Epoch 265: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3569 - MinusLogProbMetric: 2.3569 - val_loss: 2.3819 - val_MinusLogProbMetric: 2.3819 - lr: 1.2500e-04 - 61s/epoch - 311ms/step
Epoch 266/1000
2023-09-15 18:18:44.897 
Epoch 266/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.3873, val_MinusLogProbMetric: 2.3873

Epoch 266: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.3873 - val_MinusLogProbMetric: 2.3873 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 267/1000
2023-09-15 18:19:45.370 
Epoch 267/1000 
	 loss: 2.3572, MinusLogProbMetric: 2.3572, val_loss: 2.3826, val_MinusLogProbMetric: 2.3826

Epoch 267: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3572 - MinusLogProbMetric: 2.3572 - val_loss: 2.3826 - val_MinusLogProbMetric: 2.3826 - lr: 1.2500e-04 - 60s/epoch - 308ms/step
Epoch 268/1000
2023-09-15 18:20:46.097 
Epoch 268/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.3823, val_MinusLogProbMetric: 2.3823

Epoch 268: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.3823 - val_MinusLogProbMetric: 2.3823 - lr: 1.2500e-04 - 61s/epoch - 310ms/step
Epoch 269/1000
2023-09-15 18:21:46.972 
Epoch 269/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.3840, val_MinusLogProbMetric: 2.3840

Epoch 269: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.3840 - val_MinusLogProbMetric: 2.3840 - lr: 1.2500e-04 - 61s/epoch - 311ms/step
Epoch 270/1000
2023-09-15 18:22:48.391 
Epoch 270/1000 
	 loss: 2.3571, MinusLogProbMetric: 2.3571, val_loss: 2.3830, val_MinusLogProbMetric: 2.3830

Epoch 270: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3571 - MinusLogProbMetric: 2.3571 - val_loss: 2.3830 - val_MinusLogProbMetric: 2.3830 - lr: 1.2500e-04 - 61s/epoch - 313ms/step
Epoch 271/1000
2023-09-15 18:23:49.521 
Epoch 271/1000 
	 loss: 2.3569, MinusLogProbMetric: 2.3569, val_loss: 2.3831, val_MinusLogProbMetric: 2.3831

Epoch 271: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3569 - MinusLogProbMetric: 2.3569 - val_loss: 2.3831 - val_MinusLogProbMetric: 2.3831 - lr: 1.2500e-04 - 61s/epoch - 312ms/step
Epoch 272/1000
2023-09-15 18:24:50.774 
Epoch 272/1000 
	 loss: 2.3566, MinusLogProbMetric: 2.3566, val_loss: 2.3833, val_MinusLogProbMetric: 2.3833

Epoch 272: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3566 - MinusLogProbMetric: 2.3566 - val_loss: 2.3833 - val_MinusLogProbMetric: 2.3833 - lr: 1.2500e-04 - 61s/epoch - 312ms/step
Epoch 273/1000
2023-09-15 18:25:50.678 
Epoch 273/1000 
	 loss: 2.3566, MinusLogProbMetric: 2.3566, val_loss: 2.3843, val_MinusLogProbMetric: 2.3843

Epoch 273: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3566 - MinusLogProbMetric: 2.3566 - val_loss: 2.3843 - val_MinusLogProbMetric: 2.3843 - lr: 1.2500e-04 - 60s/epoch - 306ms/step
Epoch 274/1000
2023-09-15 18:26:51.096 
Epoch 274/1000 
	 loss: 2.3570, MinusLogProbMetric: 2.3570, val_loss: 2.3827, val_MinusLogProbMetric: 2.3827

Epoch 274: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3570 - MinusLogProbMetric: 2.3570 - val_loss: 2.3827 - val_MinusLogProbMetric: 2.3827 - lr: 1.2500e-04 - 60s/epoch - 308ms/step
Epoch 275/1000
2023-09-15 18:27:51.454 
Epoch 275/1000 
	 loss: 2.3569, MinusLogProbMetric: 2.3569, val_loss: 2.3840, val_MinusLogProbMetric: 2.3840

Epoch 275: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3569 - MinusLogProbMetric: 2.3569 - val_loss: 2.3840 - val_MinusLogProbMetric: 2.3840 - lr: 1.2500e-04 - 60s/epoch - 308ms/step
Epoch 276/1000
2023-09-15 18:28:52.006 
Epoch 276/1000 
	 loss: 2.3575, MinusLogProbMetric: 2.3575, val_loss: 2.3885, val_MinusLogProbMetric: 2.3885

Epoch 276: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3575 - MinusLogProbMetric: 2.3575 - val_loss: 2.3885 - val_MinusLogProbMetric: 2.3885 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 277/1000
2023-09-15 18:29:53.441 
Epoch 277/1000 
	 loss: 2.3560, MinusLogProbMetric: 2.3560, val_loss: 2.3830, val_MinusLogProbMetric: 2.3830

Epoch 277: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3560 - MinusLogProbMetric: 2.3560 - val_loss: 2.3830 - val_MinusLogProbMetric: 2.3830 - lr: 1.2500e-04 - 61s/epoch - 313ms/step
Epoch 278/1000
2023-09-15 18:30:54.131 
Epoch 278/1000 
	 loss: 2.3560, MinusLogProbMetric: 2.3560, val_loss: 2.3829, val_MinusLogProbMetric: 2.3829

Epoch 278: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3560 - MinusLogProbMetric: 2.3560 - val_loss: 2.3829 - val_MinusLogProbMetric: 2.3829 - lr: 1.2500e-04 - 61s/epoch - 310ms/step
Epoch 279/1000
2023-09-15 18:31:55.084 
Epoch 279/1000 
	 loss: 2.3570, MinusLogProbMetric: 2.3570, val_loss: 2.3823, val_MinusLogProbMetric: 2.3823

Epoch 279: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3570 - MinusLogProbMetric: 2.3570 - val_loss: 2.3823 - val_MinusLogProbMetric: 2.3823 - lr: 1.2500e-04 - 61s/epoch - 311ms/step
Epoch 280/1000
2023-09-15 18:32:55.924 
Epoch 280/1000 
	 loss: 2.3557, MinusLogProbMetric: 2.3557, val_loss: 2.3833, val_MinusLogProbMetric: 2.3833

Epoch 280: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3557 - MinusLogProbMetric: 2.3557 - val_loss: 2.3833 - val_MinusLogProbMetric: 2.3833 - lr: 1.2500e-04 - 61s/epoch - 310ms/step
Epoch 281/1000
2023-09-15 18:33:56.771 
Epoch 281/1000 
	 loss: 2.3571, MinusLogProbMetric: 2.3571, val_loss: 2.3829, val_MinusLogProbMetric: 2.3829

Epoch 281: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3571 - MinusLogProbMetric: 2.3571 - val_loss: 2.3829 - val_MinusLogProbMetric: 2.3829 - lr: 1.2500e-04 - 61s/epoch - 310ms/step
Epoch 282/1000
2023-09-15 18:34:57.232 
Epoch 282/1000 
	 loss: 2.3561, MinusLogProbMetric: 2.3561, val_loss: 2.3844, val_MinusLogProbMetric: 2.3844

Epoch 282: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3561 - MinusLogProbMetric: 2.3561 - val_loss: 2.3844 - val_MinusLogProbMetric: 2.3844 - lr: 1.2500e-04 - 60s/epoch - 308ms/step
Epoch 283/1000
2023-09-15 18:35:57.672 
Epoch 283/1000 
	 loss: 2.3568, MinusLogProbMetric: 2.3568, val_loss: 2.3856, val_MinusLogProbMetric: 2.3856

Epoch 283: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3568 - MinusLogProbMetric: 2.3568 - val_loss: 2.3856 - val_MinusLogProbMetric: 2.3856 - lr: 1.2500e-04 - 60s/epoch - 308ms/step
Epoch 284/1000
2023-09-15 18:36:58.837 
Epoch 284/1000 
	 loss: 2.3561, MinusLogProbMetric: 2.3561, val_loss: 2.3836, val_MinusLogProbMetric: 2.3836

Epoch 284: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3561 - MinusLogProbMetric: 2.3561 - val_loss: 2.3836 - val_MinusLogProbMetric: 2.3836 - lr: 1.2500e-04 - 61s/epoch - 312ms/step
Epoch 285/1000
2023-09-15 18:37:59.680 
Epoch 285/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.3830, val_MinusLogProbMetric: 2.3830

Epoch 285: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.3830 - val_MinusLogProbMetric: 2.3830 - lr: 1.2500e-04 - 61s/epoch - 310ms/step
Epoch 286/1000
2023-09-15 18:39:00.340 
Epoch 286/1000 
	 loss: 2.3559, MinusLogProbMetric: 2.3559, val_loss: 2.3855, val_MinusLogProbMetric: 2.3855

Epoch 286: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3559 - MinusLogProbMetric: 2.3559 - val_loss: 2.3855 - val_MinusLogProbMetric: 2.3855 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 287/1000
2023-09-15 18:40:00.263 
Epoch 287/1000 
	 loss: 2.3564, MinusLogProbMetric: 2.3564, val_loss: 2.3837, val_MinusLogProbMetric: 2.3837

Epoch 287: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3564 - MinusLogProbMetric: 2.3564 - val_loss: 2.3837 - val_MinusLogProbMetric: 2.3837 - lr: 1.2500e-04 - 60s/epoch - 306ms/step
Epoch 288/1000
2023-09-15 18:41:00.906 
Epoch 288/1000 
	 loss: 2.3564, MinusLogProbMetric: 2.3564, val_loss: 2.3837, val_MinusLogProbMetric: 2.3837

Epoch 288: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3564 - MinusLogProbMetric: 2.3564 - val_loss: 2.3837 - val_MinusLogProbMetric: 2.3837 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 289/1000
2023-09-15 18:42:01.225 
Epoch 289/1000 
	 loss: 2.3560, MinusLogProbMetric: 2.3560, val_loss: 2.3853, val_MinusLogProbMetric: 2.3853

Epoch 289: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3560 - MinusLogProbMetric: 2.3560 - val_loss: 2.3853 - val_MinusLogProbMetric: 2.3853 - lr: 1.2500e-04 - 60s/epoch - 308ms/step
Epoch 290/1000
2023-09-15 18:43:01.704 
Epoch 290/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.3863, val_MinusLogProbMetric: 2.3863

Epoch 290: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.3863 - val_MinusLogProbMetric: 2.3863 - lr: 1.2500e-04 - 60s/epoch - 309ms/step
Epoch 291/1000
2023-09-15 18:44:01.726 
Epoch 291/1000 
	 loss: 2.3564, MinusLogProbMetric: 2.3564, val_loss: 2.3844, val_MinusLogProbMetric: 2.3844

Epoch 291: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3564 - MinusLogProbMetric: 2.3564 - val_loss: 2.3844 - val_MinusLogProbMetric: 2.3844 - lr: 1.2500e-04 - 60s/epoch - 306ms/step
Epoch 292/1000
2023-09-15 18:45:01.838 
Epoch 292/1000 
	 loss: 2.3570, MinusLogProbMetric: 2.3570, val_loss: 2.3918, val_MinusLogProbMetric: 2.3918

Epoch 292: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3570 - MinusLogProbMetric: 2.3570 - val_loss: 2.3918 - val_MinusLogProbMetric: 2.3918 - lr: 1.2500e-04 - 60s/epoch - 307ms/step
Epoch 293/1000
2023-09-15 18:46:02.645 
Epoch 293/1000 
	 loss: 2.3538, MinusLogProbMetric: 2.3538, val_loss: 2.3820, val_MinusLogProbMetric: 2.3820

Epoch 293: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3538 - MinusLogProbMetric: 2.3538 - val_loss: 2.3820 - val_MinusLogProbMetric: 2.3820 - lr: 6.2500e-05 - 61s/epoch - 310ms/step
Epoch 294/1000
2023-09-15 18:47:02.913 
Epoch 294/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.3836, val_MinusLogProbMetric: 2.3836

Epoch 294: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.3836 - val_MinusLogProbMetric: 2.3836 - lr: 6.2500e-05 - 60s/epoch - 307ms/step
Epoch 295/1000
2023-09-15 18:48:03.063 
Epoch 295/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.3826, val_MinusLogProbMetric: 2.3826

Epoch 295: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.3826 - val_MinusLogProbMetric: 2.3826 - lr: 6.2500e-05 - 60s/epoch - 307ms/step
Epoch 296/1000
2023-09-15 18:49:03.106 
Epoch 296/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.3851, val_MinusLogProbMetric: 2.3851

Epoch 296: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.3851 - val_MinusLogProbMetric: 2.3851 - lr: 6.2500e-05 - 60s/epoch - 306ms/step
Epoch 297/1000
2023-09-15 18:50:03.785 
Epoch 297/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3834, val_MinusLogProbMetric: 2.3834

Epoch 297: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3834 - val_MinusLogProbMetric: 2.3834 - lr: 6.2500e-05 - 61s/epoch - 310ms/step
Epoch 298/1000
2023-09-15 18:51:04.465 
Epoch 298/1000 
	 loss: 2.3538, MinusLogProbMetric: 2.3538, val_loss: 2.3824, val_MinusLogProbMetric: 2.3824

Epoch 298: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3538 - MinusLogProbMetric: 2.3538 - val_loss: 2.3824 - val_MinusLogProbMetric: 2.3824 - lr: 6.2500e-05 - 61s/epoch - 310ms/step
Epoch 299/1000
2023-09-15 18:52:05.180 
Epoch 299/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.3850, val_MinusLogProbMetric: 2.3850

Epoch 299: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.3850 - val_MinusLogProbMetric: 2.3850 - lr: 6.2500e-05 - 61s/epoch - 309ms/step
Epoch 300/1000
2023-09-15 18:53:06.061 
Epoch 300/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.3823, val_MinusLogProbMetric: 2.3823

Epoch 300: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.3823 - val_MinusLogProbMetric: 2.3823 - lr: 6.2500e-05 - 61s/epoch - 311ms/step
Epoch 301/1000
2023-09-15 18:54:07.209 
Epoch 301/1000 
	 loss: 2.3530, MinusLogProbMetric: 2.3530, val_loss: 2.3825, val_MinusLogProbMetric: 2.3825

Epoch 301: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3530 - MinusLogProbMetric: 2.3530 - val_loss: 2.3825 - val_MinusLogProbMetric: 2.3825 - lr: 6.2500e-05 - 61s/epoch - 312ms/step
Epoch 302/1000
2023-09-15 18:55:07.412 
Epoch 302/1000 
	 loss: 2.3532, MinusLogProbMetric: 2.3532, val_loss: 2.3821, val_MinusLogProbMetric: 2.3821

Epoch 302: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3532 - MinusLogProbMetric: 2.3532 - val_loss: 2.3821 - val_MinusLogProbMetric: 2.3821 - lr: 6.2500e-05 - 60s/epoch - 307ms/step
Epoch 303/1000
2023-09-15 18:56:08.335 
Epoch 303/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.3817, val_MinusLogProbMetric: 2.3817

Epoch 303: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.3817 - val_MinusLogProbMetric: 2.3817 - lr: 6.2500e-05 - 61s/epoch - 311ms/step
Epoch 304/1000
2023-09-15 18:57:08.868 
Epoch 304/1000 
	 loss: 2.3530, MinusLogProbMetric: 2.3530, val_loss: 2.3822, val_MinusLogProbMetric: 2.3822

Epoch 304: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3530 - MinusLogProbMetric: 2.3530 - val_loss: 2.3822 - val_MinusLogProbMetric: 2.3822 - lr: 6.2500e-05 - 61s/epoch - 309ms/step
Epoch 305/1000
2023-09-15 18:58:09.780 
Epoch 305/1000 
	 loss: 2.3537, MinusLogProbMetric: 2.3537, val_loss: 2.3817, val_MinusLogProbMetric: 2.3817

Epoch 305: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3537 - MinusLogProbMetric: 2.3537 - val_loss: 2.3817 - val_MinusLogProbMetric: 2.3817 - lr: 6.2500e-05 - 61s/epoch - 311ms/step
Epoch 306/1000
2023-09-15 18:59:11.284 
Epoch 306/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.3846, val_MinusLogProbMetric: 2.3846

Epoch 306: val_loss did not improve from 2.38116
196/196 - 62s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.3846 - val_MinusLogProbMetric: 2.3846 - lr: 6.2500e-05 - 62s/epoch - 314ms/step
Epoch 307/1000
2023-09-15 19:00:12.267 
Epoch 307/1000 
	 loss: 2.3528, MinusLogProbMetric: 2.3528, val_loss: 2.3832, val_MinusLogProbMetric: 2.3832

Epoch 307: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3528 - MinusLogProbMetric: 2.3528 - val_loss: 2.3832 - val_MinusLogProbMetric: 2.3832 - lr: 6.2500e-05 - 61s/epoch - 311ms/step
Epoch 308/1000
2023-09-15 19:01:13.001 
Epoch 308/1000 
	 loss: 2.3533, MinusLogProbMetric: 2.3533, val_loss: 2.3828, val_MinusLogProbMetric: 2.3828

Epoch 308: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3533 - MinusLogProbMetric: 2.3533 - val_loss: 2.3828 - val_MinusLogProbMetric: 2.3828 - lr: 6.2500e-05 - 61s/epoch - 310ms/step
Epoch 309/1000
2023-09-15 19:02:13.627 
Epoch 309/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.3831, val_MinusLogProbMetric: 2.3831

Epoch 309: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.3831 - val_MinusLogProbMetric: 2.3831 - lr: 6.2500e-05 - 61s/epoch - 309ms/step
Epoch 310/1000
2023-09-15 19:03:15.547 
Epoch 310/1000 
	 loss: 2.3530, MinusLogProbMetric: 2.3530, val_loss: 2.3822, val_MinusLogProbMetric: 2.3822

Epoch 310: val_loss did not improve from 2.38116
196/196 - 62s - loss: 2.3530 - MinusLogProbMetric: 2.3530 - val_loss: 2.3822 - val_MinusLogProbMetric: 2.3822 - lr: 6.2500e-05 - 62s/epoch - 316ms/step
Epoch 311/1000
2023-09-15 19:04:16.382 
Epoch 311/1000 
	 loss: 2.3532, MinusLogProbMetric: 2.3532, val_loss: 2.3818, val_MinusLogProbMetric: 2.3818

Epoch 311: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3532 - MinusLogProbMetric: 2.3532 - val_loss: 2.3818 - val_MinusLogProbMetric: 2.3818 - lr: 6.2500e-05 - 61s/epoch - 310ms/step
Epoch 312/1000
2023-09-15 19:05:17.392 
Epoch 312/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3855, val_MinusLogProbMetric: 2.3855

Epoch 312: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3855 - val_MinusLogProbMetric: 2.3855 - lr: 6.2500e-05 - 61s/epoch - 311ms/step
Epoch 313/1000
2023-09-15 19:06:18.311 
Epoch 313/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.3840, val_MinusLogProbMetric: 2.3840

Epoch 313: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.3840 - val_MinusLogProbMetric: 2.3840 - lr: 6.2500e-05 - 61s/epoch - 311ms/step
Epoch 314/1000
2023-09-15 19:07:19.691 
Epoch 314/1000 
	 loss: 2.3532, MinusLogProbMetric: 2.3532, val_loss: 2.3822, val_MinusLogProbMetric: 2.3822

Epoch 314: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3532 - MinusLogProbMetric: 2.3532 - val_loss: 2.3822 - val_MinusLogProbMetric: 2.3822 - lr: 6.2500e-05 - 61s/epoch - 313ms/step
Epoch 315/1000
2023-09-15 19:08:21.222 
Epoch 315/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3826, val_MinusLogProbMetric: 2.3826

Epoch 315: val_loss did not improve from 2.38116
196/196 - 62s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3826 - val_MinusLogProbMetric: 2.3826 - lr: 6.2500e-05 - 62s/epoch - 314ms/step
Epoch 316/1000
2023-09-15 19:09:22.356 
Epoch 316/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3824, val_MinusLogProbMetric: 2.3824

Epoch 316: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3824 - val_MinusLogProbMetric: 2.3824 - lr: 6.2500e-05 - 61s/epoch - 312ms/step
Epoch 317/1000
2023-09-15 19:10:23.305 
Epoch 317/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3836, val_MinusLogProbMetric: 2.3836

Epoch 317: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3836 - val_MinusLogProbMetric: 2.3836 - lr: 6.2500e-05 - 61s/epoch - 311ms/step
Epoch 318/1000
2023-09-15 19:11:25.518 
Epoch 318/1000 
	 loss: 2.3532, MinusLogProbMetric: 2.3532, val_loss: 2.3821, val_MinusLogProbMetric: 2.3821

Epoch 318: val_loss did not improve from 2.38116
196/196 - 62s - loss: 2.3532 - MinusLogProbMetric: 2.3532 - val_loss: 2.3821 - val_MinusLogProbMetric: 2.3821 - lr: 6.2500e-05 - 62s/epoch - 317ms/step
Epoch 319/1000
2023-09-15 19:12:26.258 
Epoch 319/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3826, val_MinusLogProbMetric: 2.3826

Epoch 319: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3826 - val_MinusLogProbMetric: 2.3826 - lr: 6.2500e-05 - 61s/epoch - 310ms/step
Epoch 320/1000
2023-09-15 19:13:27.281 
Epoch 320/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.3831, val_MinusLogProbMetric: 2.3831

Epoch 320: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.3831 - val_MinusLogProbMetric: 2.3831 - lr: 6.2500e-05 - 61s/epoch - 311ms/step
Epoch 321/1000
2023-09-15 19:14:28.251 
Epoch 321/1000 
	 loss: 2.3527, MinusLogProbMetric: 2.3527, val_loss: 2.3822, val_MinusLogProbMetric: 2.3822

Epoch 321: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3527 - MinusLogProbMetric: 2.3527 - val_loss: 2.3822 - val_MinusLogProbMetric: 2.3822 - lr: 6.2500e-05 - 61s/epoch - 311ms/step
Epoch 322/1000
2023-09-15 19:15:28.880 
Epoch 322/1000 
	 loss: 2.3528, MinusLogProbMetric: 2.3528, val_loss: 2.3824, val_MinusLogProbMetric: 2.3824

Epoch 322: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3528 - MinusLogProbMetric: 2.3528 - val_loss: 2.3824 - val_MinusLogProbMetric: 2.3824 - lr: 6.2500e-05 - 61s/epoch - 309ms/step
Epoch 323/1000
2023-09-15 19:16:29.902 
Epoch 323/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.3824, val_MinusLogProbMetric: 2.3824

Epoch 323: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.3824 - val_MinusLogProbMetric: 2.3824 - lr: 6.2500e-05 - 61s/epoch - 311ms/step
Epoch 324/1000
2023-09-15 19:17:31.058 
Epoch 324/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3838, val_MinusLogProbMetric: 2.3838

Epoch 324: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3838 - val_MinusLogProbMetric: 2.3838 - lr: 6.2500e-05 - 61s/epoch - 312ms/step
Epoch 325/1000
2023-09-15 19:18:31.811 
Epoch 325/1000 
	 loss: 2.3530, MinusLogProbMetric: 2.3530, val_loss: 2.3844, val_MinusLogProbMetric: 2.3844

Epoch 325: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3530 - MinusLogProbMetric: 2.3530 - val_loss: 2.3844 - val_MinusLogProbMetric: 2.3844 - lr: 6.2500e-05 - 61s/epoch - 310ms/step
Epoch 326/1000
2023-09-15 19:19:32.390 
Epoch 326/1000 
	 loss: 2.3532, MinusLogProbMetric: 2.3532, val_loss: 2.3826, val_MinusLogProbMetric: 2.3826

Epoch 326: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3532 - MinusLogProbMetric: 2.3532 - val_loss: 2.3826 - val_MinusLogProbMetric: 2.3826 - lr: 6.2500e-05 - 61s/epoch - 309ms/step
Epoch 327/1000
2023-09-15 19:20:33.014 
Epoch 327/1000 
	 loss: 2.3528, MinusLogProbMetric: 2.3528, val_loss: 2.3849, val_MinusLogProbMetric: 2.3849

Epoch 327: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3528 - MinusLogProbMetric: 2.3528 - val_loss: 2.3849 - val_MinusLogProbMetric: 2.3849 - lr: 6.2500e-05 - 61s/epoch - 309ms/step
Epoch 328/1000
2023-09-15 19:21:33.956 
Epoch 328/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3821, val_MinusLogProbMetric: 2.3821

Epoch 328: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3821 - val_MinusLogProbMetric: 2.3821 - lr: 6.2500e-05 - 61s/epoch - 311ms/step
Epoch 329/1000
2023-09-15 19:22:35.250 
Epoch 329/1000 
	 loss: 2.3530, MinusLogProbMetric: 2.3530, val_loss: 2.3843, val_MinusLogProbMetric: 2.3843

Epoch 329: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3530 - MinusLogProbMetric: 2.3530 - val_loss: 2.3843 - val_MinusLogProbMetric: 2.3843 - lr: 6.2500e-05 - 61s/epoch - 313ms/step
Epoch 330/1000
2023-09-15 19:23:35.782 
Epoch 330/1000 
	 loss: 2.3530, MinusLogProbMetric: 2.3530, val_loss: 2.3819, val_MinusLogProbMetric: 2.3819

Epoch 330: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3530 - MinusLogProbMetric: 2.3530 - val_loss: 2.3819 - val_MinusLogProbMetric: 2.3819 - lr: 6.2500e-05 - 61s/epoch - 309ms/step
Epoch 331/1000
2023-09-15 19:24:37.486 
Epoch 331/1000 
	 loss: 2.3527, MinusLogProbMetric: 2.3527, val_loss: 2.3825, val_MinusLogProbMetric: 2.3825

Epoch 331: val_loss did not improve from 2.38116
196/196 - 62s - loss: 2.3527 - MinusLogProbMetric: 2.3527 - val_loss: 2.3825 - val_MinusLogProbMetric: 2.3825 - lr: 6.2500e-05 - 62s/epoch - 315ms/step
Epoch 332/1000
2023-09-15 19:25:38.408 
Epoch 332/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3842, val_MinusLogProbMetric: 2.3842

Epoch 332: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3842 - val_MinusLogProbMetric: 2.3842 - lr: 6.2500e-05 - 61s/epoch - 311ms/step
Epoch 333/1000
2023-09-15 19:26:38.467 
Epoch 333/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3821, val_MinusLogProbMetric: 2.3821

Epoch 333: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3821 - val_MinusLogProbMetric: 2.3821 - lr: 6.2500e-05 - 60s/epoch - 306ms/step
Epoch 334/1000
2023-09-15 19:27:39.016 
Epoch 334/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.3820, val_MinusLogProbMetric: 2.3820

Epoch 334: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.3820 - val_MinusLogProbMetric: 2.3820 - lr: 6.2500e-05 - 61s/epoch - 309ms/step
Epoch 335/1000
2023-09-15 19:28:39.598 
Epoch 335/1000 
	 loss: 2.3527, MinusLogProbMetric: 2.3527, val_loss: 2.3832, val_MinusLogProbMetric: 2.3832

Epoch 335: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3527 - MinusLogProbMetric: 2.3527 - val_loss: 2.3832 - val_MinusLogProbMetric: 2.3832 - lr: 6.2500e-05 - 61s/epoch - 309ms/step
Epoch 336/1000
2023-09-15 19:29:40.448 
Epoch 336/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3843, val_MinusLogProbMetric: 2.3843

Epoch 336: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3843 - val_MinusLogProbMetric: 2.3843 - lr: 6.2500e-05 - 61s/epoch - 310ms/step
Epoch 337/1000
2023-09-15 19:30:43.383 
Epoch 337/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3829, val_MinusLogProbMetric: 2.3829

Epoch 337: val_loss did not improve from 2.38116
196/196 - 63s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3829 - val_MinusLogProbMetric: 2.3829 - lr: 6.2500e-05 - 63s/epoch - 321ms/step
Epoch 338/1000
2023-09-15 19:31:51.218 
Epoch 338/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.3834, val_MinusLogProbMetric: 2.3834

Epoch 338: val_loss did not improve from 2.38116
196/196 - 68s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.3834 - val_MinusLogProbMetric: 2.3834 - lr: 6.2500e-05 - 68s/epoch - 346ms/step
Epoch 339/1000
2023-09-15 19:32:53.709 
Epoch 339/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.3822, val_MinusLogProbMetric: 2.3822

Epoch 339: val_loss did not improve from 2.38116
196/196 - 62s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.3822 - val_MinusLogProbMetric: 2.3822 - lr: 6.2500e-05 - 62s/epoch - 319ms/step
Epoch 340/1000
2023-09-15 19:33:53.840 
Epoch 340/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3829, val_MinusLogProbMetric: 2.3829

Epoch 340: val_loss did not improve from 2.38116
196/196 - 60s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3829 - val_MinusLogProbMetric: 2.3829 - lr: 6.2500e-05 - 60s/epoch - 307ms/step
Epoch 341/1000
2023-09-15 19:34:54.421 
Epoch 341/1000 
	 loss: 2.3528, MinusLogProbMetric: 2.3528, val_loss: 2.3831, val_MinusLogProbMetric: 2.3831

Epoch 341: val_loss did not improve from 2.38116
196/196 - 61s - loss: 2.3528 - MinusLogProbMetric: 2.3528 - val_loss: 2.3831 - val_MinusLogProbMetric: 2.3831 - lr: 6.2500e-05 - 61s/epoch - 309ms/step
Epoch 342/1000
2023-09-15 19:35:55.572 
Epoch 342/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3827, val_MinusLogProbMetric: 2.3827

Epoch 342: val_loss did not improve from 2.38116
Restoring model weights from the end of the best epoch: 242.
196/196 - 62s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3827 - val_MinusLogProbMetric: 2.3827 - lr: 6.2500e-05 - 62s/epoch - 315ms/step
Epoch 342: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 18.292171862907708 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 13.248394458787516 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 6.723787263035774 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fb3001c0e50> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 25.04767773183994 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 9.77029832592234 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 5.266772930044681 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fb6fbfe6290> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 541.
Model trained in 20804.86 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

Plots done in 2.81 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 102.11 s.
===========
Run 45/720 done in 20915.56 s.
===========

Directory ../../results/CsplineN_new/run_46/ already exists.
Skipping it.
===========
Run 46/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_47/ already exists.
Skipping it.
===========
Run 47/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_48/ already exists.
Skipping it.
===========
Run 48/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_49/ already exists.
Skipping it.
===========
Run 49/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_50/ already exists.
Skipping it.
===========
Run 50/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_51/ already exists.
Skipping it.
===========
Run 51/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_52/ already exists.
Skipping it.
===========
Run 52/720 already exists. Skipping it.
===========

===========
Generating train data for run 53.
===========
Train data generated in 0.28 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 4)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_53/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 721}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_53/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 4.199659 ,  6.4188223,  4.7532644, 10.006012 ],
       [ 4.22245  ,  5.9659095,  3.7776601,  8.343435 ],
       [ 9.615707 ,  5.49844  ,  7.495583 ,  5.135999 ],
       ...,
       [ 4.2172456,  6.201409 ,  3.6995027,  8.806188 ],
       [ 4.2722325,  7.532345 ,  4.6026692, 11.134918 ],
       [ 4.2096395,  6.545041 ,  4.8637457, 11.02672  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_53/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_53
self.data_kwargs: {'seed': 721}
self.x_data: [[ 5.4491744  7.62697    6.0819464  5.4084225]
 [ 4.24566    6.916348   4.558419   8.932697 ]
 [ 4.226888   5.056197   4.516181  10.139818 ]
 ...
 [ 4.2480607  5.082196   4.7570243  8.905375 ]
 [ 4.2314844  5.8616033  4.122643   8.593621 ]
 [ 4.252966   5.7376084  4.335346   9.082314 ]]
self.y_data: []
self.ndims: 4
Model defined.
Model: "model_21"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_22 (InputLayer)       [(None, 4)]               0         
                                                                 
 log_prob_layer_1 (LogProbLa  (None,)                  393420    
 yer)                                                            
                                                                 
=================================================================
Total params: 393,420
Trainable params: 393,420
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_1/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_1'")
self.model: <keras.engine.functional.Functional object at 0x7fb009563df0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fb009bc3730>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fb009bc3730>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fb009a8a380>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fb008fc4190>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fb008fc4700>, <keras.callbacks.ModelCheckpoint object at 0x7fb008fc47c0>, <keras.callbacks.EarlyStopping object at 0x7fb008fc4a30>, <keras.callbacks.ReduceLROnPlateau object at 0x7fb008fc4a60>, <keras.callbacks.TerminateOnNaN object at 0x7fb008fc46a0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 4.199659 ,  6.4188223,  4.7532644, 10.006012 ],
       [ 4.22245  ,  5.9659095,  3.7776601,  8.343435 ],
       [ 9.615707 ,  5.49844  ,  7.495583 ,  5.135999 ],
       ...,
       [ 4.2172456,  6.201409 ,  3.6995027,  8.806188 ],
       [ 4.2722325,  7.532345 ,  4.6026692, 11.134918 ],
       [ 4.2096395,  6.545041 ,  4.8637457, 11.02672  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_53/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 53/720 with hyperparameters:
timestamp = 2023-09-15 19:37:48.546275
ndims = 4
seed_train = 721
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 8
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 393420
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [5.4491744 7.62697   6.0819464 5.4084225]
Epoch 1/1000
2023-09-15 19:41:25.177 
Epoch 1/1000 
	 loss: 7.3364, MinusLogProbMetric: 7.3364, val_loss: 4.7126, val_MinusLogProbMetric: 4.7126

Epoch 1: val_loss improved from inf to 4.71257, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5
196/196 - 217s - loss: 7.3364 - MinusLogProbMetric: 7.3364 - val_loss: 4.7126 - val_MinusLogProbMetric: 4.7126 - lr: 0.0010 - 217s/epoch - 1s/step
Epoch 2/1000
2023-09-15 19:42:28.337 
Epoch 2/1000 
	 loss: 4.6106, MinusLogProbMetric: 4.6106, val_loss: 4.2473, val_MinusLogProbMetric: 4.2473

Epoch 2: val_loss improved from 4.71257 to 4.24733, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5
196/196 - 63s - loss: 4.6106 - MinusLogProbMetric: 4.6106 - val_loss: 4.2473 - val_MinusLogProbMetric: 4.2473 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 3/1000
2023-09-15 19:43:32.469 
Epoch 3/1000 
	 loss: 4.0541, MinusLogProbMetric: 4.0541, val_loss: 6.1766, val_MinusLogProbMetric: 6.1766

Epoch 3: val_loss did not improve from 4.24733
196/196 - 63s - loss: 4.0541 - MinusLogProbMetric: 4.0541 - val_loss: 6.1766 - val_MinusLogProbMetric: 6.1766 - lr: 0.0010 - 63s/epoch - 322ms/step
Epoch 4/1000
2023-09-15 19:44:34.620 
Epoch 4/1000 
	 loss: 4.0149, MinusLogProbMetric: 4.0149, val_loss: 4.2253, val_MinusLogProbMetric: 4.2253

Epoch 4: val_loss improved from 4.24733 to 4.22532, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5
196/196 - 63s - loss: 4.0149 - MinusLogProbMetric: 4.0149 - val_loss: 4.2253 - val_MinusLogProbMetric: 4.2253 - lr: 0.0010 - 63s/epoch - 322ms/step
Epoch 5/1000
2023-09-15 19:45:37.762 
Epoch 5/1000 
	 loss: 3.6459, MinusLogProbMetric: 3.6459, val_loss: 4.1926, val_MinusLogProbMetric: 4.1926

Epoch 5: val_loss improved from 4.22532 to 4.19259, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5
196/196 - 63s - loss: 3.6459 - MinusLogProbMetric: 3.6459 - val_loss: 4.1926 - val_MinusLogProbMetric: 4.1926 - lr: 0.0010 - 63s/epoch - 322ms/step
Epoch 6/1000
2023-09-15 19:46:42.393 
Epoch 6/1000 
	 loss: 3.2660, MinusLogProbMetric: 3.2660, val_loss: 2.9306, val_MinusLogProbMetric: 2.9306

Epoch 6: val_loss improved from 4.19259 to 2.93062, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5
196/196 - 65s - loss: 3.2660 - MinusLogProbMetric: 3.2660 - val_loss: 2.9306 - val_MinusLogProbMetric: 2.9306 - lr: 0.0010 - 65s/epoch - 330ms/step
Epoch 7/1000
2023-09-15 19:47:46.313 
Epoch 7/1000 
	 loss: 3.1287, MinusLogProbMetric: 3.1287, val_loss: 2.9027, val_MinusLogProbMetric: 2.9027

Epoch 7: val_loss improved from 2.93062 to 2.90270, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5
196/196 - 64s - loss: 3.1287 - MinusLogProbMetric: 3.1287 - val_loss: 2.9027 - val_MinusLogProbMetric: 2.9027 - lr: 0.0010 - 64s/epoch - 327ms/step
Epoch 8/1000
2023-09-15 19:48:49.948 
Epoch 8/1000 
	 loss: 3.1605, MinusLogProbMetric: 3.1605, val_loss: 2.6794, val_MinusLogProbMetric: 2.6794

Epoch 8: val_loss improved from 2.90270 to 2.67942, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5
196/196 - 63s - loss: 3.1605 - MinusLogProbMetric: 3.1605 - val_loss: 2.6794 - val_MinusLogProbMetric: 2.6794 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 9/1000
2023-09-15 19:49:53.931 
Epoch 9/1000 
	 loss: 2.8944, MinusLogProbMetric: 2.8944, val_loss: 2.8188, val_MinusLogProbMetric: 2.8188

Epoch 9: val_loss did not improve from 2.67942
196/196 - 63s - loss: 2.8944 - MinusLogProbMetric: 2.8944 - val_loss: 2.8188 - val_MinusLogProbMetric: 2.8188 - lr: 0.0010 - 63s/epoch - 322ms/step
Epoch 10/1000
2023-09-15 19:50:56.892 
Epoch 10/1000 
	 loss: 3.1037, MinusLogProbMetric: 3.1037, val_loss: 2.5754, val_MinusLogProbMetric: 2.5754

Epoch 10: val_loss improved from 2.67942 to 2.57537, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5
196/196 - 64s - loss: 3.1037 - MinusLogProbMetric: 3.1037 - val_loss: 2.5754 - val_MinusLogProbMetric: 2.5754 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 11/1000
2023-09-15 19:52:00.056 
Epoch 11/1000 
	 loss: 2.8552, MinusLogProbMetric: 2.8552, val_loss: 2.8314, val_MinusLogProbMetric: 2.8314

Epoch 11: val_loss did not improve from 2.57537
196/196 - 62s - loss: 2.8552 - MinusLogProbMetric: 2.8552 - val_loss: 2.8314 - val_MinusLogProbMetric: 2.8314 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 12/1000
2023-09-15 19:53:02.048 
Epoch 12/1000 
	 loss: 2.9511, MinusLogProbMetric: 2.9511, val_loss: 2.6496, val_MinusLogProbMetric: 2.6496

Epoch 12: val_loss did not improve from 2.57537
196/196 - 62s - loss: 2.9511 - MinusLogProbMetric: 2.9511 - val_loss: 2.6496 - val_MinusLogProbMetric: 2.6496 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 13/1000
2023-09-15 19:54:04.167 
Epoch 13/1000 
	 loss: 2.7588, MinusLogProbMetric: 2.7588, val_loss: 2.6375, val_MinusLogProbMetric: 2.6375

Epoch 13: val_loss did not improve from 2.57537
196/196 - 62s - loss: 2.7588 - MinusLogProbMetric: 2.7588 - val_loss: 2.6375 - val_MinusLogProbMetric: 2.6375 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 14/1000
2023-09-15 19:55:05.558 
Epoch 14/1000 
	 loss: 2.6211, MinusLogProbMetric: 2.6211, val_loss: 2.9877, val_MinusLogProbMetric: 2.9877

Epoch 14: val_loss did not improve from 2.57537
196/196 - 61s - loss: 2.6211 - MinusLogProbMetric: 2.6211 - val_loss: 2.9877 - val_MinusLogProbMetric: 2.9877 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 15/1000
2023-09-15 19:56:08.643 
Epoch 15/1000 
	 loss: 2.6841, MinusLogProbMetric: 2.6841, val_loss: 3.1362, val_MinusLogProbMetric: 3.1362

Epoch 15: val_loss did not improve from 2.57537
196/196 - 63s - loss: 2.6841 - MinusLogProbMetric: 2.6841 - val_loss: 3.1362 - val_MinusLogProbMetric: 3.1362 - lr: 0.0010 - 63s/epoch - 322ms/step
Epoch 16/1000
2023-09-15 19:57:11.919 
Epoch 16/1000 
	 loss: 2.6259, MinusLogProbMetric: 2.6259, val_loss: 2.4578, val_MinusLogProbMetric: 2.4578

Epoch 16: val_loss improved from 2.57537 to 2.45783, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5
196/196 - 64s - loss: 2.6259 - MinusLogProbMetric: 2.6259 - val_loss: 2.4578 - val_MinusLogProbMetric: 2.4578 - lr: 0.0010 - 64s/epoch - 327ms/step
Epoch 17/1000
2023-09-15 19:58:15.129 
Epoch 17/1000 
	 loss: 2.5909, MinusLogProbMetric: 2.5909, val_loss: 2.4770, val_MinusLogProbMetric: 2.4770

Epoch 17: val_loss did not improve from 2.45783
196/196 - 62s - loss: 2.5909 - MinusLogProbMetric: 2.5909 - val_loss: 2.4770 - val_MinusLogProbMetric: 2.4770 - lr: 0.0010 - 62s/epoch - 318ms/step
Epoch 18/1000
2023-09-15 19:59:17.772 
Epoch 18/1000 
	 loss: 2.5774, MinusLogProbMetric: 2.5774, val_loss: 2.8514, val_MinusLogProbMetric: 2.8514

Epoch 18: val_loss did not improve from 2.45783
196/196 - 63s - loss: 2.5774 - MinusLogProbMetric: 2.5774 - val_loss: 2.8514 - val_MinusLogProbMetric: 2.8514 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 19/1000
2023-09-15 20:00:21.513 
Epoch 19/1000 
	 loss: 2.5871, MinusLogProbMetric: 2.5871, val_loss: 2.4655, val_MinusLogProbMetric: 2.4655

Epoch 19: val_loss did not improve from 2.45783
196/196 - 64s - loss: 2.5871 - MinusLogProbMetric: 2.5871 - val_loss: 2.4655 - val_MinusLogProbMetric: 2.4655 - lr: 0.0010 - 64s/epoch - 325ms/step
Epoch 20/1000
2023-09-15 20:01:23.533 
Epoch 20/1000 
	 loss: 2.5197, MinusLogProbMetric: 2.5197, val_loss: 2.4264, val_MinusLogProbMetric: 2.4264

Epoch 20: val_loss improved from 2.45783 to 2.42641, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5
196/196 - 63s - loss: 2.5197 - MinusLogProbMetric: 2.5197 - val_loss: 2.4264 - val_MinusLogProbMetric: 2.4264 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 21/1000
2023-09-15 20:02:26.949 
Epoch 21/1000 
	 loss: 2.5122, MinusLogProbMetric: 2.5122, val_loss: 2.4409, val_MinusLogProbMetric: 2.4409

Epoch 21: val_loss did not improve from 2.42641
196/196 - 63s - loss: 2.5122 - MinusLogProbMetric: 2.5122 - val_loss: 2.4409 - val_MinusLogProbMetric: 2.4409 - lr: 0.0010 - 63s/epoch - 319ms/step
Epoch 22/1000
2023-09-15 20:03:29.542 
Epoch 22/1000 
	 loss: 2.5484, MinusLogProbMetric: 2.5484, val_loss: 2.4470, val_MinusLogProbMetric: 2.4470

Epoch 22: val_loss did not improve from 2.42641
196/196 - 63s - loss: 2.5484 - MinusLogProbMetric: 2.5484 - val_loss: 2.4470 - val_MinusLogProbMetric: 2.4470 - lr: 0.0010 - 63s/epoch - 319ms/step
Epoch 23/1000
2023-09-15 20:04:32.143 
Epoch 23/1000 
	 loss: 2.5002, MinusLogProbMetric: 2.5002, val_loss: 2.5006, val_MinusLogProbMetric: 2.5006

Epoch 23: val_loss did not improve from 2.42641
196/196 - 63s - loss: 2.5002 - MinusLogProbMetric: 2.5002 - val_loss: 2.5006 - val_MinusLogProbMetric: 2.5006 - lr: 0.0010 - 63s/epoch - 319ms/step
Epoch 24/1000
2023-09-15 20:05:34.838 
Epoch 24/1000 
	 loss: 2.5348, MinusLogProbMetric: 2.5348, val_loss: 2.4874, val_MinusLogProbMetric: 2.4874

Epoch 24: val_loss did not improve from 2.42641
196/196 - 63s - loss: 2.5348 - MinusLogProbMetric: 2.5348 - val_loss: 2.4874 - val_MinusLogProbMetric: 2.4874 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 25/1000
2023-09-15 20:06:36.690 
Epoch 25/1000 
	 loss: 2.4932, MinusLogProbMetric: 2.4932, val_loss: 2.4699, val_MinusLogProbMetric: 2.4699

Epoch 25: val_loss did not improve from 2.42641
196/196 - 62s - loss: 2.4932 - MinusLogProbMetric: 2.4932 - val_loss: 2.4699 - val_MinusLogProbMetric: 2.4699 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 26/1000
2023-09-15 20:07:39.353 
Epoch 26/1000 
	 loss: 2.4875, MinusLogProbMetric: 2.4875, val_loss: 2.7823, val_MinusLogProbMetric: 2.7823

Epoch 26: val_loss did not improve from 2.42641
196/196 - 63s - loss: 2.4875 - MinusLogProbMetric: 2.4875 - val_loss: 2.7823 - val_MinusLogProbMetric: 2.7823 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 27/1000
2023-09-15 20:08:42.250 
Epoch 27/1000 
	 loss: 2.5020, MinusLogProbMetric: 2.5020, val_loss: 2.4143, val_MinusLogProbMetric: 2.4143

Epoch 27: val_loss improved from 2.42641 to 2.41431, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5
196/196 - 64s - loss: 2.5020 - MinusLogProbMetric: 2.5020 - val_loss: 2.4143 - val_MinusLogProbMetric: 2.4143 - lr: 0.0010 - 64s/epoch - 325ms/step
Epoch 28/1000
2023-09-15 20:09:45.983 
Epoch 28/1000 
	 loss: 2.4835, MinusLogProbMetric: 2.4835, val_loss: 2.5371, val_MinusLogProbMetric: 2.5371

Epoch 28: val_loss did not improve from 2.41431
196/196 - 63s - loss: 2.4835 - MinusLogProbMetric: 2.4835 - val_loss: 2.5371 - val_MinusLogProbMetric: 2.5371 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 29/1000
2023-09-15 20:10:48.601 
Epoch 29/1000 
	 loss: 2.4722, MinusLogProbMetric: 2.4722, val_loss: 2.4287, val_MinusLogProbMetric: 2.4287

Epoch 29: val_loss did not improve from 2.41431
196/196 - 63s - loss: 2.4722 - MinusLogProbMetric: 2.4722 - val_loss: 2.4287 - val_MinusLogProbMetric: 2.4287 - lr: 0.0010 - 63s/epoch - 319ms/step
Epoch 30/1000
2023-09-15 20:11:51.193 
Epoch 30/1000 
	 loss: 2.4582, MinusLogProbMetric: 2.4582, val_loss: 2.4731, val_MinusLogProbMetric: 2.4731

Epoch 30: val_loss did not improve from 2.41431
196/196 - 63s - loss: 2.4582 - MinusLogProbMetric: 2.4582 - val_loss: 2.4731 - val_MinusLogProbMetric: 2.4731 - lr: 0.0010 - 63s/epoch - 319ms/step
Epoch 31/1000
2023-09-15 20:12:47.721 
Epoch 31/1000 
	 loss: 2.4498, MinusLogProbMetric: 2.4498, val_loss: 2.4723, val_MinusLogProbMetric: 2.4723

Epoch 31: val_loss did not improve from 2.41431
196/196 - 57s - loss: 2.4498 - MinusLogProbMetric: 2.4498 - val_loss: 2.4723 - val_MinusLogProbMetric: 2.4723 - lr: 0.0010 - 57s/epoch - 288ms/step
Epoch 32/1000
2023-09-15 20:13:43.774 
Epoch 32/1000 
	 loss: 2.4625, MinusLogProbMetric: 2.4625, val_loss: 2.4443, val_MinusLogProbMetric: 2.4443

Epoch 32: val_loss did not improve from 2.41431
196/196 - 56s - loss: 2.4625 - MinusLogProbMetric: 2.4625 - val_loss: 2.4443 - val_MinusLogProbMetric: 2.4443 - lr: 0.0010 - 56s/epoch - 286ms/step
Epoch 33/1000
2023-09-15 20:14:45.211 
Epoch 33/1000 
	 loss: 2.4593, MinusLogProbMetric: 2.4593, val_loss: 2.5925, val_MinusLogProbMetric: 2.5925

Epoch 33: val_loss did not improve from 2.41431
196/196 - 61s - loss: 2.4593 - MinusLogProbMetric: 2.4593 - val_loss: 2.5925 - val_MinusLogProbMetric: 2.5925 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 34/1000
2023-09-15 20:15:45.971 
Epoch 34/1000 
	 loss: 2.4446, MinusLogProbMetric: 2.4446, val_loss: 2.3853, val_MinusLogProbMetric: 2.3853

Epoch 34: val_loss improved from 2.41431 to 2.38528, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5
196/196 - 62s - loss: 2.4446 - MinusLogProbMetric: 2.4446 - val_loss: 2.3853 - val_MinusLogProbMetric: 2.3853 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 35/1000
2023-09-15 20:16:47.798 
Epoch 35/1000 
	 loss: 2.4562, MinusLogProbMetric: 2.4562, val_loss: 2.4115, val_MinusLogProbMetric: 2.4115

Epoch 35: val_loss did not improve from 2.38528
196/196 - 61s - loss: 2.4562 - MinusLogProbMetric: 2.4562 - val_loss: 2.4115 - val_MinusLogProbMetric: 2.4115 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 36/1000
2023-09-15 20:17:48.059 
Epoch 36/1000 
	 loss: 2.4538, MinusLogProbMetric: 2.4538, val_loss: 2.5072, val_MinusLogProbMetric: 2.5072

Epoch 36: val_loss did not improve from 2.38528
196/196 - 60s - loss: 2.4538 - MinusLogProbMetric: 2.4538 - val_loss: 2.5072 - val_MinusLogProbMetric: 2.5072 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 37/1000
2023-09-15 20:18:48.570 
Epoch 37/1000 
	 loss: 2.4524, MinusLogProbMetric: 2.4524, val_loss: 2.4652, val_MinusLogProbMetric: 2.4652

Epoch 37: val_loss did not improve from 2.38528
196/196 - 61s - loss: 2.4524 - MinusLogProbMetric: 2.4524 - val_loss: 2.4652 - val_MinusLogProbMetric: 2.4652 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 38/1000
2023-09-15 20:19:49.105 
Epoch 38/1000 
	 loss: 2.4642, MinusLogProbMetric: 2.4642, val_loss: 2.5736, val_MinusLogProbMetric: 2.5736

Epoch 38: val_loss did not improve from 2.38528
196/196 - 61s - loss: 2.4642 - MinusLogProbMetric: 2.4642 - val_loss: 2.5736 - val_MinusLogProbMetric: 2.5736 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 39/1000
2023-09-15 20:20:49.995 
Epoch 39/1000 
	 loss: 2.4442, MinusLogProbMetric: 2.4442, val_loss: 2.3925, val_MinusLogProbMetric: 2.3925

Epoch 39: val_loss did not improve from 2.38528
196/196 - 61s - loss: 2.4442 - MinusLogProbMetric: 2.4442 - val_loss: 2.3925 - val_MinusLogProbMetric: 2.3925 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 40/1000
2023-09-15 20:21:50.379 
Epoch 40/1000 
	 loss: 2.4520, MinusLogProbMetric: 2.4520, val_loss: 2.4354, val_MinusLogProbMetric: 2.4354

Epoch 40: val_loss did not improve from 2.38528
196/196 - 60s - loss: 2.4520 - MinusLogProbMetric: 2.4520 - val_loss: 2.4354 - val_MinusLogProbMetric: 2.4354 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 41/1000
2023-09-15 20:22:51.168 
Epoch 41/1000 
	 loss: 2.4252, MinusLogProbMetric: 2.4252, val_loss: 2.4049, val_MinusLogProbMetric: 2.4049

Epoch 41: val_loss did not improve from 2.38528
196/196 - 61s - loss: 2.4252 - MinusLogProbMetric: 2.4252 - val_loss: 2.4049 - val_MinusLogProbMetric: 2.4049 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 42/1000
2023-09-15 20:23:52.721 
Epoch 42/1000 
	 loss: 2.4256, MinusLogProbMetric: 2.4256, val_loss: 2.5833, val_MinusLogProbMetric: 2.5833

Epoch 42: val_loss did not improve from 2.38528
196/196 - 62s - loss: 2.4256 - MinusLogProbMetric: 2.4256 - val_loss: 2.5833 - val_MinusLogProbMetric: 2.5833 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 43/1000
2023-09-15 20:24:53.532 
Epoch 43/1000 
	 loss: 2.4412, MinusLogProbMetric: 2.4412, val_loss: 2.4788, val_MinusLogProbMetric: 2.4788

Epoch 43: val_loss did not improve from 2.38528
196/196 - 61s - loss: 2.4412 - MinusLogProbMetric: 2.4412 - val_loss: 2.4788 - val_MinusLogProbMetric: 2.4788 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 44/1000
2023-09-15 20:25:53.943 
Epoch 44/1000 
	 loss: 2.4241, MinusLogProbMetric: 2.4241, val_loss: 2.4600, val_MinusLogProbMetric: 2.4600

Epoch 44: val_loss did not improve from 2.38528
196/196 - 60s - loss: 2.4241 - MinusLogProbMetric: 2.4241 - val_loss: 2.4600 - val_MinusLogProbMetric: 2.4600 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 45/1000
2023-09-15 20:26:54.319 
Epoch 45/1000 
	 loss: 2.4300, MinusLogProbMetric: 2.4300, val_loss: 2.4480, val_MinusLogProbMetric: 2.4480

Epoch 45: val_loss did not improve from 2.38528
196/196 - 60s - loss: 2.4300 - MinusLogProbMetric: 2.4300 - val_loss: 2.4480 - val_MinusLogProbMetric: 2.4480 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 46/1000
2023-09-15 20:27:54.737 
Epoch 46/1000 
	 loss: 2.4457, MinusLogProbMetric: 2.4457, val_loss: 2.4581, val_MinusLogProbMetric: 2.4581

Epoch 46: val_loss did not improve from 2.38528
196/196 - 60s - loss: 2.4457 - MinusLogProbMetric: 2.4457 - val_loss: 2.4581 - val_MinusLogProbMetric: 2.4581 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 47/1000
2023-09-15 20:28:55.161 
Epoch 47/1000 
	 loss: 2.4257, MinusLogProbMetric: 2.4257, val_loss: 2.4157, val_MinusLogProbMetric: 2.4157

Epoch 47: val_loss did not improve from 2.38528
196/196 - 60s - loss: 2.4257 - MinusLogProbMetric: 2.4257 - val_loss: 2.4157 - val_MinusLogProbMetric: 2.4157 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 48/1000
2023-09-15 20:29:56.105 
Epoch 48/1000 
	 loss: 2.4286, MinusLogProbMetric: 2.4286, val_loss: 2.4035, val_MinusLogProbMetric: 2.4035

Epoch 48: val_loss did not improve from 2.38528
196/196 - 61s - loss: 2.4286 - MinusLogProbMetric: 2.4286 - val_loss: 2.4035 - val_MinusLogProbMetric: 2.4035 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 49/1000
2023-09-15 20:30:56.225 
Epoch 49/1000 
	 loss: 2.4304, MinusLogProbMetric: 2.4304, val_loss: 2.3897, val_MinusLogProbMetric: 2.3897

Epoch 49: val_loss did not improve from 2.38528
196/196 - 60s - loss: 2.4304 - MinusLogProbMetric: 2.4304 - val_loss: 2.3897 - val_MinusLogProbMetric: 2.3897 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 50/1000
2023-09-15 20:31:56.513 
Epoch 50/1000 
	 loss: 2.4268, MinusLogProbMetric: 2.4268, val_loss: 2.4451, val_MinusLogProbMetric: 2.4451

Epoch 50: val_loss did not improve from 2.38528
196/196 - 60s - loss: 2.4268 - MinusLogProbMetric: 2.4268 - val_loss: 2.4451 - val_MinusLogProbMetric: 2.4451 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 51/1000
2023-09-15 20:32:57.145 
Epoch 51/1000 
	 loss: 2.4186, MinusLogProbMetric: 2.4186, val_loss: 2.3828, val_MinusLogProbMetric: 2.3828

Epoch 51: val_loss improved from 2.38528 to 2.38284, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5
196/196 - 62s - loss: 2.4186 - MinusLogProbMetric: 2.4186 - val_loss: 2.3828 - val_MinusLogProbMetric: 2.3828 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 52/1000
2023-09-15 20:33:58.259 
Epoch 52/1000 
	 loss: 2.4178, MinusLogProbMetric: 2.4178, val_loss: 2.4308, val_MinusLogProbMetric: 2.4308

Epoch 52: val_loss did not improve from 2.38284
196/196 - 60s - loss: 2.4178 - MinusLogProbMetric: 2.4178 - val_loss: 2.4308 - val_MinusLogProbMetric: 2.4308 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 53/1000
2023-09-15 20:34:58.743 
Epoch 53/1000 
	 loss: 2.4128, MinusLogProbMetric: 2.4128, val_loss: 2.3986, val_MinusLogProbMetric: 2.3986

Epoch 53: val_loss did not improve from 2.38284
196/196 - 60s - loss: 2.4128 - MinusLogProbMetric: 2.4128 - val_loss: 2.3986 - val_MinusLogProbMetric: 2.3986 - lr: 0.0010 - 60s/epoch - 309ms/step
Epoch 54/1000
2023-09-15 20:35:59.039 
Epoch 54/1000 
	 loss: 2.4460, MinusLogProbMetric: 2.4460, val_loss: 2.4617, val_MinusLogProbMetric: 2.4617

Epoch 54: val_loss did not improve from 2.38284
196/196 - 60s - loss: 2.4460 - MinusLogProbMetric: 2.4460 - val_loss: 2.4617 - val_MinusLogProbMetric: 2.4617 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 55/1000
2023-09-15 20:36:59.854 
Epoch 55/1000 
	 loss: 2.4216, MinusLogProbMetric: 2.4216, val_loss: 2.4057, val_MinusLogProbMetric: 2.4057

Epoch 55: val_loss did not improve from 2.38284
196/196 - 61s - loss: 2.4216 - MinusLogProbMetric: 2.4216 - val_loss: 2.4057 - val_MinusLogProbMetric: 2.4057 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 56/1000
2023-09-15 20:38:00.964 
Epoch 56/1000 
	 loss: 2.4162, MinusLogProbMetric: 2.4162, val_loss: 2.5475, val_MinusLogProbMetric: 2.5475

Epoch 56: val_loss did not improve from 2.38284
196/196 - 61s - loss: 2.4162 - MinusLogProbMetric: 2.4162 - val_loss: 2.5475 - val_MinusLogProbMetric: 2.5475 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 57/1000
2023-09-15 20:38:56.470 
Epoch 57/1000 
	 loss: 2.4195, MinusLogProbMetric: 2.4195, val_loss: 2.3933, val_MinusLogProbMetric: 2.3933

Epoch 57: val_loss did not improve from 2.38284
196/196 - 56s - loss: 2.4195 - MinusLogProbMetric: 2.4195 - val_loss: 2.3933 - val_MinusLogProbMetric: 2.3933 - lr: 0.0010 - 56s/epoch - 283ms/step
Epoch 58/1000
2023-09-15 20:39:46.752 
Epoch 58/1000 
	 loss: 2.4252, MinusLogProbMetric: 2.4252, val_loss: 2.3955, val_MinusLogProbMetric: 2.3955

Epoch 58: val_loss did not improve from 2.38284
196/196 - 50s - loss: 2.4252 - MinusLogProbMetric: 2.4252 - val_loss: 2.3955 - val_MinusLogProbMetric: 2.3955 - lr: 0.0010 - 50s/epoch - 257ms/step
Epoch 59/1000
2023-09-15 20:40:37.403 
Epoch 59/1000 
	 loss: 2.4114, MinusLogProbMetric: 2.4114, val_loss: 2.4794, val_MinusLogProbMetric: 2.4794

Epoch 59: val_loss did not improve from 2.38284
196/196 - 51s - loss: 2.4114 - MinusLogProbMetric: 2.4114 - val_loss: 2.4794 - val_MinusLogProbMetric: 2.4794 - lr: 0.0010 - 51s/epoch - 258ms/step
Epoch 60/1000
2023-09-15 20:41:32.983 
Epoch 60/1000 
	 loss: 2.4338, MinusLogProbMetric: 2.4338, val_loss: 2.4999, val_MinusLogProbMetric: 2.4999

Epoch 60: val_loss did not improve from 2.38284
196/196 - 56s - loss: 2.4338 - MinusLogProbMetric: 2.4338 - val_loss: 2.4999 - val_MinusLogProbMetric: 2.4999 - lr: 0.0010 - 56s/epoch - 284ms/step
Epoch 61/1000
2023-09-15 20:42:33.590 
Epoch 61/1000 
	 loss: 2.4163, MinusLogProbMetric: 2.4163, val_loss: 2.3891, val_MinusLogProbMetric: 2.3891

Epoch 61: val_loss did not improve from 2.38284
196/196 - 61s - loss: 2.4163 - MinusLogProbMetric: 2.4163 - val_loss: 2.3891 - val_MinusLogProbMetric: 2.3891 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 62/1000
2023-09-15 20:43:34.066 
Epoch 62/1000 
	 loss: 2.4047, MinusLogProbMetric: 2.4047, val_loss: 2.3830, val_MinusLogProbMetric: 2.3830

Epoch 62: val_loss did not improve from 2.38284
196/196 - 60s - loss: 2.4047 - MinusLogProbMetric: 2.4047 - val_loss: 2.3830 - val_MinusLogProbMetric: 2.3830 - lr: 0.0010 - 60s/epoch - 309ms/step
Epoch 63/1000
2023-09-15 20:44:34.425 
Epoch 63/1000 
	 loss: 2.4282, MinusLogProbMetric: 2.4282, val_loss: 2.4218, val_MinusLogProbMetric: 2.4218

Epoch 63: val_loss did not improve from 2.38284
196/196 - 60s - loss: 2.4282 - MinusLogProbMetric: 2.4282 - val_loss: 2.4218 - val_MinusLogProbMetric: 2.4218 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 64/1000
2023-09-15 20:45:34.845 
Epoch 64/1000 
	 loss: 2.4119, MinusLogProbMetric: 2.4119, val_loss: 2.4638, val_MinusLogProbMetric: 2.4638

Epoch 64: val_loss did not improve from 2.38284
196/196 - 60s - loss: 2.4119 - MinusLogProbMetric: 2.4119 - val_loss: 2.4638 - val_MinusLogProbMetric: 2.4638 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 65/1000
2023-09-15 20:46:35.016 
Epoch 65/1000 
	 loss: 2.4157, MinusLogProbMetric: 2.4157, val_loss: 2.4213, val_MinusLogProbMetric: 2.4213

Epoch 65: val_loss did not improve from 2.38284
196/196 - 60s - loss: 2.4157 - MinusLogProbMetric: 2.4157 - val_loss: 2.4213 - val_MinusLogProbMetric: 2.4213 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 66/1000
2023-09-15 20:47:35.612 
Epoch 66/1000 
	 loss: 2.4173, MinusLogProbMetric: 2.4173, val_loss: 2.3832, val_MinusLogProbMetric: 2.3832

Epoch 66: val_loss did not improve from 2.38284
196/196 - 61s - loss: 2.4173 - MinusLogProbMetric: 2.4173 - val_loss: 2.3832 - val_MinusLogProbMetric: 2.3832 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 67/1000
2023-09-15 20:48:36.719 
Epoch 67/1000 
	 loss: 2.4214, MinusLogProbMetric: 2.4214, val_loss: 2.4178, val_MinusLogProbMetric: 2.4178

Epoch 67: val_loss did not improve from 2.38284
196/196 - 61s - loss: 2.4214 - MinusLogProbMetric: 2.4214 - val_loss: 2.4178 - val_MinusLogProbMetric: 2.4178 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 68/1000
2023-09-15 20:49:37.469 
Epoch 68/1000 
	 loss: 2.4208, MinusLogProbMetric: 2.4208, val_loss: 2.3905, val_MinusLogProbMetric: 2.3905

Epoch 68: val_loss did not improve from 2.38284
196/196 - 61s - loss: 2.4208 - MinusLogProbMetric: 2.4208 - val_loss: 2.3905 - val_MinusLogProbMetric: 2.3905 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 69/1000
2023-09-15 20:50:38.053 
Epoch 69/1000 
	 loss: 2.4063, MinusLogProbMetric: 2.4063, val_loss: 2.3987, val_MinusLogProbMetric: 2.3987

Epoch 69: val_loss did not improve from 2.38284
196/196 - 61s - loss: 2.4063 - MinusLogProbMetric: 2.4063 - val_loss: 2.3987 - val_MinusLogProbMetric: 2.3987 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 70/1000
2023-09-15 20:51:37.705 
Epoch 70/1000 
	 loss: 2.4079, MinusLogProbMetric: 2.4079, val_loss: 2.4551, val_MinusLogProbMetric: 2.4551

Epoch 70: val_loss did not improve from 2.38284
196/196 - 60s - loss: 2.4079 - MinusLogProbMetric: 2.4079 - val_loss: 2.4551 - val_MinusLogProbMetric: 2.4551 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 71/1000
2023-09-15 20:52:37.560 
Epoch 71/1000 
	 loss: 2.4035, MinusLogProbMetric: 2.4035, val_loss: 2.4030, val_MinusLogProbMetric: 2.4030

Epoch 71: val_loss did not improve from 2.38284
196/196 - 60s - loss: 2.4035 - MinusLogProbMetric: 2.4035 - val_loss: 2.4030 - val_MinusLogProbMetric: 2.4030 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 72/1000
2023-09-15 20:53:37.598 
Epoch 72/1000 
	 loss: 2.4068, MinusLogProbMetric: 2.4068, val_loss: 2.4383, val_MinusLogProbMetric: 2.4383

Epoch 72: val_loss did not improve from 2.38284
196/196 - 60s - loss: 2.4068 - MinusLogProbMetric: 2.4068 - val_loss: 2.4383 - val_MinusLogProbMetric: 2.4383 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 73/1000
2023-09-15 20:54:37.634 
Epoch 73/1000 
	 loss: 2.4095, MinusLogProbMetric: 2.4095, val_loss: 2.4127, val_MinusLogProbMetric: 2.4127

Epoch 73: val_loss did not improve from 2.38284
196/196 - 60s - loss: 2.4095 - MinusLogProbMetric: 2.4095 - val_loss: 2.4127 - val_MinusLogProbMetric: 2.4127 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 74/1000
2023-09-15 20:55:37.437 
Epoch 74/1000 
	 loss: 2.3988, MinusLogProbMetric: 2.3988, val_loss: 2.4285, val_MinusLogProbMetric: 2.4285

Epoch 74: val_loss did not improve from 2.38284
196/196 - 60s - loss: 2.3988 - MinusLogProbMetric: 2.3988 - val_loss: 2.4285 - val_MinusLogProbMetric: 2.4285 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 75/1000
2023-09-15 20:56:37.352 
Epoch 75/1000 
	 loss: 2.4046, MinusLogProbMetric: 2.4046, val_loss: 2.3983, val_MinusLogProbMetric: 2.3983

Epoch 75: val_loss did not improve from 2.38284
196/196 - 60s - loss: 2.4046 - MinusLogProbMetric: 2.4046 - val_loss: 2.3983 - val_MinusLogProbMetric: 2.3983 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 76/1000
2023-09-15 20:57:37.249 
Epoch 76/1000 
	 loss: 2.3907, MinusLogProbMetric: 2.3907, val_loss: 2.3894, val_MinusLogProbMetric: 2.3894

Epoch 76: val_loss did not improve from 2.38284
196/196 - 60s - loss: 2.3907 - MinusLogProbMetric: 2.3907 - val_loss: 2.3894 - val_MinusLogProbMetric: 2.3894 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 77/1000
2023-09-15 20:58:36.465 
Epoch 77/1000 
	 loss: 2.4236, MinusLogProbMetric: 2.4236, val_loss: 2.4419, val_MinusLogProbMetric: 2.4419

Epoch 77: val_loss did not improve from 2.38284
196/196 - 59s - loss: 2.4236 - MinusLogProbMetric: 2.4236 - val_loss: 2.4419 - val_MinusLogProbMetric: 2.4419 - lr: 0.0010 - 59s/epoch - 302ms/step
Epoch 78/1000
2023-09-15 20:59:35.995 
Epoch 78/1000 
	 loss: 2.4012, MinusLogProbMetric: 2.4012, val_loss: 2.4152, val_MinusLogProbMetric: 2.4152

Epoch 78: val_loss did not improve from 2.38284
196/196 - 60s - loss: 2.4012 - MinusLogProbMetric: 2.4012 - val_loss: 2.4152 - val_MinusLogProbMetric: 2.4152 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 79/1000
2023-09-15 21:00:35.644 
Epoch 79/1000 
	 loss: 2.4017, MinusLogProbMetric: 2.4017, val_loss: 2.3793, val_MinusLogProbMetric: 2.3793

Epoch 79: val_loss improved from 2.38284 to 2.37926, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5
196/196 - 61s - loss: 2.4017 - MinusLogProbMetric: 2.4017 - val_loss: 2.3793 - val_MinusLogProbMetric: 2.3793 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 80/1000
2023-09-15 21:01:36.496 
Epoch 80/1000 
	 loss: 2.4211, MinusLogProbMetric: 2.4211, val_loss: 2.5166, val_MinusLogProbMetric: 2.5166

Epoch 80: val_loss did not improve from 2.37926
196/196 - 60s - loss: 2.4211 - MinusLogProbMetric: 2.4211 - val_loss: 2.5166 - val_MinusLogProbMetric: 2.5166 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 81/1000
2023-09-15 21:02:36.616 
Epoch 81/1000 
	 loss: 2.4206, MinusLogProbMetric: 2.4206, val_loss: 2.3815, val_MinusLogProbMetric: 2.3815

Epoch 81: val_loss did not improve from 2.37926
196/196 - 60s - loss: 2.4206 - MinusLogProbMetric: 2.4206 - val_loss: 2.3815 - val_MinusLogProbMetric: 2.3815 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 82/1000
2023-09-15 21:03:36.645 
Epoch 82/1000 
	 loss: 2.4170, MinusLogProbMetric: 2.4170, val_loss: 2.4160, val_MinusLogProbMetric: 2.4160

Epoch 82: val_loss did not improve from 2.37926
196/196 - 60s - loss: 2.4170 - MinusLogProbMetric: 2.4170 - val_loss: 2.4160 - val_MinusLogProbMetric: 2.4160 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 83/1000
2023-09-15 21:04:36.525 
Epoch 83/1000 
	 loss: 2.4041, MinusLogProbMetric: 2.4041, val_loss: 2.3817, val_MinusLogProbMetric: 2.3817

Epoch 83: val_loss did not improve from 2.37926
196/196 - 60s - loss: 2.4041 - MinusLogProbMetric: 2.4041 - val_loss: 2.3817 - val_MinusLogProbMetric: 2.3817 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 84/1000
2023-09-15 21:05:36.909 
Epoch 84/1000 
	 loss: 2.4057, MinusLogProbMetric: 2.4057, val_loss: 2.3995, val_MinusLogProbMetric: 2.3995

Epoch 84: val_loss did not improve from 2.37926
196/196 - 60s - loss: 2.4057 - MinusLogProbMetric: 2.4057 - val_loss: 2.3995 - val_MinusLogProbMetric: 2.3995 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 85/1000
2023-09-15 21:06:36.874 
Epoch 85/1000 
	 loss: 2.3956, MinusLogProbMetric: 2.3956, val_loss: 2.3746, val_MinusLogProbMetric: 2.3746

Epoch 85: val_loss improved from 2.37926 to 2.37458, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5
196/196 - 61s - loss: 2.3956 - MinusLogProbMetric: 2.3956 - val_loss: 2.3746 - val_MinusLogProbMetric: 2.3746 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 86/1000
2023-09-15 21:07:37.757 
Epoch 86/1000 
	 loss: 2.3966, MinusLogProbMetric: 2.3966, val_loss: 2.4229, val_MinusLogProbMetric: 2.4229

Epoch 86: val_loss did not improve from 2.37458
196/196 - 60s - loss: 2.3966 - MinusLogProbMetric: 2.3966 - val_loss: 2.4229 - val_MinusLogProbMetric: 2.4229 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 87/1000
2023-09-15 21:08:37.897 
Epoch 87/1000 
	 loss: 2.3931, MinusLogProbMetric: 2.3931, val_loss: 2.3854, val_MinusLogProbMetric: 2.3854

Epoch 87: val_loss did not improve from 2.37458
196/196 - 60s - loss: 2.3931 - MinusLogProbMetric: 2.3931 - val_loss: 2.3854 - val_MinusLogProbMetric: 2.3854 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 88/1000
2023-09-15 21:09:37.403 
Epoch 88/1000 
	 loss: 2.4126, MinusLogProbMetric: 2.4126, val_loss: 2.3789, val_MinusLogProbMetric: 2.3789

Epoch 88: val_loss did not improve from 2.37458
196/196 - 60s - loss: 2.4126 - MinusLogProbMetric: 2.4126 - val_loss: 2.3789 - val_MinusLogProbMetric: 2.3789 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 89/1000
2023-09-15 21:10:36.935 
Epoch 89/1000 
	 loss: 2.3948, MinusLogProbMetric: 2.3948, val_loss: 2.3946, val_MinusLogProbMetric: 2.3946

Epoch 89: val_loss did not improve from 2.37458
196/196 - 60s - loss: 2.3948 - MinusLogProbMetric: 2.3948 - val_loss: 2.3946 - val_MinusLogProbMetric: 2.3946 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 90/1000
2023-09-15 21:11:36.556 
Epoch 90/1000 
	 loss: 2.4076, MinusLogProbMetric: 2.4076, val_loss: 2.3803, val_MinusLogProbMetric: 2.3803

Epoch 90: val_loss did not improve from 2.37458
196/196 - 60s - loss: 2.4076 - MinusLogProbMetric: 2.4076 - val_loss: 2.3803 - val_MinusLogProbMetric: 2.3803 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 91/1000
2023-09-15 21:12:36.163 
Epoch 91/1000 
	 loss: 2.4072, MinusLogProbMetric: 2.4072, val_loss: 2.4064, val_MinusLogProbMetric: 2.4064

Epoch 91: val_loss did not improve from 2.37458
196/196 - 60s - loss: 2.4072 - MinusLogProbMetric: 2.4072 - val_loss: 2.4064 - val_MinusLogProbMetric: 2.4064 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 92/1000
2023-09-15 21:13:35.670 
Epoch 92/1000 
	 loss: 2.4091, MinusLogProbMetric: 2.4091, val_loss: 2.4023, val_MinusLogProbMetric: 2.4023

Epoch 92: val_loss did not improve from 2.37458
196/196 - 60s - loss: 2.4091 - MinusLogProbMetric: 2.4091 - val_loss: 2.4023 - val_MinusLogProbMetric: 2.4023 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 93/1000
2023-09-15 21:14:35.175 
Epoch 93/1000 
	 loss: 2.3977, MinusLogProbMetric: 2.3977, val_loss: 2.3780, val_MinusLogProbMetric: 2.3780

Epoch 93: val_loss did not improve from 2.37458
196/196 - 60s - loss: 2.3977 - MinusLogProbMetric: 2.3977 - val_loss: 2.3780 - val_MinusLogProbMetric: 2.3780 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 94/1000
2023-09-15 21:15:34.446 
Epoch 94/1000 
	 loss: 2.4004, MinusLogProbMetric: 2.4004, val_loss: 2.3888, val_MinusLogProbMetric: 2.3888

Epoch 94: val_loss did not improve from 2.37458
196/196 - 59s - loss: 2.4004 - MinusLogProbMetric: 2.4004 - val_loss: 2.3888 - val_MinusLogProbMetric: 2.3888 - lr: 0.0010 - 59s/epoch - 302ms/step
Epoch 95/1000
2023-09-15 21:16:34.090 
Epoch 95/1000 
	 loss: 2.3962, MinusLogProbMetric: 2.3962, val_loss: 2.3799, val_MinusLogProbMetric: 2.3799

Epoch 95: val_loss did not improve from 2.37458
196/196 - 60s - loss: 2.3962 - MinusLogProbMetric: 2.3962 - val_loss: 2.3799 - val_MinusLogProbMetric: 2.3799 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 96/1000
2023-09-15 21:17:34.005 
Epoch 96/1000 
	 loss: 2.3955, MinusLogProbMetric: 2.3955, val_loss: 2.4451, val_MinusLogProbMetric: 2.4451

Epoch 96: val_loss did not improve from 2.37458
196/196 - 60s - loss: 2.3955 - MinusLogProbMetric: 2.3955 - val_loss: 2.4451 - val_MinusLogProbMetric: 2.4451 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 97/1000
2023-09-15 21:18:34.561 
Epoch 97/1000 
	 loss: 2.4001, MinusLogProbMetric: 2.4001, val_loss: 2.3902, val_MinusLogProbMetric: 2.3902

Epoch 97: val_loss did not improve from 2.37458
196/196 - 61s - loss: 2.4001 - MinusLogProbMetric: 2.4001 - val_loss: 2.3902 - val_MinusLogProbMetric: 2.3902 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 98/1000
2023-09-15 21:19:35.270 
Epoch 98/1000 
	 loss: 2.3942, MinusLogProbMetric: 2.3942, val_loss: 2.5473, val_MinusLogProbMetric: 2.5473

Epoch 98: val_loss did not improve from 2.37458
196/196 - 61s - loss: 2.3942 - MinusLogProbMetric: 2.3942 - val_loss: 2.5473 - val_MinusLogProbMetric: 2.5473 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 99/1000
2023-09-15 21:20:35.179 
Epoch 99/1000 
	 loss: 2.4162, MinusLogProbMetric: 2.4162, val_loss: 2.3885, val_MinusLogProbMetric: 2.3885

Epoch 99: val_loss did not improve from 2.37458
196/196 - 60s - loss: 2.4162 - MinusLogProbMetric: 2.4162 - val_loss: 2.3885 - val_MinusLogProbMetric: 2.3885 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 100/1000
2023-09-15 21:21:35.506 
Epoch 100/1000 
	 loss: 2.3922, MinusLogProbMetric: 2.3922, val_loss: 2.4017, val_MinusLogProbMetric: 2.4017

Epoch 100: val_loss did not improve from 2.37458
196/196 - 60s - loss: 2.3922 - MinusLogProbMetric: 2.3922 - val_loss: 2.4017 - val_MinusLogProbMetric: 2.4017 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 101/1000
2023-09-15 21:22:33.617 
Epoch 101/1000 
	 loss: 2.3951, MinusLogProbMetric: 2.3951, val_loss: 2.3778, val_MinusLogProbMetric: 2.3778

Epoch 101: val_loss did not improve from 2.37458
196/196 - 58s - loss: 2.3951 - MinusLogProbMetric: 2.3951 - val_loss: 2.3778 - val_MinusLogProbMetric: 2.3778 - lr: 0.0010 - 58s/epoch - 296ms/step
Epoch 102/1000
2023-09-15 21:23:28.174 
Epoch 102/1000 
	 loss: 2.3986, MinusLogProbMetric: 2.3986, val_loss: 2.3849, val_MinusLogProbMetric: 2.3849

Epoch 102: val_loss did not improve from 2.37458
196/196 - 55s - loss: 2.3986 - MinusLogProbMetric: 2.3986 - val_loss: 2.3849 - val_MinusLogProbMetric: 2.3849 - lr: 0.0010 - 55s/epoch - 278ms/step
Epoch 103/1000
2023-09-15 21:24:25.165 
Epoch 103/1000 
	 loss: 2.3987, MinusLogProbMetric: 2.3987, val_loss: 2.3858, val_MinusLogProbMetric: 2.3858

Epoch 103: val_loss did not improve from 2.37458
196/196 - 57s - loss: 2.3987 - MinusLogProbMetric: 2.3987 - val_loss: 2.3858 - val_MinusLogProbMetric: 2.3858 - lr: 0.0010 - 57s/epoch - 291ms/step
Epoch 104/1000
2023-09-15 21:25:16.402 
Epoch 104/1000 
	 loss: 2.3872, MinusLogProbMetric: 2.3872, val_loss: 2.3933, val_MinusLogProbMetric: 2.3933

Epoch 104: val_loss did not improve from 2.37458
196/196 - 51s - loss: 2.3872 - MinusLogProbMetric: 2.3872 - val_loss: 2.3933 - val_MinusLogProbMetric: 2.3933 - lr: 0.0010 - 51s/epoch - 261ms/step
Epoch 105/1000
2023-09-15 21:26:07.489 
Epoch 105/1000 
	 loss: 2.3860, MinusLogProbMetric: 2.3860, val_loss: 2.3777, val_MinusLogProbMetric: 2.3777

Epoch 105: val_loss did not improve from 2.37458
196/196 - 51s - loss: 2.3860 - MinusLogProbMetric: 2.3860 - val_loss: 2.3777 - val_MinusLogProbMetric: 2.3777 - lr: 0.0010 - 51s/epoch - 261ms/step
Epoch 106/1000
2023-09-15 21:27:03.656 
Epoch 106/1000 
	 loss: 2.4013, MinusLogProbMetric: 2.4013, val_loss: 2.4575, val_MinusLogProbMetric: 2.4575

Epoch 106: val_loss did not improve from 2.37458
196/196 - 56s - loss: 2.4013 - MinusLogProbMetric: 2.4013 - val_loss: 2.4575 - val_MinusLogProbMetric: 2.4575 - lr: 0.0010 - 56s/epoch - 287ms/step
Epoch 107/1000
2023-09-15 21:28:03.545 
Epoch 107/1000 
	 loss: 2.3955, MinusLogProbMetric: 2.3955, val_loss: 2.3804, val_MinusLogProbMetric: 2.3804

Epoch 107: val_loss did not improve from 2.37458
196/196 - 60s - loss: 2.3955 - MinusLogProbMetric: 2.3955 - val_loss: 2.3804 - val_MinusLogProbMetric: 2.3804 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 108/1000
2023-09-15 21:29:02.708 
Epoch 108/1000 
	 loss: 2.3854, MinusLogProbMetric: 2.3854, val_loss: 2.3819, val_MinusLogProbMetric: 2.3819

Epoch 108: val_loss did not improve from 2.37458
196/196 - 59s - loss: 2.3854 - MinusLogProbMetric: 2.3854 - val_loss: 2.3819 - val_MinusLogProbMetric: 2.3819 - lr: 0.0010 - 59s/epoch - 302ms/step
Epoch 109/1000
2023-09-15 21:30:02.654 
Epoch 109/1000 
	 loss: 2.3954, MinusLogProbMetric: 2.3954, val_loss: 2.3823, val_MinusLogProbMetric: 2.3823

Epoch 109: val_loss did not improve from 2.37458
196/196 - 60s - loss: 2.3954 - MinusLogProbMetric: 2.3954 - val_loss: 2.3823 - val_MinusLogProbMetric: 2.3823 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 110/1000
2023-09-15 21:31:02.843 
Epoch 110/1000 
	 loss: 2.3815, MinusLogProbMetric: 2.3815, val_loss: 2.3734, val_MinusLogProbMetric: 2.3734

Epoch 110: val_loss improved from 2.37458 to 2.37340, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5
196/196 - 61s - loss: 2.3815 - MinusLogProbMetric: 2.3815 - val_loss: 2.3734 - val_MinusLogProbMetric: 2.3734 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 111/1000
2023-09-15 21:32:04.025 
Epoch 111/1000 
	 loss: 2.3960, MinusLogProbMetric: 2.3960, val_loss: 2.3944, val_MinusLogProbMetric: 2.3944

Epoch 111: val_loss did not improve from 2.37340
196/196 - 60s - loss: 2.3960 - MinusLogProbMetric: 2.3960 - val_loss: 2.3944 - val_MinusLogProbMetric: 2.3944 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 112/1000
2023-09-15 21:33:04.625 
Epoch 112/1000 
	 loss: 2.3847, MinusLogProbMetric: 2.3847, val_loss: 2.4512, val_MinusLogProbMetric: 2.4512

Epoch 112: val_loss did not improve from 2.37340
196/196 - 61s - loss: 2.3847 - MinusLogProbMetric: 2.3847 - val_loss: 2.4512 - val_MinusLogProbMetric: 2.4512 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 113/1000
2023-09-15 21:34:04.694 
Epoch 113/1000 
	 loss: 2.4046, MinusLogProbMetric: 2.4046, val_loss: 2.3839, val_MinusLogProbMetric: 2.3839

Epoch 113: val_loss did not improve from 2.37340
196/196 - 60s - loss: 2.4046 - MinusLogProbMetric: 2.4046 - val_loss: 2.3839 - val_MinusLogProbMetric: 2.3839 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 114/1000
2023-09-15 21:35:05.249 
Epoch 114/1000 
	 loss: 2.3831, MinusLogProbMetric: 2.3831, val_loss: 2.3846, val_MinusLogProbMetric: 2.3846

Epoch 114: val_loss did not improve from 2.37340
196/196 - 61s - loss: 2.3831 - MinusLogProbMetric: 2.3831 - val_loss: 2.3846 - val_MinusLogProbMetric: 2.3846 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 115/1000
2023-09-15 21:36:06.059 
Epoch 115/1000 
	 loss: 2.3915, MinusLogProbMetric: 2.3915, val_loss: 2.3769, val_MinusLogProbMetric: 2.3769

Epoch 115: val_loss did not improve from 2.37340
196/196 - 61s - loss: 2.3915 - MinusLogProbMetric: 2.3915 - val_loss: 2.3769 - val_MinusLogProbMetric: 2.3769 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 116/1000
2023-09-15 21:37:05.872 
Epoch 116/1000 
	 loss: 2.4010, MinusLogProbMetric: 2.4010, val_loss: 2.3903, val_MinusLogProbMetric: 2.3903

Epoch 116: val_loss did not improve from 2.37340
196/196 - 60s - loss: 2.4010 - MinusLogProbMetric: 2.4010 - val_loss: 2.3903 - val_MinusLogProbMetric: 2.3903 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 117/1000
2023-09-15 21:38:05.172 
Epoch 117/1000 
	 loss: 2.3915, MinusLogProbMetric: 2.3915, val_loss: 2.4061, val_MinusLogProbMetric: 2.4061

Epoch 117: val_loss did not improve from 2.37340
196/196 - 59s - loss: 2.3915 - MinusLogProbMetric: 2.3915 - val_loss: 2.4061 - val_MinusLogProbMetric: 2.4061 - lr: 0.0010 - 59s/epoch - 303ms/step
Epoch 118/1000
2023-09-15 21:39:05.670 
Epoch 118/1000 
	 loss: 2.3886, MinusLogProbMetric: 2.3886, val_loss: 2.3735, val_MinusLogProbMetric: 2.3735

Epoch 118: val_loss did not improve from 2.37340
196/196 - 60s - loss: 2.3886 - MinusLogProbMetric: 2.3886 - val_loss: 2.3735 - val_MinusLogProbMetric: 2.3735 - lr: 0.0010 - 60s/epoch - 309ms/step
Epoch 119/1000
2023-09-15 21:40:06.251 
Epoch 119/1000 
	 loss: 2.3908, MinusLogProbMetric: 2.3908, val_loss: 2.3808, val_MinusLogProbMetric: 2.3808

Epoch 119: val_loss did not improve from 2.37340
196/196 - 61s - loss: 2.3908 - MinusLogProbMetric: 2.3908 - val_loss: 2.3808 - val_MinusLogProbMetric: 2.3808 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 120/1000
2023-09-15 21:41:06.229 
Epoch 120/1000 
	 loss: 2.3889, MinusLogProbMetric: 2.3889, val_loss: 2.4149, val_MinusLogProbMetric: 2.4149

Epoch 120: val_loss did not improve from 2.37340
196/196 - 60s - loss: 2.3889 - MinusLogProbMetric: 2.3889 - val_loss: 2.4149 - val_MinusLogProbMetric: 2.4149 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 121/1000
2023-09-15 21:42:06.347 
Epoch 121/1000 
	 loss: 2.3887, MinusLogProbMetric: 2.3887, val_loss: 2.3881, val_MinusLogProbMetric: 2.3881

Epoch 121: val_loss did not improve from 2.37340
196/196 - 60s - loss: 2.3887 - MinusLogProbMetric: 2.3887 - val_loss: 2.3881 - val_MinusLogProbMetric: 2.3881 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 122/1000
2023-09-15 21:43:07.791 
Epoch 122/1000 
	 loss: 2.3873, MinusLogProbMetric: 2.3873, val_loss: 2.4136, val_MinusLogProbMetric: 2.4136

Epoch 122: val_loss did not improve from 2.37340
196/196 - 61s - loss: 2.3873 - MinusLogProbMetric: 2.3873 - val_loss: 2.4136 - val_MinusLogProbMetric: 2.4136 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 123/1000
2023-09-15 21:44:12.905 
Epoch 123/1000 
	 loss: 2.3926, MinusLogProbMetric: 2.3926, val_loss: 2.4262, val_MinusLogProbMetric: 2.4262

Epoch 123: val_loss did not improve from 2.37340
196/196 - 65s - loss: 2.3926 - MinusLogProbMetric: 2.3926 - val_loss: 2.4262 - val_MinusLogProbMetric: 2.4262 - lr: 0.0010 - 65s/epoch - 332ms/step
Epoch 124/1000
2023-09-15 21:45:13.265 
Epoch 124/1000 
	 loss: 2.3931, MinusLogProbMetric: 2.3931, val_loss: 2.4003, val_MinusLogProbMetric: 2.4003

Epoch 124: val_loss did not improve from 2.37340
196/196 - 60s - loss: 2.3931 - MinusLogProbMetric: 2.3931 - val_loss: 2.4003 - val_MinusLogProbMetric: 2.4003 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 125/1000
2023-09-15 21:46:08.416 
Epoch 125/1000 
	 loss: 2.3876, MinusLogProbMetric: 2.3876, val_loss: 2.5256, val_MinusLogProbMetric: 2.5256

Epoch 125: val_loss did not improve from 2.37340
196/196 - 55s - loss: 2.3876 - MinusLogProbMetric: 2.3876 - val_loss: 2.5256 - val_MinusLogProbMetric: 2.5256 - lr: 0.0010 - 55s/epoch - 281ms/step
Epoch 126/1000
2023-09-15 21:47:16.156 
Epoch 126/1000 
	 loss: 2.3889, MinusLogProbMetric: 2.3889, val_loss: 2.4550, val_MinusLogProbMetric: 2.4550

Epoch 126: val_loss did not improve from 2.37340
196/196 - 68s - loss: 2.3889 - MinusLogProbMetric: 2.3889 - val_loss: 2.4550 - val_MinusLogProbMetric: 2.4550 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 127/1000
2023-09-15 21:48:23.100 
Epoch 127/1000 
	 loss: 2.3896, MinusLogProbMetric: 2.3896, val_loss: 2.4141, val_MinusLogProbMetric: 2.4141

Epoch 127: val_loss did not improve from 2.37340
196/196 - 67s - loss: 2.3896 - MinusLogProbMetric: 2.3896 - val_loss: 2.4141 - val_MinusLogProbMetric: 2.4141 - lr: 0.0010 - 67s/epoch - 342ms/step
Epoch 128/1000
2023-09-15 21:49:26.012 
Epoch 128/1000 
	 loss: 2.3918, MinusLogProbMetric: 2.3918, val_loss: 2.3863, val_MinusLogProbMetric: 2.3863

Epoch 128: val_loss did not improve from 2.37340
196/196 - 63s - loss: 2.3918 - MinusLogProbMetric: 2.3918 - val_loss: 2.3863 - val_MinusLogProbMetric: 2.3863 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 129/1000
2023-09-15 21:50:26.368 
Epoch 129/1000 
	 loss: 2.3841, MinusLogProbMetric: 2.3841, val_loss: 2.3898, val_MinusLogProbMetric: 2.3898

Epoch 129: val_loss did not improve from 2.37340
196/196 - 60s - loss: 2.3841 - MinusLogProbMetric: 2.3841 - val_loss: 2.3898 - val_MinusLogProbMetric: 2.3898 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 130/1000
2023-09-15 21:51:26.863 
Epoch 130/1000 
	 loss: 2.3866, MinusLogProbMetric: 2.3866, val_loss: 2.4015, val_MinusLogProbMetric: 2.4015

Epoch 130: val_loss did not improve from 2.37340
196/196 - 60s - loss: 2.3866 - MinusLogProbMetric: 2.3866 - val_loss: 2.4015 - val_MinusLogProbMetric: 2.4015 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 131/1000
2023-09-15 21:52:28.442 
Epoch 131/1000 
	 loss: 2.3831, MinusLogProbMetric: 2.3831, val_loss: 2.3850, val_MinusLogProbMetric: 2.3850

Epoch 131: val_loss did not improve from 2.37340
196/196 - 62s - loss: 2.3831 - MinusLogProbMetric: 2.3831 - val_loss: 2.3850 - val_MinusLogProbMetric: 2.3850 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 132/1000
2023-09-15 21:53:34.877 
Epoch 132/1000 
	 loss: 2.3960, MinusLogProbMetric: 2.3960, val_loss: 2.3907, val_MinusLogProbMetric: 2.3907

Epoch 132: val_loss did not improve from 2.37340
196/196 - 66s - loss: 2.3960 - MinusLogProbMetric: 2.3960 - val_loss: 2.3907 - val_MinusLogProbMetric: 2.3907 - lr: 0.0010 - 66s/epoch - 339ms/step
Epoch 133/1000
2023-09-15 21:54:38.751 
Epoch 133/1000 
	 loss: 2.3870, MinusLogProbMetric: 2.3870, val_loss: 2.3758, val_MinusLogProbMetric: 2.3758

Epoch 133: val_loss did not improve from 2.37340
196/196 - 64s - loss: 2.3870 - MinusLogProbMetric: 2.3870 - val_loss: 2.3758 - val_MinusLogProbMetric: 2.3758 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 134/1000
2023-09-15 21:55:32.878 
Epoch 134/1000 
	 loss: 2.3889, MinusLogProbMetric: 2.3889, val_loss: 2.4702, val_MinusLogProbMetric: 2.4702

Epoch 134: val_loss did not improve from 2.37340
196/196 - 54s - loss: 2.3889 - MinusLogProbMetric: 2.3889 - val_loss: 2.4702 - val_MinusLogProbMetric: 2.4702 - lr: 0.0010 - 54s/epoch - 276ms/step
Epoch 135/1000
2023-09-15 21:56:25.699 
Epoch 135/1000 
	 loss: 2.3871, MinusLogProbMetric: 2.3871, val_loss: 2.4297, val_MinusLogProbMetric: 2.4297

Epoch 135: val_loss did not improve from 2.37340
196/196 - 53s - loss: 2.3871 - MinusLogProbMetric: 2.3871 - val_loss: 2.4297 - val_MinusLogProbMetric: 2.4297 - lr: 0.0010 - 53s/epoch - 269ms/step
Epoch 136/1000
2023-09-15 21:57:21.134 
Epoch 136/1000 
	 loss: 2.3859, MinusLogProbMetric: 2.3859, val_loss: 2.4031, val_MinusLogProbMetric: 2.4031

Epoch 136: val_loss did not improve from 2.37340
196/196 - 55s - loss: 2.3859 - MinusLogProbMetric: 2.3859 - val_loss: 2.4031 - val_MinusLogProbMetric: 2.4031 - lr: 0.0010 - 55s/epoch - 283ms/step
Epoch 137/1000
2023-09-15 21:58:28.380 
Epoch 137/1000 
	 loss: 2.3793, MinusLogProbMetric: 2.3793, val_loss: 2.3809, val_MinusLogProbMetric: 2.3809

Epoch 137: val_loss did not improve from 2.37340
196/196 - 67s - loss: 2.3793 - MinusLogProbMetric: 2.3793 - val_loss: 2.3809 - val_MinusLogProbMetric: 2.3809 - lr: 0.0010 - 67s/epoch - 343ms/step
Epoch 138/1000
2023-09-15 21:59:32.836 
Epoch 138/1000 
	 loss: 2.3814, MinusLogProbMetric: 2.3814, val_loss: 2.3804, val_MinusLogProbMetric: 2.3804

Epoch 138: val_loss did not improve from 2.37340
196/196 - 64s - loss: 2.3814 - MinusLogProbMetric: 2.3814 - val_loss: 2.3804 - val_MinusLogProbMetric: 2.3804 - lr: 0.0010 - 64s/epoch - 329ms/step
Epoch 139/1000
2023-09-15 22:00:34.484 
Epoch 139/1000 
	 loss: 2.3896, MinusLogProbMetric: 2.3896, val_loss: 2.4623, val_MinusLogProbMetric: 2.4623

Epoch 139: val_loss did not improve from 2.37340
196/196 - 62s - loss: 2.3896 - MinusLogProbMetric: 2.3896 - val_loss: 2.4623 - val_MinusLogProbMetric: 2.4623 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 140/1000
2023-09-15 22:01:35.631 
Epoch 140/1000 
	 loss: 2.3855, MinusLogProbMetric: 2.3855, val_loss: 2.4487, val_MinusLogProbMetric: 2.4487

Epoch 140: val_loss did not improve from 2.37340
196/196 - 61s - loss: 2.3855 - MinusLogProbMetric: 2.3855 - val_loss: 2.4487 - val_MinusLogProbMetric: 2.4487 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 141/1000
2023-09-15 22:02:36.811 
Epoch 141/1000 
	 loss: 2.3803, MinusLogProbMetric: 2.3803, val_loss: 2.4269, val_MinusLogProbMetric: 2.4269

Epoch 141: val_loss did not improve from 2.37340
196/196 - 61s - loss: 2.3803 - MinusLogProbMetric: 2.3803 - val_loss: 2.4269 - val_MinusLogProbMetric: 2.4269 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 142/1000
2023-09-15 22:03:37.645 
Epoch 142/1000 
	 loss: 2.3837, MinusLogProbMetric: 2.3837, val_loss: 2.3904, val_MinusLogProbMetric: 2.3904

Epoch 142: val_loss did not improve from 2.37340
196/196 - 61s - loss: 2.3837 - MinusLogProbMetric: 2.3837 - val_loss: 2.3904 - val_MinusLogProbMetric: 2.3904 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 143/1000
2023-09-15 22:04:39.548 
Epoch 143/1000 
	 loss: 2.3816, MinusLogProbMetric: 2.3816, val_loss: 2.4206, val_MinusLogProbMetric: 2.4206

Epoch 143: val_loss did not improve from 2.37340
196/196 - 62s - loss: 2.3816 - MinusLogProbMetric: 2.3816 - val_loss: 2.4206 - val_MinusLogProbMetric: 2.4206 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 144/1000
2023-09-15 22:05:35.544 
Epoch 144/1000 
	 loss: 2.3843, MinusLogProbMetric: 2.3843, val_loss: 2.3954, val_MinusLogProbMetric: 2.3954

Epoch 144: val_loss did not improve from 2.37340
196/196 - 56s - loss: 2.3843 - MinusLogProbMetric: 2.3843 - val_loss: 2.3954 - val_MinusLogProbMetric: 2.3954 - lr: 0.0010 - 56s/epoch - 286ms/step
Epoch 145/1000
2023-09-15 22:06:34.775 
Epoch 145/1000 
	 loss: 2.3867, MinusLogProbMetric: 2.3867, val_loss: 2.3777, val_MinusLogProbMetric: 2.3777

Epoch 145: val_loss did not improve from 2.37340
196/196 - 59s - loss: 2.3867 - MinusLogProbMetric: 2.3867 - val_loss: 2.3777 - val_MinusLogProbMetric: 2.3777 - lr: 0.0010 - 59s/epoch - 302ms/step
Epoch 146/1000
2023-09-15 22:07:45.461 
Epoch 146/1000 
	 loss: 2.3776, MinusLogProbMetric: 2.3776, val_loss: 2.4004, val_MinusLogProbMetric: 2.4004

Epoch 146: val_loss did not improve from 2.37340
196/196 - 71s - loss: 2.3776 - MinusLogProbMetric: 2.3776 - val_loss: 2.4004 - val_MinusLogProbMetric: 2.4004 - lr: 0.0010 - 71s/epoch - 361ms/step
Epoch 147/1000
2023-09-15 22:08:58.160 
Epoch 147/1000 
	 loss: 2.3848, MinusLogProbMetric: 2.3848, val_loss: 2.4057, val_MinusLogProbMetric: 2.4057

Epoch 147: val_loss did not improve from 2.37340
196/196 - 73s - loss: 2.3848 - MinusLogProbMetric: 2.3848 - val_loss: 2.4057 - val_MinusLogProbMetric: 2.4057 - lr: 0.0010 - 73s/epoch - 371ms/step
Epoch 148/1000
2023-09-15 22:10:08.387 
Epoch 148/1000 
	 loss: 2.3840, MinusLogProbMetric: 2.3840, val_loss: 2.4022, val_MinusLogProbMetric: 2.4022

Epoch 148: val_loss did not improve from 2.37340
196/196 - 70s - loss: 2.3840 - MinusLogProbMetric: 2.3840 - val_loss: 2.4022 - val_MinusLogProbMetric: 2.4022 - lr: 0.0010 - 70s/epoch - 358ms/step
Epoch 149/1000
2023-09-15 22:11:16.441 
Epoch 149/1000 
	 loss: 2.3922, MinusLogProbMetric: 2.3922, val_loss: 2.4344, val_MinusLogProbMetric: 2.4344

Epoch 149: val_loss did not improve from 2.37340
196/196 - 68s - loss: 2.3922 - MinusLogProbMetric: 2.3922 - val_loss: 2.4344 - val_MinusLogProbMetric: 2.4344 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 150/1000
2023-09-15 22:12:22.933 
Epoch 150/1000 
	 loss: 2.3835, MinusLogProbMetric: 2.3835, val_loss: 2.3947, val_MinusLogProbMetric: 2.3947

Epoch 150: val_loss did not improve from 2.37340
196/196 - 66s - loss: 2.3835 - MinusLogProbMetric: 2.3835 - val_loss: 2.3947 - val_MinusLogProbMetric: 2.3947 - lr: 0.0010 - 66s/epoch - 339ms/step
Epoch 151/1000
2023-09-15 22:13:25.549 
Epoch 151/1000 
	 loss: 2.3787, MinusLogProbMetric: 2.3787, val_loss: 2.3893, val_MinusLogProbMetric: 2.3893

Epoch 151: val_loss did not improve from 2.37340
196/196 - 63s - loss: 2.3787 - MinusLogProbMetric: 2.3787 - val_loss: 2.3893 - val_MinusLogProbMetric: 2.3893 - lr: 0.0010 - 63s/epoch - 319ms/step
Epoch 152/1000
2023-09-15 22:14:27.986 
Epoch 152/1000 
	 loss: 2.3880, MinusLogProbMetric: 2.3880, val_loss: 2.3914, val_MinusLogProbMetric: 2.3914

Epoch 152: val_loss did not improve from 2.37340
196/196 - 62s - loss: 2.3880 - MinusLogProbMetric: 2.3880 - val_loss: 2.3914 - val_MinusLogProbMetric: 2.3914 - lr: 0.0010 - 62s/epoch - 319ms/step
Epoch 153/1000
2023-09-15 22:15:30.448 
Epoch 153/1000 
	 loss: 2.3796, MinusLogProbMetric: 2.3796, val_loss: 2.3709, val_MinusLogProbMetric: 2.3709

Epoch 153: val_loss improved from 2.37340 to 2.37086, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5
196/196 - 63s - loss: 2.3796 - MinusLogProbMetric: 2.3796 - val_loss: 2.3709 - val_MinusLogProbMetric: 2.3709 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 154/1000
2023-09-15 22:16:35.521 
Epoch 154/1000 
	 loss: 2.3786, MinusLogProbMetric: 2.3786, val_loss: 2.3981, val_MinusLogProbMetric: 2.3981

Epoch 154: val_loss did not improve from 2.37086
196/196 - 64s - loss: 2.3786 - MinusLogProbMetric: 2.3786 - val_loss: 2.3981 - val_MinusLogProbMetric: 2.3981 - lr: 0.0010 - 64s/epoch - 328ms/step
Epoch 155/1000
2023-09-15 22:17:37.598 
Epoch 155/1000 
	 loss: 2.3784, MinusLogProbMetric: 2.3784, val_loss: 2.4242, val_MinusLogProbMetric: 2.4242

Epoch 155: val_loss did not improve from 2.37086
196/196 - 62s - loss: 2.3784 - MinusLogProbMetric: 2.3784 - val_loss: 2.4242 - val_MinusLogProbMetric: 2.4242 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 156/1000
2023-09-15 22:18:39.134 
Epoch 156/1000 
	 loss: 2.3826, MinusLogProbMetric: 2.3826, val_loss: 2.3760, val_MinusLogProbMetric: 2.3760

Epoch 156: val_loss did not improve from 2.37086
196/196 - 62s - loss: 2.3826 - MinusLogProbMetric: 2.3826 - val_loss: 2.3760 - val_MinusLogProbMetric: 2.3760 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 157/1000
2023-09-15 22:19:41.855 
Epoch 157/1000 
	 loss: 2.3813, MinusLogProbMetric: 2.3813, val_loss: 2.4211, val_MinusLogProbMetric: 2.4211

Epoch 157: val_loss did not improve from 2.37086
196/196 - 63s - loss: 2.3813 - MinusLogProbMetric: 2.3813 - val_loss: 2.4211 - val_MinusLogProbMetric: 2.4211 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 158/1000
2023-09-15 22:20:38.500 
Epoch 158/1000 
	 loss: 2.3818, MinusLogProbMetric: 2.3818, val_loss: 2.3892, val_MinusLogProbMetric: 2.3892

Epoch 158: val_loss did not improve from 2.37086
196/196 - 57s - loss: 2.3818 - MinusLogProbMetric: 2.3818 - val_loss: 2.3892 - val_MinusLogProbMetric: 2.3892 - lr: 0.0010 - 57s/epoch - 289ms/step
Epoch 159/1000
2023-09-15 22:21:31.506 
Epoch 159/1000 
	 loss: 2.3796, MinusLogProbMetric: 2.3796, val_loss: 2.3718, val_MinusLogProbMetric: 2.3718

Epoch 159: val_loss did not improve from 2.37086
196/196 - 53s - loss: 2.3796 - MinusLogProbMetric: 2.3796 - val_loss: 2.3718 - val_MinusLogProbMetric: 2.3718 - lr: 0.0010 - 53s/epoch - 270ms/step
Epoch 160/1000
2023-09-15 22:22:24.477 
Epoch 160/1000 
	 loss: 2.3885, MinusLogProbMetric: 2.3885, val_loss: 2.3712, val_MinusLogProbMetric: 2.3712

Epoch 160: val_loss did not improve from 2.37086
196/196 - 53s - loss: 2.3885 - MinusLogProbMetric: 2.3885 - val_loss: 2.3712 - val_MinusLogProbMetric: 2.3712 - lr: 0.0010 - 53s/epoch - 270ms/step
Epoch 161/1000
2023-09-15 22:23:32.314 
Epoch 161/1000 
	 loss: 2.3767, MinusLogProbMetric: 2.3767, val_loss: 2.3800, val_MinusLogProbMetric: 2.3800

Epoch 161: val_loss did not improve from 2.37086
196/196 - 68s - loss: 2.3767 - MinusLogProbMetric: 2.3767 - val_loss: 2.3800 - val_MinusLogProbMetric: 2.3800 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 162/1000
2023-09-15 22:24:40.906 
Epoch 162/1000 
	 loss: 2.3827, MinusLogProbMetric: 2.3827, val_loss: 2.3840, val_MinusLogProbMetric: 2.3840

Epoch 162: val_loss did not improve from 2.37086
196/196 - 69s - loss: 2.3827 - MinusLogProbMetric: 2.3827 - val_loss: 2.3840 - val_MinusLogProbMetric: 2.3840 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 163/1000
2023-09-15 22:25:46.330 
Epoch 163/1000 
	 loss: 2.3815, MinusLogProbMetric: 2.3815, val_loss: 2.4040, val_MinusLogProbMetric: 2.4040

Epoch 163: val_loss did not improve from 2.37086
196/196 - 65s - loss: 2.3815 - MinusLogProbMetric: 2.3815 - val_loss: 2.4040 - val_MinusLogProbMetric: 2.4040 - lr: 0.0010 - 65s/epoch - 334ms/step
Epoch 164/1000
2023-09-15 22:26:40.304 
Epoch 164/1000 
	 loss: 2.3940, MinusLogProbMetric: 2.3940, val_loss: 2.3842, val_MinusLogProbMetric: 2.3842

Epoch 164: val_loss did not improve from 2.37086
196/196 - 54s - loss: 2.3940 - MinusLogProbMetric: 2.3940 - val_loss: 2.3842 - val_MinusLogProbMetric: 2.3842 - lr: 0.0010 - 54s/epoch - 275ms/step
Epoch 165/1000
2023-09-15 22:27:40.887 
Epoch 165/1000 
	 loss: 2.3787, MinusLogProbMetric: 2.3787, val_loss: 2.3756, val_MinusLogProbMetric: 2.3756

Epoch 165: val_loss did not improve from 2.37086
196/196 - 61s - loss: 2.3787 - MinusLogProbMetric: 2.3787 - val_loss: 2.3756 - val_MinusLogProbMetric: 2.3756 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 166/1000
2023-09-15 22:28:43.472 
Epoch 166/1000 
	 loss: 2.3772, MinusLogProbMetric: 2.3772, val_loss: 2.4289, val_MinusLogProbMetric: 2.4289

Epoch 166: val_loss did not improve from 2.37086
196/196 - 63s - loss: 2.3772 - MinusLogProbMetric: 2.3772 - val_loss: 2.4289 - val_MinusLogProbMetric: 2.4289 - lr: 0.0010 - 63s/epoch - 319ms/step
Epoch 167/1000
2023-09-15 22:29:46.221 
Epoch 167/1000 
	 loss: 2.3846, MinusLogProbMetric: 2.3846, val_loss: 2.4411, val_MinusLogProbMetric: 2.4411

Epoch 167: val_loss did not improve from 2.37086
196/196 - 63s - loss: 2.3846 - MinusLogProbMetric: 2.3846 - val_loss: 2.4411 - val_MinusLogProbMetric: 2.4411 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 168/1000
2023-09-15 22:30:48.206 
Epoch 168/1000 
	 loss: 2.3871, MinusLogProbMetric: 2.3871, val_loss: 2.3729, val_MinusLogProbMetric: 2.3729

Epoch 168: val_loss did not improve from 2.37086
196/196 - 62s - loss: 2.3871 - MinusLogProbMetric: 2.3871 - val_loss: 2.3729 - val_MinusLogProbMetric: 2.3729 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 169/1000
2023-09-15 22:31:50.213 
Epoch 169/1000 
	 loss: 2.3773, MinusLogProbMetric: 2.3773, val_loss: 2.3757, val_MinusLogProbMetric: 2.3757

Epoch 169: val_loss did not improve from 2.37086
196/196 - 62s - loss: 2.3773 - MinusLogProbMetric: 2.3773 - val_loss: 2.3757 - val_MinusLogProbMetric: 2.3757 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 170/1000
2023-09-15 22:32:51.975 
Epoch 170/1000 
	 loss: 2.3834, MinusLogProbMetric: 2.3834, val_loss: 2.3814, val_MinusLogProbMetric: 2.3814

Epoch 170: val_loss did not improve from 2.37086
196/196 - 62s - loss: 2.3834 - MinusLogProbMetric: 2.3834 - val_loss: 2.3814 - val_MinusLogProbMetric: 2.3814 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 171/1000
2023-09-15 22:33:52.793 
Epoch 171/1000 
	 loss: 2.3910, MinusLogProbMetric: 2.3910, val_loss: 2.4159, val_MinusLogProbMetric: 2.4159

Epoch 171: val_loss did not improve from 2.37086
196/196 - 61s - loss: 2.3910 - MinusLogProbMetric: 2.3910 - val_loss: 2.4159 - val_MinusLogProbMetric: 2.4159 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 172/1000
2023-09-15 22:34:55.619 
Epoch 172/1000 
	 loss: 2.3842, MinusLogProbMetric: 2.3842, val_loss: 2.3711, val_MinusLogProbMetric: 2.3711

Epoch 172: val_loss did not improve from 2.37086
196/196 - 63s - loss: 2.3842 - MinusLogProbMetric: 2.3842 - val_loss: 2.3711 - val_MinusLogProbMetric: 2.3711 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 173/1000
2023-09-15 22:35:56.847 
Epoch 173/1000 
	 loss: 2.3894, MinusLogProbMetric: 2.3894, val_loss: 2.3872, val_MinusLogProbMetric: 2.3872

Epoch 173: val_loss did not improve from 2.37086
196/196 - 61s - loss: 2.3894 - MinusLogProbMetric: 2.3894 - val_loss: 2.3872 - val_MinusLogProbMetric: 2.3872 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 174/1000
2023-09-15 22:36:58.705 
Epoch 174/1000 
	 loss: 2.3762, MinusLogProbMetric: 2.3762, val_loss: 2.3742, val_MinusLogProbMetric: 2.3742

Epoch 174: val_loss did not improve from 2.37086
196/196 - 62s - loss: 2.3762 - MinusLogProbMetric: 2.3762 - val_loss: 2.3742 - val_MinusLogProbMetric: 2.3742 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 175/1000
2023-09-15 22:37:59.194 
Epoch 175/1000 
	 loss: 2.3787, MinusLogProbMetric: 2.3787, val_loss: 2.5729, val_MinusLogProbMetric: 2.5729

Epoch 175: val_loss did not improve from 2.37086
196/196 - 60s - loss: 2.3787 - MinusLogProbMetric: 2.3787 - val_loss: 2.5729 - val_MinusLogProbMetric: 2.5729 - lr: 0.0010 - 60s/epoch - 309ms/step
Epoch 176/1000
2023-09-15 22:38:59.450 
Epoch 176/1000 
	 loss: 2.3931, MinusLogProbMetric: 2.3931, val_loss: 2.4114, val_MinusLogProbMetric: 2.4114

Epoch 176: val_loss did not improve from 2.37086
196/196 - 60s - loss: 2.3931 - MinusLogProbMetric: 2.3931 - val_loss: 2.4114 - val_MinusLogProbMetric: 2.4114 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 177/1000
2023-09-15 22:40:00.284 
Epoch 177/1000 
	 loss: 2.3821, MinusLogProbMetric: 2.3821, val_loss: 2.4031, val_MinusLogProbMetric: 2.4031

Epoch 177: val_loss did not improve from 2.37086
196/196 - 61s - loss: 2.3821 - MinusLogProbMetric: 2.3821 - val_loss: 2.4031 - val_MinusLogProbMetric: 2.4031 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 178/1000
2023-09-15 22:41:00.762 
Epoch 178/1000 
	 loss: 2.3735, MinusLogProbMetric: 2.3735, val_loss: 2.4097, val_MinusLogProbMetric: 2.4097

Epoch 178: val_loss did not improve from 2.37086
196/196 - 60s - loss: 2.3735 - MinusLogProbMetric: 2.3735 - val_loss: 2.4097 - val_MinusLogProbMetric: 2.4097 - lr: 0.0010 - 60s/epoch - 309ms/step
Epoch 179/1000
2023-09-15 22:42:01.331 
Epoch 179/1000 
	 loss: 2.3789, MinusLogProbMetric: 2.3789, val_loss: 2.4689, val_MinusLogProbMetric: 2.4689

Epoch 179: val_loss did not improve from 2.37086
196/196 - 61s - loss: 2.3789 - MinusLogProbMetric: 2.3789 - val_loss: 2.4689 - val_MinusLogProbMetric: 2.4689 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 180/1000
2023-09-15 22:43:01.590 
Epoch 180/1000 
	 loss: 2.3760, MinusLogProbMetric: 2.3760, val_loss: 2.3794, val_MinusLogProbMetric: 2.3794

Epoch 180: val_loss did not improve from 2.37086
196/196 - 60s - loss: 2.3760 - MinusLogProbMetric: 2.3760 - val_loss: 2.3794 - val_MinusLogProbMetric: 2.3794 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 181/1000
2023-09-15 22:44:01.559 
Epoch 181/1000 
	 loss: 2.3805, MinusLogProbMetric: 2.3805, val_loss: 2.3865, val_MinusLogProbMetric: 2.3865

Epoch 181: val_loss did not improve from 2.37086
196/196 - 60s - loss: 2.3805 - MinusLogProbMetric: 2.3805 - val_loss: 2.3865 - val_MinusLogProbMetric: 2.3865 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 182/1000
2023-09-15 22:45:02.628 
Epoch 182/1000 
	 loss: 2.3784, MinusLogProbMetric: 2.3784, val_loss: 2.3889, val_MinusLogProbMetric: 2.3889

Epoch 182: val_loss did not improve from 2.37086
196/196 - 61s - loss: 2.3784 - MinusLogProbMetric: 2.3784 - val_loss: 2.3889 - val_MinusLogProbMetric: 2.3889 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 183/1000
2023-09-15 22:46:03.101 
Epoch 183/1000 
	 loss: 2.3767, MinusLogProbMetric: 2.3767, val_loss: 2.4168, val_MinusLogProbMetric: 2.4168

Epoch 183: val_loss did not improve from 2.37086
196/196 - 60s - loss: 2.3767 - MinusLogProbMetric: 2.3767 - val_loss: 2.4168 - val_MinusLogProbMetric: 2.4168 - lr: 0.0010 - 60s/epoch - 309ms/step
Epoch 184/1000
2023-09-15 22:47:02.989 
Epoch 184/1000 
	 loss: 2.3729, MinusLogProbMetric: 2.3729, val_loss: 2.4085, val_MinusLogProbMetric: 2.4085

Epoch 184: val_loss did not improve from 2.37086
196/196 - 60s - loss: 2.3729 - MinusLogProbMetric: 2.3729 - val_loss: 2.4085 - val_MinusLogProbMetric: 2.4085 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 185/1000
2023-09-15 22:48:03.464 
Epoch 185/1000 
	 loss: 2.3910, MinusLogProbMetric: 2.3910, val_loss: 2.4612, val_MinusLogProbMetric: 2.4612

Epoch 185: val_loss did not improve from 2.37086
196/196 - 60s - loss: 2.3910 - MinusLogProbMetric: 2.3910 - val_loss: 2.4612 - val_MinusLogProbMetric: 2.4612 - lr: 0.0010 - 60s/epoch - 309ms/step
Epoch 186/1000
2023-09-15 22:49:03.141 
Epoch 186/1000 
	 loss: 2.3799, MinusLogProbMetric: 2.3799, val_loss: 2.3792, val_MinusLogProbMetric: 2.3792

Epoch 186: val_loss did not improve from 2.37086
196/196 - 60s - loss: 2.3799 - MinusLogProbMetric: 2.3799 - val_loss: 2.3792 - val_MinusLogProbMetric: 2.3792 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 187/1000
2023-09-15 22:50:03.726 
Epoch 187/1000 
	 loss: 2.3694, MinusLogProbMetric: 2.3694, val_loss: 2.3720, val_MinusLogProbMetric: 2.3720

Epoch 187: val_loss did not improve from 2.37086
196/196 - 61s - loss: 2.3694 - MinusLogProbMetric: 2.3694 - val_loss: 2.3720 - val_MinusLogProbMetric: 2.3720 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 188/1000
2023-09-15 22:51:04.004 
Epoch 188/1000 
	 loss: 2.3834, MinusLogProbMetric: 2.3834, val_loss: 2.3763, val_MinusLogProbMetric: 2.3763

Epoch 188: val_loss did not improve from 2.37086
196/196 - 60s - loss: 2.3834 - MinusLogProbMetric: 2.3834 - val_loss: 2.3763 - val_MinusLogProbMetric: 2.3763 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 189/1000
2023-09-15 22:52:05.033 
Epoch 189/1000 
	 loss: 2.3700, MinusLogProbMetric: 2.3700, val_loss: 2.3824, val_MinusLogProbMetric: 2.3824

Epoch 189: val_loss did not improve from 2.37086
196/196 - 61s - loss: 2.3700 - MinusLogProbMetric: 2.3700 - val_loss: 2.3824 - val_MinusLogProbMetric: 2.3824 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 190/1000
2023-09-15 22:53:05.128 
Epoch 190/1000 
	 loss: 2.3749, MinusLogProbMetric: 2.3749, val_loss: 2.4057, val_MinusLogProbMetric: 2.4057

Epoch 190: val_loss did not improve from 2.37086
196/196 - 60s - loss: 2.3749 - MinusLogProbMetric: 2.3749 - val_loss: 2.4057 - val_MinusLogProbMetric: 2.4057 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 191/1000
2023-09-15 22:54:04.923 
Epoch 191/1000 
	 loss: 2.3851, MinusLogProbMetric: 2.3851, val_loss: 2.3732, val_MinusLogProbMetric: 2.3732

Epoch 191: val_loss did not improve from 2.37086
196/196 - 60s - loss: 2.3851 - MinusLogProbMetric: 2.3851 - val_loss: 2.3732 - val_MinusLogProbMetric: 2.3732 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 192/1000
2023-09-15 22:55:04.529 
Epoch 192/1000 
	 loss: 2.3752, MinusLogProbMetric: 2.3752, val_loss: 2.3804, val_MinusLogProbMetric: 2.3804

Epoch 192: val_loss did not improve from 2.37086
196/196 - 60s - loss: 2.3752 - MinusLogProbMetric: 2.3752 - val_loss: 2.3804 - val_MinusLogProbMetric: 2.3804 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 193/1000
2023-09-15 22:56:04.386 
Epoch 193/1000 
	 loss: 2.3754, MinusLogProbMetric: 2.3754, val_loss: 2.3971, val_MinusLogProbMetric: 2.3971

Epoch 193: val_loss did not improve from 2.37086
196/196 - 60s - loss: 2.3754 - MinusLogProbMetric: 2.3754 - val_loss: 2.3971 - val_MinusLogProbMetric: 2.3971 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 194/1000
2023-09-15 22:57:04.431 
Epoch 194/1000 
	 loss: 2.3852, MinusLogProbMetric: 2.3852, val_loss: 2.3938, val_MinusLogProbMetric: 2.3938

Epoch 194: val_loss did not improve from 2.37086
196/196 - 60s - loss: 2.3852 - MinusLogProbMetric: 2.3852 - val_loss: 2.3938 - val_MinusLogProbMetric: 2.3938 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 195/1000
2023-09-15 22:58:04.308 
Epoch 195/1000 
	 loss: 2.3832, MinusLogProbMetric: 2.3832, val_loss: 2.3766, val_MinusLogProbMetric: 2.3766

Epoch 195: val_loss did not improve from 2.37086
196/196 - 60s - loss: 2.3832 - MinusLogProbMetric: 2.3832 - val_loss: 2.3766 - val_MinusLogProbMetric: 2.3766 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 196/1000
2023-09-15 22:59:04.611 
Epoch 196/1000 
	 loss: 2.3737, MinusLogProbMetric: 2.3737, val_loss: 2.3880, val_MinusLogProbMetric: 2.3880

Epoch 196: val_loss did not improve from 2.37086
196/196 - 60s - loss: 2.3737 - MinusLogProbMetric: 2.3737 - val_loss: 2.3880 - val_MinusLogProbMetric: 2.3880 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 197/1000
2023-09-15 23:00:04.665 
Epoch 197/1000 
	 loss: 2.3784, MinusLogProbMetric: 2.3784, val_loss: 2.3912, val_MinusLogProbMetric: 2.3912

Epoch 197: val_loss did not improve from 2.37086
196/196 - 60s - loss: 2.3784 - MinusLogProbMetric: 2.3784 - val_loss: 2.3912 - val_MinusLogProbMetric: 2.3912 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 198/1000
2023-09-15 23:01:04.375 
Epoch 198/1000 
	 loss: 2.3718, MinusLogProbMetric: 2.3718, val_loss: 2.3803, val_MinusLogProbMetric: 2.3803

Epoch 198: val_loss did not improve from 2.37086
196/196 - 60s - loss: 2.3718 - MinusLogProbMetric: 2.3718 - val_loss: 2.3803 - val_MinusLogProbMetric: 2.3803 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 199/1000
2023-09-15 23:02:05.039 
Epoch 199/1000 
	 loss: 2.3738, MinusLogProbMetric: 2.3738, val_loss: 2.3747, val_MinusLogProbMetric: 2.3747

Epoch 199: val_loss did not improve from 2.37086
196/196 - 61s - loss: 2.3738 - MinusLogProbMetric: 2.3738 - val_loss: 2.3747 - val_MinusLogProbMetric: 2.3747 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 200/1000
2023-09-15 23:03:06.006 
Epoch 200/1000 
	 loss: 2.3748, MinusLogProbMetric: 2.3748, val_loss: 2.3880, val_MinusLogProbMetric: 2.3880

Epoch 200: val_loss did not improve from 2.37086
196/196 - 61s - loss: 2.3748 - MinusLogProbMetric: 2.3748 - val_loss: 2.3880 - val_MinusLogProbMetric: 2.3880 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 201/1000
2023-09-15 23:04:05.775 
Epoch 201/1000 
	 loss: 2.3764, MinusLogProbMetric: 2.3764, val_loss: 2.3951, val_MinusLogProbMetric: 2.3951

Epoch 201: val_loss did not improve from 2.37086
196/196 - 60s - loss: 2.3764 - MinusLogProbMetric: 2.3764 - val_loss: 2.3951 - val_MinusLogProbMetric: 2.3951 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 202/1000
2023-09-15 23:05:02.916 
Epoch 202/1000 
	 loss: 2.3781, MinusLogProbMetric: 2.3781, val_loss: 2.3736, val_MinusLogProbMetric: 2.3736

Epoch 202: val_loss did not improve from 2.37086
196/196 - 57s - loss: 2.3781 - MinusLogProbMetric: 2.3781 - val_loss: 2.3736 - val_MinusLogProbMetric: 2.3736 - lr: 0.0010 - 57s/epoch - 292ms/step
Epoch 203/1000
2023-09-15 23:05:59.947 
Epoch 203/1000 
	 loss: 2.3728, MinusLogProbMetric: 2.3728, val_loss: 2.3825, val_MinusLogProbMetric: 2.3825

Epoch 203: val_loss did not improve from 2.37086
196/196 - 57s - loss: 2.3728 - MinusLogProbMetric: 2.3728 - val_loss: 2.3825 - val_MinusLogProbMetric: 2.3825 - lr: 0.0010 - 57s/epoch - 291ms/step
Epoch 204/1000
2023-09-15 23:06:59.360 
Epoch 204/1000 
	 loss: 2.3578, MinusLogProbMetric: 2.3578, val_loss: 2.3719, val_MinusLogProbMetric: 2.3719

Epoch 204: val_loss did not improve from 2.37086
196/196 - 59s - loss: 2.3578 - MinusLogProbMetric: 2.3578 - val_loss: 2.3719 - val_MinusLogProbMetric: 2.3719 - lr: 5.0000e-04 - 59s/epoch - 303ms/step
Epoch 205/1000
2023-09-15 23:07:59.897 
Epoch 205/1000 
	 loss: 2.3572, MinusLogProbMetric: 2.3572, val_loss: 2.3701, val_MinusLogProbMetric: 2.3701

Epoch 205: val_loss improved from 2.37086 to 2.37014, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5
196/196 - 61s - loss: 2.3572 - MinusLogProbMetric: 2.3572 - val_loss: 2.3701 - val_MinusLogProbMetric: 2.3701 - lr: 5.0000e-04 - 61s/epoch - 314ms/step
Epoch 206/1000
2023-09-15 23:09:01.221 
Epoch 206/1000 
	 loss: 2.3551, MinusLogProbMetric: 2.3551, val_loss: 2.3727, val_MinusLogProbMetric: 2.3727

Epoch 206: val_loss did not improve from 2.37014
196/196 - 60s - loss: 2.3551 - MinusLogProbMetric: 2.3551 - val_loss: 2.3727 - val_MinusLogProbMetric: 2.3727 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 207/1000
2023-09-15 23:10:02.082 
Epoch 207/1000 
	 loss: 2.3539, MinusLogProbMetric: 2.3539, val_loss: 2.3721, val_MinusLogProbMetric: 2.3721

Epoch 207: val_loss did not improve from 2.37014
196/196 - 61s - loss: 2.3539 - MinusLogProbMetric: 2.3539 - val_loss: 2.3721 - val_MinusLogProbMetric: 2.3721 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 208/1000
2023-09-15 23:11:02.936 
Epoch 208/1000 
	 loss: 2.3551, MinusLogProbMetric: 2.3551, val_loss: 2.3710, val_MinusLogProbMetric: 2.3710

Epoch 208: val_loss did not improve from 2.37014
196/196 - 61s - loss: 2.3551 - MinusLogProbMetric: 2.3551 - val_loss: 2.3710 - val_MinusLogProbMetric: 2.3710 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 209/1000
2023-09-15 23:12:03.471 
Epoch 209/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.3732, val_MinusLogProbMetric: 2.3732

Epoch 209: val_loss did not improve from 2.37014
196/196 - 61s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.3732 - val_MinusLogProbMetric: 2.3732 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 210/1000
2023-09-15 23:13:03.771 
Epoch 210/1000 
	 loss: 2.3546, MinusLogProbMetric: 2.3546, val_loss: 2.3719, val_MinusLogProbMetric: 2.3719

Epoch 210: val_loss did not improve from 2.37014
196/196 - 60s - loss: 2.3546 - MinusLogProbMetric: 2.3546 - val_loss: 2.3719 - val_MinusLogProbMetric: 2.3719 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 211/1000
2023-09-15 23:14:03.829 
Epoch 211/1000 
	 loss: 2.3549, MinusLogProbMetric: 2.3549, val_loss: 2.3754, val_MinusLogProbMetric: 2.3754

Epoch 211: val_loss did not improve from 2.37014
196/196 - 60s - loss: 2.3549 - MinusLogProbMetric: 2.3549 - val_loss: 2.3754 - val_MinusLogProbMetric: 2.3754 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 212/1000
2023-09-15 23:15:04.423 
Epoch 212/1000 
	 loss: 2.3548, MinusLogProbMetric: 2.3548, val_loss: 2.3709, val_MinusLogProbMetric: 2.3709

Epoch 212: val_loss did not improve from 2.37014
196/196 - 61s - loss: 2.3548 - MinusLogProbMetric: 2.3548 - val_loss: 2.3709 - val_MinusLogProbMetric: 2.3709 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 213/1000
2023-09-15 23:16:04.607 
Epoch 213/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.3764, val_MinusLogProbMetric: 2.3764

Epoch 213: val_loss did not improve from 2.37014
196/196 - 60s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.3764 - val_MinusLogProbMetric: 2.3764 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 214/1000
2023-09-15 23:17:05.394 
Epoch 214/1000 
	 loss: 2.3547, MinusLogProbMetric: 2.3547, val_loss: 2.3660, val_MinusLogProbMetric: 2.3660

Epoch 214: val_loss improved from 2.37014 to 2.36603, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5
196/196 - 62s - loss: 2.3547 - MinusLogProbMetric: 2.3547 - val_loss: 2.3660 - val_MinusLogProbMetric: 2.3660 - lr: 5.0000e-04 - 62s/epoch - 315ms/step
Epoch 215/1000
2023-09-15 23:18:07.610 
Epoch 215/1000 
	 loss: 2.3542, MinusLogProbMetric: 2.3542, val_loss: 2.3689, val_MinusLogProbMetric: 2.3689

Epoch 215: val_loss did not improve from 2.36603
196/196 - 61s - loss: 2.3542 - MinusLogProbMetric: 2.3542 - val_loss: 2.3689 - val_MinusLogProbMetric: 2.3689 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 216/1000
2023-09-15 23:19:07.793 
Epoch 216/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3680, val_MinusLogProbMetric: 2.3680

Epoch 216: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3680 - val_MinusLogProbMetric: 2.3680 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 217/1000
2023-09-15 23:20:07.952 
Epoch 217/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3710, val_MinusLogProbMetric: 2.3710

Epoch 217: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3710 - val_MinusLogProbMetric: 2.3710 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 218/1000
2023-09-15 23:21:08.066 
Epoch 218/1000 
	 loss: 2.3523, MinusLogProbMetric: 2.3523, val_loss: 2.3697, val_MinusLogProbMetric: 2.3697

Epoch 218: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3523 - MinusLogProbMetric: 2.3523 - val_loss: 2.3697 - val_MinusLogProbMetric: 2.3697 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 219/1000
2023-09-15 23:22:07.827 
Epoch 219/1000 
	 loss: 2.3561, MinusLogProbMetric: 2.3561, val_loss: 2.3755, val_MinusLogProbMetric: 2.3755

Epoch 219: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3561 - MinusLogProbMetric: 2.3561 - val_loss: 2.3755 - val_MinusLogProbMetric: 2.3755 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 220/1000
2023-09-15 23:23:08.671 
Epoch 220/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.3691, val_MinusLogProbMetric: 2.3691

Epoch 220: val_loss did not improve from 2.36603
196/196 - 61s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.3691 - val_MinusLogProbMetric: 2.3691 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 221/1000
2023-09-15 23:24:08.445 
Epoch 221/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3707, val_MinusLogProbMetric: 2.3707

Epoch 221: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3707 - val_MinusLogProbMetric: 2.3707 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 222/1000
2023-09-15 23:25:08.567 
Epoch 222/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3706, val_MinusLogProbMetric: 2.3706

Epoch 222: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3706 - val_MinusLogProbMetric: 2.3706 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 223/1000
2023-09-15 23:26:08.093 
Epoch 223/1000 
	 loss: 2.3544, MinusLogProbMetric: 2.3544, val_loss: 2.3693, val_MinusLogProbMetric: 2.3693

Epoch 223: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3544 - MinusLogProbMetric: 2.3544 - val_loss: 2.3693 - val_MinusLogProbMetric: 2.3693 - lr: 5.0000e-04 - 60s/epoch - 304ms/step
Epoch 224/1000
2023-09-15 23:27:08.210 
Epoch 224/1000 
	 loss: 2.3585, MinusLogProbMetric: 2.3585, val_loss: 2.3807, val_MinusLogProbMetric: 2.3807

Epoch 224: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3585 - MinusLogProbMetric: 2.3585 - val_loss: 2.3807 - val_MinusLogProbMetric: 2.3807 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 225/1000
2023-09-15 23:28:08.919 
Epoch 225/1000 
	 loss: 2.3537, MinusLogProbMetric: 2.3537, val_loss: 2.3843, val_MinusLogProbMetric: 2.3843

Epoch 225: val_loss did not improve from 2.36603
196/196 - 61s - loss: 2.3537 - MinusLogProbMetric: 2.3537 - val_loss: 2.3843 - val_MinusLogProbMetric: 2.3843 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 226/1000
2023-09-15 23:29:09.285 
Epoch 226/1000 
	 loss: 2.3539, MinusLogProbMetric: 2.3539, val_loss: 2.3763, val_MinusLogProbMetric: 2.3763

Epoch 226: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3539 - MinusLogProbMetric: 2.3539 - val_loss: 2.3763 - val_MinusLogProbMetric: 2.3763 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 227/1000
2023-09-15 23:30:07.103 
Epoch 227/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3668, val_MinusLogProbMetric: 2.3668

Epoch 227: val_loss did not improve from 2.36603
196/196 - 58s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3668 - val_MinusLogProbMetric: 2.3668 - lr: 5.0000e-04 - 58s/epoch - 295ms/step
Epoch 228/1000
2023-09-15 23:31:02.637 
Epoch 228/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3786, val_MinusLogProbMetric: 2.3786

Epoch 228: val_loss did not improve from 2.36603
196/196 - 56s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3786 - val_MinusLogProbMetric: 2.3786 - lr: 5.0000e-04 - 56s/epoch - 283ms/step
Epoch 229/1000
2023-09-15 23:32:00.524 
Epoch 229/1000 
	 loss: 2.3530, MinusLogProbMetric: 2.3530, val_loss: 2.3885, val_MinusLogProbMetric: 2.3885

Epoch 229: val_loss did not improve from 2.36603
196/196 - 58s - loss: 2.3530 - MinusLogProbMetric: 2.3530 - val_loss: 2.3885 - val_MinusLogProbMetric: 2.3885 - lr: 5.0000e-04 - 58s/epoch - 295ms/step
Epoch 230/1000
2023-09-15 23:33:00.872 
Epoch 230/1000 
	 loss: 2.3543, MinusLogProbMetric: 2.3543, val_loss: 2.4054, val_MinusLogProbMetric: 2.4054

Epoch 230: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3543 - MinusLogProbMetric: 2.3543 - val_loss: 2.4054 - val_MinusLogProbMetric: 2.4054 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 231/1000
2023-09-15 23:34:01.267 
Epoch 231/1000 
	 loss: 2.3565, MinusLogProbMetric: 2.3565, val_loss: 2.4247, val_MinusLogProbMetric: 2.4247

Epoch 231: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3565 - MinusLogProbMetric: 2.3565 - val_loss: 2.4247 - val_MinusLogProbMetric: 2.4247 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 232/1000
2023-09-15 23:35:01.449 
Epoch 232/1000 
	 loss: 2.3545, MinusLogProbMetric: 2.3545, val_loss: 2.3749, val_MinusLogProbMetric: 2.3749

Epoch 232: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3545 - MinusLogProbMetric: 2.3545 - val_loss: 2.3749 - val_MinusLogProbMetric: 2.3749 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 233/1000
2023-09-15 23:36:01.368 
Epoch 233/1000 
	 loss: 2.3508, MinusLogProbMetric: 2.3508, val_loss: 2.3747, val_MinusLogProbMetric: 2.3747

Epoch 233: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3508 - MinusLogProbMetric: 2.3508 - val_loss: 2.3747 - val_MinusLogProbMetric: 2.3747 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 234/1000
2023-09-15 23:37:01.921 
Epoch 234/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3730, val_MinusLogProbMetric: 2.3730

Epoch 234: val_loss did not improve from 2.36603
196/196 - 61s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3730 - val_MinusLogProbMetric: 2.3730 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 235/1000
2023-09-15 23:38:02.105 
Epoch 235/1000 
	 loss: 2.3511, MinusLogProbMetric: 2.3511, val_loss: 2.3686, val_MinusLogProbMetric: 2.3686

Epoch 235: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3511 - MinusLogProbMetric: 2.3511 - val_loss: 2.3686 - val_MinusLogProbMetric: 2.3686 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 236/1000
2023-09-15 23:39:01.727 
Epoch 236/1000 
	 loss: 2.3545, MinusLogProbMetric: 2.3545, val_loss: 2.3711, val_MinusLogProbMetric: 2.3711

Epoch 236: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3545 - MinusLogProbMetric: 2.3545 - val_loss: 2.3711 - val_MinusLogProbMetric: 2.3711 - lr: 5.0000e-04 - 60s/epoch - 304ms/step
Epoch 237/1000
2023-09-15 23:40:01.705 
Epoch 237/1000 
	 loss: 2.3540, MinusLogProbMetric: 2.3540, val_loss: 2.3702, val_MinusLogProbMetric: 2.3702

Epoch 237: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3540 - MinusLogProbMetric: 2.3540 - val_loss: 2.3702 - val_MinusLogProbMetric: 2.3702 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 238/1000
2023-09-15 23:41:01.870 
Epoch 238/1000 
	 loss: 2.3547, MinusLogProbMetric: 2.3547, val_loss: 2.3688, val_MinusLogProbMetric: 2.3688

Epoch 238: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3547 - MinusLogProbMetric: 2.3547 - val_loss: 2.3688 - val_MinusLogProbMetric: 2.3688 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 239/1000
2023-09-15 23:42:01.816 
Epoch 239/1000 
	 loss: 2.3519, MinusLogProbMetric: 2.3519, val_loss: 2.3769, val_MinusLogProbMetric: 2.3769

Epoch 239: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3519 - MinusLogProbMetric: 2.3519 - val_loss: 2.3769 - val_MinusLogProbMetric: 2.3769 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 240/1000
2023-09-15 23:43:01.253 
Epoch 240/1000 
	 loss: 2.3522, MinusLogProbMetric: 2.3522, val_loss: 2.3699, val_MinusLogProbMetric: 2.3699

Epoch 240: val_loss did not improve from 2.36603
196/196 - 59s - loss: 2.3522 - MinusLogProbMetric: 2.3522 - val_loss: 2.3699 - val_MinusLogProbMetric: 2.3699 - lr: 5.0000e-04 - 59s/epoch - 303ms/step
Epoch 241/1000
2023-09-15 23:44:00.611 
Epoch 241/1000 
	 loss: 2.3554, MinusLogProbMetric: 2.3554, val_loss: 2.3877, val_MinusLogProbMetric: 2.3877

Epoch 241: val_loss did not improve from 2.36603
196/196 - 59s - loss: 2.3554 - MinusLogProbMetric: 2.3554 - val_loss: 2.3877 - val_MinusLogProbMetric: 2.3877 - lr: 5.0000e-04 - 59s/epoch - 303ms/step
Epoch 242/1000
2023-09-15 23:45:00.355 
Epoch 242/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3671, val_MinusLogProbMetric: 2.3671

Epoch 242: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3671 - val_MinusLogProbMetric: 2.3671 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 243/1000
2023-09-15 23:46:00.474 
Epoch 243/1000 
	 loss: 2.3528, MinusLogProbMetric: 2.3528, val_loss: 2.3668, val_MinusLogProbMetric: 2.3668

Epoch 243: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3528 - MinusLogProbMetric: 2.3528 - val_loss: 2.3668 - val_MinusLogProbMetric: 2.3668 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 244/1000
2023-09-15 23:47:00.462 
Epoch 244/1000 
	 loss: 2.3521, MinusLogProbMetric: 2.3521, val_loss: 2.3846, val_MinusLogProbMetric: 2.3846

Epoch 244: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3521 - MinusLogProbMetric: 2.3521 - val_loss: 2.3846 - val_MinusLogProbMetric: 2.3846 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 245/1000
2023-09-15 23:48:00.661 
Epoch 245/1000 
	 loss: 2.3538, MinusLogProbMetric: 2.3538, val_loss: 2.3718, val_MinusLogProbMetric: 2.3718

Epoch 245: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3538 - MinusLogProbMetric: 2.3538 - val_loss: 2.3718 - val_MinusLogProbMetric: 2.3718 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 246/1000
2023-09-15 23:49:00.912 
Epoch 246/1000 
	 loss: 2.3539, MinusLogProbMetric: 2.3539, val_loss: 2.3833, val_MinusLogProbMetric: 2.3833

Epoch 246: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3539 - MinusLogProbMetric: 2.3539 - val_loss: 2.3833 - val_MinusLogProbMetric: 2.3833 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 247/1000
2023-09-15 23:50:00.333 
Epoch 247/1000 
	 loss: 2.3542, MinusLogProbMetric: 2.3542, val_loss: 2.3785, val_MinusLogProbMetric: 2.3785

Epoch 247: val_loss did not improve from 2.36603
196/196 - 59s - loss: 2.3542 - MinusLogProbMetric: 2.3542 - val_loss: 2.3785 - val_MinusLogProbMetric: 2.3785 - lr: 5.0000e-04 - 59s/epoch - 303ms/step
Epoch 248/1000
2023-09-15 23:51:00.607 
Epoch 248/1000 
	 loss: 2.3520, MinusLogProbMetric: 2.3520, val_loss: 2.3705, val_MinusLogProbMetric: 2.3705

Epoch 248: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3520 - MinusLogProbMetric: 2.3520 - val_loss: 2.3705 - val_MinusLogProbMetric: 2.3705 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 249/1000
2023-09-15 23:51:59.938 
Epoch 249/1000 
	 loss: 2.3574, MinusLogProbMetric: 2.3574, val_loss: 2.3785, val_MinusLogProbMetric: 2.3785

Epoch 249: val_loss did not improve from 2.36603
196/196 - 59s - loss: 2.3574 - MinusLogProbMetric: 2.3574 - val_loss: 2.3785 - val_MinusLogProbMetric: 2.3785 - lr: 5.0000e-04 - 59s/epoch - 303ms/step
Epoch 250/1000
2023-09-15 23:52:59.388 
Epoch 250/1000 
	 loss: 2.3513, MinusLogProbMetric: 2.3513, val_loss: 2.3910, val_MinusLogProbMetric: 2.3910

Epoch 250: val_loss did not improve from 2.36603
196/196 - 59s - loss: 2.3513 - MinusLogProbMetric: 2.3513 - val_loss: 2.3910 - val_MinusLogProbMetric: 2.3910 - lr: 5.0000e-04 - 59s/epoch - 303ms/step
Epoch 251/1000
2023-09-15 23:53:59.435 
Epoch 251/1000 
	 loss: 2.3552, MinusLogProbMetric: 2.3552, val_loss: 2.4025, val_MinusLogProbMetric: 2.4025

Epoch 251: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3552 - MinusLogProbMetric: 2.3552 - val_loss: 2.4025 - val_MinusLogProbMetric: 2.4025 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 252/1000
2023-09-15 23:54:59.528 
Epoch 252/1000 
	 loss: 2.3575, MinusLogProbMetric: 2.3575, val_loss: 2.3815, val_MinusLogProbMetric: 2.3815

Epoch 252: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3575 - MinusLogProbMetric: 2.3575 - val_loss: 2.3815 - val_MinusLogProbMetric: 2.3815 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 253/1000
2023-09-15 23:55:59.904 
Epoch 253/1000 
	 loss: 2.3545, MinusLogProbMetric: 2.3545, val_loss: 2.3768, val_MinusLogProbMetric: 2.3768

Epoch 253: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3545 - MinusLogProbMetric: 2.3545 - val_loss: 2.3768 - val_MinusLogProbMetric: 2.3768 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 254/1000
2023-09-15 23:56:59.915 
Epoch 254/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.3731, val_MinusLogProbMetric: 2.3731

Epoch 254: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.3731 - val_MinusLogProbMetric: 2.3731 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 255/1000
2023-09-15 23:57:59.240 
Epoch 255/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.3675, val_MinusLogProbMetric: 2.3675

Epoch 255: val_loss did not improve from 2.36603
196/196 - 59s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.3675 - val_MinusLogProbMetric: 2.3675 - lr: 5.0000e-04 - 59s/epoch - 303ms/step
Epoch 256/1000
2023-09-15 23:58:59.277 
Epoch 256/1000 
	 loss: 2.3521, MinusLogProbMetric: 2.3521, val_loss: 2.3718, val_MinusLogProbMetric: 2.3718

Epoch 256: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3521 - MinusLogProbMetric: 2.3521 - val_loss: 2.3718 - val_MinusLogProbMetric: 2.3718 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 257/1000
2023-09-15 23:59:59.790 
Epoch 257/1000 
	 loss: 2.3568, MinusLogProbMetric: 2.3568, val_loss: 2.3670, val_MinusLogProbMetric: 2.3670

Epoch 257: val_loss did not improve from 2.36603
196/196 - 61s - loss: 2.3568 - MinusLogProbMetric: 2.3568 - val_loss: 2.3670 - val_MinusLogProbMetric: 2.3670 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 258/1000
2023-09-16 00:00:59.930 
Epoch 258/1000 
	 loss: 2.3514, MinusLogProbMetric: 2.3514, val_loss: 2.3699, val_MinusLogProbMetric: 2.3699

Epoch 258: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3514 - MinusLogProbMetric: 2.3514 - val_loss: 2.3699 - val_MinusLogProbMetric: 2.3699 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 259/1000
2023-09-16 00:02:00.433 
Epoch 259/1000 
	 loss: 2.3527, MinusLogProbMetric: 2.3527, val_loss: 2.3722, val_MinusLogProbMetric: 2.3722

Epoch 259: val_loss did not improve from 2.36603
196/196 - 61s - loss: 2.3527 - MinusLogProbMetric: 2.3527 - val_loss: 2.3722 - val_MinusLogProbMetric: 2.3722 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 260/1000
2023-09-16 00:03:00.777 
Epoch 260/1000 
	 loss: 2.3533, MinusLogProbMetric: 2.3533, val_loss: 2.3912, val_MinusLogProbMetric: 2.3912

Epoch 260: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3533 - MinusLogProbMetric: 2.3533 - val_loss: 2.3912 - val_MinusLogProbMetric: 2.3912 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 261/1000
2023-09-16 00:04:00.716 
Epoch 261/1000 
	 loss: 2.3507, MinusLogProbMetric: 2.3507, val_loss: 2.3781, val_MinusLogProbMetric: 2.3781

Epoch 261: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3507 - MinusLogProbMetric: 2.3507 - val_loss: 2.3781 - val_MinusLogProbMetric: 2.3781 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 262/1000
2023-09-16 00:05:00.462 
Epoch 262/1000 
	 loss: 2.3515, MinusLogProbMetric: 2.3515, val_loss: 2.3713, val_MinusLogProbMetric: 2.3713

Epoch 262: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3515 - MinusLogProbMetric: 2.3515 - val_loss: 2.3713 - val_MinusLogProbMetric: 2.3713 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 263/1000
2023-09-16 00:06:00.798 
Epoch 263/1000 
	 loss: 2.3513, MinusLogProbMetric: 2.3513, val_loss: 2.3807, val_MinusLogProbMetric: 2.3807

Epoch 263: val_loss did not improve from 2.36603
196/196 - 60s - loss: 2.3513 - MinusLogProbMetric: 2.3513 - val_loss: 2.3807 - val_MinusLogProbMetric: 2.3807 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 264/1000
2023-09-16 00:07:00.895 
Epoch 264/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3654, val_MinusLogProbMetric: 2.3654

Epoch 264: val_loss improved from 2.36603 to 2.36543, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_53/weights/best_weights.h5
196/196 - 61s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3654 - val_MinusLogProbMetric: 2.3654 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 265/1000
2023-09-16 00:08:01.955 
Epoch 265/1000 
	 loss: 2.3532, MinusLogProbMetric: 2.3532, val_loss: 2.3884, val_MinusLogProbMetric: 2.3884

Epoch 265: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3532 - MinusLogProbMetric: 2.3532 - val_loss: 2.3884 - val_MinusLogProbMetric: 2.3884 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 266/1000
2023-09-16 00:09:02.033 
Epoch 266/1000 
	 loss: 2.3514, MinusLogProbMetric: 2.3514, val_loss: 2.3822, val_MinusLogProbMetric: 2.3822

Epoch 266: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3514 - MinusLogProbMetric: 2.3514 - val_loss: 2.3822 - val_MinusLogProbMetric: 2.3822 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 267/1000
2023-09-16 00:10:02.290 
Epoch 267/1000 
	 loss: 2.3545, MinusLogProbMetric: 2.3545, val_loss: 2.3704, val_MinusLogProbMetric: 2.3704

Epoch 267: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3545 - MinusLogProbMetric: 2.3545 - val_loss: 2.3704 - val_MinusLogProbMetric: 2.3704 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 268/1000
2023-09-16 00:11:02.223 
Epoch 268/1000 
	 loss: 2.3539, MinusLogProbMetric: 2.3539, val_loss: 2.3748, val_MinusLogProbMetric: 2.3748

Epoch 268: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3539 - MinusLogProbMetric: 2.3539 - val_loss: 2.3748 - val_MinusLogProbMetric: 2.3748 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 269/1000
2023-09-16 00:12:01.805 
Epoch 269/1000 
	 loss: 2.3501, MinusLogProbMetric: 2.3501, val_loss: 2.3736, val_MinusLogProbMetric: 2.3736

Epoch 269: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3501 - MinusLogProbMetric: 2.3501 - val_loss: 2.3736 - val_MinusLogProbMetric: 2.3736 - lr: 5.0000e-04 - 60s/epoch - 304ms/step
Epoch 270/1000
2023-09-16 00:12:56.969 
Epoch 270/1000 
	 loss: 2.3544, MinusLogProbMetric: 2.3544, val_loss: 2.3699, val_MinusLogProbMetric: 2.3699

Epoch 270: val_loss did not improve from 2.36543
196/196 - 55s - loss: 2.3544 - MinusLogProbMetric: 2.3544 - val_loss: 2.3699 - val_MinusLogProbMetric: 2.3699 - lr: 5.0000e-04 - 55s/epoch - 281ms/step
Epoch 271/1000
2023-09-16 00:13:49.029 
Epoch 271/1000 
	 loss: 2.3538, MinusLogProbMetric: 2.3538, val_loss: 2.3739, val_MinusLogProbMetric: 2.3739

Epoch 271: val_loss did not improve from 2.36543
196/196 - 52s - loss: 2.3538 - MinusLogProbMetric: 2.3538 - val_loss: 2.3739 - val_MinusLogProbMetric: 2.3739 - lr: 5.0000e-04 - 52s/epoch - 266ms/step
Epoch 272/1000
2023-09-16 00:14:48.092 
Epoch 272/1000 
	 loss: 2.3496, MinusLogProbMetric: 2.3496, val_loss: 2.3673, val_MinusLogProbMetric: 2.3673

Epoch 272: val_loss did not improve from 2.36543
196/196 - 59s - loss: 2.3496 - MinusLogProbMetric: 2.3496 - val_loss: 2.3673 - val_MinusLogProbMetric: 2.3673 - lr: 5.0000e-04 - 59s/epoch - 301ms/step
Epoch 273/1000
2023-09-16 00:15:47.875 
Epoch 273/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3684, val_MinusLogProbMetric: 2.3684

Epoch 273: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3684 - val_MinusLogProbMetric: 2.3684 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 274/1000
2023-09-16 00:16:48.130 
Epoch 274/1000 
	 loss: 2.3496, MinusLogProbMetric: 2.3496, val_loss: 2.3719, val_MinusLogProbMetric: 2.3719

Epoch 274: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3496 - MinusLogProbMetric: 2.3496 - val_loss: 2.3719 - val_MinusLogProbMetric: 2.3719 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 275/1000
2023-09-16 00:17:48.743 
Epoch 275/1000 
	 loss: 2.3517, MinusLogProbMetric: 2.3517, val_loss: 2.3689, val_MinusLogProbMetric: 2.3689

Epoch 275: val_loss did not improve from 2.36543
196/196 - 61s - loss: 2.3517 - MinusLogProbMetric: 2.3517 - val_loss: 2.3689 - val_MinusLogProbMetric: 2.3689 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 276/1000
2023-09-16 00:18:48.569 
Epoch 276/1000 
	 loss: 2.3506, MinusLogProbMetric: 2.3506, val_loss: 2.3662, val_MinusLogProbMetric: 2.3662

Epoch 276: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3506 - MinusLogProbMetric: 2.3506 - val_loss: 2.3662 - val_MinusLogProbMetric: 2.3662 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 277/1000
2023-09-16 00:19:48.715 
Epoch 277/1000 
	 loss: 2.3506, MinusLogProbMetric: 2.3506, val_loss: 2.3691, val_MinusLogProbMetric: 2.3691

Epoch 277: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3506 - MinusLogProbMetric: 2.3506 - val_loss: 2.3691 - val_MinusLogProbMetric: 2.3691 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 278/1000
2023-09-16 00:20:48.544 
Epoch 278/1000 
	 loss: 2.3499, MinusLogProbMetric: 2.3499, val_loss: 2.3851, val_MinusLogProbMetric: 2.3851

Epoch 278: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3499 - MinusLogProbMetric: 2.3499 - val_loss: 2.3851 - val_MinusLogProbMetric: 2.3851 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 279/1000
2023-09-16 00:21:48.012 
Epoch 279/1000 
	 loss: 2.3537, MinusLogProbMetric: 2.3537, val_loss: 2.3711, val_MinusLogProbMetric: 2.3711

Epoch 279: val_loss did not improve from 2.36543
196/196 - 59s - loss: 2.3537 - MinusLogProbMetric: 2.3537 - val_loss: 2.3711 - val_MinusLogProbMetric: 2.3711 - lr: 5.0000e-04 - 59s/epoch - 303ms/step
Epoch 280/1000
2023-09-16 00:22:48.075 
Epoch 280/1000 
	 loss: 2.3517, MinusLogProbMetric: 2.3517, val_loss: 2.3694, val_MinusLogProbMetric: 2.3694

Epoch 280: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3517 - MinusLogProbMetric: 2.3517 - val_loss: 2.3694 - val_MinusLogProbMetric: 2.3694 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 281/1000
2023-09-16 00:23:48.243 
Epoch 281/1000 
	 loss: 2.3494, MinusLogProbMetric: 2.3494, val_loss: 2.3722, val_MinusLogProbMetric: 2.3722

Epoch 281: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3494 - MinusLogProbMetric: 2.3494 - val_loss: 2.3722 - val_MinusLogProbMetric: 2.3722 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 282/1000
2023-09-16 00:24:48.362 
Epoch 282/1000 
	 loss: 2.3552, MinusLogProbMetric: 2.3552, val_loss: 2.3687, val_MinusLogProbMetric: 2.3687

Epoch 282: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3552 - MinusLogProbMetric: 2.3552 - val_loss: 2.3687 - val_MinusLogProbMetric: 2.3687 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 283/1000
2023-09-16 00:25:48.372 
Epoch 283/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3704, val_MinusLogProbMetric: 2.3704

Epoch 283: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3704 - val_MinusLogProbMetric: 2.3704 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 284/1000
2023-09-16 00:26:48.785 
Epoch 284/1000 
	 loss: 2.3516, MinusLogProbMetric: 2.3516, val_loss: 2.4011, val_MinusLogProbMetric: 2.4011

Epoch 284: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3516 - MinusLogProbMetric: 2.3516 - val_loss: 2.4011 - val_MinusLogProbMetric: 2.4011 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 285/1000
2023-09-16 00:27:49.475 
Epoch 285/1000 
	 loss: 2.3505, MinusLogProbMetric: 2.3505, val_loss: 2.4028, val_MinusLogProbMetric: 2.4028

Epoch 285: val_loss did not improve from 2.36543
196/196 - 61s - loss: 2.3505 - MinusLogProbMetric: 2.3505 - val_loss: 2.4028 - val_MinusLogProbMetric: 2.4028 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 286/1000
2023-09-16 00:28:49.877 
Epoch 286/1000 
	 loss: 2.3552, MinusLogProbMetric: 2.3552, val_loss: 2.3793, val_MinusLogProbMetric: 2.3793

Epoch 286: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3552 - MinusLogProbMetric: 2.3552 - val_loss: 2.3793 - val_MinusLogProbMetric: 2.3793 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 287/1000
2023-09-16 00:29:49.711 
Epoch 287/1000 
	 loss: 2.3520, MinusLogProbMetric: 2.3520, val_loss: 2.3715, val_MinusLogProbMetric: 2.3715

Epoch 287: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3520 - MinusLogProbMetric: 2.3520 - val_loss: 2.3715 - val_MinusLogProbMetric: 2.3715 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 288/1000
2023-09-16 00:30:49.477 
Epoch 288/1000 
	 loss: 2.3521, MinusLogProbMetric: 2.3521, val_loss: 2.3711, val_MinusLogProbMetric: 2.3711

Epoch 288: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3521 - MinusLogProbMetric: 2.3521 - val_loss: 2.3711 - val_MinusLogProbMetric: 2.3711 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 289/1000
2023-09-16 00:31:49.404 
Epoch 289/1000 
	 loss: 2.3520, MinusLogProbMetric: 2.3520, val_loss: 2.3718, val_MinusLogProbMetric: 2.3718

Epoch 289: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3520 - MinusLogProbMetric: 2.3520 - val_loss: 2.3718 - val_MinusLogProbMetric: 2.3718 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 290/1000
2023-09-16 00:32:49.453 
Epoch 290/1000 
	 loss: 2.3504, MinusLogProbMetric: 2.3504, val_loss: 2.3721, val_MinusLogProbMetric: 2.3721

Epoch 290: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3504 - MinusLogProbMetric: 2.3504 - val_loss: 2.3721 - val_MinusLogProbMetric: 2.3721 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 291/1000
2023-09-16 00:33:49.120 
Epoch 291/1000 
	 loss: 2.3496, MinusLogProbMetric: 2.3496, val_loss: 2.3724, val_MinusLogProbMetric: 2.3724

Epoch 291: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3496 - MinusLogProbMetric: 2.3496 - val_loss: 2.3724 - val_MinusLogProbMetric: 2.3724 - lr: 5.0000e-04 - 60s/epoch - 304ms/step
Epoch 292/1000
2023-09-16 00:34:49.141 
Epoch 292/1000 
	 loss: 2.3513, MinusLogProbMetric: 2.3513, val_loss: 2.3712, val_MinusLogProbMetric: 2.3712

Epoch 292: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3513 - MinusLogProbMetric: 2.3513 - val_loss: 2.3712 - val_MinusLogProbMetric: 2.3712 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 293/1000
2023-09-16 00:35:49.052 
Epoch 293/1000 
	 loss: 2.3498, MinusLogProbMetric: 2.3498, val_loss: 2.3806, val_MinusLogProbMetric: 2.3806

Epoch 293: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3498 - MinusLogProbMetric: 2.3498 - val_loss: 2.3806 - val_MinusLogProbMetric: 2.3806 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 294/1000
2023-09-16 00:36:49.067 
Epoch 294/1000 
	 loss: 2.3514, MinusLogProbMetric: 2.3514, val_loss: 2.3808, val_MinusLogProbMetric: 2.3808

Epoch 294: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3514 - MinusLogProbMetric: 2.3514 - val_loss: 2.3808 - val_MinusLogProbMetric: 2.3808 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 295/1000
2023-09-16 00:37:49.568 
Epoch 295/1000 
	 loss: 2.3508, MinusLogProbMetric: 2.3508, val_loss: 2.3696, val_MinusLogProbMetric: 2.3696

Epoch 295: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3508 - MinusLogProbMetric: 2.3508 - val_loss: 2.3696 - val_MinusLogProbMetric: 2.3696 - lr: 5.0000e-04 - 60s/epoch - 309ms/step
Epoch 296/1000
2023-09-16 00:38:49.900 
Epoch 296/1000 
	 loss: 2.3509, MinusLogProbMetric: 2.3509, val_loss: 2.3697, val_MinusLogProbMetric: 2.3697

Epoch 296: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3509 - MinusLogProbMetric: 2.3509 - val_loss: 2.3697 - val_MinusLogProbMetric: 2.3697 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 297/1000
2023-09-16 00:39:50.186 
Epoch 297/1000 
	 loss: 2.3523, MinusLogProbMetric: 2.3523, val_loss: 2.3688, val_MinusLogProbMetric: 2.3688

Epoch 297: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3523 - MinusLogProbMetric: 2.3523 - val_loss: 2.3688 - val_MinusLogProbMetric: 2.3688 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 298/1000
2023-09-16 00:40:50.139 
Epoch 298/1000 
	 loss: 2.3497, MinusLogProbMetric: 2.3497, val_loss: 2.3917, val_MinusLogProbMetric: 2.3917

Epoch 298: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3497 - MinusLogProbMetric: 2.3497 - val_loss: 2.3917 - val_MinusLogProbMetric: 2.3917 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 299/1000
2023-09-16 00:41:50.808 
Epoch 299/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3728, val_MinusLogProbMetric: 2.3728

Epoch 299: val_loss did not improve from 2.36543
196/196 - 61s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3728 - val_MinusLogProbMetric: 2.3728 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 300/1000
2023-09-16 00:42:51.540 
Epoch 300/1000 
	 loss: 2.3530, MinusLogProbMetric: 2.3530, val_loss: 2.3750, val_MinusLogProbMetric: 2.3750

Epoch 300: val_loss did not improve from 2.36543
196/196 - 61s - loss: 2.3530 - MinusLogProbMetric: 2.3530 - val_loss: 2.3750 - val_MinusLogProbMetric: 2.3750 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 301/1000
2023-09-16 00:43:50.690 
Epoch 301/1000 
	 loss: 2.3508, MinusLogProbMetric: 2.3508, val_loss: 2.3761, val_MinusLogProbMetric: 2.3761

Epoch 301: val_loss did not improve from 2.36543
196/196 - 59s - loss: 2.3508 - MinusLogProbMetric: 2.3508 - val_loss: 2.3761 - val_MinusLogProbMetric: 2.3761 - lr: 5.0000e-04 - 59s/epoch - 302ms/step
Epoch 302/1000
2023-09-16 00:44:50.810 
Epoch 302/1000 
	 loss: 2.3501, MinusLogProbMetric: 2.3501, val_loss: 2.3697, val_MinusLogProbMetric: 2.3697

Epoch 302: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3501 - MinusLogProbMetric: 2.3501 - val_loss: 2.3697 - val_MinusLogProbMetric: 2.3697 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 303/1000
2023-09-16 00:45:50.875 
Epoch 303/1000 
	 loss: 2.3519, MinusLogProbMetric: 2.3519, val_loss: 2.3772, val_MinusLogProbMetric: 2.3772

Epoch 303: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3519 - MinusLogProbMetric: 2.3519 - val_loss: 2.3772 - val_MinusLogProbMetric: 2.3772 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 304/1000
2023-09-16 00:46:51.058 
Epoch 304/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3794, val_MinusLogProbMetric: 2.3794

Epoch 304: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3794 - val_MinusLogProbMetric: 2.3794 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 305/1000
2023-09-16 00:47:51.226 
Epoch 305/1000 
	 loss: 2.3545, MinusLogProbMetric: 2.3545, val_loss: 2.3758, val_MinusLogProbMetric: 2.3758

Epoch 305: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3545 - MinusLogProbMetric: 2.3545 - val_loss: 2.3758 - val_MinusLogProbMetric: 2.3758 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 306/1000
2023-09-16 00:48:51.631 
Epoch 306/1000 
	 loss: 2.3491, MinusLogProbMetric: 2.3491, val_loss: 2.3690, val_MinusLogProbMetric: 2.3690

Epoch 306: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3491 - MinusLogProbMetric: 2.3491 - val_loss: 2.3690 - val_MinusLogProbMetric: 2.3690 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 307/1000
2023-09-16 00:49:52.042 
Epoch 307/1000 
	 loss: 2.3517, MinusLogProbMetric: 2.3517, val_loss: 2.3705, val_MinusLogProbMetric: 2.3705

Epoch 307: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3517 - MinusLogProbMetric: 2.3517 - val_loss: 2.3705 - val_MinusLogProbMetric: 2.3705 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 308/1000
2023-09-16 00:50:52.126 
Epoch 308/1000 
	 loss: 2.3505, MinusLogProbMetric: 2.3505, val_loss: 2.3866, val_MinusLogProbMetric: 2.3866

Epoch 308: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3505 - MinusLogProbMetric: 2.3505 - val_loss: 2.3866 - val_MinusLogProbMetric: 2.3866 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 309/1000
2023-09-16 00:51:51.495 
Epoch 309/1000 
	 loss: 2.3512, MinusLogProbMetric: 2.3512, val_loss: 2.3732, val_MinusLogProbMetric: 2.3732

Epoch 309: val_loss did not improve from 2.36543
196/196 - 59s - loss: 2.3512 - MinusLogProbMetric: 2.3512 - val_loss: 2.3732 - val_MinusLogProbMetric: 2.3732 - lr: 5.0000e-04 - 59s/epoch - 303ms/step
Epoch 310/1000
2023-09-16 00:52:51.795 
Epoch 310/1000 
	 loss: 2.3519, MinusLogProbMetric: 2.3519, val_loss: 2.3738, val_MinusLogProbMetric: 2.3738

Epoch 310: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3519 - MinusLogProbMetric: 2.3519 - val_loss: 2.3738 - val_MinusLogProbMetric: 2.3738 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 311/1000
2023-09-16 00:53:52.221 
Epoch 311/1000 
	 loss: 2.3495, MinusLogProbMetric: 2.3495, val_loss: 2.3750, val_MinusLogProbMetric: 2.3750

Epoch 311: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3495 - MinusLogProbMetric: 2.3495 - val_loss: 2.3750 - val_MinusLogProbMetric: 2.3750 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 312/1000
2023-09-16 00:54:51.517 
Epoch 312/1000 
	 loss: 2.3501, MinusLogProbMetric: 2.3501, val_loss: 2.3822, val_MinusLogProbMetric: 2.3822

Epoch 312: val_loss did not improve from 2.36543
196/196 - 59s - loss: 2.3501 - MinusLogProbMetric: 2.3501 - val_loss: 2.3822 - val_MinusLogProbMetric: 2.3822 - lr: 5.0000e-04 - 59s/epoch - 303ms/step
Epoch 313/1000
2023-09-16 00:55:51.588 
Epoch 313/1000 
	 loss: 2.3538, MinusLogProbMetric: 2.3538, val_loss: 2.3716, val_MinusLogProbMetric: 2.3716

Epoch 313: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3538 - MinusLogProbMetric: 2.3538 - val_loss: 2.3716 - val_MinusLogProbMetric: 2.3716 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 314/1000
2023-09-16 00:56:51.951 
Epoch 314/1000 
	 loss: 2.3530, MinusLogProbMetric: 2.3530, val_loss: 2.3715, val_MinusLogProbMetric: 2.3715

Epoch 314: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3530 - MinusLogProbMetric: 2.3530 - val_loss: 2.3715 - val_MinusLogProbMetric: 2.3715 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 315/1000
2023-09-16 00:57:51.560 
Epoch 315/1000 
	 loss: 2.3441, MinusLogProbMetric: 2.3441, val_loss: 2.3736, val_MinusLogProbMetric: 2.3736

Epoch 315: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3441 - MinusLogProbMetric: 2.3441 - val_loss: 2.3736 - val_MinusLogProbMetric: 2.3736 - lr: 2.5000e-04 - 60s/epoch - 304ms/step
Epoch 316/1000
2023-09-16 00:58:50.960 
Epoch 316/1000 
	 loss: 2.3410, MinusLogProbMetric: 2.3410, val_loss: 2.3686, val_MinusLogProbMetric: 2.3686

Epoch 316: val_loss did not improve from 2.36543
196/196 - 59s - loss: 2.3410 - MinusLogProbMetric: 2.3410 - val_loss: 2.3686 - val_MinusLogProbMetric: 2.3686 - lr: 2.5000e-04 - 59s/epoch - 303ms/step
Epoch 317/1000
2023-09-16 00:59:51.563 
Epoch 317/1000 
	 loss: 2.3436, MinusLogProbMetric: 2.3436, val_loss: 2.3785, val_MinusLogProbMetric: 2.3785

Epoch 317: val_loss did not improve from 2.36543
196/196 - 61s - loss: 2.3436 - MinusLogProbMetric: 2.3436 - val_loss: 2.3785 - val_MinusLogProbMetric: 2.3785 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 318/1000
2023-09-16 01:00:51.563 
Epoch 318/1000 
	 loss: 2.3420, MinusLogProbMetric: 2.3420, val_loss: 2.3699, val_MinusLogProbMetric: 2.3699

Epoch 318: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3420 - MinusLogProbMetric: 2.3420 - val_loss: 2.3699 - val_MinusLogProbMetric: 2.3699 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 319/1000
2023-09-16 01:01:51.436 
Epoch 319/1000 
	 loss: 2.3414, MinusLogProbMetric: 2.3414, val_loss: 2.3684, val_MinusLogProbMetric: 2.3684

Epoch 319: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3414 - MinusLogProbMetric: 2.3414 - val_loss: 2.3684 - val_MinusLogProbMetric: 2.3684 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 320/1000
2023-09-16 01:02:51.627 
Epoch 320/1000 
	 loss: 2.3407, MinusLogProbMetric: 2.3407, val_loss: 2.3684, val_MinusLogProbMetric: 2.3684

Epoch 320: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3407 - MinusLogProbMetric: 2.3407 - val_loss: 2.3684 - val_MinusLogProbMetric: 2.3684 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 321/1000
2023-09-16 01:03:51.093 
Epoch 321/1000 
	 loss: 2.3416, MinusLogProbMetric: 2.3416, val_loss: 2.3703, val_MinusLogProbMetric: 2.3703

Epoch 321: val_loss did not improve from 2.36543
196/196 - 59s - loss: 2.3416 - MinusLogProbMetric: 2.3416 - val_loss: 2.3703 - val_MinusLogProbMetric: 2.3703 - lr: 2.5000e-04 - 59s/epoch - 303ms/step
Epoch 322/1000
2023-09-16 01:04:51.416 
Epoch 322/1000 
	 loss: 2.3408, MinusLogProbMetric: 2.3408, val_loss: 2.3693, val_MinusLogProbMetric: 2.3693

Epoch 322: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3408 - MinusLogProbMetric: 2.3408 - val_loss: 2.3693 - val_MinusLogProbMetric: 2.3693 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 323/1000
2023-09-16 01:05:51.204 
Epoch 323/1000 
	 loss: 2.3419, MinusLogProbMetric: 2.3419, val_loss: 2.3691, val_MinusLogProbMetric: 2.3691

Epoch 323: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3419 - MinusLogProbMetric: 2.3419 - val_loss: 2.3691 - val_MinusLogProbMetric: 2.3691 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 324/1000
2023-09-16 01:06:50.983 
Epoch 324/1000 
	 loss: 2.3406, MinusLogProbMetric: 2.3406, val_loss: 2.3687, val_MinusLogProbMetric: 2.3687

Epoch 324: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3406 - MinusLogProbMetric: 2.3406 - val_loss: 2.3687 - val_MinusLogProbMetric: 2.3687 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 325/1000
2023-09-16 01:07:50.741 
Epoch 325/1000 
	 loss: 2.3412, MinusLogProbMetric: 2.3412, val_loss: 2.3684, val_MinusLogProbMetric: 2.3684

Epoch 325: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3412 - MinusLogProbMetric: 2.3412 - val_loss: 2.3684 - val_MinusLogProbMetric: 2.3684 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 326/1000
2023-09-16 01:08:51.453 
Epoch 326/1000 
	 loss: 2.3416, MinusLogProbMetric: 2.3416, val_loss: 2.3764, val_MinusLogProbMetric: 2.3764

Epoch 326: val_loss did not improve from 2.36543
196/196 - 61s - loss: 2.3416 - MinusLogProbMetric: 2.3416 - val_loss: 2.3764 - val_MinusLogProbMetric: 2.3764 - lr: 2.5000e-04 - 61s/epoch - 310ms/step
Epoch 327/1000
2023-09-16 01:09:51.921 
Epoch 327/1000 
	 loss: 2.3410, MinusLogProbMetric: 2.3410, val_loss: 2.3678, val_MinusLogProbMetric: 2.3678

Epoch 327: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3410 - MinusLogProbMetric: 2.3410 - val_loss: 2.3678 - val_MinusLogProbMetric: 2.3678 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 328/1000
2023-09-16 01:10:51.408 
Epoch 328/1000 
	 loss: 2.3419, MinusLogProbMetric: 2.3419, val_loss: 2.3671, val_MinusLogProbMetric: 2.3671

Epoch 328: val_loss did not improve from 2.36543
196/196 - 59s - loss: 2.3419 - MinusLogProbMetric: 2.3419 - val_loss: 2.3671 - val_MinusLogProbMetric: 2.3671 - lr: 2.5000e-04 - 59s/epoch - 303ms/step
Epoch 329/1000
2023-09-16 01:11:51.252 
Epoch 329/1000 
	 loss: 2.3416, MinusLogProbMetric: 2.3416, val_loss: 2.3702, val_MinusLogProbMetric: 2.3702

Epoch 329: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3416 - MinusLogProbMetric: 2.3416 - val_loss: 2.3702 - val_MinusLogProbMetric: 2.3702 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 330/1000
2023-09-16 01:12:51.289 
Epoch 330/1000 
	 loss: 2.3414, MinusLogProbMetric: 2.3414, val_loss: 2.3743, val_MinusLogProbMetric: 2.3743

Epoch 330: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3414 - MinusLogProbMetric: 2.3414 - val_loss: 2.3743 - val_MinusLogProbMetric: 2.3743 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 331/1000
2023-09-16 01:13:50.922 
Epoch 331/1000 
	 loss: 2.3408, MinusLogProbMetric: 2.3408, val_loss: 2.3721, val_MinusLogProbMetric: 2.3721

Epoch 331: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3408 - MinusLogProbMetric: 2.3408 - val_loss: 2.3721 - val_MinusLogProbMetric: 2.3721 - lr: 2.5000e-04 - 60s/epoch - 304ms/step
Epoch 332/1000
2023-09-16 01:14:51.158 
Epoch 332/1000 
	 loss: 2.3411, MinusLogProbMetric: 2.3411, val_loss: 2.3749, val_MinusLogProbMetric: 2.3749

Epoch 332: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3411 - MinusLogProbMetric: 2.3411 - val_loss: 2.3749 - val_MinusLogProbMetric: 2.3749 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 333/1000
2023-09-16 01:15:51.109 
Epoch 333/1000 
	 loss: 2.3410, MinusLogProbMetric: 2.3410, val_loss: 2.3698, val_MinusLogProbMetric: 2.3698

Epoch 333: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3410 - MinusLogProbMetric: 2.3410 - val_loss: 2.3698 - val_MinusLogProbMetric: 2.3698 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 334/1000
2023-09-16 01:16:51.252 
Epoch 334/1000 
	 loss: 2.3401, MinusLogProbMetric: 2.3401, val_loss: 2.3704, val_MinusLogProbMetric: 2.3704

Epoch 334: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3401 - MinusLogProbMetric: 2.3401 - val_loss: 2.3704 - val_MinusLogProbMetric: 2.3704 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 335/1000
2023-09-16 01:17:50.921 
Epoch 335/1000 
	 loss: 2.3422, MinusLogProbMetric: 2.3422, val_loss: 2.3672, val_MinusLogProbMetric: 2.3672

Epoch 335: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3422 - MinusLogProbMetric: 2.3422 - val_loss: 2.3672 - val_MinusLogProbMetric: 2.3672 - lr: 2.5000e-04 - 60s/epoch - 304ms/step
Epoch 336/1000
2023-09-16 01:18:50.849 
Epoch 336/1000 
	 loss: 2.3413, MinusLogProbMetric: 2.3413, val_loss: 2.3684, val_MinusLogProbMetric: 2.3684

Epoch 336: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3413 - MinusLogProbMetric: 2.3413 - val_loss: 2.3684 - val_MinusLogProbMetric: 2.3684 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 337/1000
2023-09-16 01:19:50.661 
Epoch 337/1000 
	 loss: 2.3406, MinusLogProbMetric: 2.3406, val_loss: 2.3685, val_MinusLogProbMetric: 2.3685

Epoch 337: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3406 - MinusLogProbMetric: 2.3406 - val_loss: 2.3685 - val_MinusLogProbMetric: 2.3685 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 338/1000
2023-09-16 01:20:50.466 
Epoch 338/1000 
	 loss: 2.3420, MinusLogProbMetric: 2.3420, val_loss: 2.3717, val_MinusLogProbMetric: 2.3717

Epoch 338: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3420 - MinusLogProbMetric: 2.3420 - val_loss: 2.3717 - val_MinusLogProbMetric: 2.3717 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 339/1000
2023-09-16 01:21:49.962 
Epoch 339/1000 
	 loss: 2.3411, MinusLogProbMetric: 2.3411, val_loss: 2.3690, val_MinusLogProbMetric: 2.3690

Epoch 339: val_loss did not improve from 2.36543
196/196 - 59s - loss: 2.3411 - MinusLogProbMetric: 2.3411 - val_loss: 2.3690 - val_MinusLogProbMetric: 2.3690 - lr: 2.5000e-04 - 59s/epoch - 304ms/step
Epoch 340/1000
2023-09-16 01:22:49.639 
Epoch 340/1000 
	 loss: 2.3407, MinusLogProbMetric: 2.3407, val_loss: 2.3699, val_MinusLogProbMetric: 2.3699

Epoch 340: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3407 - MinusLogProbMetric: 2.3407 - val_loss: 2.3699 - val_MinusLogProbMetric: 2.3699 - lr: 2.5000e-04 - 60s/epoch - 304ms/step
Epoch 341/1000
2023-09-16 01:23:49.540 
Epoch 341/1000 
	 loss: 2.3402, MinusLogProbMetric: 2.3402, val_loss: 2.3712, val_MinusLogProbMetric: 2.3712

Epoch 341: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3402 - MinusLogProbMetric: 2.3402 - val_loss: 2.3712 - val_MinusLogProbMetric: 2.3712 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 342/1000
2023-09-16 01:24:49.554 
Epoch 342/1000 
	 loss: 2.3415, MinusLogProbMetric: 2.3415, val_loss: 2.3730, val_MinusLogProbMetric: 2.3730

Epoch 342: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3415 - MinusLogProbMetric: 2.3415 - val_loss: 2.3730 - val_MinusLogProbMetric: 2.3730 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 343/1000
2023-09-16 01:25:49.699 
Epoch 343/1000 
	 loss: 2.3411, MinusLogProbMetric: 2.3411, val_loss: 2.3710, val_MinusLogProbMetric: 2.3710

Epoch 343: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3411 - MinusLogProbMetric: 2.3411 - val_loss: 2.3710 - val_MinusLogProbMetric: 2.3710 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 344/1000
2023-09-16 01:26:49.750 
Epoch 344/1000 
	 loss: 2.3418, MinusLogProbMetric: 2.3418, val_loss: 2.3686, val_MinusLogProbMetric: 2.3686

Epoch 344: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3418 - MinusLogProbMetric: 2.3418 - val_loss: 2.3686 - val_MinusLogProbMetric: 2.3686 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 345/1000
2023-09-16 01:27:49.651 
Epoch 345/1000 
	 loss: 2.3412, MinusLogProbMetric: 2.3412, val_loss: 2.3700, val_MinusLogProbMetric: 2.3700

Epoch 345: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3412 - MinusLogProbMetric: 2.3412 - val_loss: 2.3700 - val_MinusLogProbMetric: 2.3700 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 346/1000
2023-09-16 01:28:49.971 
Epoch 346/1000 
	 loss: 2.3399, MinusLogProbMetric: 2.3399, val_loss: 2.3682, val_MinusLogProbMetric: 2.3682

Epoch 346: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3399 - MinusLogProbMetric: 2.3399 - val_loss: 2.3682 - val_MinusLogProbMetric: 2.3682 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 347/1000
2023-09-16 01:29:49.842 
Epoch 347/1000 
	 loss: 2.3411, MinusLogProbMetric: 2.3411, val_loss: 2.3696, val_MinusLogProbMetric: 2.3696

Epoch 347: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3411 - MinusLogProbMetric: 2.3411 - val_loss: 2.3696 - val_MinusLogProbMetric: 2.3696 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 348/1000
2023-09-16 01:30:49.645 
Epoch 348/1000 
	 loss: 2.3408, MinusLogProbMetric: 2.3408, val_loss: 2.3684, val_MinusLogProbMetric: 2.3684

Epoch 348: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3408 - MinusLogProbMetric: 2.3408 - val_loss: 2.3684 - val_MinusLogProbMetric: 2.3684 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 349/1000
2023-09-16 01:31:49.232 
Epoch 349/1000 
	 loss: 2.3401, MinusLogProbMetric: 2.3401, val_loss: 2.3712, val_MinusLogProbMetric: 2.3712

Epoch 349: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3401 - MinusLogProbMetric: 2.3401 - val_loss: 2.3712 - val_MinusLogProbMetric: 2.3712 - lr: 2.5000e-04 - 60s/epoch - 304ms/step
Epoch 350/1000
2023-09-16 01:32:49.384 
Epoch 350/1000 
	 loss: 2.3400, MinusLogProbMetric: 2.3400, val_loss: 2.3683, val_MinusLogProbMetric: 2.3683

Epoch 350: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3400 - MinusLogProbMetric: 2.3400 - val_loss: 2.3683 - val_MinusLogProbMetric: 2.3683 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 351/1000
2023-09-16 01:33:49.529 
Epoch 351/1000 
	 loss: 2.3402, MinusLogProbMetric: 2.3402, val_loss: 2.3692, val_MinusLogProbMetric: 2.3692

Epoch 351: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3402 - MinusLogProbMetric: 2.3402 - val_loss: 2.3692 - val_MinusLogProbMetric: 2.3692 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 352/1000
2023-09-16 01:34:49.811 
Epoch 352/1000 
	 loss: 2.3397, MinusLogProbMetric: 2.3397, val_loss: 2.3681, val_MinusLogProbMetric: 2.3681

Epoch 352: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3397 - MinusLogProbMetric: 2.3397 - val_loss: 2.3681 - val_MinusLogProbMetric: 2.3681 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 353/1000
2023-09-16 01:35:50.038 
Epoch 353/1000 
	 loss: 2.3396, MinusLogProbMetric: 2.3396, val_loss: 2.3678, val_MinusLogProbMetric: 2.3678

Epoch 353: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3396 - MinusLogProbMetric: 2.3396 - val_loss: 2.3678 - val_MinusLogProbMetric: 2.3678 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 354/1000
2023-09-16 01:36:50.122 
Epoch 354/1000 
	 loss: 2.3429, MinusLogProbMetric: 2.3429, val_loss: 2.3685, val_MinusLogProbMetric: 2.3685

Epoch 354: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3429 - MinusLogProbMetric: 2.3429 - val_loss: 2.3685 - val_MinusLogProbMetric: 2.3685 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 355/1000
2023-09-16 01:37:50.230 
Epoch 355/1000 
	 loss: 2.3407, MinusLogProbMetric: 2.3407, val_loss: 2.3671, val_MinusLogProbMetric: 2.3671

Epoch 355: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3407 - MinusLogProbMetric: 2.3407 - val_loss: 2.3671 - val_MinusLogProbMetric: 2.3671 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 356/1000
2023-09-16 01:38:49.963 
Epoch 356/1000 
	 loss: 2.3410, MinusLogProbMetric: 2.3410, val_loss: 2.3710, val_MinusLogProbMetric: 2.3710

Epoch 356: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3410 - MinusLogProbMetric: 2.3410 - val_loss: 2.3710 - val_MinusLogProbMetric: 2.3710 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 357/1000
2023-09-16 01:39:49.973 
Epoch 357/1000 
	 loss: 2.3408, MinusLogProbMetric: 2.3408, val_loss: 2.3679, val_MinusLogProbMetric: 2.3679

Epoch 357: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3408 - MinusLogProbMetric: 2.3408 - val_loss: 2.3679 - val_MinusLogProbMetric: 2.3679 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 358/1000
2023-09-16 01:40:50.114 
Epoch 358/1000 
	 loss: 2.3399, MinusLogProbMetric: 2.3399, val_loss: 2.3685, val_MinusLogProbMetric: 2.3685

Epoch 358: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3399 - MinusLogProbMetric: 2.3399 - val_loss: 2.3685 - val_MinusLogProbMetric: 2.3685 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 359/1000
2023-09-16 01:41:50.442 
Epoch 359/1000 
	 loss: 2.3404, MinusLogProbMetric: 2.3404, val_loss: 2.3690, val_MinusLogProbMetric: 2.3690

Epoch 359: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3404 - MinusLogProbMetric: 2.3404 - val_loss: 2.3690 - val_MinusLogProbMetric: 2.3690 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 360/1000
2023-09-16 01:42:50.449 
Epoch 360/1000 
	 loss: 2.3417, MinusLogProbMetric: 2.3417, val_loss: 2.3716, val_MinusLogProbMetric: 2.3716

Epoch 360: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3417 - MinusLogProbMetric: 2.3417 - val_loss: 2.3716 - val_MinusLogProbMetric: 2.3716 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 361/1000
2023-09-16 01:43:50.522 
Epoch 361/1000 
	 loss: 2.3414, MinusLogProbMetric: 2.3414, val_loss: 2.3693, val_MinusLogProbMetric: 2.3693

Epoch 361: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3414 - MinusLogProbMetric: 2.3414 - val_loss: 2.3693 - val_MinusLogProbMetric: 2.3693 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 362/1000
2023-09-16 01:44:49.806 
Epoch 362/1000 
	 loss: 2.3393, MinusLogProbMetric: 2.3393, val_loss: 2.3711, val_MinusLogProbMetric: 2.3711

Epoch 362: val_loss did not improve from 2.36543
196/196 - 59s - loss: 2.3393 - MinusLogProbMetric: 2.3393 - val_loss: 2.3711 - val_MinusLogProbMetric: 2.3711 - lr: 2.5000e-04 - 59s/epoch - 302ms/step
Epoch 363/1000
2023-09-16 01:45:49.767 
Epoch 363/1000 
	 loss: 2.3411, MinusLogProbMetric: 2.3411, val_loss: 2.3701, val_MinusLogProbMetric: 2.3701

Epoch 363: val_loss did not improve from 2.36543
196/196 - 60s - loss: 2.3411 - MinusLogProbMetric: 2.3411 - val_loss: 2.3701 - val_MinusLogProbMetric: 2.3701 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 364/1000
2023-09-16 01:46:49.319 
Epoch 364/1000 
	 loss: 2.3405, MinusLogProbMetric: 2.3405, val_loss: 2.3680, val_MinusLogProbMetric: 2.3680

Epoch 364: val_loss did not improve from 2.36543
Restoring model weights from the end of the best epoch: 264.
196/196 - 60s - loss: 2.3405 - MinusLogProbMetric: 2.3405 - val_loss: 2.3680 - val_MinusLogProbMetric: 2.3680 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 364: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 19.851616320200264 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 8.749102363130078 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 6.935815924080089 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fb6ebb879a0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 25.245707519119605 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 7.836621881928295 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 5.7179689151234925 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fb3001c0af0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 721.
Model trained in 22141.54 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

Plots done in 2.93 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 97.47 s.
===========
Run 53/720 done in 22249.07 s.
===========

Directory ../../results/CsplineN_new/run_54/ already exists.
Skipping it.
===========
Run 54/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_55/ already exists.
Skipping it.
===========
Run 55/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_56/ already exists.
Skipping it.
===========
Run 56/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_57/ already exists.
Skipping it.
===========
Run 57/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_58/ already exists.
Skipping it.
===========
Run 58/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_59/ already exists.
Skipping it.
===========
Run 59/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_60/ already exists.
Skipping it.
===========
Run 60/720 already exists. Skipping it.
===========

===========
Generating train data for run 61.
===========
Train data generated in 0.28 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 4)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_61/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 869}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_61/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 4.2224045,  6.3126664,  4.220428 ,  9.5536375],
       [ 5.9553733,  7.400246 ,  6.071695 ,  5.4666376],
       [ 4.2218738,  5.60354  ,  5.2988334, 10.490914 ],
       ...,
       [ 4.261398 ,  4.849532 ,  4.964608 ,  7.365599 ],
       [ 4.2277927,  7.577397 ,  3.4247391,  8.758287 ],
       [ 9.224762 ,  4.0652366,  8.090745 ,  4.5582495]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_61/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_61
self.data_kwargs: {'seed': 869}
self.x_data: [[ 4.2643785  5.3753843  3.8076253  8.415629 ]
 [ 4.2386503  7.0399632  5.982357   8.823267 ]
 [10.235745   2.7710257  7.885809   5.6953764]
 ...
 [ 4.242386   4.6672173  3.6948192  8.379883 ]
 [ 4.2246094  8.648494   5.339075   9.586297 ]
 [ 8.464835   3.7949617  7.9151964  5.820163 ]]
self.y_data: []
self.ndims: 4
Model defined.
Model: "model_32"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_33 (InputLayer)       [(None, 4)]               0         
                                                                 
 log_prob_layer_2 (LogProbLa  (None,)                  393420    
 yer)                                                            
                                                                 
=================================================================
Total params: 393,420
Trainable params: 393,420
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_2/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_2'")
self.model: <keras.engine.functional.Functional object at 0x7fb7164972b0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fb1c477fc10>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fb1c477fc10>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fb716054820>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fb22025f8e0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fb22025fe50>, <keras.callbacks.ModelCheckpoint object at 0x7fb22025ff10>, <keras.callbacks.EarlyStopping object at 0x7fb22025fe20>, <keras.callbacks.ReduceLROnPlateau object at 0x7fb22025ffd0>, <keras.callbacks.TerminateOnNaN object at 0x7fb2202b4040>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 4.2224045,  6.3126664,  4.220428 ,  9.5536375],
       [ 5.9553733,  7.400246 ,  6.071695 ,  5.4666376],
       [ 4.2218738,  5.60354  ,  5.2988334, 10.490914 ],
       ...,
       [ 4.261398 ,  4.849532 ,  4.964608 ,  7.365599 ],
       [ 4.2277927,  7.577397 ,  3.4247391,  8.758287 ],
       [ 9.224762 ,  4.0652366,  8.090745 ,  4.5582495]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_61/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 61/720 with hyperparameters:
timestamp = 2023-09-16 01:48:36.444667
ndims = 4
seed_train = 869
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 8
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 393420
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [4.2643785 5.3753843 3.8076253 8.415629 ]
Epoch 1/1000
2023-09-16 01:52:05.678 
Epoch 1/1000 
	 loss: 9.8615, MinusLogProbMetric: 9.8615, val_loss: 5.0135, val_MinusLogProbMetric: 5.0135

Epoch 1: val_loss improved from inf to 5.01349, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 210s - loss: 9.8615 - MinusLogProbMetric: 9.8615 - val_loss: 5.0135 - val_MinusLogProbMetric: 5.0135 - lr: 0.0010 - 210s/epoch - 1s/step
Epoch 2/1000
2023-09-16 01:53:09.864 
Epoch 2/1000 
	 loss: 4.6557, MinusLogProbMetric: 4.6557, val_loss: 5.8233, val_MinusLogProbMetric: 5.8233

Epoch 2: val_loss did not improve from 5.01349
196/196 - 63s - loss: 4.6557 - MinusLogProbMetric: 4.6557 - val_loss: 5.8233 - val_MinusLogProbMetric: 5.8233 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 3/1000
2023-09-16 01:54:13.299 
Epoch 3/1000 
	 loss: 4.5605, MinusLogProbMetric: 4.5605, val_loss: 3.6475, val_MinusLogProbMetric: 3.6475

Epoch 3: val_loss improved from 5.01349 to 3.64748, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 64s - loss: 4.5605 - MinusLogProbMetric: 4.5605 - val_loss: 3.6475 - val_MinusLogProbMetric: 3.6475 - lr: 0.0010 - 64s/epoch - 329ms/step
Epoch 4/1000
2023-09-16 01:55:17.784 
Epoch 4/1000 
	 loss: 3.8700, MinusLogProbMetric: 3.8700, val_loss: 4.0591, val_MinusLogProbMetric: 4.0591

Epoch 4: val_loss did not improve from 3.64748
196/196 - 63s - loss: 3.8700 - MinusLogProbMetric: 3.8700 - val_loss: 4.0591 - val_MinusLogProbMetric: 4.0591 - lr: 0.0010 - 63s/epoch - 324ms/step
Epoch 5/1000
2023-09-16 01:56:21.381 
Epoch 5/1000 
	 loss: 3.8244, MinusLogProbMetric: 3.8244, val_loss: 4.0830, val_MinusLogProbMetric: 4.0830

Epoch 5: val_loss did not improve from 3.64748
196/196 - 64s - loss: 3.8244 - MinusLogProbMetric: 3.8244 - val_loss: 4.0830 - val_MinusLogProbMetric: 4.0830 - lr: 0.0010 - 64s/epoch - 324ms/step
Epoch 6/1000
2023-09-16 01:57:23.793 
Epoch 6/1000 
	 loss: 3.8888, MinusLogProbMetric: 3.8888, val_loss: 3.6541, val_MinusLogProbMetric: 3.6541

Epoch 6: val_loss did not improve from 3.64748
196/196 - 62s - loss: 3.8888 - MinusLogProbMetric: 3.8888 - val_loss: 3.6541 - val_MinusLogProbMetric: 3.6541 - lr: 0.0010 - 62s/epoch - 318ms/step
Epoch 7/1000
2023-09-16 01:58:26.662 
Epoch 7/1000 
	 loss: 3.7918, MinusLogProbMetric: 3.7918, val_loss: 3.3328, val_MinusLogProbMetric: 3.3328

Epoch 7: val_loss improved from 3.64748 to 3.33284, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 64s - loss: 3.7918 - MinusLogProbMetric: 3.7918 - val_loss: 3.3328 - val_MinusLogProbMetric: 3.3328 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 8/1000
2023-09-16 01:59:30.495 
Epoch 8/1000 
	 loss: 3.4090, MinusLogProbMetric: 3.4090, val_loss: 3.2656, val_MinusLogProbMetric: 3.2656

Epoch 8: val_loss improved from 3.33284 to 3.26559, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 64s - loss: 3.4090 - MinusLogProbMetric: 3.4090 - val_loss: 3.2656 - val_MinusLogProbMetric: 3.2656 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 9/1000
2023-09-16 02:00:35.689 
Epoch 9/1000 
	 loss: 3.2398, MinusLogProbMetric: 3.2398, val_loss: 3.3706, val_MinusLogProbMetric: 3.3706

Epoch 9: val_loss did not improve from 3.26559
196/196 - 64s - loss: 3.2398 - MinusLogProbMetric: 3.2398 - val_loss: 3.3706 - val_MinusLogProbMetric: 3.3706 - lr: 0.0010 - 64s/epoch - 327ms/step
Epoch 10/1000
2023-09-16 02:01:40.789 
Epoch 10/1000 
	 loss: 3.1681, MinusLogProbMetric: 3.1681, val_loss: 2.7453, val_MinusLogProbMetric: 2.7453

Epoch 10: val_loss improved from 3.26559 to 2.74529, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 66s - loss: 3.1681 - MinusLogProbMetric: 3.1681 - val_loss: 2.7453 - val_MinusLogProbMetric: 2.7453 - lr: 0.0010 - 66s/epoch - 338ms/step
Epoch 11/1000
2023-09-16 02:02:46.148 
Epoch 11/1000 
	 loss: 3.1487, MinusLogProbMetric: 3.1487, val_loss: 2.8826, val_MinusLogProbMetric: 2.8826

Epoch 11: val_loss did not improve from 2.74529
196/196 - 64s - loss: 3.1487 - MinusLogProbMetric: 3.1487 - val_loss: 2.8826 - val_MinusLogProbMetric: 2.8826 - lr: 0.0010 - 64s/epoch - 328ms/step
Epoch 12/1000
2023-09-16 02:03:50.683 
Epoch 12/1000 
	 loss: 3.0930, MinusLogProbMetric: 3.0930, val_loss: 5.2252, val_MinusLogProbMetric: 5.2252

Epoch 12: val_loss did not improve from 2.74529
196/196 - 65s - loss: 3.0930 - MinusLogProbMetric: 3.0930 - val_loss: 5.2252 - val_MinusLogProbMetric: 5.2252 - lr: 0.0010 - 65s/epoch - 329ms/step
Epoch 13/1000
2023-09-16 02:04:55.571 
Epoch 13/1000 
	 loss: 3.1068, MinusLogProbMetric: 3.1068, val_loss: 3.1061, val_MinusLogProbMetric: 3.1061

Epoch 13: val_loss did not improve from 2.74529
196/196 - 65s - loss: 3.1068 - MinusLogProbMetric: 3.1068 - val_loss: 3.1061 - val_MinusLogProbMetric: 3.1061 - lr: 0.0010 - 65s/epoch - 331ms/step
Epoch 14/1000
2023-09-16 02:06:00.216 
Epoch 14/1000 
	 loss: 2.9626, MinusLogProbMetric: 2.9626, val_loss: 2.8955, val_MinusLogProbMetric: 2.8955

Epoch 14: val_loss did not improve from 2.74529
196/196 - 65s - loss: 2.9626 - MinusLogProbMetric: 2.9626 - val_loss: 2.8955 - val_MinusLogProbMetric: 2.8955 - lr: 0.0010 - 65s/epoch - 330ms/step
Epoch 15/1000
2023-09-16 02:07:03.003 
Epoch 15/1000 
	 loss: 3.0679, MinusLogProbMetric: 3.0679, val_loss: 2.7518, val_MinusLogProbMetric: 2.7518

Epoch 15: val_loss did not improve from 2.74529
196/196 - 63s - loss: 3.0679 - MinusLogProbMetric: 3.0679 - val_loss: 2.7518 - val_MinusLogProbMetric: 2.7518 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 16/1000
2023-09-16 02:08:06.163 
Epoch 16/1000 
	 loss: 2.8277, MinusLogProbMetric: 2.8277, val_loss: 2.6536, val_MinusLogProbMetric: 2.6536

Epoch 16: val_loss improved from 2.74529 to 2.65360, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 64s - loss: 2.8277 - MinusLogProbMetric: 2.8277 - val_loss: 2.6536 - val_MinusLogProbMetric: 2.6536 - lr: 0.0010 - 64s/epoch - 328ms/step
Epoch 17/1000
2023-09-16 02:09:11.136 
Epoch 17/1000 
	 loss: 2.8106, MinusLogProbMetric: 2.8106, val_loss: 2.6671, val_MinusLogProbMetric: 2.6671

Epoch 17: val_loss did not improve from 2.65360
196/196 - 64s - loss: 2.8106 - MinusLogProbMetric: 2.8106 - val_loss: 2.6671 - val_MinusLogProbMetric: 2.6671 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 18/1000
2023-09-16 02:10:14.191 
Epoch 18/1000 
	 loss: 2.8847, MinusLogProbMetric: 2.8847, val_loss: 2.5679, val_MinusLogProbMetric: 2.5679

Epoch 18: val_loss improved from 2.65360 to 2.56786, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 64s - loss: 2.8847 - MinusLogProbMetric: 2.8847 - val_loss: 2.5679 - val_MinusLogProbMetric: 2.5679 - lr: 0.0010 - 64s/epoch - 327ms/step
Epoch 19/1000
2023-09-16 02:11:18.649 
Epoch 19/1000 
	 loss: 2.7743, MinusLogProbMetric: 2.7743, val_loss: 2.9186, val_MinusLogProbMetric: 2.9186

Epoch 19: val_loss did not improve from 2.56786
196/196 - 63s - loss: 2.7743 - MinusLogProbMetric: 2.7743 - val_loss: 2.9186 - val_MinusLogProbMetric: 2.9186 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 20/1000
2023-09-16 02:12:21.320 
Epoch 20/1000 
	 loss: 2.7004, MinusLogProbMetric: 2.7004, val_loss: 2.7404, val_MinusLogProbMetric: 2.7404

Epoch 20: val_loss did not improve from 2.56786
196/196 - 63s - loss: 2.7004 - MinusLogProbMetric: 2.7004 - val_loss: 2.7404 - val_MinusLogProbMetric: 2.7404 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 21/1000
2023-09-16 02:13:24.705 
Epoch 21/1000 
	 loss: 2.6363, MinusLogProbMetric: 2.6363, val_loss: 2.6257, val_MinusLogProbMetric: 2.6257

Epoch 21: val_loss did not improve from 2.56786
196/196 - 63s - loss: 2.6363 - MinusLogProbMetric: 2.6363 - val_loss: 2.6257 - val_MinusLogProbMetric: 2.6257 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 22/1000
2023-09-16 02:14:27.568 
Epoch 22/1000 
	 loss: 2.6663, MinusLogProbMetric: 2.6663, val_loss: 2.8396, val_MinusLogProbMetric: 2.8396

Epoch 22: val_loss did not improve from 2.56786
196/196 - 63s - loss: 2.6663 - MinusLogProbMetric: 2.6663 - val_loss: 2.8396 - val_MinusLogProbMetric: 2.8396 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 23/1000
2023-09-16 02:15:30.605 
Epoch 23/1000 
	 loss: 2.6576, MinusLogProbMetric: 2.6576, val_loss: 2.5134, val_MinusLogProbMetric: 2.5134

Epoch 23: val_loss improved from 2.56786 to 2.51343, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 64s - loss: 2.6576 - MinusLogProbMetric: 2.6576 - val_loss: 2.5134 - val_MinusLogProbMetric: 2.5134 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 24/1000
2023-09-16 02:16:34.830 
Epoch 24/1000 
	 loss: 2.6815, MinusLogProbMetric: 2.6815, val_loss: 2.4634, val_MinusLogProbMetric: 2.4634

Epoch 24: val_loss improved from 2.51343 to 2.46335, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 65s - loss: 2.6815 - MinusLogProbMetric: 2.6815 - val_loss: 2.4634 - val_MinusLogProbMetric: 2.4634 - lr: 0.0010 - 65s/epoch - 329ms/step
Epoch 25/1000
2023-09-16 02:17:38.103 
Epoch 25/1000 
	 loss: 2.6005, MinusLogProbMetric: 2.6005, val_loss: 2.4454, val_MinusLogProbMetric: 2.4454

Epoch 25: val_loss improved from 2.46335 to 2.44536, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 63s - loss: 2.6005 - MinusLogProbMetric: 2.6005 - val_loss: 2.4454 - val_MinusLogProbMetric: 2.4454 - lr: 0.0010 - 63s/epoch - 322ms/step
Epoch 26/1000
2023-09-16 02:18:42.639 
Epoch 26/1000 
	 loss: 2.6280, MinusLogProbMetric: 2.6280, val_loss: 3.3974, val_MinusLogProbMetric: 3.3974

Epoch 26: val_loss did not improve from 2.44536
196/196 - 64s - loss: 2.6280 - MinusLogProbMetric: 2.6280 - val_loss: 3.3974 - val_MinusLogProbMetric: 3.3974 - lr: 0.0010 - 64s/epoch - 324ms/step
Epoch 27/1000
2023-09-16 02:19:45.019 
Epoch 27/1000 
	 loss: 2.5661, MinusLogProbMetric: 2.5661, val_loss: 2.4482, val_MinusLogProbMetric: 2.4482

Epoch 27: val_loss did not improve from 2.44536
196/196 - 62s - loss: 2.5661 - MinusLogProbMetric: 2.5661 - val_loss: 2.4482 - val_MinusLogProbMetric: 2.4482 - lr: 0.0010 - 62s/epoch - 318ms/step
Epoch 28/1000
2023-09-16 02:20:48.410 
Epoch 28/1000 
	 loss: 2.5849, MinusLogProbMetric: 2.5849, val_loss: 2.5631, val_MinusLogProbMetric: 2.5631

Epoch 28: val_loss did not improve from 2.44536
196/196 - 63s - loss: 2.5849 - MinusLogProbMetric: 2.5849 - val_loss: 2.5631 - val_MinusLogProbMetric: 2.5631 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 29/1000
2023-09-16 02:21:46.476 
Epoch 29/1000 
	 loss: 2.5628, MinusLogProbMetric: 2.5628, val_loss: 2.5286, val_MinusLogProbMetric: 2.5286

Epoch 29: val_loss did not improve from 2.44536
196/196 - 58s - loss: 2.5628 - MinusLogProbMetric: 2.5628 - val_loss: 2.5286 - val_MinusLogProbMetric: 2.5286 - lr: 0.0010 - 58s/epoch - 296ms/step
Epoch 30/1000
2023-09-16 02:22:42.105 
Epoch 30/1000 
	 loss: 2.5447, MinusLogProbMetric: 2.5447, val_loss: 2.4606, val_MinusLogProbMetric: 2.4606

Epoch 30: val_loss did not improve from 2.44536
196/196 - 56s - loss: 2.5447 - MinusLogProbMetric: 2.5447 - val_loss: 2.4606 - val_MinusLogProbMetric: 2.4606 - lr: 0.0010 - 56s/epoch - 284ms/step
Epoch 31/1000
2023-09-16 02:23:43.274 
Epoch 31/1000 
	 loss: 2.5465, MinusLogProbMetric: 2.5465, val_loss: 2.4205, val_MinusLogProbMetric: 2.4205

Epoch 31: val_loss improved from 2.44536 to 2.42053, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 62s - loss: 2.5465 - MinusLogProbMetric: 2.5465 - val_loss: 2.4205 - val_MinusLogProbMetric: 2.4205 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 32/1000
2023-09-16 02:24:48.120 
Epoch 32/1000 
	 loss: 2.5400, MinusLogProbMetric: 2.5400, val_loss: 2.5737, val_MinusLogProbMetric: 2.5737

Epoch 32: val_loss did not improve from 2.42053
196/196 - 64s - loss: 2.5400 - MinusLogProbMetric: 2.5400 - val_loss: 2.5737 - val_MinusLogProbMetric: 2.5737 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 33/1000
2023-09-16 02:25:50.962 
Epoch 33/1000 
	 loss: 2.5361, MinusLogProbMetric: 2.5361, val_loss: 2.4468, val_MinusLogProbMetric: 2.4468

Epoch 33: val_loss did not improve from 2.42053
196/196 - 63s - loss: 2.5361 - MinusLogProbMetric: 2.5361 - val_loss: 2.4468 - val_MinusLogProbMetric: 2.4468 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 34/1000
2023-09-16 02:26:52.304 
Epoch 34/1000 
	 loss: 2.5503, MinusLogProbMetric: 2.5503, val_loss: 2.5107, val_MinusLogProbMetric: 2.5107

Epoch 34: val_loss did not improve from 2.42053
196/196 - 61s - loss: 2.5503 - MinusLogProbMetric: 2.5503 - val_loss: 2.5107 - val_MinusLogProbMetric: 2.5107 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 35/1000
2023-09-16 02:27:53.255 
Epoch 35/1000 
	 loss: 2.5072, MinusLogProbMetric: 2.5072, val_loss: 2.5352, val_MinusLogProbMetric: 2.5352

Epoch 35: val_loss did not improve from 2.42053
196/196 - 61s - loss: 2.5072 - MinusLogProbMetric: 2.5072 - val_loss: 2.5352 - val_MinusLogProbMetric: 2.5352 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 36/1000
2023-09-16 02:28:55.744 
Epoch 36/1000 
	 loss: 2.5133, MinusLogProbMetric: 2.5133, val_loss: 2.6062, val_MinusLogProbMetric: 2.6062

Epoch 36: val_loss did not improve from 2.42053
196/196 - 62s - loss: 2.5133 - MinusLogProbMetric: 2.5133 - val_loss: 2.6062 - val_MinusLogProbMetric: 2.6062 - lr: 0.0010 - 62s/epoch - 319ms/step
Epoch 37/1000
2023-09-16 02:29:57.889 
Epoch 37/1000 
	 loss: 2.5026, MinusLogProbMetric: 2.5026, val_loss: 2.9575, val_MinusLogProbMetric: 2.9575

Epoch 37: val_loss did not improve from 2.42053
196/196 - 62s - loss: 2.5026 - MinusLogProbMetric: 2.5026 - val_loss: 2.9575 - val_MinusLogProbMetric: 2.9575 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 38/1000
2023-09-16 02:30:59.600 
Epoch 38/1000 
	 loss: 2.4837, MinusLogProbMetric: 2.4837, val_loss: 2.4380, val_MinusLogProbMetric: 2.4380

Epoch 38: val_loss did not improve from 2.42053
196/196 - 62s - loss: 2.4837 - MinusLogProbMetric: 2.4837 - val_loss: 2.4380 - val_MinusLogProbMetric: 2.4380 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 39/1000
2023-09-16 02:32:01.231 
Epoch 39/1000 
	 loss: 2.5191, MinusLogProbMetric: 2.5191, val_loss: 2.8114, val_MinusLogProbMetric: 2.8114

Epoch 39: val_loss did not improve from 2.42053
196/196 - 62s - loss: 2.5191 - MinusLogProbMetric: 2.5191 - val_loss: 2.8114 - val_MinusLogProbMetric: 2.8114 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 40/1000
2023-09-16 02:33:03.442 
Epoch 40/1000 
	 loss: 2.5032, MinusLogProbMetric: 2.5032, val_loss: 2.4360, val_MinusLogProbMetric: 2.4360

Epoch 40: val_loss did not improve from 2.42053
196/196 - 62s - loss: 2.5032 - MinusLogProbMetric: 2.5032 - val_loss: 2.4360 - val_MinusLogProbMetric: 2.4360 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 41/1000
2023-09-16 02:34:04.789 
Epoch 41/1000 
	 loss: 2.4916, MinusLogProbMetric: 2.4916, val_loss: 2.4506, val_MinusLogProbMetric: 2.4506

Epoch 41: val_loss did not improve from 2.42053
196/196 - 61s - loss: 2.4916 - MinusLogProbMetric: 2.4916 - val_loss: 2.4506 - val_MinusLogProbMetric: 2.4506 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 42/1000
2023-09-16 02:35:06.264 
Epoch 42/1000 
	 loss: 2.5036, MinusLogProbMetric: 2.5036, val_loss: 2.4610, val_MinusLogProbMetric: 2.4610

Epoch 42: val_loss did not improve from 2.42053
196/196 - 61s - loss: 2.5036 - MinusLogProbMetric: 2.5036 - val_loss: 2.4610 - val_MinusLogProbMetric: 2.4610 - lr: 0.0010 - 61s/epoch - 314ms/step
Epoch 43/1000
2023-09-16 02:36:07.714 
Epoch 43/1000 
	 loss: 2.5142, MinusLogProbMetric: 2.5142, val_loss: 2.5335, val_MinusLogProbMetric: 2.5335

Epoch 43: val_loss did not improve from 2.42053
196/196 - 61s - loss: 2.5142 - MinusLogProbMetric: 2.5142 - val_loss: 2.5335 - val_MinusLogProbMetric: 2.5335 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 44/1000
2023-09-16 02:37:10.250 
Epoch 44/1000 
	 loss: 2.4939, MinusLogProbMetric: 2.4939, val_loss: 2.4720, val_MinusLogProbMetric: 2.4720

Epoch 44: val_loss did not improve from 2.42053
196/196 - 63s - loss: 2.4939 - MinusLogProbMetric: 2.4939 - val_loss: 2.4720 - val_MinusLogProbMetric: 2.4720 - lr: 0.0010 - 63s/epoch - 319ms/step
Epoch 45/1000
2023-09-16 02:38:11.845 
Epoch 45/1000 
	 loss: 2.4548, MinusLogProbMetric: 2.4548, val_loss: 2.4866, val_MinusLogProbMetric: 2.4866

Epoch 45: val_loss did not improve from 2.42053
196/196 - 62s - loss: 2.4548 - MinusLogProbMetric: 2.4548 - val_loss: 2.4866 - val_MinusLogProbMetric: 2.4866 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 46/1000
2023-09-16 02:39:13.780 
Epoch 46/1000 
	 loss: 2.4736, MinusLogProbMetric: 2.4736, val_loss: 2.5251, val_MinusLogProbMetric: 2.5251

Epoch 46: val_loss did not improve from 2.42053
196/196 - 62s - loss: 2.4736 - MinusLogProbMetric: 2.4736 - val_loss: 2.5251 - val_MinusLogProbMetric: 2.5251 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 47/1000
2023-09-16 02:40:14.740 
Epoch 47/1000 
	 loss: 2.4780, MinusLogProbMetric: 2.4780, val_loss: 2.4535, val_MinusLogProbMetric: 2.4535

Epoch 47: val_loss did not improve from 2.42053
196/196 - 61s - loss: 2.4780 - MinusLogProbMetric: 2.4780 - val_loss: 2.4535 - val_MinusLogProbMetric: 2.4535 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 48/1000
2023-09-16 02:41:16.069 
Epoch 48/1000 
	 loss: 2.4857, MinusLogProbMetric: 2.4857, val_loss: 2.5123, val_MinusLogProbMetric: 2.5123

Epoch 48: val_loss did not improve from 2.42053
196/196 - 61s - loss: 2.4857 - MinusLogProbMetric: 2.4857 - val_loss: 2.5123 - val_MinusLogProbMetric: 2.5123 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 49/1000
2023-09-16 02:42:17.663 
Epoch 49/1000 
	 loss: 2.4737, MinusLogProbMetric: 2.4737, val_loss: 2.4469, val_MinusLogProbMetric: 2.4469

Epoch 49: val_loss did not improve from 2.42053
196/196 - 62s - loss: 2.4737 - MinusLogProbMetric: 2.4737 - val_loss: 2.4469 - val_MinusLogProbMetric: 2.4469 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 50/1000
2023-09-16 02:43:19.836 
Epoch 50/1000 
	 loss: 2.4604, MinusLogProbMetric: 2.4604, val_loss: 2.4311, val_MinusLogProbMetric: 2.4311

Epoch 50: val_loss did not improve from 2.42053
196/196 - 62s - loss: 2.4604 - MinusLogProbMetric: 2.4604 - val_loss: 2.4311 - val_MinusLogProbMetric: 2.4311 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 51/1000
2023-09-16 02:44:22.021 
Epoch 51/1000 
	 loss: 2.4675, MinusLogProbMetric: 2.4675, val_loss: 2.7840, val_MinusLogProbMetric: 2.7840

Epoch 51: val_loss did not improve from 2.42053
196/196 - 62s - loss: 2.4675 - MinusLogProbMetric: 2.4675 - val_loss: 2.7840 - val_MinusLogProbMetric: 2.7840 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 52/1000
2023-09-16 02:45:23.391 
Epoch 52/1000 
	 loss: 2.4958, MinusLogProbMetric: 2.4958, val_loss: 2.5148, val_MinusLogProbMetric: 2.5148

Epoch 52: val_loss did not improve from 2.42053
196/196 - 61s - loss: 2.4958 - MinusLogProbMetric: 2.4958 - val_loss: 2.5148 - val_MinusLogProbMetric: 2.5148 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 53/1000
2023-09-16 02:46:25.208 
Epoch 53/1000 
	 loss: 2.4358, MinusLogProbMetric: 2.4358, val_loss: 2.4042, val_MinusLogProbMetric: 2.4042

Epoch 53: val_loss improved from 2.42053 to 2.40421, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 63s - loss: 2.4358 - MinusLogProbMetric: 2.4358 - val_loss: 2.4042 - val_MinusLogProbMetric: 2.4042 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 54/1000
2023-09-16 02:47:27.443 
Epoch 54/1000 
	 loss: 2.4620, MinusLogProbMetric: 2.4620, val_loss: 2.4067, val_MinusLogProbMetric: 2.4067

Epoch 54: val_loss did not improve from 2.40421
196/196 - 61s - loss: 2.4620 - MinusLogProbMetric: 2.4620 - val_loss: 2.4067 - val_MinusLogProbMetric: 2.4067 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 55/1000
2023-09-16 02:48:28.359 
Epoch 55/1000 
	 loss: 2.4649, MinusLogProbMetric: 2.4649, val_loss: 2.4417, val_MinusLogProbMetric: 2.4417

Epoch 55: val_loss did not improve from 2.40421
196/196 - 61s - loss: 2.4649 - MinusLogProbMetric: 2.4649 - val_loss: 2.4417 - val_MinusLogProbMetric: 2.4417 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 56/1000
2023-09-16 02:49:29.418 
Epoch 56/1000 
	 loss: 2.4562, MinusLogProbMetric: 2.4562, val_loss: 2.4049, val_MinusLogProbMetric: 2.4049

Epoch 56: val_loss did not improve from 2.40421
196/196 - 61s - loss: 2.4562 - MinusLogProbMetric: 2.4562 - val_loss: 2.4049 - val_MinusLogProbMetric: 2.4049 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 57/1000
2023-09-16 02:50:31.049 
Epoch 57/1000 
	 loss: 2.4452, MinusLogProbMetric: 2.4452, val_loss: 2.7552, val_MinusLogProbMetric: 2.7552

Epoch 57: val_loss did not improve from 2.40421
196/196 - 62s - loss: 2.4452 - MinusLogProbMetric: 2.4452 - val_loss: 2.7552 - val_MinusLogProbMetric: 2.7552 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 58/1000
2023-09-16 02:51:32.758 
Epoch 58/1000 
	 loss: 2.4810, MinusLogProbMetric: 2.4810, val_loss: 2.3912, val_MinusLogProbMetric: 2.3912

Epoch 58: val_loss improved from 2.40421 to 2.39119, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 63s - loss: 2.4810 - MinusLogProbMetric: 2.4810 - val_loss: 2.3912 - val_MinusLogProbMetric: 2.3912 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 59/1000
2023-09-16 02:52:35.415 
Epoch 59/1000 
	 loss: 2.4376, MinusLogProbMetric: 2.4376, val_loss: 2.3920, val_MinusLogProbMetric: 2.3920

Epoch 59: val_loss did not improve from 2.39119
196/196 - 61s - loss: 2.4376 - MinusLogProbMetric: 2.4376 - val_loss: 2.3920 - val_MinusLogProbMetric: 2.3920 - lr: 0.0010 - 61s/epoch - 314ms/step
Epoch 60/1000
2023-09-16 02:53:37.203 
Epoch 60/1000 
	 loss: 2.4417, MinusLogProbMetric: 2.4417, val_loss: 2.4269, val_MinusLogProbMetric: 2.4269

Epoch 60: val_loss did not improve from 2.39119
196/196 - 62s - loss: 2.4417 - MinusLogProbMetric: 2.4417 - val_loss: 2.4269 - val_MinusLogProbMetric: 2.4269 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 61/1000
2023-09-16 02:54:38.718 
Epoch 61/1000 
	 loss: 2.4625, MinusLogProbMetric: 2.4625, val_loss: 2.3935, val_MinusLogProbMetric: 2.3935

Epoch 61: val_loss did not improve from 2.39119
196/196 - 62s - loss: 2.4625 - MinusLogProbMetric: 2.4625 - val_loss: 2.3935 - val_MinusLogProbMetric: 2.3935 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 62/1000
2023-09-16 02:55:40.398 
Epoch 62/1000 
	 loss: 2.4330, MinusLogProbMetric: 2.4330, val_loss: 2.5163, val_MinusLogProbMetric: 2.5163

Epoch 62: val_loss did not improve from 2.39119
196/196 - 62s - loss: 2.4330 - MinusLogProbMetric: 2.4330 - val_loss: 2.5163 - val_MinusLogProbMetric: 2.5163 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 63/1000
2023-09-16 02:56:42.002 
Epoch 63/1000 
	 loss: 2.4477, MinusLogProbMetric: 2.4477, val_loss: 2.4173, val_MinusLogProbMetric: 2.4173

Epoch 63: val_loss did not improve from 2.39119
196/196 - 62s - loss: 2.4477 - MinusLogProbMetric: 2.4477 - val_loss: 2.4173 - val_MinusLogProbMetric: 2.4173 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 64/1000
2023-09-16 02:57:43.650 
Epoch 64/1000 
	 loss: 2.4421, MinusLogProbMetric: 2.4421, val_loss: 2.5296, val_MinusLogProbMetric: 2.5296

Epoch 64: val_loss did not improve from 2.39119
196/196 - 62s - loss: 2.4421 - MinusLogProbMetric: 2.4421 - val_loss: 2.5296 - val_MinusLogProbMetric: 2.5296 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 65/1000
2023-09-16 02:58:45.227 
Epoch 65/1000 
	 loss: 2.4378, MinusLogProbMetric: 2.4378, val_loss: 2.5570, val_MinusLogProbMetric: 2.5570

Epoch 65: val_loss did not improve from 2.39119
196/196 - 62s - loss: 2.4378 - MinusLogProbMetric: 2.4378 - val_loss: 2.5570 - val_MinusLogProbMetric: 2.5570 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 66/1000
2023-09-16 02:59:46.719 
Epoch 66/1000 
	 loss: 2.4633, MinusLogProbMetric: 2.4633, val_loss: 2.4057, val_MinusLogProbMetric: 2.4057

Epoch 66: val_loss did not improve from 2.39119
196/196 - 61s - loss: 2.4633 - MinusLogProbMetric: 2.4633 - val_loss: 2.4057 - val_MinusLogProbMetric: 2.4057 - lr: 0.0010 - 61s/epoch - 314ms/step
Epoch 67/1000
2023-09-16 03:00:48.186 
Epoch 67/1000 
	 loss: 2.4313, MinusLogProbMetric: 2.4313, val_loss: 2.5707, val_MinusLogProbMetric: 2.5707

Epoch 67: val_loss did not improve from 2.39119
196/196 - 61s - loss: 2.4313 - MinusLogProbMetric: 2.4313 - val_loss: 2.5707 - val_MinusLogProbMetric: 2.5707 - lr: 0.0010 - 61s/epoch - 314ms/step
Epoch 68/1000
2023-09-16 03:01:49.501 
Epoch 68/1000 
	 loss: 2.4460, MinusLogProbMetric: 2.4460, val_loss: 2.4811, val_MinusLogProbMetric: 2.4811

Epoch 68: val_loss did not improve from 2.39119
196/196 - 61s - loss: 2.4460 - MinusLogProbMetric: 2.4460 - val_loss: 2.4811 - val_MinusLogProbMetric: 2.4811 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 69/1000
2023-09-16 03:02:48.183 
Epoch 69/1000 
	 loss: 2.4337, MinusLogProbMetric: 2.4337, val_loss: 2.4067, val_MinusLogProbMetric: 2.4067

Epoch 69: val_loss did not improve from 2.39119
196/196 - 59s - loss: 2.4337 - MinusLogProbMetric: 2.4337 - val_loss: 2.4067 - val_MinusLogProbMetric: 2.4067 - lr: 0.0010 - 59s/epoch - 299ms/step
Epoch 70/1000
2023-09-16 03:03:44.016 
Epoch 70/1000 
	 loss: 2.4422, MinusLogProbMetric: 2.4422, val_loss: 2.4973, val_MinusLogProbMetric: 2.4973

Epoch 70: val_loss did not improve from 2.39119
196/196 - 56s - loss: 2.4422 - MinusLogProbMetric: 2.4422 - val_loss: 2.4973 - val_MinusLogProbMetric: 2.4973 - lr: 0.0010 - 56s/epoch - 285ms/step
Epoch 71/1000
2023-09-16 03:04:41.141 
Epoch 71/1000 
	 loss: 2.4481, MinusLogProbMetric: 2.4481, val_loss: 2.4576, val_MinusLogProbMetric: 2.4576

Epoch 71: val_loss did not improve from 2.39119
196/196 - 57s - loss: 2.4481 - MinusLogProbMetric: 2.4481 - val_loss: 2.4576 - val_MinusLogProbMetric: 2.4576 - lr: 0.0010 - 57s/epoch - 291ms/step
Epoch 72/1000
2023-09-16 03:05:44.995 
Epoch 72/1000 
	 loss: 2.4442, MinusLogProbMetric: 2.4442, val_loss: 2.4237, val_MinusLogProbMetric: 2.4237

Epoch 72: val_loss did not improve from 2.39119
196/196 - 64s - loss: 2.4442 - MinusLogProbMetric: 2.4442 - val_loss: 2.4237 - val_MinusLogProbMetric: 2.4237 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 73/1000
2023-09-16 03:06:48.722 
Epoch 73/1000 
	 loss: 2.4451, MinusLogProbMetric: 2.4451, val_loss: 2.3966, val_MinusLogProbMetric: 2.3966

Epoch 73: val_loss did not improve from 2.39119
196/196 - 64s - loss: 2.4451 - MinusLogProbMetric: 2.4451 - val_loss: 2.3966 - val_MinusLogProbMetric: 2.3966 - lr: 0.0010 - 64s/epoch - 325ms/step
Epoch 74/1000
2023-09-16 03:07:53.278 
Epoch 74/1000 
	 loss: 2.4330, MinusLogProbMetric: 2.4330, val_loss: 2.3991, val_MinusLogProbMetric: 2.3991

Epoch 74: val_loss did not improve from 2.39119
196/196 - 65s - loss: 2.4330 - MinusLogProbMetric: 2.4330 - val_loss: 2.3991 - val_MinusLogProbMetric: 2.3991 - lr: 0.0010 - 65s/epoch - 329ms/step
Epoch 75/1000
2023-09-16 03:08:54.305 
Epoch 75/1000 
	 loss: 2.4199, MinusLogProbMetric: 2.4199, val_loss: 2.3879, val_MinusLogProbMetric: 2.3879

Epoch 75: val_loss improved from 2.39119 to 2.38791, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 62s - loss: 2.4199 - MinusLogProbMetric: 2.4199 - val_loss: 2.3879 - val_MinusLogProbMetric: 2.3879 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 76/1000
2023-09-16 03:09:56.720 
Epoch 76/1000 
	 loss: 2.4388, MinusLogProbMetric: 2.4388, val_loss: 2.5286, val_MinusLogProbMetric: 2.5286

Epoch 76: val_loss did not improve from 2.38791
196/196 - 61s - loss: 2.4388 - MinusLogProbMetric: 2.4388 - val_loss: 2.5286 - val_MinusLogProbMetric: 2.5286 - lr: 0.0010 - 61s/epoch - 314ms/step
Epoch 77/1000
2023-09-16 03:10:58.286 
Epoch 77/1000 
	 loss: 2.4185, MinusLogProbMetric: 2.4185, val_loss: 2.3940, val_MinusLogProbMetric: 2.3940

Epoch 77: val_loss did not improve from 2.38791
196/196 - 62s - loss: 2.4185 - MinusLogProbMetric: 2.4185 - val_loss: 2.3940 - val_MinusLogProbMetric: 2.3940 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 78/1000
2023-09-16 03:11:59.123 
Epoch 78/1000 
	 loss: 2.4403, MinusLogProbMetric: 2.4403, val_loss: 2.4118, val_MinusLogProbMetric: 2.4118

Epoch 78: val_loss did not improve from 2.38791
196/196 - 61s - loss: 2.4403 - MinusLogProbMetric: 2.4403 - val_loss: 2.4118 - val_MinusLogProbMetric: 2.4118 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 79/1000
2023-09-16 03:12:59.788 
Epoch 79/1000 
	 loss: 2.4233, MinusLogProbMetric: 2.4233, val_loss: 2.3955, val_MinusLogProbMetric: 2.3955

Epoch 79: val_loss did not improve from 2.38791
196/196 - 61s - loss: 2.4233 - MinusLogProbMetric: 2.4233 - val_loss: 2.3955 - val_MinusLogProbMetric: 2.3955 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 80/1000
2023-09-16 03:14:01.342 
Epoch 80/1000 
	 loss: 2.4453, MinusLogProbMetric: 2.4453, val_loss: 2.4274, val_MinusLogProbMetric: 2.4274

Epoch 80: val_loss did not improve from 2.38791
196/196 - 62s - loss: 2.4453 - MinusLogProbMetric: 2.4453 - val_loss: 2.4274 - val_MinusLogProbMetric: 2.4274 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 81/1000
2023-09-16 03:15:02.772 
Epoch 81/1000 
	 loss: 2.4235, MinusLogProbMetric: 2.4235, val_loss: 2.4098, val_MinusLogProbMetric: 2.4098

Epoch 81: val_loss did not improve from 2.38791
196/196 - 61s - loss: 2.4235 - MinusLogProbMetric: 2.4235 - val_loss: 2.4098 - val_MinusLogProbMetric: 2.4098 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 82/1000
2023-09-16 03:16:04.938 
Epoch 82/1000 
	 loss: 2.4257, MinusLogProbMetric: 2.4257, val_loss: 2.4138, val_MinusLogProbMetric: 2.4138

Epoch 82: val_loss did not improve from 2.38791
196/196 - 62s - loss: 2.4257 - MinusLogProbMetric: 2.4257 - val_loss: 2.4138 - val_MinusLogProbMetric: 2.4138 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 83/1000
2023-09-16 03:17:06.367 
Epoch 83/1000 
	 loss: 2.4306, MinusLogProbMetric: 2.4306, val_loss: 2.3905, val_MinusLogProbMetric: 2.3905

Epoch 83: val_loss did not improve from 2.38791
196/196 - 61s - loss: 2.4306 - MinusLogProbMetric: 2.4306 - val_loss: 2.3905 - val_MinusLogProbMetric: 2.3905 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 84/1000
2023-09-16 03:18:08.100 
Epoch 84/1000 
	 loss: 2.4272, MinusLogProbMetric: 2.4272, val_loss: 2.5048, val_MinusLogProbMetric: 2.5048

Epoch 84: val_loss did not improve from 2.38791
196/196 - 62s - loss: 2.4272 - MinusLogProbMetric: 2.4272 - val_loss: 2.5048 - val_MinusLogProbMetric: 2.5048 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 85/1000
2023-09-16 03:19:10.209 
Epoch 85/1000 
	 loss: 2.4188, MinusLogProbMetric: 2.4188, val_loss: 2.4011, val_MinusLogProbMetric: 2.4011

Epoch 85: val_loss did not improve from 2.38791
196/196 - 62s - loss: 2.4188 - MinusLogProbMetric: 2.4188 - val_loss: 2.4011 - val_MinusLogProbMetric: 2.4011 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 86/1000
2023-09-16 03:20:12.624 
Epoch 86/1000 
	 loss: 2.4308, MinusLogProbMetric: 2.4308, val_loss: 2.3937, val_MinusLogProbMetric: 2.3937

Epoch 86: val_loss did not improve from 2.38791
196/196 - 62s - loss: 2.4308 - MinusLogProbMetric: 2.4308 - val_loss: 2.3937 - val_MinusLogProbMetric: 2.3937 - lr: 0.0010 - 62s/epoch - 318ms/step
Epoch 87/1000
2023-09-16 03:21:13.749 
Epoch 87/1000 
	 loss: 2.4131, MinusLogProbMetric: 2.4131, val_loss: 2.5420, val_MinusLogProbMetric: 2.5420

Epoch 87: val_loss did not improve from 2.38791
196/196 - 61s - loss: 2.4131 - MinusLogProbMetric: 2.4131 - val_loss: 2.5420 - val_MinusLogProbMetric: 2.5420 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 88/1000
2023-09-16 03:22:15.741 
Epoch 88/1000 
	 loss: 2.4188, MinusLogProbMetric: 2.4188, val_loss: 2.4623, val_MinusLogProbMetric: 2.4623

Epoch 88: val_loss did not improve from 2.38791
196/196 - 62s - loss: 2.4188 - MinusLogProbMetric: 2.4188 - val_loss: 2.4623 - val_MinusLogProbMetric: 2.4623 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 89/1000
2023-09-16 03:23:17.710 
Epoch 89/1000 
	 loss: 2.4208, MinusLogProbMetric: 2.4208, val_loss: 2.3790, val_MinusLogProbMetric: 2.3790

Epoch 89: val_loss improved from 2.38791 to 2.37905, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 63s - loss: 2.4208 - MinusLogProbMetric: 2.4208 - val_loss: 2.3790 - val_MinusLogProbMetric: 2.3790 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 90/1000
2023-09-16 03:24:12.129 
Epoch 90/1000 
	 loss: 2.4296, MinusLogProbMetric: 2.4296, val_loss: 2.3842, val_MinusLogProbMetric: 2.3842

Epoch 90: val_loss did not improve from 2.37905
196/196 - 54s - loss: 2.4296 - MinusLogProbMetric: 2.4296 - val_loss: 2.3842 - val_MinusLogProbMetric: 2.3842 - lr: 0.0010 - 54s/epoch - 273ms/step
Epoch 91/1000
2023-09-16 03:25:05.413 
Epoch 91/1000 
	 loss: 2.4261, MinusLogProbMetric: 2.4261, val_loss: 2.4873, val_MinusLogProbMetric: 2.4873

Epoch 91: val_loss did not improve from 2.37905
196/196 - 53s - loss: 2.4261 - MinusLogProbMetric: 2.4261 - val_loss: 2.4873 - val_MinusLogProbMetric: 2.4873 - lr: 0.0010 - 53s/epoch - 272ms/step
Epoch 92/1000
2023-09-16 03:25:56.994 
Epoch 92/1000 
	 loss: 2.4232, MinusLogProbMetric: 2.4232, val_loss: 2.4203, val_MinusLogProbMetric: 2.4203

Epoch 92: val_loss did not improve from 2.37905
196/196 - 52s - loss: 2.4232 - MinusLogProbMetric: 2.4232 - val_loss: 2.4203 - val_MinusLogProbMetric: 2.4203 - lr: 0.0010 - 52s/epoch - 263ms/step
Epoch 93/1000
2023-09-16 03:26:53.551 
Epoch 93/1000 
	 loss: 2.4333, MinusLogProbMetric: 2.4333, val_loss: 2.3971, val_MinusLogProbMetric: 2.3971

Epoch 93: val_loss did not improve from 2.37905
196/196 - 57s - loss: 2.4333 - MinusLogProbMetric: 2.4333 - val_loss: 2.3971 - val_MinusLogProbMetric: 2.3971 - lr: 0.0010 - 57s/epoch - 289ms/step
Epoch 94/1000
2023-09-16 03:27:57.336 
Epoch 94/1000 
	 loss: 2.4249, MinusLogProbMetric: 2.4249, val_loss: 2.4079, val_MinusLogProbMetric: 2.4079

Epoch 94: val_loss did not improve from 2.37905
196/196 - 64s - loss: 2.4249 - MinusLogProbMetric: 2.4249 - val_loss: 2.4079 - val_MinusLogProbMetric: 2.4079 - lr: 0.0010 - 64s/epoch - 325ms/step
Epoch 95/1000
2023-09-16 03:28:59.305 
Epoch 95/1000 
	 loss: 2.4206, MinusLogProbMetric: 2.4206, val_loss: 2.5369, val_MinusLogProbMetric: 2.5369

Epoch 95: val_loss did not improve from 2.37905
196/196 - 62s - loss: 2.4206 - MinusLogProbMetric: 2.4206 - val_loss: 2.5369 - val_MinusLogProbMetric: 2.5369 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 96/1000
2023-09-16 03:30:00.990 
Epoch 96/1000 
	 loss: 2.4266, MinusLogProbMetric: 2.4266, val_loss: 2.4662, val_MinusLogProbMetric: 2.4662

Epoch 96: val_loss did not improve from 2.37905
196/196 - 62s - loss: 2.4266 - MinusLogProbMetric: 2.4266 - val_loss: 2.4662 - val_MinusLogProbMetric: 2.4662 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 97/1000
2023-09-16 03:31:03.183 
Epoch 97/1000 
	 loss: 2.4329, MinusLogProbMetric: 2.4329, val_loss: 2.4714, val_MinusLogProbMetric: 2.4714

Epoch 97: val_loss did not improve from 2.37905
196/196 - 62s - loss: 2.4329 - MinusLogProbMetric: 2.4329 - val_loss: 2.4714 - val_MinusLogProbMetric: 2.4714 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 98/1000
2023-09-16 03:32:05.975 
Epoch 98/1000 
	 loss: 2.4293, MinusLogProbMetric: 2.4293, val_loss: 2.3941, val_MinusLogProbMetric: 2.3941

Epoch 98: val_loss did not improve from 2.37905
196/196 - 63s - loss: 2.4293 - MinusLogProbMetric: 2.4293 - val_loss: 2.3941 - val_MinusLogProbMetric: 2.3941 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 99/1000
2023-09-16 03:33:07.412 
Epoch 99/1000 
	 loss: 2.4246, MinusLogProbMetric: 2.4246, val_loss: 2.3887, val_MinusLogProbMetric: 2.3887

Epoch 99: val_loss did not improve from 2.37905
196/196 - 61s - loss: 2.4246 - MinusLogProbMetric: 2.4246 - val_loss: 2.3887 - val_MinusLogProbMetric: 2.3887 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 100/1000
2023-09-16 03:34:09.821 
Epoch 100/1000 
	 loss: 2.4163, MinusLogProbMetric: 2.4163, val_loss: 2.3779, val_MinusLogProbMetric: 2.3779

Epoch 100: val_loss improved from 2.37905 to 2.37788, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 63s - loss: 2.4163 - MinusLogProbMetric: 2.4163 - val_loss: 2.3779 - val_MinusLogProbMetric: 2.3779 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 101/1000
2023-09-16 03:35:12.800 
Epoch 101/1000 
	 loss: 2.4104, MinusLogProbMetric: 2.4104, val_loss: 2.3805, val_MinusLogProbMetric: 2.3805

Epoch 101: val_loss did not improve from 2.37788
196/196 - 62s - loss: 2.4104 - MinusLogProbMetric: 2.4104 - val_loss: 2.3805 - val_MinusLogProbMetric: 2.3805 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 102/1000
2023-09-16 03:36:14.249 
Epoch 102/1000 
	 loss: 2.4267, MinusLogProbMetric: 2.4267, val_loss: 2.3874, val_MinusLogProbMetric: 2.3874

Epoch 102: val_loss did not improve from 2.37788
196/196 - 61s - loss: 2.4267 - MinusLogProbMetric: 2.4267 - val_loss: 2.3874 - val_MinusLogProbMetric: 2.3874 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 103/1000
2023-09-16 03:37:16.323 
Epoch 103/1000 
	 loss: 2.4106, MinusLogProbMetric: 2.4106, val_loss: 2.3930, val_MinusLogProbMetric: 2.3930

Epoch 103: val_loss did not improve from 2.37788
196/196 - 62s - loss: 2.4106 - MinusLogProbMetric: 2.4106 - val_loss: 2.3930 - val_MinusLogProbMetric: 2.3930 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 104/1000
2023-09-16 03:38:18.102 
Epoch 104/1000 
	 loss: 2.4214, MinusLogProbMetric: 2.4214, val_loss: 2.4750, val_MinusLogProbMetric: 2.4750

Epoch 104: val_loss did not improve from 2.37788
196/196 - 62s - loss: 2.4214 - MinusLogProbMetric: 2.4214 - val_loss: 2.4750 - val_MinusLogProbMetric: 2.4750 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 105/1000
2023-09-16 03:39:20.309 
Epoch 105/1000 
	 loss: 2.4097, MinusLogProbMetric: 2.4097, val_loss: 2.4183, val_MinusLogProbMetric: 2.4183

Epoch 105: val_loss did not improve from 2.37788
196/196 - 62s - loss: 2.4097 - MinusLogProbMetric: 2.4097 - val_loss: 2.4183 - val_MinusLogProbMetric: 2.4183 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 106/1000
2023-09-16 03:40:23.269 
Epoch 106/1000 
	 loss: 2.4162, MinusLogProbMetric: 2.4162, val_loss: 2.4291, val_MinusLogProbMetric: 2.4291

Epoch 106: val_loss did not improve from 2.37788
196/196 - 63s - loss: 2.4162 - MinusLogProbMetric: 2.4162 - val_loss: 2.4291 - val_MinusLogProbMetric: 2.4291 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 107/1000
2023-09-16 03:41:24.238 
Epoch 107/1000 
	 loss: 2.4161, MinusLogProbMetric: 2.4161, val_loss: 2.3987, val_MinusLogProbMetric: 2.3987

Epoch 107: val_loss did not improve from 2.37788
196/196 - 61s - loss: 2.4161 - MinusLogProbMetric: 2.4161 - val_loss: 2.3987 - val_MinusLogProbMetric: 2.3987 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 108/1000
2023-09-16 03:42:25.968 
Epoch 108/1000 
	 loss: 2.4086, MinusLogProbMetric: 2.4086, val_loss: 2.4403, val_MinusLogProbMetric: 2.4403

Epoch 108: val_loss did not improve from 2.37788
196/196 - 62s - loss: 2.4086 - MinusLogProbMetric: 2.4086 - val_loss: 2.4403 - val_MinusLogProbMetric: 2.4403 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 109/1000
2023-09-16 03:43:27.804 
Epoch 109/1000 
	 loss: 2.4242, MinusLogProbMetric: 2.4242, val_loss: 2.3982, val_MinusLogProbMetric: 2.3982

Epoch 109: val_loss did not improve from 2.37788
196/196 - 62s - loss: 2.4242 - MinusLogProbMetric: 2.4242 - val_loss: 2.3982 - val_MinusLogProbMetric: 2.3982 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 110/1000
2023-09-16 03:44:29.391 
Epoch 110/1000 
	 loss: 2.4194, MinusLogProbMetric: 2.4194, val_loss: 2.3900, val_MinusLogProbMetric: 2.3900

Epoch 110: val_loss did not improve from 2.37788
196/196 - 62s - loss: 2.4194 - MinusLogProbMetric: 2.4194 - val_loss: 2.3900 - val_MinusLogProbMetric: 2.3900 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 111/1000
2023-09-16 03:45:31.910 
Epoch 111/1000 
	 loss: 2.4199, MinusLogProbMetric: 2.4199, val_loss: 2.3789, val_MinusLogProbMetric: 2.3789

Epoch 111: val_loss did not improve from 2.37788
196/196 - 63s - loss: 2.4199 - MinusLogProbMetric: 2.4199 - val_loss: 2.3789 - val_MinusLogProbMetric: 2.3789 - lr: 0.0010 - 63s/epoch - 319ms/step
Epoch 112/1000
2023-09-16 03:46:32.755 
Epoch 112/1000 
	 loss: 2.4003, MinusLogProbMetric: 2.4003, val_loss: 2.3950, val_MinusLogProbMetric: 2.3950

Epoch 112: val_loss did not improve from 2.37788
196/196 - 61s - loss: 2.4003 - MinusLogProbMetric: 2.4003 - val_loss: 2.3950 - val_MinusLogProbMetric: 2.3950 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 113/1000
2023-09-16 03:47:33.561 
Epoch 113/1000 
	 loss: 2.4079, MinusLogProbMetric: 2.4079, val_loss: 2.5904, val_MinusLogProbMetric: 2.5904

Epoch 113: val_loss did not improve from 2.37788
196/196 - 61s - loss: 2.4079 - MinusLogProbMetric: 2.4079 - val_loss: 2.5904 - val_MinusLogProbMetric: 2.5904 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 114/1000
2023-09-16 03:48:36.057 
Epoch 114/1000 
	 loss: 2.4121, MinusLogProbMetric: 2.4121, val_loss: 2.3999, val_MinusLogProbMetric: 2.3999

Epoch 114: val_loss did not improve from 2.37788
196/196 - 62s - loss: 2.4121 - MinusLogProbMetric: 2.4121 - val_loss: 2.3999 - val_MinusLogProbMetric: 2.3999 - lr: 0.0010 - 62s/epoch - 319ms/step
Epoch 115/1000
2023-09-16 03:49:38.022 
Epoch 115/1000 
	 loss: 2.4201, MinusLogProbMetric: 2.4201, val_loss: 2.3861, val_MinusLogProbMetric: 2.3861

Epoch 115: val_loss did not improve from 2.37788
196/196 - 62s - loss: 2.4201 - MinusLogProbMetric: 2.4201 - val_loss: 2.3861 - val_MinusLogProbMetric: 2.3861 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 116/1000
2023-09-16 03:50:39.154 
Epoch 116/1000 
	 loss: 2.4150, MinusLogProbMetric: 2.4150, val_loss: 2.4155, val_MinusLogProbMetric: 2.4155

Epoch 116: val_loss did not improve from 2.37788
196/196 - 61s - loss: 2.4150 - MinusLogProbMetric: 2.4150 - val_loss: 2.4155 - val_MinusLogProbMetric: 2.4155 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 117/1000
2023-09-16 03:51:32.212 
Epoch 117/1000 
	 loss: 2.4126, MinusLogProbMetric: 2.4126, val_loss: 2.4040, val_MinusLogProbMetric: 2.4040

Epoch 117: val_loss did not improve from 2.37788
196/196 - 53s - loss: 2.4126 - MinusLogProbMetric: 2.4126 - val_loss: 2.4040 - val_MinusLogProbMetric: 2.4040 - lr: 0.0010 - 53s/epoch - 271ms/step
Epoch 118/1000
2023-09-16 03:52:28.715 
Epoch 118/1000 
	 loss: 2.4104, MinusLogProbMetric: 2.4104, val_loss: 2.3757, val_MinusLogProbMetric: 2.3757

Epoch 118: val_loss improved from 2.37788 to 2.37574, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 57s - loss: 2.4104 - MinusLogProbMetric: 2.4104 - val_loss: 2.3757 - val_MinusLogProbMetric: 2.3757 - lr: 0.0010 - 57s/epoch - 293ms/step
Epoch 119/1000
2023-09-16 03:53:32.856 
Epoch 119/1000 
	 loss: 2.4026, MinusLogProbMetric: 2.4026, val_loss: 2.3912, val_MinusLogProbMetric: 2.3912

Epoch 119: val_loss did not improve from 2.37574
196/196 - 63s - loss: 2.4026 - MinusLogProbMetric: 2.4026 - val_loss: 2.3912 - val_MinusLogProbMetric: 2.3912 - lr: 0.0010 - 63s/epoch - 322ms/step
Epoch 120/1000
2023-09-16 03:54:35.577 
Epoch 120/1000 
	 loss: 2.4105, MinusLogProbMetric: 2.4105, val_loss: 2.5124, val_MinusLogProbMetric: 2.5124

Epoch 120: val_loss did not improve from 2.37574
196/196 - 63s - loss: 2.4105 - MinusLogProbMetric: 2.4105 - val_loss: 2.5124 - val_MinusLogProbMetric: 2.5124 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 121/1000
2023-09-16 03:55:37.642 
Epoch 121/1000 
	 loss: 2.4005, MinusLogProbMetric: 2.4005, val_loss: 2.3904, val_MinusLogProbMetric: 2.3904

Epoch 121: val_loss did not improve from 2.37574
196/196 - 62s - loss: 2.4005 - MinusLogProbMetric: 2.4005 - val_loss: 2.3904 - val_MinusLogProbMetric: 2.3904 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 122/1000
2023-09-16 03:56:38.871 
Epoch 122/1000 
	 loss: 2.4051, MinusLogProbMetric: 2.4051, val_loss: 2.3793, val_MinusLogProbMetric: 2.3793

Epoch 122: val_loss did not improve from 2.37574
196/196 - 61s - loss: 2.4051 - MinusLogProbMetric: 2.4051 - val_loss: 2.3793 - val_MinusLogProbMetric: 2.3793 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 123/1000
2023-09-16 03:57:41.546 
Epoch 123/1000 
	 loss: 2.4278, MinusLogProbMetric: 2.4278, val_loss: 2.4038, val_MinusLogProbMetric: 2.4038

Epoch 123: val_loss did not improve from 2.37574
196/196 - 63s - loss: 2.4278 - MinusLogProbMetric: 2.4278 - val_loss: 2.4038 - val_MinusLogProbMetric: 2.4038 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 124/1000
2023-09-16 03:58:43.986 
Epoch 124/1000 
	 loss: 2.4081, MinusLogProbMetric: 2.4081, val_loss: 2.3818, val_MinusLogProbMetric: 2.3818

Epoch 124: val_loss did not improve from 2.37574
196/196 - 62s - loss: 2.4081 - MinusLogProbMetric: 2.4081 - val_loss: 2.3818 - val_MinusLogProbMetric: 2.3818 - lr: 0.0010 - 62s/epoch - 319ms/step
Epoch 125/1000
2023-09-16 03:59:47.126 
Epoch 125/1000 
	 loss: 2.4109, MinusLogProbMetric: 2.4109, val_loss: 2.4819, val_MinusLogProbMetric: 2.4819

Epoch 125: val_loss did not improve from 2.37574
196/196 - 63s - loss: 2.4109 - MinusLogProbMetric: 2.4109 - val_loss: 2.4819 - val_MinusLogProbMetric: 2.4819 - lr: 0.0010 - 63s/epoch - 322ms/step
Epoch 126/1000
2023-09-16 04:00:50.521 
Epoch 126/1000 
	 loss: 2.4053, MinusLogProbMetric: 2.4053, val_loss: 2.3911, val_MinusLogProbMetric: 2.3911

Epoch 126: val_loss did not improve from 2.37574
196/196 - 63s - loss: 2.4053 - MinusLogProbMetric: 2.4053 - val_loss: 2.3911 - val_MinusLogProbMetric: 2.3911 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 127/1000
2023-09-16 04:01:52.760 
Epoch 127/1000 
	 loss: 2.4009, MinusLogProbMetric: 2.4009, val_loss: 2.4059, val_MinusLogProbMetric: 2.4059

Epoch 127: val_loss did not improve from 2.37574
196/196 - 62s - loss: 2.4009 - MinusLogProbMetric: 2.4009 - val_loss: 2.4059 - val_MinusLogProbMetric: 2.4059 - lr: 0.0010 - 62s/epoch - 318ms/step
Epoch 128/1000
2023-09-16 04:02:55.020 
Epoch 128/1000 
	 loss: 2.3991, MinusLogProbMetric: 2.3991, val_loss: 2.3927, val_MinusLogProbMetric: 2.3927

Epoch 128: val_loss did not improve from 2.37574
196/196 - 62s - loss: 2.3991 - MinusLogProbMetric: 2.3991 - val_loss: 2.3927 - val_MinusLogProbMetric: 2.3927 - lr: 0.0010 - 62s/epoch - 318ms/step
Epoch 129/1000
2023-09-16 04:03:57.030 
Epoch 129/1000 
	 loss: 2.4034, MinusLogProbMetric: 2.4034, val_loss: 2.3817, val_MinusLogProbMetric: 2.3817

Epoch 129: val_loss did not improve from 2.37574
196/196 - 62s - loss: 2.4034 - MinusLogProbMetric: 2.4034 - val_loss: 2.3817 - val_MinusLogProbMetric: 2.3817 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 130/1000
2023-09-16 04:04:59.080 
Epoch 130/1000 
	 loss: 2.4047, MinusLogProbMetric: 2.4047, val_loss: 2.3917, val_MinusLogProbMetric: 2.3917

Epoch 130: val_loss did not improve from 2.37574
196/196 - 62s - loss: 2.4047 - MinusLogProbMetric: 2.4047 - val_loss: 2.3917 - val_MinusLogProbMetric: 2.3917 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 131/1000
2023-09-16 04:06:00.357 
Epoch 131/1000 
	 loss: 2.4111, MinusLogProbMetric: 2.4111, val_loss: 2.3906, val_MinusLogProbMetric: 2.3906

Epoch 131: val_loss did not improve from 2.37574
196/196 - 61s - loss: 2.4111 - MinusLogProbMetric: 2.4111 - val_loss: 2.3906 - val_MinusLogProbMetric: 2.3906 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 132/1000
2023-09-16 04:07:02.794 
Epoch 132/1000 
	 loss: 2.4192, MinusLogProbMetric: 2.4192, val_loss: 2.3846, val_MinusLogProbMetric: 2.3846

Epoch 132: val_loss did not improve from 2.37574
196/196 - 62s - loss: 2.4192 - MinusLogProbMetric: 2.4192 - val_loss: 2.3846 - val_MinusLogProbMetric: 2.3846 - lr: 0.0010 - 62s/epoch - 319ms/step
Epoch 133/1000
2023-09-16 04:08:05.367 
Epoch 133/1000 
	 loss: 2.4028, MinusLogProbMetric: 2.4028, val_loss: 2.4322, val_MinusLogProbMetric: 2.4322

Epoch 133: val_loss did not improve from 2.37574
196/196 - 63s - loss: 2.4028 - MinusLogProbMetric: 2.4028 - val_loss: 2.4322 - val_MinusLogProbMetric: 2.4322 - lr: 0.0010 - 63s/epoch - 319ms/step
Epoch 134/1000
2023-09-16 04:09:07.291 
Epoch 134/1000 
	 loss: 2.4142, MinusLogProbMetric: 2.4142, val_loss: 2.4376, val_MinusLogProbMetric: 2.4376

Epoch 134: val_loss did not improve from 2.37574
196/196 - 62s - loss: 2.4142 - MinusLogProbMetric: 2.4142 - val_loss: 2.4376 - val_MinusLogProbMetric: 2.4376 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 135/1000
2023-09-16 04:10:08.657 
Epoch 135/1000 
	 loss: 2.3969, MinusLogProbMetric: 2.3969, val_loss: 2.4029, val_MinusLogProbMetric: 2.4029

Epoch 135: val_loss did not improve from 2.37574
196/196 - 61s - loss: 2.3969 - MinusLogProbMetric: 2.3969 - val_loss: 2.4029 - val_MinusLogProbMetric: 2.4029 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 136/1000
2023-09-16 04:11:11.108 
Epoch 136/1000 
	 loss: 2.4106, MinusLogProbMetric: 2.4106, val_loss: 2.4195, val_MinusLogProbMetric: 2.4195

Epoch 136: val_loss did not improve from 2.37574
196/196 - 62s - loss: 2.4106 - MinusLogProbMetric: 2.4106 - val_loss: 2.4195 - val_MinusLogProbMetric: 2.4195 - lr: 0.0010 - 62s/epoch - 319ms/step
Epoch 137/1000
2023-09-16 04:12:12.554 
Epoch 137/1000 
	 loss: 2.4059, MinusLogProbMetric: 2.4059, val_loss: 2.3804, val_MinusLogProbMetric: 2.3804

Epoch 137: val_loss did not improve from 2.37574
196/196 - 61s - loss: 2.4059 - MinusLogProbMetric: 2.4059 - val_loss: 2.3804 - val_MinusLogProbMetric: 2.3804 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 138/1000
2023-09-16 04:13:11.511 
Epoch 138/1000 
	 loss: 2.4000, MinusLogProbMetric: 2.4000, val_loss: 2.3984, val_MinusLogProbMetric: 2.3984

Epoch 138: val_loss did not improve from 2.37574
196/196 - 59s - loss: 2.4000 - MinusLogProbMetric: 2.4000 - val_loss: 2.3984 - val_MinusLogProbMetric: 2.3984 - lr: 0.0010 - 59s/epoch - 301ms/step
Epoch 139/1000
2023-09-16 04:14:11.229 
Epoch 139/1000 
	 loss: 2.4091, MinusLogProbMetric: 2.4091, val_loss: 2.4562, val_MinusLogProbMetric: 2.4562

Epoch 139: val_loss did not improve from 2.37574
196/196 - 60s - loss: 2.4091 - MinusLogProbMetric: 2.4091 - val_loss: 2.4562 - val_MinusLogProbMetric: 2.4562 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 140/1000
2023-09-16 04:15:15.123 
Epoch 140/1000 
	 loss: 2.4015, MinusLogProbMetric: 2.4015, val_loss: 2.4704, val_MinusLogProbMetric: 2.4704

Epoch 140: val_loss did not improve from 2.37574
196/196 - 64s - loss: 2.4015 - MinusLogProbMetric: 2.4015 - val_loss: 2.4704 - val_MinusLogProbMetric: 2.4704 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 141/1000
2023-09-16 04:16:17.889 
Epoch 141/1000 
	 loss: 2.3981, MinusLogProbMetric: 2.3981, val_loss: 2.4135, val_MinusLogProbMetric: 2.4135

Epoch 141: val_loss did not improve from 2.37574
196/196 - 63s - loss: 2.3981 - MinusLogProbMetric: 2.3981 - val_loss: 2.4135 - val_MinusLogProbMetric: 2.4135 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 142/1000
2023-09-16 04:17:20.262 
Epoch 142/1000 
	 loss: 2.4086, MinusLogProbMetric: 2.4086, val_loss: 2.3781, val_MinusLogProbMetric: 2.3781

Epoch 142: val_loss did not improve from 2.37574
196/196 - 62s - loss: 2.4086 - MinusLogProbMetric: 2.4086 - val_loss: 2.3781 - val_MinusLogProbMetric: 2.3781 - lr: 0.0010 - 62s/epoch - 318ms/step
Epoch 143/1000
2023-09-16 04:18:21.690 
Epoch 143/1000 
	 loss: 2.4138, MinusLogProbMetric: 2.4138, val_loss: 2.4463, val_MinusLogProbMetric: 2.4463

Epoch 143: val_loss did not improve from 2.37574
196/196 - 61s - loss: 2.4138 - MinusLogProbMetric: 2.4138 - val_loss: 2.4463 - val_MinusLogProbMetric: 2.4463 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 144/1000
2023-09-16 04:19:23.384 
Epoch 144/1000 
	 loss: 2.4038, MinusLogProbMetric: 2.4038, val_loss: 2.3870, val_MinusLogProbMetric: 2.3870

Epoch 144: val_loss did not improve from 2.37574
196/196 - 62s - loss: 2.4038 - MinusLogProbMetric: 2.4038 - val_loss: 2.3870 - val_MinusLogProbMetric: 2.3870 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 145/1000
2023-09-16 04:20:25.327 
Epoch 145/1000 
	 loss: 2.3946, MinusLogProbMetric: 2.3946, val_loss: 2.3881, val_MinusLogProbMetric: 2.3881

Epoch 145: val_loss did not improve from 2.37574
196/196 - 62s - loss: 2.3946 - MinusLogProbMetric: 2.3946 - val_loss: 2.3881 - val_MinusLogProbMetric: 2.3881 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 146/1000
2023-09-16 04:21:26.988 
Epoch 146/1000 
	 loss: 2.4045, MinusLogProbMetric: 2.4045, val_loss: 2.3984, val_MinusLogProbMetric: 2.3984

Epoch 146: val_loss did not improve from 2.37574
196/196 - 62s - loss: 2.4045 - MinusLogProbMetric: 2.4045 - val_loss: 2.3984 - val_MinusLogProbMetric: 2.3984 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 147/1000
2023-09-16 04:22:28.206 
Epoch 147/1000 
	 loss: 2.3917, MinusLogProbMetric: 2.3917, val_loss: 2.4328, val_MinusLogProbMetric: 2.4328

Epoch 147: val_loss did not improve from 2.37574
196/196 - 61s - loss: 2.3917 - MinusLogProbMetric: 2.3917 - val_loss: 2.4328 - val_MinusLogProbMetric: 2.4328 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 148/1000
2023-09-16 04:23:29.498 
Epoch 148/1000 
	 loss: 2.3977, MinusLogProbMetric: 2.3977, val_loss: 2.3923, val_MinusLogProbMetric: 2.3923

Epoch 148: val_loss did not improve from 2.37574
196/196 - 61s - loss: 2.3977 - MinusLogProbMetric: 2.3977 - val_loss: 2.3923 - val_MinusLogProbMetric: 2.3923 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 149/1000
2023-09-16 04:24:30.864 
Epoch 149/1000 
	 loss: 2.4003, MinusLogProbMetric: 2.4003, val_loss: 2.4770, val_MinusLogProbMetric: 2.4770

Epoch 149: val_loss did not improve from 2.37574
196/196 - 61s - loss: 2.4003 - MinusLogProbMetric: 2.4003 - val_loss: 2.4770 - val_MinusLogProbMetric: 2.4770 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 150/1000
2023-09-16 04:25:34.145 
Epoch 150/1000 
	 loss: 2.4150, MinusLogProbMetric: 2.4150, val_loss: 2.5470, val_MinusLogProbMetric: 2.5470

Epoch 150: val_loss did not improve from 2.37574
196/196 - 63s - loss: 2.4150 - MinusLogProbMetric: 2.4150 - val_loss: 2.5470 - val_MinusLogProbMetric: 2.5470 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 151/1000
2023-09-16 04:26:35.449 
Epoch 151/1000 
	 loss: 2.4144, MinusLogProbMetric: 2.4144, val_loss: 2.5502, val_MinusLogProbMetric: 2.5502

Epoch 151: val_loss did not improve from 2.37574
196/196 - 61s - loss: 2.4144 - MinusLogProbMetric: 2.4144 - val_loss: 2.5502 - val_MinusLogProbMetric: 2.5502 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 152/1000
2023-09-16 04:27:34.585 
Epoch 152/1000 
	 loss: 2.3880, MinusLogProbMetric: 2.3880, val_loss: 2.3888, val_MinusLogProbMetric: 2.3888

Epoch 152: val_loss did not improve from 2.37574
196/196 - 59s - loss: 2.3880 - MinusLogProbMetric: 2.3880 - val_loss: 2.3888 - val_MinusLogProbMetric: 2.3888 - lr: 0.0010 - 59s/epoch - 302ms/step
Epoch 153/1000
2023-09-16 04:28:33.671 
Epoch 153/1000 
	 loss: 2.4066, MinusLogProbMetric: 2.4066, val_loss: 2.3836, val_MinusLogProbMetric: 2.3836

Epoch 153: val_loss did not improve from 2.37574
196/196 - 59s - loss: 2.4066 - MinusLogProbMetric: 2.4066 - val_loss: 2.3836 - val_MinusLogProbMetric: 2.3836 - lr: 0.0010 - 59s/epoch - 301ms/step
Epoch 154/1000
2023-09-16 04:29:26.140 
Epoch 154/1000 
	 loss: 2.3960, MinusLogProbMetric: 2.3960, val_loss: 2.4040, val_MinusLogProbMetric: 2.4040

Epoch 154: val_loss did not improve from 2.37574
196/196 - 52s - loss: 2.3960 - MinusLogProbMetric: 2.3960 - val_loss: 2.4040 - val_MinusLogProbMetric: 2.4040 - lr: 0.0010 - 52s/epoch - 268ms/step
Epoch 155/1000
2023-09-16 04:30:17.436 
Epoch 155/1000 
	 loss: 2.3987, MinusLogProbMetric: 2.3987, val_loss: 2.3996, val_MinusLogProbMetric: 2.3996

Epoch 155: val_loss did not improve from 2.37574
196/196 - 51s - loss: 2.3987 - MinusLogProbMetric: 2.3987 - val_loss: 2.3996 - val_MinusLogProbMetric: 2.3996 - lr: 0.0010 - 51s/epoch - 262ms/step
Epoch 156/1000
2023-09-16 04:31:16.783 
Epoch 156/1000 
	 loss: 2.4024, MinusLogProbMetric: 2.4024, val_loss: 2.4243, val_MinusLogProbMetric: 2.4243

Epoch 156: val_loss did not improve from 2.37574
196/196 - 59s - loss: 2.4024 - MinusLogProbMetric: 2.4024 - val_loss: 2.4243 - val_MinusLogProbMetric: 2.4243 - lr: 0.0010 - 59s/epoch - 303ms/step
Epoch 157/1000
2023-09-16 04:32:16.754 
Epoch 157/1000 
	 loss: 2.3974, MinusLogProbMetric: 2.3974, val_loss: 2.4052, val_MinusLogProbMetric: 2.4052

Epoch 157: val_loss did not improve from 2.37574
196/196 - 60s - loss: 2.3974 - MinusLogProbMetric: 2.3974 - val_loss: 2.4052 - val_MinusLogProbMetric: 2.4052 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 158/1000
2023-09-16 04:33:17.389 
Epoch 158/1000 
	 loss: 2.4209, MinusLogProbMetric: 2.4209, val_loss: 2.4452, val_MinusLogProbMetric: 2.4452

Epoch 158: val_loss did not improve from 2.37574
196/196 - 61s - loss: 2.4209 - MinusLogProbMetric: 2.4209 - val_loss: 2.4452 - val_MinusLogProbMetric: 2.4452 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 159/1000
2023-09-16 04:34:17.874 
Epoch 159/1000 
	 loss: 2.3937, MinusLogProbMetric: 2.3937, val_loss: 2.4751, val_MinusLogProbMetric: 2.4751

Epoch 159: val_loss did not improve from 2.37574
196/196 - 60s - loss: 2.3937 - MinusLogProbMetric: 2.3937 - val_loss: 2.4751 - val_MinusLogProbMetric: 2.4751 - lr: 0.0010 - 60s/epoch - 309ms/step
Epoch 160/1000
2023-09-16 04:35:18.450 
Epoch 160/1000 
	 loss: 2.4068, MinusLogProbMetric: 2.4068, val_loss: 2.4043, val_MinusLogProbMetric: 2.4043

Epoch 160: val_loss did not improve from 2.37574
196/196 - 61s - loss: 2.4068 - MinusLogProbMetric: 2.4068 - val_loss: 2.4043 - val_MinusLogProbMetric: 2.4043 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 161/1000
2023-09-16 04:36:18.971 
Epoch 161/1000 
	 loss: 2.3977, MinusLogProbMetric: 2.3977, val_loss: 2.4124, val_MinusLogProbMetric: 2.4124

Epoch 161: val_loss did not improve from 2.37574
196/196 - 61s - loss: 2.3977 - MinusLogProbMetric: 2.3977 - val_loss: 2.4124 - val_MinusLogProbMetric: 2.4124 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 162/1000
2023-09-16 04:37:20.092 
Epoch 162/1000 
	 loss: 2.3872, MinusLogProbMetric: 2.3872, val_loss: 2.3724, val_MinusLogProbMetric: 2.3724

Epoch 162: val_loss improved from 2.37574 to 2.37237, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 62s - loss: 2.3872 - MinusLogProbMetric: 2.3872 - val_loss: 2.3724 - val_MinusLogProbMetric: 2.3724 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 163/1000
2023-09-16 04:38:21.904 
Epoch 163/1000 
	 loss: 2.3921, MinusLogProbMetric: 2.3921, val_loss: 2.4080, val_MinusLogProbMetric: 2.4080

Epoch 163: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3921 - MinusLogProbMetric: 2.3921 - val_loss: 2.4080 - val_MinusLogProbMetric: 2.4080 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 164/1000
2023-09-16 04:39:22.502 
Epoch 164/1000 
	 loss: 2.4093, MinusLogProbMetric: 2.4093, val_loss: 2.4207, val_MinusLogProbMetric: 2.4207

Epoch 164: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.4093 - MinusLogProbMetric: 2.4093 - val_loss: 2.4207 - val_MinusLogProbMetric: 2.4207 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 165/1000
2023-09-16 04:40:23.425 
Epoch 165/1000 
	 loss: 2.3946, MinusLogProbMetric: 2.3946, val_loss: 2.4256, val_MinusLogProbMetric: 2.4256

Epoch 165: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3946 - MinusLogProbMetric: 2.3946 - val_loss: 2.4256 - val_MinusLogProbMetric: 2.4256 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 166/1000
2023-09-16 04:41:23.887 
Epoch 166/1000 
	 loss: 2.3980, MinusLogProbMetric: 2.3980, val_loss: 2.3891, val_MinusLogProbMetric: 2.3891

Epoch 166: val_loss did not improve from 2.37237
196/196 - 60s - loss: 2.3980 - MinusLogProbMetric: 2.3980 - val_loss: 2.3891 - val_MinusLogProbMetric: 2.3891 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 167/1000
2023-09-16 04:42:25.088 
Epoch 167/1000 
	 loss: 2.3969, MinusLogProbMetric: 2.3969, val_loss: 2.3790, val_MinusLogProbMetric: 2.3790

Epoch 167: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3969 - MinusLogProbMetric: 2.3969 - val_loss: 2.3790 - val_MinusLogProbMetric: 2.3790 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 168/1000
2023-09-16 04:43:26.271 
Epoch 168/1000 
	 loss: 2.3928, MinusLogProbMetric: 2.3928, val_loss: 2.4305, val_MinusLogProbMetric: 2.4305

Epoch 168: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3928 - MinusLogProbMetric: 2.3928 - val_loss: 2.4305 - val_MinusLogProbMetric: 2.4305 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 169/1000
2023-09-16 04:44:27.074 
Epoch 169/1000 
	 loss: 2.3983, MinusLogProbMetric: 2.3983, val_loss: 2.4664, val_MinusLogProbMetric: 2.4664

Epoch 169: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3983 - MinusLogProbMetric: 2.3983 - val_loss: 2.4664 - val_MinusLogProbMetric: 2.4664 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 170/1000
2023-09-16 04:45:27.355 
Epoch 170/1000 
	 loss: 2.4042, MinusLogProbMetric: 2.4042, val_loss: 2.4788, val_MinusLogProbMetric: 2.4788

Epoch 170: val_loss did not improve from 2.37237
196/196 - 60s - loss: 2.4042 - MinusLogProbMetric: 2.4042 - val_loss: 2.4788 - val_MinusLogProbMetric: 2.4788 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 171/1000
2023-09-16 04:46:27.809 
Epoch 171/1000 
	 loss: 2.3966, MinusLogProbMetric: 2.3966, val_loss: 2.3907, val_MinusLogProbMetric: 2.3907

Epoch 171: val_loss did not improve from 2.37237
196/196 - 60s - loss: 2.3966 - MinusLogProbMetric: 2.3966 - val_loss: 2.3907 - val_MinusLogProbMetric: 2.3907 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 172/1000
2023-09-16 04:47:27.938 
Epoch 172/1000 
	 loss: 2.3938, MinusLogProbMetric: 2.3938, val_loss: 2.3837, val_MinusLogProbMetric: 2.3837

Epoch 172: val_loss did not improve from 2.37237
196/196 - 60s - loss: 2.3938 - MinusLogProbMetric: 2.3938 - val_loss: 2.3837 - val_MinusLogProbMetric: 2.3837 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 173/1000
2023-09-16 04:48:28.398 
Epoch 173/1000 
	 loss: 2.4049, MinusLogProbMetric: 2.4049, val_loss: 2.3956, val_MinusLogProbMetric: 2.3956

Epoch 173: val_loss did not improve from 2.37237
196/196 - 60s - loss: 2.4049 - MinusLogProbMetric: 2.4049 - val_loss: 2.3956 - val_MinusLogProbMetric: 2.3956 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 174/1000
2023-09-16 04:49:28.942 
Epoch 174/1000 
	 loss: 2.3982, MinusLogProbMetric: 2.3982, val_loss: 2.3996, val_MinusLogProbMetric: 2.3996

Epoch 174: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3982 - MinusLogProbMetric: 2.3982 - val_loss: 2.3996 - val_MinusLogProbMetric: 2.3996 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 175/1000
2023-09-16 04:50:29.651 
Epoch 175/1000 
	 loss: 2.3921, MinusLogProbMetric: 2.3921, val_loss: 2.3929, val_MinusLogProbMetric: 2.3929

Epoch 175: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3921 - MinusLogProbMetric: 2.3921 - val_loss: 2.3929 - val_MinusLogProbMetric: 2.3929 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 176/1000
2023-09-16 04:51:30.154 
Epoch 176/1000 
	 loss: 2.4082, MinusLogProbMetric: 2.4082, val_loss: 2.4267, val_MinusLogProbMetric: 2.4267

Epoch 176: val_loss did not improve from 2.37237
196/196 - 60s - loss: 2.4082 - MinusLogProbMetric: 2.4082 - val_loss: 2.4267 - val_MinusLogProbMetric: 2.4267 - lr: 0.0010 - 60s/epoch - 309ms/step
Epoch 177/1000
2023-09-16 04:52:30.689 
Epoch 177/1000 
	 loss: 2.3926, MinusLogProbMetric: 2.3926, val_loss: 2.4120, val_MinusLogProbMetric: 2.4120

Epoch 177: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3926 - MinusLogProbMetric: 2.3926 - val_loss: 2.4120 - val_MinusLogProbMetric: 2.4120 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 178/1000
2023-09-16 04:53:31.371 
Epoch 178/1000 
	 loss: 2.3916, MinusLogProbMetric: 2.3916, val_loss: 2.4081, val_MinusLogProbMetric: 2.4081

Epoch 178: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3916 - MinusLogProbMetric: 2.3916 - val_loss: 2.4081 - val_MinusLogProbMetric: 2.4081 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 179/1000
2023-09-16 04:54:32.810 
Epoch 179/1000 
	 loss: 2.3883, MinusLogProbMetric: 2.3883, val_loss: 2.4003, val_MinusLogProbMetric: 2.4003

Epoch 179: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3883 - MinusLogProbMetric: 2.3883 - val_loss: 2.4003 - val_MinusLogProbMetric: 2.4003 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 180/1000
2023-09-16 04:55:33.582 
Epoch 180/1000 
	 loss: 2.3997, MinusLogProbMetric: 2.3997, val_loss: 2.3845, val_MinusLogProbMetric: 2.3845

Epoch 180: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3997 - MinusLogProbMetric: 2.3997 - val_loss: 2.3845 - val_MinusLogProbMetric: 2.3845 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 181/1000
2023-09-16 04:56:34.081 
Epoch 181/1000 
	 loss: 2.4037, MinusLogProbMetric: 2.4037, val_loss: 2.3800, val_MinusLogProbMetric: 2.3800

Epoch 181: val_loss did not improve from 2.37237
196/196 - 60s - loss: 2.4037 - MinusLogProbMetric: 2.4037 - val_loss: 2.3800 - val_MinusLogProbMetric: 2.3800 - lr: 0.0010 - 60s/epoch - 309ms/step
Epoch 182/1000
2023-09-16 04:57:34.836 
Epoch 182/1000 
	 loss: 2.3981, MinusLogProbMetric: 2.3981, val_loss: 2.4244, val_MinusLogProbMetric: 2.4244

Epoch 182: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3981 - MinusLogProbMetric: 2.3981 - val_loss: 2.4244 - val_MinusLogProbMetric: 2.4244 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 183/1000
2023-09-16 04:58:35.504 
Epoch 183/1000 
	 loss: 2.4024, MinusLogProbMetric: 2.4024, val_loss: 2.3911, val_MinusLogProbMetric: 2.3911

Epoch 183: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.4024 - MinusLogProbMetric: 2.4024 - val_loss: 2.3911 - val_MinusLogProbMetric: 2.3911 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 184/1000
2023-09-16 04:59:36.862 
Epoch 184/1000 
	 loss: 2.3914, MinusLogProbMetric: 2.3914, val_loss: 2.3805, val_MinusLogProbMetric: 2.3805

Epoch 184: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3914 - MinusLogProbMetric: 2.3914 - val_loss: 2.3805 - val_MinusLogProbMetric: 2.3805 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 185/1000
2023-09-16 05:00:38.079 
Epoch 185/1000 
	 loss: 2.3916, MinusLogProbMetric: 2.3916, val_loss: 2.4274, val_MinusLogProbMetric: 2.4274

Epoch 185: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3916 - MinusLogProbMetric: 2.3916 - val_loss: 2.4274 - val_MinusLogProbMetric: 2.4274 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 186/1000
2023-09-16 05:01:38.616 
Epoch 186/1000 
	 loss: 2.3896, MinusLogProbMetric: 2.3896, val_loss: 2.5182, val_MinusLogProbMetric: 2.5182

Epoch 186: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3896 - MinusLogProbMetric: 2.3896 - val_loss: 2.5182 - val_MinusLogProbMetric: 2.5182 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 187/1000
2023-09-16 05:02:39.613 
Epoch 187/1000 
	 loss: 2.3897, MinusLogProbMetric: 2.3897, val_loss: 2.4960, val_MinusLogProbMetric: 2.4960

Epoch 187: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3897 - MinusLogProbMetric: 2.3897 - val_loss: 2.4960 - val_MinusLogProbMetric: 2.4960 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 188/1000
2023-09-16 05:03:40.381 
Epoch 188/1000 
	 loss: 2.4027, MinusLogProbMetric: 2.4027, val_loss: 2.3857, val_MinusLogProbMetric: 2.3857

Epoch 188: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.4027 - MinusLogProbMetric: 2.4027 - val_loss: 2.3857 - val_MinusLogProbMetric: 2.3857 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 189/1000
2023-09-16 05:04:40.889 
Epoch 189/1000 
	 loss: 2.3916, MinusLogProbMetric: 2.3916, val_loss: 2.3789, val_MinusLogProbMetric: 2.3789

Epoch 189: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3916 - MinusLogProbMetric: 2.3916 - val_loss: 2.3789 - val_MinusLogProbMetric: 2.3789 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 190/1000
2023-09-16 05:05:41.523 
Epoch 190/1000 
	 loss: 2.3973, MinusLogProbMetric: 2.3973, val_loss: 2.3990, val_MinusLogProbMetric: 2.3990

Epoch 190: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3973 - MinusLogProbMetric: 2.3973 - val_loss: 2.3990 - val_MinusLogProbMetric: 2.3990 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 191/1000
2023-09-16 05:06:42.064 
Epoch 191/1000 
	 loss: 2.3807, MinusLogProbMetric: 2.3807, val_loss: 2.5039, val_MinusLogProbMetric: 2.5039

Epoch 191: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3807 - MinusLogProbMetric: 2.3807 - val_loss: 2.5039 - val_MinusLogProbMetric: 2.5039 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 192/1000
2023-09-16 05:07:42.847 
Epoch 192/1000 
	 loss: 2.3999, MinusLogProbMetric: 2.3999, val_loss: 2.4200, val_MinusLogProbMetric: 2.4200

Epoch 192: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3999 - MinusLogProbMetric: 2.3999 - val_loss: 2.4200 - val_MinusLogProbMetric: 2.4200 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 193/1000
2023-09-16 05:08:43.637 
Epoch 193/1000 
	 loss: 2.3806, MinusLogProbMetric: 2.3806, val_loss: 2.4975, val_MinusLogProbMetric: 2.4975

Epoch 193: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3806 - MinusLogProbMetric: 2.3806 - val_loss: 2.4975 - val_MinusLogProbMetric: 2.4975 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 194/1000
2023-09-16 05:09:44.361 
Epoch 194/1000 
	 loss: 2.3972, MinusLogProbMetric: 2.3972, val_loss: 2.4161, val_MinusLogProbMetric: 2.4161

Epoch 194: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3972 - MinusLogProbMetric: 2.3972 - val_loss: 2.4161 - val_MinusLogProbMetric: 2.4161 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 195/1000
2023-09-16 05:10:44.697 
Epoch 195/1000 
	 loss: 2.3908, MinusLogProbMetric: 2.3908, val_loss: 2.3788, val_MinusLogProbMetric: 2.3788

Epoch 195: val_loss did not improve from 2.37237
196/196 - 60s - loss: 2.3908 - MinusLogProbMetric: 2.3908 - val_loss: 2.3788 - val_MinusLogProbMetric: 2.3788 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 196/1000
2023-09-16 05:11:45.910 
Epoch 196/1000 
	 loss: 2.3861, MinusLogProbMetric: 2.3861, val_loss: 2.4517, val_MinusLogProbMetric: 2.4517

Epoch 196: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3861 - MinusLogProbMetric: 2.3861 - val_loss: 2.4517 - val_MinusLogProbMetric: 2.4517 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 197/1000
2023-09-16 05:12:46.710 
Epoch 197/1000 
	 loss: 2.3930, MinusLogProbMetric: 2.3930, val_loss: 2.3886, val_MinusLogProbMetric: 2.3886

Epoch 197: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3930 - MinusLogProbMetric: 2.3930 - val_loss: 2.3886 - val_MinusLogProbMetric: 2.3886 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 198/1000
2023-09-16 05:13:47.651 
Epoch 198/1000 
	 loss: 2.3917, MinusLogProbMetric: 2.3917, val_loss: 2.4375, val_MinusLogProbMetric: 2.4375

Epoch 198: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3917 - MinusLogProbMetric: 2.3917 - val_loss: 2.4375 - val_MinusLogProbMetric: 2.4375 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 199/1000
2023-09-16 05:14:48.556 
Epoch 199/1000 
	 loss: 2.3899, MinusLogProbMetric: 2.3899, val_loss: 2.3891, val_MinusLogProbMetric: 2.3891

Epoch 199: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3899 - MinusLogProbMetric: 2.3899 - val_loss: 2.3891 - val_MinusLogProbMetric: 2.3891 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 200/1000
2023-09-16 05:15:49.499 
Epoch 200/1000 
	 loss: 2.3897, MinusLogProbMetric: 2.3897, val_loss: 2.4081, val_MinusLogProbMetric: 2.4081

Epoch 200: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3897 - MinusLogProbMetric: 2.3897 - val_loss: 2.4081 - val_MinusLogProbMetric: 2.4081 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 201/1000
2023-09-16 05:16:49.968 
Epoch 201/1000 
	 loss: 2.3836, MinusLogProbMetric: 2.3836, val_loss: 2.3983, val_MinusLogProbMetric: 2.3983

Epoch 201: val_loss did not improve from 2.37237
196/196 - 60s - loss: 2.3836 - MinusLogProbMetric: 2.3836 - val_loss: 2.3983 - val_MinusLogProbMetric: 2.3983 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 202/1000
2023-09-16 05:17:50.771 
Epoch 202/1000 
	 loss: 2.3905, MinusLogProbMetric: 2.3905, val_loss: 2.3876, val_MinusLogProbMetric: 2.3876

Epoch 202: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3905 - MinusLogProbMetric: 2.3905 - val_loss: 2.3876 - val_MinusLogProbMetric: 2.3876 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 203/1000
2023-09-16 05:18:51.684 
Epoch 203/1000 
	 loss: 2.3890, MinusLogProbMetric: 2.3890, val_loss: 2.3956, val_MinusLogProbMetric: 2.3956

Epoch 203: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3890 - MinusLogProbMetric: 2.3890 - val_loss: 2.3956 - val_MinusLogProbMetric: 2.3956 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 204/1000
2023-09-16 05:19:52.238 
Epoch 204/1000 
	 loss: 2.3979, MinusLogProbMetric: 2.3979, val_loss: 2.4635, val_MinusLogProbMetric: 2.4635

Epoch 204: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3979 - MinusLogProbMetric: 2.3979 - val_loss: 2.4635 - val_MinusLogProbMetric: 2.4635 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 205/1000
2023-09-16 05:20:53.477 
Epoch 205/1000 
	 loss: 2.3917, MinusLogProbMetric: 2.3917, val_loss: 2.4072, val_MinusLogProbMetric: 2.4072

Epoch 205: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3917 - MinusLogProbMetric: 2.3917 - val_loss: 2.4072 - val_MinusLogProbMetric: 2.4072 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 206/1000
2023-09-16 05:21:53.996 
Epoch 206/1000 
	 loss: 2.3824, MinusLogProbMetric: 2.3824, val_loss: 2.4222, val_MinusLogProbMetric: 2.4222

Epoch 206: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3824 - MinusLogProbMetric: 2.3824 - val_loss: 2.4222 - val_MinusLogProbMetric: 2.4222 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 207/1000
2023-09-16 05:22:55.034 
Epoch 207/1000 
	 loss: 2.3988, MinusLogProbMetric: 2.3988, val_loss: 2.3916, val_MinusLogProbMetric: 2.3916

Epoch 207: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3988 - MinusLogProbMetric: 2.3988 - val_loss: 2.3916 - val_MinusLogProbMetric: 2.3916 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 208/1000
2023-09-16 05:23:55.509 
Epoch 208/1000 
	 loss: 2.3986, MinusLogProbMetric: 2.3986, val_loss: 2.3813, val_MinusLogProbMetric: 2.3813

Epoch 208: val_loss did not improve from 2.37237
196/196 - 60s - loss: 2.3986 - MinusLogProbMetric: 2.3986 - val_loss: 2.3813 - val_MinusLogProbMetric: 2.3813 - lr: 0.0010 - 60s/epoch - 309ms/step
Epoch 209/1000
2023-09-16 05:24:55.922 
Epoch 209/1000 
	 loss: 2.3884, MinusLogProbMetric: 2.3884, val_loss: 2.3867, val_MinusLogProbMetric: 2.3867

Epoch 209: val_loss did not improve from 2.37237
196/196 - 60s - loss: 2.3884 - MinusLogProbMetric: 2.3884 - val_loss: 2.3867 - val_MinusLogProbMetric: 2.3867 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 210/1000
2023-09-16 05:25:56.563 
Epoch 210/1000 
	 loss: 2.3962, MinusLogProbMetric: 2.3962, val_loss: 2.4070, val_MinusLogProbMetric: 2.4070

Epoch 210: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3962 - MinusLogProbMetric: 2.3962 - val_loss: 2.4070 - val_MinusLogProbMetric: 2.4070 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 211/1000
2023-09-16 05:26:57.112 
Epoch 211/1000 
	 loss: 2.3890, MinusLogProbMetric: 2.3890, val_loss: 2.3782, val_MinusLogProbMetric: 2.3782

Epoch 211: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3890 - MinusLogProbMetric: 2.3890 - val_loss: 2.3782 - val_MinusLogProbMetric: 2.3782 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 212/1000
2023-09-16 05:27:57.985 
Epoch 212/1000 
	 loss: 2.3793, MinusLogProbMetric: 2.3793, val_loss: 2.3748, val_MinusLogProbMetric: 2.3748

Epoch 212: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3793 - MinusLogProbMetric: 2.3793 - val_loss: 2.3748 - val_MinusLogProbMetric: 2.3748 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 213/1000
2023-09-16 05:28:58.653 
Epoch 213/1000 
	 loss: 2.3573, MinusLogProbMetric: 2.3573, val_loss: 2.3894, val_MinusLogProbMetric: 2.3894

Epoch 213: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3573 - MinusLogProbMetric: 2.3573 - val_loss: 2.3894 - val_MinusLogProbMetric: 2.3894 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 214/1000
2023-09-16 05:29:58.959 
Epoch 214/1000 
	 loss: 2.3568, MinusLogProbMetric: 2.3568, val_loss: 2.4069, val_MinusLogProbMetric: 2.4069

Epoch 214: val_loss did not improve from 2.37237
196/196 - 60s - loss: 2.3568 - MinusLogProbMetric: 2.3568 - val_loss: 2.4069 - val_MinusLogProbMetric: 2.4069 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 215/1000
2023-09-16 05:30:59.712 
Epoch 215/1000 
	 loss: 2.3595, MinusLogProbMetric: 2.3595, val_loss: 2.3834, val_MinusLogProbMetric: 2.3834

Epoch 215: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3595 - MinusLogProbMetric: 2.3595 - val_loss: 2.3834 - val_MinusLogProbMetric: 2.3834 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 216/1000
2023-09-16 05:32:00.544 
Epoch 216/1000 
	 loss: 2.3623, MinusLogProbMetric: 2.3623, val_loss: 2.3772, val_MinusLogProbMetric: 2.3772

Epoch 216: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3623 - MinusLogProbMetric: 2.3623 - val_loss: 2.3772 - val_MinusLogProbMetric: 2.3772 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 217/1000
2023-09-16 05:33:01.437 
Epoch 217/1000 
	 loss: 2.3582, MinusLogProbMetric: 2.3582, val_loss: 2.3817, val_MinusLogProbMetric: 2.3817

Epoch 217: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3582 - MinusLogProbMetric: 2.3582 - val_loss: 2.3817 - val_MinusLogProbMetric: 2.3817 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 218/1000
2023-09-16 05:34:02.085 
Epoch 218/1000 
	 loss: 2.3596, MinusLogProbMetric: 2.3596, val_loss: 2.3750, val_MinusLogProbMetric: 2.3750

Epoch 218: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3596 - MinusLogProbMetric: 2.3596 - val_loss: 2.3750 - val_MinusLogProbMetric: 2.3750 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 219/1000
2023-09-16 05:35:03.067 
Epoch 219/1000 
	 loss: 2.3598, MinusLogProbMetric: 2.3598, val_loss: 2.3859, val_MinusLogProbMetric: 2.3859

Epoch 219: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3598 - MinusLogProbMetric: 2.3598 - val_loss: 2.3859 - val_MinusLogProbMetric: 2.3859 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 220/1000
2023-09-16 05:36:04.091 
Epoch 220/1000 
	 loss: 2.3579, MinusLogProbMetric: 2.3579, val_loss: 2.3834, val_MinusLogProbMetric: 2.3834

Epoch 220: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3579 - MinusLogProbMetric: 2.3579 - val_loss: 2.3834 - val_MinusLogProbMetric: 2.3834 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 221/1000
2023-09-16 05:37:04.966 
Epoch 221/1000 
	 loss: 2.3625, MinusLogProbMetric: 2.3625, val_loss: 2.4106, val_MinusLogProbMetric: 2.4106

Epoch 221: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3625 - MinusLogProbMetric: 2.3625 - val_loss: 2.4106 - val_MinusLogProbMetric: 2.4106 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 222/1000
2023-09-16 05:38:06.308 
Epoch 222/1000 
	 loss: 2.3619, MinusLogProbMetric: 2.3619, val_loss: 2.3764, val_MinusLogProbMetric: 2.3764

Epoch 222: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3619 - MinusLogProbMetric: 2.3619 - val_loss: 2.3764 - val_MinusLogProbMetric: 2.3764 - lr: 5.0000e-04 - 61s/epoch - 313ms/step
Epoch 223/1000
2023-09-16 05:39:02.454 
Epoch 223/1000 
	 loss: 2.3612, MinusLogProbMetric: 2.3612, val_loss: 2.4284, val_MinusLogProbMetric: 2.4284

Epoch 223: val_loss did not improve from 2.37237
196/196 - 56s - loss: 2.3612 - MinusLogProbMetric: 2.3612 - val_loss: 2.4284 - val_MinusLogProbMetric: 2.4284 - lr: 5.0000e-04 - 56s/epoch - 286ms/step
Epoch 224/1000
2023-09-16 05:40:04.047 
Epoch 224/1000 
	 loss: 2.3646, MinusLogProbMetric: 2.3646, val_loss: 2.3791, val_MinusLogProbMetric: 2.3791

Epoch 224: val_loss did not improve from 2.37237
196/196 - 62s - loss: 2.3646 - MinusLogProbMetric: 2.3646 - val_loss: 2.3791 - val_MinusLogProbMetric: 2.3791 - lr: 5.0000e-04 - 62s/epoch - 314ms/step
Epoch 225/1000
2023-09-16 05:41:05.211 
Epoch 225/1000 
	 loss: 2.3582, MinusLogProbMetric: 2.3582, val_loss: 2.3812, val_MinusLogProbMetric: 2.3812

Epoch 225: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3582 - MinusLogProbMetric: 2.3582 - val_loss: 2.3812 - val_MinusLogProbMetric: 2.3812 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 226/1000
2023-09-16 05:42:06.129 
Epoch 226/1000 
	 loss: 2.3588, MinusLogProbMetric: 2.3588, val_loss: 2.3756, val_MinusLogProbMetric: 2.3756

Epoch 226: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3588 - MinusLogProbMetric: 2.3588 - val_loss: 2.3756 - val_MinusLogProbMetric: 2.3756 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 227/1000
2023-09-16 05:43:07.081 
Epoch 227/1000 
	 loss: 2.3567, MinusLogProbMetric: 2.3567, val_loss: 2.3733, val_MinusLogProbMetric: 2.3733

Epoch 227: val_loss did not improve from 2.37237
196/196 - 61s - loss: 2.3567 - MinusLogProbMetric: 2.3567 - val_loss: 2.3733 - val_MinusLogProbMetric: 2.3733 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 228/1000
2023-09-16 05:44:07.463 
Epoch 228/1000 
	 loss: 2.3539, MinusLogProbMetric: 2.3539, val_loss: 2.3709, val_MinusLogProbMetric: 2.3709

Epoch 228: val_loss improved from 2.37237 to 2.37085, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 61s - loss: 2.3539 - MinusLogProbMetric: 2.3539 - val_loss: 2.3709 - val_MinusLogProbMetric: 2.3709 - lr: 5.0000e-04 - 61s/epoch - 313ms/step
Epoch 229/1000
2023-09-16 05:45:09.220 
Epoch 229/1000 
	 loss: 2.3569, MinusLogProbMetric: 2.3569, val_loss: 2.3965, val_MinusLogProbMetric: 2.3965

Epoch 229: val_loss did not improve from 2.37085
196/196 - 61s - loss: 2.3569 - MinusLogProbMetric: 2.3569 - val_loss: 2.3965 - val_MinusLogProbMetric: 2.3965 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 230/1000
2023-09-16 05:46:10.073 
Epoch 230/1000 
	 loss: 2.3606, MinusLogProbMetric: 2.3606, val_loss: 2.3906, val_MinusLogProbMetric: 2.3906

Epoch 230: val_loss did not improve from 2.37085
196/196 - 61s - loss: 2.3606 - MinusLogProbMetric: 2.3606 - val_loss: 2.3906 - val_MinusLogProbMetric: 2.3906 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 231/1000
2023-09-16 05:47:11.272 
Epoch 231/1000 
	 loss: 2.3627, MinusLogProbMetric: 2.3627, val_loss: 2.4100, val_MinusLogProbMetric: 2.4100

Epoch 231: val_loss did not improve from 2.37085
196/196 - 61s - loss: 2.3627 - MinusLogProbMetric: 2.3627 - val_loss: 2.4100 - val_MinusLogProbMetric: 2.4100 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 232/1000
2023-09-16 05:48:11.908 
Epoch 232/1000 
	 loss: 2.3616, MinusLogProbMetric: 2.3616, val_loss: 2.3741, val_MinusLogProbMetric: 2.3741

Epoch 232: val_loss did not improve from 2.37085
196/196 - 61s - loss: 2.3616 - MinusLogProbMetric: 2.3616 - val_loss: 2.3741 - val_MinusLogProbMetric: 2.3741 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 233/1000
2023-09-16 05:49:12.250 
Epoch 233/1000 
	 loss: 2.3571, MinusLogProbMetric: 2.3571, val_loss: 2.3698, val_MinusLogProbMetric: 2.3698

Epoch 233: val_loss improved from 2.37085 to 2.36983, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 61s - loss: 2.3571 - MinusLogProbMetric: 2.3571 - val_loss: 2.3698 - val_MinusLogProbMetric: 2.3698 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 234/1000
2023-09-16 05:50:13.553 
Epoch 234/1000 
	 loss: 2.3659, MinusLogProbMetric: 2.3659, val_loss: 2.3761, val_MinusLogProbMetric: 2.3761

Epoch 234: val_loss did not improve from 2.36983
196/196 - 60s - loss: 2.3659 - MinusLogProbMetric: 2.3659 - val_loss: 2.3761 - val_MinusLogProbMetric: 2.3761 - lr: 5.0000e-04 - 60s/epoch - 309ms/step
Epoch 235/1000
2023-09-16 05:51:14.074 
Epoch 235/1000 
	 loss: 2.3581, MinusLogProbMetric: 2.3581, val_loss: 2.4014, val_MinusLogProbMetric: 2.4014

Epoch 235: val_loss did not improve from 2.36983
196/196 - 61s - loss: 2.3581 - MinusLogProbMetric: 2.3581 - val_loss: 2.4014 - val_MinusLogProbMetric: 2.4014 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 236/1000
2023-09-16 05:52:14.820 
Epoch 236/1000 
	 loss: 2.3643, MinusLogProbMetric: 2.3643, val_loss: 2.3782, val_MinusLogProbMetric: 2.3782

Epoch 236: val_loss did not improve from 2.36983
196/196 - 61s - loss: 2.3643 - MinusLogProbMetric: 2.3643 - val_loss: 2.3782 - val_MinusLogProbMetric: 2.3782 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 237/1000
2023-09-16 05:53:15.729 
Epoch 237/1000 
	 loss: 2.3572, MinusLogProbMetric: 2.3572, val_loss: 2.3728, val_MinusLogProbMetric: 2.3728

Epoch 237: val_loss did not improve from 2.36983
196/196 - 61s - loss: 2.3572 - MinusLogProbMetric: 2.3572 - val_loss: 2.3728 - val_MinusLogProbMetric: 2.3728 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 238/1000
2023-09-16 05:54:16.345 
Epoch 238/1000 
	 loss: 2.3558, MinusLogProbMetric: 2.3558, val_loss: 2.3769, val_MinusLogProbMetric: 2.3769

Epoch 238: val_loss did not improve from 2.36983
196/196 - 61s - loss: 2.3558 - MinusLogProbMetric: 2.3558 - val_loss: 2.3769 - val_MinusLogProbMetric: 2.3769 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 239/1000
2023-09-16 05:55:17.518 
Epoch 239/1000 
	 loss: 2.3637, MinusLogProbMetric: 2.3637, val_loss: 2.3690, val_MinusLogProbMetric: 2.3690

Epoch 239: val_loss improved from 2.36983 to 2.36896, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 62s - loss: 2.3637 - MinusLogProbMetric: 2.3637 - val_loss: 2.3690 - val_MinusLogProbMetric: 2.3690 - lr: 5.0000e-04 - 62s/epoch - 317ms/step
Epoch 240/1000
2023-09-16 05:56:19.306 
Epoch 240/1000 
	 loss: 2.3588, MinusLogProbMetric: 2.3588, val_loss: 2.3717, val_MinusLogProbMetric: 2.3717

Epoch 240: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3588 - MinusLogProbMetric: 2.3588 - val_loss: 2.3717 - val_MinusLogProbMetric: 2.3717 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 241/1000
2023-09-16 05:57:20.390 
Epoch 241/1000 
	 loss: 2.3626, MinusLogProbMetric: 2.3626, val_loss: 2.3780, val_MinusLogProbMetric: 2.3780

Epoch 241: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3626 - MinusLogProbMetric: 2.3626 - val_loss: 2.3780 - val_MinusLogProbMetric: 2.3780 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 242/1000
2023-09-16 05:58:21.095 
Epoch 242/1000 
	 loss: 2.3589, MinusLogProbMetric: 2.3589, val_loss: 2.3701, val_MinusLogProbMetric: 2.3701

Epoch 242: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3589 - MinusLogProbMetric: 2.3589 - val_loss: 2.3701 - val_MinusLogProbMetric: 2.3701 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 243/1000
2023-09-16 05:59:21.754 
Epoch 243/1000 
	 loss: 2.3560, MinusLogProbMetric: 2.3560, val_loss: 2.3841, val_MinusLogProbMetric: 2.3841

Epoch 243: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3560 - MinusLogProbMetric: 2.3560 - val_loss: 2.3841 - val_MinusLogProbMetric: 2.3841 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 244/1000
2023-09-16 06:00:22.826 
Epoch 244/1000 
	 loss: 2.3580, MinusLogProbMetric: 2.3580, val_loss: 2.3904, val_MinusLogProbMetric: 2.3904

Epoch 244: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3580 - MinusLogProbMetric: 2.3580 - val_loss: 2.3904 - val_MinusLogProbMetric: 2.3904 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 245/1000
2023-09-16 06:01:23.399 
Epoch 245/1000 
	 loss: 2.3589, MinusLogProbMetric: 2.3589, val_loss: 2.3835, val_MinusLogProbMetric: 2.3835

Epoch 245: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3589 - MinusLogProbMetric: 2.3589 - val_loss: 2.3835 - val_MinusLogProbMetric: 2.3835 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 246/1000
2023-09-16 06:02:23.795 
Epoch 246/1000 
	 loss: 2.3581, MinusLogProbMetric: 2.3581, val_loss: 2.3780, val_MinusLogProbMetric: 2.3780

Epoch 246: val_loss did not improve from 2.36896
196/196 - 60s - loss: 2.3581 - MinusLogProbMetric: 2.3581 - val_loss: 2.3780 - val_MinusLogProbMetric: 2.3780 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 247/1000
2023-09-16 06:03:24.146 
Epoch 247/1000 
	 loss: 2.3546, MinusLogProbMetric: 2.3546, val_loss: 2.3765, val_MinusLogProbMetric: 2.3765

Epoch 247: val_loss did not improve from 2.36896
196/196 - 60s - loss: 2.3546 - MinusLogProbMetric: 2.3546 - val_loss: 2.3765 - val_MinusLogProbMetric: 2.3765 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 248/1000
2023-09-16 06:04:25.249 
Epoch 248/1000 
	 loss: 2.3616, MinusLogProbMetric: 2.3616, val_loss: 2.3753, val_MinusLogProbMetric: 2.3753

Epoch 248: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3616 - MinusLogProbMetric: 2.3616 - val_loss: 2.3753 - val_MinusLogProbMetric: 2.3753 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 249/1000
2023-09-16 06:05:26.038 
Epoch 249/1000 
	 loss: 2.3574, MinusLogProbMetric: 2.3574, val_loss: 2.3920, val_MinusLogProbMetric: 2.3920

Epoch 249: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3574 - MinusLogProbMetric: 2.3574 - val_loss: 2.3920 - val_MinusLogProbMetric: 2.3920 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 250/1000
2023-09-16 06:06:27.063 
Epoch 250/1000 
	 loss: 2.3558, MinusLogProbMetric: 2.3558, val_loss: 2.3787, val_MinusLogProbMetric: 2.3787

Epoch 250: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3558 - MinusLogProbMetric: 2.3558 - val_loss: 2.3787 - val_MinusLogProbMetric: 2.3787 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 251/1000
2023-09-16 06:07:27.407 
Epoch 251/1000 
	 loss: 2.3575, MinusLogProbMetric: 2.3575, val_loss: 2.3906, val_MinusLogProbMetric: 2.3906

Epoch 251: val_loss did not improve from 2.36896
196/196 - 60s - loss: 2.3575 - MinusLogProbMetric: 2.3575 - val_loss: 2.3906 - val_MinusLogProbMetric: 2.3906 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 252/1000
2023-09-16 06:08:28.080 
Epoch 252/1000 
	 loss: 2.3558, MinusLogProbMetric: 2.3558, val_loss: 2.3731, val_MinusLogProbMetric: 2.3731

Epoch 252: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3558 - MinusLogProbMetric: 2.3558 - val_loss: 2.3731 - val_MinusLogProbMetric: 2.3731 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 253/1000
2023-09-16 06:09:29.614 
Epoch 253/1000 
	 loss: 2.3616, MinusLogProbMetric: 2.3616, val_loss: 2.3748, val_MinusLogProbMetric: 2.3748

Epoch 253: val_loss did not improve from 2.36896
196/196 - 62s - loss: 2.3616 - MinusLogProbMetric: 2.3616 - val_loss: 2.3748 - val_MinusLogProbMetric: 2.3748 - lr: 5.0000e-04 - 62s/epoch - 314ms/step
Epoch 254/1000
2023-09-16 06:10:30.910 
Epoch 254/1000 
	 loss: 2.3565, MinusLogProbMetric: 2.3565, val_loss: 2.3776, val_MinusLogProbMetric: 2.3776

Epoch 254: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3565 - MinusLogProbMetric: 2.3565 - val_loss: 2.3776 - val_MinusLogProbMetric: 2.3776 - lr: 5.0000e-04 - 61s/epoch - 313ms/step
Epoch 255/1000
2023-09-16 06:11:30.994 
Epoch 255/1000 
	 loss: 2.3603, MinusLogProbMetric: 2.3603, val_loss: 2.3804, val_MinusLogProbMetric: 2.3804

Epoch 255: val_loss did not improve from 2.36896
196/196 - 60s - loss: 2.3603 - MinusLogProbMetric: 2.3603 - val_loss: 2.3804 - val_MinusLogProbMetric: 2.3804 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 256/1000
2023-09-16 06:12:31.252 
Epoch 256/1000 
	 loss: 2.3631, MinusLogProbMetric: 2.3631, val_loss: 2.3800, val_MinusLogProbMetric: 2.3800

Epoch 256: val_loss did not improve from 2.36896
196/196 - 60s - loss: 2.3631 - MinusLogProbMetric: 2.3631 - val_loss: 2.3800 - val_MinusLogProbMetric: 2.3800 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 257/1000
2023-09-16 06:13:31.346 
Epoch 257/1000 
	 loss: 2.3587, MinusLogProbMetric: 2.3587, val_loss: 2.3737, val_MinusLogProbMetric: 2.3737

Epoch 257: val_loss did not improve from 2.36896
196/196 - 60s - loss: 2.3587 - MinusLogProbMetric: 2.3587 - val_loss: 2.3737 - val_MinusLogProbMetric: 2.3737 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 258/1000
2023-09-16 06:14:31.961 
Epoch 258/1000 
	 loss: 2.3614, MinusLogProbMetric: 2.3614, val_loss: 2.3832, val_MinusLogProbMetric: 2.3832

Epoch 258: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3614 - MinusLogProbMetric: 2.3614 - val_loss: 2.3832 - val_MinusLogProbMetric: 2.3832 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 259/1000
2023-09-16 06:15:32.256 
Epoch 259/1000 
	 loss: 2.3583, MinusLogProbMetric: 2.3583, val_loss: 2.3780, val_MinusLogProbMetric: 2.3780

Epoch 259: val_loss did not improve from 2.36896
196/196 - 60s - loss: 2.3583 - MinusLogProbMetric: 2.3583 - val_loss: 2.3780 - val_MinusLogProbMetric: 2.3780 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 260/1000
2023-09-16 06:16:33.091 
Epoch 260/1000 
	 loss: 2.3651, MinusLogProbMetric: 2.3651, val_loss: 2.4107, val_MinusLogProbMetric: 2.4107

Epoch 260: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3651 - MinusLogProbMetric: 2.3651 - val_loss: 2.4107 - val_MinusLogProbMetric: 2.4107 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 261/1000
2023-09-16 06:17:33.210 
Epoch 261/1000 
	 loss: 2.3588, MinusLogProbMetric: 2.3588, val_loss: 2.4106, val_MinusLogProbMetric: 2.4106

Epoch 261: val_loss did not improve from 2.36896
196/196 - 60s - loss: 2.3588 - MinusLogProbMetric: 2.3588 - val_loss: 2.4106 - val_MinusLogProbMetric: 2.4106 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 262/1000
2023-09-16 06:18:34.078 
Epoch 262/1000 
	 loss: 2.3594, MinusLogProbMetric: 2.3594, val_loss: 2.3884, val_MinusLogProbMetric: 2.3884

Epoch 262: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3594 - MinusLogProbMetric: 2.3594 - val_loss: 2.3884 - val_MinusLogProbMetric: 2.3884 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 263/1000
2023-09-16 06:19:35.056 
Epoch 263/1000 
	 loss: 2.3621, MinusLogProbMetric: 2.3621, val_loss: 2.3754, val_MinusLogProbMetric: 2.3754

Epoch 263: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3621 - MinusLogProbMetric: 2.3621 - val_loss: 2.3754 - val_MinusLogProbMetric: 2.3754 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 264/1000
2023-09-16 06:20:35.990 
Epoch 264/1000 
	 loss: 2.3588, MinusLogProbMetric: 2.3588, val_loss: 2.3830, val_MinusLogProbMetric: 2.3830

Epoch 264: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3588 - MinusLogProbMetric: 2.3588 - val_loss: 2.3830 - val_MinusLogProbMetric: 2.3830 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 265/1000
2023-09-16 06:21:36.678 
Epoch 265/1000 
	 loss: 2.3556, MinusLogProbMetric: 2.3556, val_loss: 2.3720, val_MinusLogProbMetric: 2.3720

Epoch 265: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3556 - MinusLogProbMetric: 2.3556 - val_loss: 2.3720 - val_MinusLogProbMetric: 2.3720 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 266/1000
2023-09-16 06:22:37.507 
Epoch 266/1000 
	 loss: 2.3592, MinusLogProbMetric: 2.3592, val_loss: 2.3908, val_MinusLogProbMetric: 2.3908

Epoch 266: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3592 - MinusLogProbMetric: 2.3592 - val_loss: 2.3908 - val_MinusLogProbMetric: 2.3908 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 267/1000
2023-09-16 06:23:38.155 
Epoch 267/1000 
	 loss: 2.3586, MinusLogProbMetric: 2.3586, val_loss: 2.3818, val_MinusLogProbMetric: 2.3818

Epoch 267: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3586 - MinusLogProbMetric: 2.3586 - val_loss: 2.3818 - val_MinusLogProbMetric: 2.3818 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 268/1000
2023-09-16 06:24:38.205 
Epoch 268/1000 
	 loss: 2.3580, MinusLogProbMetric: 2.3580, val_loss: 2.3797, val_MinusLogProbMetric: 2.3797

Epoch 268: val_loss did not improve from 2.36896
196/196 - 60s - loss: 2.3580 - MinusLogProbMetric: 2.3580 - val_loss: 2.3797 - val_MinusLogProbMetric: 2.3797 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 269/1000
2023-09-16 06:25:38.765 
Epoch 269/1000 
	 loss: 2.3545, MinusLogProbMetric: 2.3545, val_loss: 2.3792, val_MinusLogProbMetric: 2.3792

Epoch 269: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3545 - MinusLogProbMetric: 2.3545 - val_loss: 2.3792 - val_MinusLogProbMetric: 2.3792 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 270/1000
2023-09-16 06:26:39.457 
Epoch 270/1000 
	 loss: 2.3564, MinusLogProbMetric: 2.3564, val_loss: 2.3729, val_MinusLogProbMetric: 2.3729

Epoch 270: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3564 - MinusLogProbMetric: 2.3564 - val_loss: 2.3729 - val_MinusLogProbMetric: 2.3729 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 271/1000
2023-09-16 06:27:40.249 
Epoch 271/1000 
	 loss: 2.3588, MinusLogProbMetric: 2.3588, val_loss: 2.4033, val_MinusLogProbMetric: 2.4033

Epoch 271: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3588 - MinusLogProbMetric: 2.3588 - val_loss: 2.4033 - val_MinusLogProbMetric: 2.4033 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 272/1000
2023-09-16 06:28:40.463 
Epoch 272/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.3804, val_MinusLogProbMetric: 2.3804

Epoch 272: val_loss did not improve from 2.36896
196/196 - 60s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.3804 - val_MinusLogProbMetric: 2.3804 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 273/1000
2023-09-16 06:29:40.808 
Epoch 273/1000 
	 loss: 2.3574, MinusLogProbMetric: 2.3574, val_loss: 2.3754, val_MinusLogProbMetric: 2.3754

Epoch 273: val_loss did not improve from 2.36896
196/196 - 60s - loss: 2.3574 - MinusLogProbMetric: 2.3574 - val_loss: 2.3754 - val_MinusLogProbMetric: 2.3754 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 274/1000
2023-09-16 06:30:42.066 
Epoch 274/1000 
	 loss: 2.3616, MinusLogProbMetric: 2.3616, val_loss: 2.4035, val_MinusLogProbMetric: 2.4035

Epoch 274: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3616 - MinusLogProbMetric: 2.3616 - val_loss: 2.4035 - val_MinusLogProbMetric: 2.4035 - lr: 5.0000e-04 - 61s/epoch - 313ms/step
Epoch 275/1000
2023-09-16 06:31:42.460 
Epoch 275/1000 
	 loss: 2.3585, MinusLogProbMetric: 2.3585, val_loss: 2.3839, val_MinusLogProbMetric: 2.3839

Epoch 275: val_loss did not improve from 2.36896
196/196 - 60s - loss: 2.3585 - MinusLogProbMetric: 2.3585 - val_loss: 2.3839 - val_MinusLogProbMetric: 2.3839 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 276/1000
2023-09-16 06:32:43.728 
Epoch 276/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3767, val_MinusLogProbMetric: 2.3767

Epoch 276: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3767 - val_MinusLogProbMetric: 2.3767 - lr: 5.0000e-04 - 61s/epoch - 313ms/step
Epoch 277/1000
2023-09-16 06:33:44.667 
Epoch 277/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.3707, val_MinusLogProbMetric: 2.3707

Epoch 277: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.3707 - val_MinusLogProbMetric: 2.3707 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 278/1000
2023-09-16 06:34:45.869 
Epoch 278/1000 
	 loss: 2.3565, MinusLogProbMetric: 2.3565, val_loss: 2.3737, val_MinusLogProbMetric: 2.3737

Epoch 278: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3565 - MinusLogProbMetric: 2.3565 - val_loss: 2.3737 - val_MinusLogProbMetric: 2.3737 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 279/1000
2023-09-16 06:35:46.470 
Epoch 279/1000 
	 loss: 2.3570, MinusLogProbMetric: 2.3570, val_loss: 2.4103, val_MinusLogProbMetric: 2.4103

Epoch 279: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3570 - MinusLogProbMetric: 2.3570 - val_loss: 2.4103 - val_MinusLogProbMetric: 2.4103 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 280/1000
2023-09-16 06:36:47.422 
Epoch 280/1000 
	 loss: 2.3539, MinusLogProbMetric: 2.3539, val_loss: 2.3955, val_MinusLogProbMetric: 2.3955

Epoch 280: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3539 - MinusLogProbMetric: 2.3539 - val_loss: 2.3955 - val_MinusLogProbMetric: 2.3955 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 281/1000
2023-09-16 06:37:48.218 
Epoch 281/1000 
	 loss: 2.3572, MinusLogProbMetric: 2.3572, val_loss: 2.3729, val_MinusLogProbMetric: 2.3729

Epoch 281: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3572 - MinusLogProbMetric: 2.3572 - val_loss: 2.3729 - val_MinusLogProbMetric: 2.3729 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 282/1000
2023-09-16 06:38:49.205 
Epoch 282/1000 
	 loss: 2.3538, MinusLogProbMetric: 2.3538, val_loss: 2.3818, val_MinusLogProbMetric: 2.3818

Epoch 282: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3538 - MinusLogProbMetric: 2.3538 - val_loss: 2.3818 - val_MinusLogProbMetric: 2.3818 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 283/1000
2023-09-16 06:39:49.589 
Epoch 283/1000 
	 loss: 2.3542, MinusLogProbMetric: 2.3542, val_loss: 2.3721, val_MinusLogProbMetric: 2.3721

Epoch 283: val_loss did not improve from 2.36896
196/196 - 60s - loss: 2.3542 - MinusLogProbMetric: 2.3542 - val_loss: 2.3721 - val_MinusLogProbMetric: 2.3721 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 284/1000
2023-09-16 06:40:50.083 
Epoch 284/1000 
	 loss: 2.3538, MinusLogProbMetric: 2.3538, val_loss: 2.3754, val_MinusLogProbMetric: 2.3754

Epoch 284: val_loss did not improve from 2.36896
196/196 - 60s - loss: 2.3538 - MinusLogProbMetric: 2.3538 - val_loss: 2.3754 - val_MinusLogProbMetric: 2.3754 - lr: 5.0000e-04 - 60s/epoch - 309ms/step
Epoch 285/1000
2023-09-16 06:41:50.573 
Epoch 285/1000 
	 loss: 2.3558, MinusLogProbMetric: 2.3558, val_loss: 2.3756, val_MinusLogProbMetric: 2.3756

Epoch 285: val_loss did not improve from 2.36896
196/196 - 60s - loss: 2.3558 - MinusLogProbMetric: 2.3558 - val_loss: 2.3756 - val_MinusLogProbMetric: 2.3756 - lr: 5.0000e-04 - 60s/epoch - 309ms/step
Epoch 286/1000
2023-09-16 06:42:51.090 
Epoch 286/1000 
	 loss: 2.3537, MinusLogProbMetric: 2.3537, val_loss: 2.3778, val_MinusLogProbMetric: 2.3778

Epoch 286: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3537 - MinusLogProbMetric: 2.3537 - val_loss: 2.3778 - val_MinusLogProbMetric: 2.3778 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 287/1000
2023-09-16 06:43:52.341 
Epoch 287/1000 
	 loss: 2.3547, MinusLogProbMetric: 2.3547, val_loss: 2.3783, val_MinusLogProbMetric: 2.3783

Epoch 287: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3547 - MinusLogProbMetric: 2.3547 - val_loss: 2.3783 - val_MinusLogProbMetric: 2.3783 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 288/1000
2023-09-16 06:44:54.188 
Epoch 288/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.3827, val_MinusLogProbMetric: 2.3827

Epoch 288: val_loss did not improve from 2.36896
196/196 - 62s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.3827 - val_MinusLogProbMetric: 2.3827 - lr: 5.0000e-04 - 62s/epoch - 316ms/step
Epoch 289/1000
2023-09-16 06:45:55.417 
Epoch 289/1000 
	 loss: 2.3574, MinusLogProbMetric: 2.3574, val_loss: 2.3722, val_MinusLogProbMetric: 2.3722

Epoch 289: val_loss did not improve from 2.36896
196/196 - 61s - loss: 2.3574 - MinusLogProbMetric: 2.3574 - val_loss: 2.3722 - val_MinusLogProbMetric: 2.3722 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 290/1000
2023-09-16 06:46:56.107 
Epoch 290/1000 
	 loss: 2.3459, MinusLogProbMetric: 2.3459, val_loss: 2.3683, val_MinusLogProbMetric: 2.3683

Epoch 290: val_loss improved from 2.36896 to 2.36830, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_61/weights/best_weights.h5
196/196 - 62s - loss: 2.3459 - MinusLogProbMetric: 2.3459 - val_loss: 2.3683 - val_MinusLogProbMetric: 2.3683 - lr: 2.5000e-04 - 62s/epoch - 315ms/step
Epoch 291/1000
2023-09-16 06:47:57.743 
Epoch 291/1000 
	 loss: 2.3453, MinusLogProbMetric: 2.3453, val_loss: 2.3712, val_MinusLogProbMetric: 2.3712

Epoch 291: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3453 - MinusLogProbMetric: 2.3453 - val_loss: 2.3712 - val_MinusLogProbMetric: 2.3712 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 292/1000
2023-09-16 06:48:58.622 
Epoch 292/1000 
	 loss: 2.3458, MinusLogProbMetric: 2.3458, val_loss: 2.3710, val_MinusLogProbMetric: 2.3710

Epoch 292: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3458 - MinusLogProbMetric: 2.3458 - val_loss: 2.3710 - val_MinusLogProbMetric: 2.3710 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 293/1000
2023-09-16 06:49:59.717 
Epoch 293/1000 
	 loss: 2.3488, MinusLogProbMetric: 2.3488, val_loss: 2.3711, val_MinusLogProbMetric: 2.3711

Epoch 293: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3488 - MinusLogProbMetric: 2.3488 - val_loss: 2.3711 - val_MinusLogProbMetric: 2.3711 - lr: 2.5000e-04 - 61s/epoch - 312ms/step
Epoch 294/1000
2023-09-16 06:51:00.408 
Epoch 294/1000 
	 loss: 2.3464, MinusLogProbMetric: 2.3464, val_loss: 2.3725, val_MinusLogProbMetric: 2.3725

Epoch 294: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3464 - MinusLogProbMetric: 2.3464 - val_loss: 2.3725 - val_MinusLogProbMetric: 2.3725 - lr: 2.5000e-04 - 61s/epoch - 310ms/step
Epoch 295/1000
2023-09-16 06:52:00.995 
Epoch 295/1000 
	 loss: 2.3465, MinusLogProbMetric: 2.3465, val_loss: 2.3836, val_MinusLogProbMetric: 2.3836

Epoch 295: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3465 - MinusLogProbMetric: 2.3465 - val_loss: 2.3836 - val_MinusLogProbMetric: 2.3836 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 296/1000
2023-09-16 06:53:01.580 
Epoch 296/1000 
	 loss: 2.3452, MinusLogProbMetric: 2.3452, val_loss: 2.3717, val_MinusLogProbMetric: 2.3717

Epoch 296: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3452 - MinusLogProbMetric: 2.3452 - val_loss: 2.3717 - val_MinusLogProbMetric: 2.3717 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 297/1000
2023-09-16 06:54:01.963 
Epoch 297/1000 
	 loss: 2.3461, MinusLogProbMetric: 2.3461, val_loss: 2.3846, val_MinusLogProbMetric: 2.3846

Epoch 297: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3461 - MinusLogProbMetric: 2.3461 - val_loss: 2.3846 - val_MinusLogProbMetric: 2.3846 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 298/1000
2023-09-16 06:55:03.296 
Epoch 298/1000 
	 loss: 2.3475, MinusLogProbMetric: 2.3475, val_loss: 2.3696, val_MinusLogProbMetric: 2.3696

Epoch 298: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3475 - MinusLogProbMetric: 2.3475 - val_loss: 2.3696 - val_MinusLogProbMetric: 2.3696 - lr: 2.5000e-04 - 61s/epoch - 313ms/step
Epoch 299/1000
2023-09-16 06:56:03.850 
Epoch 299/1000 
	 loss: 2.3457, MinusLogProbMetric: 2.3457, val_loss: 2.3715, val_MinusLogProbMetric: 2.3715

Epoch 299: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3457 - MinusLogProbMetric: 2.3457 - val_loss: 2.3715 - val_MinusLogProbMetric: 2.3715 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 300/1000
2023-09-16 06:57:04.545 
Epoch 300/1000 
	 loss: 2.3460, MinusLogProbMetric: 2.3460, val_loss: 2.3750, val_MinusLogProbMetric: 2.3750

Epoch 300: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3460 - MinusLogProbMetric: 2.3460 - val_loss: 2.3750 - val_MinusLogProbMetric: 2.3750 - lr: 2.5000e-04 - 61s/epoch - 310ms/step
Epoch 301/1000
2023-09-16 06:58:05.324 
Epoch 301/1000 
	 loss: 2.3473, MinusLogProbMetric: 2.3473, val_loss: 2.3747, val_MinusLogProbMetric: 2.3747

Epoch 301: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3473 - MinusLogProbMetric: 2.3473 - val_loss: 2.3747 - val_MinusLogProbMetric: 2.3747 - lr: 2.5000e-04 - 61s/epoch - 310ms/step
Epoch 302/1000
2023-09-16 06:59:06.344 
Epoch 302/1000 
	 loss: 2.3450, MinusLogProbMetric: 2.3450, val_loss: 2.3721, val_MinusLogProbMetric: 2.3721

Epoch 302: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3450 - MinusLogProbMetric: 2.3450 - val_loss: 2.3721 - val_MinusLogProbMetric: 2.3721 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 303/1000
2023-09-16 07:00:07.312 
Epoch 303/1000 
	 loss: 2.3469, MinusLogProbMetric: 2.3469, val_loss: 2.3733, val_MinusLogProbMetric: 2.3733

Epoch 303: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3469 - MinusLogProbMetric: 2.3469 - val_loss: 2.3733 - val_MinusLogProbMetric: 2.3733 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 304/1000
2023-09-16 07:01:07.685 
Epoch 304/1000 
	 loss: 2.3444, MinusLogProbMetric: 2.3444, val_loss: 2.3723, val_MinusLogProbMetric: 2.3723

Epoch 304: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3444 - MinusLogProbMetric: 2.3444 - val_loss: 2.3723 - val_MinusLogProbMetric: 2.3723 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 305/1000
2023-09-16 07:02:08.927 
Epoch 305/1000 
	 loss: 2.3487, MinusLogProbMetric: 2.3487, val_loss: 2.3704, val_MinusLogProbMetric: 2.3704

Epoch 305: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3487 - MinusLogProbMetric: 2.3487 - val_loss: 2.3704 - val_MinusLogProbMetric: 2.3704 - lr: 2.5000e-04 - 61s/epoch - 312ms/step
Epoch 306/1000
2023-09-16 07:03:09.730 
Epoch 306/1000 
	 loss: 2.3438, MinusLogProbMetric: 2.3438, val_loss: 2.3730, val_MinusLogProbMetric: 2.3730

Epoch 306: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3438 - MinusLogProbMetric: 2.3438 - val_loss: 2.3730 - val_MinusLogProbMetric: 2.3730 - lr: 2.5000e-04 - 61s/epoch - 310ms/step
Epoch 307/1000
2023-09-16 07:04:11.189 
Epoch 307/1000 
	 loss: 2.3480, MinusLogProbMetric: 2.3480, val_loss: 2.3750, val_MinusLogProbMetric: 2.3750

Epoch 307: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3480 - MinusLogProbMetric: 2.3480 - val_loss: 2.3750 - val_MinusLogProbMetric: 2.3750 - lr: 2.5000e-04 - 61s/epoch - 314ms/step
Epoch 308/1000
2023-09-16 07:05:11.777 
Epoch 308/1000 
	 loss: 2.3482, MinusLogProbMetric: 2.3482, val_loss: 2.3748, val_MinusLogProbMetric: 2.3748

Epoch 308: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3482 - MinusLogProbMetric: 2.3482 - val_loss: 2.3748 - val_MinusLogProbMetric: 2.3748 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 309/1000
2023-09-16 07:06:11.790 
Epoch 309/1000 
	 loss: 2.3454, MinusLogProbMetric: 2.3454, val_loss: 2.3833, val_MinusLogProbMetric: 2.3833

Epoch 309: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3454 - MinusLogProbMetric: 2.3454 - val_loss: 2.3833 - val_MinusLogProbMetric: 2.3833 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 310/1000
2023-09-16 07:07:12.062 
Epoch 310/1000 
	 loss: 2.3465, MinusLogProbMetric: 2.3465, val_loss: 2.3742, val_MinusLogProbMetric: 2.3742

Epoch 310: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3465 - MinusLogProbMetric: 2.3465 - val_loss: 2.3742 - val_MinusLogProbMetric: 2.3742 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 311/1000
2023-09-16 07:08:13.027 
Epoch 311/1000 
	 loss: 2.3493, MinusLogProbMetric: 2.3493, val_loss: 2.3753, val_MinusLogProbMetric: 2.3753

Epoch 311: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3493 - MinusLogProbMetric: 2.3493 - val_loss: 2.3753 - val_MinusLogProbMetric: 2.3753 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 312/1000
2023-09-16 07:09:13.686 
Epoch 312/1000 
	 loss: 2.3461, MinusLogProbMetric: 2.3461, val_loss: 2.3898, val_MinusLogProbMetric: 2.3898

Epoch 312: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3461 - MinusLogProbMetric: 2.3461 - val_loss: 2.3898 - val_MinusLogProbMetric: 2.3898 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 313/1000
2023-09-16 07:10:14.366 
Epoch 313/1000 
	 loss: 2.3448, MinusLogProbMetric: 2.3448, val_loss: 2.3701, val_MinusLogProbMetric: 2.3701

Epoch 313: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3448 - MinusLogProbMetric: 2.3448 - val_loss: 2.3701 - val_MinusLogProbMetric: 2.3701 - lr: 2.5000e-04 - 61s/epoch - 310ms/step
Epoch 314/1000
2023-09-16 07:11:15.242 
Epoch 314/1000 
	 loss: 2.3466, MinusLogProbMetric: 2.3466, val_loss: 2.3738, val_MinusLogProbMetric: 2.3738

Epoch 314: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3466 - MinusLogProbMetric: 2.3466 - val_loss: 2.3738 - val_MinusLogProbMetric: 2.3738 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 315/1000
2023-09-16 07:12:16.158 
Epoch 315/1000 
	 loss: 2.3459, MinusLogProbMetric: 2.3459, val_loss: 2.3861, val_MinusLogProbMetric: 2.3861

Epoch 315: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3459 - MinusLogProbMetric: 2.3459 - val_loss: 2.3861 - val_MinusLogProbMetric: 2.3861 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 316/1000
2023-09-16 07:13:16.209 
Epoch 316/1000 
	 loss: 2.3447, MinusLogProbMetric: 2.3447, val_loss: 2.3725, val_MinusLogProbMetric: 2.3725

Epoch 316: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3447 - MinusLogProbMetric: 2.3447 - val_loss: 2.3725 - val_MinusLogProbMetric: 2.3725 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 317/1000
2023-09-16 07:14:16.326 
Epoch 317/1000 
	 loss: 2.3450, MinusLogProbMetric: 2.3450, val_loss: 2.3775, val_MinusLogProbMetric: 2.3775

Epoch 317: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3450 - MinusLogProbMetric: 2.3450 - val_loss: 2.3775 - val_MinusLogProbMetric: 2.3775 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 318/1000
2023-09-16 07:15:16.865 
Epoch 318/1000 
	 loss: 2.3474, MinusLogProbMetric: 2.3474, val_loss: 2.3708, val_MinusLogProbMetric: 2.3708

Epoch 318: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3474 - MinusLogProbMetric: 2.3474 - val_loss: 2.3708 - val_MinusLogProbMetric: 2.3708 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 319/1000
2023-09-16 07:16:17.799 
Epoch 319/1000 
	 loss: 2.3460, MinusLogProbMetric: 2.3460, val_loss: 2.3701, val_MinusLogProbMetric: 2.3701

Epoch 319: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3460 - MinusLogProbMetric: 2.3460 - val_loss: 2.3701 - val_MinusLogProbMetric: 2.3701 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 320/1000
2023-09-16 07:17:18.316 
Epoch 320/1000 
	 loss: 2.3448, MinusLogProbMetric: 2.3448, val_loss: 2.3708, val_MinusLogProbMetric: 2.3708

Epoch 320: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3448 - MinusLogProbMetric: 2.3448 - val_loss: 2.3708 - val_MinusLogProbMetric: 2.3708 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 321/1000
2023-09-16 07:18:19.189 
Epoch 321/1000 
	 loss: 2.3457, MinusLogProbMetric: 2.3457, val_loss: 2.3692, val_MinusLogProbMetric: 2.3692

Epoch 321: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3457 - MinusLogProbMetric: 2.3457 - val_loss: 2.3692 - val_MinusLogProbMetric: 2.3692 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 322/1000
2023-09-16 07:19:19.699 
Epoch 322/1000 
	 loss: 2.3444, MinusLogProbMetric: 2.3444, val_loss: 2.3718, val_MinusLogProbMetric: 2.3718

Epoch 322: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3444 - MinusLogProbMetric: 2.3444 - val_loss: 2.3718 - val_MinusLogProbMetric: 2.3718 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 323/1000
2023-09-16 07:20:19.501 
Epoch 323/1000 
	 loss: 2.3459, MinusLogProbMetric: 2.3459, val_loss: 2.3734, val_MinusLogProbMetric: 2.3734

Epoch 323: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3459 - MinusLogProbMetric: 2.3459 - val_loss: 2.3734 - val_MinusLogProbMetric: 2.3734 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 324/1000
2023-09-16 07:21:20.039 
Epoch 324/1000 
	 loss: 2.3441, MinusLogProbMetric: 2.3441, val_loss: 2.3714, val_MinusLogProbMetric: 2.3714

Epoch 324: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3441 - MinusLogProbMetric: 2.3441 - val_loss: 2.3714 - val_MinusLogProbMetric: 2.3714 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 325/1000
2023-09-16 07:22:20.413 
Epoch 325/1000 
	 loss: 2.3468, MinusLogProbMetric: 2.3468, val_loss: 2.3734, val_MinusLogProbMetric: 2.3734

Epoch 325: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3468 - MinusLogProbMetric: 2.3468 - val_loss: 2.3734 - val_MinusLogProbMetric: 2.3734 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 326/1000
2023-09-16 07:23:21.315 
Epoch 326/1000 
	 loss: 2.3445, MinusLogProbMetric: 2.3445, val_loss: 2.3720, val_MinusLogProbMetric: 2.3720

Epoch 326: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3445 - MinusLogProbMetric: 2.3445 - val_loss: 2.3720 - val_MinusLogProbMetric: 2.3720 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 327/1000
2023-09-16 07:24:21.714 
Epoch 327/1000 
	 loss: 2.3486, MinusLogProbMetric: 2.3486, val_loss: 2.3812, val_MinusLogProbMetric: 2.3812

Epoch 327: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3486 - MinusLogProbMetric: 2.3486 - val_loss: 2.3812 - val_MinusLogProbMetric: 2.3812 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 328/1000
2023-09-16 07:25:22.603 
Epoch 328/1000 
	 loss: 2.3459, MinusLogProbMetric: 2.3459, val_loss: 2.3738, val_MinusLogProbMetric: 2.3738

Epoch 328: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3459 - MinusLogProbMetric: 2.3459 - val_loss: 2.3738 - val_MinusLogProbMetric: 2.3738 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 329/1000
2023-09-16 07:26:23.161 
Epoch 329/1000 
	 loss: 2.3458, MinusLogProbMetric: 2.3458, val_loss: 2.3749, val_MinusLogProbMetric: 2.3749

Epoch 329: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3458 - MinusLogProbMetric: 2.3458 - val_loss: 2.3749 - val_MinusLogProbMetric: 2.3749 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 330/1000
2023-09-16 07:27:23.644 
Epoch 330/1000 
	 loss: 2.3454, MinusLogProbMetric: 2.3454, val_loss: 2.3721, val_MinusLogProbMetric: 2.3721

Epoch 330: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3454 - MinusLogProbMetric: 2.3454 - val_loss: 2.3721 - val_MinusLogProbMetric: 2.3721 - lr: 2.5000e-04 - 60s/epoch - 309ms/step
Epoch 331/1000
2023-09-16 07:28:24.680 
Epoch 331/1000 
	 loss: 2.3455, MinusLogProbMetric: 2.3455, val_loss: 2.3719, val_MinusLogProbMetric: 2.3719

Epoch 331: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3455 - MinusLogProbMetric: 2.3455 - val_loss: 2.3719 - val_MinusLogProbMetric: 2.3719 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 332/1000
2023-09-16 07:29:25.875 
Epoch 332/1000 
	 loss: 2.3453, MinusLogProbMetric: 2.3453, val_loss: 2.3742, val_MinusLogProbMetric: 2.3742

Epoch 332: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3453 - MinusLogProbMetric: 2.3453 - val_loss: 2.3742 - val_MinusLogProbMetric: 2.3742 - lr: 2.5000e-04 - 61s/epoch - 312ms/step
Epoch 333/1000
2023-09-16 07:30:26.058 
Epoch 333/1000 
	 loss: 2.3445, MinusLogProbMetric: 2.3445, val_loss: 2.3830, val_MinusLogProbMetric: 2.3830

Epoch 333: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3445 - MinusLogProbMetric: 2.3445 - val_loss: 2.3830 - val_MinusLogProbMetric: 2.3830 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 334/1000
2023-09-16 07:31:27.432 
Epoch 334/1000 
	 loss: 2.3457, MinusLogProbMetric: 2.3457, val_loss: 2.3708, val_MinusLogProbMetric: 2.3708

Epoch 334: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3457 - MinusLogProbMetric: 2.3457 - val_loss: 2.3708 - val_MinusLogProbMetric: 2.3708 - lr: 2.5000e-04 - 61s/epoch - 313ms/step
Epoch 335/1000
2023-09-16 07:32:27.699 
Epoch 335/1000 
	 loss: 2.3444, MinusLogProbMetric: 2.3444, val_loss: 2.3717, val_MinusLogProbMetric: 2.3717

Epoch 335: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3444 - MinusLogProbMetric: 2.3444 - val_loss: 2.3717 - val_MinusLogProbMetric: 2.3717 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 336/1000
2023-09-16 07:33:28.640 
Epoch 336/1000 
	 loss: 2.3438, MinusLogProbMetric: 2.3438, val_loss: 2.3709, val_MinusLogProbMetric: 2.3709

Epoch 336: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3438 - MinusLogProbMetric: 2.3438 - val_loss: 2.3709 - val_MinusLogProbMetric: 2.3709 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 337/1000
2023-09-16 07:34:29.729 
Epoch 337/1000 
	 loss: 2.3454, MinusLogProbMetric: 2.3454, val_loss: 2.3725, val_MinusLogProbMetric: 2.3725

Epoch 337: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3454 - MinusLogProbMetric: 2.3454 - val_loss: 2.3725 - val_MinusLogProbMetric: 2.3725 - lr: 2.5000e-04 - 61s/epoch - 312ms/step
Epoch 338/1000
2023-09-16 07:35:30.686 
Epoch 338/1000 
	 loss: 2.3460, MinusLogProbMetric: 2.3460, val_loss: 2.3734, val_MinusLogProbMetric: 2.3734

Epoch 338: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3460 - MinusLogProbMetric: 2.3460 - val_loss: 2.3734 - val_MinusLogProbMetric: 2.3734 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 339/1000
2023-09-16 07:36:31.790 
Epoch 339/1000 
	 loss: 2.3469, MinusLogProbMetric: 2.3469, val_loss: 2.3719, val_MinusLogProbMetric: 2.3719

Epoch 339: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3469 - MinusLogProbMetric: 2.3469 - val_loss: 2.3719 - val_MinusLogProbMetric: 2.3719 - lr: 2.5000e-04 - 61s/epoch - 312ms/step
Epoch 340/1000
2023-09-16 07:37:32.296 
Epoch 340/1000 
	 loss: 2.3458, MinusLogProbMetric: 2.3458, val_loss: 2.3728, val_MinusLogProbMetric: 2.3728

Epoch 340: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3458 - MinusLogProbMetric: 2.3458 - val_loss: 2.3728 - val_MinusLogProbMetric: 2.3728 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 341/1000
2023-09-16 07:38:33.140 
Epoch 341/1000 
	 loss: 2.3403, MinusLogProbMetric: 2.3403, val_loss: 2.3693, val_MinusLogProbMetric: 2.3693

Epoch 341: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3403 - MinusLogProbMetric: 2.3403 - val_loss: 2.3693 - val_MinusLogProbMetric: 2.3693 - lr: 1.2500e-04 - 61s/epoch - 310ms/step
Epoch 342/1000
2023-09-16 07:39:33.718 
Epoch 342/1000 
	 loss: 2.3394, MinusLogProbMetric: 2.3394, val_loss: 2.3712, val_MinusLogProbMetric: 2.3712

Epoch 342: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3394 - MinusLogProbMetric: 2.3394 - val_loss: 2.3712 - val_MinusLogProbMetric: 2.3712 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 343/1000
2023-09-16 07:40:34.139 
Epoch 343/1000 
	 loss: 2.3413, MinusLogProbMetric: 2.3413, val_loss: 2.3688, val_MinusLogProbMetric: 2.3688

Epoch 343: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3413 - MinusLogProbMetric: 2.3413 - val_loss: 2.3688 - val_MinusLogProbMetric: 2.3688 - lr: 1.2500e-04 - 60s/epoch - 308ms/step
Epoch 344/1000
2023-09-16 07:41:34.805 
Epoch 344/1000 
	 loss: 2.3398, MinusLogProbMetric: 2.3398, val_loss: 2.3707, val_MinusLogProbMetric: 2.3707

Epoch 344: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3398 - MinusLogProbMetric: 2.3398 - val_loss: 2.3707 - val_MinusLogProbMetric: 2.3707 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 345/1000
2023-09-16 07:42:35.468 
Epoch 345/1000 
	 loss: 2.3394, MinusLogProbMetric: 2.3394, val_loss: 2.3700, val_MinusLogProbMetric: 2.3700

Epoch 345: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3394 - MinusLogProbMetric: 2.3394 - val_loss: 2.3700 - val_MinusLogProbMetric: 2.3700 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 346/1000
2023-09-16 07:43:36.335 
Epoch 346/1000 
	 loss: 2.3402, MinusLogProbMetric: 2.3402, val_loss: 2.3704, val_MinusLogProbMetric: 2.3704

Epoch 346: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3402 - MinusLogProbMetric: 2.3402 - val_loss: 2.3704 - val_MinusLogProbMetric: 2.3704 - lr: 1.2500e-04 - 61s/epoch - 311ms/step
Epoch 347/1000
2023-09-16 07:44:36.664 
Epoch 347/1000 
	 loss: 2.3405, MinusLogProbMetric: 2.3405, val_loss: 2.3799, val_MinusLogProbMetric: 2.3799

Epoch 347: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3405 - MinusLogProbMetric: 2.3405 - val_loss: 2.3799 - val_MinusLogProbMetric: 2.3799 - lr: 1.2500e-04 - 60s/epoch - 308ms/step
Epoch 348/1000
2023-09-16 07:45:37.119 
Epoch 348/1000 
	 loss: 2.3399, MinusLogProbMetric: 2.3399, val_loss: 2.3694, val_MinusLogProbMetric: 2.3694

Epoch 348: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3399 - MinusLogProbMetric: 2.3399 - val_loss: 2.3694 - val_MinusLogProbMetric: 2.3694 - lr: 1.2500e-04 - 60s/epoch - 308ms/step
Epoch 349/1000
2023-09-16 07:46:38.515 
Epoch 349/1000 
	 loss: 2.3399, MinusLogProbMetric: 2.3399, val_loss: 2.3729, val_MinusLogProbMetric: 2.3729

Epoch 349: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3399 - MinusLogProbMetric: 2.3399 - val_loss: 2.3729 - val_MinusLogProbMetric: 2.3729 - lr: 1.2500e-04 - 61s/epoch - 313ms/step
Epoch 350/1000
2023-09-16 07:47:38.969 
Epoch 350/1000 
	 loss: 2.3412, MinusLogProbMetric: 2.3412, val_loss: 2.3735, val_MinusLogProbMetric: 2.3735

Epoch 350: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3412 - MinusLogProbMetric: 2.3412 - val_loss: 2.3735 - val_MinusLogProbMetric: 2.3735 - lr: 1.2500e-04 - 60s/epoch - 308ms/step
Epoch 351/1000
2023-09-16 07:48:40.506 
Epoch 351/1000 
	 loss: 2.3399, MinusLogProbMetric: 2.3399, val_loss: 2.3697, val_MinusLogProbMetric: 2.3697

Epoch 351: val_loss did not improve from 2.36830
196/196 - 62s - loss: 2.3399 - MinusLogProbMetric: 2.3399 - val_loss: 2.3697 - val_MinusLogProbMetric: 2.3697 - lr: 1.2500e-04 - 62s/epoch - 314ms/step
Epoch 352/1000
2023-09-16 07:49:41.398 
Epoch 352/1000 
	 loss: 2.3397, MinusLogProbMetric: 2.3397, val_loss: 2.3719, val_MinusLogProbMetric: 2.3719

Epoch 352: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3397 - MinusLogProbMetric: 2.3397 - val_loss: 2.3719 - val_MinusLogProbMetric: 2.3719 - lr: 1.2500e-04 - 61s/epoch - 311ms/step
Epoch 353/1000
2023-09-16 07:50:42.044 
Epoch 353/1000 
	 loss: 2.3410, MinusLogProbMetric: 2.3410, val_loss: 2.3699, val_MinusLogProbMetric: 2.3699

Epoch 353: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3410 - MinusLogProbMetric: 2.3410 - val_loss: 2.3699 - val_MinusLogProbMetric: 2.3699 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 354/1000
2023-09-16 07:51:41.993 
Epoch 354/1000 
	 loss: 2.3393, MinusLogProbMetric: 2.3393, val_loss: 2.3710, val_MinusLogProbMetric: 2.3710

Epoch 354: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3393 - MinusLogProbMetric: 2.3393 - val_loss: 2.3710 - val_MinusLogProbMetric: 2.3710 - lr: 1.2500e-04 - 60s/epoch - 306ms/step
Epoch 355/1000
2023-09-16 07:52:42.201 
Epoch 355/1000 
	 loss: 2.3394, MinusLogProbMetric: 2.3394, val_loss: 2.3709, val_MinusLogProbMetric: 2.3709

Epoch 355: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3394 - MinusLogProbMetric: 2.3394 - val_loss: 2.3709 - val_MinusLogProbMetric: 2.3709 - lr: 1.2500e-04 - 60s/epoch - 307ms/step
Epoch 356/1000
2023-09-16 07:53:42.818 
Epoch 356/1000 
	 loss: 2.3406, MinusLogProbMetric: 2.3406, val_loss: 2.3706, val_MinusLogProbMetric: 2.3706

Epoch 356: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3406 - MinusLogProbMetric: 2.3406 - val_loss: 2.3706 - val_MinusLogProbMetric: 2.3706 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 357/1000
2023-09-16 07:54:43.373 
Epoch 357/1000 
	 loss: 2.3407, MinusLogProbMetric: 2.3407, val_loss: 2.3728, val_MinusLogProbMetric: 2.3728

Epoch 357: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3407 - MinusLogProbMetric: 2.3407 - val_loss: 2.3728 - val_MinusLogProbMetric: 2.3728 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 358/1000
2023-09-16 07:55:44.118 
Epoch 358/1000 
	 loss: 2.3402, MinusLogProbMetric: 2.3402, val_loss: 2.3690, val_MinusLogProbMetric: 2.3690

Epoch 358: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3402 - MinusLogProbMetric: 2.3402 - val_loss: 2.3690 - val_MinusLogProbMetric: 2.3690 - lr: 1.2500e-04 - 61s/epoch - 310ms/step
Epoch 359/1000
2023-09-16 07:56:44.559 
Epoch 359/1000 
	 loss: 2.3399, MinusLogProbMetric: 2.3399, val_loss: 2.3711, val_MinusLogProbMetric: 2.3711

Epoch 359: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3399 - MinusLogProbMetric: 2.3399 - val_loss: 2.3711 - val_MinusLogProbMetric: 2.3711 - lr: 1.2500e-04 - 60s/epoch - 308ms/step
Epoch 360/1000
2023-09-16 07:57:45.285 
Epoch 360/1000 
	 loss: 2.3407, MinusLogProbMetric: 2.3407, val_loss: 2.3701, val_MinusLogProbMetric: 2.3701

Epoch 360: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3407 - MinusLogProbMetric: 2.3407 - val_loss: 2.3701 - val_MinusLogProbMetric: 2.3701 - lr: 1.2500e-04 - 61s/epoch - 310ms/step
Epoch 361/1000
2023-09-16 07:58:46.105 
Epoch 361/1000 
	 loss: 2.3396, MinusLogProbMetric: 2.3396, val_loss: 2.3722, val_MinusLogProbMetric: 2.3722

Epoch 361: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3396 - MinusLogProbMetric: 2.3396 - val_loss: 2.3722 - val_MinusLogProbMetric: 2.3722 - lr: 1.2500e-04 - 61s/epoch - 310ms/step
Epoch 362/1000
2023-09-16 07:59:48.327 
Epoch 362/1000 
	 loss: 2.3409, MinusLogProbMetric: 2.3409, val_loss: 2.3751, val_MinusLogProbMetric: 2.3751

Epoch 362: val_loss did not improve from 2.36830
196/196 - 62s - loss: 2.3409 - MinusLogProbMetric: 2.3409 - val_loss: 2.3751 - val_MinusLogProbMetric: 2.3751 - lr: 1.2500e-04 - 62s/epoch - 317ms/step
Epoch 363/1000
2023-09-16 08:00:49.505 
Epoch 363/1000 
	 loss: 2.3398, MinusLogProbMetric: 2.3398, val_loss: 2.3705, val_MinusLogProbMetric: 2.3705

Epoch 363: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3398 - MinusLogProbMetric: 2.3398 - val_loss: 2.3705 - val_MinusLogProbMetric: 2.3705 - lr: 1.2500e-04 - 61s/epoch - 312ms/step
Epoch 364/1000
2023-09-16 08:01:50.463 
Epoch 364/1000 
	 loss: 2.3393, MinusLogProbMetric: 2.3393, val_loss: 2.3699, val_MinusLogProbMetric: 2.3699

Epoch 364: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3393 - MinusLogProbMetric: 2.3393 - val_loss: 2.3699 - val_MinusLogProbMetric: 2.3699 - lr: 1.2500e-04 - 61s/epoch - 311ms/step
Epoch 365/1000
2023-09-16 08:02:50.977 
Epoch 365/1000 
	 loss: 2.3393, MinusLogProbMetric: 2.3393, val_loss: 2.3702, val_MinusLogProbMetric: 2.3702

Epoch 365: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3393 - MinusLogProbMetric: 2.3393 - val_loss: 2.3702 - val_MinusLogProbMetric: 2.3702 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 366/1000
2023-09-16 08:03:51.623 
Epoch 366/1000 
	 loss: 2.3390, MinusLogProbMetric: 2.3390, val_loss: 2.3745, val_MinusLogProbMetric: 2.3745

Epoch 366: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3390 - MinusLogProbMetric: 2.3390 - val_loss: 2.3745 - val_MinusLogProbMetric: 2.3745 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 367/1000
2023-09-16 08:04:51.409 
Epoch 367/1000 
	 loss: 2.3395, MinusLogProbMetric: 2.3395, val_loss: 2.3719, val_MinusLogProbMetric: 2.3719

Epoch 367: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3395 - MinusLogProbMetric: 2.3395 - val_loss: 2.3719 - val_MinusLogProbMetric: 2.3719 - lr: 1.2500e-04 - 60s/epoch - 305ms/step
Epoch 368/1000
2023-09-16 08:05:52.443 
Epoch 368/1000 
	 loss: 2.3395, MinusLogProbMetric: 2.3395, val_loss: 2.3704, val_MinusLogProbMetric: 2.3704

Epoch 368: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3395 - MinusLogProbMetric: 2.3395 - val_loss: 2.3704 - val_MinusLogProbMetric: 2.3704 - lr: 1.2500e-04 - 61s/epoch - 311ms/step
Epoch 369/1000
2023-09-16 08:06:53.485 
Epoch 369/1000 
	 loss: 2.3388, MinusLogProbMetric: 2.3388, val_loss: 2.3712, val_MinusLogProbMetric: 2.3712

Epoch 369: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3388 - MinusLogProbMetric: 2.3388 - val_loss: 2.3712 - val_MinusLogProbMetric: 2.3712 - lr: 1.2500e-04 - 61s/epoch - 311ms/step
Epoch 370/1000
2023-09-16 08:07:54.010 
Epoch 370/1000 
	 loss: 2.3396, MinusLogProbMetric: 2.3396, val_loss: 2.3714, val_MinusLogProbMetric: 2.3714

Epoch 370: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3396 - MinusLogProbMetric: 2.3396 - val_loss: 2.3714 - val_MinusLogProbMetric: 2.3714 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 371/1000
2023-09-16 08:08:54.633 
Epoch 371/1000 
	 loss: 2.3390, MinusLogProbMetric: 2.3390, val_loss: 2.3727, val_MinusLogProbMetric: 2.3727

Epoch 371: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3390 - MinusLogProbMetric: 2.3390 - val_loss: 2.3727 - val_MinusLogProbMetric: 2.3727 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 372/1000
2023-09-16 08:09:55.847 
Epoch 372/1000 
	 loss: 2.3397, MinusLogProbMetric: 2.3397, val_loss: 2.3733, val_MinusLogProbMetric: 2.3733

Epoch 372: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3397 - MinusLogProbMetric: 2.3397 - val_loss: 2.3733 - val_MinusLogProbMetric: 2.3733 - lr: 1.2500e-04 - 61s/epoch - 312ms/step
Epoch 373/1000
2023-09-16 08:10:56.757 
Epoch 373/1000 
	 loss: 2.3399, MinusLogProbMetric: 2.3399, val_loss: 2.3704, val_MinusLogProbMetric: 2.3704

Epoch 373: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3399 - MinusLogProbMetric: 2.3399 - val_loss: 2.3704 - val_MinusLogProbMetric: 2.3704 - lr: 1.2500e-04 - 61s/epoch - 311ms/step
Epoch 374/1000
2023-09-16 08:11:57.428 
Epoch 374/1000 
	 loss: 2.3393, MinusLogProbMetric: 2.3393, val_loss: 2.3690, val_MinusLogProbMetric: 2.3690

Epoch 374: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3393 - MinusLogProbMetric: 2.3393 - val_loss: 2.3690 - val_MinusLogProbMetric: 2.3690 - lr: 1.2500e-04 - 61s/epoch - 310ms/step
Epoch 375/1000
2023-09-16 08:12:58.706 
Epoch 375/1000 
	 loss: 2.3392, MinusLogProbMetric: 2.3392, val_loss: 2.3766, val_MinusLogProbMetric: 2.3766

Epoch 375: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3392 - MinusLogProbMetric: 2.3392 - val_loss: 2.3766 - val_MinusLogProbMetric: 2.3766 - lr: 1.2500e-04 - 61s/epoch - 313ms/step
Epoch 376/1000
2023-09-16 08:13:59.776 
Epoch 376/1000 
	 loss: 2.3393, MinusLogProbMetric: 2.3393, val_loss: 2.3698, val_MinusLogProbMetric: 2.3698

Epoch 376: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3393 - MinusLogProbMetric: 2.3393 - val_loss: 2.3698 - val_MinusLogProbMetric: 2.3698 - lr: 1.2500e-04 - 61s/epoch - 312ms/step
Epoch 377/1000
2023-09-16 08:14:59.945 
Epoch 377/1000 
	 loss: 2.3398, MinusLogProbMetric: 2.3398, val_loss: 2.3720, val_MinusLogProbMetric: 2.3720

Epoch 377: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3398 - MinusLogProbMetric: 2.3398 - val_loss: 2.3720 - val_MinusLogProbMetric: 2.3720 - lr: 1.2500e-04 - 60s/epoch - 307ms/step
Epoch 378/1000
2023-09-16 08:16:00.510 
Epoch 378/1000 
	 loss: 2.3402, MinusLogProbMetric: 2.3402, val_loss: 2.3723, val_MinusLogProbMetric: 2.3723

Epoch 378: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3402 - MinusLogProbMetric: 2.3402 - val_loss: 2.3723 - val_MinusLogProbMetric: 2.3723 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 379/1000
2023-09-16 08:17:01.463 
Epoch 379/1000 
	 loss: 2.3390, MinusLogProbMetric: 2.3390, val_loss: 2.3703, val_MinusLogProbMetric: 2.3703

Epoch 379: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3390 - MinusLogProbMetric: 2.3390 - val_loss: 2.3703 - val_MinusLogProbMetric: 2.3703 - lr: 1.2500e-04 - 61s/epoch - 311ms/step
Epoch 380/1000
2023-09-16 08:18:02.082 
Epoch 380/1000 
	 loss: 2.3394, MinusLogProbMetric: 2.3394, val_loss: 2.3717, val_MinusLogProbMetric: 2.3717

Epoch 380: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3394 - MinusLogProbMetric: 2.3394 - val_loss: 2.3717 - val_MinusLogProbMetric: 2.3717 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 381/1000
2023-09-16 08:19:02.655 
Epoch 381/1000 
	 loss: 2.3403, MinusLogProbMetric: 2.3403, val_loss: 2.3706, val_MinusLogProbMetric: 2.3706

Epoch 381: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3403 - MinusLogProbMetric: 2.3403 - val_loss: 2.3706 - val_MinusLogProbMetric: 2.3706 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 382/1000
2023-09-16 08:20:03.210 
Epoch 382/1000 
	 loss: 2.3394, MinusLogProbMetric: 2.3394, val_loss: 2.3721, val_MinusLogProbMetric: 2.3721

Epoch 382: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3394 - MinusLogProbMetric: 2.3394 - val_loss: 2.3721 - val_MinusLogProbMetric: 2.3721 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 383/1000
2023-09-16 08:21:03.717 
Epoch 383/1000 
	 loss: 2.3393, MinusLogProbMetric: 2.3393, val_loss: 2.3719, val_MinusLogProbMetric: 2.3719

Epoch 383: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3393 - MinusLogProbMetric: 2.3393 - val_loss: 2.3719 - val_MinusLogProbMetric: 2.3719 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 384/1000
2023-09-16 08:22:04.601 
Epoch 384/1000 
	 loss: 2.3398, MinusLogProbMetric: 2.3398, val_loss: 2.3718, val_MinusLogProbMetric: 2.3718

Epoch 384: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3398 - MinusLogProbMetric: 2.3398 - val_loss: 2.3718 - val_MinusLogProbMetric: 2.3718 - lr: 1.2500e-04 - 61s/epoch - 311ms/step
Epoch 385/1000
2023-09-16 08:23:05.210 
Epoch 385/1000 
	 loss: 2.3398, MinusLogProbMetric: 2.3398, val_loss: 2.3703, val_MinusLogProbMetric: 2.3703

Epoch 385: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3398 - MinusLogProbMetric: 2.3398 - val_loss: 2.3703 - val_MinusLogProbMetric: 2.3703 - lr: 1.2500e-04 - 61s/epoch - 309ms/step
Epoch 386/1000
2023-09-16 08:24:05.999 
Epoch 386/1000 
	 loss: 2.3394, MinusLogProbMetric: 2.3394, val_loss: 2.3697, val_MinusLogProbMetric: 2.3697

Epoch 386: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3394 - MinusLogProbMetric: 2.3394 - val_loss: 2.3697 - val_MinusLogProbMetric: 2.3697 - lr: 1.2500e-04 - 61s/epoch - 310ms/step
Epoch 387/1000
2023-09-16 08:25:06.957 
Epoch 387/1000 
	 loss: 2.3393, MinusLogProbMetric: 2.3393, val_loss: 2.3711, val_MinusLogProbMetric: 2.3711

Epoch 387: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3393 - MinusLogProbMetric: 2.3393 - val_loss: 2.3711 - val_MinusLogProbMetric: 2.3711 - lr: 1.2500e-04 - 61s/epoch - 311ms/step
Epoch 388/1000
2023-09-16 08:26:07.247 
Epoch 388/1000 
	 loss: 2.3391, MinusLogProbMetric: 2.3391, val_loss: 2.3712, val_MinusLogProbMetric: 2.3712

Epoch 388: val_loss did not improve from 2.36830
196/196 - 60s - loss: 2.3391 - MinusLogProbMetric: 2.3391 - val_loss: 2.3712 - val_MinusLogProbMetric: 2.3712 - lr: 1.2500e-04 - 60s/epoch - 308ms/step
Epoch 389/1000
2023-09-16 08:27:08.004 
Epoch 389/1000 
	 loss: 2.3402, MinusLogProbMetric: 2.3402, val_loss: 2.3711, val_MinusLogProbMetric: 2.3711

Epoch 389: val_loss did not improve from 2.36830
196/196 - 61s - loss: 2.3402 - MinusLogProbMetric: 2.3402 - val_loss: 2.3711 - val_MinusLogProbMetric: 2.3711 - lr: 1.2500e-04 - 61s/epoch - 310ms/step
Epoch 390/1000
2023-09-16 08:28:08.439 
Epoch 390/1000 
	 loss: 2.3388, MinusLogProbMetric: 2.3388, val_loss: 2.3688, val_MinusLogProbMetric: 2.3688

Epoch 390: val_loss did not improve from 2.36830
Restoring model weights from the end of the best epoch: 290.
196/196 - 61s - loss: 2.3388 - MinusLogProbMetric: 2.3388 - val_loss: 2.3688 - val_MinusLogProbMetric: 2.3688 - lr: 1.2500e-04 - 61s/epoch - 312ms/step
Epoch 390: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:5 out of the last 5 calls to <function LRMetric.Test_tf.<locals>.compute_test at 0x7fb11c6e8940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
LR metric calculation completed in 17.864089637994766 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
WARNING:tensorflow:5 out of the last 5 calls to <function KSTest.Test_tf.<locals>.compute_test at 0x7fb11c6ea7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
KS tests calculation completed in 14.238674623891711 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:5 out of the last 5 calls to <function SWDMetric.Test_tf.<locals>.compute_test at 0x7fb11c6e9900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
SWD metric calculation completed in 6.754996618954465 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fb11c6ea200> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:6 out of the last 6 calls to <function LRMetric.Test_tf.<locals>.compute_test at 0x7fb2cc5d3eb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
LR metric calculation completed in 19.089192959014326 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
WARNING:tensorflow:6 out of the last 6 calls to <function KSTest.Test_tf.<locals>.compute_test at 0x7faf40574d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
KS tests calculation completed in 7.38019537483342 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:6 out of the last 6 calls to <function SWDMetric.Test_tf.<locals>.compute_test at 0x7fb2cc5d2dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
SWD metric calculation completed in 6.8386742430739105 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7faf40574d30> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 869.
Model trained in 23972.79 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

Plots done in 3.09 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 96.08 s.
===========
Run 61/720 done in 24077.75 s.
===========

Directory ../../results/CsplineN_new/run_62/ already exists.
Skipping it.
===========
Run 62/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_63/ already exists.
Skipping it.
===========
Run 63/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_64/ already exists.
Skipping it.
===========
Run 64/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_65/ already exists.
Skipping it.
===========
Run 65/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_66/ already exists.
Skipping it.
===========
Run 66/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_67/ already exists.
Skipping it.
===========
Run 67/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_68/ already exists.
Skipping it.
===========
Run 68/720 already exists. Skipping it.
===========

===========
Generating train data for run 69.
===========
Train data generated in 0.28 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 4)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_69/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 926}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_69/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 9.036821 ,  4.7705116,  8.516701 ,  4.5271635],
       [ 4.2073317,  6.531003 ,  5.3180447,  9.38196  ],
       [ 4.238654 ,  4.98909  ,  4.2195296,  8.856048 ],
       ...,
       [ 4.236962 ,  7.949092 ,  5.112082 ,  8.334676 ],
       [ 4.2190785,  6.289809 ,  4.1673417,  9.976453 ],
       [10.736699 ,  2.9054773,  8.213886 ,  6.05053  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_69/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_69
self.data_kwargs: {'seed': 926}
self.x_data: [[4.240712  6.2412577 5.575936  8.372037 ]
 [6.461165  8.044901  6.0199018 5.3768544]
 [4.238709  7.4034963 3.406543  8.91474  ]
 ...
 [4.206514  6.1442623 4.08315   8.084269 ]
 [4.2575107 6.489152  3.5227385 9.106118 ]
 [4.5291443 8.208476  5.9955726 5.5052757]]
self.y_data: []
self.ndims: 4
Model defined.
Model: "model_43"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_44 (InputLayer)       [(None, 4)]               0         
                                                                 
 log_prob_layer_3 (LogProbLa  (None,)                  393420    
 yer)                                                            
                                                                 
=================================================================
Total params: 393,420
Trainable params: 393,420
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_3/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_3'")
self.model: <keras.engine.functional.Functional object at 0x7faf40654f10>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7faee473c4c0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7faee473c4c0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7faed42ef700>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fb008364b20>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fb008365090>, <keras.callbacks.ModelCheckpoint object at 0x7fb008365150>, <keras.callbacks.EarlyStopping object at 0x7fb0083653c0>, <keras.callbacks.ReduceLROnPlateau object at 0x7fb0083653f0>, <keras.callbacks.TerminateOnNaN object at 0x7fb008365030>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 9.036821 ,  4.7705116,  8.516701 ,  4.5271635],
       [ 4.2073317,  6.531003 ,  5.3180447,  9.38196  ],
       [ 4.238654 ,  4.98909  ,  4.2195296,  8.856048 ],
       ...,
       [ 4.236962 ,  7.949092 ,  5.112082 ,  8.334676 ],
       [ 4.2190785,  6.289809 ,  4.1673417,  9.976453 ],
       [10.736699 ,  2.9054773,  8.213886 ,  6.05053  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_69/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 69/720 with hyperparameters:
timestamp = 2023-09-16 08:29:55.024411
ndims = 4
seed_train = 926
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 8
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 393420
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [4.240712  6.2412577 5.575936  8.372037 ]
Epoch 1/1000
2023-09-16 08:32:59.731 
Epoch 1/1000 
	 loss: 8.1378, MinusLogProbMetric: 8.1378, val_loss: 4.6883, val_MinusLogProbMetric: 4.6883

Epoch 1: val_loss improved from inf to 4.68826, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 186s - loss: 8.1378 - MinusLogProbMetric: 8.1378 - val_loss: 4.6883 - val_MinusLogProbMetric: 4.6883 - lr: 0.0010 - 186s/epoch - 947ms/step
Epoch 2/1000
2023-09-16 08:34:01.574 
Epoch 2/1000 
	 loss: 4.1348, MinusLogProbMetric: 4.1348, val_loss: 3.5787, val_MinusLogProbMetric: 3.5787

Epoch 2: val_loss improved from 4.68826 to 3.57873, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 61s - loss: 4.1348 - MinusLogProbMetric: 4.1348 - val_loss: 3.5787 - val_MinusLogProbMetric: 3.5787 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 3/1000
2023-09-16 08:35:02.868 
Epoch 3/1000 
	 loss: 3.9967, MinusLogProbMetric: 3.9967, val_loss: 3.7755, val_MinusLogProbMetric: 3.7755

Epoch 3: val_loss did not improve from 3.57873
196/196 - 60s - loss: 3.9967 - MinusLogProbMetric: 3.9967 - val_loss: 3.7755 - val_MinusLogProbMetric: 3.7755 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 4/1000
2023-09-16 08:36:02.292 
Epoch 4/1000 
	 loss: 3.5787, MinusLogProbMetric: 3.5787, val_loss: 3.5555, val_MinusLogProbMetric: 3.5555

Epoch 4: val_loss improved from 3.57873 to 3.55546, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 60s - loss: 3.5787 - MinusLogProbMetric: 3.5787 - val_loss: 3.5555 - val_MinusLogProbMetric: 3.5555 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 5/1000
2023-09-16 08:36:57.981 
Epoch 5/1000 
	 loss: 3.4178, MinusLogProbMetric: 3.4178, val_loss: 3.2499, val_MinusLogProbMetric: 3.2499

Epoch 5: val_loss improved from 3.55546 to 3.24992, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 56s - loss: 3.4178 - MinusLogProbMetric: 3.4178 - val_loss: 3.2499 - val_MinusLogProbMetric: 3.2499 - lr: 0.0010 - 56s/epoch - 285ms/step
Epoch 6/1000
2023-09-16 08:37:53.520 
Epoch 6/1000 
	 loss: 3.3376, MinusLogProbMetric: 3.3376, val_loss: 3.8529, val_MinusLogProbMetric: 3.8529

Epoch 6: val_loss did not improve from 3.24992
196/196 - 55s - loss: 3.3376 - MinusLogProbMetric: 3.3376 - val_loss: 3.8529 - val_MinusLogProbMetric: 3.8529 - lr: 0.0010 - 55s/epoch - 279ms/step
Epoch 7/1000
2023-09-16 08:38:53.465 
Epoch 7/1000 
	 loss: 3.1373, MinusLogProbMetric: 3.1373, val_loss: 2.9230, val_MinusLogProbMetric: 2.9230

Epoch 7: val_loss improved from 3.24992 to 2.92298, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 61s - loss: 3.1373 - MinusLogProbMetric: 3.1373 - val_loss: 2.9230 - val_MinusLogProbMetric: 2.9230 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 8/1000
2023-09-16 08:40:00.305 
Epoch 8/1000 
	 loss: 3.0787, MinusLogProbMetric: 3.0787, val_loss: 3.2156, val_MinusLogProbMetric: 3.2156

Epoch 8: val_loss did not improve from 2.92298
196/196 - 66s - loss: 3.0787 - MinusLogProbMetric: 3.0787 - val_loss: 3.2156 - val_MinusLogProbMetric: 3.2156 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 9/1000
2023-09-16 08:41:03.958 
Epoch 9/1000 
	 loss: 2.9930, MinusLogProbMetric: 2.9930, val_loss: 2.7835, val_MinusLogProbMetric: 2.7835

Epoch 9: val_loss improved from 2.92298 to 2.78349, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 65s - loss: 2.9930 - MinusLogProbMetric: 2.9930 - val_loss: 2.7835 - val_MinusLogProbMetric: 2.7835 - lr: 0.0010 - 65s/epoch - 330ms/step
Epoch 10/1000
2023-09-16 08:42:09.830 
Epoch 10/1000 
	 loss: 2.8527, MinusLogProbMetric: 2.8527, val_loss: 2.9871, val_MinusLogProbMetric: 2.9871

Epoch 10: val_loss did not improve from 2.78349
196/196 - 65s - loss: 2.8527 - MinusLogProbMetric: 2.8527 - val_loss: 2.9871 - val_MinusLogProbMetric: 2.9871 - lr: 0.0010 - 65s/epoch - 331ms/step
Epoch 11/1000
2023-09-16 08:43:14.432 
Epoch 11/1000 
	 loss: 2.8296, MinusLogProbMetric: 2.8296, val_loss: 2.6864, val_MinusLogProbMetric: 2.6864

Epoch 11: val_loss improved from 2.78349 to 2.68640, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 66s - loss: 2.8296 - MinusLogProbMetric: 2.8296 - val_loss: 2.6864 - val_MinusLogProbMetric: 2.6864 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 12/1000
2023-09-16 08:44:20.143 
Epoch 12/1000 
	 loss: 2.7567, MinusLogProbMetric: 2.7567, val_loss: 2.5814, val_MinusLogProbMetric: 2.5814

Epoch 12: val_loss improved from 2.68640 to 2.58137, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 65s - loss: 2.7567 - MinusLogProbMetric: 2.7567 - val_loss: 2.5814 - val_MinusLogProbMetric: 2.5814 - lr: 0.0010 - 65s/epoch - 334ms/step
Epoch 13/1000
2023-09-16 08:45:24.476 
Epoch 13/1000 
	 loss: 2.6940, MinusLogProbMetric: 2.6940, val_loss: 2.7154, val_MinusLogProbMetric: 2.7154

Epoch 13: val_loss did not improve from 2.58137
196/196 - 63s - loss: 2.6940 - MinusLogProbMetric: 2.6940 - val_loss: 2.7154 - val_MinusLogProbMetric: 2.7154 - lr: 0.0010 - 63s/epoch - 324ms/step
Epoch 14/1000
2023-09-16 08:46:25.685 
Epoch 14/1000 
	 loss: 2.7362, MinusLogProbMetric: 2.7362, val_loss: 2.5526, val_MinusLogProbMetric: 2.5526

Epoch 14: val_loss improved from 2.58137 to 2.55257, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 62s - loss: 2.7362 - MinusLogProbMetric: 2.7362 - val_loss: 2.5526 - val_MinusLogProbMetric: 2.5526 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 15/1000
2023-09-16 08:47:28.389 
Epoch 15/1000 
	 loss: 2.6469, MinusLogProbMetric: 2.6469, val_loss: 2.5598, val_MinusLogProbMetric: 2.5598

Epoch 15: val_loss did not improve from 2.55257
196/196 - 62s - loss: 2.6469 - MinusLogProbMetric: 2.6469 - val_loss: 2.5598 - val_MinusLogProbMetric: 2.5598 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 16/1000
2023-09-16 08:48:30.140 
Epoch 16/1000 
	 loss: 2.6333, MinusLogProbMetric: 2.6333, val_loss: 2.6896, val_MinusLogProbMetric: 2.6896

Epoch 16: val_loss did not improve from 2.55257
196/196 - 62s - loss: 2.6333 - MinusLogProbMetric: 2.6333 - val_loss: 2.6896 - val_MinusLogProbMetric: 2.6896 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 17/1000
2023-09-16 08:49:31.793 
Epoch 17/1000 
	 loss: 2.6045, MinusLogProbMetric: 2.6045, val_loss: 2.5844, val_MinusLogProbMetric: 2.5844

Epoch 17: val_loss did not improve from 2.55257
196/196 - 62s - loss: 2.6045 - MinusLogProbMetric: 2.6045 - val_loss: 2.5844 - val_MinusLogProbMetric: 2.5844 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 18/1000
2023-09-16 08:50:33.126 
Epoch 18/1000 
	 loss: 2.6253, MinusLogProbMetric: 2.6253, val_loss: 2.5750, val_MinusLogProbMetric: 2.5750

Epoch 18: val_loss did not improve from 2.55257
196/196 - 61s - loss: 2.6253 - MinusLogProbMetric: 2.6253 - val_loss: 2.5750 - val_MinusLogProbMetric: 2.5750 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 19/1000
2023-09-16 08:51:34.339 
Epoch 19/1000 
	 loss: 2.5827, MinusLogProbMetric: 2.5827, val_loss: 2.7202, val_MinusLogProbMetric: 2.7202

Epoch 19: val_loss did not improve from 2.55257
196/196 - 61s - loss: 2.5827 - MinusLogProbMetric: 2.5827 - val_loss: 2.7202 - val_MinusLogProbMetric: 2.7202 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 20/1000
2023-09-16 08:52:35.513 
Epoch 20/1000 
	 loss: 2.5938, MinusLogProbMetric: 2.5938, val_loss: 2.4763, val_MinusLogProbMetric: 2.4763

Epoch 20: val_loss improved from 2.55257 to 2.47634, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 62s - loss: 2.5938 - MinusLogProbMetric: 2.5938 - val_loss: 2.4763 - val_MinusLogProbMetric: 2.4763 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 21/1000
2023-09-16 08:53:36.995 
Epoch 21/1000 
	 loss: 2.5661, MinusLogProbMetric: 2.5661, val_loss: 2.5177, val_MinusLogProbMetric: 2.5177

Epoch 21: val_loss did not improve from 2.47634
196/196 - 60s - loss: 2.5661 - MinusLogProbMetric: 2.5661 - val_loss: 2.5177 - val_MinusLogProbMetric: 2.5177 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 22/1000
2023-09-16 08:54:38.014 
Epoch 22/1000 
	 loss: 2.5462, MinusLogProbMetric: 2.5462, val_loss: 2.5319, val_MinusLogProbMetric: 2.5319

Epoch 22: val_loss did not improve from 2.47634
196/196 - 61s - loss: 2.5462 - MinusLogProbMetric: 2.5462 - val_loss: 2.5319 - val_MinusLogProbMetric: 2.5319 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 23/1000
2023-09-16 08:55:40.040 
Epoch 23/1000 
	 loss: 2.5333, MinusLogProbMetric: 2.5333, val_loss: 2.5011, val_MinusLogProbMetric: 2.5011

Epoch 23: val_loss did not improve from 2.47634
196/196 - 62s - loss: 2.5333 - MinusLogProbMetric: 2.5333 - val_loss: 2.5011 - val_MinusLogProbMetric: 2.5011 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 24/1000
2023-09-16 08:56:40.462 
Epoch 24/1000 
	 loss: 2.5392, MinusLogProbMetric: 2.5392, val_loss: 2.4681, val_MinusLogProbMetric: 2.4681

Epoch 24: val_loss improved from 2.47634 to 2.46811, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 62s - loss: 2.5392 - MinusLogProbMetric: 2.5392 - val_loss: 2.4681 - val_MinusLogProbMetric: 2.4681 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 25/1000
2023-09-16 08:57:42.065 
Epoch 25/1000 
	 loss: 2.5243, MinusLogProbMetric: 2.5243, val_loss: 2.6482, val_MinusLogProbMetric: 2.6482

Epoch 25: val_loss did not improve from 2.46811
196/196 - 61s - loss: 2.5243 - MinusLogProbMetric: 2.5243 - val_loss: 2.6482 - val_MinusLogProbMetric: 2.6482 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 26/1000
2023-09-16 08:58:42.291 
Epoch 26/1000 
	 loss: 2.5407, MinusLogProbMetric: 2.5407, val_loss: 2.5903, val_MinusLogProbMetric: 2.5903

Epoch 26: val_loss did not improve from 2.46811
196/196 - 60s - loss: 2.5407 - MinusLogProbMetric: 2.5407 - val_loss: 2.5903 - val_MinusLogProbMetric: 2.5903 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 27/1000
2023-09-16 08:59:42.845 
Epoch 27/1000 
	 loss: 2.5278, MinusLogProbMetric: 2.5278, val_loss: 2.5500, val_MinusLogProbMetric: 2.5500

Epoch 27: val_loss did not improve from 2.46811
196/196 - 61s - loss: 2.5278 - MinusLogProbMetric: 2.5278 - val_loss: 2.5500 - val_MinusLogProbMetric: 2.5500 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 28/1000
2023-09-16 09:00:37.811 
Epoch 28/1000 
	 loss: 2.5006, MinusLogProbMetric: 2.5006, val_loss: 2.4943, val_MinusLogProbMetric: 2.4943

Epoch 28: val_loss did not improve from 2.46811
196/196 - 55s - loss: 2.5006 - MinusLogProbMetric: 2.5006 - val_loss: 2.4943 - val_MinusLogProbMetric: 2.4943 - lr: 0.0010 - 55s/epoch - 280ms/step
Epoch 29/1000
2023-09-16 09:01:28.268 
Epoch 29/1000 
	 loss: 2.5038, MinusLogProbMetric: 2.5038, val_loss: 2.4440, val_MinusLogProbMetric: 2.4440

Epoch 29: val_loss improved from 2.46811 to 2.44395, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 51s - loss: 2.5038 - MinusLogProbMetric: 2.5038 - val_loss: 2.4440 - val_MinusLogProbMetric: 2.4440 - lr: 0.0010 - 51s/epoch - 261ms/step
Epoch 30/1000
2023-09-16 09:02:21.859 
Epoch 30/1000 
	 loss: 2.5056, MinusLogProbMetric: 2.5056, val_loss: 2.5772, val_MinusLogProbMetric: 2.5772

Epoch 30: val_loss did not improve from 2.44395
196/196 - 53s - loss: 2.5056 - MinusLogProbMetric: 2.5056 - val_loss: 2.5772 - val_MinusLogProbMetric: 2.5772 - lr: 0.0010 - 53s/epoch - 269ms/step
Epoch 31/1000
2023-09-16 09:03:18.116 
Epoch 31/1000 
	 loss: 2.4742, MinusLogProbMetric: 2.4742, val_loss: 2.4652, val_MinusLogProbMetric: 2.4652

Epoch 31: val_loss did not improve from 2.44395
196/196 - 56s - loss: 2.4742 - MinusLogProbMetric: 2.4742 - val_loss: 2.4652 - val_MinusLogProbMetric: 2.4652 - lr: 0.0010 - 56s/epoch - 287ms/step
Epoch 32/1000
2023-09-16 09:04:16.862 
Epoch 32/1000 
	 loss: 2.4921, MinusLogProbMetric: 2.4921, val_loss: 2.4488, val_MinusLogProbMetric: 2.4488

Epoch 32: val_loss did not improve from 2.44395
196/196 - 59s - loss: 2.4921 - MinusLogProbMetric: 2.4921 - val_loss: 2.4488 - val_MinusLogProbMetric: 2.4488 - lr: 0.0010 - 59s/epoch - 300ms/step
Epoch 33/1000
2023-09-16 09:05:16.530 
Epoch 33/1000 
	 loss: 2.5025, MinusLogProbMetric: 2.5025, val_loss: 2.4319, val_MinusLogProbMetric: 2.4319

Epoch 33: val_loss improved from 2.44395 to 2.43193, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 60s - loss: 2.5025 - MinusLogProbMetric: 2.5025 - val_loss: 2.4319 - val_MinusLogProbMetric: 2.4319 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 34/1000
2023-09-16 09:06:16.705 
Epoch 34/1000 
	 loss: 2.4944, MinusLogProbMetric: 2.4944, val_loss: 2.5453, val_MinusLogProbMetric: 2.5453

Epoch 34: val_loss did not improve from 2.43193
196/196 - 59s - loss: 2.4944 - MinusLogProbMetric: 2.4944 - val_loss: 2.5453 - val_MinusLogProbMetric: 2.5453 - lr: 0.0010 - 59s/epoch - 303ms/step
Epoch 35/1000
2023-09-16 09:07:16.879 
Epoch 35/1000 
	 loss: 2.5104, MinusLogProbMetric: 2.5104, val_loss: 2.4922, val_MinusLogProbMetric: 2.4922

Epoch 35: val_loss did not improve from 2.43193
196/196 - 60s - loss: 2.5104 - MinusLogProbMetric: 2.5104 - val_loss: 2.4922 - val_MinusLogProbMetric: 2.4922 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 36/1000
2023-09-16 09:08:17.033 
Epoch 36/1000 
	 loss: 2.4958, MinusLogProbMetric: 2.4958, val_loss: 2.5516, val_MinusLogProbMetric: 2.5516

Epoch 36: val_loss did not improve from 2.43193
196/196 - 60s - loss: 2.4958 - MinusLogProbMetric: 2.4958 - val_loss: 2.5516 - val_MinusLogProbMetric: 2.5516 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 37/1000
2023-09-16 09:09:16.457 
Epoch 37/1000 
	 loss: 2.4600, MinusLogProbMetric: 2.4600, val_loss: 2.4399, val_MinusLogProbMetric: 2.4399

Epoch 37: val_loss did not improve from 2.43193
196/196 - 59s - loss: 2.4600 - MinusLogProbMetric: 2.4600 - val_loss: 2.4399 - val_MinusLogProbMetric: 2.4399 - lr: 0.0010 - 59s/epoch - 303ms/step
Epoch 38/1000
2023-09-16 09:10:12.130 
Epoch 38/1000 
	 loss: 2.4665, MinusLogProbMetric: 2.4665, val_loss: 2.4591, val_MinusLogProbMetric: 2.4591

Epoch 38: val_loss did not improve from 2.43193
196/196 - 56s - loss: 2.4665 - MinusLogProbMetric: 2.4665 - val_loss: 2.4591 - val_MinusLogProbMetric: 2.4591 - lr: 0.0010 - 56s/epoch - 284ms/step
Epoch 39/1000
2023-09-16 09:11:05.925 
Epoch 39/1000 
	 loss: 2.4592, MinusLogProbMetric: 2.4592, val_loss: 2.4578, val_MinusLogProbMetric: 2.4578

Epoch 39: val_loss did not improve from 2.43193
196/196 - 54s - loss: 2.4592 - MinusLogProbMetric: 2.4592 - val_loss: 2.4578 - val_MinusLogProbMetric: 2.4578 - lr: 0.0010 - 54s/epoch - 274ms/step
Epoch 40/1000
2023-09-16 09:11:59.818 
Epoch 40/1000 
	 loss: 2.4680, MinusLogProbMetric: 2.4680, val_loss: 2.6026, val_MinusLogProbMetric: 2.6026

Epoch 40: val_loss did not improve from 2.43193
196/196 - 54s - loss: 2.4680 - MinusLogProbMetric: 2.4680 - val_loss: 2.6026 - val_MinusLogProbMetric: 2.6026 - lr: 0.0010 - 54s/epoch - 275ms/step
Epoch 41/1000
2023-09-16 09:12:59.546 
Epoch 41/1000 
	 loss: 2.4825, MinusLogProbMetric: 2.4825, val_loss: 2.9713, val_MinusLogProbMetric: 2.9713

Epoch 41: val_loss did not improve from 2.43193
196/196 - 60s - loss: 2.4825 - MinusLogProbMetric: 2.4825 - val_loss: 2.9713 - val_MinusLogProbMetric: 2.9713 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 42/1000
2023-09-16 09:13:59.762 
Epoch 42/1000 
	 loss: 2.4808, MinusLogProbMetric: 2.4808, val_loss: 2.4449, val_MinusLogProbMetric: 2.4449

Epoch 42: val_loss did not improve from 2.43193
196/196 - 60s - loss: 2.4808 - MinusLogProbMetric: 2.4808 - val_loss: 2.4449 - val_MinusLogProbMetric: 2.4449 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 43/1000
2023-09-16 09:15:00.207 
Epoch 43/1000 
	 loss: 2.4558, MinusLogProbMetric: 2.4558, val_loss: 2.5949, val_MinusLogProbMetric: 2.5949

Epoch 43: val_loss did not improve from 2.43193
196/196 - 60s - loss: 2.4558 - MinusLogProbMetric: 2.4558 - val_loss: 2.5949 - val_MinusLogProbMetric: 2.5949 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 44/1000
2023-09-16 09:16:01.390 
Epoch 44/1000 
	 loss: 2.4645, MinusLogProbMetric: 2.4645, val_loss: 2.4974, val_MinusLogProbMetric: 2.4974

Epoch 44: val_loss did not improve from 2.43193
196/196 - 61s - loss: 2.4645 - MinusLogProbMetric: 2.4645 - val_loss: 2.4974 - val_MinusLogProbMetric: 2.4974 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 45/1000
2023-09-16 09:17:01.831 
Epoch 45/1000 
	 loss: 2.4471, MinusLogProbMetric: 2.4471, val_loss: 2.4437, val_MinusLogProbMetric: 2.4437

Epoch 45: val_loss did not improve from 2.43193
196/196 - 60s - loss: 2.4471 - MinusLogProbMetric: 2.4471 - val_loss: 2.4437 - val_MinusLogProbMetric: 2.4437 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 46/1000
2023-09-16 09:18:02.429 
Epoch 46/1000 
	 loss: 2.4452, MinusLogProbMetric: 2.4452, val_loss: 2.4600, val_MinusLogProbMetric: 2.4600

Epoch 46: val_loss did not improve from 2.43193
196/196 - 61s - loss: 2.4452 - MinusLogProbMetric: 2.4452 - val_loss: 2.4600 - val_MinusLogProbMetric: 2.4600 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 47/1000
2023-09-16 09:19:03.048 
Epoch 47/1000 
	 loss: 2.4483, MinusLogProbMetric: 2.4483, val_loss: 2.4249, val_MinusLogProbMetric: 2.4249

Epoch 47: val_loss improved from 2.43193 to 2.42489, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 62s - loss: 2.4483 - MinusLogProbMetric: 2.4483 - val_loss: 2.4249 - val_MinusLogProbMetric: 2.4249 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 48/1000
2023-09-16 09:20:04.699 
Epoch 48/1000 
	 loss: 2.4352, MinusLogProbMetric: 2.4352, val_loss: 2.5641, val_MinusLogProbMetric: 2.5641

Epoch 48: val_loss did not improve from 2.42489
196/196 - 60s - loss: 2.4352 - MinusLogProbMetric: 2.4352 - val_loss: 2.5641 - val_MinusLogProbMetric: 2.5641 - lr: 0.0010 - 60s/epoch - 309ms/step
Epoch 49/1000
2023-09-16 09:21:05.244 
Epoch 49/1000 
	 loss: 2.4636, MinusLogProbMetric: 2.4636, val_loss: 2.4229, val_MinusLogProbMetric: 2.4229

Epoch 49: val_loss improved from 2.42489 to 2.42293, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 62s - loss: 2.4636 - MinusLogProbMetric: 2.4636 - val_loss: 2.4229 - val_MinusLogProbMetric: 2.4229 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 50/1000
2023-09-16 09:22:06.362 
Epoch 50/1000 
	 loss: 2.4541, MinusLogProbMetric: 2.4541, val_loss: 2.8886, val_MinusLogProbMetric: 2.8886

Epoch 50: val_loss did not improve from 2.42293
196/196 - 60s - loss: 2.4541 - MinusLogProbMetric: 2.4541 - val_loss: 2.8886 - val_MinusLogProbMetric: 2.8886 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 51/1000
2023-09-16 09:23:06.817 
Epoch 51/1000 
	 loss: 2.4871, MinusLogProbMetric: 2.4871, val_loss: 2.4512, val_MinusLogProbMetric: 2.4512

Epoch 51: val_loss did not improve from 2.42293
196/196 - 60s - loss: 2.4871 - MinusLogProbMetric: 2.4871 - val_loss: 2.4512 - val_MinusLogProbMetric: 2.4512 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 52/1000
2023-09-16 09:24:07.594 
Epoch 52/1000 
	 loss: 2.4727, MinusLogProbMetric: 2.4727, val_loss: 2.4525, val_MinusLogProbMetric: 2.4525

Epoch 52: val_loss did not improve from 2.42293
196/196 - 61s - loss: 2.4727 - MinusLogProbMetric: 2.4727 - val_loss: 2.4525 - val_MinusLogProbMetric: 2.4525 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 53/1000
2023-09-16 09:25:08.180 
Epoch 53/1000 
	 loss: 2.4663, MinusLogProbMetric: 2.4663, val_loss: 2.4902, val_MinusLogProbMetric: 2.4902

Epoch 53: val_loss did not improve from 2.42293
196/196 - 61s - loss: 2.4663 - MinusLogProbMetric: 2.4663 - val_loss: 2.4902 - val_MinusLogProbMetric: 2.4902 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 54/1000
2023-09-16 09:26:08.564 
Epoch 54/1000 
	 loss: 2.4475, MinusLogProbMetric: 2.4475, val_loss: 2.4450, val_MinusLogProbMetric: 2.4450

Epoch 54: val_loss did not improve from 2.42293
196/196 - 60s - loss: 2.4475 - MinusLogProbMetric: 2.4475 - val_loss: 2.4450 - val_MinusLogProbMetric: 2.4450 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 55/1000
2023-09-16 09:27:09.248 
Epoch 55/1000 
	 loss: 2.4297, MinusLogProbMetric: 2.4297, val_loss: 2.4344, val_MinusLogProbMetric: 2.4344

Epoch 55: val_loss did not improve from 2.42293
196/196 - 61s - loss: 2.4297 - MinusLogProbMetric: 2.4297 - val_loss: 2.4344 - val_MinusLogProbMetric: 2.4344 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 56/1000
2023-09-16 09:28:10.077 
Epoch 56/1000 
	 loss: 2.4498, MinusLogProbMetric: 2.4498, val_loss: 2.5134, val_MinusLogProbMetric: 2.5134

Epoch 56: val_loss did not improve from 2.42293
196/196 - 61s - loss: 2.4498 - MinusLogProbMetric: 2.4498 - val_loss: 2.5134 - val_MinusLogProbMetric: 2.5134 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 57/1000
2023-09-16 09:29:10.739 
Epoch 57/1000 
	 loss: 2.4573, MinusLogProbMetric: 2.4573, val_loss: 2.5873, val_MinusLogProbMetric: 2.5873

Epoch 57: val_loss did not improve from 2.42293
196/196 - 61s - loss: 2.4573 - MinusLogProbMetric: 2.4573 - val_loss: 2.5873 - val_MinusLogProbMetric: 2.5873 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 58/1000
2023-09-16 09:30:11.428 
Epoch 58/1000 
	 loss: 2.4423, MinusLogProbMetric: 2.4423, val_loss: 2.5054, val_MinusLogProbMetric: 2.5054

Epoch 58: val_loss did not improve from 2.42293
196/196 - 61s - loss: 2.4423 - MinusLogProbMetric: 2.4423 - val_loss: 2.5054 - val_MinusLogProbMetric: 2.5054 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 59/1000
2023-09-16 09:31:12.544 
Epoch 59/1000 
	 loss: 2.4425, MinusLogProbMetric: 2.4425, val_loss: 2.4577, val_MinusLogProbMetric: 2.4577

Epoch 59: val_loss did not improve from 2.42293
196/196 - 61s - loss: 2.4425 - MinusLogProbMetric: 2.4425 - val_loss: 2.4577 - val_MinusLogProbMetric: 2.4577 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 60/1000
2023-09-16 09:32:13.354 
Epoch 60/1000 
	 loss: 2.4231, MinusLogProbMetric: 2.4231, val_loss: 2.4751, val_MinusLogProbMetric: 2.4751

Epoch 60: val_loss did not improve from 2.42293
196/196 - 61s - loss: 2.4231 - MinusLogProbMetric: 2.4231 - val_loss: 2.4751 - val_MinusLogProbMetric: 2.4751 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 61/1000
2023-09-16 09:33:14.102 
Epoch 61/1000 
	 loss: 2.4351, MinusLogProbMetric: 2.4351, val_loss: 2.6361, val_MinusLogProbMetric: 2.6361

Epoch 61: val_loss did not improve from 2.42293
196/196 - 61s - loss: 2.4351 - MinusLogProbMetric: 2.4351 - val_loss: 2.6361 - val_MinusLogProbMetric: 2.6361 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 62/1000
2023-09-16 09:34:15.364 
Epoch 62/1000 
	 loss: 2.4294, MinusLogProbMetric: 2.4294, val_loss: 2.5802, val_MinusLogProbMetric: 2.5802

Epoch 62: val_loss did not improve from 2.42293
196/196 - 61s - loss: 2.4294 - MinusLogProbMetric: 2.4294 - val_loss: 2.5802 - val_MinusLogProbMetric: 2.5802 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 63/1000
2023-09-16 09:35:15.680 
Epoch 63/1000 
	 loss: 2.4319, MinusLogProbMetric: 2.4319, val_loss: 2.4569, val_MinusLogProbMetric: 2.4569

Epoch 63: val_loss did not improve from 2.42293
196/196 - 60s - loss: 2.4319 - MinusLogProbMetric: 2.4319 - val_loss: 2.4569 - val_MinusLogProbMetric: 2.4569 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 64/1000
2023-09-16 09:36:13.929 
Epoch 64/1000 
	 loss: 2.4222, MinusLogProbMetric: 2.4222, val_loss: 2.5635, val_MinusLogProbMetric: 2.5635

Epoch 64: val_loss did not improve from 2.42293
196/196 - 58s - loss: 2.4222 - MinusLogProbMetric: 2.4222 - val_loss: 2.5635 - val_MinusLogProbMetric: 2.5635 - lr: 0.0010 - 58s/epoch - 297ms/step
Epoch 65/1000
2023-09-16 09:37:09.283 
Epoch 65/1000 
	 loss: 2.4469, MinusLogProbMetric: 2.4469, val_loss: 2.4673, val_MinusLogProbMetric: 2.4673

Epoch 65: val_loss did not improve from 2.42293
196/196 - 55s - loss: 2.4469 - MinusLogProbMetric: 2.4469 - val_loss: 2.4673 - val_MinusLogProbMetric: 2.4673 - lr: 0.0010 - 55s/epoch - 282ms/step
Epoch 66/1000
2023-09-16 09:38:10.286 
Epoch 66/1000 
	 loss: 2.4257, MinusLogProbMetric: 2.4257, val_loss: 2.4284, val_MinusLogProbMetric: 2.4284

Epoch 66: val_loss did not improve from 2.42293
196/196 - 61s - loss: 2.4257 - MinusLogProbMetric: 2.4257 - val_loss: 2.4284 - val_MinusLogProbMetric: 2.4284 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 67/1000
2023-09-16 09:39:10.969 
Epoch 67/1000 
	 loss: 2.4468, MinusLogProbMetric: 2.4468, val_loss: 2.4350, val_MinusLogProbMetric: 2.4350

Epoch 67: val_loss did not improve from 2.42293
196/196 - 61s - loss: 2.4468 - MinusLogProbMetric: 2.4468 - val_loss: 2.4350 - val_MinusLogProbMetric: 2.4350 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 68/1000
2023-09-16 09:40:11.302 
Epoch 68/1000 
	 loss: 2.4443, MinusLogProbMetric: 2.4443, val_loss: 2.4822, val_MinusLogProbMetric: 2.4822

Epoch 68: val_loss did not improve from 2.42293
196/196 - 60s - loss: 2.4443 - MinusLogProbMetric: 2.4443 - val_loss: 2.4822 - val_MinusLogProbMetric: 2.4822 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 69/1000
2023-09-16 09:41:11.866 
Epoch 69/1000 
	 loss: 2.4240, MinusLogProbMetric: 2.4240, val_loss: 2.4351, val_MinusLogProbMetric: 2.4351

Epoch 69: val_loss did not improve from 2.42293
196/196 - 61s - loss: 2.4240 - MinusLogProbMetric: 2.4240 - val_loss: 2.4351 - val_MinusLogProbMetric: 2.4351 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 70/1000
2023-09-16 09:42:12.067 
Epoch 70/1000 
	 loss: 2.4080, MinusLogProbMetric: 2.4080, val_loss: 2.4258, val_MinusLogProbMetric: 2.4258

Epoch 70: val_loss did not improve from 2.42293
196/196 - 60s - loss: 2.4080 - MinusLogProbMetric: 2.4080 - val_loss: 2.4258 - val_MinusLogProbMetric: 2.4258 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 71/1000
2023-09-16 09:43:12.502 
Epoch 71/1000 
	 loss: 2.4098, MinusLogProbMetric: 2.4098, val_loss: 2.4751, val_MinusLogProbMetric: 2.4751

Epoch 71: val_loss did not improve from 2.42293
196/196 - 60s - loss: 2.4098 - MinusLogProbMetric: 2.4098 - val_loss: 2.4751 - val_MinusLogProbMetric: 2.4751 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 72/1000
2023-09-16 09:44:13.401 
Epoch 72/1000 
	 loss: 2.4235, MinusLogProbMetric: 2.4235, val_loss: 2.4822, val_MinusLogProbMetric: 2.4822

Epoch 72: val_loss did not improve from 2.42293
196/196 - 61s - loss: 2.4235 - MinusLogProbMetric: 2.4235 - val_loss: 2.4822 - val_MinusLogProbMetric: 2.4822 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 73/1000
2023-09-16 09:45:14.498 
Epoch 73/1000 
	 loss: 2.4172, MinusLogProbMetric: 2.4172, val_loss: 2.4388, val_MinusLogProbMetric: 2.4388

Epoch 73: val_loss did not improve from 2.42293
196/196 - 61s - loss: 2.4172 - MinusLogProbMetric: 2.4172 - val_loss: 2.4388 - val_MinusLogProbMetric: 2.4388 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 74/1000
2023-09-16 09:46:14.620 
Epoch 74/1000 
	 loss: 2.4207, MinusLogProbMetric: 2.4207, val_loss: 2.4142, val_MinusLogProbMetric: 2.4142

Epoch 74: val_loss improved from 2.42293 to 2.41418, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 61s - loss: 2.4207 - MinusLogProbMetric: 2.4207 - val_loss: 2.4142 - val_MinusLogProbMetric: 2.4142 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 75/1000
2023-09-16 09:47:15.924 
Epoch 75/1000 
	 loss: 2.4129, MinusLogProbMetric: 2.4129, val_loss: 2.4383, val_MinusLogProbMetric: 2.4383

Epoch 75: val_loss did not improve from 2.41418
196/196 - 60s - loss: 2.4129 - MinusLogProbMetric: 2.4129 - val_loss: 2.4383 - val_MinusLogProbMetric: 2.4383 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 76/1000
2023-09-16 09:48:16.571 
Epoch 76/1000 
	 loss: 2.4139, MinusLogProbMetric: 2.4139, val_loss: 2.4489, val_MinusLogProbMetric: 2.4489

Epoch 76: val_loss did not improve from 2.41418
196/196 - 61s - loss: 2.4139 - MinusLogProbMetric: 2.4139 - val_loss: 2.4489 - val_MinusLogProbMetric: 2.4489 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 77/1000
2023-09-16 09:49:17.067 
Epoch 77/1000 
	 loss: 2.4266, MinusLogProbMetric: 2.4266, val_loss: 2.5623, val_MinusLogProbMetric: 2.5623

Epoch 77: val_loss did not improve from 2.41418
196/196 - 60s - loss: 2.4266 - MinusLogProbMetric: 2.4266 - val_loss: 2.5623 - val_MinusLogProbMetric: 2.5623 - lr: 0.0010 - 60s/epoch - 309ms/step
Epoch 78/1000
2023-09-16 09:50:17.255 
Epoch 78/1000 
	 loss: 2.4078, MinusLogProbMetric: 2.4078, val_loss: 2.4334, val_MinusLogProbMetric: 2.4334

Epoch 78: val_loss did not improve from 2.41418
196/196 - 60s - loss: 2.4078 - MinusLogProbMetric: 2.4078 - val_loss: 2.4334 - val_MinusLogProbMetric: 2.4334 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 79/1000
2023-09-16 09:51:17.339 
Epoch 79/1000 
	 loss: 2.3961, MinusLogProbMetric: 2.3961, val_loss: 2.4422, val_MinusLogProbMetric: 2.4422

Epoch 79: val_loss did not improve from 2.41418
196/196 - 60s - loss: 2.3961 - MinusLogProbMetric: 2.3961 - val_loss: 2.4422 - val_MinusLogProbMetric: 2.4422 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 80/1000
2023-09-16 09:52:17.904 
Epoch 80/1000 
	 loss: 2.4237, MinusLogProbMetric: 2.4237, val_loss: 2.4478, val_MinusLogProbMetric: 2.4478

Epoch 80: val_loss did not improve from 2.41418
196/196 - 61s - loss: 2.4237 - MinusLogProbMetric: 2.4237 - val_loss: 2.4478 - val_MinusLogProbMetric: 2.4478 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 81/1000
2023-09-16 09:53:18.273 
Epoch 81/1000 
	 loss: 2.3998, MinusLogProbMetric: 2.3998, val_loss: 2.4493, val_MinusLogProbMetric: 2.4493

Epoch 81: val_loss did not improve from 2.41418
196/196 - 60s - loss: 2.3998 - MinusLogProbMetric: 2.3998 - val_loss: 2.4493 - val_MinusLogProbMetric: 2.4493 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 82/1000
2023-09-16 09:54:18.841 
Epoch 82/1000 
	 loss: 2.4180, MinusLogProbMetric: 2.4180, val_loss: 2.4115, val_MinusLogProbMetric: 2.4115

Epoch 82: val_loss improved from 2.41418 to 2.41152, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 62s - loss: 2.4180 - MinusLogProbMetric: 2.4180 - val_loss: 2.4115 - val_MinusLogProbMetric: 2.4115 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 83/1000
2023-09-16 09:55:20.422 
Epoch 83/1000 
	 loss: 2.4040, MinusLogProbMetric: 2.4040, val_loss: 2.4200, val_MinusLogProbMetric: 2.4200

Epoch 83: val_loss did not improve from 2.41152
196/196 - 61s - loss: 2.4040 - MinusLogProbMetric: 2.4040 - val_loss: 2.4200 - val_MinusLogProbMetric: 2.4200 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 84/1000
2023-09-16 09:56:20.966 
Epoch 84/1000 
	 loss: 2.4108, MinusLogProbMetric: 2.4108, val_loss: 2.4196, val_MinusLogProbMetric: 2.4196

Epoch 84: val_loss did not improve from 2.41152
196/196 - 61s - loss: 2.4108 - MinusLogProbMetric: 2.4108 - val_loss: 2.4196 - val_MinusLogProbMetric: 2.4196 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 85/1000
2023-09-16 09:57:21.966 
Epoch 85/1000 
	 loss: 2.4293, MinusLogProbMetric: 2.4293, val_loss: 2.4755, val_MinusLogProbMetric: 2.4755

Epoch 85: val_loss did not improve from 2.41152
196/196 - 61s - loss: 2.4293 - MinusLogProbMetric: 2.4293 - val_loss: 2.4755 - val_MinusLogProbMetric: 2.4755 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 86/1000
2023-09-16 09:58:22.464 
Epoch 86/1000 
	 loss: 2.4166, MinusLogProbMetric: 2.4166, val_loss: 2.6677, val_MinusLogProbMetric: 2.6677

Epoch 86: val_loss did not improve from 2.41152
196/196 - 60s - loss: 2.4166 - MinusLogProbMetric: 2.4166 - val_loss: 2.6677 - val_MinusLogProbMetric: 2.6677 - lr: 0.0010 - 60s/epoch - 309ms/step
Epoch 87/1000
2023-09-16 09:59:22.222 
Epoch 87/1000 
	 loss: 2.4133, MinusLogProbMetric: 2.4133, val_loss: 2.4164, val_MinusLogProbMetric: 2.4164

Epoch 87: val_loss did not improve from 2.41152
196/196 - 60s - loss: 2.4133 - MinusLogProbMetric: 2.4133 - val_loss: 2.4164 - val_MinusLogProbMetric: 2.4164 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 88/1000
2023-09-16 10:00:22.841 
Epoch 88/1000 
	 loss: 2.4174, MinusLogProbMetric: 2.4174, val_loss: 2.6022, val_MinusLogProbMetric: 2.6022

Epoch 88: val_loss did not improve from 2.41152
196/196 - 61s - loss: 2.4174 - MinusLogProbMetric: 2.4174 - val_loss: 2.6022 - val_MinusLogProbMetric: 2.6022 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 89/1000
2023-09-16 10:01:23.520 
Epoch 89/1000 
	 loss: 2.4112, MinusLogProbMetric: 2.4112, val_loss: 2.4323, val_MinusLogProbMetric: 2.4323

Epoch 89: val_loss did not improve from 2.41152
196/196 - 61s - loss: 2.4112 - MinusLogProbMetric: 2.4112 - val_loss: 2.4323 - val_MinusLogProbMetric: 2.4323 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 90/1000
2023-09-16 10:02:23.790 
Epoch 90/1000 
	 loss: 2.4139, MinusLogProbMetric: 2.4139, val_loss: 2.5179, val_MinusLogProbMetric: 2.5179

Epoch 90: val_loss did not improve from 2.41152
196/196 - 60s - loss: 2.4139 - MinusLogProbMetric: 2.4139 - val_loss: 2.5179 - val_MinusLogProbMetric: 2.5179 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 91/1000
2023-09-16 10:03:24.969 
Epoch 91/1000 
	 loss: 2.4127, MinusLogProbMetric: 2.4127, val_loss: 2.4511, val_MinusLogProbMetric: 2.4511

Epoch 91: val_loss did not improve from 2.41152
196/196 - 61s - loss: 2.4127 - MinusLogProbMetric: 2.4127 - val_loss: 2.4511 - val_MinusLogProbMetric: 2.4511 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 92/1000
2023-09-16 10:04:25.810 
Epoch 92/1000 
	 loss: 2.4147, MinusLogProbMetric: 2.4147, val_loss: 2.4163, val_MinusLogProbMetric: 2.4163

Epoch 92: val_loss did not improve from 2.41152
196/196 - 61s - loss: 2.4147 - MinusLogProbMetric: 2.4147 - val_loss: 2.4163 - val_MinusLogProbMetric: 2.4163 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 93/1000
2023-09-16 10:05:17.395 
Epoch 93/1000 
	 loss: 2.4065, MinusLogProbMetric: 2.4065, val_loss: 2.4571, val_MinusLogProbMetric: 2.4571

Epoch 93: val_loss did not improve from 2.41152
196/196 - 52s - loss: 2.4065 - MinusLogProbMetric: 2.4065 - val_loss: 2.4571 - val_MinusLogProbMetric: 2.4571 - lr: 0.0010 - 52s/epoch - 263ms/step
Epoch 94/1000
2023-09-16 10:06:11.020 
Epoch 94/1000 
	 loss: 2.4140, MinusLogProbMetric: 2.4140, val_loss: 2.4201, val_MinusLogProbMetric: 2.4201

Epoch 94: val_loss did not improve from 2.41152
196/196 - 54s - loss: 2.4140 - MinusLogProbMetric: 2.4140 - val_loss: 2.4201 - val_MinusLogProbMetric: 2.4201 - lr: 0.0010 - 54s/epoch - 274ms/step
Epoch 95/1000
2023-09-16 10:07:09.279 
Epoch 95/1000 
	 loss: 2.3897, MinusLogProbMetric: 2.3897, val_loss: 2.4261, val_MinusLogProbMetric: 2.4261

Epoch 95: val_loss did not improve from 2.41152
196/196 - 58s - loss: 2.3897 - MinusLogProbMetric: 2.3897 - val_loss: 2.4261 - val_MinusLogProbMetric: 2.4261 - lr: 0.0010 - 58s/epoch - 297ms/step
Epoch 96/1000
2023-09-16 10:08:09.454 
Epoch 96/1000 
	 loss: 2.4066, MinusLogProbMetric: 2.4066, val_loss: 2.4204, val_MinusLogProbMetric: 2.4204

Epoch 96: val_loss did not improve from 2.41152
196/196 - 60s - loss: 2.4066 - MinusLogProbMetric: 2.4066 - val_loss: 2.4204 - val_MinusLogProbMetric: 2.4204 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 97/1000
2023-09-16 10:09:09.748 
Epoch 97/1000 
	 loss: 2.4106, MinusLogProbMetric: 2.4106, val_loss: 2.4431, val_MinusLogProbMetric: 2.4431

Epoch 97: val_loss did not improve from 2.41152
196/196 - 60s - loss: 2.4106 - MinusLogProbMetric: 2.4106 - val_loss: 2.4431 - val_MinusLogProbMetric: 2.4431 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 98/1000
2023-09-16 10:10:10.589 
Epoch 98/1000 
	 loss: 2.4093, MinusLogProbMetric: 2.4093, val_loss: 2.4966, val_MinusLogProbMetric: 2.4966

Epoch 98: val_loss did not improve from 2.41152
196/196 - 61s - loss: 2.4093 - MinusLogProbMetric: 2.4093 - val_loss: 2.4966 - val_MinusLogProbMetric: 2.4966 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 99/1000
2023-09-16 10:11:11.033 
Epoch 99/1000 
	 loss: 2.4002, MinusLogProbMetric: 2.4002, val_loss: 2.5272, val_MinusLogProbMetric: 2.5272

Epoch 99: val_loss did not improve from 2.41152
196/196 - 60s - loss: 2.4002 - MinusLogProbMetric: 2.4002 - val_loss: 2.5272 - val_MinusLogProbMetric: 2.5272 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 100/1000
2023-09-16 10:12:11.554 
Epoch 100/1000 
	 loss: 2.4064, MinusLogProbMetric: 2.4064, val_loss: 2.4201, val_MinusLogProbMetric: 2.4201

Epoch 100: val_loss did not improve from 2.41152
196/196 - 61s - loss: 2.4064 - MinusLogProbMetric: 2.4064 - val_loss: 2.4201 - val_MinusLogProbMetric: 2.4201 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 101/1000
2023-09-16 10:13:12.339 
Epoch 101/1000 
	 loss: 2.4136, MinusLogProbMetric: 2.4136, val_loss: 2.4199, val_MinusLogProbMetric: 2.4199

Epoch 101: val_loss did not improve from 2.41152
196/196 - 61s - loss: 2.4136 - MinusLogProbMetric: 2.4136 - val_loss: 2.4199 - val_MinusLogProbMetric: 2.4199 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 102/1000
2023-09-16 10:14:13.502 
Epoch 102/1000 
	 loss: 2.4088, MinusLogProbMetric: 2.4088, val_loss: 2.4236, val_MinusLogProbMetric: 2.4236

Epoch 102: val_loss did not improve from 2.41152
196/196 - 61s - loss: 2.4088 - MinusLogProbMetric: 2.4088 - val_loss: 2.4236 - val_MinusLogProbMetric: 2.4236 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 103/1000
2023-09-16 10:15:14.126 
Epoch 103/1000 
	 loss: 2.3971, MinusLogProbMetric: 2.3971, val_loss: 2.4405, val_MinusLogProbMetric: 2.4405

Epoch 103: val_loss did not improve from 2.41152
196/196 - 61s - loss: 2.3971 - MinusLogProbMetric: 2.3971 - val_loss: 2.4405 - val_MinusLogProbMetric: 2.4405 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 104/1000
2023-09-16 10:16:14.575 
Epoch 104/1000 
	 loss: 2.4033, MinusLogProbMetric: 2.4033, val_loss: 2.4189, val_MinusLogProbMetric: 2.4189

Epoch 104: val_loss did not improve from 2.41152
196/196 - 60s - loss: 2.4033 - MinusLogProbMetric: 2.4033 - val_loss: 2.4189 - val_MinusLogProbMetric: 2.4189 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 105/1000
2023-09-16 10:17:14.745 
Epoch 105/1000 
	 loss: 2.4098, MinusLogProbMetric: 2.4098, val_loss: 2.4940, val_MinusLogProbMetric: 2.4940

Epoch 105: val_loss did not improve from 2.41152
196/196 - 60s - loss: 2.4098 - MinusLogProbMetric: 2.4098 - val_loss: 2.4940 - val_MinusLogProbMetric: 2.4940 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 106/1000
2023-09-16 10:18:14.833 
Epoch 106/1000 
	 loss: 2.4018, MinusLogProbMetric: 2.4018, val_loss: 2.4436, val_MinusLogProbMetric: 2.4436

Epoch 106: val_loss did not improve from 2.41152
196/196 - 60s - loss: 2.4018 - MinusLogProbMetric: 2.4018 - val_loss: 2.4436 - val_MinusLogProbMetric: 2.4436 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 107/1000
2023-09-16 10:19:15.720 
Epoch 107/1000 
	 loss: 2.4098, MinusLogProbMetric: 2.4098, val_loss: 2.4274, val_MinusLogProbMetric: 2.4274

Epoch 107: val_loss did not improve from 2.41152
196/196 - 61s - loss: 2.4098 - MinusLogProbMetric: 2.4098 - val_loss: 2.4274 - val_MinusLogProbMetric: 2.4274 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 108/1000
2023-09-16 10:20:16.547 
Epoch 108/1000 
	 loss: 2.4067, MinusLogProbMetric: 2.4067, val_loss: 2.4203, val_MinusLogProbMetric: 2.4203

Epoch 108: val_loss did not improve from 2.41152
196/196 - 61s - loss: 2.4067 - MinusLogProbMetric: 2.4067 - val_loss: 2.4203 - val_MinusLogProbMetric: 2.4203 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 109/1000
2023-09-16 10:21:18.996 
Epoch 109/1000 
	 loss: 2.3906, MinusLogProbMetric: 2.3906, val_loss: 2.4407, val_MinusLogProbMetric: 2.4407

Epoch 109: val_loss did not improve from 2.41152
196/196 - 62s - loss: 2.3906 - MinusLogProbMetric: 2.3906 - val_loss: 2.4407 - val_MinusLogProbMetric: 2.4407 - lr: 0.0010 - 62s/epoch - 319ms/step
Epoch 110/1000
2023-09-16 10:22:21.651 
Epoch 110/1000 
	 loss: 2.4021, MinusLogProbMetric: 2.4021, val_loss: 2.4426, val_MinusLogProbMetric: 2.4426

Epoch 110: val_loss did not improve from 2.41152
196/196 - 63s - loss: 2.4021 - MinusLogProbMetric: 2.4021 - val_loss: 2.4426 - val_MinusLogProbMetric: 2.4426 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 111/1000
2023-09-16 10:23:25.203 
Epoch 111/1000 
	 loss: 2.4043, MinusLogProbMetric: 2.4043, val_loss: 2.5228, val_MinusLogProbMetric: 2.5228

Epoch 111: val_loss did not improve from 2.41152
196/196 - 64s - loss: 2.4043 - MinusLogProbMetric: 2.4043 - val_loss: 2.5228 - val_MinusLogProbMetric: 2.5228 - lr: 0.0010 - 64s/epoch - 324ms/step
Epoch 112/1000
2023-09-16 10:24:28.518 
Epoch 112/1000 
	 loss: 2.4046, MinusLogProbMetric: 2.4046, val_loss: 2.4188, val_MinusLogProbMetric: 2.4188

Epoch 112: val_loss did not improve from 2.41152
196/196 - 63s - loss: 2.4046 - MinusLogProbMetric: 2.4046 - val_loss: 2.4188 - val_MinusLogProbMetric: 2.4188 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 113/1000
2023-09-16 10:25:31.372 
Epoch 113/1000 
	 loss: 2.4008, MinusLogProbMetric: 2.4008, val_loss: 2.4465, val_MinusLogProbMetric: 2.4465

Epoch 113: val_loss did not improve from 2.41152
196/196 - 63s - loss: 2.4008 - MinusLogProbMetric: 2.4008 - val_loss: 2.4465 - val_MinusLogProbMetric: 2.4465 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 114/1000
2023-09-16 10:26:35.189 
Epoch 114/1000 
	 loss: 2.4024, MinusLogProbMetric: 2.4024, val_loss: 2.5563, val_MinusLogProbMetric: 2.5563

Epoch 114: val_loss did not improve from 2.41152
196/196 - 64s - loss: 2.4024 - MinusLogProbMetric: 2.4024 - val_loss: 2.5563 - val_MinusLogProbMetric: 2.5563 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 115/1000
2023-09-16 10:27:36.414 
Epoch 115/1000 
	 loss: 2.4055, MinusLogProbMetric: 2.4055, val_loss: 2.4272, val_MinusLogProbMetric: 2.4272

Epoch 115: val_loss did not improve from 2.41152
196/196 - 61s - loss: 2.4055 - MinusLogProbMetric: 2.4055 - val_loss: 2.4272 - val_MinusLogProbMetric: 2.4272 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 116/1000
2023-09-16 10:28:37.880 
Epoch 116/1000 
	 loss: 2.3988, MinusLogProbMetric: 2.3988, val_loss: 2.4571, val_MinusLogProbMetric: 2.4571

Epoch 116: val_loss did not improve from 2.41152
196/196 - 61s - loss: 2.3988 - MinusLogProbMetric: 2.3988 - val_loss: 2.4571 - val_MinusLogProbMetric: 2.4571 - lr: 0.0010 - 61s/epoch - 314ms/step
Epoch 117/1000
2023-09-16 10:29:38.268 
Epoch 117/1000 
	 loss: 2.4027, MinusLogProbMetric: 2.4027, val_loss: 2.4325, val_MinusLogProbMetric: 2.4325

Epoch 117: val_loss did not improve from 2.41152
196/196 - 60s - loss: 2.4027 - MinusLogProbMetric: 2.4027 - val_loss: 2.4325 - val_MinusLogProbMetric: 2.4325 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 118/1000
2023-09-16 10:30:38.859 
Epoch 118/1000 
	 loss: 2.3896, MinusLogProbMetric: 2.3896, val_loss: 2.4568, val_MinusLogProbMetric: 2.4568

Epoch 118: val_loss did not improve from 2.41152
196/196 - 61s - loss: 2.3896 - MinusLogProbMetric: 2.3896 - val_loss: 2.4568 - val_MinusLogProbMetric: 2.4568 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 119/1000
2023-09-16 10:31:41.462 
Epoch 119/1000 
	 loss: 2.3961, MinusLogProbMetric: 2.3961, val_loss: 2.4308, val_MinusLogProbMetric: 2.4308

Epoch 119: val_loss did not improve from 2.41152
196/196 - 63s - loss: 2.3961 - MinusLogProbMetric: 2.3961 - val_loss: 2.4308 - val_MinusLogProbMetric: 2.4308 - lr: 0.0010 - 63s/epoch - 319ms/step
Epoch 120/1000
2023-09-16 10:32:44.804 
Epoch 120/1000 
	 loss: 2.4119, MinusLogProbMetric: 2.4119, val_loss: 2.4288, val_MinusLogProbMetric: 2.4288

Epoch 120: val_loss did not improve from 2.41152
196/196 - 63s - loss: 2.4119 - MinusLogProbMetric: 2.4119 - val_loss: 2.4288 - val_MinusLogProbMetric: 2.4288 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 121/1000
2023-09-16 10:33:47.773 
Epoch 121/1000 
	 loss: 2.3934, MinusLogProbMetric: 2.3934, val_loss: 2.4077, val_MinusLogProbMetric: 2.4077

Epoch 121: val_loss improved from 2.41152 to 2.40771, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 64s - loss: 2.3934 - MinusLogProbMetric: 2.3934 - val_loss: 2.4077 - val_MinusLogProbMetric: 2.4077 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 122/1000
2023-09-16 10:34:51.147 
Epoch 122/1000 
	 loss: 2.3968, MinusLogProbMetric: 2.3968, val_loss: 2.4278, val_MinusLogProbMetric: 2.4278

Epoch 122: val_loss did not improve from 2.40771
196/196 - 62s - loss: 2.3968 - MinusLogProbMetric: 2.3968 - val_loss: 2.4278 - val_MinusLogProbMetric: 2.4278 - lr: 0.0010 - 62s/epoch - 319ms/step
Epoch 123/1000
2023-09-16 10:35:53.465 
Epoch 123/1000 
	 loss: 2.4001, MinusLogProbMetric: 2.4001, val_loss: 2.4466, val_MinusLogProbMetric: 2.4466

Epoch 123: val_loss did not improve from 2.40771
196/196 - 62s - loss: 2.4001 - MinusLogProbMetric: 2.4001 - val_loss: 2.4466 - val_MinusLogProbMetric: 2.4466 - lr: 0.0010 - 62s/epoch - 318ms/step
Epoch 124/1000
2023-09-16 10:36:55.554 
Epoch 124/1000 
	 loss: 2.4027, MinusLogProbMetric: 2.4027, val_loss: 2.4406, val_MinusLogProbMetric: 2.4406

Epoch 124: val_loss did not improve from 2.40771
196/196 - 62s - loss: 2.4027 - MinusLogProbMetric: 2.4027 - val_loss: 2.4406 - val_MinusLogProbMetric: 2.4406 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 125/1000
2023-09-16 10:37:57.508 
Epoch 125/1000 
	 loss: 2.3952, MinusLogProbMetric: 2.3952, val_loss: 2.6006, val_MinusLogProbMetric: 2.6006

Epoch 125: val_loss did not improve from 2.40771
196/196 - 62s - loss: 2.3952 - MinusLogProbMetric: 2.3952 - val_loss: 2.6006 - val_MinusLogProbMetric: 2.6006 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 126/1000
2023-09-16 10:38:58.960 
Epoch 126/1000 
	 loss: 2.3931, MinusLogProbMetric: 2.3931, val_loss: 2.4140, val_MinusLogProbMetric: 2.4140

Epoch 126: val_loss did not improve from 2.40771
196/196 - 61s - loss: 2.3931 - MinusLogProbMetric: 2.3931 - val_loss: 2.4140 - val_MinusLogProbMetric: 2.4140 - lr: 0.0010 - 61s/epoch - 314ms/step
Epoch 127/1000
2023-09-16 10:39:59.164 
Epoch 127/1000 
	 loss: 2.4040, MinusLogProbMetric: 2.4040, val_loss: 2.4487, val_MinusLogProbMetric: 2.4487

Epoch 127: val_loss did not improve from 2.40771
196/196 - 60s - loss: 2.4040 - MinusLogProbMetric: 2.4040 - val_loss: 2.4487 - val_MinusLogProbMetric: 2.4487 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 128/1000
2023-09-16 10:41:01.758 
Epoch 128/1000 
	 loss: 2.3953, MinusLogProbMetric: 2.3953, val_loss: 2.4302, val_MinusLogProbMetric: 2.4302

Epoch 128: val_loss did not improve from 2.40771
196/196 - 63s - loss: 2.3953 - MinusLogProbMetric: 2.3953 - val_loss: 2.4302 - val_MinusLogProbMetric: 2.4302 - lr: 0.0010 - 63s/epoch - 319ms/step
Epoch 129/1000
2023-09-16 10:42:03.530 
Epoch 129/1000 
	 loss: 2.3971, MinusLogProbMetric: 2.3971, val_loss: 2.5523, val_MinusLogProbMetric: 2.5523

Epoch 129: val_loss did not improve from 2.40771
196/196 - 62s - loss: 2.3971 - MinusLogProbMetric: 2.3971 - val_loss: 2.5523 - val_MinusLogProbMetric: 2.5523 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 130/1000
2023-09-16 10:43:05.183 
Epoch 130/1000 
	 loss: 2.4127, MinusLogProbMetric: 2.4127, val_loss: 2.4296, val_MinusLogProbMetric: 2.4296

Epoch 130: val_loss did not improve from 2.40771
196/196 - 62s - loss: 2.4127 - MinusLogProbMetric: 2.4127 - val_loss: 2.4296 - val_MinusLogProbMetric: 2.4296 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 131/1000
2023-09-16 10:44:06.973 
Epoch 131/1000 
	 loss: 2.3888, MinusLogProbMetric: 2.3888, val_loss: 2.4304, val_MinusLogProbMetric: 2.4304

Epoch 131: val_loss did not improve from 2.40771
196/196 - 62s - loss: 2.3888 - MinusLogProbMetric: 2.3888 - val_loss: 2.4304 - val_MinusLogProbMetric: 2.4304 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 132/1000
2023-09-16 10:45:08.991 
Epoch 132/1000 
	 loss: 2.3971, MinusLogProbMetric: 2.3971, val_loss: 2.4635, val_MinusLogProbMetric: 2.4635

Epoch 132: val_loss did not improve from 2.40771
196/196 - 62s - loss: 2.3971 - MinusLogProbMetric: 2.3971 - val_loss: 2.4635 - val_MinusLogProbMetric: 2.4635 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 133/1000
2023-09-16 10:46:10.306 
Epoch 133/1000 
	 loss: 2.3992, MinusLogProbMetric: 2.3992, val_loss: 2.4164, val_MinusLogProbMetric: 2.4164

Epoch 133: val_loss did not improve from 2.40771
196/196 - 61s - loss: 2.3992 - MinusLogProbMetric: 2.3992 - val_loss: 2.4164 - val_MinusLogProbMetric: 2.4164 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 134/1000
2023-09-16 10:47:12.376 
Epoch 134/1000 
	 loss: 2.3948, MinusLogProbMetric: 2.3948, val_loss: 2.4654, val_MinusLogProbMetric: 2.4654

Epoch 134: val_loss did not improve from 2.40771
196/196 - 62s - loss: 2.3948 - MinusLogProbMetric: 2.3948 - val_loss: 2.4654 - val_MinusLogProbMetric: 2.4654 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 135/1000
2023-09-16 10:48:13.894 
Epoch 135/1000 
	 loss: 2.3884, MinusLogProbMetric: 2.3884, val_loss: 2.5600, val_MinusLogProbMetric: 2.5600

Epoch 135: val_loss did not improve from 2.40771
196/196 - 62s - loss: 2.3884 - MinusLogProbMetric: 2.3884 - val_loss: 2.5600 - val_MinusLogProbMetric: 2.5600 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 136/1000
2023-09-16 10:49:14.329 
Epoch 136/1000 
	 loss: 2.3957, MinusLogProbMetric: 2.3957, val_loss: 2.4172, val_MinusLogProbMetric: 2.4172

Epoch 136: val_loss did not improve from 2.40771
196/196 - 60s - loss: 2.3957 - MinusLogProbMetric: 2.3957 - val_loss: 2.4172 - val_MinusLogProbMetric: 2.4172 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 137/1000
2023-09-16 10:50:16.408 
Epoch 137/1000 
	 loss: 2.3880, MinusLogProbMetric: 2.3880, val_loss: 2.4205, val_MinusLogProbMetric: 2.4205

Epoch 137: val_loss did not improve from 2.40771
196/196 - 62s - loss: 2.3880 - MinusLogProbMetric: 2.3880 - val_loss: 2.4205 - val_MinusLogProbMetric: 2.4205 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 138/1000
2023-09-16 10:51:17.993 
Epoch 138/1000 
	 loss: 2.3916, MinusLogProbMetric: 2.3916, val_loss: 2.4444, val_MinusLogProbMetric: 2.4444

Epoch 138: val_loss did not improve from 2.40771
196/196 - 62s - loss: 2.3916 - MinusLogProbMetric: 2.3916 - val_loss: 2.4444 - val_MinusLogProbMetric: 2.4444 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 139/1000
2023-09-16 10:52:19.359 
Epoch 139/1000 
	 loss: 2.4068, MinusLogProbMetric: 2.4068, val_loss: 2.4828, val_MinusLogProbMetric: 2.4828

Epoch 139: val_loss did not improve from 2.40771
196/196 - 61s - loss: 2.4068 - MinusLogProbMetric: 2.4068 - val_loss: 2.4828 - val_MinusLogProbMetric: 2.4828 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 140/1000
2023-09-16 10:53:21.273 
Epoch 140/1000 
	 loss: 2.3901, MinusLogProbMetric: 2.3901, val_loss: 2.4067, val_MinusLogProbMetric: 2.4067

Epoch 140: val_loss improved from 2.40771 to 2.40669, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 63s - loss: 2.3901 - MinusLogProbMetric: 2.3901 - val_loss: 2.4067 - val_MinusLogProbMetric: 2.4067 - lr: 0.0010 - 63s/epoch - 322ms/step
Epoch 141/1000
2023-09-16 10:54:20.369 
Epoch 141/1000 
	 loss: 2.3907, MinusLogProbMetric: 2.3907, val_loss: 2.4310, val_MinusLogProbMetric: 2.4310

Epoch 141: val_loss did not improve from 2.40669
196/196 - 58s - loss: 2.3907 - MinusLogProbMetric: 2.3907 - val_loss: 2.4310 - val_MinusLogProbMetric: 2.4310 - lr: 0.0010 - 58s/epoch - 296ms/step
Epoch 142/1000
2023-09-16 10:55:22.362 
Epoch 142/1000 
	 loss: 2.3878, MinusLogProbMetric: 2.3878, val_loss: 2.4397, val_MinusLogProbMetric: 2.4397

Epoch 142: val_loss did not improve from 2.40669
196/196 - 62s - loss: 2.3878 - MinusLogProbMetric: 2.3878 - val_loss: 2.4397 - val_MinusLogProbMetric: 2.4397 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 143/1000
2023-09-16 10:56:23.591 
Epoch 143/1000 
	 loss: 2.4050, MinusLogProbMetric: 2.4050, val_loss: 2.4050, val_MinusLogProbMetric: 2.4050

Epoch 143: val_loss improved from 2.40669 to 2.40500, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 62s - loss: 2.4050 - MinusLogProbMetric: 2.4050 - val_loss: 2.4050 - val_MinusLogProbMetric: 2.4050 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 144/1000
2023-09-16 10:57:26.286 
Epoch 144/1000 
	 loss: 2.3879, MinusLogProbMetric: 2.3879, val_loss: 2.5004, val_MinusLogProbMetric: 2.5004

Epoch 144: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3879 - MinusLogProbMetric: 2.3879 - val_loss: 2.5004 - val_MinusLogProbMetric: 2.5004 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 145/1000
2023-09-16 10:58:29.547 
Epoch 145/1000 
	 loss: 2.3923, MinusLogProbMetric: 2.3923, val_loss: 2.4515, val_MinusLogProbMetric: 2.4515

Epoch 145: val_loss did not improve from 2.40500
196/196 - 63s - loss: 2.3923 - MinusLogProbMetric: 2.3923 - val_loss: 2.4515 - val_MinusLogProbMetric: 2.4515 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 146/1000
2023-09-16 10:59:31.717 
Epoch 146/1000 
	 loss: 2.3842, MinusLogProbMetric: 2.3842, val_loss: 2.4471, val_MinusLogProbMetric: 2.4471

Epoch 146: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3842 - MinusLogProbMetric: 2.3842 - val_loss: 2.4471 - val_MinusLogProbMetric: 2.4471 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 147/1000
2023-09-16 11:00:34.063 
Epoch 147/1000 
	 loss: 2.3959, MinusLogProbMetric: 2.3959, val_loss: 2.5222, val_MinusLogProbMetric: 2.5222

Epoch 147: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3959 - MinusLogProbMetric: 2.3959 - val_loss: 2.5222 - val_MinusLogProbMetric: 2.5222 - lr: 0.0010 - 62s/epoch - 318ms/step
Epoch 148/1000
2023-09-16 11:01:35.667 
Epoch 148/1000 
	 loss: 2.3933, MinusLogProbMetric: 2.3933, val_loss: 2.4113, val_MinusLogProbMetric: 2.4113

Epoch 148: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3933 - MinusLogProbMetric: 2.3933 - val_loss: 2.4113 - val_MinusLogProbMetric: 2.4113 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 149/1000
2023-09-16 11:02:38.481 
Epoch 149/1000 
	 loss: 2.4034, MinusLogProbMetric: 2.4034, val_loss: 2.4254, val_MinusLogProbMetric: 2.4254

Epoch 149: val_loss did not improve from 2.40500
196/196 - 63s - loss: 2.4034 - MinusLogProbMetric: 2.4034 - val_loss: 2.4254 - val_MinusLogProbMetric: 2.4254 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 150/1000
2023-09-16 11:03:40.285 
Epoch 150/1000 
	 loss: 2.3906, MinusLogProbMetric: 2.3906, val_loss: 2.4905, val_MinusLogProbMetric: 2.4905

Epoch 150: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3906 - MinusLogProbMetric: 2.3906 - val_loss: 2.4905 - val_MinusLogProbMetric: 2.4905 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 151/1000
2023-09-16 11:04:41.462 
Epoch 151/1000 
	 loss: 2.3917, MinusLogProbMetric: 2.3917, val_loss: 2.4128, val_MinusLogProbMetric: 2.4128

Epoch 151: val_loss did not improve from 2.40500
196/196 - 61s - loss: 2.3917 - MinusLogProbMetric: 2.3917 - val_loss: 2.4128 - val_MinusLogProbMetric: 2.4128 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 152/1000
2023-09-16 11:05:43.545 
Epoch 152/1000 
	 loss: 2.3824, MinusLogProbMetric: 2.3824, val_loss: 2.4285, val_MinusLogProbMetric: 2.4285

Epoch 152: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3824 - MinusLogProbMetric: 2.3824 - val_loss: 2.4285 - val_MinusLogProbMetric: 2.4285 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 153/1000
2023-09-16 11:06:45.124 
Epoch 153/1000 
	 loss: 2.3964, MinusLogProbMetric: 2.3964, val_loss: 2.4407, val_MinusLogProbMetric: 2.4407

Epoch 153: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3964 - MinusLogProbMetric: 2.3964 - val_loss: 2.4407 - val_MinusLogProbMetric: 2.4407 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 154/1000
2023-09-16 11:07:46.776 
Epoch 154/1000 
	 loss: 2.4007, MinusLogProbMetric: 2.4007, val_loss: 2.4416, val_MinusLogProbMetric: 2.4416

Epoch 154: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.4007 - MinusLogProbMetric: 2.4007 - val_loss: 2.4416 - val_MinusLogProbMetric: 2.4416 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 155/1000
2023-09-16 11:08:48.411 
Epoch 155/1000 
	 loss: 2.3884, MinusLogProbMetric: 2.3884, val_loss: 2.4613, val_MinusLogProbMetric: 2.4613

Epoch 155: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3884 - MinusLogProbMetric: 2.3884 - val_loss: 2.4613 - val_MinusLogProbMetric: 2.4613 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 156/1000
2023-09-16 11:09:49.533 
Epoch 156/1000 
	 loss: 2.3929, MinusLogProbMetric: 2.3929, val_loss: 2.5958, val_MinusLogProbMetric: 2.5958

Epoch 156: val_loss did not improve from 2.40500
196/196 - 61s - loss: 2.3929 - MinusLogProbMetric: 2.3929 - val_loss: 2.5958 - val_MinusLogProbMetric: 2.5958 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 157/1000
2023-09-16 11:10:51.723 
Epoch 157/1000 
	 loss: 2.3950, MinusLogProbMetric: 2.3950, val_loss: 2.4623, val_MinusLogProbMetric: 2.4623

Epoch 157: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3950 - MinusLogProbMetric: 2.3950 - val_loss: 2.4623 - val_MinusLogProbMetric: 2.4623 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 158/1000
2023-09-16 11:11:53.672 
Epoch 158/1000 
	 loss: 2.4004, MinusLogProbMetric: 2.4004, val_loss: 2.4863, val_MinusLogProbMetric: 2.4863

Epoch 158: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.4004 - MinusLogProbMetric: 2.4004 - val_loss: 2.4863 - val_MinusLogProbMetric: 2.4863 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 159/1000
2023-09-16 11:12:56.011 
Epoch 159/1000 
	 loss: 2.3925, MinusLogProbMetric: 2.3925, val_loss: 2.4768, val_MinusLogProbMetric: 2.4768

Epoch 159: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3925 - MinusLogProbMetric: 2.3925 - val_loss: 2.4768 - val_MinusLogProbMetric: 2.4768 - lr: 0.0010 - 62s/epoch - 318ms/step
Epoch 160/1000
2023-09-16 11:13:57.031 
Epoch 160/1000 
	 loss: 2.3818, MinusLogProbMetric: 2.3818, val_loss: 2.4417, val_MinusLogProbMetric: 2.4417

Epoch 160: val_loss did not improve from 2.40500
196/196 - 61s - loss: 2.3818 - MinusLogProbMetric: 2.3818 - val_loss: 2.4417 - val_MinusLogProbMetric: 2.4417 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 161/1000
2023-09-16 11:14:58.946 
Epoch 161/1000 
	 loss: 2.3818, MinusLogProbMetric: 2.3818, val_loss: 2.4635, val_MinusLogProbMetric: 2.4635

Epoch 161: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3818 - MinusLogProbMetric: 2.3818 - val_loss: 2.4635 - val_MinusLogProbMetric: 2.4635 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 162/1000
2023-09-16 11:16:00.255 
Epoch 162/1000 
	 loss: 2.3967, MinusLogProbMetric: 2.3967, val_loss: 2.4463, val_MinusLogProbMetric: 2.4463

Epoch 162: val_loss did not improve from 2.40500
196/196 - 61s - loss: 2.3967 - MinusLogProbMetric: 2.3967 - val_loss: 2.4463 - val_MinusLogProbMetric: 2.4463 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 163/1000
2023-09-16 11:17:01.837 
Epoch 163/1000 
	 loss: 2.3875, MinusLogProbMetric: 2.3875, val_loss: 2.4119, val_MinusLogProbMetric: 2.4119

Epoch 163: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3875 - MinusLogProbMetric: 2.3875 - val_loss: 2.4119 - val_MinusLogProbMetric: 2.4119 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 164/1000
2023-09-16 11:18:04.192 
Epoch 164/1000 
	 loss: 2.3890, MinusLogProbMetric: 2.3890, val_loss: 2.4568, val_MinusLogProbMetric: 2.4568

Epoch 164: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3890 - MinusLogProbMetric: 2.3890 - val_loss: 2.4568 - val_MinusLogProbMetric: 2.4568 - lr: 0.0010 - 62s/epoch - 318ms/step
Epoch 165/1000
2023-09-16 11:19:07.029 
Epoch 165/1000 
	 loss: 2.3867, MinusLogProbMetric: 2.3867, val_loss: 2.4146, val_MinusLogProbMetric: 2.4146

Epoch 165: val_loss did not improve from 2.40500
196/196 - 63s - loss: 2.3867 - MinusLogProbMetric: 2.3867 - val_loss: 2.4146 - val_MinusLogProbMetric: 2.4146 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 166/1000
2023-09-16 11:20:08.521 
Epoch 166/1000 
	 loss: 2.3814, MinusLogProbMetric: 2.3814, val_loss: 2.4961, val_MinusLogProbMetric: 2.4961

Epoch 166: val_loss did not improve from 2.40500
196/196 - 61s - loss: 2.3814 - MinusLogProbMetric: 2.3814 - val_loss: 2.4961 - val_MinusLogProbMetric: 2.4961 - lr: 0.0010 - 61s/epoch - 314ms/step
Epoch 167/1000
2023-09-16 11:21:10.900 
Epoch 167/1000 
	 loss: 2.3814, MinusLogProbMetric: 2.3814, val_loss: 2.4346, val_MinusLogProbMetric: 2.4346

Epoch 167: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3814 - MinusLogProbMetric: 2.3814 - val_loss: 2.4346 - val_MinusLogProbMetric: 2.4346 - lr: 0.0010 - 62s/epoch - 318ms/step
Epoch 168/1000
2023-09-16 11:22:13.473 
Epoch 168/1000 
	 loss: 2.3796, MinusLogProbMetric: 2.3796, val_loss: 2.4097, val_MinusLogProbMetric: 2.4097

Epoch 168: val_loss did not improve from 2.40500
196/196 - 63s - loss: 2.3796 - MinusLogProbMetric: 2.3796 - val_loss: 2.4097 - val_MinusLogProbMetric: 2.4097 - lr: 0.0010 - 63s/epoch - 319ms/step
Epoch 169/1000
2023-09-16 11:23:15.759 
Epoch 169/1000 
	 loss: 2.3819, MinusLogProbMetric: 2.3819, val_loss: 2.4103, val_MinusLogProbMetric: 2.4103

Epoch 169: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3819 - MinusLogProbMetric: 2.3819 - val_loss: 2.4103 - val_MinusLogProbMetric: 2.4103 - lr: 0.0010 - 62s/epoch - 318ms/step
Epoch 170/1000
2023-09-16 11:24:17.802 
Epoch 170/1000 
	 loss: 2.3769, MinusLogProbMetric: 2.3769, val_loss: 2.4297, val_MinusLogProbMetric: 2.4297

Epoch 170: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3769 - MinusLogProbMetric: 2.3769 - val_loss: 2.4297 - val_MinusLogProbMetric: 2.4297 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 171/1000
2023-09-16 11:25:20.624 
Epoch 171/1000 
	 loss: 2.3901, MinusLogProbMetric: 2.3901, val_loss: 2.4459, val_MinusLogProbMetric: 2.4459

Epoch 171: val_loss did not improve from 2.40500
196/196 - 63s - loss: 2.3901 - MinusLogProbMetric: 2.3901 - val_loss: 2.4459 - val_MinusLogProbMetric: 2.4459 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 172/1000
2023-09-16 11:26:24.144 
Epoch 172/1000 
	 loss: 2.4003, MinusLogProbMetric: 2.4003, val_loss: 2.4284, val_MinusLogProbMetric: 2.4284

Epoch 172: val_loss did not improve from 2.40500
196/196 - 64s - loss: 2.4003 - MinusLogProbMetric: 2.4003 - val_loss: 2.4284 - val_MinusLogProbMetric: 2.4284 - lr: 0.0010 - 64s/epoch - 324ms/step
Epoch 173/1000
2023-09-16 11:27:26.114 
Epoch 173/1000 
	 loss: 2.3931, MinusLogProbMetric: 2.3931, val_loss: 2.4138, val_MinusLogProbMetric: 2.4138

Epoch 173: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3931 - MinusLogProbMetric: 2.3931 - val_loss: 2.4138 - val_MinusLogProbMetric: 2.4138 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 174/1000
2023-09-16 11:28:28.087 
Epoch 174/1000 
	 loss: 2.3882, MinusLogProbMetric: 2.3882, val_loss: 2.4099, val_MinusLogProbMetric: 2.4099

Epoch 174: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3882 - MinusLogProbMetric: 2.3882 - val_loss: 2.4099 - val_MinusLogProbMetric: 2.4099 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 175/1000
2023-09-16 11:29:30.961 
Epoch 175/1000 
	 loss: 2.3959, MinusLogProbMetric: 2.3959, val_loss: 2.4131, val_MinusLogProbMetric: 2.4131

Epoch 175: val_loss did not improve from 2.40500
196/196 - 63s - loss: 2.3959 - MinusLogProbMetric: 2.3959 - val_loss: 2.4131 - val_MinusLogProbMetric: 2.4131 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 176/1000
2023-09-16 11:30:34.165 
Epoch 176/1000 
	 loss: 2.3876, MinusLogProbMetric: 2.3876, val_loss: 2.4179, val_MinusLogProbMetric: 2.4179

Epoch 176: val_loss did not improve from 2.40500
196/196 - 63s - loss: 2.3876 - MinusLogProbMetric: 2.3876 - val_loss: 2.4179 - val_MinusLogProbMetric: 2.4179 - lr: 0.0010 - 63s/epoch - 322ms/step
Epoch 177/1000
2023-09-16 11:31:35.657 
Epoch 177/1000 
	 loss: 2.3883, MinusLogProbMetric: 2.3883, val_loss: 2.4134, val_MinusLogProbMetric: 2.4134

Epoch 177: val_loss did not improve from 2.40500
196/196 - 61s - loss: 2.3883 - MinusLogProbMetric: 2.3883 - val_loss: 2.4134 - val_MinusLogProbMetric: 2.4134 - lr: 0.0010 - 61s/epoch - 314ms/step
Epoch 178/1000
2023-09-16 11:32:38.157 
Epoch 178/1000 
	 loss: 2.3812, MinusLogProbMetric: 2.3812, val_loss: 2.4166, val_MinusLogProbMetric: 2.4166

Epoch 178: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3812 - MinusLogProbMetric: 2.3812 - val_loss: 2.4166 - val_MinusLogProbMetric: 2.4166 - lr: 0.0010 - 62s/epoch - 319ms/step
Epoch 179/1000
2023-09-16 11:33:40.619 
Epoch 179/1000 
	 loss: 2.3851, MinusLogProbMetric: 2.3851, val_loss: 2.4168, val_MinusLogProbMetric: 2.4168

Epoch 179: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3851 - MinusLogProbMetric: 2.3851 - val_loss: 2.4168 - val_MinusLogProbMetric: 2.4168 - lr: 0.0010 - 62s/epoch - 319ms/step
Epoch 180/1000
2023-09-16 11:34:43.536 
Epoch 180/1000 
	 loss: 2.3757, MinusLogProbMetric: 2.3757, val_loss: 2.4282, val_MinusLogProbMetric: 2.4282

Epoch 180: val_loss did not improve from 2.40500
196/196 - 63s - loss: 2.3757 - MinusLogProbMetric: 2.3757 - val_loss: 2.4282 - val_MinusLogProbMetric: 2.4282 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 181/1000
2023-09-16 11:35:44.639 
Epoch 181/1000 
	 loss: 2.3736, MinusLogProbMetric: 2.3736, val_loss: 2.4158, val_MinusLogProbMetric: 2.4158

Epoch 181: val_loss did not improve from 2.40500
196/196 - 61s - loss: 2.3736 - MinusLogProbMetric: 2.3736 - val_loss: 2.4158 - val_MinusLogProbMetric: 2.4158 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 182/1000
2023-09-16 11:36:47.553 
Epoch 182/1000 
	 loss: 2.3802, MinusLogProbMetric: 2.3802, val_loss: 2.4305, val_MinusLogProbMetric: 2.4305

Epoch 182: val_loss did not improve from 2.40500
196/196 - 63s - loss: 2.3802 - MinusLogProbMetric: 2.3802 - val_loss: 2.4305 - val_MinusLogProbMetric: 2.4305 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 183/1000
2023-09-16 11:37:48.545 
Epoch 183/1000 
	 loss: 2.3916, MinusLogProbMetric: 2.3916, val_loss: 2.4370, val_MinusLogProbMetric: 2.4370

Epoch 183: val_loss did not improve from 2.40500
196/196 - 61s - loss: 2.3916 - MinusLogProbMetric: 2.3916 - val_loss: 2.4370 - val_MinusLogProbMetric: 2.4370 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 184/1000
2023-09-16 11:38:50.099 
Epoch 184/1000 
	 loss: 2.3789, MinusLogProbMetric: 2.3789, val_loss: 2.4132, val_MinusLogProbMetric: 2.4132

Epoch 184: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3789 - MinusLogProbMetric: 2.3789 - val_loss: 2.4132 - val_MinusLogProbMetric: 2.4132 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 185/1000
2023-09-16 11:39:52.784 
Epoch 185/1000 
	 loss: 2.3808, MinusLogProbMetric: 2.3808, val_loss: 2.4268, val_MinusLogProbMetric: 2.4268

Epoch 185: val_loss did not improve from 2.40500
196/196 - 63s - loss: 2.3808 - MinusLogProbMetric: 2.3808 - val_loss: 2.4268 - val_MinusLogProbMetric: 2.4268 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 186/1000
2023-09-16 11:40:53.731 
Epoch 186/1000 
	 loss: 2.3786, MinusLogProbMetric: 2.3786, val_loss: 2.4198, val_MinusLogProbMetric: 2.4198

Epoch 186: val_loss did not improve from 2.40500
196/196 - 61s - loss: 2.3786 - MinusLogProbMetric: 2.3786 - val_loss: 2.4198 - val_MinusLogProbMetric: 2.4198 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 187/1000
2023-09-16 11:41:54.331 
Epoch 187/1000 
	 loss: 2.3801, MinusLogProbMetric: 2.3801, val_loss: 2.5025, val_MinusLogProbMetric: 2.5025

Epoch 187: val_loss did not improve from 2.40500
196/196 - 61s - loss: 2.3801 - MinusLogProbMetric: 2.3801 - val_loss: 2.5025 - val_MinusLogProbMetric: 2.5025 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 188/1000
2023-09-16 11:42:56.337 
Epoch 188/1000 
	 loss: 2.3899, MinusLogProbMetric: 2.3899, val_loss: 2.4462, val_MinusLogProbMetric: 2.4462

Epoch 188: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3899 - MinusLogProbMetric: 2.3899 - val_loss: 2.4462 - val_MinusLogProbMetric: 2.4462 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 189/1000
2023-09-16 11:43:57.865 
Epoch 189/1000 
	 loss: 2.3858, MinusLogProbMetric: 2.3858, val_loss: 2.4116, val_MinusLogProbMetric: 2.4116

Epoch 189: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3858 - MinusLogProbMetric: 2.3858 - val_loss: 2.4116 - val_MinusLogProbMetric: 2.4116 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 190/1000
2023-09-16 11:44:59.152 
Epoch 190/1000 
	 loss: 2.3804, MinusLogProbMetric: 2.3804, val_loss: 2.4271, val_MinusLogProbMetric: 2.4271

Epoch 190: val_loss did not improve from 2.40500
196/196 - 61s - loss: 2.3804 - MinusLogProbMetric: 2.3804 - val_loss: 2.4271 - val_MinusLogProbMetric: 2.4271 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 191/1000
2023-09-16 11:46:01.563 
Epoch 191/1000 
	 loss: 2.3852, MinusLogProbMetric: 2.3852, val_loss: 2.4094, val_MinusLogProbMetric: 2.4094

Epoch 191: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3852 - MinusLogProbMetric: 2.3852 - val_loss: 2.4094 - val_MinusLogProbMetric: 2.4094 - lr: 0.0010 - 62s/epoch - 318ms/step
Epoch 192/1000
2023-09-16 11:47:02.256 
Epoch 192/1000 
	 loss: 2.3965, MinusLogProbMetric: 2.3965, val_loss: 2.4153, val_MinusLogProbMetric: 2.4153

Epoch 192: val_loss did not improve from 2.40500
196/196 - 61s - loss: 2.3965 - MinusLogProbMetric: 2.3965 - val_loss: 2.4153 - val_MinusLogProbMetric: 2.4153 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 193/1000
2023-09-16 11:48:03.571 
Epoch 193/1000 
	 loss: 2.3843, MinusLogProbMetric: 2.3843, val_loss: 2.4236, val_MinusLogProbMetric: 2.4236

Epoch 193: val_loss did not improve from 2.40500
196/196 - 61s - loss: 2.3843 - MinusLogProbMetric: 2.3843 - val_loss: 2.4236 - val_MinusLogProbMetric: 2.4236 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 194/1000
2023-09-16 11:49:04.232 
Epoch 194/1000 
	 loss: 2.3632, MinusLogProbMetric: 2.3632, val_loss: 2.4293, val_MinusLogProbMetric: 2.4293

Epoch 194: val_loss did not improve from 2.40500
196/196 - 61s - loss: 2.3632 - MinusLogProbMetric: 2.3632 - val_loss: 2.4293 - val_MinusLogProbMetric: 2.4293 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 195/1000
2023-09-16 11:50:05.573 
Epoch 195/1000 
	 loss: 2.3582, MinusLogProbMetric: 2.3582, val_loss: 2.4121, val_MinusLogProbMetric: 2.4121

Epoch 195: val_loss did not improve from 2.40500
196/196 - 61s - loss: 2.3582 - MinusLogProbMetric: 2.3582 - val_loss: 2.4121 - val_MinusLogProbMetric: 2.4121 - lr: 5.0000e-04 - 61s/epoch - 313ms/step
Epoch 196/1000
2023-09-16 11:51:06.149 
Epoch 196/1000 
	 loss: 2.3574, MinusLogProbMetric: 2.3574, val_loss: 2.4064, val_MinusLogProbMetric: 2.4064

Epoch 196: val_loss did not improve from 2.40500
196/196 - 61s - loss: 2.3574 - MinusLogProbMetric: 2.3574 - val_loss: 2.4064 - val_MinusLogProbMetric: 2.4064 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 197/1000
2023-09-16 11:52:07.023 
Epoch 197/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.4069, val_MinusLogProbMetric: 2.4069

Epoch 197: val_loss did not improve from 2.40500
196/196 - 61s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.4069 - val_MinusLogProbMetric: 2.4069 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 198/1000
2023-09-16 11:53:07.752 
Epoch 198/1000 
	 loss: 2.3565, MinusLogProbMetric: 2.3565, val_loss: 2.4082, val_MinusLogProbMetric: 2.4082

Epoch 198: val_loss did not improve from 2.40500
196/196 - 61s - loss: 2.3565 - MinusLogProbMetric: 2.3565 - val_loss: 2.4082 - val_MinusLogProbMetric: 2.4082 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 199/1000
2023-09-16 11:54:09.297 
Epoch 199/1000 
	 loss: 2.3580, MinusLogProbMetric: 2.3580, val_loss: 2.4108, val_MinusLogProbMetric: 2.4108

Epoch 199: val_loss did not improve from 2.40500
196/196 - 62s - loss: 2.3580 - MinusLogProbMetric: 2.3580 - val_loss: 2.4108 - val_MinusLogProbMetric: 2.4108 - lr: 5.0000e-04 - 62s/epoch - 314ms/step
Epoch 200/1000
2023-09-16 11:55:10.523 
Epoch 200/1000 
	 loss: 2.3586, MinusLogProbMetric: 2.3586, val_loss: 2.4121, val_MinusLogProbMetric: 2.4121

Epoch 200: val_loss did not improve from 2.40500
196/196 - 61s - loss: 2.3586 - MinusLogProbMetric: 2.3586 - val_loss: 2.4121 - val_MinusLogProbMetric: 2.4121 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 201/1000
2023-09-16 11:56:11.072 
Epoch 201/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.4448, val_MinusLogProbMetric: 2.4448

Epoch 201: val_loss did not improve from 2.40500
196/196 - 61s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.4448 - val_MinusLogProbMetric: 2.4448 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 202/1000
2023-09-16 11:57:11.305 
Epoch 202/1000 
	 loss: 2.3569, MinusLogProbMetric: 2.3569, val_loss: 2.4032, val_MinusLogProbMetric: 2.4032

Epoch 202: val_loss improved from 2.40500 to 2.40319, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 61s - loss: 2.3569 - MinusLogProbMetric: 2.3569 - val_loss: 2.4032 - val_MinusLogProbMetric: 2.4032 - lr: 5.0000e-04 - 61s/epoch - 313ms/step
Epoch 203/1000
2023-09-16 11:58:13.703 
Epoch 203/1000 
	 loss: 2.3540, MinusLogProbMetric: 2.3540, val_loss: 2.4009, val_MinusLogProbMetric: 2.4009

Epoch 203: val_loss improved from 2.40319 to 2.40088, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 62s - loss: 2.3540 - MinusLogProbMetric: 2.3540 - val_loss: 2.4009 - val_MinusLogProbMetric: 2.4009 - lr: 5.0000e-04 - 62s/epoch - 319ms/step
Epoch 204/1000
2023-09-16 11:59:16.354 
Epoch 204/1000 
	 loss: 2.3549, MinusLogProbMetric: 2.3549, val_loss: 2.3994, val_MinusLogProbMetric: 2.3994

Epoch 204: val_loss improved from 2.40088 to 2.39938, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 62s - loss: 2.3549 - MinusLogProbMetric: 2.3549 - val_loss: 2.3994 - val_MinusLogProbMetric: 2.3994 - lr: 5.0000e-04 - 62s/epoch - 319ms/step
Epoch 205/1000
2023-09-16 12:00:19.314 
Epoch 205/1000 
	 loss: 2.3614, MinusLogProbMetric: 2.3614, val_loss: 2.4150, val_MinusLogProbMetric: 2.4150

Epoch 205: val_loss did not improve from 2.39938
196/196 - 62s - loss: 2.3614 - MinusLogProbMetric: 2.3614 - val_loss: 2.4150 - val_MinusLogProbMetric: 2.4150 - lr: 5.0000e-04 - 62s/epoch - 317ms/step
Epoch 206/1000
2023-09-16 12:01:21.676 
Epoch 206/1000 
	 loss: 2.3608, MinusLogProbMetric: 2.3608, val_loss: 2.4092, val_MinusLogProbMetric: 2.4092

Epoch 206: val_loss did not improve from 2.39938
196/196 - 62s - loss: 2.3608 - MinusLogProbMetric: 2.3608 - val_loss: 2.4092 - val_MinusLogProbMetric: 2.4092 - lr: 5.0000e-04 - 62s/epoch - 318ms/step
Epoch 207/1000
2023-09-16 12:02:23.736 
Epoch 207/1000 
	 loss: 2.3600, MinusLogProbMetric: 2.3600, val_loss: 2.4289, val_MinusLogProbMetric: 2.4289

Epoch 207: val_loss did not improve from 2.39938
196/196 - 62s - loss: 2.3600 - MinusLogProbMetric: 2.3600 - val_loss: 2.4289 - val_MinusLogProbMetric: 2.4289 - lr: 5.0000e-04 - 62s/epoch - 317ms/step
Epoch 208/1000
2023-09-16 12:03:24.894 
Epoch 208/1000 
	 loss: 2.3584, MinusLogProbMetric: 2.3584, val_loss: 2.4042, val_MinusLogProbMetric: 2.4042

Epoch 208: val_loss did not improve from 2.39938
196/196 - 61s - loss: 2.3584 - MinusLogProbMetric: 2.3584 - val_loss: 2.4042 - val_MinusLogProbMetric: 2.4042 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 209/1000
2023-09-16 12:04:25.949 
Epoch 209/1000 
	 loss: 2.3556, MinusLogProbMetric: 2.3556, val_loss: 2.4007, val_MinusLogProbMetric: 2.4007

Epoch 209: val_loss did not improve from 2.39938
196/196 - 61s - loss: 2.3556 - MinusLogProbMetric: 2.3556 - val_loss: 2.4007 - val_MinusLogProbMetric: 2.4007 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 210/1000
2023-09-16 12:05:26.505 
Epoch 210/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.4113, val_MinusLogProbMetric: 2.4113

Epoch 210: val_loss did not improve from 2.39938
196/196 - 61s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.4113 - val_MinusLogProbMetric: 2.4113 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 211/1000
2023-09-16 12:06:27.457 
Epoch 211/1000 
	 loss: 2.3568, MinusLogProbMetric: 2.3568, val_loss: 2.4061, val_MinusLogProbMetric: 2.4061

Epoch 211: val_loss did not improve from 2.39938
196/196 - 61s - loss: 2.3568 - MinusLogProbMetric: 2.3568 - val_loss: 2.4061 - val_MinusLogProbMetric: 2.4061 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 212/1000
2023-09-16 12:07:28.607 
Epoch 212/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.4143, val_MinusLogProbMetric: 2.4143

Epoch 212: val_loss did not improve from 2.39938
196/196 - 61s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.4143 - val_MinusLogProbMetric: 2.4143 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 213/1000
2023-09-16 12:08:29.352 
Epoch 213/1000 
	 loss: 2.3552, MinusLogProbMetric: 2.3552, val_loss: 2.4082, val_MinusLogProbMetric: 2.4082

Epoch 213: val_loss did not improve from 2.39938
196/196 - 61s - loss: 2.3552 - MinusLogProbMetric: 2.3552 - val_loss: 2.4082 - val_MinusLogProbMetric: 2.4082 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 214/1000
2023-09-16 12:09:30.659 
Epoch 214/1000 
	 loss: 2.3555, MinusLogProbMetric: 2.3555, val_loss: 2.4153, val_MinusLogProbMetric: 2.4153

Epoch 214: val_loss did not improve from 2.39938
196/196 - 61s - loss: 2.3555 - MinusLogProbMetric: 2.3555 - val_loss: 2.4153 - val_MinusLogProbMetric: 2.4153 - lr: 5.0000e-04 - 61s/epoch - 313ms/step
Epoch 215/1000
2023-09-16 12:10:30.747 
Epoch 215/1000 
	 loss: 2.3575, MinusLogProbMetric: 2.3575, val_loss: 2.4026, val_MinusLogProbMetric: 2.4026

Epoch 215: val_loss did not improve from 2.39938
196/196 - 60s - loss: 2.3575 - MinusLogProbMetric: 2.3575 - val_loss: 2.4026 - val_MinusLogProbMetric: 2.4026 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 216/1000
2023-09-16 12:11:31.506 
Epoch 216/1000 
	 loss: 2.3540, MinusLogProbMetric: 2.3540, val_loss: 2.4052, val_MinusLogProbMetric: 2.4052

Epoch 216: val_loss did not improve from 2.39938
196/196 - 61s - loss: 2.3540 - MinusLogProbMetric: 2.3540 - val_loss: 2.4052 - val_MinusLogProbMetric: 2.4052 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 217/1000
2023-09-16 12:12:31.529 
Epoch 217/1000 
	 loss: 2.3542, MinusLogProbMetric: 2.3542, val_loss: 2.4360, val_MinusLogProbMetric: 2.4360

Epoch 217: val_loss did not improve from 2.39938
196/196 - 60s - loss: 2.3542 - MinusLogProbMetric: 2.3542 - val_loss: 2.4360 - val_MinusLogProbMetric: 2.4360 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 218/1000
2023-09-16 12:13:31.663 
Epoch 218/1000 
	 loss: 2.3572, MinusLogProbMetric: 2.3572, val_loss: 2.4034, val_MinusLogProbMetric: 2.4034

Epoch 218: val_loss did not improve from 2.39938
196/196 - 60s - loss: 2.3572 - MinusLogProbMetric: 2.3572 - val_loss: 2.4034 - val_MinusLogProbMetric: 2.4034 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 219/1000
2023-09-16 12:14:32.144 
Epoch 219/1000 
	 loss: 2.3573, MinusLogProbMetric: 2.3573, val_loss: 2.4030, val_MinusLogProbMetric: 2.4030

Epoch 219: val_loss did not improve from 2.39938
196/196 - 60s - loss: 2.3573 - MinusLogProbMetric: 2.3573 - val_loss: 2.4030 - val_MinusLogProbMetric: 2.4030 - lr: 5.0000e-04 - 60s/epoch - 309ms/step
Epoch 220/1000
2023-09-16 12:15:33.693 
Epoch 220/1000 
	 loss: 2.3537, MinusLogProbMetric: 2.3537, val_loss: 2.4007, val_MinusLogProbMetric: 2.4007

Epoch 220: val_loss did not improve from 2.39938
196/196 - 62s - loss: 2.3537 - MinusLogProbMetric: 2.3537 - val_loss: 2.4007 - val_MinusLogProbMetric: 2.4007 - lr: 5.0000e-04 - 62s/epoch - 314ms/step
Epoch 221/1000
2023-09-16 12:16:35.286 
Epoch 221/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.4052, val_MinusLogProbMetric: 2.4052

Epoch 221: val_loss did not improve from 2.39938
196/196 - 62s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.4052 - val_MinusLogProbMetric: 2.4052 - lr: 5.0000e-04 - 62s/epoch - 314ms/step
Epoch 222/1000
2023-09-16 12:17:36.156 
Epoch 222/1000 
	 loss: 2.3558, MinusLogProbMetric: 2.3558, val_loss: 2.4093, val_MinusLogProbMetric: 2.4093

Epoch 222: val_loss did not improve from 2.39938
196/196 - 61s - loss: 2.3558 - MinusLogProbMetric: 2.3558 - val_loss: 2.4093 - val_MinusLogProbMetric: 2.4093 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 223/1000
2023-09-16 12:18:37.110 
Epoch 223/1000 
	 loss: 2.3555, MinusLogProbMetric: 2.3555, val_loss: 2.4044, val_MinusLogProbMetric: 2.4044

Epoch 223: val_loss did not improve from 2.39938
196/196 - 61s - loss: 2.3555 - MinusLogProbMetric: 2.3555 - val_loss: 2.4044 - val_MinusLogProbMetric: 2.4044 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 224/1000
2023-09-16 12:19:39.265 
Epoch 224/1000 
	 loss: 2.3509, MinusLogProbMetric: 2.3509, val_loss: 2.4016, val_MinusLogProbMetric: 2.4016

Epoch 224: val_loss did not improve from 2.39938
196/196 - 62s - loss: 2.3509 - MinusLogProbMetric: 2.3509 - val_loss: 2.4016 - val_MinusLogProbMetric: 2.4016 - lr: 5.0000e-04 - 62s/epoch - 317ms/step
Epoch 225/1000
2023-09-16 12:20:40.268 
Epoch 225/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.4044, val_MinusLogProbMetric: 2.4044

Epoch 225: val_loss did not improve from 2.39938
196/196 - 61s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.4044 - val_MinusLogProbMetric: 2.4044 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 226/1000
2023-09-16 12:21:40.010 
Epoch 226/1000 
	 loss: 2.3550, MinusLogProbMetric: 2.3550, val_loss: 2.4120, val_MinusLogProbMetric: 2.4120

Epoch 226: val_loss did not improve from 2.39938
196/196 - 60s - loss: 2.3550 - MinusLogProbMetric: 2.3550 - val_loss: 2.4120 - val_MinusLogProbMetric: 2.4120 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 227/1000
2023-09-16 12:22:40.634 
Epoch 227/1000 
	 loss: 2.3522, MinusLogProbMetric: 2.3522, val_loss: 2.4264, val_MinusLogProbMetric: 2.4264

Epoch 227: val_loss did not improve from 2.39938
196/196 - 61s - loss: 2.3522 - MinusLogProbMetric: 2.3522 - val_loss: 2.4264 - val_MinusLogProbMetric: 2.4264 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 228/1000
2023-09-16 12:23:41.292 
Epoch 228/1000 
	 loss: 2.3579, MinusLogProbMetric: 2.3579, val_loss: 2.3987, val_MinusLogProbMetric: 2.3987

Epoch 228: val_loss improved from 2.39938 to 2.39873, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_69/weights/best_weights.h5
196/196 - 62s - loss: 2.3579 - MinusLogProbMetric: 2.3579 - val_loss: 2.3987 - val_MinusLogProbMetric: 2.3987 - lr: 5.0000e-04 - 62s/epoch - 315ms/step
Epoch 229/1000
2023-09-16 12:24:42.900 
Epoch 229/1000 
	 loss: 2.3580, MinusLogProbMetric: 2.3580, val_loss: 2.4032, val_MinusLogProbMetric: 2.4032

Epoch 229: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3580 - MinusLogProbMetric: 2.3580 - val_loss: 2.4032 - val_MinusLogProbMetric: 2.4032 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 230/1000
2023-09-16 12:25:43.383 
Epoch 230/1000 
	 loss: 2.3555, MinusLogProbMetric: 2.3555, val_loss: 2.4044, val_MinusLogProbMetric: 2.4044

Epoch 230: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3555 - MinusLogProbMetric: 2.3555 - val_loss: 2.4044 - val_MinusLogProbMetric: 2.4044 - lr: 5.0000e-04 - 60s/epoch - 309ms/step
Epoch 231/1000
2023-09-16 12:26:43.333 
Epoch 231/1000 
	 loss: 2.3532, MinusLogProbMetric: 2.3532, val_loss: 2.4065, val_MinusLogProbMetric: 2.4065

Epoch 231: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3532 - MinusLogProbMetric: 2.3532 - val_loss: 2.4065 - val_MinusLogProbMetric: 2.4065 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 232/1000
2023-09-16 12:27:44.348 
Epoch 232/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.4053, val_MinusLogProbMetric: 2.4053

Epoch 232: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.4053 - val_MinusLogProbMetric: 2.4053 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 233/1000
2023-09-16 12:28:45.036 
Epoch 233/1000 
	 loss: 2.3537, MinusLogProbMetric: 2.3537, val_loss: 2.4031, val_MinusLogProbMetric: 2.4031

Epoch 233: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3537 - MinusLogProbMetric: 2.3537 - val_loss: 2.4031 - val_MinusLogProbMetric: 2.4031 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 234/1000
2023-09-16 12:29:45.844 
Epoch 234/1000 
	 loss: 2.3558, MinusLogProbMetric: 2.3558, val_loss: 2.4046, val_MinusLogProbMetric: 2.4046

Epoch 234: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3558 - MinusLogProbMetric: 2.3558 - val_loss: 2.4046 - val_MinusLogProbMetric: 2.4046 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 235/1000
2023-09-16 12:30:46.363 
Epoch 235/1000 
	 loss: 2.3543, MinusLogProbMetric: 2.3543, val_loss: 2.4014, val_MinusLogProbMetric: 2.4014

Epoch 235: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3543 - MinusLogProbMetric: 2.3543 - val_loss: 2.4014 - val_MinusLogProbMetric: 2.4014 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 236/1000
2023-09-16 12:31:47.721 
Epoch 236/1000 
	 loss: 2.3560, MinusLogProbMetric: 2.3560, val_loss: 2.4046, val_MinusLogProbMetric: 2.4046

Epoch 236: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3560 - MinusLogProbMetric: 2.3560 - val_loss: 2.4046 - val_MinusLogProbMetric: 2.4046 - lr: 5.0000e-04 - 61s/epoch - 313ms/step
Epoch 237/1000
2023-09-16 12:32:48.759 
Epoch 237/1000 
	 loss: 2.3544, MinusLogProbMetric: 2.3544, val_loss: 2.4201, val_MinusLogProbMetric: 2.4201

Epoch 237: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3544 - MinusLogProbMetric: 2.3544 - val_loss: 2.4201 - val_MinusLogProbMetric: 2.4201 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 238/1000
2023-09-16 12:33:49.309 
Epoch 238/1000 
	 loss: 2.3555, MinusLogProbMetric: 2.3555, val_loss: 2.4032, val_MinusLogProbMetric: 2.4032

Epoch 238: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3555 - MinusLogProbMetric: 2.3555 - val_loss: 2.4032 - val_MinusLogProbMetric: 2.4032 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 239/1000
2023-09-16 12:34:49.470 
Epoch 239/1000 
	 loss: 2.3494, MinusLogProbMetric: 2.3494, val_loss: 2.4087, val_MinusLogProbMetric: 2.4087

Epoch 239: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3494 - MinusLogProbMetric: 2.3494 - val_loss: 2.4087 - val_MinusLogProbMetric: 2.4087 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 240/1000
2023-09-16 12:35:50.210 
Epoch 240/1000 
	 loss: 2.3558, MinusLogProbMetric: 2.3558, val_loss: 2.4076, val_MinusLogProbMetric: 2.4076

Epoch 240: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3558 - MinusLogProbMetric: 2.3558 - val_loss: 2.4076 - val_MinusLogProbMetric: 2.4076 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 241/1000
2023-09-16 12:36:51.015 
Epoch 241/1000 
	 loss: 2.3538, MinusLogProbMetric: 2.3538, val_loss: 2.4094, val_MinusLogProbMetric: 2.4094

Epoch 241: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3538 - MinusLogProbMetric: 2.3538 - val_loss: 2.4094 - val_MinusLogProbMetric: 2.4094 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 242/1000
2023-09-16 12:37:51.278 
Epoch 242/1000 
	 loss: 2.3548, MinusLogProbMetric: 2.3548, val_loss: 2.4618, val_MinusLogProbMetric: 2.4618

Epoch 242: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3548 - MinusLogProbMetric: 2.3548 - val_loss: 2.4618 - val_MinusLogProbMetric: 2.4618 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 243/1000
2023-09-16 12:38:51.341 
Epoch 243/1000 
	 loss: 2.3542, MinusLogProbMetric: 2.3542, val_loss: 2.4052, val_MinusLogProbMetric: 2.4052

Epoch 243: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3542 - MinusLogProbMetric: 2.3542 - val_loss: 2.4052 - val_MinusLogProbMetric: 2.4052 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 244/1000
2023-09-16 12:39:51.536 
Epoch 244/1000 
	 loss: 2.3585, MinusLogProbMetric: 2.3585, val_loss: 2.4132, val_MinusLogProbMetric: 2.4132

Epoch 244: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3585 - MinusLogProbMetric: 2.3585 - val_loss: 2.4132 - val_MinusLogProbMetric: 2.4132 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 245/1000
2023-09-16 12:40:52.393 
Epoch 245/1000 
	 loss: 2.3537, MinusLogProbMetric: 2.3537, val_loss: 2.4100, val_MinusLogProbMetric: 2.4100

Epoch 245: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3537 - MinusLogProbMetric: 2.3537 - val_loss: 2.4100 - val_MinusLogProbMetric: 2.4100 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 246/1000
2023-09-16 12:41:53.098 
Epoch 246/1000 
	 loss: 2.3554, MinusLogProbMetric: 2.3554, val_loss: 2.4110, val_MinusLogProbMetric: 2.4110

Epoch 246: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3554 - MinusLogProbMetric: 2.3554 - val_loss: 2.4110 - val_MinusLogProbMetric: 2.4110 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 247/1000
2023-09-16 12:42:53.302 
Epoch 247/1000 
	 loss: 2.3565, MinusLogProbMetric: 2.3565, val_loss: 2.4045, val_MinusLogProbMetric: 2.4045

Epoch 247: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3565 - MinusLogProbMetric: 2.3565 - val_loss: 2.4045 - val_MinusLogProbMetric: 2.4045 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 248/1000
2023-09-16 12:43:52.881 
Epoch 248/1000 
	 loss: 2.3544, MinusLogProbMetric: 2.3544, val_loss: 2.4249, val_MinusLogProbMetric: 2.4249

Epoch 248: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3544 - MinusLogProbMetric: 2.3544 - val_loss: 2.4249 - val_MinusLogProbMetric: 2.4249 - lr: 5.0000e-04 - 60s/epoch - 304ms/step
Epoch 249/1000
2023-09-16 12:44:53.392 
Epoch 249/1000 
	 loss: 2.3582, MinusLogProbMetric: 2.3582, val_loss: 2.4310, val_MinusLogProbMetric: 2.4310

Epoch 249: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3582 - MinusLogProbMetric: 2.3582 - val_loss: 2.4310 - val_MinusLogProbMetric: 2.4310 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 250/1000
2023-09-16 12:45:53.449 
Epoch 250/1000 
	 loss: 2.3570, MinusLogProbMetric: 2.3570, val_loss: 2.4046, val_MinusLogProbMetric: 2.4046

Epoch 250: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3570 - MinusLogProbMetric: 2.3570 - val_loss: 2.4046 - val_MinusLogProbMetric: 2.4046 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 251/1000
2023-09-16 12:46:54.675 
Epoch 251/1000 
	 loss: 2.3547, MinusLogProbMetric: 2.3547, val_loss: 2.4032, val_MinusLogProbMetric: 2.4032

Epoch 251: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3547 - MinusLogProbMetric: 2.3547 - val_loss: 2.4032 - val_MinusLogProbMetric: 2.4032 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 252/1000
2023-09-16 12:47:55.394 
Epoch 252/1000 
	 loss: 2.3511, MinusLogProbMetric: 2.3511, val_loss: 2.4125, val_MinusLogProbMetric: 2.4125

Epoch 252: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3511 - MinusLogProbMetric: 2.3511 - val_loss: 2.4125 - val_MinusLogProbMetric: 2.4125 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 253/1000
2023-09-16 12:48:55.202 
Epoch 253/1000 
	 loss: 2.3586, MinusLogProbMetric: 2.3586, val_loss: 2.4166, val_MinusLogProbMetric: 2.4166

Epoch 253: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3586 - MinusLogProbMetric: 2.3586 - val_loss: 2.4166 - val_MinusLogProbMetric: 2.4166 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 254/1000
2023-09-16 12:49:55.831 
Epoch 254/1000 
	 loss: 2.3552, MinusLogProbMetric: 2.3552, val_loss: 2.4156, val_MinusLogProbMetric: 2.4156

Epoch 254: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3552 - MinusLogProbMetric: 2.3552 - val_loss: 2.4156 - val_MinusLogProbMetric: 2.4156 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 255/1000
2023-09-16 12:50:56.148 
Epoch 255/1000 
	 loss: 2.3532, MinusLogProbMetric: 2.3532, val_loss: 2.4068, val_MinusLogProbMetric: 2.4068

Epoch 255: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3532 - MinusLogProbMetric: 2.3532 - val_loss: 2.4068 - val_MinusLogProbMetric: 2.4068 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 256/1000
2023-09-16 12:51:56.453 
Epoch 256/1000 
	 loss: 2.3561, MinusLogProbMetric: 2.3561, val_loss: 2.4193, val_MinusLogProbMetric: 2.4193

Epoch 256: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3561 - MinusLogProbMetric: 2.3561 - val_loss: 2.4193 - val_MinusLogProbMetric: 2.4193 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 257/1000
2023-09-16 12:52:57.112 
Epoch 257/1000 
	 loss: 2.3599, MinusLogProbMetric: 2.3599, val_loss: 2.4069, val_MinusLogProbMetric: 2.4069

Epoch 257: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3599 - MinusLogProbMetric: 2.3599 - val_loss: 2.4069 - val_MinusLogProbMetric: 2.4069 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 258/1000
2023-09-16 12:53:58.010 
Epoch 258/1000 
	 loss: 2.3567, MinusLogProbMetric: 2.3567, val_loss: 2.4025, val_MinusLogProbMetric: 2.4025

Epoch 258: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3567 - MinusLogProbMetric: 2.3567 - val_loss: 2.4025 - val_MinusLogProbMetric: 2.4025 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 259/1000
2023-09-16 12:54:58.664 
Epoch 259/1000 
	 loss: 2.3512, MinusLogProbMetric: 2.3512, val_loss: 2.4057, val_MinusLogProbMetric: 2.4057

Epoch 259: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3512 - MinusLogProbMetric: 2.3512 - val_loss: 2.4057 - val_MinusLogProbMetric: 2.4057 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 260/1000
2023-09-16 12:55:59.394 
Epoch 260/1000 
	 loss: 2.3503, MinusLogProbMetric: 2.3503, val_loss: 2.4069, val_MinusLogProbMetric: 2.4069

Epoch 260: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3503 - MinusLogProbMetric: 2.3503 - val_loss: 2.4069 - val_MinusLogProbMetric: 2.4069 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 261/1000
2023-09-16 12:56:59.677 
Epoch 261/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.4257, val_MinusLogProbMetric: 2.4257

Epoch 261: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.4257 - val_MinusLogProbMetric: 2.4257 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 262/1000
2023-09-16 12:58:00.551 
Epoch 262/1000 
	 loss: 2.3587, MinusLogProbMetric: 2.3587, val_loss: 2.4030, val_MinusLogProbMetric: 2.4030

Epoch 262: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3587 - MinusLogProbMetric: 2.3587 - val_loss: 2.4030 - val_MinusLogProbMetric: 2.4030 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 263/1000
2023-09-16 12:59:02.114 
Epoch 263/1000 
	 loss: 2.3584, MinusLogProbMetric: 2.3584, val_loss: 2.4116, val_MinusLogProbMetric: 2.4116

Epoch 263: val_loss did not improve from 2.39873
196/196 - 62s - loss: 2.3584 - MinusLogProbMetric: 2.3584 - val_loss: 2.4116 - val_MinusLogProbMetric: 2.4116 - lr: 5.0000e-04 - 62s/epoch - 314ms/step
Epoch 264/1000
2023-09-16 13:00:03.291 
Epoch 264/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.4179, val_MinusLogProbMetric: 2.4179

Epoch 264: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.4179 - val_MinusLogProbMetric: 2.4179 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 265/1000
2023-09-16 13:01:03.622 
Epoch 265/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.4133, val_MinusLogProbMetric: 2.4133

Epoch 265: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.4133 - val_MinusLogProbMetric: 2.4133 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 266/1000
2023-09-16 13:02:04.221 
Epoch 266/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.4575, val_MinusLogProbMetric: 2.4575

Epoch 266: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.4575 - val_MinusLogProbMetric: 2.4575 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 267/1000
2023-09-16 13:03:04.915 
Epoch 267/1000 
	 loss: 2.3568, MinusLogProbMetric: 2.3568, val_loss: 2.4058, val_MinusLogProbMetric: 2.4058

Epoch 267: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3568 - MinusLogProbMetric: 2.3568 - val_loss: 2.4058 - val_MinusLogProbMetric: 2.4058 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 268/1000
2023-09-16 13:04:05.459 
Epoch 268/1000 
	 loss: 2.3528, MinusLogProbMetric: 2.3528, val_loss: 2.4409, val_MinusLogProbMetric: 2.4409

Epoch 268: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3528 - MinusLogProbMetric: 2.3528 - val_loss: 2.4409 - val_MinusLogProbMetric: 2.4409 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 269/1000
2023-09-16 13:05:05.701 
Epoch 269/1000 
	 loss: 2.3532, MinusLogProbMetric: 2.3532, val_loss: 2.4035, val_MinusLogProbMetric: 2.4035

Epoch 269: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3532 - MinusLogProbMetric: 2.3532 - val_loss: 2.4035 - val_MinusLogProbMetric: 2.4035 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 270/1000
2023-09-16 13:06:06.470 
Epoch 270/1000 
	 loss: 2.3551, MinusLogProbMetric: 2.3551, val_loss: 2.4027, val_MinusLogProbMetric: 2.4027

Epoch 270: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3551 - MinusLogProbMetric: 2.3551 - val_loss: 2.4027 - val_MinusLogProbMetric: 2.4027 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 271/1000
2023-09-16 13:07:06.923 
Epoch 271/1000 
	 loss: 2.3495, MinusLogProbMetric: 2.3495, val_loss: 2.4006, val_MinusLogProbMetric: 2.4006

Epoch 271: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3495 - MinusLogProbMetric: 2.3495 - val_loss: 2.4006 - val_MinusLogProbMetric: 2.4006 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 272/1000
2023-09-16 13:08:07.140 
Epoch 272/1000 
	 loss: 2.3522, MinusLogProbMetric: 2.3522, val_loss: 2.4264, val_MinusLogProbMetric: 2.4264

Epoch 272: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3522 - MinusLogProbMetric: 2.3522 - val_loss: 2.4264 - val_MinusLogProbMetric: 2.4264 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 273/1000
2023-09-16 13:09:07.285 
Epoch 273/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.4043, val_MinusLogProbMetric: 2.4043

Epoch 273: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.4043 - val_MinusLogProbMetric: 2.4043 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 274/1000
2023-09-16 13:10:07.953 
Epoch 274/1000 
	 loss: 2.3552, MinusLogProbMetric: 2.3552, val_loss: 2.4087, val_MinusLogProbMetric: 2.4087

Epoch 274: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3552 - MinusLogProbMetric: 2.3552 - val_loss: 2.4087 - val_MinusLogProbMetric: 2.4087 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 275/1000
2023-09-16 13:11:08.775 
Epoch 275/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.4103, val_MinusLogProbMetric: 2.4103

Epoch 275: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.4103 - val_MinusLogProbMetric: 2.4103 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 276/1000
2023-09-16 13:12:08.967 
Epoch 276/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.4026, val_MinusLogProbMetric: 2.4026

Epoch 276: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.4026 - val_MinusLogProbMetric: 2.4026 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 277/1000
2023-09-16 13:13:09.058 
Epoch 277/1000 
	 loss: 2.3514, MinusLogProbMetric: 2.3514, val_loss: 2.4249, val_MinusLogProbMetric: 2.4249

Epoch 277: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3514 - MinusLogProbMetric: 2.3514 - val_loss: 2.4249 - val_MinusLogProbMetric: 2.4249 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 278/1000
2023-09-16 13:14:09.475 
Epoch 278/1000 
	 loss: 2.3543, MinusLogProbMetric: 2.3543, val_loss: 2.4025, val_MinusLogProbMetric: 2.4025

Epoch 278: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3543 - MinusLogProbMetric: 2.3543 - val_loss: 2.4025 - val_MinusLogProbMetric: 2.4025 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 279/1000
2023-09-16 13:15:09.827 
Epoch 279/1000 
	 loss: 2.3429, MinusLogProbMetric: 2.3429, val_loss: 2.4005, val_MinusLogProbMetric: 2.4005

Epoch 279: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3429 - MinusLogProbMetric: 2.3429 - val_loss: 2.4005 - val_MinusLogProbMetric: 2.4005 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 280/1000
2023-09-16 13:16:09.262 
Epoch 280/1000 
	 loss: 2.3422, MinusLogProbMetric: 2.3422, val_loss: 2.4043, val_MinusLogProbMetric: 2.4043

Epoch 280: val_loss did not improve from 2.39873
196/196 - 59s - loss: 2.3422 - MinusLogProbMetric: 2.3422 - val_loss: 2.4043 - val_MinusLogProbMetric: 2.4043 - lr: 2.5000e-04 - 59s/epoch - 303ms/step
Epoch 281/1000
2023-09-16 13:17:09.250 
Epoch 281/1000 
	 loss: 2.3428, MinusLogProbMetric: 2.3428, val_loss: 2.4028, val_MinusLogProbMetric: 2.4028

Epoch 281: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3428 - MinusLogProbMetric: 2.3428 - val_loss: 2.4028 - val_MinusLogProbMetric: 2.4028 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 282/1000
2023-09-16 13:18:09.602 
Epoch 282/1000 
	 loss: 2.3420, MinusLogProbMetric: 2.3420, val_loss: 2.3991, val_MinusLogProbMetric: 2.3991

Epoch 282: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3420 - MinusLogProbMetric: 2.3420 - val_loss: 2.3991 - val_MinusLogProbMetric: 2.3991 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 283/1000
2023-09-16 13:19:09.438 
Epoch 283/1000 
	 loss: 2.3402, MinusLogProbMetric: 2.3402, val_loss: 2.3993, val_MinusLogProbMetric: 2.3993

Epoch 283: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3402 - MinusLogProbMetric: 2.3402 - val_loss: 2.3993 - val_MinusLogProbMetric: 2.3993 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 284/1000
2023-09-16 13:20:09.752 
Epoch 284/1000 
	 loss: 2.3426, MinusLogProbMetric: 2.3426, val_loss: 2.3991, val_MinusLogProbMetric: 2.3991

Epoch 284: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3426 - MinusLogProbMetric: 2.3426 - val_loss: 2.3991 - val_MinusLogProbMetric: 2.3991 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 285/1000
2023-09-16 13:21:10.591 
Epoch 285/1000 
	 loss: 2.3421, MinusLogProbMetric: 2.3421, val_loss: 2.4019, val_MinusLogProbMetric: 2.4019

Epoch 285: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3421 - MinusLogProbMetric: 2.3421 - val_loss: 2.4019 - val_MinusLogProbMetric: 2.4019 - lr: 2.5000e-04 - 61s/epoch - 310ms/step
Epoch 286/1000
2023-09-16 13:22:10.303 
Epoch 286/1000 
	 loss: 2.3433, MinusLogProbMetric: 2.3433, val_loss: 2.4012, val_MinusLogProbMetric: 2.4012

Epoch 286: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3433 - MinusLogProbMetric: 2.3433 - val_loss: 2.4012 - val_MinusLogProbMetric: 2.4012 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 287/1000
2023-09-16 13:23:10.853 
Epoch 287/1000 
	 loss: 2.3421, MinusLogProbMetric: 2.3421, val_loss: 2.4016, val_MinusLogProbMetric: 2.4016

Epoch 287: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3421 - MinusLogProbMetric: 2.3421 - val_loss: 2.4016 - val_MinusLogProbMetric: 2.4016 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 288/1000
2023-09-16 13:24:11.377 
Epoch 288/1000 
	 loss: 2.3405, MinusLogProbMetric: 2.3405, val_loss: 2.4129, val_MinusLogProbMetric: 2.4129

Epoch 288: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3405 - MinusLogProbMetric: 2.3405 - val_loss: 2.4129 - val_MinusLogProbMetric: 2.4129 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 289/1000
2023-09-16 13:25:11.849 
Epoch 289/1000 
	 loss: 2.3448, MinusLogProbMetric: 2.3448, val_loss: 2.4041, val_MinusLogProbMetric: 2.4041

Epoch 289: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3448 - MinusLogProbMetric: 2.3448 - val_loss: 2.4041 - val_MinusLogProbMetric: 2.4041 - lr: 2.5000e-04 - 60s/epoch - 309ms/step
Epoch 290/1000
2023-09-16 13:26:11.847 
Epoch 290/1000 
	 loss: 2.3421, MinusLogProbMetric: 2.3421, val_loss: 2.4010, val_MinusLogProbMetric: 2.4010

Epoch 290: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3421 - MinusLogProbMetric: 2.3421 - val_loss: 2.4010 - val_MinusLogProbMetric: 2.4010 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 291/1000
2023-09-16 13:27:11.712 
Epoch 291/1000 
	 loss: 2.3421, MinusLogProbMetric: 2.3421, val_loss: 2.4022, val_MinusLogProbMetric: 2.4022

Epoch 291: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3421 - MinusLogProbMetric: 2.3421 - val_loss: 2.4022 - val_MinusLogProbMetric: 2.4022 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 292/1000
2023-09-16 13:28:11.414 
Epoch 292/1000 
	 loss: 2.3424, MinusLogProbMetric: 2.3424, val_loss: 2.4008, val_MinusLogProbMetric: 2.4008

Epoch 292: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3424 - MinusLogProbMetric: 2.3424 - val_loss: 2.4008 - val_MinusLogProbMetric: 2.4008 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 293/1000
2023-09-16 13:29:11.444 
Epoch 293/1000 
	 loss: 2.3418, MinusLogProbMetric: 2.3418, val_loss: 2.4046, val_MinusLogProbMetric: 2.4046

Epoch 293: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3418 - MinusLogProbMetric: 2.3418 - val_loss: 2.4046 - val_MinusLogProbMetric: 2.4046 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 294/1000
2023-09-16 13:30:11.508 
Epoch 294/1000 
	 loss: 2.3452, MinusLogProbMetric: 2.3452, val_loss: 2.3993, val_MinusLogProbMetric: 2.3993

Epoch 294: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3452 - MinusLogProbMetric: 2.3452 - val_loss: 2.3993 - val_MinusLogProbMetric: 2.3993 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 295/1000
2023-09-16 13:31:11.946 
Epoch 295/1000 
	 loss: 2.3426, MinusLogProbMetric: 2.3426, val_loss: 2.4001, val_MinusLogProbMetric: 2.4001

Epoch 295: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3426 - MinusLogProbMetric: 2.3426 - val_loss: 2.4001 - val_MinusLogProbMetric: 2.4001 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 296/1000
2023-09-16 13:32:11.776 
Epoch 296/1000 
	 loss: 2.3423, MinusLogProbMetric: 2.3423, val_loss: 2.4086, val_MinusLogProbMetric: 2.4086

Epoch 296: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3423 - MinusLogProbMetric: 2.3423 - val_loss: 2.4086 - val_MinusLogProbMetric: 2.4086 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 297/1000
2023-09-16 13:33:11.895 
Epoch 297/1000 
	 loss: 2.3412, MinusLogProbMetric: 2.3412, val_loss: 2.4035, val_MinusLogProbMetric: 2.4035

Epoch 297: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3412 - MinusLogProbMetric: 2.3412 - val_loss: 2.4035 - val_MinusLogProbMetric: 2.4035 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 298/1000
2023-09-16 13:34:12.112 
Epoch 298/1000 
	 loss: 2.3425, MinusLogProbMetric: 2.3425, val_loss: 2.4014, val_MinusLogProbMetric: 2.4014

Epoch 298: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3425 - MinusLogProbMetric: 2.3425 - val_loss: 2.4014 - val_MinusLogProbMetric: 2.4014 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 299/1000
2023-09-16 13:35:12.012 
Epoch 299/1000 
	 loss: 2.3419, MinusLogProbMetric: 2.3419, val_loss: 2.4163, val_MinusLogProbMetric: 2.4163

Epoch 299: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3419 - MinusLogProbMetric: 2.3419 - val_loss: 2.4163 - val_MinusLogProbMetric: 2.4163 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 300/1000
2023-09-16 13:36:11.572 
Epoch 300/1000 
	 loss: 2.3441, MinusLogProbMetric: 2.3441, val_loss: 2.3990, val_MinusLogProbMetric: 2.3990

Epoch 300: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3441 - MinusLogProbMetric: 2.3441 - val_loss: 2.3990 - val_MinusLogProbMetric: 2.3990 - lr: 2.5000e-04 - 60s/epoch - 304ms/step
Epoch 301/1000
2023-09-16 13:37:11.951 
Epoch 301/1000 
	 loss: 2.3406, MinusLogProbMetric: 2.3406, val_loss: 2.4000, val_MinusLogProbMetric: 2.4000

Epoch 301: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3406 - MinusLogProbMetric: 2.3406 - val_loss: 2.4000 - val_MinusLogProbMetric: 2.4000 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 302/1000
2023-09-16 13:38:12.088 
Epoch 302/1000 
	 loss: 2.3421, MinusLogProbMetric: 2.3421, val_loss: 2.4050, val_MinusLogProbMetric: 2.4050

Epoch 302: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3421 - MinusLogProbMetric: 2.3421 - val_loss: 2.4050 - val_MinusLogProbMetric: 2.4050 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 303/1000
2023-09-16 13:39:12.406 
Epoch 303/1000 
	 loss: 2.3408, MinusLogProbMetric: 2.3408, val_loss: 2.4190, val_MinusLogProbMetric: 2.4190

Epoch 303: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3408 - MinusLogProbMetric: 2.3408 - val_loss: 2.4190 - val_MinusLogProbMetric: 2.4190 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 304/1000
2023-09-16 13:40:12.608 
Epoch 304/1000 
	 loss: 2.3406, MinusLogProbMetric: 2.3406, val_loss: 2.4031, val_MinusLogProbMetric: 2.4031

Epoch 304: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3406 - MinusLogProbMetric: 2.3406 - val_loss: 2.4031 - val_MinusLogProbMetric: 2.4031 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 305/1000
2023-09-16 13:41:13.101 
Epoch 305/1000 
	 loss: 2.3429, MinusLogProbMetric: 2.3429, val_loss: 2.4001, val_MinusLogProbMetric: 2.4001

Epoch 305: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3429 - MinusLogProbMetric: 2.3429 - val_loss: 2.4001 - val_MinusLogProbMetric: 2.4001 - lr: 2.5000e-04 - 60s/epoch - 309ms/step
Epoch 306/1000
2023-09-16 13:42:13.508 
Epoch 306/1000 
	 loss: 2.3408, MinusLogProbMetric: 2.3408, val_loss: 2.4028, val_MinusLogProbMetric: 2.4028

Epoch 306: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3408 - MinusLogProbMetric: 2.3408 - val_loss: 2.4028 - val_MinusLogProbMetric: 2.4028 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 307/1000
2023-09-16 13:43:13.980 
Epoch 307/1000 
	 loss: 2.3393, MinusLogProbMetric: 2.3393, val_loss: 2.3993, val_MinusLogProbMetric: 2.3993

Epoch 307: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3393 - MinusLogProbMetric: 2.3393 - val_loss: 2.3993 - val_MinusLogProbMetric: 2.3993 - lr: 2.5000e-04 - 60s/epoch - 309ms/step
Epoch 308/1000
2023-09-16 13:44:14.378 
Epoch 308/1000 
	 loss: 2.3430, MinusLogProbMetric: 2.3430, val_loss: 2.4043, val_MinusLogProbMetric: 2.4043

Epoch 308: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3430 - MinusLogProbMetric: 2.3430 - val_loss: 2.4043 - val_MinusLogProbMetric: 2.4043 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 309/1000
2023-09-16 13:45:15.864 
Epoch 309/1000 
	 loss: 2.3426, MinusLogProbMetric: 2.3426, val_loss: 2.4054, val_MinusLogProbMetric: 2.4054

Epoch 309: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3426 - MinusLogProbMetric: 2.3426 - val_loss: 2.4054 - val_MinusLogProbMetric: 2.4054 - lr: 2.5000e-04 - 61s/epoch - 314ms/step
Epoch 310/1000
2023-09-16 13:46:19.079 
Epoch 310/1000 
	 loss: 2.3411, MinusLogProbMetric: 2.3411, val_loss: 2.4083, val_MinusLogProbMetric: 2.4083

Epoch 310: val_loss did not improve from 2.39873
196/196 - 63s - loss: 2.3411 - MinusLogProbMetric: 2.3411 - val_loss: 2.4083 - val_MinusLogProbMetric: 2.4083 - lr: 2.5000e-04 - 63s/epoch - 323ms/step
Epoch 311/1000
2023-09-16 13:47:22.367 
Epoch 311/1000 
	 loss: 2.3404, MinusLogProbMetric: 2.3404, val_loss: 2.4021, val_MinusLogProbMetric: 2.4021

Epoch 311: val_loss did not improve from 2.39873
196/196 - 63s - loss: 2.3404 - MinusLogProbMetric: 2.3404 - val_loss: 2.4021 - val_MinusLogProbMetric: 2.4021 - lr: 2.5000e-04 - 63s/epoch - 323ms/step
Epoch 312/1000
2023-09-16 13:48:23.851 
Epoch 312/1000 
	 loss: 2.3416, MinusLogProbMetric: 2.3416, val_loss: 2.4062, val_MinusLogProbMetric: 2.4062

Epoch 312: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3416 - MinusLogProbMetric: 2.3416 - val_loss: 2.4062 - val_MinusLogProbMetric: 2.4062 - lr: 2.5000e-04 - 61s/epoch - 314ms/step
Epoch 313/1000
2023-09-16 13:49:26.520 
Epoch 313/1000 
	 loss: 2.3401, MinusLogProbMetric: 2.3401, val_loss: 2.4003, val_MinusLogProbMetric: 2.4003

Epoch 313: val_loss did not improve from 2.39873
196/196 - 63s - loss: 2.3401 - MinusLogProbMetric: 2.3401 - val_loss: 2.4003 - val_MinusLogProbMetric: 2.4003 - lr: 2.5000e-04 - 63s/epoch - 320ms/step
Epoch 314/1000
2023-09-16 13:50:28.145 
Epoch 314/1000 
	 loss: 2.3409, MinusLogProbMetric: 2.3409, val_loss: 2.4054, val_MinusLogProbMetric: 2.4054

Epoch 314: val_loss did not improve from 2.39873
196/196 - 62s - loss: 2.3409 - MinusLogProbMetric: 2.3409 - val_loss: 2.4054 - val_MinusLogProbMetric: 2.4054 - lr: 2.5000e-04 - 62s/epoch - 314ms/step
Epoch 315/1000
2023-09-16 13:51:30.114 
Epoch 315/1000 
	 loss: 2.3407, MinusLogProbMetric: 2.3407, val_loss: 2.4004, val_MinusLogProbMetric: 2.4004

Epoch 315: val_loss did not improve from 2.39873
196/196 - 62s - loss: 2.3407 - MinusLogProbMetric: 2.3407 - val_loss: 2.4004 - val_MinusLogProbMetric: 2.4004 - lr: 2.5000e-04 - 62s/epoch - 316ms/step
Epoch 316/1000
2023-09-16 13:52:32.516 
Epoch 316/1000 
	 loss: 2.3412, MinusLogProbMetric: 2.3412, val_loss: 2.4021, val_MinusLogProbMetric: 2.4021

Epoch 316: val_loss did not improve from 2.39873
196/196 - 62s - loss: 2.3412 - MinusLogProbMetric: 2.3412 - val_loss: 2.4021 - val_MinusLogProbMetric: 2.4021 - lr: 2.5000e-04 - 62s/epoch - 318ms/step
Epoch 317/1000
2023-09-16 13:53:34.519 
Epoch 317/1000 
	 loss: 2.3418, MinusLogProbMetric: 2.3418, val_loss: 2.4027, val_MinusLogProbMetric: 2.4027

Epoch 317: val_loss did not improve from 2.39873
196/196 - 62s - loss: 2.3418 - MinusLogProbMetric: 2.3418 - val_loss: 2.4027 - val_MinusLogProbMetric: 2.4027 - lr: 2.5000e-04 - 62s/epoch - 316ms/step
Epoch 318/1000
2023-09-16 13:54:35.276 
Epoch 318/1000 
	 loss: 2.3409, MinusLogProbMetric: 2.3409, val_loss: 2.4067, val_MinusLogProbMetric: 2.4067

Epoch 318: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3409 - MinusLogProbMetric: 2.3409 - val_loss: 2.4067 - val_MinusLogProbMetric: 2.4067 - lr: 2.5000e-04 - 61s/epoch - 310ms/step
Epoch 319/1000
2023-09-16 13:55:36.237 
Epoch 319/1000 
	 loss: 2.3424, MinusLogProbMetric: 2.3424, val_loss: 2.4002, val_MinusLogProbMetric: 2.4002

Epoch 319: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3424 - MinusLogProbMetric: 2.3424 - val_loss: 2.4002 - val_MinusLogProbMetric: 2.4002 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 320/1000
2023-09-16 13:56:36.794 
Epoch 320/1000 
	 loss: 2.3403, MinusLogProbMetric: 2.3403, val_loss: 2.4017, val_MinusLogProbMetric: 2.4017

Epoch 320: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3403 - MinusLogProbMetric: 2.3403 - val_loss: 2.4017 - val_MinusLogProbMetric: 2.4017 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 321/1000
2023-09-16 13:57:38.852 
Epoch 321/1000 
	 loss: 2.3428, MinusLogProbMetric: 2.3428, val_loss: 2.3998, val_MinusLogProbMetric: 2.3998

Epoch 321: val_loss did not improve from 2.39873
196/196 - 62s - loss: 2.3428 - MinusLogProbMetric: 2.3428 - val_loss: 2.3998 - val_MinusLogProbMetric: 2.3998 - lr: 2.5000e-04 - 62s/epoch - 317ms/step
Epoch 322/1000
2023-09-16 13:58:38.649 
Epoch 322/1000 
	 loss: 2.3422, MinusLogProbMetric: 2.3422, val_loss: 2.4030, val_MinusLogProbMetric: 2.4030

Epoch 322: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3422 - MinusLogProbMetric: 2.3422 - val_loss: 2.4030 - val_MinusLogProbMetric: 2.4030 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 323/1000
2023-09-16 13:59:39.615 
Epoch 323/1000 
	 loss: 2.3406, MinusLogProbMetric: 2.3406, val_loss: 2.4011, val_MinusLogProbMetric: 2.4011

Epoch 323: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3406 - MinusLogProbMetric: 2.3406 - val_loss: 2.4011 - val_MinusLogProbMetric: 2.4011 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 324/1000
2023-09-16 14:00:40.412 
Epoch 324/1000 
	 loss: 2.3422, MinusLogProbMetric: 2.3422, val_loss: 2.4013, val_MinusLogProbMetric: 2.4013

Epoch 324: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3422 - MinusLogProbMetric: 2.3422 - val_loss: 2.4013 - val_MinusLogProbMetric: 2.4013 - lr: 2.5000e-04 - 61s/epoch - 310ms/step
Epoch 325/1000
2023-09-16 14:01:41.499 
Epoch 325/1000 
	 loss: 2.3418, MinusLogProbMetric: 2.3418, val_loss: 2.4032, val_MinusLogProbMetric: 2.4032

Epoch 325: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3418 - MinusLogProbMetric: 2.3418 - val_loss: 2.4032 - val_MinusLogProbMetric: 2.4032 - lr: 2.5000e-04 - 61s/epoch - 312ms/step
Epoch 326/1000
2023-09-16 14:02:41.839 
Epoch 326/1000 
	 loss: 2.3400, MinusLogProbMetric: 2.3400, val_loss: 2.4169, val_MinusLogProbMetric: 2.4169

Epoch 326: val_loss did not improve from 2.39873
196/196 - 60s - loss: 2.3400 - MinusLogProbMetric: 2.3400 - val_loss: 2.4169 - val_MinusLogProbMetric: 2.4169 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 327/1000
2023-09-16 14:03:42.362 
Epoch 327/1000 
	 loss: 2.3420, MinusLogProbMetric: 2.3420, val_loss: 2.4008, val_MinusLogProbMetric: 2.4008

Epoch 327: val_loss did not improve from 2.39873
196/196 - 61s - loss: 2.3420 - MinusLogProbMetric: 2.3420 - val_loss: 2.4008 - val_MinusLogProbMetric: 2.4008 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 328/1000
2023-09-16 14:04:36.656 
Epoch 328/1000 
	 loss: 2.3424, MinusLogProbMetric: 2.3424, val_loss: 2.4030, val_MinusLogProbMetric: 2.4030

Epoch 328: val_loss did not improve from 2.39873
Restoring model weights from the end of the best epoch: 228.
196/196 - 55s - loss: 2.3424 - MinusLogProbMetric: 2.3424 - val_loss: 2.4030 - val_MinusLogProbMetric: 2.4030 - lr: 2.5000e-04 - 55s/epoch - 280ms/step
Epoch 328: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 19.216178961796686 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 13.352222668007016 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 5.655280004022643 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7faf8c4e0ee0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 24.47006044909358 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 7.864101375918835 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 7.2112789480015635 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fafeaeb6a70> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 926.
Model trained in 20082.37 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

Plots done in 2.41 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 100.14 s.
===========
Run 69/720 done in 20192.20 s.
===========

Directory ../../results/CsplineN_new/run_70/ already exists.
Skipping it.
===========
Run 70/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_71/ already exists.
Skipping it.
===========
Run 71/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_72/ already exists.
Skipping it.
===========
Run 72/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_73/ already exists.
Skipping it.
===========
Run 73/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_74/ already exists.
Skipping it.
===========
Run 74/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_75/ already exists.
Skipping it.
===========
Run 75/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_76/ already exists.
Skipping it.
===========
Run 76/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_77/ already exists.
Skipping it.
===========
Run 77/720 already exists. Skipping it.
===========

===========
Generating train data for run 78.
===========
Train data generated in 0.12 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 4)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_78/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 933}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_78/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[4.240899 , 6.2453055, 4.0978756, 7.8219056],
       [4.2243705, 6.0521903, 3.7794876, 8.870851 ],
       [4.247851 , 8.277347 , 4.718091 , 8.781199 ],
       ...,
       [4.228189 , 7.2775874, 4.130633 , 7.536749 ],
       [4.2335677, 6.441522 , 3.5377116, 8.565796 ],
       [9.439851 , 3.85006  , 8.399076 , 4.676129 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_78/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_78
self.data_kwargs: {'seed': 933}
self.x_data: [[ 4.2380886  8.209582   4.989638   7.670489 ]
 [ 5.1177273  9.509857   5.910046   5.419195 ]
 [ 9.293757   4.781643   8.46373    5.3345113]
 ...
 [ 4.256047   5.6400986  4.6473556 10.257152 ]
 [ 4.226376   6.687247   5.7610765  8.807774 ]
 [ 4.2561584  6.960633   4.133372   8.783352 ]]
self.y_data: []
self.ndims: 4
Model defined.
Model: "model_54"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_55 (InputLayer)       [(None, 4)]               0         
                                                                 
 log_prob_layer_4 (LogProbLa  (None,)                  1441740   
 yer)                                                            
                                                                 
=================================================================
Total params: 1,441,740
Trainable params: 1,441,740
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_4/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_4'")
self.model: <keras.engine.functional.Functional object at 0x7fb7166c0ca0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fb148621210>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fb148621210>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fb124146d10>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fb0f42649a0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fb0f4264f10>, <keras.callbacks.ModelCheckpoint object at 0x7fb0f4264fd0>, <keras.callbacks.EarlyStopping object at 0x7fb0f4265240>, <keras.callbacks.ReduceLROnPlateau object at 0x7fb0f4265270>, <keras.callbacks.TerminateOnNaN object at 0x7fb0f4264eb0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[4.240899 , 6.2453055, 4.0978756, 7.8219056],
       [4.2243705, 6.0521903, 3.7794876, 8.870851 ],
       [4.247851 , 8.277347 , 4.718091 , 8.781199 ],
       ...,
       [4.228189 , 7.2775874, 4.130633 , 7.536749 ],
       [4.2335677, 6.441522 , 3.5377116, 8.565796 ],
       [9.439851 , 3.85006  , 8.399076 , 4.676129 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_78/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 78/720 with hyperparameters:
timestamp = 2023-09-16 14:06:26.199760
ndims = 4
seed_train = 933
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 8
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 1441740
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [4.2380886 8.209582  4.989638  7.670489 ]
Epoch 1/1000
2023-09-16 14:09:33.797 
Epoch 1/1000 
	 loss: 6.8630, MinusLogProbMetric: 6.8630, val_loss: 4.0466, val_MinusLogProbMetric: 4.0466

Epoch 1: val_loss improved from inf to 4.04657, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 188s - loss: 6.8630 - MinusLogProbMetric: 6.8630 - val_loss: 4.0466 - val_MinusLogProbMetric: 4.0466 - lr: 0.0010 - 188s/epoch - 960ms/step
Epoch 2/1000
2023-09-16 14:10:31.442 
Epoch 2/1000 
	 loss: 4.0886, MinusLogProbMetric: 4.0886, val_loss: 3.5917, val_MinusLogProbMetric: 3.5917

Epoch 2: val_loss improved from 4.04657 to 3.59172, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 58s - loss: 4.0886 - MinusLogProbMetric: 4.0886 - val_loss: 3.5917 - val_MinusLogProbMetric: 3.5917 - lr: 0.0010 - 58s/epoch - 294ms/step
Epoch 3/1000
2023-09-16 14:11:35.766 
Epoch 3/1000 
	 loss: 3.5278, MinusLogProbMetric: 3.5278, val_loss: 3.3453, val_MinusLogProbMetric: 3.3453

Epoch 3: val_loss improved from 3.59172 to 3.34530, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 64s - loss: 3.5278 - MinusLogProbMetric: 3.5278 - val_loss: 3.3453 - val_MinusLogProbMetric: 3.3453 - lr: 0.0010 - 64s/epoch - 327ms/step
Epoch 4/1000
2023-09-16 14:12:39.455 
Epoch 4/1000 
	 loss: 3.2590, MinusLogProbMetric: 3.2590, val_loss: 3.1383, val_MinusLogProbMetric: 3.1383

Epoch 4: val_loss improved from 3.34530 to 3.13827, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 64s - loss: 3.2590 - MinusLogProbMetric: 3.2590 - val_loss: 3.1383 - val_MinusLogProbMetric: 3.1383 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 5/1000
2023-09-16 14:13:47.760 
Epoch 5/1000 
	 loss: 3.0559, MinusLogProbMetric: 3.0559, val_loss: 2.7393, val_MinusLogProbMetric: 2.7393

Epoch 5: val_loss improved from 3.13827 to 2.73931, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 68s - loss: 3.0559 - MinusLogProbMetric: 3.0559 - val_loss: 2.7393 - val_MinusLogProbMetric: 2.7393 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 6/1000
2023-09-16 14:14:57.837 
Epoch 6/1000 
	 loss: 2.9490, MinusLogProbMetric: 2.9490, val_loss: 2.7728, val_MinusLogProbMetric: 2.7728

Epoch 6: val_loss did not improve from 2.73931
196/196 - 69s - loss: 2.9490 - MinusLogProbMetric: 2.9490 - val_loss: 2.7728 - val_MinusLogProbMetric: 2.7728 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 7/1000
2023-09-16 14:16:03.707 
Epoch 7/1000 
	 loss: 2.7737, MinusLogProbMetric: 2.7737, val_loss: 2.9265, val_MinusLogProbMetric: 2.9265

Epoch 7: val_loss did not improve from 2.73931
196/196 - 66s - loss: 2.7737 - MinusLogProbMetric: 2.7737 - val_loss: 2.9265 - val_MinusLogProbMetric: 2.9265 - lr: 0.0010 - 66s/epoch - 336ms/step
Epoch 8/1000
2023-09-16 14:17:10.816 
Epoch 8/1000 
	 loss: 2.7700, MinusLogProbMetric: 2.7700, val_loss: 2.6513, val_MinusLogProbMetric: 2.6513

Epoch 8: val_loss improved from 2.73931 to 2.65128, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 68s - loss: 2.7700 - MinusLogProbMetric: 2.7700 - val_loss: 2.6513 - val_MinusLogProbMetric: 2.6513 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 9/1000
2023-09-16 14:18:18.105 
Epoch 9/1000 
	 loss: 2.6930, MinusLogProbMetric: 2.6930, val_loss: 2.5015, val_MinusLogProbMetric: 2.5015

Epoch 9: val_loss improved from 2.65128 to 2.50151, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 67s - loss: 2.6930 - MinusLogProbMetric: 2.6930 - val_loss: 2.5015 - val_MinusLogProbMetric: 2.5015 - lr: 0.0010 - 67s/epoch - 342ms/step
Epoch 10/1000
2023-09-16 14:19:24.272 
Epoch 10/1000 
	 loss: 2.6159, MinusLogProbMetric: 2.6159, val_loss: 2.4955, val_MinusLogProbMetric: 2.4955

Epoch 10: val_loss improved from 2.50151 to 2.49555, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 66s - loss: 2.6159 - MinusLogProbMetric: 2.6159 - val_loss: 2.4955 - val_MinusLogProbMetric: 2.4955 - lr: 0.0010 - 66s/epoch - 338ms/step
Epoch 11/1000
2023-09-16 14:20:30.867 
Epoch 11/1000 
	 loss: 2.5428, MinusLogProbMetric: 2.5428, val_loss: 2.4630, val_MinusLogProbMetric: 2.4630

Epoch 11: val_loss improved from 2.49555 to 2.46298, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 67s - loss: 2.5428 - MinusLogProbMetric: 2.5428 - val_loss: 2.4630 - val_MinusLogProbMetric: 2.4630 - lr: 0.0010 - 67s/epoch - 340ms/step
Epoch 12/1000
2023-09-16 14:21:34.921 
Epoch 12/1000 
	 loss: 2.5478, MinusLogProbMetric: 2.5478, val_loss: 2.8151, val_MinusLogProbMetric: 2.8151

Epoch 12: val_loss did not improve from 2.46298
196/196 - 63s - loss: 2.5478 - MinusLogProbMetric: 2.5478 - val_loss: 2.8151 - val_MinusLogProbMetric: 2.8151 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 13/1000
2023-09-16 14:22:37.606 
Epoch 13/1000 
	 loss: 2.5703, MinusLogProbMetric: 2.5703, val_loss: 2.6007, val_MinusLogProbMetric: 2.6007

Epoch 13: val_loss did not improve from 2.46298
196/196 - 63s - loss: 2.5703 - MinusLogProbMetric: 2.5703 - val_loss: 2.6007 - val_MinusLogProbMetric: 2.6007 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 14/1000
2023-09-16 14:23:41.179 
Epoch 14/1000 
	 loss: 2.5672, MinusLogProbMetric: 2.5672, val_loss: 2.6835, val_MinusLogProbMetric: 2.6835

Epoch 14: val_loss did not improve from 2.46298
196/196 - 64s - loss: 2.5672 - MinusLogProbMetric: 2.5672 - val_loss: 2.6835 - val_MinusLogProbMetric: 2.6835 - lr: 0.0010 - 64s/epoch - 324ms/step
Epoch 15/1000
2023-09-16 14:24:45.142 
Epoch 15/1000 
	 loss: 2.5180, MinusLogProbMetric: 2.5180, val_loss: 2.6420, val_MinusLogProbMetric: 2.6420

Epoch 15: val_loss did not improve from 2.46298
196/196 - 64s - loss: 2.5180 - MinusLogProbMetric: 2.5180 - val_loss: 2.6420 - val_MinusLogProbMetric: 2.6420 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 16/1000
2023-09-16 14:25:48.831 
Epoch 16/1000 
	 loss: 2.4863, MinusLogProbMetric: 2.4863, val_loss: 2.4506, val_MinusLogProbMetric: 2.4506

Epoch 16: val_loss improved from 2.46298 to 2.45061, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 65s - loss: 2.4863 - MinusLogProbMetric: 2.4863 - val_loss: 2.4506 - val_MinusLogProbMetric: 2.4506 - lr: 0.0010 - 65s/epoch - 330ms/step
Epoch 17/1000
2023-09-16 14:26:54.330 
Epoch 17/1000 
	 loss: 2.4818, MinusLogProbMetric: 2.4818, val_loss: 2.5788, val_MinusLogProbMetric: 2.5788

Epoch 17: val_loss did not improve from 2.45061
196/196 - 65s - loss: 2.4818 - MinusLogProbMetric: 2.4818 - val_loss: 2.5788 - val_MinusLogProbMetric: 2.5788 - lr: 0.0010 - 65s/epoch - 329ms/step
Epoch 18/1000
2023-09-16 14:27:59.884 
Epoch 18/1000 
	 loss: 2.4782, MinusLogProbMetric: 2.4782, val_loss: 2.5714, val_MinusLogProbMetric: 2.5714

Epoch 18: val_loss did not improve from 2.45061
196/196 - 66s - loss: 2.4782 - MinusLogProbMetric: 2.4782 - val_loss: 2.5714 - val_MinusLogProbMetric: 2.5714 - lr: 0.0010 - 66s/epoch - 334ms/step
Epoch 19/1000
2023-09-16 14:29:04.437 
Epoch 19/1000 
	 loss: 2.4741, MinusLogProbMetric: 2.4741, val_loss: 2.5835, val_MinusLogProbMetric: 2.5835

Epoch 19: val_loss did not improve from 2.45061
196/196 - 65s - loss: 2.4741 - MinusLogProbMetric: 2.4741 - val_loss: 2.5835 - val_MinusLogProbMetric: 2.5835 - lr: 0.0010 - 65s/epoch - 329ms/step
Epoch 20/1000
2023-09-16 14:30:09.454 
Epoch 20/1000 
	 loss: 2.4762, MinusLogProbMetric: 2.4762, val_loss: 2.5005, val_MinusLogProbMetric: 2.5005

Epoch 20: val_loss did not improve from 2.45061
196/196 - 65s - loss: 2.4762 - MinusLogProbMetric: 2.4762 - val_loss: 2.5005 - val_MinusLogProbMetric: 2.5005 - lr: 0.0010 - 65s/epoch - 332ms/step
Epoch 21/1000
2023-09-16 14:31:14.938 
Epoch 21/1000 
	 loss: 2.4562, MinusLogProbMetric: 2.4562, val_loss: 2.5025, val_MinusLogProbMetric: 2.5025

Epoch 21: val_loss did not improve from 2.45061
196/196 - 65s - loss: 2.4562 - MinusLogProbMetric: 2.4562 - val_loss: 2.5025 - val_MinusLogProbMetric: 2.5025 - lr: 0.0010 - 65s/epoch - 334ms/step
Epoch 22/1000
2023-09-16 14:32:20.406 
Epoch 22/1000 
	 loss: 2.4595, MinusLogProbMetric: 2.4595, val_loss: 2.5803, val_MinusLogProbMetric: 2.5803

Epoch 22: val_loss did not improve from 2.45061
196/196 - 65s - loss: 2.4595 - MinusLogProbMetric: 2.4595 - val_loss: 2.5803 - val_MinusLogProbMetric: 2.5803 - lr: 0.0010 - 65s/epoch - 334ms/step
Epoch 23/1000
2023-09-16 14:33:24.457 
Epoch 23/1000 
	 loss: 2.4447, MinusLogProbMetric: 2.4447, val_loss: 2.4780, val_MinusLogProbMetric: 2.4780

Epoch 23: val_loss did not improve from 2.45061
196/196 - 64s - loss: 2.4447 - MinusLogProbMetric: 2.4447 - val_loss: 2.4780 - val_MinusLogProbMetric: 2.4780 - lr: 0.0010 - 64s/epoch - 327ms/step
Epoch 24/1000
2023-09-16 14:34:29.081 
Epoch 24/1000 
	 loss: 2.4503, MinusLogProbMetric: 2.4503, val_loss: 2.4408, val_MinusLogProbMetric: 2.4408

Epoch 24: val_loss improved from 2.45061 to 2.44076, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 66s - loss: 2.4503 - MinusLogProbMetric: 2.4503 - val_loss: 2.4408 - val_MinusLogProbMetric: 2.4408 - lr: 0.0010 - 66s/epoch - 334ms/step
Epoch 25/1000
2023-09-16 14:35:38.027 
Epoch 25/1000 
	 loss: 2.4375, MinusLogProbMetric: 2.4375, val_loss: 2.4739, val_MinusLogProbMetric: 2.4739

Epoch 25: val_loss did not improve from 2.44076
196/196 - 68s - loss: 2.4375 - MinusLogProbMetric: 2.4375 - val_loss: 2.4739 - val_MinusLogProbMetric: 2.4739 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 26/1000
2023-09-16 14:36:44.283 
Epoch 26/1000 
	 loss: 2.4443, MinusLogProbMetric: 2.4443, val_loss: 2.4451, val_MinusLogProbMetric: 2.4451

Epoch 26: val_loss did not improve from 2.44076
196/196 - 66s - loss: 2.4443 - MinusLogProbMetric: 2.4443 - val_loss: 2.4451 - val_MinusLogProbMetric: 2.4451 - lr: 0.0010 - 66s/epoch - 338ms/step
Epoch 27/1000
2023-09-16 14:37:50.786 
Epoch 27/1000 
	 loss: 2.4459, MinusLogProbMetric: 2.4459, val_loss: 2.5392, val_MinusLogProbMetric: 2.5392

Epoch 27: val_loss did not improve from 2.44076
196/196 - 66s - loss: 2.4459 - MinusLogProbMetric: 2.4459 - val_loss: 2.5392 - val_MinusLogProbMetric: 2.5392 - lr: 0.0010 - 66s/epoch - 339ms/step
Epoch 28/1000
2023-09-16 14:38:57.309 
Epoch 28/1000 
	 loss: 2.4250, MinusLogProbMetric: 2.4250, val_loss: 2.4605, val_MinusLogProbMetric: 2.4605

Epoch 28: val_loss did not improve from 2.44076
196/196 - 67s - loss: 2.4250 - MinusLogProbMetric: 2.4250 - val_loss: 2.4605 - val_MinusLogProbMetric: 2.4605 - lr: 0.0010 - 67s/epoch - 339ms/step
Epoch 29/1000
2023-09-16 14:40:03.803 
Epoch 29/1000 
	 loss: 2.4283, MinusLogProbMetric: 2.4283, val_loss: 2.4648, val_MinusLogProbMetric: 2.4648

Epoch 29: val_loss did not improve from 2.44076
196/196 - 66s - loss: 2.4283 - MinusLogProbMetric: 2.4283 - val_loss: 2.4648 - val_MinusLogProbMetric: 2.4648 - lr: 0.0010 - 66s/epoch - 339ms/step
Epoch 30/1000
2023-09-16 14:41:11.005 
Epoch 30/1000 
	 loss: 2.4323, MinusLogProbMetric: 2.4323, val_loss: 2.4578, val_MinusLogProbMetric: 2.4578

Epoch 30: val_loss did not improve from 2.44076
196/196 - 67s - loss: 2.4323 - MinusLogProbMetric: 2.4323 - val_loss: 2.4578 - val_MinusLogProbMetric: 2.4578 - lr: 0.0010 - 67s/epoch - 343ms/step
Epoch 31/1000
2023-09-16 14:42:16.782 
Epoch 31/1000 
	 loss: 2.4446, MinusLogProbMetric: 2.4446, val_loss: 2.4692, val_MinusLogProbMetric: 2.4692

Epoch 31: val_loss did not improve from 2.44076
196/196 - 66s - loss: 2.4446 - MinusLogProbMetric: 2.4446 - val_loss: 2.4692 - val_MinusLogProbMetric: 2.4692 - lr: 0.0010 - 66s/epoch - 336ms/step
Epoch 32/1000
2023-09-16 14:43:21.307 
Epoch 32/1000 
	 loss: 2.4303, MinusLogProbMetric: 2.4303, val_loss: 2.6301, val_MinusLogProbMetric: 2.6301

Epoch 32: val_loss did not improve from 2.44076
196/196 - 65s - loss: 2.4303 - MinusLogProbMetric: 2.4303 - val_loss: 2.6301 - val_MinusLogProbMetric: 2.6301 - lr: 0.0010 - 65s/epoch - 329ms/step
Epoch 33/1000
2023-09-16 14:44:25.001 
Epoch 33/1000 
	 loss: 2.4212, MinusLogProbMetric: 2.4212, val_loss: 2.4299, val_MinusLogProbMetric: 2.4299

Epoch 33: val_loss improved from 2.44076 to 2.42994, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 65s - loss: 2.4212 - MinusLogProbMetric: 2.4212 - val_loss: 2.4299 - val_MinusLogProbMetric: 2.4299 - lr: 0.0010 - 65s/epoch - 330ms/step
Epoch 34/1000
2023-09-16 14:45:31.338 
Epoch 34/1000 
	 loss: 2.4293, MinusLogProbMetric: 2.4293, val_loss: 2.5496, val_MinusLogProbMetric: 2.5496

Epoch 34: val_loss did not improve from 2.42994
196/196 - 65s - loss: 2.4293 - MinusLogProbMetric: 2.4293 - val_loss: 2.5496 - val_MinusLogProbMetric: 2.5496 - lr: 0.0010 - 65s/epoch - 333ms/step
Epoch 35/1000
2023-09-16 14:46:36.531 
Epoch 35/1000 
	 loss: 2.4254, MinusLogProbMetric: 2.4254, val_loss: 2.4243, val_MinusLogProbMetric: 2.4243

Epoch 35: val_loss improved from 2.42994 to 2.42428, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 66s - loss: 2.4254 - MinusLogProbMetric: 2.4254 - val_loss: 2.4243 - val_MinusLogProbMetric: 2.4243 - lr: 0.0010 - 66s/epoch - 338ms/step
Epoch 36/1000
2023-09-16 14:47:42.544 
Epoch 36/1000 
	 loss: 2.4300, MinusLogProbMetric: 2.4300, val_loss: 2.4211, val_MinusLogProbMetric: 2.4211

Epoch 36: val_loss improved from 2.42428 to 2.42108, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 66s - loss: 2.4300 - MinusLogProbMetric: 2.4300 - val_loss: 2.4211 - val_MinusLogProbMetric: 2.4211 - lr: 0.0010 - 66s/epoch - 336ms/step
Epoch 37/1000
2023-09-16 14:48:49.388 
Epoch 37/1000 
	 loss: 2.4180, MinusLogProbMetric: 2.4180, val_loss: 2.4811, val_MinusLogProbMetric: 2.4811

Epoch 37: val_loss did not improve from 2.42108
196/196 - 66s - loss: 2.4180 - MinusLogProbMetric: 2.4180 - val_loss: 2.4811 - val_MinusLogProbMetric: 2.4811 - lr: 0.0010 - 66s/epoch - 336ms/step
Epoch 38/1000
2023-09-16 14:49:53.813 
Epoch 38/1000 
	 loss: 2.4138, MinusLogProbMetric: 2.4138, val_loss: 2.5447, val_MinusLogProbMetric: 2.5447

Epoch 38: val_loss did not improve from 2.42108
196/196 - 64s - loss: 2.4138 - MinusLogProbMetric: 2.4138 - val_loss: 2.5447 - val_MinusLogProbMetric: 2.5447 - lr: 0.0010 - 64s/epoch - 329ms/step
Epoch 39/1000
2023-09-16 14:51:00.412 
Epoch 39/1000 
	 loss: 2.4141, MinusLogProbMetric: 2.4141, val_loss: 2.4197, val_MinusLogProbMetric: 2.4197

Epoch 39: val_loss improved from 2.42108 to 2.41973, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 68s - loss: 2.4141 - MinusLogProbMetric: 2.4141 - val_loss: 2.4197 - val_MinusLogProbMetric: 2.4197 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 40/1000
2023-09-16 14:52:08.160 
Epoch 40/1000 
	 loss: 2.4196, MinusLogProbMetric: 2.4196, val_loss: 2.4809, val_MinusLogProbMetric: 2.4809

Epoch 40: val_loss did not improve from 2.41973
196/196 - 67s - loss: 2.4196 - MinusLogProbMetric: 2.4196 - val_loss: 2.4809 - val_MinusLogProbMetric: 2.4809 - lr: 0.0010 - 67s/epoch - 340ms/step
Epoch 41/1000
2023-09-16 14:53:12.601 
Epoch 41/1000 
	 loss: 2.4118, MinusLogProbMetric: 2.4118, val_loss: 2.4414, val_MinusLogProbMetric: 2.4414

Epoch 41: val_loss did not improve from 2.41973
196/196 - 64s - loss: 2.4118 - MinusLogProbMetric: 2.4118 - val_loss: 2.4414 - val_MinusLogProbMetric: 2.4414 - lr: 0.0010 - 64s/epoch - 329ms/step
Epoch 42/1000
2023-09-16 14:54:16.754 
Epoch 42/1000 
	 loss: 2.4000, MinusLogProbMetric: 2.4000, val_loss: 2.4358, val_MinusLogProbMetric: 2.4358

Epoch 42: val_loss did not improve from 2.41973
196/196 - 64s - loss: 2.4000 - MinusLogProbMetric: 2.4000 - val_loss: 2.4358 - val_MinusLogProbMetric: 2.4358 - lr: 0.0010 - 64s/epoch - 327ms/step
Epoch 43/1000
2023-09-16 14:55:18.001 
Epoch 43/1000 
	 loss: 2.4155, MinusLogProbMetric: 2.4155, val_loss: 2.4679, val_MinusLogProbMetric: 2.4679

Epoch 43: val_loss did not improve from 2.41973
196/196 - 61s - loss: 2.4155 - MinusLogProbMetric: 2.4155 - val_loss: 2.4679 - val_MinusLogProbMetric: 2.4679 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 44/1000
2023-09-16 14:56:13.294 
Epoch 44/1000 
	 loss: 2.4103, MinusLogProbMetric: 2.4103, val_loss: 2.4598, val_MinusLogProbMetric: 2.4598

Epoch 44: val_loss did not improve from 2.41973
196/196 - 55s - loss: 2.4103 - MinusLogProbMetric: 2.4103 - val_loss: 2.4598 - val_MinusLogProbMetric: 2.4598 - lr: 0.0010 - 55s/epoch - 282ms/step
Epoch 45/1000
2023-09-16 14:57:12.216 
Epoch 45/1000 
	 loss: 2.4098, MinusLogProbMetric: 2.4098, val_loss: 2.4342, val_MinusLogProbMetric: 2.4342

Epoch 45: val_loss did not improve from 2.41973
196/196 - 59s - loss: 2.4098 - MinusLogProbMetric: 2.4098 - val_loss: 2.4342 - val_MinusLogProbMetric: 2.4342 - lr: 0.0010 - 59s/epoch - 301ms/step
Epoch 46/1000
2023-09-16 14:58:17.187 
Epoch 46/1000 
	 loss: 2.4101, MinusLogProbMetric: 2.4101, val_loss: 2.4402, val_MinusLogProbMetric: 2.4402

Epoch 46: val_loss did not improve from 2.41973
196/196 - 65s - loss: 2.4101 - MinusLogProbMetric: 2.4101 - val_loss: 2.4402 - val_MinusLogProbMetric: 2.4402 - lr: 0.0010 - 65s/epoch - 331ms/step
Epoch 47/1000
2023-09-16 14:59:19.835 
Epoch 47/1000 
	 loss: 2.4222, MinusLogProbMetric: 2.4222, val_loss: 2.4694, val_MinusLogProbMetric: 2.4694

Epoch 47: val_loss did not improve from 2.41973
196/196 - 63s - loss: 2.4222 - MinusLogProbMetric: 2.4222 - val_loss: 2.4694 - val_MinusLogProbMetric: 2.4694 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 48/1000
2023-09-16 15:00:24.065 
Epoch 48/1000 
	 loss: 2.4151, MinusLogProbMetric: 2.4151, val_loss: 2.4319, val_MinusLogProbMetric: 2.4319

Epoch 48: val_loss did not improve from 2.41973
196/196 - 64s - loss: 2.4151 - MinusLogProbMetric: 2.4151 - val_loss: 2.4319 - val_MinusLogProbMetric: 2.4319 - lr: 0.0010 - 64s/epoch - 328ms/step
Epoch 49/1000
2023-09-16 15:01:27.891 
Epoch 49/1000 
	 loss: 2.4015, MinusLogProbMetric: 2.4015, val_loss: 2.4779, val_MinusLogProbMetric: 2.4779

Epoch 49: val_loss did not improve from 2.41973
196/196 - 64s - loss: 2.4015 - MinusLogProbMetric: 2.4015 - val_loss: 2.4779 - val_MinusLogProbMetric: 2.4779 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 50/1000
2023-09-16 15:02:32.833 
Epoch 50/1000 
	 loss: 2.4004, MinusLogProbMetric: 2.4004, val_loss: 2.4464, val_MinusLogProbMetric: 2.4464

Epoch 50: val_loss did not improve from 2.41973
196/196 - 65s - loss: 2.4004 - MinusLogProbMetric: 2.4004 - val_loss: 2.4464 - val_MinusLogProbMetric: 2.4464 - lr: 0.0010 - 65s/epoch - 331ms/step
Epoch 51/1000
2023-09-16 15:03:36.399 
Epoch 51/1000 
	 loss: 2.4066, MinusLogProbMetric: 2.4066, val_loss: 2.4492, val_MinusLogProbMetric: 2.4492

Epoch 51: val_loss did not improve from 2.41973
196/196 - 64s - loss: 2.4066 - MinusLogProbMetric: 2.4066 - val_loss: 2.4492 - val_MinusLogProbMetric: 2.4492 - lr: 0.0010 - 64s/epoch - 324ms/step
Epoch 52/1000
2023-09-16 15:04:40.389 
Epoch 52/1000 
	 loss: 2.4058, MinusLogProbMetric: 2.4058, val_loss: 2.4659, val_MinusLogProbMetric: 2.4659

Epoch 52: val_loss did not improve from 2.41973
196/196 - 64s - loss: 2.4058 - MinusLogProbMetric: 2.4058 - val_loss: 2.4659 - val_MinusLogProbMetric: 2.4659 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 53/1000
2023-09-16 15:05:44.617 
Epoch 53/1000 
	 loss: 2.4100, MinusLogProbMetric: 2.4100, val_loss: 2.4427, val_MinusLogProbMetric: 2.4427

Epoch 53: val_loss did not improve from 2.41973
196/196 - 64s - loss: 2.4100 - MinusLogProbMetric: 2.4100 - val_loss: 2.4427 - val_MinusLogProbMetric: 2.4427 - lr: 0.0010 - 64s/epoch - 328ms/step
Epoch 54/1000
2023-09-16 15:06:46.710 
Epoch 54/1000 
	 loss: 2.4034, MinusLogProbMetric: 2.4034, val_loss: 2.4317, val_MinusLogProbMetric: 2.4317

Epoch 54: val_loss did not improve from 2.41973
196/196 - 62s - loss: 2.4034 - MinusLogProbMetric: 2.4034 - val_loss: 2.4317 - val_MinusLogProbMetric: 2.4317 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 55/1000
2023-09-16 15:07:47.630 
Epoch 55/1000 
	 loss: 2.3999, MinusLogProbMetric: 2.3999, val_loss: 2.4401, val_MinusLogProbMetric: 2.4401

Epoch 55: val_loss did not improve from 2.41973
196/196 - 61s - loss: 2.3999 - MinusLogProbMetric: 2.3999 - val_loss: 2.4401 - val_MinusLogProbMetric: 2.4401 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 56/1000
2023-09-16 15:08:52.591 
Epoch 56/1000 
	 loss: 2.3929, MinusLogProbMetric: 2.3929, val_loss: 2.4369, val_MinusLogProbMetric: 2.4369

Epoch 56: val_loss did not improve from 2.41973
196/196 - 65s - loss: 2.3929 - MinusLogProbMetric: 2.3929 - val_loss: 2.4369 - val_MinusLogProbMetric: 2.4369 - lr: 0.0010 - 65s/epoch - 331ms/step
Epoch 57/1000
2023-09-16 15:09:58.271 
Epoch 57/1000 
	 loss: 2.4134, MinusLogProbMetric: 2.4134, val_loss: 2.4482, val_MinusLogProbMetric: 2.4482

Epoch 57: val_loss did not improve from 2.41973
196/196 - 66s - loss: 2.4134 - MinusLogProbMetric: 2.4134 - val_loss: 2.4482 - val_MinusLogProbMetric: 2.4482 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 58/1000
2023-09-16 15:11:02.971 
Epoch 58/1000 
	 loss: 2.3962, MinusLogProbMetric: 2.3962, val_loss: 2.4284, val_MinusLogProbMetric: 2.4284

Epoch 58: val_loss did not improve from 2.41973
196/196 - 65s - loss: 2.3962 - MinusLogProbMetric: 2.3962 - val_loss: 2.4284 - val_MinusLogProbMetric: 2.4284 - lr: 0.0010 - 65s/epoch - 330ms/step
Epoch 59/1000
2023-09-16 15:12:03.558 
Epoch 59/1000 
	 loss: 2.4001, MinusLogProbMetric: 2.4001, val_loss: 2.4802, val_MinusLogProbMetric: 2.4802

Epoch 59: val_loss did not improve from 2.41973
196/196 - 61s - loss: 2.4001 - MinusLogProbMetric: 2.4001 - val_loss: 2.4802 - val_MinusLogProbMetric: 2.4802 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 60/1000
2023-09-16 15:13:00.445 
Epoch 60/1000 
	 loss: 2.4060, MinusLogProbMetric: 2.4060, val_loss: 2.4305, val_MinusLogProbMetric: 2.4305

Epoch 60: val_loss did not improve from 2.41973
196/196 - 57s - loss: 2.4060 - MinusLogProbMetric: 2.4060 - val_loss: 2.4305 - val_MinusLogProbMetric: 2.4305 - lr: 0.0010 - 57s/epoch - 290ms/step
Epoch 61/1000
2023-09-16 15:13:54.578 
Epoch 61/1000 
	 loss: 2.3947, MinusLogProbMetric: 2.3947, val_loss: 2.4953, val_MinusLogProbMetric: 2.4953

Epoch 61: val_loss did not improve from 2.41973
196/196 - 54s - loss: 2.3947 - MinusLogProbMetric: 2.3947 - val_loss: 2.4953 - val_MinusLogProbMetric: 2.4953 - lr: 0.0010 - 54s/epoch - 276ms/step
Epoch 62/1000
2023-09-16 15:14:57.715 
Epoch 62/1000 
	 loss: 2.4038, MinusLogProbMetric: 2.4038, val_loss: 2.4082, val_MinusLogProbMetric: 2.4082

Epoch 62: val_loss improved from 2.41973 to 2.40823, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 64s - loss: 2.4038 - MinusLogProbMetric: 2.4038 - val_loss: 2.4082 - val_MinusLogProbMetric: 2.4082 - lr: 0.0010 - 64s/epoch - 328ms/step
Epoch 63/1000
2023-09-16 15:16:04.176 
Epoch 63/1000 
	 loss: 2.3981, MinusLogProbMetric: 2.3981, val_loss: 2.4531, val_MinusLogProbMetric: 2.4531

Epoch 63: val_loss did not improve from 2.40823
196/196 - 65s - loss: 2.3981 - MinusLogProbMetric: 2.3981 - val_loss: 2.4531 - val_MinusLogProbMetric: 2.4531 - lr: 0.0010 - 65s/epoch - 334ms/step
Epoch 64/1000
2023-09-16 15:17:05.661 
Epoch 64/1000 
	 loss: 2.3908, MinusLogProbMetric: 2.3908, val_loss: 2.4285, val_MinusLogProbMetric: 2.4285

Epoch 64: val_loss did not improve from 2.40823
196/196 - 61s - loss: 2.3908 - MinusLogProbMetric: 2.3908 - val_loss: 2.4285 - val_MinusLogProbMetric: 2.4285 - lr: 0.0010 - 61s/epoch - 314ms/step
Epoch 65/1000
2023-09-16 15:18:12.684 
Epoch 65/1000 
	 loss: 2.3953, MinusLogProbMetric: 2.3953, val_loss: 2.4571, val_MinusLogProbMetric: 2.4571

Epoch 65: val_loss did not improve from 2.40823
196/196 - 67s - loss: 2.3953 - MinusLogProbMetric: 2.3953 - val_loss: 2.4571 - val_MinusLogProbMetric: 2.4571 - lr: 0.0010 - 67s/epoch - 342ms/step
Epoch 66/1000
2023-09-16 15:19:21.126 
Epoch 66/1000 
	 loss: 2.4014, MinusLogProbMetric: 2.4014, val_loss: 2.4211, val_MinusLogProbMetric: 2.4211

Epoch 66: val_loss did not improve from 2.40823
196/196 - 68s - loss: 2.4014 - MinusLogProbMetric: 2.4014 - val_loss: 2.4211 - val_MinusLogProbMetric: 2.4211 - lr: 0.0010 - 68s/epoch - 349ms/step
Epoch 67/1000
2023-09-16 15:20:30.590 
Epoch 67/1000 
	 loss: 2.4007, MinusLogProbMetric: 2.4007, val_loss: 2.4183, val_MinusLogProbMetric: 2.4183

Epoch 67: val_loss did not improve from 2.40823
196/196 - 69s - loss: 2.4007 - MinusLogProbMetric: 2.4007 - val_loss: 2.4183 - val_MinusLogProbMetric: 2.4183 - lr: 0.0010 - 69s/epoch - 354ms/step
Epoch 68/1000
2023-09-16 15:21:39.559 
Epoch 68/1000 
	 loss: 2.3970, MinusLogProbMetric: 2.3970, val_loss: 2.4136, val_MinusLogProbMetric: 2.4136

Epoch 68: val_loss did not improve from 2.40823
196/196 - 69s - loss: 2.3970 - MinusLogProbMetric: 2.3970 - val_loss: 2.4136 - val_MinusLogProbMetric: 2.4136 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 69/1000
2023-09-16 15:22:39.307 
Epoch 69/1000 
	 loss: 2.3926, MinusLogProbMetric: 2.3926, val_loss: 2.4551, val_MinusLogProbMetric: 2.4551

Epoch 69: val_loss did not improve from 2.40823
196/196 - 60s - loss: 2.3926 - MinusLogProbMetric: 2.3926 - val_loss: 2.4551 - val_MinusLogProbMetric: 2.4551 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 70/1000
2023-09-16 15:23:45.701 
Epoch 70/1000 
	 loss: 2.4073, MinusLogProbMetric: 2.4073, val_loss: 2.4455, val_MinusLogProbMetric: 2.4455

Epoch 70: val_loss did not improve from 2.40823
196/196 - 66s - loss: 2.4073 - MinusLogProbMetric: 2.4073 - val_loss: 2.4455 - val_MinusLogProbMetric: 2.4455 - lr: 0.0010 - 66s/epoch - 339ms/step
Epoch 71/1000
2023-09-16 15:24:50.393 
Epoch 71/1000 
	 loss: 2.3851, MinusLogProbMetric: 2.3851, val_loss: 2.4200, val_MinusLogProbMetric: 2.4200

Epoch 71: val_loss did not improve from 2.40823
196/196 - 65s - loss: 2.3851 - MinusLogProbMetric: 2.3851 - val_loss: 2.4200 - val_MinusLogProbMetric: 2.4200 - lr: 0.0010 - 65s/epoch - 330ms/step
Epoch 72/1000
2023-09-16 15:25:58.242 
Epoch 72/1000 
	 loss: 2.3887, MinusLogProbMetric: 2.3887, val_loss: 2.4738, val_MinusLogProbMetric: 2.4738

Epoch 72: val_loss did not improve from 2.40823
196/196 - 68s - loss: 2.3887 - MinusLogProbMetric: 2.3887 - val_loss: 2.4738 - val_MinusLogProbMetric: 2.4738 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 73/1000
2023-09-16 15:27:06.415 
Epoch 73/1000 
	 loss: 2.3961, MinusLogProbMetric: 2.3961, val_loss: 2.4516, val_MinusLogProbMetric: 2.4516

Epoch 73: val_loss did not improve from 2.40823
196/196 - 68s - loss: 2.3961 - MinusLogProbMetric: 2.3961 - val_loss: 2.4516 - val_MinusLogProbMetric: 2.4516 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 74/1000
2023-09-16 15:28:14.719 
Epoch 74/1000 
	 loss: 2.3991, MinusLogProbMetric: 2.3991, val_loss: 2.4343, val_MinusLogProbMetric: 2.4343

Epoch 74: val_loss did not improve from 2.40823
196/196 - 68s - loss: 2.3991 - MinusLogProbMetric: 2.3991 - val_loss: 2.4343 - val_MinusLogProbMetric: 2.4343 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 75/1000
2023-09-16 15:29:23.962 
Epoch 75/1000 
	 loss: 2.3915, MinusLogProbMetric: 2.3915, val_loss: 2.4206, val_MinusLogProbMetric: 2.4206

Epoch 75: val_loss did not improve from 2.40823
196/196 - 69s - loss: 2.3915 - MinusLogProbMetric: 2.3915 - val_loss: 2.4206 - val_MinusLogProbMetric: 2.4206 - lr: 0.0010 - 69s/epoch - 353ms/step
Epoch 76/1000
2023-09-16 15:30:34.069 
Epoch 76/1000 
	 loss: 2.3821, MinusLogProbMetric: 2.3821, val_loss: 2.4212, val_MinusLogProbMetric: 2.4212

Epoch 76: val_loss did not improve from 2.40823
196/196 - 70s - loss: 2.3821 - MinusLogProbMetric: 2.3821 - val_loss: 2.4212 - val_MinusLogProbMetric: 2.4212 - lr: 0.0010 - 70s/epoch - 358ms/step
Epoch 77/1000
2023-09-16 15:31:40.951 
Epoch 77/1000 
	 loss: 2.3949, MinusLogProbMetric: 2.3949, val_loss: 2.4058, val_MinusLogProbMetric: 2.4058

Epoch 77: val_loss improved from 2.40823 to 2.40579, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 68s - loss: 2.3949 - MinusLogProbMetric: 2.3949 - val_loss: 2.4058 - val_MinusLogProbMetric: 2.4058 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 78/1000
2023-09-16 15:32:47.910 
Epoch 78/1000 
	 loss: 2.3961, MinusLogProbMetric: 2.3961, val_loss: 2.4336, val_MinusLogProbMetric: 2.4336

Epoch 78: val_loss did not improve from 2.40579
196/196 - 66s - loss: 2.3961 - MinusLogProbMetric: 2.3961 - val_loss: 2.4336 - val_MinusLogProbMetric: 2.4336 - lr: 0.0010 - 66s/epoch - 336ms/step
Epoch 79/1000
2023-09-16 15:33:52.967 
Epoch 79/1000 
	 loss: 2.3881, MinusLogProbMetric: 2.3881, val_loss: 2.4128, val_MinusLogProbMetric: 2.4128

Epoch 79: val_loss did not improve from 2.40579
196/196 - 65s - loss: 2.3881 - MinusLogProbMetric: 2.3881 - val_loss: 2.4128 - val_MinusLogProbMetric: 2.4128 - lr: 0.0010 - 65s/epoch - 332ms/step
Epoch 80/1000
2023-09-16 15:34:58.657 
Epoch 80/1000 
	 loss: 2.3898, MinusLogProbMetric: 2.3898, val_loss: 2.4284, val_MinusLogProbMetric: 2.4284

Epoch 80: val_loss did not improve from 2.40579
196/196 - 66s - loss: 2.3898 - MinusLogProbMetric: 2.3898 - val_loss: 2.4284 - val_MinusLogProbMetric: 2.4284 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 81/1000
2023-09-16 15:36:03.416 
Epoch 81/1000 
	 loss: 2.3921, MinusLogProbMetric: 2.3921, val_loss: 2.4274, val_MinusLogProbMetric: 2.4274

Epoch 81: val_loss did not improve from 2.40579
196/196 - 65s - loss: 2.3921 - MinusLogProbMetric: 2.3921 - val_loss: 2.4274 - val_MinusLogProbMetric: 2.4274 - lr: 0.0010 - 65s/epoch - 330ms/step
Epoch 82/1000
2023-09-16 15:37:08.703 
Epoch 82/1000 
	 loss: 2.3857, MinusLogProbMetric: 2.3857, val_loss: 2.4919, val_MinusLogProbMetric: 2.4919

Epoch 82: val_loss did not improve from 2.40579
196/196 - 65s - loss: 2.3857 - MinusLogProbMetric: 2.3857 - val_loss: 2.4919 - val_MinusLogProbMetric: 2.4919 - lr: 0.0010 - 65s/epoch - 333ms/step
Epoch 83/1000
2023-09-16 15:38:14.809 
Epoch 83/1000 
	 loss: 2.3941, MinusLogProbMetric: 2.3941, val_loss: 2.4194, val_MinusLogProbMetric: 2.4194

Epoch 83: val_loss did not improve from 2.40579
196/196 - 66s - loss: 2.3941 - MinusLogProbMetric: 2.3941 - val_loss: 2.4194 - val_MinusLogProbMetric: 2.4194 - lr: 0.0010 - 66s/epoch - 337ms/step
Epoch 84/1000
2023-09-16 15:39:19.323 
Epoch 84/1000 
	 loss: 2.3822, MinusLogProbMetric: 2.3822, val_loss: 2.4110, val_MinusLogProbMetric: 2.4110

Epoch 84: val_loss did not improve from 2.40579
196/196 - 65s - loss: 2.3822 - MinusLogProbMetric: 2.3822 - val_loss: 2.4110 - val_MinusLogProbMetric: 2.4110 - lr: 0.0010 - 65s/epoch - 329ms/step
Epoch 85/1000
2023-09-16 15:40:24.883 
Epoch 85/1000 
	 loss: 2.3898, MinusLogProbMetric: 2.3898, val_loss: 2.4309, val_MinusLogProbMetric: 2.4309

Epoch 85: val_loss did not improve from 2.40579
196/196 - 66s - loss: 2.3898 - MinusLogProbMetric: 2.3898 - val_loss: 2.4309 - val_MinusLogProbMetric: 2.4309 - lr: 0.0010 - 66s/epoch - 334ms/step
Epoch 86/1000
2023-09-16 15:41:30.170 
Epoch 86/1000 
	 loss: 2.3734, MinusLogProbMetric: 2.3734, val_loss: 2.4210, val_MinusLogProbMetric: 2.4210

Epoch 86: val_loss did not improve from 2.40579
196/196 - 65s - loss: 2.3734 - MinusLogProbMetric: 2.3734 - val_loss: 2.4210 - val_MinusLogProbMetric: 2.4210 - lr: 0.0010 - 65s/epoch - 333ms/step
Epoch 87/1000
2023-09-16 15:42:35.092 
Epoch 87/1000 
	 loss: 2.3794, MinusLogProbMetric: 2.3794, val_loss: 2.4039, val_MinusLogProbMetric: 2.4039

Epoch 87: val_loss improved from 2.40579 to 2.40393, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 66s - loss: 2.3794 - MinusLogProbMetric: 2.3794 - val_loss: 2.4039 - val_MinusLogProbMetric: 2.4039 - lr: 0.0010 - 66s/epoch - 337ms/step
Epoch 88/1000
2023-09-16 15:43:40.626 
Epoch 88/1000 
	 loss: 2.3771, MinusLogProbMetric: 2.3771, val_loss: 2.4021, val_MinusLogProbMetric: 2.4021

Epoch 88: val_loss improved from 2.40393 to 2.40211, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 66s - loss: 2.3771 - MinusLogProbMetric: 2.3771 - val_loss: 2.4021 - val_MinusLogProbMetric: 2.4021 - lr: 0.0010 - 66s/epoch - 334ms/step
Epoch 89/1000
2023-09-16 15:44:46.582 
Epoch 89/1000 
	 loss: 2.3869, MinusLogProbMetric: 2.3869, val_loss: 2.4437, val_MinusLogProbMetric: 2.4437

Epoch 89: val_loss did not improve from 2.40211
196/196 - 65s - loss: 2.3869 - MinusLogProbMetric: 2.3869 - val_loss: 2.4437 - val_MinusLogProbMetric: 2.4437 - lr: 0.0010 - 65s/epoch - 331ms/step
Epoch 90/1000
2023-09-16 15:45:51.629 
Epoch 90/1000 
	 loss: 2.3850, MinusLogProbMetric: 2.3850, val_loss: 2.4424, val_MinusLogProbMetric: 2.4424

Epoch 90: val_loss did not improve from 2.40211
196/196 - 65s - loss: 2.3850 - MinusLogProbMetric: 2.3850 - val_loss: 2.4424 - val_MinusLogProbMetric: 2.4424 - lr: 0.0010 - 65s/epoch - 332ms/step
Epoch 91/1000
2023-09-16 15:46:57.335 
Epoch 91/1000 
	 loss: 2.3787, MinusLogProbMetric: 2.3787, val_loss: 2.4369, val_MinusLogProbMetric: 2.4369

Epoch 91: val_loss did not improve from 2.40211
196/196 - 66s - loss: 2.3787 - MinusLogProbMetric: 2.3787 - val_loss: 2.4369 - val_MinusLogProbMetric: 2.4369 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 92/1000
2023-09-16 15:48:02.284 
Epoch 92/1000 
	 loss: 2.3882, MinusLogProbMetric: 2.3882, val_loss: 2.4440, val_MinusLogProbMetric: 2.4440

Epoch 92: val_loss did not improve from 2.40211
196/196 - 65s - loss: 2.3882 - MinusLogProbMetric: 2.3882 - val_loss: 2.4440 - val_MinusLogProbMetric: 2.4440 - lr: 0.0010 - 65s/epoch - 331ms/step
Epoch 93/1000
2023-09-16 15:49:06.809 
Epoch 93/1000 
	 loss: 2.3849, MinusLogProbMetric: 2.3849, val_loss: 2.4421, val_MinusLogProbMetric: 2.4421

Epoch 93: val_loss did not improve from 2.40211
196/196 - 65s - loss: 2.3849 - MinusLogProbMetric: 2.3849 - val_loss: 2.4421 - val_MinusLogProbMetric: 2.4421 - lr: 0.0010 - 65s/epoch - 329ms/step
Epoch 94/1000
2023-09-16 15:50:12.387 
Epoch 94/1000 
	 loss: 2.3815, MinusLogProbMetric: 2.3815, val_loss: 2.4234, val_MinusLogProbMetric: 2.4234

Epoch 94: val_loss did not improve from 2.40211
196/196 - 66s - loss: 2.3815 - MinusLogProbMetric: 2.3815 - val_loss: 2.4234 - val_MinusLogProbMetric: 2.4234 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 95/1000
2023-09-16 15:51:16.913 
Epoch 95/1000 
	 loss: 2.3792, MinusLogProbMetric: 2.3792, val_loss: 2.4845, val_MinusLogProbMetric: 2.4845

Epoch 95: val_loss did not improve from 2.40211
196/196 - 65s - loss: 2.3792 - MinusLogProbMetric: 2.3792 - val_loss: 2.4845 - val_MinusLogProbMetric: 2.4845 - lr: 0.0010 - 65s/epoch - 329ms/step
Epoch 96/1000
2023-09-16 15:52:22.536 
Epoch 96/1000 
	 loss: 2.3788, MinusLogProbMetric: 2.3788, val_loss: 2.4508, val_MinusLogProbMetric: 2.4508

Epoch 96: val_loss did not improve from 2.40211
196/196 - 66s - loss: 2.3788 - MinusLogProbMetric: 2.3788 - val_loss: 2.4508 - val_MinusLogProbMetric: 2.4508 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 97/1000
2023-09-16 15:53:27.666 
Epoch 97/1000 
	 loss: 2.3843, MinusLogProbMetric: 2.3843, val_loss: 2.4342, val_MinusLogProbMetric: 2.4342

Epoch 97: val_loss did not improve from 2.40211
196/196 - 65s - loss: 2.3843 - MinusLogProbMetric: 2.3843 - val_loss: 2.4342 - val_MinusLogProbMetric: 2.4342 - lr: 0.0010 - 65s/epoch - 332ms/step
Epoch 98/1000
2023-09-16 15:54:33.783 
Epoch 98/1000 
	 loss: 2.3839, MinusLogProbMetric: 2.3839, val_loss: 2.4119, val_MinusLogProbMetric: 2.4119

Epoch 98: val_loss did not improve from 2.40211
196/196 - 66s - loss: 2.3839 - MinusLogProbMetric: 2.3839 - val_loss: 2.4119 - val_MinusLogProbMetric: 2.4119 - lr: 0.0010 - 66s/epoch - 337ms/step
Epoch 99/1000
2023-09-16 15:55:38.705 
Epoch 99/1000 
	 loss: 2.3882, MinusLogProbMetric: 2.3882, val_loss: 2.4258, val_MinusLogProbMetric: 2.4258

Epoch 99: val_loss did not improve from 2.40211
196/196 - 65s - loss: 2.3882 - MinusLogProbMetric: 2.3882 - val_loss: 2.4258 - val_MinusLogProbMetric: 2.4258 - lr: 0.0010 - 65s/epoch - 331ms/step
Epoch 100/1000
2023-09-16 15:56:43.193 
Epoch 100/1000 
	 loss: 2.3796, MinusLogProbMetric: 2.3796, val_loss: 2.4244, val_MinusLogProbMetric: 2.4244

Epoch 100: val_loss did not improve from 2.40211
196/196 - 64s - loss: 2.3796 - MinusLogProbMetric: 2.3796 - val_loss: 2.4244 - val_MinusLogProbMetric: 2.4244 - lr: 0.0010 - 64s/epoch - 329ms/step
Epoch 101/1000
2023-09-16 15:57:48.181 
Epoch 101/1000 
	 loss: 2.3842, MinusLogProbMetric: 2.3842, val_loss: 2.4030, val_MinusLogProbMetric: 2.4030

Epoch 101: val_loss did not improve from 2.40211
196/196 - 65s - loss: 2.3842 - MinusLogProbMetric: 2.3842 - val_loss: 2.4030 - val_MinusLogProbMetric: 2.4030 - lr: 0.0010 - 65s/epoch - 332ms/step
Epoch 102/1000
2023-09-16 15:58:53.926 
Epoch 102/1000 
	 loss: 2.3703, MinusLogProbMetric: 2.3703, val_loss: 2.4213, val_MinusLogProbMetric: 2.4213

Epoch 102: val_loss did not improve from 2.40211
196/196 - 66s - loss: 2.3703 - MinusLogProbMetric: 2.3703 - val_loss: 2.4213 - val_MinusLogProbMetric: 2.4213 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 103/1000
2023-09-16 15:59:58.933 
Epoch 103/1000 
	 loss: 2.3813, MinusLogProbMetric: 2.3813, val_loss: 2.4063, val_MinusLogProbMetric: 2.4063

Epoch 103: val_loss did not improve from 2.40211
196/196 - 65s - loss: 2.3813 - MinusLogProbMetric: 2.3813 - val_loss: 2.4063 - val_MinusLogProbMetric: 2.4063 - lr: 0.0010 - 65s/epoch - 332ms/step
Epoch 104/1000
2023-09-16 16:01:05.085 
Epoch 104/1000 
	 loss: 2.3763, MinusLogProbMetric: 2.3763, val_loss: 2.4024, val_MinusLogProbMetric: 2.4024

Epoch 104: val_loss did not improve from 2.40211
196/196 - 66s - loss: 2.3763 - MinusLogProbMetric: 2.3763 - val_loss: 2.4024 - val_MinusLogProbMetric: 2.4024 - lr: 0.0010 - 66s/epoch - 337ms/step
Epoch 105/1000
2023-09-16 16:02:09.913 
Epoch 105/1000 
	 loss: 2.3770, MinusLogProbMetric: 2.3770, val_loss: 2.4213, val_MinusLogProbMetric: 2.4213

Epoch 105: val_loss did not improve from 2.40211
196/196 - 65s - loss: 2.3770 - MinusLogProbMetric: 2.3770 - val_loss: 2.4213 - val_MinusLogProbMetric: 2.4213 - lr: 0.0010 - 65s/epoch - 331ms/step
Epoch 106/1000
2023-09-16 16:03:13.590 
Epoch 106/1000 
	 loss: 2.3829, MinusLogProbMetric: 2.3829, val_loss: 2.4233, val_MinusLogProbMetric: 2.4233

Epoch 106: val_loss did not improve from 2.40211
196/196 - 64s - loss: 2.3829 - MinusLogProbMetric: 2.3829 - val_loss: 2.4233 - val_MinusLogProbMetric: 2.4233 - lr: 0.0010 - 64s/epoch - 325ms/step
Epoch 107/1000
2023-09-16 16:04:17.358 
Epoch 107/1000 
	 loss: 2.3763, MinusLogProbMetric: 2.3763, val_loss: 2.4140, val_MinusLogProbMetric: 2.4140

Epoch 107: val_loss did not improve from 2.40211
196/196 - 64s - loss: 2.3763 - MinusLogProbMetric: 2.3763 - val_loss: 2.4140 - val_MinusLogProbMetric: 2.4140 - lr: 0.0010 - 64s/epoch - 325ms/step
Epoch 108/1000
2023-09-16 16:05:20.275 
Epoch 108/1000 
	 loss: 2.3820, MinusLogProbMetric: 2.3820, val_loss: 2.4260, val_MinusLogProbMetric: 2.4260

Epoch 108: val_loss did not improve from 2.40211
196/196 - 63s - loss: 2.3820 - MinusLogProbMetric: 2.3820 - val_loss: 2.4260 - val_MinusLogProbMetric: 2.4260 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 109/1000
2023-09-16 16:06:23.310 
Epoch 109/1000 
	 loss: 2.3735, MinusLogProbMetric: 2.3735, val_loss: 2.4507, val_MinusLogProbMetric: 2.4507

Epoch 109: val_loss did not improve from 2.40211
196/196 - 63s - loss: 2.3735 - MinusLogProbMetric: 2.3735 - val_loss: 2.4507 - val_MinusLogProbMetric: 2.4507 - lr: 0.0010 - 63s/epoch - 322ms/step
Epoch 110/1000
2023-09-16 16:07:28.056 
Epoch 110/1000 
	 loss: 2.3806, MinusLogProbMetric: 2.3806, val_loss: 2.4145, val_MinusLogProbMetric: 2.4145

Epoch 110: val_loss did not improve from 2.40211
196/196 - 65s - loss: 2.3806 - MinusLogProbMetric: 2.3806 - val_loss: 2.4145 - val_MinusLogProbMetric: 2.4145 - lr: 0.0010 - 65s/epoch - 330ms/step
Epoch 111/1000
2023-09-16 16:08:31.568 
Epoch 111/1000 
	 loss: 2.3720, MinusLogProbMetric: 2.3720, val_loss: 2.4126, val_MinusLogProbMetric: 2.4126

Epoch 111: val_loss did not improve from 2.40211
196/196 - 64s - loss: 2.3720 - MinusLogProbMetric: 2.3720 - val_loss: 2.4126 - val_MinusLogProbMetric: 2.4126 - lr: 0.0010 - 64s/epoch - 324ms/step
Epoch 112/1000
2023-09-16 16:09:34.537 
Epoch 112/1000 
	 loss: 2.3756, MinusLogProbMetric: 2.3756, val_loss: 2.4098, val_MinusLogProbMetric: 2.4098

Epoch 112: val_loss did not improve from 2.40211
196/196 - 63s - loss: 2.3756 - MinusLogProbMetric: 2.3756 - val_loss: 2.4098 - val_MinusLogProbMetric: 2.4098 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 113/1000
2023-09-16 16:10:38.386 
Epoch 113/1000 
	 loss: 2.3753, MinusLogProbMetric: 2.3753, val_loss: 2.4349, val_MinusLogProbMetric: 2.4349

Epoch 113: val_loss did not improve from 2.40211
196/196 - 64s - loss: 2.3753 - MinusLogProbMetric: 2.3753 - val_loss: 2.4349 - val_MinusLogProbMetric: 2.4349 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 114/1000
2023-09-16 16:11:41.478 
Epoch 114/1000 
	 loss: 2.3735, MinusLogProbMetric: 2.3735, val_loss: 2.4023, val_MinusLogProbMetric: 2.4023

Epoch 114: val_loss did not improve from 2.40211
196/196 - 63s - loss: 2.3735 - MinusLogProbMetric: 2.3735 - val_loss: 2.4023 - val_MinusLogProbMetric: 2.4023 - lr: 0.0010 - 63s/epoch - 322ms/step
Epoch 115/1000
2023-09-16 16:12:45.186 
Epoch 115/1000 
	 loss: 2.3798, MinusLogProbMetric: 2.3798, val_loss: 2.4083, val_MinusLogProbMetric: 2.4083

Epoch 115: val_loss did not improve from 2.40211
196/196 - 64s - loss: 2.3798 - MinusLogProbMetric: 2.3798 - val_loss: 2.4083 - val_MinusLogProbMetric: 2.4083 - lr: 0.0010 - 64s/epoch - 325ms/step
Epoch 116/1000
2023-09-16 16:13:47.862 
Epoch 116/1000 
	 loss: 2.3752, MinusLogProbMetric: 2.3752, val_loss: 2.4363, val_MinusLogProbMetric: 2.4363

Epoch 116: val_loss did not improve from 2.40211
196/196 - 63s - loss: 2.3752 - MinusLogProbMetric: 2.3752 - val_loss: 2.4363 - val_MinusLogProbMetric: 2.4363 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 117/1000
2023-09-16 16:14:50.360 
Epoch 117/1000 
	 loss: 2.3754, MinusLogProbMetric: 2.3754, val_loss: 2.4091, val_MinusLogProbMetric: 2.4091

Epoch 117: val_loss did not improve from 2.40211
196/196 - 62s - loss: 2.3754 - MinusLogProbMetric: 2.3754 - val_loss: 2.4091 - val_MinusLogProbMetric: 2.4091 - lr: 0.0010 - 62s/epoch - 319ms/step
Epoch 118/1000
2023-09-16 16:15:54.143 
Epoch 118/1000 
	 loss: 2.3731, MinusLogProbMetric: 2.3731, val_loss: 2.4039, val_MinusLogProbMetric: 2.4039

Epoch 118: val_loss did not improve from 2.40211
196/196 - 64s - loss: 2.3731 - MinusLogProbMetric: 2.3731 - val_loss: 2.4039 - val_MinusLogProbMetric: 2.4039 - lr: 0.0010 - 64s/epoch - 325ms/step
Epoch 119/1000
2023-09-16 16:16:56.408 
Epoch 119/1000 
	 loss: 2.3697, MinusLogProbMetric: 2.3697, val_loss: 2.4060, val_MinusLogProbMetric: 2.4060

Epoch 119: val_loss did not improve from 2.40211
196/196 - 62s - loss: 2.3697 - MinusLogProbMetric: 2.3697 - val_loss: 2.4060 - val_MinusLogProbMetric: 2.4060 - lr: 0.0010 - 62s/epoch - 318ms/step
Epoch 120/1000
2023-09-16 16:17:59.283 
Epoch 120/1000 
	 loss: 2.3669, MinusLogProbMetric: 2.3669, val_loss: 2.3975, val_MinusLogProbMetric: 2.3975

Epoch 120: val_loss improved from 2.40211 to 2.39750, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 64s - loss: 2.3669 - MinusLogProbMetric: 2.3669 - val_loss: 2.3975 - val_MinusLogProbMetric: 2.3975 - lr: 0.0010 - 64s/epoch - 327ms/step
Epoch 121/1000
2023-09-16 16:19:03.818 
Epoch 121/1000 
	 loss: 2.3686, MinusLogProbMetric: 2.3686, val_loss: 2.4170, val_MinusLogProbMetric: 2.4170

Epoch 121: val_loss did not improve from 2.39750
196/196 - 63s - loss: 2.3686 - MinusLogProbMetric: 2.3686 - val_loss: 2.4170 - val_MinusLogProbMetric: 2.4170 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 122/1000
2023-09-16 16:20:07.148 
Epoch 122/1000 
	 loss: 2.3711, MinusLogProbMetric: 2.3711, val_loss: 2.4080, val_MinusLogProbMetric: 2.4080

Epoch 122: val_loss did not improve from 2.39750
196/196 - 63s - loss: 2.3711 - MinusLogProbMetric: 2.3711 - val_loss: 2.4080 - val_MinusLogProbMetric: 2.4080 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 123/1000
2023-09-16 16:21:12.855 
Epoch 123/1000 
	 loss: 2.3733, MinusLogProbMetric: 2.3733, val_loss: 2.4234, val_MinusLogProbMetric: 2.4234

Epoch 123: val_loss did not improve from 2.39750
196/196 - 66s - loss: 2.3733 - MinusLogProbMetric: 2.3733 - val_loss: 2.4234 - val_MinusLogProbMetric: 2.4234 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 124/1000
2023-09-16 16:22:17.454 
Epoch 124/1000 
	 loss: 2.3769, MinusLogProbMetric: 2.3769, val_loss: 2.4597, val_MinusLogProbMetric: 2.4597

Epoch 124: val_loss did not improve from 2.39750
196/196 - 65s - loss: 2.3769 - MinusLogProbMetric: 2.3769 - val_loss: 2.4597 - val_MinusLogProbMetric: 2.4597 - lr: 0.0010 - 65s/epoch - 330ms/step
Epoch 125/1000
2023-09-16 16:23:21.117 
Epoch 125/1000 
	 loss: 2.3726, MinusLogProbMetric: 2.3726, val_loss: 2.4420, val_MinusLogProbMetric: 2.4420

Epoch 125: val_loss did not improve from 2.39750
196/196 - 64s - loss: 2.3726 - MinusLogProbMetric: 2.3726 - val_loss: 2.4420 - val_MinusLogProbMetric: 2.4420 - lr: 0.0010 - 64s/epoch - 325ms/step
Epoch 126/1000
2023-09-16 16:24:25.180 
Epoch 126/1000 
	 loss: 2.3797, MinusLogProbMetric: 2.3797, val_loss: 2.4121, val_MinusLogProbMetric: 2.4121

Epoch 126: val_loss did not improve from 2.39750
196/196 - 64s - loss: 2.3797 - MinusLogProbMetric: 2.3797 - val_loss: 2.4121 - val_MinusLogProbMetric: 2.4121 - lr: 0.0010 - 64s/epoch - 327ms/step
Epoch 127/1000
2023-09-16 16:25:30.097 
Epoch 127/1000 
	 loss: 2.3748, MinusLogProbMetric: 2.3748, val_loss: 2.4537, val_MinusLogProbMetric: 2.4537

Epoch 127: val_loss did not improve from 2.39750
196/196 - 65s - loss: 2.3748 - MinusLogProbMetric: 2.3748 - val_loss: 2.4537 - val_MinusLogProbMetric: 2.4537 - lr: 0.0010 - 65s/epoch - 331ms/step
Epoch 128/1000
2023-09-16 16:26:33.478 
Epoch 128/1000 
	 loss: 2.3722, MinusLogProbMetric: 2.3722, val_loss: 2.4044, val_MinusLogProbMetric: 2.4044

Epoch 128: val_loss did not improve from 2.39750
196/196 - 63s - loss: 2.3722 - MinusLogProbMetric: 2.3722 - val_loss: 2.4044 - val_MinusLogProbMetric: 2.4044 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 129/1000
2023-09-16 16:27:37.516 
Epoch 129/1000 
	 loss: 2.3778, MinusLogProbMetric: 2.3778, val_loss: 2.4053, val_MinusLogProbMetric: 2.4053

Epoch 129: val_loss did not improve from 2.39750
196/196 - 64s - loss: 2.3778 - MinusLogProbMetric: 2.3778 - val_loss: 2.4053 - val_MinusLogProbMetric: 2.4053 - lr: 0.0010 - 64s/epoch - 327ms/step
Epoch 130/1000
2023-09-16 16:28:41.476 
Epoch 130/1000 
	 loss: 2.3765, MinusLogProbMetric: 2.3765, val_loss: 2.4549, val_MinusLogProbMetric: 2.4549

Epoch 130: val_loss did not improve from 2.39750
196/196 - 64s - loss: 2.3765 - MinusLogProbMetric: 2.3765 - val_loss: 2.4549 - val_MinusLogProbMetric: 2.4549 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 131/1000
2023-09-16 16:29:44.693 
Epoch 131/1000 
	 loss: 2.3714, MinusLogProbMetric: 2.3714, val_loss: 2.4386, val_MinusLogProbMetric: 2.4386

Epoch 131: val_loss did not improve from 2.39750
196/196 - 63s - loss: 2.3714 - MinusLogProbMetric: 2.3714 - val_loss: 2.4386 - val_MinusLogProbMetric: 2.4386 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 132/1000
2023-09-16 16:30:48.381 
Epoch 132/1000 
	 loss: 2.3781, MinusLogProbMetric: 2.3781, val_loss: 2.4089, val_MinusLogProbMetric: 2.4089

Epoch 132: val_loss did not improve from 2.39750
196/196 - 64s - loss: 2.3781 - MinusLogProbMetric: 2.3781 - val_loss: 2.4089 - val_MinusLogProbMetric: 2.4089 - lr: 0.0010 - 64s/epoch - 325ms/step
Epoch 133/1000
2023-09-16 16:31:52.419 
Epoch 133/1000 
	 loss: 2.3777, MinusLogProbMetric: 2.3777, val_loss: 2.4290, val_MinusLogProbMetric: 2.4290

Epoch 133: val_loss did not improve from 2.39750
196/196 - 64s - loss: 2.3777 - MinusLogProbMetric: 2.3777 - val_loss: 2.4290 - val_MinusLogProbMetric: 2.4290 - lr: 0.0010 - 64s/epoch - 327ms/step
Epoch 134/1000
2023-09-16 16:32:55.300 
Epoch 134/1000 
	 loss: 2.3753, MinusLogProbMetric: 2.3753, val_loss: 2.4485, val_MinusLogProbMetric: 2.4485

Epoch 134: val_loss did not improve from 2.39750
196/196 - 63s - loss: 2.3753 - MinusLogProbMetric: 2.3753 - val_loss: 2.4485 - val_MinusLogProbMetric: 2.4485 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 135/1000
2023-09-16 16:33:58.904 
Epoch 135/1000 
	 loss: 2.3675, MinusLogProbMetric: 2.3675, val_loss: 2.4166, val_MinusLogProbMetric: 2.4166

Epoch 135: val_loss did not improve from 2.39750
196/196 - 64s - loss: 2.3675 - MinusLogProbMetric: 2.3675 - val_loss: 2.4166 - val_MinusLogProbMetric: 2.4166 - lr: 0.0010 - 64s/epoch - 325ms/step
Epoch 136/1000
2023-09-16 16:35:01.126 
Epoch 136/1000 
	 loss: 2.3672, MinusLogProbMetric: 2.3672, val_loss: 2.4720, val_MinusLogProbMetric: 2.4720

Epoch 136: val_loss did not improve from 2.39750
196/196 - 62s - loss: 2.3672 - MinusLogProbMetric: 2.3672 - val_loss: 2.4720 - val_MinusLogProbMetric: 2.4720 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 137/1000
2023-09-16 16:36:03.418 
Epoch 137/1000 
	 loss: 2.3721, MinusLogProbMetric: 2.3721, val_loss: 2.3974, val_MinusLogProbMetric: 2.3974

Epoch 137: val_loss improved from 2.39750 to 2.39736, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 63s - loss: 2.3721 - MinusLogProbMetric: 2.3721 - val_loss: 2.3974 - val_MinusLogProbMetric: 2.3974 - lr: 0.0010 - 63s/epoch - 324ms/step
Epoch 138/1000
2023-09-16 16:37:08.194 
Epoch 138/1000 
	 loss: 2.3676, MinusLogProbMetric: 2.3676, val_loss: 2.4345, val_MinusLogProbMetric: 2.4345

Epoch 138: val_loss did not improve from 2.39736
196/196 - 64s - loss: 2.3676 - MinusLogProbMetric: 2.3676 - val_loss: 2.4345 - val_MinusLogProbMetric: 2.4345 - lr: 0.0010 - 64s/epoch - 324ms/step
Epoch 139/1000
2023-09-16 16:38:10.891 
Epoch 139/1000 
	 loss: 2.3740, MinusLogProbMetric: 2.3740, val_loss: 2.4084, val_MinusLogProbMetric: 2.4084

Epoch 139: val_loss did not improve from 2.39736
196/196 - 63s - loss: 2.3740 - MinusLogProbMetric: 2.3740 - val_loss: 2.4084 - val_MinusLogProbMetric: 2.4084 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 140/1000
2023-09-16 16:39:14.198 
Epoch 140/1000 
	 loss: 2.3695, MinusLogProbMetric: 2.3695, val_loss: 2.4034, val_MinusLogProbMetric: 2.4034

Epoch 140: val_loss did not improve from 2.39736
196/196 - 63s - loss: 2.3695 - MinusLogProbMetric: 2.3695 - val_loss: 2.4034 - val_MinusLogProbMetric: 2.4034 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 141/1000
2023-09-16 16:40:16.828 
Epoch 141/1000 
	 loss: 2.3831, MinusLogProbMetric: 2.3831, val_loss: 2.4134, val_MinusLogProbMetric: 2.4134

Epoch 141: val_loss did not improve from 2.39736
196/196 - 63s - loss: 2.3831 - MinusLogProbMetric: 2.3831 - val_loss: 2.4134 - val_MinusLogProbMetric: 2.4134 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 142/1000
2023-09-16 16:41:19.736 
Epoch 142/1000 
	 loss: 2.3721, MinusLogProbMetric: 2.3721, val_loss: 2.4647, val_MinusLogProbMetric: 2.4647

Epoch 142: val_loss did not improve from 2.39736
196/196 - 63s - loss: 2.3721 - MinusLogProbMetric: 2.3721 - val_loss: 2.4647 - val_MinusLogProbMetric: 2.4647 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 143/1000
2023-09-16 16:42:22.621 
Epoch 143/1000 
	 loss: 2.3685, MinusLogProbMetric: 2.3685, val_loss: 2.4023, val_MinusLogProbMetric: 2.4023

Epoch 143: val_loss did not improve from 2.39736
196/196 - 63s - loss: 2.3685 - MinusLogProbMetric: 2.3685 - val_loss: 2.4023 - val_MinusLogProbMetric: 2.4023 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 144/1000
2023-09-16 16:43:25.462 
Epoch 144/1000 
	 loss: 2.3649, MinusLogProbMetric: 2.3649, val_loss: 2.4232, val_MinusLogProbMetric: 2.4232

Epoch 144: val_loss did not improve from 2.39736
196/196 - 63s - loss: 2.3649 - MinusLogProbMetric: 2.3649 - val_loss: 2.4232 - val_MinusLogProbMetric: 2.4232 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 145/1000
2023-09-16 16:44:28.967 
Epoch 145/1000 
	 loss: 2.3737, MinusLogProbMetric: 2.3737, val_loss: 2.4142, val_MinusLogProbMetric: 2.4142

Epoch 145: val_loss did not improve from 2.39736
196/196 - 64s - loss: 2.3737 - MinusLogProbMetric: 2.3737 - val_loss: 2.4142 - val_MinusLogProbMetric: 2.4142 - lr: 0.0010 - 64s/epoch - 324ms/step
Epoch 146/1000
2023-09-16 16:45:32.462 
Epoch 146/1000 
	 loss: 2.3731, MinusLogProbMetric: 2.3731, val_loss: 2.4085, val_MinusLogProbMetric: 2.4085

Epoch 146: val_loss did not improve from 2.39736
196/196 - 63s - loss: 2.3731 - MinusLogProbMetric: 2.3731 - val_loss: 2.4085 - val_MinusLogProbMetric: 2.4085 - lr: 0.0010 - 63s/epoch - 324ms/step
Epoch 147/1000
2023-09-16 16:46:35.344 
Epoch 147/1000 
	 loss: 2.3659, MinusLogProbMetric: 2.3659, val_loss: 2.4050, val_MinusLogProbMetric: 2.4050

Epoch 147: val_loss did not improve from 2.39736
196/196 - 63s - loss: 2.3659 - MinusLogProbMetric: 2.3659 - val_loss: 2.4050 - val_MinusLogProbMetric: 2.4050 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 148/1000
2023-09-16 16:47:38.873 
Epoch 148/1000 
	 loss: 2.3701, MinusLogProbMetric: 2.3701, val_loss: 2.4947, val_MinusLogProbMetric: 2.4947

Epoch 148: val_loss did not improve from 2.39736
196/196 - 64s - loss: 2.3701 - MinusLogProbMetric: 2.3701 - val_loss: 2.4947 - val_MinusLogProbMetric: 2.4947 - lr: 0.0010 - 64s/epoch - 324ms/step
Epoch 149/1000
2023-09-16 16:48:42.074 
Epoch 149/1000 
	 loss: 2.3689, MinusLogProbMetric: 2.3689, val_loss: 2.4112, val_MinusLogProbMetric: 2.4112

Epoch 149: val_loss did not improve from 2.39736
196/196 - 63s - loss: 2.3689 - MinusLogProbMetric: 2.3689 - val_loss: 2.4112 - val_MinusLogProbMetric: 2.4112 - lr: 0.0010 - 63s/epoch - 322ms/step
Epoch 150/1000
2023-09-16 16:49:43.847 
Epoch 150/1000 
	 loss: 2.3676, MinusLogProbMetric: 2.3676, val_loss: 2.3980, val_MinusLogProbMetric: 2.3980

Epoch 150: val_loss did not improve from 2.39736
196/196 - 62s - loss: 2.3676 - MinusLogProbMetric: 2.3676 - val_loss: 2.3980 - val_MinusLogProbMetric: 2.3980 - lr: 0.0010 - 62s/epoch - 315ms/step
Epoch 151/1000
2023-09-16 16:50:47.390 
Epoch 151/1000 
	 loss: 2.3679, MinusLogProbMetric: 2.3679, val_loss: 2.3995, val_MinusLogProbMetric: 2.3995

Epoch 151: val_loss did not improve from 2.39736
196/196 - 64s - loss: 2.3679 - MinusLogProbMetric: 2.3679 - val_loss: 2.3995 - val_MinusLogProbMetric: 2.3995 - lr: 0.0010 - 64s/epoch - 324ms/step
Epoch 152/1000
2023-09-16 16:51:50.308 
Epoch 152/1000 
	 loss: 2.3681, MinusLogProbMetric: 2.3681, val_loss: 2.4158, val_MinusLogProbMetric: 2.4158

Epoch 152: val_loss did not improve from 2.39736
196/196 - 63s - loss: 2.3681 - MinusLogProbMetric: 2.3681 - val_loss: 2.4158 - val_MinusLogProbMetric: 2.4158 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 153/1000
2023-09-16 16:52:54.052 
Epoch 153/1000 
	 loss: 2.3663, MinusLogProbMetric: 2.3663, val_loss: 2.4082, val_MinusLogProbMetric: 2.4082

Epoch 153: val_loss did not improve from 2.39736
196/196 - 64s - loss: 2.3663 - MinusLogProbMetric: 2.3663 - val_loss: 2.4082 - val_MinusLogProbMetric: 2.4082 - lr: 0.0010 - 64s/epoch - 325ms/step
Epoch 154/1000
2023-09-16 16:53:56.619 
Epoch 154/1000 
	 loss: 2.3668, MinusLogProbMetric: 2.3668, val_loss: 2.4057, val_MinusLogProbMetric: 2.4057

Epoch 154: val_loss did not improve from 2.39736
196/196 - 63s - loss: 2.3668 - MinusLogProbMetric: 2.3668 - val_loss: 2.4057 - val_MinusLogProbMetric: 2.4057 - lr: 0.0010 - 63s/epoch - 319ms/step
Epoch 155/1000
2023-09-16 16:54:59.694 
Epoch 155/1000 
	 loss: 2.3674, MinusLogProbMetric: 2.3674, val_loss: 2.4640, val_MinusLogProbMetric: 2.4640

Epoch 155: val_loss did not improve from 2.39736
196/196 - 63s - loss: 2.3674 - MinusLogProbMetric: 2.3674 - val_loss: 2.4640 - val_MinusLogProbMetric: 2.4640 - lr: 0.0010 - 63s/epoch - 322ms/step
Epoch 156/1000
2023-09-16 16:56:01.805 
Epoch 156/1000 
	 loss: 2.3721, MinusLogProbMetric: 2.3721, val_loss: 2.4162, val_MinusLogProbMetric: 2.4162

Epoch 156: val_loss did not improve from 2.39736
196/196 - 62s - loss: 2.3721 - MinusLogProbMetric: 2.3721 - val_loss: 2.4162 - val_MinusLogProbMetric: 2.4162 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 157/1000
2023-09-16 16:57:04.182 
Epoch 157/1000 
	 loss: 2.3726, MinusLogProbMetric: 2.3726, val_loss: 2.4094, val_MinusLogProbMetric: 2.4094

Epoch 157: val_loss did not improve from 2.39736
196/196 - 62s - loss: 2.3726 - MinusLogProbMetric: 2.3726 - val_loss: 2.4094 - val_MinusLogProbMetric: 2.4094 - lr: 0.0010 - 62s/epoch - 318ms/step
Epoch 158/1000
2023-09-16 16:58:07.727 
Epoch 158/1000 
	 loss: 2.3632, MinusLogProbMetric: 2.3632, val_loss: 2.4155, val_MinusLogProbMetric: 2.4155

Epoch 158: val_loss did not improve from 2.39736
196/196 - 64s - loss: 2.3632 - MinusLogProbMetric: 2.3632 - val_loss: 2.4155 - val_MinusLogProbMetric: 2.4155 - lr: 0.0010 - 64s/epoch - 324ms/step
Epoch 159/1000
2023-09-16 16:59:11.240 
Epoch 159/1000 
	 loss: 2.3666, MinusLogProbMetric: 2.3666, val_loss: 2.4187, val_MinusLogProbMetric: 2.4187

Epoch 159: val_loss did not improve from 2.39736
196/196 - 64s - loss: 2.3666 - MinusLogProbMetric: 2.3666 - val_loss: 2.4187 - val_MinusLogProbMetric: 2.4187 - lr: 0.0010 - 64s/epoch - 324ms/step
Epoch 160/1000
2023-09-16 17:00:14.889 
Epoch 160/1000 
	 loss: 2.3657, MinusLogProbMetric: 2.3657, val_loss: 2.4023, val_MinusLogProbMetric: 2.4023

Epoch 160: val_loss did not improve from 2.39736
196/196 - 64s - loss: 2.3657 - MinusLogProbMetric: 2.3657 - val_loss: 2.4023 - val_MinusLogProbMetric: 2.4023 - lr: 0.0010 - 64s/epoch - 325ms/step
Epoch 161/1000
2023-09-16 17:01:18.549 
Epoch 161/1000 
	 loss: 2.3633, MinusLogProbMetric: 2.3633, val_loss: 2.4232, val_MinusLogProbMetric: 2.4232

Epoch 161: val_loss did not improve from 2.39736
196/196 - 64s - loss: 2.3633 - MinusLogProbMetric: 2.3633 - val_loss: 2.4232 - val_MinusLogProbMetric: 2.4232 - lr: 0.0010 - 64s/epoch - 325ms/step
Epoch 162/1000
2023-09-16 17:02:20.538 
Epoch 162/1000 
	 loss: 2.3666, MinusLogProbMetric: 2.3666, val_loss: 2.4059, val_MinusLogProbMetric: 2.4059

Epoch 162: val_loss did not improve from 2.39736
196/196 - 62s - loss: 2.3666 - MinusLogProbMetric: 2.3666 - val_loss: 2.4059 - val_MinusLogProbMetric: 2.4059 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 163/1000
2023-09-16 17:03:22.645 
Epoch 163/1000 
	 loss: 2.3668, MinusLogProbMetric: 2.3668, val_loss: 2.4069, val_MinusLogProbMetric: 2.4069

Epoch 163: val_loss did not improve from 2.39736
196/196 - 62s - loss: 2.3668 - MinusLogProbMetric: 2.3668 - val_loss: 2.4069 - val_MinusLogProbMetric: 2.4069 - lr: 0.0010 - 62s/epoch - 317ms/step
Epoch 164/1000
2023-09-16 17:04:25.976 
Epoch 164/1000 
	 loss: 2.3740, MinusLogProbMetric: 2.3740, val_loss: 2.3953, val_MinusLogProbMetric: 2.3953

Epoch 164: val_loss improved from 2.39736 to 2.39529, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 64s - loss: 2.3740 - MinusLogProbMetric: 2.3740 - val_loss: 2.3953 - val_MinusLogProbMetric: 2.3953 - lr: 0.0010 - 64s/epoch - 329ms/step
Epoch 165/1000
2023-09-16 17:05:30.508 
Epoch 165/1000 
	 loss: 2.3650, MinusLogProbMetric: 2.3650, val_loss: 2.4373, val_MinusLogProbMetric: 2.4373

Epoch 165: val_loss did not improve from 2.39529
196/196 - 63s - loss: 2.3650 - MinusLogProbMetric: 2.3650 - val_loss: 2.4373 - val_MinusLogProbMetric: 2.4373 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 166/1000
2023-09-16 17:06:32.379 
Epoch 166/1000 
	 loss: 2.3691, MinusLogProbMetric: 2.3691, val_loss: 2.4293, val_MinusLogProbMetric: 2.4293

Epoch 166: val_loss did not improve from 2.39529
196/196 - 62s - loss: 2.3691 - MinusLogProbMetric: 2.3691 - val_loss: 2.4293 - val_MinusLogProbMetric: 2.4293 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 167/1000
2023-09-16 17:07:34.411 
Epoch 167/1000 
	 loss: 2.3615, MinusLogProbMetric: 2.3615, val_loss: 2.4006, val_MinusLogProbMetric: 2.4006

Epoch 167: val_loss did not improve from 2.39529
196/196 - 62s - loss: 2.3615 - MinusLogProbMetric: 2.3615 - val_loss: 2.4006 - val_MinusLogProbMetric: 2.4006 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 168/1000
2023-09-16 17:08:40.039 
Epoch 168/1000 
	 loss: 2.3623, MinusLogProbMetric: 2.3623, val_loss: 2.4169, val_MinusLogProbMetric: 2.4169

Epoch 168: val_loss did not improve from 2.39529
196/196 - 66s - loss: 2.3623 - MinusLogProbMetric: 2.3623 - val_loss: 2.4169 - val_MinusLogProbMetric: 2.4169 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 169/1000
2023-09-16 17:09:43.499 
Epoch 169/1000 
	 loss: 2.3604, MinusLogProbMetric: 2.3604, val_loss: 2.4063, val_MinusLogProbMetric: 2.4063

Epoch 169: val_loss did not improve from 2.39529
196/196 - 63s - loss: 2.3604 - MinusLogProbMetric: 2.3604 - val_loss: 2.4063 - val_MinusLogProbMetric: 2.4063 - lr: 0.0010 - 63s/epoch - 324ms/step
Epoch 170/1000
2023-09-16 17:10:46.408 
Epoch 170/1000 
	 loss: 2.3674, MinusLogProbMetric: 2.3674, val_loss: 2.4636, val_MinusLogProbMetric: 2.4636

Epoch 170: val_loss did not improve from 2.39529
196/196 - 63s - loss: 2.3674 - MinusLogProbMetric: 2.3674 - val_loss: 2.4636 - val_MinusLogProbMetric: 2.4636 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 171/1000
2023-09-16 17:11:48.837 
Epoch 171/1000 
	 loss: 2.3651, MinusLogProbMetric: 2.3651, val_loss: 2.4076, val_MinusLogProbMetric: 2.4076

Epoch 171: val_loss did not improve from 2.39529
196/196 - 62s - loss: 2.3651 - MinusLogProbMetric: 2.3651 - val_loss: 2.4076 - val_MinusLogProbMetric: 2.4076 - lr: 0.0010 - 62s/epoch - 318ms/step
Epoch 172/1000
2023-09-16 17:12:51.708 
Epoch 172/1000 
	 loss: 2.3700, MinusLogProbMetric: 2.3700, val_loss: 2.4409, val_MinusLogProbMetric: 2.4409

Epoch 172: val_loss did not improve from 2.39529
196/196 - 63s - loss: 2.3700 - MinusLogProbMetric: 2.3700 - val_loss: 2.4409 - val_MinusLogProbMetric: 2.4409 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 173/1000
2023-09-16 17:13:55.305 
Epoch 173/1000 
	 loss: 2.3665, MinusLogProbMetric: 2.3665, val_loss: 2.4138, val_MinusLogProbMetric: 2.4138

Epoch 173: val_loss did not improve from 2.39529
196/196 - 64s - loss: 2.3665 - MinusLogProbMetric: 2.3665 - val_loss: 2.4138 - val_MinusLogProbMetric: 2.4138 - lr: 0.0010 - 64s/epoch - 324ms/step
Epoch 174/1000
2023-09-16 17:14:58.284 
Epoch 174/1000 
	 loss: 2.3646, MinusLogProbMetric: 2.3646, val_loss: 2.4059, val_MinusLogProbMetric: 2.4059

Epoch 174: val_loss did not improve from 2.39529
196/196 - 63s - loss: 2.3646 - MinusLogProbMetric: 2.3646 - val_loss: 2.4059 - val_MinusLogProbMetric: 2.4059 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 175/1000
2023-09-16 17:16:02.198 
Epoch 175/1000 
	 loss: 2.3660, MinusLogProbMetric: 2.3660, val_loss: 2.4345, val_MinusLogProbMetric: 2.4345

Epoch 175: val_loss did not improve from 2.39529
196/196 - 64s - loss: 2.3660 - MinusLogProbMetric: 2.3660 - val_loss: 2.4345 - val_MinusLogProbMetric: 2.4345 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 176/1000
2023-09-16 17:17:04.623 
Epoch 176/1000 
	 loss: 2.3681, MinusLogProbMetric: 2.3681, val_loss: 2.4016, val_MinusLogProbMetric: 2.4016

Epoch 176: val_loss did not improve from 2.39529
196/196 - 62s - loss: 2.3681 - MinusLogProbMetric: 2.3681 - val_loss: 2.4016 - val_MinusLogProbMetric: 2.4016 - lr: 0.0010 - 62s/epoch - 318ms/step
Epoch 177/1000
2023-09-16 17:18:06.514 
Epoch 177/1000 
	 loss: 2.3666, MinusLogProbMetric: 2.3666, val_loss: 2.4090, val_MinusLogProbMetric: 2.4090

Epoch 177: val_loss did not improve from 2.39529
196/196 - 62s - loss: 2.3666 - MinusLogProbMetric: 2.3666 - val_loss: 2.4090 - val_MinusLogProbMetric: 2.4090 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 178/1000
2023-09-16 17:19:09.357 
Epoch 178/1000 
	 loss: 2.3651, MinusLogProbMetric: 2.3651, val_loss: 2.4137, val_MinusLogProbMetric: 2.4137

Epoch 178: val_loss did not improve from 2.39529
196/196 - 63s - loss: 2.3651 - MinusLogProbMetric: 2.3651 - val_loss: 2.4137 - val_MinusLogProbMetric: 2.4137 - lr: 0.0010 - 63s/epoch - 321ms/step
Epoch 179/1000
2023-09-16 17:20:12.099 
Epoch 179/1000 
	 loss: 2.3610, MinusLogProbMetric: 2.3610, val_loss: 2.4028, val_MinusLogProbMetric: 2.4028

Epoch 179: val_loss did not improve from 2.39529
196/196 - 63s - loss: 2.3610 - MinusLogProbMetric: 2.3610 - val_loss: 2.4028 - val_MinusLogProbMetric: 2.4028 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 180/1000
2023-09-16 17:21:11.232 
Epoch 180/1000 
	 loss: 2.3642, MinusLogProbMetric: 2.3642, val_loss: 2.4222, val_MinusLogProbMetric: 2.4222

Epoch 180: val_loss did not improve from 2.39529
196/196 - 59s - loss: 2.3642 - MinusLogProbMetric: 2.3642 - val_loss: 2.4222 - val_MinusLogProbMetric: 2.4222 - lr: 0.0010 - 59s/epoch - 302ms/step
Epoch 181/1000
2023-09-16 17:22:01.587 
Epoch 181/1000 
	 loss: 2.3618, MinusLogProbMetric: 2.3618, val_loss: 2.3981, val_MinusLogProbMetric: 2.3981

Epoch 181: val_loss did not improve from 2.39529
196/196 - 50s - loss: 2.3618 - MinusLogProbMetric: 2.3618 - val_loss: 2.3981 - val_MinusLogProbMetric: 2.3981 - lr: 0.0010 - 50s/epoch - 257ms/step
Epoch 182/1000
2023-09-16 17:22:53.788 
Epoch 182/1000 
	 loss: 2.3649, MinusLogProbMetric: 2.3649, val_loss: 2.3976, val_MinusLogProbMetric: 2.3976

Epoch 182: val_loss did not improve from 2.39529
196/196 - 52s - loss: 2.3649 - MinusLogProbMetric: 2.3649 - val_loss: 2.3976 - val_MinusLogProbMetric: 2.3976 - lr: 0.0010 - 52s/epoch - 266ms/step
Epoch 183/1000
2023-09-16 17:23:44.674 
Epoch 183/1000 
	 loss: 2.3638, MinusLogProbMetric: 2.3638, val_loss: 2.4121, val_MinusLogProbMetric: 2.4121

Epoch 183: val_loss did not improve from 2.39529
196/196 - 51s - loss: 2.3638 - MinusLogProbMetric: 2.3638 - val_loss: 2.4121 - val_MinusLogProbMetric: 2.4121 - lr: 0.0010 - 51s/epoch - 260ms/step
Epoch 184/1000
2023-09-16 17:24:37.545 
Epoch 184/1000 
	 loss: 2.3713, MinusLogProbMetric: 2.3713, val_loss: 2.4035, val_MinusLogProbMetric: 2.4035

Epoch 184: val_loss did not improve from 2.39529
196/196 - 53s - loss: 2.3713 - MinusLogProbMetric: 2.3713 - val_loss: 2.4035 - val_MinusLogProbMetric: 2.4035 - lr: 0.0010 - 53s/epoch - 270ms/step
Epoch 185/1000
2023-09-16 17:25:29.332 
Epoch 185/1000 
	 loss: 2.3623, MinusLogProbMetric: 2.3623, val_loss: 2.4290, val_MinusLogProbMetric: 2.4290

Epoch 185: val_loss did not improve from 2.39529
196/196 - 52s - loss: 2.3623 - MinusLogProbMetric: 2.3623 - val_loss: 2.4290 - val_MinusLogProbMetric: 2.4290 - lr: 0.0010 - 52s/epoch - 264ms/step
Epoch 186/1000
2023-09-16 17:26:26.437 
Epoch 186/1000 
	 loss: 2.3669, MinusLogProbMetric: 2.3669, val_loss: 2.4066, val_MinusLogProbMetric: 2.4066

Epoch 186: val_loss did not improve from 2.39529
196/196 - 57s - loss: 2.3669 - MinusLogProbMetric: 2.3669 - val_loss: 2.4066 - val_MinusLogProbMetric: 2.4066 - lr: 0.0010 - 57s/epoch - 291ms/step
Epoch 187/1000
2023-09-16 17:27:25.770 
Epoch 187/1000 
	 loss: 2.3597, MinusLogProbMetric: 2.3597, val_loss: 2.4189, val_MinusLogProbMetric: 2.4189

Epoch 187: val_loss did not improve from 2.39529
196/196 - 59s - loss: 2.3597 - MinusLogProbMetric: 2.3597 - val_loss: 2.4189 - val_MinusLogProbMetric: 2.4189 - lr: 0.0010 - 59s/epoch - 303ms/step
Epoch 188/1000
2023-09-16 17:28:26.461 
Epoch 188/1000 
	 loss: 2.3685, MinusLogProbMetric: 2.3685, val_loss: 2.4124, val_MinusLogProbMetric: 2.4124

Epoch 188: val_loss did not improve from 2.39529
196/196 - 61s - loss: 2.3685 - MinusLogProbMetric: 2.3685 - val_loss: 2.4124 - val_MinusLogProbMetric: 2.4124 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 189/1000
2023-09-16 17:29:27.728 
Epoch 189/1000 
	 loss: 2.3622, MinusLogProbMetric: 2.3622, val_loss: 2.4444, val_MinusLogProbMetric: 2.4444

Epoch 189: val_loss did not improve from 2.39529
196/196 - 61s - loss: 2.3622 - MinusLogProbMetric: 2.3622 - val_loss: 2.4444 - val_MinusLogProbMetric: 2.4444 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 190/1000
2023-09-16 17:30:28.979 
Epoch 190/1000 
	 loss: 2.3633, MinusLogProbMetric: 2.3633, val_loss: 2.4198, val_MinusLogProbMetric: 2.4198

Epoch 190: val_loss did not improve from 2.39529
196/196 - 61s - loss: 2.3633 - MinusLogProbMetric: 2.3633 - val_loss: 2.4198 - val_MinusLogProbMetric: 2.4198 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 191/1000
2023-09-16 17:31:29.950 
Epoch 191/1000 
	 loss: 2.3637, MinusLogProbMetric: 2.3637, val_loss: 2.4105, val_MinusLogProbMetric: 2.4105

Epoch 191: val_loss did not improve from 2.39529
196/196 - 61s - loss: 2.3637 - MinusLogProbMetric: 2.3637 - val_loss: 2.4105 - val_MinusLogProbMetric: 2.4105 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 192/1000
2023-09-16 17:32:31.536 
Epoch 192/1000 
	 loss: 2.3620, MinusLogProbMetric: 2.3620, val_loss: 2.4030, val_MinusLogProbMetric: 2.4030

Epoch 192: val_loss did not improve from 2.39529
196/196 - 62s - loss: 2.3620 - MinusLogProbMetric: 2.3620 - val_loss: 2.4030 - val_MinusLogProbMetric: 2.4030 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 193/1000
2023-09-16 17:33:33.064 
Epoch 193/1000 
	 loss: 2.3610, MinusLogProbMetric: 2.3610, val_loss: 2.4014, val_MinusLogProbMetric: 2.4014

Epoch 193: val_loss did not improve from 2.39529
196/196 - 62s - loss: 2.3610 - MinusLogProbMetric: 2.3610 - val_loss: 2.4014 - val_MinusLogProbMetric: 2.4014 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 194/1000
2023-09-16 17:34:33.816 
Epoch 194/1000 
	 loss: 2.3571, MinusLogProbMetric: 2.3571, val_loss: 2.3998, val_MinusLogProbMetric: 2.3998

Epoch 194: val_loss did not improve from 2.39529
196/196 - 61s - loss: 2.3571 - MinusLogProbMetric: 2.3571 - val_loss: 2.3998 - val_MinusLogProbMetric: 2.3998 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 195/1000
2023-09-16 17:35:34.782 
Epoch 195/1000 
	 loss: 2.3634, MinusLogProbMetric: 2.3634, val_loss: 2.4338, val_MinusLogProbMetric: 2.4338

Epoch 195: val_loss did not improve from 2.39529
196/196 - 61s - loss: 2.3634 - MinusLogProbMetric: 2.3634 - val_loss: 2.4338 - val_MinusLogProbMetric: 2.4338 - lr: 0.0010 - 61s/epoch - 311ms/step
Epoch 196/1000
2023-09-16 17:36:36.186 
Epoch 196/1000 
	 loss: 2.3630, MinusLogProbMetric: 2.3630, val_loss: 2.4005, val_MinusLogProbMetric: 2.4005

Epoch 196: val_loss did not improve from 2.39529
196/196 - 61s - loss: 2.3630 - MinusLogProbMetric: 2.3630 - val_loss: 2.4005 - val_MinusLogProbMetric: 2.4005 - lr: 0.0010 - 61s/epoch - 313ms/step
Epoch 197/1000
2023-09-16 17:37:37.043 
Epoch 197/1000 
	 loss: 2.3576, MinusLogProbMetric: 2.3576, val_loss: 2.3991, val_MinusLogProbMetric: 2.3991

Epoch 197: val_loss did not improve from 2.39529
196/196 - 61s - loss: 2.3576 - MinusLogProbMetric: 2.3576 - val_loss: 2.3991 - val_MinusLogProbMetric: 2.3991 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 198/1000
2023-09-16 17:38:37.382 
Epoch 198/1000 
	 loss: 2.3592, MinusLogProbMetric: 2.3592, val_loss: 2.3989, val_MinusLogProbMetric: 2.3989

Epoch 198: val_loss did not improve from 2.39529
196/196 - 60s - loss: 2.3592 - MinusLogProbMetric: 2.3592 - val_loss: 2.3989 - val_MinusLogProbMetric: 2.3989 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 199/1000
2023-09-16 17:39:37.994 
Epoch 199/1000 
	 loss: 2.3601, MinusLogProbMetric: 2.3601, val_loss: 2.3982, val_MinusLogProbMetric: 2.3982

Epoch 199: val_loss did not improve from 2.39529
196/196 - 61s - loss: 2.3601 - MinusLogProbMetric: 2.3601 - val_loss: 2.3982 - val_MinusLogProbMetric: 2.3982 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 200/1000
2023-09-16 17:40:40.248 
Epoch 200/1000 
	 loss: 2.3652, MinusLogProbMetric: 2.3652, val_loss: 2.4144, val_MinusLogProbMetric: 2.4144

Epoch 200: val_loss did not improve from 2.39529
196/196 - 62s - loss: 2.3652 - MinusLogProbMetric: 2.3652 - val_loss: 2.4144 - val_MinusLogProbMetric: 2.4144 - lr: 0.0010 - 62s/epoch - 318ms/step
Epoch 201/1000
2023-09-16 17:41:44.165 
Epoch 201/1000 
	 loss: 2.3633, MinusLogProbMetric: 2.3633, val_loss: 2.4022, val_MinusLogProbMetric: 2.4022

Epoch 201: val_loss did not improve from 2.39529
196/196 - 64s - loss: 2.3633 - MinusLogProbMetric: 2.3633 - val_loss: 2.4022 - val_MinusLogProbMetric: 2.4022 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 202/1000
2023-09-16 17:42:47.804 
Epoch 202/1000 
	 loss: 2.3651, MinusLogProbMetric: 2.3651, val_loss: 2.4087, val_MinusLogProbMetric: 2.4087

Epoch 202: val_loss did not improve from 2.39529
196/196 - 64s - loss: 2.3651 - MinusLogProbMetric: 2.3651 - val_loss: 2.4087 - val_MinusLogProbMetric: 2.4087 - lr: 0.0010 - 64s/epoch - 325ms/step
Epoch 203/1000
2023-09-16 17:43:52.618 
Epoch 203/1000 
	 loss: 2.3623, MinusLogProbMetric: 2.3623, val_loss: 2.4122, val_MinusLogProbMetric: 2.4122

Epoch 203: val_loss did not improve from 2.39529
196/196 - 65s - loss: 2.3623 - MinusLogProbMetric: 2.3623 - val_loss: 2.4122 - val_MinusLogProbMetric: 2.4122 - lr: 0.0010 - 65s/epoch - 331ms/step
Epoch 204/1000
2023-09-16 17:44:56.429 
Epoch 204/1000 
	 loss: 2.3678, MinusLogProbMetric: 2.3678, val_loss: 2.4056, val_MinusLogProbMetric: 2.4056

Epoch 204: val_loss did not improve from 2.39529
196/196 - 64s - loss: 2.3678 - MinusLogProbMetric: 2.3678 - val_loss: 2.4056 - val_MinusLogProbMetric: 2.4056 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 205/1000
2023-09-16 17:45:59.815 
Epoch 205/1000 
	 loss: 2.3659, MinusLogProbMetric: 2.3659, val_loss: 2.4385, val_MinusLogProbMetric: 2.4385

Epoch 205: val_loss did not improve from 2.39529
196/196 - 63s - loss: 2.3659 - MinusLogProbMetric: 2.3659 - val_loss: 2.4385 - val_MinusLogProbMetric: 2.4385 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 206/1000
2023-09-16 17:47:03.025 
Epoch 206/1000 
	 loss: 2.3642, MinusLogProbMetric: 2.3642, val_loss: 2.4549, val_MinusLogProbMetric: 2.4549

Epoch 206: val_loss did not improve from 2.39529
196/196 - 63s - loss: 2.3642 - MinusLogProbMetric: 2.3642 - val_loss: 2.4549 - val_MinusLogProbMetric: 2.4549 - lr: 0.0010 - 63s/epoch - 322ms/step
Epoch 207/1000
2023-09-16 17:48:07.546 
Epoch 207/1000 
	 loss: 2.3585, MinusLogProbMetric: 2.3585, val_loss: 2.4107, val_MinusLogProbMetric: 2.4107

Epoch 207: val_loss did not improve from 2.39529
196/196 - 65s - loss: 2.3585 - MinusLogProbMetric: 2.3585 - val_loss: 2.4107 - val_MinusLogProbMetric: 2.4107 - lr: 0.0010 - 65s/epoch - 329ms/step
Epoch 208/1000
2023-09-16 17:49:10.995 
Epoch 208/1000 
	 loss: 2.3667, MinusLogProbMetric: 2.3667, val_loss: 2.4006, val_MinusLogProbMetric: 2.4006

Epoch 208: val_loss did not improve from 2.39529
196/196 - 63s - loss: 2.3667 - MinusLogProbMetric: 2.3667 - val_loss: 2.4006 - val_MinusLogProbMetric: 2.4006 - lr: 0.0010 - 63s/epoch - 324ms/step
Epoch 209/1000
2023-09-16 17:50:14.609 
Epoch 209/1000 
	 loss: 2.3650, MinusLogProbMetric: 2.3650, val_loss: 2.4151, val_MinusLogProbMetric: 2.4151

Epoch 209: val_loss did not improve from 2.39529
196/196 - 64s - loss: 2.3650 - MinusLogProbMetric: 2.3650 - val_loss: 2.4151 - val_MinusLogProbMetric: 2.4151 - lr: 0.0010 - 64s/epoch - 325ms/step
Epoch 210/1000
2023-09-16 17:51:18.403 
Epoch 210/1000 
	 loss: 2.3634, MinusLogProbMetric: 2.3634, val_loss: 2.4065, val_MinusLogProbMetric: 2.4065

Epoch 210: val_loss did not improve from 2.39529
196/196 - 64s - loss: 2.3634 - MinusLogProbMetric: 2.3634 - val_loss: 2.4065 - val_MinusLogProbMetric: 2.4065 - lr: 0.0010 - 64s/epoch - 325ms/step
Epoch 211/1000
2023-09-16 17:52:21.687 
Epoch 211/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3998, val_MinusLogProbMetric: 2.3998

Epoch 211: val_loss did not improve from 2.39529
196/196 - 63s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3998 - val_MinusLogProbMetric: 2.3998 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 212/1000
2023-09-16 17:53:25.094 
Epoch 212/1000 
	 loss: 2.3583, MinusLogProbMetric: 2.3583, val_loss: 2.4035, val_MinusLogProbMetric: 2.4035

Epoch 212: val_loss did not improve from 2.39529
196/196 - 63s - loss: 2.3583 - MinusLogProbMetric: 2.3583 - val_loss: 2.4035 - val_MinusLogProbMetric: 2.4035 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 213/1000
2023-09-16 17:54:27.088 
Epoch 213/1000 
	 loss: 2.3595, MinusLogProbMetric: 2.3595, val_loss: 2.4063, val_MinusLogProbMetric: 2.4063

Epoch 213: val_loss did not improve from 2.39529
196/196 - 62s - loss: 2.3595 - MinusLogProbMetric: 2.3595 - val_loss: 2.4063 - val_MinusLogProbMetric: 2.4063 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 214/1000
2023-09-16 17:55:26.182 
Epoch 214/1000 
	 loss: 2.3606, MinusLogProbMetric: 2.3606, val_loss: 2.4119, val_MinusLogProbMetric: 2.4119

Epoch 214: val_loss did not improve from 2.39529
196/196 - 59s - loss: 2.3606 - MinusLogProbMetric: 2.3606 - val_loss: 2.4119 - val_MinusLogProbMetric: 2.4119 - lr: 0.0010 - 59s/epoch - 301ms/step
Epoch 215/1000
2023-09-16 17:56:21.767 
Epoch 215/1000 
	 loss: 2.3408, MinusLogProbMetric: 2.3408, val_loss: 2.3989, val_MinusLogProbMetric: 2.3989

Epoch 215: val_loss did not improve from 2.39529
196/196 - 56s - loss: 2.3408 - MinusLogProbMetric: 2.3408 - val_loss: 2.3989 - val_MinusLogProbMetric: 2.3989 - lr: 5.0000e-04 - 56s/epoch - 284ms/step
Epoch 216/1000
2023-09-16 17:57:20.676 
Epoch 216/1000 
	 loss: 2.3404, MinusLogProbMetric: 2.3404, val_loss: 2.3962, val_MinusLogProbMetric: 2.3962

Epoch 216: val_loss did not improve from 2.39529
196/196 - 59s - loss: 2.3404 - MinusLogProbMetric: 2.3404 - val_loss: 2.3962 - val_MinusLogProbMetric: 2.3962 - lr: 5.0000e-04 - 59s/epoch - 301ms/step
Epoch 217/1000
2023-09-16 17:58:25.992 
Epoch 217/1000 
	 loss: 2.3416, MinusLogProbMetric: 2.3416, val_loss: 2.4333, val_MinusLogProbMetric: 2.4333

Epoch 217: val_loss did not improve from 2.39529
196/196 - 65s - loss: 2.3416 - MinusLogProbMetric: 2.3416 - val_loss: 2.4333 - val_MinusLogProbMetric: 2.4333 - lr: 5.0000e-04 - 65s/epoch - 333ms/step
Epoch 218/1000
2023-09-16 17:59:31.024 
Epoch 218/1000 
	 loss: 2.3427, MinusLogProbMetric: 2.3427, val_loss: 2.4127, val_MinusLogProbMetric: 2.4127

Epoch 218: val_loss did not improve from 2.39529
196/196 - 65s - loss: 2.3427 - MinusLogProbMetric: 2.3427 - val_loss: 2.4127 - val_MinusLogProbMetric: 2.4127 - lr: 5.0000e-04 - 65s/epoch - 332ms/step
Epoch 219/1000
2023-09-16 18:00:37.202 
Epoch 219/1000 
	 loss: 2.3413, MinusLogProbMetric: 2.3413, val_loss: 2.3938, val_MinusLogProbMetric: 2.3938

Epoch 219: val_loss improved from 2.39529 to 2.39379, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 67s - loss: 2.3413 - MinusLogProbMetric: 2.3413 - val_loss: 2.3938 - val_MinusLogProbMetric: 2.3938 - lr: 5.0000e-04 - 67s/epoch - 343ms/step
Epoch 220/1000
2023-09-16 18:01:44.320 
Epoch 220/1000 
	 loss: 2.3399, MinusLogProbMetric: 2.3399, val_loss: 2.3977, val_MinusLogProbMetric: 2.3977

Epoch 220: val_loss did not improve from 2.39379
196/196 - 66s - loss: 2.3399 - MinusLogProbMetric: 2.3399 - val_loss: 2.3977 - val_MinusLogProbMetric: 2.3977 - lr: 5.0000e-04 - 66s/epoch - 337ms/step
Epoch 221/1000
2023-09-16 18:02:50.447 
Epoch 221/1000 
	 loss: 2.3401, MinusLogProbMetric: 2.3401, val_loss: 2.4049, val_MinusLogProbMetric: 2.4049

Epoch 221: val_loss did not improve from 2.39379
196/196 - 66s - loss: 2.3401 - MinusLogProbMetric: 2.3401 - val_loss: 2.4049 - val_MinusLogProbMetric: 2.4049 - lr: 5.0000e-04 - 66s/epoch - 337ms/step
Epoch 222/1000
2023-09-16 18:03:56.153 
Epoch 222/1000 
	 loss: 2.3404, MinusLogProbMetric: 2.3404, val_loss: 2.3993, val_MinusLogProbMetric: 2.3993

Epoch 222: val_loss did not improve from 2.39379
196/196 - 66s - loss: 2.3404 - MinusLogProbMetric: 2.3404 - val_loss: 2.3993 - val_MinusLogProbMetric: 2.3993 - lr: 5.0000e-04 - 66s/epoch - 335ms/step
Epoch 223/1000
2023-09-16 18:05:01.360 
Epoch 223/1000 
	 loss: 2.3375, MinusLogProbMetric: 2.3375, val_loss: 2.3965, val_MinusLogProbMetric: 2.3965

Epoch 223: val_loss did not improve from 2.39379
196/196 - 65s - loss: 2.3375 - MinusLogProbMetric: 2.3375 - val_loss: 2.3965 - val_MinusLogProbMetric: 2.3965 - lr: 5.0000e-04 - 65s/epoch - 333ms/step
Epoch 224/1000
2023-09-16 18:06:07.470 
Epoch 224/1000 
	 loss: 2.3402, MinusLogProbMetric: 2.3402, val_loss: 2.4045, val_MinusLogProbMetric: 2.4045

Epoch 224: val_loss did not improve from 2.39379
196/196 - 66s - loss: 2.3402 - MinusLogProbMetric: 2.3402 - val_loss: 2.4045 - val_MinusLogProbMetric: 2.4045 - lr: 5.0000e-04 - 66s/epoch - 337ms/step
Epoch 225/1000
2023-09-16 18:07:12.908 
Epoch 225/1000 
	 loss: 2.3390, MinusLogProbMetric: 2.3390, val_loss: 2.3938, val_MinusLogProbMetric: 2.3938

Epoch 225: val_loss did not improve from 2.39379
196/196 - 65s - loss: 2.3390 - MinusLogProbMetric: 2.3390 - val_loss: 2.3938 - val_MinusLogProbMetric: 2.3938 - lr: 5.0000e-04 - 65s/epoch - 334ms/step
Epoch 226/1000
2023-09-16 18:08:18.189 
Epoch 226/1000 
	 loss: 2.3417, MinusLogProbMetric: 2.3417, val_loss: 2.4213, val_MinusLogProbMetric: 2.4213

Epoch 226: val_loss did not improve from 2.39379
196/196 - 65s - loss: 2.3417 - MinusLogProbMetric: 2.3417 - val_loss: 2.4213 - val_MinusLogProbMetric: 2.4213 - lr: 5.0000e-04 - 65s/epoch - 333ms/step
Epoch 227/1000
2023-09-16 18:09:23.824 
Epoch 227/1000 
	 loss: 2.3385, MinusLogProbMetric: 2.3385, val_loss: 2.4087, val_MinusLogProbMetric: 2.4087

Epoch 227: val_loss did not improve from 2.39379
196/196 - 66s - loss: 2.3385 - MinusLogProbMetric: 2.3385 - val_loss: 2.4087 - val_MinusLogProbMetric: 2.4087 - lr: 5.0000e-04 - 66s/epoch - 335ms/step
Epoch 228/1000
2023-09-16 18:10:28.320 
Epoch 228/1000 
	 loss: 2.3384, MinusLogProbMetric: 2.3384, val_loss: 2.3971, val_MinusLogProbMetric: 2.3971

Epoch 228: val_loss did not improve from 2.39379
196/196 - 64s - loss: 2.3384 - MinusLogProbMetric: 2.3384 - val_loss: 2.3971 - val_MinusLogProbMetric: 2.3971 - lr: 5.0000e-04 - 64s/epoch - 329ms/step
Epoch 229/1000
2023-09-16 18:11:33.373 
Epoch 229/1000 
	 loss: 2.3379, MinusLogProbMetric: 2.3379, val_loss: 2.4074, val_MinusLogProbMetric: 2.4074

Epoch 229: val_loss did not improve from 2.39379
196/196 - 65s - loss: 2.3379 - MinusLogProbMetric: 2.3379 - val_loss: 2.4074 - val_MinusLogProbMetric: 2.4074 - lr: 5.0000e-04 - 65s/epoch - 332ms/step
Epoch 230/1000
2023-09-16 18:12:38.604 
Epoch 230/1000 
	 loss: 2.3406, MinusLogProbMetric: 2.3406, val_loss: 2.4021, val_MinusLogProbMetric: 2.4021

Epoch 230: val_loss did not improve from 2.39379
196/196 - 65s - loss: 2.3406 - MinusLogProbMetric: 2.3406 - val_loss: 2.4021 - val_MinusLogProbMetric: 2.4021 - lr: 5.0000e-04 - 65s/epoch - 333ms/step
Epoch 231/1000
2023-09-16 18:13:42.948 
Epoch 231/1000 
	 loss: 2.3389, MinusLogProbMetric: 2.3389, val_loss: 2.4031, val_MinusLogProbMetric: 2.4031

Epoch 231: val_loss did not improve from 2.39379
196/196 - 64s - loss: 2.3389 - MinusLogProbMetric: 2.3389 - val_loss: 2.4031 - val_MinusLogProbMetric: 2.4031 - lr: 5.0000e-04 - 64s/epoch - 328ms/step
Epoch 232/1000
2023-09-16 18:14:48.595 
Epoch 232/1000 
	 loss: 2.3387, MinusLogProbMetric: 2.3387, val_loss: 2.3968, val_MinusLogProbMetric: 2.3968

Epoch 232: val_loss did not improve from 2.39379
196/196 - 66s - loss: 2.3387 - MinusLogProbMetric: 2.3387 - val_loss: 2.3968 - val_MinusLogProbMetric: 2.3968 - lr: 5.0000e-04 - 66s/epoch - 335ms/step
Epoch 233/1000
2023-09-16 18:15:53.336 
Epoch 233/1000 
	 loss: 2.3395, MinusLogProbMetric: 2.3395, val_loss: 2.3940, val_MinusLogProbMetric: 2.3940

Epoch 233: val_loss did not improve from 2.39379
196/196 - 65s - loss: 2.3395 - MinusLogProbMetric: 2.3395 - val_loss: 2.3940 - val_MinusLogProbMetric: 2.3940 - lr: 5.0000e-04 - 65s/epoch - 330ms/step
Epoch 234/1000
2023-09-16 18:16:57.537 
Epoch 234/1000 
	 loss: 2.3396, MinusLogProbMetric: 2.3396, val_loss: 2.3953, val_MinusLogProbMetric: 2.3953

Epoch 234: val_loss did not improve from 2.39379
196/196 - 64s - loss: 2.3396 - MinusLogProbMetric: 2.3396 - val_loss: 2.3953 - val_MinusLogProbMetric: 2.3953 - lr: 5.0000e-04 - 64s/epoch - 328ms/step
Epoch 235/1000
2023-09-16 18:18:02.513 
Epoch 235/1000 
	 loss: 2.3426, MinusLogProbMetric: 2.3426, val_loss: 2.3965, val_MinusLogProbMetric: 2.3965

Epoch 235: val_loss did not improve from 2.39379
196/196 - 65s - loss: 2.3426 - MinusLogProbMetric: 2.3426 - val_loss: 2.3965 - val_MinusLogProbMetric: 2.3965 - lr: 5.0000e-04 - 65s/epoch - 332ms/step
Epoch 236/1000
2023-09-16 18:19:07.767 
Epoch 236/1000 
	 loss: 2.3406, MinusLogProbMetric: 2.3406, val_loss: 2.3968, val_MinusLogProbMetric: 2.3968

Epoch 236: val_loss did not improve from 2.39379
196/196 - 65s - loss: 2.3406 - MinusLogProbMetric: 2.3406 - val_loss: 2.3968 - val_MinusLogProbMetric: 2.3968 - lr: 5.0000e-04 - 65s/epoch - 333ms/step
Epoch 237/1000
2023-09-16 18:20:12.671 
Epoch 237/1000 
	 loss: 2.3392, MinusLogProbMetric: 2.3392, val_loss: 2.3937, val_MinusLogProbMetric: 2.3937

Epoch 237: val_loss improved from 2.39379 to 2.39365, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 66s - loss: 2.3392 - MinusLogProbMetric: 2.3392 - val_loss: 2.3937 - val_MinusLogProbMetric: 2.3937 - lr: 5.0000e-04 - 66s/epoch - 336ms/step
Epoch 238/1000
2023-09-16 18:21:18.354 
Epoch 238/1000 
	 loss: 2.3366, MinusLogProbMetric: 2.3366, val_loss: 2.3942, val_MinusLogProbMetric: 2.3942

Epoch 238: val_loss did not improve from 2.39365
196/196 - 65s - loss: 2.3366 - MinusLogProbMetric: 2.3366 - val_loss: 2.3942 - val_MinusLogProbMetric: 2.3942 - lr: 5.0000e-04 - 65s/epoch - 330ms/step
Epoch 239/1000
2023-09-16 18:22:23.991 
Epoch 239/1000 
	 loss: 2.3415, MinusLogProbMetric: 2.3415, val_loss: 2.4132, val_MinusLogProbMetric: 2.4132

Epoch 239: val_loss did not improve from 2.39365
196/196 - 66s - loss: 2.3415 - MinusLogProbMetric: 2.3415 - val_loss: 2.4132 - val_MinusLogProbMetric: 2.4132 - lr: 5.0000e-04 - 66s/epoch - 335ms/step
Epoch 240/1000
2023-09-16 18:23:28.665 
Epoch 240/1000 
	 loss: 2.3396, MinusLogProbMetric: 2.3396, val_loss: 2.3975, val_MinusLogProbMetric: 2.3975

Epoch 240: val_loss did not improve from 2.39365
196/196 - 65s - loss: 2.3396 - MinusLogProbMetric: 2.3396 - val_loss: 2.3975 - val_MinusLogProbMetric: 2.3975 - lr: 5.0000e-04 - 65s/epoch - 330ms/step
Epoch 241/1000
2023-09-16 18:24:31.924 
Epoch 241/1000 
	 loss: 2.3413, MinusLogProbMetric: 2.3413, val_loss: 2.3933, val_MinusLogProbMetric: 2.3933

Epoch 241: val_loss improved from 2.39365 to 2.39330, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 65s - loss: 2.3413 - MinusLogProbMetric: 2.3413 - val_loss: 2.3933 - val_MinusLogProbMetric: 2.3933 - lr: 5.0000e-04 - 65s/epoch - 329ms/step
Epoch 242/1000
2023-09-16 18:25:36.986 
Epoch 242/1000 
	 loss: 2.3382, MinusLogProbMetric: 2.3382, val_loss: 2.3929, val_MinusLogProbMetric: 2.3929

Epoch 242: val_loss improved from 2.39330 to 2.39290, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 65s - loss: 2.3382 - MinusLogProbMetric: 2.3382 - val_loss: 2.3929 - val_MinusLogProbMetric: 2.3929 - lr: 5.0000e-04 - 65s/epoch - 330ms/step
Epoch 243/1000
2023-09-16 18:26:43.027 
Epoch 243/1000 
	 loss: 2.3382, MinusLogProbMetric: 2.3382, val_loss: 2.3950, val_MinusLogProbMetric: 2.3950

Epoch 243: val_loss did not improve from 2.39290
196/196 - 65s - loss: 2.3382 - MinusLogProbMetric: 2.3382 - val_loss: 2.3950 - val_MinusLogProbMetric: 2.3950 - lr: 5.0000e-04 - 65s/epoch - 333ms/step
Epoch 244/1000
2023-09-16 18:27:48.892 
Epoch 244/1000 
	 loss: 2.3362, MinusLogProbMetric: 2.3362, val_loss: 2.3955, val_MinusLogProbMetric: 2.3955

Epoch 244: val_loss did not improve from 2.39290
196/196 - 66s - loss: 2.3362 - MinusLogProbMetric: 2.3362 - val_loss: 2.3955 - val_MinusLogProbMetric: 2.3955 - lr: 5.0000e-04 - 66s/epoch - 336ms/step
Epoch 245/1000
2023-09-16 18:28:53.409 
Epoch 245/1000 
	 loss: 2.3404, MinusLogProbMetric: 2.3404, val_loss: 2.3932, val_MinusLogProbMetric: 2.3932

Epoch 245: val_loss did not improve from 2.39290
196/196 - 65s - loss: 2.3404 - MinusLogProbMetric: 2.3404 - val_loss: 2.3932 - val_MinusLogProbMetric: 2.3932 - lr: 5.0000e-04 - 65s/epoch - 329ms/step
Epoch 246/1000
2023-09-16 18:29:58.705 
Epoch 246/1000 
	 loss: 2.3399, MinusLogProbMetric: 2.3399, val_loss: 2.3927, val_MinusLogProbMetric: 2.3927

Epoch 246: val_loss improved from 2.39290 to 2.39270, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 66s - loss: 2.3399 - MinusLogProbMetric: 2.3399 - val_loss: 2.3927 - val_MinusLogProbMetric: 2.3927 - lr: 5.0000e-04 - 66s/epoch - 338ms/step
Epoch 247/1000
2023-09-16 18:31:04.784 
Epoch 247/1000 
	 loss: 2.3393, MinusLogProbMetric: 2.3393, val_loss: 2.4297, val_MinusLogProbMetric: 2.4297

Epoch 247: val_loss did not improve from 2.39270
196/196 - 65s - loss: 2.3393 - MinusLogProbMetric: 2.3393 - val_loss: 2.4297 - val_MinusLogProbMetric: 2.4297 - lr: 5.0000e-04 - 65s/epoch - 332ms/step
Epoch 248/1000
2023-09-16 18:32:08.541 
Epoch 248/1000 
	 loss: 2.3389, MinusLogProbMetric: 2.3389, val_loss: 2.3987, val_MinusLogProbMetric: 2.3987

Epoch 248: val_loss did not improve from 2.39270
196/196 - 64s - loss: 2.3389 - MinusLogProbMetric: 2.3389 - val_loss: 2.3987 - val_MinusLogProbMetric: 2.3987 - lr: 5.0000e-04 - 64s/epoch - 325ms/step
Epoch 249/1000
2023-09-16 18:33:13.421 
Epoch 249/1000 
	 loss: 2.3382, MinusLogProbMetric: 2.3382, val_loss: 2.4059, val_MinusLogProbMetric: 2.4059

Epoch 249: val_loss did not improve from 2.39270
196/196 - 65s - loss: 2.3382 - MinusLogProbMetric: 2.3382 - val_loss: 2.4059 - val_MinusLogProbMetric: 2.4059 - lr: 5.0000e-04 - 65s/epoch - 331ms/step
Epoch 250/1000
2023-09-16 18:34:16.081 
Epoch 250/1000 
	 loss: 2.3376, MinusLogProbMetric: 2.3376, val_loss: 2.3968, val_MinusLogProbMetric: 2.3968

Epoch 250: val_loss did not improve from 2.39270
196/196 - 63s - loss: 2.3376 - MinusLogProbMetric: 2.3376 - val_loss: 2.3968 - val_MinusLogProbMetric: 2.3968 - lr: 5.0000e-04 - 63s/epoch - 320ms/step
Epoch 251/1000
2023-09-16 18:35:19.039 
Epoch 251/1000 
	 loss: 2.3391, MinusLogProbMetric: 2.3391, val_loss: 2.4028, val_MinusLogProbMetric: 2.4028

Epoch 251: val_loss did not improve from 2.39270
196/196 - 63s - loss: 2.3391 - MinusLogProbMetric: 2.3391 - val_loss: 2.4028 - val_MinusLogProbMetric: 2.4028 - lr: 5.0000e-04 - 63s/epoch - 321ms/step
Epoch 252/1000
2023-09-16 18:36:22.134 
Epoch 252/1000 
	 loss: 2.3399, MinusLogProbMetric: 2.3399, val_loss: 2.3963, val_MinusLogProbMetric: 2.3963

Epoch 252: val_loss did not improve from 2.39270
196/196 - 63s - loss: 2.3399 - MinusLogProbMetric: 2.3399 - val_loss: 2.3963 - val_MinusLogProbMetric: 2.3963 - lr: 5.0000e-04 - 63s/epoch - 322ms/step
Epoch 253/1000
2023-09-16 18:37:25.277 
Epoch 253/1000 
	 loss: 2.3386, MinusLogProbMetric: 2.3386, val_loss: 2.3955, val_MinusLogProbMetric: 2.3955

Epoch 253: val_loss did not improve from 2.39270
196/196 - 63s - loss: 2.3386 - MinusLogProbMetric: 2.3386 - val_loss: 2.3955 - val_MinusLogProbMetric: 2.3955 - lr: 5.0000e-04 - 63s/epoch - 322ms/step
Epoch 254/1000
2023-09-16 18:38:28.526 
Epoch 254/1000 
	 loss: 2.3364, MinusLogProbMetric: 2.3364, val_loss: 2.4032, val_MinusLogProbMetric: 2.4032

Epoch 254: val_loss did not improve from 2.39270
196/196 - 63s - loss: 2.3364 - MinusLogProbMetric: 2.3364 - val_loss: 2.4032 - val_MinusLogProbMetric: 2.4032 - lr: 5.0000e-04 - 63s/epoch - 323ms/step
Epoch 255/1000
2023-09-16 18:39:32.850 
Epoch 255/1000 
	 loss: 2.3388, MinusLogProbMetric: 2.3388, val_loss: 2.4017, val_MinusLogProbMetric: 2.4017

Epoch 255: val_loss did not improve from 2.39270
196/196 - 64s - loss: 2.3388 - MinusLogProbMetric: 2.3388 - val_loss: 2.4017 - val_MinusLogProbMetric: 2.4017 - lr: 5.0000e-04 - 64s/epoch - 328ms/step
Epoch 256/1000
2023-09-16 18:40:37.140 
Epoch 256/1000 
	 loss: 2.3359, MinusLogProbMetric: 2.3359, val_loss: 2.3960, val_MinusLogProbMetric: 2.3960

Epoch 256: val_loss did not improve from 2.39270
196/196 - 64s - loss: 2.3359 - MinusLogProbMetric: 2.3359 - val_loss: 2.3960 - val_MinusLogProbMetric: 2.3960 - lr: 5.0000e-04 - 64s/epoch - 328ms/step
Epoch 257/1000
2023-09-16 18:41:41.565 
Epoch 257/1000 
	 loss: 2.3380, MinusLogProbMetric: 2.3380, val_loss: 2.3934, val_MinusLogProbMetric: 2.3934

Epoch 257: val_loss did not improve from 2.39270
196/196 - 64s - loss: 2.3380 - MinusLogProbMetric: 2.3380 - val_loss: 2.3934 - val_MinusLogProbMetric: 2.3934 - lr: 5.0000e-04 - 64s/epoch - 329ms/step
Epoch 258/1000
2023-09-16 18:42:44.937 
Epoch 258/1000 
	 loss: 2.3383, MinusLogProbMetric: 2.3383, val_loss: 2.4024, val_MinusLogProbMetric: 2.4024

Epoch 258: val_loss did not improve from 2.39270
196/196 - 63s - loss: 2.3383 - MinusLogProbMetric: 2.3383 - val_loss: 2.4024 - val_MinusLogProbMetric: 2.4024 - lr: 5.0000e-04 - 63s/epoch - 323ms/step
Epoch 259/1000
2023-09-16 18:43:49.472 
Epoch 259/1000 
	 loss: 2.3387, MinusLogProbMetric: 2.3387, val_loss: 2.3929, val_MinusLogProbMetric: 2.3929

Epoch 259: val_loss did not improve from 2.39270
196/196 - 65s - loss: 2.3387 - MinusLogProbMetric: 2.3387 - val_loss: 2.3929 - val_MinusLogProbMetric: 2.3929 - lr: 5.0000e-04 - 65s/epoch - 329ms/step
Epoch 260/1000
2023-09-16 18:44:52.186 
Epoch 260/1000 
	 loss: 2.3398, MinusLogProbMetric: 2.3398, val_loss: 2.3961, val_MinusLogProbMetric: 2.3961

Epoch 260: val_loss did not improve from 2.39270
196/196 - 63s - loss: 2.3398 - MinusLogProbMetric: 2.3398 - val_loss: 2.3961 - val_MinusLogProbMetric: 2.3961 - lr: 5.0000e-04 - 63s/epoch - 320ms/step
Epoch 261/1000
2023-09-16 18:45:55.738 
Epoch 261/1000 
	 loss: 2.3371, MinusLogProbMetric: 2.3371, val_loss: 2.4359, val_MinusLogProbMetric: 2.4359

Epoch 261: val_loss did not improve from 2.39270
196/196 - 64s - loss: 2.3371 - MinusLogProbMetric: 2.3371 - val_loss: 2.4359 - val_MinusLogProbMetric: 2.4359 - lr: 5.0000e-04 - 64s/epoch - 324ms/step
Epoch 262/1000
2023-09-16 18:46:59.567 
Epoch 262/1000 
	 loss: 2.3376, MinusLogProbMetric: 2.3376, val_loss: 2.3952, val_MinusLogProbMetric: 2.3952

Epoch 262: val_loss did not improve from 2.39270
196/196 - 64s - loss: 2.3376 - MinusLogProbMetric: 2.3376 - val_loss: 2.3952 - val_MinusLogProbMetric: 2.3952 - lr: 5.0000e-04 - 64s/epoch - 326ms/step
Epoch 263/1000
2023-09-16 18:48:02.403 
Epoch 263/1000 
	 loss: 2.3393, MinusLogProbMetric: 2.3393, val_loss: 2.4010, val_MinusLogProbMetric: 2.4010

Epoch 263: val_loss did not improve from 2.39270
196/196 - 63s - loss: 2.3393 - MinusLogProbMetric: 2.3393 - val_loss: 2.4010 - val_MinusLogProbMetric: 2.4010 - lr: 5.0000e-04 - 63s/epoch - 321ms/step
Epoch 264/1000
2023-09-16 18:48:57.715 
Epoch 264/1000 
	 loss: 2.3380, MinusLogProbMetric: 2.3380, val_loss: 2.4031, val_MinusLogProbMetric: 2.4031

Epoch 264: val_loss did not improve from 2.39270
196/196 - 55s - loss: 2.3380 - MinusLogProbMetric: 2.3380 - val_loss: 2.4031 - val_MinusLogProbMetric: 2.4031 - lr: 5.0000e-04 - 55s/epoch - 282ms/step
Epoch 265/1000
2023-09-16 18:49:48.581 
Epoch 265/1000 
	 loss: 2.3379, MinusLogProbMetric: 2.3379, val_loss: 2.3989, val_MinusLogProbMetric: 2.3989

Epoch 265: val_loss did not improve from 2.39270
196/196 - 51s - loss: 2.3379 - MinusLogProbMetric: 2.3379 - val_loss: 2.3989 - val_MinusLogProbMetric: 2.3989 - lr: 5.0000e-04 - 51s/epoch - 260ms/step
Epoch 266/1000
2023-09-16 18:50:39.229 
Epoch 266/1000 
	 loss: 2.3353, MinusLogProbMetric: 2.3353, val_loss: 2.4154, val_MinusLogProbMetric: 2.4154

Epoch 266: val_loss did not improve from 2.39270
196/196 - 51s - loss: 2.3353 - MinusLogProbMetric: 2.3353 - val_loss: 2.4154 - val_MinusLogProbMetric: 2.4154 - lr: 5.0000e-04 - 51s/epoch - 258ms/step
Epoch 267/1000
2023-09-16 18:51:37.013 
Epoch 267/1000 
	 loss: 2.3420, MinusLogProbMetric: 2.3420, val_loss: 2.3934, val_MinusLogProbMetric: 2.3934

Epoch 267: val_loss did not improve from 2.39270
196/196 - 58s - loss: 2.3420 - MinusLogProbMetric: 2.3420 - val_loss: 2.3934 - val_MinusLogProbMetric: 2.3934 - lr: 5.0000e-04 - 58s/epoch - 295ms/step
Epoch 268/1000
2023-09-16 18:52:40.682 
Epoch 268/1000 
	 loss: 2.3386, MinusLogProbMetric: 2.3386, val_loss: 2.4135, val_MinusLogProbMetric: 2.4135

Epoch 268: val_loss did not improve from 2.39270
196/196 - 64s - loss: 2.3386 - MinusLogProbMetric: 2.3386 - val_loss: 2.4135 - val_MinusLogProbMetric: 2.4135 - lr: 5.0000e-04 - 64s/epoch - 325ms/step
Epoch 269/1000
2023-09-16 18:53:41.235 
Epoch 269/1000 
	 loss: 2.3380, MinusLogProbMetric: 2.3380, val_loss: 2.3970, val_MinusLogProbMetric: 2.3970

Epoch 269: val_loss did not improve from 2.39270
196/196 - 61s - loss: 2.3380 - MinusLogProbMetric: 2.3380 - val_loss: 2.3970 - val_MinusLogProbMetric: 2.3970 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 270/1000
2023-09-16 18:54:44.120 
Epoch 270/1000 
	 loss: 2.3374, MinusLogProbMetric: 2.3374, val_loss: 2.4079, val_MinusLogProbMetric: 2.4079

Epoch 270: val_loss did not improve from 2.39270
196/196 - 63s - loss: 2.3374 - MinusLogProbMetric: 2.3374 - val_loss: 2.4079 - val_MinusLogProbMetric: 2.4079 - lr: 5.0000e-04 - 63s/epoch - 321ms/step
Epoch 271/1000
2023-09-16 18:55:48.339 
Epoch 271/1000 
	 loss: 2.3380, MinusLogProbMetric: 2.3380, val_loss: 2.3961, val_MinusLogProbMetric: 2.3961

Epoch 271: val_loss did not improve from 2.39270
196/196 - 64s - loss: 2.3380 - MinusLogProbMetric: 2.3380 - val_loss: 2.3961 - val_MinusLogProbMetric: 2.3961 - lr: 5.0000e-04 - 64s/epoch - 328ms/step
Epoch 272/1000
2023-09-16 18:56:53.842 
Epoch 272/1000 
	 loss: 2.3365, MinusLogProbMetric: 2.3365, val_loss: 2.3968, val_MinusLogProbMetric: 2.3968

Epoch 272: val_loss did not improve from 2.39270
196/196 - 65s - loss: 2.3365 - MinusLogProbMetric: 2.3365 - val_loss: 2.3968 - val_MinusLogProbMetric: 2.3968 - lr: 5.0000e-04 - 65s/epoch - 334ms/step
Epoch 273/1000
2023-09-16 18:57:59.279 
Epoch 273/1000 
	 loss: 2.3373, MinusLogProbMetric: 2.3373, val_loss: 2.3957, val_MinusLogProbMetric: 2.3957

Epoch 273: val_loss did not improve from 2.39270
196/196 - 65s - loss: 2.3373 - MinusLogProbMetric: 2.3373 - val_loss: 2.3957 - val_MinusLogProbMetric: 2.3957 - lr: 5.0000e-04 - 65s/epoch - 334ms/step
Epoch 274/1000
2023-09-16 18:59:04.534 
Epoch 274/1000 
	 loss: 2.3376, MinusLogProbMetric: 2.3376, val_loss: 2.3982, val_MinusLogProbMetric: 2.3982

Epoch 274: val_loss did not improve from 2.39270
196/196 - 65s - loss: 2.3376 - MinusLogProbMetric: 2.3376 - val_loss: 2.3982 - val_MinusLogProbMetric: 2.3982 - lr: 5.0000e-04 - 65s/epoch - 333ms/step
Epoch 275/1000
2023-09-16 19:00:09.675 
Epoch 275/1000 
	 loss: 2.3367, MinusLogProbMetric: 2.3367, val_loss: 2.3963, val_MinusLogProbMetric: 2.3963

Epoch 275: val_loss did not improve from 2.39270
196/196 - 65s - loss: 2.3367 - MinusLogProbMetric: 2.3367 - val_loss: 2.3963 - val_MinusLogProbMetric: 2.3963 - lr: 5.0000e-04 - 65s/epoch - 332ms/step
Epoch 276/1000
2023-09-16 19:01:14.972 
Epoch 276/1000 
	 loss: 2.3393, MinusLogProbMetric: 2.3393, val_loss: 2.3970, val_MinusLogProbMetric: 2.3970

Epoch 276: val_loss did not improve from 2.39270
196/196 - 65s - loss: 2.3393 - MinusLogProbMetric: 2.3393 - val_loss: 2.3970 - val_MinusLogProbMetric: 2.3970 - lr: 5.0000e-04 - 65s/epoch - 333ms/step
Epoch 277/1000
2023-09-16 19:02:21.469 
Epoch 277/1000 
	 loss: 2.3371, MinusLogProbMetric: 2.3371, val_loss: 2.4006, val_MinusLogProbMetric: 2.4006

Epoch 277: val_loss did not improve from 2.39270
196/196 - 66s - loss: 2.3371 - MinusLogProbMetric: 2.3371 - val_loss: 2.4006 - val_MinusLogProbMetric: 2.4006 - lr: 5.0000e-04 - 66s/epoch - 339ms/step
Epoch 278/1000
2023-09-16 19:03:27.868 
Epoch 278/1000 
	 loss: 2.3375, MinusLogProbMetric: 2.3375, val_loss: 2.4011, val_MinusLogProbMetric: 2.4011

Epoch 278: val_loss did not improve from 2.39270
196/196 - 66s - loss: 2.3375 - MinusLogProbMetric: 2.3375 - val_loss: 2.4011 - val_MinusLogProbMetric: 2.4011 - lr: 5.0000e-04 - 66s/epoch - 339ms/step
Epoch 279/1000
2023-09-16 19:04:33.783 
Epoch 279/1000 
	 loss: 2.3375, MinusLogProbMetric: 2.3375, val_loss: 2.4040, val_MinusLogProbMetric: 2.4040

Epoch 279: val_loss did not improve from 2.39270
196/196 - 66s - loss: 2.3375 - MinusLogProbMetric: 2.3375 - val_loss: 2.4040 - val_MinusLogProbMetric: 2.4040 - lr: 5.0000e-04 - 66s/epoch - 336ms/step
Epoch 280/1000
2023-09-16 19:05:38.051 
Epoch 280/1000 
	 loss: 2.3379, MinusLogProbMetric: 2.3379, val_loss: 2.4096, val_MinusLogProbMetric: 2.4096

Epoch 280: val_loss did not improve from 2.39270
196/196 - 64s - loss: 2.3379 - MinusLogProbMetric: 2.3379 - val_loss: 2.4096 - val_MinusLogProbMetric: 2.4096 - lr: 5.0000e-04 - 64s/epoch - 328ms/step
Epoch 281/1000
2023-09-16 19:06:42.222 
Epoch 281/1000 
	 loss: 2.3388, MinusLogProbMetric: 2.3388, val_loss: 2.3971, val_MinusLogProbMetric: 2.3971

Epoch 281: val_loss did not improve from 2.39270
196/196 - 64s - loss: 2.3388 - MinusLogProbMetric: 2.3388 - val_loss: 2.3971 - val_MinusLogProbMetric: 2.3971 - lr: 5.0000e-04 - 64s/epoch - 327ms/step
Epoch 282/1000
2023-09-16 19:07:46.625 
Epoch 282/1000 
	 loss: 2.3356, MinusLogProbMetric: 2.3356, val_loss: 2.4016, val_MinusLogProbMetric: 2.4016

Epoch 282: val_loss did not improve from 2.39270
196/196 - 64s - loss: 2.3356 - MinusLogProbMetric: 2.3356 - val_loss: 2.4016 - val_MinusLogProbMetric: 2.4016 - lr: 5.0000e-04 - 64s/epoch - 329ms/step
Epoch 283/1000
2023-09-16 19:08:51.452 
Epoch 283/1000 
	 loss: 2.3377, MinusLogProbMetric: 2.3377, val_loss: 2.3993, val_MinusLogProbMetric: 2.3993

Epoch 283: val_loss did not improve from 2.39270
196/196 - 65s - loss: 2.3377 - MinusLogProbMetric: 2.3377 - val_loss: 2.3993 - val_MinusLogProbMetric: 2.3993 - lr: 5.0000e-04 - 65s/epoch - 331ms/step
Epoch 284/1000
2023-09-16 19:09:55.058 
Epoch 284/1000 
	 loss: 2.3388, MinusLogProbMetric: 2.3388, val_loss: 2.4030, val_MinusLogProbMetric: 2.4030

Epoch 284: val_loss did not improve from 2.39270
196/196 - 64s - loss: 2.3388 - MinusLogProbMetric: 2.3388 - val_loss: 2.4030 - val_MinusLogProbMetric: 2.4030 - lr: 5.0000e-04 - 64s/epoch - 324ms/step
Epoch 285/1000
2023-09-16 19:10:58.936 
Epoch 285/1000 
	 loss: 2.3379, MinusLogProbMetric: 2.3379, val_loss: 2.3963, val_MinusLogProbMetric: 2.3963

Epoch 285: val_loss did not improve from 2.39270
196/196 - 64s - loss: 2.3379 - MinusLogProbMetric: 2.3379 - val_loss: 2.3963 - val_MinusLogProbMetric: 2.3963 - lr: 5.0000e-04 - 64s/epoch - 326ms/step
Epoch 286/1000
2023-09-16 19:12:02.114 
Epoch 286/1000 
	 loss: 2.3370, MinusLogProbMetric: 2.3370, val_loss: 2.3958, val_MinusLogProbMetric: 2.3958

Epoch 286: val_loss did not improve from 2.39270
196/196 - 63s - loss: 2.3370 - MinusLogProbMetric: 2.3370 - val_loss: 2.3958 - val_MinusLogProbMetric: 2.3958 - lr: 5.0000e-04 - 63s/epoch - 322ms/step
Epoch 287/1000
2023-09-16 19:13:05.673 
Epoch 287/1000 
	 loss: 2.3350, MinusLogProbMetric: 2.3350, val_loss: 2.4012, val_MinusLogProbMetric: 2.4012

Epoch 287: val_loss did not improve from 2.39270
196/196 - 64s - loss: 2.3350 - MinusLogProbMetric: 2.3350 - val_loss: 2.4012 - val_MinusLogProbMetric: 2.4012 - lr: 5.0000e-04 - 64s/epoch - 324ms/step
Epoch 288/1000
2023-09-16 19:14:09.725 
Epoch 288/1000 
	 loss: 2.3354, MinusLogProbMetric: 2.3354, val_loss: 2.4035, val_MinusLogProbMetric: 2.4035

Epoch 288: val_loss did not improve from 2.39270
196/196 - 64s - loss: 2.3354 - MinusLogProbMetric: 2.3354 - val_loss: 2.4035 - val_MinusLogProbMetric: 2.4035 - lr: 5.0000e-04 - 64s/epoch - 327ms/step
Epoch 289/1000
2023-09-16 19:15:14.345 
Epoch 289/1000 
	 loss: 2.3368, MinusLogProbMetric: 2.3368, val_loss: 2.3989, val_MinusLogProbMetric: 2.3989

Epoch 289: val_loss did not improve from 2.39270
196/196 - 65s - loss: 2.3368 - MinusLogProbMetric: 2.3368 - val_loss: 2.3989 - val_MinusLogProbMetric: 2.3989 - lr: 5.0000e-04 - 65s/epoch - 330ms/step
Epoch 290/1000
2023-09-16 19:16:18.752 
Epoch 290/1000 
	 loss: 2.3409, MinusLogProbMetric: 2.3409, val_loss: 2.3927, val_MinusLogProbMetric: 2.3927

Epoch 290: val_loss improved from 2.39270 to 2.39267, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 65s - loss: 2.3409 - MinusLogProbMetric: 2.3409 - val_loss: 2.3927 - val_MinusLogProbMetric: 2.3927 - lr: 5.0000e-04 - 65s/epoch - 332ms/step
Epoch 291/1000
2023-09-16 19:17:24.180 
Epoch 291/1000 
	 loss: 2.3540, MinusLogProbMetric: 2.3540, val_loss: 2.4002, val_MinusLogProbMetric: 2.4002

Epoch 291: val_loss did not improve from 2.39267
196/196 - 65s - loss: 2.3540 - MinusLogProbMetric: 2.3540 - val_loss: 2.4002 - val_MinusLogProbMetric: 2.4002 - lr: 5.0000e-04 - 65s/epoch - 330ms/step
Epoch 292/1000
2023-09-16 19:18:29.547 
Epoch 292/1000 
	 loss: 2.3441, MinusLogProbMetric: 2.3441, val_loss: 2.4032, val_MinusLogProbMetric: 2.4032

Epoch 292: val_loss did not improve from 2.39267
196/196 - 65s - loss: 2.3441 - MinusLogProbMetric: 2.3441 - val_loss: 2.4032 - val_MinusLogProbMetric: 2.4032 - lr: 5.0000e-04 - 65s/epoch - 333ms/step
Epoch 293/1000
2023-09-16 19:19:34.438 
Epoch 293/1000 
	 loss: 2.3378, MinusLogProbMetric: 2.3378, val_loss: 2.4022, val_MinusLogProbMetric: 2.4022

Epoch 293: val_loss did not improve from 2.39267
196/196 - 65s - loss: 2.3378 - MinusLogProbMetric: 2.3378 - val_loss: 2.4022 - val_MinusLogProbMetric: 2.4022 - lr: 5.0000e-04 - 65s/epoch - 331ms/step
Epoch 294/1000
2023-09-16 19:20:38.683 
Epoch 294/1000 
	 loss: 2.3383, MinusLogProbMetric: 2.3383, val_loss: 2.3952, val_MinusLogProbMetric: 2.3952

Epoch 294: val_loss did not improve from 2.39267
196/196 - 64s - loss: 2.3383 - MinusLogProbMetric: 2.3383 - val_loss: 2.3952 - val_MinusLogProbMetric: 2.3952 - lr: 5.0000e-04 - 64s/epoch - 328ms/step
Epoch 295/1000
2023-09-16 19:21:43.059 
Epoch 295/1000 
	 loss: 2.3380, MinusLogProbMetric: 2.3380, val_loss: 2.4016, val_MinusLogProbMetric: 2.4016

Epoch 295: val_loss did not improve from 2.39267
196/196 - 64s - loss: 2.3380 - MinusLogProbMetric: 2.3380 - val_loss: 2.4016 - val_MinusLogProbMetric: 2.4016 - lr: 5.0000e-04 - 64s/epoch - 328ms/step
Epoch 296/1000
2023-09-16 19:22:46.971 
Epoch 296/1000 
	 loss: 2.3375, MinusLogProbMetric: 2.3375, val_loss: 2.4042, val_MinusLogProbMetric: 2.4042

Epoch 296: val_loss did not improve from 2.39267
196/196 - 64s - loss: 2.3375 - MinusLogProbMetric: 2.3375 - val_loss: 2.4042 - val_MinusLogProbMetric: 2.4042 - lr: 5.0000e-04 - 64s/epoch - 326ms/step
Epoch 297/1000
2023-09-16 19:23:51.552 
Epoch 297/1000 
	 loss: 2.3281, MinusLogProbMetric: 2.3281, val_loss: 2.3929, val_MinusLogProbMetric: 2.3929

Epoch 297: val_loss did not improve from 2.39267
196/196 - 65s - loss: 2.3281 - MinusLogProbMetric: 2.3281 - val_loss: 2.3929 - val_MinusLogProbMetric: 2.3929 - lr: 2.5000e-04 - 65s/epoch - 329ms/step
Epoch 298/1000
2023-09-16 19:24:55.928 
Epoch 298/1000 
	 loss: 2.3267, MinusLogProbMetric: 2.3267, val_loss: 2.3994, val_MinusLogProbMetric: 2.3994

Epoch 298: val_loss did not improve from 2.39267
196/196 - 64s - loss: 2.3267 - MinusLogProbMetric: 2.3267 - val_loss: 2.3994 - val_MinusLogProbMetric: 2.3994 - lr: 2.5000e-04 - 64s/epoch - 328ms/step
Epoch 299/1000
2023-09-16 19:26:00.483 
Epoch 299/1000 
	 loss: 2.3275, MinusLogProbMetric: 2.3275, val_loss: 2.3915, val_MinusLogProbMetric: 2.3915

Epoch 299: val_loss improved from 2.39267 to 2.39153, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 66s - loss: 2.3275 - MinusLogProbMetric: 2.3275 - val_loss: 2.3915 - val_MinusLogProbMetric: 2.3915 - lr: 2.5000e-04 - 66s/epoch - 334ms/step
Epoch 300/1000
2023-09-16 19:27:06.614 
Epoch 300/1000 
	 loss: 2.3267, MinusLogProbMetric: 2.3267, val_loss: 2.3935, val_MinusLogProbMetric: 2.3935

Epoch 300: val_loss did not improve from 2.39153
196/196 - 65s - loss: 2.3267 - MinusLogProbMetric: 2.3267 - val_loss: 2.3935 - val_MinusLogProbMetric: 2.3935 - lr: 2.5000e-04 - 65s/epoch - 332ms/step
Epoch 301/1000
2023-09-16 19:28:11.623 
Epoch 301/1000 
	 loss: 2.3262, MinusLogProbMetric: 2.3262, val_loss: 2.3937, val_MinusLogProbMetric: 2.3937

Epoch 301: val_loss did not improve from 2.39153
196/196 - 65s - loss: 2.3262 - MinusLogProbMetric: 2.3262 - val_loss: 2.3937 - val_MinusLogProbMetric: 2.3937 - lr: 2.5000e-04 - 65s/epoch - 332ms/step
Epoch 302/1000
2023-09-16 19:29:16.329 
Epoch 302/1000 
	 loss: 2.3263, MinusLogProbMetric: 2.3263, val_loss: 2.3931, val_MinusLogProbMetric: 2.3931

Epoch 302: val_loss did not improve from 2.39153
196/196 - 65s - loss: 2.3263 - MinusLogProbMetric: 2.3263 - val_loss: 2.3931 - val_MinusLogProbMetric: 2.3931 - lr: 2.5000e-04 - 65s/epoch - 330ms/step
Epoch 303/1000
2023-09-16 19:30:21.385 
Epoch 303/1000 
	 loss: 2.3283, MinusLogProbMetric: 2.3283, val_loss: 2.3951, val_MinusLogProbMetric: 2.3951

Epoch 303: val_loss did not improve from 2.39153
196/196 - 65s - loss: 2.3283 - MinusLogProbMetric: 2.3283 - val_loss: 2.3951 - val_MinusLogProbMetric: 2.3951 - lr: 2.5000e-04 - 65s/epoch - 332ms/step
Epoch 304/1000
2023-09-16 19:31:25.425 
Epoch 304/1000 
	 loss: 2.3269, MinusLogProbMetric: 2.3269, val_loss: 2.3912, val_MinusLogProbMetric: 2.3912

Epoch 304: val_loss improved from 2.39153 to 2.39123, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_78/weights/best_weights.h5
196/196 - 65s - loss: 2.3269 - MinusLogProbMetric: 2.3269 - val_loss: 2.3912 - val_MinusLogProbMetric: 2.3912 - lr: 2.5000e-04 - 65s/epoch - 333ms/step
Epoch 305/1000
2023-09-16 19:32:30.316 
Epoch 305/1000 
	 loss: 2.3262, MinusLogProbMetric: 2.3262, val_loss: 2.3979, val_MinusLogProbMetric: 2.3979

Epoch 305: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3262 - MinusLogProbMetric: 2.3262 - val_loss: 2.3979 - val_MinusLogProbMetric: 2.3979 - lr: 2.5000e-04 - 64s/epoch - 325ms/step
Epoch 306/1000
2023-09-16 19:33:33.979 
Epoch 306/1000 
	 loss: 2.3263, MinusLogProbMetric: 2.3263, val_loss: 2.3928, val_MinusLogProbMetric: 2.3928

Epoch 306: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3263 - MinusLogProbMetric: 2.3263 - val_loss: 2.3928 - val_MinusLogProbMetric: 2.3928 - lr: 2.5000e-04 - 64s/epoch - 325ms/step
Epoch 307/1000
2023-09-16 19:34:37.751 
Epoch 307/1000 
	 loss: 2.3253, MinusLogProbMetric: 2.3253, val_loss: 2.3936, val_MinusLogProbMetric: 2.3936

Epoch 307: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3253 - MinusLogProbMetric: 2.3253 - val_loss: 2.3936 - val_MinusLogProbMetric: 2.3936 - lr: 2.5000e-04 - 64s/epoch - 325ms/step
Epoch 308/1000
2023-09-16 19:35:41.963 
Epoch 308/1000 
	 loss: 2.3278, MinusLogProbMetric: 2.3278, val_loss: 2.4008, val_MinusLogProbMetric: 2.4008

Epoch 308: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3278 - MinusLogProbMetric: 2.3278 - val_loss: 2.4008 - val_MinusLogProbMetric: 2.4008 - lr: 2.5000e-04 - 64s/epoch - 328ms/step
Epoch 309/1000
2023-09-16 19:36:45.456 
Epoch 309/1000 
	 loss: 2.3271, MinusLogProbMetric: 2.3271, val_loss: 2.3977, val_MinusLogProbMetric: 2.3977

Epoch 309: val_loss did not improve from 2.39123
196/196 - 63s - loss: 2.3271 - MinusLogProbMetric: 2.3271 - val_loss: 2.3977 - val_MinusLogProbMetric: 2.3977 - lr: 2.5000e-04 - 63s/epoch - 324ms/step
Epoch 310/1000
2023-09-16 19:37:49.311 
Epoch 310/1000 
	 loss: 2.3264, MinusLogProbMetric: 2.3264, val_loss: 2.3943, val_MinusLogProbMetric: 2.3943

Epoch 310: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3264 - MinusLogProbMetric: 2.3264 - val_loss: 2.3943 - val_MinusLogProbMetric: 2.3943 - lr: 2.5000e-04 - 64s/epoch - 326ms/step
Epoch 311/1000
2023-09-16 19:38:53.365 
Epoch 311/1000 
	 loss: 2.3266, MinusLogProbMetric: 2.3266, val_loss: 2.3940, val_MinusLogProbMetric: 2.3940

Epoch 311: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3266 - MinusLogProbMetric: 2.3266 - val_loss: 2.3940 - val_MinusLogProbMetric: 2.3940 - lr: 2.5000e-04 - 64s/epoch - 327ms/step
Epoch 312/1000
2023-09-16 19:39:57.360 
Epoch 312/1000 
	 loss: 2.3248, MinusLogProbMetric: 2.3248, val_loss: 2.3943, val_MinusLogProbMetric: 2.3943

Epoch 312: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3248 - MinusLogProbMetric: 2.3248 - val_loss: 2.3943 - val_MinusLogProbMetric: 2.3943 - lr: 2.5000e-04 - 64s/epoch - 327ms/step
Epoch 313/1000
2023-09-16 19:40:58.657 
Epoch 313/1000 
	 loss: 2.3254, MinusLogProbMetric: 2.3254, val_loss: 2.3958, val_MinusLogProbMetric: 2.3958

Epoch 313: val_loss did not improve from 2.39123
196/196 - 61s - loss: 2.3254 - MinusLogProbMetric: 2.3254 - val_loss: 2.3958 - val_MinusLogProbMetric: 2.3958 - lr: 2.5000e-04 - 61s/epoch - 313ms/step
Epoch 314/1000
2023-09-16 19:41:58.362 
Epoch 314/1000 
	 loss: 2.3261, MinusLogProbMetric: 2.3261, val_loss: 2.3987, val_MinusLogProbMetric: 2.3987

Epoch 314: val_loss did not improve from 2.39123
196/196 - 60s - loss: 2.3261 - MinusLogProbMetric: 2.3261 - val_loss: 2.3987 - val_MinusLogProbMetric: 2.3987 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 315/1000
2023-09-16 19:43:03.015 
Epoch 315/1000 
	 loss: 2.3251, MinusLogProbMetric: 2.3251, val_loss: 2.3927, val_MinusLogProbMetric: 2.3927

Epoch 315: val_loss did not improve from 2.39123
196/196 - 65s - loss: 2.3251 - MinusLogProbMetric: 2.3251 - val_loss: 2.3927 - val_MinusLogProbMetric: 2.3927 - lr: 2.5000e-04 - 65s/epoch - 330ms/step
Epoch 316/1000
2023-09-16 19:44:06.906 
Epoch 316/1000 
	 loss: 2.3253, MinusLogProbMetric: 2.3253, val_loss: 2.3951, val_MinusLogProbMetric: 2.3951

Epoch 316: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3253 - MinusLogProbMetric: 2.3253 - val_loss: 2.3951 - val_MinusLogProbMetric: 2.3951 - lr: 2.5000e-04 - 64s/epoch - 326ms/step
Epoch 317/1000
2023-09-16 19:45:14.396 
Epoch 317/1000 
	 loss: 2.3247, MinusLogProbMetric: 2.3247, val_loss: 2.3948, val_MinusLogProbMetric: 2.3948

Epoch 317: val_loss did not improve from 2.39123
196/196 - 67s - loss: 2.3247 - MinusLogProbMetric: 2.3247 - val_loss: 2.3948 - val_MinusLogProbMetric: 2.3948 - lr: 2.5000e-04 - 67s/epoch - 344ms/step
Epoch 318/1000
2023-09-16 19:46:23.718 
Epoch 318/1000 
	 loss: 2.3252, MinusLogProbMetric: 2.3252, val_loss: 2.3953, val_MinusLogProbMetric: 2.3953

Epoch 318: val_loss did not improve from 2.39123
196/196 - 69s - loss: 2.3252 - MinusLogProbMetric: 2.3252 - val_loss: 2.3953 - val_MinusLogProbMetric: 2.3953 - lr: 2.5000e-04 - 69s/epoch - 354ms/step
Epoch 319/1000
2023-09-16 19:47:33.324 
Epoch 319/1000 
	 loss: 2.3244, MinusLogProbMetric: 2.3244, val_loss: 2.3960, val_MinusLogProbMetric: 2.3960

Epoch 319: val_loss did not improve from 2.39123
196/196 - 70s - loss: 2.3244 - MinusLogProbMetric: 2.3244 - val_loss: 2.3960 - val_MinusLogProbMetric: 2.3960 - lr: 2.5000e-04 - 70s/epoch - 355ms/step
Epoch 320/1000
2023-09-16 19:48:42.509 
Epoch 320/1000 
	 loss: 2.3239, MinusLogProbMetric: 2.3239, val_loss: 2.3937, val_MinusLogProbMetric: 2.3937

Epoch 320: val_loss did not improve from 2.39123
196/196 - 69s - loss: 2.3239 - MinusLogProbMetric: 2.3239 - val_loss: 2.3937 - val_MinusLogProbMetric: 2.3937 - lr: 2.5000e-04 - 69s/epoch - 353ms/step
Epoch 321/1000
2023-09-16 19:49:50.709 
Epoch 321/1000 
	 loss: 2.3245, MinusLogProbMetric: 2.3245, val_loss: 2.3943, val_MinusLogProbMetric: 2.3943

Epoch 321: val_loss did not improve from 2.39123
196/196 - 68s - loss: 2.3245 - MinusLogProbMetric: 2.3245 - val_loss: 2.3943 - val_MinusLogProbMetric: 2.3943 - lr: 2.5000e-04 - 68s/epoch - 348ms/step
Epoch 322/1000
2023-09-16 19:50:55.194 
Epoch 322/1000 
	 loss: 2.3247, MinusLogProbMetric: 2.3247, val_loss: 2.3970, val_MinusLogProbMetric: 2.3970

Epoch 322: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3247 - MinusLogProbMetric: 2.3247 - val_loss: 2.3970 - val_MinusLogProbMetric: 2.3970 - lr: 2.5000e-04 - 64s/epoch - 329ms/step
Epoch 323/1000
2023-09-16 19:52:01.169 
Epoch 323/1000 
	 loss: 2.3259, MinusLogProbMetric: 2.3259, val_loss: 2.3978, val_MinusLogProbMetric: 2.3978

Epoch 323: val_loss did not improve from 2.39123
196/196 - 66s - loss: 2.3259 - MinusLogProbMetric: 2.3259 - val_loss: 2.3978 - val_MinusLogProbMetric: 2.3978 - lr: 2.5000e-04 - 66s/epoch - 337ms/step
Epoch 324/1000
2023-09-16 19:53:07.038 
Epoch 324/1000 
	 loss: 2.3251, MinusLogProbMetric: 2.3251, val_loss: 2.3985, val_MinusLogProbMetric: 2.3985

Epoch 324: val_loss did not improve from 2.39123
196/196 - 66s - loss: 2.3251 - MinusLogProbMetric: 2.3251 - val_loss: 2.3985 - val_MinusLogProbMetric: 2.3985 - lr: 2.5000e-04 - 66s/epoch - 336ms/step
Epoch 325/1000
2023-09-16 19:54:12.008 
Epoch 325/1000 
	 loss: 2.3251, MinusLogProbMetric: 2.3251, val_loss: 2.4023, val_MinusLogProbMetric: 2.4023

Epoch 325: val_loss did not improve from 2.39123
196/196 - 65s - loss: 2.3251 - MinusLogProbMetric: 2.3251 - val_loss: 2.4023 - val_MinusLogProbMetric: 2.4023 - lr: 2.5000e-04 - 65s/epoch - 331ms/step
Epoch 326/1000
2023-09-16 19:55:16.868 
Epoch 326/1000 
	 loss: 2.3253, MinusLogProbMetric: 2.3253, val_loss: 2.4012, val_MinusLogProbMetric: 2.4012

Epoch 326: val_loss did not improve from 2.39123
196/196 - 65s - loss: 2.3253 - MinusLogProbMetric: 2.3253 - val_loss: 2.4012 - val_MinusLogProbMetric: 2.4012 - lr: 2.5000e-04 - 65s/epoch - 331ms/step
Epoch 327/1000
2023-09-16 19:56:23.825 
Epoch 327/1000 
	 loss: 2.3244, MinusLogProbMetric: 2.3244, val_loss: 2.3942, val_MinusLogProbMetric: 2.3942

Epoch 327: val_loss did not improve from 2.39123
196/196 - 67s - loss: 2.3244 - MinusLogProbMetric: 2.3244 - val_loss: 2.3942 - val_MinusLogProbMetric: 2.3942 - lr: 2.5000e-04 - 67s/epoch - 342ms/step
Epoch 328/1000
2023-09-16 19:57:30.794 
Epoch 328/1000 
	 loss: 2.3246, MinusLogProbMetric: 2.3246, val_loss: 2.3967, val_MinusLogProbMetric: 2.3967

Epoch 328: val_loss did not improve from 2.39123
196/196 - 67s - loss: 2.3246 - MinusLogProbMetric: 2.3246 - val_loss: 2.3967 - val_MinusLogProbMetric: 2.3967 - lr: 2.5000e-04 - 67s/epoch - 342ms/step
Epoch 329/1000
2023-09-16 19:58:34.302 
Epoch 329/1000 
	 loss: 2.3250, MinusLogProbMetric: 2.3250, val_loss: 2.3935, val_MinusLogProbMetric: 2.3935

Epoch 329: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3250 - MinusLogProbMetric: 2.3250 - val_loss: 2.3935 - val_MinusLogProbMetric: 2.3935 - lr: 2.5000e-04 - 64s/epoch - 324ms/step
Epoch 330/1000
2023-09-16 19:59:39.053 
Epoch 330/1000 
	 loss: 2.3245, MinusLogProbMetric: 2.3245, val_loss: 2.3964, val_MinusLogProbMetric: 2.3964

Epoch 330: val_loss did not improve from 2.39123
196/196 - 65s - loss: 2.3245 - MinusLogProbMetric: 2.3245 - val_loss: 2.3964 - val_MinusLogProbMetric: 2.3964 - lr: 2.5000e-04 - 65s/epoch - 330ms/step
Epoch 331/1000
2023-09-16 20:00:42.405 
Epoch 331/1000 
	 loss: 2.3248, MinusLogProbMetric: 2.3248, val_loss: 2.3986, val_MinusLogProbMetric: 2.3986

Epoch 331: val_loss did not improve from 2.39123
196/196 - 63s - loss: 2.3248 - MinusLogProbMetric: 2.3248 - val_loss: 2.3986 - val_MinusLogProbMetric: 2.3986 - lr: 2.5000e-04 - 63s/epoch - 323ms/step
Epoch 332/1000
2023-09-16 20:01:45.053 
Epoch 332/1000 
	 loss: 2.3244, MinusLogProbMetric: 2.3244, val_loss: 2.3955, val_MinusLogProbMetric: 2.3955

Epoch 332: val_loss did not improve from 2.39123
196/196 - 63s - loss: 2.3244 - MinusLogProbMetric: 2.3244 - val_loss: 2.3955 - val_MinusLogProbMetric: 2.3955 - lr: 2.5000e-04 - 63s/epoch - 320ms/step
Epoch 333/1000
2023-09-16 20:02:47.849 
Epoch 333/1000 
	 loss: 2.3241, MinusLogProbMetric: 2.3241, val_loss: 2.3943, val_MinusLogProbMetric: 2.3943

Epoch 333: val_loss did not improve from 2.39123
196/196 - 63s - loss: 2.3241 - MinusLogProbMetric: 2.3241 - val_loss: 2.3943 - val_MinusLogProbMetric: 2.3943 - lr: 2.5000e-04 - 63s/epoch - 320ms/step
Epoch 334/1000
2023-09-16 20:03:51.552 
Epoch 334/1000 
	 loss: 2.3243, MinusLogProbMetric: 2.3243, val_loss: 2.3967, val_MinusLogProbMetric: 2.3967

Epoch 334: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3243 - MinusLogProbMetric: 2.3243 - val_loss: 2.3967 - val_MinusLogProbMetric: 2.3967 - lr: 2.5000e-04 - 64s/epoch - 325ms/step
Epoch 335/1000
2023-09-16 20:04:58.077 
Epoch 335/1000 
	 loss: 2.3240, MinusLogProbMetric: 2.3240, val_loss: 2.3981, val_MinusLogProbMetric: 2.3981

Epoch 335: val_loss did not improve from 2.39123
196/196 - 67s - loss: 2.3240 - MinusLogProbMetric: 2.3240 - val_loss: 2.3981 - val_MinusLogProbMetric: 2.3981 - lr: 2.5000e-04 - 67s/epoch - 339ms/step
Epoch 336/1000
2023-09-16 20:06:02.045 
Epoch 336/1000 
	 loss: 2.3246, MinusLogProbMetric: 2.3246, val_loss: 2.3966, val_MinusLogProbMetric: 2.3966

Epoch 336: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3246 - MinusLogProbMetric: 2.3246 - val_loss: 2.3966 - val_MinusLogProbMetric: 2.3966 - lr: 2.5000e-04 - 64s/epoch - 326ms/step
Epoch 337/1000
2023-09-16 20:07:05.475 
Epoch 337/1000 
	 loss: 2.3252, MinusLogProbMetric: 2.3252, val_loss: 2.3966, val_MinusLogProbMetric: 2.3966

Epoch 337: val_loss did not improve from 2.39123
196/196 - 63s - loss: 2.3252 - MinusLogProbMetric: 2.3252 - val_loss: 2.3966 - val_MinusLogProbMetric: 2.3966 - lr: 2.5000e-04 - 63s/epoch - 324ms/step
Epoch 338/1000
2023-09-16 20:08:09.781 
Epoch 338/1000 
	 loss: 2.3246, MinusLogProbMetric: 2.3246, val_loss: 2.3963, val_MinusLogProbMetric: 2.3963

Epoch 338: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3246 - MinusLogProbMetric: 2.3246 - val_loss: 2.3963 - val_MinusLogProbMetric: 2.3963 - lr: 2.5000e-04 - 64s/epoch - 328ms/step
Epoch 339/1000
2023-09-16 20:09:14.281 
Epoch 339/1000 
	 loss: 2.3249, MinusLogProbMetric: 2.3249, val_loss: 2.3948, val_MinusLogProbMetric: 2.3948

Epoch 339: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3249 - MinusLogProbMetric: 2.3249 - val_loss: 2.3948 - val_MinusLogProbMetric: 2.3948 - lr: 2.5000e-04 - 64s/epoch - 329ms/step
Epoch 340/1000
2023-09-16 20:10:18.474 
Epoch 340/1000 
	 loss: 2.3264, MinusLogProbMetric: 2.3264, val_loss: 2.3958, val_MinusLogProbMetric: 2.3958

Epoch 340: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3264 - MinusLogProbMetric: 2.3264 - val_loss: 2.3958 - val_MinusLogProbMetric: 2.3958 - lr: 2.5000e-04 - 64s/epoch - 327ms/step
Epoch 341/1000
2023-09-16 20:11:23.269 
Epoch 341/1000 
	 loss: 2.3247, MinusLogProbMetric: 2.3247, val_loss: 2.3971, val_MinusLogProbMetric: 2.3971

Epoch 341: val_loss did not improve from 2.39123
196/196 - 65s - loss: 2.3247 - MinusLogProbMetric: 2.3247 - val_loss: 2.3971 - val_MinusLogProbMetric: 2.3971 - lr: 2.5000e-04 - 65s/epoch - 331ms/step
Epoch 342/1000
2023-09-16 20:12:29.660 
Epoch 342/1000 
	 loss: 2.3243, MinusLogProbMetric: 2.3243, val_loss: 2.4009, val_MinusLogProbMetric: 2.4009

Epoch 342: val_loss did not improve from 2.39123
196/196 - 66s - loss: 2.3243 - MinusLogProbMetric: 2.3243 - val_loss: 2.4009 - val_MinusLogProbMetric: 2.4009 - lr: 2.5000e-04 - 66s/epoch - 339ms/step
Epoch 343/1000
2023-09-16 20:13:33.577 
Epoch 343/1000 
	 loss: 2.3240, MinusLogProbMetric: 2.3240, val_loss: 2.3945, val_MinusLogProbMetric: 2.3945

Epoch 343: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3240 - MinusLogProbMetric: 2.3240 - val_loss: 2.3945 - val_MinusLogProbMetric: 2.3945 - lr: 2.5000e-04 - 64s/epoch - 326ms/step
Epoch 344/1000
2023-09-16 20:14:37.514 
Epoch 344/1000 
	 loss: 2.3247, MinusLogProbMetric: 2.3247, val_loss: 2.3989, val_MinusLogProbMetric: 2.3989

Epoch 344: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3247 - MinusLogProbMetric: 2.3247 - val_loss: 2.3989 - val_MinusLogProbMetric: 2.3989 - lr: 2.5000e-04 - 64s/epoch - 326ms/step
Epoch 345/1000
2023-09-16 20:15:42.500 
Epoch 345/1000 
	 loss: 2.3234, MinusLogProbMetric: 2.3234, val_loss: 2.3956, val_MinusLogProbMetric: 2.3956

Epoch 345: val_loss did not improve from 2.39123
196/196 - 65s - loss: 2.3234 - MinusLogProbMetric: 2.3234 - val_loss: 2.3956 - val_MinusLogProbMetric: 2.3956 - lr: 2.5000e-04 - 65s/epoch - 332ms/step
Epoch 346/1000
2023-09-16 20:16:46.431 
Epoch 346/1000 
	 loss: 2.3246, MinusLogProbMetric: 2.3246, val_loss: 2.3978, val_MinusLogProbMetric: 2.3978

Epoch 346: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3246 - MinusLogProbMetric: 2.3246 - val_loss: 2.3978 - val_MinusLogProbMetric: 2.3978 - lr: 2.5000e-04 - 64s/epoch - 326ms/step
Epoch 347/1000
2023-09-16 20:17:47.753 
Epoch 347/1000 
	 loss: 2.3237, MinusLogProbMetric: 2.3237, val_loss: 2.3976, val_MinusLogProbMetric: 2.3976

Epoch 347: val_loss did not improve from 2.39123
196/196 - 61s - loss: 2.3237 - MinusLogProbMetric: 2.3237 - val_loss: 2.3976 - val_MinusLogProbMetric: 2.3976 - lr: 2.5000e-04 - 61s/epoch - 313ms/step
Epoch 348/1000
2023-09-16 20:18:43.770 
Epoch 348/1000 
	 loss: 2.3247, MinusLogProbMetric: 2.3247, val_loss: 2.3993, val_MinusLogProbMetric: 2.3993

Epoch 348: val_loss did not improve from 2.39123
196/196 - 56s - loss: 2.3247 - MinusLogProbMetric: 2.3247 - val_loss: 2.3993 - val_MinusLogProbMetric: 2.3993 - lr: 2.5000e-04 - 56s/epoch - 286ms/step
Epoch 349/1000
2023-09-16 20:19:47.991 
Epoch 349/1000 
	 loss: 2.3260, MinusLogProbMetric: 2.3260, val_loss: 2.3949, val_MinusLogProbMetric: 2.3949

Epoch 349: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3260 - MinusLogProbMetric: 2.3260 - val_loss: 2.3949 - val_MinusLogProbMetric: 2.3949 - lr: 2.5000e-04 - 64s/epoch - 328ms/step
Epoch 350/1000
2023-09-16 20:20:52.034 
Epoch 350/1000 
	 loss: 2.3241, MinusLogProbMetric: 2.3241, val_loss: 2.3939, val_MinusLogProbMetric: 2.3939

Epoch 350: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3241 - MinusLogProbMetric: 2.3241 - val_loss: 2.3939 - val_MinusLogProbMetric: 2.3939 - lr: 2.5000e-04 - 64s/epoch - 327ms/step
Epoch 351/1000
2023-09-16 20:21:56.599 
Epoch 351/1000 
	 loss: 2.3236, MinusLogProbMetric: 2.3236, val_loss: 2.3969, val_MinusLogProbMetric: 2.3969

Epoch 351: val_loss did not improve from 2.39123
196/196 - 65s - loss: 2.3236 - MinusLogProbMetric: 2.3236 - val_loss: 2.3969 - val_MinusLogProbMetric: 2.3969 - lr: 2.5000e-04 - 65s/epoch - 329ms/step
Epoch 352/1000
2023-09-16 20:23:01.100 
Epoch 352/1000 
	 loss: 2.3244, MinusLogProbMetric: 2.3244, val_loss: 2.3981, val_MinusLogProbMetric: 2.3981

Epoch 352: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3244 - MinusLogProbMetric: 2.3244 - val_loss: 2.3981 - val_MinusLogProbMetric: 2.3981 - lr: 2.5000e-04 - 64s/epoch - 329ms/step
Epoch 353/1000
2023-09-16 20:24:04.656 
Epoch 353/1000 
	 loss: 2.3262, MinusLogProbMetric: 2.3262, val_loss: 2.3954, val_MinusLogProbMetric: 2.3954

Epoch 353: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3262 - MinusLogProbMetric: 2.3262 - val_loss: 2.3954 - val_MinusLogProbMetric: 2.3954 - lr: 2.5000e-04 - 64s/epoch - 324ms/step
Epoch 354/1000
2023-09-16 20:25:08.857 
Epoch 354/1000 
	 loss: 2.3235, MinusLogProbMetric: 2.3235, val_loss: 2.3955, val_MinusLogProbMetric: 2.3955

Epoch 354: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3235 - MinusLogProbMetric: 2.3235 - val_loss: 2.3955 - val_MinusLogProbMetric: 2.3955 - lr: 2.5000e-04 - 64s/epoch - 328ms/step
Epoch 355/1000
2023-09-16 20:26:13.522 
Epoch 355/1000 
	 loss: 2.3195, MinusLogProbMetric: 2.3195, val_loss: 2.3953, val_MinusLogProbMetric: 2.3953

Epoch 355: val_loss did not improve from 2.39123
196/196 - 65s - loss: 2.3195 - MinusLogProbMetric: 2.3195 - val_loss: 2.3953 - val_MinusLogProbMetric: 2.3953 - lr: 1.2500e-04 - 65s/epoch - 330ms/step
Epoch 356/1000
2023-09-16 20:27:19.447 
Epoch 356/1000 
	 loss: 2.3186, MinusLogProbMetric: 2.3186, val_loss: 2.3939, val_MinusLogProbMetric: 2.3939

Epoch 356: val_loss did not improve from 2.39123
196/196 - 66s - loss: 2.3186 - MinusLogProbMetric: 2.3186 - val_loss: 2.3939 - val_MinusLogProbMetric: 2.3939 - lr: 1.2500e-04 - 66s/epoch - 336ms/step
Epoch 357/1000
2023-09-16 20:28:23.172 
Epoch 357/1000 
	 loss: 2.3191, MinusLogProbMetric: 2.3191, val_loss: 2.3939, val_MinusLogProbMetric: 2.3939

Epoch 357: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3191 - MinusLogProbMetric: 2.3191 - val_loss: 2.3939 - val_MinusLogProbMetric: 2.3939 - lr: 1.2500e-04 - 64s/epoch - 325ms/step
Epoch 358/1000
2023-09-16 20:29:27.579 
Epoch 358/1000 
	 loss: 2.3182, MinusLogProbMetric: 2.3182, val_loss: 2.3940, val_MinusLogProbMetric: 2.3940

Epoch 358: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3182 - MinusLogProbMetric: 2.3182 - val_loss: 2.3940 - val_MinusLogProbMetric: 2.3940 - lr: 1.2500e-04 - 64s/epoch - 329ms/step
Epoch 359/1000
2023-09-16 20:30:31.809 
Epoch 359/1000 
	 loss: 2.3183, MinusLogProbMetric: 2.3183, val_loss: 2.3963, val_MinusLogProbMetric: 2.3963

Epoch 359: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3183 - MinusLogProbMetric: 2.3183 - val_loss: 2.3963 - val_MinusLogProbMetric: 2.3963 - lr: 1.2500e-04 - 64s/epoch - 328ms/step
Epoch 360/1000
2023-09-16 20:31:36.167 
Epoch 360/1000 
	 loss: 2.3182, MinusLogProbMetric: 2.3182, val_loss: 2.3961, val_MinusLogProbMetric: 2.3961

Epoch 360: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3182 - MinusLogProbMetric: 2.3182 - val_loss: 2.3961 - val_MinusLogProbMetric: 2.3961 - lr: 1.2500e-04 - 64s/epoch - 328ms/step
Epoch 361/1000
2023-09-16 20:32:39.924 
Epoch 361/1000 
	 loss: 2.3185, MinusLogProbMetric: 2.3185, val_loss: 2.3956, val_MinusLogProbMetric: 2.3956

Epoch 361: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3185 - MinusLogProbMetric: 2.3185 - val_loss: 2.3956 - val_MinusLogProbMetric: 2.3956 - lr: 1.2500e-04 - 64s/epoch - 325ms/step
Epoch 362/1000
2023-09-16 20:33:43.150 
Epoch 362/1000 
	 loss: 2.3184, MinusLogProbMetric: 2.3184, val_loss: 2.3953, val_MinusLogProbMetric: 2.3953

Epoch 362: val_loss did not improve from 2.39123
196/196 - 63s - loss: 2.3184 - MinusLogProbMetric: 2.3184 - val_loss: 2.3953 - val_MinusLogProbMetric: 2.3953 - lr: 1.2500e-04 - 63s/epoch - 323ms/step
Epoch 363/1000
2023-09-16 20:34:46.458 
Epoch 363/1000 
	 loss: 2.3178, MinusLogProbMetric: 2.3178, val_loss: 2.3959, val_MinusLogProbMetric: 2.3959

Epoch 363: val_loss did not improve from 2.39123
196/196 - 63s - loss: 2.3178 - MinusLogProbMetric: 2.3178 - val_loss: 2.3959 - val_MinusLogProbMetric: 2.3959 - lr: 1.2500e-04 - 63s/epoch - 323ms/step
Epoch 364/1000
2023-09-16 20:35:48.842 
Epoch 364/1000 
	 loss: 2.3181, MinusLogProbMetric: 2.3181, val_loss: 2.3970, val_MinusLogProbMetric: 2.3970

Epoch 364: val_loss did not improve from 2.39123
196/196 - 62s - loss: 2.3181 - MinusLogProbMetric: 2.3181 - val_loss: 2.3970 - val_MinusLogProbMetric: 2.3970 - lr: 1.2500e-04 - 62s/epoch - 318ms/step
Epoch 365/1000
2023-09-16 20:36:51.046 
Epoch 365/1000 
	 loss: 2.3182, MinusLogProbMetric: 2.3182, val_loss: 2.3952, val_MinusLogProbMetric: 2.3952

Epoch 365: val_loss did not improve from 2.39123
196/196 - 62s - loss: 2.3182 - MinusLogProbMetric: 2.3182 - val_loss: 2.3952 - val_MinusLogProbMetric: 2.3952 - lr: 1.2500e-04 - 62s/epoch - 317ms/step
Epoch 366/1000
2023-09-16 20:37:52.820 
Epoch 366/1000 
	 loss: 2.3183, MinusLogProbMetric: 2.3183, val_loss: 2.3954, val_MinusLogProbMetric: 2.3954

Epoch 366: val_loss did not improve from 2.39123
196/196 - 62s - loss: 2.3183 - MinusLogProbMetric: 2.3183 - val_loss: 2.3954 - val_MinusLogProbMetric: 2.3954 - lr: 1.2500e-04 - 62s/epoch - 315ms/step
Epoch 367/1000
2023-09-16 20:38:54.957 
Epoch 367/1000 
	 loss: 2.3186, MinusLogProbMetric: 2.3186, val_loss: 2.3963, val_MinusLogProbMetric: 2.3963

Epoch 367: val_loss did not improve from 2.39123
196/196 - 62s - loss: 2.3186 - MinusLogProbMetric: 2.3186 - val_loss: 2.3963 - val_MinusLogProbMetric: 2.3963 - lr: 1.2500e-04 - 62s/epoch - 317ms/step
Epoch 368/1000
2023-09-16 20:39:57.440 
Epoch 368/1000 
	 loss: 2.3178, MinusLogProbMetric: 2.3178, val_loss: 2.3973, val_MinusLogProbMetric: 2.3973

Epoch 368: val_loss did not improve from 2.39123
196/196 - 62s - loss: 2.3178 - MinusLogProbMetric: 2.3178 - val_loss: 2.3973 - val_MinusLogProbMetric: 2.3973 - lr: 1.2500e-04 - 62s/epoch - 319ms/step
Epoch 369/1000
2023-09-16 20:41:00.087 
Epoch 369/1000 
	 loss: 2.3188, MinusLogProbMetric: 2.3188, val_loss: 2.3962, val_MinusLogProbMetric: 2.3962

Epoch 369: val_loss did not improve from 2.39123
196/196 - 63s - loss: 2.3188 - MinusLogProbMetric: 2.3188 - val_loss: 2.3962 - val_MinusLogProbMetric: 2.3962 - lr: 1.2500e-04 - 63s/epoch - 320ms/step
Epoch 370/1000
2023-09-16 20:42:03.475 
Epoch 370/1000 
	 loss: 2.3181, MinusLogProbMetric: 2.3181, val_loss: 2.3945, val_MinusLogProbMetric: 2.3945

Epoch 370: val_loss did not improve from 2.39123
196/196 - 63s - loss: 2.3181 - MinusLogProbMetric: 2.3181 - val_loss: 2.3945 - val_MinusLogProbMetric: 2.3945 - lr: 1.2500e-04 - 63s/epoch - 323ms/step
Epoch 371/1000
2023-09-16 20:43:05.776 
Epoch 371/1000 
	 loss: 2.3182, MinusLogProbMetric: 2.3182, val_loss: 2.3965, val_MinusLogProbMetric: 2.3965

Epoch 371: val_loss did not improve from 2.39123
196/196 - 62s - loss: 2.3182 - MinusLogProbMetric: 2.3182 - val_loss: 2.3965 - val_MinusLogProbMetric: 2.3965 - lr: 1.2500e-04 - 62s/epoch - 318ms/step
Epoch 372/1000
2023-09-16 20:44:08.921 
Epoch 372/1000 
	 loss: 2.3183, MinusLogProbMetric: 2.3183, val_loss: 2.3957, val_MinusLogProbMetric: 2.3957

Epoch 372: val_loss did not improve from 2.39123
196/196 - 63s - loss: 2.3183 - MinusLogProbMetric: 2.3183 - val_loss: 2.3957 - val_MinusLogProbMetric: 2.3957 - lr: 1.2500e-04 - 63s/epoch - 322ms/step
Epoch 373/1000
2023-09-16 20:45:12.924 
Epoch 373/1000 
	 loss: 2.3187, MinusLogProbMetric: 2.3187, val_loss: 2.3958, val_MinusLogProbMetric: 2.3958

Epoch 373: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3187 - MinusLogProbMetric: 2.3187 - val_loss: 2.3958 - val_MinusLogProbMetric: 2.3958 - lr: 1.2500e-04 - 64s/epoch - 327ms/step
Epoch 374/1000
2023-09-16 20:46:15.723 
Epoch 374/1000 
	 loss: 2.3177, MinusLogProbMetric: 2.3177, val_loss: 2.3950, val_MinusLogProbMetric: 2.3950

Epoch 374: val_loss did not improve from 2.39123
196/196 - 63s - loss: 2.3177 - MinusLogProbMetric: 2.3177 - val_loss: 2.3950 - val_MinusLogProbMetric: 2.3950 - lr: 1.2500e-04 - 63s/epoch - 320ms/step
Epoch 375/1000
2023-09-16 20:47:19.065 
Epoch 375/1000 
	 loss: 2.3169, MinusLogProbMetric: 2.3169, val_loss: 2.3956, val_MinusLogProbMetric: 2.3956

Epoch 375: val_loss did not improve from 2.39123
196/196 - 63s - loss: 2.3169 - MinusLogProbMetric: 2.3169 - val_loss: 2.3956 - val_MinusLogProbMetric: 2.3956 - lr: 1.2500e-04 - 63s/epoch - 323ms/step
Epoch 376/1000
2023-09-16 20:48:21.853 
Epoch 376/1000 
	 loss: 2.3182, MinusLogProbMetric: 2.3182, val_loss: 2.3948, val_MinusLogProbMetric: 2.3948

Epoch 376: val_loss did not improve from 2.39123
196/196 - 63s - loss: 2.3182 - MinusLogProbMetric: 2.3182 - val_loss: 2.3948 - val_MinusLogProbMetric: 2.3948 - lr: 1.2500e-04 - 63s/epoch - 320ms/step
Epoch 377/1000
2023-09-16 20:49:14.259 
Epoch 377/1000 
	 loss: 2.3181, MinusLogProbMetric: 2.3181, val_loss: 2.3944, val_MinusLogProbMetric: 2.3944

Epoch 377: val_loss did not improve from 2.39123
196/196 - 52s - loss: 2.3181 - MinusLogProbMetric: 2.3181 - val_loss: 2.3944 - val_MinusLogProbMetric: 2.3944 - lr: 1.2500e-04 - 52s/epoch - 267ms/step
Epoch 378/1000
2023-09-16 20:50:07.966 
Epoch 378/1000 
	 loss: 2.3180, MinusLogProbMetric: 2.3180, val_loss: 2.3944, val_MinusLogProbMetric: 2.3944

Epoch 378: val_loss did not improve from 2.39123
196/196 - 54s - loss: 2.3180 - MinusLogProbMetric: 2.3180 - val_loss: 2.3944 - val_MinusLogProbMetric: 2.3944 - lr: 1.2500e-04 - 54s/epoch - 274ms/step
Epoch 379/1000
2023-09-16 20:51:09.298 
Epoch 379/1000 
	 loss: 2.3184, MinusLogProbMetric: 2.3184, val_loss: 2.3958, val_MinusLogProbMetric: 2.3958

Epoch 379: val_loss did not improve from 2.39123
196/196 - 61s - loss: 2.3184 - MinusLogProbMetric: 2.3184 - val_loss: 2.3958 - val_MinusLogProbMetric: 2.3958 - lr: 1.2500e-04 - 61s/epoch - 313ms/step
Epoch 380/1000
2023-09-16 20:52:12.315 
Epoch 380/1000 
	 loss: 2.3177, MinusLogProbMetric: 2.3177, val_loss: 2.3973, val_MinusLogProbMetric: 2.3973

Epoch 380: val_loss did not improve from 2.39123
196/196 - 63s - loss: 2.3177 - MinusLogProbMetric: 2.3177 - val_loss: 2.3973 - val_MinusLogProbMetric: 2.3973 - lr: 1.2500e-04 - 63s/epoch - 322ms/step
Epoch 381/1000
2023-09-16 20:53:14.917 
Epoch 381/1000 
	 loss: 2.3180, MinusLogProbMetric: 2.3180, val_loss: 2.3975, val_MinusLogProbMetric: 2.3975

Epoch 381: val_loss did not improve from 2.39123
196/196 - 63s - loss: 2.3180 - MinusLogProbMetric: 2.3180 - val_loss: 2.3975 - val_MinusLogProbMetric: 2.3975 - lr: 1.2500e-04 - 63s/epoch - 319ms/step
Epoch 382/1000
2023-09-16 20:54:17.587 
Epoch 382/1000 
	 loss: 2.3183, MinusLogProbMetric: 2.3183, val_loss: 2.3951, val_MinusLogProbMetric: 2.3951

Epoch 382: val_loss did not improve from 2.39123
196/196 - 63s - loss: 2.3183 - MinusLogProbMetric: 2.3183 - val_loss: 2.3951 - val_MinusLogProbMetric: 2.3951 - lr: 1.2500e-04 - 63s/epoch - 320ms/step
Epoch 383/1000
2023-09-16 20:55:20.339 
Epoch 383/1000 
	 loss: 2.3173, MinusLogProbMetric: 2.3173, val_loss: 2.3952, val_MinusLogProbMetric: 2.3952

Epoch 383: val_loss did not improve from 2.39123
196/196 - 63s - loss: 2.3173 - MinusLogProbMetric: 2.3173 - val_loss: 2.3952 - val_MinusLogProbMetric: 2.3952 - lr: 1.2500e-04 - 63s/epoch - 320ms/step
Epoch 384/1000
2023-09-16 20:56:23.881 
Epoch 384/1000 
	 loss: 2.3176, MinusLogProbMetric: 2.3176, val_loss: 2.3965, val_MinusLogProbMetric: 2.3965

Epoch 384: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3176 - MinusLogProbMetric: 2.3176 - val_loss: 2.3965 - val_MinusLogProbMetric: 2.3965 - lr: 1.2500e-04 - 64s/epoch - 324ms/step
Epoch 385/1000
2023-09-16 20:57:27.792 
Epoch 385/1000 
	 loss: 2.3173, MinusLogProbMetric: 2.3173, val_loss: 2.3954, val_MinusLogProbMetric: 2.3954

Epoch 385: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3173 - MinusLogProbMetric: 2.3173 - val_loss: 2.3954 - val_MinusLogProbMetric: 2.3954 - lr: 1.2500e-04 - 64s/epoch - 326ms/step
Epoch 386/1000
2023-09-16 20:58:30.595 
Epoch 386/1000 
	 loss: 2.3174, MinusLogProbMetric: 2.3174, val_loss: 2.3987, val_MinusLogProbMetric: 2.3987

Epoch 386: val_loss did not improve from 2.39123
196/196 - 63s - loss: 2.3174 - MinusLogProbMetric: 2.3174 - val_loss: 2.3987 - val_MinusLogProbMetric: 2.3987 - lr: 1.2500e-04 - 63s/epoch - 320ms/step
Epoch 387/1000
2023-09-16 20:59:34.419 
Epoch 387/1000 
	 loss: 2.3172, MinusLogProbMetric: 2.3172, val_loss: 2.3956, val_MinusLogProbMetric: 2.3956

Epoch 387: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3172 - MinusLogProbMetric: 2.3172 - val_loss: 2.3956 - val_MinusLogProbMetric: 2.3956 - lr: 1.2500e-04 - 64s/epoch - 326ms/step
Epoch 388/1000
2023-09-16 21:00:38.108 
Epoch 388/1000 
	 loss: 2.3173, MinusLogProbMetric: 2.3173, val_loss: 2.3971, val_MinusLogProbMetric: 2.3971

Epoch 388: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3173 - MinusLogProbMetric: 2.3173 - val_loss: 2.3971 - val_MinusLogProbMetric: 2.3971 - lr: 1.2500e-04 - 64s/epoch - 325ms/step
Epoch 389/1000
2023-09-16 21:01:41.549 
Epoch 389/1000 
	 loss: 2.3172, MinusLogProbMetric: 2.3172, val_loss: 2.3956, val_MinusLogProbMetric: 2.3956

Epoch 389: val_loss did not improve from 2.39123
196/196 - 63s - loss: 2.3172 - MinusLogProbMetric: 2.3172 - val_loss: 2.3956 - val_MinusLogProbMetric: 2.3956 - lr: 1.2500e-04 - 63s/epoch - 324ms/step
Epoch 390/1000
2023-09-16 21:02:45.078 
Epoch 390/1000 
	 loss: 2.3173, MinusLogProbMetric: 2.3173, val_loss: 2.3952, val_MinusLogProbMetric: 2.3952

Epoch 390: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3173 - MinusLogProbMetric: 2.3173 - val_loss: 2.3952 - val_MinusLogProbMetric: 2.3952 - lr: 1.2500e-04 - 64s/epoch - 324ms/step
Epoch 391/1000
2023-09-16 21:03:49.738 
Epoch 391/1000 
	 loss: 2.3175, MinusLogProbMetric: 2.3175, val_loss: 2.3993, val_MinusLogProbMetric: 2.3993

Epoch 391: val_loss did not improve from 2.39123
196/196 - 65s - loss: 2.3175 - MinusLogProbMetric: 2.3175 - val_loss: 2.3993 - val_MinusLogProbMetric: 2.3993 - lr: 1.2500e-04 - 65s/epoch - 330ms/step
Epoch 392/1000
2023-09-16 21:04:54.000 
Epoch 392/1000 
	 loss: 2.3178, MinusLogProbMetric: 2.3178, val_loss: 2.3966, val_MinusLogProbMetric: 2.3966

Epoch 392: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3178 - MinusLogProbMetric: 2.3178 - val_loss: 2.3966 - val_MinusLogProbMetric: 2.3966 - lr: 1.2500e-04 - 64s/epoch - 328ms/step
Epoch 393/1000
2023-09-16 21:05:58.695 
Epoch 393/1000 
	 loss: 2.3170, MinusLogProbMetric: 2.3170, val_loss: 2.3963, val_MinusLogProbMetric: 2.3963

Epoch 393: val_loss did not improve from 2.39123
196/196 - 65s - loss: 2.3170 - MinusLogProbMetric: 2.3170 - val_loss: 2.3963 - val_MinusLogProbMetric: 2.3963 - lr: 1.2500e-04 - 65s/epoch - 330ms/step
Epoch 394/1000
2023-09-16 21:07:03.076 
Epoch 394/1000 
	 loss: 2.3171, MinusLogProbMetric: 2.3171, val_loss: 2.3977, val_MinusLogProbMetric: 2.3977

Epoch 394: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3171 - MinusLogProbMetric: 2.3171 - val_loss: 2.3977 - val_MinusLogProbMetric: 2.3977 - lr: 1.2500e-04 - 64s/epoch - 328ms/step
Epoch 395/1000
2023-09-16 21:08:07.421 
Epoch 395/1000 
	 loss: 2.3173, MinusLogProbMetric: 2.3173, val_loss: 2.3987, val_MinusLogProbMetric: 2.3987

Epoch 395: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3173 - MinusLogProbMetric: 2.3173 - val_loss: 2.3987 - val_MinusLogProbMetric: 2.3987 - lr: 1.2500e-04 - 64s/epoch - 328ms/step
Epoch 396/1000
2023-09-16 21:09:12.622 
Epoch 396/1000 
	 loss: 2.3178, MinusLogProbMetric: 2.3178, val_loss: 2.3976, val_MinusLogProbMetric: 2.3976

Epoch 396: val_loss did not improve from 2.39123
196/196 - 65s - loss: 2.3178 - MinusLogProbMetric: 2.3178 - val_loss: 2.3976 - val_MinusLogProbMetric: 2.3976 - lr: 1.2500e-04 - 65s/epoch - 333ms/step
Epoch 397/1000
2023-09-16 21:10:17.788 
Epoch 397/1000 
	 loss: 2.3177, MinusLogProbMetric: 2.3177, val_loss: 2.3955, val_MinusLogProbMetric: 2.3955

Epoch 397: val_loss did not improve from 2.39123
196/196 - 65s - loss: 2.3177 - MinusLogProbMetric: 2.3177 - val_loss: 2.3955 - val_MinusLogProbMetric: 2.3955 - lr: 1.2500e-04 - 65s/epoch - 332ms/step
Epoch 398/1000
2023-09-16 21:11:22.594 
Epoch 398/1000 
	 loss: 2.3178, MinusLogProbMetric: 2.3178, val_loss: 2.3959, val_MinusLogProbMetric: 2.3959

Epoch 398: val_loss did not improve from 2.39123
196/196 - 65s - loss: 2.3178 - MinusLogProbMetric: 2.3178 - val_loss: 2.3959 - val_MinusLogProbMetric: 2.3959 - lr: 1.2500e-04 - 65s/epoch - 331ms/step
Epoch 399/1000
2023-09-16 21:12:28.086 
Epoch 399/1000 
	 loss: 2.3170, MinusLogProbMetric: 2.3170, val_loss: 2.3956, val_MinusLogProbMetric: 2.3956

Epoch 399: val_loss did not improve from 2.39123
196/196 - 65s - loss: 2.3170 - MinusLogProbMetric: 2.3170 - val_loss: 2.3956 - val_MinusLogProbMetric: 2.3956 - lr: 1.2500e-04 - 65s/epoch - 334ms/step
Epoch 400/1000
2023-09-16 21:13:33.270 
Epoch 400/1000 
	 loss: 2.3168, MinusLogProbMetric: 2.3168, val_loss: 2.3963, val_MinusLogProbMetric: 2.3963

Epoch 400: val_loss did not improve from 2.39123
196/196 - 65s - loss: 2.3168 - MinusLogProbMetric: 2.3168 - val_loss: 2.3963 - val_MinusLogProbMetric: 2.3963 - lr: 1.2500e-04 - 65s/epoch - 333ms/step
Epoch 401/1000
2023-09-16 21:14:37.999 
Epoch 401/1000 
	 loss: 2.3172, MinusLogProbMetric: 2.3172, val_loss: 2.3962, val_MinusLogProbMetric: 2.3962

Epoch 401: val_loss did not improve from 2.39123
196/196 - 65s - loss: 2.3172 - MinusLogProbMetric: 2.3172 - val_loss: 2.3962 - val_MinusLogProbMetric: 2.3962 - lr: 1.2500e-04 - 65s/epoch - 330ms/step
Epoch 402/1000
2023-09-16 21:15:42.771 
Epoch 402/1000 
	 loss: 2.3179, MinusLogProbMetric: 2.3179, val_loss: 2.3991, val_MinusLogProbMetric: 2.3991

Epoch 402: val_loss did not improve from 2.39123
196/196 - 65s - loss: 2.3179 - MinusLogProbMetric: 2.3179 - val_loss: 2.3991 - val_MinusLogProbMetric: 2.3991 - lr: 1.2500e-04 - 65s/epoch - 330ms/step
Epoch 403/1000
2023-09-16 21:16:46.675 
Epoch 403/1000 
	 loss: 2.3168, MinusLogProbMetric: 2.3168, val_loss: 2.3970, val_MinusLogProbMetric: 2.3970

Epoch 403: val_loss did not improve from 2.39123
196/196 - 64s - loss: 2.3168 - MinusLogProbMetric: 2.3168 - val_loss: 2.3970 - val_MinusLogProbMetric: 2.3970 - lr: 1.2500e-04 - 64s/epoch - 326ms/step
Epoch 404/1000
2023-09-16 21:17:42.570 
Epoch 404/1000 
	 loss: 2.3171, MinusLogProbMetric: 2.3171, val_loss: 2.3964, val_MinusLogProbMetric: 2.3964

Epoch 404: val_loss did not improve from 2.39123
Restoring model weights from the end of the best epoch: 304.
196/196 - 56s - loss: 2.3171 - MinusLogProbMetric: 2.3171 - val_loss: 2.3964 - val_MinusLogProbMetric: 2.3964 - lr: 1.2500e-04 - 56s/epoch - 288ms/step
Epoch 404: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 20.577074625063688 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 9.176428890088573 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 6.953318350948393 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fb1dc759ab0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 34.309753781184554 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 10.675984897883609 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 8.826443772995844 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fb6965d11b0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 933.
Model trained in 25877.03 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

Plots done in 2.93 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 124.24 s.
===========
Run 78/720 done in 26009.92 s.
===========

Directory ../../results/CsplineN_new/run_79/ already exists.
Skipping it.
===========
Run 79/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_80/ already exists.
Skipping it.
===========
Run 80/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_81/ already exists.
Skipping it.
===========
Run 81/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_82/ already exists.
Skipping it.
===========
Run 82/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_83/ already exists.
Skipping it.
===========
Run 83/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_84/ already exists.
Skipping it.
===========
Run 84/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_85/ already exists.
Skipping it.
===========
Run 85/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_86/ already exists.
Skipping it.
===========
Run 86/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_87/ already exists.
Skipping it.
===========
Run 87/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_88/ already exists.
Skipping it.
===========
Run 88/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_89/ already exists.
Skipping it.
===========
Run 89/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_90/ already exists.
Skipping it.
===========
Run 90/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_91/ already exists.
Skipping it.
===========
Run 91/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_92/ already exists.
Skipping it.
===========
Run 92/720 already exists. Skipping it.
===========

===========
Generating train data for run 93.
===========
Train data generated in 0.13 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 8)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_93/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 187}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_93/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 9.254465  ,  3.1223931 ,  7.9368167 , ..., 10.395914  ,
        -0.08702636,  0.6943853 ],
       [ 0.26058534,  8.442333  ,  8.423006  , ...,  8.0570345 ,
         4.5869675 ,  7.9426966 ],
       [ 5.4172125 ,  6.227207  ,  5.7839417 , ...,  6.0398493 ,
         4.041137  ,  8.88386   ],
       ...,
       [10.37041   ,  3.1324084 ,  7.9367023 , ..., 10.270834  ,
        -0.6690038 ,  1.66524   ],
       [ 0.54079515,  8.789834  ,  7.020314  , ...,  8.154197  ,
         4.581874  ,  7.754122  ],
       [ 5.4191546 ,  6.604123  ,  5.5508165 , ...,  7.0494995 ,
         3.9102433 ,  8.995361  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_93/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_93
self.data_kwargs: {'seed': 187}
self.x_data: [[ 4.8629886e-01  8.1342735e+00  7.7527704e+00 ...  8.4884710e+00
   5.0437560e+00  7.9026518e+00]
 [ 9.6937618e+00  4.3710842e+00  7.9162822e+00 ...  9.2179098e+00
   1.7197957e+00  1.4433438e-01]
 [ 9.9820375e+00  4.4276152e+00  7.9205709e+00 ...  8.2881136e+00
   9.8332351e-01  9.4699204e-02]
 ...
 [ 8.9955826e+00  3.4959929e+00  7.9108043e+00 ...  9.5866652e+00
   1.0308118e+00 -1.7110687e-01]
 [-8.8769197e-03  8.8605108e+00  7.0928335e+00 ...  8.1833010e+00
   4.6313362e+00  7.9553847e+00]
 [ 9.2109098e+00  4.5829487e+00  7.9332881e+00 ...  9.8095055e+00
   1.0140632e+00  1.1891223e+00]]
self.y_data: []
self.ndims: 8
Model defined.
Model: "model_65"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_66 (InputLayer)       [(None, 8)]               0         
                                                                 
 log_prob_layer_5 (LogProbLa  (None,)                  455320    
 yer)                                                            
                                                                 
=================================================================
Total params: 455,320
Trainable params: 455,320
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_5/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_5'")
self.model: <keras.engine.functional.Functional object at 0x7faee44fd690>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7faed4173f40>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7faed4173f40>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7faec4770a60>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7faf8c14cf10>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7faf8c14d0c0>, <keras.callbacks.ModelCheckpoint object at 0x7faf8c14eb30>, <keras.callbacks.EarlyStopping object at 0x7faf8c14d0f0>, <keras.callbacks.ReduceLROnPlateau object at 0x7faf8c14d7b0>, <keras.callbacks.TerminateOnNaN object at 0x7faf8c14c8e0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 9.254465  ,  3.1223931 ,  7.9368167 , ..., 10.395914  ,
        -0.08702636,  0.6943853 ],
       [ 0.26058534,  8.442333  ,  8.423006  , ...,  8.0570345 ,
         4.5869675 ,  7.9426966 ],
       [ 5.4172125 ,  6.227207  ,  5.7839417 , ...,  6.0398493 ,
         4.041137  ,  8.88386   ],
       ...,
       [10.37041   ,  3.1324084 ,  7.9367023 , ..., 10.270834  ,
        -0.6690038 ,  1.66524   ],
       [ 0.54079515,  8.789834  ,  7.020314  , ...,  8.154197  ,
         4.581874  ,  7.754122  ],
       [ 5.4191546 ,  6.604123  ,  5.5508165 , ...,  7.0494995 ,
         3.9102433 ,  8.995361  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_93/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 93/720 with hyperparameters:
timestamp = 2023-09-16 21:19:56.576862
ndims = 8
seed_train = 187
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 8
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 455320
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 0.48629886  8.134274    7.7527704   8.691655   10.482439    8.488471
  5.043756    7.902652  ]
Epoch 1/1000
2023-09-16 21:24:00.730 
Epoch 1/1000 
	 loss: 14.7161, MinusLogProbMetric: 14.7161, val_loss: 6.5300, val_MinusLogProbMetric: 6.5300

Epoch 1: val_loss improved from inf to 6.52999, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 245s - loss: 14.7161 - MinusLogProbMetric: 14.7161 - val_loss: 6.5300 - val_MinusLogProbMetric: 6.5300 - lr: 0.0010 - 245s/epoch - 1s/step
Epoch 2/1000
2023-09-16 21:25:08.765 
Epoch 2/1000 
	 loss: 6.5151, MinusLogProbMetric: 6.5151, val_loss: 5.6483, val_MinusLogProbMetric: 5.6483

Epoch 2: val_loss improved from 6.52999 to 5.64835, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 68s - loss: 6.5151 - MinusLogProbMetric: 6.5151 - val_loss: 5.6483 - val_MinusLogProbMetric: 5.6483 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 3/1000
2023-09-16 21:26:15.818 
Epoch 3/1000 
	 loss: 5.6454, MinusLogProbMetric: 5.6454, val_loss: 5.0228, val_MinusLogProbMetric: 5.0228

Epoch 3: val_loss improved from 5.64835 to 5.02284, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 67s - loss: 5.6454 - MinusLogProbMetric: 5.6454 - val_loss: 5.0228 - val_MinusLogProbMetric: 5.0228 - lr: 0.0010 - 67s/epoch - 342ms/step
Epoch 4/1000
2023-09-16 21:27:22.886 
Epoch 4/1000 
	 loss: 5.3871, MinusLogProbMetric: 5.3871, val_loss: 5.2551, val_MinusLogProbMetric: 5.2551

Epoch 4: val_loss did not improve from 5.02284
196/196 - 66s - loss: 5.3871 - MinusLogProbMetric: 5.3871 - val_loss: 5.2551 - val_MinusLogProbMetric: 5.2551 - lr: 0.0010 - 66s/epoch - 337ms/step
Epoch 5/1000
2023-09-16 21:28:29.161 
Epoch 5/1000 
	 loss: 5.4619, MinusLogProbMetric: 5.4619, val_loss: 5.9675, val_MinusLogProbMetric: 5.9675

Epoch 5: val_loss did not improve from 5.02284
196/196 - 66s - loss: 5.4619 - MinusLogProbMetric: 5.4619 - val_loss: 5.9675 - val_MinusLogProbMetric: 5.9675 - lr: 0.0010 - 66s/epoch - 338ms/step
Epoch 6/1000
2023-09-16 21:29:35.194 
Epoch 6/1000 
	 loss: 5.1518, MinusLogProbMetric: 5.1518, val_loss: 5.0565, val_MinusLogProbMetric: 5.0565

Epoch 6: val_loss did not improve from 5.02284
196/196 - 66s - loss: 5.1518 - MinusLogProbMetric: 5.1518 - val_loss: 5.0565 - val_MinusLogProbMetric: 5.0565 - lr: 0.0010 - 66s/epoch - 337ms/step
Epoch 7/1000
2023-09-16 21:30:34.369 
Epoch 7/1000 
	 loss: 5.0869, MinusLogProbMetric: 5.0869, val_loss: 5.4066, val_MinusLogProbMetric: 5.4066

Epoch 7: val_loss did not improve from 5.02284
196/196 - 59s - loss: 5.0869 - MinusLogProbMetric: 5.0869 - val_loss: 5.4066 - val_MinusLogProbMetric: 5.4066 - lr: 0.0010 - 59s/epoch - 302ms/step
Epoch 8/1000
2023-09-16 21:31:35.093 
Epoch 8/1000 
	 loss: 4.9430, MinusLogProbMetric: 4.9430, val_loss: 4.9004, val_MinusLogProbMetric: 4.9004

Epoch 8: val_loss improved from 5.02284 to 4.90038, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 62s - loss: 4.9430 - MinusLogProbMetric: 4.9430 - val_loss: 4.9004 - val_MinusLogProbMetric: 4.9004 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 9/1000
2023-09-16 21:32:43.375 
Epoch 9/1000 
	 loss: 4.8678, MinusLogProbMetric: 4.8678, val_loss: 4.7127, val_MinusLogProbMetric: 4.7127

Epoch 9: val_loss improved from 4.90038 to 4.71273, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 68s - loss: 4.8678 - MinusLogProbMetric: 4.8678 - val_loss: 4.7127 - val_MinusLogProbMetric: 4.7127 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 10/1000
2023-09-16 21:33:47.308 
Epoch 10/1000 
	 loss: 4.8443, MinusLogProbMetric: 4.8443, val_loss: 4.8423, val_MinusLogProbMetric: 4.8423

Epoch 10: val_loss did not improve from 4.71273
196/196 - 63s - loss: 4.8443 - MinusLogProbMetric: 4.8443 - val_loss: 4.8423 - val_MinusLogProbMetric: 4.8423 - lr: 0.0010 - 63s/epoch - 322ms/step
Epoch 11/1000
2023-09-16 21:34:53.942 
Epoch 11/1000 
	 loss: 4.7964, MinusLogProbMetric: 4.7964, val_loss: 4.8893, val_MinusLogProbMetric: 4.8893

Epoch 11: val_loss did not improve from 4.71273
196/196 - 67s - loss: 4.7964 - MinusLogProbMetric: 4.7964 - val_loss: 4.8893 - val_MinusLogProbMetric: 4.8893 - lr: 0.0010 - 67s/epoch - 340ms/step
Epoch 12/1000
2023-09-16 21:35:59.463 
Epoch 12/1000 
	 loss: 4.7793, MinusLogProbMetric: 4.7793, val_loss: 4.6340, val_MinusLogProbMetric: 4.6340

Epoch 12: val_loss improved from 4.71273 to 4.63400, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 66s - loss: 4.7793 - MinusLogProbMetric: 4.7793 - val_loss: 4.6340 - val_MinusLogProbMetric: 4.6340 - lr: 0.0010 - 66s/epoch - 339ms/step
Epoch 13/1000
2023-09-16 21:37:06.254 
Epoch 13/1000 
	 loss: 4.7424, MinusLogProbMetric: 4.7424, val_loss: 4.6204, val_MinusLogProbMetric: 4.6204

Epoch 13: val_loss improved from 4.63400 to 4.62036, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 67s - loss: 4.7424 - MinusLogProbMetric: 4.7424 - val_loss: 4.6204 - val_MinusLogProbMetric: 4.6204 - lr: 0.0010 - 67s/epoch - 341ms/step
Epoch 14/1000
2023-09-16 21:38:12.204 
Epoch 14/1000 
	 loss: 4.6554, MinusLogProbMetric: 4.6554, val_loss: 4.5288, val_MinusLogProbMetric: 4.5288

Epoch 14: val_loss improved from 4.62036 to 4.52875, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 66s - loss: 4.6554 - MinusLogProbMetric: 4.6554 - val_loss: 4.5288 - val_MinusLogProbMetric: 4.5288 - lr: 0.0010 - 66s/epoch - 337ms/step
Epoch 15/1000
2023-09-16 21:39:17.622 
Epoch 15/1000 
	 loss: 4.6724, MinusLogProbMetric: 4.6724, val_loss: 4.7789, val_MinusLogProbMetric: 4.7789

Epoch 15: val_loss did not improve from 4.52875
196/196 - 64s - loss: 4.6724 - MinusLogProbMetric: 4.6724 - val_loss: 4.7789 - val_MinusLogProbMetric: 4.7789 - lr: 0.0010 - 64s/epoch - 328ms/step
Epoch 16/1000
2023-09-16 21:40:21.314 
Epoch 16/1000 
	 loss: 4.6917, MinusLogProbMetric: 4.6917, val_loss: 4.9532, val_MinusLogProbMetric: 4.9532

Epoch 16: val_loss did not improve from 4.52875
196/196 - 64s - loss: 4.6917 - MinusLogProbMetric: 4.6917 - val_loss: 4.9532 - val_MinusLogProbMetric: 4.9532 - lr: 0.0010 - 64s/epoch - 325ms/step
Epoch 17/1000
2023-09-16 21:41:26.216 
Epoch 17/1000 
	 loss: 4.6321, MinusLogProbMetric: 4.6321, val_loss: 4.9421, val_MinusLogProbMetric: 4.9421

Epoch 17: val_loss did not improve from 4.52875
196/196 - 65s - loss: 4.6321 - MinusLogProbMetric: 4.6321 - val_loss: 4.9421 - val_MinusLogProbMetric: 4.9421 - lr: 0.0010 - 65s/epoch - 331ms/step
Epoch 18/1000
2023-09-16 21:42:31.908 
Epoch 18/1000 
	 loss: 4.6643, MinusLogProbMetric: 4.6643, val_loss: 4.7759, val_MinusLogProbMetric: 4.7759

Epoch 18: val_loss did not improve from 4.52875
196/196 - 66s - loss: 4.6643 - MinusLogProbMetric: 4.6643 - val_loss: 4.7759 - val_MinusLogProbMetric: 4.7759 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 19/1000
2023-09-16 21:43:37.555 
Epoch 19/1000 
	 loss: 4.5696, MinusLogProbMetric: 4.5696, val_loss: 4.4550, val_MinusLogProbMetric: 4.4550

Epoch 19: val_loss improved from 4.52875 to 4.45499, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 67s - loss: 4.5696 - MinusLogProbMetric: 4.5696 - val_loss: 4.4550 - val_MinusLogProbMetric: 4.4550 - lr: 0.0010 - 67s/epoch - 341ms/step
Epoch 20/1000
2023-09-16 21:44:45.384 
Epoch 20/1000 
	 loss: 4.6121, MinusLogProbMetric: 4.6121, val_loss: 5.0840, val_MinusLogProbMetric: 5.0840

Epoch 20: val_loss did not improve from 4.45499
196/196 - 67s - loss: 4.6121 - MinusLogProbMetric: 4.6121 - val_loss: 5.0840 - val_MinusLogProbMetric: 5.0840 - lr: 0.0010 - 67s/epoch - 340ms/step
Epoch 21/1000
2023-09-16 21:45:50.696 
Epoch 21/1000 
	 loss: 4.5731, MinusLogProbMetric: 4.5731, val_loss: 4.4156, val_MinusLogProbMetric: 4.4156

Epoch 21: val_loss improved from 4.45499 to 4.41557, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 66s - loss: 4.5731 - MinusLogProbMetric: 4.5731 - val_loss: 4.4156 - val_MinusLogProbMetric: 4.4156 - lr: 0.0010 - 66s/epoch - 339ms/step
Epoch 22/1000
2023-09-16 21:46:57.775 
Epoch 22/1000 
	 loss: 4.5076, MinusLogProbMetric: 4.5076, val_loss: 5.0119, val_MinusLogProbMetric: 5.0119

Epoch 22: val_loss did not improve from 4.41557
196/196 - 66s - loss: 4.5076 - MinusLogProbMetric: 4.5076 - val_loss: 5.0119 - val_MinusLogProbMetric: 5.0119 - lr: 0.0010 - 66s/epoch - 337ms/step
Epoch 23/1000
2023-09-16 21:48:03.782 
Epoch 23/1000 
	 loss: 4.5506, MinusLogProbMetric: 4.5506, val_loss: 4.8648, val_MinusLogProbMetric: 4.8648

Epoch 23: val_loss did not improve from 4.41557
196/196 - 66s - loss: 4.5506 - MinusLogProbMetric: 4.5506 - val_loss: 4.8648 - val_MinusLogProbMetric: 4.8648 - lr: 0.0010 - 66s/epoch - 337ms/step
Epoch 24/1000
2023-09-16 21:49:10.935 
Epoch 24/1000 
	 loss: 4.4896, MinusLogProbMetric: 4.4896, val_loss: 4.7057, val_MinusLogProbMetric: 4.7057

Epoch 24: val_loss did not improve from 4.41557
196/196 - 67s - loss: 4.4896 - MinusLogProbMetric: 4.4896 - val_loss: 4.7057 - val_MinusLogProbMetric: 4.7057 - lr: 0.0010 - 67s/epoch - 343ms/step
Epoch 25/1000
2023-09-16 21:50:17.673 
Epoch 25/1000 
	 loss: 4.4529, MinusLogProbMetric: 4.4529, val_loss: 4.7913, val_MinusLogProbMetric: 4.7913

Epoch 25: val_loss did not improve from 4.41557
196/196 - 67s - loss: 4.4529 - MinusLogProbMetric: 4.4529 - val_loss: 4.7913 - val_MinusLogProbMetric: 4.7913 - lr: 0.0010 - 67s/epoch - 340ms/step
Epoch 26/1000
2023-09-16 21:51:24.768 
Epoch 26/1000 
	 loss: 4.4725, MinusLogProbMetric: 4.4725, val_loss: 4.6026, val_MinusLogProbMetric: 4.6026

Epoch 26: val_loss did not improve from 4.41557
196/196 - 67s - loss: 4.4725 - MinusLogProbMetric: 4.4725 - val_loss: 4.6026 - val_MinusLogProbMetric: 4.6026 - lr: 0.0010 - 67s/epoch - 342ms/step
Epoch 27/1000
2023-09-16 21:52:32.180 
Epoch 27/1000 
	 loss: 4.4598, MinusLogProbMetric: 4.4598, val_loss: 4.5445, val_MinusLogProbMetric: 4.5445

Epoch 27: val_loss did not improve from 4.41557
196/196 - 67s - loss: 4.4598 - MinusLogProbMetric: 4.4598 - val_loss: 4.5445 - val_MinusLogProbMetric: 4.5445 - lr: 0.0010 - 67s/epoch - 344ms/step
Epoch 28/1000
2023-09-16 21:53:38.519 
Epoch 28/1000 
	 loss: 4.4334, MinusLogProbMetric: 4.4334, val_loss: 4.6857, val_MinusLogProbMetric: 4.6857

Epoch 28: val_loss did not improve from 4.41557
196/196 - 66s - loss: 4.4334 - MinusLogProbMetric: 4.4334 - val_loss: 4.6857 - val_MinusLogProbMetric: 4.6857 - lr: 0.0010 - 66s/epoch - 338ms/step
Epoch 29/1000
2023-09-16 21:54:44.170 
Epoch 29/1000 
	 loss: 4.4289, MinusLogProbMetric: 4.4289, val_loss: 4.4024, val_MinusLogProbMetric: 4.4024

Epoch 29: val_loss improved from 4.41557 to 4.40241, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 67s - loss: 4.4289 - MinusLogProbMetric: 4.4289 - val_loss: 4.4024 - val_MinusLogProbMetric: 4.4024 - lr: 0.0010 - 67s/epoch - 340ms/step
Epoch 30/1000
2023-09-16 21:55:52.798 
Epoch 30/1000 
	 loss: 4.3958, MinusLogProbMetric: 4.3958, val_loss: 4.3497, val_MinusLogProbMetric: 4.3497

Epoch 30: val_loss improved from 4.40241 to 4.34971, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 69s - loss: 4.3958 - MinusLogProbMetric: 4.3958 - val_loss: 4.3497 - val_MinusLogProbMetric: 4.3497 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 31/1000
2023-09-16 21:57:01.180 
Epoch 31/1000 
	 loss: 4.4411, MinusLogProbMetric: 4.4411, val_loss: 4.4145, val_MinusLogProbMetric: 4.4145

Epoch 31: val_loss did not improve from 4.34971
196/196 - 67s - loss: 4.4411 - MinusLogProbMetric: 4.4411 - val_loss: 4.4145 - val_MinusLogProbMetric: 4.4145 - lr: 0.0010 - 67s/epoch - 344ms/step
Epoch 32/1000
2023-09-16 21:58:07.077 
Epoch 32/1000 
	 loss: 4.3860, MinusLogProbMetric: 4.3860, val_loss: 4.4405, val_MinusLogProbMetric: 4.4405

Epoch 32: val_loss did not improve from 4.34971
196/196 - 66s - loss: 4.3860 - MinusLogProbMetric: 4.3860 - val_loss: 4.4405 - val_MinusLogProbMetric: 4.4405 - lr: 0.0010 - 66s/epoch - 336ms/step
Epoch 33/1000
2023-09-16 21:59:13.388 
Epoch 33/1000 
	 loss: 4.3682, MinusLogProbMetric: 4.3682, val_loss: 4.3601, val_MinusLogProbMetric: 4.3601

Epoch 33: val_loss did not improve from 4.34971
196/196 - 66s - loss: 4.3682 - MinusLogProbMetric: 4.3682 - val_loss: 4.3601 - val_MinusLogProbMetric: 4.3601 - lr: 0.0010 - 66s/epoch - 338ms/step
Epoch 34/1000
2023-09-16 22:00:18.784 
Epoch 34/1000 
	 loss: 4.3947, MinusLogProbMetric: 4.3947, val_loss: 4.6948, val_MinusLogProbMetric: 4.6948

Epoch 34: val_loss did not improve from 4.34971
196/196 - 65s - loss: 4.3947 - MinusLogProbMetric: 4.3947 - val_loss: 4.6948 - val_MinusLogProbMetric: 4.6948 - lr: 0.0010 - 65s/epoch - 334ms/step
Epoch 35/1000
2023-09-16 22:01:23.908 
Epoch 35/1000 
	 loss: 4.3719, MinusLogProbMetric: 4.3719, val_loss: 4.3355, val_MinusLogProbMetric: 4.3355

Epoch 35: val_loss improved from 4.34971 to 4.33553, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 66s - loss: 4.3719 - MinusLogProbMetric: 4.3719 - val_loss: 4.3355 - val_MinusLogProbMetric: 4.3355 - lr: 0.0010 - 66s/epoch - 338ms/step
Epoch 36/1000
2023-09-16 22:02:31.726 
Epoch 36/1000 
	 loss: 4.3612, MinusLogProbMetric: 4.3612, val_loss: 4.5843, val_MinusLogProbMetric: 4.5843

Epoch 36: val_loss did not improve from 4.33553
196/196 - 67s - loss: 4.3612 - MinusLogProbMetric: 4.3612 - val_loss: 4.5843 - val_MinusLogProbMetric: 4.5843 - lr: 0.0010 - 67s/epoch - 341ms/step
Epoch 37/1000
2023-09-16 22:03:37.454 
Epoch 37/1000 
	 loss: 4.3645, MinusLogProbMetric: 4.3645, val_loss: 4.3503, val_MinusLogProbMetric: 4.3503

Epoch 37: val_loss did not improve from 4.33553
196/196 - 66s - loss: 4.3645 - MinusLogProbMetric: 4.3645 - val_loss: 4.3503 - val_MinusLogProbMetric: 4.3503 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 38/1000
2023-09-16 22:04:42.802 
Epoch 38/1000 
	 loss: 4.3513, MinusLogProbMetric: 4.3513, val_loss: 4.3183, val_MinusLogProbMetric: 4.3183

Epoch 38: val_loss improved from 4.33553 to 4.31833, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 66s - loss: 4.3513 - MinusLogProbMetric: 4.3513 - val_loss: 4.3183 - val_MinusLogProbMetric: 4.3183 - lr: 0.0010 - 66s/epoch - 339ms/step
Epoch 39/1000
2023-09-16 22:05:50.326 
Epoch 39/1000 
	 loss: 4.3649, MinusLogProbMetric: 4.3649, val_loss: 4.3182, val_MinusLogProbMetric: 4.3182

Epoch 39: val_loss improved from 4.31833 to 4.31820, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 67s - loss: 4.3649 - MinusLogProbMetric: 4.3649 - val_loss: 4.3182 - val_MinusLogProbMetric: 4.3182 - lr: 0.0010 - 67s/epoch - 344ms/step
Epoch 40/1000
2023-09-16 22:06:56.957 
Epoch 40/1000 
	 loss: 4.3297, MinusLogProbMetric: 4.3297, val_loss: 4.3444, val_MinusLogProbMetric: 4.3444

Epoch 40: val_loss did not improve from 4.31820
196/196 - 66s - loss: 4.3297 - MinusLogProbMetric: 4.3297 - val_loss: 4.3444 - val_MinusLogProbMetric: 4.3444 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 41/1000
2023-09-16 22:08:02.163 
Epoch 41/1000 
	 loss: 4.3725, MinusLogProbMetric: 4.3725, val_loss: 4.7589, val_MinusLogProbMetric: 4.7589

Epoch 41: val_loss did not improve from 4.31820
196/196 - 65s - loss: 4.3725 - MinusLogProbMetric: 4.3725 - val_loss: 4.7589 - val_MinusLogProbMetric: 4.7589 - lr: 0.0010 - 65s/epoch - 333ms/step
Epoch 42/1000
2023-09-16 22:09:07.875 
Epoch 42/1000 
	 loss: 4.3142, MinusLogProbMetric: 4.3142, val_loss: 4.3632, val_MinusLogProbMetric: 4.3632

Epoch 42: val_loss did not improve from 4.31820
196/196 - 66s - loss: 4.3142 - MinusLogProbMetric: 4.3142 - val_loss: 4.3632 - val_MinusLogProbMetric: 4.3632 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 43/1000
2023-09-16 22:10:13.319 
Epoch 43/1000 
	 loss: 4.3443, MinusLogProbMetric: 4.3443, val_loss: 4.4162, val_MinusLogProbMetric: 4.4162

Epoch 43: val_loss did not improve from 4.31820
196/196 - 65s - loss: 4.3443 - MinusLogProbMetric: 4.3443 - val_loss: 4.4162 - val_MinusLogProbMetric: 4.4162 - lr: 0.0010 - 65s/epoch - 334ms/step
Epoch 44/1000
2023-09-16 22:11:18.866 
Epoch 44/1000 
	 loss: 4.3083, MinusLogProbMetric: 4.3083, val_loss: 4.2963, val_MinusLogProbMetric: 4.2963

Epoch 44: val_loss improved from 4.31820 to 4.29628, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 66s - loss: 4.3083 - MinusLogProbMetric: 4.3083 - val_loss: 4.2963 - val_MinusLogProbMetric: 4.2963 - lr: 0.0010 - 66s/epoch - 339ms/step
Epoch 45/1000
2023-09-16 22:12:26.218 
Epoch 45/1000 
	 loss: 4.3341, MinusLogProbMetric: 4.3341, val_loss: 4.3809, val_MinusLogProbMetric: 4.3809

Epoch 45: val_loss did not improve from 4.29628
196/196 - 66s - loss: 4.3341 - MinusLogProbMetric: 4.3341 - val_loss: 4.3809 - val_MinusLogProbMetric: 4.3809 - lr: 0.0010 - 66s/epoch - 339ms/step
Epoch 46/1000
2023-09-16 22:13:33.222 
Epoch 46/1000 
	 loss: 4.2908, MinusLogProbMetric: 4.2908, val_loss: 4.2831, val_MinusLogProbMetric: 4.2831

Epoch 46: val_loss improved from 4.29628 to 4.28309, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 68s - loss: 4.2908 - MinusLogProbMetric: 4.2908 - val_loss: 4.2831 - val_MinusLogProbMetric: 4.2831 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 47/1000
2023-09-16 22:14:39.837 
Epoch 47/1000 
	 loss: 4.3238, MinusLogProbMetric: 4.3238, val_loss: 6.0868, val_MinusLogProbMetric: 6.0868

Epoch 47: val_loss did not improve from 4.28309
196/196 - 65s - loss: 4.3238 - MinusLogProbMetric: 4.3238 - val_loss: 6.0868 - val_MinusLogProbMetric: 6.0868 - lr: 0.0010 - 65s/epoch - 334ms/step
Epoch 48/1000
2023-09-16 22:15:38.059 
Epoch 48/1000 
	 loss: 4.3606, MinusLogProbMetric: 4.3606, val_loss: 4.6398, val_MinusLogProbMetric: 4.6398

Epoch 48: val_loss did not improve from 4.28309
196/196 - 58s - loss: 4.3606 - MinusLogProbMetric: 4.3606 - val_loss: 4.6398 - val_MinusLogProbMetric: 4.6398 - lr: 0.0010 - 58s/epoch - 297ms/step
Epoch 49/1000
2023-09-16 22:16:35.400 
Epoch 49/1000 
	 loss: 4.2836, MinusLogProbMetric: 4.2836, val_loss: 4.2679, val_MinusLogProbMetric: 4.2679

Epoch 49: val_loss improved from 4.28309 to 4.26790, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 58s - loss: 4.2836 - MinusLogProbMetric: 4.2836 - val_loss: 4.2679 - val_MinusLogProbMetric: 4.2679 - lr: 0.0010 - 58s/epoch - 298ms/step
Epoch 50/1000
2023-09-16 22:17:40.872 
Epoch 50/1000 
	 loss: 4.2905, MinusLogProbMetric: 4.2905, val_loss: 4.2490, val_MinusLogProbMetric: 4.2490

Epoch 50: val_loss improved from 4.26790 to 4.24904, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 65s - loss: 4.2905 - MinusLogProbMetric: 4.2905 - val_loss: 4.2490 - val_MinusLogProbMetric: 4.2490 - lr: 0.0010 - 65s/epoch - 334ms/step
Epoch 51/1000
2023-09-16 22:18:48.283 
Epoch 51/1000 
	 loss: 4.2739, MinusLogProbMetric: 4.2739, val_loss: 4.2651, val_MinusLogProbMetric: 4.2651

Epoch 51: val_loss did not improve from 4.24904
196/196 - 66s - loss: 4.2739 - MinusLogProbMetric: 4.2739 - val_loss: 4.2651 - val_MinusLogProbMetric: 4.2651 - lr: 0.0010 - 66s/epoch - 339ms/step
Epoch 52/1000
2023-09-16 22:19:54.871 
Epoch 52/1000 
	 loss: 4.2731, MinusLogProbMetric: 4.2731, val_loss: 4.4033, val_MinusLogProbMetric: 4.4033

Epoch 52: val_loss did not improve from 4.24904
196/196 - 67s - loss: 4.2731 - MinusLogProbMetric: 4.2731 - val_loss: 4.4033 - val_MinusLogProbMetric: 4.4033 - lr: 0.0010 - 67s/epoch - 340ms/step
Epoch 53/1000
2023-09-16 22:21:00.172 
Epoch 53/1000 
	 loss: 4.3025, MinusLogProbMetric: 4.3025, val_loss: 4.4143, val_MinusLogProbMetric: 4.4143

Epoch 53: val_loss did not improve from 4.24904
196/196 - 65s - loss: 4.3025 - MinusLogProbMetric: 4.3025 - val_loss: 4.4143 - val_MinusLogProbMetric: 4.4143 - lr: 0.0010 - 65s/epoch - 333ms/step
Epoch 54/1000
2023-09-16 22:22:05.389 
Epoch 54/1000 
	 loss: 4.2761, MinusLogProbMetric: 4.2761, val_loss: 4.3164, val_MinusLogProbMetric: 4.3164

Epoch 54: val_loss did not improve from 4.24904
196/196 - 65s - loss: 4.2761 - MinusLogProbMetric: 4.2761 - val_loss: 4.3164 - val_MinusLogProbMetric: 4.3164 - lr: 0.0010 - 65s/epoch - 333ms/step
Epoch 55/1000
2023-09-16 22:23:05.667 
Epoch 55/1000 
	 loss: 4.2790, MinusLogProbMetric: 4.2790, val_loss: 4.2413, val_MinusLogProbMetric: 4.2413

Epoch 55: val_loss improved from 4.24904 to 4.24133, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 61s - loss: 4.2790 - MinusLogProbMetric: 4.2790 - val_loss: 4.2413 - val_MinusLogProbMetric: 4.2413 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 56/1000
2023-09-16 22:24:03.701 
Epoch 56/1000 
	 loss: 4.2441, MinusLogProbMetric: 4.2441, val_loss: 4.2817, val_MinusLogProbMetric: 4.2817

Epoch 56: val_loss did not improve from 4.24133
196/196 - 57s - loss: 4.2441 - MinusLogProbMetric: 4.2441 - val_loss: 4.2817 - val_MinusLogProbMetric: 4.2817 - lr: 0.0010 - 57s/epoch - 292ms/step
Epoch 57/1000
2023-09-16 22:25:07.218 
Epoch 57/1000 
	 loss: 4.2637, MinusLogProbMetric: 4.2637, val_loss: 4.4104, val_MinusLogProbMetric: 4.4104

Epoch 57: val_loss did not improve from 4.24133
196/196 - 64s - loss: 4.2637 - MinusLogProbMetric: 4.2637 - val_loss: 4.4104 - val_MinusLogProbMetric: 4.4104 - lr: 0.0010 - 64s/epoch - 324ms/step
Epoch 58/1000
2023-09-16 22:26:13.923 
Epoch 58/1000 
	 loss: 4.2595, MinusLogProbMetric: 4.2595, val_loss: 4.2969, val_MinusLogProbMetric: 4.2969

Epoch 58: val_loss did not improve from 4.24133
196/196 - 67s - loss: 4.2595 - MinusLogProbMetric: 4.2595 - val_loss: 4.2969 - val_MinusLogProbMetric: 4.2969 - lr: 0.0010 - 67s/epoch - 340ms/step
Epoch 59/1000
2023-09-16 22:27:20.116 
Epoch 59/1000 
	 loss: 4.2582, MinusLogProbMetric: 4.2582, val_loss: 4.3429, val_MinusLogProbMetric: 4.3429

Epoch 59: val_loss did not improve from 4.24133
196/196 - 66s - loss: 4.2582 - MinusLogProbMetric: 4.2582 - val_loss: 4.3429 - val_MinusLogProbMetric: 4.3429 - lr: 0.0010 - 66s/epoch - 338ms/step
Epoch 60/1000
2023-09-16 22:28:26.383 
Epoch 60/1000 
	 loss: 4.2447, MinusLogProbMetric: 4.2447, val_loss: 4.3037, val_MinusLogProbMetric: 4.3037

Epoch 60: val_loss did not improve from 4.24133
196/196 - 66s - loss: 4.2447 - MinusLogProbMetric: 4.2447 - val_loss: 4.3037 - val_MinusLogProbMetric: 4.3037 - lr: 0.0010 - 66s/epoch - 338ms/step
Epoch 61/1000
2023-09-16 22:29:32.134 
Epoch 61/1000 
	 loss: 4.2553, MinusLogProbMetric: 4.2553, val_loss: 4.3213, val_MinusLogProbMetric: 4.3213

Epoch 61: val_loss did not improve from 4.24133
196/196 - 66s - loss: 4.2553 - MinusLogProbMetric: 4.2553 - val_loss: 4.3213 - val_MinusLogProbMetric: 4.3213 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 62/1000
2023-09-16 22:30:37.956 
Epoch 62/1000 
	 loss: 4.2499, MinusLogProbMetric: 4.2499, val_loss: 4.2806, val_MinusLogProbMetric: 4.2806

Epoch 62: val_loss did not improve from 4.24133
196/196 - 66s - loss: 4.2499 - MinusLogProbMetric: 4.2499 - val_loss: 4.2806 - val_MinusLogProbMetric: 4.2806 - lr: 0.0010 - 66s/epoch - 336ms/step
Epoch 63/1000
2023-09-16 22:31:42.852 
Epoch 63/1000 
	 loss: 4.2209, MinusLogProbMetric: 4.2209, val_loss: 4.2693, val_MinusLogProbMetric: 4.2693

Epoch 63: val_loss did not improve from 4.24133
196/196 - 65s - loss: 4.2209 - MinusLogProbMetric: 4.2209 - val_loss: 4.2693 - val_MinusLogProbMetric: 4.2693 - lr: 0.0010 - 65s/epoch - 331ms/step
Epoch 64/1000
2023-09-16 22:32:47.580 
Epoch 64/1000 
	 loss: 4.2598, MinusLogProbMetric: 4.2598, val_loss: 4.7095, val_MinusLogProbMetric: 4.7095

Epoch 64: val_loss did not improve from 4.24133
196/196 - 65s - loss: 4.2598 - MinusLogProbMetric: 4.2598 - val_loss: 4.7095 - val_MinusLogProbMetric: 4.7095 - lr: 0.0010 - 65s/epoch - 330ms/step
Epoch 65/1000
2023-09-16 22:33:53.373 
Epoch 65/1000 
	 loss: 4.2465, MinusLogProbMetric: 4.2465, val_loss: 4.5776, val_MinusLogProbMetric: 4.5776

Epoch 65: val_loss did not improve from 4.24133
196/196 - 66s - loss: 4.2465 - MinusLogProbMetric: 4.2465 - val_loss: 4.5776 - val_MinusLogProbMetric: 4.5776 - lr: 0.0010 - 66s/epoch - 336ms/step
Epoch 66/1000
2023-09-16 22:34:58.394 
Epoch 66/1000 
	 loss: 4.2150, MinusLogProbMetric: 4.2150, val_loss: 4.3251, val_MinusLogProbMetric: 4.3251

Epoch 66: val_loss did not improve from 4.24133
196/196 - 65s - loss: 4.2150 - MinusLogProbMetric: 4.2150 - val_loss: 4.3251 - val_MinusLogProbMetric: 4.3251 - lr: 0.0010 - 65s/epoch - 332ms/step
Epoch 67/1000
2023-09-16 22:36:03.331 
Epoch 67/1000 
	 loss: 4.2408, MinusLogProbMetric: 4.2408, val_loss: 4.5384, val_MinusLogProbMetric: 4.5384

Epoch 67: val_loss did not improve from 4.24133
196/196 - 65s - loss: 4.2408 - MinusLogProbMetric: 4.2408 - val_loss: 4.5384 - val_MinusLogProbMetric: 4.5384 - lr: 0.0010 - 65s/epoch - 331ms/step
Epoch 68/1000
2023-09-16 22:37:04.405 
Epoch 68/1000 
	 loss: 4.2081, MinusLogProbMetric: 4.2081, val_loss: 4.4047, val_MinusLogProbMetric: 4.4047

Epoch 68: val_loss did not improve from 4.24133
196/196 - 61s - loss: 4.2081 - MinusLogProbMetric: 4.2081 - val_loss: 4.4047 - val_MinusLogProbMetric: 4.4047 - lr: 0.0010 - 61s/epoch - 312ms/step
Epoch 69/1000
2023-09-16 22:37:59.123 
Epoch 69/1000 
	 loss: 4.2241, MinusLogProbMetric: 4.2241, val_loss: 4.2721, val_MinusLogProbMetric: 4.2721

Epoch 69: val_loss did not improve from 4.24133
196/196 - 55s - loss: 4.2241 - MinusLogProbMetric: 4.2241 - val_loss: 4.2721 - val_MinusLogProbMetric: 4.2721 - lr: 0.0010 - 55s/epoch - 279ms/step
Epoch 70/1000
2023-09-16 22:38:57.100 
Epoch 70/1000 
	 loss: 4.2100, MinusLogProbMetric: 4.2100, val_loss: 4.2697, val_MinusLogProbMetric: 4.2697

Epoch 70: val_loss did not improve from 4.24133
196/196 - 58s - loss: 4.2100 - MinusLogProbMetric: 4.2100 - val_loss: 4.2697 - val_MinusLogProbMetric: 4.2697 - lr: 0.0010 - 58s/epoch - 296ms/step
Epoch 71/1000
2023-09-16 22:40:02.686 
Epoch 71/1000 
	 loss: 4.2163, MinusLogProbMetric: 4.2163, val_loss: 4.5204, val_MinusLogProbMetric: 4.5204

Epoch 71: val_loss did not improve from 4.24133
196/196 - 66s - loss: 4.2163 - MinusLogProbMetric: 4.2163 - val_loss: 4.5204 - val_MinusLogProbMetric: 4.5204 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 72/1000
2023-09-16 22:41:08.424 
Epoch 72/1000 
	 loss: 4.2362, MinusLogProbMetric: 4.2362, val_loss: 4.2642, val_MinusLogProbMetric: 4.2642

Epoch 72: val_loss did not improve from 4.24133
196/196 - 66s - loss: 4.2362 - MinusLogProbMetric: 4.2362 - val_loss: 4.2642 - val_MinusLogProbMetric: 4.2642 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 73/1000
2023-09-16 22:42:13.606 
Epoch 73/1000 
	 loss: 4.1937, MinusLogProbMetric: 4.1937, val_loss: 4.2521, val_MinusLogProbMetric: 4.2521

Epoch 73: val_loss did not improve from 4.24133
196/196 - 65s - loss: 4.1937 - MinusLogProbMetric: 4.1937 - val_loss: 4.2521 - val_MinusLogProbMetric: 4.2521 - lr: 0.0010 - 65s/epoch - 333ms/step
Epoch 74/1000
2023-09-16 22:43:18.653 
Epoch 74/1000 
	 loss: 4.2313, MinusLogProbMetric: 4.2313, val_loss: 4.3139, val_MinusLogProbMetric: 4.3139

Epoch 74: val_loss did not improve from 4.24133
196/196 - 65s - loss: 4.2313 - MinusLogProbMetric: 4.2313 - val_loss: 4.3139 - val_MinusLogProbMetric: 4.3139 - lr: 0.0010 - 65s/epoch - 332ms/step
Epoch 75/1000
2023-09-16 22:44:24.989 
Epoch 75/1000 
	 loss: 4.1829, MinusLogProbMetric: 4.1829, val_loss: 4.2384, val_MinusLogProbMetric: 4.2384

Epoch 75: val_loss improved from 4.24133 to 4.23840, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 67s - loss: 4.1829 - MinusLogProbMetric: 4.1829 - val_loss: 4.2384 - val_MinusLogProbMetric: 4.2384 - lr: 0.0010 - 67s/epoch - 344ms/step
Epoch 76/1000
2023-09-16 22:45:31.911 
Epoch 76/1000 
	 loss: 4.2070, MinusLogProbMetric: 4.2070, val_loss: 4.2740, val_MinusLogProbMetric: 4.2740

Epoch 76: val_loss did not improve from 4.23840
196/196 - 66s - loss: 4.2070 - MinusLogProbMetric: 4.2070 - val_loss: 4.2740 - val_MinusLogProbMetric: 4.2740 - lr: 0.0010 - 66s/epoch - 336ms/step
Epoch 77/1000
2023-09-16 22:46:37.062 
Epoch 77/1000 
	 loss: 4.1979, MinusLogProbMetric: 4.1979, val_loss: 4.7854, val_MinusLogProbMetric: 4.7854

Epoch 77: val_loss did not improve from 4.23840
196/196 - 65s - loss: 4.1979 - MinusLogProbMetric: 4.1979 - val_loss: 4.7854 - val_MinusLogProbMetric: 4.7854 - lr: 0.0010 - 65s/epoch - 332ms/step
Epoch 78/1000
2023-09-16 22:47:43.108 
Epoch 78/1000 
	 loss: 4.1951, MinusLogProbMetric: 4.1951, val_loss: 4.2538, val_MinusLogProbMetric: 4.2538

Epoch 78: val_loss did not improve from 4.23840
196/196 - 66s - loss: 4.1951 - MinusLogProbMetric: 4.1951 - val_loss: 4.2538 - val_MinusLogProbMetric: 4.2538 - lr: 0.0010 - 66s/epoch - 337ms/step
Epoch 79/1000
2023-09-16 22:48:49.500 
Epoch 79/1000 
	 loss: 4.1937, MinusLogProbMetric: 4.1937, val_loss: 4.2380, val_MinusLogProbMetric: 4.2380

Epoch 79: val_loss improved from 4.23840 to 4.23797, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 68s - loss: 4.1937 - MinusLogProbMetric: 4.1937 - val_loss: 4.2380 - val_MinusLogProbMetric: 4.2380 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 80/1000
2023-09-16 22:49:55.666 
Epoch 80/1000 
	 loss: 4.1934, MinusLogProbMetric: 4.1934, val_loss: 4.7340, val_MinusLogProbMetric: 4.7340

Epoch 80: val_loss did not improve from 4.23797
196/196 - 65s - loss: 4.1934 - MinusLogProbMetric: 4.1934 - val_loss: 4.7340 - val_MinusLogProbMetric: 4.7340 - lr: 0.0010 - 65s/epoch - 331ms/step
Epoch 81/1000
2023-09-16 22:51:01.453 
Epoch 81/1000 
	 loss: 4.2148, MinusLogProbMetric: 4.2148, val_loss: 4.2786, val_MinusLogProbMetric: 4.2786

Epoch 81: val_loss did not improve from 4.23797
196/196 - 66s - loss: 4.2148 - MinusLogProbMetric: 4.2148 - val_loss: 4.2786 - val_MinusLogProbMetric: 4.2786 - lr: 0.0010 - 66s/epoch - 336ms/step
Epoch 82/1000
2023-09-16 22:52:07.278 
Epoch 82/1000 
	 loss: 4.1692, MinusLogProbMetric: 4.1692, val_loss: 4.3232, val_MinusLogProbMetric: 4.3232

Epoch 82: val_loss did not improve from 4.23797
196/196 - 66s - loss: 4.1692 - MinusLogProbMetric: 4.1692 - val_loss: 4.3232 - val_MinusLogProbMetric: 4.3232 - lr: 0.0010 - 66s/epoch - 336ms/step
Epoch 83/1000
2023-09-16 22:53:12.971 
Epoch 83/1000 
	 loss: 4.1923, MinusLogProbMetric: 4.1923, val_loss: 4.2210, val_MinusLogProbMetric: 4.2210

Epoch 83: val_loss improved from 4.23797 to 4.22105, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 67s - loss: 4.1923 - MinusLogProbMetric: 4.1923 - val_loss: 4.2210 - val_MinusLogProbMetric: 4.2210 - lr: 0.0010 - 67s/epoch - 340ms/step
Epoch 84/1000
2023-09-16 22:54:20.078 
Epoch 84/1000 
	 loss: 4.1951, MinusLogProbMetric: 4.1951, val_loss: 4.3140, val_MinusLogProbMetric: 4.3140

Epoch 84: val_loss did not improve from 4.22105
196/196 - 66s - loss: 4.1951 - MinusLogProbMetric: 4.1951 - val_loss: 4.3140 - val_MinusLogProbMetric: 4.3140 - lr: 0.0010 - 66s/epoch - 338ms/step
Epoch 85/1000
2023-09-16 22:55:24.587 
Epoch 85/1000 
	 loss: 4.1935, MinusLogProbMetric: 4.1935, val_loss: 4.2633, val_MinusLogProbMetric: 4.2633

Epoch 85: val_loss did not improve from 4.22105
196/196 - 65s - loss: 4.1935 - MinusLogProbMetric: 4.1935 - val_loss: 4.2633 - val_MinusLogProbMetric: 4.2633 - lr: 0.0010 - 65s/epoch - 329ms/step
Epoch 86/1000
2023-09-16 22:56:26.104 
Epoch 86/1000 
	 loss: 4.1815, MinusLogProbMetric: 4.1815, val_loss: 4.3898, val_MinusLogProbMetric: 4.3898

Epoch 86: val_loss did not improve from 4.22105
196/196 - 62s - loss: 4.1815 - MinusLogProbMetric: 4.1815 - val_loss: 4.3898 - val_MinusLogProbMetric: 4.3898 - lr: 0.0010 - 62s/epoch - 314ms/step
Epoch 87/1000
2023-09-16 22:57:31.655 
Epoch 87/1000 
	 loss: 4.1990, MinusLogProbMetric: 4.1990, val_loss: 4.2290, val_MinusLogProbMetric: 4.2290

Epoch 87: val_loss did not improve from 4.22105
196/196 - 66s - loss: 4.1990 - MinusLogProbMetric: 4.1990 - val_loss: 4.2290 - val_MinusLogProbMetric: 4.2290 - lr: 0.0010 - 66s/epoch - 334ms/step
Epoch 88/1000
2023-09-16 22:58:38.489 
Epoch 88/1000 
	 loss: 4.1796, MinusLogProbMetric: 4.1796, val_loss: 4.8488, val_MinusLogProbMetric: 4.8488

Epoch 88: val_loss did not improve from 4.22105
196/196 - 67s - loss: 4.1796 - MinusLogProbMetric: 4.1796 - val_loss: 4.8488 - val_MinusLogProbMetric: 4.8488 - lr: 0.0010 - 67s/epoch - 341ms/step
Epoch 89/1000
2023-09-16 22:59:44.383 
Epoch 89/1000 
	 loss: 4.1853, MinusLogProbMetric: 4.1853, val_loss: 4.2499, val_MinusLogProbMetric: 4.2499

Epoch 89: val_loss did not improve from 4.22105
196/196 - 66s - loss: 4.1853 - MinusLogProbMetric: 4.1853 - val_loss: 4.2499 - val_MinusLogProbMetric: 4.2499 - lr: 0.0010 - 66s/epoch - 336ms/step
Epoch 90/1000
2023-09-16 23:00:50.817 
Epoch 90/1000 
	 loss: 4.1558, MinusLogProbMetric: 4.1558, val_loss: 4.2182, val_MinusLogProbMetric: 4.2182

Epoch 90: val_loss improved from 4.22105 to 4.21816, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 68s - loss: 4.1558 - MinusLogProbMetric: 4.1558 - val_loss: 4.2182 - val_MinusLogProbMetric: 4.2182 - lr: 0.0010 - 68s/epoch - 344ms/step
Epoch 91/1000
2023-09-16 23:01:57.408 
Epoch 91/1000 
	 loss: 4.1743, MinusLogProbMetric: 4.1743, val_loss: 4.3826, val_MinusLogProbMetric: 4.3826

Epoch 91: val_loss did not improve from 4.21816
196/196 - 65s - loss: 4.1743 - MinusLogProbMetric: 4.1743 - val_loss: 4.3826 - val_MinusLogProbMetric: 4.3826 - lr: 0.0010 - 65s/epoch - 334ms/step
Epoch 92/1000
2023-09-16 23:03:03.628 
Epoch 92/1000 
	 loss: 4.1767, MinusLogProbMetric: 4.1767, val_loss: 4.2291, val_MinusLogProbMetric: 4.2291

Epoch 92: val_loss did not improve from 4.21816
196/196 - 66s - loss: 4.1767 - MinusLogProbMetric: 4.1767 - val_loss: 4.2291 - val_MinusLogProbMetric: 4.2291 - lr: 0.0010 - 66s/epoch - 338ms/step
Epoch 93/1000
2023-09-16 23:04:09.384 
Epoch 93/1000 
	 loss: 4.1615, MinusLogProbMetric: 4.1615, val_loss: 4.3662, val_MinusLogProbMetric: 4.3662

Epoch 93: val_loss did not improve from 4.21816
196/196 - 66s - loss: 4.1615 - MinusLogProbMetric: 4.1615 - val_loss: 4.3662 - val_MinusLogProbMetric: 4.3662 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 94/1000
2023-09-16 23:05:16.292 
Epoch 94/1000 
	 loss: 4.1712, MinusLogProbMetric: 4.1712, val_loss: 4.2892, val_MinusLogProbMetric: 4.2892

Epoch 94: val_loss did not improve from 4.21816
196/196 - 67s - loss: 4.1712 - MinusLogProbMetric: 4.1712 - val_loss: 4.2892 - val_MinusLogProbMetric: 4.2892 - lr: 0.0010 - 67s/epoch - 341ms/step
Epoch 95/1000
2023-09-16 23:06:22.312 
Epoch 95/1000 
	 loss: 4.1707, MinusLogProbMetric: 4.1707, val_loss: 4.3305, val_MinusLogProbMetric: 4.3305

Epoch 95: val_loss did not improve from 4.21816
196/196 - 66s - loss: 4.1707 - MinusLogProbMetric: 4.1707 - val_loss: 4.3305 - val_MinusLogProbMetric: 4.3305 - lr: 0.0010 - 66s/epoch - 337ms/step
Epoch 96/1000
2023-09-16 23:07:29.330 
Epoch 96/1000 
	 loss: 4.1893, MinusLogProbMetric: 4.1893, val_loss: 4.2548, val_MinusLogProbMetric: 4.2548

Epoch 96: val_loss did not improve from 4.21816
196/196 - 67s - loss: 4.1893 - MinusLogProbMetric: 4.1893 - val_loss: 4.2548 - val_MinusLogProbMetric: 4.2548 - lr: 0.0010 - 67s/epoch - 342ms/step
Epoch 97/1000
2023-09-16 23:08:37.087 
Epoch 97/1000 
	 loss: 4.1632, MinusLogProbMetric: 4.1632, val_loss: 4.2580, val_MinusLogProbMetric: 4.2580

Epoch 97: val_loss did not improve from 4.21816
196/196 - 68s - loss: 4.1632 - MinusLogProbMetric: 4.1632 - val_loss: 4.2580 - val_MinusLogProbMetric: 4.2580 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 98/1000
2023-09-16 23:09:43.337 
Epoch 98/1000 
	 loss: 4.1784, MinusLogProbMetric: 4.1784, val_loss: 4.5832, val_MinusLogProbMetric: 4.5832

Epoch 98: val_loss did not improve from 4.21816
196/196 - 66s - loss: 4.1784 - MinusLogProbMetric: 4.1784 - val_loss: 4.5832 - val_MinusLogProbMetric: 4.5832 - lr: 0.0010 - 66s/epoch - 338ms/step
Epoch 99/1000
2023-09-16 23:10:50.420 
Epoch 99/1000 
	 loss: 4.1722, MinusLogProbMetric: 4.1722, val_loss: 4.2897, val_MinusLogProbMetric: 4.2897

Epoch 99: val_loss did not improve from 4.21816
196/196 - 67s - loss: 4.1722 - MinusLogProbMetric: 4.1722 - val_loss: 4.2897 - val_MinusLogProbMetric: 4.2897 - lr: 0.0010 - 67s/epoch - 342ms/step
Epoch 100/1000
2023-09-16 23:11:57.154 
Epoch 100/1000 
	 loss: 4.1500, MinusLogProbMetric: 4.1500, val_loss: 4.2345, val_MinusLogProbMetric: 4.2345

Epoch 100: val_loss did not improve from 4.21816
196/196 - 67s - loss: 4.1500 - MinusLogProbMetric: 4.1500 - val_loss: 4.2345 - val_MinusLogProbMetric: 4.2345 - lr: 0.0010 - 67s/epoch - 340ms/step
Epoch 101/1000
2023-09-16 23:13:04.911 
Epoch 101/1000 
	 loss: 4.1630, MinusLogProbMetric: 4.1630, val_loss: 4.4164, val_MinusLogProbMetric: 4.4164

Epoch 101: val_loss did not improve from 4.21816
196/196 - 68s - loss: 4.1630 - MinusLogProbMetric: 4.1630 - val_loss: 4.4164 - val_MinusLogProbMetric: 4.4164 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 102/1000
2023-09-16 23:14:11.832 
Epoch 102/1000 
	 loss: 4.1628, MinusLogProbMetric: 4.1628, val_loss: 4.3211, val_MinusLogProbMetric: 4.3211

Epoch 102: val_loss did not improve from 4.21816
196/196 - 67s - loss: 4.1628 - MinusLogProbMetric: 4.1628 - val_loss: 4.3211 - val_MinusLogProbMetric: 4.3211 - lr: 0.0010 - 67s/epoch - 341ms/step
Epoch 103/1000
2023-09-16 23:15:18.999 
Epoch 103/1000 
	 loss: 4.1543, MinusLogProbMetric: 4.1543, val_loss: 4.2050, val_MinusLogProbMetric: 4.2050

Epoch 103: val_loss improved from 4.21816 to 4.20502, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 68s - loss: 4.1543 - MinusLogProbMetric: 4.1543 - val_loss: 4.2050 - val_MinusLogProbMetric: 4.2050 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 104/1000
2023-09-16 23:16:27.229 
Epoch 104/1000 
	 loss: 4.1593, MinusLogProbMetric: 4.1593, val_loss: 4.3549, val_MinusLogProbMetric: 4.3549

Epoch 104: val_loss did not improve from 4.20502
196/196 - 67s - loss: 4.1593 - MinusLogProbMetric: 4.1593 - val_loss: 4.3549 - val_MinusLogProbMetric: 4.3549 - lr: 0.0010 - 67s/epoch - 343ms/step
Epoch 105/1000
2023-09-16 23:17:35.552 
Epoch 105/1000 
	 loss: 4.1451, MinusLogProbMetric: 4.1451, val_loss: 4.3068, val_MinusLogProbMetric: 4.3068

Epoch 105: val_loss did not improve from 4.20502
196/196 - 68s - loss: 4.1451 - MinusLogProbMetric: 4.1451 - val_loss: 4.3068 - val_MinusLogProbMetric: 4.3068 - lr: 0.0010 - 68s/epoch - 349ms/step
Epoch 106/1000
2023-09-16 23:18:33.475 
Epoch 106/1000 
	 loss: 4.1732, MinusLogProbMetric: 4.1732, val_loss: 4.2245, val_MinusLogProbMetric: 4.2245

Epoch 106: val_loss did not improve from 4.20502
196/196 - 58s - loss: 4.1732 - MinusLogProbMetric: 4.1732 - val_loss: 4.2245 - val_MinusLogProbMetric: 4.2245 - lr: 0.0010 - 58s/epoch - 295ms/step
Epoch 107/1000
2023-09-16 23:19:28.268 
Epoch 107/1000 
	 loss: 4.1501, MinusLogProbMetric: 4.1501, val_loss: 4.2193, val_MinusLogProbMetric: 4.2193

Epoch 107: val_loss did not improve from 4.20502
196/196 - 55s - loss: 4.1501 - MinusLogProbMetric: 4.1501 - val_loss: 4.2193 - val_MinusLogProbMetric: 4.2193 - lr: 0.0010 - 55s/epoch - 280ms/step
Epoch 108/1000
2023-09-16 23:20:33.706 
Epoch 108/1000 
	 loss: 4.1497, MinusLogProbMetric: 4.1497, val_loss: 4.2324, val_MinusLogProbMetric: 4.2324

Epoch 108: val_loss did not improve from 4.20502
196/196 - 65s - loss: 4.1497 - MinusLogProbMetric: 4.1497 - val_loss: 4.2324 - val_MinusLogProbMetric: 4.2324 - lr: 0.0010 - 65s/epoch - 334ms/step
Epoch 109/1000
2023-09-16 23:21:37.266 
Epoch 109/1000 
	 loss: 4.1381, MinusLogProbMetric: 4.1381, val_loss: 4.2213, val_MinusLogProbMetric: 4.2213

Epoch 109: val_loss did not improve from 4.20502
196/196 - 64s - loss: 4.1381 - MinusLogProbMetric: 4.1381 - val_loss: 4.2213 - val_MinusLogProbMetric: 4.2213 - lr: 0.0010 - 64s/epoch - 324ms/step
Epoch 110/1000
2023-09-16 23:22:34.144 
Epoch 110/1000 
	 loss: 4.1513, MinusLogProbMetric: 4.1513, val_loss: 4.2539, val_MinusLogProbMetric: 4.2539

Epoch 110: val_loss did not improve from 4.20502
196/196 - 57s - loss: 4.1513 - MinusLogProbMetric: 4.1513 - val_loss: 4.2539 - val_MinusLogProbMetric: 4.2539 - lr: 0.0010 - 57s/epoch - 290ms/step
Epoch 111/1000
2023-09-16 23:23:34.381 
Epoch 111/1000 
	 loss: 4.1571, MinusLogProbMetric: 4.1571, val_loss: 4.3161, val_MinusLogProbMetric: 4.3161

Epoch 111: val_loss did not improve from 4.20502
196/196 - 60s - loss: 4.1571 - MinusLogProbMetric: 4.1571 - val_loss: 4.3161 - val_MinusLogProbMetric: 4.3161 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 112/1000
2023-09-16 23:24:41.555 
Epoch 112/1000 
	 loss: 4.1528, MinusLogProbMetric: 4.1528, val_loss: 4.2719, val_MinusLogProbMetric: 4.2719

Epoch 112: val_loss did not improve from 4.20502
196/196 - 67s - loss: 4.1528 - MinusLogProbMetric: 4.1528 - val_loss: 4.2719 - val_MinusLogProbMetric: 4.2719 - lr: 0.0010 - 67s/epoch - 343ms/step
Epoch 113/1000
2023-09-16 23:25:48.380 
Epoch 113/1000 
	 loss: 4.1441, MinusLogProbMetric: 4.1441, val_loss: 4.2619, val_MinusLogProbMetric: 4.2619

Epoch 113: val_loss did not improve from 4.20502
196/196 - 67s - loss: 4.1441 - MinusLogProbMetric: 4.1441 - val_loss: 4.2619 - val_MinusLogProbMetric: 4.2619 - lr: 0.0010 - 67s/epoch - 341ms/step
Epoch 114/1000
2023-09-16 23:26:55.273 
Epoch 114/1000 
	 loss: 4.1241, MinusLogProbMetric: 4.1241, val_loss: 4.2327, val_MinusLogProbMetric: 4.2327

Epoch 114: val_loss did not improve from 4.20502
196/196 - 67s - loss: 4.1241 - MinusLogProbMetric: 4.1241 - val_loss: 4.2327 - val_MinusLogProbMetric: 4.2327 - lr: 0.0010 - 67s/epoch - 341ms/step
Epoch 115/1000
2023-09-16 23:28:01.280 
Epoch 115/1000 
	 loss: 4.1515, MinusLogProbMetric: 4.1515, val_loss: 4.2925, val_MinusLogProbMetric: 4.2925

Epoch 115: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.1515 - MinusLogProbMetric: 4.1515 - val_loss: 4.2925 - val_MinusLogProbMetric: 4.2925 - lr: 0.0010 - 66s/epoch - 337ms/step
Epoch 116/1000
2023-09-16 23:29:08.571 
Epoch 116/1000 
	 loss: 4.1479, MinusLogProbMetric: 4.1479, val_loss: 4.4010, val_MinusLogProbMetric: 4.4010

Epoch 116: val_loss did not improve from 4.20502
196/196 - 67s - loss: 4.1479 - MinusLogProbMetric: 4.1479 - val_loss: 4.4010 - val_MinusLogProbMetric: 4.4010 - lr: 0.0010 - 67s/epoch - 343ms/step
Epoch 117/1000
2023-09-16 23:30:15.429 
Epoch 117/1000 
	 loss: 4.1445, MinusLogProbMetric: 4.1445, val_loss: 4.3086, val_MinusLogProbMetric: 4.3086

Epoch 117: val_loss did not improve from 4.20502
196/196 - 67s - loss: 4.1445 - MinusLogProbMetric: 4.1445 - val_loss: 4.3086 - val_MinusLogProbMetric: 4.3086 - lr: 0.0010 - 67s/epoch - 341ms/step
Epoch 118/1000
2023-09-16 23:31:22.516 
Epoch 118/1000 
	 loss: 4.1558, MinusLogProbMetric: 4.1558, val_loss: 4.2751, val_MinusLogProbMetric: 4.2751

Epoch 118: val_loss did not improve from 4.20502
196/196 - 67s - loss: 4.1558 - MinusLogProbMetric: 4.1558 - val_loss: 4.2751 - val_MinusLogProbMetric: 4.2751 - lr: 0.0010 - 67s/epoch - 342ms/step
Epoch 119/1000
2023-09-16 23:32:27.526 
Epoch 119/1000 
	 loss: 4.1281, MinusLogProbMetric: 4.1281, val_loss: 4.2560, val_MinusLogProbMetric: 4.2560

Epoch 119: val_loss did not improve from 4.20502
196/196 - 65s - loss: 4.1281 - MinusLogProbMetric: 4.1281 - val_loss: 4.2560 - val_MinusLogProbMetric: 4.2560 - lr: 0.0010 - 65s/epoch - 332ms/step
Epoch 120/1000
2023-09-16 23:33:33.542 
Epoch 120/1000 
	 loss: 4.1234, MinusLogProbMetric: 4.1234, val_loss: 4.2417, val_MinusLogProbMetric: 4.2417

Epoch 120: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.1234 - MinusLogProbMetric: 4.1234 - val_loss: 4.2417 - val_MinusLogProbMetric: 4.2417 - lr: 0.0010 - 66s/epoch - 337ms/step
Epoch 121/1000
2023-09-16 23:34:39.550 
Epoch 121/1000 
	 loss: 4.1323, MinusLogProbMetric: 4.1323, val_loss: 4.3250, val_MinusLogProbMetric: 4.3250

Epoch 121: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.1323 - MinusLogProbMetric: 4.1323 - val_loss: 4.3250 - val_MinusLogProbMetric: 4.3250 - lr: 0.0010 - 66s/epoch - 337ms/step
Epoch 122/1000
2023-09-16 23:35:45.117 
Epoch 122/1000 
	 loss: 4.1405, MinusLogProbMetric: 4.1405, val_loss: 4.2939, val_MinusLogProbMetric: 4.2939

Epoch 122: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.1405 - MinusLogProbMetric: 4.1405 - val_loss: 4.2939 - val_MinusLogProbMetric: 4.2939 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 123/1000
2023-09-16 23:36:50.884 
Epoch 123/1000 
	 loss: 4.1301, MinusLogProbMetric: 4.1301, val_loss: 4.2275, val_MinusLogProbMetric: 4.2275

Epoch 123: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.1301 - MinusLogProbMetric: 4.1301 - val_loss: 4.2275 - val_MinusLogProbMetric: 4.2275 - lr: 0.0010 - 66s/epoch - 336ms/step
Epoch 124/1000
2023-09-16 23:37:56.731 
Epoch 124/1000 
	 loss: 4.1195, MinusLogProbMetric: 4.1195, val_loss: 4.3178, val_MinusLogProbMetric: 4.3178

Epoch 124: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.1195 - MinusLogProbMetric: 4.1195 - val_loss: 4.3178 - val_MinusLogProbMetric: 4.3178 - lr: 0.0010 - 66s/epoch - 336ms/step
Epoch 125/1000
2023-09-16 23:39:03.106 
Epoch 125/1000 
	 loss: 4.1238, MinusLogProbMetric: 4.1238, val_loss: 4.2522, val_MinusLogProbMetric: 4.2522

Epoch 125: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.1238 - MinusLogProbMetric: 4.1238 - val_loss: 4.2522 - val_MinusLogProbMetric: 4.2522 - lr: 0.0010 - 66s/epoch - 339ms/step
Epoch 126/1000
2023-09-16 23:40:08.896 
Epoch 126/1000 
	 loss: 4.1301, MinusLogProbMetric: 4.1301, val_loss: 4.2820, val_MinusLogProbMetric: 4.2820

Epoch 126: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.1301 - MinusLogProbMetric: 4.1301 - val_loss: 4.2820 - val_MinusLogProbMetric: 4.2820 - lr: 0.0010 - 66s/epoch - 336ms/step
Epoch 127/1000
2023-09-16 23:41:15.587 
Epoch 127/1000 
	 loss: 4.1121, MinusLogProbMetric: 4.1121, val_loss: 4.2130, val_MinusLogProbMetric: 4.2130

Epoch 127: val_loss did not improve from 4.20502
196/196 - 67s - loss: 4.1121 - MinusLogProbMetric: 4.1121 - val_loss: 4.2130 - val_MinusLogProbMetric: 4.2130 - lr: 0.0010 - 67s/epoch - 340ms/step
Epoch 128/1000
2023-09-16 23:42:21.779 
Epoch 128/1000 
	 loss: 4.1196, MinusLogProbMetric: 4.1196, val_loss: 4.2130, val_MinusLogProbMetric: 4.2130

Epoch 128: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.1196 - MinusLogProbMetric: 4.1196 - val_loss: 4.2130 - val_MinusLogProbMetric: 4.2130 - lr: 0.0010 - 66s/epoch - 338ms/step
Epoch 129/1000
2023-09-16 23:43:27.333 
Epoch 129/1000 
	 loss: 4.1030, MinusLogProbMetric: 4.1030, val_loss: 4.2662, val_MinusLogProbMetric: 4.2662

Epoch 129: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.1030 - MinusLogProbMetric: 4.1030 - val_loss: 4.2662 - val_MinusLogProbMetric: 4.2662 - lr: 0.0010 - 66s/epoch - 334ms/step
Epoch 130/1000
2023-09-16 23:44:33.373 
Epoch 130/1000 
	 loss: 4.1056, MinusLogProbMetric: 4.1056, val_loss: 4.2549, val_MinusLogProbMetric: 4.2549

Epoch 130: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.1056 - MinusLogProbMetric: 4.1056 - val_loss: 4.2549 - val_MinusLogProbMetric: 4.2549 - lr: 0.0010 - 66s/epoch - 337ms/step
Epoch 131/1000
2023-09-16 23:45:39.115 
Epoch 131/1000 
	 loss: 4.1210, MinusLogProbMetric: 4.1210, val_loss: 4.3054, val_MinusLogProbMetric: 4.3054

Epoch 131: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.1210 - MinusLogProbMetric: 4.1210 - val_loss: 4.3054 - val_MinusLogProbMetric: 4.3054 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 132/1000
2023-09-16 23:46:44.411 
Epoch 132/1000 
	 loss: 4.1134, MinusLogProbMetric: 4.1134, val_loss: 4.2648, val_MinusLogProbMetric: 4.2648

Epoch 132: val_loss did not improve from 4.20502
196/196 - 65s - loss: 4.1134 - MinusLogProbMetric: 4.1134 - val_loss: 4.2648 - val_MinusLogProbMetric: 4.2648 - lr: 0.0010 - 65s/epoch - 333ms/step
Epoch 133/1000
2023-09-16 23:47:49.931 
Epoch 133/1000 
	 loss: 4.1411, MinusLogProbMetric: 4.1411, val_loss: 4.4840, val_MinusLogProbMetric: 4.4840

Epoch 133: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.1411 - MinusLogProbMetric: 4.1411 - val_loss: 4.4840 - val_MinusLogProbMetric: 4.4840 - lr: 0.0010 - 66s/epoch - 334ms/step
Epoch 134/1000
2023-09-16 23:48:56.919 
Epoch 134/1000 
	 loss: 4.1149, MinusLogProbMetric: 4.1149, val_loss: 4.2927, val_MinusLogProbMetric: 4.2927

Epoch 134: val_loss did not improve from 4.20502
196/196 - 67s - loss: 4.1149 - MinusLogProbMetric: 4.1149 - val_loss: 4.2927 - val_MinusLogProbMetric: 4.2927 - lr: 0.0010 - 67s/epoch - 342ms/step
Epoch 135/1000
2023-09-16 23:50:03.033 
Epoch 135/1000 
	 loss: 4.1148, MinusLogProbMetric: 4.1148, val_loss: 4.2510, val_MinusLogProbMetric: 4.2510

Epoch 135: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.1148 - MinusLogProbMetric: 4.1148 - val_loss: 4.2510 - val_MinusLogProbMetric: 4.2510 - lr: 0.0010 - 66s/epoch - 337ms/step
Epoch 136/1000
2023-09-16 23:51:08.604 
Epoch 136/1000 
	 loss: 4.1219, MinusLogProbMetric: 4.1219, val_loss: 4.2245, val_MinusLogProbMetric: 4.2245

Epoch 136: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.1219 - MinusLogProbMetric: 4.1219 - val_loss: 4.2245 - val_MinusLogProbMetric: 4.2245 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 137/1000
2023-09-16 23:52:15.076 
Epoch 137/1000 
	 loss: 4.1316, MinusLogProbMetric: 4.1316, val_loss: 4.2152, val_MinusLogProbMetric: 4.2152

Epoch 137: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.1316 - MinusLogProbMetric: 4.1316 - val_loss: 4.2152 - val_MinusLogProbMetric: 4.2152 - lr: 0.0010 - 66s/epoch - 339ms/step
Epoch 138/1000
2023-09-16 23:53:21.517 
Epoch 138/1000 
	 loss: 4.1131, MinusLogProbMetric: 4.1131, val_loss: 4.2553, val_MinusLogProbMetric: 4.2553

Epoch 138: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.1131 - MinusLogProbMetric: 4.1131 - val_loss: 4.2553 - val_MinusLogProbMetric: 4.2553 - lr: 0.0010 - 66s/epoch - 339ms/step
Epoch 139/1000
2023-09-16 23:54:28.547 
Epoch 139/1000 
	 loss: 4.1086, MinusLogProbMetric: 4.1086, val_loss: 4.3966, val_MinusLogProbMetric: 4.3966

Epoch 139: val_loss did not improve from 4.20502
196/196 - 67s - loss: 4.1086 - MinusLogProbMetric: 4.1086 - val_loss: 4.3966 - val_MinusLogProbMetric: 4.3966 - lr: 0.0010 - 67s/epoch - 342ms/step
Epoch 140/1000
2023-09-16 23:55:35.575 
Epoch 140/1000 
	 loss: 4.1133, MinusLogProbMetric: 4.1133, val_loss: 4.2525, val_MinusLogProbMetric: 4.2525

Epoch 140: val_loss did not improve from 4.20502
196/196 - 67s - loss: 4.1133 - MinusLogProbMetric: 4.1133 - val_loss: 4.2525 - val_MinusLogProbMetric: 4.2525 - lr: 0.0010 - 67s/epoch - 342ms/step
Epoch 141/1000
2023-09-16 23:56:42.620 
Epoch 141/1000 
	 loss: 4.1226, MinusLogProbMetric: 4.1226, val_loss: 4.2377, val_MinusLogProbMetric: 4.2377

Epoch 141: val_loss did not improve from 4.20502
196/196 - 67s - loss: 4.1226 - MinusLogProbMetric: 4.1226 - val_loss: 4.2377 - val_MinusLogProbMetric: 4.2377 - lr: 0.0010 - 67s/epoch - 342ms/step
Epoch 142/1000
2023-09-16 23:57:49.072 
Epoch 142/1000 
	 loss: 4.1145, MinusLogProbMetric: 4.1145, val_loss: 4.2886, val_MinusLogProbMetric: 4.2886

Epoch 142: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.1145 - MinusLogProbMetric: 4.1145 - val_loss: 4.2886 - val_MinusLogProbMetric: 4.2886 - lr: 0.0010 - 66s/epoch - 339ms/step
Epoch 143/1000
2023-09-16 23:58:55.633 
Epoch 143/1000 
	 loss: 4.1104, MinusLogProbMetric: 4.1104, val_loss: 4.2208, val_MinusLogProbMetric: 4.2208

Epoch 143: val_loss did not improve from 4.20502
196/196 - 67s - loss: 4.1104 - MinusLogProbMetric: 4.1104 - val_loss: 4.2208 - val_MinusLogProbMetric: 4.2208 - lr: 0.0010 - 67s/epoch - 340ms/step
Epoch 144/1000
2023-09-17 00:00:01.307 
Epoch 144/1000 
	 loss: 4.0998, MinusLogProbMetric: 4.0998, val_loss: 4.2877, val_MinusLogProbMetric: 4.2877

Epoch 144: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.0998 - MinusLogProbMetric: 4.0998 - val_loss: 4.2877 - val_MinusLogProbMetric: 4.2877 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 145/1000
2023-09-17 00:01:05.984 
Epoch 145/1000 
	 loss: 4.1060, MinusLogProbMetric: 4.1060, val_loss: 4.2489, val_MinusLogProbMetric: 4.2489

Epoch 145: val_loss did not improve from 4.20502
196/196 - 65s - loss: 4.1060 - MinusLogProbMetric: 4.1060 - val_loss: 4.2489 - val_MinusLogProbMetric: 4.2489 - lr: 0.0010 - 65s/epoch - 330ms/step
Epoch 146/1000
2023-09-17 00:02:11.593 
Epoch 146/1000 
	 loss: 4.1045, MinusLogProbMetric: 4.1045, val_loss: 4.4669, val_MinusLogProbMetric: 4.4669

Epoch 146: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.1045 - MinusLogProbMetric: 4.1045 - val_loss: 4.4669 - val_MinusLogProbMetric: 4.4669 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 147/1000
2023-09-17 00:03:16.949 
Epoch 147/1000 
	 loss: 4.1071, MinusLogProbMetric: 4.1071, val_loss: 4.3345, val_MinusLogProbMetric: 4.3345

Epoch 147: val_loss did not improve from 4.20502
196/196 - 65s - loss: 4.1071 - MinusLogProbMetric: 4.1071 - val_loss: 4.3345 - val_MinusLogProbMetric: 4.3345 - lr: 0.0010 - 65s/epoch - 333ms/step
Epoch 148/1000
2023-09-17 00:04:22.540 
Epoch 148/1000 
	 loss: 4.1059, MinusLogProbMetric: 4.1059, val_loss: 4.3327, val_MinusLogProbMetric: 4.3327

Epoch 148: val_loss did not improve from 4.20502
196/196 - 66s - loss: 4.1059 - MinusLogProbMetric: 4.1059 - val_loss: 4.3327 - val_MinusLogProbMetric: 4.3327 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 149/1000
2023-09-17 00:05:30.023 
Epoch 149/1000 
	 loss: 4.1249, MinusLogProbMetric: 4.1249, val_loss: 4.2794, val_MinusLogProbMetric: 4.2794

Epoch 149: val_loss did not improve from 4.20502
196/196 - 67s - loss: 4.1249 - MinusLogProbMetric: 4.1249 - val_loss: 4.2794 - val_MinusLogProbMetric: 4.2794 - lr: 0.0010 - 67s/epoch - 344ms/step
Epoch 150/1000
2023-09-17 00:06:36.817 
Epoch 150/1000 
	 loss: 4.0773, MinusLogProbMetric: 4.0773, val_loss: 4.2757, val_MinusLogProbMetric: 4.2757

Epoch 150: val_loss did not improve from 4.20502
196/196 - 67s - loss: 4.0773 - MinusLogProbMetric: 4.0773 - val_loss: 4.2757 - val_MinusLogProbMetric: 4.2757 - lr: 0.0010 - 67s/epoch - 341ms/step
Epoch 151/1000
2023-09-17 00:07:44.170 
Epoch 151/1000 
	 loss: 4.0995, MinusLogProbMetric: 4.0995, val_loss: 4.2751, val_MinusLogProbMetric: 4.2751

Epoch 151: val_loss did not improve from 4.20502
196/196 - 67s - loss: 4.0995 - MinusLogProbMetric: 4.0995 - val_loss: 4.2751 - val_MinusLogProbMetric: 4.2751 - lr: 0.0010 - 67s/epoch - 344ms/step
Epoch 152/1000
2023-09-17 00:08:51.473 
Epoch 152/1000 
	 loss: 4.0839, MinusLogProbMetric: 4.0839, val_loss: 4.4805, val_MinusLogProbMetric: 4.4805

Epoch 152: val_loss did not improve from 4.20502
196/196 - 67s - loss: 4.0839 - MinusLogProbMetric: 4.0839 - val_loss: 4.4805 - val_MinusLogProbMetric: 4.4805 - lr: 0.0010 - 67s/epoch - 343ms/step
Epoch 153/1000
2023-09-17 00:09:58.685 
Epoch 153/1000 
	 loss: 4.1087, MinusLogProbMetric: 4.1087, val_loss: 4.3118, val_MinusLogProbMetric: 4.3118

Epoch 153: val_loss did not improve from 4.20502
196/196 - 67s - loss: 4.1087 - MinusLogProbMetric: 4.1087 - val_loss: 4.3118 - val_MinusLogProbMetric: 4.3118 - lr: 0.0010 - 67s/epoch - 343ms/step
Epoch 154/1000
2023-09-17 00:11:06.815 
Epoch 154/1000 
	 loss: 4.0142, MinusLogProbMetric: 4.0142, val_loss: 4.2338, val_MinusLogProbMetric: 4.2338

Epoch 154: val_loss did not improve from 4.20502
196/196 - 68s - loss: 4.0142 - MinusLogProbMetric: 4.0142 - val_loss: 4.2338 - val_MinusLogProbMetric: 4.2338 - lr: 5.0000e-04 - 68s/epoch - 348ms/step
Epoch 155/1000
2023-09-17 00:12:14.323 
Epoch 155/1000 
	 loss: 4.0159, MinusLogProbMetric: 4.0159, val_loss: 4.2009, val_MinusLogProbMetric: 4.2009

Epoch 155: val_loss improved from 4.20502 to 4.20093, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 69s - loss: 4.0159 - MinusLogProbMetric: 4.0159 - val_loss: 4.2009 - val_MinusLogProbMetric: 4.2009 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 156/1000
2023-09-17 00:13:22.514 
Epoch 156/1000 
	 loss: 4.0056, MinusLogProbMetric: 4.0056, val_loss: 4.2319, val_MinusLogProbMetric: 4.2319

Epoch 156: val_loss did not improve from 4.20093
196/196 - 67s - loss: 4.0056 - MinusLogProbMetric: 4.0056 - val_loss: 4.2319 - val_MinusLogProbMetric: 4.2319 - lr: 5.0000e-04 - 67s/epoch - 343ms/step
Epoch 157/1000
2023-09-17 00:14:29.724 
Epoch 157/1000 
	 loss: 4.0225, MinusLogProbMetric: 4.0225, val_loss: 4.1999, val_MinusLogProbMetric: 4.1999

Epoch 157: val_loss improved from 4.20093 to 4.19992, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 68s - loss: 4.0225 - MinusLogProbMetric: 4.0225 - val_loss: 4.1999 - val_MinusLogProbMetric: 4.1999 - lr: 5.0000e-04 - 68s/epoch - 348ms/step
Epoch 158/1000
2023-09-17 00:15:37.170 
Epoch 158/1000 
	 loss: 4.0045, MinusLogProbMetric: 4.0045, val_loss: 4.1962, val_MinusLogProbMetric: 4.1962

Epoch 158: val_loss improved from 4.19992 to 4.19623, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 68s - loss: 4.0045 - MinusLogProbMetric: 4.0045 - val_loss: 4.1962 - val_MinusLogProbMetric: 4.1962 - lr: 5.0000e-04 - 68s/epoch - 345ms/step
Epoch 159/1000
2023-09-17 00:16:43.987 
Epoch 159/1000 
	 loss: 4.0066, MinusLogProbMetric: 4.0066, val_loss: 4.1919, val_MinusLogProbMetric: 4.1919

Epoch 159: val_loss improved from 4.19623 to 4.19190, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_93/weights/best_weights.h5
196/196 - 67s - loss: 4.0066 - MinusLogProbMetric: 4.0066 - val_loss: 4.1919 - val_MinusLogProbMetric: 4.1919 - lr: 5.0000e-04 - 67s/epoch - 340ms/step
Epoch 160/1000
2023-09-17 00:17:50.926 
Epoch 160/1000 
	 loss: 4.0047, MinusLogProbMetric: 4.0047, val_loss: 4.2086, val_MinusLogProbMetric: 4.2086

Epoch 160: val_loss did not improve from 4.19190
196/196 - 66s - loss: 4.0047 - MinusLogProbMetric: 4.0047 - val_loss: 4.2086 - val_MinusLogProbMetric: 4.2086 - lr: 5.0000e-04 - 66s/epoch - 337ms/step
Epoch 161/1000
2023-09-17 00:18:56.589 
Epoch 161/1000 
	 loss: 4.0064, MinusLogProbMetric: 4.0064, val_loss: 4.2201, val_MinusLogProbMetric: 4.2201

Epoch 161: val_loss did not improve from 4.19190
196/196 - 66s - loss: 4.0064 - MinusLogProbMetric: 4.0064 - val_loss: 4.2201 - val_MinusLogProbMetric: 4.2201 - lr: 5.0000e-04 - 66s/epoch - 335ms/step
Epoch 162/1000
2023-09-17 00:20:01.913 
Epoch 162/1000 
	 loss: 4.0063, MinusLogProbMetric: 4.0063, val_loss: 4.2166, val_MinusLogProbMetric: 4.2166

Epoch 162: val_loss did not improve from 4.19190
196/196 - 65s - loss: 4.0063 - MinusLogProbMetric: 4.0063 - val_loss: 4.2166 - val_MinusLogProbMetric: 4.2166 - lr: 5.0000e-04 - 65s/epoch - 333ms/step
Epoch 163/1000
2023-09-17 00:21:08.350 
Epoch 163/1000 
	 loss: 4.0050, MinusLogProbMetric: 4.0050, val_loss: 4.2781, val_MinusLogProbMetric: 4.2781

Epoch 163: val_loss did not improve from 4.19190
196/196 - 66s - loss: 4.0050 - MinusLogProbMetric: 4.0050 - val_loss: 4.2781 - val_MinusLogProbMetric: 4.2781 - lr: 5.0000e-04 - 66s/epoch - 339ms/step
Epoch 164/1000
2023-09-17 00:22:13.878 
Epoch 164/1000 
	 loss: 3.9956, MinusLogProbMetric: 3.9956, val_loss: 4.1999, val_MinusLogProbMetric: 4.1999

Epoch 164: val_loss did not improve from 4.19190
196/196 - 66s - loss: 3.9956 - MinusLogProbMetric: 3.9956 - val_loss: 4.1999 - val_MinusLogProbMetric: 4.1999 - lr: 5.0000e-04 - 66s/epoch - 334ms/step
Epoch 165/1000
2023-09-17 00:23:20.229 
Epoch 165/1000 
	 loss: 4.0021, MinusLogProbMetric: 4.0021, val_loss: 4.2796, val_MinusLogProbMetric: 4.2796

Epoch 165: val_loss did not improve from 4.19190
196/196 - 66s - loss: 4.0021 - MinusLogProbMetric: 4.0021 - val_loss: 4.2796 - val_MinusLogProbMetric: 4.2796 - lr: 5.0000e-04 - 66s/epoch - 339ms/step
Epoch 166/1000
2023-09-17 00:24:26.859 
Epoch 166/1000 
	 loss: 4.0172, MinusLogProbMetric: 4.0172, val_loss: 4.2219, val_MinusLogProbMetric: 4.2219

Epoch 166: val_loss did not improve from 4.19190
196/196 - 67s - loss: 4.0172 - MinusLogProbMetric: 4.0172 - val_loss: 4.2219 - val_MinusLogProbMetric: 4.2219 - lr: 5.0000e-04 - 67s/epoch - 340ms/step
Epoch 167/1000
2023-09-17 00:25:32.571 
Epoch 167/1000 
	 loss: 4.0105, MinusLogProbMetric: 4.0105, val_loss: 4.2118, val_MinusLogProbMetric: 4.2118

Epoch 167: val_loss did not improve from 4.19190
196/196 - 66s - loss: 4.0105 - MinusLogProbMetric: 4.0105 - val_loss: 4.2118 - val_MinusLogProbMetric: 4.2118 - lr: 5.0000e-04 - 66s/epoch - 335ms/step
Epoch 168/1000
2023-09-17 00:26:38.534 
Epoch 168/1000 
	 loss: 4.0029, MinusLogProbMetric: 4.0029, val_loss: 4.1955, val_MinusLogProbMetric: 4.1955

Epoch 168: val_loss did not improve from 4.19190
196/196 - 66s - loss: 4.0029 - MinusLogProbMetric: 4.0029 - val_loss: 4.1955 - val_MinusLogProbMetric: 4.1955 - lr: 5.0000e-04 - 66s/epoch - 337ms/step
Epoch 169/1000
2023-09-17 00:27:44.024 
Epoch 169/1000 
	 loss: 4.0013, MinusLogProbMetric: 4.0013, val_loss: 4.2205, val_MinusLogProbMetric: 4.2205

Epoch 169: val_loss did not improve from 4.19190
196/196 - 65s - loss: 4.0013 - MinusLogProbMetric: 4.0013 - val_loss: 4.2205 - val_MinusLogProbMetric: 4.2205 - lr: 5.0000e-04 - 65s/epoch - 334ms/step
Epoch 170/1000
2023-09-17 00:28:49.224 
Epoch 170/1000 
	 loss: 4.0028, MinusLogProbMetric: 4.0028, val_loss: 4.2551, val_MinusLogProbMetric: 4.2551

Epoch 170: val_loss did not improve from 4.19190
196/196 - 65s - loss: 4.0028 - MinusLogProbMetric: 4.0028 - val_loss: 4.2551 - val_MinusLogProbMetric: 4.2551 - lr: 5.0000e-04 - 65s/epoch - 333ms/step
Epoch 171/1000
2023-09-17 00:29:54.531 
Epoch 171/1000 
	 loss: 4.0080, MinusLogProbMetric: 4.0080, val_loss: 4.2417, val_MinusLogProbMetric: 4.2417

Epoch 171: val_loss did not improve from 4.19190
196/196 - 65s - loss: 4.0080 - MinusLogProbMetric: 4.0080 - val_loss: 4.2417 - val_MinusLogProbMetric: 4.2417 - lr: 5.0000e-04 - 65s/epoch - 333ms/step
Epoch 172/1000
2023-09-17 00:30:59.646 
Epoch 172/1000 
	 loss: 3.9964, MinusLogProbMetric: 3.9964, val_loss: 4.2258, val_MinusLogProbMetric: 4.2258

Epoch 172: val_loss did not improve from 4.19190
196/196 - 65s - loss: 3.9964 - MinusLogProbMetric: 3.9964 - val_loss: 4.2258 - val_MinusLogProbMetric: 4.2258 - lr: 5.0000e-04 - 65s/epoch - 332ms/step
Epoch 173/1000
2023-09-17 00:32:04.195 
Epoch 173/1000 
	 loss: 4.0041, MinusLogProbMetric: 4.0041, val_loss: 4.3126, val_MinusLogProbMetric: 4.3126

Epoch 173: val_loss did not improve from 4.19190
196/196 - 65s - loss: 4.0041 - MinusLogProbMetric: 4.0041 - val_loss: 4.3126 - val_MinusLogProbMetric: 4.3126 - lr: 5.0000e-04 - 65s/epoch - 329ms/step
Epoch 174/1000
2023-09-17 00:33:09.860 
Epoch 174/1000 
	 loss: 3.9959, MinusLogProbMetric: 3.9959, val_loss: 4.2421, val_MinusLogProbMetric: 4.2421

Epoch 174: val_loss did not improve from 4.19190
196/196 - 66s - loss: 3.9959 - MinusLogProbMetric: 3.9959 - val_loss: 4.2421 - val_MinusLogProbMetric: 4.2421 - lr: 5.0000e-04 - 66s/epoch - 335ms/step
Epoch 175/1000
2023-09-17 00:34:15.317 
Epoch 175/1000 
	 loss: 3.9943, MinusLogProbMetric: 3.9943, val_loss: 4.1978, val_MinusLogProbMetric: 4.1978

Epoch 175: val_loss did not improve from 4.19190
196/196 - 65s - loss: 3.9943 - MinusLogProbMetric: 3.9943 - val_loss: 4.1978 - val_MinusLogProbMetric: 4.1978 - lr: 5.0000e-04 - 65s/epoch - 334ms/step
Epoch 176/1000
2023-09-17 00:35:21.293 
Epoch 176/1000 
	 loss: 3.9986, MinusLogProbMetric: 3.9986, val_loss: 4.2382, val_MinusLogProbMetric: 4.2382

Epoch 176: val_loss did not improve from 4.19190
196/196 - 66s - loss: 3.9986 - MinusLogProbMetric: 3.9986 - val_loss: 4.2382 - val_MinusLogProbMetric: 4.2382 - lr: 5.0000e-04 - 66s/epoch - 337ms/step
Epoch 177/1000
2023-09-17 00:36:31.020 
Epoch 177/1000 
	 loss: 3.9943, MinusLogProbMetric: 3.9943, val_loss: 4.2066, val_MinusLogProbMetric: 4.2066

Epoch 177: val_loss did not improve from 4.19190
196/196 - 70s - loss: 3.9943 - MinusLogProbMetric: 3.9943 - val_loss: 4.2066 - val_MinusLogProbMetric: 4.2066 - lr: 5.0000e-04 - 70s/epoch - 356ms/step
Epoch 178/1000
2023-09-17 00:37:36.875 
Epoch 178/1000 
	 loss: 3.9940, MinusLogProbMetric: 3.9940, val_loss: 4.2060, val_MinusLogProbMetric: 4.2060

Epoch 178: val_loss did not improve from 4.19190
196/196 - 66s - loss: 3.9940 - MinusLogProbMetric: 3.9940 - val_loss: 4.2060 - val_MinusLogProbMetric: 4.2060 - lr: 5.0000e-04 - 66s/epoch - 336ms/step
Epoch 179/1000
2023-09-17 00:38:43.338 
Epoch 179/1000 
	 loss: 4.0010, MinusLogProbMetric: 4.0010, val_loss: 4.2059, val_MinusLogProbMetric: 4.2059

Epoch 179: val_loss did not improve from 4.19190
196/196 - 66s - loss: 4.0010 - MinusLogProbMetric: 4.0010 - val_loss: 4.2059 - val_MinusLogProbMetric: 4.2059 - lr: 5.0000e-04 - 66s/epoch - 339ms/step
Epoch 180/1000
2023-09-17 00:39:50.346 
Epoch 180/1000 
	 loss: 3.9962, MinusLogProbMetric: 3.9962, val_loss: 4.2439, val_MinusLogProbMetric: 4.2439

Epoch 180: val_loss did not improve from 4.19190
196/196 - 67s - loss: 3.9962 - MinusLogProbMetric: 3.9962 - val_loss: 4.2439 - val_MinusLogProbMetric: 4.2439 - lr: 5.0000e-04 - 67s/epoch - 342ms/step
Epoch 181/1000
2023-09-17 00:40:57.706 
Epoch 181/1000 
	 loss: 3.9926, MinusLogProbMetric: 3.9926, val_loss: 4.2064, val_MinusLogProbMetric: 4.2064

Epoch 181: val_loss did not improve from 4.19190
196/196 - 67s - loss: 3.9926 - MinusLogProbMetric: 3.9926 - val_loss: 4.2064 - val_MinusLogProbMetric: 4.2064 - lr: 5.0000e-04 - 67s/epoch - 344ms/step
Epoch 182/1000
2023-09-17 00:42:04.242 
Epoch 182/1000 
	 loss: 3.9866, MinusLogProbMetric: 3.9866, val_loss: 4.2043, val_MinusLogProbMetric: 4.2043

Epoch 182: val_loss did not improve from 4.19190
196/196 - 67s - loss: 3.9866 - MinusLogProbMetric: 3.9866 - val_loss: 4.2043 - val_MinusLogProbMetric: 4.2043 - lr: 5.0000e-04 - 67s/epoch - 339ms/step
Epoch 183/1000
2023-09-17 00:43:10.927 
Epoch 183/1000 
	 loss: 3.9922, MinusLogProbMetric: 3.9922, val_loss: 4.2183, val_MinusLogProbMetric: 4.2183

Epoch 183: val_loss did not improve from 4.19190
196/196 - 67s - loss: 3.9922 - MinusLogProbMetric: 3.9922 - val_loss: 4.2183 - val_MinusLogProbMetric: 4.2183 - lr: 5.0000e-04 - 67s/epoch - 340ms/step
Epoch 184/1000
2023-09-17 00:44:16.472 
Epoch 184/1000 
	 loss: 3.9910, MinusLogProbMetric: 3.9910, val_loss: 4.2360, val_MinusLogProbMetric: 4.2360

Epoch 184: val_loss did not improve from 4.19190
196/196 - 66s - loss: 3.9910 - MinusLogProbMetric: 3.9910 - val_loss: 4.2360 - val_MinusLogProbMetric: 4.2360 - lr: 5.0000e-04 - 66s/epoch - 334ms/step
Epoch 185/1000
2023-09-17 00:45:16.878 
Epoch 185/1000 
	 loss: 3.9904, MinusLogProbMetric: 3.9904, val_loss: 4.2381, val_MinusLogProbMetric: 4.2381

Epoch 185: val_loss did not improve from 4.19190
196/196 - 60s - loss: 3.9904 - MinusLogProbMetric: 3.9904 - val_loss: 4.2381 - val_MinusLogProbMetric: 4.2381 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 186/1000
2023-09-17 00:46:20.871 
Epoch 186/1000 
	 loss: 3.9882, MinusLogProbMetric: 3.9882, val_loss: 4.2908, val_MinusLogProbMetric: 4.2908

Epoch 186: val_loss did not improve from 4.19190
196/196 - 64s - loss: 3.9882 - MinusLogProbMetric: 3.9882 - val_loss: 4.2908 - val_MinusLogProbMetric: 4.2908 - lr: 5.0000e-04 - 64s/epoch - 326ms/step
Epoch 187/1000
2023-09-17 00:47:28.937 
Epoch 187/1000 
	 loss: 3.9911, MinusLogProbMetric: 3.9911, val_loss: 4.2242, val_MinusLogProbMetric: 4.2242

Epoch 187: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9911 - MinusLogProbMetric: 3.9911 - val_loss: 4.2242 - val_MinusLogProbMetric: 4.2242 - lr: 5.0000e-04 - 68s/epoch - 347ms/step
Epoch 188/1000
2023-09-17 00:48:36.394 
Epoch 188/1000 
	 loss: 3.9921, MinusLogProbMetric: 3.9921, val_loss: 4.2033, val_MinusLogProbMetric: 4.2033

Epoch 188: val_loss did not improve from 4.19190
196/196 - 67s - loss: 3.9921 - MinusLogProbMetric: 3.9921 - val_loss: 4.2033 - val_MinusLogProbMetric: 4.2033 - lr: 5.0000e-04 - 67s/epoch - 344ms/step
Epoch 189/1000
2023-09-17 00:49:44.452 
Epoch 189/1000 
	 loss: 3.9863, MinusLogProbMetric: 3.9863, val_loss: 4.2297, val_MinusLogProbMetric: 4.2297

Epoch 189: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9863 - MinusLogProbMetric: 3.9863 - val_loss: 4.2297 - val_MinusLogProbMetric: 4.2297 - lr: 5.0000e-04 - 68s/epoch - 347ms/step
Epoch 190/1000
2023-09-17 00:50:52.610 
Epoch 190/1000 
	 loss: 3.9861, MinusLogProbMetric: 3.9861, val_loss: 4.2081, val_MinusLogProbMetric: 4.2081

Epoch 190: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9861 - MinusLogProbMetric: 3.9861 - val_loss: 4.2081 - val_MinusLogProbMetric: 4.2081 - lr: 5.0000e-04 - 68s/epoch - 348ms/step
Epoch 191/1000
2023-09-17 00:51:59.957 
Epoch 191/1000 
	 loss: 3.9919, MinusLogProbMetric: 3.9919, val_loss: 4.2625, val_MinusLogProbMetric: 4.2625

Epoch 191: val_loss did not improve from 4.19190
196/196 - 67s - loss: 3.9919 - MinusLogProbMetric: 3.9919 - val_loss: 4.2625 - val_MinusLogProbMetric: 4.2625 - lr: 5.0000e-04 - 67s/epoch - 344ms/step
Epoch 192/1000
2023-09-17 00:53:08.537 
Epoch 192/1000 
	 loss: 3.9898, MinusLogProbMetric: 3.9898, val_loss: 4.2779, val_MinusLogProbMetric: 4.2779

Epoch 192: val_loss did not improve from 4.19190
196/196 - 69s - loss: 3.9898 - MinusLogProbMetric: 3.9898 - val_loss: 4.2779 - val_MinusLogProbMetric: 4.2779 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 193/1000
2023-09-17 00:54:16.783 
Epoch 193/1000 
	 loss: 3.9990, MinusLogProbMetric: 3.9990, val_loss: 4.2271, val_MinusLogProbMetric: 4.2271

Epoch 193: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9990 - MinusLogProbMetric: 3.9990 - val_loss: 4.2271 - val_MinusLogProbMetric: 4.2271 - lr: 5.0000e-04 - 68s/epoch - 348ms/step
Epoch 194/1000
2023-09-17 00:55:25.472 
Epoch 194/1000 
	 loss: 3.9889, MinusLogProbMetric: 3.9889, val_loss: 4.3007, val_MinusLogProbMetric: 4.3007

Epoch 194: val_loss did not improve from 4.19190
196/196 - 69s - loss: 3.9889 - MinusLogProbMetric: 3.9889 - val_loss: 4.3007 - val_MinusLogProbMetric: 4.3007 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 195/1000
2023-09-17 00:56:33.566 
Epoch 195/1000 
	 loss: 3.9868, MinusLogProbMetric: 3.9868, val_loss: 4.2442, val_MinusLogProbMetric: 4.2442

Epoch 195: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9868 - MinusLogProbMetric: 3.9868 - val_loss: 4.2442 - val_MinusLogProbMetric: 4.2442 - lr: 5.0000e-04 - 68s/epoch - 347ms/step
Epoch 196/1000
2023-09-17 00:57:42.229 
Epoch 196/1000 
	 loss: 3.9839, MinusLogProbMetric: 3.9839, val_loss: 4.2346, val_MinusLogProbMetric: 4.2346

Epoch 196: val_loss did not improve from 4.19190
196/196 - 69s - loss: 3.9839 - MinusLogProbMetric: 3.9839 - val_loss: 4.2346 - val_MinusLogProbMetric: 4.2346 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 197/1000
2023-09-17 00:58:49.535 
Epoch 197/1000 
	 loss: 3.9875, MinusLogProbMetric: 3.9875, val_loss: 4.2262, val_MinusLogProbMetric: 4.2262

Epoch 197: val_loss did not improve from 4.19190
196/196 - 67s - loss: 3.9875 - MinusLogProbMetric: 3.9875 - val_loss: 4.2262 - val_MinusLogProbMetric: 4.2262 - lr: 5.0000e-04 - 67s/epoch - 343ms/step
Epoch 198/1000
2023-09-17 00:59:57.711 
Epoch 198/1000 
	 loss: 3.9851, MinusLogProbMetric: 3.9851, val_loss: 4.3135, val_MinusLogProbMetric: 4.3135

Epoch 198: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9851 - MinusLogProbMetric: 3.9851 - val_loss: 4.3135 - val_MinusLogProbMetric: 4.3135 - lr: 5.0000e-04 - 68s/epoch - 348ms/step
Epoch 199/1000
2023-09-17 01:01:05.336 
Epoch 199/1000 
	 loss: 3.9954, MinusLogProbMetric: 3.9954, val_loss: 4.2768, val_MinusLogProbMetric: 4.2768

Epoch 199: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9954 - MinusLogProbMetric: 3.9954 - val_loss: 4.2768 - val_MinusLogProbMetric: 4.2768 - lr: 5.0000e-04 - 68s/epoch - 345ms/step
Epoch 200/1000
2023-09-17 01:02:12.873 
Epoch 200/1000 
	 loss: 3.9924, MinusLogProbMetric: 3.9924, val_loss: 4.2631, val_MinusLogProbMetric: 4.2631

Epoch 200: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9924 - MinusLogProbMetric: 3.9924 - val_loss: 4.2631 - val_MinusLogProbMetric: 4.2631 - lr: 5.0000e-04 - 68s/epoch - 345ms/step
Epoch 201/1000
2023-09-17 01:03:20.567 
Epoch 201/1000 
	 loss: 3.9904, MinusLogProbMetric: 3.9904, val_loss: 4.2500, val_MinusLogProbMetric: 4.2500

Epoch 201: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9904 - MinusLogProbMetric: 3.9904 - val_loss: 4.2500 - val_MinusLogProbMetric: 4.2500 - lr: 5.0000e-04 - 68s/epoch - 345ms/step
Epoch 202/1000
2023-09-17 01:04:28.736 
Epoch 202/1000 
	 loss: 3.9928, MinusLogProbMetric: 3.9928, val_loss: 4.2219, val_MinusLogProbMetric: 4.2219

Epoch 202: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9928 - MinusLogProbMetric: 3.9928 - val_loss: 4.2219 - val_MinusLogProbMetric: 4.2219 - lr: 5.0000e-04 - 68s/epoch - 348ms/step
Epoch 203/1000
2023-09-17 01:05:36.939 
Epoch 203/1000 
	 loss: 3.9841, MinusLogProbMetric: 3.9841, val_loss: 4.2430, val_MinusLogProbMetric: 4.2430

Epoch 203: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9841 - MinusLogProbMetric: 3.9841 - val_loss: 4.2430 - val_MinusLogProbMetric: 4.2430 - lr: 5.0000e-04 - 68s/epoch - 348ms/step
Epoch 204/1000
2023-09-17 01:06:45.126 
Epoch 204/1000 
	 loss: 3.9848, MinusLogProbMetric: 3.9848, val_loss: 4.2248, val_MinusLogProbMetric: 4.2248

Epoch 204: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9848 - MinusLogProbMetric: 3.9848 - val_loss: 4.2248 - val_MinusLogProbMetric: 4.2248 - lr: 5.0000e-04 - 68s/epoch - 348ms/step
Epoch 205/1000
2023-09-17 01:07:53.524 
Epoch 205/1000 
	 loss: 3.9769, MinusLogProbMetric: 3.9769, val_loss: 4.2273, val_MinusLogProbMetric: 4.2273

Epoch 205: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9769 - MinusLogProbMetric: 3.9769 - val_loss: 4.2273 - val_MinusLogProbMetric: 4.2273 - lr: 5.0000e-04 - 68s/epoch - 349ms/step
Epoch 206/1000
2023-09-17 01:09:01.517 
Epoch 206/1000 
	 loss: 3.9829, MinusLogProbMetric: 3.9829, val_loss: 4.2762, val_MinusLogProbMetric: 4.2762

Epoch 206: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9829 - MinusLogProbMetric: 3.9829 - val_loss: 4.2762 - val_MinusLogProbMetric: 4.2762 - lr: 5.0000e-04 - 68s/epoch - 347ms/step
Epoch 207/1000
2023-09-17 01:10:09.277 
Epoch 207/1000 
	 loss: 3.9794, MinusLogProbMetric: 3.9794, val_loss: 4.2282, val_MinusLogProbMetric: 4.2282

Epoch 207: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9794 - MinusLogProbMetric: 3.9794 - val_loss: 4.2282 - val_MinusLogProbMetric: 4.2282 - lr: 5.0000e-04 - 68s/epoch - 346ms/step
Epoch 208/1000
2023-09-17 01:11:17.181 
Epoch 208/1000 
	 loss: 3.9884, MinusLogProbMetric: 3.9884, val_loss: 4.2280, val_MinusLogProbMetric: 4.2280

Epoch 208: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9884 - MinusLogProbMetric: 3.9884 - val_loss: 4.2280 - val_MinusLogProbMetric: 4.2280 - lr: 5.0000e-04 - 68s/epoch - 346ms/step
Epoch 209/1000
2023-09-17 01:12:25.007 
Epoch 209/1000 
	 loss: 3.9772, MinusLogProbMetric: 3.9772, val_loss: 4.2283, val_MinusLogProbMetric: 4.2283

Epoch 209: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9772 - MinusLogProbMetric: 3.9772 - val_loss: 4.2283 - val_MinusLogProbMetric: 4.2283 - lr: 5.0000e-04 - 68s/epoch - 346ms/step
Epoch 210/1000
2023-09-17 01:13:32.243 
Epoch 210/1000 
	 loss: 3.9482, MinusLogProbMetric: 3.9482, val_loss: 4.2259, val_MinusLogProbMetric: 4.2259

Epoch 210: val_loss did not improve from 4.19190
196/196 - 67s - loss: 3.9482 - MinusLogProbMetric: 3.9482 - val_loss: 4.2259 - val_MinusLogProbMetric: 4.2259 - lr: 2.5000e-04 - 67s/epoch - 343ms/step
Epoch 211/1000
2023-09-17 01:14:38.954 
Epoch 211/1000 
	 loss: 3.9432, MinusLogProbMetric: 3.9432, val_loss: 4.2182, val_MinusLogProbMetric: 4.2182

Epoch 211: val_loss did not improve from 4.19190
196/196 - 67s - loss: 3.9432 - MinusLogProbMetric: 3.9432 - val_loss: 4.2182 - val_MinusLogProbMetric: 4.2182 - lr: 2.5000e-04 - 67s/epoch - 340ms/step
Epoch 212/1000
2023-09-17 01:15:46.919 
Epoch 212/1000 
	 loss: 3.9452, MinusLogProbMetric: 3.9452, val_loss: 4.2113, val_MinusLogProbMetric: 4.2113

Epoch 212: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9452 - MinusLogProbMetric: 3.9452 - val_loss: 4.2113 - val_MinusLogProbMetric: 4.2113 - lr: 2.5000e-04 - 68s/epoch - 347ms/step
Epoch 213/1000
2023-09-17 01:16:53.311 
Epoch 213/1000 
	 loss: 3.9423, MinusLogProbMetric: 3.9423, val_loss: 4.2165, val_MinusLogProbMetric: 4.2165

Epoch 213: val_loss did not improve from 4.19190
196/196 - 66s - loss: 3.9423 - MinusLogProbMetric: 3.9423 - val_loss: 4.2165 - val_MinusLogProbMetric: 4.2165 - lr: 2.5000e-04 - 66s/epoch - 339ms/step
Epoch 214/1000
2023-09-17 01:18:00.689 
Epoch 214/1000 
	 loss: 3.9406, MinusLogProbMetric: 3.9406, val_loss: 4.2314, val_MinusLogProbMetric: 4.2314

Epoch 214: val_loss did not improve from 4.19190
196/196 - 67s - loss: 3.9406 - MinusLogProbMetric: 3.9406 - val_loss: 4.2314 - val_MinusLogProbMetric: 4.2314 - lr: 2.5000e-04 - 67s/epoch - 344ms/step
Epoch 215/1000
2023-09-17 01:19:08.779 
Epoch 215/1000 
	 loss: 3.9379, MinusLogProbMetric: 3.9379, val_loss: 4.2218, val_MinusLogProbMetric: 4.2218

Epoch 215: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9379 - MinusLogProbMetric: 3.9379 - val_loss: 4.2218 - val_MinusLogProbMetric: 4.2218 - lr: 2.5000e-04 - 68s/epoch - 347ms/step
Epoch 216/1000
2023-09-17 01:20:15.644 
Epoch 216/1000 
	 loss: 3.9365, MinusLogProbMetric: 3.9365, val_loss: 4.2237, val_MinusLogProbMetric: 4.2237

Epoch 216: val_loss did not improve from 4.19190
196/196 - 67s - loss: 3.9365 - MinusLogProbMetric: 3.9365 - val_loss: 4.2237 - val_MinusLogProbMetric: 4.2237 - lr: 2.5000e-04 - 67s/epoch - 341ms/step
Epoch 217/1000
2023-09-17 01:21:23.187 
Epoch 217/1000 
	 loss: 3.9385, MinusLogProbMetric: 3.9385, val_loss: 4.2229, val_MinusLogProbMetric: 4.2229

Epoch 217: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9385 - MinusLogProbMetric: 3.9385 - val_loss: 4.2229 - val_MinusLogProbMetric: 4.2229 - lr: 2.5000e-04 - 68s/epoch - 345ms/step
Epoch 218/1000
2023-09-17 01:22:31.272 
Epoch 218/1000 
	 loss: 3.9398, MinusLogProbMetric: 3.9398, val_loss: 4.2210, val_MinusLogProbMetric: 4.2210

Epoch 218: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9398 - MinusLogProbMetric: 3.9398 - val_loss: 4.2210 - val_MinusLogProbMetric: 4.2210 - lr: 2.5000e-04 - 68s/epoch - 347ms/step
Epoch 219/1000
2023-09-17 01:23:38.243 
Epoch 219/1000 
	 loss: 3.9375, MinusLogProbMetric: 3.9375, val_loss: 4.2250, val_MinusLogProbMetric: 4.2250

Epoch 219: val_loss did not improve from 4.19190
196/196 - 67s - loss: 3.9375 - MinusLogProbMetric: 3.9375 - val_loss: 4.2250 - val_MinusLogProbMetric: 4.2250 - lr: 2.5000e-04 - 67s/epoch - 342ms/step
Epoch 220/1000
2023-09-17 01:24:46.398 
Epoch 220/1000 
	 loss: 3.9351, MinusLogProbMetric: 3.9351, val_loss: 4.2271, val_MinusLogProbMetric: 4.2271

Epoch 220: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9351 - MinusLogProbMetric: 3.9351 - val_loss: 4.2271 - val_MinusLogProbMetric: 4.2271 - lr: 2.5000e-04 - 68s/epoch - 348ms/step
Epoch 221/1000
2023-09-17 01:25:54.116 
Epoch 221/1000 
	 loss: 3.9378, MinusLogProbMetric: 3.9378, val_loss: 4.2293, val_MinusLogProbMetric: 4.2293

Epoch 221: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9378 - MinusLogProbMetric: 3.9378 - val_loss: 4.2293 - val_MinusLogProbMetric: 4.2293 - lr: 2.5000e-04 - 68s/epoch - 345ms/step
Epoch 222/1000
2023-09-17 01:27:02.276 
Epoch 222/1000 
	 loss: 3.9321, MinusLogProbMetric: 3.9321, val_loss: 4.2211, val_MinusLogProbMetric: 4.2211

Epoch 222: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9321 - MinusLogProbMetric: 3.9321 - val_loss: 4.2211 - val_MinusLogProbMetric: 4.2211 - lr: 2.5000e-04 - 68s/epoch - 348ms/step
Epoch 223/1000
2023-09-17 01:28:08.755 
Epoch 223/1000 
	 loss: 3.9378, MinusLogProbMetric: 3.9378, val_loss: 4.2316, val_MinusLogProbMetric: 4.2316

Epoch 223: val_loss did not improve from 4.19190
196/196 - 66s - loss: 3.9378 - MinusLogProbMetric: 3.9378 - val_loss: 4.2316 - val_MinusLogProbMetric: 4.2316 - lr: 2.5000e-04 - 66s/epoch - 339ms/step
Epoch 224/1000
2023-09-17 01:29:07.458 
Epoch 224/1000 
	 loss: 3.9366, MinusLogProbMetric: 3.9366, val_loss: 4.2409, val_MinusLogProbMetric: 4.2409

Epoch 224: val_loss did not improve from 4.19190
196/196 - 59s - loss: 3.9366 - MinusLogProbMetric: 3.9366 - val_loss: 4.2409 - val_MinusLogProbMetric: 4.2409 - lr: 2.5000e-04 - 59s/epoch - 300ms/step
Epoch 225/1000
2023-09-17 01:30:04.276 
Epoch 225/1000 
	 loss: 3.9371, MinusLogProbMetric: 3.9371, val_loss: 4.2339, val_MinusLogProbMetric: 4.2339

Epoch 225: val_loss did not improve from 4.19190
196/196 - 57s - loss: 3.9371 - MinusLogProbMetric: 3.9371 - val_loss: 4.2339 - val_MinusLogProbMetric: 4.2339 - lr: 2.5000e-04 - 57s/epoch - 290ms/step
Epoch 226/1000
2023-09-17 01:30:54.693 
Epoch 226/1000 
	 loss: 3.9364, MinusLogProbMetric: 3.9364, val_loss: 4.2527, val_MinusLogProbMetric: 4.2527

Epoch 226: val_loss did not improve from 4.19190
196/196 - 50s - loss: 3.9364 - MinusLogProbMetric: 3.9364 - val_loss: 4.2527 - val_MinusLogProbMetric: 4.2527 - lr: 2.5000e-04 - 50s/epoch - 257ms/step
Epoch 227/1000
2023-09-17 01:31:45.205 
Epoch 227/1000 
	 loss: 3.9309, MinusLogProbMetric: 3.9309, val_loss: 4.2374, val_MinusLogProbMetric: 4.2374

Epoch 227: val_loss did not improve from 4.19190
196/196 - 51s - loss: 3.9309 - MinusLogProbMetric: 3.9309 - val_loss: 4.2374 - val_MinusLogProbMetric: 4.2374 - lr: 2.5000e-04 - 51s/epoch - 258ms/step
Epoch 228/1000
2023-09-17 01:32:40.792 
Epoch 228/1000 
	 loss: 3.9350, MinusLogProbMetric: 3.9350, val_loss: 4.2419, val_MinusLogProbMetric: 4.2419

Epoch 228: val_loss did not improve from 4.19190
196/196 - 56s - loss: 3.9350 - MinusLogProbMetric: 3.9350 - val_loss: 4.2419 - val_MinusLogProbMetric: 4.2419 - lr: 2.5000e-04 - 56s/epoch - 284ms/step
Epoch 229/1000
2023-09-17 01:33:45.741 
Epoch 229/1000 
	 loss: 3.9343, MinusLogProbMetric: 3.9343, val_loss: 4.2358, val_MinusLogProbMetric: 4.2358

Epoch 229: val_loss did not improve from 4.19190
196/196 - 65s - loss: 3.9343 - MinusLogProbMetric: 3.9343 - val_loss: 4.2358 - val_MinusLogProbMetric: 4.2358 - lr: 2.5000e-04 - 65s/epoch - 331ms/step
Epoch 230/1000
2023-09-17 01:34:55.172 
Epoch 230/1000 
	 loss: 3.9328, MinusLogProbMetric: 3.9328, val_loss: 4.2251, val_MinusLogProbMetric: 4.2251

Epoch 230: val_loss did not improve from 4.19190
196/196 - 69s - loss: 3.9328 - MinusLogProbMetric: 3.9328 - val_loss: 4.2251 - val_MinusLogProbMetric: 4.2251 - lr: 2.5000e-04 - 69s/epoch - 354ms/step
Epoch 231/1000
2023-09-17 01:36:05.145 
Epoch 231/1000 
	 loss: 3.9432, MinusLogProbMetric: 3.9432, val_loss: 4.2357, val_MinusLogProbMetric: 4.2357

Epoch 231: val_loss did not improve from 4.19190
196/196 - 70s - loss: 3.9432 - MinusLogProbMetric: 3.9432 - val_loss: 4.2357 - val_MinusLogProbMetric: 4.2357 - lr: 2.5000e-04 - 70s/epoch - 357ms/step
Epoch 232/1000
2023-09-17 01:37:13.819 
Epoch 232/1000 
	 loss: 3.9366, MinusLogProbMetric: 3.9366, val_loss: 4.2414, val_MinusLogProbMetric: 4.2414

Epoch 232: val_loss did not improve from 4.19190
196/196 - 69s - loss: 3.9366 - MinusLogProbMetric: 3.9366 - val_loss: 4.2414 - val_MinusLogProbMetric: 4.2414 - lr: 2.5000e-04 - 69s/epoch - 350ms/step
Epoch 233/1000
2023-09-17 01:38:22.335 
Epoch 233/1000 
	 loss: 3.9311, MinusLogProbMetric: 3.9311, val_loss: 4.2381, val_MinusLogProbMetric: 4.2381

Epoch 233: val_loss did not improve from 4.19190
196/196 - 69s - loss: 3.9311 - MinusLogProbMetric: 3.9311 - val_loss: 4.2381 - val_MinusLogProbMetric: 4.2381 - lr: 2.5000e-04 - 69s/epoch - 350ms/step
Epoch 234/1000
2023-09-17 01:39:30.925 
Epoch 234/1000 
	 loss: 3.9301, MinusLogProbMetric: 3.9301, val_loss: 4.2289, val_MinusLogProbMetric: 4.2289

Epoch 234: val_loss did not improve from 4.19190
196/196 - 69s - loss: 3.9301 - MinusLogProbMetric: 3.9301 - val_loss: 4.2289 - val_MinusLogProbMetric: 4.2289 - lr: 2.5000e-04 - 69s/epoch - 350ms/step
Epoch 235/1000
2023-09-17 01:40:39.420 
Epoch 235/1000 
	 loss: 3.9317, MinusLogProbMetric: 3.9317, val_loss: 4.2473, val_MinusLogProbMetric: 4.2473

Epoch 235: val_loss did not improve from 4.19190
196/196 - 68s - loss: 3.9317 - MinusLogProbMetric: 3.9317 - val_loss: 4.2473 - val_MinusLogProbMetric: 4.2473 - lr: 2.5000e-04 - 68s/epoch - 349ms/step
Epoch 236/1000
2023-09-17 01:41:46.204 
Epoch 236/1000 
	 loss: 3.9377, MinusLogProbMetric: 3.9377, val_loss: 4.2636, val_MinusLogProbMetric: 4.2636

Epoch 236: val_loss did not improve from 4.19190
196/196 - 67s - loss: 3.9377 - MinusLogProbMetric: 3.9377 - val_loss: 4.2636 - val_MinusLogProbMetric: 4.2636 - lr: 2.5000e-04 - 67s/epoch - 341ms/step
Epoch 237/1000
2023-09-17 01:42:52.635 
Epoch 237/1000 
	 loss: 3.9365, MinusLogProbMetric: 3.9365, val_loss: 4.2296, val_MinusLogProbMetric: 4.2296

Epoch 237: val_loss did not improve from 4.19190
196/196 - 66s - loss: 3.9365 - MinusLogProbMetric: 3.9365 - val_loss: 4.2296 - val_MinusLogProbMetric: 4.2296 - lr: 2.5000e-04 - 66s/epoch - 339ms/step
Epoch 238/1000
2023-09-17 01:43:59.023 
Epoch 238/1000 
	 loss: 3.9304, MinusLogProbMetric: 3.9304, val_loss: 4.2396, val_MinusLogProbMetric: 4.2396

Epoch 238: val_loss did not improve from 4.19190
196/196 - 66s - loss: 3.9304 - MinusLogProbMetric: 3.9304 - val_loss: 4.2396 - val_MinusLogProbMetric: 4.2396 - lr: 2.5000e-04 - 66s/epoch - 339ms/step
Epoch 239/1000
2023-09-17 01:45:04.755 
Epoch 239/1000 
	 loss: 3.9313, MinusLogProbMetric: 3.9313, val_loss: 4.2385, val_MinusLogProbMetric: 4.2385

Epoch 239: val_loss did not improve from 4.19190
196/196 - 66s - loss: 3.9313 - MinusLogProbMetric: 3.9313 - val_loss: 4.2385 - val_MinusLogProbMetric: 4.2385 - lr: 2.5000e-04 - 66s/epoch - 335ms/step
Epoch 240/1000
2023-09-17 01:46:09.839 
Epoch 240/1000 
	 loss: 3.9331, MinusLogProbMetric: 3.9331, val_loss: 4.2744, val_MinusLogProbMetric: 4.2744

Epoch 240: val_loss did not improve from 4.19190
196/196 - 65s - loss: 3.9331 - MinusLogProbMetric: 3.9331 - val_loss: 4.2744 - val_MinusLogProbMetric: 4.2744 - lr: 2.5000e-04 - 65s/epoch - 332ms/step
Epoch 241/1000
2023-09-17 01:47:13.802 
Epoch 241/1000 
	 loss: 3.9317, MinusLogProbMetric: 3.9317, val_loss: 4.2590, val_MinusLogProbMetric: 4.2590

Epoch 241: val_loss did not improve from 4.19190
196/196 - 64s - loss: 3.9317 - MinusLogProbMetric: 3.9317 - val_loss: 4.2590 - val_MinusLogProbMetric: 4.2590 - lr: 2.5000e-04 - 64s/epoch - 326ms/step
Epoch 242/1000
2023-09-17 01:48:17.907 
Epoch 242/1000 
	 loss: 3.9299, MinusLogProbMetric: 3.9299, val_loss: 4.2411, val_MinusLogProbMetric: 4.2411

Epoch 242: val_loss did not improve from 4.19190
196/196 - 64s - loss: 3.9299 - MinusLogProbMetric: 3.9299 - val_loss: 4.2411 - val_MinusLogProbMetric: 4.2411 - lr: 2.5000e-04 - 64s/epoch - 327ms/step
Epoch 243/1000
2023-09-17 01:49:21.770 
Epoch 243/1000 
	 loss: 3.9305, MinusLogProbMetric: 3.9305, val_loss: 4.2392, val_MinusLogProbMetric: 4.2392

Epoch 243: val_loss did not improve from 4.19190
196/196 - 64s - loss: 3.9305 - MinusLogProbMetric: 3.9305 - val_loss: 4.2392 - val_MinusLogProbMetric: 4.2392 - lr: 2.5000e-04 - 64s/epoch - 326ms/step
Epoch 244/1000
2023-09-17 01:50:26.261 
Epoch 244/1000 
	 loss: 3.9290, MinusLogProbMetric: 3.9290, val_loss: 4.2544, val_MinusLogProbMetric: 4.2544

Epoch 244: val_loss did not improve from 4.19190
196/196 - 64s - loss: 3.9290 - MinusLogProbMetric: 3.9290 - val_loss: 4.2544 - val_MinusLogProbMetric: 4.2544 - lr: 2.5000e-04 - 64s/epoch - 329ms/step
Epoch 245/1000
2023-09-17 01:51:31.166 
Epoch 245/1000 
	 loss: 3.9314, MinusLogProbMetric: 3.9314, val_loss: 4.2487, val_MinusLogProbMetric: 4.2487

Epoch 245: val_loss did not improve from 4.19190
196/196 - 65s - loss: 3.9314 - MinusLogProbMetric: 3.9314 - val_loss: 4.2487 - val_MinusLogProbMetric: 4.2487 - lr: 2.5000e-04 - 65s/epoch - 331ms/step
Epoch 246/1000
2023-09-17 01:52:35.087 
Epoch 246/1000 
	 loss: 3.9313, MinusLogProbMetric: 3.9313, val_loss: 4.2371, val_MinusLogProbMetric: 4.2371

Epoch 246: val_loss did not improve from 4.19190
196/196 - 64s - loss: 3.9313 - MinusLogProbMetric: 3.9313 - val_loss: 4.2371 - val_MinusLogProbMetric: 4.2371 - lr: 2.5000e-04 - 64s/epoch - 326ms/step
Epoch 247/1000
2023-09-17 01:53:38.942 
Epoch 247/1000 
	 loss: 3.9299, MinusLogProbMetric: 3.9299, val_loss: 4.2496, val_MinusLogProbMetric: 4.2496

Epoch 247: val_loss did not improve from 4.19190
196/196 - 64s - loss: 3.9299 - MinusLogProbMetric: 3.9299 - val_loss: 4.2496 - val_MinusLogProbMetric: 4.2496 - lr: 2.5000e-04 - 64s/epoch - 326ms/step
Epoch 248/1000
2023-09-17 01:54:43.728 
Epoch 248/1000 
	 loss: 3.9290, MinusLogProbMetric: 3.9290, val_loss: 4.2589, val_MinusLogProbMetric: 4.2589

Epoch 248: val_loss did not improve from 4.19190
196/196 - 65s - loss: 3.9290 - MinusLogProbMetric: 3.9290 - val_loss: 4.2589 - val_MinusLogProbMetric: 4.2589 - lr: 2.5000e-04 - 65s/epoch - 331ms/step
Epoch 249/1000
2023-09-17 01:55:42.862 
Epoch 249/1000 
	 loss: 3.9293, MinusLogProbMetric: 3.9293, val_loss: 4.2579, val_MinusLogProbMetric: 4.2579

Epoch 249: val_loss did not improve from 4.19190
196/196 - 59s - loss: 3.9293 - MinusLogProbMetric: 3.9293 - val_loss: 4.2579 - val_MinusLogProbMetric: 4.2579 - lr: 2.5000e-04 - 59s/epoch - 302ms/step
Epoch 250/1000
2023-09-17 01:56:37.665 
Epoch 250/1000 
	 loss: 3.9324, MinusLogProbMetric: 3.9324, val_loss: 4.2404, val_MinusLogProbMetric: 4.2404

Epoch 250: val_loss did not improve from 4.19190
196/196 - 55s - loss: 3.9324 - MinusLogProbMetric: 3.9324 - val_loss: 4.2404 - val_MinusLogProbMetric: 4.2404 - lr: 2.5000e-04 - 55s/epoch - 280ms/step
Epoch 251/1000
2023-09-17 01:57:42.069 
Epoch 251/1000 
	 loss: 3.9260, MinusLogProbMetric: 3.9260, val_loss: 4.2468, val_MinusLogProbMetric: 4.2468

Epoch 251: val_loss did not improve from 4.19190
196/196 - 64s - loss: 3.9260 - MinusLogProbMetric: 3.9260 - val_loss: 4.2468 - val_MinusLogProbMetric: 4.2468 - lr: 2.5000e-04 - 64s/epoch - 329ms/step
Epoch 252/1000
2023-09-17 01:58:46.566 
Epoch 252/1000 
	 loss: 3.9265, MinusLogProbMetric: 3.9265, val_loss: 4.2477, val_MinusLogProbMetric: 4.2477

Epoch 252: val_loss did not improve from 4.19190
196/196 - 64s - loss: 3.9265 - MinusLogProbMetric: 3.9265 - val_loss: 4.2477 - val_MinusLogProbMetric: 4.2477 - lr: 2.5000e-04 - 64s/epoch - 329ms/step
Epoch 253/1000
2023-09-17 01:59:51.666 
Epoch 253/1000 
	 loss: 3.9230, MinusLogProbMetric: 3.9230, val_loss: 4.2354, val_MinusLogProbMetric: 4.2354

Epoch 253: val_loss did not improve from 4.19190
196/196 - 65s - loss: 3.9230 - MinusLogProbMetric: 3.9230 - val_loss: 4.2354 - val_MinusLogProbMetric: 4.2354 - lr: 2.5000e-04 - 65s/epoch - 332ms/step
Epoch 254/1000
2023-09-17 02:00:55.763 
Epoch 254/1000 
	 loss: 3.9234, MinusLogProbMetric: 3.9234, val_loss: 4.2386, val_MinusLogProbMetric: 4.2386

Epoch 254: val_loss did not improve from 4.19190
196/196 - 64s - loss: 3.9234 - MinusLogProbMetric: 3.9234 - val_loss: 4.2386 - val_MinusLogProbMetric: 4.2386 - lr: 2.5000e-04 - 64s/epoch - 327ms/step
Epoch 255/1000
2023-09-17 02:02:00.425 
Epoch 255/1000 
	 loss: 3.9245, MinusLogProbMetric: 3.9245, val_loss: 4.2444, val_MinusLogProbMetric: 4.2444

Epoch 255: val_loss did not improve from 4.19190
196/196 - 65s - loss: 3.9245 - MinusLogProbMetric: 3.9245 - val_loss: 4.2444 - val_MinusLogProbMetric: 4.2444 - lr: 2.5000e-04 - 65s/epoch - 330ms/step
Epoch 256/1000
2023-09-17 02:03:05.812 
Epoch 256/1000 
	 loss: 3.9253, MinusLogProbMetric: 3.9253, val_loss: 4.2509, val_MinusLogProbMetric: 4.2509

Epoch 256: val_loss did not improve from 4.19190
196/196 - 65s - loss: 3.9253 - MinusLogProbMetric: 3.9253 - val_loss: 4.2509 - val_MinusLogProbMetric: 4.2509 - lr: 2.5000e-04 - 65s/epoch - 334ms/step
Epoch 257/1000
2023-09-17 02:04:11.779 
Epoch 257/1000 
	 loss: 3.9258, MinusLogProbMetric: 3.9258, val_loss: 4.2419, val_MinusLogProbMetric: 4.2419

Epoch 257: val_loss did not improve from 4.19190
196/196 - 66s - loss: 3.9258 - MinusLogProbMetric: 3.9258 - val_loss: 4.2419 - val_MinusLogProbMetric: 4.2419 - lr: 2.5000e-04 - 66s/epoch - 337ms/step
Epoch 258/1000
2023-09-17 02:05:13.321 
Epoch 258/1000 
	 loss: 3.9236, MinusLogProbMetric: 3.9236, val_loss: 4.2595, val_MinusLogProbMetric: 4.2595

Epoch 258: val_loss did not improve from 4.19190
196/196 - 62s - loss: 3.9236 - MinusLogProbMetric: 3.9236 - val_loss: 4.2595 - val_MinusLogProbMetric: 4.2595 - lr: 2.5000e-04 - 62s/epoch - 314ms/step
Epoch 259/1000
2023-09-17 02:06:15.348 
Epoch 259/1000 
	 loss: 3.9217, MinusLogProbMetric: 3.9217, val_loss: 4.2657, val_MinusLogProbMetric: 4.2657

Epoch 259: val_loss did not improve from 4.19190
Restoring model weights from the end of the best epoch: 159.
196/196 - 63s - loss: 3.9217 - MinusLogProbMetric: 3.9217 - val_loss: 4.2657 - val_MinusLogProbMetric: 4.2657 - lr: 2.5000e-04 - 63s/epoch - 320ms/step
Epoch 259: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 23.935267327120528 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 11.51016289088875 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 7.653264982160181 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7faf40185870> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 23.309504461009055 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 7.91803841595538 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 8.375939097022638 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fb6c0c5e7a0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 187.
Model trained in 17179.48 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

Plots done in 10.36 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 116.58 s.
===========
Run 93/720 done in 17305.11 s.
===========

Directory ../../results/CsplineN_new/run_94/ already exists.
Skipping it.
===========
Run 94/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_95/ already exists.
Skipping it.
===========
Run 95/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_96/ already exists.
Skipping it.
===========
Run 96/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_97/ already exists.
Skipping it.
===========
Run 97/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_98/ already exists.
Skipping it.
===========
Run 98/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_99/ already exists.
Skipping it.
===========
Run 99/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_100/ already exists.
Skipping it.
===========
Run 100/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_101/ already exists.
Skipping it.
===========
Run 101/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_102/ already exists.
Skipping it.
===========
Run 102/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_103/ already exists.
Skipping it.
===========
Run 103/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_104/ already exists.
Skipping it.
===========
Run 104/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_105/ already exists.
Skipping it.
===========
Run 105/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_106/ already exists.
Skipping it.
===========
Run 106/720 already exists. Skipping it.
===========

===========
Generating train data for run 107.
===========
Train data generated in 0.26 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 8)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_107/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 440}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_107/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.65712   ,  6.182868  ,  6.320793  , ...,  6.224411  ,
         4.407977  ,  8.273342  ],
       [ 5.6647167 ,  7.6784825 ,  6.103832  , ...,  6.9132586 ,
         4.0071416 ,  9.627362  ],
       [ 0.0757564 ,  8.787646  ,  9.654894  , ...,  7.7624927 ,
         4.59853   ,  7.8518796 ],
       ...,
       [ 8.965884  ,  3.0239487 ,  7.898685  , ...,  9.606702  ,
         1.019942  ,  1.8909395 ],
       [ 0.66036737,  8.391064  ,  7.9419107 , ...,  8.014944  ,
         4.8080764 ,  7.7307167 ],
       [-0.07102557,  8.791537  ,  7.5852127 , ...,  8.631427  ,
         4.910859  ,  7.877132  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_107/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_107
self.data_kwargs: {'seed': 440}
self.x_data: [[ 9.710083    3.9211245   7.8928385  ...  9.772914    0.22835314
   1.7858514 ]
 [-0.06894769  8.409845    7.820752   ...  7.9066367   4.669789
   7.6796193 ]
 [10.280643    4.250588    7.9206114  ... 10.173959    1.6905015
   1.7195234 ]
 ...
 [ 0.2729339   7.4083323   8.085693   ...  7.883582    4.7593393
   7.733472  ]
 [-0.36202502  7.93172     8.479606   ...  7.927877    5.080957
   7.6926637 ]
 [ 9.848026    4.719975    7.9264145  ...  9.937142    2.2071612
   0.98272586]]
self.y_data: []
self.ndims: 8
Model defined.
Model: "model_71"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_72 (InputLayer)       [(None, 8)]               0         
                                                                 
 log_prob_layer_6 (LogProbLa  (None,)                  258620    
 yer)                                                            
                                                                 
=================================================================
Total params: 258,620
Trainable params: 258,620
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_6/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_6'")
self.model: <keras.engine.functional.Functional object at 0x7faf5235d090>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7faf61dfb250>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7faf61dfb250>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7faf61df9b70>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7faf61dfa080>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7faf61df8100>, <keras.callbacks.ModelCheckpoint object at 0x7faf61df84f0>, <keras.callbacks.EarlyStopping object at 0x7faf61df8820>, <keras.callbacks.ReduceLROnPlateau object at 0x7faf61df87c0>, <keras.callbacks.TerminateOnNaN object at 0x7faf61df8070>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.65712   ,  6.182868  ,  6.320793  , ...,  6.224411  ,
         4.407977  ,  8.273342  ],
       [ 5.6647167 ,  7.6784825 ,  6.103832  , ...,  6.9132586 ,
         4.0071416 ,  9.627362  ],
       [ 0.0757564 ,  8.787646  ,  9.654894  , ...,  7.7624927 ,
         4.59853   ,  7.8518796 ],
       ...,
       [ 8.965884  ,  3.0239487 ,  7.898685  , ...,  9.606702  ,
         1.019942  ,  1.8909395 ],
       [ 0.66036737,  8.391064  ,  7.9419107 , ...,  8.014944  ,
         4.8080764 ,  7.7307167 ],
       [-0.07102557,  8.791537  ,  7.5852127 , ...,  8.631427  ,
         4.910859  ,  7.877132  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_107/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 107/720 with hyperparameters:
timestamp = 2023-09-17 02:08:27.413364
ndims = 8
seed_train = 440
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 5
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 258620
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [9.710083   3.9211245  7.8928385  5.807563   6.354877   9.772914
 0.22835314 1.7858514 ]
Epoch 1/1000
2023-09-17 02:10:30.797 
Epoch 1/1000 
	 loss: 14.9520, MinusLogProbMetric: 14.9520, val_loss: 6.2259, val_MinusLogProbMetric: 6.2259

Epoch 1: val_loss improved from inf to 6.22594, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 124s - loss: 14.9520 - MinusLogProbMetric: 14.9520 - val_loss: 6.2259 - val_MinusLogProbMetric: 6.2259 - lr: 0.0010 - 124s/epoch - 634ms/step
Epoch 2/1000
2023-09-17 02:11:13.128 
Epoch 2/1000 
	 loss: 5.6959, MinusLogProbMetric: 5.6959, val_loss: 5.6992, val_MinusLogProbMetric: 5.6992

Epoch 2: val_loss improved from 6.22594 to 5.69923, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 42s - loss: 5.6959 - MinusLogProbMetric: 5.6959 - val_loss: 5.6992 - val_MinusLogProbMetric: 5.6992 - lr: 0.0010 - 42s/epoch - 215ms/step
Epoch 3/1000
2023-09-17 02:11:56.472 
Epoch 3/1000 
	 loss: 5.1935, MinusLogProbMetric: 5.1935, val_loss: 5.6169, val_MinusLogProbMetric: 5.6169

Epoch 3: val_loss improved from 5.69923 to 5.61690, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 43s - loss: 5.1935 - MinusLogProbMetric: 5.1935 - val_loss: 5.6169 - val_MinusLogProbMetric: 5.6169 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 4/1000
2023-09-17 02:12:39.802 
Epoch 4/1000 
	 loss: 5.0001, MinusLogProbMetric: 5.0001, val_loss: 5.6792, val_MinusLogProbMetric: 5.6792

Epoch 4: val_loss did not improve from 5.61690
196/196 - 43s - loss: 5.0001 - MinusLogProbMetric: 5.0001 - val_loss: 5.6792 - val_MinusLogProbMetric: 5.6792 - lr: 0.0010 - 43s/epoch - 217ms/step
Epoch 5/1000
2023-09-17 02:13:21.793 
Epoch 5/1000 
	 loss: 4.8180, MinusLogProbMetric: 4.8180, val_loss: 4.8930, val_MinusLogProbMetric: 4.8930

Epoch 5: val_loss improved from 5.61690 to 4.89296, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 43s - loss: 4.8180 - MinusLogProbMetric: 4.8180 - val_loss: 4.8930 - val_MinusLogProbMetric: 4.8930 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 6/1000
2023-09-17 02:14:05.511 
Epoch 6/1000 
	 loss: 4.7389, MinusLogProbMetric: 4.7389, val_loss: 4.6421, val_MinusLogProbMetric: 4.6421

Epoch 6: val_loss improved from 4.89296 to 4.64206, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 44s - loss: 4.7389 - MinusLogProbMetric: 4.7389 - val_loss: 4.6421 - val_MinusLogProbMetric: 4.6421 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 7/1000
2023-09-17 02:14:50.251 
Epoch 7/1000 
	 loss: 4.6772, MinusLogProbMetric: 4.6772, val_loss: 4.5156, val_MinusLogProbMetric: 4.5156

Epoch 7: val_loss improved from 4.64206 to 4.51557, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 45s - loss: 4.6772 - MinusLogProbMetric: 4.6772 - val_loss: 4.5156 - val_MinusLogProbMetric: 4.5156 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 8/1000
2023-09-17 02:15:33.895 
Epoch 8/1000 
	 loss: 4.6398, MinusLogProbMetric: 4.6398, val_loss: 4.5046, val_MinusLogProbMetric: 4.5046

Epoch 8: val_loss improved from 4.51557 to 4.50458, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 44s - loss: 4.6398 - MinusLogProbMetric: 4.6398 - val_loss: 4.5046 - val_MinusLogProbMetric: 4.5046 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 9/1000
2023-09-17 02:16:17.783 
Epoch 9/1000 
	 loss: 4.5389, MinusLogProbMetric: 4.5389, val_loss: 4.5308, val_MinusLogProbMetric: 4.5308

Epoch 9: val_loss did not improve from 4.50458
196/196 - 43s - loss: 4.5389 - MinusLogProbMetric: 4.5389 - val_loss: 4.5308 - val_MinusLogProbMetric: 4.5308 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 10/1000
2023-09-17 02:17:00.807 
Epoch 10/1000 
	 loss: 4.5288, MinusLogProbMetric: 4.5288, val_loss: 5.1887, val_MinusLogProbMetric: 5.1887

Epoch 10: val_loss did not improve from 4.50458
196/196 - 43s - loss: 4.5288 - MinusLogProbMetric: 4.5288 - val_loss: 5.1887 - val_MinusLogProbMetric: 5.1887 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 11/1000
2023-09-17 02:17:44.149 
Epoch 11/1000 
	 loss: 4.4808, MinusLogProbMetric: 4.4808, val_loss: 4.6930, val_MinusLogProbMetric: 4.6930

Epoch 11: val_loss did not improve from 4.50458
196/196 - 43s - loss: 4.4808 - MinusLogProbMetric: 4.4808 - val_loss: 4.6930 - val_MinusLogProbMetric: 4.6930 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 12/1000
2023-09-17 02:18:27.419 
Epoch 12/1000 
	 loss: 4.4493, MinusLogProbMetric: 4.4493, val_loss: 4.4214, val_MinusLogProbMetric: 4.4214

Epoch 12: val_loss improved from 4.50458 to 4.42144, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 44s - loss: 4.4493 - MinusLogProbMetric: 4.4493 - val_loss: 4.4214 - val_MinusLogProbMetric: 4.4214 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 13/1000
2023-09-17 02:19:08.559 
Epoch 13/1000 
	 loss: 4.4301, MinusLogProbMetric: 4.4301, val_loss: 4.3736, val_MinusLogProbMetric: 4.3736

Epoch 13: val_loss improved from 4.42144 to 4.37364, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 41s - loss: 4.4301 - MinusLogProbMetric: 4.4301 - val_loss: 4.3736 - val_MinusLogProbMetric: 4.3736 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 14/1000
2023-09-17 02:19:49.741 
Epoch 14/1000 
	 loss: 4.3685, MinusLogProbMetric: 4.3685, val_loss: 4.3144, val_MinusLogProbMetric: 4.3144

Epoch 14: val_loss improved from 4.37364 to 4.31435, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 41s - loss: 4.3685 - MinusLogProbMetric: 4.3685 - val_loss: 4.3144 - val_MinusLogProbMetric: 4.3144 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 15/1000
2023-09-17 02:20:26.481 
Epoch 15/1000 
	 loss: 4.3534, MinusLogProbMetric: 4.3534, val_loss: 4.3800, val_MinusLogProbMetric: 4.3800

Epoch 15: val_loss did not improve from 4.31435
196/196 - 36s - loss: 4.3534 - MinusLogProbMetric: 4.3534 - val_loss: 4.3800 - val_MinusLogProbMetric: 4.3800 - lr: 0.0010 - 36s/epoch - 183ms/step
Epoch 16/1000
2023-09-17 02:21:07.991 
Epoch 16/1000 
	 loss: 4.3392, MinusLogProbMetric: 4.3392, val_loss: 4.5764, val_MinusLogProbMetric: 4.5764

Epoch 16: val_loss did not improve from 4.31435
196/196 - 42s - loss: 4.3392 - MinusLogProbMetric: 4.3392 - val_loss: 4.5764 - val_MinusLogProbMetric: 4.5764 - lr: 0.0010 - 42s/epoch - 212ms/step
Epoch 17/1000
2023-09-17 02:21:51.694 
Epoch 17/1000 
	 loss: 4.3207, MinusLogProbMetric: 4.3207, val_loss: 4.2554, val_MinusLogProbMetric: 4.2554

Epoch 17: val_loss improved from 4.31435 to 4.25542, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 44s - loss: 4.3207 - MinusLogProbMetric: 4.3207 - val_loss: 4.2554 - val_MinusLogProbMetric: 4.2554 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 18/1000
2023-09-17 02:22:35.927 
Epoch 18/1000 
	 loss: 4.3094, MinusLogProbMetric: 4.3094, val_loss: 4.2970, val_MinusLogProbMetric: 4.2970

Epoch 18: val_loss did not improve from 4.25542
196/196 - 44s - loss: 4.3094 - MinusLogProbMetric: 4.3094 - val_loss: 4.2970 - val_MinusLogProbMetric: 4.2970 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 19/1000
2023-09-17 02:23:19.301 
Epoch 19/1000 
	 loss: 4.2931, MinusLogProbMetric: 4.2931, val_loss: 4.3599, val_MinusLogProbMetric: 4.3599

Epoch 19: val_loss did not improve from 4.25542
196/196 - 43s - loss: 4.2931 - MinusLogProbMetric: 4.2931 - val_loss: 4.3599 - val_MinusLogProbMetric: 4.3599 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 20/1000
2023-09-17 02:24:03.182 
Epoch 20/1000 
	 loss: 4.2842, MinusLogProbMetric: 4.2842, val_loss: 4.2770, val_MinusLogProbMetric: 4.2770

Epoch 20: val_loss did not improve from 4.25542
196/196 - 44s - loss: 4.2842 - MinusLogProbMetric: 4.2842 - val_loss: 4.2770 - val_MinusLogProbMetric: 4.2770 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 21/1000
2023-09-17 02:24:46.175 
Epoch 21/1000 
	 loss: 4.2731, MinusLogProbMetric: 4.2731, val_loss: 4.2893, val_MinusLogProbMetric: 4.2893

Epoch 21: val_loss did not improve from 4.25542
196/196 - 43s - loss: 4.2731 - MinusLogProbMetric: 4.2731 - val_loss: 4.2893 - val_MinusLogProbMetric: 4.2893 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 22/1000
2023-09-17 02:25:30.021 
Epoch 22/1000 
	 loss: 4.2590, MinusLogProbMetric: 4.2590, val_loss: 4.2546, val_MinusLogProbMetric: 4.2546

Epoch 22: val_loss improved from 4.25542 to 4.25459, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 44s - loss: 4.2590 - MinusLogProbMetric: 4.2590 - val_loss: 4.2546 - val_MinusLogProbMetric: 4.2546 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 23/1000
2023-09-17 02:26:13.792 
Epoch 23/1000 
	 loss: 4.2729, MinusLogProbMetric: 4.2729, val_loss: 4.2644, val_MinusLogProbMetric: 4.2644

Epoch 23: val_loss did not improve from 4.25459
196/196 - 43s - loss: 4.2729 - MinusLogProbMetric: 4.2729 - val_loss: 4.2644 - val_MinusLogProbMetric: 4.2644 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 24/1000
2023-09-17 02:26:57.151 
Epoch 24/1000 
	 loss: 4.2619, MinusLogProbMetric: 4.2619, val_loss: 4.3022, val_MinusLogProbMetric: 4.3022

Epoch 24: val_loss did not improve from 4.25459
196/196 - 43s - loss: 4.2619 - MinusLogProbMetric: 4.2619 - val_loss: 4.3022 - val_MinusLogProbMetric: 4.3022 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 25/1000
2023-09-17 02:27:40.782 
Epoch 25/1000 
	 loss: 4.2448, MinusLogProbMetric: 4.2448, val_loss: 4.3259, val_MinusLogProbMetric: 4.3259

Epoch 25: val_loss did not improve from 4.25459
196/196 - 44s - loss: 4.2448 - MinusLogProbMetric: 4.2448 - val_loss: 4.3259 - val_MinusLogProbMetric: 4.3259 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 26/1000
2023-09-17 02:28:23.951 
Epoch 26/1000 
	 loss: 4.2376, MinusLogProbMetric: 4.2376, val_loss: 4.2548, val_MinusLogProbMetric: 4.2548

Epoch 26: val_loss did not improve from 4.25459
196/196 - 43s - loss: 4.2376 - MinusLogProbMetric: 4.2376 - val_loss: 4.2548 - val_MinusLogProbMetric: 4.2548 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 27/1000
2023-09-17 02:29:08.296 
Epoch 27/1000 
	 loss: 4.2357, MinusLogProbMetric: 4.2357, val_loss: 4.2268, val_MinusLogProbMetric: 4.2268

Epoch 27: val_loss improved from 4.25459 to 4.22676, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 45s - loss: 4.2357 - MinusLogProbMetric: 4.2357 - val_loss: 4.2268 - val_MinusLogProbMetric: 4.2268 - lr: 0.0010 - 45s/epoch - 231ms/step
Epoch 28/1000
2023-09-17 02:29:52.539 
Epoch 28/1000 
	 loss: 4.2298, MinusLogProbMetric: 4.2298, val_loss: 4.3134, val_MinusLogProbMetric: 4.3134

Epoch 28: val_loss did not improve from 4.22676
196/196 - 43s - loss: 4.2298 - MinusLogProbMetric: 4.2298 - val_loss: 4.3134 - val_MinusLogProbMetric: 4.3134 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 29/1000
2023-09-17 02:30:36.557 
Epoch 29/1000 
	 loss: 4.2326, MinusLogProbMetric: 4.2326, val_loss: 4.3821, val_MinusLogProbMetric: 4.3821

Epoch 29: val_loss did not improve from 4.22676
196/196 - 44s - loss: 4.2326 - MinusLogProbMetric: 4.2326 - val_loss: 4.3821 - val_MinusLogProbMetric: 4.3821 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 30/1000
2023-09-17 02:31:20.255 
Epoch 30/1000 
	 loss: 4.2211, MinusLogProbMetric: 4.2211, val_loss: 4.3558, val_MinusLogProbMetric: 4.3558

Epoch 30: val_loss did not improve from 4.22676
196/196 - 44s - loss: 4.2211 - MinusLogProbMetric: 4.2211 - val_loss: 4.3558 - val_MinusLogProbMetric: 4.3558 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 31/1000
2023-09-17 02:32:03.648 
Epoch 31/1000 
	 loss: 4.2145, MinusLogProbMetric: 4.2145, val_loss: 4.4074, val_MinusLogProbMetric: 4.4074

Epoch 31: val_loss did not improve from 4.22676
196/196 - 43s - loss: 4.2145 - MinusLogProbMetric: 4.2145 - val_loss: 4.4074 - val_MinusLogProbMetric: 4.4074 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 32/1000
2023-09-17 02:32:47.289 
Epoch 32/1000 
	 loss: 4.2148, MinusLogProbMetric: 4.2148, val_loss: 4.2635, val_MinusLogProbMetric: 4.2635

Epoch 32: val_loss did not improve from 4.22676
196/196 - 44s - loss: 4.2148 - MinusLogProbMetric: 4.2148 - val_loss: 4.2635 - val_MinusLogProbMetric: 4.2635 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 33/1000
2023-09-17 02:33:30.837 
Epoch 33/1000 
	 loss: 4.2266, MinusLogProbMetric: 4.2266, val_loss: 4.3095, val_MinusLogProbMetric: 4.3095

Epoch 33: val_loss did not improve from 4.22676
196/196 - 44s - loss: 4.2266 - MinusLogProbMetric: 4.2266 - val_loss: 4.3095 - val_MinusLogProbMetric: 4.3095 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 34/1000
2023-09-17 02:34:14.452 
Epoch 34/1000 
	 loss: 4.2113, MinusLogProbMetric: 4.2113, val_loss: 4.2425, val_MinusLogProbMetric: 4.2425

Epoch 34: val_loss did not improve from 4.22676
196/196 - 44s - loss: 4.2113 - MinusLogProbMetric: 4.2113 - val_loss: 4.2425 - val_MinusLogProbMetric: 4.2425 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 35/1000
2023-09-17 02:34:57.714 
Epoch 35/1000 
	 loss: 4.2072, MinusLogProbMetric: 4.2072, val_loss: 4.3194, val_MinusLogProbMetric: 4.3194

Epoch 35: val_loss did not improve from 4.22676
196/196 - 43s - loss: 4.2072 - MinusLogProbMetric: 4.2072 - val_loss: 4.3194 - val_MinusLogProbMetric: 4.3194 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 36/1000
2023-09-17 02:35:41.531 
Epoch 36/1000 
	 loss: 4.2039, MinusLogProbMetric: 4.2039, val_loss: 4.3354, val_MinusLogProbMetric: 4.3354

Epoch 36: val_loss did not improve from 4.22676
196/196 - 44s - loss: 4.2039 - MinusLogProbMetric: 4.2039 - val_loss: 4.3354 - val_MinusLogProbMetric: 4.3354 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 37/1000
2023-09-17 02:36:24.834 
Epoch 37/1000 
	 loss: 4.2054, MinusLogProbMetric: 4.2054, val_loss: 4.2568, val_MinusLogProbMetric: 4.2568

Epoch 37: val_loss did not improve from 4.22676
196/196 - 43s - loss: 4.2054 - MinusLogProbMetric: 4.2054 - val_loss: 4.2568 - val_MinusLogProbMetric: 4.2568 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 38/1000
2023-09-17 02:37:08.666 
Epoch 38/1000 
	 loss: 4.2007, MinusLogProbMetric: 4.2007, val_loss: 4.2878, val_MinusLogProbMetric: 4.2878

Epoch 38: val_loss did not improve from 4.22676
196/196 - 44s - loss: 4.2007 - MinusLogProbMetric: 4.2007 - val_loss: 4.2878 - val_MinusLogProbMetric: 4.2878 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 39/1000
2023-09-17 02:37:52.252 
Epoch 39/1000 
	 loss: 4.1973, MinusLogProbMetric: 4.1973, val_loss: 4.2167, val_MinusLogProbMetric: 4.2167

Epoch 39: val_loss improved from 4.22676 to 4.21672, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 44s - loss: 4.1973 - MinusLogProbMetric: 4.1973 - val_loss: 4.2167 - val_MinusLogProbMetric: 4.2167 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 40/1000
2023-09-17 02:38:37.015 
Epoch 40/1000 
	 loss: 4.2048, MinusLogProbMetric: 4.2048, val_loss: 4.2710, val_MinusLogProbMetric: 4.2710

Epoch 40: val_loss did not improve from 4.21672
196/196 - 44s - loss: 4.2048 - MinusLogProbMetric: 4.2048 - val_loss: 4.2710 - val_MinusLogProbMetric: 4.2710 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 41/1000
2023-09-17 02:39:20.220 
Epoch 41/1000 
	 loss: 4.1966, MinusLogProbMetric: 4.1966, val_loss: 4.2153, val_MinusLogProbMetric: 4.2153

Epoch 41: val_loss improved from 4.21672 to 4.21526, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 44s - loss: 4.1966 - MinusLogProbMetric: 4.1966 - val_loss: 4.2153 - val_MinusLogProbMetric: 4.2153 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 42/1000
2023-09-17 02:40:04.368 
Epoch 42/1000 
	 loss: 4.1705, MinusLogProbMetric: 4.1705, val_loss: 4.2502, val_MinusLogProbMetric: 4.2502

Epoch 42: val_loss did not improve from 4.21526
196/196 - 43s - loss: 4.1705 - MinusLogProbMetric: 4.1705 - val_loss: 4.2502 - val_MinusLogProbMetric: 4.2502 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 43/1000
2023-09-17 02:40:48.015 
Epoch 43/1000 
	 loss: 4.1897, MinusLogProbMetric: 4.1897, val_loss: 4.2302, val_MinusLogProbMetric: 4.2302

Epoch 43: val_loss did not improve from 4.21526
196/196 - 44s - loss: 4.1897 - MinusLogProbMetric: 4.1897 - val_loss: 4.2302 - val_MinusLogProbMetric: 4.2302 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 44/1000
2023-09-17 02:41:31.106 
Epoch 44/1000 
	 loss: 4.1883, MinusLogProbMetric: 4.1883, val_loss: 4.2070, val_MinusLogProbMetric: 4.2070

Epoch 44: val_loss improved from 4.21526 to 4.20696, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 44s - loss: 4.1883 - MinusLogProbMetric: 4.1883 - val_loss: 4.2070 - val_MinusLogProbMetric: 4.2070 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 45/1000
2023-09-17 02:42:15.124 
Epoch 45/1000 
	 loss: 4.1734, MinusLogProbMetric: 4.1734, val_loss: 4.2206, val_MinusLogProbMetric: 4.2206

Epoch 45: val_loss did not improve from 4.20696
196/196 - 43s - loss: 4.1734 - MinusLogProbMetric: 4.1734 - val_loss: 4.2206 - val_MinusLogProbMetric: 4.2206 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 46/1000
2023-09-17 02:42:58.635 
Epoch 46/1000 
	 loss: 4.1712, MinusLogProbMetric: 4.1712, val_loss: 4.2419, val_MinusLogProbMetric: 4.2419

Epoch 46: val_loss did not improve from 4.20696
196/196 - 44s - loss: 4.1712 - MinusLogProbMetric: 4.1712 - val_loss: 4.2419 - val_MinusLogProbMetric: 4.2419 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 47/1000
2023-09-17 02:43:42.166 
Epoch 47/1000 
	 loss: 4.1853, MinusLogProbMetric: 4.1853, val_loss: 4.2788, val_MinusLogProbMetric: 4.2788

Epoch 47: val_loss did not improve from 4.20696
196/196 - 44s - loss: 4.1853 - MinusLogProbMetric: 4.1853 - val_loss: 4.2788 - val_MinusLogProbMetric: 4.2788 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 48/1000
2023-09-17 02:44:25.378 
Epoch 48/1000 
	 loss: 4.1693, MinusLogProbMetric: 4.1693, val_loss: 4.2337, val_MinusLogProbMetric: 4.2337

Epoch 48: val_loss did not improve from 4.20696
196/196 - 43s - loss: 4.1693 - MinusLogProbMetric: 4.1693 - val_loss: 4.2337 - val_MinusLogProbMetric: 4.2337 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 49/1000
2023-09-17 02:45:08.842 
Epoch 49/1000 
	 loss: 4.1690, MinusLogProbMetric: 4.1690, val_loss: 4.2469, val_MinusLogProbMetric: 4.2469

Epoch 49: val_loss did not improve from 4.20696
196/196 - 43s - loss: 4.1690 - MinusLogProbMetric: 4.1690 - val_loss: 4.2469 - val_MinusLogProbMetric: 4.2469 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 50/1000
2023-09-17 02:45:52.136 
Epoch 50/1000 
	 loss: 4.1664, MinusLogProbMetric: 4.1664, val_loss: 4.2137, val_MinusLogProbMetric: 4.2137

Epoch 50: val_loss did not improve from 4.20696
196/196 - 43s - loss: 4.1664 - MinusLogProbMetric: 4.1664 - val_loss: 4.2137 - val_MinusLogProbMetric: 4.2137 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 51/1000
2023-09-17 02:46:36.022 
Epoch 51/1000 
	 loss: 4.1681, MinusLogProbMetric: 4.1681, val_loss: 4.1984, val_MinusLogProbMetric: 4.1984

Epoch 51: val_loss improved from 4.20696 to 4.19843, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 45s - loss: 4.1681 - MinusLogProbMetric: 4.1681 - val_loss: 4.1984 - val_MinusLogProbMetric: 4.1984 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 52/1000
2023-09-17 02:47:20.439 
Epoch 52/1000 
	 loss: 4.1586, MinusLogProbMetric: 4.1586, val_loss: 4.2212, val_MinusLogProbMetric: 4.2212

Epoch 52: val_loss did not improve from 4.19843
196/196 - 44s - loss: 4.1586 - MinusLogProbMetric: 4.1586 - val_loss: 4.2212 - val_MinusLogProbMetric: 4.2212 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 53/1000
2023-09-17 02:48:03.841 
Epoch 53/1000 
	 loss: 4.1681, MinusLogProbMetric: 4.1681, val_loss: 4.1916, val_MinusLogProbMetric: 4.1916

Epoch 53: val_loss improved from 4.19843 to 4.19157, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 44s - loss: 4.1681 - MinusLogProbMetric: 4.1681 - val_loss: 4.1916 - val_MinusLogProbMetric: 4.1916 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 54/1000
2023-09-17 02:48:47.761 
Epoch 54/1000 
	 loss: 4.1699, MinusLogProbMetric: 4.1699, val_loss: 4.2225, val_MinusLogProbMetric: 4.2225

Epoch 54: val_loss did not improve from 4.19157
196/196 - 43s - loss: 4.1699 - MinusLogProbMetric: 4.1699 - val_loss: 4.2225 - val_MinusLogProbMetric: 4.2225 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 55/1000
2023-09-17 02:49:30.898 
Epoch 55/1000 
	 loss: 4.1542, MinusLogProbMetric: 4.1542, val_loss: 4.2378, val_MinusLogProbMetric: 4.2378

Epoch 55: val_loss did not improve from 4.19157
196/196 - 43s - loss: 4.1542 - MinusLogProbMetric: 4.1542 - val_loss: 4.2378 - val_MinusLogProbMetric: 4.2378 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 56/1000
2023-09-17 02:50:14.190 
Epoch 56/1000 
	 loss: 4.1566, MinusLogProbMetric: 4.1566, val_loss: 4.2603, val_MinusLogProbMetric: 4.2603

Epoch 56: val_loss did not improve from 4.19157
196/196 - 43s - loss: 4.1566 - MinusLogProbMetric: 4.1566 - val_loss: 4.2603 - val_MinusLogProbMetric: 4.2603 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 57/1000
2023-09-17 02:50:57.424 
Epoch 57/1000 
	 loss: 4.1550, MinusLogProbMetric: 4.1550, val_loss: 4.2177, val_MinusLogProbMetric: 4.2177

Epoch 57: val_loss did not improve from 4.19157
196/196 - 43s - loss: 4.1550 - MinusLogProbMetric: 4.1550 - val_loss: 4.2177 - val_MinusLogProbMetric: 4.2177 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 58/1000
2023-09-17 02:51:40.807 
Epoch 58/1000 
	 loss: 4.1549, MinusLogProbMetric: 4.1549, val_loss: 4.2211, val_MinusLogProbMetric: 4.2211

Epoch 58: val_loss did not improve from 4.19157
196/196 - 43s - loss: 4.1549 - MinusLogProbMetric: 4.1549 - val_loss: 4.2211 - val_MinusLogProbMetric: 4.2211 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 59/1000
2023-09-17 02:52:24.279 
Epoch 59/1000 
	 loss: 4.1507, MinusLogProbMetric: 4.1507, val_loss: 4.3026, val_MinusLogProbMetric: 4.3026

Epoch 59: val_loss did not improve from 4.19157
196/196 - 43s - loss: 4.1507 - MinusLogProbMetric: 4.1507 - val_loss: 4.3026 - val_MinusLogProbMetric: 4.3026 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 60/1000
2023-09-17 02:53:08.200 
Epoch 60/1000 
	 loss: 4.1557, MinusLogProbMetric: 4.1557, val_loss: 4.2233, val_MinusLogProbMetric: 4.2233

Epoch 60: val_loss did not improve from 4.19157
196/196 - 44s - loss: 4.1557 - MinusLogProbMetric: 4.1557 - val_loss: 4.2233 - val_MinusLogProbMetric: 4.2233 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 61/1000
2023-09-17 02:53:51.932 
Epoch 61/1000 
	 loss: 4.1529, MinusLogProbMetric: 4.1529, val_loss: 4.2003, val_MinusLogProbMetric: 4.2003

Epoch 61: val_loss did not improve from 4.19157
196/196 - 44s - loss: 4.1529 - MinusLogProbMetric: 4.1529 - val_loss: 4.2003 - val_MinusLogProbMetric: 4.2003 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 62/1000
2023-09-17 02:54:35.386 
Epoch 62/1000 
	 loss: 4.1523, MinusLogProbMetric: 4.1523, val_loss: 4.2472, val_MinusLogProbMetric: 4.2472

Epoch 62: val_loss did not improve from 4.19157
196/196 - 43s - loss: 4.1523 - MinusLogProbMetric: 4.1523 - val_loss: 4.2472 - val_MinusLogProbMetric: 4.2472 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 63/1000
2023-09-17 02:55:18.599 
Epoch 63/1000 
	 loss: 4.1445, MinusLogProbMetric: 4.1445, val_loss: 4.1808, val_MinusLogProbMetric: 4.1808

Epoch 63: val_loss improved from 4.19157 to 4.18081, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 44s - loss: 4.1445 - MinusLogProbMetric: 4.1445 - val_loss: 4.1808 - val_MinusLogProbMetric: 4.1808 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 64/1000
2023-09-17 02:56:03.057 
Epoch 64/1000 
	 loss: 4.1388, MinusLogProbMetric: 4.1388, val_loss: 4.1938, val_MinusLogProbMetric: 4.1938

Epoch 64: val_loss did not improve from 4.18081
196/196 - 44s - loss: 4.1388 - MinusLogProbMetric: 4.1388 - val_loss: 4.1938 - val_MinusLogProbMetric: 4.1938 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 65/1000
2023-09-17 02:56:46.640 
Epoch 65/1000 
	 loss: 4.1483, MinusLogProbMetric: 4.1483, val_loss: 4.1952, val_MinusLogProbMetric: 4.1952

Epoch 65: val_loss did not improve from 4.18081
196/196 - 44s - loss: 4.1483 - MinusLogProbMetric: 4.1483 - val_loss: 4.1952 - val_MinusLogProbMetric: 4.1952 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 66/1000
2023-09-17 02:57:30.357 
Epoch 66/1000 
	 loss: 4.1464, MinusLogProbMetric: 4.1464, val_loss: 4.2229, val_MinusLogProbMetric: 4.2229

Epoch 66: val_loss did not improve from 4.18081
196/196 - 44s - loss: 4.1464 - MinusLogProbMetric: 4.1464 - val_loss: 4.2229 - val_MinusLogProbMetric: 4.2229 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 67/1000
2023-09-17 02:58:13.970 
Epoch 67/1000 
	 loss: 4.1375, MinusLogProbMetric: 4.1375, val_loss: 4.2985, val_MinusLogProbMetric: 4.2985

Epoch 67: val_loss did not improve from 4.18081
196/196 - 44s - loss: 4.1375 - MinusLogProbMetric: 4.1375 - val_loss: 4.2985 - val_MinusLogProbMetric: 4.2985 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 68/1000
2023-09-17 02:58:57.421 
Epoch 68/1000 
	 loss: 4.1444, MinusLogProbMetric: 4.1444, val_loss: 4.2031, val_MinusLogProbMetric: 4.2031

Epoch 68: val_loss did not improve from 4.18081
196/196 - 43s - loss: 4.1444 - MinusLogProbMetric: 4.1444 - val_loss: 4.2031 - val_MinusLogProbMetric: 4.2031 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 69/1000
2023-09-17 02:59:41.003 
Epoch 69/1000 
	 loss: 4.1293, MinusLogProbMetric: 4.1293, val_loss: 4.2482, val_MinusLogProbMetric: 4.2482

Epoch 69: val_loss did not improve from 4.18081
196/196 - 44s - loss: 4.1293 - MinusLogProbMetric: 4.1293 - val_loss: 4.2482 - val_MinusLogProbMetric: 4.2482 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 70/1000
2023-09-17 03:00:24.899 
Epoch 70/1000 
	 loss: 4.1365, MinusLogProbMetric: 4.1365, val_loss: 4.1902, val_MinusLogProbMetric: 4.1902

Epoch 70: val_loss did not improve from 4.18081
196/196 - 44s - loss: 4.1365 - MinusLogProbMetric: 4.1365 - val_loss: 4.1902 - val_MinusLogProbMetric: 4.1902 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 71/1000
2023-09-17 03:01:08.637 
Epoch 71/1000 
	 loss: 4.1336, MinusLogProbMetric: 4.1336, val_loss: 4.2579, val_MinusLogProbMetric: 4.2579

Epoch 71: val_loss did not improve from 4.18081
196/196 - 44s - loss: 4.1336 - MinusLogProbMetric: 4.1336 - val_loss: 4.2579 - val_MinusLogProbMetric: 4.2579 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 72/1000
2023-09-17 03:01:51.798 
Epoch 72/1000 
	 loss: 4.1397, MinusLogProbMetric: 4.1397, val_loss: 4.2059, val_MinusLogProbMetric: 4.2059

Epoch 72: val_loss did not improve from 4.18081
196/196 - 43s - loss: 4.1397 - MinusLogProbMetric: 4.1397 - val_loss: 4.2059 - val_MinusLogProbMetric: 4.2059 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 73/1000
2023-09-17 03:02:35.232 
Epoch 73/1000 
	 loss: 4.1291, MinusLogProbMetric: 4.1291, val_loss: 4.2177, val_MinusLogProbMetric: 4.2177

Epoch 73: val_loss did not improve from 4.18081
196/196 - 43s - loss: 4.1291 - MinusLogProbMetric: 4.1291 - val_loss: 4.2177 - val_MinusLogProbMetric: 4.2177 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 74/1000
2023-09-17 03:03:18.572 
Epoch 74/1000 
	 loss: 4.1364, MinusLogProbMetric: 4.1364, val_loss: 4.2445, val_MinusLogProbMetric: 4.2445

Epoch 74: val_loss did not improve from 4.18081
196/196 - 43s - loss: 4.1364 - MinusLogProbMetric: 4.1364 - val_loss: 4.2445 - val_MinusLogProbMetric: 4.2445 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 75/1000
2023-09-17 03:04:02.059 
Epoch 75/1000 
	 loss: 4.1339, MinusLogProbMetric: 4.1339, val_loss: 4.2000, val_MinusLogProbMetric: 4.2000

Epoch 75: val_loss did not improve from 4.18081
196/196 - 43s - loss: 4.1339 - MinusLogProbMetric: 4.1339 - val_loss: 4.2000 - val_MinusLogProbMetric: 4.2000 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 76/1000
2023-09-17 03:04:46.048 
Epoch 76/1000 
	 loss: 4.1319, MinusLogProbMetric: 4.1319, val_loss: 4.1828, val_MinusLogProbMetric: 4.1828

Epoch 76: val_loss did not improve from 4.18081
196/196 - 44s - loss: 4.1319 - MinusLogProbMetric: 4.1319 - val_loss: 4.1828 - val_MinusLogProbMetric: 4.1828 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 77/1000
2023-09-17 03:05:29.123 
Epoch 77/1000 
	 loss: 4.1272, MinusLogProbMetric: 4.1272, val_loss: 4.2356, val_MinusLogProbMetric: 4.2356

Epoch 77: val_loss did not improve from 4.18081
196/196 - 43s - loss: 4.1272 - MinusLogProbMetric: 4.1272 - val_loss: 4.2356 - val_MinusLogProbMetric: 4.2356 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 78/1000
2023-09-17 03:06:13.230 
Epoch 78/1000 
	 loss: 4.1336, MinusLogProbMetric: 4.1336, val_loss: 4.2052, val_MinusLogProbMetric: 4.2052

Epoch 78: val_loss did not improve from 4.18081
196/196 - 44s - loss: 4.1336 - MinusLogProbMetric: 4.1336 - val_loss: 4.2052 - val_MinusLogProbMetric: 4.2052 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 79/1000
2023-09-17 03:06:57.145 
Epoch 79/1000 
	 loss: 4.1373, MinusLogProbMetric: 4.1373, val_loss: 4.2965, val_MinusLogProbMetric: 4.2965

Epoch 79: val_loss did not improve from 4.18081
196/196 - 44s - loss: 4.1373 - MinusLogProbMetric: 4.1373 - val_loss: 4.2965 - val_MinusLogProbMetric: 4.2965 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 80/1000
2023-09-17 03:07:40.903 
Epoch 80/1000 
	 loss: 4.1284, MinusLogProbMetric: 4.1284, val_loss: 4.1921, val_MinusLogProbMetric: 4.1921

Epoch 80: val_loss did not improve from 4.18081
196/196 - 44s - loss: 4.1284 - MinusLogProbMetric: 4.1284 - val_loss: 4.1921 - val_MinusLogProbMetric: 4.1921 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 81/1000
2023-09-17 03:08:24.438 
Epoch 81/1000 
	 loss: 4.1190, MinusLogProbMetric: 4.1190, val_loss: 4.2141, val_MinusLogProbMetric: 4.2141

Epoch 81: val_loss did not improve from 4.18081
196/196 - 44s - loss: 4.1190 - MinusLogProbMetric: 4.1190 - val_loss: 4.2141 - val_MinusLogProbMetric: 4.2141 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 82/1000
2023-09-17 03:09:07.667 
Epoch 82/1000 
	 loss: 4.1239, MinusLogProbMetric: 4.1239, val_loss: 4.1780, val_MinusLogProbMetric: 4.1780

Epoch 82: val_loss improved from 4.18081 to 4.17798, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 44s - loss: 4.1239 - MinusLogProbMetric: 4.1239 - val_loss: 4.1780 - val_MinusLogProbMetric: 4.1780 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 83/1000
2023-09-17 03:09:52.195 
Epoch 83/1000 
	 loss: 4.1215, MinusLogProbMetric: 4.1215, val_loss: 4.2009, val_MinusLogProbMetric: 4.2009

Epoch 83: val_loss did not improve from 4.17798
196/196 - 44s - loss: 4.1215 - MinusLogProbMetric: 4.1215 - val_loss: 4.2009 - val_MinusLogProbMetric: 4.2009 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 84/1000
2023-09-17 03:10:35.453 
Epoch 84/1000 
	 loss: 4.1318, MinusLogProbMetric: 4.1318, val_loss: 4.1825, val_MinusLogProbMetric: 4.1825

Epoch 84: val_loss did not improve from 4.17798
196/196 - 43s - loss: 4.1318 - MinusLogProbMetric: 4.1318 - val_loss: 4.1825 - val_MinusLogProbMetric: 4.1825 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 85/1000
2023-09-17 03:11:18.721 
Epoch 85/1000 
	 loss: 4.1245, MinusLogProbMetric: 4.1245, val_loss: 4.1896, val_MinusLogProbMetric: 4.1896

Epoch 85: val_loss did not improve from 4.17798
196/196 - 43s - loss: 4.1245 - MinusLogProbMetric: 4.1245 - val_loss: 4.1896 - val_MinusLogProbMetric: 4.1896 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 86/1000
2023-09-17 03:12:02.329 
Epoch 86/1000 
	 loss: 4.1274, MinusLogProbMetric: 4.1274, val_loss: 4.1715, val_MinusLogProbMetric: 4.1715

Epoch 86: val_loss improved from 4.17798 to 4.17150, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 44s - loss: 4.1274 - MinusLogProbMetric: 4.1274 - val_loss: 4.1715 - val_MinusLogProbMetric: 4.1715 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 87/1000
2023-09-17 03:12:47.087 
Epoch 87/1000 
	 loss: 4.1233, MinusLogProbMetric: 4.1233, val_loss: 4.1746, val_MinusLogProbMetric: 4.1746

Epoch 87: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1233 - MinusLogProbMetric: 4.1233 - val_loss: 4.1746 - val_MinusLogProbMetric: 4.1746 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 88/1000
2023-09-17 03:13:30.182 
Epoch 88/1000 
	 loss: 4.1230, MinusLogProbMetric: 4.1230, val_loss: 4.3185, val_MinusLogProbMetric: 4.3185

Epoch 88: val_loss did not improve from 4.17150
196/196 - 43s - loss: 4.1230 - MinusLogProbMetric: 4.1230 - val_loss: 4.3185 - val_MinusLogProbMetric: 4.3185 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 89/1000
2023-09-17 03:14:13.938 
Epoch 89/1000 
	 loss: 4.1249, MinusLogProbMetric: 4.1249, val_loss: 4.2598, val_MinusLogProbMetric: 4.2598

Epoch 89: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1249 - MinusLogProbMetric: 4.1249 - val_loss: 4.2598 - val_MinusLogProbMetric: 4.2598 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 90/1000
2023-09-17 03:14:57.200 
Epoch 90/1000 
	 loss: 4.1199, MinusLogProbMetric: 4.1199, val_loss: 4.1850, val_MinusLogProbMetric: 4.1850

Epoch 90: val_loss did not improve from 4.17150
196/196 - 43s - loss: 4.1199 - MinusLogProbMetric: 4.1199 - val_loss: 4.1850 - val_MinusLogProbMetric: 4.1850 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 91/1000
2023-09-17 03:15:40.737 
Epoch 91/1000 
	 loss: 4.1117, MinusLogProbMetric: 4.1117, val_loss: 4.1753, val_MinusLogProbMetric: 4.1753

Epoch 91: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1117 - MinusLogProbMetric: 4.1117 - val_loss: 4.1753 - val_MinusLogProbMetric: 4.1753 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 92/1000
2023-09-17 03:16:24.162 
Epoch 92/1000 
	 loss: 4.1127, MinusLogProbMetric: 4.1127, val_loss: 4.1908, val_MinusLogProbMetric: 4.1908

Epoch 92: val_loss did not improve from 4.17150
196/196 - 43s - loss: 4.1127 - MinusLogProbMetric: 4.1127 - val_loss: 4.1908 - val_MinusLogProbMetric: 4.1908 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 93/1000
2023-09-17 03:17:07.599 
Epoch 93/1000 
	 loss: 4.1125, MinusLogProbMetric: 4.1125, val_loss: 4.2061, val_MinusLogProbMetric: 4.2061

Epoch 93: val_loss did not improve from 4.17150
196/196 - 43s - loss: 4.1125 - MinusLogProbMetric: 4.1125 - val_loss: 4.2061 - val_MinusLogProbMetric: 4.2061 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 94/1000
2023-09-17 03:17:50.871 
Epoch 94/1000 
	 loss: 4.1162, MinusLogProbMetric: 4.1162, val_loss: 4.1977, val_MinusLogProbMetric: 4.1977

Epoch 94: val_loss did not improve from 4.17150
196/196 - 43s - loss: 4.1162 - MinusLogProbMetric: 4.1162 - val_loss: 4.1977 - val_MinusLogProbMetric: 4.1977 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 95/1000
2023-09-17 03:18:35.001 
Epoch 95/1000 
	 loss: 4.1116, MinusLogProbMetric: 4.1116, val_loss: 4.1943, val_MinusLogProbMetric: 4.1943

Epoch 95: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1116 - MinusLogProbMetric: 4.1116 - val_loss: 4.1943 - val_MinusLogProbMetric: 4.1943 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 96/1000
2023-09-17 03:19:18.713 
Epoch 96/1000 
	 loss: 4.1106, MinusLogProbMetric: 4.1106, val_loss: 4.1757, val_MinusLogProbMetric: 4.1757

Epoch 96: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1106 - MinusLogProbMetric: 4.1106 - val_loss: 4.1757 - val_MinusLogProbMetric: 4.1757 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 97/1000
2023-09-17 03:20:02.426 
Epoch 97/1000 
	 loss: 4.1081, MinusLogProbMetric: 4.1081, val_loss: 4.1992, val_MinusLogProbMetric: 4.1992

Epoch 97: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1081 - MinusLogProbMetric: 4.1081 - val_loss: 4.1992 - val_MinusLogProbMetric: 4.1992 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 98/1000
2023-09-17 03:20:45.981 
Epoch 98/1000 
	 loss: 4.1192, MinusLogProbMetric: 4.1192, val_loss: 4.1728, val_MinusLogProbMetric: 4.1728

Epoch 98: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1192 - MinusLogProbMetric: 4.1192 - val_loss: 4.1728 - val_MinusLogProbMetric: 4.1728 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 99/1000
2023-09-17 03:21:29.625 
Epoch 99/1000 
	 loss: 4.1174, MinusLogProbMetric: 4.1174, val_loss: 4.1759, val_MinusLogProbMetric: 4.1759

Epoch 99: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1174 - MinusLogProbMetric: 4.1174 - val_loss: 4.1759 - val_MinusLogProbMetric: 4.1759 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 100/1000
2023-09-17 03:22:13.318 
Epoch 100/1000 
	 loss: 4.1155, MinusLogProbMetric: 4.1155, val_loss: 4.1791, val_MinusLogProbMetric: 4.1791

Epoch 100: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1155 - MinusLogProbMetric: 4.1155 - val_loss: 4.1791 - val_MinusLogProbMetric: 4.1791 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 101/1000
2023-09-17 03:22:56.901 
Epoch 101/1000 
	 loss: 4.1140, MinusLogProbMetric: 4.1140, val_loss: 4.2442, val_MinusLogProbMetric: 4.2442

Epoch 101: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1140 - MinusLogProbMetric: 4.1140 - val_loss: 4.2442 - val_MinusLogProbMetric: 4.2442 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 102/1000
2023-09-17 03:23:40.496 
Epoch 102/1000 
	 loss: 4.1206, MinusLogProbMetric: 4.1206, val_loss: 4.1910, val_MinusLogProbMetric: 4.1910

Epoch 102: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1206 - MinusLogProbMetric: 4.1206 - val_loss: 4.1910 - val_MinusLogProbMetric: 4.1910 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 103/1000
2023-09-17 03:24:23.714 
Epoch 103/1000 
	 loss: 4.1124, MinusLogProbMetric: 4.1124, val_loss: 4.2126, val_MinusLogProbMetric: 4.2126

Epoch 103: val_loss did not improve from 4.17150
196/196 - 43s - loss: 4.1124 - MinusLogProbMetric: 4.1124 - val_loss: 4.2126 - val_MinusLogProbMetric: 4.2126 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 104/1000
2023-09-17 03:25:06.869 
Epoch 104/1000 
	 loss: 4.1064, MinusLogProbMetric: 4.1064, val_loss: 4.2153, val_MinusLogProbMetric: 4.2153

Epoch 104: val_loss did not improve from 4.17150
196/196 - 43s - loss: 4.1064 - MinusLogProbMetric: 4.1064 - val_loss: 4.2153 - val_MinusLogProbMetric: 4.2153 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 105/1000
2023-09-17 03:25:50.539 
Epoch 105/1000 
	 loss: 4.1169, MinusLogProbMetric: 4.1169, val_loss: 4.2100, val_MinusLogProbMetric: 4.2100

Epoch 105: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1169 - MinusLogProbMetric: 4.1169 - val_loss: 4.2100 - val_MinusLogProbMetric: 4.2100 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 106/1000
2023-09-17 03:26:34.526 
Epoch 106/1000 
	 loss: 4.1051, MinusLogProbMetric: 4.1051, val_loss: 4.2019, val_MinusLogProbMetric: 4.2019

Epoch 106: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1051 - MinusLogProbMetric: 4.1051 - val_loss: 4.2019 - val_MinusLogProbMetric: 4.2019 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 107/1000
2023-09-17 03:27:18.309 
Epoch 107/1000 
	 loss: 4.1043, MinusLogProbMetric: 4.1043, val_loss: 4.2081, val_MinusLogProbMetric: 4.2081

Epoch 107: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1043 - MinusLogProbMetric: 4.1043 - val_loss: 4.2081 - val_MinusLogProbMetric: 4.2081 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 108/1000
2023-09-17 03:28:02.103 
Epoch 108/1000 
	 loss: 4.1088, MinusLogProbMetric: 4.1088, val_loss: 4.2022, val_MinusLogProbMetric: 4.2022

Epoch 108: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1088 - MinusLogProbMetric: 4.1088 - val_loss: 4.2022 - val_MinusLogProbMetric: 4.2022 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 109/1000
2023-09-17 03:28:46.363 
Epoch 109/1000 
	 loss: 4.1107, MinusLogProbMetric: 4.1107, val_loss: 4.1739, val_MinusLogProbMetric: 4.1739

Epoch 109: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1107 - MinusLogProbMetric: 4.1107 - val_loss: 4.1739 - val_MinusLogProbMetric: 4.1739 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 110/1000
2023-09-17 03:29:30.641 
Epoch 110/1000 
	 loss: 4.1010, MinusLogProbMetric: 4.1010, val_loss: 4.1958, val_MinusLogProbMetric: 4.1958

Epoch 110: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1010 - MinusLogProbMetric: 4.1010 - val_loss: 4.1958 - val_MinusLogProbMetric: 4.1958 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 111/1000
2023-09-17 03:30:15.045 
Epoch 111/1000 
	 loss: 4.1074, MinusLogProbMetric: 4.1074, val_loss: 4.1940, val_MinusLogProbMetric: 4.1940

Epoch 111: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1074 - MinusLogProbMetric: 4.1074 - val_loss: 4.1940 - val_MinusLogProbMetric: 4.1940 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 112/1000
2023-09-17 03:30:59.143 
Epoch 112/1000 
	 loss: 4.1055, MinusLogProbMetric: 4.1055, val_loss: 4.1849, val_MinusLogProbMetric: 4.1849

Epoch 112: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1055 - MinusLogProbMetric: 4.1055 - val_loss: 4.1849 - val_MinusLogProbMetric: 4.1849 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 113/1000
2023-09-17 03:31:43.971 
Epoch 113/1000 
	 loss: 4.0988, MinusLogProbMetric: 4.0988, val_loss: 4.2396, val_MinusLogProbMetric: 4.2396

Epoch 113: val_loss did not improve from 4.17150
196/196 - 45s - loss: 4.0988 - MinusLogProbMetric: 4.0988 - val_loss: 4.2396 - val_MinusLogProbMetric: 4.2396 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 114/1000
2023-09-17 03:32:28.444 
Epoch 114/1000 
	 loss: 4.1033, MinusLogProbMetric: 4.1033, val_loss: 4.1851, val_MinusLogProbMetric: 4.1851

Epoch 114: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1033 - MinusLogProbMetric: 4.1033 - val_loss: 4.1851 - val_MinusLogProbMetric: 4.1851 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 115/1000
2023-09-17 03:33:12.739 
Epoch 115/1000 
	 loss: 4.1002, MinusLogProbMetric: 4.1002, val_loss: 4.1955, val_MinusLogProbMetric: 4.1955

Epoch 115: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1002 - MinusLogProbMetric: 4.1002 - val_loss: 4.1955 - val_MinusLogProbMetric: 4.1955 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 116/1000
2023-09-17 03:33:57.085 
Epoch 116/1000 
	 loss: 4.1014, MinusLogProbMetric: 4.1014, val_loss: 4.1966, val_MinusLogProbMetric: 4.1966

Epoch 116: val_loss did not improve from 4.17150
196/196 - 44s - loss: 4.1014 - MinusLogProbMetric: 4.1014 - val_loss: 4.1966 - val_MinusLogProbMetric: 4.1966 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 117/1000
2023-09-17 03:34:42.019 
Epoch 117/1000 
	 loss: 4.0959, MinusLogProbMetric: 4.0959, val_loss: 4.1995, val_MinusLogProbMetric: 4.1995

Epoch 117: val_loss did not improve from 4.17150
196/196 - 45s - loss: 4.0959 - MinusLogProbMetric: 4.0959 - val_loss: 4.1995 - val_MinusLogProbMetric: 4.1995 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 118/1000
2023-09-17 03:35:26.800 
Epoch 118/1000 
	 loss: 4.1039, MinusLogProbMetric: 4.1039, val_loss: 4.1798, val_MinusLogProbMetric: 4.1798

Epoch 118: val_loss did not improve from 4.17150
196/196 - 45s - loss: 4.1039 - MinusLogProbMetric: 4.1039 - val_loss: 4.1798 - val_MinusLogProbMetric: 4.1798 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 119/1000
2023-09-17 03:36:11.336 
Epoch 119/1000 
	 loss: 4.0960, MinusLogProbMetric: 4.0960, val_loss: 4.2497, val_MinusLogProbMetric: 4.2497

Epoch 119: val_loss did not improve from 4.17150
196/196 - 45s - loss: 4.0960 - MinusLogProbMetric: 4.0960 - val_loss: 4.2497 - val_MinusLogProbMetric: 4.2497 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 120/1000
2023-09-17 03:36:55.977 
Epoch 120/1000 
	 loss: 4.0981, MinusLogProbMetric: 4.0981, val_loss: 4.2241, val_MinusLogProbMetric: 4.2241

Epoch 120: val_loss did not improve from 4.17150
196/196 - 45s - loss: 4.0981 - MinusLogProbMetric: 4.0981 - val_loss: 4.2241 - val_MinusLogProbMetric: 4.2241 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 121/1000
2023-09-17 03:37:40.762 
Epoch 121/1000 
	 loss: 4.1040, MinusLogProbMetric: 4.1040, val_loss: 4.1755, val_MinusLogProbMetric: 4.1755

Epoch 121: val_loss did not improve from 4.17150
196/196 - 45s - loss: 4.1040 - MinusLogProbMetric: 4.1040 - val_loss: 4.1755 - val_MinusLogProbMetric: 4.1755 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 122/1000
2023-09-17 03:38:25.482 
Epoch 122/1000 
	 loss: 4.1029, MinusLogProbMetric: 4.1029, val_loss: 4.1800, val_MinusLogProbMetric: 4.1800

Epoch 122: val_loss did not improve from 4.17150
196/196 - 45s - loss: 4.1029 - MinusLogProbMetric: 4.1029 - val_loss: 4.1800 - val_MinusLogProbMetric: 4.1800 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 123/1000
2023-09-17 03:39:09.992 
Epoch 123/1000 
	 loss: 4.0954, MinusLogProbMetric: 4.0954, val_loss: 4.1712, val_MinusLogProbMetric: 4.1712

Epoch 123: val_loss improved from 4.17150 to 4.17124, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 45s - loss: 4.0954 - MinusLogProbMetric: 4.0954 - val_loss: 4.1712 - val_MinusLogProbMetric: 4.1712 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 124/1000
2023-09-17 03:39:54.956 
Epoch 124/1000 
	 loss: 4.0985, MinusLogProbMetric: 4.0985, val_loss: 4.1848, val_MinusLogProbMetric: 4.1848

Epoch 124: val_loss did not improve from 4.17124
196/196 - 44s - loss: 4.0985 - MinusLogProbMetric: 4.0985 - val_loss: 4.1848 - val_MinusLogProbMetric: 4.1848 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 125/1000
2023-09-17 03:40:39.957 
Epoch 125/1000 
	 loss: 4.0917, MinusLogProbMetric: 4.0917, val_loss: 4.1752, val_MinusLogProbMetric: 4.1752

Epoch 125: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0917 - MinusLogProbMetric: 4.0917 - val_loss: 4.1752 - val_MinusLogProbMetric: 4.1752 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 126/1000
2023-09-17 03:41:24.580 
Epoch 126/1000 
	 loss: 4.0958, MinusLogProbMetric: 4.0958, val_loss: 4.1763, val_MinusLogProbMetric: 4.1763

Epoch 126: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0958 - MinusLogProbMetric: 4.0958 - val_loss: 4.1763 - val_MinusLogProbMetric: 4.1763 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 127/1000
2023-09-17 03:42:09.094 
Epoch 127/1000 
	 loss: 4.0874, MinusLogProbMetric: 4.0874, val_loss: 4.1847, val_MinusLogProbMetric: 4.1847

Epoch 127: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0874 - MinusLogProbMetric: 4.0874 - val_loss: 4.1847 - val_MinusLogProbMetric: 4.1847 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 128/1000
2023-09-17 03:42:53.718 
Epoch 128/1000 
	 loss: 4.0988, MinusLogProbMetric: 4.0988, val_loss: 4.2252, val_MinusLogProbMetric: 4.2252

Epoch 128: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0988 - MinusLogProbMetric: 4.0988 - val_loss: 4.2252 - val_MinusLogProbMetric: 4.2252 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 129/1000
2023-09-17 03:43:38.199 
Epoch 129/1000 
	 loss: 4.0941, MinusLogProbMetric: 4.0941, val_loss: 4.1962, val_MinusLogProbMetric: 4.1962

Epoch 129: val_loss did not improve from 4.17124
196/196 - 44s - loss: 4.0941 - MinusLogProbMetric: 4.0941 - val_loss: 4.1962 - val_MinusLogProbMetric: 4.1962 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 130/1000
2023-09-17 03:44:23.125 
Epoch 130/1000 
	 loss: 4.1003, MinusLogProbMetric: 4.1003, val_loss: 4.2683, val_MinusLogProbMetric: 4.2683

Epoch 130: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.1003 - MinusLogProbMetric: 4.1003 - val_loss: 4.2683 - val_MinusLogProbMetric: 4.2683 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 131/1000
2023-09-17 03:45:07.820 
Epoch 131/1000 
	 loss: 4.0942, MinusLogProbMetric: 4.0942, val_loss: 4.2040, val_MinusLogProbMetric: 4.2040

Epoch 131: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0942 - MinusLogProbMetric: 4.0942 - val_loss: 4.2040 - val_MinusLogProbMetric: 4.2040 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 132/1000
2023-09-17 03:45:52.223 
Epoch 132/1000 
	 loss: 4.0902, MinusLogProbMetric: 4.0902, val_loss: 4.1928, val_MinusLogProbMetric: 4.1928

Epoch 132: val_loss did not improve from 4.17124
196/196 - 44s - loss: 4.0902 - MinusLogProbMetric: 4.0902 - val_loss: 4.1928 - val_MinusLogProbMetric: 4.1928 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 133/1000
2023-09-17 03:46:37.067 
Epoch 133/1000 
	 loss: 4.0940, MinusLogProbMetric: 4.0940, val_loss: 4.1892, val_MinusLogProbMetric: 4.1892

Epoch 133: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0940 - MinusLogProbMetric: 4.0940 - val_loss: 4.1892 - val_MinusLogProbMetric: 4.1892 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 134/1000
2023-09-17 03:47:21.675 
Epoch 134/1000 
	 loss: 4.0894, MinusLogProbMetric: 4.0894, val_loss: 4.1887, val_MinusLogProbMetric: 4.1887

Epoch 134: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0894 - MinusLogProbMetric: 4.0894 - val_loss: 4.1887 - val_MinusLogProbMetric: 4.1887 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 135/1000
2023-09-17 03:48:06.242 
Epoch 135/1000 
	 loss: 4.0945, MinusLogProbMetric: 4.0945, val_loss: 4.2348, val_MinusLogProbMetric: 4.2348

Epoch 135: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0945 - MinusLogProbMetric: 4.0945 - val_loss: 4.2348 - val_MinusLogProbMetric: 4.2348 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 136/1000
2023-09-17 03:48:51.044 
Epoch 136/1000 
	 loss: 4.0961, MinusLogProbMetric: 4.0961, val_loss: 4.1835, val_MinusLogProbMetric: 4.1835

Epoch 136: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0961 - MinusLogProbMetric: 4.0961 - val_loss: 4.1835 - val_MinusLogProbMetric: 4.1835 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 137/1000
2023-09-17 03:49:35.829 
Epoch 137/1000 
	 loss: 4.0920, MinusLogProbMetric: 4.0920, val_loss: 4.2146, val_MinusLogProbMetric: 4.2146

Epoch 137: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0920 - MinusLogProbMetric: 4.0920 - val_loss: 4.2146 - val_MinusLogProbMetric: 4.2146 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 138/1000
2023-09-17 03:50:20.421 
Epoch 138/1000 
	 loss: 4.0982, MinusLogProbMetric: 4.0982, val_loss: 4.1872, val_MinusLogProbMetric: 4.1872

Epoch 138: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0982 - MinusLogProbMetric: 4.0982 - val_loss: 4.1872 - val_MinusLogProbMetric: 4.1872 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 139/1000
2023-09-17 03:51:04.688 
Epoch 139/1000 
	 loss: 4.0864, MinusLogProbMetric: 4.0864, val_loss: 4.1958, val_MinusLogProbMetric: 4.1958

Epoch 139: val_loss did not improve from 4.17124
196/196 - 44s - loss: 4.0864 - MinusLogProbMetric: 4.0864 - val_loss: 4.1958 - val_MinusLogProbMetric: 4.1958 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 140/1000
2023-09-17 03:51:49.624 
Epoch 140/1000 
	 loss: 4.0894, MinusLogProbMetric: 4.0894, val_loss: 4.2082, val_MinusLogProbMetric: 4.2082

Epoch 140: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0894 - MinusLogProbMetric: 4.0894 - val_loss: 4.2082 - val_MinusLogProbMetric: 4.2082 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 141/1000
2023-09-17 03:52:34.283 
Epoch 141/1000 
	 loss: 4.0887, MinusLogProbMetric: 4.0887, val_loss: 4.1773, val_MinusLogProbMetric: 4.1773

Epoch 141: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0887 - MinusLogProbMetric: 4.0887 - val_loss: 4.1773 - val_MinusLogProbMetric: 4.1773 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 142/1000
2023-09-17 03:53:19.034 
Epoch 142/1000 
	 loss: 4.0892, MinusLogProbMetric: 4.0892, val_loss: 4.2099, val_MinusLogProbMetric: 4.2099

Epoch 142: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0892 - MinusLogProbMetric: 4.0892 - val_loss: 4.2099 - val_MinusLogProbMetric: 4.2099 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 143/1000
2023-09-17 03:54:04.200 
Epoch 143/1000 
	 loss: 4.0914, MinusLogProbMetric: 4.0914, val_loss: 4.2415, val_MinusLogProbMetric: 4.2415

Epoch 143: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0914 - MinusLogProbMetric: 4.0914 - val_loss: 4.2415 - val_MinusLogProbMetric: 4.2415 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 144/1000
2023-09-17 03:54:48.923 
Epoch 144/1000 
	 loss: 4.0968, MinusLogProbMetric: 4.0968, val_loss: 4.2486, val_MinusLogProbMetric: 4.2486

Epoch 144: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0968 - MinusLogProbMetric: 4.0968 - val_loss: 4.2486 - val_MinusLogProbMetric: 4.2486 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 145/1000
2023-09-17 03:55:33.552 
Epoch 145/1000 
	 loss: 4.0837, MinusLogProbMetric: 4.0837, val_loss: 4.1927, val_MinusLogProbMetric: 4.1927

Epoch 145: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0837 - MinusLogProbMetric: 4.0837 - val_loss: 4.1927 - val_MinusLogProbMetric: 4.1927 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 146/1000
2023-09-17 03:56:18.659 
Epoch 146/1000 
	 loss: 4.0805, MinusLogProbMetric: 4.0805, val_loss: 4.2056, val_MinusLogProbMetric: 4.2056

Epoch 146: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0805 - MinusLogProbMetric: 4.0805 - val_loss: 4.2056 - val_MinusLogProbMetric: 4.2056 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 147/1000
2023-09-17 03:57:03.664 
Epoch 147/1000 
	 loss: 4.0918, MinusLogProbMetric: 4.0918, val_loss: 4.2268, val_MinusLogProbMetric: 4.2268

Epoch 147: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0918 - MinusLogProbMetric: 4.0918 - val_loss: 4.2268 - val_MinusLogProbMetric: 4.2268 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 148/1000
2023-09-17 03:57:48.310 
Epoch 148/1000 
	 loss: 4.0849, MinusLogProbMetric: 4.0849, val_loss: 4.1832, val_MinusLogProbMetric: 4.1832

Epoch 148: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0849 - MinusLogProbMetric: 4.0849 - val_loss: 4.1832 - val_MinusLogProbMetric: 4.1832 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 149/1000
2023-09-17 03:58:33.134 
Epoch 149/1000 
	 loss: 4.0930, MinusLogProbMetric: 4.0930, val_loss: 4.2036, val_MinusLogProbMetric: 4.2036

Epoch 149: val_loss did not improve from 4.17124
196/196 - 45s - loss: 4.0930 - MinusLogProbMetric: 4.0930 - val_loss: 4.2036 - val_MinusLogProbMetric: 4.2036 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 150/1000
2023-09-17 03:59:18.010 
Epoch 150/1000 
	 loss: 4.0835, MinusLogProbMetric: 4.0835, val_loss: 4.1656, val_MinusLogProbMetric: 4.1656

Epoch 150: val_loss improved from 4.17124 to 4.16562, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 46s - loss: 4.0835 - MinusLogProbMetric: 4.0835 - val_loss: 4.1656 - val_MinusLogProbMetric: 4.1656 - lr: 0.0010 - 46s/epoch - 233ms/step
Epoch 151/1000
2023-09-17 04:00:03.816 
Epoch 151/1000 
	 loss: 4.0883, MinusLogProbMetric: 4.0883, val_loss: 4.2097, val_MinusLogProbMetric: 4.2097

Epoch 151: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0883 - MinusLogProbMetric: 4.0883 - val_loss: 4.2097 - val_MinusLogProbMetric: 4.2097 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 152/1000
2023-09-17 04:00:48.343 
Epoch 152/1000 
	 loss: 4.0892, MinusLogProbMetric: 4.0892, val_loss: 4.1715, val_MinusLogProbMetric: 4.1715

Epoch 152: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0892 - MinusLogProbMetric: 4.0892 - val_loss: 4.1715 - val_MinusLogProbMetric: 4.1715 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 153/1000
2023-09-17 04:01:33.295 
Epoch 153/1000 
	 loss: 4.0945, MinusLogProbMetric: 4.0945, val_loss: 4.1921, val_MinusLogProbMetric: 4.1921

Epoch 153: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0945 - MinusLogProbMetric: 4.0945 - val_loss: 4.1921 - val_MinusLogProbMetric: 4.1921 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 154/1000
2023-09-17 04:02:18.180 
Epoch 154/1000 
	 loss: 4.0800, MinusLogProbMetric: 4.0800, val_loss: 4.1810, val_MinusLogProbMetric: 4.1810

Epoch 154: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0800 - MinusLogProbMetric: 4.0800 - val_loss: 4.1810 - val_MinusLogProbMetric: 4.1810 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 155/1000
2023-09-17 04:03:03.035 
Epoch 155/1000 
	 loss: 4.0771, MinusLogProbMetric: 4.0771, val_loss: 4.1804, val_MinusLogProbMetric: 4.1804

Epoch 155: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0771 - MinusLogProbMetric: 4.0771 - val_loss: 4.1804 - val_MinusLogProbMetric: 4.1804 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 156/1000
2023-09-17 04:03:48.058 
Epoch 156/1000 
	 loss: 4.0823, MinusLogProbMetric: 4.0823, val_loss: 4.1963, val_MinusLogProbMetric: 4.1963

Epoch 156: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0823 - MinusLogProbMetric: 4.0823 - val_loss: 4.1963 - val_MinusLogProbMetric: 4.1963 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 157/1000
2023-09-17 04:04:33.017 
Epoch 157/1000 
	 loss: 4.0784, MinusLogProbMetric: 4.0784, val_loss: 4.1927, val_MinusLogProbMetric: 4.1927

Epoch 157: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0784 - MinusLogProbMetric: 4.0784 - val_loss: 4.1927 - val_MinusLogProbMetric: 4.1927 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 158/1000
2023-09-17 04:05:17.464 
Epoch 158/1000 
	 loss: 4.0801, MinusLogProbMetric: 4.0801, val_loss: 4.2319, val_MinusLogProbMetric: 4.2319

Epoch 158: val_loss did not improve from 4.16562
196/196 - 44s - loss: 4.0801 - MinusLogProbMetric: 4.0801 - val_loss: 4.2319 - val_MinusLogProbMetric: 4.2319 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 159/1000
2023-09-17 04:06:02.128 
Epoch 159/1000 
	 loss: 4.0900, MinusLogProbMetric: 4.0900, val_loss: 4.2128, val_MinusLogProbMetric: 4.2128

Epoch 159: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0900 - MinusLogProbMetric: 4.0900 - val_loss: 4.2128 - val_MinusLogProbMetric: 4.2128 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 160/1000
2023-09-17 04:06:46.946 
Epoch 160/1000 
	 loss: 4.0824, MinusLogProbMetric: 4.0824, val_loss: 4.1963, val_MinusLogProbMetric: 4.1963

Epoch 160: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0824 - MinusLogProbMetric: 4.0824 - val_loss: 4.1963 - val_MinusLogProbMetric: 4.1963 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 161/1000
2023-09-17 04:07:31.818 
Epoch 161/1000 
	 loss: 4.0774, MinusLogProbMetric: 4.0774, val_loss: 4.1971, val_MinusLogProbMetric: 4.1971

Epoch 161: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0774 - MinusLogProbMetric: 4.0774 - val_loss: 4.1971 - val_MinusLogProbMetric: 4.1971 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 162/1000
2023-09-17 04:08:16.470 
Epoch 162/1000 
	 loss: 4.0822, MinusLogProbMetric: 4.0822, val_loss: 4.1989, val_MinusLogProbMetric: 4.1989

Epoch 162: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0822 - MinusLogProbMetric: 4.0822 - val_loss: 4.1989 - val_MinusLogProbMetric: 4.1989 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 163/1000
2023-09-17 04:09:01.094 
Epoch 163/1000 
	 loss: 4.0748, MinusLogProbMetric: 4.0748, val_loss: 4.2256, val_MinusLogProbMetric: 4.2256

Epoch 163: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0748 - MinusLogProbMetric: 4.0748 - val_loss: 4.2256 - val_MinusLogProbMetric: 4.2256 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 164/1000
2023-09-17 04:09:45.542 
Epoch 164/1000 
	 loss: 4.0811, MinusLogProbMetric: 4.0811, val_loss: 4.1995, val_MinusLogProbMetric: 4.1995

Epoch 164: val_loss did not improve from 4.16562
196/196 - 44s - loss: 4.0811 - MinusLogProbMetric: 4.0811 - val_loss: 4.1995 - val_MinusLogProbMetric: 4.1995 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 165/1000
2023-09-17 04:10:30.533 
Epoch 165/1000 
	 loss: 4.0843, MinusLogProbMetric: 4.0843, val_loss: 4.1765, val_MinusLogProbMetric: 4.1765

Epoch 165: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0843 - MinusLogProbMetric: 4.0843 - val_loss: 4.1765 - val_MinusLogProbMetric: 4.1765 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 166/1000
2023-09-17 04:11:15.213 
Epoch 166/1000 
	 loss: 4.0805, MinusLogProbMetric: 4.0805, val_loss: 4.1973, val_MinusLogProbMetric: 4.1973

Epoch 166: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0805 - MinusLogProbMetric: 4.0805 - val_loss: 4.1973 - val_MinusLogProbMetric: 4.1973 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 167/1000
2023-09-17 04:12:00.067 
Epoch 167/1000 
	 loss: 4.0842, MinusLogProbMetric: 4.0842, val_loss: 4.1999, val_MinusLogProbMetric: 4.1999

Epoch 167: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0842 - MinusLogProbMetric: 4.0842 - val_loss: 4.1999 - val_MinusLogProbMetric: 4.1999 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 168/1000
2023-09-17 04:12:45.104 
Epoch 168/1000 
	 loss: 4.0845, MinusLogProbMetric: 4.0845, val_loss: 4.1920, val_MinusLogProbMetric: 4.1920

Epoch 168: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0845 - MinusLogProbMetric: 4.0845 - val_loss: 4.1920 - val_MinusLogProbMetric: 4.1920 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 169/1000
2023-09-17 04:13:27.333 
Epoch 169/1000 
	 loss: 4.0814, MinusLogProbMetric: 4.0814, val_loss: 4.1879, val_MinusLogProbMetric: 4.1879

Epoch 169: val_loss did not improve from 4.16562
196/196 - 42s - loss: 4.0814 - MinusLogProbMetric: 4.0814 - val_loss: 4.1879 - val_MinusLogProbMetric: 4.1879 - lr: 0.0010 - 42s/epoch - 215ms/step
Epoch 170/1000
2023-09-17 04:14:05.514 
Epoch 170/1000 
	 loss: 4.0762, MinusLogProbMetric: 4.0762, val_loss: 4.1828, val_MinusLogProbMetric: 4.1828

Epoch 170: val_loss did not improve from 4.16562
196/196 - 38s - loss: 4.0762 - MinusLogProbMetric: 4.0762 - val_loss: 4.1828 - val_MinusLogProbMetric: 4.1828 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 171/1000
2023-09-17 04:14:41.281 
Epoch 171/1000 
	 loss: 4.0739, MinusLogProbMetric: 4.0739, val_loss: 4.1733, val_MinusLogProbMetric: 4.1733

Epoch 171: val_loss did not improve from 4.16562
196/196 - 36s - loss: 4.0739 - MinusLogProbMetric: 4.0739 - val_loss: 4.1733 - val_MinusLogProbMetric: 4.1733 - lr: 0.0010 - 36s/epoch - 182ms/step
Epoch 172/1000
2023-09-17 04:15:17.064 
Epoch 172/1000 
	 loss: 4.0720, MinusLogProbMetric: 4.0720, val_loss: 4.1757, val_MinusLogProbMetric: 4.1757

Epoch 172: val_loss did not improve from 4.16562
196/196 - 36s - loss: 4.0720 - MinusLogProbMetric: 4.0720 - val_loss: 4.1757 - val_MinusLogProbMetric: 4.1757 - lr: 0.0010 - 36s/epoch - 183ms/step
Epoch 173/1000
2023-09-17 04:16:00.234 
Epoch 173/1000 
	 loss: 4.0748, MinusLogProbMetric: 4.0748, val_loss: 4.2017, val_MinusLogProbMetric: 4.2017

Epoch 173: val_loss did not improve from 4.16562
196/196 - 43s - loss: 4.0748 - MinusLogProbMetric: 4.0748 - val_loss: 4.2017 - val_MinusLogProbMetric: 4.2017 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 174/1000
2023-09-17 04:16:44.588 
Epoch 174/1000 
	 loss: 4.0856, MinusLogProbMetric: 4.0856, val_loss: 4.2048, val_MinusLogProbMetric: 4.2048

Epoch 174: val_loss did not improve from 4.16562
196/196 - 44s - loss: 4.0856 - MinusLogProbMetric: 4.0856 - val_loss: 4.2048 - val_MinusLogProbMetric: 4.2048 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 175/1000
2023-09-17 04:17:28.195 
Epoch 175/1000 
	 loss: 4.0772, MinusLogProbMetric: 4.0772, val_loss: 4.1780, val_MinusLogProbMetric: 4.1780

Epoch 175: val_loss did not improve from 4.16562
196/196 - 44s - loss: 4.0772 - MinusLogProbMetric: 4.0772 - val_loss: 4.1780 - val_MinusLogProbMetric: 4.1780 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 176/1000
2023-09-17 04:18:12.952 
Epoch 176/1000 
	 loss: 4.0729, MinusLogProbMetric: 4.0729, val_loss: 4.2193, val_MinusLogProbMetric: 4.2193

Epoch 176: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0729 - MinusLogProbMetric: 4.0729 - val_loss: 4.2193 - val_MinusLogProbMetric: 4.2193 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 177/1000
2023-09-17 04:18:57.298 
Epoch 177/1000 
	 loss: 4.0768, MinusLogProbMetric: 4.0768, val_loss: 4.1824, val_MinusLogProbMetric: 4.1824

Epoch 177: val_loss did not improve from 4.16562
196/196 - 44s - loss: 4.0768 - MinusLogProbMetric: 4.0768 - val_loss: 4.1824 - val_MinusLogProbMetric: 4.1824 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 178/1000
2023-09-17 04:19:41.839 
Epoch 178/1000 
	 loss: 4.0784, MinusLogProbMetric: 4.0784, val_loss: 4.2174, val_MinusLogProbMetric: 4.2174

Epoch 178: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0784 - MinusLogProbMetric: 4.0784 - val_loss: 4.2174 - val_MinusLogProbMetric: 4.2174 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 179/1000
2023-09-17 04:20:26.345 
Epoch 179/1000 
	 loss: 4.0709, MinusLogProbMetric: 4.0709, val_loss: 4.1942, val_MinusLogProbMetric: 4.1942

Epoch 179: val_loss did not improve from 4.16562
196/196 - 44s - loss: 4.0709 - MinusLogProbMetric: 4.0709 - val_loss: 4.1942 - val_MinusLogProbMetric: 4.1942 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 180/1000
2023-09-17 04:21:10.552 
Epoch 180/1000 
	 loss: 4.0746, MinusLogProbMetric: 4.0746, val_loss: 4.2191, val_MinusLogProbMetric: 4.2191

Epoch 180: val_loss did not improve from 4.16562
196/196 - 44s - loss: 4.0746 - MinusLogProbMetric: 4.0746 - val_loss: 4.2191 - val_MinusLogProbMetric: 4.2191 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 181/1000
2023-09-17 04:21:55.121 
Epoch 181/1000 
	 loss: 4.0772, MinusLogProbMetric: 4.0772, val_loss: 4.1907, val_MinusLogProbMetric: 4.1907

Epoch 181: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0772 - MinusLogProbMetric: 4.0772 - val_loss: 4.1907 - val_MinusLogProbMetric: 4.1907 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 182/1000
2023-09-17 04:22:39.541 
Epoch 182/1000 
	 loss: 4.0762, MinusLogProbMetric: 4.0762, val_loss: 4.1787, val_MinusLogProbMetric: 4.1787

Epoch 182: val_loss did not improve from 4.16562
196/196 - 44s - loss: 4.0762 - MinusLogProbMetric: 4.0762 - val_loss: 4.1787 - val_MinusLogProbMetric: 4.1787 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 183/1000
2023-09-17 04:23:24.217 
Epoch 183/1000 
	 loss: 4.0736, MinusLogProbMetric: 4.0736, val_loss: 4.2123, val_MinusLogProbMetric: 4.2123

Epoch 183: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0736 - MinusLogProbMetric: 4.0736 - val_loss: 4.2123 - val_MinusLogProbMetric: 4.2123 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 184/1000
2023-09-17 04:24:08.908 
Epoch 184/1000 
	 loss: 4.0753, MinusLogProbMetric: 4.0753, val_loss: 4.2141, val_MinusLogProbMetric: 4.2141

Epoch 184: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0753 - MinusLogProbMetric: 4.0753 - val_loss: 4.2141 - val_MinusLogProbMetric: 4.2141 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 185/1000
2023-09-17 04:24:53.395 
Epoch 185/1000 
	 loss: 4.0762, MinusLogProbMetric: 4.0762, val_loss: 4.1936, val_MinusLogProbMetric: 4.1936

Epoch 185: val_loss did not improve from 4.16562
196/196 - 44s - loss: 4.0762 - MinusLogProbMetric: 4.0762 - val_loss: 4.1936 - val_MinusLogProbMetric: 4.1936 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 186/1000
2023-09-17 04:25:37.609 
Epoch 186/1000 
	 loss: 4.0751, MinusLogProbMetric: 4.0751, val_loss: 4.1997, val_MinusLogProbMetric: 4.1997

Epoch 186: val_loss did not improve from 4.16562
196/196 - 44s - loss: 4.0751 - MinusLogProbMetric: 4.0751 - val_loss: 4.1997 - val_MinusLogProbMetric: 4.1997 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 187/1000
2023-09-17 04:26:21.957 
Epoch 187/1000 
	 loss: 4.0714, MinusLogProbMetric: 4.0714, val_loss: 4.1884, val_MinusLogProbMetric: 4.1884

Epoch 187: val_loss did not improve from 4.16562
196/196 - 44s - loss: 4.0714 - MinusLogProbMetric: 4.0714 - val_loss: 4.1884 - val_MinusLogProbMetric: 4.1884 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 188/1000
2023-09-17 04:27:06.337 
Epoch 188/1000 
	 loss: 4.0717, MinusLogProbMetric: 4.0717, val_loss: 4.1896, val_MinusLogProbMetric: 4.1896

Epoch 188: val_loss did not improve from 4.16562
196/196 - 44s - loss: 4.0717 - MinusLogProbMetric: 4.0717 - val_loss: 4.1896 - val_MinusLogProbMetric: 4.1896 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 189/1000
2023-09-17 04:27:49.794 
Epoch 189/1000 
	 loss: 4.0726, MinusLogProbMetric: 4.0726, val_loss: 4.1766, val_MinusLogProbMetric: 4.1766

Epoch 189: val_loss did not improve from 4.16562
196/196 - 43s - loss: 4.0726 - MinusLogProbMetric: 4.0726 - val_loss: 4.1766 - val_MinusLogProbMetric: 4.1766 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 190/1000
2023-09-17 04:28:31.014 
Epoch 190/1000 
	 loss: 4.0719, MinusLogProbMetric: 4.0719, val_loss: 4.2079, val_MinusLogProbMetric: 4.2079

Epoch 190: val_loss did not improve from 4.16562
196/196 - 41s - loss: 4.0719 - MinusLogProbMetric: 4.0719 - val_loss: 4.2079 - val_MinusLogProbMetric: 4.2079 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 191/1000
2023-09-17 04:29:07.769 
Epoch 191/1000 
	 loss: 4.0698, MinusLogProbMetric: 4.0698, val_loss: 4.1950, val_MinusLogProbMetric: 4.1950

Epoch 191: val_loss did not improve from 4.16562
196/196 - 37s - loss: 4.0698 - MinusLogProbMetric: 4.0698 - val_loss: 4.1950 - val_MinusLogProbMetric: 4.1950 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 192/1000
2023-09-17 04:29:43.701 
Epoch 192/1000 
	 loss: 4.0686, MinusLogProbMetric: 4.0686, val_loss: 4.2000, val_MinusLogProbMetric: 4.2000

Epoch 192: val_loss did not improve from 4.16562
196/196 - 36s - loss: 4.0686 - MinusLogProbMetric: 4.0686 - val_loss: 4.2000 - val_MinusLogProbMetric: 4.2000 - lr: 0.0010 - 36s/epoch - 183ms/step
Epoch 193/1000
2023-09-17 04:30:27.031 
Epoch 193/1000 
	 loss: 4.0734, MinusLogProbMetric: 4.0734, val_loss: 4.1799, val_MinusLogProbMetric: 4.1799

Epoch 193: val_loss did not improve from 4.16562
196/196 - 43s - loss: 4.0734 - MinusLogProbMetric: 4.0734 - val_loss: 4.1799 - val_MinusLogProbMetric: 4.1799 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 194/1000
2023-09-17 04:31:11.451 
Epoch 194/1000 
	 loss: 4.0693, MinusLogProbMetric: 4.0693, val_loss: 4.1869, val_MinusLogProbMetric: 4.1869

Epoch 194: val_loss did not improve from 4.16562
196/196 - 44s - loss: 4.0693 - MinusLogProbMetric: 4.0693 - val_loss: 4.1869 - val_MinusLogProbMetric: 4.1869 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 195/1000
2023-09-17 04:31:54.890 
Epoch 195/1000 
	 loss: 4.0659, MinusLogProbMetric: 4.0659, val_loss: 4.1844, val_MinusLogProbMetric: 4.1844

Epoch 195: val_loss did not improve from 4.16562
196/196 - 43s - loss: 4.0659 - MinusLogProbMetric: 4.0659 - val_loss: 4.1844 - val_MinusLogProbMetric: 4.1844 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 196/1000
2023-09-17 04:32:39.169 
Epoch 196/1000 
	 loss: 4.0700, MinusLogProbMetric: 4.0700, val_loss: 4.1928, val_MinusLogProbMetric: 4.1928

Epoch 196: val_loss did not improve from 4.16562
196/196 - 44s - loss: 4.0700 - MinusLogProbMetric: 4.0700 - val_loss: 4.1928 - val_MinusLogProbMetric: 4.1928 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 197/1000
2023-09-17 04:33:23.795 
Epoch 197/1000 
	 loss: 4.0678, MinusLogProbMetric: 4.0678, val_loss: 4.2419, val_MinusLogProbMetric: 4.2419

Epoch 197: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0678 - MinusLogProbMetric: 4.0678 - val_loss: 4.2419 - val_MinusLogProbMetric: 4.2419 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 198/1000
2023-09-17 04:34:08.504 
Epoch 198/1000 
	 loss: 4.0690, MinusLogProbMetric: 4.0690, val_loss: 4.2039, val_MinusLogProbMetric: 4.2039

Epoch 198: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0690 - MinusLogProbMetric: 4.0690 - val_loss: 4.2039 - val_MinusLogProbMetric: 4.2039 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 199/1000
2023-09-17 04:34:53.046 
Epoch 199/1000 
	 loss: 4.0736, MinusLogProbMetric: 4.0736, val_loss: 4.2069, val_MinusLogProbMetric: 4.2069

Epoch 199: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0736 - MinusLogProbMetric: 4.0736 - val_loss: 4.2069 - val_MinusLogProbMetric: 4.2069 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 200/1000
2023-09-17 04:35:37.414 
Epoch 200/1000 
	 loss: 4.0667, MinusLogProbMetric: 4.0667, val_loss: 4.2283, val_MinusLogProbMetric: 4.2283

Epoch 200: val_loss did not improve from 4.16562
196/196 - 44s - loss: 4.0667 - MinusLogProbMetric: 4.0667 - val_loss: 4.2283 - val_MinusLogProbMetric: 4.2283 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 201/1000
2023-09-17 04:36:22.357 
Epoch 201/1000 
	 loss: 4.0361, MinusLogProbMetric: 4.0361, val_loss: 4.1658, val_MinusLogProbMetric: 4.1658

Epoch 201: val_loss did not improve from 4.16562
196/196 - 45s - loss: 4.0361 - MinusLogProbMetric: 4.0361 - val_loss: 4.1658 - val_MinusLogProbMetric: 4.1658 - lr: 5.0000e-04 - 45s/epoch - 229ms/step
Epoch 202/1000
2023-09-17 04:37:06.750 
Epoch 202/1000 
	 loss: 4.0342, MinusLogProbMetric: 4.0342, val_loss: 4.1887, val_MinusLogProbMetric: 4.1887

Epoch 202: val_loss did not improve from 4.16562
196/196 - 44s - loss: 4.0342 - MinusLogProbMetric: 4.0342 - val_loss: 4.1887 - val_MinusLogProbMetric: 4.1887 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 203/1000
2023-09-17 04:37:51.320 
Epoch 203/1000 
	 loss: 4.0347, MinusLogProbMetric: 4.0347, val_loss: 4.1642, val_MinusLogProbMetric: 4.1642

Epoch 203: val_loss improved from 4.16562 to 4.16425, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 45s - loss: 4.0347 - MinusLogProbMetric: 4.0347 - val_loss: 4.1642 - val_MinusLogProbMetric: 4.1642 - lr: 5.0000e-04 - 45s/epoch - 231ms/step
Epoch 204/1000
2023-09-17 04:38:36.734 
Epoch 204/1000 
	 loss: 4.0354, MinusLogProbMetric: 4.0354, val_loss: 4.1588, val_MinusLogProbMetric: 4.1588

Epoch 204: val_loss improved from 4.16425 to 4.15878, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_107/weights/best_weights.h5
196/196 - 45s - loss: 4.0354 - MinusLogProbMetric: 4.0354 - val_loss: 4.1588 - val_MinusLogProbMetric: 4.1588 - lr: 5.0000e-04 - 45s/epoch - 231ms/step
Epoch 205/1000
2023-09-17 04:39:21.719 
Epoch 205/1000 
	 loss: 4.0327, MinusLogProbMetric: 4.0327, val_loss: 4.1910, val_MinusLogProbMetric: 4.1910

Epoch 205: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0327 - MinusLogProbMetric: 4.0327 - val_loss: 4.1910 - val_MinusLogProbMetric: 4.1910 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 206/1000
2023-09-17 04:40:06.394 
Epoch 206/1000 
	 loss: 4.0347, MinusLogProbMetric: 4.0347, val_loss: 4.1701, val_MinusLogProbMetric: 4.1701

Epoch 206: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0347 - MinusLogProbMetric: 4.0347 - val_loss: 4.1701 - val_MinusLogProbMetric: 4.1701 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 207/1000
2023-09-17 04:40:50.800 
Epoch 207/1000 
	 loss: 4.0326, MinusLogProbMetric: 4.0326, val_loss: 4.1702, val_MinusLogProbMetric: 4.1702

Epoch 207: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0326 - MinusLogProbMetric: 4.0326 - val_loss: 4.1702 - val_MinusLogProbMetric: 4.1702 - lr: 5.0000e-04 - 44s/epoch - 227ms/step
Epoch 208/1000
2023-09-17 04:41:35.416 
Epoch 208/1000 
	 loss: 4.0369, MinusLogProbMetric: 4.0369, val_loss: 4.1684, val_MinusLogProbMetric: 4.1684

Epoch 208: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0369 - MinusLogProbMetric: 4.0369 - val_loss: 4.1684 - val_MinusLogProbMetric: 4.1684 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 209/1000
2023-09-17 04:42:17.390 
Epoch 209/1000 
	 loss: 4.0339, MinusLogProbMetric: 4.0339, val_loss: 4.1652, val_MinusLogProbMetric: 4.1652

Epoch 209: val_loss did not improve from 4.15878
196/196 - 42s - loss: 4.0339 - MinusLogProbMetric: 4.0339 - val_loss: 4.1652 - val_MinusLogProbMetric: 4.1652 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 210/1000
2023-09-17 04:42:59.690 
Epoch 210/1000 
	 loss: 4.0327, MinusLogProbMetric: 4.0327, val_loss: 4.1771, val_MinusLogProbMetric: 4.1771

Epoch 210: val_loss did not improve from 4.15878
196/196 - 42s - loss: 4.0327 - MinusLogProbMetric: 4.0327 - val_loss: 4.1771 - val_MinusLogProbMetric: 4.1771 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 211/1000
2023-09-17 04:43:38.935 
Epoch 211/1000 
	 loss: 4.0335, MinusLogProbMetric: 4.0335, val_loss: 4.1715, val_MinusLogProbMetric: 4.1715

Epoch 211: val_loss did not improve from 4.15878
196/196 - 39s - loss: 4.0335 - MinusLogProbMetric: 4.0335 - val_loss: 4.1715 - val_MinusLogProbMetric: 4.1715 - lr: 5.0000e-04 - 39s/epoch - 200ms/step
Epoch 212/1000
2023-09-17 04:44:14.714 
Epoch 212/1000 
	 loss: 4.0308, MinusLogProbMetric: 4.0308, val_loss: 4.1757, val_MinusLogProbMetric: 4.1757

Epoch 212: val_loss did not improve from 4.15878
196/196 - 36s - loss: 4.0308 - MinusLogProbMetric: 4.0308 - val_loss: 4.1757 - val_MinusLogProbMetric: 4.1757 - lr: 5.0000e-04 - 36s/epoch - 183ms/step
Epoch 213/1000
2023-09-17 04:44:50.335 
Epoch 213/1000 
	 loss: 4.0316, MinusLogProbMetric: 4.0316, val_loss: 4.1797, val_MinusLogProbMetric: 4.1797

Epoch 213: val_loss did not improve from 4.15878
196/196 - 36s - loss: 4.0316 - MinusLogProbMetric: 4.0316 - val_loss: 4.1797 - val_MinusLogProbMetric: 4.1797 - lr: 5.0000e-04 - 36s/epoch - 182ms/step
Epoch 214/1000
2023-09-17 04:45:33.192 
Epoch 214/1000 
	 loss: 4.0320, MinusLogProbMetric: 4.0320, val_loss: 4.1675, val_MinusLogProbMetric: 4.1675

Epoch 214: val_loss did not improve from 4.15878
196/196 - 43s - loss: 4.0320 - MinusLogProbMetric: 4.0320 - val_loss: 4.1675 - val_MinusLogProbMetric: 4.1675 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 215/1000
2023-09-17 04:46:14.868 
Epoch 215/1000 
	 loss: 4.0296, MinusLogProbMetric: 4.0296, val_loss: 4.1759, val_MinusLogProbMetric: 4.1759

Epoch 215: val_loss did not improve from 4.15878
196/196 - 42s - loss: 4.0296 - MinusLogProbMetric: 4.0296 - val_loss: 4.1759 - val_MinusLogProbMetric: 4.1759 - lr: 5.0000e-04 - 42s/epoch - 213ms/step
Epoch 216/1000
2023-09-17 04:46:56.629 
Epoch 216/1000 
	 loss: 4.0294, MinusLogProbMetric: 4.0294, val_loss: 4.1673, val_MinusLogProbMetric: 4.1673

Epoch 216: val_loss did not improve from 4.15878
196/196 - 42s - loss: 4.0294 - MinusLogProbMetric: 4.0294 - val_loss: 4.1673 - val_MinusLogProbMetric: 4.1673 - lr: 5.0000e-04 - 42s/epoch - 213ms/step
Epoch 217/1000
2023-09-17 04:47:40.251 
Epoch 217/1000 
	 loss: 4.0297, MinusLogProbMetric: 4.0297, val_loss: 4.1701, val_MinusLogProbMetric: 4.1701

Epoch 217: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0297 - MinusLogProbMetric: 4.0297 - val_loss: 4.1701 - val_MinusLogProbMetric: 4.1701 - lr: 5.0000e-04 - 44s/epoch - 223ms/step
Epoch 218/1000
2023-09-17 04:48:24.158 
Epoch 218/1000 
	 loss: 4.0322, MinusLogProbMetric: 4.0322, val_loss: 4.1708, val_MinusLogProbMetric: 4.1708

Epoch 218: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0322 - MinusLogProbMetric: 4.0322 - val_loss: 4.1708 - val_MinusLogProbMetric: 4.1708 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 219/1000
2023-09-17 04:49:07.972 
Epoch 219/1000 
	 loss: 4.0289, MinusLogProbMetric: 4.0289, val_loss: 4.1751, val_MinusLogProbMetric: 4.1751

Epoch 219: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0289 - MinusLogProbMetric: 4.0289 - val_loss: 4.1751 - val_MinusLogProbMetric: 4.1751 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 220/1000
2023-09-17 04:49:52.346 
Epoch 220/1000 
	 loss: 4.0290, MinusLogProbMetric: 4.0290, val_loss: 4.1724, val_MinusLogProbMetric: 4.1724

Epoch 220: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0290 - MinusLogProbMetric: 4.0290 - val_loss: 4.1724 - val_MinusLogProbMetric: 4.1724 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 221/1000
2023-09-17 04:50:36.633 
Epoch 221/1000 
	 loss: 4.0308, MinusLogProbMetric: 4.0308, val_loss: 4.1707, val_MinusLogProbMetric: 4.1707

Epoch 221: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0308 - MinusLogProbMetric: 4.0308 - val_loss: 4.1707 - val_MinusLogProbMetric: 4.1707 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 222/1000
2023-09-17 04:51:21.341 
Epoch 222/1000 
	 loss: 4.0315, MinusLogProbMetric: 4.0315, val_loss: 4.1794, val_MinusLogProbMetric: 4.1794

Epoch 222: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0315 - MinusLogProbMetric: 4.0315 - val_loss: 4.1794 - val_MinusLogProbMetric: 4.1794 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 223/1000
2023-09-17 04:52:05.500 
Epoch 223/1000 
	 loss: 4.0316, MinusLogProbMetric: 4.0316, val_loss: 4.1820, val_MinusLogProbMetric: 4.1820

Epoch 223: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0316 - MinusLogProbMetric: 4.0316 - val_loss: 4.1820 - val_MinusLogProbMetric: 4.1820 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 224/1000
2023-09-17 04:52:49.904 
Epoch 224/1000 
	 loss: 4.0283, MinusLogProbMetric: 4.0283, val_loss: 4.1774, val_MinusLogProbMetric: 4.1774

Epoch 224: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0283 - MinusLogProbMetric: 4.0283 - val_loss: 4.1774 - val_MinusLogProbMetric: 4.1774 - lr: 5.0000e-04 - 44s/epoch - 227ms/step
Epoch 225/1000
2023-09-17 04:53:34.141 
Epoch 225/1000 
	 loss: 4.0324, MinusLogProbMetric: 4.0324, val_loss: 4.1651, val_MinusLogProbMetric: 4.1651

Epoch 225: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0324 - MinusLogProbMetric: 4.0324 - val_loss: 4.1651 - val_MinusLogProbMetric: 4.1651 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 226/1000
2023-09-17 04:54:18.494 
Epoch 226/1000 
	 loss: 4.0282, MinusLogProbMetric: 4.0282, val_loss: 4.1818, val_MinusLogProbMetric: 4.1818

Epoch 226: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0282 - MinusLogProbMetric: 4.0282 - val_loss: 4.1818 - val_MinusLogProbMetric: 4.1818 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 227/1000
2023-09-17 04:55:02.450 
Epoch 227/1000 
	 loss: 4.0291, MinusLogProbMetric: 4.0291, val_loss: 4.1701, val_MinusLogProbMetric: 4.1701

Epoch 227: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0291 - MinusLogProbMetric: 4.0291 - val_loss: 4.1701 - val_MinusLogProbMetric: 4.1701 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 228/1000
2023-09-17 04:55:46.728 
Epoch 228/1000 
	 loss: 4.0290, MinusLogProbMetric: 4.0290, val_loss: 4.1865, val_MinusLogProbMetric: 4.1865

Epoch 228: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0290 - MinusLogProbMetric: 4.0290 - val_loss: 4.1865 - val_MinusLogProbMetric: 4.1865 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 229/1000
2023-09-17 04:56:30.736 
Epoch 229/1000 
	 loss: 4.0283, MinusLogProbMetric: 4.0283, val_loss: 4.1738, val_MinusLogProbMetric: 4.1738

Epoch 229: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0283 - MinusLogProbMetric: 4.0283 - val_loss: 4.1738 - val_MinusLogProbMetric: 4.1738 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 230/1000
2023-09-17 04:57:15.051 
Epoch 230/1000 
	 loss: 4.0286, MinusLogProbMetric: 4.0286, val_loss: 4.1716, val_MinusLogProbMetric: 4.1716

Epoch 230: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0286 - MinusLogProbMetric: 4.0286 - val_loss: 4.1716 - val_MinusLogProbMetric: 4.1716 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 231/1000
2023-09-17 04:57:59.256 
Epoch 231/1000 
	 loss: 4.0267, MinusLogProbMetric: 4.0267, val_loss: 4.1703, val_MinusLogProbMetric: 4.1703

Epoch 231: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0267 - MinusLogProbMetric: 4.0267 - val_loss: 4.1703 - val_MinusLogProbMetric: 4.1703 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 232/1000
2023-09-17 04:58:43.617 
Epoch 232/1000 
	 loss: 4.0276, MinusLogProbMetric: 4.0276, val_loss: 4.1721, val_MinusLogProbMetric: 4.1721

Epoch 232: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0276 - MinusLogProbMetric: 4.0276 - val_loss: 4.1721 - val_MinusLogProbMetric: 4.1721 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 233/1000
2023-09-17 04:59:28.290 
Epoch 233/1000 
	 loss: 4.0280, MinusLogProbMetric: 4.0280, val_loss: 4.1746, val_MinusLogProbMetric: 4.1746

Epoch 233: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0280 - MinusLogProbMetric: 4.0280 - val_loss: 4.1746 - val_MinusLogProbMetric: 4.1746 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 234/1000
2023-09-17 05:00:12.359 
Epoch 234/1000 
	 loss: 4.0279, MinusLogProbMetric: 4.0279, val_loss: 4.1713, val_MinusLogProbMetric: 4.1713

Epoch 234: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0279 - MinusLogProbMetric: 4.0279 - val_loss: 4.1713 - val_MinusLogProbMetric: 4.1713 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 235/1000
2023-09-17 05:00:49.580 
Epoch 235/1000 
	 loss: 4.0266, MinusLogProbMetric: 4.0266, val_loss: 4.1757, val_MinusLogProbMetric: 4.1757

Epoch 235: val_loss did not improve from 4.15878
196/196 - 37s - loss: 4.0266 - MinusLogProbMetric: 4.0266 - val_loss: 4.1757 - val_MinusLogProbMetric: 4.1757 - lr: 5.0000e-04 - 37s/epoch - 190ms/step
Epoch 236/1000
2023-09-17 05:01:27.396 
Epoch 236/1000 
	 loss: 4.0320, MinusLogProbMetric: 4.0320, val_loss: 4.1706, val_MinusLogProbMetric: 4.1706

Epoch 236: val_loss did not improve from 4.15878
196/196 - 38s - loss: 4.0320 - MinusLogProbMetric: 4.0320 - val_loss: 4.1706 - val_MinusLogProbMetric: 4.1706 - lr: 5.0000e-04 - 38s/epoch - 193ms/step
Epoch 237/1000
2023-09-17 05:02:03.982 
Epoch 237/1000 
	 loss: 4.0271, MinusLogProbMetric: 4.0271, val_loss: 4.1820, val_MinusLogProbMetric: 4.1820

Epoch 237: val_loss did not improve from 4.15878
196/196 - 37s - loss: 4.0271 - MinusLogProbMetric: 4.0271 - val_loss: 4.1820 - val_MinusLogProbMetric: 4.1820 - lr: 5.0000e-04 - 37s/epoch - 187ms/step
Epoch 238/1000
2023-09-17 05:02:48.135 
Epoch 238/1000 
	 loss: 4.0282, MinusLogProbMetric: 4.0282, val_loss: 4.1741, val_MinusLogProbMetric: 4.1741

Epoch 238: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0282 - MinusLogProbMetric: 4.0282 - val_loss: 4.1741 - val_MinusLogProbMetric: 4.1741 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 239/1000
2023-09-17 05:03:32.714 
Epoch 239/1000 
	 loss: 4.0280, MinusLogProbMetric: 4.0280, val_loss: 4.1739, val_MinusLogProbMetric: 4.1739

Epoch 239: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0280 - MinusLogProbMetric: 4.0280 - val_loss: 4.1739 - val_MinusLogProbMetric: 4.1739 - lr: 5.0000e-04 - 45s/epoch - 227ms/step
Epoch 240/1000
2023-09-17 05:04:17.108 
Epoch 240/1000 
	 loss: 4.0275, MinusLogProbMetric: 4.0275, val_loss: 4.1771, val_MinusLogProbMetric: 4.1771

Epoch 240: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0275 - MinusLogProbMetric: 4.0275 - val_loss: 4.1771 - val_MinusLogProbMetric: 4.1771 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 241/1000
2023-09-17 05:05:01.526 
Epoch 241/1000 
	 loss: 4.0283, MinusLogProbMetric: 4.0283, val_loss: 4.1833, val_MinusLogProbMetric: 4.1833

Epoch 241: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0283 - MinusLogProbMetric: 4.0283 - val_loss: 4.1833 - val_MinusLogProbMetric: 4.1833 - lr: 5.0000e-04 - 44s/epoch - 227ms/step
Epoch 242/1000
2023-09-17 05:05:45.669 
Epoch 242/1000 
	 loss: 4.0251, MinusLogProbMetric: 4.0251, val_loss: 4.1943, val_MinusLogProbMetric: 4.1943

Epoch 242: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0251 - MinusLogProbMetric: 4.0251 - val_loss: 4.1943 - val_MinusLogProbMetric: 4.1943 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 243/1000
2023-09-17 05:06:30.426 
Epoch 243/1000 
	 loss: 4.0282, MinusLogProbMetric: 4.0282, val_loss: 4.1776, val_MinusLogProbMetric: 4.1776

Epoch 243: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0282 - MinusLogProbMetric: 4.0282 - val_loss: 4.1776 - val_MinusLogProbMetric: 4.1776 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 244/1000
2023-09-17 05:07:14.882 
Epoch 244/1000 
	 loss: 4.0286, MinusLogProbMetric: 4.0286, val_loss: 4.1859, val_MinusLogProbMetric: 4.1859

Epoch 244: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0286 - MinusLogProbMetric: 4.0286 - val_loss: 4.1859 - val_MinusLogProbMetric: 4.1859 - lr: 5.0000e-04 - 44s/epoch - 227ms/step
Epoch 245/1000
2023-09-17 05:07:59.233 
Epoch 245/1000 
	 loss: 4.0299, MinusLogProbMetric: 4.0299, val_loss: 4.1914, val_MinusLogProbMetric: 4.1914

Epoch 245: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0299 - MinusLogProbMetric: 4.0299 - val_loss: 4.1914 - val_MinusLogProbMetric: 4.1914 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 246/1000
2023-09-17 05:08:43.933 
Epoch 246/1000 
	 loss: 4.0264, MinusLogProbMetric: 4.0264, val_loss: 4.1708, val_MinusLogProbMetric: 4.1708

Epoch 246: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0264 - MinusLogProbMetric: 4.0264 - val_loss: 4.1708 - val_MinusLogProbMetric: 4.1708 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 247/1000
2023-09-17 05:09:28.330 
Epoch 247/1000 
	 loss: 4.0277, MinusLogProbMetric: 4.0277, val_loss: 4.1790, val_MinusLogProbMetric: 4.1790

Epoch 247: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0277 - MinusLogProbMetric: 4.0277 - val_loss: 4.1790 - val_MinusLogProbMetric: 4.1790 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 248/1000
2023-09-17 05:10:12.385 
Epoch 248/1000 
	 loss: 4.0260, MinusLogProbMetric: 4.0260, val_loss: 4.1813, val_MinusLogProbMetric: 4.1813

Epoch 248: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0260 - MinusLogProbMetric: 4.0260 - val_loss: 4.1813 - val_MinusLogProbMetric: 4.1813 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 249/1000
2023-09-17 05:10:56.766 
Epoch 249/1000 
	 loss: 4.0255, MinusLogProbMetric: 4.0255, val_loss: 4.1881, val_MinusLogProbMetric: 4.1881

Epoch 249: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0255 - MinusLogProbMetric: 4.0255 - val_loss: 4.1881 - val_MinusLogProbMetric: 4.1881 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 250/1000
2023-09-17 05:11:41.219 
Epoch 250/1000 
	 loss: 4.0263, MinusLogProbMetric: 4.0263, val_loss: 4.1758, val_MinusLogProbMetric: 4.1758

Epoch 250: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0263 - MinusLogProbMetric: 4.0263 - val_loss: 4.1758 - val_MinusLogProbMetric: 4.1758 - lr: 5.0000e-04 - 44s/epoch - 227ms/step
Epoch 251/1000
2023-09-17 05:12:25.669 
Epoch 251/1000 
	 loss: 4.0237, MinusLogProbMetric: 4.0237, val_loss: 4.1784, val_MinusLogProbMetric: 4.1784

Epoch 251: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0237 - MinusLogProbMetric: 4.0237 - val_loss: 4.1784 - val_MinusLogProbMetric: 4.1784 - lr: 5.0000e-04 - 44s/epoch - 227ms/step
Epoch 252/1000
2023-09-17 05:13:10.154 
Epoch 252/1000 
	 loss: 4.0243, MinusLogProbMetric: 4.0243, val_loss: 4.1857, val_MinusLogProbMetric: 4.1857

Epoch 252: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0243 - MinusLogProbMetric: 4.0243 - val_loss: 4.1857 - val_MinusLogProbMetric: 4.1857 - lr: 5.0000e-04 - 44s/epoch - 227ms/step
Epoch 253/1000
2023-09-17 05:13:54.574 
Epoch 253/1000 
	 loss: 4.0302, MinusLogProbMetric: 4.0302, val_loss: 4.1862, val_MinusLogProbMetric: 4.1862

Epoch 253: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0302 - MinusLogProbMetric: 4.0302 - val_loss: 4.1862 - val_MinusLogProbMetric: 4.1862 - lr: 5.0000e-04 - 44s/epoch - 227ms/step
Epoch 254/1000
2023-09-17 05:14:38.918 
Epoch 254/1000 
	 loss: 4.0262, MinusLogProbMetric: 4.0262, val_loss: 4.1742, val_MinusLogProbMetric: 4.1742

Epoch 254: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0262 - MinusLogProbMetric: 4.0262 - val_loss: 4.1742 - val_MinusLogProbMetric: 4.1742 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 255/1000
2023-09-17 05:15:23.591 
Epoch 255/1000 
	 loss: 4.0088, MinusLogProbMetric: 4.0088, val_loss: 4.1732, val_MinusLogProbMetric: 4.1732

Epoch 255: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0088 - MinusLogProbMetric: 4.0088 - val_loss: 4.1732 - val_MinusLogProbMetric: 4.1732 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 256/1000
2023-09-17 05:16:07.647 
Epoch 256/1000 
	 loss: 4.0084, MinusLogProbMetric: 4.0084, val_loss: 4.1712, val_MinusLogProbMetric: 4.1712

Epoch 256: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0084 - MinusLogProbMetric: 4.0084 - val_loss: 4.1712 - val_MinusLogProbMetric: 4.1712 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 257/1000
2023-09-17 05:16:52.365 
Epoch 257/1000 
	 loss: 4.0067, MinusLogProbMetric: 4.0067, val_loss: 4.1777, val_MinusLogProbMetric: 4.1777

Epoch 257: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0067 - MinusLogProbMetric: 4.0067 - val_loss: 4.1777 - val_MinusLogProbMetric: 4.1777 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 258/1000
2023-09-17 05:17:36.798 
Epoch 258/1000 
	 loss: 4.0058, MinusLogProbMetric: 4.0058, val_loss: 4.1732, val_MinusLogProbMetric: 4.1732

Epoch 258: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0058 - MinusLogProbMetric: 4.0058 - val_loss: 4.1732 - val_MinusLogProbMetric: 4.1732 - lr: 2.5000e-04 - 44s/epoch - 227ms/step
Epoch 259/1000
2023-09-17 05:18:21.235 
Epoch 259/1000 
	 loss: 4.0068, MinusLogProbMetric: 4.0068, val_loss: 4.1758, val_MinusLogProbMetric: 4.1758

Epoch 259: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0068 - MinusLogProbMetric: 4.0068 - val_loss: 4.1758 - val_MinusLogProbMetric: 4.1758 - lr: 2.5000e-04 - 44s/epoch - 227ms/step
Epoch 260/1000
2023-09-17 05:19:06.071 
Epoch 260/1000 
	 loss: 4.0069, MinusLogProbMetric: 4.0069, val_loss: 4.1785, val_MinusLogProbMetric: 4.1785

Epoch 260: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0069 - MinusLogProbMetric: 4.0069 - val_loss: 4.1785 - val_MinusLogProbMetric: 4.1785 - lr: 2.5000e-04 - 45s/epoch - 229ms/step
Epoch 261/1000
2023-09-17 05:19:50.814 
Epoch 261/1000 
	 loss: 4.0056, MinusLogProbMetric: 4.0056, val_loss: 4.1783, val_MinusLogProbMetric: 4.1783

Epoch 261: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0056 - MinusLogProbMetric: 4.0056 - val_loss: 4.1783 - val_MinusLogProbMetric: 4.1783 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 262/1000
2023-09-17 05:20:35.408 
Epoch 262/1000 
	 loss: 4.0078, MinusLogProbMetric: 4.0078, val_loss: 4.1771, val_MinusLogProbMetric: 4.1771

Epoch 262: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0078 - MinusLogProbMetric: 4.0078 - val_loss: 4.1771 - val_MinusLogProbMetric: 4.1771 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 263/1000
2023-09-17 05:21:19.812 
Epoch 263/1000 
	 loss: 4.0051, MinusLogProbMetric: 4.0051, val_loss: 4.1846, val_MinusLogProbMetric: 4.1846

Epoch 263: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0051 - MinusLogProbMetric: 4.0051 - val_loss: 4.1846 - val_MinusLogProbMetric: 4.1846 - lr: 2.5000e-04 - 44s/epoch - 227ms/step
Epoch 264/1000
2023-09-17 05:22:04.271 
Epoch 264/1000 
	 loss: 4.0073, MinusLogProbMetric: 4.0073, val_loss: 4.1736, val_MinusLogProbMetric: 4.1736

Epoch 264: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0073 - MinusLogProbMetric: 4.0073 - val_loss: 4.1736 - val_MinusLogProbMetric: 4.1736 - lr: 2.5000e-04 - 44s/epoch - 227ms/step
Epoch 265/1000
2023-09-17 05:22:48.791 
Epoch 265/1000 
	 loss: 4.0059, MinusLogProbMetric: 4.0059, val_loss: 4.1737, val_MinusLogProbMetric: 4.1737

Epoch 265: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0059 - MinusLogProbMetric: 4.0059 - val_loss: 4.1737 - val_MinusLogProbMetric: 4.1737 - lr: 2.5000e-04 - 45s/epoch - 227ms/step
Epoch 266/1000
2023-09-17 05:23:33.455 
Epoch 266/1000 
	 loss: 4.0063, MinusLogProbMetric: 4.0063, val_loss: 4.1776, val_MinusLogProbMetric: 4.1776

Epoch 266: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0063 - MinusLogProbMetric: 4.0063 - val_loss: 4.1776 - val_MinusLogProbMetric: 4.1776 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 267/1000
2023-09-17 05:24:18.115 
Epoch 267/1000 
	 loss: 4.0058, MinusLogProbMetric: 4.0058, val_loss: 4.1770, val_MinusLogProbMetric: 4.1770

Epoch 267: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0058 - MinusLogProbMetric: 4.0058 - val_loss: 4.1770 - val_MinusLogProbMetric: 4.1770 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 268/1000
2023-09-17 05:25:02.744 
Epoch 268/1000 
	 loss: 4.0049, MinusLogProbMetric: 4.0049, val_loss: 4.1747, val_MinusLogProbMetric: 4.1747

Epoch 268: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0049 - MinusLogProbMetric: 4.0049 - val_loss: 4.1747 - val_MinusLogProbMetric: 4.1747 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 269/1000
2023-09-17 05:25:47.236 
Epoch 269/1000 
	 loss: 4.0045, MinusLogProbMetric: 4.0045, val_loss: 4.1775, val_MinusLogProbMetric: 4.1775

Epoch 269: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0045 - MinusLogProbMetric: 4.0045 - val_loss: 4.1775 - val_MinusLogProbMetric: 4.1775 - lr: 2.5000e-04 - 44s/epoch - 227ms/step
Epoch 270/1000
2023-09-17 05:26:31.564 
Epoch 270/1000 
	 loss: 4.0054, MinusLogProbMetric: 4.0054, val_loss: 4.1803, val_MinusLogProbMetric: 4.1803

Epoch 270: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0054 - MinusLogProbMetric: 4.0054 - val_loss: 4.1803 - val_MinusLogProbMetric: 4.1803 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 271/1000
2023-09-17 05:27:14.658 
Epoch 271/1000 
	 loss: 4.0058, MinusLogProbMetric: 4.0058, val_loss: 4.1770, val_MinusLogProbMetric: 4.1770

Epoch 271: val_loss did not improve from 4.15878
196/196 - 43s - loss: 4.0058 - MinusLogProbMetric: 4.0058 - val_loss: 4.1770 - val_MinusLogProbMetric: 4.1770 - lr: 2.5000e-04 - 43s/epoch - 220ms/step
Epoch 272/1000
2023-09-17 05:27:53.858 
Epoch 272/1000 
	 loss: 4.0059, MinusLogProbMetric: 4.0059, val_loss: 4.1862, val_MinusLogProbMetric: 4.1862

Epoch 272: val_loss did not improve from 4.15878
196/196 - 39s - loss: 4.0059 - MinusLogProbMetric: 4.0059 - val_loss: 4.1862 - val_MinusLogProbMetric: 4.1862 - lr: 2.5000e-04 - 39s/epoch - 200ms/step
Epoch 273/1000
2023-09-17 05:28:34.130 
Epoch 273/1000 
	 loss: 4.0055, MinusLogProbMetric: 4.0055, val_loss: 4.1813, val_MinusLogProbMetric: 4.1813

Epoch 273: val_loss did not improve from 4.15878
196/196 - 40s - loss: 4.0055 - MinusLogProbMetric: 4.0055 - val_loss: 4.1813 - val_MinusLogProbMetric: 4.1813 - lr: 2.5000e-04 - 40s/epoch - 205ms/step
Epoch 274/1000
2023-09-17 05:29:14.556 
Epoch 274/1000 
	 loss: 4.0064, MinusLogProbMetric: 4.0064, val_loss: 4.1775, val_MinusLogProbMetric: 4.1775

Epoch 274: val_loss did not improve from 4.15878
196/196 - 40s - loss: 4.0064 - MinusLogProbMetric: 4.0064 - val_loss: 4.1775 - val_MinusLogProbMetric: 4.1775 - lr: 2.5000e-04 - 40s/epoch - 206ms/step
Epoch 275/1000
2023-09-17 05:29:59.486 
Epoch 275/1000 
	 loss: 4.0058, MinusLogProbMetric: 4.0058, val_loss: 4.1774, val_MinusLogProbMetric: 4.1774

Epoch 275: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0058 - MinusLogProbMetric: 4.0058 - val_loss: 4.1774 - val_MinusLogProbMetric: 4.1774 - lr: 2.5000e-04 - 45s/epoch - 229ms/step
Epoch 276/1000
2023-09-17 05:30:44.123 
Epoch 276/1000 
	 loss: 4.0050, MinusLogProbMetric: 4.0050, val_loss: 4.1848, val_MinusLogProbMetric: 4.1848

Epoch 276: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0050 - MinusLogProbMetric: 4.0050 - val_loss: 4.1848 - val_MinusLogProbMetric: 4.1848 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 277/1000
2023-09-17 05:31:28.424 
Epoch 277/1000 
	 loss: 4.0049, MinusLogProbMetric: 4.0049, val_loss: 4.1820, val_MinusLogProbMetric: 4.1820

Epoch 277: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0049 - MinusLogProbMetric: 4.0049 - val_loss: 4.1820 - val_MinusLogProbMetric: 4.1820 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 278/1000
2023-09-17 05:32:13.075 
Epoch 278/1000 
	 loss: 4.0045, MinusLogProbMetric: 4.0045, val_loss: 4.1800, val_MinusLogProbMetric: 4.1800

Epoch 278: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0045 - MinusLogProbMetric: 4.0045 - val_loss: 4.1800 - val_MinusLogProbMetric: 4.1800 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 279/1000
2023-09-17 05:32:57.307 
Epoch 279/1000 
	 loss: 4.0061, MinusLogProbMetric: 4.0061, val_loss: 4.1805, val_MinusLogProbMetric: 4.1805

Epoch 279: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0061 - MinusLogProbMetric: 4.0061 - val_loss: 4.1805 - val_MinusLogProbMetric: 4.1805 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 280/1000
2023-09-17 05:33:41.846 
Epoch 280/1000 
	 loss: 4.0034, MinusLogProbMetric: 4.0034, val_loss: 4.1848, val_MinusLogProbMetric: 4.1848

Epoch 280: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0034 - MinusLogProbMetric: 4.0034 - val_loss: 4.1848 - val_MinusLogProbMetric: 4.1848 - lr: 2.5000e-04 - 45s/epoch - 227ms/step
Epoch 281/1000
2023-09-17 05:34:26.500 
Epoch 281/1000 
	 loss: 4.0038, MinusLogProbMetric: 4.0038, val_loss: 4.1788, val_MinusLogProbMetric: 4.1788

Epoch 281: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0038 - MinusLogProbMetric: 4.0038 - val_loss: 4.1788 - val_MinusLogProbMetric: 4.1788 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 282/1000
2023-09-17 05:35:11.069 
Epoch 282/1000 
	 loss: 4.0031, MinusLogProbMetric: 4.0031, val_loss: 4.1836, val_MinusLogProbMetric: 4.1836

Epoch 282: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0031 - MinusLogProbMetric: 4.0031 - val_loss: 4.1836 - val_MinusLogProbMetric: 4.1836 - lr: 2.5000e-04 - 45s/epoch - 227ms/step
Epoch 283/1000
2023-09-17 05:35:55.502 
Epoch 283/1000 
	 loss: 4.0040, MinusLogProbMetric: 4.0040, val_loss: 4.1764, val_MinusLogProbMetric: 4.1764

Epoch 283: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0040 - MinusLogProbMetric: 4.0040 - val_loss: 4.1764 - val_MinusLogProbMetric: 4.1764 - lr: 2.5000e-04 - 44s/epoch - 227ms/step
Epoch 284/1000
2023-09-17 05:36:40.232 
Epoch 284/1000 
	 loss: 4.0033, MinusLogProbMetric: 4.0033, val_loss: 4.1818, val_MinusLogProbMetric: 4.1818

Epoch 284: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0033 - MinusLogProbMetric: 4.0033 - val_loss: 4.1818 - val_MinusLogProbMetric: 4.1818 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 285/1000
2023-09-17 05:37:24.683 
Epoch 285/1000 
	 loss: 4.0049, MinusLogProbMetric: 4.0049, val_loss: 4.1888, val_MinusLogProbMetric: 4.1888

Epoch 285: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0049 - MinusLogProbMetric: 4.0049 - val_loss: 4.1888 - val_MinusLogProbMetric: 4.1888 - lr: 2.5000e-04 - 44s/epoch - 227ms/step
Epoch 286/1000
2023-09-17 05:38:09.666 
Epoch 286/1000 
	 loss: 4.0038, MinusLogProbMetric: 4.0038, val_loss: 4.1880, val_MinusLogProbMetric: 4.1880

Epoch 286: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0038 - MinusLogProbMetric: 4.0038 - val_loss: 4.1880 - val_MinusLogProbMetric: 4.1880 - lr: 2.5000e-04 - 45s/epoch - 229ms/step
Epoch 287/1000
2023-09-17 05:38:54.681 
Epoch 287/1000 
	 loss: 4.0039, MinusLogProbMetric: 4.0039, val_loss: 4.1839, val_MinusLogProbMetric: 4.1839

Epoch 287: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0039 - MinusLogProbMetric: 4.0039 - val_loss: 4.1839 - val_MinusLogProbMetric: 4.1839 - lr: 2.5000e-04 - 45s/epoch - 230ms/step
Epoch 288/1000
2023-09-17 05:39:39.596 
Epoch 288/1000 
	 loss: 4.0034, MinusLogProbMetric: 4.0034, val_loss: 4.1819, val_MinusLogProbMetric: 4.1819

Epoch 288: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0034 - MinusLogProbMetric: 4.0034 - val_loss: 4.1819 - val_MinusLogProbMetric: 4.1819 - lr: 2.5000e-04 - 45s/epoch - 229ms/step
Epoch 289/1000
2023-09-17 05:40:24.080 
Epoch 289/1000 
	 loss: 4.0029, MinusLogProbMetric: 4.0029, val_loss: 4.1833, val_MinusLogProbMetric: 4.1833

Epoch 289: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0029 - MinusLogProbMetric: 4.0029 - val_loss: 4.1833 - val_MinusLogProbMetric: 4.1833 - lr: 2.5000e-04 - 44s/epoch - 227ms/step
Epoch 290/1000
2023-09-17 05:41:08.235 
Epoch 290/1000 
	 loss: 4.0036, MinusLogProbMetric: 4.0036, val_loss: 4.1920, val_MinusLogProbMetric: 4.1920

Epoch 290: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0036 - MinusLogProbMetric: 4.0036 - val_loss: 4.1920 - val_MinusLogProbMetric: 4.1920 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 291/1000
2023-09-17 05:41:52.889 
Epoch 291/1000 
	 loss: 4.0020, MinusLogProbMetric: 4.0020, val_loss: 4.1826, val_MinusLogProbMetric: 4.1826

Epoch 291: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0020 - MinusLogProbMetric: 4.0020 - val_loss: 4.1826 - val_MinusLogProbMetric: 4.1826 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 292/1000
2023-09-17 05:42:37.707 
Epoch 292/1000 
	 loss: 4.0031, MinusLogProbMetric: 4.0031, val_loss: 4.1849, val_MinusLogProbMetric: 4.1849

Epoch 292: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0031 - MinusLogProbMetric: 4.0031 - val_loss: 4.1849 - val_MinusLogProbMetric: 4.1849 - lr: 2.5000e-04 - 45s/epoch - 229ms/step
Epoch 293/1000
2023-09-17 05:43:22.918 
Epoch 293/1000 
	 loss: 4.0024, MinusLogProbMetric: 4.0024, val_loss: 4.1869, val_MinusLogProbMetric: 4.1869

Epoch 293: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0024 - MinusLogProbMetric: 4.0024 - val_loss: 4.1869 - val_MinusLogProbMetric: 4.1869 - lr: 2.5000e-04 - 45s/epoch - 231ms/step
Epoch 294/1000
2023-09-17 05:44:07.315 
Epoch 294/1000 
	 loss: 4.0030, MinusLogProbMetric: 4.0030, val_loss: 4.1958, val_MinusLogProbMetric: 4.1958

Epoch 294: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0030 - MinusLogProbMetric: 4.0030 - val_loss: 4.1958 - val_MinusLogProbMetric: 4.1958 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 295/1000
2023-09-17 05:44:52.261 
Epoch 295/1000 
	 loss: 4.0037, MinusLogProbMetric: 4.0037, val_loss: 4.1825, val_MinusLogProbMetric: 4.1825

Epoch 295: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0037 - MinusLogProbMetric: 4.0037 - val_loss: 4.1825 - val_MinusLogProbMetric: 4.1825 - lr: 2.5000e-04 - 45s/epoch - 229ms/step
Epoch 296/1000
2023-09-17 05:45:36.993 
Epoch 296/1000 
	 loss: 4.0041, MinusLogProbMetric: 4.0041, val_loss: 4.1815, val_MinusLogProbMetric: 4.1815

Epoch 296: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0041 - MinusLogProbMetric: 4.0041 - val_loss: 4.1815 - val_MinusLogProbMetric: 4.1815 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 297/1000
2023-09-17 05:46:19.120 
Epoch 297/1000 
	 loss: 4.0038, MinusLogProbMetric: 4.0038, val_loss: 4.1930, val_MinusLogProbMetric: 4.1930

Epoch 297: val_loss did not improve from 4.15878
196/196 - 42s - loss: 4.0038 - MinusLogProbMetric: 4.0038 - val_loss: 4.1930 - val_MinusLogProbMetric: 4.1930 - lr: 2.5000e-04 - 42s/epoch - 215ms/step
Epoch 298/1000
2023-09-17 05:46:58.656 
Epoch 298/1000 
	 loss: 4.0029, MinusLogProbMetric: 4.0029, val_loss: 4.1891, val_MinusLogProbMetric: 4.1891

Epoch 298: val_loss did not improve from 4.15878
196/196 - 40s - loss: 4.0029 - MinusLogProbMetric: 4.0029 - val_loss: 4.1891 - val_MinusLogProbMetric: 4.1891 - lr: 2.5000e-04 - 40s/epoch - 202ms/step
Epoch 299/1000
2023-09-17 05:47:35.365 
Epoch 299/1000 
	 loss: 4.0038, MinusLogProbMetric: 4.0038, val_loss: 4.1818, val_MinusLogProbMetric: 4.1818

Epoch 299: val_loss did not improve from 4.15878
196/196 - 37s - loss: 4.0038 - MinusLogProbMetric: 4.0038 - val_loss: 4.1818 - val_MinusLogProbMetric: 4.1818 - lr: 2.5000e-04 - 37s/epoch - 187ms/step
Epoch 300/1000
2023-09-17 05:48:16.666 
Epoch 300/1000 
	 loss: 4.0015, MinusLogProbMetric: 4.0015, val_loss: 4.1803, val_MinusLogProbMetric: 4.1803

Epoch 300: val_loss did not improve from 4.15878
196/196 - 41s - loss: 4.0015 - MinusLogProbMetric: 4.0015 - val_loss: 4.1803 - val_MinusLogProbMetric: 4.1803 - lr: 2.5000e-04 - 41s/epoch - 211ms/step
Epoch 301/1000
2023-09-17 05:49:00.962 
Epoch 301/1000 
	 loss: 4.0020, MinusLogProbMetric: 4.0020, val_loss: 4.1867, val_MinusLogProbMetric: 4.1867

Epoch 301: val_loss did not improve from 4.15878
196/196 - 44s - loss: 4.0020 - MinusLogProbMetric: 4.0020 - val_loss: 4.1867 - val_MinusLogProbMetric: 4.1867 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 302/1000
2023-09-17 05:49:45.613 
Epoch 302/1000 
	 loss: 4.0011, MinusLogProbMetric: 4.0011, val_loss: 4.1897, val_MinusLogProbMetric: 4.1897

Epoch 302: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0011 - MinusLogProbMetric: 4.0011 - val_loss: 4.1897 - val_MinusLogProbMetric: 4.1897 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 303/1000
2023-09-17 05:50:30.415 
Epoch 303/1000 
	 loss: 4.0012, MinusLogProbMetric: 4.0012, val_loss: 4.1826, val_MinusLogProbMetric: 4.1826

Epoch 303: val_loss did not improve from 4.15878
196/196 - 45s - loss: 4.0012 - MinusLogProbMetric: 4.0012 - val_loss: 4.1826 - val_MinusLogProbMetric: 4.1826 - lr: 2.5000e-04 - 45s/epoch - 229ms/step
Epoch 304/1000
2023-09-17 05:51:15.478 
Epoch 304/1000 
	 loss: 4.0016, MinusLogProbMetric: 4.0016, val_loss: 4.1832, val_MinusLogProbMetric: 4.1832

Epoch 304: val_loss did not improve from 4.15878
Restoring model weights from the end of the best epoch: 204.
196/196 - 46s - loss: 4.0016 - MinusLogProbMetric: 4.0016 - val_loss: 4.1832 - val_MinusLogProbMetric: 4.1832 - lr: 2.5000e-04 - 46s/epoch - 232ms/step
Epoch 304: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 15.193752045975998 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 8.75998700899072 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 5.644051891984418 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fb274525fc0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 16.151030962821096 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 7.907604431034997 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 5.941622351994738 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fb25c47f910> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 440.
Model trained in 13368.63 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

Plots done in 18.92 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 95.30 s.
===========
Run 107/720 done in 13478.69 s.
===========

Directory ../../results/CsplineN_new/run_108/ already exists.
Skipping it.
===========
Run 108/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_109/ already exists.
Skipping it.
===========
Run 109/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_110/ already exists.
Skipping it.
===========
Run 110/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_111/ already exists.
Skipping it.
===========
Run 111/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_112/ already exists.
Skipping it.
===========
Run 112/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_113/ already exists.
Skipping it.
===========
Run 113/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_114/ already exists.
Skipping it.
===========
Run 114/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_115/ already exists.
Skipping it.
===========
Run 115/720 already exists. Skipping it.
===========

===========
Generating train data for run 116.
===========
Train data generated in 0.20 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 8)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_116/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 520}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_116/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[10.049758  ,  4.268385  ,  7.926563  , ...,  9.30884   ,
         0.8377404 ,  1.4002337 ],
       [ 0.8883975 ,  8.264331  ,  8.186552  , ...,  7.562158  ,
         4.5833206 ,  7.646627  ],
       [ 9.455839  ,  4.437851  ,  7.931938  , ..., 10.117145  ,
         1.5715699 ,  1.667325  ],
       ...,
       [-0.0213912 ,  7.4854965 ,  8.31225   , ...,  7.0570807 ,
         4.387896  ,  7.8744864 ],
       [ 9.783626  ,  3.9129486 ,  7.941707  , ...,  9.4071455 ,
         0.9804493 ,  1.4779084 ],
       [ 0.09697292,  9.003742  ,  6.7814546 , ...,  7.649544  ,
         4.3774447 ,  7.836157  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_116/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_116
self.data_kwargs: {'seed': 520}
self.x_data: [[ 9.807922    4.0352354   7.8932676  ...  9.471432   -0.28331584
   1.3571403 ]
 [ 0.32675052  8.673955    8.208642   ...  8.794708    4.7731004
   7.736645  ]
 [ 0.21370578  8.460088    8.035857   ...  9.266987    4.615468
   7.978693  ]
 ...
 [ 0.03638138  7.8445787   7.0564733  ...  8.316563    4.394707
   7.6804276 ]
 [ 5.456363    6.464849    5.8161635  ...  6.1865835   4.5304494
   8.093089  ]
 [ 0.28881437  7.741578    7.9390054  ...  7.438477    4.385378
   8.055629  ]]
self.y_data: []
self.ndims: 8
Model defined.
Model: "model_77"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_78 (InputLayer)       [(None, 8)]               0         
                                                                 
 log_prob_layer_7 (LogProbLa  (None,)                  844220    
 yer)                                                            
                                                                 
=================================================================
Total params: 844,220
Trainable params: 844,220
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_7/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_7'")
self.model: <keras.engine.functional.Functional object at 0x7faf5235cd90>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7faeac1c4a90>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7faeac1c4a90>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fafe8bb3580>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7faedc5ee6b0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_116/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7faedc5ef9a0>, <keras.callbacks.ModelCheckpoint object at 0x7faedc5effd0>, <keras.callbacks.EarlyStopping object at 0x7faedc5ef340>, <keras.callbacks.ReduceLROnPlateau object at 0x7faedc5efe80>, <keras.callbacks.TerminateOnNaN object at 0x7faedc5ec9a0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[10.049758  ,  4.268385  ,  7.926563  , ...,  9.30884   ,
         0.8377404 ,  1.4002337 ],
       [ 0.8883975 ,  8.264331  ,  8.186552  , ...,  7.562158  ,
         4.5833206 ,  7.646627  ],
       [ 9.455839  ,  4.437851  ,  7.931938  , ..., 10.117145  ,
         1.5715699 ,  1.667325  ],
       ...,
       [-0.0213912 ,  7.4854965 ,  8.31225   , ...,  7.0570807 ,
         4.387896  ,  7.8744864 ],
       [ 9.783626  ,  3.9129486 ,  7.941707  , ...,  9.4071455 ,
         0.9804493 ,  1.4779084 ],
       [ 0.09697292,  9.003742  ,  6.7814546 , ...,  7.649544  ,
         4.3774447 ,  7.836157  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_116/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 116/720 with hyperparameters:
timestamp = 2023-09-17 05:52:58.054341
ndims = 8
seed_train = 520
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 5
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 844220
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 9.807922    4.0352354   7.8932676   6.2930956   6.419638    9.471432
 -0.28331584  1.3571403 ]
Epoch 1/1000
2023-09-17 05:55:17.910 
Epoch 1/1000 
	 loss: 12.9504, MinusLogProbMetric: 12.9504, val_loss: 6.8605, val_MinusLogProbMetric: 6.8605

Epoch 1: val_loss improved from inf to 6.86047, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_116/weights/best_weights.h5
196/196 - 141s - loss: 12.9504 - MinusLogProbMetric: 12.9504 - val_loss: 6.8605 - val_MinusLogProbMetric: 6.8605 - lr: 0.0010 - 141s/epoch - 717ms/step
Epoch 2/1000
2023-09-17 05:56:02.342 
Epoch 2/1000 
	 loss: 6.4000, MinusLogProbMetric: 6.4000, val_loss: 6.1211, val_MinusLogProbMetric: 6.1211

Epoch 2: val_loss improved from 6.86047 to 6.12108, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_116/weights/best_weights.h5
196/196 - 45s - loss: 6.4000 - MinusLogProbMetric: 6.4000 - val_loss: 6.1211 - val_MinusLogProbMetric: 6.1211 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 3/1000
2023-09-17 05:56:47.565 
Epoch 3/1000 
	 loss: 5.9322, MinusLogProbMetric: 5.9322, val_loss: 5.6733, val_MinusLogProbMetric: 5.6733

Epoch 3: val_loss improved from 6.12108 to 5.67329, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_116/weights/best_weights.h5
196/196 - 44s - loss: 5.9322 - MinusLogProbMetric: 5.9322 - val_loss: 5.6733 - val_MinusLogProbMetric: 5.6733 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 4/1000
2023-09-17 05:57:31.694 
Epoch 4/1000 
	 loss: 5.6069, MinusLogProbMetric: 5.6069, val_loss: 5.7340, val_MinusLogProbMetric: 5.7340

Epoch 4: val_loss did not improve from 5.67329
196/196 - 43s - loss: 5.6069 - MinusLogProbMetric: 5.6069 - val_loss: 5.7340 - val_MinusLogProbMetric: 5.7340 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 5/1000
2023-09-17 05:58:14.834 
Epoch 5/1000 
	 loss: 5.3694, MinusLogProbMetric: 5.3694, val_loss: 4.7605, val_MinusLogProbMetric: 4.7605

Epoch 5: val_loss improved from 5.67329 to 4.76051, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_116/weights/best_weights.h5
196/196 - 44s - loss: 5.3694 - MinusLogProbMetric: 5.3694 - val_loss: 4.7605 - val_MinusLogProbMetric: 4.7605 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 6/1000
2023-09-17 05:58:58.684 
Epoch 6/1000 
	 loss: 5.4509, MinusLogProbMetric: 5.4509, val_loss: 5.0371, val_MinusLogProbMetric: 5.0371

Epoch 6: val_loss did not improve from 4.76051
196/196 - 43s - loss: 5.4509 - MinusLogProbMetric: 5.4509 - val_loss: 5.0371 - val_MinusLogProbMetric: 5.0371 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 7/1000
2023-09-17 05:59:42.098 
Epoch 7/1000 
	 loss: 5.0249, MinusLogProbMetric: 5.0249, val_loss: 5.1558, val_MinusLogProbMetric: 5.1558

Epoch 7: val_loss did not improve from 4.76051
196/196 - 43s - loss: 5.0249 - MinusLogProbMetric: 5.0249 - val_loss: 5.1558 - val_MinusLogProbMetric: 5.1558 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 8/1000
2023-09-17 06:00:25.475 
Epoch 8/1000 
	 loss: 5.1025, MinusLogProbMetric: 5.1025, val_loss: 5.1709, val_MinusLogProbMetric: 5.1709

Epoch 8: val_loss did not improve from 4.76051
196/196 - 43s - loss: 5.1025 - MinusLogProbMetric: 5.1025 - val_loss: 5.1709 - val_MinusLogProbMetric: 5.1709 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 9/1000
2023-09-17 06:01:09.039 
Epoch 9/1000 
	 loss: 4.8751, MinusLogProbMetric: 4.8751, val_loss: 4.5856, val_MinusLogProbMetric: 4.5856

Epoch 9: val_loss improved from 4.76051 to 4.58556, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_116/weights/best_weights.h5
196/196 - 44s - loss: 4.8751 - MinusLogProbMetric: 4.8751 - val_loss: 4.5856 - val_MinusLogProbMetric: 4.5856 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 10/1000
2023-09-17 06:01:53.145 
Epoch 10/1000 
	 loss: 4.8720, MinusLogProbMetric: 4.8720, val_loss: 4.8136, val_MinusLogProbMetric: 4.8136

Epoch 10: val_loss did not improve from 4.58556
196/196 - 43s - loss: 4.8720 - MinusLogProbMetric: 4.8720 - val_loss: 4.8136 - val_MinusLogProbMetric: 4.8136 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 11/1000
2023-09-17 06:02:36.495 
Epoch 11/1000 
	 loss: 4.8106, MinusLogProbMetric: 4.8106, val_loss: 4.5922, val_MinusLogProbMetric: 4.5922

Epoch 11: val_loss did not improve from 4.58556
196/196 - 43s - loss: 4.8106 - MinusLogProbMetric: 4.8106 - val_loss: 4.5922 - val_MinusLogProbMetric: 4.5922 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 12/1000
2023-09-17 06:03:20.168 
Epoch 12/1000 
	 loss: 4.7951, MinusLogProbMetric: 4.7951, val_loss: 4.5476, val_MinusLogProbMetric: 4.5476

Epoch 12: val_loss improved from 4.58556 to 4.54761, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_116/weights/best_weights.h5
196/196 - 44s - loss: 4.7951 - MinusLogProbMetric: 4.7951 - val_loss: 4.5476 - val_MinusLogProbMetric: 4.5476 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 13/1000
2023-09-17 06:04:04.074 
Epoch 13/1000 
	 loss: 4.7953, MinusLogProbMetric: 4.7953, val_loss: 4.6243, val_MinusLogProbMetric: 4.6243

Epoch 13: val_loss did not improve from 4.54761
196/196 - 43s - loss: 4.7953 - MinusLogProbMetric: 4.7953 - val_loss: 4.6243 - val_MinusLogProbMetric: 4.6243 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 14/1000
2023-09-17 06:04:47.493 
Epoch 14/1000 
	 loss: 4.7237, MinusLogProbMetric: 4.7237, val_loss: 5.3960, val_MinusLogProbMetric: 5.3960

Epoch 14: val_loss did not improve from 4.54761
196/196 - 43s - loss: 4.7237 - MinusLogProbMetric: 4.7237 - val_loss: 5.3960 - val_MinusLogProbMetric: 5.3960 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 15/1000
2023-09-17 06:05:30.666 
Epoch 15/1000 
	 loss: 4.6766, MinusLogProbMetric: 4.6766, val_loss: 4.5646, val_MinusLogProbMetric: 4.5646

Epoch 15: val_loss did not improve from 4.54761
196/196 - 43s - loss: 4.6766 - MinusLogProbMetric: 4.6766 - val_loss: 4.5646 - val_MinusLogProbMetric: 4.5646 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 16/1000
2023-09-17 06:06:14.086 
Epoch 16/1000 
	 loss: 4.7328, MinusLogProbMetric: 4.7328, val_loss: 4.5113, val_MinusLogProbMetric: 4.5113

Epoch 16: val_loss improved from 4.54761 to 4.51126, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_116/weights/best_weights.h5
196/196 - 44s - loss: 4.7328 - MinusLogProbMetric: 4.7328 - val_loss: 4.5113 - val_MinusLogProbMetric: 4.5113 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 17/1000
2023-09-17 06:06:58.909 
Epoch 17/1000 
	 loss: 4.6437, MinusLogProbMetric: 4.6437, val_loss: 4.4898, val_MinusLogProbMetric: 4.4898

Epoch 17: val_loss improved from 4.51126 to 4.48980, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_116/weights/best_weights.h5
196/196 - 45s - loss: 4.6437 - MinusLogProbMetric: 4.6437 - val_loss: 4.4898 - val_MinusLogProbMetric: 4.4898 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 18/1000
2023-09-17 06:07:43.099 
Epoch 18/1000 
	 loss: 4.6334, MinusLogProbMetric: 4.6334, val_loss: 4.5446, val_MinusLogProbMetric: 4.5446

Epoch 18: val_loss did not improve from 4.48980
196/196 - 43s - loss: 4.6334 - MinusLogProbMetric: 4.6334 - val_loss: 4.5446 - val_MinusLogProbMetric: 4.5446 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 19/1000
2023-09-17 06:08:26.438 
Epoch 19/1000 
	 loss: 4.5872, MinusLogProbMetric: 4.5872, val_loss: 4.4754, val_MinusLogProbMetric: 4.4754

Epoch 19: val_loss improved from 4.48980 to 4.47544, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_116/weights/best_weights.h5
196/196 - 44s - loss: 4.5872 - MinusLogProbMetric: 4.5872 - val_loss: 4.4754 - val_MinusLogProbMetric: 4.4754 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 20/1000
2023-09-17 06:09:10.948 
Epoch 20/1000 
	 loss: 4.5524, MinusLogProbMetric: 4.5524, val_loss: 4.5867, val_MinusLogProbMetric: 4.5867

Epoch 20: val_loss did not improve from 4.47544
196/196 - 44s - loss: 4.5524 - MinusLogProbMetric: 4.5524 - val_loss: 4.5867 - val_MinusLogProbMetric: 4.5867 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 21/1000
2023-09-17 06:09:54.387 
Epoch 21/1000 
	 loss: 4.4959, MinusLogProbMetric: 4.4959, val_loss: 4.3212, val_MinusLogProbMetric: 4.3212

Epoch 21: val_loss improved from 4.47544 to 4.32115, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_116/weights/best_weights.h5
196/196 - 44s - loss: 4.4959 - MinusLogProbMetric: 4.4959 - val_loss: 4.3212 - val_MinusLogProbMetric: 4.3212 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 22/1000
2023-09-17 06:10:38.529 
Epoch 22/1000 
	 loss: 4.5348, MinusLogProbMetric: 4.5348, val_loss: 4.3343, val_MinusLogProbMetric: 4.3343

Epoch 22: val_loss did not improve from 4.32115
196/196 - 43s - loss: 4.5348 - MinusLogProbMetric: 4.5348 - val_loss: 4.3343 - val_MinusLogProbMetric: 4.3343 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 23/1000
2023-09-17 06:11:22.175 
Epoch 23/1000 
	 loss: 4.4895, MinusLogProbMetric: 4.4895, val_loss: 4.6428, val_MinusLogProbMetric: 4.6428

Epoch 23: val_loss did not improve from 4.32115
196/196 - 44s - loss: 4.4895 - MinusLogProbMetric: 4.4895 - val_loss: 4.6428 - val_MinusLogProbMetric: 4.6428 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 24/1000
2023-09-17 06:12:05.305 
Epoch 24/1000 
	 loss: 4.4636, MinusLogProbMetric: 4.4636, val_loss: 5.1446, val_MinusLogProbMetric: 5.1446

Epoch 24: val_loss did not improve from 4.32115
196/196 - 43s - loss: 4.4636 - MinusLogProbMetric: 4.4636 - val_loss: 5.1446 - val_MinusLogProbMetric: 5.1446 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 25/1000
2023-09-17 06:12:48.551 
Epoch 25/1000 
	 loss: 4.5093, MinusLogProbMetric: 4.5093, val_loss: 4.4248, val_MinusLogProbMetric: 4.4248

Epoch 25: val_loss did not improve from 4.32115
196/196 - 43s - loss: 4.5093 - MinusLogProbMetric: 4.5093 - val_loss: 4.4248 - val_MinusLogProbMetric: 4.4248 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 26/1000
2023-09-17 06:13:32.294 
Epoch 26/1000 
	 loss: 4.4360, MinusLogProbMetric: 4.4360, val_loss: 4.3874, val_MinusLogProbMetric: 4.3874

Epoch 26: val_loss did not improve from 4.32115
196/196 - 44s - loss: 4.4360 - MinusLogProbMetric: 4.4360 - val_loss: 4.3874 - val_MinusLogProbMetric: 4.3874 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 27/1000
2023-09-17 06:14:15.467 
Epoch 27/1000 
	 loss: 4.4284, MinusLogProbMetric: 4.4284, val_loss: 4.9569, val_MinusLogProbMetric: 4.9569

Epoch 27: val_loss did not improve from 4.32115
196/196 - 43s - loss: 4.4284 - MinusLogProbMetric: 4.4284 - val_loss: 4.9569 - val_MinusLogProbMetric: 4.9569 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 28/1000
2023-09-17 06:14:59.359 
Epoch 28/1000 
	 loss: 4.4864, MinusLogProbMetric: 4.4864, val_loss: 4.6173, val_MinusLogProbMetric: 4.6173

Epoch 28: val_loss did not improve from 4.32115
196/196 - 44s - loss: 4.4864 - MinusLogProbMetric: 4.4864 - val_loss: 4.6173 - val_MinusLogProbMetric: 4.6173 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 29/1000
2023-09-17 06:15:42.693 
Epoch 29/1000 
	 loss: 4.4557, MinusLogProbMetric: 4.4557, val_loss: 4.4707, val_MinusLogProbMetric: 4.4707

Epoch 29: val_loss did not improve from 4.32115
196/196 - 43s - loss: 4.4557 - MinusLogProbMetric: 4.4557 - val_loss: 4.4707 - val_MinusLogProbMetric: 4.4707 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 30/1000
2023-09-17 06:16:25.858 
Epoch 30/1000 
	 loss: 4.4132, MinusLogProbMetric: 4.4132, val_loss: 4.2945, val_MinusLogProbMetric: 4.2945

Epoch 30: val_loss improved from 4.32115 to 4.29446, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_116/weights/best_weights.h5
196/196 - 44s - loss: 4.4132 - MinusLogProbMetric: 4.4132 - val_loss: 4.2945 - val_MinusLogProbMetric: 4.2945 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 31/1000
2023-09-17 06:17:09.925 
Epoch 31/1000 
	 loss: 4.4170, MinusLogProbMetric: 4.4170, val_loss: 4.3673, val_MinusLogProbMetric: 4.3673

Epoch 31: val_loss did not improve from 4.29446
196/196 - 43s - loss: 4.4170 - MinusLogProbMetric: 4.4170 - val_loss: 4.3673 - val_MinusLogProbMetric: 4.3673 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 32/1000
2023-09-17 06:17:53.521 
Epoch 32/1000 
	 loss: 4.4057, MinusLogProbMetric: 4.4057, val_loss: 4.8244, val_MinusLogProbMetric: 4.8244

Epoch 32: val_loss did not improve from 4.29446
196/196 - 44s - loss: 4.4057 - MinusLogProbMetric: 4.4057 - val_loss: 4.8244 - val_MinusLogProbMetric: 4.8244 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 33/1000
2023-09-17 06:18:37.131 
Epoch 33/1000 
	 loss: 4.3541, MinusLogProbMetric: 4.3541, val_loss: 4.3012, val_MinusLogProbMetric: 4.3012

Epoch 33: val_loss did not improve from 4.29446
196/196 - 44s - loss: 4.3541 - MinusLogProbMetric: 4.3541 - val_loss: 4.3012 - val_MinusLogProbMetric: 4.3012 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 34/1000
2023-09-17 06:19:20.858 
Epoch 34/1000 
	 loss: 4.3489, MinusLogProbMetric: 4.3489, val_loss: 4.2188, val_MinusLogProbMetric: 4.2188

Epoch 34: val_loss improved from 4.29446 to 4.21878, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_116/weights/best_weights.h5
196/196 - 45s - loss: 4.3489 - MinusLogProbMetric: 4.3489 - val_loss: 4.2188 - val_MinusLogProbMetric: 4.2188 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 35/1000
2023-09-17 06:20:05.430 
Epoch 35/1000 
	 loss: 4.3545, MinusLogProbMetric: 4.3545, val_loss: 4.4498, val_MinusLogProbMetric: 4.4498

Epoch 35: val_loss did not improve from 4.21878
196/196 - 44s - loss: 4.3545 - MinusLogProbMetric: 4.3545 - val_loss: 4.4498 - val_MinusLogProbMetric: 4.4498 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 36/1000
2023-09-17 06:20:48.970 
Epoch 36/1000 
	 loss: 4.4278, MinusLogProbMetric: 4.4278, val_loss: 4.4268, val_MinusLogProbMetric: 4.4268

Epoch 36: val_loss did not improve from 4.21878
196/196 - 44s - loss: 4.4278 - MinusLogProbMetric: 4.4278 - val_loss: 4.4268 - val_MinusLogProbMetric: 4.4268 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 37/1000
2023-09-17 06:21:32.536 
Epoch 37/1000 
	 loss: 4.3336, MinusLogProbMetric: 4.3336, val_loss: 4.4268, val_MinusLogProbMetric: 4.4268

Epoch 37: val_loss did not improve from 4.21878
196/196 - 44s - loss: 4.3336 - MinusLogProbMetric: 4.3336 - val_loss: 4.4268 - val_MinusLogProbMetric: 4.4268 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 38/1000
2023-09-17 06:22:15.904 
Epoch 38/1000 
	 loss: 4.3503, MinusLogProbMetric: 4.3503, val_loss: 4.6601, val_MinusLogProbMetric: 4.6601

Epoch 38: val_loss did not improve from 4.21878
196/196 - 43s - loss: 4.3503 - MinusLogProbMetric: 4.3503 - val_loss: 4.6601 - val_MinusLogProbMetric: 4.6601 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 39/1000
2023-09-17 06:22:59.387 
Epoch 39/1000 
	 loss: 4.3322, MinusLogProbMetric: 4.3322, val_loss: 4.3061, val_MinusLogProbMetric: 4.3061

Epoch 39: val_loss did not improve from 4.21878
196/196 - 43s - loss: 4.3322 - MinusLogProbMetric: 4.3322 - val_loss: 4.3061 - val_MinusLogProbMetric: 4.3061 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 40/1000
2023-09-17 06:23:42.859 
Epoch 40/1000 
	 loss: 4.3165, MinusLogProbMetric: 4.3165, val_loss: 4.2894, val_MinusLogProbMetric: 4.2894

Epoch 40: val_loss did not improve from 4.21878
196/196 - 43s - loss: 4.3165 - MinusLogProbMetric: 4.3165 - val_loss: 4.2894 - val_MinusLogProbMetric: 4.2894 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 41/1000
2023-09-17 06:24:26.540 
Epoch 41/1000 
	 loss: 4.3224, MinusLogProbMetric: 4.3224, val_loss: 4.4658, val_MinusLogProbMetric: 4.4658

Epoch 41: val_loss did not improve from 4.21878
196/196 - 44s - loss: 4.3224 - MinusLogProbMetric: 4.3224 - val_loss: 4.4658 - val_MinusLogProbMetric: 4.4658 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 42/1000
2023-09-17 06:25:10.083 
Epoch 42/1000 
	 loss: 4.3266, MinusLogProbMetric: 4.3266, val_loss: 4.4531, val_MinusLogProbMetric: 4.4531

Epoch 42: val_loss did not improve from 4.21878
196/196 - 44s - loss: 4.3266 - MinusLogProbMetric: 4.3266 - val_loss: 4.4531 - val_MinusLogProbMetric: 4.4531 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 43/1000
2023-09-17 06:25:53.863 
Epoch 43/1000 
	 loss: 4.2923, MinusLogProbMetric: 4.2923, val_loss: 4.5437, val_MinusLogProbMetric: 4.5437

Epoch 43: val_loss did not improve from 4.21878
196/196 - 44s - loss: 4.2923 - MinusLogProbMetric: 4.2923 - val_loss: 4.5437 - val_MinusLogProbMetric: 4.5437 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 44/1000
2023-09-17 06:26:37.293 
Epoch 44/1000 
	 loss: 4.3153, MinusLogProbMetric: 4.3153, val_loss: 4.2349, val_MinusLogProbMetric: 4.2349

Epoch 44: val_loss did not improve from 4.21878
196/196 - 43s - loss: 4.3153 - MinusLogProbMetric: 4.3153 - val_loss: 4.2349 - val_MinusLogProbMetric: 4.2349 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 45/1000
2023-09-17 06:27:21.073 
Epoch 45/1000 
	 loss: 4.2938, MinusLogProbMetric: 4.2938, val_loss: 4.2881, val_MinusLogProbMetric: 4.2881

Epoch 45: val_loss did not improve from 4.21878
196/196 - 44s - loss: 4.2938 - MinusLogProbMetric: 4.2938 - val_loss: 4.2881 - val_MinusLogProbMetric: 4.2881 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 46/1000
2023-09-17 06:28:05.079 
Epoch 46/1000 
	 loss: 4.2930, MinusLogProbMetric: 4.2930, val_loss: 4.2572, val_MinusLogProbMetric: 4.2572

Epoch 46: val_loss did not improve from 4.21878
196/196 - 44s - loss: 4.2930 - MinusLogProbMetric: 4.2930 - val_loss: 4.2572 - val_MinusLogProbMetric: 4.2572 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 47/1000
2023-09-17 06:28:48.542 
Epoch 47/1000 
	 loss: 4.2704, MinusLogProbMetric: 4.2704, val_loss: 4.2490, val_MinusLogProbMetric: 4.2490

Epoch 47: val_loss did not improve from 4.21878
196/196 - 43s - loss: 4.2704 - MinusLogProbMetric: 4.2704 - val_loss: 4.2490 - val_MinusLogProbMetric: 4.2490 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 48/1000
2023-09-17 06:29:32.082 
Epoch 48/1000 
	 loss: 4.3305, MinusLogProbMetric: 4.3305, val_loss: 4.3334, val_MinusLogProbMetric: 4.3334

Epoch 48: val_loss did not improve from 4.21878
196/196 - 44s - loss: 4.3305 - MinusLogProbMetric: 4.3305 - val_loss: 4.3334 - val_MinusLogProbMetric: 4.3334 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 49/1000
2023-09-17 06:30:16.031 
Epoch 49/1000 
	 loss: 4.2591, MinusLogProbMetric: 4.2591, val_loss: 4.1995, val_MinusLogProbMetric: 4.1995

Epoch 49: val_loss improved from 4.21878 to 4.19949, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_116/weights/best_weights.h5
196/196 - 45s - loss: 4.2591 - MinusLogProbMetric: 4.2591 - val_loss: 4.1995 - val_MinusLogProbMetric: 4.1995 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 50/1000
2023-09-17 06:31:00.225 
Epoch 50/1000 
	 loss: 4.2602, MinusLogProbMetric: 4.2602, val_loss: 4.3124, val_MinusLogProbMetric: 4.3124

Epoch 50: val_loss did not improve from 4.19949
196/196 - 43s - loss: 4.2602 - MinusLogProbMetric: 4.2602 - val_loss: 4.3124 - val_MinusLogProbMetric: 4.3124 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 51/1000
2023-09-17 06:31:43.745 
Epoch 51/1000 
	 loss: 4.2914, MinusLogProbMetric: 4.2914, val_loss: 4.3651, val_MinusLogProbMetric: 4.3651

Epoch 51: val_loss did not improve from 4.19949
196/196 - 44s - loss: 4.2914 - MinusLogProbMetric: 4.2914 - val_loss: 4.3651 - val_MinusLogProbMetric: 4.3651 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 52/1000
2023-09-17 06:32:27.581 
Epoch 52/1000 
	 loss: 4.2620, MinusLogProbMetric: 4.2620, val_loss: 4.2253, val_MinusLogProbMetric: 4.2253

Epoch 52: val_loss did not improve from 4.19949
196/196 - 44s - loss: 4.2620 - MinusLogProbMetric: 4.2620 - val_loss: 4.2253 - val_MinusLogProbMetric: 4.2253 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 53/1000
2023-09-17 06:33:11.234 
Epoch 53/1000 
	 loss: 4.2889, MinusLogProbMetric: 4.2889, val_loss: 4.3060, val_MinusLogProbMetric: 4.3060

Epoch 53: val_loss did not improve from 4.19949
196/196 - 44s - loss: 4.2889 - MinusLogProbMetric: 4.2889 - val_loss: 4.3060 - val_MinusLogProbMetric: 4.3060 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 54/1000
2023-09-17 06:33:55.226 
Epoch 54/1000 
	 loss: 4.2518, MinusLogProbMetric: 4.2518, val_loss: 4.3771, val_MinusLogProbMetric: 4.3771

Epoch 54: val_loss did not improve from 4.19949
196/196 - 44s - loss: 4.2518 - MinusLogProbMetric: 4.2518 - val_loss: 4.3771 - val_MinusLogProbMetric: 4.3771 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 55/1000
2023-09-17 06:34:39.104 
Epoch 55/1000 
	 loss: 4.2649, MinusLogProbMetric: 4.2649, val_loss: 4.4729, val_MinusLogProbMetric: 4.4729

Epoch 55: val_loss did not improve from 4.19949
196/196 - 44s - loss: 4.2649 - MinusLogProbMetric: 4.2649 - val_loss: 4.4729 - val_MinusLogProbMetric: 4.4729 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 56/1000
2023-09-17 06:35:22.598 
Epoch 56/1000 
	 loss: 4.2504, MinusLogProbMetric: 4.2504, val_loss: 4.2206, val_MinusLogProbMetric: 4.2206

Epoch 56: val_loss did not improve from 4.19949
196/196 - 43s - loss: 4.2504 - MinusLogProbMetric: 4.2504 - val_loss: 4.2206 - val_MinusLogProbMetric: 4.2206 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 57/1000
2023-09-17 06:36:06.250 
Epoch 57/1000 
	 loss: 4.2253, MinusLogProbMetric: 4.2253, val_loss: 4.2400, val_MinusLogProbMetric: 4.2400

Epoch 57: val_loss did not improve from 4.19949
196/196 - 44s - loss: 4.2253 - MinusLogProbMetric: 4.2253 - val_loss: 4.2400 - val_MinusLogProbMetric: 4.2400 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 58/1000
2023-09-17 06:36:49.986 
Epoch 58/1000 
	 loss: 4.2503, MinusLogProbMetric: 4.2503, val_loss: 4.2263, val_MinusLogProbMetric: 4.2263

Epoch 58: val_loss did not improve from 4.19949
196/196 - 44s - loss: 4.2503 - MinusLogProbMetric: 4.2503 - val_loss: 4.2263 - val_MinusLogProbMetric: 4.2263 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 59/1000
2023-09-17 06:37:33.678 
Epoch 59/1000 
	 loss: 4.2188, MinusLogProbMetric: 4.2188, val_loss: 4.2405, val_MinusLogProbMetric: 4.2405

Epoch 59: val_loss did not improve from 4.19949
196/196 - 44s - loss: 4.2188 - MinusLogProbMetric: 4.2188 - val_loss: 4.2405 - val_MinusLogProbMetric: 4.2405 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 60/1000
2023-09-17 06:38:17.150 
Epoch 60/1000 
	 loss: 4.2290, MinusLogProbMetric: 4.2290, val_loss: 4.2991, val_MinusLogProbMetric: 4.2991

Epoch 60: val_loss did not improve from 4.19949
196/196 - 43s - loss: 4.2290 - MinusLogProbMetric: 4.2290 - val_loss: 4.2991 - val_MinusLogProbMetric: 4.2991 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 61/1000
2023-09-17 06:39:00.474 
Epoch 61/1000 
	 loss: 4.2351, MinusLogProbMetric: 4.2351, val_loss: 4.3026, val_MinusLogProbMetric: 4.3026

Epoch 61: val_loss did not improve from 4.19949
196/196 - 43s - loss: 4.2351 - MinusLogProbMetric: 4.2351 - val_loss: 4.3026 - val_MinusLogProbMetric: 4.3026 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 62/1000
2023-09-17 06:39:44.268 
Epoch 62/1000 
	 loss: 4.2307, MinusLogProbMetric: 4.2307, val_loss: 4.2518, val_MinusLogProbMetric: 4.2518

Epoch 62: val_loss did not improve from 4.19949
196/196 - 44s - loss: 4.2307 - MinusLogProbMetric: 4.2307 - val_loss: 4.2518 - val_MinusLogProbMetric: 4.2518 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 63/1000
2023-09-17 06:40:27.811 
Epoch 63/1000 
	 loss: 4.2469, MinusLogProbMetric: 4.2469, val_loss: 4.2159, val_MinusLogProbMetric: 4.2159

Epoch 63: val_loss did not improve from 4.19949
196/196 - 44s - loss: 4.2469 - MinusLogProbMetric: 4.2469 - val_loss: 4.2159 - val_MinusLogProbMetric: 4.2159 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 64/1000
2023-09-17 06:41:11.479 
Epoch 64/1000 
	 loss: 4.1924, MinusLogProbMetric: 4.1924, val_loss: 4.3684, val_MinusLogProbMetric: 4.3684

Epoch 64: val_loss did not improve from 4.19949
196/196 - 44s - loss: 4.1924 - MinusLogProbMetric: 4.1924 - val_loss: 4.3684 - val_MinusLogProbMetric: 4.3684 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 65/1000
2023-09-17 06:41:55.208 
Epoch 65/1000 
	 loss: 4.2438, MinusLogProbMetric: 4.2438, val_loss: 4.2876, val_MinusLogProbMetric: 4.2876

Epoch 65: val_loss did not improve from 4.19949
196/196 - 44s - loss: 4.2438 - MinusLogProbMetric: 4.2438 - val_loss: 4.2876 - val_MinusLogProbMetric: 4.2876 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 66/1000
2023-09-17 06:42:39.052 
Epoch 66/1000 
	 loss: 4.2432, MinusLogProbMetric: 4.2432, val_loss: 4.3337, val_MinusLogProbMetric: 4.3337

Epoch 66: val_loss did not improve from 4.19949
196/196 - 44s - loss: 4.2432 - MinusLogProbMetric: 4.2432 - val_loss: 4.3337 - val_MinusLogProbMetric: 4.3337 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 67/1000
2023-09-17 06:43:22.559 
Epoch 67/1000 
	 loss: 4.2184, MinusLogProbMetric: 4.2184, val_loss: 4.2256, val_MinusLogProbMetric: 4.2256

Epoch 67: val_loss did not improve from 4.19949
196/196 - 44s - loss: 4.2184 - MinusLogProbMetric: 4.2184 - val_loss: 4.2256 - val_MinusLogProbMetric: 4.2256 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 68/1000
2023-09-17 06:44:06.247 
Epoch 68/1000 
	 loss: 4.1875, MinusLogProbMetric: 4.1875, val_loss: 4.1756, val_MinusLogProbMetric: 4.1756

Epoch 68: val_loss improved from 4.19949 to 4.17561, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_116/weights/best_weights.h5
196/196 - 44s - loss: 4.1875 - MinusLogProbMetric: 4.1875 - val_loss: 4.1756 - val_MinusLogProbMetric: 4.1756 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 69/1000
2023-09-17 06:44:50.378 
Epoch 69/1000 
	 loss: 4.2061, MinusLogProbMetric: 4.2061, val_loss: 4.1916, val_MinusLogProbMetric: 4.1916

Epoch 69: val_loss did not improve from 4.17561
196/196 - 43s - loss: 4.2061 - MinusLogProbMetric: 4.2061 - val_loss: 4.1916 - val_MinusLogProbMetric: 4.1916 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 70/1000
2023-09-17 06:45:33.930 
Epoch 70/1000 
	 loss: 4.2365, MinusLogProbMetric: 4.2365, val_loss: 4.1831, val_MinusLogProbMetric: 4.1831

Epoch 70: val_loss did not improve from 4.17561
196/196 - 44s - loss: 4.2365 - MinusLogProbMetric: 4.2365 - val_loss: 4.1831 - val_MinusLogProbMetric: 4.1831 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 71/1000
2023-09-17 06:46:17.365 
Epoch 71/1000 
	 loss: 4.2176, MinusLogProbMetric: 4.2176, val_loss: 4.2864, val_MinusLogProbMetric: 4.2864

Epoch 71: val_loss did not improve from 4.17561
196/196 - 43s - loss: 4.2176 - MinusLogProbMetric: 4.2176 - val_loss: 4.2864 - val_MinusLogProbMetric: 4.2864 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 72/1000
2023-09-17 06:47:01.057 
Epoch 72/1000 
	 loss: 4.1958, MinusLogProbMetric: 4.1958, val_loss: 4.2616, val_MinusLogProbMetric: 4.2616

Epoch 72: val_loss did not improve from 4.17561
196/196 - 44s - loss: 4.1958 - MinusLogProbMetric: 4.1958 - val_loss: 4.2616 - val_MinusLogProbMetric: 4.2616 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 73/1000
2023-09-17 06:47:44.137 
Epoch 73/1000 
	 loss: 4.2041, MinusLogProbMetric: 4.2041, val_loss: 4.2133, val_MinusLogProbMetric: 4.2133

Epoch 73: val_loss did not improve from 4.17561
196/196 - 43s - loss: 4.2041 - MinusLogProbMetric: 4.2041 - val_loss: 4.2133 - val_MinusLogProbMetric: 4.2133 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 74/1000
2023-09-17 06:48:27.511 
Epoch 74/1000 
	 loss: 4.1993, MinusLogProbMetric: 4.1993, val_loss: 4.2265, val_MinusLogProbMetric: 4.2265

Epoch 74: val_loss did not improve from 4.17561
196/196 - 43s - loss: 4.1993 - MinusLogProbMetric: 4.1993 - val_loss: 4.2265 - val_MinusLogProbMetric: 4.2265 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 75/1000
2023-09-17 06:49:11.038 
Epoch 75/1000 
	 loss: 4.1926, MinusLogProbMetric: 4.1926, val_loss: 4.3038, val_MinusLogProbMetric: 4.3038

Epoch 75: val_loss did not improve from 4.17561
196/196 - 44s - loss: 4.1926 - MinusLogProbMetric: 4.1926 - val_loss: 4.3038 - val_MinusLogProbMetric: 4.3038 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 76/1000
2023-09-17 06:49:53.830 
Epoch 76/1000 
	 loss: 4.1859, MinusLogProbMetric: 4.1859, val_loss: 4.3219, val_MinusLogProbMetric: 4.3219

Epoch 76: val_loss did not improve from 4.17561
196/196 - 43s - loss: 4.1859 - MinusLogProbMetric: 4.1859 - val_loss: 4.3219 - val_MinusLogProbMetric: 4.3219 - lr: 0.0010 - 43s/epoch - 218ms/step
Epoch 77/1000
2023-09-17 06:50:36.736 
Epoch 77/1000 
	 loss: 4.1897, MinusLogProbMetric: 4.1897, val_loss: 4.2078, val_MinusLogProbMetric: 4.2078

Epoch 77: val_loss did not improve from 4.17561
196/196 - 43s - loss: 4.1897 - MinusLogProbMetric: 4.1897 - val_loss: 4.2078 - val_MinusLogProbMetric: 4.2078 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 78/1000
2023-09-17 06:51:19.914 
Epoch 78/1000 
	 loss: 4.1940, MinusLogProbMetric: 4.1940, val_loss: 4.2421, val_MinusLogProbMetric: 4.2421

Epoch 78: val_loss did not improve from 4.17561
196/196 - 43s - loss: 4.1940 - MinusLogProbMetric: 4.1940 - val_loss: 4.2421 - val_MinusLogProbMetric: 4.2421 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 79/1000
2023-09-17 06:52:03.466 
Epoch 79/1000 
	 loss: 4.1883, MinusLogProbMetric: 4.1883, val_loss: 4.2281, val_MinusLogProbMetric: 4.2281

Epoch 79: val_loss did not improve from 4.17561
196/196 - 44s - loss: 4.1883 - MinusLogProbMetric: 4.1883 - val_loss: 4.2281 - val_MinusLogProbMetric: 4.2281 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 80/1000
2023-09-17 06:52:46.940 
Epoch 80/1000 
	 loss: 4.2090, MinusLogProbMetric: 4.2090, val_loss: 4.2068, val_MinusLogProbMetric: 4.2068

Epoch 80: val_loss did not improve from 4.17561
196/196 - 43s - loss: 4.2090 - MinusLogProbMetric: 4.2090 - val_loss: 4.2068 - val_MinusLogProbMetric: 4.2068 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 81/1000
2023-09-17 06:53:30.510 
Epoch 81/1000 
	 loss: 4.1953, MinusLogProbMetric: 4.1953, val_loss: 4.3154, val_MinusLogProbMetric: 4.3154

Epoch 81: val_loss did not improve from 4.17561
196/196 - 44s - loss: 4.1953 - MinusLogProbMetric: 4.1953 - val_loss: 4.3154 - val_MinusLogProbMetric: 4.3154 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 82/1000
2023-09-17 06:54:13.872 
Epoch 82/1000 
	 loss: 4.2063, MinusLogProbMetric: 4.2063, val_loss: 4.6479, val_MinusLogProbMetric: 4.6479

Epoch 82: val_loss did not improve from 4.17561
196/196 - 43s - loss: 4.2063 - MinusLogProbMetric: 4.2063 - val_loss: 4.6479 - val_MinusLogProbMetric: 4.6479 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 83/1000
2023-09-17 06:54:57.499 
Epoch 83/1000 
	 loss: 4.2025, MinusLogProbMetric: 4.2025, val_loss: 4.2389, val_MinusLogProbMetric: 4.2389

Epoch 83: val_loss did not improve from 4.17561
196/196 - 44s - loss: 4.2025 - MinusLogProbMetric: 4.2025 - val_loss: 4.2389 - val_MinusLogProbMetric: 4.2389 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 84/1000
2023-09-17 06:55:40.905 
Epoch 84/1000 
	 loss: 4.1615, MinusLogProbMetric: 4.1615, val_loss: 4.2115, val_MinusLogProbMetric: 4.2115

Epoch 84: val_loss did not improve from 4.17561
196/196 - 43s - loss: 4.1615 - MinusLogProbMetric: 4.1615 - val_loss: 4.2115 - val_MinusLogProbMetric: 4.2115 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 85/1000
2023-09-17 06:56:24.890 
Epoch 85/1000 
	 loss: 4.1775, MinusLogProbMetric: 4.1775, val_loss: 4.1701, val_MinusLogProbMetric: 4.1701

Epoch 85: val_loss improved from 4.17561 to 4.17006, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_116/weights/best_weights.h5
196/196 - 45s - loss: 4.1775 - MinusLogProbMetric: 4.1775 - val_loss: 4.1701 - val_MinusLogProbMetric: 4.1701 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 86/1000
2023-09-17 06:57:09.687 
Epoch 86/1000 
	 loss: 4.1721, MinusLogProbMetric: 4.1721, val_loss: 4.3434, val_MinusLogProbMetric: 4.3434

Epoch 86: val_loss did not improve from 4.17006
196/196 - 44s - loss: 4.1721 - MinusLogProbMetric: 4.1721 - val_loss: 4.3434 - val_MinusLogProbMetric: 4.3434 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 87/1000
2023-09-17 06:57:53.286 
Epoch 87/1000 
	 loss: 4.1778, MinusLogProbMetric: 4.1778, val_loss: 4.2067, val_MinusLogProbMetric: 4.2067

Epoch 87: val_loss did not improve from 4.17006
196/196 - 44s - loss: 4.1778 - MinusLogProbMetric: 4.1778 - val_loss: 4.2067 - val_MinusLogProbMetric: 4.2067 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 88/1000
2023-09-17 06:58:37.083 
Epoch 88/1000 
	 loss: 4.1813, MinusLogProbMetric: 4.1813, val_loss: 4.3080, val_MinusLogProbMetric: 4.3080

Epoch 88: val_loss did not improve from 4.17006
196/196 - 44s - loss: 4.1813 - MinusLogProbMetric: 4.1813 - val_loss: 4.3080 - val_MinusLogProbMetric: 4.3080 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 89/1000
2023-09-17 06:59:20.433 
Epoch 89/1000 
	 loss: 4.1791, MinusLogProbMetric: 4.1791, val_loss: 4.4604, val_MinusLogProbMetric: 4.4604

Epoch 89: val_loss did not improve from 4.17006
196/196 - 43s - loss: 4.1791 - MinusLogProbMetric: 4.1791 - val_loss: 4.4604 - val_MinusLogProbMetric: 4.4604 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 90/1000
2023-09-17 07:00:03.700 
Epoch 90/1000 
	 loss: 4.1647, MinusLogProbMetric: 4.1647, val_loss: 4.2651, val_MinusLogProbMetric: 4.2651

Epoch 90: val_loss did not improve from 4.17006
196/196 - 43s - loss: 4.1647 - MinusLogProbMetric: 4.1647 - val_loss: 4.2651 - val_MinusLogProbMetric: 4.2651 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 91/1000
2023-09-17 07:00:47.230 
Epoch 91/1000 
	 loss: 4.1689, MinusLogProbMetric: 4.1689, val_loss: 4.1992, val_MinusLogProbMetric: 4.1992

Epoch 91: val_loss did not improve from 4.17006
196/196 - 44s - loss: 4.1689 - MinusLogProbMetric: 4.1689 - val_loss: 4.1992 - val_MinusLogProbMetric: 4.1992 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 92/1000
2023-09-17 07:01:31.091 
Epoch 92/1000 
	 loss: 4.1605, MinusLogProbMetric: 4.1605, val_loss: 4.2199, val_MinusLogProbMetric: 4.2199

Epoch 92: val_loss did not improve from 4.17006
196/196 - 44s - loss: 4.1605 - MinusLogProbMetric: 4.1605 - val_loss: 4.2199 - val_MinusLogProbMetric: 4.2199 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 93/1000
2023-09-17 07:02:14.855 
Epoch 93/1000 
	 loss: 4.1657, MinusLogProbMetric: 4.1657, val_loss: 4.2591, val_MinusLogProbMetric: 4.2591

Epoch 93: val_loss did not improve from 4.17006
196/196 - 44s - loss: 4.1657 - MinusLogProbMetric: 4.1657 - val_loss: 4.2591 - val_MinusLogProbMetric: 4.2591 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 94/1000
2023-09-17 07:02:57.980 
Epoch 94/1000 
	 loss: 4.1611, MinusLogProbMetric: 4.1611, val_loss: 4.2716, val_MinusLogProbMetric: 4.2716

Epoch 94: val_loss did not improve from 4.17006
196/196 - 43s - loss: 4.1611 - MinusLogProbMetric: 4.1611 - val_loss: 4.2716 - val_MinusLogProbMetric: 4.2716 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 95/1000
2023-09-17 07:03:41.810 
Epoch 95/1000 
	 loss: 4.1611, MinusLogProbMetric: 4.1611, val_loss: 4.2064, val_MinusLogProbMetric: 4.2064

Epoch 95: val_loss did not improve from 4.17006
196/196 - 44s - loss: 4.1611 - MinusLogProbMetric: 4.1611 - val_loss: 4.2064 - val_MinusLogProbMetric: 4.2064 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 96/1000
2023-09-17 07:04:24.859 
Epoch 96/1000 
	 loss: 4.1651, MinusLogProbMetric: 4.1651, val_loss: 4.1696, val_MinusLogProbMetric: 4.1696

Epoch 96: val_loss improved from 4.17006 to 4.16961, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_116/weights/best_weights.h5
196/196 - 44s - loss: 4.1651 - MinusLogProbMetric: 4.1651 - val_loss: 4.1696 - val_MinusLogProbMetric: 4.1696 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 97/1000
2023-09-17 07:05:09.104 
Epoch 97/1000 
	 loss: 4.1579, MinusLogProbMetric: 4.1579, val_loss: 4.1790, val_MinusLogProbMetric: 4.1790

Epoch 97: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.1579 - MinusLogProbMetric: 4.1579 - val_loss: 4.1790 - val_MinusLogProbMetric: 4.1790 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 98/1000
2023-09-17 07:05:53.024 
Epoch 98/1000 
	 loss: 4.1534, MinusLogProbMetric: 4.1534, val_loss: 4.2172, val_MinusLogProbMetric: 4.2172

Epoch 98: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1534 - MinusLogProbMetric: 4.1534 - val_loss: 4.2172 - val_MinusLogProbMetric: 4.2172 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 99/1000
2023-09-17 07:06:36.629 
Epoch 99/1000 
	 loss: 4.1519, MinusLogProbMetric: 4.1519, val_loss: 4.3094, val_MinusLogProbMetric: 4.3094

Epoch 99: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1519 - MinusLogProbMetric: 4.1519 - val_loss: 4.3094 - val_MinusLogProbMetric: 4.3094 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 100/1000
2023-09-17 07:07:20.136 
Epoch 100/1000 
	 loss: 4.1605, MinusLogProbMetric: 4.1605, val_loss: 4.1875, val_MinusLogProbMetric: 4.1875

Epoch 100: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1605 - MinusLogProbMetric: 4.1605 - val_loss: 4.1875 - val_MinusLogProbMetric: 4.1875 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 101/1000
2023-09-17 07:08:03.838 
Epoch 101/1000 
	 loss: 4.1754, MinusLogProbMetric: 4.1754, val_loss: 4.1794, val_MinusLogProbMetric: 4.1794

Epoch 101: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1754 - MinusLogProbMetric: 4.1754 - val_loss: 4.1794 - val_MinusLogProbMetric: 4.1794 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 102/1000
2023-09-17 07:08:47.392 
Epoch 102/1000 
	 loss: 4.1613, MinusLogProbMetric: 4.1613, val_loss: 4.2047, val_MinusLogProbMetric: 4.2047

Epoch 102: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1613 - MinusLogProbMetric: 4.1613 - val_loss: 4.2047 - val_MinusLogProbMetric: 4.2047 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 103/1000
2023-09-17 07:09:30.805 
Epoch 103/1000 
	 loss: 4.1639, MinusLogProbMetric: 4.1639, val_loss: 4.2452, val_MinusLogProbMetric: 4.2452

Epoch 103: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.1639 - MinusLogProbMetric: 4.1639 - val_loss: 4.2452 - val_MinusLogProbMetric: 4.2452 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 104/1000
2023-09-17 07:10:14.286 
Epoch 104/1000 
	 loss: 4.1526, MinusLogProbMetric: 4.1526, val_loss: 4.2102, val_MinusLogProbMetric: 4.2102

Epoch 104: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.1526 - MinusLogProbMetric: 4.1526 - val_loss: 4.2102 - val_MinusLogProbMetric: 4.2102 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 105/1000
2023-09-17 07:10:58.059 
Epoch 105/1000 
	 loss: 4.1337, MinusLogProbMetric: 4.1337, val_loss: 4.1924, val_MinusLogProbMetric: 4.1924

Epoch 105: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1337 - MinusLogProbMetric: 4.1337 - val_loss: 4.1924 - val_MinusLogProbMetric: 4.1924 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 106/1000
2023-09-17 07:11:37.845 
Epoch 106/1000 
	 loss: 4.1528, MinusLogProbMetric: 4.1528, val_loss: 4.2327, val_MinusLogProbMetric: 4.2327

Epoch 106: val_loss did not improve from 4.16961
196/196 - 40s - loss: 4.1528 - MinusLogProbMetric: 4.1528 - val_loss: 4.2327 - val_MinusLogProbMetric: 4.2327 - lr: 0.0010 - 40s/epoch - 203ms/step
Epoch 107/1000
2023-09-17 07:12:18.186 
Epoch 107/1000 
	 loss: 4.1565, MinusLogProbMetric: 4.1565, val_loss: 4.1952, val_MinusLogProbMetric: 4.1952

Epoch 107: val_loss did not improve from 4.16961
196/196 - 40s - loss: 4.1565 - MinusLogProbMetric: 4.1565 - val_loss: 4.1952 - val_MinusLogProbMetric: 4.1952 - lr: 0.0010 - 40s/epoch - 206ms/step
Epoch 108/1000
2023-09-17 07:12:54.995 
Epoch 108/1000 
	 loss: 4.1315, MinusLogProbMetric: 4.1315, val_loss: 4.2919, val_MinusLogProbMetric: 4.2919

Epoch 108: val_loss did not improve from 4.16961
196/196 - 37s - loss: 4.1315 - MinusLogProbMetric: 4.1315 - val_loss: 4.2919 - val_MinusLogProbMetric: 4.2919 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 109/1000
2023-09-17 07:13:31.406 
Epoch 109/1000 
	 loss: 4.1403, MinusLogProbMetric: 4.1403, val_loss: 4.2053, val_MinusLogProbMetric: 4.2053

Epoch 109: val_loss did not improve from 4.16961
196/196 - 36s - loss: 4.1403 - MinusLogProbMetric: 4.1403 - val_loss: 4.2053 - val_MinusLogProbMetric: 4.2053 - lr: 0.0010 - 36s/epoch - 186ms/step
Epoch 110/1000
2023-09-17 07:14:14.872 
Epoch 110/1000 
	 loss: 4.1529, MinusLogProbMetric: 4.1529, val_loss: 4.1823, val_MinusLogProbMetric: 4.1823

Epoch 110: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.1529 - MinusLogProbMetric: 4.1529 - val_loss: 4.1823 - val_MinusLogProbMetric: 4.1823 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 111/1000
2023-09-17 07:14:58.553 
Epoch 111/1000 
	 loss: 4.1425, MinusLogProbMetric: 4.1425, val_loss: 4.3374, val_MinusLogProbMetric: 4.3374

Epoch 111: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1425 - MinusLogProbMetric: 4.1425 - val_loss: 4.3374 - val_MinusLogProbMetric: 4.3374 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 112/1000
2023-09-17 07:15:41.387 
Epoch 112/1000 
	 loss: 4.1468, MinusLogProbMetric: 4.1468, val_loss: 4.2238, val_MinusLogProbMetric: 4.2238

Epoch 112: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.1468 - MinusLogProbMetric: 4.1468 - val_loss: 4.2238 - val_MinusLogProbMetric: 4.2238 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 113/1000
2023-09-17 07:16:25.145 
Epoch 113/1000 
	 loss: 4.1548, MinusLogProbMetric: 4.1548, val_loss: 4.2207, val_MinusLogProbMetric: 4.2207

Epoch 113: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1548 - MinusLogProbMetric: 4.1548 - val_loss: 4.2207 - val_MinusLogProbMetric: 4.2207 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 114/1000
2023-09-17 07:17:08.814 
Epoch 114/1000 
	 loss: 4.1358, MinusLogProbMetric: 4.1358, val_loss: 4.2017, val_MinusLogProbMetric: 4.2017

Epoch 114: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1358 - MinusLogProbMetric: 4.1358 - val_loss: 4.2017 - val_MinusLogProbMetric: 4.2017 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 115/1000
2023-09-17 07:17:52.079 
Epoch 115/1000 
	 loss: 4.1319, MinusLogProbMetric: 4.1319, val_loss: 4.1835, val_MinusLogProbMetric: 4.1835

Epoch 115: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.1319 - MinusLogProbMetric: 4.1319 - val_loss: 4.1835 - val_MinusLogProbMetric: 4.1835 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 116/1000
2023-09-17 07:18:35.296 
Epoch 116/1000 
	 loss: 4.1368, MinusLogProbMetric: 4.1368, val_loss: 4.1975, val_MinusLogProbMetric: 4.1975

Epoch 116: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.1368 - MinusLogProbMetric: 4.1368 - val_loss: 4.1975 - val_MinusLogProbMetric: 4.1975 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 117/1000
2023-09-17 07:19:12.040 
Epoch 117/1000 
	 loss: 4.1350, MinusLogProbMetric: 4.1350, val_loss: 4.2457, val_MinusLogProbMetric: 4.2457

Epoch 117: val_loss did not improve from 4.16961
196/196 - 37s - loss: 4.1350 - MinusLogProbMetric: 4.1350 - val_loss: 4.2457 - val_MinusLogProbMetric: 4.2457 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 118/1000
2023-09-17 07:19:49.419 
Epoch 118/1000 
	 loss: 4.1256, MinusLogProbMetric: 4.1256, val_loss: 4.2017, val_MinusLogProbMetric: 4.2017

Epoch 118: val_loss did not improve from 4.16961
196/196 - 37s - loss: 4.1256 - MinusLogProbMetric: 4.1256 - val_loss: 4.2017 - val_MinusLogProbMetric: 4.2017 - lr: 0.0010 - 37s/epoch - 191ms/step
Epoch 119/1000
2023-09-17 07:20:30.177 
Epoch 119/1000 
	 loss: 4.1249, MinusLogProbMetric: 4.1249, val_loss: 4.2277, val_MinusLogProbMetric: 4.2277

Epoch 119: val_loss did not improve from 4.16961
196/196 - 41s - loss: 4.1249 - MinusLogProbMetric: 4.1249 - val_loss: 4.2277 - val_MinusLogProbMetric: 4.2277 - lr: 0.0010 - 41s/epoch - 208ms/step
Epoch 120/1000
2023-09-17 07:21:14.373 
Epoch 120/1000 
	 loss: 4.1377, MinusLogProbMetric: 4.1377, val_loss: 4.1771, val_MinusLogProbMetric: 4.1771

Epoch 120: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1377 - MinusLogProbMetric: 4.1377 - val_loss: 4.1771 - val_MinusLogProbMetric: 4.1771 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 121/1000
2023-09-17 07:21:58.303 
Epoch 121/1000 
	 loss: 4.1157, MinusLogProbMetric: 4.1157, val_loss: 4.1721, val_MinusLogProbMetric: 4.1721

Epoch 121: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1157 - MinusLogProbMetric: 4.1157 - val_loss: 4.1721 - val_MinusLogProbMetric: 4.1721 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 122/1000
2023-09-17 07:22:42.053 
Epoch 122/1000 
	 loss: 4.1246, MinusLogProbMetric: 4.1246, val_loss: 4.2054, val_MinusLogProbMetric: 4.2054

Epoch 122: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1246 - MinusLogProbMetric: 4.1246 - val_loss: 4.2054 - val_MinusLogProbMetric: 4.2054 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 123/1000
2023-09-17 07:23:25.670 
Epoch 123/1000 
	 loss: 4.1483, MinusLogProbMetric: 4.1483, val_loss: 4.3368, val_MinusLogProbMetric: 4.3368

Epoch 123: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1483 - MinusLogProbMetric: 4.1483 - val_loss: 4.3368 - val_MinusLogProbMetric: 4.3368 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 124/1000
2023-09-17 07:24:09.161 
Epoch 124/1000 
	 loss: 4.1384, MinusLogProbMetric: 4.1384, val_loss: 4.2030, val_MinusLogProbMetric: 4.2030

Epoch 124: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.1384 - MinusLogProbMetric: 4.1384 - val_loss: 4.2030 - val_MinusLogProbMetric: 4.2030 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 125/1000
2023-09-17 07:24:52.653 
Epoch 125/1000 
	 loss: 4.1359, MinusLogProbMetric: 4.1359, val_loss: 4.2177, val_MinusLogProbMetric: 4.2177

Epoch 125: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.1359 - MinusLogProbMetric: 4.1359 - val_loss: 4.2177 - val_MinusLogProbMetric: 4.2177 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 126/1000
2023-09-17 07:25:35.864 
Epoch 126/1000 
	 loss: 4.1215, MinusLogProbMetric: 4.1215, val_loss: 4.1710, val_MinusLogProbMetric: 4.1710

Epoch 126: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.1215 - MinusLogProbMetric: 4.1215 - val_loss: 4.1710 - val_MinusLogProbMetric: 4.1710 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 127/1000
2023-09-17 07:26:19.242 
Epoch 127/1000 
	 loss: 4.1580, MinusLogProbMetric: 4.1580, val_loss: 4.4375, val_MinusLogProbMetric: 4.4375

Epoch 127: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.1580 - MinusLogProbMetric: 4.1580 - val_loss: 4.4375 - val_MinusLogProbMetric: 4.4375 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 128/1000
2023-09-17 07:27:02.489 
Epoch 128/1000 
	 loss: 4.1312, MinusLogProbMetric: 4.1312, val_loss: 4.2403, val_MinusLogProbMetric: 4.2403

Epoch 128: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.1312 - MinusLogProbMetric: 4.1312 - val_loss: 4.2403 - val_MinusLogProbMetric: 4.2403 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 129/1000
2023-09-17 07:27:45.566 
Epoch 129/1000 
	 loss: 4.1274, MinusLogProbMetric: 4.1274, val_loss: 4.1874, val_MinusLogProbMetric: 4.1874

Epoch 129: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.1274 - MinusLogProbMetric: 4.1274 - val_loss: 4.1874 - val_MinusLogProbMetric: 4.1874 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 130/1000
2023-09-17 07:28:29.486 
Epoch 130/1000 
	 loss: 4.1589, MinusLogProbMetric: 4.1589, val_loss: 4.3148, val_MinusLogProbMetric: 4.3148

Epoch 130: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1589 - MinusLogProbMetric: 4.1589 - val_loss: 4.3148 - val_MinusLogProbMetric: 4.3148 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 131/1000
2023-09-17 07:29:13.163 
Epoch 131/1000 
	 loss: 4.1132, MinusLogProbMetric: 4.1132, val_loss: 4.2706, val_MinusLogProbMetric: 4.2706

Epoch 131: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1132 - MinusLogProbMetric: 4.1132 - val_loss: 4.2706 - val_MinusLogProbMetric: 4.2706 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 132/1000
2023-09-17 07:29:56.769 
Epoch 132/1000 
	 loss: 4.0971, MinusLogProbMetric: 4.0971, val_loss: 4.1995, val_MinusLogProbMetric: 4.1995

Epoch 132: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.0971 - MinusLogProbMetric: 4.0971 - val_loss: 4.1995 - val_MinusLogProbMetric: 4.1995 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 133/1000
2023-09-17 07:30:40.232 
Epoch 133/1000 
	 loss: 4.1163, MinusLogProbMetric: 4.1163, val_loss: 4.2143, val_MinusLogProbMetric: 4.2143

Epoch 133: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.1163 - MinusLogProbMetric: 4.1163 - val_loss: 4.2143 - val_MinusLogProbMetric: 4.2143 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 134/1000
2023-09-17 07:31:23.835 
Epoch 134/1000 
	 loss: 4.1080, MinusLogProbMetric: 4.1080, val_loss: 4.1920, val_MinusLogProbMetric: 4.1920

Epoch 134: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1080 - MinusLogProbMetric: 4.1080 - val_loss: 4.1920 - val_MinusLogProbMetric: 4.1920 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 135/1000
2023-09-17 07:32:06.946 
Epoch 135/1000 
	 loss: 4.1163, MinusLogProbMetric: 4.1163, val_loss: 4.4182, val_MinusLogProbMetric: 4.4182

Epoch 135: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.1163 - MinusLogProbMetric: 4.1163 - val_loss: 4.4182 - val_MinusLogProbMetric: 4.4182 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 136/1000
2023-09-17 07:32:50.657 
Epoch 136/1000 
	 loss: 4.1208, MinusLogProbMetric: 4.1208, val_loss: 4.3605, val_MinusLogProbMetric: 4.3605

Epoch 136: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1208 - MinusLogProbMetric: 4.1208 - val_loss: 4.3605 - val_MinusLogProbMetric: 4.3605 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 137/1000
2023-09-17 07:33:34.553 
Epoch 137/1000 
	 loss: 4.1190, MinusLogProbMetric: 4.1190, val_loss: 4.2061, val_MinusLogProbMetric: 4.2061

Epoch 137: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1190 - MinusLogProbMetric: 4.1190 - val_loss: 4.2061 - val_MinusLogProbMetric: 4.2061 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 138/1000
2023-09-17 07:34:18.275 
Epoch 138/1000 
	 loss: 4.1032, MinusLogProbMetric: 4.1032, val_loss: 4.1946, val_MinusLogProbMetric: 4.1946

Epoch 138: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1032 - MinusLogProbMetric: 4.1032 - val_loss: 4.1946 - val_MinusLogProbMetric: 4.1946 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 139/1000
2023-09-17 07:35:01.952 
Epoch 139/1000 
	 loss: 4.1226, MinusLogProbMetric: 4.1226, val_loss: 4.1933, val_MinusLogProbMetric: 4.1933

Epoch 139: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1226 - MinusLogProbMetric: 4.1226 - val_loss: 4.1933 - val_MinusLogProbMetric: 4.1933 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 140/1000
2023-09-17 07:35:45.351 
Epoch 140/1000 
	 loss: 4.1151, MinusLogProbMetric: 4.1151, val_loss: 4.1930, val_MinusLogProbMetric: 4.1930

Epoch 140: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.1151 - MinusLogProbMetric: 4.1151 - val_loss: 4.1930 - val_MinusLogProbMetric: 4.1930 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 141/1000
2023-09-17 07:36:28.854 
Epoch 141/1000 
	 loss: 4.1068, MinusLogProbMetric: 4.1068, val_loss: 4.2021, val_MinusLogProbMetric: 4.2021

Epoch 141: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.1068 - MinusLogProbMetric: 4.1068 - val_loss: 4.2021 - val_MinusLogProbMetric: 4.2021 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 142/1000
2023-09-17 07:37:12.343 
Epoch 142/1000 
	 loss: 4.0971, MinusLogProbMetric: 4.0971, val_loss: 4.3063, val_MinusLogProbMetric: 4.3063

Epoch 142: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.0971 - MinusLogProbMetric: 4.0971 - val_loss: 4.3063 - val_MinusLogProbMetric: 4.3063 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 143/1000
2023-09-17 07:37:55.063 
Epoch 143/1000 
	 loss: 4.1211, MinusLogProbMetric: 4.1211, val_loss: 4.1948, val_MinusLogProbMetric: 4.1948

Epoch 143: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.1211 - MinusLogProbMetric: 4.1211 - val_loss: 4.1948 - val_MinusLogProbMetric: 4.1948 - lr: 0.0010 - 43s/epoch - 218ms/step
Epoch 144/1000
2023-09-17 07:38:38.354 
Epoch 144/1000 
	 loss: 4.1132, MinusLogProbMetric: 4.1132, val_loss: 4.2577, val_MinusLogProbMetric: 4.2577

Epoch 144: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.1132 - MinusLogProbMetric: 4.1132 - val_loss: 4.2577 - val_MinusLogProbMetric: 4.2577 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 145/1000
2023-09-17 07:39:21.504 
Epoch 145/1000 
	 loss: 4.1166, MinusLogProbMetric: 4.1166, val_loss: 4.2357, val_MinusLogProbMetric: 4.2357

Epoch 145: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.1166 - MinusLogProbMetric: 4.1166 - val_loss: 4.2357 - val_MinusLogProbMetric: 4.2357 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 146/1000
2023-09-17 07:40:04.935 
Epoch 146/1000 
	 loss: 4.1036, MinusLogProbMetric: 4.1036, val_loss: 4.2440, val_MinusLogProbMetric: 4.2440

Epoch 146: val_loss did not improve from 4.16961
196/196 - 43s - loss: 4.1036 - MinusLogProbMetric: 4.1036 - val_loss: 4.2440 - val_MinusLogProbMetric: 4.2440 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 147/1000
2023-09-17 07:40:48.892 
Epoch 147/1000 
	 loss: 4.0448, MinusLogProbMetric: 4.0448, val_loss: 4.1816, val_MinusLogProbMetric: 4.1816

Epoch 147: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.0448 - MinusLogProbMetric: 4.0448 - val_loss: 4.1816 - val_MinusLogProbMetric: 4.1816 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 148/1000
2023-09-17 07:41:32.576 
Epoch 148/1000 
	 loss: 4.0379, MinusLogProbMetric: 4.0379, val_loss: 4.1895, val_MinusLogProbMetric: 4.1895

Epoch 148: val_loss did not improve from 4.16961
196/196 - 44s - loss: 4.0379 - MinusLogProbMetric: 4.0379 - val_loss: 4.1895 - val_MinusLogProbMetric: 4.1895 - lr: 5.0000e-04 - 44s/epoch - 223ms/step
Epoch 149/1000
2023-09-17 07:42:16.424 
Epoch 149/1000 
	 loss: 4.0432, MinusLogProbMetric: 4.0432, val_loss: 4.1612, val_MinusLogProbMetric: 4.1612

Epoch 149: val_loss improved from 4.16961 to 4.16122, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_116/weights/best_weights.h5
196/196 - 45s - loss: 4.0432 - MinusLogProbMetric: 4.0432 - val_loss: 4.1612 - val_MinusLogProbMetric: 4.1612 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 150/1000
2023-09-17 07:43:00.584 
Epoch 150/1000 
	 loss: 4.0386, MinusLogProbMetric: 4.0386, val_loss: 4.1715, val_MinusLogProbMetric: 4.1715

Epoch 150: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0386 - MinusLogProbMetric: 4.0386 - val_loss: 4.1715 - val_MinusLogProbMetric: 4.1715 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 151/1000
2023-09-17 07:43:44.024 
Epoch 151/1000 
	 loss: 4.0382, MinusLogProbMetric: 4.0382, val_loss: 4.1753, val_MinusLogProbMetric: 4.1753

Epoch 151: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0382 - MinusLogProbMetric: 4.0382 - val_loss: 4.1753 - val_MinusLogProbMetric: 4.1753 - lr: 5.0000e-04 - 43s/epoch - 222ms/step
Epoch 152/1000
2023-09-17 07:44:27.341 
Epoch 152/1000 
	 loss: 4.0403, MinusLogProbMetric: 4.0403, val_loss: 4.1654, val_MinusLogProbMetric: 4.1654

Epoch 152: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0403 - MinusLogProbMetric: 4.0403 - val_loss: 4.1654 - val_MinusLogProbMetric: 4.1654 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 153/1000
2023-09-17 07:45:10.493 
Epoch 153/1000 
	 loss: 4.0380, MinusLogProbMetric: 4.0380, val_loss: 4.1989, val_MinusLogProbMetric: 4.1989

Epoch 153: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0380 - MinusLogProbMetric: 4.0380 - val_loss: 4.1989 - val_MinusLogProbMetric: 4.1989 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 154/1000
2023-09-17 07:45:54.768 
Epoch 154/1000 
	 loss: 4.0391, MinusLogProbMetric: 4.0391, val_loss: 4.1923, val_MinusLogProbMetric: 4.1923

Epoch 154: val_loss did not improve from 4.16122
196/196 - 44s - loss: 4.0391 - MinusLogProbMetric: 4.0391 - val_loss: 4.1923 - val_MinusLogProbMetric: 4.1923 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 155/1000
2023-09-17 07:46:38.658 
Epoch 155/1000 
	 loss: 4.0444, MinusLogProbMetric: 4.0444, val_loss: 4.2061, val_MinusLogProbMetric: 4.2061

Epoch 155: val_loss did not improve from 4.16122
196/196 - 44s - loss: 4.0444 - MinusLogProbMetric: 4.0444 - val_loss: 4.2061 - val_MinusLogProbMetric: 4.2061 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 156/1000
2023-09-17 07:47:22.282 
Epoch 156/1000 
	 loss: 4.0345, MinusLogProbMetric: 4.0345, val_loss: 4.1730, val_MinusLogProbMetric: 4.1730

Epoch 156: val_loss did not improve from 4.16122
196/196 - 44s - loss: 4.0345 - MinusLogProbMetric: 4.0345 - val_loss: 4.1730 - val_MinusLogProbMetric: 4.1730 - lr: 5.0000e-04 - 44s/epoch - 223ms/step
Epoch 157/1000
2023-09-17 07:48:05.971 
Epoch 157/1000 
	 loss: 4.0347, MinusLogProbMetric: 4.0347, val_loss: 4.1827, val_MinusLogProbMetric: 4.1827

Epoch 157: val_loss did not improve from 4.16122
196/196 - 44s - loss: 4.0347 - MinusLogProbMetric: 4.0347 - val_loss: 4.1827 - val_MinusLogProbMetric: 4.1827 - lr: 5.0000e-04 - 44s/epoch - 223ms/step
Epoch 158/1000
2023-09-17 07:48:49.760 
Epoch 158/1000 
	 loss: 4.0370, MinusLogProbMetric: 4.0370, val_loss: 4.2031, val_MinusLogProbMetric: 4.2031

Epoch 158: val_loss did not improve from 4.16122
196/196 - 44s - loss: 4.0370 - MinusLogProbMetric: 4.0370 - val_loss: 4.2031 - val_MinusLogProbMetric: 4.2031 - lr: 5.0000e-04 - 44s/epoch - 223ms/step
Epoch 159/1000
2023-09-17 07:49:33.576 
Epoch 159/1000 
	 loss: 4.0410, MinusLogProbMetric: 4.0410, val_loss: 4.2151, val_MinusLogProbMetric: 4.2151

Epoch 159: val_loss did not improve from 4.16122
196/196 - 44s - loss: 4.0410 - MinusLogProbMetric: 4.0410 - val_loss: 4.2151 - val_MinusLogProbMetric: 4.2151 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 160/1000
2023-09-17 07:50:17.911 
Epoch 160/1000 
	 loss: 4.0405, MinusLogProbMetric: 4.0405, val_loss: 4.1933, val_MinusLogProbMetric: 4.1933

Epoch 160: val_loss did not improve from 4.16122
196/196 - 44s - loss: 4.0405 - MinusLogProbMetric: 4.0405 - val_loss: 4.1933 - val_MinusLogProbMetric: 4.1933 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 161/1000
2023-09-17 07:51:01.539 
Epoch 161/1000 
	 loss: 4.0358, MinusLogProbMetric: 4.0358, val_loss: 4.1988, val_MinusLogProbMetric: 4.1988

Epoch 161: val_loss did not improve from 4.16122
196/196 - 44s - loss: 4.0358 - MinusLogProbMetric: 4.0358 - val_loss: 4.1988 - val_MinusLogProbMetric: 4.1988 - lr: 5.0000e-04 - 44s/epoch - 223ms/step
Epoch 162/1000
2023-09-17 07:51:45.430 
Epoch 162/1000 
	 loss: 4.0439, MinusLogProbMetric: 4.0439, val_loss: 4.2538, val_MinusLogProbMetric: 4.2538

Epoch 162: val_loss did not improve from 4.16122
196/196 - 44s - loss: 4.0439 - MinusLogProbMetric: 4.0439 - val_loss: 4.2538 - val_MinusLogProbMetric: 4.2538 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 163/1000
2023-09-17 07:52:28.252 
Epoch 163/1000 
	 loss: 4.0326, MinusLogProbMetric: 4.0326, val_loss: 4.2256, val_MinusLogProbMetric: 4.2256

Epoch 163: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0326 - MinusLogProbMetric: 4.0326 - val_loss: 4.2256 - val_MinusLogProbMetric: 4.2256 - lr: 5.0000e-04 - 43s/epoch - 218ms/step
Epoch 164/1000
2023-09-17 07:53:05.201 
Epoch 164/1000 
	 loss: 4.0413, MinusLogProbMetric: 4.0413, val_loss: 4.1967, val_MinusLogProbMetric: 4.1967

Epoch 164: val_loss did not improve from 4.16122
196/196 - 37s - loss: 4.0413 - MinusLogProbMetric: 4.0413 - val_loss: 4.1967 - val_MinusLogProbMetric: 4.1967 - lr: 5.0000e-04 - 37s/epoch - 188ms/step
Epoch 165/1000
2023-09-17 07:53:40.249 
Epoch 165/1000 
	 loss: 4.0365, MinusLogProbMetric: 4.0365, val_loss: 4.1928, val_MinusLogProbMetric: 4.1928

Epoch 165: val_loss did not improve from 4.16122
196/196 - 35s - loss: 4.0365 - MinusLogProbMetric: 4.0365 - val_loss: 4.1928 - val_MinusLogProbMetric: 4.1928 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 166/1000
2023-09-17 07:54:15.100 
Epoch 166/1000 
	 loss: 4.0327, MinusLogProbMetric: 4.0327, val_loss: 4.1897, val_MinusLogProbMetric: 4.1897

Epoch 166: val_loss did not improve from 4.16122
196/196 - 35s - loss: 4.0327 - MinusLogProbMetric: 4.0327 - val_loss: 4.1897 - val_MinusLogProbMetric: 4.1897 - lr: 5.0000e-04 - 35s/epoch - 178ms/step
Epoch 167/1000
2023-09-17 07:54:50.330 
Epoch 167/1000 
	 loss: 4.0390, MinusLogProbMetric: 4.0390, val_loss: 4.1872, val_MinusLogProbMetric: 4.1872

Epoch 167: val_loss did not improve from 4.16122
196/196 - 35s - loss: 4.0390 - MinusLogProbMetric: 4.0390 - val_loss: 4.1872 - val_MinusLogProbMetric: 4.1872 - lr: 5.0000e-04 - 35s/epoch - 180ms/step
Epoch 168/1000
2023-09-17 07:55:30.399 
Epoch 168/1000 
	 loss: 4.0316, MinusLogProbMetric: 4.0316, val_loss: 4.1806, val_MinusLogProbMetric: 4.1806

Epoch 168: val_loss did not improve from 4.16122
196/196 - 40s - loss: 4.0316 - MinusLogProbMetric: 4.0316 - val_loss: 4.1806 - val_MinusLogProbMetric: 4.1806 - lr: 5.0000e-04 - 40s/epoch - 204ms/step
Epoch 169/1000
2023-09-17 07:56:13.721 
Epoch 169/1000 
	 loss: 4.0325, MinusLogProbMetric: 4.0325, val_loss: 4.2159, val_MinusLogProbMetric: 4.2159

Epoch 169: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0325 - MinusLogProbMetric: 4.0325 - val_loss: 4.2159 - val_MinusLogProbMetric: 4.2159 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 170/1000
2023-09-17 07:56:52.877 
Epoch 170/1000 
	 loss: 4.0309, MinusLogProbMetric: 4.0309, val_loss: 4.1920, val_MinusLogProbMetric: 4.1920

Epoch 170: val_loss did not improve from 4.16122
196/196 - 39s - loss: 4.0309 - MinusLogProbMetric: 4.0309 - val_loss: 4.1920 - val_MinusLogProbMetric: 4.1920 - lr: 5.0000e-04 - 39s/epoch - 200ms/step
Epoch 171/1000
2023-09-17 07:57:33.181 
Epoch 171/1000 
	 loss: 4.0290, MinusLogProbMetric: 4.0290, val_loss: 4.2162, val_MinusLogProbMetric: 4.2162

Epoch 171: val_loss did not improve from 4.16122
196/196 - 40s - loss: 4.0290 - MinusLogProbMetric: 4.0290 - val_loss: 4.2162 - val_MinusLogProbMetric: 4.2162 - lr: 5.0000e-04 - 40s/epoch - 206ms/step
Epoch 172/1000
2023-09-17 07:58:13.241 
Epoch 172/1000 
	 loss: 4.0359, MinusLogProbMetric: 4.0359, val_loss: 4.1866, val_MinusLogProbMetric: 4.1866

Epoch 172: val_loss did not improve from 4.16122
196/196 - 40s - loss: 4.0359 - MinusLogProbMetric: 4.0359 - val_loss: 4.1866 - val_MinusLogProbMetric: 4.1866 - lr: 5.0000e-04 - 40s/epoch - 204ms/step
Epoch 173/1000
2023-09-17 07:58:56.823 
Epoch 173/1000 
	 loss: 4.0276, MinusLogProbMetric: 4.0276, val_loss: 4.1722, val_MinusLogProbMetric: 4.1722

Epoch 173: val_loss did not improve from 4.16122
196/196 - 44s - loss: 4.0276 - MinusLogProbMetric: 4.0276 - val_loss: 4.1722 - val_MinusLogProbMetric: 4.1722 - lr: 5.0000e-04 - 44s/epoch - 222ms/step
Epoch 174/1000
2023-09-17 07:59:40.095 
Epoch 174/1000 
	 loss: 4.0321, MinusLogProbMetric: 4.0321, val_loss: 4.1804, val_MinusLogProbMetric: 4.1804

Epoch 174: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0321 - MinusLogProbMetric: 4.0321 - val_loss: 4.1804 - val_MinusLogProbMetric: 4.1804 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 175/1000
2023-09-17 08:00:23.309 
Epoch 175/1000 
	 loss: 4.0346, MinusLogProbMetric: 4.0346, val_loss: 4.1817, val_MinusLogProbMetric: 4.1817

Epoch 175: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0346 - MinusLogProbMetric: 4.0346 - val_loss: 4.1817 - val_MinusLogProbMetric: 4.1817 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 176/1000
2023-09-17 08:01:07.335 
Epoch 176/1000 
	 loss: 4.0341, MinusLogProbMetric: 4.0341, val_loss: 4.1947, val_MinusLogProbMetric: 4.1947

Epoch 176: val_loss did not improve from 4.16122
196/196 - 44s - loss: 4.0341 - MinusLogProbMetric: 4.0341 - val_loss: 4.1947 - val_MinusLogProbMetric: 4.1947 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 177/1000
2023-09-17 08:01:50.735 
Epoch 177/1000 
	 loss: 4.0244, MinusLogProbMetric: 4.0244, val_loss: 4.1889, val_MinusLogProbMetric: 4.1889

Epoch 177: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0244 - MinusLogProbMetric: 4.0244 - val_loss: 4.1889 - val_MinusLogProbMetric: 4.1889 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 178/1000
2023-09-17 08:02:34.154 
Epoch 178/1000 
	 loss: 4.0294, MinusLogProbMetric: 4.0294, val_loss: 4.1869, val_MinusLogProbMetric: 4.1869

Epoch 178: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0294 - MinusLogProbMetric: 4.0294 - val_loss: 4.1869 - val_MinusLogProbMetric: 4.1869 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 179/1000
2023-09-17 08:03:17.101 
Epoch 179/1000 
	 loss: 4.0280, MinusLogProbMetric: 4.0280, val_loss: 4.2371, val_MinusLogProbMetric: 4.2371

Epoch 179: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0280 - MinusLogProbMetric: 4.0280 - val_loss: 4.2371 - val_MinusLogProbMetric: 4.2371 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 180/1000
2023-09-17 08:04:00.549 
Epoch 180/1000 
	 loss: 4.0273, MinusLogProbMetric: 4.0273, val_loss: 4.1898, val_MinusLogProbMetric: 4.1898

Epoch 180: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0273 - MinusLogProbMetric: 4.0273 - val_loss: 4.1898 - val_MinusLogProbMetric: 4.1898 - lr: 5.0000e-04 - 43s/epoch - 222ms/step
Epoch 181/1000
2023-09-17 08:04:43.599 
Epoch 181/1000 
	 loss: 4.0271, MinusLogProbMetric: 4.0271, val_loss: 4.2032, val_MinusLogProbMetric: 4.2032

Epoch 181: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0271 - MinusLogProbMetric: 4.0271 - val_loss: 4.2032 - val_MinusLogProbMetric: 4.2032 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 182/1000
2023-09-17 08:05:26.676 
Epoch 182/1000 
	 loss: 4.0299, MinusLogProbMetric: 4.0299, val_loss: 4.1954, val_MinusLogProbMetric: 4.1954

Epoch 182: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0299 - MinusLogProbMetric: 4.0299 - val_loss: 4.1954 - val_MinusLogProbMetric: 4.1954 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 183/1000
2023-09-17 08:06:09.717 
Epoch 183/1000 
	 loss: 4.0292, MinusLogProbMetric: 4.0292, val_loss: 4.2088, val_MinusLogProbMetric: 4.2088

Epoch 183: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0292 - MinusLogProbMetric: 4.0292 - val_loss: 4.2088 - val_MinusLogProbMetric: 4.2088 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 184/1000
2023-09-17 08:06:52.806 
Epoch 184/1000 
	 loss: 4.0319, MinusLogProbMetric: 4.0319, val_loss: 4.1865, val_MinusLogProbMetric: 4.1865

Epoch 184: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0319 - MinusLogProbMetric: 4.0319 - val_loss: 4.1865 - val_MinusLogProbMetric: 4.1865 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 185/1000
2023-09-17 08:07:35.874 
Epoch 185/1000 
	 loss: 4.0319, MinusLogProbMetric: 4.0319, val_loss: 4.2092, val_MinusLogProbMetric: 4.2092

Epoch 185: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0319 - MinusLogProbMetric: 4.0319 - val_loss: 4.2092 - val_MinusLogProbMetric: 4.2092 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 186/1000
2023-09-17 08:08:19.037 
Epoch 186/1000 
	 loss: 4.0234, MinusLogProbMetric: 4.0234, val_loss: 4.2001, val_MinusLogProbMetric: 4.2001

Epoch 186: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0234 - MinusLogProbMetric: 4.0234 - val_loss: 4.2001 - val_MinusLogProbMetric: 4.2001 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 187/1000
2023-09-17 08:09:02.720 
Epoch 187/1000 
	 loss: 4.0242, MinusLogProbMetric: 4.0242, val_loss: 4.2429, val_MinusLogProbMetric: 4.2429

Epoch 187: val_loss did not improve from 4.16122
196/196 - 44s - loss: 4.0242 - MinusLogProbMetric: 4.0242 - val_loss: 4.2429 - val_MinusLogProbMetric: 4.2429 - lr: 5.0000e-04 - 44s/epoch - 223ms/step
Epoch 188/1000
2023-09-17 08:09:45.879 
Epoch 188/1000 
	 loss: 4.0280, MinusLogProbMetric: 4.0280, val_loss: 4.1997, val_MinusLogProbMetric: 4.1997

Epoch 188: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0280 - MinusLogProbMetric: 4.0280 - val_loss: 4.1997 - val_MinusLogProbMetric: 4.1997 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 189/1000
2023-09-17 08:10:29.413 
Epoch 189/1000 
	 loss: 4.0258, MinusLogProbMetric: 4.0258, val_loss: 4.1895, val_MinusLogProbMetric: 4.1895

Epoch 189: val_loss did not improve from 4.16122
196/196 - 44s - loss: 4.0258 - MinusLogProbMetric: 4.0258 - val_loss: 4.1895 - val_MinusLogProbMetric: 4.1895 - lr: 5.0000e-04 - 44s/epoch - 222ms/step
Epoch 190/1000
2023-09-17 08:11:12.480 
Epoch 190/1000 
	 loss: 4.0232, MinusLogProbMetric: 4.0232, val_loss: 4.1950, val_MinusLogProbMetric: 4.1950

Epoch 190: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0232 - MinusLogProbMetric: 4.0232 - val_loss: 4.1950 - val_MinusLogProbMetric: 4.1950 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 191/1000
2023-09-17 08:11:55.553 
Epoch 191/1000 
	 loss: 4.0166, MinusLogProbMetric: 4.0166, val_loss: 4.2044, val_MinusLogProbMetric: 4.2044

Epoch 191: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0166 - MinusLogProbMetric: 4.0166 - val_loss: 4.2044 - val_MinusLogProbMetric: 4.2044 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 192/1000
2023-09-17 08:12:38.741 
Epoch 192/1000 
	 loss: 4.0242, MinusLogProbMetric: 4.0242, val_loss: 4.2106, val_MinusLogProbMetric: 4.2106

Epoch 192: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0242 - MinusLogProbMetric: 4.0242 - val_loss: 4.2106 - val_MinusLogProbMetric: 4.2106 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 193/1000
2023-09-17 08:13:21.481 
Epoch 193/1000 
	 loss: 4.0243, MinusLogProbMetric: 4.0243, val_loss: 4.2067, val_MinusLogProbMetric: 4.2067

Epoch 193: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0243 - MinusLogProbMetric: 4.0243 - val_loss: 4.2067 - val_MinusLogProbMetric: 4.2067 - lr: 5.0000e-04 - 43s/epoch - 218ms/step
Epoch 194/1000
2023-09-17 08:14:04.358 
Epoch 194/1000 
	 loss: 4.0184, MinusLogProbMetric: 4.0184, val_loss: 4.1979, val_MinusLogProbMetric: 4.1979

Epoch 194: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0184 - MinusLogProbMetric: 4.0184 - val_loss: 4.1979 - val_MinusLogProbMetric: 4.1979 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 195/1000
2023-09-17 08:14:47.528 
Epoch 195/1000 
	 loss: 4.0163, MinusLogProbMetric: 4.0163, val_loss: 4.1992, val_MinusLogProbMetric: 4.1992

Epoch 195: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0163 - MinusLogProbMetric: 4.0163 - val_loss: 4.1992 - val_MinusLogProbMetric: 4.1992 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 196/1000
2023-09-17 08:15:30.330 
Epoch 196/1000 
	 loss: 4.0192, MinusLogProbMetric: 4.0192, val_loss: 4.1899, val_MinusLogProbMetric: 4.1899

Epoch 196: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0192 - MinusLogProbMetric: 4.0192 - val_loss: 4.1899 - val_MinusLogProbMetric: 4.1899 - lr: 5.0000e-04 - 43s/epoch - 218ms/step
Epoch 197/1000
2023-09-17 08:16:13.222 
Epoch 197/1000 
	 loss: 4.0159, MinusLogProbMetric: 4.0159, val_loss: 4.1894, val_MinusLogProbMetric: 4.1894

Epoch 197: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0159 - MinusLogProbMetric: 4.0159 - val_loss: 4.1894 - val_MinusLogProbMetric: 4.1894 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 198/1000
2023-09-17 08:16:56.355 
Epoch 198/1000 
	 loss: 4.0218, MinusLogProbMetric: 4.0218, val_loss: 4.1972, val_MinusLogProbMetric: 4.1972

Epoch 198: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0218 - MinusLogProbMetric: 4.0218 - val_loss: 4.1972 - val_MinusLogProbMetric: 4.1972 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 199/1000
2023-09-17 08:17:39.596 
Epoch 199/1000 
	 loss: 4.0161, MinusLogProbMetric: 4.0161, val_loss: 4.2459, val_MinusLogProbMetric: 4.2459

Epoch 199: val_loss did not improve from 4.16122
196/196 - 43s - loss: 4.0161 - MinusLogProbMetric: 4.0161 - val_loss: 4.2459 - val_MinusLogProbMetric: 4.2459 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 200/1000
2023-09-17 08:18:22.876 
Epoch 200/1000 
	 loss: 3.9932, MinusLogProbMetric: 3.9932, val_loss: 4.1928, val_MinusLogProbMetric: 4.1928

Epoch 200: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9932 - MinusLogProbMetric: 3.9932 - val_loss: 4.1928 - val_MinusLogProbMetric: 4.1928 - lr: 2.5000e-04 - 43s/epoch - 221ms/step
Epoch 201/1000
2023-09-17 08:19:05.967 
Epoch 201/1000 
	 loss: 3.9855, MinusLogProbMetric: 3.9855, val_loss: 4.1958, val_MinusLogProbMetric: 4.1958

Epoch 201: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9855 - MinusLogProbMetric: 3.9855 - val_loss: 4.1958 - val_MinusLogProbMetric: 4.1958 - lr: 2.5000e-04 - 43s/epoch - 220ms/step
Epoch 202/1000
2023-09-17 08:19:48.843 
Epoch 202/1000 
	 loss: 3.9841, MinusLogProbMetric: 3.9841, val_loss: 4.1921, val_MinusLogProbMetric: 4.1921

Epoch 202: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9841 - MinusLogProbMetric: 3.9841 - val_loss: 4.1921 - val_MinusLogProbMetric: 4.1921 - lr: 2.5000e-04 - 43s/epoch - 219ms/step
Epoch 203/1000
2023-09-17 08:20:31.612 
Epoch 203/1000 
	 loss: 3.9875, MinusLogProbMetric: 3.9875, val_loss: 4.1917, val_MinusLogProbMetric: 4.1917

Epoch 203: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9875 - MinusLogProbMetric: 3.9875 - val_loss: 4.1917 - val_MinusLogProbMetric: 4.1917 - lr: 2.5000e-04 - 43s/epoch - 218ms/step
Epoch 204/1000
2023-09-17 08:21:14.827 
Epoch 204/1000 
	 loss: 3.9877, MinusLogProbMetric: 3.9877, val_loss: 4.2091, val_MinusLogProbMetric: 4.2091

Epoch 204: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9877 - MinusLogProbMetric: 3.9877 - val_loss: 4.2091 - val_MinusLogProbMetric: 4.2091 - lr: 2.5000e-04 - 43s/epoch - 220ms/step
Epoch 205/1000
2023-09-17 08:21:58.247 
Epoch 205/1000 
	 loss: 3.9833, MinusLogProbMetric: 3.9833, val_loss: 4.1986, val_MinusLogProbMetric: 4.1986

Epoch 205: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9833 - MinusLogProbMetric: 3.9833 - val_loss: 4.1986 - val_MinusLogProbMetric: 4.1986 - lr: 2.5000e-04 - 43s/epoch - 222ms/step
Epoch 206/1000
2023-09-17 08:22:41.390 
Epoch 206/1000 
	 loss: 3.9844, MinusLogProbMetric: 3.9844, val_loss: 4.2047, val_MinusLogProbMetric: 4.2047

Epoch 206: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9844 - MinusLogProbMetric: 3.9844 - val_loss: 4.2047 - val_MinusLogProbMetric: 4.2047 - lr: 2.5000e-04 - 43s/epoch - 220ms/step
Epoch 207/1000
2023-09-17 08:23:24.126 
Epoch 207/1000 
	 loss: 3.9858, MinusLogProbMetric: 3.9858, val_loss: 4.2047, val_MinusLogProbMetric: 4.2047

Epoch 207: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9858 - MinusLogProbMetric: 3.9858 - val_loss: 4.2047 - val_MinusLogProbMetric: 4.2047 - lr: 2.5000e-04 - 43s/epoch - 218ms/step
Epoch 208/1000
2023-09-17 08:24:06.923 
Epoch 208/1000 
	 loss: 3.9858, MinusLogProbMetric: 3.9858, val_loss: 4.2175, val_MinusLogProbMetric: 4.2175

Epoch 208: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9858 - MinusLogProbMetric: 3.9858 - val_loss: 4.2175 - val_MinusLogProbMetric: 4.2175 - lr: 2.5000e-04 - 43s/epoch - 218ms/step
Epoch 209/1000
2023-09-17 08:24:49.626 
Epoch 209/1000 
	 loss: 3.9848, MinusLogProbMetric: 3.9848, val_loss: 4.2024, val_MinusLogProbMetric: 4.2024

Epoch 209: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9848 - MinusLogProbMetric: 3.9848 - val_loss: 4.2024 - val_MinusLogProbMetric: 4.2024 - lr: 2.5000e-04 - 43s/epoch - 218ms/step
Epoch 210/1000
2023-09-17 08:25:32.673 
Epoch 210/1000 
	 loss: 3.9837, MinusLogProbMetric: 3.9837, val_loss: 4.2011, val_MinusLogProbMetric: 4.2011

Epoch 210: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9837 - MinusLogProbMetric: 3.9837 - val_loss: 4.2011 - val_MinusLogProbMetric: 4.2011 - lr: 2.5000e-04 - 43s/epoch - 220ms/step
Epoch 211/1000
2023-09-17 08:26:15.275 
Epoch 211/1000 
	 loss: 3.9823, MinusLogProbMetric: 3.9823, val_loss: 4.2015, val_MinusLogProbMetric: 4.2015

Epoch 211: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9823 - MinusLogProbMetric: 3.9823 - val_loss: 4.2015 - val_MinusLogProbMetric: 4.2015 - lr: 2.5000e-04 - 43s/epoch - 217ms/step
Epoch 212/1000
2023-09-17 08:26:57.988 
Epoch 212/1000 
	 loss: 3.9848, MinusLogProbMetric: 3.9848, val_loss: 4.2041, val_MinusLogProbMetric: 4.2041

Epoch 212: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9848 - MinusLogProbMetric: 3.9848 - val_loss: 4.2041 - val_MinusLogProbMetric: 4.2041 - lr: 2.5000e-04 - 43s/epoch - 218ms/step
Epoch 213/1000
2023-09-17 08:27:40.850 
Epoch 213/1000 
	 loss: 3.9843, MinusLogProbMetric: 3.9843, val_loss: 4.2061, val_MinusLogProbMetric: 4.2061

Epoch 213: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9843 - MinusLogProbMetric: 3.9843 - val_loss: 4.2061 - val_MinusLogProbMetric: 4.2061 - lr: 2.5000e-04 - 43s/epoch - 219ms/step
Epoch 214/1000
2023-09-17 08:28:24.035 
Epoch 214/1000 
	 loss: 3.9781, MinusLogProbMetric: 3.9781, val_loss: 4.2096, val_MinusLogProbMetric: 4.2096

Epoch 214: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9781 - MinusLogProbMetric: 3.9781 - val_loss: 4.2096 - val_MinusLogProbMetric: 4.2096 - lr: 2.5000e-04 - 43s/epoch - 220ms/step
Epoch 215/1000
2023-09-17 08:29:06.847 
Epoch 215/1000 
	 loss: 3.9821, MinusLogProbMetric: 3.9821, val_loss: 4.2047, val_MinusLogProbMetric: 4.2047

Epoch 215: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9821 - MinusLogProbMetric: 3.9821 - val_loss: 4.2047 - val_MinusLogProbMetric: 4.2047 - lr: 2.5000e-04 - 43s/epoch - 218ms/step
Epoch 216/1000
2023-09-17 08:29:49.873 
Epoch 216/1000 
	 loss: 3.9815, MinusLogProbMetric: 3.9815, val_loss: 4.2020, val_MinusLogProbMetric: 4.2020

Epoch 216: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9815 - MinusLogProbMetric: 3.9815 - val_loss: 4.2020 - val_MinusLogProbMetric: 4.2020 - lr: 2.5000e-04 - 43s/epoch - 219ms/step
Epoch 217/1000
2023-09-17 08:30:32.805 
Epoch 217/1000 
	 loss: 3.9794, MinusLogProbMetric: 3.9794, val_loss: 4.2126, val_MinusLogProbMetric: 4.2126

Epoch 217: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9794 - MinusLogProbMetric: 3.9794 - val_loss: 4.2126 - val_MinusLogProbMetric: 4.2126 - lr: 2.5000e-04 - 43s/epoch - 219ms/step
Epoch 218/1000
2023-09-17 08:31:16.182 
Epoch 218/1000 
	 loss: 3.9810, MinusLogProbMetric: 3.9810, val_loss: 4.2057, val_MinusLogProbMetric: 4.2057

Epoch 218: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9810 - MinusLogProbMetric: 3.9810 - val_loss: 4.2057 - val_MinusLogProbMetric: 4.2057 - lr: 2.5000e-04 - 43s/epoch - 221ms/step
Epoch 219/1000
2023-09-17 08:31:59.564 
Epoch 219/1000 
	 loss: 3.9809, MinusLogProbMetric: 3.9809, val_loss: 4.2472, val_MinusLogProbMetric: 4.2472

Epoch 219: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9809 - MinusLogProbMetric: 3.9809 - val_loss: 4.2472 - val_MinusLogProbMetric: 4.2472 - lr: 2.5000e-04 - 43s/epoch - 221ms/step
Epoch 220/1000
2023-09-17 08:32:42.657 
Epoch 220/1000 
	 loss: 3.9810, MinusLogProbMetric: 3.9810, val_loss: 4.2101, val_MinusLogProbMetric: 4.2101

Epoch 220: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9810 - MinusLogProbMetric: 3.9810 - val_loss: 4.2101 - val_MinusLogProbMetric: 4.2101 - lr: 2.5000e-04 - 43s/epoch - 220ms/step
Epoch 221/1000
2023-09-17 08:33:25.872 
Epoch 221/1000 
	 loss: 3.9813, MinusLogProbMetric: 3.9813, val_loss: 4.2036, val_MinusLogProbMetric: 4.2036

Epoch 221: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9813 - MinusLogProbMetric: 3.9813 - val_loss: 4.2036 - val_MinusLogProbMetric: 4.2036 - lr: 2.5000e-04 - 43s/epoch - 220ms/step
Epoch 222/1000
2023-09-17 08:34:08.859 
Epoch 222/1000 
	 loss: 3.9804, MinusLogProbMetric: 3.9804, val_loss: 4.2138, val_MinusLogProbMetric: 4.2138

Epoch 222: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9804 - MinusLogProbMetric: 3.9804 - val_loss: 4.2138 - val_MinusLogProbMetric: 4.2138 - lr: 2.5000e-04 - 43s/epoch - 219ms/step
Epoch 223/1000
2023-09-17 08:34:51.645 
Epoch 223/1000 
	 loss: 3.9766, MinusLogProbMetric: 3.9766, val_loss: 4.2138, val_MinusLogProbMetric: 4.2138

Epoch 223: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9766 - MinusLogProbMetric: 3.9766 - val_loss: 4.2138 - val_MinusLogProbMetric: 4.2138 - lr: 2.5000e-04 - 43s/epoch - 218ms/step
Epoch 224/1000
2023-09-17 08:35:34.498 
Epoch 224/1000 
	 loss: 3.9782, MinusLogProbMetric: 3.9782, val_loss: 4.2338, val_MinusLogProbMetric: 4.2338

Epoch 224: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9782 - MinusLogProbMetric: 3.9782 - val_loss: 4.2338 - val_MinusLogProbMetric: 4.2338 - lr: 2.5000e-04 - 43s/epoch - 219ms/step
Epoch 225/1000
2023-09-17 08:36:17.376 
Epoch 225/1000 
	 loss: 3.9798, MinusLogProbMetric: 3.9798, val_loss: 4.2147, val_MinusLogProbMetric: 4.2147

Epoch 225: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9798 - MinusLogProbMetric: 3.9798 - val_loss: 4.2147 - val_MinusLogProbMetric: 4.2147 - lr: 2.5000e-04 - 43s/epoch - 219ms/step
Epoch 226/1000
2023-09-17 08:37:00.618 
Epoch 226/1000 
	 loss: 3.9782, MinusLogProbMetric: 3.9782, val_loss: 4.2222, val_MinusLogProbMetric: 4.2222

Epoch 226: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9782 - MinusLogProbMetric: 3.9782 - val_loss: 4.2222 - val_MinusLogProbMetric: 4.2222 - lr: 2.5000e-04 - 43s/epoch - 221ms/step
Epoch 227/1000
2023-09-17 08:37:43.655 
Epoch 227/1000 
	 loss: 3.9823, MinusLogProbMetric: 3.9823, val_loss: 4.2101, val_MinusLogProbMetric: 4.2101

Epoch 227: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9823 - MinusLogProbMetric: 3.9823 - val_loss: 4.2101 - val_MinusLogProbMetric: 4.2101 - lr: 2.5000e-04 - 43s/epoch - 220ms/step
Epoch 228/1000
2023-09-17 08:38:26.488 
Epoch 228/1000 
	 loss: 3.9741, MinusLogProbMetric: 3.9741, val_loss: 4.2075, val_MinusLogProbMetric: 4.2075

Epoch 228: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9741 - MinusLogProbMetric: 3.9741 - val_loss: 4.2075 - val_MinusLogProbMetric: 4.2075 - lr: 2.5000e-04 - 43s/epoch - 219ms/step
Epoch 229/1000
2023-09-17 08:39:09.159 
Epoch 229/1000 
	 loss: 3.9742, MinusLogProbMetric: 3.9742, val_loss: 4.2061, val_MinusLogProbMetric: 4.2061

Epoch 229: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9742 - MinusLogProbMetric: 3.9742 - val_loss: 4.2061 - val_MinusLogProbMetric: 4.2061 - lr: 2.5000e-04 - 43s/epoch - 218ms/step
Epoch 230/1000
2023-09-17 08:39:51.954 
Epoch 230/1000 
	 loss: 3.9788, MinusLogProbMetric: 3.9788, val_loss: 4.2289, val_MinusLogProbMetric: 4.2289

Epoch 230: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9788 - MinusLogProbMetric: 3.9788 - val_loss: 4.2289 - val_MinusLogProbMetric: 4.2289 - lr: 2.5000e-04 - 43s/epoch - 218ms/step
Epoch 231/1000
2023-09-17 08:40:34.979 
Epoch 231/1000 
	 loss: 3.9791, MinusLogProbMetric: 3.9791, val_loss: 4.2126, val_MinusLogProbMetric: 4.2126

Epoch 231: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9791 - MinusLogProbMetric: 3.9791 - val_loss: 4.2126 - val_MinusLogProbMetric: 4.2126 - lr: 2.5000e-04 - 43s/epoch - 220ms/step
Epoch 232/1000
2023-09-17 08:41:18.150 
Epoch 232/1000 
	 loss: 3.9734, MinusLogProbMetric: 3.9734, val_loss: 4.2179, val_MinusLogProbMetric: 4.2179

Epoch 232: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9734 - MinusLogProbMetric: 3.9734 - val_loss: 4.2179 - val_MinusLogProbMetric: 4.2179 - lr: 2.5000e-04 - 43s/epoch - 220ms/step
Epoch 233/1000
2023-09-17 08:42:01.370 
Epoch 233/1000 
	 loss: 3.9772, MinusLogProbMetric: 3.9772, val_loss: 4.2148, val_MinusLogProbMetric: 4.2148

Epoch 233: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9772 - MinusLogProbMetric: 3.9772 - val_loss: 4.2148 - val_MinusLogProbMetric: 4.2148 - lr: 2.5000e-04 - 43s/epoch - 221ms/step
Epoch 234/1000
2023-09-17 08:42:44.191 
Epoch 234/1000 
	 loss: 3.9769, MinusLogProbMetric: 3.9769, val_loss: 4.2199, val_MinusLogProbMetric: 4.2199

Epoch 234: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9769 - MinusLogProbMetric: 3.9769 - val_loss: 4.2199 - val_MinusLogProbMetric: 4.2199 - lr: 2.5000e-04 - 43s/epoch - 218ms/step
Epoch 235/1000
2023-09-17 08:43:26.836 
Epoch 235/1000 
	 loss: 3.9755, MinusLogProbMetric: 3.9755, val_loss: 4.2293, val_MinusLogProbMetric: 4.2293

Epoch 235: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9755 - MinusLogProbMetric: 3.9755 - val_loss: 4.2293 - val_MinusLogProbMetric: 4.2293 - lr: 2.5000e-04 - 43s/epoch - 218ms/step
Epoch 236/1000
2023-09-17 08:44:09.634 
Epoch 236/1000 
	 loss: 3.9737, MinusLogProbMetric: 3.9737, val_loss: 4.2098, val_MinusLogProbMetric: 4.2098

Epoch 236: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9737 - MinusLogProbMetric: 3.9737 - val_loss: 4.2098 - val_MinusLogProbMetric: 4.2098 - lr: 2.5000e-04 - 43s/epoch - 218ms/step
Epoch 237/1000
2023-09-17 08:44:52.882 
Epoch 237/1000 
	 loss: 3.9758, MinusLogProbMetric: 3.9758, val_loss: 4.2119, val_MinusLogProbMetric: 4.2119

Epoch 237: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9758 - MinusLogProbMetric: 3.9758 - val_loss: 4.2119 - val_MinusLogProbMetric: 4.2119 - lr: 2.5000e-04 - 43s/epoch - 221ms/step
Epoch 238/1000
2023-09-17 08:45:36.260 
Epoch 238/1000 
	 loss: 3.9744, MinusLogProbMetric: 3.9744, val_loss: 4.2514, val_MinusLogProbMetric: 4.2514

Epoch 238: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9744 - MinusLogProbMetric: 3.9744 - val_loss: 4.2514 - val_MinusLogProbMetric: 4.2514 - lr: 2.5000e-04 - 43s/epoch - 221ms/step
Epoch 239/1000
2023-09-17 08:46:19.711 
Epoch 239/1000 
	 loss: 3.9739, MinusLogProbMetric: 3.9739, val_loss: 4.2403, val_MinusLogProbMetric: 4.2403

Epoch 239: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9739 - MinusLogProbMetric: 3.9739 - val_loss: 4.2403 - val_MinusLogProbMetric: 4.2403 - lr: 2.5000e-04 - 43s/epoch - 222ms/step
Epoch 240/1000
2023-09-17 08:47:03.792 
Epoch 240/1000 
	 loss: 3.9722, MinusLogProbMetric: 3.9722, val_loss: 4.2261, val_MinusLogProbMetric: 4.2261

Epoch 240: val_loss did not improve from 4.16122
196/196 - 44s - loss: 3.9722 - MinusLogProbMetric: 3.9722 - val_loss: 4.2261 - val_MinusLogProbMetric: 4.2261 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 241/1000
2023-09-17 08:47:47.462 
Epoch 241/1000 
	 loss: 3.9732, MinusLogProbMetric: 3.9732, val_loss: 4.2103, val_MinusLogProbMetric: 4.2103

Epoch 241: val_loss did not improve from 4.16122
196/196 - 44s - loss: 3.9732 - MinusLogProbMetric: 3.9732 - val_loss: 4.2103 - val_MinusLogProbMetric: 4.2103 - lr: 2.5000e-04 - 44s/epoch - 223ms/step
Epoch 242/1000
2023-09-17 08:48:31.432 
Epoch 242/1000 
	 loss: 3.9686, MinusLogProbMetric: 3.9686, val_loss: 4.2299, val_MinusLogProbMetric: 4.2299

Epoch 242: val_loss did not improve from 4.16122
196/196 - 44s - loss: 3.9686 - MinusLogProbMetric: 3.9686 - val_loss: 4.2299 - val_MinusLogProbMetric: 4.2299 - lr: 2.5000e-04 - 44s/epoch - 224ms/step
Epoch 243/1000
2023-09-17 08:49:14.717 
Epoch 243/1000 
	 loss: 3.9753, MinusLogProbMetric: 3.9753, val_loss: 4.2225, val_MinusLogProbMetric: 4.2225

Epoch 243: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9753 - MinusLogProbMetric: 3.9753 - val_loss: 4.2225 - val_MinusLogProbMetric: 4.2225 - lr: 2.5000e-04 - 43s/epoch - 221ms/step
Epoch 244/1000
2023-09-17 08:49:58.451 
Epoch 244/1000 
	 loss: 3.9730, MinusLogProbMetric: 3.9730, val_loss: 4.2341, val_MinusLogProbMetric: 4.2341

Epoch 244: val_loss did not improve from 4.16122
196/196 - 44s - loss: 3.9730 - MinusLogProbMetric: 3.9730 - val_loss: 4.2341 - val_MinusLogProbMetric: 4.2341 - lr: 2.5000e-04 - 44s/epoch - 223ms/step
Epoch 245/1000
2023-09-17 08:50:40.316 
Epoch 245/1000 
	 loss: 3.9717, MinusLogProbMetric: 3.9717, val_loss: 4.2767, val_MinusLogProbMetric: 4.2767

Epoch 245: val_loss did not improve from 4.16122
196/196 - 42s - loss: 3.9717 - MinusLogProbMetric: 3.9717 - val_loss: 4.2767 - val_MinusLogProbMetric: 4.2767 - lr: 2.5000e-04 - 42s/epoch - 214ms/step
Epoch 246/1000
2023-09-17 08:51:17.065 
Epoch 246/1000 
	 loss: 3.9732, MinusLogProbMetric: 3.9732, val_loss: 4.2246, val_MinusLogProbMetric: 4.2246

Epoch 246: val_loss did not improve from 4.16122
196/196 - 37s - loss: 3.9732 - MinusLogProbMetric: 3.9732 - val_loss: 4.2246 - val_MinusLogProbMetric: 4.2246 - lr: 2.5000e-04 - 37s/epoch - 187ms/step
Epoch 247/1000
2023-09-17 08:51:52.263 
Epoch 247/1000 
	 loss: 3.9726, MinusLogProbMetric: 3.9726, val_loss: 4.2312, val_MinusLogProbMetric: 4.2312

Epoch 247: val_loss did not improve from 4.16122
196/196 - 35s - loss: 3.9726 - MinusLogProbMetric: 3.9726 - val_loss: 4.2312 - val_MinusLogProbMetric: 4.2312 - lr: 2.5000e-04 - 35s/epoch - 180ms/step
Epoch 248/1000
2023-09-17 08:52:35.242 
Epoch 248/1000 
	 loss: 3.9677, MinusLogProbMetric: 3.9677, val_loss: 4.2309, val_MinusLogProbMetric: 4.2309

Epoch 248: val_loss did not improve from 4.16122
196/196 - 43s - loss: 3.9677 - MinusLogProbMetric: 3.9677 - val_loss: 4.2309 - val_MinusLogProbMetric: 4.2309 - lr: 2.5000e-04 - 43s/epoch - 219ms/step
Epoch 249/1000
2023-09-17 08:53:17.838 
Epoch 249/1000 
	 loss: 3.9718, MinusLogProbMetric: 3.9718, val_loss: 4.2473, val_MinusLogProbMetric: 4.2473

Epoch 249: val_loss did not improve from 4.16122
Restoring model weights from the end of the best epoch: 149.
196/196 - 43s - loss: 3.9718 - MinusLogProbMetric: 3.9718 - val_loss: 4.2473 - val_MinusLogProbMetric: 4.2473 - lr: 2.5000e-04 - 43s/epoch - 219ms/step
Epoch 249: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 15.759810274001211 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 8.46006766310893 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 5.735425070161 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fb1603dadd0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 17.473369849845767 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 7.014152121962979 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 5.094692096114159 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fb009e07370> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 520.
Model trained in 10820.29 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

Plots done in 17.48 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 101.04 s.
===========
Run 116/720 done in 10928.36 s.
===========

Directory ../../results/CsplineN_new/run_117/ already exists.
Skipping it.
===========
Run 117/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_118/ already exists.
Skipping it.
===========
Run 118/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_119/ already exists.
Skipping it.
===========
Run 119/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_120/ already exists.
Skipping it.
===========
Run 120/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_121/ already exists.
Skipping it.
===========
Run 121/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_122/ already exists.
Skipping it.
===========
Run 122/720 already exists. Skipping it.
===========

===========
Generating train data for run 123.
===========
Train data generated in 0.31 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 8)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_123/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 541}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_123/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.605106  ,  7.555199  ,  5.8969812 , ...,  6.0633097 ,
         4.213488  ,  7.9610686 ],
       [-0.03266917,  8.659664  ,  8.145809  , ...,  7.0603924 ,
         4.425395  ,  7.974749  ],
       [ 0.5810849 ,  8.428163  ,  7.7555046 , ...,  8.034664  ,
         4.659582  ,  7.758199  ],
       ...,
       [ 5.5784693 ,  7.232018  ,  6.224973  , ...,  6.3483973 ,
         3.7786217 ,  9.633856  ],
       [10.255534  ,  3.2266226 ,  7.9144135 , ...,  9.707513  ,
         1.5043423 , -0.24488598],
       [ 5.351089  ,  6.862731  ,  5.867759  , ...,  6.5452332 ,
         4.1859884 ,  9.183208  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_123/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_123
self.data_kwargs: {'seed': 541}
self.x_data: [[1.0149058  8.782051   8.494204   ... 6.942116   4.4473033  7.8108134 ]
 [0.29131094 8.416969   8.482672   ... 7.0929565  4.490889   7.841071  ]
 [0.17071505 9.477481   8.4464655  ... 8.11068    4.2243447  7.8915396 ]
 ...
 [9.377269   3.6923888  7.887424   ... 9.56523    0.750024   0.21164405]
 [0.4224009  8.317188   7.279487   ... 8.793006   4.708524   7.86607   ]
 [5.4228163  6.747814   6.187633   ... 6.2050085  4.0420876  8.511587  ]]
self.y_data: []
self.ndims: 8
Model defined.
Model: "model_83"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_84 (InputLayer)       [(None, 8)]               0         
                                                                 
 log_prob_layer_8 (LogProbLa  (None,)                  258620    
 yer)                                                            
                                                                 
=================================================================
Total params: 258,620
Trainable params: 258,620
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_8/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_8'")
self.model: <keras.engine.functional.Functional object at 0x7fb0bc30be80>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fafb5225ab0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fafb5225ab0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7faf84c9fd30>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fb0bc6b8220>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fb0bc6bac50>, <keras.callbacks.ModelCheckpoint object at 0x7fb0bc6b8880>, <keras.callbacks.EarlyStopping object at 0x7fb0bc6b91e0>, <keras.callbacks.ReduceLROnPlateau object at 0x7fb0bc6b8070>, <keras.callbacks.TerminateOnNaN object at 0x7fb0bc6ba8c0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.605106  ,  7.555199  ,  5.8969812 , ...,  6.0633097 ,
         4.213488  ,  7.9610686 ],
       [-0.03266917,  8.659664  ,  8.145809  , ...,  7.0603924 ,
         4.425395  ,  7.974749  ],
       [ 0.5810849 ,  8.428163  ,  7.7555046 , ...,  8.034664  ,
         4.659582  ,  7.758199  ],
       ...,
       [ 5.5784693 ,  7.232018  ,  6.224973  , ...,  6.3483973 ,
         3.7786217 ,  9.633856  ],
       [10.255534  ,  3.2266226 ,  7.9144135 , ...,  9.707513  ,
         1.5043423 , -0.24488598],
       [ 5.351089  ,  6.862731  ,  5.867759  , ...,  6.5452332 ,
         4.1859884 ,  9.183208  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_123/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 123/720 with hyperparameters:
timestamp = 2023-09-17 08:55:06.170077
ndims = 8
seed_train = 541
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 5
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 258620
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [1.0149058 8.782051  8.494204  8.708666  9.265548  6.942116  4.4473033
 7.8108134]
Epoch 1/1000
2023-09-17 08:57:12.100 
Epoch 1/1000 
	 loss: 10.5247, MinusLogProbMetric: 10.5247, val_loss: 5.7996, val_MinusLogProbMetric: 5.7996

Epoch 1: val_loss improved from inf to 5.79959, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 126s - loss: 10.5247 - MinusLogProbMetric: 10.5247 - val_loss: 5.7996 - val_MinusLogProbMetric: 5.7996 - lr: 0.0010 - 126s/epoch - 645ms/step
Epoch 2/1000
2023-09-17 08:57:56.271 
Epoch 2/1000 
	 loss: 5.5298, MinusLogProbMetric: 5.5298, val_loss: 6.0725, val_MinusLogProbMetric: 6.0725

Epoch 2: val_loss did not improve from 5.79959
196/196 - 43s - loss: 5.5298 - MinusLogProbMetric: 5.5298 - val_loss: 6.0725 - val_MinusLogProbMetric: 6.0725 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 3/1000
2023-09-17 08:58:39.785 
Epoch 3/1000 
	 loss: 5.3106, MinusLogProbMetric: 5.3106, val_loss: 5.1537, val_MinusLogProbMetric: 5.1537

Epoch 3: val_loss improved from 5.79959 to 5.15370, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 44s - loss: 5.3106 - MinusLogProbMetric: 5.3106 - val_loss: 5.1537 - val_MinusLogProbMetric: 5.1537 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 4/1000
2023-09-17 08:59:23.511 
Epoch 4/1000 
	 loss: 5.3434, MinusLogProbMetric: 5.3434, val_loss: 4.8535, val_MinusLogProbMetric: 4.8535

Epoch 4: val_loss improved from 5.15370 to 4.85353, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 44s - loss: 5.3434 - MinusLogProbMetric: 5.3434 - val_loss: 4.8535 - val_MinusLogProbMetric: 4.8535 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 5/1000
2023-09-17 09:00:07.762 
Epoch 5/1000 
	 loss: 4.9295, MinusLogProbMetric: 4.9295, val_loss: 4.7484, val_MinusLogProbMetric: 4.7484

Epoch 5: val_loss improved from 4.85353 to 4.74836, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 44s - loss: 4.9295 - MinusLogProbMetric: 4.9295 - val_loss: 4.7484 - val_MinusLogProbMetric: 4.7484 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 6/1000
2023-09-17 09:00:51.684 
Epoch 6/1000 
	 loss: 4.9298, MinusLogProbMetric: 4.9298, val_loss: 4.6958, val_MinusLogProbMetric: 4.6958

Epoch 6: val_loss improved from 4.74836 to 4.69581, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 44s - loss: 4.9298 - MinusLogProbMetric: 4.9298 - val_loss: 4.6958 - val_MinusLogProbMetric: 4.6958 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 7/1000
2023-09-17 09:01:35.950 
Epoch 7/1000 
	 loss: 4.7532, MinusLogProbMetric: 4.7532, val_loss: 4.9455, val_MinusLogProbMetric: 4.9455

Epoch 7: val_loss did not improve from 4.69581
196/196 - 44s - loss: 4.7532 - MinusLogProbMetric: 4.7532 - val_loss: 4.9455 - val_MinusLogProbMetric: 4.9455 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 8/1000
2023-09-17 09:02:19.255 
Epoch 8/1000 
	 loss: 4.8080, MinusLogProbMetric: 4.8080, val_loss: 4.9149, val_MinusLogProbMetric: 4.9149

Epoch 8: val_loss did not improve from 4.69581
196/196 - 43s - loss: 4.8080 - MinusLogProbMetric: 4.8080 - val_loss: 4.9149 - val_MinusLogProbMetric: 4.9149 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 9/1000
2023-09-17 09:03:02.731 
Epoch 9/1000 
	 loss: 4.7378, MinusLogProbMetric: 4.7378, val_loss: 4.5836, val_MinusLogProbMetric: 4.5836

Epoch 9: val_loss improved from 4.69581 to 4.58363, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 44s - loss: 4.7378 - MinusLogProbMetric: 4.7378 - val_loss: 4.5836 - val_MinusLogProbMetric: 4.5836 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 10/1000
2023-09-17 09:03:46.885 
Epoch 10/1000 
	 loss: 4.7486, MinusLogProbMetric: 4.7486, val_loss: 4.5592, val_MinusLogProbMetric: 4.5592

Epoch 10: val_loss improved from 4.58363 to 4.55919, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 44s - loss: 4.7486 - MinusLogProbMetric: 4.7486 - val_loss: 4.5592 - val_MinusLogProbMetric: 4.5592 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 11/1000
2023-09-17 09:04:31.009 
Epoch 11/1000 
	 loss: 4.6126, MinusLogProbMetric: 4.6126, val_loss: 5.4031, val_MinusLogProbMetric: 5.4031

Epoch 11: val_loss did not improve from 4.55919
196/196 - 43s - loss: 4.6126 - MinusLogProbMetric: 4.6126 - val_loss: 5.4031 - val_MinusLogProbMetric: 5.4031 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 12/1000
2023-09-17 09:05:14.434 
Epoch 12/1000 
	 loss: 4.6772, MinusLogProbMetric: 4.6772, val_loss: 4.9082, val_MinusLogProbMetric: 4.9082

Epoch 12: val_loss did not improve from 4.55919
196/196 - 43s - loss: 4.6772 - MinusLogProbMetric: 4.6772 - val_loss: 4.9082 - val_MinusLogProbMetric: 4.9082 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 13/1000
2023-09-17 09:05:57.502 
Epoch 13/1000 
	 loss: 4.5801, MinusLogProbMetric: 4.5801, val_loss: 4.3570, val_MinusLogProbMetric: 4.3570

Epoch 13: val_loss improved from 4.55919 to 4.35696, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 44s - loss: 4.5801 - MinusLogProbMetric: 4.5801 - val_loss: 4.3570 - val_MinusLogProbMetric: 4.3570 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 14/1000
2023-09-17 09:06:41.830 
Epoch 14/1000 
	 loss: 4.6258, MinusLogProbMetric: 4.6258, val_loss: 4.4885, val_MinusLogProbMetric: 4.4885

Epoch 14: val_loss did not improve from 4.35696
196/196 - 44s - loss: 4.6258 - MinusLogProbMetric: 4.6258 - val_loss: 4.4885 - val_MinusLogProbMetric: 4.4885 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 15/1000
2023-09-17 09:07:24.813 
Epoch 15/1000 
	 loss: 4.5372, MinusLogProbMetric: 4.5372, val_loss: 4.4529, val_MinusLogProbMetric: 4.4529

Epoch 15: val_loss did not improve from 4.35696
196/196 - 43s - loss: 4.5372 - MinusLogProbMetric: 4.5372 - val_loss: 4.4529 - val_MinusLogProbMetric: 4.4529 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 16/1000
2023-09-17 09:08:07.896 
Epoch 16/1000 
	 loss: 4.5254, MinusLogProbMetric: 4.5254, val_loss: 4.4045, val_MinusLogProbMetric: 4.4045

Epoch 16: val_loss did not improve from 4.35696
196/196 - 43s - loss: 4.5254 - MinusLogProbMetric: 4.5254 - val_loss: 4.4045 - val_MinusLogProbMetric: 4.4045 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 17/1000
2023-09-17 09:08:50.931 
Epoch 17/1000 
	 loss: 4.5319, MinusLogProbMetric: 4.5319, val_loss: 4.5069, val_MinusLogProbMetric: 4.5069

Epoch 17: val_loss did not improve from 4.35696
196/196 - 43s - loss: 4.5319 - MinusLogProbMetric: 4.5319 - val_loss: 4.5069 - val_MinusLogProbMetric: 4.5069 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 18/1000
2023-09-17 09:09:33.814 
Epoch 18/1000 
	 loss: 4.4535, MinusLogProbMetric: 4.4535, val_loss: 4.9041, val_MinusLogProbMetric: 4.9041

Epoch 18: val_loss did not improve from 4.35696
196/196 - 43s - loss: 4.4535 - MinusLogProbMetric: 4.4535 - val_loss: 4.9041 - val_MinusLogProbMetric: 4.9041 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 19/1000
2023-09-17 09:10:16.956 
Epoch 19/1000 
	 loss: 4.4954, MinusLogProbMetric: 4.4954, val_loss: 4.3898, val_MinusLogProbMetric: 4.3898

Epoch 19: val_loss did not improve from 4.35696
196/196 - 43s - loss: 4.4954 - MinusLogProbMetric: 4.4954 - val_loss: 4.3898 - val_MinusLogProbMetric: 4.3898 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 20/1000
2023-09-17 09:10:59.735 
Epoch 20/1000 
	 loss: 4.4284, MinusLogProbMetric: 4.4284, val_loss: 4.3046, val_MinusLogProbMetric: 4.3046

Epoch 20: val_loss improved from 4.35696 to 4.30460, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 44s - loss: 4.4284 - MinusLogProbMetric: 4.4284 - val_loss: 4.3046 - val_MinusLogProbMetric: 4.3046 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 21/1000
2023-09-17 09:11:44.033 
Epoch 21/1000 
	 loss: 4.4247, MinusLogProbMetric: 4.4247, val_loss: 4.3433, val_MinusLogProbMetric: 4.3433

Epoch 21: val_loss did not improve from 4.30460
196/196 - 43s - loss: 4.4247 - MinusLogProbMetric: 4.4247 - val_loss: 4.3433 - val_MinusLogProbMetric: 4.3433 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 22/1000
2023-09-17 09:12:27.263 
Epoch 22/1000 
	 loss: 4.3929, MinusLogProbMetric: 4.3929, val_loss: 4.3638, val_MinusLogProbMetric: 4.3638

Epoch 22: val_loss did not improve from 4.30460
196/196 - 43s - loss: 4.3929 - MinusLogProbMetric: 4.3929 - val_loss: 4.3638 - val_MinusLogProbMetric: 4.3638 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 23/1000
2023-09-17 09:13:10.796 
Epoch 23/1000 
	 loss: 4.4179, MinusLogProbMetric: 4.4179, val_loss: 4.3654, val_MinusLogProbMetric: 4.3654

Epoch 23: val_loss did not improve from 4.30460
196/196 - 44s - loss: 4.4179 - MinusLogProbMetric: 4.4179 - val_loss: 4.3654 - val_MinusLogProbMetric: 4.3654 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 24/1000
2023-09-17 09:13:54.354 
Epoch 24/1000 
	 loss: 4.3590, MinusLogProbMetric: 4.3590, val_loss: 4.2978, val_MinusLogProbMetric: 4.2978

Epoch 24: val_loss improved from 4.30460 to 4.29783, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 44s - loss: 4.3590 - MinusLogProbMetric: 4.3590 - val_loss: 4.2978 - val_MinusLogProbMetric: 4.2978 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 25/1000
2023-09-17 09:14:38.632 
Epoch 25/1000 
	 loss: 4.3895, MinusLogProbMetric: 4.3895, val_loss: 4.2901, val_MinusLogProbMetric: 4.2901

Epoch 25: val_loss improved from 4.29783 to 4.29013, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 44s - loss: 4.3895 - MinusLogProbMetric: 4.3895 - val_loss: 4.2901 - val_MinusLogProbMetric: 4.2901 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 26/1000
2023-09-17 09:15:22.516 
Epoch 26/1000 
	 loss: 4.3499, MinusLogProbMetric: 4.3499, val_loss: 4.3380, val_MinusLogProbMetric: 4.3380

Epoch 26: val_loss did not improve from 4.29013
196/196 - 43s - loss: 4.3499 - MinusLogProbMetric: 4.3499 - val_loss: 4.3380 - val_MinusLogProbMetric: 4.3380 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 27/1000
2023-09-17 09:16:05.894 
Epoch 27/1000 
	 loss: 4.3233, MinusLogProbMetric: 4.3233, val_loss: 4.4893, val_MinusLogProbMetric: 4.4893

Epoch 27: val_loss did not improve from 4.29013
196/196 - 43s - loss: 4.3233 - MinusLogProbMetric: 4.3233 - val_loss: 4.4893 - val_MinusLogProbMetric: 4.4893 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 28/1000
2023-09-17 09:16:49.061 
Epoch 28/1000 
	 loss: 4.3170, MinusLogProbMetric: 4.3170, val_loss: 4.3923, val_MinusLogProbMetric: 4.3923

Epoch 28: val_loss did not improve from 4.29013
196/196 - 43s - loss: 4.3170 - MinusLogProbMetric: 4.3170 - val_loss: 4.3923 - val_MinusLogProbMetric: 4.3923 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 29/1000
2023-09-17 09:17:32.391 
Epoch 29/1000 
	 loss: 4.3570, MinusLogProbMetric: 4.3570, val_loss: 4.3399, val_MinusLogProbMetric: 4.3399

Epoch 29: val_loss did not improve from 4.29013
196/196 - 43s - loss: 4.3570 - MinusLogProbMetric: 4.3570 - val_loss: 4.3399 - val_MinusLogProbMetric: 4.3399 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 30/1000
2023-09-17 09:18:15.424 
Epoch 30/1000 
	 loss: 4.3456, MinusLogProbMetric: 4.3456, val_loss: 4.3681, val_MinusLogProbMetric: 4.3681

Epoch 30: val_loss did not improve from 4.29013
196/196 - 43s - loss: 4.3456 - MinusLogProbMetric: 4.3456 - val_loss: 4.3681 - val_MinusLogProbMetric: 4.3681 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 31/1000
2023-09-17 09:18:58.180 
Epoch 31/1000 
	 loss: 4.3135, MinusLogProbMetric: 4.3135, val_loss: 4.2587, val_MinusLogProbMetric: 4.2587

Epoch 31: val_loss improved from 4.29013 to 4.25866, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 44s - loss: 4.3135 - MinusLogProbMetric: 4.3135 - val_loss: 4.2587 - val_MinusLogProbMetric: 4.2587 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 32/1000
2023-09-17 09:19:41.896 
Epoch 32/1000 
	 loss: 4.2947, MinusLogProbMetric: 4.2947, val_loss: 4.2615, val_MinusLogProbMetric: 4.2615

Epoch 32: val_loss did not improve from 4.25866
196/196 - 43s - loss: 4.2947 - MinusLogProbMetric: 4.2947 - val_loss: 4.2615 - val_MinusLogProbMetric: 4.2615 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 33/1000
2023-09-17 09:20:24.881 
Epoch 33/1000 
	 loss: 4.3040, MinusLogProbMetric: 4.3040, val_loss: 4.2026, val_MinusLogProbMetric: 4.2026

Epoch 33: val_loss improved from 4.25866 to 4.20256, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 44s - loss: 4.3040 - MinusLogProbMetric: 4.3040 - val_loss: 4.2026 - val_MinusLogProbMetric: 4.2026 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 34/1000
2023-09-17 09:21:08.915 
Epoch 34/1000 
	 loss: 4.2895, MinusLogProbMetric: 4.2895, val_loss: 4.4802, val_MinusLogProbMetric: 4.4802

Epoch 34: val_loss did not improve from 4.20256
196/196 - 43s - loss: 4.2895 - MinusLogProbMetric: 4.2895 - val_loss: 4.4802 - val_MinusLogProbMetric: 4.4802 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 35/1000
2023-09-17 09:21:52.112 
Epoch 35/1000 
	 loss: 4.2963, MinusLogProbMetric: 4.2963, val_loss: 4.2911, val_MinusLogProbMetric: 4.2911

Epoch 35: val_loss did not improve from 4.20256
196/196 - 43s - loss: 4.2963 - MinusLogProbMetric: 4.2963 - val_loss: 4.2911 - val_MinusLogProbMetric: 4.2911 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 36/1000
2023-09-17 09:22:35.179 
Epoch 36/1000 
	 loss: 4.2700, MinusLogProbMetric: 4.2700, val_loss: 4.4110, val_MinusLogProbMetric: 4.4110

Epoch 36: val_loss did not improve from 4.20256
196/196 - 43s - loss: 4.2700 - MinusLogProbMetric: 4.2700 - val_loss: 4.4110 - val_MinusLogProbMetric: 4.4110 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 37/1000
2023-09-17 09:23:18.094 
Epoch 37/1000 
	 loss: 4.2652, MinusLogProbMetric: 4.2652, val_loss: 4.3098, val_MinusLogProbMetric: 4.3098

Epoch 37: val_loss did not improve from 4.20256
196/196 - 43s - loss: 4.2652 - MinusLogProbMetric: 4.2652 - val_loss: 4.3098 - val_MinusLogProbMetric: 4.3098 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 38/1000
2023-09-17 09:24:00.665 
Epoch 38/1000 
	 loss: 4.2629, MinusLogProbMetric: 4.2629, val_loss: 4.3185, val_MinusLogProbMetric: 4.3185

Epoch 38: val_loss did not improve from 4.20256
196/196 - 43s - loss: 4.2629 - MinusLogProbMetric: 4.2629 - val_loss: 4.3185 - val_MinusLogProbMetric: 4.3185 - lr: 0.0010 - 43s/epoch - 217ms/step
Epoch 39/1000
2023-09-17 09:24:43.645 
Epoch 39/1000 
	 loss: 4.2468, MinusLogProbMetric: 4.2468, val_loss: 4.2192, val_MinusLogProbMetric: 4.2192

Epoch 39: val_loss did not improve from 4.20256
196/196 - 43s - loss: 4.2468 - MinusLogProbMetric: 4.2468 - val_loss: 4.2192 - val_MinusLogProbMetric: 4.2192 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 40/1000
2023-09-17 09:25:27.200 
Epoch 40/1000 
	 loss: 4.2586, MinusLogProbMetric: 4.2586, val_loss: 4.2897, val_MinusLogProbMetric: 4.2897

Epoch 40: val_loss did not improve from 4.20256
196/196 - 44s - loss: 4.2586 - MinusLogProbMetric: 4.2586 - val_loss: 4.2897 - val_MinusLogProbMetric: 4.2897 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 41/1000
2023-09-17 09:26:10.342 
Epoch 41/1000 
	 loss: 4.2457, MinusLogProbMetric: 4.2457, val_loss: 4.5143, val_MinusLogProbMetric: 4.5143

Epoch 41: val_loss did not improve from 4.20256
196/196 - 43s - loss: 4.2457 - MinusLogProbMetric: 4.2457 - val_loss: 4.5143 - val_MinusLogProbMetric: 4.5143 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 42/1000
2023-09-17 09:26:53.808 
Epoch 42/1000 
	 loss: 4.2574, MinusLogProbMetric: 4.2574, val_loss: 4.2961, val_MinusLogProbMetric: 4.2961

Epoch 42: val_loss did not improve from 4.20256
196/196 - 43s - loss: 4.2574 - MinusLogProbMetric: 4.2574 - val_loss: 4.2961 - val_MinusLogProbMetric: 4.2961 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 43/1000
2023-09-17 09:27:36.473 
Epoch 43/1000 
	 loss: 4.2333, MinusLogProbMetric: 4.2333, val_loss: 4.1793, val_MinusLogProbMetric: 4.1793

Epoch 43: val_loss improved from 4.20256 to 4.17933, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 43s - loss: 4.2333 - MinusLogProbMetric: 4.2333 - val_loss: 4.1793 - val_MinusLogProbMetric: 4.1793 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 44/1000
2023-09-17 09:28:20.394 
Epoch 44/1000 
	 loss: 4.2278, MinusLogProbMetric: 4.2278, val_loss: 4.2272, val_MinusLogProbMetric: 4.2272

Epoch 44: val_loss did not improve from 4.17933
196/196 - 43s - loss: 4.2278 - MinusLogProbMetric: 4.2278 - val_loss: 4.2272 - val_MinusLogProbMetric: 4.2272 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 45/1000
2023-09-17 09:29:03.798 
Epoch 45/1000 
	 loss: 4.2559, MinusLogProbMetric: 4.2559, val_loss: 4.4962, val_MinusLogProbMetric: 4.4962

Epoch 45: val_loss did not improve from 4.17933
196/196 - 43s - loss: 4.2559 - MinusLogProbMetric: 4.2559 - val_loss: 4.4962 - val_MinusLogProbMetric: 4.4962 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 46/1000
2023-09-17 09:29:46.310 
Epoch 46/1000 
	 loss: 4.2523, MinusLogProbMetric: 4.2523, val_loss: 4.4035, val_MinusLogProbMetric: 4.4035

Epoch 46: val_loss did not improve from 4.17933
196/196 - 43s - loss: 4.2523 - MinusLogProbMetric: 4.2523 - val_loss: 4.4035 - val_MinusLogProbMetric: 4.4035 - lr: 0.0010 - 43s/epoch - 217ms/step
Epoch 47/1000
2023-09-17 09:30:28.674 
Epoch 47/1000 
	 loss: 4.2237, MinusLogProbMetric: 4.2237, val_loss: 4.2804, val_MinusLogProbMetric: 4.2804

Epoch 47: val_loss did not improve from 4.17933
196/196 - 42s - loss: 4.2237 - MinusLogProbMetric: 4.2237 - val_loss: 4.2804 - val_MinusLogProbMetric: 4.2804 - lr: 0.0010 - 42s/epoch - 216ms/step
Epoch 48/1000
2023-09-17 09:31:12.410 
Epoch 48/1000 
	 loss: 4.2181, MinusLogProbMetric: 4.2181, val_loss: 4.1915, val_MinusLogProbMetric: 4.1915

Epoch 48: val_loss did not improve from 4.17933
196/196 - 44s - loss: 4.2181 - MinusLogProbMetric: 4.2181 - val_loss: 4.1915 - val_MinusLogProbMetric: 4.1915 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 49/1000
2023-09-17 09:31:55.143 
Epoch 49/1000 
	 loss: 4.2229, MinusLogProbMetric: 4.2229, val_loss: 4.2871, val_MinusLogProbMetric: 4.2871

Epoch 49: val_loss did not improve from 4.17933
196/196 - 43s - loss: 4.2229 - MinusLogProbMetric: 4.2229 - val_loss: 4.2871 - val_MinusLogProbMetric: 4.2871 - lr: 0.0010 - 43s/epoch - 218ms/step
Epoch 50/1000
2023-09-17 09:32:37.888 
Epoch 50/1000 
	 loss: 4.2273, MinusLogProbMetric: 4.2273, val_loss: 4.1925, val_MinusLogProbMetric: 4.1925

Epoch 50: val_loss did not improve from 4.17933
196/196 - 43s - loss: 4.2273 - MinusLogProbMetric: 4.2273 - val_loss: 4.1925 - val_MinusLogProbMetric: 4.1925 - lr: 0.0010 - 43s/epoch - 218ms/step
Epoch 51/1000
2023-09-17 09:33:20.615 
Epoch 51/1000 
	 loss: 4.2058, MinusLogProbMetric: 4.2058, val_loss: 4.3350, val_MinusLogProbMetric: 4.3350

Epoch 51: val_loss did not improve from 4.17933
196/196 - 43s - loss: 4.2058 - MinusLogProbMetric: 4.2058 - val_loss: 4.3350 - val_MinusLogProbMetric: 4.3350 - lr: 0.0010 - 43s/epoch - 218ms/step
Epoch 52/1000
2023-09-17 09:34:01.767 
Epoch 52/1000 
	 loss: 4.2352, MinusLogProbMetric: 4.2352, val_loss: 4.2001, val_MinusLogProbMetric: 4.2001

Epoch 52: val_loss did not improve from 4.17933
196/196 - 41s - loss: 4.2352 - MinusLogProbMetric: 4.2352 - val_loss: 4.2001 - val_MinusLogProbMetric: 4.2001 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 53/1000
2023-09-17 09:34:37.685 
Epoch 53/1000 
	 loss: 4.2125, MinusLogProbMetric: 4.2125, val_loss: 4.2317, val_MinusLogProbMetric: 4.2317

Epoch 53: val_loss did not improve from 4.17933
196/196 - 36s - loss: 4.2125 - MinusLogProbMetric: 4.2125 - val_loss: 4.2317 - val_MinusLogProbMetric: 4.2317 - lr: 0.0010 - 36s/epoch - 183ms/step
Epoch 54/1000
2023-09-17 09:35:13.430 
Epoch 54/1000 
	 loss: 4.2368, MinusLogProbMetric: 4.2368, val_loss: 4.3198, val_MinusLogProbMetric: 4.3198

Epoch 54: val_loss did not improve from 4.17933
196/196 - 36s - loss: 4.2368 - MinusLogProbMetric: 4.2368 - val_loss: 4.3198 - val_MinusLogProbMetric: 4.3198 - lr: 0.0010 - 36s/epoch - 182ms/step
Epoch 55/1000
2023-09-17 09:35:51.790 
Epoch 55/1000 
	 loss: 4.1926, MinusLogProbMetric: 4.1926, val_loss: 4.1781, val_MinusLogProbMetric: 4.1781

Epoch 55: val_loss improved from 4.17933 to 4.17806, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 39s - loss: 4.1926 - MinusLogProbMetric: 4.1926 - val_loss: 4.1781 - val_MinusLogProbMetric: 4.1781 - lr: 0.0010 - 39s/epoch - 200ms/step
Epoch 56/1000
2023-09-17 09:36:35.712 
Epoch 56/1000 
	 loss: 4.1954, MinusLogProbMetric: 4.1954, val_loss: 4.2384, val_MinusLogProbMetric: 4.2384

Epoch 56: val_loss did not improve from 4.17806
196/196 - 43s - loss: 4.1954 - MinusLogProbMetric: 4.1954 - val_loss: 4.2384 - val_MinusLogProbMetric: 4.2384 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 57/1000
2023-09-17 09:37:18.518 
Epoch 57/1000 
	 loss: 4.2167, MinusLogProbMetric: 4.2167, val_loss: 4.3207, val_MinusLogProbMetric: 4.3207

Epoch 57: val_loss did not improve from 4.17806
196/196 - 43s - loss: 4.2167 - MinusLogProbMetric: 4.2167 - val_loss: 4.3207 - val_MinusLogProbMetric: 4.3207 - lr: 0.0010 - 43s/epoch - 218ms/step
Epoch 58/1000
2023-09-17 09:38:02.011 
Epoch 58/1000 
	 loss: 4.2126, MinusLogProbMetric: 4.2126, val_loss: 4.2117, val_MinusLogProbMetric: 4.2117

Epoch 58: val_loss did not improve from 4.17806
196/196 - 43s - loss: 4.2126 - MinusLogProbMetric: 4.2126 - val_loss: 4.2117 - val_MinusLogProbMetric: 4.2117 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 59/1000
2023-09-17 09:38:45.725 
Epoch 59/1000 
	 loss: 4.1961, MinusLogProbMetric: 4.1961, val_loss: 4.1936, val_MinusLogProbMetric: 4.1936

Epoch 59: val_loss did not improve from 4.17806
196/196 - 44s - loss: 4.1961 - MinusLogProbMetric: 4.1961 - val_loss: 4.1936 - val_MinusLogProbMetric: 4.1936 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 60/1000
2023-09-17 09:39:29.616 
Epoch 60/1000 
	 loss: 4.1849, MinusLogProbMetric: 4.1849, val_loss: 4.2789, val_MinusLogProbMetric: 4.2789

Epoch 60: val_loss did not improve from 4.17806
196/196 - 44s - loss: 4.1849 - MinusLogProbMetric: 4.1849 - val_loss: 4.2789 - val_MinusLogProbMetric: 4.2789 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 61/1000
2023-09-17 09:40:13.265 
Epoch 61/1000 
	 loss: 4.1983, MinusLogProbMetric: 4.1983, val_loss: 4.2020, val_MinusLogProbMetric: 4.2020

Epoch 61: val_loss did not improve from 4.17806
196/196 - 44s - loss: 4.1983 - MinusLogProbMetric: 4.1983 - val_loss: 4.2020 - val_MinusLogProbMetric: 4.2020 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 62/1000
2023-09-17 09:40:57.362 
Epoch 62/1000 
	 loss: 4.1992, MinusLogProbMetric: 4.1992, val_loss: 4.2102, val_MinusLogProbMetric: 4.2102

Epoch 62: val_loss did not improve from 4.17806
196/196 - 44s - loss: 4.1992 - MinusLogProbMetric: 4.1992 - val_loss: 4.2102 - val_MinusLogProbMetric: 4.2102 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 63/1000
2023-09-17 09:41:40.870 
Epoch 63/1000 
	 loss: 4.1765, MinusLogProbMetric: 4.1765, val_loss: 4.2372, val_MinusLogProbMetric: 4.2372

Epoch 63: val_loss did not improve from 4.17806
196/196 - 44s - loss: 4.1765 - MinusLogProbMetric: 4.1765 - val_loss: 4.2372 - val_MinusLogProbMetric: 4.2372 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 64/1000
2023-09-17 09:42:24.119 
Epoch 64/1000 
	 loss: 4.1808, MinusLogProbMetric: 4.1808, val_loss: 4.1756, val_MinusLogProbMetric: 4.1756

Epoch 64: val_loss improved from 4.17806 to 4.17556, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 44s - loss: 4.1808 - MinusLogProbMetric: 4.1808 - val_loss: 4.1756 - val_MinusLogProbMetric: 4.1756 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 65/1000
2023-09-17 09:43:07.838 
Epoch 65/1000 
	 loss: 4.1663, MinusLogProbMetric: 4.1663, val_loss: 4.1894, val_MinusLogProbMetric: 4.1894

Epoch 65: val_loss did not improve from 4.17556
196/196 - 43s - loss: 4.1663 - MinusLogProbMetric: 4.1663 - val_loss: 4.1894 - val_MinusLogProbMetric: 4.1894 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 66/1000
2023-09-17 09:43:51.304 
Epoch 66/1000 
	 loss: 4.1731, MinusLogProbMetric: 4.1731, val_loss: 4.2377, val_MinusLogProbMetric: 4.2377

Epoch 66: val_loss did not improve from 4.17556
196/196 - 43s - loss: 4.1731 - MinusLogProbMetric: 4.1731 - val_loss: 4.2377 - val_MinusLogProbMetric: 4.2377 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 67/1000
2023-09-17 09:44:34.493 
Epoch 67/1000 
	 loss: 4.1722, MinusLogProbMetric: 4.1722, val_loss: 4.1625, val_MinusLogProbMetric: 4.1625

Epoch 67: val_loss improved from 4.17556 to 4.16252, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 44s - loss: 4.1722 - MinusLogProbMetric: 4.1722 - val_loss: 4.1625 - val_MinusLogProbMetric: 4.1625 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 68/1000
2023-09-17 09:45:18.501 
Epoch 68/1000 
	 loss: 4.1830, MinusLogProbMetric: 4.1830, val_loss: 4.3411, val_MinusLogProbMetric: 4.3411

Epoch 68: val_loss did not improve from 4.16252
196/196 - 43s - loss: 4.1830 - MinusLogProbMetric: 4.1830 - val_loss: 4.3411 - val_MinusLogProbMetric: 4.3411 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 69/1000
2023-09-17 09:46:01.975 
Epoch 69/1000 
	 loss: 4.1881, MinusLogProbMetric: 4.1881, val_loss: 4.2851, val_MinusLogProbMetric: 4.2851

Epoch 69: val_loss did not improve from 4.16252
196/196 - 43s - loss: 4.1881 - MinusLogProbMetric: 4.1881 - val_loss: 4.2851 - val_MinusLogProbMetric: 4.2851 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 70/1000
2023-09-17 09:46:45.393 
Epoch 70/1000 
	 loss: 4.1912, MinusLogProbMetric: 4.1912, val_loss: 4.2752, val_MinusLogProbMetric: 4.2752

Epoch 70: val_loss did not improve from 4.16252
196/196 - 43s - loss: 4.1912 - MinusLogProbMetric: 4.1912 - val_loss: 4.2752 - val_MinusLogProbMetric: 4.2752 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 71/1000
2023-09-17 09:47:28.751 
Epoch 71/1000 
	 loss: 4.1666, MinusLogProbMetric: 4.1666, val_loss: 4.2346, val_MinusLogProbMetric: 4.2346

Epoch 71: val_loss did not improve from 4.16252
196/196 - 43s - loss: 4.1666 - MinusLogProbMetric: 4.1666 - val_loss: 4.2346 - val_MinusLogProbMetric: 4.2346 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 72/1000
2023-09-17 09:48:12.309 
Epoch 72/1000 
	 loss: 4.1703, MinusLogProbMetric: 4.1703, val_loss: 4.2237, val_MinusLogProbMetric: 4.2237

Epoch 72: val_loss did not improve from 4.16252
196/196 - 44s - loss: 4.1703 - MinusLogProbMetric: 4.1703 - val_loss: 4.2237 - val_MinusLogProbMetric: 4.2237 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 73/1000
2023-09-17 09:48:55.480 
Epoch 73/1000 
	 loss: 4.1564, MinusLogProbMetric: 4.1564, val_loss: 4.1698, val_MinusLogProbMetric: 4.1698

Epoch 73: val_loss did not improve from 4.16252
196/196 - 43s - loss: 4.1564 - MinusLogProbMetric: 4.1564 - val_loss: 4.1698 - val_MinusLogProbMetric: 4.1698 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 74/1000
2023-09-17 09:49:39.007 
Epoch 74/1000 
	 loss: 4.1685, MinusLogProbMetric: 4.1685, val_loss: 4.1803, val_MinusLogProbMetric: 4.1803

Epoch 74: val_loss did not improve from 4.16252
196/196 - 44s - loss: 4.1685 - MinusLogProbMetric: 4.1685 - val_loss: 4.1803 - val_MinusLogProbMetric: 4.1803 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 75/1000
2023-09-17 09:50:22.065 
Epoch 75/1000 
	 loss: 4.1615, MinusLogProbMetric: 4.1615, val_loss: 4.2049, val_MinusLogProbMetric: 4.2049

Epoch 75: val_loss did not improve from 4.16252
196/196 - 43s - loss: 4.1615 - MinusLogProbMetric: 4.1615 - val_loss: 4.2049 - val_MinusLogProbMetric: 4.2049 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 76/1000
2023-09-17 09:51:05.630 
Epoch 76/1000 
	 loss: 4.1653, MinusLogProbMetric: 4.1653, val_loss: 4.1595, val_MinusLogProbMetric: 4.1595

Epoch 76: val_loss improved from 4.16252 to 4.15949, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 44s - loss: 4.1653 - MinusLogProbMetric: 4.1653 - val_loss: 4.1595 - val_MinusLogProbMetric: 4.1595 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 77/1000
2023-09-17 09:51:49.996 
Epoch 77/1000 
	 loss: 4.1569, MinusLogProbMetric: 4.1569, val_loss: 4.1876, val_MinusLogProbMetric: 4.1876

Epoch 77: val_loss did not improve from 4.15949
196/196 - 44s - loss: 4.1569 - MinusLogProbMetric: 4.1569 - val_loss: 4.1876 - val_MinusLogProbMetric: 4.1876 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 78/1000
2023-09-17 09:52:33.581 
Epoch 78/1000 
	 loss: 4.1579, MinusLogProbMetric: 4.1579, val_loss: 4.3164, val_MinusLogProbMetric: 4.3164

Epoch 78: val_loss did not improve from 4.15949
196/196 - 44s - loss: 4.1579 - MinusLogProbMetric: 4.1579 - val_loss: 4.3164 - val_MinusLogProbMetric: 4.3164 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 79/1000
2023-09-17 09:53:17.150 
Epoch 79/1000 
	 loss: 4.1833, MinusLogProbMetric: 4.1833, val_loss: 4.2439, val_MinusLogProbMetric: 4.2439

Epoch 79: val_loss did not improve from 4.15949
196/196 - 44s - loss: 4.1833 - MinusLogProbMetric: 4.1833 - val_loss: 4.2439 - val_MinusLogProbMetric: 4.2439 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 80/1000
2023-09-17 09:54:00.999 
Epoch 80/1000 
	 loss: 4.1639, MinusLogProbMetric: 4.1639, val_loss: 4.2284, val_MinusLogProbMetric: 4.2284

Epoch 80: val_loss did not improve from 4.15949
196/196 - 44s - loss: 4.1639 - MinusLogProbMetric: 4.1639 - val_loss: 4.2284 - val_MinusLogProbMetric: 4.2284 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 81/1000
2023-09-17 09:54:44.448 
Epoch 81/1000 
	 loss: 4.1606, MinusLogProbMetric: 4.1606, val_loss: 4.2272, val_MinusLogProbMetric: 4.2272

Epoch 81: val_loss did not improve from 4.15949
196/196 - 43s - loss: 4.1606 - MinusLogProbMetric: 4.1606 - val_loss: 4.2272 - val_MinusLogProbMetric: 4.2272 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 82/1000
2023-09-17 09:55:27.556 
Epoch 82/1000 
	 loss: 4.1595, MinusLogProbMetric: 4.1595, val_loss: 4.2292, val_MinusLogProbMetric: 4.2292

Epoch 82: val_loss did not improve from 4.15949
196/196 - 43s - loss: 4.1595 - MinusLogProbMetric: 4.1595 - val_loss: 4.2292 - val_MinusLogProbMetric: 4.2292 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 83/1000
2023-09-17 09:56:11.279 
Epoch 83/1000 
	 loss: 4.1476, MinusLogProbMetric: 4.1476, val_loss: 4.2077, val_MinusLogProbMetric: 4.2077

Epoch 83: val_loss did not improve from 4.15949
196/196 - 44s - loss: 4.1476 - MinusLogProbMetric: 4.1476 - val_loss: 4.2077 - val_MinusLogProbMetric: 4.2077 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 84/1000
2023-09-17 09:56:54.861 
Epoch 84/1000 
	 loss: 4.1626, MinusLogProbMetric: 4.1626, val_loss: 4.2432, val_MinusLogProbMetric: 4.2432

Epoch 84: val_loss did not improve from 4.15949
196/196 - 44s - loss: 4.1626 - MinusLogProbMetric: 4.1626 - val_loss: 4.2432 - val_MinusLogProbMetric: 4.2432 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 85/1000
2023-09-17 09:57:38.344 
Epoch 85/1000 
	 loss: 4.1567, MinusLogProbMetric: 4.1567, val_loss: 4.2435, val_MinusLogProbMetric: 4.2435

Epoch 85: val_loss did not improve from 4.15949
196/196 - 43s - loss: 4.1567 - MinusLogProbMetric: 4.1567 - val_loss: 4.2435 - val_MinusLogProbMetric: 4.2435 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 86/1000
2023-09-17 09:58:22.406 
Epoch 86/1000 
	 loss: 4.1516, MinusLogProbMetric: 4.1516, val_loss: 4.1571, val_MinusLogProbMetric: 4.1571

Epoch 86: val_loss improved from 4.15949 to 4.15711, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 45s - loss: 4.1516 - MinusLogProbMetric: 4.1516 - val_loss: 4.1571 - val_MinusLogProbMetric: 4.1571 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 87/1000
2023-09-17 09:59:06.749 
Epoch 87/1000 
	 loss: 4.1458, MinusLogProbMetric: 4.1458, val_loss: 4.3330, val_MinusLogProbMetric: 4.3330

Epoch 87: val_loss did not improve from 4.15711
196/196 - 44s - loss: 4.1458 - MinusLogProbMetric: 4.1458 - val_loss: 4.3330 - val_MinusLogProbMetric: 4.3330 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 88/1000
2023-09-17 09:59:50.049 
Epoch 88/1000 
	 loss: 4.1533, MinusLogProbMetric: 4.1533, val_loss: 4.2299, val_MinusLogProbMetric: 4.2299

Epoch 88: val_loss did not improve from 4.15711
196/196 - 43s - loss: 4.1533 - MinusLogProbMetric: 4.1533 - val_loss: 4.2299 - val_MinusLogProbMetric: 4.2299 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 89/1000
2023-09-17 10:00:33.359 
Epoch 89/1000 
	 loss: 4.1488, MinusLogProbMetric: 4.1488, val_loss: 4.2032, val_MinusLogProbMetric: 4.2032

Epoch 89: val_loss did not improve from 4.15711
196/196 - 43s - loss: 4.1488 - MinusLogProbMetric: 4.1488 - val_loss: 4.2032 - val_MinusLogProbMetric: 4.2032 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 90/1000
2023-09-17 10:01:16.546 
Epoch 90/1000 
	 loss: 4.1364, MinusLogProbMetric: 4.1364, val_loss: 4.2186, val_MinusLogProbMetric: 4.2186

Epoch 90: val_loss did not improve from 4.15711
196/196 - 43s - loss: 4.1364 - MinusLogProbMetric: 4.1364 - val_loss: 4.2186 - val_MinusLogProbMetric: 4.2186 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 91/1000
2023-09-17 10:01:59.511 
Epoch 91/1000 
	 loss: 4.1582, MinusLogProbMetric: 4.1582, val_loss: 4.1676, val_MinusLogProbMetric: 4.1676

Epoch 91: val_loss did not improve from 4.15711
196/196 - 43s - loss: 4.1582 - MinusLogProbMetric: 4.1582 - val_loss: 4.1676 - val_MinusLogProbMetric: 4.1676 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 92/1000
2023-09-17 10:02:43.019 
Epoch 92/1000 
	 loss: 4.1396, MinusLogProbMetric: 4.1396, val_loss: 4.2160, val_MinusLogProbMetric: 4.2160

Epoch 92: val_loss did not improve from 4.15711
196/196 - 44s - loss: 4.1396 - MinusLogProbMetric: 4.1396 - val_loss: 4.2160 - val_MinusLogProbMetric: 4.2160 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 93/1000
2023-09-17 10:03:26.592 
Epoch 93/1000 
	 loss: 4.1561, MinusLogProbMetric: 4.1561, val_loss: 4.1931, val_MinusLogProbMetric: 4.1931

Epoch 93: val_loss did not improve from 4.15711
196/196 - 44s - loss: 4.1561 - MinusLogProbMetric: 4.1561 - val_loss: 4.1931 - val_MinusLogProbMetric: 4.1931 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 94/1000
2023-09-17 10:04:10.475 
Epoch 94/1000 
	 loss: 4.1427, MinusLogProbMetric: 4.1427, val_loss: 4.2255, val_MinusLogProbMetric: 4.2255

Epoch 94: val_loss did not improve from 4.15711
196/196 - 44s - loss: 4.1427 - MinusLogProbMetric: 4.1427 - val_loss: 4.2255 - val_MinusLogProbMetric: 4.2255 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 95/1000
2023-09-17 10:04:53.843 
Epoch 95/1000 
	 loss: 4.1417, MinusLogProbMetric: 4.1417, val_loss: 4.3201, val_MinusLogProbMetric: 4.3201

Epoch 95: val_loss did not improve from 4.15711
196/196 - 43s - loss: 4.1417 - MinusLogProbMetric: 4.1417 - val_loss: 4.3201 - val_MinusLogProbMetric: 4.3201 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 96/1000
2023-09-17 10:05:37.620 
Epoch 96/1000 
	 loss: 4.1384, MinusLogProbMetric: 4.1384, val_loss: 4.2416, val_MinusLogProbMetric: 4.2416

Epoch 96: val_loss did not improve from 4.15711
196/196 - 44s - loss: 4.1384 - MinusLogProbMetric: 4.1384 - val_loss: 4.2416 - val_MinusLogProbMetric: 4.2416 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 97/1000
2023-09-17 10:06:20.827 
Epoch 97/1000 
	 loss: 4.1420, MinusLogProbMetric: 4.1420, val_loss: 4.3746, val_MinusLogProbMetric: 4.3746

Epoch 97: val_loss did not improve from 4.15711
196/196 - 43s - loss: 4.1420 - MinusLogProbMetric: 4.1420 - val_loss: 4.3746 - val_MinusLogProbMetric: 4.3746 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 98/1000
2023-09-17 10:07:04.527 
Epoch 98/1000 
	 loss: 4.1344, MinusLogProbMetric: 4.1344, val_loss: 4.2685, val_MinusLogProbMetric: 4.2685

Epoch 98: val_loss did not improve from 4.15711
196/196 - 44s - loss: 4.1344 - MinusLogProbMetric: 4.1344 - val_loss: 4.2685 - val_MinusLogProbMetric: 4.2685 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 99/1000
2023-09-17 10:07:48.190 
Epoch 99/1000 
	 loss: 4.1270, MinusLogProbMetric: 4.1270, val_loss: 4.1415, val_MinusLogProbMetric: 4.1415

Epoch 99: val_loss improved from 4.15711 to 4.14147, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 44s - loss: 4.1270 - MinusLogProbMetric: 4.1270 - val_loss: 4.1415 - val_MinusLogProbMetric: 4.1415 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 100/1000
2023-09-17 10:08:32.438 
Epoch 100/1000 
	 loss: 4.1349, MinusLogProbMetric: 4.1349, val_loss: 4.2044, val_MinusLogProbMetric: 4.2044

Epoch 100: val_loss did not improve from 4.14147
196/196 - 43s - loss: 4.1349 - MinusLogProbMetric: 4.1349 - val_loss: 4.2044 - val_MinusLogProbMetric: 4.2044 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 101/1000
2023-09-17 10:09:15.967 
Epoch 101/1000 
	 loss: 4.1432, MinusLogProbMetric: 4.1432, val_loss: 4.2854, val_MinusLogProbMetric: 4.2854

Epoch 101: val_loss did not improve from 4.14147
196/196 - 44s - loss: 4.1432 - MinusLogProbMetric: 4.1432 - val_loss: 4.2854 - val_MinusLogProbMetric: 4.2854 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 102/1000
2023-09-17 10:09:58.940 
Epoch 102/1000 
	 loss: 4.1279, MinusLogProbMetric: 4.1279, val_loss: 4.1642, val_MinusLogProbMetric: 4.1642

Epoch 102: val_loss did not improve from 4.14147
196/196 - 43s - loss: 4.1279 - MinusLogProbMetric: 4.1279 - val_loss: 4.1642 - val_MinusLogProbMetric: 4.1642 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 103/1000
2023-09-17 10:10:42.673 
Epoch 103/1000 
	 loss: 4.1312, MinusLogProbMetric: 4.1312, val_loss: 4.1756, val_MinusLogProbMetric: 4.1756

Epoch 103: val_loss did not improve from 4.14147
196/196 - 44s - loss: 4.1312 - MinusLogProbMetric: 4.1312 - val_loss: 4.1756 - val_MinusLogProbMetric: 4.1756 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 104/1000
2023-09-17 10:11:26.512 
Epoch 104/1000 
	 loss: 4.1258, MinusLogProbMetric: 4.1258, val_loss: 4.1504, val_MinusLogProbMetric: 4.1504

Epoch 104: val_loss did not improve from 4.14147
196/196 - 44s - loss: 4.1258 - MinusLogProbMetric: 4.1258 - val_loss: 4.1504 - val_MinusLogProbMetric: 4.1504 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 105/1000
2023-09-17 10:12:10.299 
Epoch 105/1000 
	 loss: 4.1329, MinusLogProbMetric: 4.1329, val_loss: 4.1893, val_MinusLogProbMetric: 4.1893

Epoch 105: val_loss did not improve from 4.14147
196/196 - 44s - loss: 4.1329 - MinusLogProbMetric: 4.1329 - val_loss: 4.1893 - val_MinusLogProbMetric: 4.1893 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 106/1000
2023-09-17 10:12:53.628 
Epoch 106/1000 
	 loss: 4.1252, MinusLogProbMetric: 4.1252, val_loss: 4.1784, val_MinusLogProbMetric: 4.1784

Epoch 106: val_loss did not improve from 4.14147
196/196 - 43s - loss: 4.1252 - MinusLogProbMetric: 4.1252 - val_loss: 4.1784 - val_MinusLogProbMetric: 4.1784 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 107/1000
2023-09-17 10:13:37.127 
Epoch 107/1000 
	 loss: 4.1439, MinusLogProbMetric: 4.1439, val_loss: 4.2609, val_MinusLogProbMetric: 4.2609

Epoch 107: val_loss did not improve from 4.14147
196/196 - 43s - loss: 4.1439 - MinusLogProbMetric: 4.1439 - val_loss: 4.2609 - val_MinusLogProbMetric: 4.2609 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 108/1000
2023-09-17 10:14:20.486 
Epoch 108/1000 
	 loss: 4.1333, MinusLogProbMetric: 4.1333, val_loss: 4.1437, val_MinusLogProbMetric: 4.1437

Epoch 108: val_loss did not improve from 4.14147
196/196 - 43s - loss: 4.1333 - MinusLogProbMetric: 4.1333 - val_loss: 4.1437 - val_MinusLogProbMetric: 4.1437 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 109/1000
2023-09-17 10:15:04.089 
Epoch 109/1000 
	 loss: 4.1318, MinusLogProbMetric: 4.1318, val_loss: 4.1434, val_MinusLogProbMetric: 4.1434

Epoch 109: val_loss did not improve from 4.14147
196/196 - 44s - loss: 4.1318 - MinusLogProbMetric: 4.1318 - val_loss: 4.1434 - val_MinusLogProbMetric: 4.1434 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 110/1000
2023-09-17 10:15:47.271 
Epoch 110/1000 
	 loss: 4.1162, MinusLogProbMetric: 4.1162, val_loss: 4.2272, val_MinusLogProbMetric: 4.2272

Epoch 110: val_loss did not improve from 4.14147
196/196 - 43s - loss: 4.1162 - MinusLogProbMetric: 4.1162 - val_loss: 4.2272 - val_MinusLogProbMetric: 4.2272 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 111/1000
2023-09-17 10:16:30.921 
Epoch 111/1000 
	 loss: 4.1346, MinusLogProbMetric: 4.1346, val_loss: 4.2185, val_MinusLogProbMetric: 4.2185

Epoch 111: val_loss did not improve from 4.14147
196/196 - 44s - loss: 4.1346 - MinusLogProbMetric: 4.1346 - val_loss: 4.2185 - val_MinusLogProbMetric: 4.2185 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 112/1000
2023-09-17 10:17:13.957 
Epoch 112/1000 
	 loss: 4.1216, MinusLogProbMetric: 4.1216, val_loss: 4.1875, val_MinusLogProbMetric: 4.1875

Epoch 112: val_loss did not improve from 4.14147
196/196 - 43s - loss: 4.1216 - MinusLogProbMetric: 4.1216 - val_loss: 4.1875 - val_MinusLogProbMetric: 4.1875 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 113/1000
2023-09-17 10:17:57.577 
Epoch 113/1000 
	 loss: 4.1263, MinusLogProbMetric: 4.1263, val_loss: 4.1648, val_MinusLogProbMetric: 4.1648

Epoch 113: val_loss did not improve from 4.14147
196/196 - 44s - loss: 4.1263 - MinusLogProbMetric: 4.1263 - val_loss: 4.1648 - val_MinusLogProbMetric: 4.1648 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 114/1000
2023-09-17 10:18:41.237 
Epoch 114/1000 
	 loss: 4.1089, MinusLogProbMetric: 4.1089, val_loss: 4.1755, val_MinusLogProbMetric: 4.1755

Epoch 114: val_loss did not improve from 4.14147
196/196 - 44s - loss: 4.1089 - MinusLogProbMetric: 4.1089 - val_loss: 4.1755 - val_MinusLogProbMetric: 4.1755 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 115/1000
2023-09-17 10:19:24.565 
Epoch 115/1000 
	 loss: 4.1237, MinusLogProbMetric: 4.1237, val_loss: 4.1819, val_MinusLogProbMetric: 4.1819

Epoch 115: val_loss did not improve from 4.14147
196/196 - 43s - loss: 4.1237 - MinusLogProbMetric: 4.1237 - val_loss: 4.1819 - val_MinusLogProbMetric: 4.1819 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 116/1000
2023-09-17 10:20:08.257 
Epoch 116/1000 
	 loss: 4.1285, MinusLogProbMetric: 4.1285, val_loss: 4.1412, val_MinusLogProbMetric: 4.1412

Epoch 116: val_loss improved from 4.14147 to 4.14116, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_123/weights/best_weights.h5
196/196 - 45s - loss: 4.1285 - MinusLogProbMetric: 4.1285 - val_loss: 4.1412 - val_MinusLogProbMetric: 4.1412 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 117/1000
2023-09-17 10:20:52.354 
Epoch 117/1000 
	 loss: 4.1163, MinusLogProbMetric: 4.1163, val_loss: 4.1803, val_MinusLogProbMetric: 4.1803

Epoch 117: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.1163 - MinusLogProbMetric: 4.1163 - val_loss: 4.1803 - val_MinusLogProbMetric: 4.1803 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 118/1000
2023-09-17 10:21:36.268 
Epoch 118/1000 
	 loss: 4.1224, MinusLogProbMetric: 4.1224, val_loss: 4.2086, val_MinusLogProbMetric: 4.2086

Epoch 118: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.1224 - MinusLogProbMetric: 4.1224 - val_loss: 4.2086 - val_MinusLogProbMetric: 4.2086 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 119/1000
2023-09-17 10:22:19.721 
Epoch 119/1000 
	 loss: 4.1103, MinusLogProbMetric: 4.1103, val_loss: 4.2123, val_MinusLogProbMetric: 4.2123

Epoch 119: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.1103 - MinusLogProbMetric: 4.1103 - val_loss: 4.2123 - val_MinusLogProbMetric: 4.2123 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 120/1000
2023-09-17 10:23:03.378 
Epoch 120/1000 
	 loss: 4.1118, MinusLogProbMetric: 4.1118, val_loss: 4.2237, val_MinusLogProbMetric: 4.2237

Epoch 120: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.1118 - MinusLogProbMetric: 4.1118 - val_loss: 4.2237 - val_MinusLogProbMetric: 4.2237 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 121/1000
2023-09-17 10:23:47.242 
Epoch 121/1000 
	 loss: 4.1137, MinusLogProbMetric: 4.1137, val_loss: 4.1668, val_MinusLogProbMetric: 4.1668

Epoch 121: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.1137 - MinusLogProbMetric: 4.1137 - val_loss: 4.1668 - val_MinusLogProbMetric: 4.1668 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 122/1000
2023-09-17 10:24:31.080 
Epoch 122/1000 
	 loss: 4.1087, MinusLogProbMetric: 4.1087, val_loss: 4.2481, val_MinusLogProbMetric: 4.2481

Epoch 122: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.1087 - MinusLogProbMetric: 4.1087 - val_loss: 4.2481 - val_MinusLogProbMetric: 4.2481 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 123/1000
2023-09-17 10:25:15.137 
Epoch 123/1000 
	 loss: 4.1032, MinusLogProbMetric: 4.1032, val_loss: 4.1569, val_MinusLogProbMetric: 4.1569

Epoch 123: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.1032 - MinusLogProbMetric: 4.1032 - val_loss: 4.1569 - val_MinusLogProbMetric: 4.1569 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 124/1000
2023-09-17 10:25:58.790 
Epoch 124/1000 
	 loss: 4.1083, MinusLogProbMetric: 4.1083, val_loss: 4.1719, val_MinusLogProbMetric: 4.1719

Epoch 124: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.1083 - MinusLogProbMetric: 4.1083 - val_loss: 4.1719 - val_MinusLogProbMetric: 4.1719 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 125/1000
2023-09-17 10:26:42.779 
Epoch 125/1000 
	 loss: 4.1193, MinusLogProbMetric: 4.1193, val_loss: 4.1588, val_MinusLogProbMetric: 4.1588

Epoch 125: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.1193 - MinusLogProbMetric: 4.1193 - val_loss: 4.1588 - val_MinusLogProbMetric: 4.1588 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 126/1000
2023-09-17 10:27:27.005 
Epoch 126/1000 
	 loss: 4.1121, MinusLogProbMetric: 4.1121, val_loss: 4.2328, val_MinusLogProbMetric: 4.2328

Epoch 126: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.1121 - MinusLogProbMetric: 4.1121 - val_loss: 4.2328 - val_MinusLogProbMetric: 4.2328 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 127/1000
2023-09-17 10:28:10.442 
Epoch 127/1000 
	 loss: 4.1036, MinusLogProbMetric: 4.1036, val_loss: 4.2080, val_MinusLogProbMetric: 4.2080

Epoch 127: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.1036 - MinusLogProbMetric: 4.1036 - val_loss: 4.2080 - val_MinusLogProbMetric: 4.2080 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 128/1000
2023-09-17 10:28:54.126 
Epoch 128/1000 
	 loss: 4.1056, MinusLogProbMetric: 4.1056, val_loss: 4.4325, val_MinusLogProbMetric: 4.4325

Epoch 128: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.1056 - MinusLogProbMetric: 4.1056 - val_loss: 4.4325 - val_MinusLogProbMetric: 4.4325 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 129/1000
2023-09-17 10:29:37.336 
Epoch 129/1000 
	 loss: 4.1197, MinusLogProbMetric: 4.1197, val_loss: 4.2044, val_MinusLogProbMetric: 4.2044

Epoch 129: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.1197 - MinusLogProbMetric: 4.1197 - val_loss: 4.2044 - val_MinusLogProbMetric: 4.2044 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 130/1000
2023-09-17 10:30:20.827 
Epoch 130/1000 
	 loss: 4.1105, MinusLogProbMetric: 4.1105, val_loss: 4.1625, val_MinusLogProbMetric: 4.1625

Epoch 130: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.1105 - MinusLogProbMetric: 4.1105 - val_loss: 4.1625 - val_MinusLogProbMetric: 4.1625 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 131/1000
2023-09-17 10:31:04.586 
Epoch 131/1000 
	 loss: 4.0963, MinusLogProbMetric: 4.0963, val_loss: 4.1699, val_MinusLogProbMetric: 4.1699

Epoch 131: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0963 - MinusLogProbMetric: 4.0963 - val_loss: 4.1699 - val_MinusLogProbMetric: 4.1699 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 132/1000
2023-09-17 10:31:48.522 
Epoch 132/1000 
	 loss: 4.0954, MinusLogProbMetric: 4.0954, val_loss: 4.1991, val_MinusLogProbMetric: 4.1991

Epoch 132: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0954 - MinusLogProbMetric: 4.0954 - val_loss: 4.1991 - val_MinusLogProbMetric: 4.1991 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 133/1000
2023-09-17 10:32:31.920 
Epoch 133/1000 
	 loss: 4.0983, MinusLogProbMetric: 4.0983, val_loss: 4.2651, val_MinusLogProbMetric: 4.2651

Epoch 133: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.0983 - MinusLogProbMetric: 4.0983 - val_loss: 4.2651 - val_MinusLogProbMetric: 4.2651 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 134/1000
2023-09-17 10:33:15.402 
Epoch 134/1000 
	 loss: 4.1087, MinusLogProbMetric: 4.1087, val_loss: 4.2407, val_MinusLogProbMetric: 4.2407

Epoch 134: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.1087 - MinusLogProbMetric: 4.1087 - val_loss: 4.2407 - val_MinusLogProbMetric: 4.2407 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 135/1000
2023-09-17 10:33:59.400 
Epoch 135/1000 
	 loss: 4.1159, MinusLogProbMetric: 4.1159, val_loss: 4.1651, val_MinusLogProbMetric: 4.1651

Epoch 135: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.1159 - MinusLogProbMetric: 4.1159 - val_loss: 4.1651 - val_MinusLogProbMetric: 4.1651 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 136/1000
2023-09-17 10:34:43.038 
Epoch 136/1000 
	 loss: 4.1067, MinusLogProbMetric: 4.1067, val_loss: 4.1654, val_MinusLogProbMetric: 4.1654

Epoch 136: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.1067 - MinusLogProbMetric: 4.1067 - val_loss: 4.1654 - val_MinusLogProbMetric: 4.1654 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 137/1000
2023-09-17 10:35:27.473 
Epoch 137/1000 
	 loss: 4.1144, MinusLogProbMetric: 4.1144, val_loss: 4.1487, val_MinusLogProbMetric: 4.1487

Epoch 137: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.1144 - MinusLogProbMetric: 4.1144 - val_loss: 4.1487 - val_MinusLogProbMetric: 4.1487 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 138/1000
2023-09-17 10:36:11.001 
Epoch 138/1000 
	 loss: 4.1055, MinusLogProbMetric: 4.1055, val_loss: 4.2230, val_MinusLogProbMetric: 4.2230

Epoch 138: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.1055 - MinusLogProbMetric: 4.1055 - val_loss: 4.2230 - val_MinusLogProbMetric: 4.2230 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 139/1000
2023-09-17 10:36:54.450 
Epoch 139/1000 
	 loss: 4.0994, MinusLogProbMetric: 4.0994, val_loss: 4.1847, val_MinusLogProbMetric: 4.1847

Epoch 139: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.0994 - MinusLogProbMetric: 4.0994 - val_loss: 4.1847 - val_MinusLogProbMetric: 4.1847 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 140/1000
2023-09-17 10:37:38.371 
Epoch 140/1000 
	 loss: 4.0958, MinusLogProbMetric: 4.0958, val_loss: 4.2297, val_MinusLogProbMetric: 4.2297

Epoch 140: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0958 - MinusLogProbMetric: 4.0958 - val_loss: 4.2297 - val_MinusLogProbMetric: 4.2297 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 141/1000
2023-09-17 10:38:22.235 
Epoch 141/1000 
	 loss: 4.0965, MinusLogProbMetric: 4.0965, val_loss: 4.1695, val_MinusLogProbMetric: 4.1695

Epoch 141: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0965 - MinusLogProbMetric: 4.0965 - val_loss: 4.1695 - val_MinusLogProbMetric: 4.1695 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 142/1000
2023-09-17 10:39:06.235 
Epoch 142/1000 
	 loss: 4.1036, MinusLogProbMetric: 4.1036, val_loss: 4.2968, val_MinusLogProbMetric: 4.2968

Epoch 142: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.1036 - MinusLogProbMetric: 4.1036 - val_loss: 4.2968 - val_MinusLogProbMetric: 4.2968 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 143/1000
2023-09-17 10:39:49.135 
Epoch 143/1000 
	 loss: 4.1095, MinusLogProbMetric: 4.1095, val_loss: 4.2443, val_MinusLogProbMetric: 4.2443

Epoch 143: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.1095 - MinusLogProbMetric: 4.1095 - val_loss: 4.2443 - val_MinusLogProbMetric: 4.2443 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 144/1000
2023-09-17 10:40:32.375 
Epoch 144/1000 
	 loss: 4.0948, MinusLogProbMetric: 4.0948, val_loss: 4.1977, val_MinusLogProbMetric: 4.1977

Epoch 144: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.0948 - MinusLogProbMetric: 4.0948 - val_loss: 4.1977 - val_MinusLogProbMetric: 4.1977 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 145/1000
2023-09-17 10:41:16.187 
Epoch 145/1000 
	 loss: 4.1090, MinusLogProbMetric: 4.1090, val_loss: 4.1853, val_MinusLogProbMetric: 4.1853

Epoch 145: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.1090 - MinusLogProbMetric: 4.1090 - val_loss: 4.1853 - val_MinusLogProbMetric: 4.1853 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 146/1000
2023-09-17 10:42:00.258 
Epoch 146/1000 
	 loss: 4.0935, MinusLogProbMetric: 4.0935, val_loss: 4.2280, val_MinusLogProbMetric: 4.2280

Epoch 146: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0935 - MinusLogProbMetric: 4.0935 - val_loss: 4.2280 - val_MinusLogProbMetric: 4.2280 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 147/1000
2023-09-17 10:42:44.200 
Epoch 147/1000 
	 loss: 4.1022, MinusLogProbMetric: 4.1022, val_loss: 4.2210, val_MinusLogProbMetric: 4.2210

Epoch 147: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.1022 - MinusLogProbMetric: 4.1022 - val_loss: 4.2210 - val_MinusLogProbMetric: 4.2210 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 148/1000
2023-09-17 10:43:28.203 
Epoch 148/1000 
	 loss: 4.0991, MinusLogProbMetric: 4.0991, val_loss: 4.2160, val_MinusLogProbMetric: 4.2160

Epoch 148: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0991 - MinusLogProbMetric: 4.0991 - val_loss: 4.2160 - val_MinusLogProbMetric: 4.2160 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 149/1000
2023-09-17 10:44:12.376 
Epoch 149/1000 
	 loss: 4.0976, MinusLogProbMetric: 4.0976, val_loss: 4.2084, val_MinusLogProbMetric: 4.2084

Epoch 149: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0976 - MinusLogProbMetric: 4.0976 - val_loss: 4.2084 - val_MinusLogProbMetric: 4.2084 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 150/1000
2023-09-17 10:44:56.588 
Epoch 150/1000 
	 loss: 4.0950, MinusLogProbMetric: 4.0950, val_loss: 4.1616, val_MinusLogProbMetric: 4.1616

Epoch 150: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0950 - MinusLogProbMetric: 4.0950 - val_loss: 4.1616 - val_MinusLogProbMetric: 4.1616 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 151/1000
2023-09-17 10:45:41.073 
Epoch 151/1000 
	 loss: 4.0985, MinusLogProbMetric: 4.0985, val_loss: 4.1694, val_MinusLogProbMetric: 4.1694

Epoch 151: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0985 - MinusLogProbMetric: 4.0985 - val_loss: 4.1694 - val_MinusLogProbMetric: 4.1694 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 152/1000
2023-09-17 10:46:25.248 
Epoch 152/1000 
	 loss: 4.0917, MinusLogProbMetric: 4.0917, val_loss: 4.1748, val_MinusLogProbMetric: 4.1748

Epoch 152: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0917 - MinusLogProbMetric: 4.0917 - val_loss: 4.1748 - val_MinusLogProbMetric: 4.1748 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 153/1000
2023-09-17 10:47:09.157 
Epoch 153/1000 
	 loss: 4.1011, MinusLogProbMetric: 4.1011, val_loss: 4.1639, val_MinusLogProbMetric: 4.1639

Epoch 153: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.1011 - MinusLogProbMetric: 4.1011 - val_loss: 4.1639 - val_MinusLogProbMetric: 4.1639 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 154/1000
2023-09-17 10:47:52.877 
Epoch 154/1000 
	 loss: 4.0852, MinusLogProbMetric: 4.0852, val_loss: 4.1631, val_MinusLogProbMetric: 4.1631

Epoch 154: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0852 - MinusLogProbMetric: 4.0852 - val_loss: 4.1631 - val_MinusLogProbMetric: 4.1631 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 155/1000
2023-09-17 10:48:36.750 
Epoch 155/1000 
	 loss: 4.0945, MinusLogProbMetric: 4.0945, val_loss: 4.1882, val_MinusLogProbMetric: 4.1882

Epoch 155: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0945 - MinusLogProbMetric: 4.0945 - val_loss: 4.1882 - val_MinusLogProbMetric: 4.1882 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 156/1000
2023-09-17 10:49:20.911 
Epoch 156/1000 
	 loss: 4.0951, MinusLogProbMetric: 4.0951, val_loss: 4.1780, val_MinusLogProbMetric: 4.1780

Epoch 156: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0951 - MinusLogProbMetric: 4.0951 - val_loss: 4.1780 - val_MinusLogProbMetric: 4.1780 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 157/1000
2023-09-17 10:50:04.813 
Epoch 157/1000 
	 loss: 4.0926, MinusLogProbMetric: 4.0926, val_loss: 4.2089, val_MinusLogProbMetric: 4.2089

Epoch 157: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0926 - MinusLogProbMetric: 4.0926 - val_loss: 4.2089 - val_MinusLogProbMetric: 4.2089 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 158/1000
2023-09-17 10:50:44.386 
Epoch 158/1000 
	 loss: 4.0963, MinusLogProbMetric: 4.0963, val_loss: 4.2621, val_MinusLogProbMetric: 4.2621

Epoch 158: val_loss did not improve from 4.14116
196/196 - 40s - loss: 4.0963 - MinusLogProbMetric: 4.0963 - val_loss: 4.2621 - val_MinusLogProbMetric: 4.2621 - lr: 0.0010 - 40s/epoch - 202ms/step
Epoch 159/1000
2023-09-17 10:51:24.769 
Epoch 159/1000 
	 loss: 4.1065, MinusLogProbMetric: 4.1065, val_loss: 4.1958, val_MinusLogProbMetric: 4.1958

Epoch 159: val_loss did not improve from 4.14116
196/196 - 40s - loss: 4.1065 - MinusLogProbMetric: 4.1065 - val_loss: 4.1958 - val_MinusLogProbMetric: 4.1958 - lr: 0.0010 - 40s/epoch - 206ms/step
Epoch 160/1000
2023-09-17 10:52:01.682 
Epoch 160/1000 
	 loss: 4.0879, MinusLogProbMetric: 4.0879, val_loss: 4.1626, val_MinusLogProbMetric: 4.1626

Epoch 160: val_loss did not improve from 4.14116
196/196 - 37s - loss: 4.0879 - MinusLogProbMetric: 4.0879 - val_loss: 4.1626 - val_MinusLogProbMetric: 4.1626 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 161/1000
2023-09-17 10:52:38.110 
Epoch 161/1000 
	 loss: 4.0941, MinusLogProbMetric: 4.0941, val_loss: 4.3208, val_MinusLogProbMetric: 4.3208

Epoch 161: val_loss did not improve from 4.14116
196/196 - 36s - loss: 4.0941 - MinusLogProbMetric: 4.0941 - val_loss: 4.3208 - val_MinusLogProbMetric: 4.3208 - lr: 0.0010 - 36s/epoch - 186ms/step
Epoch 162/1000
2023-09-17 10:53:16.946 
Epoch 162/1000 
	 loss: 4.0863, MinusLogProbMetric: 4.0863, val_loss: 4.1869, val_MinusLogProbMetric: 4.1869

Epoch 162: val_loss did not improve from 4.14116
196/196 - 39s - loss: 4.0863 - MinusLogProbMetric: 4.0863 - val_loss: 4.1869 - val_MinusLogProbMetric: 4.1869 - lr: 0.0010 - 39s/epoch - 198ms/step
Epoch 163/1000
2023-09-17 10:53:56.580 
Epoch 163/1000 
	 loss: 4.0857, MinusLogProbMetric: 4.0857, val_loss: 4.2411, val_MinusLogProbMetric: 4.2411

Epoch 163: val_loss did not improve from 4.14116
196/196 - 40s - loss: 4.0857 - MinusLogProbMetric: 4.0857 - val_loss: 4.2411 - val_MinusLogProbMetric: 4.2411 - lr: 0.0010 - 40s/epoch - 202ms/step
Epoch 164/1000
2023-09-17 10:54:37.970 
Epoch 164/1000 
	 loss: 4.0794, MinusLogProbMetric: 4.0794, val_loss: 4.1946, val_MinusLogProbMetric: 4.1946

Epoch 164: val_loss did not improve from 4.14116
196/196 - 41s - loss: 4.0794 - MinusLogProbMetric: 4.0794 - val_loss: 4.1946 - val_MinusLogProbMetric: 4.1946 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 165/1000
2023-09-17 10:55:19.953 
Epoch 165/1000 
	 loss: 4.0856, MinusLogProbMetric: 4.0856, val_loss: 4.1904, val_MinusLogProbMetric: 4.1904

Epoch 165: val_loss did not improve from 4.14116
196/196 - 42s - loss: 4.0856 - MinusLogProbMetric: 4.0856 - val_loss: 4.1904 - val_MinusLogProbMetric: 4.1904 - lr: 0.0010 - 42s/epoch - 214ms/step
Epoch 166/1000
2023-09-17 10:56:04.094 
Epoch 166/1000 
	 loss: 4.0832, MinusLogProbMetric: 4.0832, val_loss: 4.2551, val_MinusLogProbMetric: 4.2551

Epoch 166: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0832 - MinusLogProbMetric: 4.0832 - val_loss: 4.2551 - val_MinusLogProbMetric: 4.2551 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 167/1000
2023-09-17 10:56:48.400 
Epoch 167/1000 
	 loss: 4.0457, MinusLogProbMetric: 4.0457, val_loss: 4.1465, val_MinusLogProbMetric: 4.1465

Epoch 167: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0457 - MinusLogProbMetric: 4.0457 - val_loss: 4.1465 - val_MinusLogProbMetric: 4.1465 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 168/1000
2023-09-17 10:57:32.475 
Epoch 168/1000 
	 loss: 4.0380, MinusLogProbMetric: 4.0380, val_loss: 4.1505, val_MinusLogProbMetric: 4.1505

Epoch 168: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0380 - MinusLogProbMetric: 4.0380 - val_loss: 4.1505 - val_MinusLogProbMetric: 4.1505 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 169/1000
2023-09-17 10:58:16.683 
Epoch 169/1000 
	 loss: 4.0331, MinusLogProbMetric: 4.0331, val_loss: 4.1518, val_MinusLogProbMetric: 4.1518

Epoch 169: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0331 - MinusLogProbMetric: 4.0331 - val_loss: 4.1518 - val_MinusLogProbMetric: 4.1518 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 170/1000
2023-09-17 10:59:00.875 
Epoch 170/1000 
	 loss: 4.0318, MinusLogProbMetric: 4.0318, val_loss: 4.1512, val_MinusLogProbMetric: 4.1512

Epoch 170: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0318 - MinusLogProbMetric: 4.0318 - val_loss: 4.1512 - val_MinusLogProbMetric: 4.1512 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 171/1000
2023-09-17 10:59:44.846 
Epoch 171/1000 
	 loss: 4.0333, MinusLogProbMetric: 4.0333, val_loss: 4.2246, val_MinusLogProbMetric: 4.2246

Epoch 171: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0333 - MinusLogProbMetric: 4.0333 - val_loss: 4.2246 - val_MinusLogProbMetric: 4.2246 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 172/1000
2023-09-17 11:00:29.114 
Epoch 172/1000 
	 loss: 4.0345, MinusLogProbMetric: 4.0345, val_loss: 4.1596, val_MinusLogProbMetric: 4.1596

Epoch 172: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0345 - MinusLogProbMetric: 4.0345 - val_loss: 4.1596 - val_MinusLogProbMetric: 4.1596 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 173/1000
2023-09-17 11:01:13.684 
Epoch 173/1000 
	 loss: 4.0334, MinusLogProbMetric: 4.0334, val_loss: 4.2113, val_MinusLogProbMetric: 4.2113

Epoch 173: val_loss did not improve from 4.14116
196/196 - 45s - loss: 4.0334 - MinusLogProbMetric: 4.0334 - val_loss: 4.2113 - val_MinusLogProbMetric: 4.2113 - lr: 5.0000e-04 - 45s/epoch - 227ms/step
Epoch 174/1000
2023-09-17 11:01:58.349 
Epoch 174/1000 
	 loss: 4.0332, MinusLogProbMetric: 4.0332, val_loss: 4.1698, val_MinusLogProbMetric: 4.1698

Epoch 174: val_loss did not improve from 4.14116
196/196 - 45s - loss: 4.0332 - MinusLogProbMetric: 4.0332 - val_loss: 4.1698 - val_MinusLogProbMetric: 4.1698 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 175/1000
2023-09-17 11:02:43.092 
Epoch 175/1000 
	 loss: 4.0313, MinusLogProbMetric: 4.0313, val_loss: 4.1613, val_MinusLogProbMetric: 4.1613

Epoch 175: val_loss did not improve from 4.14116
196/196 - 45s - loss: 4.0313 - MinusLogProbMetric: 4.0313 - val_loss: 4.1613 - val_MinusLogProbMetric: 4.1613 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 176/1000
2023-09-17 11:03:27.786 
Epoch 176/1000 
	 loss: 4.0299, MinusLogProbMetric: 4.0299, val_loss: 4.1546, val_MinusLogProbMetric: 4.1546

Epoch 176: val_loss did not improve from 4.14116
196/196 - 45s - loss: 4.0299 - MinusLogProbMetric: 4.0299 - val_loss: 4.1546 - val_MinusLogProbMetric: 4.1546 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 177/1000
2023-09-17 11:04:12.522 
Epoch 177/1000 
	 loss: 4.0334, MinusLogProbMetric: 4.0334, val_loss: 4.2074, val_MinusLogProbMetric: 4.2074

Epoch 177: val_loss did not improve from 4.14116
196/196 - 45s - loss: 4.0334 - MinusLogProbMetric: 4.0334 - val_loss: 4.2074 - val_MinusLogProbMetric: 4.2074 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 178/1000
2023-09-17 11:04:56.715 
Epoch 178/1000 
	 loss: 4.0309, MinusLogProbMetric: 4.0309, val_loss: 4.1594, val_MinusLogProbMetric: 4.1594

Epoch 178: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0309 - MinusLogProbMetric: 4.0309 - val_loss: 4.1594 - val_MinusLogProbMetric: 4.1594 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 179/1000
2023-09-17 11:05:40.928 
Epoch 179/1000 
	 loss: 4.0290, MinusLogProbMetric: 4.0290, val_loss: 4.1605, val_MinusLogProbMetric: 4.1605

Epoch 179: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0290 - MinusLogProbMetric: 4.0290 - val_loss: 4.1605 - val_MinusLogProbMetric: 4.1605 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 180/1000
2023-09-17 11:06:25.268 
Epoch 180/1000 
	 loss: 4.0333, MinusLogProbMetric: 4.0333, val_loss: 4.1576, val_MinusLogProbMetric: 4.1576

Epoch 180: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0333 - MinusLogProbMetric: 4.0333 - val_loss: 4.1576 - val_MinusLogProbMetric: 4.1576 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 181/1000
2023-09-17 11:07:09.834 
Epoch 181/1000 
	 loss: 4.0359, MinusLogProbMetric: 4.0359, val_loss: 4.1780, val_MinusLogProbMetric: 4.1780

Epoch 181: val_loss did not improve from 4.14116
196/196 - 45s - loss: 4.0359 - MinusLogProbMetric: 4.0359 - val_loss: 4.1780 - val_MinusLogProbMetric: 4.1780 - lr: 5.0000e-04 - 45s/epoch - 227ms/step
Epoch 182/1000
2023-09-17 11:07:54.055 
Epoch 182/1000 
	 loss: 4.0275, MinusLogProbMetric: 4.0275, val_loss: 4.1730, val_MinusLogProbMetric: 4.1730

Epoch 182: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0275 - MinusLogProbMetric: 4.0275 - val_loss: 4.1730 - val_MinusLogProbMetric: 4.1730 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 183/1000
2023-09-17 11:08:38.308 
Epoch 183/1000 
	 loss: 4.0294, MinusLogProbMetric: 4.0294, val_loss: 4.1683, val_MinusLogProbMetric: 4.1683

Epoch 183: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0294 - MinusLogProbMetric: 4.0294 - val_loss: 4.1683 - val_MinusLogProbMetric: 4.1683 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 184/1000
2023-09-17 11:09:22.975 
Epoch 184/1000 
	 loss: 4.0322, MinusLogProbMetric: 4.0322, val_loss: 4.1810, val_MinusLogProbMetric: 4.1810

Epoch 184: val_loss did not improve from 4.14116
196/196 - 45s - loss: 4.0322 - MinusLogProbMetric: 4.0322 - val_loss: 4.1810 - val_MinusLogProbMetric: 4.1810 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 185/1000
2023-09-17 11:10:06.981 
Epoch 185/1000 
	 loss: 4.0325, MinusLogProbMetric: 4.0325, val_loss: 4.1640, val_MinusLogProbMetric: 4.1640

Epoch 185: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0325 - MinusLogProbMetric: 4.0325 - val_loss: 4.1640 - val_MinusLogProbMetric: 4.1640 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 186/1000
2023-09-17 11:10:50.744 
Epoch 186/1000 
	 loss: 4.0310, MinusLogProbMetric: 4.0310, val_loss: 4.1718, val_MinusLogProbMetric: 4.1718

Epoch 186: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0310 - MinusLogProbMetric: 4.0310 - val_loss: 4.1718 - val_MinusLogProbMetric: 4.1718 - lr: 5.0000e-04 - 44s/epoch - 223ms/step
Epoch 187/1000
2023-09-17 11:11:34.227 
Epoch 187/1000 
	 loss: 4.0263, MinusLogProbMetric: 4.0263, val_loss: 4.1814, val_MinusLogProbMetric: 4.1814

Epoch 187: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.0263 - MinusLogProbMetric: 4.0263 - val_loss: 4.1814 - val_MinusLogProbMetric: 4.1814 - lr: 5.0000e-04 - 43s/epoch - 222ms/step
Epoch 188/1000
2023-09-17 11:12:17.745 
Epoch 188/1000 
	 loss: 4.0329, MinusLogProbMetric: 4.0329, val_loss: 4.1765, val_MinusLogProbMetric: 4.1765

Epoch 188: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0329 - MinusLogProbMetric: 4.0329 - val_loss: 4.1765 - val_MinusLogProbMetric: 4.1765 - lr: 5.0000e-04 - 44s/epoch - 222ms/step
Epoch 189/1000
2023-09-17 11:12:59.466 
Epoch 189/1000 
	 loss: 4.0284, MinusLogProbMetric: 4.0284, val_loss: 4.1662, val_MinusLogProbMetric: 4.1662

Epoch 189: val_loss did not improve from 4.14116
196/196 - 42s - loss: 4.0284 - MinusLogProbMetric: 4.0284 - val_loss: 4.1662 - val_MinusLogProbMetric: 4.1662 - lr: 5.0000e-04 - 42s/epoch - 213ms/step
Epoch 190/1000
2023-09-17 11:13:39.218 
Epoch 190/1000 
	 loss: 4.0270, MinusLogProbMetric: 4.0270, val_loss: 4.1833, val_MinusLogProbMetric: 4.1833

Epoch 190: val_loss did not improve from 4.14116
196/196 - 40s - loss: 4.0270 - MinusLogProbMetric: 4.0270 - val_loss: 4.1833 - val_MinusLogProbMetric: 4.1833 - lr: 5.0000e-04 - 40s/epoch - 203ms/step
Epoch 191/1000
2023-09-17 11:14:13.995 
Epoch 191/1000 
	 loss: 4.0283, MinusLogProbMetric: 4.0283, val_loss: 4.1689, val_MinusLogProbMetric: 4.1689

Epoch 191: val_loss did not improve from 4.14116
196/196 - 35s - loss: 4.0283 - MinusLogProbMetric: 4.0283 - val_loss: 4.1689 - val_MinusLogProbMetric: 4.1689 - lr: 5.0000e-04 - 35s/epoch - 177ms/step
Epoch 192/1000
2023-09-17 11:14:48.136 
Epoch 192/1000 
	 loss: 4.0308, MinusLogProbMetric: 4.0308, val_loss: 4.1715, val_MinusLogProbMetric: 4.1715

Epoch 192: val_loss did not improve from 4.14116
196/196 - 34s - loss: 4.0308 - MinusLogProbMetric: 4.0308 - val_loss: 4.1715 - val_MinusLogProbMetric: 4.1715 - lr: 5.0000e-04 - 34s/epoch - 174ms/step
Epoch 193/1000
2023-09-17 11:15:23.562 
Epoch 193/1000 
	 loss: 4.0255, MinusLogProbMetric: 4.0255, val_loss: 4.1894, val_MinusLogProbMetric: 4.1894

Epoch 193: val_loss did not improve from 4.14116
196/196 - 35s - loss: 4.0255 - MinusLogProbMetric: 4.0255 - val_loss: 4.1894 - val_MinusLogProbMetric: 4.1894 - lr: 5.0000e-04 - 35s/epoch - 181ms/step
Epoch 194/1000
2023-09-17 11:16:04.115 
Epoch 194/1000 
	 loss: 4.0291, MinusLogProbMetric: 4.0291, val_loss: 4.1762, val_MinusLogProbMetric: 4.1762

Epoch 194: val_loss did not improve from 4.14116
196/196 - 41s - loss: 4.0291 - MinusLogProbMetric: 4.0291 - val_loss: 4.1762 - val_MinusLogProbMetric: 4.1762 - lr: 5.0000e-04 - 41s/epoch - 207ms/step
Epoch 195/1000
2023-09-17 11:16:47.653 
Epoch 195/1000 
	 loss: 4.0268, MinusLogProbMetric: 4.0268, val_loss: 4.1874, val_MinusLogProbMetric: 4.1874

Epoch 195: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0268 - MinusLogProbMetric: 4.0268 - val_loss: 4.1874 - val_MinusLogProbMetric: 4.1874 - lr: 5.0000e-04 - 44s/epoch - 222ms/step
Epoch 196/1000
2023-09-17 11:17:29.310 
Epoch 196/1000 
	 loss: 4.0271, MinusLogProbMetric: 4.0271, val_loss: 4.1827, val_MinusLogProbMetric: 4.1827

Epoch 196: val_loss did not improve from 4.14116
196/196 - 42s - loss: 4.0271 - MinusLogProbMetric: 4.0271 - val_loss: 4.1827 - val_MinusLogProbMetric: 4.1827 - lr: 5.0000e-04 - 42s/epoch - 213ms/step
Epoch 197/1000
2023-09-17 11:18:12.837 
Epoch 197/1000 
	 loss: 4.0239, MinusLogProbMetric: 4.0239, val_loss: 4.1694, val_MinusLogProbMetric: 4.1694

Epoch 197: val_loss did not improve from 4.14116
196/196 - 44s - loss: 4.0239 - MinusLogProbMetric: 4.0239 - val_loss: 4.1694 - val_MinusLogProbMetric: 4.1694 - lr: 5.0000e-04 - 44s/epoch - 222ms/step
Epoch 198/1000
2023-09-17 11:18:55.814 
Epoch 198/1000 
	 loss: 4.0219, MinusLogProbMetric: 4.0219, val_loss: 4.1687, val_MinusLogProbMetric: 4.1687

Epoch 198: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.0219 - MinusLogProbMetric: 4.0219 - val_loss: 4.1687 - val_MinusLogProbMetric: 4.1687 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 199/1000
2023-09-17 11:19:38.410 
Epoch 199/1000 
	 loss: 4.0289, MinusLogProbMetric: 4.0289, val_loss: 4.1640, val_MinusLogProbMetric: 4.1640

Epoch 199: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.0289 - MinusLogProbMetric: 4.0289 - val_loss: 4.1640 - val_MinusLogProbMetric: 4.1640 - lr: 5.0000e-04 - 43s/epoch - 217ms/step
Epoch 200/1000
2023-09-17 11:20:21.216 
Epoch 200/1000 
	 loss: 4.0203, MinusLogProbMetric: 4.0203, val_loss: 4.1757, val_MinusLogProbMetric: 4.1757

Epoch 200: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.0203 - MinusLogProbMetric: 4.0203 - val_loss: 4.1757 - val_MinusLogProbMetric: 4.1757 - lr: 5.0000e-04 - 43s/epoch - 218ms/step
Epoch 201/1000
2023-09-17 11:21:04.370 
Epoch 201/1000 
	 loss: 4.0248, MinusLogProbMetric: 4.0248, val_loss: 4.1923, val_MinusLogProbMetric: 4.1923

Epoch 201: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.0248 - MinusLogProbMetric: 4.0248 - val_loss: 4.1923 - val_MinusLogProbMetric: 4.1923 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 202/1000
2023-09-17 11:21:46.837 
Epoch 202/1000 
	 loss: 4.0249, MinusLogProbMetric: 4.0249, val_loss: 4.1750, val_MinusLogProbMetric: 4.1750

Epoch 202: val_loss did not improve from 4.14116
196/196 - 42s - loss: 4.0249 - MinusLogProbMetric: 4.0249 - val_loss: 4.1750 - val_MinusLogProbMetric: 4.1750 - lr: 5.0000e-04 - 42s/epoch - 217ms/step
Epoch 203/1000
2023-09-17 11:22:29.443 
Epoch 203/1000 
	 loss: 4.0272, MinusLogProbMetric: 4.0272, val_loss: 4.1685, val_MinusLogProbMetric: 4.1685

Epoch 203: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.0272 - MinusLogProbMetric: 4.0272 - val_loss: 4.1685 - val_MinusLogProbMetric: 4.1685 - lr: 5.0000e-04 - 43s/epoch - 217ms/step
Epoch 204/1000
2023-09-17 11:23:12.018 
Epoch 204/1000 
	 loss: 4.0220, MinusLogProbMetric: 4.0220, val_loss: 4.1945, val_MinusLogProbMetric: 4.1945

Epoch 204: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.0220 - MinusLogProbMetric: 4.0220 - val_loss: 4.1945 - val_MinusLogProbMetric: 4.1945 - lr: 5.0000e-04 - 43s/epoch - 217ms/step
Epoch 205/1000
2023-09-17 11:23:54.881 
Epoch 205/1000 
	 loss: 4.0231, MinusLogProbMetric: 4.0231, val_loss: 4.1834, val_MinusLogProbMetric: 4.1834

Epoch 205: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.0231 - MinusLogProbMetric: 4.0231 - val_loss: 4.1834 - val_MinusLogProbMetric: 4.1834 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 206/1000
2023-09-17 11:24:37.643 
Epoch 206/1000 
	 loss: 4.0219, MinusLogProbMetric: 4.0219, val_loss: 4.1742, val_MinusLogProbMetric: 4.1742

Epoch 206: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.0219 - MinusLogProbMetric: 4.0219 - val_loss: 4.1742 - val_MinusLogProbMetric: 4.1742 - lr: 5.0000e-04 - 43s/epoch - 218ms/step
Epoch 207/1000
2023-09-17 11:25:20.483 
Epoch 207/1000 
	 loss: 4.0181, MinusLogProbMetric: 4.0181, val_loss: 4.1752, val_MinusLogProbMetric: 4.1752

Epoch 207: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.0181 - MinusLogProbMetric: 4.0181 - val_loss: 4.1752 - val_MinusLogProbMetric: 4.1752 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 208/1000
2023-09-17 11:26:03.631 
Epoch 208/1000 
	 loss: 4.0195, MinusLogProbMetric: 4.0195, val_loss: 4.1954, val_MinusLogProbMetric: 4.1954

Epoch 208: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.0195 - MinusLogProbMetric: 4.0195 - val_loss: 4.1954 - val_MinusLogProbMetric: 4.1954 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 209/1000
2023-09-17 11:26:46.213 
Epoch 209/1000 
	 loss: 4.0239, MinusLogProbMetric: 4.0239, val_loss: 4.1712, val_MinusLogProbMetric: 4.1712

Epoch 209: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.0239 - MinusLogProbMetric: 4.0239 - val_loss: 4.1712 - val_MinusLogProbMetric: 4.1712 - lr: 5.0000e-04 - 43s/epoch - 217ms/step
Epoch 210/1000
2023-09-17 11:27:29.212 
Epoch 210/1000 
	 loss: 4.0190, MinusLogProbMetric: 4.0190, val_loss: 4.1940, val_MinusLogProbMetric: 4.1940

Epoch 210: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.0190 - MinusLogProbMetric: 4.0190 - val_loss: 4.1940 - val_MinusLogProbMetric: 4.1940 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 211/1000
2023-09-17 11:28:11.860 
Epoch 211/1000 
	 loss: 4.0178, MinusLogProbMetric: 4.0178, val_loss: 4.1719, val_MinusLogProbMetric: 4.1719

Epoch 211: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.0178 - MinusLogProbMetric: 4.0178 - val_loss: 4.1719 - val_MinusLogProbMetric: 4.1719 - lr: 5.0000e-04 - 43s/epoch - 218ms/step
Epoch 212/1000
2023-09-17 11:28:54.306 
Epoch 212/1000 
	 loss: 4.0196, MinusLogProbMetric: 4.0196, val_loss: 4.1747, val_MinusLogProbMetric: 4.1747

Epoch 212: val_loss did not improve from 4.14116
196/196 - 42s - loss: 4.0196 - MinusLogProbMetric: 4.0196 - val_loss: 4.1747 - val_MinusLogProbMetric: 4.1747 - lr: 5.0000e-04 - 42s/epoch - 217ms/step
Epoch 213/1000
2023-09-17 11:29:36.923 
Epoch 213/1000 
	 loss: 4.0197, MinusLogProbMetric: 4.0197, val_loss: 4.1711, val_MinusLogProbMetric: 4.1711

Epoch 213: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.0197 - MinusLogProbMetric: 4.0197 - val_loss: 4.1711 - val_MinusLogProbMetric: 4.1711 - lr: 5.0000e-04 - 43s/epoch - 217ms/step
Epoch 214/1000
2023-09-17 11:30:19.771 
Epoch 214/1000 
	 loss: 4.0157, MinusLogProbMetric: 4.0157, val_loss: 4.1778, val_MinusLogProbMetric: 4.1778

Epoch 214: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.0157 - MinusLogProbMetric: 4.0157 - val_loss: 4.1778 - val_MinusLogProbMetric: 4.1778 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 215/1000
2023-09-17 11:31:02.869 
Epoch 215/1000 
	 loss: 4.0221, MinusLogProbMetric: 4.0221, val_loss: 4.1812, val_MinusLogProbMetric: 4.1812

Epoch 215: val_loss did not improve from 4.14116
196/196 - 43s - loss: 4.0221 - MinusLogProbMetric: 4.0221 - val_loss: 4.1812 - val_MinusLogProbMetric: 4.1812 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 216/1000
2023-09-17 11:31:45.723 
Epoch 216/1000 
	 loss: 4.0198, MinusLogProbMetric: 4.0198, val_loss: 4.1840, val_MinusLogProbMetric: 4.1840

Epoch 216: val_loss did not improve from 4.14116
Restoring model weights from the end of the best epoch: 116.
196/196 - 43s - loss: 4.0198 - MinusLogProbMetric: 4.0198 - val_loss: 4.1840 - val_MinusLogProbMetric: 4.1840 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 216: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 13.003066488076001 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 8.011067059123889 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 5.365912324981764 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fb1dc67a710> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 14.62066687992774 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 7.080551862018183 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 5.025888124015182 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fae5cde1120> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 541.
Model trained in 9400.11 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

Plots done in 15.94 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 86.13 s.
===========
Run 123/720 done in 9492.69 s.
===========

Directory ../../results/CsplineN_new/run_124/ already exists.
Skipping it.
===========
Run 124/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_125/ already exists.
Skipping it.
===========
Run 125/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_126/ already exists.
Skipping it.
===========
Run 126/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_127/ already exists.
Skipping it.
===========
Run 127/720 already exists. Skipping it.
===========

===========
Generating train data for run 128.
===========
Train data generated in 0.24 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 8)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_128/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 541}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_128/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.605106  ,  7.555199  ,  5.8969812 , ...,  6.0633097 ,
         4.213488  ,  7.9610686 ],
       [-0.03266917,  8.659664  ,  8.145809  , ...,  7.0603924 ,
         4.425395  ,  7.974749  ],
       [ 0.5810849 ,  8.428163  ,  7.7555046 , ...,  8.034664  ,
         4.659582  ,  7.758199  ],
       ...,
       [ 5.5784693 ,  7.232018  ,  6.224973  , ...,  6.3483973 ,
         3.7786217 ,  9.633856  ],
       [10.255534  ,  3.2266226 ,  7.9144135 , ...,  9.707513  ,
         1.5043423 , -0.24488598],
       [ 5.351089  ,  6.862731  ,  5.867759  , ...,  6.5452332 ,
         4.1859884 ,  9.183208  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_128/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_128
self.data_kwargs: {'seed': 541}
self.x_data: [[1.0149058  8.782051   8.494204   ... 6.942116   4.4473033  7.8108134 ]
 [0.29131094 8.416969   8.482672   ... 7.0929565  4.490889   7.841071  ]
 [0.17071505 9.477481   8.4464655  ... 8.11068    4.2243447  7.8915396 ]
 ...
 [9.377269   3.6923888  7.887424   ... 9.56523    0.750024   0.21164405]
 [0.4224009  8.317188   7.279487   ... 8.793006   4.708524   7.86607   ]
 [5.4228163  6.747814   6.187633   ... 6.2050085  4.0420876  8.511587  ]]
self.y_data: []
self.ndims: 8
Model defined.
Model: "model_94"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_95 (InputLayer)       [(None, 8)]               0         
                                                                 
 log_prob_layer_9 (LogProbLa  (None,)                  1688440   
 yer)                                                            
                                                                 
=================================================================
Total params: 1,688,440
Trainable params: 1,688,440
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_9/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_9'")
self.model: <keras.engine.functional.Functional object at 0x7fae8c42b310>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7faeac36ce80>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7faeac36ce80>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fb648ee2e30>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fb05c764f10>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_128/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fb05c765480>, <keras.callbacks.ModelCheckpoint object at 0x7fb05c765540>, <keras.callbacks.EarlyStopping object at 0x7fb05c7657b0>, <keras.callbacks.ReduceLROnPlateau object at 0x7fb05c7657e0>, <keras.callbacks.TerminateOnNaN object at 0x7fb05c765420>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.605106  ,  7.555199  ,  5.8969812 , ...,  6.0633097 ,
         4.213488  ,  7.9610686 ],
       [-0.03266917,  8.659664  ,  8.145809  , ...,  7.0603924 ,
         4.425395  ,  7.974749  ],
       [ 0.5810849 ,  8.428163  ,  7.7555046 , ...,  8.034664  ,
         4.659582  ,  7.758199  ],
       ...,
       [ 5.5784693 ,  7.232018  ,  6.224973  , ...,  6.3483973 ,
         3.7786217 ,  9.633856  ],
       [10.255534  ,  3.2266226 ,  7.9144135 , ...,  9.707513  ,
         1.5043423 , -0.24488598],
       [ 5.351089  ,  6.862731  ,  5.867759  , ...,  6.5452332 ,
         4.1859884 ,  9.183208  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_128/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 128/720 with hyperparameters:
timestamp = 2023-09-17 11:33:24.079886
ndims = 8
seed_train = 541
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 1688440
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [1.0149058 8.782051  8.494204  8.708666  9.265548  6.942116  4.4473033
 7.8108134]
Epoch 1/1000
2023-09-17 11:37:49.892 
Epoch 1/1000 
	 loss: 14.3805, MinusLogProbMetric: 14.3805, val_loss: 7.0100, val_MinusLogProbMetric: 7.0100

Epoch 1: val_loss improved from inf to 7.01001, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_128/weights/best_weights.h5
196/196 - 267s - loss: 14.3805 - MinusLogProbMetric: 14.3805 - val_loss: 7.0100 - val_MinusLogProbMetric: 7.0100 - lr: 0.0010 - 267s/epoch - 1s/step
Epoch 2/1000
2023-09-17 11:39:15.497 
Epoch 2/1000 
	 loss: 7.3250, MinusLogProbMetric: 7.3250, val_loss: 6.0321, val_MinusLogProbMetric: 6.0321

Epoch 2: val_loss improved from 7.01001 to 6.03210, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_128/weights/best_weights.h5
196/196 - 85s - loss: 7.3250 - MinusLogProbMetric: 7.3250 - val_loss: 6.0321 - val_MinusLogProbMetric: 6.0321 - lr: 0.0010 - 85s/epoch - 435ms/step
Epoch 3/1000
2023-09-17 11:40:40.628 
Epoch 3/1000 
	 loss: 5.9904, MinusLogProbMetric: 5.9904, val_loss: 5.7586, val_MinusLogProbMetric: 5.7586

Epoch 3: val_loss improved from 6.03210 to 5.75862, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_128/weights/best_weights.h5
196/196 - 85s - loss: 5.9904 - MinusLogProbMetric: 5.9904 - val_loss: 5.7586 - val_MinusLogProbMetric: 5.7586 - lr: 0.0010 - 85s/epoch - 433ms/step
Epoch 4/1000
2023-09-17 11:42:05.798 
Epoch 4/1000 
	 loss: 5.5488, MinusLogProbMetric: 5.5488, val_loss: 5.1886, val_MinusLogProbMetric: 5.1886

Epoch 4: val_loss improved from 5.75862 to 5.18856, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_128/weights/best_weights.h5
196/196 - 85s - loss: 5.5488 - MinusLogProbMetric: 5.5488 - val_loss: 5.1886 - val_MinusLogProbMetric: 5.1886 - lr: 0.0010 - 85s/epoch - 434ms/step
Epoch 5/1000
2023-09-17 11:43:30.674 
Epoch 5/1000 
	 loss: 5.2937, MinusLogProbMetric: 5.2937, val_loss: 5.3329, val_MinusLogProbMetric: 5.3329

Epoch 5: val_loss did not improve from 5.18856
196/196 - 84s - loss: 5.2937 - MinusLogProbMetric: 5.2937 - val_loss: 5.3329 - val_MinusLogProbMetric: 5.3329 - lr: 0.0010 - 84s/epoch - 426ms/step
Epoch 6/1000
2023-09-17 11:44:53.367 
Epoch 6/1000 
	 loss: 5.1970, MinusLogProbMetric: 5.1970, val_loss: 4.7705, val_MinusLogProbMetric: 4.7705

Epoch 6: val_loss improved from 5.18856 to 4.77050, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_128/weights/best_weights.h5
196/196 - 84s - loss: 5.1970 - MinusLogProbMetric: 5.1970 - val_loss: 4.7705 - val_MinusLogProbMetric: 4.7705 - lr: 0.0010 - 84s/epoch - 429ms/step
Epoch 7/1000
2023-09-17 11:46:17.785 
Epoch 7/1000 
	 loss: 5.0379, MinusLogProbMetric: 5.0379, val_loss: 5.3698, val_MinusLogProbMetric: 5.3698

Epoch 7: val_loss did not improve from 4.77050
196/196 - 83s - loss: 5.0379 - MinusLogProbMetric: 5.0379 - val_loss: 5.3698 - val_MinusLogProbMetric: 5.3698 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 8/1000
2023-09-17 11:47:41.182 
Epoch 8/1000 
	 loss: 4.9798, MinusLogProbMetric: 4.9798, val_loss: 4.7520, val_MinusLogProbMetric: 4.7520

Epoch 8: val_loss improved from 4.77050 to 4.75199, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_128/weights/best_weights.h5
196/196 - 85s - loss: 4.9798 - MinusLogProbMetric: 4.9798 - val_loss: 4.7520 - val_MinusLogProbMetric: 4.7520 - lr: 0.0010 - 85s/epoch - 433ms/step
Epoch 9/1000
2023-09-17 11:49:06.166 
Epoch 9/1000 
	 loss: 4.8891, MinusLogProbMetric: 4.8891, val_loss: 5.1694, val_MinusLogProbMetric: 5.1694

Epoch 9: val_loss did not improve from 4.75199
196/196 - 84s - loss: 4.8891 - MinusLogProbMetric: 4.8891 - val_loss: 5.1694 - val_MinusLogProbMetric: 5.1694 - lr: 0.0010 - 84s/epoch - 426ms/step
Epoch 10/1000
2023-09-17 11:50:29.295 
Epoch 10/1000 
	 loss: 4.7929, MinusLogProbMetric: 4.7929, val_loss: 5.3204, val_MinusLogProbMetric: 5.3204

Epoch 10: val_loss did not improve from 4.75199
196/196 - 83s - loss: 4.7929 - MinusLogProbMetric: 4.7929 - val_loss: 5.3204 - val_MinusLogProbMetric: 5.3204 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 11/1000
2023-09-17 11:51:52.013 
Epoch 11/1000 
	 loss: 4.7412, MinusLogProbMetric: 4.7412, val_loss: 5.0615, val_MinusLogProbMetric: 5.0615

Epoch 11: val_loss did not improve from 4.75199
196/196 - 83s - loss: 4.7412 - MinusLogProbMetric: 4.7412 - val_loss: 5.0615 - val_MinusLogProbMetric: 5.0615 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 12/1000
2023-09-17 11:53:15.203 
Epoch 12/1000 
	 loss: 4.8587, MinusLogProbMetric: 4.8587, val_loss: 4.6492, val_MinusLogProbMetric: 4.6492

Epoch 12: val_loss improved from 4.75199 to 4.64917, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_128/weights/best_weights.h5
196/196 - 85s - loss: 4.8587 - MinusLogProbMetric: 4.8587 - val_loss: 4.6492 - val_MinusLogProbMetric: 4.6492 - lr: 0.0010 - 85s/epoch - 433ms/step
Epoch 13/1000
2023-09-17 11:54:39.857 
Epoch 13/1000 
	 loss: 4.7342, MinusLogProbMetric: 4.7342, val_loss: 4.6976, val_MinusLogProbMetric: 4.6976

Epoch 13: val_loss did not improve from 4.64917
196/196 - 83s - loss: 4.7342 - MinusLogProbMetric: 4.7342 - val_loss: 4.6976 - val_MinusLogProbMetric: 4.6976 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 14/1000
2023-09-17 11:56:03.051 
Epoch 14/1000 
	 loss: 4.6359, MinusLogProbMetric: 4.6359, val_loss: 4.5605, val_MinusLogProbMetric: 4.5605

Epoch 14: val_loss improved from 4.64917 to 4.56053, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_128/weights/best_weights.h5
196/196 - 85s - loss: 4.6359 - MinusLogProbMetric: 4.6359 - val_loss: 4.5605 - val_MinusLogProbMetric: 4.5605 - lr: 0.0010 - 85s/epoch - 432ms/step
Epoch 15/1000
2023-09-17 11:57:28.002 
Epoch 15/1000 
	 loss: 4.6371, MinusLogProbMetric: 4.6371, val_loss: 4.7025, val_MinusLogProbMetric: 4.7025

Epoch 15: val_loss did not improve from 4.56053
196/196 - 84s - loss: 4.6371 - MinusLogProbMetric: 4.6371 - val_loss: 4.7025 - val_MinusLogProbMetric: 4.7025 - lr: 0.0010 - 84s/epoch - 426ms/step
Epoch 16/1000
2023-09-17 11:58:51.238 
Epoch 16/1000 
	 loss: 4.5581, MinusLogProbMetric: 4.5581, val_loss: 4.4244, val_MinusLogProbMetric: 4.4244

Epoch 16: val_loss improved from 4.56053 to 4.42442, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_128/weights/best_weights.h5
196/196 - 85s - loss: 4.5581 - MinusLogProbMetric: 4.5581 - val_loss: 4.4244 - val_MinusLogProbMetric: 4.4244 - lr: 0.0010 - 85s/epoch - 432ms/step
Epoch 17/1000
2023-09-17 12:00:15.889 
Epoch 17/1000 
	 loss: 4.5100, MinusLogProbMetric: 4.5100, val_loss: 4.5322, val_MinusLogProbMetric: 4.5322

Epoch 17: val_loss did not improve from 4.42442
196/196 - 83s - loss: 4.5100 - MinusLogProbMetric: 4.5100 - val_loss: 4.5322 - val_MinusLogProbMetric: 4.5322 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 18/1000
2023-09-17 12:01:38.084 
Epoch 18/1000 
	 loss: 4.4716, MinusLogProbMetric: 4.4716, val_loss: 4.6021, val_MinusLogProbMetric: 4.6021

Epoch 18: val_loss did not improve from 4.42442
196/196 - 82s - loss: 4.4716 - MinusLogProbMetric: 4.4716 - val_loss: 4.6021 - val_MinusLogProbMetric: 4.6021 - lr: 0.0010 - 82s/epoch - 419ms/step
Epoch 19/1000
2023-09-17 12:03:01.436 
Epoch 19/1000 
	 loss: 4.4580, MinusLogProbMetric: 4.4580, val_loss: 4.4749, val_MinusLogProbMetric: 4.4749

Epoch 19: val_loss did not improve from 4.42442
196/196 - 83s - loss: 4.4580 - MinusLogProbMetric: 4.4580 - val_loss: 4.4749 - val_MinusLogProbMetric: 4.4749 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 20/1000
2023-09-17 12:04:24.495 
Epoch 20/1000 
	 loss: 4.4501, MinusLogProbMetric: 4.4501, val_loss: 4.6530, val_MinusLogProbMetric: 4.6530

Epoch 20: val_loss did not improve from 4.42442
196/196 - 83s - loss: 4.4501 - MinusLogProbMetric: 4.4501 - val_loss: 4.6530 - val_MinusLogProbMetric: 4.6530 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 21/1000
2023-09-17 12:05:47.482 
Epoch 21/1000 
	 loss: 4.4968, MinusLogProbMetric: 4.4968, val_loss: 4.4567, val_MinusLogProbMetric: 4.4567

Epoch 21: val_loss did not improve from 4.42442
196/196 - 83s - loss: 4.4968 - MinusLogProbMetric: 4.4968 - val_loss: 4.4567 - val_MinusLogProbMetric: 4.4567 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 22/1000
2023-09-17 12:07:10.837 
Epoch 22/1000 
	 loss: 4.4038, MinusLogProbMetric: 4.4038, val_loss: 4.2701, val_MinusLogProbMetric: 4.2701

Epoch 22: val_loss improved from 4.42442 to 4.27009, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_128/weights/best_weights.h5
196/196 - 85s - loss: 4.4038 - MinusLogProbMetric: 4.4038 - val_loss: 4.2701 - val_MinusLogProbMetric: 4.2701 - lr: 0.0010 - 85s/epoch - 434ms/step
Epoch 23/1000
2023-09-17 12:08:34.726 
Epoch 23/1000 
	 loss: 4.4449, MinusLogProbMetric: 4.4449, val_loss: 4.3719, val_MinusLogProbMetric: 4.3719

Epoch 23: val_loss did not improve from 4.27009
196/196 - 82s - loss: 4.4449 - MinusLogProbMetric: 4.4449 - val_loss: 4.3719 - val_MinusLogProbMetric: 4.3719 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 24/1000
2023-09-17 12:09:57.553 
Epoch 24/1000 
	 loss: 4.3721, MinusLogProbMetric: 4.3721, val_loss: 4.7203, val_MinusLogProbMetric: 4.7203

Epoch 24: val_loss did not improve from 4.27009
196/196 - 83s - loss: 4.3721 - MinusLogProbMetric: 4.3721 - val_loss: 4.7203 - val_MinusLogProbMetric: 4.7203 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 25/1000
2023-09-17 12:11:20.043 
Epoch 25/1000 
	 loss: 4.3866, MinusLogProbMetric: 4.3866, val_loss: 4.5658, val_MinusLogProbMetric: 4.5658

Epoch 25: val_loss did not improve from 4.27009
196/196 - 82s - loss: 4.3866 - MinusLogProbMetric: 4.3866 - val_loss: 4.5658 - val_MinusLogProbMetric: 4.5658 - lr: 0.0010 - 82s/epoch - 421ms/step
Epoch 26/1000
2023-09-17 12:12:42.743 
Epoch 26/1000 
	 loss: 4.3514, MinusLogProbMetric: 4.3514, val_loss: 4.6925, val_MinusLogProbMetric: 4.6925

Epoch 26: val_loss did not improve from 4.27009
196/196 - 83s - loss: 4.3514 - MinusLogProbMetric: 4.3514 - val_loss: 4.6925 - val_MinusLogProbMetric: 4.6925 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 27/1000
2023-09-17 12:14:05.045 
Epoch 27/1000 
	 loss: 4.3701, MinusLogProbMetric: 4.3701, val_loss: 4.3435, val_MinusLogProbMetric: 4.3435

Epoch 27: val_loss did not improve from 4.27009
196/196 - 82s - loss: 4.3701 - MinusLogProbMetric: 4.3701 - val_loss: 4.3435 - val_MinusLogProbMetric: 4.3435 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 28/1000
2023-09-17 12:15:28.661 
Epoch 28/1000 
	 loss: 4.3162, MinusLogProbMetric: 4.3162, val_loss: 4.2951, val_MinusLogProbMetric: 4.2951

Epoch 28: val_loss did not improve from 4.27009
196/196 - 84s - loss: 4.3162 - MinusLogProbMetric: 4.3162 - val_loss: 4.2951 - val_MinusLogProbMetric: 4.2951 - lr: 0.0010 - 84s/epoch - 427ms/step
Epoch 29/1000
2023-09-17 12:16:50.917 
Epoch 29/1000 
	 loss: 4.2977, MinusLogProbMetric: 4.2977, val_loss: 4.4222, val_MinusLogProbMetric: 4.4222

Epoch 29: val_loss did not improve from 4.27009
196/196 - 82s - loss: 4.2977 - MinusLogProbMetric: 4.2977 - val_loss: 4.4222 - val_MinusLogProbMetric: 4.4222 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 30/1000
2023-09-17 12:18:13.389 
Epoch 30/1000 
	 loss: 4.3312, MinusLogProbMetric: 4.3312, val_loss: 4.4821, val_MinusLogProbMetric: 4.4821

Epoch 30: val_loss did not improve from 4.27009
196/196 - 82s - loss: 4.3312 - MinusLogProbMetric: 4.3312 - val_loss: 4.4821 - val_MinusLogProbMetric: 4.4821 - lr: 0.0010 - 82s/epoch - 421ms/step
Epoch 31/1000
2023-09-17 12:19:35.904 
Epoch 31/1000 
	 loss: 4.2856, MinusLogProbMetric: 4.2856, val_loss: 4.3057, val_MinusLogProbMetric: 4.3057

Epoch 31: val_loss did not improve from 4.27009
196/196 - 83s - loss: 4.2856 - MinusLogProbMetric: 4.2856 - val_loss: 4.3057 - val_MinusLogProbMetric: 4.3057 - lr: 0.0010 - 83s/epoch - 421ms/step
Epoch 32/1000
2023-09-17 12:20:58.891 
Epoch 32/1000 
	 loss: 4.3617, MinusLogProbMetric: 4.3617, val_loss: 4.4117, val_MinusLogProbMetric: 4.4117

Epoch 32: val_loss did not improve from 4.27009
196/196 - 83s - loss: 4.3617 - MinusLogProbMetric: 4.3617 - val_loss: 4.4117 - val_MinusLogProbMetric: 4.4117 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 33/1000
2023-09-17 12:22:22.185 
Epoch 33/1000 
	 loss: 4.2953, MinusLogProbMetric: 4.2953, val_loss: 4.2353, val_MinusLogProbMetric: 4.2353

Epoch 33: val_loss improved from 4.27009 to 4.23527, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_128/weights/best_weights.h5
196/196 - 85s - loss: 4.2953 - MinusLogProbMetric: 4.2953 - val_loss: 4.2353 - val_MinusLogProbMetric: 4.2353 - lr: 0.0010 - 85s/epoch - 434ms/step
Epoch 34/1000
2023-09-17 12:23:47.802 
Epoch 34/1000 
	 loss: 4.3012, MinusLogProbMetric: 4.3012, val_loss: 4.4627, val_MinusLogProbMetric: 4.4627

Epoch 34: val_loss did not improve from 4.23527
196/196 - 84s - loss: 4.3012 - MinusLogProbMetric: 4.3012 - val_loss: 4.4627 - val_MinusLogProbMetric: 4.4627 - lr: 0.0010 - 84s/epoch - 427ms/step
Epoch 35/1000
2023-09-17 12:25:10.902 
Epoch 35/1000 
	 loss: 4.2909, MinusLogProbMetric: 4.2909, val_loss: 4.3280, val_MinusLogProbMetric: 4.3280

Epoch 35: val_loss did not improve from 4.23527
196/196 - 83s - loss: 4.2909 - MinusLogProbMetric: 4.2909 - val_loss: 4.3280 - val_MinusLogProbMetric: 4.3280 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 36/1000
2023-09-17 12:26:31.017 
Epoch 36/1000 
	 loss: 4.2849, MinusLogProbMetric: 4.2849, val_loss: 4.4285, val_MinusLogProbMetric: 4.4285

Epoch 36: val_loss did not improve from 4.23527
196/196 - 80s - loss: 4.2849 - MinusLogProbMetric: 4.2849 - val_loss: 4.4285 - val_MinusLogProbMetric: 4.4285 - lr: 0.0010 - 80s/epoch - 409ms/step
Epoch 37/1000
2023-09-17 12:27:42.295 
Epoch 37/1000 
	 loss: 4.2707, MinusLogProbMetric: 4.2707, val_loss: 4.1998, val_MinusLogProbMetric: 4.1998

Epoch 37: val_loss improved from 4.23527 to 4.19982, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_128/weights/best_weights.h5
196/196 - 73s - loss: 4.2707 - MinusLogProbMetric: 4.2707 - val_loss: 4.1998 - val_MinusLogProbMetric: 4.1998 - lr: 0.0010 - 73s/epoch - 372ms/step
Epoch 38/1000
2023-09-17 12:29:04.713 
Epoch 38/1000 
	 loss: 4.2539, MinusLogProbMetric: 4.2539, val_loss: 4.3457, val_MinusLogProbMetric: 4.3457

Epoch 38: val_loss did not improve from 4.19982
196/196 - 81s - loss: 4.2539 - MinusLogProbMetric: 4.2539 - val_loss: 4.3457 - val_MinusLogProbMetric: 4.3457 - lr: 0.0010 - 81s/epoch - 413ms/step
Epoch 39/1000
2023-09-17 12:30:27.695 
Epoch 39/1000 
	 loss: 4.2466, MinusLogProbMetric: 4.2466, val_loss: 4.2785, val_MinusLogProbMetric: 4.2785

Epoch 39: val_loss did not improve from 4.19982
196/196 - 83s - loss: 4.2466 - MinusLogProbMetric: 4.2466 - val_loss: 4.2785 - val_MinusLogProbMetric: 4.2785 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 40/1000
2023-09-17 12:31:49.522 
Epoch 40/1000 
	 loss: 4.2759, MinusLogProbMetric: 4.2759, val_loss: 4.2169, val_MinusLogProbMetric: 4.2169

Epoch 40: val_loss did not improve from 4.19982
196/196 - 82s - loss: 4.2759 - MinusLogProbMetric: 4.2759 - val_loss: 4.2169 - val_MinusLogProbMetric: 4.2169 - lr: 0.0010 - 82s/epoch - 417ms/step
Epoch 41/1000
2023-09-17 12:33:13.101 
Epoch 41/1000 
	 loss: 4.2352, MinusLogProbMetric: 4.2352, val_loss: 4.3320, val_MinusLogProbMetric: 4.3320

Epoch 41: val_loss did not improve from 4.19982
196/196 - 84s - loss: 4.2352 - MinusLogProbMetric: 4.2352 - val_loss: 4.3320 - val_MinusLogProbMetric: 4.3320 - lr: 0.0010 - 84s/epoch - 426ms/step
Epoch 42/1000
2023-09-17 12:34:35.855 
Epoch 42/1000 
	 loss: 4.2500, MinusLogProbMetric: 4.2500, val_loss: 4.3405, val_MinusLogProbMetric: 4.3405

Epoch 42: val_loss did not improve from 4.19982
196/196 - 83s - loss: 4.2500 - MinusLogProbMetric: 4.2500 - val_loss: 4.3405 - val_MinusLogProbMetric: 4.3405 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 43/1000
2023-09-17 12:35:59.442 
Epoch 43/1000 
	 loss: 4.2456, MinusLogProbMetric: 4.2456, val_loss: 4.2447, val_MinusLogProbMetric: 4.2447

Epoch 43: val_loss did not improve from 4.19982
196/196 - 84s - loss: 4.2456 - MinusLogProbMetric: 4.2456 - val_loss: 4.2447 - val_MinusLogProbMetric: 4.2447 - lr: 0.0010 - 84s/epoch - 426ms/step
Epoch 44/1000
2023-09-17 12:37:22.202 
Epoch 44/1000 
	 loss: 4.2117, MinusLogProbMetric: 4.2117, val_loss: 4.2947, val_MinusLogProbMetric: 4.2947

Epoch 44: val_loss did not improve from 4.19982
196/196 - 83s - loss: 4.2117 - MinusLogProbMetric: 4.2117 - val_loss: 4.2947 - val_MinusLogProbMetric: 4.2947 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 45/1000
2023-09-17 12:38:44.610 
Epoch 45/1000 
	 loss: 4.2185, MinusLogProbMetric: 4.2185, val_loss: 4.2504, val_MinusLogProbMetric: 4.2504

Epoch 45: val_loss did not improve from 4.19982
196/196 - 82s - loss: 4.2185 - MinusLogProbMetric: 4.2185 - val_loss: 4.2504 - val_MinusLogProbMetric: 4.2504 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 46/1000
2023-09-17 12:40:06.960 
Epoch 46/1000 
	 loss: 4.2213, MinusLogProbMetric: 4.2213, val_loss: 4.3481, val_MinusLogProbMetric: 4.3481

Epoch 46: val_loss did not improve from 4.19982
196/196 - 82s - loss: 4.2213 - MinusLogProbMetric: 4.2213 - val_loss: 4.3481 - val_MinusLogProbMetric: 4.3481 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 47/1000
2023-09-17 12:41:29.692 
Epoch 47/1000 
	 loss: 4.2054, MinusLogProbMetric: 4.2054, val_loss: 4.4147, val_MinusLogProbMetric: 4.4147

Epoch 47: val_loss did not improve from 4.19982
196/196 - 83s - loss: 4.2054 - MinusLogProbMetric: 4.2054 - val_loss: 4.4147 - val_MinusLogProbMetric: 4.4147 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 48/1000
2023-09-17 12:42:52.368 
Epoch 48/1000 
	 loss: 4.2168, MinusLogProbMetric: 4.2168, val_loss: 4.2058, val_MinusLogProbMetric: 4.2058

Epoch 48: val_loss did not improve from 4.19982
196/196 - 83s - loss: 4.2168 - MinusLogProbMetric: 4.2168 - val_loss: 4.2058 - val_MinusLogProbMetric: 4.2058 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 49/1000
2023-09-17 12:44:15.905 
Epoch 49/1000 
	 loss: 4.2038, MinusLogProbMetric: 4.2038, val_loss: 4.3449, val_MinusLogProbMetric: 4.3449

Epoch 49: val_loss did not improve from 4.19982
196/196 - 84s - loss: 4.2038 - MinusLogProbMetric: 4.2038 - val_loss: 4.3449 - val_MinusLogProbMetric: 4.3449 - lr: 0.0010 - 84s/epoch - 426ms/step
Epoch 50/1000
2023-09-17 12:45:38.406 
Epoch 50/1000 
	 loss: 4.2204, MinusLogProbMetric: 4.2204, val_loss: 4.2094, val_MinusLogProbMetric: 4.2094

Epoch 50: val_loss did not improve from 4.19982
196/196 - 82s - loss: 4.2204 - MinusLogProbMetric: 4.2204 - val_loss: 4.2094 - val_MinusLogProbMetric: 4.2094 - lr: 0.0010 - 82s/epoch - 421ms/step
Epoch 51/1000
2023-09-17 12:47:02.114 
Epoch 51/1000 
	 loss: 4.1820, MinusLogProbMetric: 4.1820, val_loss: 4.2309, val_MinusLogProbMetric: 4.2309

Epoch 51: val_loss did not improve from 4.19982
196/196 - 84s - loss: 4.1820 - MinusLogProbMetric: 4.1820 - val_loss: 4.2309 - val_MinusLogProbMetric: 4.2309 - lr: 0.0010 - 84s/epoch - 427ms/step
Epoch 52/1000
2023-09-17 12:48:25.694 
Epoch 52/1000 
	 loss: 4.2068, MinusLogProbMetric: 4.2068, val_loss: 4.2074, val_MinusLogProbMetric: 4.2074

Epoch 52: val_loss did not improve from 4.19982
196/196 - 84s - loss: 4.2068 - MinusLogProbMetric: 4.2068 - val_loss: 4.2074 - val_MinusLogProbMetric: 4.2074 - lr: 0.0010 - 84s/epoch - 426ms/step
Epoch 53/1000
2023-09-17 12:49:48.893 
Epoch 53/1000 
	 loss: 4.2235, MinusLogProbMetric: 4.2235, val_loss: 4.2114, val_MinusLogProbMetric: 4.2114

Epoch 53: val_loss did not improve from 4.19982
196/196 - 83s - loss: 4.2235 - MinusLogProbMetric: 4.2235 - val_loss: 4.2114 - val_MinusLogProbMetric: 4.2114 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 54/1000
2023-09-17 12:51:12.294 
Epoch 54/1000 
	 loss: 4.2041, MinusLogProbMetric: 4.2041, val_loss: 4.2421, val_MinusLogProbMetric: 4.2421

Epoch 54: val_loss did not improve from 4.19982
196/196 - 83s - loss: 4.2041 - MinusLogProbMetric: 4.2041 - val_loss: 4.2421 - val_MinusLogProbMetric: 4.2421 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 55/1000
2023-09-17 12:52:35.973 
Epoch 55/1000 
	 loss: 4.1881, MinusLogProbMetric: 4.1881, val_loss: 4.3586, val_MinusLogProbMetric: 4.3586

Epoch 55: val_loss did not improve from 4.19982
196/196 - 84s - loss: 4.1881 - MinusLogProbMetric: 4.1881 - val_loss: 4.3586 - val_MinusLogProbMetric: 4.3586 - lr: 0.0010 - 84s/epoch - 427ms/step
Epoch 56/1000
2023-09-17 12:53:58.646 
Epoch 56/1000 
	 loss: 4.1881, MinusLogProbMetric: 4.1881, val_loss: 4.2501, val_MinusLogProbMetric: 4.2501

Epoch 56: val_loss did not improve from 4.19982
196/196 - 83s - loss: 4.1881 - MinusLogProbMetric: 4.1881 - val_loss: 4.2501 - val_MinusLogProbMetric: 4.2501 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 57/1000
2023-09-17 12:55:22.114 
Epoch 57/1000 
	 loss: 4.1690, MinusLogProbMetric: 4.1690, val_loss: 4.2152, val_MinusLogProbMetric: 4.2152

Epoch 57: val_loss did not improve from 4.19982
196/196 - 83s - loss: 4.1690 - MinusLogProbMetric: 4.1690 - val_loss: 4.2152 - val_MinusLogProbMetric: 4.2152 - lr: 0.0010 - 83s/epoch - 426ms/step
Epoch 58/1000
2023-09-17 12:56:44.843 
Epoch 58/1000 
	 loss: 4.1693, MinusLogProbMetric: 4.1693, val_loss: 4.3279, val_MinusLogProbMetric: 4.3279

Epoch 58: val_loss did not improve from 4.19982
196/196 - 83s - loss: 4.1693 - MinusLogProbMetric: 4.1693 - val_loss: 4.3279 - val_MinusLogProbMetric: 4.3279 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 59/1000
2023-09-17 12:58:08.028 
Epoch 59/1000 
	 loss: 4.1825, MinusLogProbMetric: 4.1825, val_loss: 4.3084, val_MinusLogProbMetric: 4.3084

Epoch 59: val_loss did not improve from 4.19982
196/196 - 83s - loss: 4.1825 - MinusLogProbMetric: 4.1825 - val_loss: 4.3084 - val_MinusLogProbMetric: 4.3084 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 60/1000
2023-09-17 12:59:31.371 
Epoch 60/1000 
	 loss: 4.1723, MinusLogProbMetric: 4.1723, val_loss: 4.3442, val_MinusLogProbMetric: 4.3442

Epoch 60: val_loss did not improve from 4.19982
196/196 - 83s - loss: 4.1723 - MinusLogProbMetric: 4.1723 - val_loss: 4.3442 - val_MinusLogProbMetric: 4.3442 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 61/1000
2023-09-17 13:00:54.435 
Epoch 61/1000 
	 loss: 4.1688, MinusLogProbMetric: 4.1688, val_loss: 4.2030, val_MinusLogProbMetric: 4.2030

Epoch 61: val_loss did not improve from 4.19982
196/196 - 83s - loss: 4.1688 - MinusLogProbMetric: 4.1688 - val_loss: 4.2030 - val_MinusLogProbMetric: 4.2030 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 62/1000
2023-09-17 13:02:17.279 
Epoch 62/1000 
	 loss: 4.1716, MinusLogProbMetric: 4.1716, val_loss: 4.1775, val_MinusLogProbMetric: 4.1775

Epoch 62: val_loss improved from 4.19982 to 4.17753, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_128/weights/best_weights.h5
196/196 - 84s - loss: 4.1716 - MinusLogProbMetric: 4.1716 - val_loss: 4.1775 - val_MinusLogProbMetric: 4.1775 - lr: 0.0010 - 84s/epoch - 430ms/step
Epoch 63/1000
2023-09-17 13:03:42.078 
Epoch 63/1000 
	 loss: 4.1485, MinusLogProbMetric: 4.1485, val_loss: 4.2808, val_MinusLogProbMetric: 4.2808

Epoch 63: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.1485 - MinusLogProbMetric: 4.1485 - val_loss: 4.2808 - val_MinusLogProbMetric: 4.2808 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 64/1000
2023-09-17 13:05:04.603 
Epoch 64/1000 
	 loss: 4.1584, MinusLogProbMetric: 4.1584, val_loss: 4.2700, val_MinusLogProbMetric: 4.2700

Epoch 64: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.1584 - MinusLogProbMetric: 4.1584 - val_loss: 4.2700 - val_MinusLogProbMetric: 4.2700 - lr: 0.0010 - 83s/epoch - 421ms/step
Epoch 65/1000
2023-09-17 13:06:27.878 
Epoch 65/1000 
	 loss: 4.1544, MinusLogProbMetric: 4.1544, val_loss: 4.2502, val_MinusLogProbMetric: 4.2502

Epoch 65: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.1544 - MinusLogProbMetric: 4.1544 - val_loss: 4.2502 - val_MinusLogProbMetric: 4.2502 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 66/1000
2023-09-17 13:07:51.090 
Epoch 66/1000 
	 loss: 4.1740, MinusLogProbMetric: 4.1740, val_loss: 4.1895, val_MinusLogProbMetric: 4.1895

Epoch 66: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.1740 - MinusLogProbMetric: 4.1740 - val_loss: 4.1895 - val_MinusLogProbMetric: 4.1895 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 67/1000
2023-09-17 13:09:15.013 
Epoch 67/1000 
	 loss: 4.1374, MinusLogProbMetric: 4.1374, val_loss: 4.2033, val_MinusLogProbMetric: 4.2033

Epoch 67: val_loss did not improve from 4.17753
196/196 - 84s - loss: 4.1374 - MinusLogProbMetric: 4.1374 - val_loss: 4.2033 - val_MinusLogProbMetric: 4.2033 - lr: 0.0010 - 84s/epoch - 428ms/step
Epoch 68/1000
2023-09-17 13:10:37.724 
Epoch 68/1000 
	 loss: 4.1608, MinusLogProbMetric: 4.1608, val_loss: 4.6646, val_MinusLogProbMetric: 4.6646

Epoch 68: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.1608 - MinusLogProbMetric: 4.1608 - val_loss: 4.6646 - val_MinusLogProbMetric: 4.6646 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 69/1000
2023-09-17 13:12:00.722 
Epoch 69/1000 
	 loss: 4.1697, MinusLogProbMetric: 4.1697, val_loss: 4.1961, val_MinusLogProbMetric: 4.1961

Epoch 69: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.1697 - MinusLogProbMetric: 4.1697 - val_loss: 4.1961 - val_MinusLogProbMetric: 4.1961 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 70/1000
2023-09-17 13:13:23.247 
Epoch 70/1000 
	 loss: 4.1650, MinusLogProbMetric: 4.1650, val_loss: 4.3495, val_MinusLogProbMetric: 4.3495

Epoch 70: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.1650 - MinusLogProbMetric: 4.1650 - val_loss: 4.3495 - val_MinusLogProbMetric: 4.3495 - lr: 0.0010 - 83s/epoch - 421ms/step
Epoch 71/1000
2023-09-17 13:14:46.513 
Epoch 71/1000 
	 loss: 4.1239, MinusLogProbMetric: 4.1239, val_loss: 4.2337, val_MinusLogProbMetric: 4.2337

Epoch 71: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.1239 - MinusLogProbMetric: 4.1239 - val_loss: 4.2337 - val_MinusLogProbMetric: 4.2337 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 72/1000
2023-09-17 13:16:08.931 
Epoch 72/1000 
	 loss: 4.1443, MinusLogProbMetric: 4.1443, val_loss: 4.2986, val_MinusLogProbMetric: 4.2986

Epoch 72: val_loss did not improve from 4.17753
196/196 - 82s - loss: 4.1443 - MinusLogProbMetric: 4.1443 - val_loss: 4.2986 - val_MinusLogProbMetric: 4.2986 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 73/1000
2023-09-17 13:17:32.617 
Epoch 73/1000 
	 loss: 4.1628, MinusLogProbMetric: 4.1628, val_loss: 4.3940, val_MinusLogProbMetric: 4.3940

Epoch 73: val_loss did not improve from 4.17753
196/196 - 84s - loss: 4.1628 - MinusLogProbMetric: 4.1628 - val_loss: 4.3940 - val_MinusLogProbMetric: 4.3940 - lr: 0.0010 - 84s/epoch - 427ms/step
Epoch 74/1000
2023-09-17 13:18:55.974 
Epoch 74/1000 
	 loss: 4.1417, MinusLogProbMetric: 4.1417, val_loss: 4.3221, val_MinusLogProbMetric: 4.3221

Epoch 74: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.1417 - MinusLogProbMetric: 4.1417 - val_loss: 4.3221 - val_MinusLogProbMetric: 4.3221 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 75/1000
2023-09-17 13:20:19.606 
Epoch 75/1000 
	 loss: 4.1308, MinusLogProbMetric: 4.1308, val_loss: 4.3808, val_MinusLogProbMetric: 4.3808

Epoch 75: val_loss did not improve from 4.17753
196/196 - 84s - loss: 4.1308 - MinusLogProbMetric: 4.1308 - val_loss: 4.3808 - val_MinusLogProbMetric: 4.3808 - lr: 0.0010 - 84s/epoch - 427ms/step
Epoch 76/1000
2023-09-17 13:21:42.787 
Epoch 76/1000 
	 loss: 4.1340, MinusLogProbMetric: 4.1340, val_loss: 4.2866, val_MinusLogProbMetric: 4.2866

Epoch 76: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.1340 - MinusLogProbMetric: 4.1340 - val_loss: 4.2866 - val_MinusLogProbMetric: 4.2866 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 77/1000
2023-09-17 13:23:06.753 
Epoch 77/1000 
	 loss: 4.1445, MinusLogProbMetric: 4.1445, val_loss: 4.2616, val_MinusLogProbMetric: 4.2616

Epoch 77: val_loss did not improve from 4.17753
196/196 - 84s - loss: 4.1445 - MinusLogProbMetric: 4.1445 - val_loss: 4.2616 - val_MinusLogProbMetric: 4.2616 - lr: 0.0010 - 84s/epoch - 428ms/step
Epoch 78/1000
2023-09-17 13:24:29.728 
Epoch 78/1000 
	 loss: 4.1378, MinusLogProbMetric: 4.1378, val_loss: 4.3438, val_MinusLogProbMetric: 4.3438

Epoch 78: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.1378 - MinusLogProbMetric: 4.1378 - val_loss: 4.3438 - val_MinusLogProbMetric: 4.3438 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 79/1000
2023-09-17 13:25:51.828 
Epoch 79/1000 
	 loss: 4.1587, MinusLogProbMetric: 4.1587, val_loss: 4.2531, val_MinusLogProbMetric: 4.2531

Epoch 79: val_loss did not improve from 4.17753
196/196 - 82s - loss: 4.1587 - MinusLogProbMetric: 4.1587 - val_loss: 4.2531 - val_MinusLogProbMetric: 4.2531 - lr: 0.0010 - 82s/epoch - 419ms/step
Epoch 80/1000
2023-09-17 13:27:15.170 
Epoch 80/1000 
	 loss: 4.1281, MinusLogProbMetric: 4.1281, val_loss: 4.2550, val_MinusLogProbMetric: 4.2550

Epoch 80: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.1281 - MinusLogProbMetric: 4.1281 - val_loss: 4.2550 - val_MinusLogProbMetric: 4.2550 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 81/1000
2023-09-17 13:28:37.375 
Epoch 81/1000 
	 loss: 4.1225, MinusLogProbMetric: 4.1225, val_loss: 4.2207, val_MinusLogProbMetric: 4.2207

Epoch 81: val_loss did not improve from 4.17753
196/196 - 82s - loss: 4.1225 - MinusLogProbMetric: 4.1225 - val_loss: 4.2207 - val_MinusLogProbMetric: 4.2207 - lr: 0.0010 - 82s/epoch - 419ms/step
Epoch 82/1000
2023-09-17 13:29:58.770 
Epoch 82/1000 
	 loss: 4.1352, MinusLogProbMetric: 4.1352, val_loss: 4.1970, val_MinusLogProbMetric: 4.1970

Epoch 82: val_loss did not improve from 4.17753
196/196 - 81s - loss: 4.1352 - MinusLogProbMetric: 4.1352 - val_loss: 4.1970 - val_MinusLogProbMetric: 4.1970 - lr: 0.0010 - 81s/epoch - 415ms/step
Epoch 83/1000
2023-09-17 13:31:21.205 
Epoch 83/1000 
	 loss: 4.1336, MinusLogProbMetric: 4.1336, val_loss: 4.3056, val_MinusLogProbMetric: 4.3056

Epoch 83: val_loss did not improve from 4.17753
196/196 - 82s - loss: 4.1336 - MinusLogProbMetric: 4.1336 - val_loss: 4.3056 - val_MinusLogProbMetric: 4.3056 - lr: 0.0010 - 82s/epoch - 421ms/step
Epoch 84/1000
2023-09-17 13:32:44.362 
Epoch 84/1000 
	 loss: 4.1099, MinusLogProbMetric: 4.1099, val_loss: 4.2082, val_MinusLogProbMetric: 4.2082

Epoch 84: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.1099 - MinusLogProbMetric: 4.1099 - val_loss: 4.2082 - val_MinusLogProbMetric: 4.2082 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 85/1000
2023-09-17 13:34:08.054 
Epoch 85/1000 
	 loss: 4.1031, MinusLogProbMetric: 4.1031, val_loss: 4.1873, val_MinusLogProbMetric: 4.1873

Epoch 85: val_loss did not improve from 4.17753
196/196 - 84s - loss: 4.1031 - MinusLogProbMetric: 4.1031 - val_loss: 4.1873 - val_MinusLogProbMetric: 4.1873 - lr: 0.0010 - 84s/epoch - 427ms/step
Epoch 86/1000
2023-09-17 13:35:31.188 
Epoch 86/1000 
	 loss: 4.0987, MinusLogProbMetric: 4.0987, val_loss: 4.2470, val_MinusLogProbMetric: 4.2470

Epoch 86: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.0987 - MinusLogProbMetric: 4.0987 - val_loss: 4.2470 - val_MinusLogProbMetric: 4.2470 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 87/1000
2023-09-17 13:36:54.737 
Epoch 87/1000 
	 loss: 4.1146, MinusLogProbMetric: 4.1146, val_loss: 4.3572, val_MinusLogProbMetric: 4.3572

Epoch 87: val_loss did not improve from 4.17753
196/196 - 84s - loss: 4.1146 - MinusLogProbMetric: 4.1146 - val_loss: 4.3572 - val_MinusLogProbMetric: 4.3572 - lr: 0.0010 - 84s/epoch - 426ms/step
Epoch 88/1000
2023-09-17 13:38:17.698 
Epoch 88/1000 
	 loss: 4.1125, MinusLogProbMetric: 4.1125, val_loss: 4.2124, val_MinusLogProbMetric: 4.2124

Epoch 88: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.1125 - MinusLogProbMetric: 4.1125 - val_loss: 4.2124 - val_MinusLogProbMetric: 4.2124 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 89/1000
2023-09-17 13:39:40.985 
Epoch 89/1000 
	 loss: 4.0933, MinusLogProbMetric: 4.0933, val_loss: 4.2942, val_MinusLogProbMetric: 4.2942

Epoch 89: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.0933 - MinusLogProbMetric: 4.0933 - val_loss: 4.2942 - val_MinusLogProbMetric: 4.2942 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 90/1000
2023-09-17 13:41:03.503 
Epoch 90/1000 
	 loss: 4.1079, MinusLogProbMetric: 4.1079, val_loss: 4.2184, val_MinusLogProbMetric: 4.2184

Epoch 90: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.1079 - MinusLogProbMetric: 4.1079 - val_loss: 4.2184 - val_MinusLogProbMetric: 4.2184 - lr: 0.0010 - 83s/epoch - 421ms/step
Epoch 91/1000
2023-09-17 13:42:26.890 
Epoch 91/1000 
	 loss: 4.1138, MinusLogProbMetric: 4.1138, val_loss: 4.2158, val_MinusLogProbMetric: 4.2158

Epoch 91: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.1138 - MinusLogProbMetric: 4.1138 - val_loss: 4.2158 - val_MinusLogProbMetric: 4.2158 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 92/1000
2023-09-17 13:43:49.070 
Epoch 92/1000 
	 loss: 4.1031, MinusLogProbMetric: 4.1031, val_loss: 4.4376, val_MinusLogProbMetric: 4.4376

Epoch 92: val_loss did not improve from 4.17753
196/196 - 82s - loss: 4.1031 - MinusLogProbMetric: 4.1031 - val_loss: 4.4376 - val_MinusLogProbMetric: 4.4376 - lr: 0.0010 - 82s/epoch - 419ms/step
Epoch 93/1000
2023-09-17 13:45:11.570 
Epoch 93/1000 
	 loss: 4.1281, MinusLogProbMetric: 4.1281, val_loss: 4.3476, val_MinusLogProbMetric: 4.3476

Epoch 93: val_loss did not improve from 4.17753
196/196 - 82s - loss: 4.1281 - MinusLogProbMetric: 4.1281 - val_loss: 4.3476 - val_MinusLogProbMetric: 4.3476 - lr: 0.0010 - 82s/epoch - 421ms/step
Epoch 94/1000
2023-09-17 13:46:34.714 
Epoch 94/1000 
	 loss: 4.0928, MinusLogProbMetric: 4.0928, val_loss: 4.2441, val_MinusLogProbMetric: 4.2441

Epoch 94: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.0928 - MinusLogProbMetric: 4.0928 - val_loss: 4.2441 - val_MinusLogProbMetric: 4.2441 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 95/1000
2023-09-17 13:47:58.216 
Epoch 95/1000 
	 loss: 4.0941, MinusLogProbMetric: 4.0941, val_loss: 4.2241, val_MinusLogProbMetric: 4.2241

Epoch 95: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.0941 - MinusLogProbMetric: 4.0941 - val_loss: 4.2241 - val_MinusLogProbMetric: 4.2241 - lr: 0.0010 - 83s/epoch - 426ms/step
Epoch 96/1000
2023-09-17 13:49:21.446 
Epoch 96/1000 
	 loss: 4.0993, MinusLogProbMetric: 4.0993, val_loss: 4.2384, val_MinusLogProbMetric: 4.2384

Epoch 96: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.0993 - MinusLogProbMetric: 4.0993 - val_loss: 4.2384 - val_MinusLogProbMetric: 4.2384 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 97/1000
2023-09-17 13:50:44.571 
Epoch 97/1000 
	 loss: 4.1000, MinusLogProbMetric: 4.1000, val_loss: 4.3015, val_MinusLogProbMetric: 4.3015

Epoch 97: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.1000 - MinusLogProbMetric: 4.1000 - val_loss: 4.3015 - val_MinusLogProbMetric: 4.3015 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 98/1000
2023-09-17 13:52:06.958 
Epoch 98/1000 
	 loss: 4.0947, MinusLogProbMetric: 4.0947, val_loss: 4.3612, val_MinusLogProbMetric: 4.3612

Epoch 98: val_loss did not improve from 4.17753
196/196 - 82s - loss: 4.0947 - MinusLogProbMetric: 4.0947 - val_loss: 4.3612 - val_MinusLogProbMetric: 4.3612 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 99/1000
2023-09-17 13:53:30.591 
Epoch 99/1000 
	 loss: 4.0982, MinusLogProbMetric: 4.0982, val_loss: 4.2088, val_MinusLogProbMetric: 4.2088

Epoch 99: val_loss did not improve from 4.17753
196/196 - 84s - loss: 4.0982 - MinusLogProbMetric: 4.0982 - val_loss: 4.2088 - val_MinusLogProbMetric: 4.2088 - lr: 0.0010 - 84s/epoch - 427ms/step
Epoch 100/1000
2023-09-17 13:54:53.848 
Epoch 100/1000 
	 loss: 4.0941, MinusLogProbMetric: 4.0941, val_loss: 4.1951, val_MinusLogProbMetric: 4.1951

Epoch 100: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.0941 - MinusLogProbMetric: 4.0941 - val_loss: 4.1951 - val_MinusLogProbMetric: 4.1951 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 101/1000
2023-09-17 13:56:16.906 
Epoch 101/1000 
	 loss: 4.0890, MinusLogProbMetric: 4.0890, val_loss: 4.2747, val_MinusLogProbMetric: 4.2747

Epoch 101: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.0890 - MinusLogProbMetric: 4.0890 - val_loss: 4.2747 - val_MinusLogProbMetric: 4.2747 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 102/1000
2023-09-17 13:57:39.713 
Epoch 102/1000 
	 loss: 4.0929, MinusLogProbMetric: 4.0929, val_loss: 4.2347, val_MinusLogProbMetric: 4.2347

Epoch 102: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.0929 - MinusLogProbMetric: 4.0929 - val_loss: 4.2347 - val_MinusLogProbMetric: 4.2347 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 103/1000
2023-09-17 13:59:03.416 
Epoch 103/1000 
	 loss: 4.0773, MinusLogProbMetric: 4.0773, val_loss: 4.2697, val_MinusLogProbMetric: 4.2697

Epoch 103: val_loss did not improve from 4.17753
196/196 - 84s - loss: 4.0773 - MinusLogProbMetric: 4.0773 - val_loss: 4.2697 - val_MinusLogProbMetric: 4.2697 - lr: 0.0010 - 84s/epoch - 427ms/step
Epoch 104/1000
2023-09-17 14:00:26.165 
Epoch 104/1000 
	 loss: 4.0970, MinusLogProbMetric: 4.0970, val_loss: 4.2224, val_MinusLogProbMetric: 4.2224

Epoch 104: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.0970 - MinusLogProbMetric: 4.0970 - val_loss: 4.2224 - val_MinusLogProbMetric: 4.2224 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 105/1000
2023-09-17 14:01:49.586 
Epoch 105/1000 
	 loss: 4.0747, MinusLogProbMetric: 4.0747, val_loss: 4.2164, val_MinusLogProbMetric: 4.2164

Epoch 105: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.0747 - MinusLogProbMetric: 4.0747 - val_loss: 4.2164 - val_MinusLogProbMetric: 4.2164 - lr: 0.0010 - 83s/epoch - 426ms/step
Epoch 106/1000
2023-09-17 14:03:13.038 
Epoch 106/1000 
	 loss: 4.0811, MinusLogProbMetric: 4.0811, val_loss: 4.1858, val_MinusLogProbMetric: 4.1858

Epoch 106: val_loss did not improve from 4.17753
196/196 - 83s - loss: 4.0811 - MinusLogProbMetric: 4.0811 - val_loss: 4.1858 - val_MinusLogProbMetric: 4.1858 - lr: 0.0010 - 83s/epoch - 426ms/step
Epoch 107/1000
2023-09-17 14:04:26.630 
Epoch 107/1000 
	 loss: 4.0837, MinusLogProbMetric: 4.0837, val_loss: 4.3213, val_MinusLogProbMetric: 4.3213

Epoch 107: val_loss did not improve from 4.17753
196/196 - 74s - loss: 4.0837 - MinusLogProbMetric: 4.0837 - val_loss: 4.3213 - val_MinusLogProbMetric: 4.3213 - lr: 0.0010 - 74s/epoch - 375ms/step
Epoch 108/1000
2023-09-17 14:05:37.232 
Epoch 108/1000 
	 loss: 4.0805, MinusLogProbMetric: 4.0805, val_loss: 4.2934, val_MinusLogProbMetric: 4.2934

Epoch 108: val_loss did not improve from 4.17753
196/196 - 71s - loss: 4.0805 - MinusLogProbMetric: 4.0805 - val_loss: 4.2934 - val_MinusLogProbMetric: 4.2934 - lr: 0.0010 - 71s/epoch - 360ms/step
Epoch 109/1000
2023-09-17 14:06:52.951 
Epoch 109/1000 
	 loss: 4.0786, MinusLogProbMetric: 4.0786, val_loss: 4.2541, val_MinusLogProbMetric: 4.2541

Epoch 109: val_loss did not improve from 4.17753
196/196 - 76s - loss: 4.0786 - MinusLogProbMetric: 4.0786 - val_loss: 4.2541 - val_MinusLogProbMetric: 4.2541 - lr: 0.0010 - 76s/epoch - 386ms/step
Epoch 110/1000
2023-09-17 14:08:02.444 
Epoch 110/1000 
	 loss: 4.0673, MinusLogProbMetric: 4.0673, val_loss: 4.1823, val_MinusLogProbMetric: 4.1823

Epoch 110: val_loss did not improve from 4.17753
196/196 - 69s - loss: 4.0673 - MinusLogProbMetric: 4.0673 - val_loss: 4.1823 - val_MinusLogProbMetric: 4.1823 - lr: 0.0010 - 69s/epoch - 355ms/step
Epoch 111/1000
2023-09-17 14:09:17.424 
Epoch 111/1000 
	 loss: 4.0923, MinusLogProbMetric: 4.0923, val_loss: 4.2262, val_MinusLogProbMetric: 4.2262

Epoch 111: val_loss did not improve from 4.17753
196/196 - 75s - loss: 4.0923 - MinusLogProbMetric: 4.0923 - val_loss: 4.2262 - val_MinusLogProbMetric: 4.2262 - lr: 0.0010 - 75s/epoch - 383ms/step
Epoch 112/1000
2023-09-17 14:10:39.266 
Epoch 112/1000 
	 loss: 4.0810, MinusLogProbMetric: 4.0810, val_loss: 4.2317, val_MinusLogProbMetric: 4.2317

Epoch 112: val_loss did not improve from 4.17753
196/196 - 82s - loss: 4.0810 - MinusLogProbMetric: 4.0810 - val_loss: 4.2317 - val_MinusLogProbMetric: 4.2317 - lr: 0.0010 - 82s/epoch - 418ms/step
Epoch 113/1000
2023-09-17 14:12:01.898 
Epoch 113/1000 
	 loss: 3.9930, MinusLogProbMetric: 3.9930, val_loss: 4.3224, val_MinusLogProbMetric: 4.3224

Epoch 113: val_loss did not improve from 4.17753
196/196 - 83s - loss: 3.9930 - MinusLogProbMetric: 3.9930 - val_loss: 4.3224 - val_MinusLogProbMetric: 4.3224 - lr: 5.0000e-04 - 83s/epoch - 422ms/step
Epoch 114/1000
2023-09-17 14:13:25.504 
Epoch 114/1000 
	 loss: 3.9869, MinusLogProbMetric: 3.9869, val_loss: 4.2039, val_MinusLogProbMetric: 4.2039

Epoch 114: val_loss did not improve from 4.17753
196/196 - 84s - loss: 3.9869 - MinusLogProbMetric: 3.9869 - val_loss: 4.2039 - val_MinusLogProbMetric: 4.2039 - lr: 5.0000e-04 - 84s/epoch - 427ms/step
Epoch 115/1000
2023-09-17 14:14:47.924 
Epoch 115/1000 
	 loss: 3.9940, MinusLogProbMetric: 3.9940, val_loss: 4.1617, val_MinusLogProbMetric: 4.1617

Epoch 115: val_loss improved from 4.17753 to 4.16169, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_128/weights/best_weights.h5
196/196 - 84s - loss: 3.9940 - MinusLogProbMetric: 3.9940 - val_loss: 4.1617 - val_MinusLogProbMetric: 4.1617 - lr: 5.0000e-04 - 84s/epoch - 427ms/step
Epoch 116/1000
2023-09-17 14:16:11.001 
Epoch 116/1000 
	 loss: 3.9924, MinusLogProbMetric: 3.9924, val_loss: 4.2035, val_MinusLogProbMetric: 4.2035

Epoch 116: val_loss did not improve from 4.16169
196/196 - 82s - loss: 3.9924 - MinusLogProbMetric: 3.9924 - val_loss: 4.2035 - val_MinusLogProbMetric: 4.2035 - lr: 5.0000e-04 - 82s/epoch - 417ms/step
Epoch 117/1000
2023-09-17 14:17:30.960 
Epoch 117/1000 
	 loss: 3.9831, MinusLogProbMetric: 3.9831, val_loss: 4.1875, val_MinusLogProbMetric: 4.1875

Epoch 117: val_loss did not improve from 4.16169
196/196 - 80s - loss: 3.9831 - MinusLogProbMetric: 3.9831 - val_loss: 4.1875 - val_MinusLogProbMetric: 4.1875 - lr: 5.0000e-04 - 80s/epoch - 408ms/step
Epoch 118/1000
2023-09-17 14:18:45.446 
Epoch 118/1000 
	 loss: 3.9818, MinusLogProbMetric: 3.9818, val_loss: 4.1729, val_MinusLogProbMetric: 4.1729

Epoch 118: val_loss did not improve from 4.16169
196/196 - 74s - loss: 3.9818 - MinusLogProbMetric: 3.9818 - val_loss: 4.1729 - val_MinusLogProbMetric: 4.1729 - lr: 5.0000e-04 - 74s/epoch - 380ms/step
Epoch 119/1000
2023-09-17 14:19:55.752 
Epoch 119/1000 
	 loss: 3.9829, MinusLogProbMetric: 3.9829, val_loss: 4.2066, val_MinusLogProbMetric: 4.2066

Epoch 119: val_loss did not improve from 4.16169
196/196 - 70s - loss: 3.9829 - MinusLogProbMetric: 3.9829 - val_loss: 4.2066 - val_MinusLogProbMetric: 4.2066 - lr: 5.0000e-04 - 70s/epoch - 359ms/step
Epoch 120/1000
2023-09-17 14:21:16.043 
Epoch 120/1000 
	 loss: 3.9841, MinusLogProbMetric: 3.9841, val_loss: 4.2103, val_MinusLogProbMetric: 4.2103

Epoch 120: val_loss did not improve from 4.16169
196/196 - 80s - loss: 3.9841 - MinusLogProbMetric: 3.9841 - val_loss: 4.2103 - val_MinusLogProbMetric: 4.2103 - lr: 5.0000e-04 - 80s/epoch - 410ms/step
Epoch 121/1000
2023-09-17 14:22:37.756 
Epoch 121/1000 
	 loss: 3.9837, MinusLogProbMetric: 3.9837, val_loss: 4.2127, val_MinusLogProbMetric: 4.2127

Epoch 121: val_loss did not improve from 4.16169
196/196 - 82s - loss: 3.9837 - MinusLogProbMetric: 3.9837 - val_loss: 4.2127 - val_MinusLogProbMetric: 4.2127 - lr: 5.0000e-04 - 82s/epoch - 417ms/step
Epoch 122/1000
2023-09-17 14:24:01.462 
Epoch 122/1000 
	 loss: 3.9887, MinusLogProbMetric: 3.9887, val_loss: 4.1720, val_MinusLogProbMetric: 4.1720

Epoch 122: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.9887 - MinusLogProbMetric: 3.9887 - val_loss: 4.1720 - val_MinusLogProbMetric: 4.1720 - lr: 5.0000e-04 - 84s/epoch - 427ms/step
Epoch 123/1000
2023-09-17 14:25:24.286 
Epoch 123/1000 
	 loss: 3.9762, MinusLogProbMetric: 3.9762, val_loss: 4.1710, val_MinusLogProbMetric: 4.1710

Epoch 123: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9762 - MinusLogProbMetric: 3.9762 - val_loss: 4.1710 - val_MinusLogProbMetric: 4.1710 - lr: 5.0000e-04 - 83s/epoch - 423ms/step
Epoch 124/1000
2023-09-17 14:26:46.472 
Epoch 124/1000 
	 loss: 3.9786, MinusLogProbMetric: 3.9786, val_loss: 4.1941, val_MinusLogProbMetric: 4.1941

Epoch 124: val_loss did not improve from 4.16169
196/196 - 82s - loss: 3.9786 - MinusLogProbMetric: 3.9786 - val_loss: 4.1941 - val_MinusLogProbMetric: 4.1941 - lr: 5.0000e-04 - 82s/epoch - 419ms/step
Epoch 125/1000
2023-09-17 14:28:09.560 
Epoch 125/1000 
	 loss: 3.9829, MinusLogProbMetric: 3.9829, val_loss: 4.1945, val_MinusLogProbMetric: 4.1945

Epoch 125: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9829 - MinusLogProbMetric: 3.9829 - val_loss: 4.1945 - val_MinusLogProbMetric: 4.1945 - lr: 5.0000e-04 - 83s/epoch - 424ms/step
Epoch 126/1000
2023-09-17 14:29:32.362 
Epoch 126/1000 
	 loss: 3.9763, MinusLogProbMetric: 3.9763, val_loss: 4.1813, val_MinusLogProbMetric: 4.1813

Epoch 126: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9763 - MinusLogProbMetric: 3.9763 - val_loss: 4.1813 - val_MinusLogProbMetric: 4.1813 - lr: 5.0000e-04 - 83s/epoch - 422ms/step
Epoch 127/1000
2023-09-17 14:30:54.995 
Epoch 127/1000 
	 loss: 3.9823, MinusLogProbMetric: 3.9823, val_loss: 4.1955, val_MinusLogProbMetric: 4.1955

Epoch 127: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9823 - MinusLogProbMetric: 3.9823 - val_loss: 4.1955 - val_MinusLogProbMetric: 4.1955 - lr: 5.0000e-04 - 83s/epoch - 422ms/step
Epoch 128/1000
2023-09-17 14:32:16.843 
Epoch 128/1000 
	 loss: 3.9721, MinusLogProbMetric: 3.9721, val_loss: 4.1855, val_MinusLogProbMetric: 4.1855

Epoch 128: val_loss did not improve from 4.16169
196/196 - 82s - loss: 3.9721 - MinusLogProbMetric: 3.9721 - val_loss: 4.1855 - val_MinusLogProbMetric: 4.1855 - lr: 5.0000e-04 - 82s/epoch - 418ms/step
Epoch 129/1000
2023-09-17 14:33:39.234 
Epoch 129/1000 
	 loss: 3.9752, MinusLogProbMetric: 3.9752, val_loss: 4.1905, val_MinusLogProbMetric: 4.1905

Epoch 129: val_loss did not improve from 4.16169
196/196 - 82s - loss: 3.9752 - MinusLogProbMetric: 3.9752 - val_loss: 4.1905 - val_MinusLogProbMetric: 4.1905 - lr: 5.0000e-04 - 82s/epoch - 420ms/step
Epoch 130/1000
2023-09-17 14:35:01.275 
Epoch 130/1000 
	 loss: 3.9659, MinusLogProbMetric: 3.9659, val_loss: 4.1929, val_MinusLogProbMetric: 4.1929

Epoch 130: val_loss did not improve from 4.16169
196/196 - 82s - loss: 3.9659 - MinusLogProbMetric: 3.9659 - val_loss: 4.1929 - val_MinusLogProbMetric: 4.1929 - lr: 5.0000e-04 - 82s/epoch - 419ms/step
Epoch 131/1000
2023-09-17 14:36:23.785 
Epoch 131/1000 
	 loss: 3.9803, MinusLogProbMetric: 3.9803, val_loss: 4.1933, val_MinusLogProbMetric: 4.1933

Epoch 131: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9803 - MinusLogProbMetric: 3.9803 - val_loss: 4.1933 - val_MinusLogProbMetric: 4.1933 - lr: 5.0000e-04 - 83s/epoch - 421ms/step
Epoch 132/1000
2023-09-17 14:37:46.829 
Epoch 132/1000 
	 loss: 3.9757, MinusLogProbMetric: 3.9757, val_loss: 4.2020, val_MinusLogProbMetric: 4.2020

Epoch 132: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9757 - MinusLogProbMetric: 3.9757 - val_loss: 4.2020 - val_MinusLogProbMetric: 4.2020 - lr: 5.0000e-04 - 83s/epoch - 424ms/step
Epoch 133/1000
2023-09-17 14:39:09.954 
Epoch 133/1000 
	 loss: 3.9659, MinusLogProbMetric: 3.9659, val_loss: 4.2302, val_MinusLogProbMetric: 4.2302

Epoch 133: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9659 - MinusLogProbMetric: 3.9659 - val_loss: 4.2302 - val_MinusLogProbMetric: 4.2302 - lr: 5.0000e-04 - 83s/epoch - 424ms/step
Epoch 134/1000
2023-09-17 14:40:32.777 
Epoch 134/1000 
	 loss: 3.9685, MinusLogProbMetric: 3.9685, val_loss: 4.2068, val_MinusLogProbMetric: 4.2068

Epoch 134: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9685 - MinusLogProbMetric: 3.9685 - val_loss: 4.2068 - val_MinusLogProbMetric: 4.2068 - lr: 5.0000e-04 - 83s/epoch - 423ms/step
Epoch 135/1000
2023-09-17 14:41:55.382 
Epoch 135/1000 
	 loss: 3.9699, MinusLogProbMetric: 3.9699, val_loss: 4.2120, val_MinusLogProbMetric: 4.2120

Epoch 135: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9699 - MinusLogProbMetric: 3.9699 - val_loss: 4.2120 - val_MinusLogProbMetric: 4.2120 - lr: 5.0000e-04 - 83s/epoch - 421ms/step
Epoch 136/1000
2023-09-17 14:43:18.213 
Epoch 136/1000 
	 loss: 3.9763, MinusLogProbMetric: 3.9763, val_loss: 4.1910, val_MinusLogProbMetric: 4.1910

Epoch 136: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9763 - MinusLogProbMetric: 3.9763 - val_loss: 4.1910 - val_MinusLogProbMetric: 4.1910 - lr: 5.0000e-04 - 83s/epoch - 423ms/step
Epoch 137/1000
2023-09-17 14:44:40.983 
Epoch 137/1000 
	 loss: 3.9608, MinusLogProbMetric: 3.9608, val_loss: 4.1980, val_MinusLogProbMetric: 4.1980

Epoch 137: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9608 - MinusLogProbMetric: 3.9608 - val_loss: 4.1980 - val_MinusLogProbMetric: 4.1980 - lr: 5.0000e-04 - 83s/epoch - 422ms/step
Epoch 138/1000
2023-09-17 14:46:02.039 
Epoch 138/1000 
	 loss: 3.9595, MinusLogProbMetric: 3.9595, val_loss: 4.1981, val_MinusLogProbMetric: 4.1981

Epoch 138: val_loss did not improve from 4.16169
196/196 - 81s - loss: 3.9595 - MinusLogProbMetric: 3.9595 - val_loss: 4.1981 - val_MinusLogProbMetric: 4.1981 - lr: 5.0000e-04 - 81s/epoch - 414ms/step
Epoch 139/1000
2023-09-17 14:47:11.739 
Epoch 139/1000 
	 loss: 3.9623, MinusLogProbMetric: 3.9623, val_loss: 4.1970, val_MinusLogProbMetric: 4.1970

Epoch 139: val_loss did not improve from 4.16169
196/196 - 70s - loss: 3.9623 - MinusLogProbMetric: 3.9623 - val_loss: 4.1970 - val_MinusLogProbMetric: 4.1970 - lr: 5.0000e-04 - 70s/epoch - 356ms/step
Epoch 140/1000
2023-09-17 14:48:23.675 
Epoch 140/1000 
	 loss: 3.9568, MinusLogProbMetric: 3.9568, val_loss: 4.2244, val_MinusLogProbMetric: 4.2244

Epoch 140: val_loss did not improve from 4.16169
196/196 - 72s - loss: 3.9568 - MinusLogProbMetric: 3.9568 - val_loss: 4.2244 - val_MinusLogProbMetric: 4.2244 - lr: 5.0000e-04 - 72s/epoch - 367ms/step
Epoch 141/1000
2023-09-17 14:49:46.880 
Epoch 141/1000 
	 loss: 3.9589, MinusLogProbMetric: 3.9589, val_loss: 4.2026, val_MinusLogProbMetric: 4.2026

Epoch 141: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9589 - MinusLogProbMetric: 3.9589 - val_loss: 4.2026 - val_MinusLogProbMetric: 4.2026 - lr: 5.0000e-04 - 83s/epoch - 424ms/step
Epoch 142/1000
2023-09-17 14:51:06.934 
Epoch 142/1000 
	 loss: 3.9557, MinusLogProbMetric: 3.9557, val_loss: 4.2303, val_MinusLogProbMetric: 4.2303

Epoch 142: val_loss did not improve from 4.16169
196/196 - 80s - loss: 3.9557 - MinusLogProbMetric: 3.9557 - val_loss: 4.2303 - val_MinusLogProbMetric: 4.2303 - lr: 5.0000e-04 - 80s/epoch - 408ms/step
Epoch 143/1000
2023-09-17 14:52:29.646 
Epoch 143/1000 
	 loss: 3.9621, MinusLogProbMetric: 3.9621, val_loss: 4.2180, val_MinusLogProbMetric: 4.2180

Epoch 143: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9621 - MinusLogProbMetric: 3.9621 - val_loss: 4.2180 - val_MinusLogProbMetric: 4.2180 - lr: 5.0000e-04 - 83s/epoch - 422ms/step
Epoch 144/1000
2023-09-17 14:53:52.190 
Epoch 144/1000 
	 loss: 3.9548, MinusLogProbMetric: 3.9548, val_loss: 4.2032, val_MinusLogProbMetric: 4.2032

Epoch 144: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9548 - MinusLogProbMetric: 3.9548 - val_loss: 4.2032 - val_MinusLogProbMetric: 4.2032 - lr: 5.0000e-04 - 83s/epoch - 421ms/step
Epoch 145/1000
2023-09-17 14:55:14.823 
Epoch 145/1000 
	 loss: 3.9561, MinusLogProbMetric: 3.9561, val_loss: 4.2577, val_MinusLogProbMetric: 4.2577

Epoch 145: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9561 - MinusLogProbMetric: 3.9561 - val_loss: 4.2577 - val_MinusLogProbMetric: 4.2577 - lr: 5.0000e-04 - 83s/epoch - 422ms/step
Epoch 146/1000
2023-09-17 14:56:37.321 
Epoch 146/1000 
	 loss: 3.9597, MinusLogProbMetric: 3.9597, val_loss: 4.2056, val_MinusLogProbMetric: 4.2056

Epoch 146: val_loss did not improve from 4.16169
196/196 - 82s - loss: 3.9597 - MinusLogProbMetric: 3.9597 - val_loss: 4.2056 - val_MinusLogProbMetric: 4.2056 - lr: 5.0000e-04 - 82s/epoch - 421ms/step
Epoch 147/1000
2023-09-17 14:57:59.795 
Epoch 147/1000 
	 loss: 3.9644, MinusLogProbMetric: 3.9644, val_loss: 4.2173, val_MinusLogProbMetric: 4.2173

Epoch 147: val_loss did not improve from 4.16169
196/196 - 82s - loss: 3.9644 - MinusLogProbMetric: 3.9644 - val_loss: 4.2173 - val_MinusLogProbMetric: 4.2173 - lr: 5.0000e-04 - 82s/epoch - 421ms/step
Epoch 148/1000
2023-09-17 14:59:23.297 
Epoch 148/1000 
	 loss: 3.9637, MinusLogProbMetric: 3.9637, val_loss: 4.2075, val_MinusLogProbMetric: 4.2075

Epoch 148: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.9637 - MinusLogProbMetric: 3.9637 - val_loss: 4.2075 - val_MinusLogProbMetric: 4.2075 - lr: 5.0000e-04 - 84s/epoch - 426ms/step
Epoch 149/1000
2023-09-17 15:00:45.605 
Epoch 149/1000 
	 loss: 3.9529, MinusLogProbMetric: 3.9529, val_loss: 4.2939, val_MinusLogProbMetric: 4.2939

Epoch 149: val_loss did not improve from 4.16169
196/196 - 82s - loss: 3.9529 - MinusLogProbMetric: 3.9529 - val_loss: 4.2939 - val_MinusLogProbMetric: 4.2939 - lr: 5.0000e-04 - 82s/epoch - 420ms/step
Epoch 150/1000
2023-09-17 15:02:08.150 
Epoch 150/1000 
	 loss: 3.9541, MinusLogProbMetric: 3.9541, val_loss: 4.2321, val_MinusLogProbMetric: 4.2321

Epoch 150: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9541 - MinusLogProbMetric: 3.9541 - val_loss: 4.2321 - val_MinusLogProbMetric: 4.2321 - lr: 5.0000e-04 - 83s/epoch - 421ms/step
Epoch 151/1000
2023-09-17 15:03:30.588 
Epoch 151/1000 
	 loss: 3.9577, MinusLogProbMetric: 3.9577, val_loss: 4.2135, val_MinusLogProbMetric: 4.2135

Epoch 151: val_loss did not improve from 4.16169
196/196 - 82s - loss: 3.9577 - MinusLogProbMetric: 3.9577 - val_loss: 4.2135 - val_MinusLogProbMetric: 4.2135 - lr: 5.0000e-04 - 82s/epoch - 421ms/step
Epoch 152/1000
2023-09-17 15:04:53.165 
Epoch 152/1000 
	 loss: 3.9473, MinusLogProbMetric: 3.9473, val_loss: 4.2468, val_MinusLogProbMetric: 4.2468

Epoch 152: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9473 - MinusLogProbMetric: 3.9473 - val_loss: 4.2468 - val_MinusLogProbMetric: 4.2468 - lr: 5.0000e-04 - 83s/epoch - 421ms/step
Epoch 153/1000
2023-09-17 15:06:16.743 
Epoch 153/1000 
	 loss: 3.9517, MinusLogProbMetric: 3.9517, val_loss: 4.2105, val_MinusLogProbMetric: 4.2105

Epoch 153: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.9517 - MinusLogProbMetric: 3.9517 - val_loss: 4.2105 - val_MinusLogProbMetric: 4.2105 - lr: 5.0000e-04 - 84s/epoch - 426ms/step
Epoch 154/1000
2023-09-17 15:07:25.866 
Epoch 154/1000 
	 loss: 3.9466, MinusLogProbMetric: 3.9466, val_loss: 4.2693, val_MinusLogProbMetric: 4.2693

Epoch 154: val_loss did not improve from 4.16169
196/196 - 69s - loss: 3.9466 - MinusLogProbMetric: 3.9466 - val_loss: 4.2693 - val_MinusLogProbMetric: 4.2693 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 155/1000
2023-09-17 15:08:41.468 
Epoch 155/1000 
	 loss: 3.9470, MinusLogProbMetric: 3.9470, val_loss: 4.2444, val_MinusLogProbMetric: 4.2444

Epoch 155: val_loss did not improve from 4.16169
196/196 - 76s - loss: 3.9470 - MinusLogProbMetric: 3.9470 - val_loss: 4.2444 - val_MinusLogProbMetric: 4.2444 - lr: 5.0000e-04 - 76s/epoch - 386ms/step
Epoch 156/1000
2023-09-17 15:10:05.133 
Epoch 156/1000 
	 loss: 3.9500, MinusLogProbMetric: 3.9500, val_loss: 4.2200, val_MinusLogProbMetric: 4.2200

Epoch 156: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.9500 - MinusLogProbMetric: 3.9500 - val_loss: 4.2200 - val_MinusLogProbMetric: 4.2200 - lr: 5.0000e-04 - 84s/epoch - 427ms/step
Epoch 157/1000
2023-09-17 15:11:29.577 
Epoch 157/1000 
	 loss: 3.9674, MinusLogProbMetric: 3.9674, val_loss: 4.2355, val_MinusLogProbMetric: 4.2355

Epoch 157: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.9674 - MinusLogProbMetric: 3.9674 - val_loss: 4.2355 - val_MinusLogProbMetric: 4.2355 - lr: 5.0000e-04 - 84s/epoch - 431ms/step
Epoch 158/1000
2023-09-17 15:12:53.521 
Epoch 158/1000 
	 loss: 3.9482, MinusLogProbMetric: 3.9482, val_loss: 4.2604, val_MinusLogProbMetric: 4.2604

Epoch 158: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.9482 - MinusLogProbMetric: 3.9482 - val_loss: 4.2604 - val_MinusLogProbMetric: 4.2604 - lr: 5.0000e-04 - 84s/epoch - 428ms/step
Epoch 159/1000
2023-09-17 15:14:17.104 
Epoch 159/1000 
	 loss: 3.9553, MinusLogProbMetric: 3.9553, val_loss: 4.2323, val_MinusLogProbMetric: 4.2323

Epoch 159: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.9553 - MinusLogProbMetric: 3.9553 - val_loss: 4.2323 - val_MinusLogProbMetric: 4.2323 - lr: 5.0000e-04 - 84s/epoch - 426ms/step
Epoch 160/1000
2023-09-17 15:15:40.634 
Epoch 160/1000 
	 loss: 3.9456, MinusLogProbMetric: 3.9456, val_loss: 4.2283, val_MinusLogProbMetric: 4.2283

Epoch 160: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.9456 - MinusLogProbMetric: 3.9456 - val_loss: 4.2283 - val_MinusLogProbMetric: 4.2283 - lr: 5.0000e-04 - 84s/epoch - 426ms/step
Epoch 161/1000
2023-09-17 15:17:03.986 
Epoch 161/1000 
	 loss: 3.9474, MinusLogProbMetric: 3.9474, val_loss: 4.3535, val_MinusLogProbMetric: 4.3535

Epoch 161: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9474 - MinusLogProbMetric: 3.9474 - val_loss: 4.3535 - val_MinusLogProbMetric: 4.3535 - lr: 5.0000e-04 - 83s/epoch - 425ms/step
Epoch 162/1000
2023-09-17 15:18:27.487 
Epoch 162/1000 
	 loss: 3.9442, MinusLogProbMetric: 3.9442, val_loss: 4.2298, val_MinusLogProbMetric: 4.2298

Epoch 162: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9442 - MinusLogProbMetric: 3.9442 - val_loss: 4.2298 - val_MinusLogProbMetric: 4.2298 - lr: 5.0000e-04 - 83s/epoch - 426ms/step
Epoch 163/1000
2023-09-17 15:19:50.906 
Epoch 163/1000 
	 loss: 3.9400, MinusLogProbMetric: 3.9400, val_loss: 4.2319, val_MinusLogProbMetric: 4.2319

Epoch 163: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9400 - MinusLogProbMetric: 3.9400 - val_loss: 4.2319 - val_MinusLogProbMetric: 4.2319 - lr: 5.0000e-04 - 83s/epoch - 426ms/step
Epoch 164/1000
2023-09-17 15:21:14.317 
Epoch 164/1000 
	 loss: 3.9500, MinusLogProbMetric: 3.9500, val_loss: 4.2322, val_MinusLogProbMetric: 4.2322

Epoch 164: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9500 - MinusLogProbMetric: 3.9500 - val_loss: 4.2322 - val_MinusLogProbMetric: 4.2322 - lr: 5.0000e-04 - 83s/epoch - 426ms/step
Epoch 165/1000
2023-09-17 15:22:37.289 
Epoch 165/1000 
	 loss: 3.9433, MinusLogProbMetric: 3.9433, val_loss: 4.2613, val_MinusLogProbMetric: 4.2613

Epoch 165: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.9433 - MinusLogProbMetric: 3.9433 - val_loss: 4.2613 - val_MinusLogProbMetric: 4.2613 - lr: 5.0000e-04 - 83s/epoch - 423ms/step
Epoch 166/1000
2023-09-17 15:23:49.639 
Epoch 166/1000 
	 loss: 3.8974, MinusLogProbMetric: 3.8974, val_loss: 4.2196, val_MinusLogProbMetric: 4.2196

Epoch 166: val_loss did not improve from 4.16169
196/196 - 72s - loss: 3.8974 - MinusLogProbMetric: 3.8974 - val_loss: 4.2196 - val_MinusLogProbMetric: 4.2196 - lr: 2.5000e-04 - 72s/epoch - 369ms/step
Epoch 167/1000
2023-09-17 15:25:03.076 
Epoch 167/1000 
	 loss: 3.8939, MinusLogProbMetric: 3.8939, val_loss: 4.2161, val_MinusLogProbMetric: 4.2161

Epoch 167: val_loss did not improve from 4.16169
196/196 - 73s - loss: 3.8939 - MinusLogProbMetric: 3.8939 - val_loss: 4.2161 - val_MinusLogProbMetric: 4.2161 - lr: 2.5000e-04 - 73s/epoch - 375ms/step
Epoch 168/1000
2023-09-17 15:26:27.063 
Epoch 168/1000 
	 loss: 3.8924, MinusLogProbMetric: 3.8924, val_loss: 4.2314, val_MinusLogProbMetric: 4.2314

Epoch 168: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.8924 - MinusLogProbMetric: 3.8924 - val_loss: 4.2314 - val_MinusLogProbMetric: 4.2314 - lr: 2.5000e-04 - 84s/epoch - 428ms/step
Epoch 169/1000
2023-09-17 15:27:50.834 
Epoch 169/1000 
	 loss: 3.8917, MinusLogProbMetric: 3.8917, val_loss: 4.2270, val_MinusLogProbMetric: 4.2270

Epoch 169: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.8917 - MinusLogProbMetric: 3.8917 - val_loss: 4.2270 - val_MinusLogProbMetric: 4.2270 - lr: 2.5000e-04 - 84s/epoch - 427ms/step
Epoch 170/1000
2023-09-17 15:29:14.986 
Epoch 170/1000 
	 loss: 3.8908, MinusLogProbMetric: 3.8908, val_loss: 4.2263, val_MinusLogProbMetric: 4.2263

Epoch 170: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.8908 - MinusLogProbMetric: 3.8908 - val_loss: 4.2263 - val_MinusLogProbMetric: 4.2263 - lr: 2.5000e-04 - 84s/epoch - 429ms/step
Epoch 171/1000
2023-09-17 15:30:38.364 
Epoch 171/1000 
	 loss: 3.8918, MinusLogProbMetric: 3.8918, val_loss: 4.2314, val_MinusLogProbMetric: 4.2314

Epoch 171: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.8918 - MinusLogProbMetric: 3.8918 - val_loss: 4.2314 - val_MinusLogProbMetric: 4.2314 - lr: 2.5000e-04 - 83s/epoch - 425ms/step
Epoch 172/1000
2023-09-17 15:32:03.180 
Epoch 172/1000 
	 loss: 3.8847, MinusLogProbMetric: 3.8847, val_loss: 4.2308, val_MinusLogProbMetric: 4.2308

Epoch 172: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8847 - MinusLogProbMetric: 3.8847 - val_loss: 4.2308 - val_MinusLogProbMetric: 4.2308 - lr: 2.5000e-04 - 85s/epoch - 433ms/step
Epoch 173/1000
2023-09-17 15:33:27.899 
Epoch 173/1000 
	 loss: 3.8891, MinusLogProbMetric: 3.8891, val_loss: 4.2686, val_MinusLogProbMetric: 4.2686

Epoch 173: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8891 - MinusLogProbMetric: 3.8891 - val_loss: 4.2686 - val_MinusLogProbMetric: 4.2686 - lr: 2.5000e-04 - 85s/epoch - 432ms/step
Epoch 174/1000
2023-09-17 15:34:52.773 
Epoch 174/1000 
	 loss: 3.8851, MinusLogProbMetric: 3.8851, val_loss: 4.2477, val_MinusLogProbMetric: 4.2477

Epoch 174: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8851 - MinusLogProbMetric: 3.8851 - val_loss: 4.2477 - val_MinusLogProbMetric: 4.2477 - lr: 2.5000e-04 - 85s/epoch - 433ms/step
Epoch 175/1000
2023-09-17 15:36:17.779 
Epoch 175/1000 
	 loss: 3.8817, MinusLogProbMetric: 3.8817, val_loss: 4.2332, val_MinusLogProbMetric: 4.2332

Epoch 175: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8817 - MinusLogProbMetric: 3.8817 - val_loss: 4.2332 - val_MinusLogProbMetric: 4.2332 - lr: 2.5000e-04 - 85s/epoch - 434ms/step
Epoch 176/1000
2023-09-17 15:37:41.490 
Epoch 176/1000 
	 loss: 3.8830, MinusLogProbMetric: 3.8830, val_loss: 4.2397, val_MinusLogProbMetric: 4.2397

Epoch 176: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.8830 - MinusLogProbMetric: 3.8830 - val_loss: 4.2397 - val_MinusLogProbMetric: 4.2397 - lr: 2.5000e-04 - 84s/epoch - 427ms/step
Epoch 177/1000
2023-09-17 15:39:05.617 
Epoch 177/1000 
	 loss: 3.8849, MinusLogProbMetric: 3.8849, val_loss: 4.2382, val_MinusLogProbMetric: 4.2382

Epoch 177: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.8849 - MinusLogProbMetric: 3.8849 - val_loss: 4.2382 - val_MinusLogProbMetric: 4.2382 - lr: 2.5000e-04 - 84s/epoch - 429ms/step
Epoch 178/1000
2023-09-17 15:40:29.854 
Epoch 178/1000 
	 loss: 3.8811, MinusLogProbMetric: 3.8811, val_loss: 4.2356, val_MinusLogProbMetric: 4.2356

Epoch 178: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.8811 - MinusLogProbMetric: 3.8811 - val_loss: 4.2356 - val_MinusLogProbMetric: 4.2356 - lr: 2.5000e-04 - 84s/epoch - 430ms/step
Epoch 179/1000
2023-09-17 15:41:53.893 
Epoch 179/1000 
	 loss: 3.8810, MinusLogProbMetric: 3.8810, val_loss: 4.2511, val_MinusLogProbMetric: 4.2511

Epoch 179: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.8810 - MinusLogProbMetric: 3.8810 - val_loss: 4.2511 - val_MinusLogProbMetric: 4.2511 - lr: 2.5000e-04 - 84s/epoch - 429ms/step
Epoch 180/1000
2023-09-17 15:43:19.014 
Epoch 180/1000 
	 loss: 3.8826, MinusLogProbMetric: 3.8826, val_loss: 4.2679, val_MinusLogProbMetric: 4.2679

Epoch 180: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8826 - MinusLogProbMetric: 3.8826 - val_loss: 4.2679 - val_MinusLogProbMetric: 4.2679 - lr: 2.5000e-04 - 85s/epoch - 434ms/step
Epoch 181/1000
2023-09-17 15:44:43.597 
Epoch 181/1000 
	 loss: 3.8830, MinusLogProbMetric: 3.8830, val_loss: 4.2528, val_MinusLogProbMetric: 4.2528

Epoch 181: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8830 - MinusLogProbMetric: 3.8830 - val_loss: 4.2528 - val_MinusLogProbMetric: 4.2528 - lr: 2.5000e-04 - 85s/epoch - 432ms/step
Epoch 182/1000
2023-09-17 15:46:08.931 
Epoch 182/1000 
	 loss: 3.8759, MinusLogProbMetric: 3.8759, val_loss: 4.2453, val_MinusLogProbMetric: 4.2453

Epoch 182: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8759 - MinusLogProbMetric: 3.8759 - val_loss: 4.2453 - val_MinusLogProbMetric: 4.2453 - lr: 2.5000e-04 - 85s/epoch - 435ms/step
Epoch 183/1000
2023-09-17 15:47:34.197 
Epoch 183/1000 
	 loss: 3.8787, MinusLogProbMetric: 3.8787, val_loss: 4.2580, val_MinusLogProbMetric: 4.2580

Epoch 183: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8787 - MinusLogProbMetric: 3.8787 - val_loss: 4.2580 - val_MinusLogProbMetric: 4.2580 - lr: 2.5000e-04 - 85s/epoch - 435ms/step
Epoch 184/1000
2023-09-17 15:48:58.385 
Epoch 184/1000 
	 loss: 3.8778, MinusLogProbMetric: 3.8778, val_loss: 4.2625, val_MinusLogProbMetric: 4.2625

Epoch 184: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.8778 - MinusLogProbMetric: 3.8778 - val_loss: 4.2625 - val_MinusLogProbMetric: 4.2625 - lr: 2.5000e-04 - 84s/epoch - 430ms/step
Epoch 185/1000
2023-09-17 15:50:23.593 
Epoch 185/1000 
	 loss: 3.8777, MinusLogProbMetric: 3.8777, val_loss: 4.2515, val_MinusLogProbMetric: 4.2515

Epoch 185: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8777 - MinusLogProbMetric: 3.8777 - val_loss: 4.2515 - val_MinusLogProbMetric: 4.2515 - lr: 2.5000e-04 - 85s/epoch - 435ms/step
Epoch 186/1000
2023-09-17 15:51:48.518 
Epoch 186/1000 
	 loss: 3.8765, MinusLogProbMetric: 3.8765, val_loss: 4.2507, val_MinusLogProbMetric: 4.2507

Epoch 186: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8765 - MinusLogProbMetric: 3.8765 - val_loss: 4.2507 - val_MinusLogProbMetric: 4.2507 - lr: 2.5000e-04 - 85s/epoch - 433ms/step
Epoch 187/1000
2023-09-17 15:53:13.702 
Epoch 187/1000 
	 loss: 3.8756, MinusLogProbMetric: 3.8756, val_loss: 4.2476, val_MinusLogProbMetric: 4.2476

Epoch 187: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8756 - MinusLogProbMetric: 3.8756 - val_loss: 4.2476 - val_MinusLogProbMetric: 4.2476 - lr: 2.5000e-04 - 85s/epoch - 435ms/step
Epoch 188/1000
2023-09-17 15:54:38.006 
Epoch 188/1000 
	 loss: 3.8762, MinusLogProbMetric: 3.8762, val_loss: 4.2919, val_MinusLogProbMetric: 4.2919

Epoch 188: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.8762 - MinusLogProbMetric: 3.8762 - val_loss: 4.2919 - val_MinusLogProbMetric: 4.2919 - lr: 2.5000e-04 - 84s/epoch - 430ms/step
Epoch 189/1000
2023-09-17 15:56:02.531 
Epoch 189/1000 
	 loss: 3.8738, MinusLogProbMetric: 3.8738, val_loss: 4.2460, val_MinusLogProbMetric: 4.2460

Epoch 189: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8738 - MinusLogProbMetric: 3.8738 - val_loss: 4.2460 - val_MinusLogProbMetric: 4.2460 - lr: 2.5000e-04 - 85s/epoch - 431ms/step
Epoch 190/1000
2023-09-17 15:57:26.518 
Epoch 190/1000 
	 loss: 3.8712, MinusLogProbMetric: 3.8712, val_loss: 4.2616, val_MinusLogProbMetric: 4.2616

Epoch 190: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.8712 - MinusLogProbMetric: 3.8712 - val_loss: 4.2616 - val_MinusLogProbMetric: 4.2616 - lr: 2.5000e-04 - 84s/epoch - 428ms/step
Epoch 191/1000
2023-09-17 15:58:51.072 
Epoch 191/1000 
	 loss: 3.8712, MinusLogProbMetric: 3.8712, val_loss: 4.2592, val_MinusLogProbMetric: 4.2592

Epoch 191: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8712 - MinusLogProbMetric: 3.8712 - val_loss: 4.2592 - val_MinusLogProbMetric: 4.2592 - lr: 2.5000e-04 - 85s/epoch - 431ms/step
Epoch 192/1000
2023-09-17 16:00:15.833 
Epoch 192/1000 
	 loss: 3.8729, MinusLogProbMetric: 3.8729, val_loss: 4.2556, val_MinusLogProbMetric: 4.2556

Epoch 192: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8729 - MinusLogProbMetric: 3.8729 - val_loss: 4.2556 - val_MinusLogProbMetric: 4.2556 - lr: 2.5000e-04 - 85s/epoch - 432ms/step
Epoch 193/1000
2023-09-17 16:01:39.987 
Epoch 193/1000 
	 loss: 3.8681, MinusLogProbMetric: 3.8681, val_loss: 4.2594, val_MinusLogProbMetric: 4.2594

Epoch 193: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.8681 - MinusLogProbMetric: 3.8681 - val_loss: 4.2594 - val_MinusLogProbMetric: 4.2594 - lr: 2.5000e-04 - 84s/epoch - 429ms/step
Epoch 194/1000
2023-09-17 16:03:04.041 
Epoch 194/1000 
	 loss: 3.8673, MinusLogProbMetric: 3.8673, val_loss: 4.2611, val_MinusLogProbMetric: 4.2611

Epoch 194: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.8673 - MinusLogProbMetric: 3.8673 - val_loss: 4.2611 - val_MinusLogProbMetric: 4.2611 - lr: 2.5000e-04 - 84s/epoch - 429ms/step
Epoch 195/1000
2023-09-17 16:04:29.145 
Epoch 195/1000 
	 loss: 3.8672, MinusLogProbMetric: 3.8672, val_loss: 4.2571, val_MinusLogProbMetric: 4.2571

Epoch 195: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8672 - MinusLogProbMetric: 3.8672 - val_loss: 4.2571 - val_MinusLogProbMetric: 4.2571 - lr: 2.5000e-04 - 85s/epoch - 434ms/step
Epoch 196/1000
2023-09-17 16:05:53.241 
Epoch 196/1000 
	 loss: 3.8721, MinusLogProbMetric: 3.8721, val_loss: 4.2634, val_MinusLogProbMetric: 4.2634

Epoch 196: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.8721 - MinusLogProbMetric: 3.8721 - val_loss: 4.2634 - val_MinusLogProbMetric: 4.2634 - lr: 2.5000e-04 - 84s/epoch - 429ms/step
Epoch 197/1000
2023-09-17 16:07:17.710 
Epoch 197/1000 
	 loss: 3.8654, MinusLogProbMetric: 3.8654, val_loss: 4.2891, val_MinusLogProbMetric: 4.2891

Epoch 197: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.8654 - MinusLogProbMetric: 3.8654 - val_loss: 4.2891 - val_MinusLogProbMetric: 4.2891 - lr: 2.5000e-04 - 84s/epoch - 431ms/step
Epoch 198/1000
2023-09-17 16:08:41.649 
Epoch 198/1000 
	 loss: 3.8711, MinusLogProbMetric: 3.8711, val_loss: 4.2743, val_MinusLogProbMetric: 4.2743

Epoch 198: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.8711 - MinusLogProbMetric: 3.8711 - val_loss: 4.2743 - val_MinusLogProbMetric: 4.2743 - lr: 2.5000e-04 - 84s/epoch - 428ms/step
Epoch 199/1000
2023-09-17 16:10:04.640 
Epoch 199/1000 
	 loss: 3.8686, MinusLogProbMetric: 3.8686, val_loss: 4.2708, val_MinusLogProbMetric: 4.2708

Epoch 199: val_loss did not improve from 4.16169
196/196 - 83s - loss: 3.8686 - MinusLogProbMetric: 3.8686 - val_loss: 4.2708 - val_MinusLogProbMetric: 4.2708 - lr: 2.5000e-04 - 83s/epoch - 423ms/step
Epoch 200/1000
2023-09-17 16:11:29.434 
Epoch 200/1000 
	 loss: 3.8706, MinusLogProbMetric: 3.8706, val_loss: 4.2634, val_MinusLogProbMetric: 4.2634

Epoch 200: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8706 - MinusLogProbMetric: 3.8706 - val_loss: 4.2634 - val_MinusLogProbMetric: 4.2634 - lr: 2.5000e-04 - 85s/epoch - 433ms/step
Epoch 201/1000
2023-09-17 16:12:53.188 
Epoch 201/1000 
	 loss: 3.8643, MinusLogProbMetric: 3.8643, val_loss: 4.2634, val_MinusLogProbMetric: 4.2634

Epoch 201: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.8643 - MinusLogProbMetric: 3.8643 - val_loss: 4.2634 - val_MinusLogProbMetric: 4.2634 - lr: 2.5000e-04 - 84s/epoch - 427ms/step
Epoch 202/1000
2023-09-17 16:14:18.722 
Epoch 202/1000 
	 loss: 3.8673, MinusLogProbMetric: 3.8673, val_loss: 4.2811, val_MinusLogProbMetric: 4.2811

Epoch 202: val_loss did not improve from 4.16169
196/196 - 86s - loss: 3.8673 - MinusLogProbMetric: 3.8673 - val_loss: 4.2811 - val_MinusLogProbMetric: 4.2811 - lr: 2.5000e-04 - 86s/epoch - 436ms/step
Epoch 203/1000
2023-09-17 16:15:43.505 
Epoch 203/1000 
	 loss: 3.8666, MinusLogProbMetric: 3.8666, val_loss: 4.2706, val_MinusLogProbMetric: 4.2706

Epoch 203: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8666 - MinusLogProbMetric: 3.8666 - val_loss: 4.2706 - val_MinusLogProbMetric: 4.2706 - lr: 2.5000e-04 - 85s/epoch - 433ms/step
Epoch 204/1000
2023-09-17 16:17:09.051 
Epoch 204/1000 
	 loss: 3.8611, MinusLogProbMetric: 3.8611, val_loss: 4.2729, val_MinusLogProbMetric: 4.2729

Epoch 204: val_loss did not improve from 4.16169
196/196 - 86s - loss: 3.8611 - MinusLogProbMetric: 3.8611 - val_loss: 4.2729 - val_MinusLogProbMetric: 4.2729 - lr: 2.5000e-04 - 86s/epoch - 436ms/step
Epoch 205/1000
2023-09-17 16:18:34.483 
Epoch 205/1000 
	 loss: 3.8651, MinusLogProbMetric: 3.8651, val_loss: 4.2635, val_MinusLogProbMetric: 4.2635

Epoch 205: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8651 - MinusLogProbMetric: 3.8651 - val_loss: 4.2635 - val_MinusLogProbMetric: 4.2635 - lr: 2.5000e-04 - 85s/epoch - 436ms/step
Epoch 206/1000
2023-09-17 16:19:59.516 
Epoch 206/1000 
	 loss: 3.8600, MinusLogProbMetric: 3.8600, val_loss: 4.2821, val_MinusLogProbMetric: 4.2821

Epoch 206: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8600 - MinusLogProbMetric: 3.8600 - val_loss: 4.2821 - val_MinusLogProbMetric: 4.2821 - lr: 2.5000e-04 - 85s/epoch - 434ms/step
Epoch 207/1000
2023-09-17 16:21:24.311 
Epoch 207/1000 
	 loss: 3.8596, MinusLogProbMetric: 3.8596, val_loss: 4.2869, val_MinusLogProbMetric: 4.2869

Epoch 207: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8596 - MinusLogProbMetric: 3.8596 - val_loss: 4.2869 - val_MinusLogProbMetric: 4.2869 - lr: 2.5000e-04 - 85s/epoch - 433ms/step
Epoch 208/1000
2023-09-17 16:22:48.511 
Epoch 208/1000 
	 loss: 3.8593, MinusLogProbMetric: 3.8593, val_loss: 4.2726, val_MinusLogProbMetric: 4.2726

Epoch 208: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.8593 - MinusLogProbMetric: 3.8593 - val_loss: 4.2726 - val_MinusLogProbMetric: 4.2726 - lr: 2.5000e-04 - 84s/epoch - 430ms/step
Epoch 209/1000
2023-09-17 16:24:13.115 
Epoch 209/1000 
	 loss: 3.8603, MinusLogProbMetric: 3.8603, val_loss: 4.2811, val_MinusLogProbMetric: 4.2811

Epoch 209: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8603 - MinusLogProbMetric: 3.8603 - val_loss: 4.2811 - val_MinusLogProbMetric: 4.2811 - lr: 2.5000e-04 - 85s/epoch - 432ms/step
Epoch 210/1000
2023-09-17 16:25:38.006 
Epoch 210/1000 
	 loss: 3.8612, MinusLogProbMetric: 3.8612, val_loss: 4.2965, val_MinusLogProbMetric: 4.2965

Epoch 210: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8612 - MinusLogProbMetric: 3.8612 - val_loss: 4.2965 - val_MinusLogProbMetric: 4.2965 - lr: 2.5000e-04 - 85s/epoch - 433ms/step
Epoch 211/1000
2023-09-17 16:27:02.236 
Epoch 211/1000 
	 loss: 3.8564, MinusLogProbMetric: 3.8564, val_loss: 4.2779, val_MinusLogProbMetric: 4.2779

Epoch 211: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.8564 - MinusLogProbMetric: 3.8564 - val_loss: 4.2779 - val_MinusLogProbMetric: 4.2779 - lr: 2.5000e-04 - 84s/epoch - 430ms/step
Epoch 212/1000
2023-09-17 16:28:26.687 
Epoch 212/1000 
	 loss: 3.8559, MinusLogProbMetric: 3.8559, val_loss: 4.2797, val_MinusLogProbMetric: 4.2797

Epoch 212: val_loss did not improve from 4.16169
196/196 - 84s - loss: 3.8559 - MinusLogProbMetric: 3.8559 - val_loss: 4.2797 - val_MinusLogProbMetric: 4.2797 - lr: 2.5000e-04 - 84s/epoch - 431ms/step
Epoch 213/1000
2023-09-17 16:29:51.878 
Epoch 213/1000 
	 loss: 3.8612, MinusLogProbMetric: 3.8612, val_loss: 4.2752, val_MinusLogProbMetric: 4.2752

Epoch 213: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8612 - MinusLogProbMetric: 3.8612 - val_loss: 4.2752 - val_MinusLogProbMetric: 4.2752 - lr: 2.5000e-04 - 85s/epoch - 435ms/step
Epoch 214/1000
2023-09-17 16:31:16.634 
Epoch 214/1000 
	 loss: 3.8543, MinusLogProbMetric: 3.8543, val_loss: 4.2832, val_MinusLogProbMetric: 4.2832

Epoch 214: val_loss did not improve from 4.16169
196/196 - 85s - loss: 3.8543 - MinusLogProbMetric: 3.8543 - val_loss: 4.2832 - val_MinusLogProbMetric: 4.2832 - lr: 2.5000e-04 - 85s/epoch - 432ms/step
Epoch 215/1000
2023-09-17 16:32:41.694 
Epoch 215/1000 
	 loss: 3.8557, MinusLogProbMetric: 3.8557, val_loss: 4.2723, val_MinusLogProbMetric: 4.2723

Epoch 215: val_loss did not improve from 4.16169
Restoring model weights from the end of the best epoch: 115.
196/196 - 86s - loss: 3.8557 - MinusLogProbMetric: 3.8557 - val_loss: 4.2723 - val_MinusLogProbMetric: 4.2723 - lr: 2.5000e-04 - 86s/epoch - 439ms/step
Epoch 215: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 34.25748025602661 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 15.118367145070806 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 12.319800214841962 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fafb4280ee0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 37.724503222852945 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 10.940948164090514 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 10.45856780000031 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fb01067f250> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 541.
Model trained in 17958.67 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

Plots done in 8.69 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 174.75 s.
===========
Run 128/720 done in 18145.12 s.
===========

Directory ../../results/CsplineN_new/run_129/ already exists.
Skipping it.
===========
Run 129/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_130/ already exists.
Skipping it.
===========
Run 130/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_131/ already exists.
Skipping it.
===========
Run 131/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_132/ already exists.
Skipping it.
===========
Run 132/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_133/ already exists.
Skipping it.
===========
Run 133/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_134/ already exists.
Skipping it.
===========
Run 134/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_135/ already exists.
Skipping it.
===========
Run 135/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_136/ already exists.
Skipping it.
===========
Run 136/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_137/ already exists.
Skipping it.
===========
Run 137/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_138/ already exists.
Skipping it.
===========
Run 138/720 already exists. Skipping it.
===========

===========
Generating train data for run 139.
===========
Train data generated in 0.24 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 8)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_139/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 869}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_139/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 0.61799645,  8.237518  ,  8.006255  , ...,  7.834555  ,
         4.7280736 ,  7.689174  ],
       [ 5.481625  ,  6.9627843 ,  5.7126226 , ...,  6.6819267 ,
         4.8551073 ,  8.634348  ],
       [ 5.299945  ,  6.518964  ,  6.039483  , ...,  6.3382916 ,
         4.9134555 ,  9.522966  ],
       ...,
       [-0.205272  ,  8.150926  ,  7.3524895 , ...,  7.5290494 ,
         4.8201356 ,  7.6373005 ],
       [ 5.388147  ,  6.632578  ,  5.747198  , ...,  6.5986295 ,
         4.313551  ,  8.522521  ],
       [ 0.42833382,  8.747221  ,  7.0049896 , ...,  8.388566  ,
         4.799433  ,  7.7025967 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_139/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_139
self.data_kwargs: {'seed': 869}
self.x_data: [[ 0.0866988   8.150065    8.732732   ...  8.2140045   4.4064074
   7.8443403 ]
 [ 0.42227775  7.744668    7.734037   ...  7.100643    4.6667027
   7.8751583 ]
 [-0.30241555  9.065342    7.5888805  ...  7.0850635   4.936197
   7.917019  ]
 ...
 [ 9.04035     3.18411     7.9490247  ...  9.436011    1.4732187
   0.9044997 ]
 [ 0.14992183  7.905571    7.5591397  ...  7.754206    4.6232414
   7.742322  ]
 [ 0.07435906  8.626885    6.995445   ...  7.934003    4.403983
   7.611454  ]]
self.y_data: []
self.ndims: 8
Model defined.
Model: "model_100"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_101 (InputLayer)      [(None, 8)]               0         
                                                                 
 log_prob_layer_10 (LogProbL  (None,)                  258620    
 ayer)                                                           
                                                                 
=================================================================
Total params: 258,620
Trainable params: 258,620
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_10/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_10'")
self.model: <keras.engine.functional.Functional object at 0x7faea5ec0550>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7faeccaf1750>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7faeccaf1750>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7faeacb6dcc0>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7faea5534ee0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7faea5535450>, <keras.callbacks.ModelCheckpoint object at 0x7faea5535510>, <keras.callbacks.EarlyStopping object at 0x7faea5535780>, <keras.callbacks.ReduceLROnPlateau object at 0x7faea55357b0>, <keras.callbacks.TerminateOnNaN object at 0x7faea55353f0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 0.61799645,  8.237518  ,  8.006255  , ...,  7.834555  ,
         4.7280736 ,  7.689174  ],
       [ 5.481625  ,  6.9627843 ,  5.7126226 , ...,  6.6819267 ,
         4.8551073 ,  8.634348  ],
       [ 5.299945  ,  6.518964  ,  6.039483  , ...,  6.3382916 ,
         4.9134555 ,  9.522966  ],
       ...,
       [-0.205272  ,  8.150926  ,  7.3524895 , ...,  7.5290494 ,
         4.8201356 ,  7.6373005 ],
       [ 5.388147  ,  6.632578  ,  5.747198  , ...,  6.5986295 ,
         4.313551  ,  8.522521  ],
       [ 0.42833382,  8.747221  ,  7.0049896 , ...,  8.388566  ,
         4.799433  ,  7.7025967 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_139/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 139/720 with hyperparameters:
timestamp = 2023-09-17 16:35:43.965001
ndims = 8
seed_train = 869
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 5
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 258620
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 0.0866988  8.150065   8.732732   8.70646   10.149027   8.2140045
  4.4064074  7.8443403]
Epoch 1/1000
2023-09-17 16:37:49.874 
Epoch 1/1000 
	 loss: 14.2400, MinusLogProbMetric: 14.2400, val_loss: 6.3900, val_MinusLogProbMetric: 6.3900

Epoch 1: val_loss improved from inf to 6.39000, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 127s - loss: 14.2400 - MinusLogProbMetric: 14.2400 - val_loss: 6.3900 - val_MinusLogProbMetric: 6.3900 - lr: 0.0010 - 127s/epoch - 646ms/step
Epoch 2/1000
2023-09-17 16:38:34.832 
Epoch 2/1000 
	 loss: 5.9784, MinusLogProbMetric: 5.9784, val_loss: 6.4653, val_MinusLogProbMetric: 6.4653

Epoch 2: val_loss did not improve from 6.39000
196/196 - 44s - loss: 5.9784 - MinusLogProbMetric: 5.9784 - val_loss: 6.4653 - val_MinusLogProbMetric: 6.4653 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 3/1000
2023-09-17 16:39:18.223 
Epoch 3/1000 
	 loss: 5.3902, MinusLogProbMetric: 5.3902, val_loss: 5.2862, val_MinusLogProbMetric: 5.2862

Epoch 3: val_loss improved from 6.39000 to 5.28615, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 44s - loss: 5.3902 - MinusLogProbMetric: 5.3902 - val_loss: 5.2862 - val_MinusLogProbMetric: 5.2862 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 4/1000
2023-09-17 16:40:03.048 
Epoch 4/1000 
	 loss: 5.0992, MinusLogProbMetric: 5.0992, val_loss: 4.8654, val_MinusLogProbMetric: 4.8654

Epoch 4: val_loss improved from 5.28615 to 4.86540, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 45s - loss: 5.0992 - MinusLogProbMetric: 5.0992 - val_loss: 4.8654 - val_MinusLogProbMetric: 4.8654 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 5/1000
2023-09-17 16:40:47.681 
Epoch 5/1000 
	 loss: 5.0609, MinusLogProbMetric: 5.0609, val_loss: 5.4358, val_MinusLogProbMetric: 5.4358

Epoch 5: val_loss did not improve from 4.86540
196/196 - 44s - loss: 5.0609 - MinusLogProbMetric: 5.0609 - val_loss: 5.4358 - val_MinusLogProbMetric: 5.4358 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 6/1000
2023-09-17 16:41:31.632 
Epoch 6/1000 
	 loss: 4.8513, MinusLogProbMetric: 4.8513, val_loss: 4.8470, val_MinusLogProbMetric: 4.8470

Epoch 6: val_loss improved from 4.86540 to 4.84697, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 45s - loss: 4.8513 - MinusLogProbMetric: 4.8513 - val_loss: 4.8470 - val_MinusLogProbMetric: 4.8470 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 7/1000
2023-09-17 16:42:16.734 
Epoch 7/1000 
	 loss: 4.7044, MinusLogProbMetric: 4.7044, val_loss: 4.4835, val_MinusLogProbMetric: 4.4835

Epoch 7: val_loss improved from 4.84697 to 4.48352, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 45s - loss: 4.7044 - MinusLogProbMetric: 4.7044 - val_loss: 4.4835 - val_MinusLogProbMetric: 4.4835 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 8/1000
2023-09-17 16:43:02.166 
Epoch 8/1000 
	 loss: 4.6393, MinusLogProbMetric: 4.6393, val_loss: 4.4202, val_MinusLogProbMetric: 4.4202

Epoch 8: val_loss improved from 4.48352 to 4.42025, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 45s - loss: 4.6393 - MinusLogProbMetric: 4.6393 - val_loss: 4.4202 - val_MinusLogProbMetric: 4.4202 - lr: 0.0010 - 45s/epoch - 231ms/step
Epoch 9/1000
2023-09-17 16:43:47.515 
Epoch 9/1000 
	 loss: 4.4831, MinusLogProbMetric: 4.4831, val_loss: 4.3707, val_MinusLogProbMetric: 4.3707

Epoch 9: val_loss improved from 4.42025 to 4.37074, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 45s - loss: 4.4831 - MinusLogProbMetric: 4.4831 - val_loss: 4.3707 - val_MinusLogProbMetric: 4.3707 - lr: 0.0010 - 45s/epoch - 231ms/step
Epoch 10/1000
2023-09-17 16:44:32.607 
Epoch 10/1000 
	 loss: 4.5511, MinusLogProbMetric: 4.5511, val_loss: 4.5478, val_MinusLogProbMetric: 4.5478

Epoch 10: val_loss did not improve from 4.37074
196/196 - 44s - loss: 4.5511 - MinusLogProbMetric: 4.5511 - val_loss: 4.5478 - val_MinusLogProbMetric: 4.5478 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 11/1000
2023-09-17 16:45:17.319 
Epoch 11/1000 
	 loss: 4.4565, MinusLogProbMetric: 4.4565, val_loss: 4.3087, val_MinusLogProbMetric: 4.3087

Epoch 11: val_loss improved from 4.37074 to 4.30866, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 46s - loss: 4.4565 - MinusLogProbMetric: 4.4565 - val_loss: 4.3087 - val_MinusLogProbMetric: 4.3087 - lr: 0.0010 - 46s/epoch - 232ms/step
Epoch 12/1000
2023-09-17 16:46:02.779 
Epoch 12/1000 
	 loss: 4.4483, MinusLogProbMetric: 4.4483, val_loss: 4.4062, val_MinusLogProbMetric: 4.4062

Epoch 12: val_loss did not improve from 4.30866
196/196 - 45s - loss: 4.4483 - MinusLogProbMetric: 4.4483 - val_loss: 4.4062 - val_MinusLogProbMetric: 4.4062 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 13/1000
2023-09-17 16:46:47.292 
Epoch 13/1000 
	 loss: 4.3972, MinusLogProbMetric: 4.3972, val_loss: 4.5287, val_MinusLogProbMetric: 4.5287

Epoch 13: val_loss did not improve from 4.30866
196/196 - 45s - loss: 4.3972 - MinusLogProbMetric: 4.3972 - val_loss: 4.5287 - val_MinusLogProbMetric: 4.5287 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 14/1000
2023-09-17 16:47:32.468 
Epoch 14/1000 
	 loss: 4.3607, MinusLogProbMetric: 4.3607, val_loss: 4.3029, val_MinusLogProbMetric: 4.3029

Epoch 14: val_loss improved from 4.30866 to 4.30285, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 46s - loss: 4.3607 - MinusLogProbMetric: 4.3607 - val_loss: 4.3029 - val_MinusLogProbMetric: 4.3029 - lr: 0.0010 - 46s/epoch - 235ms/step
Epoch 15/1000
2023-09-17 16:48:18.399 
Epoch 15/1000 
	 loss: 4.3462, MinusLogProbMetric: 4.3462, val_loss: 4.8179, val_MinusLogProbMetric: 4.8179

Epoch 15: val_loss did not improve from 4.30285
196/196 - 45s - loss: 4.3462 - MinusLogProbMetric: 4.3462 - val_loss: 4.8179 - val_MinusLogProbMetric: 4.8179 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 16/1000
2023-09-17 16:49:03.129 
Epoch 16/1000 
	 loss: 4.3137, MinusLogProbMetric: 4.3137, val_loss: 4.3988, val_MinusLogProbMetric: 4.3988

Epoch 16: val_loss did not improve from 4.30285
196/196 - 45s - loss: 4.3137 - MinusLogProbMetric: 4.3137 - val_loss: 4.3988 - val_MinusLogProbMetric: 4.3988 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 17/1000
2023-09-17 16:49:47.675 
Epoch 17/1000 
	 loss: 4.3226, MinusLogProbMetric: 4.3226, val_loss: 4.3467, val_MinusLogProbMetric: 4.3467

Epoch 17: val_loss did not improve from 4.30285
196/196 - 45s - loss: 4.3226 - MinusLogProbMetric: 4.3226 - val_loss: 4.3467 - val_MinusLogProbMetric: 4.3467 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 18/1000
2023-09-17 16:50:32.333 
Epoch 18/1000 
	 loss: 4.2738, MinusLogProbMetric: 4.2738, val_loss: 4.4110, val_MinusLogProbMetric: 4.4110

Epoch 18: val_loss did not improve from 4.30285
196/196 - 45s - loss: 4.2738 - MinusLogProbMetric: 4.2738 - val_loss: 4.4110 - val_MinusLogProbMetric: 4.4110 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 19/1000
2023-09-17 16:51:17.238 
Epoch 19/1000 
	 loss: 4.2799, MinusLogProbMetric: 4.2799, val_loss: 4.3412, val_MinusLogProbMetric: 4.3412

Epoch 19: val_loss did not improve from 4.30285
196/196 - 45s - loss: 4.2799 - MinusLogProbMetric: 4.2799 - val_loss: 4.3412 - val_MinusLogProbMetric: 4.3412 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 20/1000
2023-09-17 16:52:01.991 
Epoch 20/1000 
	 loss: 4.2776, MinusLogProbMetric: 4.2776, val_loss: 4.3308, val_MinusLogProbMetric: 4.3308

Epoch 20: val_loss did not improve from 4.30285
196/196 - 45s - loss: 4.2776 - MinusLogProbMetric: 4.2776 - val_loss: 4.3308 - val_MinusLogProbMetric: 4.3308 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 21/1000
2023-09-17 16:52:46.668 
Epoch 21/1000 
	 loss: 4.2678, MinusLogProbMetric: 4.2678, val_loss: 4.4327, val_MinusLogProbMetric: 4.4327

Epoch 21: val_loss did not improve from 4.30285
196/196 - 45s - loss: 4.2678 - MinusLogProbMetric: 4.2678 - val_loss: 4.4327 - val_MinusLogProbMetric: 4.4327 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 22/1000
2023-09-17 16:53:31.444 
Epoch 22/1000 
	 loss: 4.2694, MinusLogProbMetric: 4.2694, val_loss: 4.2160, val_MinusLogProbMetric: 4.2160

Epoch 22: val_loss improved from 4.30285 to 4.21603, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 46s - loss: 4.2694 - MinusLogProbMetric: 4.2694 - val_loss: 4.2160 - val_MinusLogProbMetric: 4.2160 - lr: 0.0010 - 46s/epoch - 233ms/step
Epoch 23/1000
2023-09-17 16:54:16.908 
Epoch 23/1000 
	 loss: 4.2422, MinusLogProbMetric: 4.2422, val_loss: 4.2578, val_MinusLogProbMetric: 4.2578

Epoch 23: val_loss did not improve from 4.21603
196/196 - 45s - loss: 4.2422 - MinusLogProbMetric: 4.2422 - val_loss: 4.2578 - val_MinusLogProbMetric: 4.2578 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 24/1000
2023-09-17 16:55:01.748 
Epoch 24/1000 
	 loss: 4.2477, MinusLogProbMetric: 4.2477, val_loss: 4.5302, val_MinusLogProbMetric: 4.5302

Epoch 24: val_loss did not improve from 4.21603
196/196 - 45s - loss: 4.2477 - MinusLogProbMetric: 4.2477 - val_loss: 4.5302 - val_MinusLogProbMetric: 4.5302 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 25/1000
2023-09-17 16:55:46.752 
Epoch 25/1000 
	 loss: 4.2442, MinusLogProbMetric: 4.2442, val_loss: 4.2078, val_MinusLogProbMetric: 4.2078

Epoch 25: val_loss improved from 4.21603 to 4.20776, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 46s - loss: 4.2442 - MinusLogProbMetric: 4.2442 - val_loss: 4.2078 - val_MinusLogProbMetric: 4.2078 - lr: 0.0010 - 46s/epoch - 234ms/step
Epoch 26/1000
2023-09-17 16:56:32.614 
Epoch 26/1000 
	 loss: 4.2171, MinusLogProbMetric: 4.2171, val_loss: 4.3938, val_MinusLogProbMetric: 4.3938

Epoch 26: val_loss did not improve from 4.20776
196/196 - 45s - loss: 4.2171 - MinusLogProbMetric: 4.2171 - val_loss: 4.3938 - val_MinusLogProbMetric: 4.3938 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 27/1000
2023-09-17 16:57:17.757 
Epoch 27/1000 
	 loss: 4.2341, MinusLogProbMetric: 4.2341, val_loss: 4.2823, val_MinusLogProbMetric: 4.2823

Epoch 27: val_loss did not improve from 4.20776
196/196 - 45s - loss: 4.2341 - MinusLogProbMetric: 4.2341 - val_loss: 4.2823 - val_MinusLogProbMetric: 4.2823 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 28/1000
2023-09-17 16:58:02.547 
Epoch 28/1000 
	 loss: 4.2191, MinusLogProbMetric: 4.2191, val_loss: 4.2948, val_MinusLogProbMetric: 4.2948

Epoch 28: val_loss did not improve from 4.20776
196/196 - 45s - loss: 4.2191 - MinusLogProbMetric: 4.2191 - val_loss: 4.2948 - val_MinusLogProbMetric: 4.2948 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 29/1000
2023-09-17 16:58:47.542 
Epoch 29/1000 
	 loss: 4.2293, MinusLogProbMetric: 4.2293, val_loss: 4.2730, val_MinusLogProbMetric: 4.2730

Epoch 29: val_loss did not improve from 4.20776
196/196 - 45s - loss: 4.2293 - MinusLogProbMetric: 4.2293 - val_loss: 4.2730 - val_MinusLogProbMetric: 4.2730 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 30/1000
2023-09-17 16:59:32.634 
Epoch 30/1000 
	 loss: 4.2136, MinusLogProbMetric: 4.2136, val_loss: 4.3330, val_MinusLogProbMetric: 4.3330

Epoch 30: val_loss did not improve from 4.20776
196/196 - 45s - loss: 4.2136 - MinusLogProbMetric: 4.2136 - val_loss: 4.3330 - val_MinusLogProbMetric: 4.3330 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 31/1000
2023-09-17 17:00:17.676 
Epoch 31/1000 
	 loss: 4.2029, MinusLogProbMetric: 4.2029, val_loss: 4.2152, val_MinusLogProbMetric: 4.2152

Epoch 31: val_loss did not improve from 4.20776
196/196 - 45s - loss: 4.2029 - MinusLogProbMetric: 4.2029 - val_loss: 4.2152 - val_MinusLogProbMetric: 4.2152 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 32/1000
2023-09-17 17:01:02.757 
Epoch 32/1000 
	 loss: 4.2027, MinusLogProbMetric: 4.2027, val_loss: 4.2009, val_MinusLogProbMetric: 4.2009

Epoch 32: val_loss improved from 4.20776 to 4.20091, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 46s - loss: 4.2027 - MinusLogProbMetric: 4.2027 - val_loss: 4.2009 - val_MinusLogProbMetric: 4.2009 - lr: 0.0010 - 46s/epoch - 235ms/step
Epoch 33/1000
2023-09-17 17:01:48.537 
Epoch 33/1000 
	 loss: 4.1937, MinusLogProbMetric: 4.1937, val_loss: 4.2159, val_MinusLogProbMetric: 4.2159

Epoch 33: val_loss did not improve from 4.20091
196/196 - 45s - loss: 4.1937 - MinusLogProbMetric: 4.1937 - val_loss: 4.2159 - val_MinusLogProbMetric: 4.2159 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 34/1000
2023-09-17 17:02:33.689 
Epoch 34/1000 
	 loss: 4.2088, MinusLogProbMetric: 4.2088, val_loss: 4.2820, val_MinusLogProbMetric: 4.2820

Epoch 34: val_loss did not improve from 4.20091
196/196 - 45s - loss: 4.2088 - MinusLogProbMetric: 4.2088 - val_loss: 4.2820 - val_MinusLogProbMetric: 4.2820 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 35/1000
2023-09-17 17:03:18.524 
Epoch 35/1000 
	 loss: 4.2101, MinusLogProbMetric: 4.2101, val_loss: 4.2797, val_MinusLogProbMetric: 4.2797

Epoch 35: val_loss did not improve from 4.20091
196/196 - 45s - loss: 4.2101 - MinusLogProbMetric: 4.2101 - val_loss: 4.2797 - val_MinusLogProbMetric: 4.2797 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 36/1000
2023-09-17 17:04:03.473 
Epoch 36/1000 
	 loss: 4.1890, MinusLogProbMetric: 4.1890, val_loss: 4.2094, val_MinusLogProbMetric: 4.2094

Epoch 36: val_loss did not improve from 4.20091
196/196 - 45s - loss: 4.1890 - MinusLogProbMetric: 4.1890 - val_loss: 4.2094 - val_MinusLogProbMetric: 4.2094 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 37/1000
2023-09-17 17:04:48.495 
Epoch 37/1000 
	 loss: 4.1918, MinusLogProbMetric: 4.1918, val_loss: 4.2891, val_MinusLogProbMetric: 4.2891

Epoch 37: val_loss did not improve from 4.20091
196/196 - 45s - loss: 4.1918 - MinusLogProbMetric: 4.1918 - val_loss: 4.2891 - val_MinusLogProbMetric: 4.2891 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 38/1000
2023-09-17 17:05:33.574 
Epoch 38/1000 
	 loss: 4.1835, MinusLogProbMetric: 4.1835, val_loss: 4.2009, val_MinusLogProbMetric: 4.2009

Epoch 38: val_loss improved from 4.20091 to 4.20091, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 46s - loss: 4.1835 - MinusLogProbMetric: 4.1835 - val_loss: 4.2009 - val_MinusLogProbMetric: 4.2009 - lr: 0.0010 - 46s/epoch - 233ms/step
Epoch 39/1000
2023-09-17 17:06:19.422 
Epoch 39/1000 
	 loss: 4.1805, MinusLogProbMetric: 4.1805, val_loss: 4.1833, val_MinusLogProbMetric: 4.1833

Epoch 39: val_loss improved from 4.20091 to 4.18334, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 46s - loss: 4.1805 - MinusLogProbMetric: 4.1805 - val_loss: 4.1833 - val_MinusLogProbMetric: 4.1833 - lr: 0.0010 - 46s/epoch - 236ms/step
Epoch 40/1000
2023-09-17 17:07:05.196 
Epoch 40/1000 
	 loss: 4.1823, MinusLogProbMetric: 4.1823, val_loss: 4.2172, val_MinusLogProbMetric: 4.2172

Epoch 40: val_loss did not improve from 4.18334
196/196 - 45s - loss: 4.1823 - MinusLogProbMetric: 4.1823 - val_loss: 4.2172 - val_MinusLogProbMetric: 4.2172 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 41/1000
2023-09-17 17:07:50.273 
Epoch 41/1000 
	 loss: 4.1768, MinusLogProbMetric: 4.1768, val_loss: 4.4253, val_MinusLogProbMetric: 4.4253

Epoch 41: val_loss did not improve from 4.18334
196/196 - 45s - loss: 4.1768 - MinusLogProbMetric: 4.1768 - val_loss: 4.4253 - val_MinusLogProbMetric: 4.4253 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 42/1000
2023-09-17 17:08:35.354 
Epoch 42/1000 
	 loss: 4.1814, MinusLogProbMetric: 4.1814, val_loss: 4.2442, val_MinusLogProbMetric: 4.2442

Epoch 42: val_loss did not improve from 4.18334
196/196 - 45s - loss: 4.1814 - MinusLogProbMetric: 4.1814 - val_loss: 4.2442 - val_MinusLogProbMetric: 4.2442 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 43/1000
2023-09-17 17:09:20.205 
Epoch 43/1000 
	 loss: 4.1695, MinusLogProbMetric: 4.1695, val_loss: 4.3023, val_MinusLogProbMetric: 4.3023

Epoch 43: val_loss did not improve from 4.18334
196/196 - 45s - loss: 4.1695 - MinusLogProbMetric: 4.1695 - val_loss: 4.3023 - val_MinusLogProbMetric: 4.3023 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 44/1000
2023-09-17 17:10:05.139 
Epoch 44/1000 
	 loss: 4.1659, MinusLogProbMetric: 4.1659, val_loss: 4.1838, val_MinusLogProbMetric: 4.1838

Epoch 44: val_loss did not improve from 4.18334
196/196 - 45s - loss: 4.1659 - MinusLogProbMetric: 4.1659 - val_loss: 4.1838 - val_MinusLogProbMetric: 4.1838 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 45/1000
2023-09-17 17:10:50.320 
Epoch 45/1000 
	 loss: 4.1716, MinusLogProbMetric: 4.1716, val_loss: 4.2962, val_MinusLogProbMetric: 4.2962

Epoch 45: val_loss did not improve from 4.18334
196/196 - 45s - loss: 4.1716 - MinusLogProbMetric: 4.1716 - val_loss: 4.2962 - val_MinusLogProbMetric: 4.2962 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 46/1000
2023-09-17 17:11:35.321 
Epoch 46/1000 
	 loss: 4.1793, MinusLogProbMetric: 4.1793, val_loss: 4.1915, val_MinusLogProbMetric: 4.1915

Epoch 46: val_loss did not improve from 4.18334
196/196 - 45s - loss: 4.1793 - MinusLogProbMetric: 4.1793 - val_loss: 4.1915 - val_MinusLogProbMetric: 4.1915 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 47/1000
2023-09-17 17:12:20.312 
Epoch 47/1000 
	 loss: 4.1519, MinusLogProbMetric: 4.1519, val_loss: 4.2048, val_MinusLogProbMetric: 4.2048

Epoch 47: val_loss did not improve from 4.18334
196/196 - 45s - loss: 4.1519 - MinusLogProbMetric: 4.1519 - val_loss: 4.2048 - val_MinusLogProbMetric: 4.2048 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 48/1000
2023-09-17 17:13:04.909 
Epoch 48/1000 
	 loss: 4.1747, MinusLogProbMetric: 4.1747, val_loss: 4.1814, val_MinusLogProbMetric: 4.1814

Epoch 48: val_loss improved from 4.18334 to 4.18138, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 45s - loss: 4.1747 - MinusLogProbMetric: 4.1747 - val_loss: 4.1814 - val_MinusLogProbMetric: 4.1814 - lr: 0.0010 - 45s/epoch - 231ms/step
Epoch 49/1000
2023-09-17 17:13:50.264 
Epoch 49/1000 
	 loss: 4.1619, MinusLogProbMetric: 4.1619, val_loss: 4.2381, val_MinusLogProbMetric: 4.2381

Epoch 49: val_loss did not improve from 4.18138
196/196 - 45s - loss: 4.1619 - MinusLogProbMetric: 4.1619 - val_loss: 4.2381 - val_MinusLogProbMetric: 4.2381 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 50/1000
2023-09-17 17:14:34.971 
Epoch 50/1000 
	 loss: 4.1646, MinusLogProbMetric: 4.1646, val_loss: 4.1996, val_MinusLogProbMetric: 4.1996

Epoch 50: val_loss did not improve from 4.18138
196/196 - 45s - loss: 4.1646 - MinusLogProbMetric: 4.1646 - val_loss: 4.1996 - val_MinusLogProbMetric: 4.1996 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 51/1000
2023-09-17 17:15:19.908 
Epoch 51/1000 
	 loss: 4.1457, MinusLogProbMetric: 4.1457, val_loss: 4.1947, val_MinusLogProbMetric: 4.1947

Epoch 51: val_loss did not improve from 4.18138
196/196 - 45s - loss: 4.1457 - MinusLogProbMetric: 4.1457 - val_loss: 4.1947 - val_MinusLogProbMetric: 4.1947 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 52/1000
2023-09-17 17:16:04.797 
Epoch 52/1000 
	 loss: 4.1648, MinusLogProbMetric: 4.1648, val_loss: 4.1805, val_MinusLogProbMetric: 4.1805

Epoch 52: val_loss improved from 4.18138 to 4.18052, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 46s - loss: 4.1648 - MinusLogProbMetric: 4.1648 - val_loss: 4.1805 - val_MinusLogProbMetric: 4.1805 - lr: 0.0010 - 46s/epoch - 233ms/step
Epoch 53/1000
2023-09-17 17:16:50.304 
Epoch 53/1000 
	 loss: 4.1471, MinusLogProbMetric: 4.1471, val_loss: 4.2411, val_MinusLogProbMetric: 4.2411

Epoch 53: val_loss did not improve from 4.18052
196/196 - 45s - loss: 4.1471 - MinusLogProbMetric: 4.1471 - val_loss: 4.2411 - val_MinusLogProbMetric: 4.2411 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 54/1000
2023-09-17 17:17:35.275 
Epoch 54/1000 
	 loss: 4.1780, MinusLogProbMetric: 4.1780, val_loss: 4.1979, val_MinusLogProbMetric: 4.1979

Epoch 54: val_loss did not improve from 4.18052
196/196 - 45s - loss: 4.1780 - MinusLogProbMetric: 4.1780 - val_loss: 4.1979 - val_MinusLogProbMetric: 4.1979 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 55/1000
2023-09-17 17:18:20.008 
Epoch 55/1000 
	 loss: 4.1622, MinusLogProbMetric: 4.1622, val_loss: 4.2154, val_MinusLogProbMetric: 4.2154

Epoch 55: val_loss did not improve from 4.18052
196/196 - 45s - loss: 4.1622 - MinusLogProbMetric: 4.1622 - val_loss: 4.2154 - val_MinusLogProbMetric: 4.2154 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 56/1000
2023-09-17 17:19:04.863 
Epoch 56/1000 
	 loss: 4.1514, MinusLogProbMetric: 4.1514, val_loss: 4.2445, val_MinusLogProbMetric: 4.2445

Epoch 56: val_loss did not improve from 4.18052
196/196 - 45s - loss: 4.1514 - MinusLogProbMetric: 4.1514 - val_loss: 4.2445 - val_MinusLogProbMetric: 4.2445 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 57/1000
2023-09-17 17:19:50.110 
Epoch 57/1000 
	 loss: 4.1567, MinusLogProbMetric: 4.1567, val_loss: 4.1761, val_MinusLogProbMetric: 4.1761

Epoch 57: val_loss improved from 4.18052 to 4.17606, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 46s - loss: 4.1567 - MinusLogProbMetric: 4.1567 - val_loss: 4.1761 - val_MinusLogProbMetric: 4.1761 - lr: 0.0010 - 46s/epoch - 235ms/step
Epoch 58/1000
2023-09-17 17:20:35.863 
Epoch 58/1000 
	 loss: 4.1511, MinusLogProbMetric: 4.1511, val_loss: 4.1782, val_MinusLogProbMetric: 4.1782

Epoch 58: val_loss did not improve from 4.17606
196/196 - 45s - loss: 4.1511 - MinusLogProbMetric: 4.1511 - val_loss: 4.1782 - val_MinusLogProbMetric: 4.1782 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 59/1000
2023-09-17 17:21:20.393 
Epoch 59/1000 
	 loss: 4.1350, MinusLogProbMetric: 4.1350, val_loss: 4.1576, val_MinusLogProbMetric: 4.1576

Epoch 59: val_loss improved from 4.17606 to 4.15765, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 45s - loss: 4.1350 - MinusLogProbMetric: 4.1350 - val_loss: 4.1576 - val_MinusLogProbMetric: 4.1576 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 60/1000
2023-09-17 17:22:05.768 
Epoch 60/1000 
	 loss: 4.1479, MinusLogProbMetric: 4.1479, val_loss: 4.2085, val_MinusLogProbMetric: 4.2085

Epoch 60: val_loss did not improve from 4.15765
196/196 - 45s - loss: 4.1479 - MinusLogProbMetric: 4.1479 - val_loss: 4.2085 - val_MinusLogProbMetric: 4.2085 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 61/1000
2023-09-17 17:22:50.316 
Epoch 61/1000 
	 loss: 4.1513, MinusLogProbMetric: 4.1513, val_loss: 4.3212, val_MinusLogProbMetric: 4.3212

Epoch 61: val_loss did not improve from 4.15765
196/196 - 45s - loss: 4.1513 - MinusLogProbMetric: 4.1513 - val_loss: 4.3212 - val_MinusLogProbMetric: 4.3212 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 62/1000
2023-09-17 17:23:35.089 
Epoch 62/1000 
	 loss: 4.1374, MinusLogProbMetric: 4.1374, val_loss: 4.1736, val_MinusLogProbMetric: 4.1736

Epoch 62: val_loss did not improve from 4.15765
196/196 - 45s - loss: 4.1374 - MinusLogProbMetric: 4.1374 - val_loss: 4.1736 - val_MinusLogProbMetric: 4.1736 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 63/1000
2023-09-17 17:24:19.814 
Epoch 63/1000 
	 loss: 4.1353, MinusLogProbMetric: 4.1353, val_loss: 4.1915, val_MinusLogProbMetric: 4.1915

Epoch 63: val_loss did not improve from 4.15765
196/196 - 45s - loss: 4.1353 - MinusLogProbMetric: 4.1353 - val_loss: 4.1915 - val_MinusLogProbMetric: 4.1915 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 64/1000
2023-09-17 17:25:04.800 
Epoch 64/1000 
	 loss: 4.1463, MinusLogProbMetric: 4.1463, val_loss: 4.2273, val_MinusLogProbMetric: 4.2273

Epoch 64: val_loss did not improve from 4.15765
196/196 - 45s - loss: 4.1463 - MinusLogProbMetric: 4.1463 - val_loss: 4.2273 - val_MinusLogProbMetric: 4.2273 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 65/1000
2023-09-17 17:25:49.105 
Epoch 65/1000 
	 loss: 4.1432, MinusLogProbMetric: 4.1432, val_loss: 4.1848, val_MinusLogProbMetric: 4.1848

Epoch 65: val_loss did not improve from 4.15765
196/196 - 44s - loss: 4.1432 - MinusLogProbMetric: 4.1432 - val_loss: 4.1848 - val_MinusLogProbMetric: 4.1848 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 66/1000
2023-09-17 17:26:33.456 
Epoch 66/1000 
	 loss: 4.1380, MinusLogProbMetric: 4.1380, val_loss: 4.1781, val_MinusLogProbMetric: 4.1781

Epoch 66: val_loss did not improve from 4.15765
196/196 - 44s - loss: 4.1380 - MinusLogProbMetric: 4.1380 - val_loss: 4.1781 - val_MinusLogProbMetric: 4.1781 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 67/1000
2023-09-17 17:27:18.130 
Epoch 67/1000 
	 loss: 4.1284, MinusLogProbMetric: 4.1284, val_loss: 4.1780, val_MinusLogProbMetric: 4.1780

Epoch 67: val_loss did not improve from 4.15765
196/196 - 45s - loss: 4.1284 - MinusLogProbMetric: 4.1284 - val_loss: 4.1780 - val_MinusLogProbMetric: 4.1780 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 68/1000
2023-09-17 17:28:02.522 
Epoch 68/1000 
	 loss: 4.1391, MinusLogProbMetric: 4.1391, val_loss: 4.2082, val_MinusLogProbMetric: 4.2082

Epoch 68: val_loss did not improve from 4.15765
196/196 - 44s - loss: 4.1391 - MinusLogProbMetric: 4.1391 - val_loss: 4.2082 - val_MinusLogProbMetric: 4.2082 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 69/1000
2023-09-17 17:28:47.189 
Epoch 69/1000 
	 loss: 4.1329, MinusLogProbMetric: 4.1329, val_loss: 4.1868, val_MinusLogProbMetric: 4.1868

Epoch 69: val_loss did not improve from 4.15765
196/196 - 45s - loss: 4.1329 - MinusLogProbMetric: 4.1329 - val_loss: 4.1868 - val_MinusLogProbMetric: 4.1868 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 70/1000
2023-09-17 17:29:32.246 
Epoch 70/1000 
	 loss: 4.1380, MinusLogProbMetric: 4.1380, val_loss: 4.1858, val_MinusLogProbMetric: 4.1858

Epoch 70: val_loss did not improve from 4.15765
196/196 - 45s - loss: 4.1380 - MinusLogProbMetric: 4.1380 - val_loss: 4.1858 - val_MinusLogProbMetric: 4.1858 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 71/1000
2023-09-17 17:30:16.956 
Epoch 71/1000 
	 loss: 4.1325, MinusLogProbMetric: 4.1325, val_loss: 4.1816, val_MinusLogProbMetric: 4.1816

Epoch 71: val_loss did not improve from 4.15765
196/196 - 45s - loss: 4.1325 - MinusLogProbMetric: 4.1325 - val_loss: 4.1816 - val_MinusLogProbMetric: 4.1816 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 72/1000
2023-09-17 17:31:01.604 
Epoch 72/1000 
	 loss: 4.1321, MinusLogProbMetric: 4.1321, val_loss: 4.1813, val_MinusLogProbMetric: 4.1813

Epoch 72: val_loss did not improve from 4.15765
196/196 - 45s - loss: 4.1321 - MinusLogProbMetric: 4.1321 - val_loss: 4.1813 - val_MinusLogProbMetric: 4.1813 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 73/1000
2023-09-17 17:31:46.323 
Epoch 73/1000 
	 loss: 4.1231, MinusLogProbMetric: 4.1231, val_loss: 4.1710, val_MinusLogProbMetric: 4.1710

Epoch 73: val_loss did not improve from 4.15765
196/196 - 45s - loss: 4.1231 - MinusLogProbMetric: 4.1231 - val_loss: 4.1710 - val_MinusLogProbMetric: 4.1710 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 74/1000
2023-09-17 17:32:30.866 
Epoch 74/1000 
	 loss: 4.1235, MinusLogProbMetric: 4.1235, val_loss: 4.1777, val_MinusLogProbMetric: 4.1777

Epoch 74: val_loss did not improve from 4.15765
196/196 - 45s - loss: 4.1235 - MinusLogProbMetric: 4.1235 - val_loss: 4.1777 - val_MinusLogProbMetric: 4.1777 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 75/1000
2023-09-17 17:33:14.898 
Epoch 75/1000 
	 loss: 4.1212, MinusLogProbMetric: 4.1212, val_loss: 4.1814, val_MinusLogProbMetric: 4.1814

Epoch 75: val_loss did not improve from 4.15765
196/196 - 44s - loss: 4.1212 - MinusLogProbMetric: 4.1212 - val_loss: 4.1814 - val_MinusLogProbMetric: 4.1814 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 76/1000
2023-09-17 17:33:59.371 
Epoch 76/1000 
	 loss: 4.1411, MinusLogProbMetric: 4.1411, val_loss: 4.2483, val_MinusLogProbMetric: 4.2483

Epoch 76: val_loss did not improve from 4.15765
196/196 - 44s - loss: 4.1411 - MinusLogProbMetric: 4.1411 - val_loss: 4.2483 - val_MinusLogProbMetric: 4.2483 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 77/1000
2023-09-17 17:34:44.253 
Epoch 77/1000 
	 loss: 4.1315, MinusLogProbMetric: 4.1315, val_loss: 4.2090, val_MinusLogProbMetric: 4.2090

Epoch 77: val_loss did not improve from 4.15765
196/196 - 45s - loss: 4.1315 - MinusLogProbMetric: 4.1315 - val_loss: 4.2090 - val_MinusLogProbMetric: 4.2090 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 78/1000
2023-09-17 17:35:28.958 
Epoch 78/1000 
	 loss: 4.1361, MinusLogProbMetric: 4.1361, val_loss: 4.2277, val_MinusLogProbMetric: 4.2277

Epoch 78: val_loss did not improve from 4.15765
196/196 - 45s - loss: 4.1361 - MinusLogProbMetric: 4.1361 - val_loss: 4.2277 - val_MinusLogProbMetric: 4.2277 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 79/1000
2023-09-17 17:36:13.673 
Epoch 79/1000 
	 loss: 4.1222, MinusLogProbMetric: 4.1222, val_loss: 4.1596, val_MinusLogProbMetric: 4.1596

Epoch 79: val_loss did not improve from 4.15765
196/196 - 45s - loss: 4.1222 - MinusLogProbMetric: 4.1222 - val_loss: 4.1596 - val_MinusLogProbMetric: 4.1596 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 80/1000
2023-09-17 17:36:58.518 
Epoch 80/1000 
	 loss: 4.1172, MinusLogProbMetric: 4.1172, val_loss: 4.2038, val_MinusLogProbMetric: 4.2038

Epoch 80: val_loss did not improve from 4.15765
196/196 - 45s - loss: 4.1172 - MinusLogProbMetric: 4.1172 - val_loss: 4.2038 - val_MinusLogProbMetric: 4.2038 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 81/1000
2023-09-17 17:37:43.324 
Epoch 81/1000 
	 loss: 4.1250, MinusLogProbMetric: 4.1250, val_loss: 4.2068, val_MinusLogProbMetric: 4.2068

Epoch 81: val_loss did not improve from 4.15765
196/196 - 45s - loss: 4.1250 - MinusLogProbMetric: 4.1250 - val_loss: 4.2068 - val_MinusLogProbMetric: 4.2068 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 82/1000
2023-09-17 17:38:27.916 
Epoch 82/1000 
	 loss: 4.1241, MinusLogProbMetric: 4.1241, val_loss: 4.2249, val_MinusLogProbMetric: 4.2249

Epoch 82: val_loss did not improve from 4.15765
196/196 - 45s - loss: 4.1241 - MinusLogProbMetric: 4.1241 - val_loss: 4.2249 - val_MinusLogProbMetric: 4.2249 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 83/1000
2023-09-17 17:39:05.127 
Epoch 83/1000 
	 loss: 4.1249, MinusLogProbMetric: 4.1249, val_loss: 4.2693, val_MinusLogProbMetric: 4.2693

Epoch 83: val_loss did not improve from 4.15765
196/196 - 37s - loss: 4.1249 - MinusLogProbMetric: 4.1249 - val_loss: 4.2693 - val_MinusLogProbMetric: 4.2693 - lr: 0.0010 - 37s/epoch - 190ms/step
Epoch 84/1000
2023-09-17 17:39:41.443 
Epoch 84/1000 
	 loss: 4.1099, MinusLogProbMetric: 4.1099, val_loss: 4.2678, val_MinusLogProbMetric: 4.2678

Epoch 84: val_loss did not improve from 4.15765
196/196 - 36s - loss: 4.1099 - MinusLogProbMetric: 4.1099 - val_loss: 4.2678 - val_MinusLogProbMetric: 4.2678 - lr: 0.0010 - 36s/epoch - 185ms/step
Epoch 85/1000
2023-09-17 17:40:18.240 
Epoch 85/1000 
	 loss: 4.1127, MinusLogProbMetric: 4.1127, val_loss: 4.1666, val_MinusLogProbMetric: 4.1666

Epoch 85: val_loss did not improve from 4.15765
196/196 - 37s - loss: 4.1127 - MinusLogProbMetric: 4.1127 - val_loss: 4.1666 - val_MinusLogProbMetric: 4.1666 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 86/1000
2023-09-17 17:41:00.208 
Epoch 86/1000 
	 loss: 4.1220, MinusLogProbMetric: 4.1220, val_loss: 4.1593, val_MinusLogProbMetric: 4.1593

Epoch 86: val_loss did not improve from 4.15765
196/196 - 42s - loss: 4.1220 - MinusLogProbMetric: 4.1220 - val_loss: 4.1593 - val_MinusLogProbMetric: 4.1593 - lr: 0.0010 - 42s/epoch - 214ms/step
Epoch 87/1000
2023-09-17 17:41:44.939 
Epoch 87/1000 
	 loss: 4.1093, MinusLogProbMetric: 4.1093, val_loss: 4.1739, val_MinusLogProbMetric: 4.1739

Epoch 87: val_loss did not improve from 4.15765
196/196 - 45s - loss: 4.1093 - MinusLogProbMetric: 4.1093 - val_loss: 4.1739 - val_MinusLogProbMetric: 4.1739 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 88/1000
2023-09-17 17:42:28.807 
Epoch 88/1000 
	 loss: 4.1166, MinusLogProbMetric: 4.1166, val_loss: 4.2276, val_MinusLogProbMetric: 4.2276

Epoch 88: val_loss did not improve from 4.15765
196/196 - 44s - loss: 4.1166 - MinusLogProbMetric: 4.1166 - val_loss: 4.2276 - val_MinusLogProbMetric: 4.2276 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 89/1000
2023-09-17 17:43:13.098 
Epoch 89/1000 
	 loss: 4.1358, MinusLogProbMetric: 4.1358, val_loss: 4.1887, val_MinusLogProbMetric: 4.1887

Epoch 89: val_loss did not improve from 4.15765
196/196 - 44s - loss: 4.1358 - MinusLogProbMetric: 4.1358 - val_loss: 4.1887 - val_MinusLogProbMetric: 4.1887 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 90/1000
2023-09-17 17:43:53.344 
Epoch 90/1000 
	 loss: 4.1177, MinusLogProbMetric: 4.1177, val_loss: 4.1983, val_MinusLogProbMetric: 4.1983

Epoch 90: val_loss did not improve from 4.15765
196/196 - 40s - loss: 4.1177 - MinusLogProbMetric: 4.1177 - val_loss: 4.1983 - val_MinusLogProbMetric: 4.1983 - lr: 0.0010 - 40s/epoch - 205ms/step
Epoch 91/1000
2023-09-17 17:44:33.361 
Epoch 91/1000 
	 loss: 4.1027, MinusLogProbMetric: 4.1027, val_loss: 4.2132, val_MinusLogProbMetric: 4.2132

Epoch 91: val_loss did not improve from 4.15765
196/196 - 40s - loss: 4.1027 - MinusLogProbMetric: 4.1027 - val_loss: 4.2132 - val_MinusLogProbMetric: 4.2132 - lr: 0.0010 - 40s/epoch - 204ms/step
Epoch 92/1000
2023-09-17 17:45:09.829 
Epoch 92/1000 
	 loss: 4.1111, MinusLogProbMetric: 4.1111, val_loss: 4.1862, val_MinusLogProbMetric: 4.1862

Epoch 92: val_loss did not improve from 4.15765
196/196 - 36s - loss: 4.1111 - MinusLogProbMetric: 4.1111 - val_loss: 4.1862 - val_MinusLogProbMetric: 4.1862 - lr: 0.0010 - 36s/epoch - 186ms/step
Epoch 93/1000
2023-09-17 17:45:46.748 
Epoch 93/1000 
	 loss: 4.1121, MinusLogProbMetric: 4.1121, val_loss: 4.1761, val_MinusLogProbMetric: 4.1761

Epoch 93: val_loss did not improve from 4.15765
196/196 - 37s - loss: 4.1121 - MinusLogProbMetric: 4.1121 - val_loss: 4.1761 - val_MinusLogProbMetric: 4.1761 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 94/1000
2023-09-17 17:46:29.821 
Epoch 94/1000 
	 loss: 4.1153, MinusLogProbMetric: 4.1153, val_loss: 4.2161, val_MinusLogProbMetric: 4.2161

Epoch 94: val_loss did not improve from 4.15765
196/196 - 43s - loss: 4.1153 - MinusLogProbMetric: 4.1153 - val_loss: 4.2161 - val_MinusLogProbMetric: 4.2161 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 95/1000
2023-09-17 17:47:13.622 
Epoch 95/1000 
	 loss: 4.1072, MinusLogProbMetric: 4.1072, val_loss: 4.1889, val_MinusLogProbMetric: 4.1889

Epoch 95: val_loss did not improve from 4.15765
196/196 - 44s - loss: 4.1072 - MinusLogProbMetric: 4.1072 - val_loss: 4.1889 - val_MinusLogProbMetric: 4.1889 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 96/1000
2023-09-17 17:47:57.784 
Epoch 96/1000 
	 loss: 4.1069, MinusLogProbMetric: 4.1069, val_loss: 4.1985, val_MinusLogProbMetric: 4.1985

Epoch 96: val_loss did not improve from 4.15765
196/196 - 44s - loss: 4.1069 - MinusLogProbMetric: 4.1069 - val_loss: 4.1985 - val_MinusLogProbMetric: 4.1985 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 97/1000
2023-09-17 17:48:41.700 
Epoch 97/1000 
	 loss: 4.1128, MinusLogProbMetric: 4.1128, val_loss: 4.1770, val_MinusLogProbMetric: 4.1770

Epoch 97: val_loss did not improve from 4.15765
196/196 - 44s - loss: 4.1128 - MinusLogProbMetric: 4.1128 - val_loss: 4.1770 - val_MinusLogProbMetric: 4.1770 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 98/1000
2023-09-17 17:49:25.931 
Epoch 98/1000 
	 loss: 4.1008, MinusLogProbMetric: 4.1008, val_loss: 4.2650, val_MinusLogProbMetric: 4.2650

Epoch 98: val_loss did not improve from 4.15765
196/196 - 44s - loss: 4.1008 - MinusLogProbMetric: 4.1008 - val_loss: 4.2650 - val_MinusLogProbMetric: 4.2650 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 99/1000
2023-09-17 17:50:09.477 
Epoch 99/1000 
	 loss: 4.1098, MinusLogProbMetric: 4.1098, val_loss: 4.1955, val_MinusLogProbMetric: 4.1955

Epoch 99: val_loss did not improve from 4.15765
196/196 - 44s - loss: 4.1098 - MinusLogProbMetric: 4.1098 - val_loss: 4.1955 - val_MinusLogProbMetric: 4.1955 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 100/1000
2023-09-17 17:50:53.558 
Epoch 100/1000 
	 loss: 4.1153, MinusLogProbMetric: 4.1153, val_loss: 4.1909, val_MinusLogProbMetric: 4.1909

Epoch 100: val_loss did not improve from 4.15765
196/196 - 44s - loss: 4.1153 - MinusLogProbMetric: 4.1153 - val_loss: 4.1909 - val_MinusLogProbMetric: 4.1909 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 101/1000
2023-09-17 17:51:37.794 
Epoch 101/1000 
	 loss: 4.1036, MinusLogProbMetric: 4.1036, val_loss: 4.1891, val_MinusLogProbMetric: 4.1891

Epoch 101: val_loss did not improve from 4.15765
196/196 - 44s - loss: 4.1036 - MinusLogProbMetric: 4.1036 - val_loss: 4.1891 - val_MinusLogProbMetric: 4.1891 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 102/1000
2023-09-17 17:52:21.938 
Epoch 102/1000 
	 loss: 4.1073, MinusLogProbMetric: 4.1073, val_loss: 4.1675, val_MinusLogProbMetric: 4.1675

Epoch 102: val_loss did not improve from 4.15765
196/196 - 44s - loss: 4.1073 - MinusLogProbMetric: 4.1073 - val_loss: 4.1675 - val_MinusLogProbMetric: 4.1675 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 103/1000
2023-09-17 17:53:06.037 
Epoch 103/1000 
	 loss: 4.1151, MinusLogProbMetric: 4.1151, val_loss: 4.1667, val_MinusLogProbMetric: 4.1667

Epoch 103: val_loss did not improve from 4.15765
196/196 - 44s - loss: 4.1151 - MinusLogProbMetric: 4.1151 - val_loss: 4.1667 - val_MinusLogProbMetric: 4.1667 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 104/1000
2023-09-17 17:53:50.247 
Epoch 104/1000 
	 loss: 4.1017, MinusLogProbMetric: 4.1017, val_loss: 4.1683, val_MinusLogProbMetric: 4.1683

Epoch 104: val_loss did not improve from 4.15765
196/196 - 44s - loss: 4.1017 - MinusLogProbMetric: 4.1017 - val_loss: 4.1683 - val_MinusLogProbMetric: 4.1683 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 105/1000
2023-09-17 17:54:33.816 
Epoch 105/1000 
	 loss: 4.1033, MinusLogProbMetric: 4.1033, val_loss: 4.1631, val_MinusLogProbMetric: 4.1631

Epoch 105: val_loss did not improve from 4.15765
196/196 - 44s - loss: 4.1033 - MinusLogProbMetric: 4.1033 - val_loss: 4.1631 - val_MinusLogProbMetric: 4.1631 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 106/1000
2023-09-17 17:55:17.334 
Epoch 106/1000 
	 loss: 4.0995, MinusLogProbMetric: 4.0995, val_loss: 4.1939, val_MinusLogProbMetric: 4.1939

Epoch 106: val_loss did not improve from 4.15765
196/196 - 44s - loss: 4.0995 - MinusLogProbMetric: 4.0995 - val_loss: 4.1939 - val_MinusLogProbMetric: 4.1939 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 107/1000
2023-09-17 17:56:01.834 
Epoch 107/1000 
	 loss: 4.1272, MinusLogProbMetric: 4.1272, val_loss: 4.1564, val_MinusLogProbMetric: 4.1564

Epoch 107: val_loss improved from 4.15765 to 4.15636, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 45s - loss: 4.1272 - MinusLogProbMetric: 4.1272 - val_loss: 4.1564 - val_MinusLogProbMetric: 4.1564 - lr: 0.0010 - 45s/epoch - 232ms/step
Epoch 108/1000
2023-09-17 17:56:46.960 
Epoch 108/1000 
	 loss: 4.1056, MinusLogProbMetric: 4.1056, val_loss: 4.2690, val_MinusLogProbMetric: 4.2690

Epoch 108: val_loss did not improve from 4.15636
196/196 - 44s - loss: 4.1056 - MinusLogProbMetric: 4.1056 - val_loss: 4.2690 - val_MinusLogProbMetric: 4.2690 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 109/1000
2023-09-17 17:57:31.273 
Epoch 109/1000 
	 loss: 4.1048, MinusLogProbMetric: 4.1048, val_loss: 4.1637, val_MinusLogProbMetric: 4.1637

Epoch 109: val_loss did not improve from 4.15636
196/196 - 44s - loss: 4.1048 - MinusLogProbMetric: 4.1048 - val_loss: 4.1637 - val_MinusLogProbMetric: 4.1637 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 110/1000
2023-09-17 17:58:15.141 
Epoch 110/1000 
	 loss: 4.1007, MinusLogProbMetric: 4.1007, val_loss: 4.2238, val_MinusLogProbMetric: 4.2238

Epoch 110: val_loss did not improve from 4.15636
196/196 - 44s - loss: 4.1007 - MinusLogProbMetric: 4.1007 - val_loss: 4.2238 - val_MinusLogProbMetric: 4.2238 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 111/1000
2023-09-17 17:58:59.011 
Epoch 111/1000 
	 loss: 4.1031, MinusLogProbMetric: 4.1031, val_loss: 4.1967, val_MinusLogProbMetric: 4.1967

Epoch 111: val_loss did not improve from 4.15636
196/196 - 44s - loss: 4.1031 - MinusLogProbMetric: 4.1031 - val_loss: 4.1967 - val_MinusLogProbMetric: 4.1967 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 112/1000
2023-09-17 17:59:43.152 
Epoch 112/1000 
	 loss: 4.0966, MinusLogProbMetric: 4.0966, val_loss: 4.1855, val_MinusLogProbMetric: 4.1855

Epoch 112: val_loss did not improve from 4.15636
196/196 - 44s - loss: 4.0966 - MinusLogProbMetric: 4.0966 - val_loss: 4.1855 - val_MinusLogProbMetric: 4.1855 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 113/1000
2023-09-17 18:00:27.425 
Epoch 113/1000 
	 loss: 4.0973, MinusLogProbMetric: 4.0973, val_loss: 4.1927, val_MinusLogProbMetric: 4.1927

Epoch 113: val_loss did not improve from 4.15636
196/196 - 44s - loss: 4.0973 - MinusLogProbMetric: 4.0973 - val_loss: 4.1927 - val_MinusLogProbMetric: 4.1927 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 114/1000
2023-09-17 18:01:11.494 
Epoch 114/1000 
	 loss: 4.1057, MinusLogProbMetric: 4.1057, val_loss: 4.2098, val_MinusLogProbMetric: 4.2098

Epoch 114: val_loss did not improve from 4.15636
196/196 - 44s - loss: 4.1057 - MinusLogProbMetric: 4.1057 - val_loss: 4.2098 - val_MinusLogProbMetric: 4.2098 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 115/1000
2023-09-17 18:01:55.205 
Epoch 115/1000 
	 loss: 4.0975, MinusLogProbMetric: 4.0975, val_loss: 4.2092, val_MinusLogProbMetric: 4.2092

Epoch 115: val_loss did not improve from 4.15636
196/196 - 44s - loss: 4.0975 - MinusLogProbMetric: 4.0975 - val_loss: 4.2092 - val_MinusLogProbMetric: 4.2092 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 116/1000
2023-09-17 18:02:39.293 
Epoch 116/1000 
	 loss: 4.1030, MinusLogProbMetric: 4.1030, val_loss: 4.1645, val_MinusLogProbMetric: 4.1645

Epoch 116: val_loss did not improve from 4.15636
196/196 - 44s - loss: 4.1030 - MinusLogProbMetric: 4.1030 - val_loss: 4.1645 - val_MinusLogProbMetric: 4.1645 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 117/1000
2023-09-17 18:03:23.582 
Epoch 117/1000 
	 loss: 4.1017, MinusLogProbMetric: 4.1017, val_loss: 4.1531, val_MinusLogProbMetric: 4.1531

Epoch 117: val_loss improved from 4.15636 to 4.15313, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 45s - loss: 4.1017 - MinusLogProbMetric: 4.1017 - val_loss: 4.1531 - val_MinusLogProbMetric: 4.1531 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 118/1000
2023-09-17 18:04:08.296 
Epoch 118/1000 
	 loss: 4.0954, MinusLogProbMetric: 4.0954, val_loss: 4.1931, val_MinusLogProbMetric: 4.1931

Epoch 118: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0954 - MinusLogProbMetric: 4.0954 - val_loss: 4.1931 - val_MinusLogProbMetric: 4.1931 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 119/1000
2023-09-17 18:04:52.291 
Epoch 119/1000 
	 loss: 4.1046, MinusLogProbMetric: 4.1046, val_loss: 4.1675, val_MinusLogProbMetric: 4.1675

Epoch 119: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.1046 - MinusLogProbMetric: 4.1046 - val_loss: 4.1675 - val_MinusLogProbMetric: 4.1675 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 120/1000
2023-09-17 18:05:36.285 
Epoch 120/1000 
	 loss: 4.1011, MinusLogProbMetric: 4.1011, val_loss: 4.1736, val_MinusLogProbMetric: 4.1736

Epoch 120: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.1011 - MinusLogProbMetric: 4.1011 - val_loss: 4.1736 - val_MinusLogProbMetric: 4.1736 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 121/1000
2023-09-17 18:06:20.525 
Epoch 121/1000 
	 loss: 4.0861, MinusLogProbMetric: 4.0861, val_loss: 4.1804, val_MinusLogProbMetric: 4.1804

Epoch 121: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0861 - MinusLogProbMetric: 4.0861 - val_loss: 4.1804 - val_MinusLogProbMetric: 4.1804 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 122/1000
2023-09-17 18:07:04.607 
Epoch 122/1000 
	 loss: 4.0971, MinusLogProbMetric: 4.0971, val_loss: 4.1647, val_MinusLogProbMetric: 4.1647

Epoch 122: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0971 - MinusLogProbMetric: 4.0971 - val_loss: 4.1647 - val_MinusLogProbMetric: 4.1647 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 123/1000
2023-09-17 18:07:49.072 
Epoch 123/1000 
	 loss: 4.0930, MinusLogProbMetric: 4.0930, val_loss: 4.1826, val_MinusLogProbMetric: 4.1826

Epoch 123: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0930 - MinusLogProbMetric: 4.0930 - val_loss: 4.1826 - val_MinusLogProbMetric: 4.1826 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 124/1000
2023-09-17 18:08:33.068 
Epoch 124/1000 
	 loss: 4.0944, MinusLogProbMetric: 4.0944, val_loss: 4.1797, val_MinusLogProbMetric: 4.1797

Epoch 124: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0944 - MinusLogProbMetric: 4.0944 - val_loss: 4.1797 - val_MinusLogProbMetric: 4.1797 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 125/1000
2023-09-17 18:09:16.969 
Epoch 125/1000 
	 loss: 4.0892, MinusLogProbMetric: 4.0892, val_loss: 4.1617, val_MinusLogProbMetric: 4.1617

Epoch 125: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0892 - MinusLogProbMetric: 4.0892 - val_loss: 4.1617 - val_MinusLogProbMetric: 4.1617 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 126/1000
2023-09-17 18:10:01.260 
Epoch 126/1000 
	 loss: 4.0889, MinusLogProbMetric: 4.0889, val_loss: 4.2613, val_MinusLogProbMetric: 4.2613

Epoch 126: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0889 - MinusLogProbMetric: 4.0889 - val_loss: 4.2613 - val_MinusLogProbMetric: 4.2613 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 127/1000
2023-09-17 18:10:45.158 
Epoch 127/1000 
	 loss: 4.0937, MinusLogProbMetric: 4.0937, val_loss: 4.1545, val_MinusLogProbMetric: 4.1545

Epoch 127: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0937 - MinusLogProbMetric: 4.0937 - val_loss: 4.1545 - val_MinusLogProbMetric: 4.1545 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 128/1000
2023-09-17 18:11:28.716 
Epoch 128/1000 
	 loss: 4.0887, MinusLogProbMetric: 4.0887, val_loss: 4.1762, val_MinusLogProbMetric: 4.1762

Epoch 128: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0887 - MinusLogProbMetric: 4.0887 - val_loss: 4.1762 - val_MinusLogProbMetric: 4.1762 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 129/1000
2023-09-17 18:12:12.658 
Epoch 129/1000 
	 loss: 4.0938, MinusLogProbMetric: 4.0938, val_loss: 4.1829, val_MinusLogProbMetric: 4.1829

Epoch 129: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0938 - MinusLogProbMetric: 4.0938 - val_loss: 4.1829 - val_MinusLogProbMetric: 4.1829 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 130/1000
2023-09-17 18:12:56.606 
Epoch 130/1000 
	 loss: 4.0905, MinusLogProbMetric: 4.0905, val_loss: 4.1791, val_MinusLogProbMetric: 4.1791

Epoch 130: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0905 - MinusLogProbMetric: 4.0905 - val_loss: 4.1791 - val_MinusLogProbMetric: 4.1791 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 131/1000
2023-09-17 18:13:40.646 
Epoch 131/1000 
	 loss: 4.0880, MinusLogProbMetric: 4.0880, val_loss: 4.2031, val_MinusLogProbMetric: 4.2031

Epoch 131: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0880 - MinusLogProbMetric: 4.0880 - val_loss: 4.2031 - val_MinusLogProbMetric: 4.2031 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 132/1000
2023-09-17 18:14:24.604 
Epoch 132/1000 
	 loss: 4.0903, MinusLogProbMetric: 4.0903, val_loss: 4.2328, val_MinusLogProbMetric: 4.2328

Epoch 132: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0903 - MinusLogProbMetric: 4.0903 - val_loss: 4.2328 - val_MinusLogProbMetric: 4.2328 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 133/1000
2023-09-17 18:15:09.057 
Epoch 133/1000 
	 loss: 4.0828, MinusLogProbMetric: 4.0828, val_loss: 4.1747, val_MinusLogProbMetric: 4.1747

Epoch 133: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0828 - MinusLogProbMetric: 4.0828 - val_loss: 4.1747 - val_MinusLogProbMetric: 4.1747 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 134/1000
2023-09-17 18:15:53.482 
Epoch 134/1000 
	 loss: 4.0852, MinusLogProbMetric: 4.0852, val_loss: 4.2078, val_MinusLogProbMetric: 4.2078

Epoch 134: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0852 - MinusLogProbMetric: 4.0852 - val_loss: 4.2078 - val_MinusLogProbMetric: 4.2078 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 135/1000
2023-09-17 18:16:38.051 
Epoch 135/1000 
	 loss: 4.0832, MinusLogProbMetric: 4.0832, val_loss: 4.1641, val_MinusLogProbMetric: 4.1641

Epoch 135: val_loss did not improve from 4.15313
196/196 - 45s - loss: 4.0832 - MinusLogProbMetric: 4.0832 - val_loss: 4.1641 - val_MinusLogProbMetric: 4.1641 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 136/1000
2023-09-17 18:17:22.432 
Epoch 136/1000 
	 loss: 4.0847, MinusLogProbMetric: 4.0847, val_loss: 4.1619, val_MinusLogProbMetric: 4.1619

Epoch 136: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0847 - MinusLogProbMetric: 4.0847 - val_loss: 4.1619 - val_MinusLogProbMetric: 4.1619 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 137/1000
2023-09-17 18:18:06.320 
Epoch 137/1000 
	 loss: 4.0821, MinusLogProbMetric: 4.0821, val_loss: 4.1604, val_MinusLogProbMetric: 4.1604

Epoch 137: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0821 - MinusLogProbMetric: 4.0821 - val_loss: 4.1604 - val_MinusLogProbMetric: 4.1604 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 138/1000
2023-09-17 18:18:50.139 
Epoch 138/1000 
	 loss: 4.0857, MinusLogProbMetric: 4.0857, val_loss: 4.2153, val_MinusLogProbMetric: 4.2153

Epoch 138: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0857 - MinusLogProbMetric: 4.0857 - val_loss: 4.2153 - val_MinusLogProbMetric: 4.2153 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 139/1000
2023-09-17 18:19:34.352 
Epoch 139/1000 
	 loss: 4.0848, MinusLogProbMetric: 4.0848, val_loss: 4.1667, val_MinusLogProbMetric: 4.1667

Epoch 139: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0848 - MinusLogProbMetric: 4.0848 - val_loss: 4.1667 - val_MinusLogProbMetric: 4.1667 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 140/1000
2023-09-17 18:20:18.579 
Epoch 140/1000 
	 loss: 4.0885, MinusLogProbMetric: 4.0885, val_loss: 4.1546, val_MinusLogProbMetric: 4.1546

Epoch 140: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0885 - MinusLogProbMetric: 4.0885 - val_loss: 4.1546 - val_MinusLogProbMetric: 4.1546 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 141/1000
2023-09-17 18:21:02.296 
Epoch 141/1000 
	 loss: 4.0902, MinusLogProbMetric: 4.0902, val_loss: 4.1692, val_MinusLogProbMetric: 4.1692

Epoch 141: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0902 - MinusLogProbMetric: 4.0902 - val_loss: 4.1692 - val_MinusLogProbMetric: 4.1692 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 142/1000
2023-09-17 18:21:46.337 
Epoch 142/1000 
	 loss: 4.0822, MinusLogProbMetric: 4.0822, val_loss: 4.1854, val_MinusLogProbMetric: 4.1854

Epoch 142: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0822 - MinusLogProbMetric: 4.0822 - val_loss: 4.1854 - val_MinusLogProbMetric: 4.1854 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 143/1000
2023-09-17 18:22:30.919 
Epoch 143/1000 
	 loss: 4.0755, MinusLogProbMetric: 4.0755, val_loss: 4.1928, val_MinusLogProbMetric: 4.1928

Epoch 143: val_loss did not improve from 4.15313
196/196 - 45s - loss: 4.0755 - MinusLogProbMetric: 4.0755 - val_loss: 4.1928 - val_MinusLogProbMetric: 4.1928 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 144/1000
2023-09-17 18:23:15.102 
Epoch 144/1000 
	 loss: 4.0866, MinusLogProbMetric: 4.0866, val_loss: 4.1835, val_MinusLogProbMetric: 4.1835

Epoch 144: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0866 - MinusLogProbMetric: 4.0866 - val_loss: 4.1835 - val_MinusLogProbMetric: 4.1835 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 145/1000
2023-09-17 18:23:56.703 
Epoch 145/1000 
	 loss: 4.0881, MinusLogProbMetric: 4.0881, val_loss: 4.1985, val_MinusLogProbMetric: 4.1985

Epoch 145: val_loss did not improve from 4.15313
196/196 - 42s - loss: 4.0881 - MinusLogProbMetric: 4.0881 - val_loss: 4.1985 - val_MinusLogProbMetric: 4.1985 - lr: 0.0010 - 42s/epoch - 212ms/step
Epoch 146/1000
2023-09-17 18:24:32.534 
Epoch 146/1000 
	 loss: 4.0862, MinusLogProbMetric: 4.0862, val_loss: 4.1747, val_MinusLogProbMetric: 4.1747

Epoch 146: val_loss did not improve from 4.15313
196/196 - 36s - loss: 4.0862 - MinusLogProbMetric: 4.0862 - val_loss: 4.1747 - val_MinusLogProbMetric: 4.1747 - lr: 0.0010 - 36s/epoch - 183ms/step
Epoch 147/1000
2023-09-17 18:25:07.295 
Epoch 147/1000 
	 loss: 4.0786, MinusLogProbMetric: 4.0786, val_loss: 4.1730, val_MinusLogProbMetric: 4.1730

Epoch 147: val_loss did not improve from 4.15313
196/196 - 35s - loss: 4.0786 - MinusLogProbMetric: 4.0786 - val_loss: 4.1730 - val_MinusLogProbMetric: 4.1730 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 148/1000
2023-09-17 18:25:43.101 
Epoch 148/1000 
	 loss: 4.0793, MinusLogProbMetric: 4.0793, val_loss: 4.2213, val_MinusLogProbMetric: 4.2213

Epoch 148: val_loss did not improve from 4.15313
196/196 - 36s - loss: 4.0793 - MinusLogProbMetric: 4.0793 - val_loss: 4.2213 - val_MinusLogProbMetric: 4.2213 - lr: 0.0010 - 36s/epoch - 183ms/step
Epoch 149/1000
2023-09-17 18:26:17.576 
Epoch 149/1000 
	 loss: 4.0858, MinusLogProbMetric: 4.0858, val_loss: 4.2434, val_MinusLogProbMetric: 4.2434

Epoch 149: val_loss did not improve from 4.15313
196/196 - 34s - loss: 4.0858 - MinusLogProbMetric: 4.0858 - val_loss: 4.2434 - val_MinusLogProbMetric: 4.2434 - lr: 0.0010 - 34s/epoch - 176ms/step
Epoch 150/1000
2023-09-17 18:26:58.563 
Epoch 150/1000 
	 loss: 4.0815, MinusLogProbMetric: 4.0815, val_loss: 4.1731, val_MinusLogProbMetric: 4.1731

Epoch 150: val_loss did not improve from 4.15313
196/196 - 41s - loss: 4.0815 - MinusLogProbMetric: 4.0815 - val_loss: 4.1731 - val_MinusLogProbMetric: 4.1731 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 151/1000
2023-09-17 18:27:42.664 
Epoch 151/1000 
	 loss: 4.0744, MinusLogProbMetric: 4.0744, val_loss: 4.1888, val_MinusLogProbMetric: 4.1888

Epoch 151: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0744 - MinusLogProbMetric: 4.0744 - val_loss: 4.1888 - val_MinusLogProbMetric: 4.1888 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 152/1000
2023-09-17 18:28:26.414 
Epoch 152/1000 
	 loss: 4.0859, MinusLogProbMetric: 4.0859, val_loss: 4.1946, val_MinusLogProbMetric: 4.1946

Epoch 152: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0859 - MinusLogProbMetric: 4.0859 - val_loss: 4.1946 - val_MinusLogProbMetric: 4.1946 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 153/1000
2023-09-17 18:29:09.461 
Epoch 153/1000 
	 loss: 4.0763, MinusLogProbMetric: 4.0763, val_loss: 4.1628, val_MinusLogProbMetric: 4.1628

Epoch 153: val_loss did not improve from 4.15313
196/196 - 43s - loss: 4.0763 - MinusLogProbMetric: 4.0763 - val_loss: 4.1628 - val_MinusLogProbMetric: 4.1628 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 154/1000
2023-09-17 18:29:53.223 
Epoch 154/1000 
	 loss: 4.0722, MinusLogProbMetric: 4.0722, val_loss: 4.1983, val_MinusLogProbMetric: 4.1983

Epoch 154: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0722 - MinusLogProbMetric: 4.0722 - val_loss: 4.1983 - val_MinusLogProbMetric: 4.1983 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 155/1000
2023-09-17 18:30:37.597 
Epoch 155/1000 
	 loss: 4.0747, MinusLogProbMetric: 4.0747, val_loss: 4.1583, val_MinusLogProbMetric: 4.1583

Epoch 155: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0747 - MinusLogProbMetric: 4.0747 - val_loss: 4.1583 - val_MinusLogProbMetric: 4.1583 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 156/1000
2023-09-17 18:31:21.398 
Epoch 156/1000 
	 loss: 4.0765, MinusLogProbMetric: 4.0765, val_loss: 4.1620, val_MinusLogProbMetric: 4.1620

Epoch 156: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0765 - MinusLogProbMetric: 4.0765 - val_loss: 4.1620 - val_MinusLogProbMetric: 4.1620 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 157/1000
2023-09-17 18:32:05.509 
Epoch 157/1000 
	 loss: 4.0802, MinusLogProbMetric: 4.0802, val_loss: 4.1750, val_MinusLogProbMetric: 4.1750

Epoch 157: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0802 - MinusLogProbMetric: 4.0802 - val_loss: 4.1750 - val_MinusLogProbMetric: 4.1750 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 158/1000
2023-09-17 18:32:49.565 
Epoch 158/1000 
	 loss: 4.0724, MinusLogProbMetric: 4.0724, val_loss: 4.1593, val_MinusLogProbMetric: 4.1593

Epoch 158: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0724 - MinusLogProbMetric: 4.0724 - val_loss: 4.1593 - val_MinusLogProbMetric: 4.1593 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 159/1000
2023-09-17 18:33:33.679 
Epoch 159/1000 
	 loss: 4.0715, MinusLogProbMetric: 4.0715, val_loss: 4.1808, val_MinusLogProbMetric: 4.1808

Epoch 159: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0715 - MinusLogProbMetric: 4.0715 - val_loss: 4.1808 - val_MinusLogProbMetric: 4.1808 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 160/1000
2023-09-17 18:34:17.498 
Epoch 160/1000 
	 loss: 4.0712, MinusLogProbMetric: 4.0712, val_loss: 4.1656, val_MinusLogProbMetric: 4.1656

Epoch 160: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0712 - MinusLogProbMetric: 4.0712 - val_loss: 4.1656 - val_MinusLogProbMetric: 4.1656 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 161/1000
2023-09-17 18:35:01.337 
Epoch 161/1000 
	 loss: 4.0739, MinusLogProbMetric: 4.0739, val_loss: 4.1663, val_MinusLogProbMetric: 4.1663

Epoch 161: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0739 - MinusLogProbMetric: 4.0739 - val_loss: 4.1663 - val_MinusLogProbMetric: 4.1663 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 162/1000
2023-09-17 18:35:44.647 
Epoch 162/1000 
	 loss: 4.0866, MinusLogProbMetric: 4.0866, val_loss: 4.2271, val_MinusLogProbMetric: 4.2271

Epoch 162: val_loss did not improve from 4.15313
196/196 - 43s - loss: 4.0866 - MinusLogProbMetric: 4.0866 - val_loss: 4.2271 - val_MinusLogProbMetric: 4.2271 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 163/1000
2023-09-17 18:36:28.945 
Epoch 163/1000 
	 loss: 4.0815, MinusLogProbMetric: 4.0815, val_loss: 4.1655, val_MinusLogProbMetric: 4.1655

Epoch 163: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0815 - MinusLogProbMetric: 4.0815 - val_loss: 4.1655 - val_MinusLogProbMetric: 4.1655 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 164/1000
2023-09-17 18:37:13.220 
Epoch 164/1000 
	 loss: 4.0718, MinusLogProbMetric: 4.0718, val_loss: 4.1757, val_MinusLogProbMetric: 4.1757

Epoch 164: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0718 - MinusLogProbMetric: 4.0718 - val_loss: 4.1757 - val_MinusLogProbMetric: 4.1757 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 165/1000
2023-09-17 18:37:57.425 
Epoch 165/1000 
	 loss: 4.0718, MinusLogProbMetric: 4.0718, val_loss: 4.1674, val_MinusLogProbMetric: 4.1674

Epoch 165: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0718 - MinusLogProbMetric: 4.0718 - val_loss: 4.1674 - val_MinusLogProbMetric: 4.1674 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 166/1000
2023-09-17 18:38:41.511 
Epoch 166/1000 
	 loss: 4.0727, MinusLogProbMetric: 4.0727, val_loss: 4.2318, val_MinusLogProbMetric: 4.2318

Epoch 166: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0727 - MinusLogProbMetric: 4.0727 - val_loss: 4.2318 - val_MinusLogProbMetric: 4.2318 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 167/1000
2023-09-17 18:39:25.874 
Epoch 167/1000 
	 loss: 4.0768, MinusLogProbMetric: 4.0768, val_loss: 4.1536, val_MinusLogProbMetric: 4.1536

Epoch 167: val_loss did not improve from 4.15313
196/196 - 44s - loss: 4.0768 - MinusLogProbMetric: 4.0768 - val_loss: 4.1536 - val_MinusLogProbMetric: 4.1536 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 168/1000
2023-09-17 18:40:09.716 
Epoch 168/1000 
	 loss: 4.0370, MinusLogProbMetric: 4.0370, val_loss: 4.1517, val_MinusLogProbMetric: 4.1517

Epoch 168: val_loss improved from 4.15313 to 4.15175, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 45s - loss: 4.0370 - MinusLogProbMetric: 4.0370 - val_loss: 4.1517 - val_MinusLogProbMetric: 4.1517 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 169/1000
2023-09-17 18:40:54.590 
Epoch 169/1000 
	 loss: 4.0351, MinusLogProbMetric: 4.0351, val_loss: 4.1451, val_MinusLogProbMetric: 4.1451

Epoch 169: val_loss improved from 4.15175 to 4.14507, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_139/weights/best_weights.h5
196/196 - 45s - loss: 4.0351 - MinusLogProbMetric: 4.0351 - val_loss: 4.1451 - val_MinusLogProbMetric: 4.1451 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 170/1000
2023-09-17 18:41:38.899 
Epoch 170/1000 
	 loss: 4.0314, MinusLogProbMetric: 4.0314, val_loss: 4.1521, val_MinusLogProbMetric: 4.1521

Epoch 170: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0314 - MinusLogProbMetric: 4.0314 - val_loss: 4.1521 - val_MinusLogProbMetric: 4.1521 - lr: 5.0000e-04 - 44s/epoch - 222ms/step
Epoch 171/1000
2023-09-17 18:42:22.965 
Epoch 171/1000 
	 loss: 4.0329, MinusLogProbMetric: 4.0329, val_loss: 4.1491, val_MinusLogProbMetric: 4.1491

Epoch 171: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0329 - MinusLogProbMetric: 4.0329 - val_loss: 4.1491 - val_MinusLogProbMetric: 4.1491 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 172/1000
2023-09-17 18:43:06.352 
Epoch 172/1000 
	 loss: 4.0342, MinusLogProbMetric: 4.0342, val_loss: 4.1704, val_MinusLogProbMetric: 4.1704

Epoch 172: val_loss did not improve from 4.14507
196/196 - 43s - loss: 4.0342 - MinusLogProbMetric: 4.0342 - val_loss: 4.1704 - val_MinusLogProbMetric: 4.1704 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 173/1000
2023-09-17 18:43:47.388 
Epoch 173/1000 
	 loss: 4.0331, MinusLogProbMetric: 4.0331, val_loss: 4.1465, val_MinusLogProbMetric: 4.1465

Epoch 173: val_loss did not improve from 4.14507
196/196 - 41s - loss: 4.0331 - MinusLogProbMetric: 4.0331 - val_loss: 4.1465 - val_MinusLogProbMetric: 4.1465 - lr: 5.0000e-04 - 41s/epoch - 209ms/step
Epoch 174/1000
2023-09-17 18:44:25.683 
Epoch 174/1000 
	 loss: 4.0332, MinusLogProbMetric: 4.0332, val_loss: 4.1566, val_MinusLogProbMetric: 4.1566

Epoch 174: val_loss did not improve from 4.14507
196/196 - 38s - loss: 4.0332 - MinusLogProbMetric: 4.0332 - val_loss: 4.1566 - val_MinusLogProbMetric: 4.1566 - lr: 5.0000e-04 - 38s/epoch - 195ms/step
Epoch 175/1000
2023-09-17 18:45:07.890 
Epoch 175/1000 
	 loss: 4.0360, MinusLogProbMetric: 4.0360, val_loss: 4.1506, val_MinusLogProbMetric: 4.1506

Epoch 175: val_loss did not improve from 4.14507
196/196 - 42s - loss: 4.0360 - MinusLogProbMetric: 4.0360 - val_loss: 4.1506 - val_MinusLogProbMetric: 4.1506 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 176/1000
2023-09-17 18:45:47.281 
Epoch 176/1000 
	 loss: 4.0324, MinusLogProbMetric: 4.0324, val_loss: 4.1676, val_MinusLogProbMetric: 4.1676

Epoch 176: val_loss did not improve from 4.14507
196/196 - 39s - loss: 4.0324 - MinusLogProbMetric: 4.0324 - val_loss: 4.1676 - val_MinusLogProbMetric: 4.1676 - lr: 5.0000e-04 - 39s/epoch - 201ms/step
Epoch 177/1000
2023-09-17 18:46:27.227 
Epoch 177/1000 
	 loss: 4.0361, MinusLogProbMetric: 4.0361, val_loss: 4.1905, val_MinusLogProbMetric: 4.1905

Epoch 177: val_loss did not improve from 4.14507
196/196 - 40s - loss: 4.0361 - MinusLogProbMetric: 4.0361 - val_loss: 4.1905 - val_MinusLogProbMetric: 4.1905 - lr: 5.0000e-04 - 40s/epoch - 204ms/step
Epoch 178/1000
2023-09-17 18:47:06.555 
Epoch 178/1000 
	 loss: 4.0325, MinusLogProbMetric: 4.0325, val_loss: 4.1692, val_MinusLogProbMetric: 4.1692

Epoch 178: val_loss did not improve from 4.14507
196/196 - 39s - loss: 4.0325 - MinusLogProbMetric: 4.0325 - val_loss: 4.1692 - val_MinusLogProbMetric: 4.1692 - lr: 5.0000e-04 - 39s/epoch - 201ms/step
Epoch 179/1000
2023-09-17 18:47:47.643 
Epoch 179/1000 
	 loss: 4.0332, MinusLogProbMetric: 4.0332, val_loss: 4.1570, val_MinusLogProbMetric: 4.1570

Epoch 179: val_loss did not improve from 4.14507
196/196 - 41s - loss: 4.0332 - MinusLogProbMetric: 4.0332 - val_loss: 4.1570 - val_MinusLogProbMetric: 4.1570 - lr: 5.0000e-04 - 41s/epoch - 210ms/step
Epoch 180/1000
2023-09-17 18:48:28.391 
Epoch 180/1000 
	 loss: 4.0323, MinusLogProbMetric: 4.0323, val_loss: 4.1615, val_MinusLogProbMetric: 4.1615

Epoch 180: val_loss did not improve from 4.14507
196/196 - 41s - loss: 4.0323 - MinusLogProbMetric: 4.0323 - val_loss: 4.1615 - val_MinusLogProbMetric: 4.1615 - lr: 5.0000e-04 - 41s/epoch - 208ms/step
Epoch 181/1000
2023-09-17 18:49:07.660 
Epoch 181/1000 
	 loss: 4.0295, MinusLogProbMetric: 4.0295, val_loss: 4.1536, val_MinusLogProbMetric: 4.1536

Epoch 181: val_loss did not improve from 4.14507
196/196 - 39s - loss: 4.0295 - MinusLogProbMetric: 4.0295 - val_loss: 4.1536 - val_MinusLogProbMetric: 4.1536 - lr: 5.0000e-04 - 39s/epoch - 200ms/step
Epoch 182/1000
2023-09-17 18:49:43.080 
Epoch 182/1000 
	 loss: 4.0346, MinusLogProbMetric: 4.0346, val_loss: 4.1592, val_MinusLogProbMetric: 4.1592

Epoch 182: val_loss did not improve from 4.14507
196/196 - 35s - loss: 4.0346 - MinusLogProbMetric: 4.0346 - val_loss: 4.1592 - val_MinusLogProbMetric: 4.1592 - lr: 5.0000e-04 - 35s/epoch - 181ms/step
Epoch 183/1000
2023-09-17 18:50:27.138 
Epoch 183/1000 
	 loss: 4.0366, MinusLogProbMetric: 4.0366, val_loss: 4.1761, val_MinusLogProbMetric: 4.1761

Epoch 183: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0366 - MinusLogProbMetric: 4.0366 - val_loss: 4.1761 - val_MinusLogProbMetric: 4.1761 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 184/1000
2023-09-17 18:51:11.607 
Epoch 184/1000 
	 loss: 4.0292, MinusLogProbMetric: 4.0292, val_loss: 4.1571, val_MinusLogProbMetric: 4.1571

Epoch 184: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0292 - MinusLogProbMetric: 4.0292 - val_loss: 4.1571 - val_MinusLogProbMetric: 4.1571 - lr: 5.0000e-04 - 44s/epoch - 227ms/step
Epoch 185/1000
2023-09-17 18:51:55.743 
Epoch 185/1000 
	 loss: 4.0317, MinusLogProbMetric: 4.0317, val_loss: 4.1517, val_MinusLogProbMetric: 4.1517

Epoch 185: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0317 - MinusLogProbMetric: 4.0317 - val_loss: 4.1517 - val_MinusLogProbMetric: 4.1517 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 186/1000
2023-09-17 18:52:39.967 
Epoch 186/1000 
	 loss: 4.0316, MinusLogProbMetric: 4.0316, val_loss: 4.1569, val_MinusLogProbMetric: 4.1569

Epoch 186: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0316 - MinusLogProbMetric: 4.0316 - val_loss: 4.1569 - val_MinusLogProbMetric: 4.1569 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 187/1000
2023-09-17 18:53:25.459 
Epoch 187/1000 
	 loss: 4.0304, MinusLogProbMetric: 4.0304, val_loss: 4.1719, val_MinusLogProbMetric: 4.1719

Epoch 187: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0304 - MinusLogProbMetric: 4.0304 - val_loss: 4.1719 - val_MinusLogProbMetric: 4.1719 - lr: 5.0000e-04 - 45s/epoch - 232ms/step
Epoch 188/1000
2023-09-17 18:54:09.838 
Epoch 188/1000 
	 loss: 4.0311, MinusLogProbMetric: 4.0311, val_loss: 4.1617, val_MinusLogProbMetric: 4.1617

Epoch 188: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0311 - MinusLogProbMetric: 4.0311 - val_loss: 4.1617 - val_MinusLogProbMetric: 4.1617 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 189/1000
2023-09-17 18:54:54.175 
Epoch 189/1000 
	 loss: 4.0336, MinusLogProbMetric: 4.0336, val_loss: 4.1529, val_MinusLogProbMetric: 4.1529

Epoch 189: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0336 - MinusLogProbMetric: 4.0336 - val_loss: 4.1529 - val_MinusLogProbMetric: 4.1529 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 190/1000
2023-09-17 18:55:38.657 
Epoch 190/1000 
	 loss: 4.0286, MinusLogProbMetric: 4.0286, val_loss: 4.1525, val_MinusLogProbMetric: 4.1525

Epoch 190: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0286 - MinusLogProbMetric: 4.0286 - val_loss: 4.1525 - val_MinusLogProbMetric: 4.1525 - lr: 5.0000e-04 - 44s/epoch - 227ms/step
Epoch 191/1000
2023-09-17 18:56:22.942 
Epoch 191/1000 
	 loss: 4.0350, MinusLogProbMetric: 4.0350, val_loss: 4.1533, val_MinusLogProbMetric: 4.1533

Epoch 191: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0350 - MinusLogProbMetric: 4.0350 - val_loss: 4.1533 - val_MinusLogProbMetric: 4.1533 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 192/1000
2023-09-17 18:57:07.501 
Epoch 192/1000 
	 loss: 4.0281, MinusLogProbMetric: 4.0281, val_loss: 4.1660, val_MinusLogProbMetric: 4.1660

Epoch 192: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0281 - MinusLogProbMetric: 4.0281 - val_loss: 4.1660 - val_MinusLogProbMetric: 4.1660 - lr: 5.0000e-04 - 45s/epoch - 227ms/step
Epoch 193/1000
2023-09-17 18:57:52.195 
Epoch 193/1000 
	 loss: 4.0267, MinusLogProbMetric: 4.0267, val_loss: 4.1609, val_MinusLogProbMetric: 4.1609

Epoch 193: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0267 - MinusLogProbMetric: 4.0267 - val_loss: 4.1609 - val_MinusLogProbMetric: 4.1609 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 194/1000
2023-09-17 18:58:36.858 
Epoch 194/1000 
	 loss: 4.0303, MinusLogProbMetric: 4.0303, val_loss: 4.1633, val_MinusLogProbMetric: 4.1633

Epoch 194: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0303 - MinusLogProbMetric: 4.0303 - val_loss: 4.1633 - val_MinusLogProbMetric: 4.1633 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 195/1000
2023-09-17 18:59:16.822 
Epoch 195/1000 
	 loss: 4.0287, MinusLogProbMetric: 4.0287, val_loss: 4.1626, val_MinusLogProbMetric: 4.1626

Epoch 195: val_loss did not improve from 4.14507
196/196 - 40s - loss: 4.0287 - MinusLogProbMetric: 4.0287 - val_loss: 4.1626 - val_MinusLogProbMetric: 4.1626 - lr: 5.0000e-04 - 40s/epoch - 204ms/step
Epoch 196/1000
2023-09-17 18:59:52.804 
Epoch 196/1000 
	 loss: 4.0258, MinusLogProbMetric: 4.0258, val_loss: 4.1796, val_MinusLogProbMetric: 4.1796

Epoch 196: val_loss did not improve from 4.14507
196/196 - 36s - loss: 4.0258 - MinusLogProbMetric: 4.0258 - val_loss: 4.1796 - val_MinusLogProbMetric: 4.1796 - lr: 5.0000e-04 - 36s/epoch - 184ms/step
Epoch 197/1000
2023-09-17 19:00:30.543 
Epoch 197/1000 
	 loss: 4.0307, MinusLogProbMetric: 4.0307, val_loss: 4.1697, val_MinusLogProbMetric: 4.1697

Epoch 197: val_loss did not improve from 4.14507
196/196 - 38s - loss: 4.0307 - MinusLogProbMetric: 4.0307 - val_loss: 4.1697 - val_MinusLogProbMetric: 4.1697 - lr: 5.0000e-04 - 38s/epoch - 193ms/step
Epoch 198/1000
2023-09-17 19:01:12.380 
Epoch 198/1000 
	 loss: 4.0314, MinusLogProbMetric: 4.0314, val_loss: 4.1587, val_MinusLogProbMetric: 4.1587

Epoch 198: val_loss did not improve from 4.14507
196/196 - 42s - loss: 4.0314 - MinusLogProbMetric: 4.0314 - val_loss: 4.1587 - val_MinusLogProbMetric: 4.1587 - lr: 5.0000e-04 - 42s/epoch - 213ms/step
Epoch 199/1000
2023-09-17 19:01:56.750 
Epoch 199/1000 
	 loss: 4.0321, MinusLogProbMetric: 4.0321, val_loss: 4.1529, val_MinusLogProbMetric: 4.1529

Epoch 199: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0321 - MinusLogProbMetric: 4.0321 - val_loss: 4.1529 - val_MinusLogProbMetric: 4.1529 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 200/1000
2023-09-17 19:02:41.444 
Epoch 200/1000 
	 loss: 4.0287, MinusLogProbMetric: 4.0287, val_loss: 4.1561, val_MinusLogProbMetric: 4.1561

Epoch 200: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0287 - MinusLogProbMetric: 4.0287 - val_loss: 4.1561 - val_MinusLogProbMetric: 4.1561 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 201/1000
2023-09-17 19:03:24.661 
Epoch 201/1000 
	 loss: 4.0268, MinusLogProbMetric: 4.0268, val_loss: 4.1605, val_MinusLogProbMetric: 4.1605

Epoch 201: val_loss did not improve from 4.14507
196/196 - 43s - loss: 4.0268 - MinusLogProbMetric: 4.0268 - val_loss: 4.1605 - val_MinusLogProbMetric: 4.1605 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 202/1000
2023-09-17 19:04:03.470 
Epoch 202/1000 
	 loss: 4.0261, MinusLogProbMetric: 4.0261, val_loss: 4.1802, val_MinusLogProbMetric: 4.1802

Epoch 202: val_loss did not improve from 4.14507
196/196 - 39s - loss: 4.0261 - MinusLogProbMetric: 4.0261 - val_loss: 4.1802 - val_MinusLogProbMetric: 4.1802 - lr: 5.0000e-04 - 39s/epoch - 198ms/step
Epoch 203/1000
2023-09-17 19:04:40.844 
Epoch 203/1000 
	 loss: 4.0279, MinusLogProbMetric: 4.0279, val_loss: 4.1782, val_MinusLogProbMetric: 4.1782

Epoch 203: val_loss did not improve from 4.14507
196/196 - 37s - loss: 4.0279 - MinusLogProbMetric: 4.0279 - val_loss: 4.1782 - val_MinusLogProbMetric: 4.1782 - lr: 5.0000e-04 - 37s/epoch - 191ms/step
Epoch 204/1000
2023-09-17 19:05:19.399 
Epoch 204/1000 
	 loss: 4.0286, MinusLogProbMetric: 4.0286, val_loss: 4.1591, val_MinusLogProbMetric: 4.1591

Epoch 204: val_loss did not improve from 4.14507
196/196 - 39s - loss: 4.0286 - MinusLogProbMetric: 4.0286 - val_loss: 4.1591 - val_MinusLogProbMetric: 4.1591 - lr: 5.0000e-04 - 39s/epoch - 197ms/step
Epoch 205/1000
2023-09-17 19:06:04.124 
Epoch 205/1000 
	 loss: 4.0274, MinusLogProbMetric: 4.0274, val_loss: 4.1668, val_MinusLogProbMetric: 4.1668

Epoch 205: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0274 - MinusLogProbMetric: 4.0274 - val_loss: 4.1668 - val_MinusLogProbMetric: 4.1668 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 206/1000
2023-09-17 19:06:49.035 
Epoch 206/1000 
	 loss: 4.0291, MinusLogProbMetric: 4.0291, val_loss: 4.1809, val_MinusLogProbMetric: 4.1809

Epoch 206: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0291 - MinusLogProbMetric: 4.0291 - val_loss: 4.1809 - val_MinusLogProbMetric: 4.1809 - lr: 5.0000e-04 - 45s/epoch - 229ms/step
Epoch 207/1000
2023-09-17 19:07:33.507 
Epoch 207/1000 
	 loss: 4.0256, MinusLogProbMetric: 4.0256, val_loss: 4.1680, val_MinusLogProbMetric: 4.1680

Epoch 207: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0256 - MinusLogProbMetric: 4.0256 - val_loss: 4.1680 - val_MinusLogProbMetric: 4.1680 - lr: 5.0000e-04 - 44s/epoch - 227ms/step
Epoch 208/1000
2023-09-17 19:08:18.203 
Epoch 208/1000 
	 loss: 4.0222, MinusLogProbMetric: 4.0222, val_loss: 4.1563, val_MinusLogProbMetric: 4.1563

Epoch 208: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0222 - MinusLogProbMetric: 4.0222 - val_loss: 4.1563 - val_MinusLogProbMetric: 4.1563 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 209/1000
2023-09-17 19:09:03.395 
Epoch 209/1000 
	 loss: 4.0255, MinusLogProbMetric: 4.0255, val_loss: 4.1651, val_MinusLogProbMetric: 4.1651

Epoch 209: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0255 - MinusLogProbMetric: 4.0255 - val_loss: 4.1651 - val_MinusLogProbMetric: 4.1651 - lr: 5.0000e-04 - 45s/epoch - 230ms/step
Epoch 210/1000
2023-09-17 19:09:48.688 
Epoch 210/1000 
	 loss: 4.0232, MinusLogProbMetric: 4.0232, val_loss: 4.1755, val_MinusLogProbMetric: 4.1755

Epoch 210: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0232 - MinusLogProbMetric: 4.0232 - val_loss: 4.1755 - val_MinusLogProbMetric: 4.1755 - lr: 5.0000e-04 - 45s/epoch - 231ms/step
Epoch 211/1000
2023-09-17 19:10:33.169 
Epoch 211/1000 
	 loss: 4.0253, MinusLogProbMetric: 4.0253, val_loss: 4.1622, val_MinusLogProbMetric: 4.1622

Epoch 211: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0253 - MinusLogProbMetric: 4.0253 - val_loss: 4.1622 - val_MinusLogProbMetric: 4.1622 - lr: 5.0000e-04 - 44s/epoch - 227ms/step
Epoch 212/1000
2023-09-17 19:11:17.903 
Epoch 212/1000 
	 loss: 4.0253, MinusLogProbMetric: 4.0253, val_loss: 4.1846, val_MinusLogProbMetric: 4.1846

Epoch 212: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0253 - MinusLogProbMetric: 4.0253 - val_loss: 4.1846 - val_MinusLogProbMetric: 4.1846 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 213/1000
2023-09-17 19:12:02.699 
Epoch 213/1000 
	 loss: 4.0248, MinusLogProbMetric: 4.0248, val_loss: 4.1601, val_MinusLogProbMetric: 4.1601

Epoch 213: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0248 - MinusLogProbMetric: 4.0248 - val_loss: 4.1601 - val_MinusLogProbMetric: 4.1601 - lr: 5.0000e-04 - 45s/epoch - 229ms/step
Epoch 214/1000
2023-09-17 19:12:47.391 
Epoch 214/1000 
	 loss: 4.0239, MinusLogProbMetric: 4.0239, val_loss: 4.1771, val_MinusLogProbMetric: 4.1771

Epoch 214: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0239 - MinusLogProbMetric: 4.0239 - val_loss: 4.1771 - val_MinusLogProbMetric: 4.1771 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 215/1000
2023-09-17 19:13:32.320 
Epoch 215/1000 
	 loss: 4.0239, MinusLogProbMetric: 4.0239, val_loss: 4.1649, val_MinusLogProbMetric: 4.1649

Epoch 215: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0239 - MinusLogProbMetric: 4.0239 - val_loss: 4.1649 - val_MinusLogProbMetric: 4.1649 - lr: 5.0000e-04 - 45s/epoch - 229ms/step
Epoch 216/1000
2023-09-17 19:14:17.359 
Epoch 216/1000 
	 loss: 4.0310, MinusLogProbMetric: 4.0310, val_loss: 4.1725, val_MinusLogProbMetric: 4.1725

Epoch 216: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0310 - MinusLogProbMetric: 4.0310 - val_loss: 4.1725 - val_MinusLogProbMetric: 4.1725 - lr: 5.0000e-04 - 45s/epoch - 230ms/step
Epoch 217/1000
2023-09-17 19:15:02.154 
Epoch 217/1000 
	 loss: 4.0234, MinusLogProbMetric: 4.0234, val_loss: 4.1571, val_MinusLogProbMetric: 4.1571

Epoch 217: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0234 - MinusLogProbMetric: 4.0234 - val_loss: 4.1571 - val_MinusLogProbMetric: 4.1571 - lr: 5.0000e-04 - 45s/epoch - 229ms/step
Epoch 218/1000
2023-09-17 19:15:46.848 
Epoch 218/1000 
	 loss: 4.0266, MinusLogProbMetric: 4.0266, val_loss: 4.1699, val_MinusLogProbMetric: 4.1699

Epoch 218: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0266 - MinusLogProbMetric: 4.0266 - val_loss: 4.1699 - val_MinusLogProbMetric: 4.1699 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 219/1000
2023-09-17 19:16:31.714 
Epoch 219/1000 
	 loss: 4.0244, MinusLogProbMetric: 4.0244, val_loss: 4.1682, val_MinusLogProbMetric: 4.1682

Epoch 219: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0244 - MinusLogProbMetric: 4.0244 - val_loss: 4.1682 - val_MinusLogProbMetric: 4.1682 - lr: 5.0000e-04 - 45s/epoch - 229ms/step
Epoch 220/1000
2023-09-17 19:17:16.018 
Epoch 220/1000 
	 loss: 4.0041, MinusLogProbMetric: 4.0041, val_loss: 4.1581, val_MinusLogProbMetric: 4.1581

Epoch 220: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0041 - MinusLogProbMetric: 4.0041 - val_loss: 4.1581 - val_MinusLogProbMetric: 4.1581 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 221/1000
2023-09-17 19:18:00.900 
Epoch 221/1000 
	 loss: 4.0056, MinusLogProbMetric: 4.0056, val_loss: 4.1548, val_MinusLogProbMetric: 4.1548

Epoch 221: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0056 - MinusLogProbMetric: 4.0056 - val_loss: 4.1548 - val_MinusLogProbMetric: 4.1548 - lr: 2.5000e-04 - 45s/epoch - 229ms/step
Epoch 222/1000
2023-09-17 19:18:45.553 
Epoch 222/1000 
	 loss: 4.0034, MinusLogProbMetric: 4.0034, val_loss: 4.1592, val_MinusLogProbMetric: 4.1592

Epoch 222: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0034 - MinusLogProbMetric: 4.0034 - val_loss: 4.1592 - val_MinusLogProbMetric: 4.1592 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 223/1000
2023-09-17 19:19:29.946 
Epoch 223/1000 
	 loss: 4.0029, MinusLogProbMetric: 4.0029, val_loss: 4.1573, val_MinusLogProbMetric: 4.1573

Epoch 223: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0029 - MinusLogProbMetric: 4.0029 - val_loss: 4.1573 - val_MinusLogProbMetric: 4.1573 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 224/1000
2023-09-17 19:20:14.624 
Epoch 224/1000 
	 loss: 4.0044, MinusLogProbMetric: 4.0044, val_loss: 4.1551, val_MinusLogProbMetric: 4.1551

Epoch 224: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0044 - MinusLogProbMetric: 4.0044 - val_loss: 4.1551 - val_MinusLogProbMetric: 4.1551 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 225/1000
2023-09-17 19:20:59.146 
Epoch 225/1000 
	 loss: 4.0022, MinusLogProbMetric: 4.0022, val_loss: 4.1557, val_MinusLogProbMetric: 4.1557

Epoch 225: val_loss did not improve from 4.14507
196/196 - 45s - loss: 4.0022 - MinusLogProbMetric: 4.0022 - val_loss: 4.1557 - val_MinusLogProbMetric: 4.1557 - lr: 2.5000e-04 - 45s/epoch - 227ms/step
Epoch 226/1000
2023-09-17 19:21:43.637 
Epoch 226/1000 
	 loss: 4.0019, MinusLogProbMetric: 4.0019, val_loss: 4.1561, val_MinusLogProbMetric: 4.1561

Epoch 226: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0019 - MinusLogProbMetric: 4.0019 - val_loss: 4.1561 - val_MinusLogProbMetric: 4.1561 - lr: 2.5000e-04 - 44s/epoch - 227ms/step
Epoch 227/1000
2023-09-17 19:22:27.964 
Epoch 227/1000 
	 loss: 4.0030, MinusLogProbMetric: 4.0030, val_loss: 4.1672, val_MinusLogProbMetric: 4.1672

Epoch 227: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0030 - MinusLogProbMetric: 4.0030 - val_loss: 4.1672 - val_MinusLogProbMetric: 4.1672 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 228/1000
2023-09-17 19:23:12.066 
Epoch 228/1000 
	 loss: 4.0023, MinusLogProbMetric: 4.0023, val_loss: 4.1624, val_MinusLogProbMetric: 4.1624

Epoch 228: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0023 - MinusLogProbMetric: 4.0023 - val_loss: 4.1624 - val_MinusLogProbMetric: 4.1624 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 229/1000
2023-09-17 19:23:56.394 
Epoch 229/1000 
	 loss: 4.0023, MinusLogProbMetric: 4.0023, val_loss: 4.1633, val_MinusLogProbMetric: 4.1633

Epoch 229: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0023 - MinusLogProbMetric: 4.0023 - val_loss: 4.1633 - val_MinusLogProbMetric: 4.1633 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 230/1000
2023-09-17 19:24:40.630 
Epoch 230/1000 
	 loss: 4.0034, MinusLogProbMetric: 4.0034, val_loss: 4.1585, val_MinusLogProbMetric: 4.1585

Epoch 230: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0034 - MinusLogProbMetric: 4.0034 - val_loss: 4.1585 - val_MinusLogProbMetric: 4.1585 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 231/1000
2023-09-17 19:25:25.037 
Epoch 231/1000 
	 loss: 4.0038, MinusLogProbMetric: 4.0038, val_loss: 4.1794, val_MinusLogProbMetric: 4.1794

Epoch 231: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0038 - MinusLogProbMetric: 4.0038 - val_loss: 4.1794 - val_MinusLogProbMetric: 4.1794 - lr: 2.5000e-04 - 44s/epoch - 227ms/step
Epoch 232/1000
2023-09-17 19:26:09.361 
Epoch 232/1000 
	 loss: 4.0036, MinusLogProbMetric: 4.0036, val_loss: 4.1632, val_MinusLogProbMetric: 4.1632

Epoch 232: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0036 - MinusLogProbMetric: 4.0036 - val_loss: 4.1632 - val_MinusLogProbMetric: 4.1632 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 233/1000
2023-09-17 19:26:53.497 
Epoch 233/1000 
	 loss: 4.0018, MinusLogProbMetric: 4.0018, val_loss: 4.1602, val_MinusLogProbMetric: 4.1602

Epoch 233: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0018 - MinusLogProbMetric: 4.0018 - val_loss: 4.1602 - val_MinusLogProbMetric: 4.1602 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 234/1000
2023-09-17 19:27:37.505 
Epoch 234/1000 
	 loss: 4.0012, MinusLogProbMetric: 4.0012, val_loss: 4.1599, val_MinusLogProbMetric: 4.1599

Epoch 234: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0012 - MinusLogProbMetric: 4.0012 - val_loss: 4.1599 - val_MinusLogProbMetric: 4.1599 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 235/1000
2023-09-17 19:28:21.485 
Epoch 235/1000 
	 loss: 4.0039, MinusLogProbMetric: 4.0039, val_loss: 4.1593, val_MinusLogProbMetric: 4.1593

Epoch 235: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0039 - MinusLogProbMetric: 4.0039 - val_loss: 4.1593 - val_MinusLogProbMetric: 4.1593 - lr: 2.5000e-04 - 44s/epoch - 224ms/step
Epoch 236/1000
2023-09-17 19:29:05.595 
Epoch 236/1000 
	 loss: 4.0009, MinusLogProbMetric: 4.0009, val_loss: 4.1615, val_MinusLogProbMetric: 4.1615

Epoch 236: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0009 - MinusLogProbMetric: 4.0009 - val_loss: 4.1615 - val_MinusLogProbMetric: 4.1615 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 237/1000
2023-09-17 19:29:49.753 
Epoch 237/1000 
	 loss: 3.9994, MinusLogProbMetric: 3.9994, val_loss: 4.1622, val_MinusLogProbMetric: 4.1622

Epoch 237: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9994 - MinusLogProbMetric: 3.9994 - val_loss: 4.1622 - val_MinusLogProbMetric: 4.1622 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 238/1000
2023-09-17 19:30:34.076 
Epoch 238/1000 
	 loss: 4.0004, MinusLogProbMetric: 4.0004, val_loss: 4.1551, val_MinusLogProbMetric: 4.1551

Epoch 238: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0004 - MinusLogProbMetric: 4.0004 - val_loss: 4.1551 - val_MinusLogProbMetric: 4.1551 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 239/1000
2023-09-17 19:31:17.722 
Epoch 239/1000 
	 loss: 3.9994, MinusLogProbMetric: 3.9994, val_loss: 4.1675, val_MinusLogProbMetric: 4.1675

Epoch 239: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9994 - MinusLogProbMetric: 3.9994 - val_loss: 4.1675 - val_MinusLogProbMetric: 4.1675 - lr: 2.5000e-04 - 44s/epoch - 223ms/step
Epoch 240/1000
2023-09-17 19:32:01.912 
Epoch 240/1000 
	 loss: 3.9997, MinusLogProbMetric: 3.9997, val_loss: 4.1769, val_MinusLogProbMetric: 4.1769

Epoch 240: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9997 - MinusLogProbMetric: 3.9997 - val_loss: 4.1769 - val_MinusLogProbMetric: 4.1769 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 241/1000
2023-09-17 19:32:46.288 
Epoch 241/1000 
	 loss: 4.0005, MinusLogProbMetric: 4.0005, val_loss: 4.1642, val_MinusLogProbMetric: 4.1642

Epoch 241: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0005 - MinusLogProbMetric: 4.0005 - val_loss: 4.1642 - val_MinusLogProbMetric: 4.1642 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 242/1000
2023-09-17 19:33:30.452 
Epoch 242/1000 
	 loss: 3.9985, MinusLogProbMetric: 3.9985, val_loss: 4.1650, val_MinusLogProbMetric: 4.1650

Epoch 242: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9985 - MinusLogProbMetric: 3.9985 - val_loss: 4.1650 - val_MinusLogProbMetric: 4.1650 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 243/1000
2023-09-17 19:34:14.414 
Epoch 243/1000 
	 loss: 4.0008, MinusLogProbMetric: 4.0008, val_loss: 4.1655, val_MinusLogProbMetric: 4.1655

Epoch 243: val_loss did not improve from 4.14507
196/196 - 44s - loss: 4.0008 - MinusLogProbMetric: 4.0008 - val_loss: 4.1655 - val_MinusLogProbMetric: 4.1655 - lr: 2.5000e-04 - 44s/epoch - 224ms/step
Epoch 244/1000
2023-09-17 19:34:58.268 
Epoch 244/1000 
	 loss: 3.9994, MinusLogProbMetric: 3.9994, val_loss: 4.1625, val_MinusLogProbMetric: 4.1625

Epoch 244: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9994 - MinusLogProbMetric: 3.9994 - val_loss: 4.1625 - val_MinusLogProbMetric: 4.1625 - lr: 2.5000e-04 - 44s/epoch - 224ms/step
Epoch 245/1000
2023-09-17 19:35:42.482 
Epoch 245/1000 
	 loss: 3.9997, MinusLogProbMetric: 3.9997, val_loss: 4.1640, val_MinusLogProbMetric: 4.1640

Epoch 245: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9997 - MinusLogProbMetric: 3.9997 - val_loss: 4.1640 - val_MinusLogProbMetric: 4.1640 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 246/1000
2023-09-17 19:36:26.146 
Epoch 246/1000 
	 loss: 3.9998, MinusLogProbMetric: 3.9998, val_loss: 4.1625, val_MinusLogProbMetric: 4.1625

Epoch 246: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9998 - MinusLogProbMetric: 3.9998 - val_loss: 4.1625 - val_MinusLogProbMetric: 4.1625 - lr: 2.5000e-04 - 44s/epoch - 223ms/step
Epoch 247/1000
2023-09-17 19:37:09.470 
Epoch 247/1000 
	 loss: 3.9982, MinusLogProbMetric: 3.9982, val_loss: 4.1609, val_MinusLogProbMetric: 4.1609

Epoch 247: val_loss did not improve from 4.14507
196/196 - 43s - loss: 3.9982 - MinusLogProbMetric: 3.9982 - val_loss: 4.1609 - val_MinusLogProbMetric: 4.1609 - lr: 2.5000e-04 - 43s/epoch - 221ms/step
Epoch 248/1000
2023-09-17 19:37:53.268 
Epoch 248/1000 
	 loss: 3.9992, MinusLogProbMetric: 3.9992, val_loss: 4.1638, val_MinusLogProbMetric: 4.1638

Epoch 248: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9992 - MinusLogProbMetric: 3.9992 - val_loss: 4.1638 - val_MinusLogProbMetric: 4.1638 - lr: 2.5000e-04 - 44s/epoch - 223ms/step
Epoch 249/1000
2023-09-17 19:38:36.882 
Epoch 249/1000 
	 loss: 3.9965, MinusLogProbMetric: 3.9965, val_loss: 4.1661, val_MinusLogProbMetric: 4.1661

Epoch 249: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9965 - MinusLogProbMetric: 3.9965 - val_loss: 4.1661 - val_MinusLogProbMetric: 4.1661 - lr: 2.5000e-04 - 44s/epoch - 223ms/step
Epoch 250/1000
2023-09-17 19:39:20.850 
Epoch 250/1000 
	 loss: 3.9968, MinusLogProbMetric: 3.9968, val_loss: 4.1669, val_MinusLogProbMetric: 4.1669

Epoch 250: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9968 - MinusLogProbMetric: 3.9968 - val_loss: 4.1669 - val_MinusLogProbMetric: 4.1669 - lr: 2.5000e-04 - 44s/epoch - 224ms/step
Epoch 251/1000
2023-09-17 19:40:03.933 
Epoch 251/1000 
	 loss: 3.9984, MinusLogProbMetric: 3.9984, val_loss: 4.1678, val_MinusLogProbMetric: 4.1678

Epoch 251: val_loss did not improve from 4.14507
196/196 - 43s - loss: 3.9984 - MinusLogProbMetric: 3.9984 - val_loss: 4.1678 - val_MinusLogProbMetric: 4.1678 - lr: 2.5000e-04 - 43s/epoch - 220ms/step
Epoch 252/1000
2023-09-17 19:40:47.814 
Epoch 252/1000 
	 loss: 3.9985, MinusLogProbMetric: 3.9985, val_loss: 4.1655, val_MinusLogProbMetric: 4.1655

Epoch 252: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9985 - MinusLogProbMetric: 3.9985 - val_loss: 4.1655 - val_MinusLogProbMetric: 4.1655 - lr: 2.5000e-04 - 44s/epoch - 224ms/step
Epoch 253/1000
2023-09-17 19:41:31.666 
Epoch 253/1000 
	 loss: 3.9998, MinusLogProbMetric: 3.9998, val_loss: 4.1588, val_MinusLogProbMetric: 4.1588

Epoch 253: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9998 - MinusLogProbMetric: 3.9998 - val_loss: 4.1588 - val_MinusLogProbMetric: 4.1588 - lr: 2.5000e-04 - 44s/epoch - 224ms/step
Epoch 254/1000
2023-09-17 19:42:15.750 
Epoch 254/1000 
	 loss: 3.9984, MinusLogProbMetric: 3.9984, val_loss: 4.1703, val_MinusLogProbMetric: 4.1703

Epoch 254: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9984 - MinusLogProbMetric: 3.9984 - val_loss: 4.1703 - val_MinusLogProbMetric: 4.1703 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 255/1000
2023-09-17 19:42:59.764 
Epoch 255/1000 
	 loss: 3.9978, MinusLogProbMetric: 3.9978, val_loss: 4.1615, val_MinusLogProbMetric: 4.1615

Epoch 255: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9978 - MinusLogProbMetric: 3.9978 - val_loss: 4.1615 - val_MinusLogProbMetric: 4.1615 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 256/1000
2023-09-17 19:43:43.586 
Epoch 256/1000 
	 loss: 3.9976, MinusLogProbMetric: 3.9976, val_loss: 4.1708, val_MinusLogProbMetric: 4.1708

Epoch 256: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9976 - MinusLogProbMetric: 3.9976 - val_loss: 4.1708 - val_MinusLogProbMetric: 4.1708 - lr: 2.5000e-04 - 44s/epoch - 224ms/step
Epoch 257/1000
2023-09-17 19:44:27.624 
Epoch 257/1000 
	 loss: 3.9972, MinusLogProbMetric: 3.9972, val_loss: 4.1684, val_MinusLogProbMetric: 4.1684

Epoch 257: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9972 - MinusLogProbMetric: 3.9972 - val_loss: 4.1684 - val_MinusLogProbMetric: 4.1684 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 258/1000
2023-09-17 19:45:11.482 
Epoch 258/1000 
	 loss: 3.9984, MinusLogProbMetric: 3.9984, val_loss: 4.1641, val_MinusLogProbMetric: 4.1641

Epoch 258: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9984 - MinusLogProbMetric: 3.9984 - val_loss: 4.1641 - val_MinusLogProbMetric: 4.1641 - lr: 2.5000e-04 - 44s/epoch - 224ms/step
Epoch 259/1000
2023-09-17 19:45:55.013 
Epoch 259/1000 
	 loss: 3.9953, MinusLogProbMetric: 3.9953, val_loss: 4.1613, val_MinusLogProbMetric: 4.1613

Epoch 259: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9953 - MinusLogProbMetric: 3.9953 - val_loss: 4.1613 - val_MinusLogProbMetric: 4.1613 - lr: 2.5000e-04 - 44s/epoch - 222ms/step
Epoch 260/1000
2023-09-17 19:46:38.866 
Epoch 260/1000 
	 loss: 3.9958, MinusLogProbMetric: 3.9958, val_loss: 4.1657, val_MinusLogProbMetric: 4.1657

Epoch 260: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9958 - MinusLogProbMetric: 3.9958 - val_loss: 4.1657 - val_MinusLogProbMetric: 4.1657 - lr: 2.5000e-04 - 44s/epoch - 224ms/step
Epoch 261/1000
2023-09-17 19:47:22.353 
Epoch 261/1000 
	 loss: 3.9974, MinusLogProbMetric: 3.9974, val_loss: 4.1664, val_MinusLogProbMetric: 4.1664

Epoch 261: val_loss did not improve from 4.14507
196/196 - 43s - loss: 3.9974 - MinusLogProbMetric: 3.9974 - val_loss: 4.1664 - val_MinusLogProbMetric: 4.1664 - lr: 2.5000e-04 - 43s/epoch - 222ms/step
Epoch 262/1000
2023-09-17 19:48:06.234 
Epoch 262/1000 
	 loss: 3.9963, MinusLogProbMetric: 3.9963, val_loss: 4.1641, val_MinusLogProbMetric: 4.1641

Epoch 262: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9963 - MinusLogProbMetric: 3.9963 - val_loss: 4.1641 - val_MinusLogProbMetric: 4.1641 - lr: 2.5000e-04 - 44s/epoch - 224ms/step
Epoch 263/1000
2023-09-17 19:48:49.965 
Epoch 263/1000 
	 loss: 3.9967, MinusLogProbMetric: 3.9967, val_loss: 4.1685, val_MinusLogProbMetric: 4.1685

Epoch 263: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9967 - MinusLogProbMetric: 3.9967 - val_loss: 4.1685 - val_MinusLogProbMetric: 4.1685 - lr: 2.5000e-04 - 44s/epoch - 223ms/step
Epoch 264/1000
2023-09-17 19:49:33.286 
Epoch 264/1000 
	 loss: 3.9979, MinusLogProbMetric: 3.9979, val_loss: 4.1612, val_MinusLogProbMetric: 4.1612

Epoch 264: val_loss did not improve from 4.14507
196/196 - 43s - loss: 3.9979 - MinusLogProbMetric: 3.9979 - val_loss: 4.1612 - val_MinusLogProbMetric: 4.1612 - lr: 2.5000e-04 - 43s/epoch - 221ms/step
Epoch 265/1000
2023-09-17 19:50:16.954 
Epoch 265/1000 
	 loss: 3.9955, MinusLogProbMetric: 3.9955, val_loss: 4.1640, val_MinusLogProbMetric: 4.1640

Epoch 265: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9955 - MinusLogProbMetric: 3.9955 - val_loss: 4.1640 - val_MinusLogProbMetric: 4.1640 - lr: 2.5000e-04 - 44s/epoch - 223ms/step
Epoch 266/1000
2023-09-17 19:51:01.040 
Epoch 266/1000 
	 loss: 3.9971, MinusLogProbMetric: 3.9971, val_loss: 4.1659, val_MinusLogProbMetric: 4.1659

Epoch 266: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9971 - MinusLogProbMetric: 3.9971 - val_loss: 4.1659 - val_MinusLogProbMetric: 4.1659 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 267/1000
2023-09-17 19:51:44.793 
Epoch 267/1000 
	 loss: 3.9959, MinusLogProbMetric: 3.9959, val_loss: 4.1720, val_MinusLogProbMetric: 4.1720

Epoch 267: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9959 - MinusLogProbMetric: 3.9959 - val_loss: 4.1720 - val_MinusLogProbMetric: 4.1720 - lr: 2.5000e-04 - 44s/epoch - 223ms/step
Epoch 268/1000
2023-09-17 19:52:28.639 
Epoch 268/1000 
	 loss: 3.9957, MinusLogProbMetric: 3.9957, val_loss: 4.1657, val_MinusLogProbMetric: 4.1657

Epoch 268: val_loss did not improve from 4.14507
196/196 - 44s - loss: 3.9957 - MinusLogProbMetric: 3.9957 - val_loss: 4.1657 - val_MinusLogProbMetric: 4.1657 - lr: 2.5000e-04 - 44s/epoch - 224ms/step
Epoch 269/1000
2023-09-17 19:53:12.480 
Epoch 269/1000 
	 loss: 3.9959, MinusLogProbMetric: 3.9959, val_loss: 4.1679, val_MinusLogProbMetric: 4.1679

Epoch 269: val_loss did not improve from 4.14507
Restoring model weights from the end of the best epoch: 169.
196/196 - 44s - loss: 3.9959 - MinusLogProbMetric: 3.9959 - val_loss: 4.1679 - val_MinusLogProbMetric: 4.1679 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 269: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 13.420100362971425 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 8.75766038801521 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 5.7880664428230375 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7faf1153f400> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 14.69604880711995 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 6.42567412997596 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 5.535171739058569 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7faeebb5d000> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 869.
Model trained in 11849.05 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

Plots done in 9.36 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 80.10 s.
===========
Run 139/720 done in 11935.57 s.
===========

Directory ../../results/CsplineN_new/run_140/ already exists.
Skipping it.
===========
Run 140/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_141/ already exists.
Skipping it.
===========
Run 141/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_142/ already exists.
Skipping it.
===========
Run 142/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_143/ already exists.
Skipping it.
===========
Run 143/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_144/ already exists.
Skipping it.
===========
Run 144/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_145/ already exists.
Skipping it.
===========
Run 145/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_146/ already exists.
Skipping it.
===========
Run 146/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_147/ already exists.
Skipping it.
===========
Run 147/720 already exists. Skipping it.
===========

===========
Generating train data for run 148.
===========
Train data generated in 0.29 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 8)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_148/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 926}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_148/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[-1.8162504e-02,  8.8381166e+00,  8.6877737e+00, ...,
         6.9322171e+00,  4.0983129e+00,  7.9362688e+00],
       [ 8.7457299e-03,  8.1090946e+00,  7.2493863e+00, ...,
         6.9349885e+00,  4.6630187e+00,  7.8035836e+00],
       [ 9.8774462e+00,  3.2168188e+00,  7.9118123e+00, ...,
         9.3064079e+00,  6.8860310e-01,  1.4308348e+00],
       ...,
       [ 4.7885728e-01,  7.5187321e+00,  7.6983232e+00, ...,
         7.2090416e+00,  4.8741002e+00,  7.5171561e+00],
       [ 2.5328305e-01,  8.1886292e+00,  8.8014259e+00, ...,
         9.1725578e+00,  4.1776223e+00,  7.7115631e+00],
       [ 2.6981741e-02,  8.2328224e+00,  7.0491204e+00, ...,
         8.6794777e+00,  4.7622304e+00,  7.8125534e+00]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_148/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_148
self.data_kwargs: {'seed': 926}
self.x_data: [[-0.05356155  7.823141    8.656547   ...  7.203113    4.5568213
   7.9341974 ]
 [ 0.33506995  8.891628    6.827406   ...  7.456951    4.5099497
   7.6623387 ]
 [ 9.696308    4.906292    7.9414268  ...  8.918397    0.67725384
  -0.04672056]
 ...
 [10.426017    4.189514    7.913414   ...  7.849298    1.1715728
   1.3694253 ]
 [ 9.3889      2.8583937   7.9482403  ...  9.59728     0.5144149
   0.49252704]
 [ 5.455715    6.4598684   6.023231   ...  6.084529    4.572967
   7.994362  ]]
self.y_data: []
self.ndims: 8
Model defined.
Model: "model_106"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_107 (InputLayer)      [(None, 8)]               0         
                                                                 
 log_prob_layer_11 (LogProbL  (None,)                  844220    
 ayer)                                                           
                                                                 
=================================================================
Total params: 844,220
Trainable params: 844,220
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_11/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_11'")
self.model: <keras.engine.functional.Functional object at 0x7fae94f23fd0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fae95fa7580>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fae95fa7580>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7faeccb33430>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fae94f77040>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_148/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fae94f775b0>, <keras.callbacks.ModelCheckpoint object at 0x7fae94f77670>, <keras.callbacks.EarlyStopping object at 0x7fae94f778e0>, <keras.callbacks.ReduceLROnPlateau object at 0x7fae94f77910>, <keras.callbacks.TerminateOnNaN object at 0x7fae94f77550>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[-1.8162504e-02,  8.8381166e+00,  8.6877737e+00, ...,
         6.9322171e+00,  4.0983129e+00,  7.9362688e+00],
       [ 8.7457299e-03,  8.1090946e+00,  7.2493863e+00, ...,
         6.9349885e+00,  4.6630187e+00,  7.8035836e+00],
       [ 9.8774462e+00,  3.2168188e+00,  7.9118123e+00, ...,
         9.3064079e+00,  6.8860310e-01,  1.4308348e+00],
       ...,
       [ 4.7885728e-01,  7.5187321e+00,  7.6983232e+00, ...,
         7.2090416e+00,  4.8741002e+00,  7.5171561e+00],
       [ 2.5328305e-01,  8.1886292e+00,  8.8014259e+00, ...,
         9.1725578e+00,  4.1776223e+00,  7.7115631e+00],
       [ 2.6981741e-02,  8.2328224e+00,  7.0491204e+00, ...,
         8.6794777e+00,  4.7622304e+00,  7.8125534e+00]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_148/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 148/720 with hyperparameters:
timestamp = 2023-09-17 19:54:39.747875
ndims = 8
seed_train = 926
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 5
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 844220
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [-0.05356155  7.823141    8.656547    8.717833   10.823843    7.203113
  4.5568213   7.9341974 ]
Epoch 1/1000
2023-09-17 19:57:17.725 
Epoch 1/1000 
	 loss: 11.9615, MinusLogProbMetric: 11.9615, val_loss: 7.2929, val_MinusLogProbMetric: 7.2929

Epoch 1: val_loss improved from inf to 7.29286, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_148/weights/best_weights.h5
196/196 - 159s - loss: 11.9615 - MinusLogProbMetric: 11.9615 - val_loss: 7.2929 - val_MinusLogProbMetric: 7.2929 - lr: 0.0010 - 159s/epoch - 809ms/step
Epoch 2/1000
2023-09-17 19:58:01.871 
Epoch 2/1000 
	 loss: 6.2860, MinusLogProbMetric: 6.2860, val_loss: 5.6164, val_MinusLogProbMetric: 5.6164

Epoch 2: val_loss improved from 7.29286 to 5.61639, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_148/weights/best_weights.h5
196/196 - 44s - loss: 6.2860 - MinusLogProbMetric: 6.2860 - val_loss: 5.6164 - val_MinusLogProbMetric: 5.6164 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 3/1000
2023-09-17 19:58:44.004 
Epoch 3/1000 
	 loss: 5.4574, MinusLogProbMetric: 5.4574, val_loss: 4.8191, val_MinusLogProbMetric: 4.8191

Epoch 3: val_loss improved from 5.61639 to 4.81912, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_148/weights/best_weights.h5
196/196 - 42s - loss: 5.4574 - MinusLogProbMetric: 5.4574 - val_loss: 4.8191 - val_MinusLogProbMetric: 4.8191 - lr: 0.0010 - 42s/epoch - 216ms/step
Epoch 4/1000
2023-09-17 19:59:26.853 
Epoch 4/1000 
	 loss: 5.1365, MinusLogProbMetric: 5.1365, val_loss: 5.1433, val_MinusLogProbMetric: 5.1433

Epoch 4: val_loss did not improve from 4.81912
196/196 - 42s - loss: 5.1365 - MinusLogProbMetric: 5.1365 - val_loss: 5.1433 - val_MinusLogProbMetric: 5.1433 - lr: 0.0010 - 42s/epoch - 214ms/step
Epoch 5/1000
2023-09-17 20:00:08.604 
Epoch 5/1000 
	 loss: 4.8924, MinusLogProbMetric: 4.8924, val_loss: 4.6975, val_MinusLogProbMetric: 4.6975

Epoch 5: val_loss improved from 4.81912 to 4.69748, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_148/weights/best_weights.h5
196/196 - 43s - loss: 4.8924 - MinusLogProbMetric: 4.8924 - val_loss: 4.6975 - val_MinusLogProbMetric: 4.6975 - lr: 0.0010 - 43s/epoch - 217ms/step
Epoch 6/1000
2023-09-17 20:00:51.800 
Epoch 6/1000 
	 loss: 4.8157, MinusLogProbMetric: 4.8157, val_loss: 4.7804, val_MinusLogProbMetric: 4.7804

Epoch 6: val_loss did not improve from 4.69748
196/196 - 42s - loss: 4.8157 - MinusLogProbMetric: 4.8157 - val_loss: 4.7804 - val_MinusLogProbMetric: 4.7804 - lr: 0.0010 - 42s/epoch - 216ms/step
Epoch 7/1000
2023-09-17 20:01:33.776 
Epoch 7/1000 
	 loss: 4.7380, MinusLogProbMetric: 4.7380, val_loss: 4.5167, val_MinusLogProbMetric: 4.5167

Epoch 7: val_loss improved from 4.69748 to 4.51675, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_148/weights/best_weights.h5
196/196 - 43s - loss: 4.7380 - MinusLogProbMetric: 4.7380 - val_loss: 4.5167 - val_MinusLogProbMetric: 4.5167 - lr: 0.0010 - 43s/epoch - 218ms/step
Epoch 8/1000
2023-09-17 20:02:16.435 
Epoch 8/1000 
	 loss: 4.6703, MinusLogProbMetric: 4.6703, val_loss: 5.7282, val_MinusLogProbMetric: 5.7282

Epoch 8: val_loss did not improve from 4.51675
196/196 - 42s - loss: 4.6703 - MinusLogProbMetric: 4.6703 - val_loss: 5.7282 - val_MinusLogProbMetric: 5.7282 - lr: 0.0010 - 42s/epoch - 214ms/step
Epoch 9/1000
2023-09-17 20:02:58.115 
Epoch 9/1000 
	 loss: 4.6271, MinusLogProbMetric: 4.6271, val_loss: 4.8465, val_MinusLogProbMetric: 4.8465

Epoch 9: val_loss did not improve from 4.51675
196/196 - 42s - loss: 4.6271 - MinusLogProbMetric: 4.6271 - val_loss: 4.8465 - val_MinusLogProbMetric: 4.8465 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 10/1000
2023-09-17 20:03:40.456 
Epoch 10/1000 
	 loss: 4.5623, MinusLogProbMetric: 4.5623, val_loss: 4.5562, val_MinusLogProbMetric: 4.5562

Epoch 10: val_loss did not improve from 4.51675
196/196 - 42s - loss: 4.5623 - MinusLogProbMetric: 4.5623 - val_loss: 4.5562 - val_MinusLogProbMetric: 4.5562 - lr: 0.0010 - 42s/epoch - 216ms/step
Epoch 11/1000
2023-09-17 20:04:22.823 
Epoch 11/1000 
	 loss: 4.5892, MinusLogProbMetric: 4.5892, val_loss: 4.5487, val_MinusLogProbMetric: 4.5487

Epoch 11: val_loss did not improve from 4.51675
196/196 - 42s - loss: 4.5892 - MinusLogProbMetric: 4.5892 - val_loss: 4.5487 - val_MinusLogProbMetric: 4.5487 - lr: 0.0010 - 42s/epoch - 216ms/step
Epoch 12/1000
2023-09-17 20:05:04.413 
Epoch 12/1000 
	 loss: 4.5150, MinusLogProbMetric: 4.5150, val_loss: 4.4181, val_MinusLogProbMetric: 4.4181

Epoch 12: val_loss improved from 4.51675 to 4.41811, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_148/weights/best_weights.h5
196/196 - 43s - loss: 4.5150 - MinusLogProbMetric: 4.5150 - val_loss: 4.4181 - val_MinusLogProbMetric: 4.4181 - lr: 0.0010 - 43s/epoch - 217ms/step
Epoch 13/1000
2023-09-17 20:05:47.552 
Epoch 13/1000 
	 loss: 4.5133, MinusLogProbMetric: 4.5133, val_loss: 4.3821, val_MinusLogProbMetric: 4.3821

Epoch 13: val_loss improved from 4.41811 to 4.38209, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_148/weights/best_weights.h5
196/196 - 43s - loss: 4.5133 - MinusLogProbMetric: 4.5133 - val_loss: 4.3821 - val_MinusLogProbMetric: 4.3821 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 14/1000
2023-09-17 20:06:30.621 
Epoch 14/1000 
	 loss: 4.4663, MinusLogProbMetric: 4.4663, val_loss: 4.4064, val_MinusLogProbMetric: 4.4064

Epoch 14: val_loss did not improve from 4.38209
196/196 - 42s - loss: 4.4663 - MinusLogProbMetric: 4.4663 - val_loss: 4.4064 - val_MinusLogProbMetric: 4.4064 - lr: 0.0010 - 42s/epoch - 216ms/step
Epoch 15/1000
2023-09-17 20:07:13.174 
Epoch 15/1000 
	 loss: 4.4641, MinusLogProbMetric: 4.4641, val_loss: 4.3151, val_MinusLogProbMetric: 4.3151

Epoch 15: val_loss improved from 4.38209 to 4.31508, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_148/weights/best_weights.h5
196/196 - 43s - loss: 4.4641 - MinusLogProbMetric: 4.4641 - val_loss: 4.3151 - val_MinusLogProbMetric: 4.3151 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 16/1000
2023-09-17 20:07:55.855 
Epoch 16/1000 
	 loss: 4.4368, MinusLogProbMetric: 4.4368, val_loss: 4.4634, val_MinusLogProbMetric: 4.4634

Epoch 16: val_loss did not improve from 4.31508
196/196 - 42s - loss: 4.4368 - MinusLogProbMetric: 4.4368 - val_loss: 4.4634 - val_MinusLogProbMetric: 4.4634 - lr: 0.0010 - 42s/epoch - 214ms/step
Epoch 17/1000
2023-09-17 20:08:37.795 
Epoch 17/1000 
	 loss: 4.3890, MinusLogProbMetric: 4.3890, val_loss: 4.3297, val_MinusLogProbMetric: 4.3297

Epoch 17: val_loss did not improve from 4.31508
196/196 - 42s - loss: 4.3890 - MinusLogProbMetric: 4.3890 - val_loss: 4.3297 - val_MinusLogProbMetric: 4.3297 - lr: 0.0010 - 42s/epoch - 214ms/step
Epoch 18/1000
2023-09-17 20:09:18.973 
Epoch 18/1000 
	 loss: 4.3985, MinusLogProbMetric: 4.3985, val_loss: 4.3340, val_MinusLogProbMetric: 4.3340

Epoch 18: val_loss did not improve from 4.31508
196/196 - 41s - loss: 4.3985 - MinusLogProbMetric: 4.3985 - val_loss: 4.3340 - val_MinusLogProbMetric: 4.3340 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 19/1000
2023-09-17 20:10:00.402 
Epoch 19/1000 
	 loss: 4.3971, MinusLogProbMetric: 4.3971, val_loss: 4.3250, val_MinusLogProbMetric: 4.3250

Epoch 19: val_loss did not improve from 4.31508
196/196 - 41s - loss: 4.3971 - MinusLogProbMetric: 4.3971 - val_loss: 4.3250 - val_MinusLogProbMetric: 4.3250 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 20/1000
2023-09-17 20:10:42.178 
Epoch 20/1000 
	 loss: 4.3550, MinusLogProbMetric: 4.3550, val_loss: 4.3323, val_MinusLogProbMetric: 4.3323

Epoch 20: val_loss did not improve from 4.31508
196/196 - 42s - loss: 4.3550 - MinusLogProbMetric: 4.3550 - val_loss: 4.3323 - val_MinusLogProbMetric: 4.3323 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 21/1000
2023-09-17 20:11:24.101 
Epoch 21/1000 
	 loss: 4.3136, MinusLogProbMetric: 4.3136, val_loss: 4.5919, val_MinusLogProbMetric: 4.5919

Epoch 21: val_loss did not improve from 4.31508
196/196 - 42s - loss: 4.3136 - MinusLogProbMetric: 4.3136 - val_loss: 4.5919 - val_MinusLogProbMetric: 4.5919 - lr: 0.0010 - 42s/epoch - 214ms/step
Epoch 22/1000
2023-09-17 20:12:05.083 
Epoch 22/1000 
	 loss: 4.3224, MinusLogProbMetric: 4.3224, val_loss: 4.3494, val_MinusLogProbMetric: 4.3494

Epoch 22: val_loss did not improve from 4.31508
196/196 - 41s - loss: 4.3224 - MinusLogProbMetric: 4.3224 - val_loss: 4.3494 - val_MinusLogProbMetric: 4.3494 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 23/1000
2023-09-17 20:12:47.288 
Epoch 23/1000 
	 loss: 4.3230, MinusLogProbMetric: 4.3230, val_loss: 4.3811, val_MinusLogProbMetric: 4.3811

Epoch 23: val_loss did not improve from 4.31508
196/196 - 42s - loss: 4.3230 - MinusLogProbMetric: 4.3230 - val_loss: 4.3811 - val_MinusLogProbMetric: 4.3811 - lr: 0.0010 - 42s/epoch - 215ms/step
Epoch 24/1000
2023-09-17 20:13:28.253 
Epoch 24/1000 
	 loss: 4.3145, MinusLogProbMetric: 4.3145, val_loss: 4.4371, val_MinusLogProbMetric: 4.4371

Epoch 24: val_loss did not improve from 4.31508
196/196 - 41s - loss: 4.3145 - MinusLogProbMetric: 4.3145 - val_loss: 4.4371 - val_MinusLogProbMetric: 4.4371 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 25/1000
2023-09-17 20:14:09.574 
Epoch 25/1000 
	 loss: 4.3046, MinusLogProbMetric: 4.3046, val_loss: 4.4504, val_MinusLogProbMetric: 4.4504

Epoch 25: val_loss did not improve from 4.31508
196/196 - 41s - loss: 4.3046 - MinusLogProbMetric: 4.3046 - val_loss: 4.4504 - val_MinusLogProbMetric: 4.4504 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 26/1000
2023-09-17 20:14:50.922 
Epoch 26/1000 
	 loss: 4.2953, MinusLogProbMetric: 4.2953, val_loss: 4.3045, val_MinusLogProbMetric: 4.3045

Epoch 26: val_loss improved from 4.31508 to 4.30450, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_148/weights/best_weights.h5
196/196 - 42s - loss: 4.2953 - MinusLogProbMetric: 4.2953 - val_loss: 4.3045 - val_MinusLogProbMetric: 4.3045 - lr: 0.0010 - 42s/epoch - 215ms/step
Epoch 27/1000
2023-09-17 20:15:33.009 
Epoch 27/1000 
	 loss: 4.2643, MinusLogProbMetric: 4.2643, val_loss: 4.3909, val_MinusLogProbMetric: 4.3909

Epoch 27: val_loss did not improve from 4.30450
196/196 - 41s - loss: 4.2643 - MinusLogProbMetric: 4.2643 - val_loss: 4.3909 - val_MinusLogProbMetric: 4.3909 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 28/1000
2023-09-17 20:16:14.591 
Epoch 28/1000 
	 loss: 4.3059, MinusLogProbMetric: 4.3059, val_loss: 4.2940, val_MinusLogProbMetric: 4.2940

Epoch 28: val_loss improved from 4.30450 to 4.29398, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_148/weights/best_weights.h5
196/196 - 42s - loss: 4.3059 - MinusLogProbMetric: 4.3059 - val_loss: 4.2940 - val_MinusLogProbMetric: 4.2940 - lr: 0.0010 - 42s/epoch - 216ms/step
Epoch 29/1000
2023-09-17 20:16:56.525 
Epoch 29/1000 
	 loss: 4.2676, MinusLogProbMetric: 4.2676, val_loss: 4.3454, val_MinusLogProbMetric: 4.3454

Epoch 29: val_loss did not improve from 4.29398
196/196 - 41s - loss: 4.2676 - MinusLogProbMetric: 4.2676 - val_loss: 4.3454 - val_MinusLogProbMetric: 4.3454 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 30/1000
2023-09-17 20:17:37.772 
Epoch 30/1000 
	 loss: 4.2732, MinusLogProbMetric: 4.2732, val_loss: 4.2999, val_MinusLogProbMetric: 4.2999

Epoch 30: val_loss did not improve from 4.29398
196/196 - 41s - loss: 4.2732 - MinusLogProbMetric: 4.2732 - val_loss: 4.2999 - val_MinusLogProbMetric: 4.2999 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 31/1000
2023-09-17 20:18:19.440 
Epoch 31/1000 
	 loss: 4.2712, MinusLogProbMetric: 4.2712, val_loss: 4.3035, val_MinusLogProbMetric: 4.3035

Epoch 31: val_loss did not improve from 4.29398
196/196 - 42s - loss: 4.2712 - MinusLogProbMetric: 4.2712 - val_loss: 4.3035 - val_MinusLogProbMetric: 4.3035 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 32/1000
2023-09-17 20:19:00.917 
Epoch 32/1000 
	 loss: 4.2572, MinusLogProbMetric: 4.2572, val_loss: 4.2877, val_MinusLogProbMetric: 4.2877

Epoch 32: val_loss improved from 4.29398 to 4.28770, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_148/weights/best_weights.h5
196/196 - 42s - loss: 4.2572 - MinusLogProbMetric: 4.2572 - val_loss: 4.2877 - val_MinusLogProbMetric: 4.2877 - lr: 0.0010 - 42s/epoch - 216ms/step
Epoch 33/1000
2023-09-17 20:19:42.143 
Epoch 33/1000 
	 loss: 4.2290, MinusLogProbMetric: 4.2290, val_loss: 4.3545, val_MinusLogProbMetric: 4.3545

Epoch 33: val_loss did not improve from 4.28770
196/196 - 40s - loss: 4.2290 - MinusLogProbMetric: 4.2290 - val_loss: 4.3545 - val_MinusLogProbMetric: 4.3545 - lr: 0.0010 - 40s/epoch - 206ms/step
Epoch 34/1000
2023-09-17 20:20:23.375 
Epoch 34/1000 
	 loss: 4.2470, MinusLogProbMetric: 4.2470, val_loss: 4.3211, val_MinusLogProbMetric: 4.3211

Epoch 34: val_loss did not improve from 4.28770
196/196 - 41s - loss: 4.2470 - MinusLogProbMetric: 4.2470 - val_loss: 4.3211 - val_MinusLogProbMetric: 4.3211 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 35/1000
2023-09-17 20:21:04.330 
Epoch 35/1000 
	 loss: 4.2057, MinusLogProbMetric: 4.2057, val_loss: 4.3192, val_MinusLogProbMetric: 4.3192

Epoch 35: val_loss did not improve from 4.28770
196/196 - 41s - loss: 4.2057 - MinusLogProbMetric: 4.2057 - val_loss: 4.3192 - val_MinusLogProbMetric: 4.3192 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 36/1000
2023-09-17 20:21:45.423 
Epoch 36/1000 
	 loss: 4.2366, MinusLogProbMetric: 4.2366, val_loss: 4.1927, val_MinusLogProbMetric: 4.1927

Epoch 36: val_loss improved from 4.28770 to 4.19265, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_148/weights/best_weights.h5
196/196 - 42s - loss: 4.2366 - MinusLogProbMetric: 4.2366 - val_loss: 4.1927 - val_MinusLogProbMetric: 4.1927 - lr: 0.0010 - 42s/epoch - 214ms/step
Epoch 37/1000
2023-09-17 20:22:28.533 
Epoch 37/1000 
	 loss: 4.2317, MinusLogProbMetric: 4.2317, val_loss: 4.3700, val_MinusLogProbMetric: 4.3700

Epoch 37: val_loss did not improve from 4.19265
196/196 - 42s - loss: 4.2317 - MinusLogProbMetric: 4.2317 - val_loss: 4.3700 - val_MinusLogProbMetric: 4.3700 - lr: 0.0010 - 42s/epoch - 215ms/step
Epoch 38/1000
2023-09-17 20:23:09.840 
Epoch 38/1000 
	 loss: 4.2321, MinusLogProbMetric: 4.2321, val_loss: 4.2047, val_MinusLogProbMetric: 4.2047

Epoch 38: val_loss did not improve from 4.19265
196/196 - 41s - loss: 4.2321 - MinusLogProbMetric: 4.2321 - val_loss: 4.2047 - val_MinusLogProbMetric: 4.2047 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 39/1000
2023-09-17 20:23:50.889 
Epoch 39/1000 
	 loss: 4.2145, MinusLogProbMetric: 4.2145, val_loss: 4.2739, val_MinusLogProbMetric: 4.2739

Epoch 39: val_loss did not improve from 4.19265
196/196 - 41s - loss: 4.2145 - MinusLogProbMetric: 4.2145 - val_loss: 4.2739 - val_MinusLogProbMetric: 4.2739 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 40/1000
2023-09-17 20:24:31.997 
Epoch 40/1000 
	 loss: 4.1956, MinusLogProbMetric: 4.1956, val_loss: 4.2250, val_MinusLogProbMetric: 4.2250

Epoch 40: val_loss did not improve from 4.19265
196/196 - 41s - loss: 4.1956 - MinusLogProbMetric: 4.1956 - val_loss: 4.2250 - val_MinusLogProbMetric: 4.2250 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 41/1000
2023-09-17 20:25:13.390 
Epoch 41/1000 
	 loss: 4.2041, MinusLogProbMetric: 4.2041, val_loss: 4.2950, val_MinusLogProbMetric: 4.2950

Epoch 41: val_loss did not improve from 4.19265
196/196 - 41s - loss: 4.2041 - MinusLogProbMetric: 4.2041 - val_loss: 4.2950 - val_MinusLogProbMetric: 4.2950 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 42/1000
2023-09-17 20:25:55.472 
Epoch 42/1000 
	 loss: 4.2181, MinusLogProbMetric: 4.2181, val_loss: 4.2425, val_MinusLogProbMetric: 4.2425

Epoch 42: val_loss did not improve from 4.19265
196/196 - 42s - loss: 4.2181 - MinusLogProbMetric: 4.2181 - val_loss: 4.2425 - val_MinusLogProbMetric: 4.2425 - lr: 0.0010 - 42s/epoch - 215ms/step
Epoch 43/1000
2023-09-17 20:26:36.914 
Epoch 43/1000 
	 loss: 4.1952, MinusLogProbMetric: 4.1952, val_loss: 4.2922, val_MinusLogProbMetric: 4.2922

Epoch 43: val_loss did not improve from 4.19265
196/196 - 41s - loss: 4.1952 - MinusLogProbMetric: 4.1952 - val_loss: 4.2922 - val_MinusLogProbMetric: 4.2922 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 44/1000
2023-09-17 20:27:18.283 
Epoch 44/1000 
	 loss: 4.1925, MinusLogProbMetric: 4.1925, val_loss: 4.3061, val_MinusLogProbMetric: 4.3061

Epoch 44: val_loss did not improve from 4.19265
196/196 - 41s - loss: 4.1925 - MinusLogProbMetric: 4.1925 - val_loss: 4.3061 - val_MinusLogProbMetric: 4.3061 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 45/1000
2023-09-17 20:28:00.672 
Epoch 45/1000 
	 loss: 4.2122, MinusLogProbMetric: 4.2122, val_loss: 4.2086, val_MinusLogProbMetric: 4.2086

Epoch 45: val_loss did not improve from 4.19265
196/196 - 42s - loss: 4.2122 - MinusLogProbMetric: 4.2122 - val_loss: 4.2086 - val_MinusLogProbMetric: 4.2086 - lr: 0.0010 - 42s/epoch - 216ms/step
Epoch 46/1000
2023-09-17 20:28:42.045 
Epoch 46/1000 
	 loss: 4.1873, MinusLogProbMetric: 4.1873, val_loss: 4.2893, val_MinusLogProbMetric: 4.2893

Epoch 46: val_loss did not improve from 4.19265
196/196 - 41s - loss: 4.1873 - MinusLogProbMetric: 4.1873 - val_loss: 4.2893 - val_MinusLogProbMetric: 4.2893 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 47/1000
2023-09-17 20:29:23.086 
Epoch 47/1000 
	 loss: 4.1881, MinusLogProbMetric: 4.1881, val_loss: 4.2530, val_MinusLogProbMetric: 4.2530

Epoch 47: val_loss did not improve from 4.19265
196/196 - 41s - loss: 4.1881 - MinusLogProbMetric: 4.1881 - val_loss: 4.2530 - val_MinusLogProbMetric: 4.2530 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 48/1000
2023-09-17 20:30:04.731 
Epoch 48/1000 
	 loss: 4.2003, MinusLogProbMetric: 4.2003, val_loss: 4.1827, val_MinusLogProbMetric: 4.1827

Epoch 48: val_loss improved from 4.19265 to 4.18274, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_148/weights/best_weights.h5
196/196 - 42s - loss: 4.2003 - MinusLogProbMetric: 4.2003 - val_loss: 4.1827 - val_MinusLogProbMetric: 4.1827 - lr: 0.0010 - 42s/epoch - 217ms/step
Epoch 49/1000
2023-09-17 20:30:47.238 
Epoch 49/1000 
	 loss: 4.1828, MinusLogProbMetric: 4.1828, val_loss: 4.2478, val_MinusLogProbMetric: 4.2478

Epoch 49: val_loss did not improve from 4.18274
196/196 - 42s - loss: 4.1828 - MinusLogProbMetric: 4.1828 - val_loss: 4.2478 - val_MinusLogProbMetric: 4.2478 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 50/1000
2023-09-17 20:31:28.378 
Epoch 50/1000 
	 loss: 4.1752, MinusLogProbMetric: 4.1752, val_loss: 4.3370, val_MinusLogProbMetric: 4.3370

Epoch 50: val_loss did not improve from 4.18274
196/196 - 41s - loss: 4.1752 - MinusLogProbMetric: 4.1752 - val_loss: 4.3370 - val_MinusLogProbMetric: 4.3370 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 51/1000
2023-09-17 20:32:09.731 
Epoch 51/1000 
	 loss: 4.1887, MinusLogProbMetric: 4.1887, val_loss: 4.2209, val_MinusLogProbMetric: 4.2209

Epoch 51: val_loss did not improve from 4.18274
196/196 - 41s - loss: 4.1887 - MinusLogProbMetric: 4.1887 - val_loss: 4.2209 - val_MinusLogProbMetric: 4.2209 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 52/1000
2023-09-17 20:32:52.027 
Epoch 52/1000 
	 loss: 4.1660, MinusLogProbMetric: 4.1660, val_loss: 4.2994, val_MinusLogProbMetric: 4.2994

Epoch 52: val_loss did not improve from 4.18274
196/196 - 42s - loss: 4.1660 - MinusLogProbMetric: 4.1660 - val_loss: 4.2994 - val_MinusLogProbMetric: 4.2994 - lr: 0.0010 - 42s/epoch - 216ms/step
Epoch 53/1000
2023-09-17 20:33:33.236 
Epoch 53/1000 
	 loss: 4.1624, MinusLogProbMetric: 4.1624, val_loss: 4.1907, val_MinusLogProbMetric: 4.1907

Epoch 53: val_loss did not improve from 4.18274
196/196 - 41s - loss: 4.1624 - MinusLogProbMetric: 4.1624 - val_loss: 4.1907 - val_MinusLogProbMetric: 4.1907 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 54/1000
2023-09-17 20:34:14.462 
Epoch 54/1000 
	 loss: 4.1678, MinusLogProbMetric: 4.1678, val_loss: 4.1867, val_MinusLogProbMetric: 4.1867

Epoch 54: val_loss did not improve from 4.18274
196/196 - 41s - loss: 4.1678 - MinusLogProbMetric: 4.1678 - val_loss: 4.1867 - val_MinusLogProbMetric: 4.1867 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 55/1000
2023-09-17 20:34:56.308 
Epoch 55/1000 
	 loss: 4.1595, MinusLogProbMetric: 4.1595, val_loss: 4.1690, val_MinusLogProbMetric: 4.1690

Epoch 55: val_loss improved from 4.18274 to 4.16898, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_148/weights/best_weights.h5
196/196 - 43s - loss: 4.1595 - MinusLogProbMetric: 4.1595 - val_loss: 4.1690 - val_MinusLogProbMetric: 4.1690 - lr: 0.0010 - 43s/epoch - 217ms/step
Epoch 56/1000
2023-09-17 20:35:38.282 
Epoch 56/1000 
	 loss: 4.1440, MinusLogProbMetric: 4.1440, val_loss: 4.4098, val_MinusLogProbMetric: 4.4098

Epoch 56: val_loss did not improve from 4.16898
196/196 - 41s - loss: 4.1440 - MinusLogProbMetric: 4.1440 - val_loss: 4.4098 - val_MinusLogProbMetric: 4.4098 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 57/1000
2023-09-17 20:36:19.973 
Epoch 57/1000 
	 loss: 4.1399, MinusLogProbMetric: 4.1399, val_loss: 4.1857, val_MinusLogProbMetric: 4.1857

Epoch 57: val_loss did not improve from 4.16898
196/196 - 42s - loss: 4.1399 - MinusLogProbMetric: 4.1399 - val_loss: 4.1857 - val_MinusLogProbMetric: 4.1857 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 58/1000
2023-09-17 20:37:02.066 
Epoch 58/1000 
	 loss: 4.1552, MinusLogProbMetric: 4.1552, val_loss: 4.1843, val_MinusLogProbMetric: 4.1843

Epoch 58: val_loss did not improve from 4.16898
196/196 - 42s - loss: 4.1552 - MinusLogProbMetric: 4.1552 - val_loss: 4.1843 - val_MinusLogProbMetric: 4.1843 - lr: 0.0010 - 42s/epoch - 215ms/step
Epoch 59/1000
2023-09-17 20:37:43.283 
Epoch 59/1000 
	 loss: 4.1576, MinusLogProbMetric: 4.1576, val_loss: 4.2038, val_MinusLogProbMetric: 4.2038

Epoch 59: val_loss did not improve from 4.16898
196/196 - 41s - loss: 4.1576 - MinusLogProbMetric: 4.1576 - val_loss: 4.2038 - val_MinusLogProbMetric: 4.2038 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 60/1000
2023-09-17 20:38:25.293 
Epoch 60/1000 
	 loss: 4.1621, MinusLogProbMetric: 4.1621, val_loss: 4.1766, val_MinusLogProbMetric: 4.1766

Epoch 60: val_loss did not improve from 4.16898
196/196 - 42s - loss: 4.1621 - MinusLogProbMetric: 4.1621 - val_loss: 4.1766 - val_MinusLogProbMetric: 4.1766 - lr: 0.0010 - 42s/epoch - 214ms/step
Epoch 61/1000
2023-09-17 20:39:06.914 
Epoch 61/1000 
	 loss: 4.1506, MinusLogProbMetric: 4.1506, val_loss: 4.2280, val_MinusLogProbMetric: 4.2280

Epoch 61: val_loss did not improve from 4.16898
196/196 - 42s - loss: 4.1506 - MinusLogProbMetric: 4.1506 - val_loss: 4.2280 - val_MinusLogProbMetric: 4.2280 - lr: 0.0010 - 42s/epoch - 212ms/step
Epoch 62/1000
2023-09-17 20:39:48.525 
Epoch 62/1000 
	 loss: 4.1563, MinusLogProbMetric: 4.1563, val_loss: 4.3379, val_MinusLogProbMetric: 4.3379

Epoch 62: val_loss did not improve from 4.16898
196/196 - 42s - loss: 4.1563 - MinusLogProbMetric: 4.1563 - val_loss: 4.3379 - val_MinusLogProbMetric: 4.3379 - lr: 0.0010 - 42s/epoch - 212ms/step
Epoch 63/1000
2023-09-17 20:40:30.202 
Epoch 63/1000 
	 loss: 4.1360, MinusLogProbMetric: 4.1360, val_loss: 4.1727, val_MinusLogProbMetric: 4.1727

Epoch 63: val_loss did not improve from 4.16898
196/196 - 42s - loss: 4.1360 - MinusLogProbMetric: 4.1360 - val_loss: 4.1727 - val_MinusLogProbMetric: 4.1727 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 64/1000
2023-09-17 20:41:11.958 
Epoch 64/1000 
	 loss: 4.1619, MinusLogProbMetric: 4.1619, val_loss: 4.1792, val_MinusLogProbMetric: 4.1792

Epoch 64: val_loss did not improve from 4.16898
196/196 - 42s - loss: 4.1619 - MinusLogProbMetric: 4.1619 - val_loss: 4.1792 - val_MinusLogProbMetric: 4.1792 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 65/1000
2023-09-17 20:41:53.477 
Epoch 65/1000 
	 loss: 4.1370, MinusLogProbMetric: 4.1370, val_loss: 4.2851, val_MinusLogProbMetric: 4.2851

Epoch 65: val_loss did not improve from 4.16898
196/196 - 42s - loss: 4.1370 - MinusLogProbMetric: 4.1370 - val_loss: 4.2851 - val_MinusLogProbMetric: 4.2851 - lr: 0.0010 - 42s/epoch - 212ms/step
Epoch 66/1000
2023-09-17 20:42:35.090 
Epoch 66/1000 
	 loss: 4.1405, MinusLogProbMetric: 4.1405, val_loss: 4.2148, val_MinusLogProbMetric: 4.2148

Epoch 66: val_loss did not improve from 4.16898
196/196 - 42s - loss: 4.1405 - MinusLogProbMetric: 4.1405 - val_loss: 4.2148 - val_MinusLogProbMetric: 4.2148 - lr: 0.0010 - 42s/epoch - 212ms/step
Epoch 67/1000
2023-09-17 20:43:17.221 
Epoch 67/1000 
	 loss: 4.1525, MinusLogProbMetric: 4.1525, val_loss: 4.2645, val_MinusLogProbMetric: 4.2645

Epoch 67: val_loss did not improve from 4.16898
196/196 - 42s - loss: 4.1525 - MinusLogProbMetric: 4.1525 - val_loss: 4.2645 - val_MinusLogProbMetric: 4.2645 - lr: 0.0010 - 42s/epoch - 215ms/step
Epoch 68/1000
2023-09-17 20:43:58.581 
Epoch 68/1000 
	 loss: 4.1363, MinusLogProbMetric: 4.1363, val_loss: 4.2002, val_MinusLogProbMetric: 4.2002

Epoch 68: val_loss did not improve from 4.16898
196/196 - 41s - loss: 4.1363 - MinusLogProbMetric: 4.1363 - val_loss: 4.2002 - val_MinusLogProbMetric: 4.2002 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 69/1000
2023-09-17 20:44:40.022 
Epoch 69/1000 
	 loss: 4.1397, MinusLogProbMetric: 4.1397, val_loss: 4.1921, val_MinusLogProbMetric: 4.1921

Epoch 69: val_loss did not improve from 4.16898
196/196 - 41s - loss: 4.1397 - MinusLogProbMetric: 4.1397 - val_loss: 4.1921 - val_MinusLogProbMetric: 4.1921 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 70/1000
2023-09-17 20:45:21.235 
Epoch 70/1000 
	 loss: 4.1319, MinusLogProbMetric: 4.1319, val_loss: 4.1992, val_MinusLogProbMetric: 4.1992

Epoch 70: val_loss did not improve from 4.16898
196/196 - 41s - loss: 4.1319 - MinusLogProbMetric: 4.1319 - val_loss: 4.1992 - val_MinusLogProbMetric: 4.1992 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 71/1000
2023-09-17 20:46:02.485 
Epoch 71/1000 
	 loss: 4.1279, MinusLogProbMetric: 4.1279, val_loss: 4.1923, val_MinusLogProbMetric: 4.1923

Epoch 71: val_loss did not improve from 4.16898
196/196 - 41s - loss: 4.1279 - MinusLogProbMetric: 4.1279 - val_loss: 4.1923 - val_MinusLogProbMetric: 4.1923 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 72/1000
2023-09-17 20:46:43.655 
Epoch 72/1000 
	 loss: 4.1335, MinusLogProbMetric: 4.1335, val_loss: 4.1876, val_MinusLogProbMetric: 4.1876

Epoch 72: val_loss did not improve from 4.16898
196/196 - 41s - loss: 4.1335 - MinusLogProbMetric: 4.1335 - val_loss: 4.1876 - val_MinusLogProbMetric: 4.1876 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 73/1000
2023-09-17 20:47:25.195 
Epoch 73/1000 
	 loss: 4.1262, MinusLogProbMetric: 4.1262, val_loss: 4.2881, val_MinusLogProbMetric: 4.2881

Epoch 73: val_loss did not improve from 4.16898
196/196 - 42s - loss: 4.1262 - MinusLogProbMetric: 4.1262 - val_loss: 4.2881 - val_MinusLogProbMetric: 4.2881 - lr: 0.0010 - 42s/epoch - 212ms/step
Epoch 74/1000
2023-09-17 20:48:07.086 
Epoch 74/1000 
	 loss: 4.1344, MinusLogProbMetric: 4.1344, val_loss: 4.2756, val_MinusLogProbMetric: 4.2756

Epoch 74: val_loss did not improve from 4.16898
196/196 - 42s - loss: 4.1344 - MinusLogProbMetric: 4.1344 - val_loss: 4.2756 - val_MinusLogProbMetric: 4.2756 - lr: 0.0010 - 42s/epoch - 214ms/step
Epoch 75/1000
2023-09-17 20:48:48.363 
Epoch 75/1000 
	 loss: 4.1401, MinusLogProbMetric: 4.1401, val_loss: 4.1804, val_MinusLogProbMetric: 4.1804

Epoch 75: val_loss did not improve from 4.16898
196/196 - 41s - loss: 4.1401 - MinusLogProbMetric: 4.1401 - val_loss: 4.1804 - val_MinusLogProbMetric: 4.1804 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 76/1000
2023-09-17 20:49:29.876 
Epoch 76/1000 
	 loss: 4.1239, MinusLogProbMetric: 4.1239, val_loss: 4.2076, val_MinusLogProbMetric: 4.2076

Epoch 76: val_loss did not improve from 4.16898
196/196 - 42s - loss: 4.1239 - MinusLogProbMetric: 4.1239 - val_loss: 4.2076 - val_MinusLogProbMetric: 4.2076 - lr: 0.0010 - 42s/epoch - 212ms/step
Epoch 77/1000
2023-09-17 20:50:11.184 
Epoch 77/1000 
	 loss: 4.1325, MinusLogProbMetric: 4.1325, val_loss: 4.2811, val_MinusLogProbMetric: 4.2811

Epoch 77: val_loss did not improve from 4.16898
196/196 - 41s - loss: 4.1325 - MinusLogProbMetric: 4.1325 - val_loss: 4.2811 - val_MinusLogProbMetric: 4.2811 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 78/1000
2023-09-17 20:50:52.864 
Epoch 78/1000 
	 loss: 4.1275, MinusLogProbMetric: 4.1275, val_loss: 4.2893, val_MinusLogProbMetric: 4.2893

Epoch 78: val_loss did not improve from 4.16898
196/196 - 42s - loss: 4.1275 - MinusLogProbMetric: 4.1275 - val_loss: 4.2893 - val_MinusLogProbMetric: 4.2893 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 79/1000
2023-09-17 20:51:33.856 
Epoch 79/1000 
	 loss: 4.1378, MinusLogProbMetric: 4.1378, val_loss: 4.1656, val_MinusLogProbMetric: 4.1656

Epoch 79: val_loss improved from 4.16898 to 4.16558, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_148/weights/best_weights.h5
196/196 - 42s - loss: 4.1378 - MinusLogProbMetric: 4.1378 - val_loss: 4.1656 - val_MinusLogProbMetric: 4.1656 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 80/1000
2023-09-17 20:52:16.975 
Epoch 80/1000 
	 loss: 4.1176, MinusLogProbMetric: 4.1176, val_loss: 4.2093, val_MinusLogProbMetric: 4.2093

Epoch 80: val_loss did not improve from 4.16558
196/196 - 42s - loss: 4.1176 - MinusLogProbMetric: 4.1176 - val_loss: 4.2093 - val_MinusLogProbMetric: 4.2093 - lr: 0.0010 - 42s/epoch - 216ms/step
Epoch 81/1000
2023-09-17 20:52:58.557 
Epoch 81/1000 
	 loss: 4.1139, MinusLogProbMetric: 4.1139, val_loss: 4.1857, val_MinusLogProbMetric: 4.1857

Epoch 81: val_loss did not improve from 4.16558
196/196 - 42s - loss: 4.1139 - MinusLogProbMetric: 4.1139 - val_loss: 4.1857 - val_MinusLogProbMetric: 4.1857 - lr: 0.0010 - 42s/epoch - 212ms/step
Epoch 82/1000
2023-09-17 20:53:40.224 
Epoch 82/1000 
	 loss: 4.1151, MinusLogProbMetric: 4.1151, val_loss: 4.1891, val_MinusLogProbMetric: 4.1891

Epoch 82: val_loss did not improve from 4.16558
196/196 - 42s - loss: 4.1151 - MinusLogProbMetric: 4.1151 - val_loss: 4.1891 - val_MinusLogProbMetric: 4.1891 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 83/1000
2023-09-17 20:54:20.955 
Epoch 83/1000 
	 loss: 4.1149, MinusLogProbMetric: 4.1149, val_loss: 4.1643, val_MinusLogProbMetric: 4.1643

Epoch 83: val_loss improved from 4.16558 to 4.16428, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_148/weights/best_weights.h5
196/196 - 41s - loss: 4.1149 - MinusLogProbMetric: 4.1149 - val_loss: 4.1643 - val_MinusLogProbMetric: 4.1643 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 84/1000
2023-09-17 20:55:02.896 
Epoch 84/1000 
	 loss: 4.1381, MinusLogProbMetric: 4.1381, val_loss: 4.1907, val_MinusLogProbMetric: 4.1907

Epoch 84: val_loss did not improve from 4.16428
196/196 - 41s - loss: 4.1381 - MinusLogProbMetric: 4.1381 - val_loss: 4.1907 - val_MinusLogProbMetric: 4.1907 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 85/1000
2023-09-17 20:55:44.213 
Epoch 85/1000 
	 loss: 4.1199, MinusLogProbMetric: 4.1199, val_loss: 4.2018, val_MinusLogProbMetric: 4.2018

Epoch 85: val_loss did not improve from 4.16428
196/196 - 41s - loss: 4.1199 - MinusLogProbMetric: 4.1199 - val_loss: 4.2018 - val_MinusLogProbMetric: 4.2018 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 86/1000
2023-09-17 20:56:25.912 
Epoch 86/1000 
	 loss: 4.1191, MinusLogProbMetric: 4.1191, val_loss: 4.2139, val_MinusLogProbMetric: 4.2139

Epoch 86: val_loss did not improve from 4.16428
196/196 - 42s - loss: 4.1191 - MinusLogProbMetric: 4.1191 - val_loss: 4.2139 - val_MinusLogProbMetric: 4.2139 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 87/1000
2023-09-17 20:57:07.298 
Epoch 87/1000 
	 loss: 4.1123, MinusLogProbMetric: 4.1123, val_loss: 4.2178, val_MinusLogProbMetric: 4.2178

Epoch 87: val_loss did not improve from 4.16428
196/196 - 41s - loss: 4.1123 - MinusLogProbMetric: 4.1123 - val_loss: 4.2178 - val_MinusLogProbMetric: 4.2178 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 88/1000
2023-09-17 20:57:48.993 
Epoch 88/1000 
	 loss: 4.1398, MinusLogProbMetric: 4.1398, val_loss: 4.2390, val_MinusLogProbMetric: 4.2390

Epoch 88: val_loss did not improve from 4.16428
196/196 - 42s - loss: 4.1398 - MinusLogProbMetric: 4.1398 - val_loss: 4.2390 - val_MinusLogProbMetric: 4.2390 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 89/1000
2023-09-17 20:58:31.229 
Epoch 89/1000 
	 loss: 4.1055, MinusLogProbMetric: 4.1055, val_loss: 4.2222, val_MinusLogProbMetric: 4.2222

Epoch 89: val_loss did not improve from 4.16428
196/196 - 42s - loss: 4.1055 - MinusLogProbMetric: 4.1055 - val_loss: 4.2222 - val_MinusLogProbMetric: 4.2222 - lr: 0.0010 - 42s/epoch - 215ms/step
Epoch 90/1000
2023-09-17 20:59:12.206 
Epoch 90/1000 
	 loss: 4.1189, MinusLogProbMetric: 4.1189, val_loss: 4.3115, val_MinusLogProbMetric: 4.3115

Epoch 90: val_loss did not improve from 4.16428
196/196 - 41s - loss: 4.1189 - MinusLogProbMetric: 4.1189 - val_loss: 4.3115 - val_MinusLogProbMetric: 4.3115 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 91/1000
2023-09-17 20:59:53.227 
Epoch 91/1000 
	 loss: 4.1121, MinusLogProbMetric: 4.1121, val_loss: 4.1787, val_MinusLogProbMetric: 4.1787

Epoch 91: val_loss did not improve from 4.16428
196/196 - 41s - loss: 4.1121 - MinusLogProbMetric: 4.1121 - val_loss: 4.1787 - val_MinusLogProbMetric: 4.1787 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 92/1000
2023-09-17 21:00:34.346 
Epoch 92/1000 
	 loss: 4.1049, MinusLogProbMetric: 4.1049, val_loss: 4.1793, val_MinusLogProbMetric: 4.1793

Epoch 92: val_loss did not improve from 4.16428
196/196 - 41s - loss: 4.1049 - MinusLogProbMetric: 4.1049 - val_loss: 4.1793 - val_MinusLogProbMetric: 4.1793 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 93/1000
2023-09-17 21:01:15.935 
Epoch 93/1000 
	 loss: 4.1098, MinusLogProbMetric: 4.1098, val_loss: 4.1771, val_MinusLogProbMetric: 4.1771

Epoch 93: val_loss did not improve from 4.16428
196/196 - 42s - loss: 4.1098 - MinusLogProbMetric: 4.1098 - val_loss: 4.1771 - val_MinusLogProbMetric: 4.1771 - lr: 0.0010 - 42s/epoch - 212ms/step
Epoch 94/1000
2023-09-17 21:01:56.994 
Epoch 94/1000 
	 loss: 4.1110, MinusLogProbMetric: 4.1110, val_loss: 4.1929, val_MinusLogProbMetric: 4.1929

Epoch 94: val_loss did not improve from 4.16428
196/196 - 41s - loss: 4.1110 - MinusLogProbMetric: 4.1110 - val_loss: 4.1929 - val_MinusLogProbMetric: 4.1929 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 95/1000
2023-09-17 21:02:38.975 
Epoch 95/1000 
	 loss: 4.1055, MinusLogProbMetric: 4.1055, val_loss: 4.2028, val_MinusLogProbMetric: 4.2028

Epoch 95: val_loss did not improve from 4.16428
196/196 - 42s - loss: 4.1055 - MinusLogProbMetric: 4.1055 - val_loss: 4.2028 - val_MinusLogProbMetric: 4.2028 - lr: 0.0010 - 42s/epoch - 214ms/step
Epoch 96/1000
2023-09-17 21:03:20.452 
Epoch 96/1000 
	 loss: 4.0912, MinusLogProbMetric: 4.0912, val_loss: 4.2330, val_MinusLogProbMetric: 4.2330

Epoch 96: val_loss did not improve from 4.16428
196/196 - 41s - loss: 4.0912 - MinusLogProbMetric: 4.0912 - val_loss: 4.2330 - val_MinusLogProbMetric: 4.2330 - lr: 0.0010 - 41s/epoch - 212ms/step
Epoch 97/1000
2023-09-17 21:04:02.194 
Epoch 97/1000 
	 loss: 4.1009, MinusLogProbMetric: 4.1009, val_loss: 4.1697, val_MinusLogProbMetric: 4.1697

Epoch 97: val_loss did not improve from 4.16428
196/196 - 42s - loss: 4.1009 - MinusLogProbMetric: 4.1009 - val_loss: 4.1697 - val_MinusLogProbMetric: 4.1697 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 98/1000
2023-09-17 21:04:43.542 
Epoch 98/1000 
	 loss: 4.1139, MinusLogProbMetric: 4.1139, val_loss: 4.2119, val_MinusLogProbMetric: 4.2119

Epoch 98: val_loss did not improve from 4.16428
196/196 - 41s - loss: 4.1139 - MinusLogProbMetric: 4.1139 - val_loss: 4.2119 - val_MinusLogProbMetric: 4.2119 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 99/1000
2023-09-17 21:05:24.757 
Epoch 99/1000 
	 loss: 4.1027, MinusLogProbMetric: 4.1027, val_loss: 4.1953, val_MinusLogProbMetric: 4.1953

Epoch 99: val_loss did not improve from 4.16428
196/196 - 41s - loss: 4.1027 - MinusLogProbMetric: 4.1027 - val_loss: 4.1953 - val_MinusLogProbMetric: 4.1953 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 100/1000
2023-09-17 21:06:05.847 
Epoch 100/1000 
	 loss: 4.0918, MinusLogProbMetric: 4.0918, val_loss: 4.2151, val_MinusLogProbMetric: 4.2151

Epoch 100: val_loss did not improve from 4.16428
196/196 - 41s - loss: 4.0918 - MinusLogProbMetric: 4.0918 - val_loss: 4.2151 - val_MinusLogProbMetric: 4.2151 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 101/1000
2023-09-17 21:06:47.207 
Epoch 101/1000 
	 loss: 4.0905, MinusLogProbMetric: 4.0905, val_loss: 4.2108, val_MinusLogProbMetric: 4.2108

Epoch 101: val_loss did not improve from 4.16428
196/196 - 41s - loss: 4.0905 - MinusLogProbMetric: 4.0905 - val_loss: 4.2108 - val_MinusLogProbMetric: 4.2108 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 102/1000
2023-09-17 21:07:27.888 
Epoch 102/1000 
	 loss: 4.1059, MinusLogProbMetric: 4.1059, val_loss: 4.1651, val_MinusLogProbMetric: 4.1651

Epoch 102: val_loss did not improve from 4.16428
196/196 - 41s - loss: 4.1059 - MinusLogProbMetric: 4.1059 - val_loss: 4.1651 - val_MinusLogProbMetric: 4.1651 - lr: 0.0010 - 41s/epoch - 208ms/step
Epoch 103/1000
2023-09-17 21:08:08.893 
Epoch 103/1000 
	 loss: 4.1023, MinusLogProbMetric: 4.1023, val_loss: 4.2989, val_MinusLogProbMetric: 4.2989

Epoch 103: val_loss did not improve from 4.16428
196/196 - 41s - loss: 4.1023 - MinusLogProbMetric: 4.1023 - val_loss: 4.2989 - val_MinusLogProbMetric: 4.2989 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 104/1000
2023-09-17 21:08:50.694 
Epoch 104/1000 
	 loss: 4.0919, MinusLogProbMetric: 4.0919, val_loss: 4.2023, val_MinusLogProbMetric: 4.2023

Epoch 104: val_loss did not improve from 4.16428
196/196 - 42s - loss: 4.0919 - MinusLogProbMetric: 4.0919 - val_loss: 4.2023 - val_MinusLogProbMetric: 4.2023 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 105/1000
2023-09-17 21:09:31.509 
Epoch 105/1000 
	 loss: 4.1040, MinusLogProbMetric: 4.1040, val_loss: 4.1548, val_MinusLogProbMetric: 4.1548

Epoch 105: val_loss improved from 4.16428 to 4.15480, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_148/weights/best_weights.h5
196/196 - 42s - loss: 4.1040 - MinusLogProbMetric: 4.1040 - val_loss: 4.1548 - val_MinusLogProbMetric: 4.1548 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 106/1000
2023-09-17 21:10:13.466 
Epoch 106/1000 
	 loss: 4.0874, MinusLogProbMetric: 4.0874, val_loss: 4.1896, val_MinusLogProbMetric: 4.1896

Epoch 106: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0874 - MinusLogProbMetric: 4.0874 - val_loss: 4.1896 - val_MinusLogProbMetric: 4.1896 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 107/1000
2023-09-17 21:10:54.550 
Epoch 107/1000 
	 loss: 4.0899, MinusLogProbMetric: 4.0899, val_loss: 4.1950, val_MinusLogProbMetric: 4.1950

Epoch 107: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0899 - MinusLogProbMetric: 4.0899 - val_loss: 4.1950 - val_MinusLogProbMetric: 4.1950 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 108/1000
2023-09-17 21:11:35.426 
Epoch 108/1000 
	 loss: 4.0818, MinusLogProbMetric: 4.0818, val_loss: 4.2779, val_MinusLogProbMetric: 4.2779

Epoch 108: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0818 - MinusLogProbMetric: 4.0818 - val_loss: 4.2779 - val_MinusLogProbMetric: 4.2779 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 109/1000
2023-09-17 21:12:16.587 
Epoch 109/1000 
	 loss: 4.1057, MinusLogProbMetric: 4.1057, val_loss: 4.2642, val_MinusLogProbMetric: 4.2642

Epoch 109: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.1057 - MinusLogProbMetric: 4.1057 - val_loss: 4.2642 - val_MinusLogProbMetric: 4.2642 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 110/1000
2023-09-17 21:12:57.502 
Epoch 110/1000 
	 loss: 4.0931, MinusLogProbMetric: 4.0931, val_loss: 4.1603, val_MinusLogProbMetric: 4.1603

Epoch 110: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0931 - MinusLogProbMetric: 4.0931 - val_loss: 4.1603 - val_MinusLogProbMetric: 4.1603 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 111/1000
2023-09-17 21:13:38.875 
Epoch 111/1000 
	 loss: 4.0812, MinusLogProbMetric: 4.0812, val_loss: 4.1923, val_MinusLogProbMetric: 4.1923

Epoch 111: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0812 - MinusLogProbMetric: 4.0812 - val_loss: 4.1923 - val_MinusLogProbMetric: 4.1923 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 112/1000
2023-09-17 21:14:20.366 
Epoch 112/1000 
	 loss: 4.0845, MinusLogProbMetric: 4.0845, val_loss: 4.2013, val_MinusLogProbMetric: 4.2013

Epoch 112: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0845 - MinusLogProbMetric: 4.0845 - val_loss: 4.2013 - val_MinusLogProbMetric: 4.2013 - lr: 0.0010 - 41s/epoch - 212ms/step
Epoch 113/1000
2023-09-17 21:15:02.223 
Epoch 113/1000 
	 loss: 4.0850, MinusLogProbMetric: 4.0850, val_loss: 4.1709, val_MinusLogProbMetric: 4.1709

Epoch 113: val_loss did not improve from 4.15480
196/196 - 42s - loss: 4.0850 - MinusLogProbMetric: 4.0850 - val_loss: 4.1709 - val_MinusLogProbMetric: 4.1709 - lr: 0.0010 - 42s/epoch - 214ms/step
Epoch 114/1000
2023-09-17 21:15:40.817 
Epoch 114/1000 
	 loss: 4.0823, MinusLogProbMetric: 4.0823, val_loss: 4.2546, val_MinusLogProbMetric: 4.2546

Epoch 114: val_loss did not improve from 4.15480
196/196 - 39s - loss: 4.0823 - MinusLogProbMetric: 4.0823 - val_loss: 4.2546 - val_MinusLogProbMetric: 4.2546 - lr: 0.0010 - 39s/epoch - 197ms/step
Epoch 115/1000
2023-09-17 21:16:17.612 
Epoch 115/1000 
	 loss: 4.0868, MinusLogProbMetric: 4.0868, val_loss: 4.2976, val_MinusLogProbMetric: 4.2976

Epoch 115: val_loss did not improve from 4.15480
196/196 - 37s - loss: 4.0868 - MinusLogProbMetric: 4.0868 - val_loss: 4.2976 - val_MinusLogProbMetric: 4.2976 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 116/1000
2023-09-17 21:16:53.123 
Epoch 116/1000 
	 loss: 4.0754, MinusLogProbMetric: 4.0754, val_loss: 4.2874, val_MinusLogProbMetric: 4.2874

Epoch 116: val_loss did not improve from 4.15480
196/196 - 36s - loss: 4.0754 - MinusLogProbMetric: 4.0754 - val_loss: 4.2874 - val_MinusLogProbMetric: 4.2874 - lr: 0.0010 - 36s/epoch - 181ms/step
Epoch 117/1000
2023-09-17 21:17:26.755 
Epoch 117/1000 
	 loss: 4.0814, MinusLogProbMetric: 4.0814, val_loss: 4.1703, val_MinusLogProbMetric: 4.1703

Epoch 117: val_loss did not improve from 4.15480
196/196 - 34s - loss: 4.0814 - MinusLogProbMetric: 4.0814 - val_loss: 4.1703 - val_MinusLogProbMetric: 4.1703 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 118/1000
2023-09-17 21:18:01.329 
Epoch 118/1000 
	 loss: 4.0931, MinusLogProbMetric: 4.0931, val_loss: 4.2445, val_MinusLogProbMetric: 4.2445

Epoch 118: val_loss did not improve from 4.15480
196/196 - 35s - loss: 4.0931 - MinusLogProbMetric: 4.0931 - val_loss: 4.2445 - val_MinusLogProbMetric: 4.2445 - lr: 0.0010 - 35s/epoch - 176ms/step
Epoch 119/1000
2023-09-17 21:18:36.248 
Epoch 119/1000 
	 loss: 4.0706, MinusLogProbMetric: 4.0706, val_loss: 4.2249, val_MinusLogProbMetric: 4.2249

Epoch 119: val_loss did not improve from 4.15480
196/196 - 35s - loss: 4.0706 - MinusLogProbMetric: 4.0706 - val_loss: 4.2249 - val_MinusLogProbMetric: 4.2249 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 120/1000
2023-09-17 21:19:16.348 
Epoch 120/1000 
	 loss: 4.0777, MinusLogProbMetric: 4.0777, val_loss: 4.2826, val_MinusLogProbMetric: 4.2826

Epoch 120: val_loss did not improve from 4.15480
196/196 - 40s - loss: 4.0777 - MinusLogProbMetric: 4.0777 - val_loss: 4.2826 - val_MinusLogProbMetric: 4.2826 - lr: 0.0010 - 40s/epoch - 205ms/step
Epoch 121/1000
2023-09-17 21:19:57.560 
Epoch 121/1000 
	 loss: 4.0796, MinusLogProbMetric: 4.0796, val_loss: 4.2182, val_MinusLogProbMetric: 4.2182

Epoch 121: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0796 - MinusLogProbMetric: 4.0796 - val_loss: 4.2182 - val_MinusLogProbMetric: 4.2182 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 122/1000
2023-09-17 21:20:38.340 
Epoch 122/1000 
	 loss: 4.0789, MinusLogProbMetric: 4.0789, val_loss: 4.1649, val_MinusLogProbMetric: 4.1649

Epoch 122: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0789 - MinusLogProbMetric: 4.0789 - val_loss: 4.1649 - val_MinusLogProbMetric: 4.1649 - lr: 0.0010 - 41s/epoch - 208ms/step
Epoch 123/1000
2023-09-17 21:21:19.876 
Epoch 123/1000 
	 loss: 4.0869, MinusLogProbMetric: 4.0869, val_loss: 4.1713, val_MinusLogProbMetric: 4.1713

Epoch 123: val_loss did not improve from 4.15480
196/196 - 42s - loss: 4.0869 - MinusLogProbMetric: 4.0869 - val_loss: 4.1713 - val_MinusLogProbMetric: 4.1713 - lr: 0.0010 - 42s/epoch - 212ms/step
Epoch 124/1000
2023-09-17 21:22:01.829 
Epoch 124/1000 
	 loss: 4.0782, MinusLogProbMetric: 4.0782, val_loss: 4.1970, val_MinusLogProbMetric: 4.1970

Epoch 124: val_loss did not improve from 4.15480
196/196 - 42s - loss: 4.0782 - MinusLogProbMetric: 4.0782 - val_loss: 4.1970 - val_MinusLogProbMetric: 4.1970 - lr: 0.0010 - 42s/epoch - 214ms/step
Epoch 125/1000
2023-09-17 21:22:42.950 
Epoch 125/1000 
	 loss: 4.0740, MinusLogProbMetric: 4.0740, val_loss: 4.2601, val_MinusLogProbMetric: 4.2601

Epoch 125: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0740 - MinusLogProbMetric: 4.0740 - val_loss: 4.2601 - val_MinusLogProbMetric: 4.2601 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 126/1000
2023-09-17 21:23:23.882 
Epoch 126/1000 
	 loss: 4.0760, MinusLogProbMetric: 4.0760, val_loss: 4.3833, val_MinusLogProbMetric: 4.3833

Epoch 126: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0760 - MinusLogProbMetric: 4.0760 - val_loss: 4.3833 - val_MinusLogProbMetric: 4.3833 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 127/1000
2023-09-17 21:24:04.894 
Epoch 127/1000 
	 loss: 4.0679, MinusLogProbMetric: 4.0679, val_loss: 4.2173, val_MinusLogProbMetric: 4.2173

Epoch 127: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0679 - MinusLogProbMetric: 4.0679 - val_loss: 4.2173 - val_MinusLogProbMetric: 4.2173 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 128/1000
2023-09-17 21:24:46.093 
Epoch 128/1000 
	 loss: 4.0746, MinusLogProbMetric: 4.0746, val_loss: 4.1562, val_MinusLogProbMetric: 4.1562

Epoch 128: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0746 - MinusLogProbMetric: 4.0746 - val_loss: 4.1562 - val_MinusLogProbMetric: 4.1562 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 129/1000
2023-09-17 21:25:27.963 
Epoch 129/1000 
	 loss: 4.0711, MinusLogProbMetric: 4.0711, val_loss: 4.2114, val_MinusLogProbMetric: 4.2114

Epoch 129: val_loss did not improve from 4.15480
196/196 - 42s - loss: 4.0711 - MinusLogProbMetric: 4.0711 - val_loss: 4.2114 - val_MinusLogProbMetric: 4.2114 - lr: 0.0010 - 42s/epoch - 214ms/step
Epoch 130/1000
2023-09-17 21:26:09.470 
Epoch 130/1000 
	 loss: 4.0643, MinusLogProbMetric: 4.0643, val_loss: 4.3178, val_MinusLogProbMetric: 4.3178

Epoch 130: val_loss did not improve from 4.15480
196/196 - 42s - loss: 4.0643 - MinusLogProbMetric: 4.0643 - val_loss: 4.3178 - val_MinusLogProbMetric: 4.3178 - lr: 0.0010 - 42s/epoch - 212ms/step
Epoch 131/1000
2023-09-17 21:26:51.357 
Epoch 131/1000 
	 loss: 4.0741, MinusLogProbMetric: 4.0741, val_loss: 4.1798, val_MinusLogProbMetric: 4.1798

Epoch 131: val_loss did not improve from 4.15480
196/196 - 42s - loss: 4.0741 - MinusLogProbMetric: 4.0741 - val_loss: 4.1798 - val_MinusLogProbMetric: 4.1798 - lr: 0.0010 - 42s/epoch - 214ms/step
Epoch 132/1000
2023-09-17 21:27:33.068 
Epoch 132/1000 
	 loss: 4.0658, MinusLogProbMetric: 4.0658, val_loss: 4.1734, val_MinusLogProbMetric: 4.1734

Epoch 132: val_loss did not improve from 4.15480
196/196 - 42s - loss: 4.0658 - MinusLogProbMetric: 4.0658 - val_loss: 4.1734 - val_MinusLogProbMetric: 4.1734 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 133/1000
2023-09-17 21:28:14.781 
Epoch 133/1000 
	 loss: 4.0635, MinusLogProbMetric: 4.0635, val_loss: 4.1794, val_MinusLogProbMetric: 4.1794

Epoch 133: val_loss did not improve from 4.15480
196/196 - 42s - loss: 4.0635 - MinusLogProbMetric: 4.0635 - val_loss: 4.1794 - val_MinusLogProbMetric: 4.1794 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 134/1000
2023-09-17 21:28:56.370 
Epoch 134/1000 
	 loss: 4.0586, MinusLogProbMetric: 4.0586, val_loss: 4.2163, val_MinusLogProbMetric: 4.2163

Epoch 134: val_loss did not improve from 4.15480
196/196 - 42s - loss: 4.0586 - MinusLogProbMetric: 4.0586 - val_loss: 4.2163 - val_MinusLogProbMetric: 4.2163 - lr: 0.0010 - 42s/epoch - 212ms/step
Epoch 135/1000
2023-09-17 21:29:37.660 
Epoch 135/1000 
	 loss: 4.0554, MinusLogProbMetric: 4.0554, val_loss: 4.1736, val_MinusLogProbMetric: 4.1736

Epoch 135: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0554 - MinusLogProbMetric: 4.0554 - val_loss: 4.1736 - val_MinusLogProbMetric: 4.1736 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 136/1000
2023-09-17 21:30:19.156 
Epoch 136/1000 
	 loss: 4.0576, MinusLogProbMetric: 4.0576, val_loss: 4.1838, val_MinusLogProbMetric: 4.1838

Epoch 136: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0576 - MinusLogProbMetric: 4.0576 - val_loss: 4.1838 - val_MinusLogProbMetric: 4.1838 - lr: 0.0010 - 41s/epoch - 212ms/step
Epoch 137/1000
2023-09-17 21:31:00.460 
Epoch 137/1000 
	 loss: 4.0570, MinusLogProbMetric: 4.0570, val_loss: 4.1730, val_MinusLogProbMetric: 4.1730

Epoch 137: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0570 - MinusLogProbMetric: 4.0570 - val_loss: 4.1730 - val_MinusLogProbMetric: 4.1730 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 138/1000
2023-09-17 21:31:41.684 
Epoch 138/1000 
	 loss: 4.0792, MinusLogProbMetric: 4.0792, val_loss: 4.1742, val_MinusLogProbMetric: 4.1742

Epoch 138: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0792 - MinusLogProbMetric: 4.0792 - val_loss: 4.1742 - val_MinusLogProbMetric: 4.1742 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 139/1000
2023-09-17 21:32:22.824 
Epoch 139/1000 
	 loss: 4.0548, MinusLogProbMetric: 4.0548, val_loss: 4.2842, val_MinusLogProbMetric: 4.2842

Epoch 139: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0548 - MinusLogProbMetric: 4.0548 - val_loss: 4.2842 - val_MinusLogProbMetric: 4.2842 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 140/1000
2023-09-17 21:33:03.593 
Epoch 140/1000 
	 loss: 4.0563, MinusLogProbMetric: 4.0563, val_loss: 4.3041, val_MinusLogProbMetric: 4.3041

Epoch 140: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0563 - MinusLogProbMetric: 4.0563 - val_loss: 4.3041 - val_MinusLogProbMetric: 4.3041 - lr: 0.0010 - 41s/epoch - 208ms/step
Epoch 141/1000
2023-09-17 21:33:43.730 
Epoch 141/1000 
	 loss: 4.0602, MinusLogProbMetric: 4.0602, val_loss: 4.2026, val_MinusLogProbMetric: 4.2026

Epoch 141: val_loss did not improve from 4.15480
196/196 - 40s - loss: 4.0602 - MinusLogProbMetric: 4.0602 - val_loss: 4.2026 - val_MinusLogProbMetric: 4.2026 - lr: 0.0010 - 40s/epoch - 205ms/step
Epoch 142/1000
2023-09-17 21:34:23.360 
Epoch 142/1000 
	 loss: 4.0652, MinusLogProbMetric: 4.0652, val_loss: 4.1917, val_MinusLogProbMetric: 4.1917

Epoch 142: val_loss did not improve from 4.15480
196/196 - 40s - loss: 4.0652 - MinusLogProbMetric: 4.0652 - val_loss: 4.1917 - val_MinusLogProbMetric: 4.1917 - lr: 0.0010 - 40s/epoch - 202ms/step
Epoch 143/1000
2023-09-17 21:34:59.953 
Epoch 143/1000 
	 loss: 4.0728, MinusLogProbMetric: 4.0728, val_loss: 4.2358, val_MinusLogProbMetric: 4.2358

Epoch 143: val_loss did not improve from 4.15480
196/196 - 37s - loss: 4.0728 - MinusLogProbMetric: 4.0728 - val_loss: 4.2358 - val_MinusLogProbMetric: 4.2358 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 144/1000
2023-09-17 21:35:36.725 
Epoch 144/1000 
	 loss: 4.0538, MinusLogProbMetric: 4.0538, val_loss: 4.2095, val_MinusLogProbMetric: 4.2095

Epoch 144: val_loss did not improve from 4.15480
196/196 - 37s - loss: 4.0538 - MinusLogProbMetric: 4.0538 - val_loss: 4.2095 - val_MinusLogProbMetric: 4.2095 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 145/1000
2023-09-17 21:36:17.861 
Epoch 145/1000 
	 loss: 4.0564, MinusLogProbMetric: 4.0564, val_loss: 4.1760, val_MinusLogProbMetric: 4.1760

Epoch 145: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0564 - MinusLogProbMetric: 4.0564 - val_loss: 4.1760 - val_MinusLogProbMetric: 4.1760 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 146/1000
2023-09-17 21:37:00.405 
Epoch 146/1000 
	 loss: 4.0449, MinusLogProbMetric: 4.0449, val_loss: 4.2396, val_MinusLogProbMetric: 4.2396

Epoch 146: val_loss did not improve from 4.15480
196/196 - 43s - loss: 4.0449 - MinusLogProbMetric: 4.0449 - val_loss: 4.2396 - val_MinusLogProbMetric: 4.2396 - lr: 0.0010 - 43s/epoch - 217ms/step
Epoch 147/1000
2023-09-17 21:37:42.216 
Epoch 147/1000 
	 loss: 4.0516, MinusLogProbMetric: 4.0516, val_loss: 4.2669, val_MinusLogProbMetric: 4.2669

Epoch 147: val_loss did not improve from 4.15480
196/196 - 42s - loss: 4.0516 - MinusLogProbMetric: 4.0516 - val_loss: 4.2669 - val_MinusLogProbMetric: 4.2669 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 148/1000
2023-09-17 21:38:24.295 
Epoch 148/1000 
	 loss: 4.0611, MinusLogProbMetric: 4.0611, val_loss: 4.2057, val_MinusLogProbMetric: 4.2057

Epoch 148: val_loss did not improve from 4.15480
196/196 - 42s - loss: 4.0611 - MinusLogProbMetric: 4.0611 - val_loss: 4.2057 - val_MinusLogProbMetric: 4.2057 - lr: 0.0010 - 42s/epoch - 215ms/step
Epoch 149/1000
2023-09-17 21:39:05.647 
Epoch 149/1000 
	 loss: 4.0519, MinusLogProbMetric: 4.0519, val_loss: 4.1681, val_MinusLogProbMetric: 4.1681

Epoch 149: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0519 - MinusLogProbMetric: 4.0519 - val_loss: 4.1681 - val_MinusLogProbMetric: 4.1681 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 150/1000
2023-09-17 21:39:46.966 
Epoch 150/1000 
	 loss: 4.0523, MinusLogProbMetric: 4.0523, val_loss: 4.1859, val_MinusLogProbMetric: 4.1859

Epoch 150: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0523 - MinusLogProbMetric: 4.0523 - val_loss: 4.1859 - val_MinusLogProbMetric: 4.1859 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 151/1000
2023-09-17 21:40:28.789 
Epoch 151/1000 
	 loss: 4.0458, MinusLogProbMetric: 4.0458, val_loss: 4.2830, val_MinusLogProbMetric: 4.2830

Epoch 151: val_loss did not improve from 4.15480
196/196 - 42s - loss: 4.0458 - MinusLogProbMetric: 4.0458 - val_loss: 4.2830 - val_MinusLogProbMetric: 4.2830 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 152/1000
2023-09-17 21:41:11.240 
Epoch 152/1000 
	 loss: 4.0470, MinusLogProbMetric: 4.0470, val_loss: 4.1983, val_MinusLogProbMetric: 4.1983

Epoch 152: val_loss did not improve from 4.15480
196/196 - 42s - loss: 4.0470 - MinusLogProbMetric: 4.0470 - val_loss: 4.1983 - val_MinusLogProbMetric: 4.1983 - lr: 0.0010 - 42s/epoch - 217ms/step
Epoch 153/1000
2023-09-17 21:41:52.253 
Epoch 153/1000 
	 loss: 4.0525, MinusLogProbMetric: 4.0525, val_loss: 4.2687, val_MinusLogProbMetric: 4.2687

Epoch 153: val_loss did not improve from 4.15480
196/196 - 41s - loss: 4.0525 - MinusLogProbMetric: 4.0525 - val_loss: 4.2687 - val_MinusLogProbMetric: 4.2687 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 154/1000
2023-09-17 21:42:33.764 
Epoch 154/1000 
	 loss: 4.0462, MinusLogProbMetric: 4.0462, val_loss: 4.1749, val_MinusLogProbMetric: 4.1749

Epoch 154: val_loss did not improve from 4.15480
196/196 - 42s - loss: 4.0462 - MinusLogProbMetric: 4.0462 - val_loss: 4.1749 - val_MinusLogProbMetric: 4.1749 - lr: 0.0010 - 42s/epoch - 212ms/step
Epoch 155/1000
2023-09-17 21:43:15.285 
Epoch 155/1000 
	 loss: 4.0504, MinusLogProbMetric: 4.0504, val_loss: 4.1896, val_MinusLogProbMetric: 4.1896

Epoch 155: val_loss did not improve from 4.15480
196/196 - 42s - loss: 4.0504 - MinusLogProbMetric: 4.0504 - val_loss: 4.1896 - val_MinusLogProbMetric: 4.1896 - lr: 0.0010 - 42s/epoch - 212ms/step
Epoch 156/1000
2023-09-17 21:43:56.781 
Epoch 156/1000 
	 loss: 3.9881, MinusLogProbMetric: 3.9881, val_loss: 4.1795, val_MinusLogProbMetric: 4.1795

Epoch 156: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9881 - MinusLogProbMetric: 3.9881 - val_loss: 4.1795 - val_MinusLogProbMetric: 4.1795 - lr: 5.0000e-04 - 41s/epoch - 212ms/step
Epoch 157/1000
2023-09-17 21:44:38.257 
Epoch 157/1000 
	 loss: 3.9863, MinusLogProbMetric: 3.9863, val_loss: 4.1721, val_MinusLogProbMetric: 4.1721

Epoch 157: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9863 - MinusLogProbMetric: 3.9863 - val_loss: 4.1721 - val_MinusLogProbMetric: 4.1721 - lr: 5.0000e-04 - 41s/epoch - 212ms/step
Epoch 158/1000
2023-09-17 21:45:19.364 
Epoch 158/1000 
	 loss: 3.9851, MinusLogProbMetric: 3.9851, val_loss: 4.1693, val_MinusLogProbMetric: 4.1693

Epoch 158: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9851 - MinusLogProbMetric: 3.9851 - val_loss: 4.1693 - val_MinusLogProbMetric: 4.1693 - lr: 5.0000e-04 - 41s/epoch - 210ms/step
Epoch 159/1000
2023-09-17 21:46:00.450 
Epoch 159/1000 
	 loss: 3.9910, MinusLogProbMetric: 3.9910, val_loss: 4.1683, val_MinusLogProbMetric: 4.1683

Epoch 159: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9910 - MinusLogProbMetric: 3.9910 - val_loss: 4.1683 - val_MinusLogProbMetric: 4.1683 - lr: 5.0000e-04 - 41s/epoch - 210ms/step
Epoch 160/1000
2023-09-17 21:46:42.090 
Epoch 160/1000 
	 loss: 3.9844, MinusLogProbMetric: 3.9844, val_loss: 4.2076, val_MinusLogProbMetric: 4.2076

Epoch 160: val_loss did not improve from 4.15480
196/196 - 42s - loss: 3.9844 - MinusLogProbMetric: 3.9844 - val_loss: 4.2076 - val_MinusLogProbMetric: 4.2076 - lr: 5.0000e-04 - 42s/epoch - 212ms/step
Epoch 161/1000
2023-09-17 21:47:24.167 
Epoch 161/1000 
	 loss: 3.9854, MinusLogProbMetric: 3.9854, val_loss: 4.1818, val_MinusLogProbMetric: 4.1818

Epoch 161: val_loss did not improve from 4.15480
196/196 - 42s - loss: 3.9854 - MinusLogProbMetric: 3.9854 - val_loss: 4.1818 - val_MinusLogProbMetric: 4.1818 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 162/1000
2023-09-17 21:48:05.495 
Epoch 162/1000 
	 loss: 3.9808, MinusLogProbMetric: 3.9808, val_loss: 4.2013, val_MinusLogProbMetric: 4.2013

Epoch 162: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9808 - MinusLogProbMetric: 3.9808 - val_loss: 4.2013 - val_MinusLogProbMetric: 4.2013 - lr: 5.0000e-04 - 41s/epoch - 211ms/step
Epoch 163/1000
2023-09-17 21:48:47.859 
Epoch 163/1000 
	 loss: 3.9817, MinusLogProbMetric: 3.9817, val_loss: 4.1679, val_MinusLogProbMetric: 4.1679

Epoch 163: val_loss did not improve from 4.15480
196/196 - 42s - loss: 3.9817 - MinusLogProbMetric: 3.9817 - val_loss: 4.1679 - val_MinusLogProbMetric: 4.1679 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 164/1000
2023-09-17 21:49:29.072 
Epoch 164/1000 
	 loss: 3.9820, MinusLogProbMetric: 3.9820, val_loss: 4.1748, val_MinusLogProbMetric: 4.1748

Epoch 164: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9820 - MinusLogProbMetric: 3.9820 - val_loss: 4.1748 - val_MinusLogProbMetric: 4.1748 - lr: 5.0000e-04 - 41s/epoch - 210ms/step
Epoch 165/1000
2023-09-17 21:50:10.554 
Epoch 165/1000 
	 loss: 3.9825, MinusLogProbMetric: 3.9825, val_loss: 4.1685, val_MinusLogProbMetric: 4.1685

Epoch 165: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9825 - MinusLogProbMetric: 3.9825 - val_loss: 4.1685 - val_MinusLogProbMetric: 4.1685 - lr: 5.0000e-04 - 41s/epoch - 212ms/step
Epoch 166/1000
2023-09-17 21:50:52.497 
Epoch 166/1000 
	 loss: 3.9815, MinusLogProbMetric: 3.9815, val_loss: 4.1728, val_MinusLogProbMetric: 4.1728

Epoch 166: val_loss did not improve from 4.15480
196/196 - 42s - loss: 3.9815 - MinusLogProbMetric: 3.9815 - val_loss: 4.1728 - val_MinusLogProbMetric: 4.1728 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 167/1000
2023-09-17 21:51:34.307 
Epoch 167/1000 
	 loss: 3.9810, MinusLogProbMetric: 3.9810, val_loss: 4.2015, val_MinusLogProbMetric: 4.2015

Epoch 167: val_loss did not improve from 4.15480
196/196 - 42s - loss: 3.9810 - MinusLogProbMetric: 3.9810 - val_loss: 4.2015 - val_MinusLogProbMetric: 4.2015 - lr: 5.0000e-04 - 42s/epoch - 213ms/step
Epoch 168/1000
2023-09-17 21:52:15.792 
Epoch 168/1000 
	 loss: 3.9802, MinusLogProbMetric: 3.9802, val_loss: 4.2287, val_MinusLogProbMetric: 4.2287

Epoch 168: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9802 - MinusLogProbMetric: 3.9802 - val_loss: 4.2287 - val_MinusLogProbMetric: 4.2287 - lr: 5.0000e-04 - 41s/epoch - 212ms/step
Epoch 169/1000
2023-09-17 21:52:57.032 
Epoch 169/1000 
	 loss: 3.9784, MinusLogProbMetric: 3.9784, val_loss: 4.1917, val_MinusLogProbMetric: 4.1917

Epoch 169: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9784 - MinusLogProbMetric: 3.9784 - val_loss: 4.1917 - val_MinusLogProbMetric: 4.1917 - lr: 5.0000e-04 - 41s/epoch - 210ms/step
Epoch 170/1000
2023-09-17 21:53:37.904 
Epoch 170/1000 
	 loss: 3.9754, MinusLogProbMetric: 3.9754, val_loss: 4.1774, val_MinusLogProbMetric: 4.1774

Epoch 170: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9754 - MinusLogProbMetric: 3.9754 - val_loss: 4.1774 - val_MinusLogProbMetric: 4.1774 - lr: 5.0000e-04 - 41s/epoch - 209ms/step
Epoch 171/1000
2023-09-17 21:54:18.676 
Epoch 171/1000 
	 loss: 3.9730, MinusLogProbMetric: 3.9730, val_loss: 4.1782, val_MinusLogProbMetric: 4.1782

Epoch 171: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9730 - MinusLogProbMetric: 3.9730 - val_loss: 4.1782 - val_MinusLogProbMetric: 4.1782 - lr: 5.0000e-04 - 41s/epoch - 208ms/step
Epoch 172/1000
2023-09-17 21:55:00.769 
Epoch 172/1000 
	 loss: 3.9733, MinusLogProbMetric: 3.9733, val_loss: 4.1787, val_MinusLogProbMetric: 4.1787

Epoch 172: val_loss did not improve from 4.15480
196/196 - 42s - loss: 3.9733 - MinusLogProbMetric: 3.9733 - val_loss: 4.1787 - val_MinusLogProbMetric: 4.1787 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 173/1000
2023-09-17 21:55:42.549 
Epoch 173/1000 
	 loss: 3.9744, MinusLogProbMetric: 3.9744, val_loss: 4.1986, val_MinusLogProbMetric: 4.1986

Epoch 173: val_loss did not improve from 4.15480
196/196 - 42s - loss: 3.9744 - MinusLogProbMetric: 3.9744 - val_loss: 4.1986 - val_MinusLogProbMetric: 4.1986 - lr: 5.0000e-04 - 42s/epoch - 213ms/step
Epoch 174/1000
2023-09-17 21:56:24.492 
Epoch 174/1000 
	 loss: 3.9756, MinusLogProbMetric: 3.9756, val_loss: 4.1994, val_MinusLogProbMetric: 4.1994

Epoch 174: val_loss did not improve from 4.15480
196/196 - 42s - loss: 3.9756 - MinusLogProbMetric: 3.9756 - val_loss: 4.1994 - val_MinusLogProbMetric: 4.1994 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 175/1000
2023-09-17 21:57:06.864 
Epoch 175/1000 
	 loss: 3.9766, MinusLogProbMetric: 3.9766, val_loss: 4.1959, val_MinusLogProbMetric: 4.1959

Epoch 175: val_loss did not improve from 4.15480
196/196 - 42s - loss: 3.9766 - MinusLogProbMetric: 3.9766 - val_loss: 4.1959 - val_MinusLogProbMetric: 4.1959 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 176/1000
2023-09-17 21:57:47.906 
Epoch 176/1000 
	 loss: 3.9798, MinusLogProbMetric: 3.9798, val_loss: 4.2041, val_MinusLogProbMetric: 4.2041

Epoch 176: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9798 - MinusLogProbMetric: 3.9798 - val_loss: 4.2041 - val_MinusLogProbMetric: 4.2041 - lr: 5.0000e-04 - 41s/epoch - 209ms/step
Epoch 177/1000
2023-09-17 21:58:28.761 
Epoch 177/1000 
	 loss: 3.9757, MinusLogProbMetric: 3.9757, val_loss: 4.1964, val_MinusLogProbMetric: 4.1964

Epoch 177: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9757 - MinusLogProbMetric: 3.9757 - val_loss: 4.1964 - val_MinusLogProbMetric: 4.1964 - lr: 5.0000e-04 - 41s/epoch - 208ms/step
Epoch 178/1000
2023-09-17 21:59:10.571 
Epoch 178/1000 
	 loss: 3.9735, MinusLogProbMetric: 3.9735, val_loss: 4.2090, val_MinusLogProbMetric: 4.2090

Epoch 178: val_loss did not improve from 4.15480
196/196 - 42s - loss: 3.9735 - MinusLogProbMetric: 3.9735 - val_loss: 4.2090 - val_MinusLogProbMetric: 4.2090 - lr: 5.0000e-04 - 42s/epoch - 213ms/step
Epoch 179/1000
2023-09-17 21:59:52.297 
Epoch 179/1000 
	 loss: 3.9792, MinusLogProbMetric: 3.9792, val_loss: 4.1936, val_MinusLogProbMetric: 4.1936

Epoch 179: val_loss did not improve from 4.15480
196/196 - 42s - loss: 3.9792 - MinusLogProbMetric: 3.9792 - val_loss: 4.1936 - val_MinusLogProbMetric: 4.1936 - lr: 5.0000e-04 - 42s/epoch - 213ms/step
Epoch 180/1000
2023-09-17 22:00:33.596 
Epoch 180/1000 
	 loss: 3.9711, MinusLogProbMetric: 3.9711, val_loss: 4.1862, val_MinusLogProbMetric: 4.1862

Epoch 180: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9711 - MinusLogProbMetric: 3.9711 - val_loss: 4.1862 - val_MinusLogProbMetric: 4.1862 - lr: 5.0000e-04 - 41s/epoch - 211ms/step
Epoch 181/1000
2023-09-17 22:01:15.003 
Epoch 181/1000 
	 loss: 3.9743, MinusLogProbMetric: 3.9743, val_loss: 4.1904, val_MinusLogProbMetric: 4.1904

Epoch 181: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9743 - MinusLogProbMetric: 3.9743 - val_loss: 4.1904 - val_MinusLogProbMetric: 4.1904 - lr: 5.0000e-04 - 41s/epoch - 211ms/step
Epoch 182/1000
2023-09-17 22:01:56.318 
Epoch 182/1000 
	 loss: 3.9724, MinusLogProbMetric: 3.9724, val_loss: 4.2125, val_MinusLogProbMetric: 4.2125

Epoch 182: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9724 - MinusLogProbMetric: 3.9724 - val_loss: 4.2125 - val_MinusLogProbMetric: 4.2125 - lr: 5.0000e-04 - 41s/epoch - 211ms/step
Epoch 183/1000
2023-09-17 22:02:37.493 
Epoch 183/1000 
	 loss: 3.9766, MinusLogProbMetric: 3.9766, val_loss: 4.1942, val_MinusLogProbMetric: 4.1942

Epoch 183: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9766 - MinusLogProbMetric: 3.9766 - val_loss: 4.1942 - val_MinusLogProbMetric: 4.1942 - lr: 5.0000e-04 - 41s/epoch - 210ms/step
Epoch 184/1000
2023-09-17 22:03:19.359 
Epoch 184/1000 
	 loss: 3.9711, MinusLogProbMetric: 3.9711, val_loss: 4.2038, val_MinusLogProbMetric: 4.2038

Epoch 184: val_loss did not improve from 4.15480
196/196 - 42s - loss: 3.9711 - MinusLogProbMetric: 3.9711 - val_loss: 4.2038 - val_MinusLogProbMetric: 4.2038 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 185/1000
2023-09-17 22:04:01.080 
Epoch 185/1000 
	 loss: 3.9717, MinusLogProbMetric: 3.9717, val_loss: 4.2179, val_MinusLogProbMetric: 4.2179

Epoch 185: val_loss did not improve from 4.15480
196/196 - 42s - loss: 3.9717 - MinusLogProbMetric: 3.9717 - val_loss: 4.2179 - val_MinusLogProbMetric: 4.2179 - lr: 5.0000e-04 - 42s/epoch - 213ms/step
Epoch 186/1000
2023-09-17 22:04:42.557 
Epoch 186/1000 
	 loss: 3.9680, MinusLogProbMetric: 3.9680, val_loss: 4.1840, val_MinusLogProbMetric: 4.1840

Epoch 186: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9680 - MinusLogProbMetric: 3.9680 - val_loss: 4.1840 - val_MinusLogProbMetric: 4.1840 - lr: 5.0000e-04 - 41s/epoch - 212ms/step
Epoch 187/1000
2023-09-17 22:05:23.827 
Epoch 187/1000 
	 loss: 3.9635, MinusLogProbMetric: 3.9635, val_loss: 4.2176, val_MinusLogProbMetric: 4.2176

Epoch 187: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9635 - MinusLogProbMetric: 3.9635 - val_loss: 4.2176 - val_MinusLogProbMetric: 4.2176 - lr: 5.0000e-04 - 41s/epoch - 211ms/step
Epoch 188/1000
2023-09-17 22:06:06.093 
Epoch 188/1000 
	 loss: 3.9737, MinusLogProbMetric: 3.9737, val_loss: 4.1866, val_MinusLogProbMetric: 4.1866

Epoch 188: val_loss did not improve from 4.15480
196/196 - 42s - loss: 3.9737 - MinusLogProbMetric: 3.9737 - val_loss: 4.1866 - val_MinusLogProbMetric: 4.1866 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 189/1000
2023-09-17 22:06:48.489 
Epoch 189/1000 
	 loss: 3.9656, MinusLogProbMetric: 3.9656, val_loss: 4.1977, val_MinusLogProbMetric: 4.1977

Epoch 189: val_loss did not improve from 4.15480
196/196 - 42s - loss: 3.9656 - MinusLogProbMetric: 3.9656 - val_loss: 4.1977 - val_MinusLogProbMetric: 4.1977 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 190/1000
2023-09-17 22:07:30.667 
Epoch 190/1000 
	 loss: 3.9654, MinusLogProbMetric: 3.9654, val_loss: 4.1822, val_MinusLogProbMetric: 4.1822

Epoch 190: val_loss did not improve from 4.15480
196/196 - 42s - loss: 3.9654 - MinusLogProbMetric: 3.9654 - val_loss: 4.1822 - val_MinusLogProbMetric: 4.1822 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 191/1000
2023-09-17 22:08:11.665 
Epoch 191/1000 
	 loss: 3.9613, MinusLogProbMetric: 3.9613, val_loss: 4.1898, val_MinusLogProbMetric: 4.1898

Epoch 191: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9613 - MinusLogProbMetric: 3.9613 - val_loss: 4.1898 - val_MinusLogProbMetric: 4.1898 - lr: 5.0000e-04 - 41s/epoch - 209ms/step
Epoch 192/1000
2023-09-17 22:08:53.587 
Epoch 192/1000 
	 loss: 3.9674, MinusLogProbMetric: 3.9674, val_loss: 4.1880, val_MinusLogProbMetric: 4.1880

Epoch 192: val_loss did not improve from 4.15480
196/196 - 42s - loss: 3.9674 - MinusLogProbMetric: 3.9674 - val_loss: 4.1880 - val_MinusLogProbMetric: 4.1880 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 193/1000
2023-09-17 22:09:35.764 
Epoch 193/1000 
	 loss: 3.9656, MinusLogProbMetric: 3.9656, val_loss: 4.2107, val_MinusLogProbMetric: 4.2107

Epoch 193: val_loss did not improve from 4.15480
196/196 - 42s - loss: 3.9656 - MinusLogProbMetric: 3.9656 - val_loss: 4.2107 - val_MinusLogProbMetric: 4.2107 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 194/1000
2023-09-17 22:10:13.854 
Epoch 194/1000 
	 loss: 3.9641, MinusLogProbMetric: 3.9641, val_loss: 4.1969, val_MinusLogProbMetric: 4.1969

Epoch 194: val_loss did not improve from 4.15480
196/196 - 38s - loss: 3.9641 - MinusLogProbMetric: 3.9641 - val_loss: 4.1969 - val_MinusLogProbMetric: 4.1969 - lr: 5.0000e-04 - 38s/epoch - 194ms/step
Epoch 195/1000
2023-09-17 22:10:47.565 
Epoch 195/1000 
	 loss: 3.9623, MinusLogProbMetric: 3.9623, val_loss: 4.2511, val_MinusLogProbMetric: 4.2511

Epoch 195: val_loss did not improve from 4.15480
196/196 - 34s - loss: 3.9623 - MinusLogProbMetric: 3.9623 - val_loss: 4.2511 - val_MinusLogProbMetric: 4.2511 - lr: 5.0000e-04 - 34s/epoch - 172ms/step
Epoch 196/1000
2023-09-17 22:11:23.971 
Epoch 196/1000 
	 loss: 3.9642, MinusLogProbMetric: 3.9642, val_loss: 4.2152, val_MinusLogProbMetric: 4.2152

Epoch 196: val_loss did not improve from 4.15480
196/196 - 36s - loss: 3.9642 - MinusLogProbMetric: 3.9642 - val_loss: 4.2152 - val_MinusLogProbMetric: 4.2152 - lr: 5.0000e-04 - 36s/epoch - 186ms/step
Epoch 197/1000
2023-09-17 22:11:57.561 
Epoch 197/1000 
	 loss: 3.9592, MinusLogProbMetric: 3.9592, val_loss: 4.1975, val_MinusLogProbMetric: 4.1975

Epoch 197: val_loss did not improve from 4.15480
196/196 - 34s - loss: 3.9592 - MinusLogProbMetric: 3.9592 - val_loss: 4.1975 - val_MinusLogProbMetric: 4.1975 - lr: 5.0000e-04 - 34s/epoch - 171ms/step
Epoch 198/1000
2023-09-17 22:12:32.109 
Epoch 198/1000 
	 loss: 3.9716, MinusLogProbMetric: 3.9716, val_loss: 4.1986, val_MinusLogProbMetric: 4.1986

Epoch 198: val_loss did not improve from 4.15480
196/196 - 35s - loss: 3.9716 - MinusLogProbMetric: 3.9716 - val_loss: 4.1986 - val_MinusLogProbMetric: 4.1986 - lr: 5.0000e-04 - 35s/epoch - 176ms/step
Epoch 199/1000
2023-09-17 22:13:12.853 
Epoch 199/1000 
	 loss: 3.9642, MinusLogProbMetric: 3.9642, val_loss: 4.1940, val_MinusLogProbMetric: 4.1940

Epoch 199: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9642 - MinusLogProbMetric: 3.9642 - val_loss: 4.1940 - val_MinusLogProbMetric: 4.1940 - lr: 5.0000e-04 - 41s/epoch - 208ms/step
Epoch 200/1000
2023-09-17 22:13:53.892 
Epoch 200/1000 
	 loss: 3.9608, MinusLogProbMetric: 3.9608, val_loss: 4.1946, val_MinusLogProbMetric: 4.1946

Epoch 200: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9608 - MinusLogProbMetric: 3.9608 - val_loss: 4.1946 - val_MinusLogProbMetric: 4.1946 - lr: 5.0000e-04 - 41s/epoch - 209ms/step
Epoch 201/1000
2023-09-17 22:14:34.827 
Epoch 201/1000 
	 loss: 3.9556, MinusLogProbMetric: 3.9556, val_loss: 4.2362, val_MinusLogProbMetric: 4.2362

Epoch 201: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9556 - MinusLogProbMetric: 3.9556 - val_loss: 4.2362 - val_MinusLogProbMetric: 4.2362 - lr: 5.0000e-04 - 41s/epoch - 209ms/step
Epoch 202/1000
2023-09-17 22:15:16.006 
Epoch 202/1000 
	 loss: 3.9643, MinusLogProbMetric: 3.9643, val_loss: 4.2266, val_MinusLogProbMetric: 4.2266

Epoch 202: val_loss did not improve from 4.15480
196/196 - 41s - loss: 3.9643 - MinusLogProbMetric: 3.9643 - val_loss: 4.2266 - val_MinusLogProbMetric: 4.2266 - lr: 5.0000e-04 - 41s/epoch - 210ms/step
Epoch 203/1000
2023-09-17 22:15:57.845 
Epoch 203/1000 
	 loss: 3.9611, MinusLogProbMetric: 3.9611, val_loss: 4.1991, val_MinusLogProbMetric: 4.1991

Epoch 203: val_loss did not improve from 4.15480
196/196 - 42s - loss: 3.9611 - MinusLogProbMetric: 3.9611 - val_loss: 4.1991 - val_MinusLogProbMetric: 4.1991 - lr: 5.0000e-04 - 42s/epoch - 213ms/step
Epoch 204/1000
2023-09-17 22:16:39.827 
Epoch 204/1000 
	 loss: 3.9609, MinusLogProbMetric: 3.9609, val_loss: 4.2300, val_MinusLogProbMetric: 4.2300

Epoch 204: val_loss did not improve from 4.15480
196/196 - 42s - loss: 3.9609 - MinusLogProbMetric: 3.9609 - val_loss: 4.2300 - val_MinusLogProbMetric: 4.2300 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 205/1000
2023-09-17 22:17:22.127 
Epoch 205/1000 
	 loss: 3.9600, MinusLogProbMetric: 3.9600, val_loss: 4.2085, val_MinusLogProbMetric: 4.2085

Epoch 205: val_loss did not improve from 4.15480
Restoring model weights from the end of the best epoch: 105.
196/196 - 43s - loss: 3.9600 - MinusLogProbMetric: 3.9600 - val_loss: 4.2085 - val_MinusLogProbMetric: 4.2085 - lr: 5.0000e-04 - 43s/epoch - 218ms/step
Epoch 205: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 17.06930159800686 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 9.55158649594523 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 5.691698262002319 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7faacbffe170> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 18.21632522600703 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 7.063311496051028 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 5.80302082397975 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7faacbffe5f0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 926.
Model trained in 8562.87 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

Plots done in 10.42 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 97.86 s.
===========
Run 148/720 done in 8667.37 s.
===========

Directory ../../results/CsplineN_new/run_149/ already exists.
Skipping it.
===========
Run 149/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_150/ already exists.
Skipping it.
===========
Run 150/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_151/ already exists.
Skipping it.
===========
Run 151/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_152/ already exists.
Skipping it.
===========
Run 152/720 already exists. Skipping it.
===========

===========
Generating train data for run 153.
===========
Train data generated in 0.26 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 8)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_153/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 933}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_153/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 0.60277855,  7.2496796 ,  7.311799  , ...,  6.471478  ,
         4.4766264 ,  7.6941757 ],
       [ 9.891631  ,  5.07585   ,  7.9255137 , ..., 10.410634  ,
         0.19630367,  0.2451933 ],
       [ 9.692471  ,  3.8958035 ,  7.898749  , ...,  9.102936  ,
         0.31555456,  1.1337659 ],
       ...,
       [ 0.69027716,  7.826899  ,  7.581092  , ...,  7.7249126 ,
         4.6991906 ,  7.747929  ],
       [ 5.4378247 ,  7.457948  ,  6.062617  , ...,  6.4751306 ,
         4.9251475 ,  9.483738  ],
       [ 0.8388093 ,  8.2027235 ,  8.194429  , ...,  7.5383434 ,
         4.5117407 ,  7.89007   ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_153/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_153
self.data_kwargs: {'seed': 933}
self.x_data: [[5.358355   6.019778   5.8569536  ... 7.515295   3.9379482  8.654374  ]
 [5.3684006  7.0696135  5.9023     ... 6.403228   4.3043017  8.278582  ]
 [0.5474414  9.273294   8.089687   ... 6.9538503  4.605232   7.7114205 ]
 ...
 [0.0460346  8.452679   7.684837   ... 7.5281396  4.5184097  8.003926  ]
 [0.35366723 9.14325    6.7288957  ... 8.428171   4.626755   7.9396896 ]
 [0.02297392 8.22993    8.40971    ... 8.825319   4.5680537  8.07164   ]]
self.y_data: []
self.ndims: 8
Model defined.
Model: "model_112"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_113 (InputLayer)      [(None, 8)]               0         
                                                                 
 log_prob_layer_12 (LogProbL  (None,)                  227660    
 ayer)                                                           
                                                                 
=================================================================
Total params: 227,660
Trainable params: 227,660
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_12/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_12'")
self.model: <keras.engine.functional.Functional object at 0x7fae95f83ee0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7faecd6e4550>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7faecd6e4550>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7faec5cce170>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7faead2ea740>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7faead2eacb0>, <keras.callbacks.ModelCheckpoint object at 0x7faead2ead70>, <keras.callbacks.EarlyStopping object at 0x7faead2eafe0>, <keras.callbacks.ReduceLROnPlateau object at 0x7faead2eb010>, <keras.callbacks.TerminateOnNaN object at 0x7faead2eac50>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 0.60277855,  7.2496796 ,  7.311799  , ...,  6.471478  ,
         4.4766264 ,  7.6941757 ],
       [ 9.891631  ,  5.07585   ,  7.9255137 , ..., 10.410634  ,
         0.19630367,  0.2451933 ],
       [ 9.692471  ,  3.8958035 ,  7.898749  , ...,  9.102936  ,
         0.31555456,  1.1337659 ],
       ...,
       [ 0.69027716,  7.826899  ,  7.581092  , ...,  7.7249126 ,
         4.6991906 ,  7.747929  ],
       [ 5.4378247 ,  7.457948  ,  6.062617  , ...,  6.4751306 ,
         4.9251475 ,  9.483738  ],
       [ 0.8388093 ,  8.2027235 ,  8.194429  , ...,  7.5383434 ,
         4.5117407 ,  7.89007   ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_153/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 153/720 with hyperparameters:
timestamp = 2023-09-17 22:19:05.505854
ndims = 8
seed_train = 933
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 5
spline_knots = 8
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 227660
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [5.358355  6.019778  5.8569536 3.3511574 3.8962636 7.515295  3.9379482
 8.654374 ]
Epoch 1/1000
2023-09-17 22:21:00.375 
Epoch 1/1000 
	 loss: 12.6401, MinusLogProbMetric: 12.6401, val_loss: 7.6669, val_MinusLogProbMetric: 7.6669

Epoch 1: val_loss improved from inf to 7.66685, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 115s - loss: 12.6401 - MinusLogProbMetric: 12.6401 - val_loss: 7.6669 - val_MinusLogProbMetric: 7.6669 - lr: 0.0010 - 115s/epoch - 588ms/step
Epoch 2/1000
2023-09-17 22:21:35.440 
Epoch 2/1000 
	 loss: 6.0674, MinusLogProbMetric: 6.0674, val_loss: 5.4737, val_MinusLogProbMetric: 5.4737

Epoch 2: val_loss improved from 7.66685 to 5.47370, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 35s - loss: 6.0674 - MinusLogProbMetric: 6.0674 - val_loss: 5.4737 - val_MinusLogProbMetric: 5.4737 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 3/1000
2023-09-17 22:22:09.862 
Epoch 3/1000 
	 loss: 5.3363, MinusLogProbMetric: 5.3363, val_loss: 4.9649, val_MinusLogProbMetric: 4.9649

Epoch 3: val_loss improved from 5.47370 to 4.96492, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 34s - loss: 5.3363 - MinusLogProbMetric: 5.3363 - val_loss: 4.9649 - val_MinusLogProbMetric: 4.9649 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 4/1000
2023-09-17 22:22:43.436 
Epoch 4/1000 
	 loss: 5.1693, MinusLogProbMetric: 5.1693, val_loss: 4.7436, val_MinusLogProbMetric: 4.7436

Epoch 4: val_loss improved from 4.96492 to 4.74365, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 34s - loss: 5.1693 - MinusLogProbMetric: 5.1693 - val_loss: 4.7436 - val_MinusLogProbMetric: 4.7436 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 5/1000
2023-09-17 22:23:17.571 
Epoch 5/1000 
	 loss: 4.8746, MinusLogProbMetric: 4.8746, val_loss: 5.4659, val_MinusLogProbMetric: 5.4659

Epoch 5: val_loss did not improve from 4.74365
196/196 - 33s - loss: 4.8746 - MinusLogProbMetric: 4.8746 - val_loss: 5.4659 - val_MinusLogProbMetric: 5.4659 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 6/1000
2023-09-17 22:23:51.197 
Epoch 6/1000 
	 loss: 4.8625, MinusLogProbMetric: 4.8625, val_loss: 4.7846, val_MinusLogProbMetric: 4.7846

Epoch 6: val_loss did not improve from 4.74365
196/196 - 34s - loss: 4.8625 - MinusLogProbMetric: 4.8625 - val_loss: 4.7846 - val_MinusLogProbMetric: 4.7846 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 7/1000
2023-09-17 22:24:24.856 
Epoch 7/1000 
	 loss: 4.7548, MinusLogProbMetric: 4.7548, val_loss: 4.7845, val_MinusLogProbMetric: 4.7845

Epoch 7: val_loss did not improve from 4.74365
196/196 - 34s - loss: 4.7548 - MinusLogProbMetric: 4.7548 - val_loss: 4.7845 - val_MinusLogProbMetric: 4.7845 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 8/1000
2023-09-17 22:24:58.371 
Epoch 8/1000 
	 loss: 4.7024, MinusLogProbMetric: 4.7024, val_loss: 4.9533, val_MinusLogProbMetric: 4.9533

Epoch 8: val_loss did not improve from 4.74365
196/196 - 34s - loss: 4.7024 - MinusLogProbMetric: 4.7024 - val_loss: 4.9533 - val_MinusLogProbMetric: 4.9533 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 9/1000
2023-09-17 22:25:31.863 
Epoch 9/1000 
	 loss: 4.5878, MinusLogProbMetric: 4.5878, val_loss: 4.4995, val_MinusLogProbMetric: 4.4995

Epoch 9: val_loss improved from 4.74365 to 4.49948, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 34s - loss: 4.5878 - MinusLogProbMetric: 4.5878 - val_loss: 4.4995 - val_MinusLogProbMetric: 4.4995 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 10/1000
2023-09-17 22:26:06.362 
Epoch 10/1000 
	 loss: 4.6277, MinusLogProbMetric: 4.6277, val_loss: 4.4586, val_MinusLogProbMetric: 4.4586

Epoch 10: val_loss improved from 4.49948 to 4.45860, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 35s - loss: 4.6277 - MinusLogProbMetric: 4.6277 - val_loss: 4.4586 - val_MinusLogProbMetric: 4.4586 - lr: 0.0010 - 35s/epoch - 176ms/step
Epoch 11/1000
2023-09-17 22:26:40.519 
Epoch 11/1000 
	 loss: 4.5270, MinusLogProbMetric: 4.5270, val_loss: 4.5085, val_MinusLogProbMetric: 4.5085

Epoch 11: val_loss did not improve from 4.45860
196/196 - 34s - loss: 4.5270 - MinusLogProbMetric: 4.5270 - val_loss: 4.5085 - val_MinusLogProbMetric: 4.5085 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 12/1000
2023-09-17 22:27:14.582 
Epoch 12/1000 
	 loss: 4.5284, MinusLogProbMetric: 4.5284, val_loss: 4.6117, val_MinusLogProbMetric: 4.6117

Epoch 12: val_loss did not improve from 4.45860
196/196 - 34s - loss: 4.5284 - MinusLogProbMetric: 4.5284 - val_loss: 4.6117 - val_MinusLogProbMetric: 4.6117 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 13/1000
2023-09-17 22:27:48.946 
Epoch 13/1000 
	 loss: 4.4772, MinusLogProbMetric: 4.4772, val_loss: 4.6179, val_MinusLogProbMetric: 4.6179

Epoch 13: val_loss did not improve from 4.45860
196/196 - 34s - loss: 4.4772 - MinusLogProbMetric: 4.4772 - val_loss: 4.6179 - val_MinusLogProbMetric: 4.6179 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 14/1000
2023-09-17 22:28:23.161 
Epoch 14/1000 
	 loss: 4.4579, MinusLogProbMetric: 4.4579, val_loss: 4.4259, val_MinusLogProbMetric: 4.4259

Epoch 14: val_loss improved from 4.45860 to 4.42586, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 35s - loss: 4.4579 - MinusLogProbMetric: 4.4579 - val_loss: 4.4259 - val_MinusLogProbMetric: 4.4259 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 15/1000
2023-09-17 22:28:58.161 
Epoch 15/1000 
	 loss: 4.4299, MinusLogProbMetric: 4.4299, val_loss: 4.3684, val_MinusLogProbMetric: 4.3684

Epoch 15: val_loss improved from 4.42586 to 4.36843, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 35s - loss: 4.4299 - MinusLogProbMetric: 4.4299 - val_loss: 4.3684 - val_MinusLogProbMetric: 4.3684 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 16/1000
2023-09-17 22:29:32.594 
Epoch 16/1000 
	 loss: 4.4235, MinusLogProbMetric: 4.4235, val_loss: 4.3182, val_MinusLogProbMetric: 4.3182

Epoch 16: val_loss improved from 4.36843 to 4.31816, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 35s - loss: 4.4235 - MinusLogProbMetric: 4.4235 - val_loss: 4.3182 - val_MinusLogProbMetric: 4.3182 - lr: 0.0010 - 35s/epoch - 176ms/step
Epoch 17/1000
2023-09-17 22:30:06.799 
Epoch 17/1000 
	 loss: 4.3826, MinusLogProbMetric: 4.3826, val_loss: 4.3478, val_MinusLogProbMetric: 4.3478

Epoch 17: val_loss did not improve from 4.31816
196/196 - 33s - loss: 4.3826 - MinusLogProbMetric: 4.3826 - val_loss: 4.3478 - val_MinusLogProbMetric: 4.3478 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 18/1000
2023-09-17 22:30:40.831 
Epoch 18/1000 
	 loss: 4.3737, MinusLogProbMetric: 4.3737, val_loss: 4.2891, val_MinusLogProbMetric: 4.2891

Epoch 18: val_loss improved from 4.31816 to 4.28915, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 35s - loss: 4.3737 - MinusLogProbMetric: 4.3737 - val_loss: 4.2891 - val_MinusLogProbMetric: 4.2891 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 19/1000
2023-09-17 22:31:14.612 
Epoch 19/1000 
	 loss: 4.3445, MinusLogProbMetric: 4.3445, val_loss: 4.4841, val_MinusLogProbMetric: 4.4841

Epoch 19: val_loss did not improve from 4.28915
196/196 - 33s - loss: 4.3445 - MinusLogProbMetric: 4.3445 - val_loss: 4.4841 - val_MinusLogProbMetric: 4.4841 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 20/1000
2023-09-17 22:31:47.664 
Epoch 20/1000 
	 loss: 4.3721, MinusLogProbMetric: 4.3721, val_loss: 4.5799, val_MinusLogProbMetric: 4.5799

Epoch 20: val_loss did not improve from 4.28915
196/196 - 33s - loss: 4.3721 - MinusLogProbMetric: 4.3721 - val_loss: 4.5799 - val_MinusLogProbMetric: 4.5799 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 21/1000
2023-09-17 22:32:20.672 
Epoch 21/1000 
	 loss: 4.3259, MinusLogProbMetric: 4.3259, val_loss: 4.3660, val_MinusLogProbMetric: 4.3660

Epoch 21: val_loss did not improve from 4.28915
196/196 - 33s - loss: 4.3259 - MinusLogProbMetric: 4.3259 - val_loss: 4.3660 - val_MinusLogProbMetric: 4.3660 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 22/1000
2023-09-17 22:32:54.268 
Epoch 22/1000 
	 loss: 4.3294, MinusLogProbMetric: 4.3294, val_loss: 4.3930, val_MinusLogProbMetric: 4.3930

Epoch 22: val_loss did not improve from 4.28915
196/196 - 34s - loss: 4.3294 - MinusLogProbMetric: 4.3294 - val_loss: 4.3930 - val_MinusLogProbMetric: 4.3930 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 23/1000
2023-09-17 22:33:27.872 
Epoch 23/1000 
	 loss: 4.3205, MinusLogProbMetric: 4.3205, val_loss: 4.2620, val_MinusLogProbMetric: 4.2620

Epoch 23: val_loss improved from 4.28915 to 4.26205, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 34s - loss: 4.3205 - MinusLogProbMetric: 4.3205 - val_loss: 4.2620 - val_MinusLogProbMetric: 4.2620 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 24/1000
2023-09-17 22:34:03.425 
Epoch 24/1000 
	 loss: 4.3120, MinusLogProbMetric: 4.3120, val_loss: 4.3819, val_MinusLogProbMetric: 4.3819

Epoch 24: val_loss did not improve from 4.26205
196/196 - 35s - loss: 4.3120 - MinusLogProbMetric: 4.3120 - val_loss: 4.3819 - val_MinusLogProbMetric: 4.3819 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 25/1000
2023-09-17 22:34:36.852 
Epoch 25/1000 
	 loss: 4.3041, MinusLogProbMetric: 4.3041, val_loss: 4.4592, val_MinusLogProbMetric: 4.4592

Epoch 25: val_loss did not improve from 4.26205
196/196 - 33s - loss: 4.3041 - MinusLogProbMetric: 4.3041 - val_loss: 4.4592 - val_MinusLogProbMetric: 4.4592 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 26/1000
2023-09-17 22:35:06.072 
Epoch 26/1000 
	 loss: 4.2996, MinusLogProbMetric: 4.2996, val_loss: 4.4489, val_MinusLogProbMetric: 4.4489

Epoch 26: val_loss did not improve from 4.26205
196/196 - 29s - loss: 4.2996 - MinusLogProbMetric: 4.2996 - val_loss: 4.4489 - val_MinusLogProbMetric: 4.4489 - lr: 0.0010 - 29s/epoch - 149ms/step
Epoch 27/1000
2023-09-17 22:35:35.145 
Epoch 27/1000 
	 loss: 4.2826, MinusLogProbMetric: 4.2826, val_loss: 4.2892, val_MinusLogProbMetric: 4.2892

Epoch 27: val_loss did not improve from 4.26205
196/196 - 29s - loss: 4.2826 - MinusLogProbMetric: 4.2826 - val_loss: 4.2892 - val_MinusLogProbMetric: 4.2892 - lr: 0.0010 - 29s/epoch - 148ms/step
Epoch 28/1000
2023-09-17 22:36:05.961 
Epoch 28/1000 
	 loss: 4.3031, MinusLogProbMetric: 4.3031, val_loss: 4.3571, val_MinusLogProbMetric: 4.3571

Epoch 28: val_loss did not improve from 4.26205
196/196 - 31s - loss: 4.3031 - MinusLogProbMetric: 4.3031 - val_loss: 4.3571 - val_MinusLogProbMetric: 4.3571 - lr: 0.0010 - 31s/epoch - 157ms/step
Epoch 29/1000
2023-09-17 22:36:40.525 
Epoch 29/1000 
	 loss: 4.2636, MinusLogProbMetric: 4.2636, val_loss: 4.2128, val_MinusLogProbMetric: 4.2128

Epoch 29: val_loss improved from 4.26205 to 4.21282, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 35s - loss: 4.2636 - MinusLogProbMetric: 4.2636 - val_loss: 4.2128 - val_MinusLogProbMetric: 4.2128 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 30/1000
2023-09-17 22:37:13.710 
Epoch 30/1000 
	 loss: 4.2580, MinusLogProbMetric: 4.2580, val_loss: 4.2302, val_MinusLogProbMetric: 4.2302

Epoch 30: val_loss did not improve from 4.21282
196/196 - 33s - loss: 4.2580 - MinusLogProbMetric: 4.2580 - val_loss: 4.2302 - val_MinusLogProbMetric: 4.2302 - lr: 0.0010 - 33s/epoch - 167ms/step
Epoch 31/1000
2023-09-17 22:37:48.741 
Epoch 31/1000 
	 loss: 4.2488, MinusLogProbMetric: 4.2488, val_loss: 4.4157, val_MinusLogProbMetric: 4.4157

Epoch 31: val_loss did not improve from 4.21282
196/196 - 35s - loss: 4.2488 - MinusLogProbMetric: 4.2488 - val_loss: 4.4157 - val_MinusLogProbMetric: 4.4157 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 32/1000
2023-09-17 22:38:22.702 
Epoch 32/1000 
	 loss: 4.2711, MinusLogProbMetric: 4.2711, val_loss: 4.2443, val_MinusLogProbMetric: 4.2443

Epoch 32: val_loss did not improve from 4.21282
196/196 - 34s - loss: 4.2711 - MinusLogProbMetric: 4.2711 - val_loss: 4.2443 - val_MinusLogProbMetric: 4.2443 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 33/1000
2023-09-17 22:38:56.197 
Epoch 33/1000 
	 loss: 4.2513, MinusLogProbMetric: 4.2513, val_loss: 4.2349, val_MinusLogProbMetric: 4.2349

Epoch 33: val_loss did not improve from 4.21282
196/196 - 33s - loss: 4.2513 - MinusLogProbMetric: 4.2513 - val_loss: 4.2349 - val_MinusLogProbMetric: 4.2349 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 34/1000
2023-09-17 22:39:30.183 
Epoch 34/1000 
	 loss: 4.2379, MinusLogProbMetric: 4.2379, val_loss: 4.2849, val_MinusLogProbMetric: 4.2849

Epoch 34: val_loss did not improve from 4.21282
196/196 - 34s - loss: 4.2379 - MinusLogProbMetric: 4.2379 - val_loss: 4.2849 - val_MinusLogProbMetric: 4.2849 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 35/1000
2023-09-17 22:40:03.497 
Epoch 35/1000 
	 loss: 4.2519, MinusLogProbMetric: 4.2519, val_loss: 4.2933, val_MinusLogProbMetric: 4.2933

Epoch 35: val_loss did not improve from 4.21282
196/196 - 33s - loss: 4.2519 - MinusLogProbMetric: 4.2519 - val_loss: 4.2933 - val_MinusLogProbMetric: 4.2933 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 36/1000
2023-09-17 22:40:37.170 
Epoch 36/1000 
	 loss: 4.2419, MinusLogProbMetric: 4.2419, val_loss: 4.2593, val_MinusLogProbMetric: 4.2593

Epoch 36: val_loss did not improve from 4.21282
196/196 - 34s - loss: 4.2419 - MinusLogProbMetric: 4.2419 - val_loss: 4.2593 - val_MinusLogProbMetric: 4.2593 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 37/1000
2023-09-17 22:41:10.696 
Epoch 37/1000 
	 loss: 4.2242, MinusLogProbMetric: 4.2242, val_loss: 4.2476, val_MinusLogProbMetric: 4.2476

Epoch 37: val_loss did not improve from 4.21282
196/196 - 34s - loss: 4.2242 - MinusLogProbMetric: 4.2242 - val_loss: 4.2476 - val_MinusLogProbMetric: 4.2476 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 38/1000
2023-09-17 22:41:44.267 
Epoch 38/1000 
	 loss: 4.2329, MinusLogProbMetric: 4.2329, val_loss: 4.3097, val_MinusLogProbMetric: 4.3097

Epoch 38: val_loss did not improve from 4.21282
196/196 - 34s - loss: 4.2329 - MinusLogProbMetric: 4.2329 - val_loss: 4.3097 - val_MinusLogProbMetric: 4.3097 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 39/1000
2023-09-17 22:42:14.611 
Epoch 39/1000 
	 loss: 4.2323, MinusLogProbMetric: 4.2323, val_loss: 4.3440, val_MinusLogProbMetric: 4.3440

Epoch 39: val_loss did not improve from 4.21282
196/196 - 30s - loss: 4.2323 - MinusLogProbMetric: 4.2323 - val_loss: 4.3440 - val_MinusLogProbMetric: 4.3440 - lr: 0.0010 - 30s/epoch - 155ms/step
Epoch 40/1000
2023-09-17 22:42:43.971 
Epoch 40/1000 
	 loss: 4.2370, MinusLogProbMetric: 4.2370, val_loss: 4.3460, val_MinusLogProbMetric: 4.3460

Epoch 40: val_loss did not improve from 4.21282
196/196 - 29s - loss: 4.2370 - MinusLogProbMetric: 4.2370 - val_loss: 4.3460 - val_MinusLogProbMetric: 4.3460 - lr: 0.0010 - 29s/epoch - 150ms/step
Epoch 41/1000
2023-09-17 22:43:13.720 
Epoch 41/1000 
	 loss: 4.2127, MinusLogProbMetric: 4.2127, val_loss: 4.2170, val_MinusLogProbMetric: 4.2170

Epoch 41: val_loss did not improve from 4.21282
196/196 - 30s - loss: 4.2127 - MinusLogProbMetric: 4.2127 - val_loss: 4.2170 - val_MinusLogProbMetric: 4.2170 - lr: 0.0010 - 30s/epoch - 152ms/step
Epoch 42/1000
2023-09-17 22:43:42.213 
Epoch 42/1000 
	 loss: 4.2234, MinusLogProbMetric: 4.2234, val_loss: 4.2694, val_MinusLogProbMetric: 4.2694

Epoch 42: val_loss did not improve from 4.21282
196/196 - 28s - loss: 4.2234 - MinusLogProbMetric: 4.2234 - val_loss: 4.2694 - val_MinusLogProbMetric: 4.2694 - lr: 0.0010 - 28s/epoch - 145ms/step
Epoch 43/1000
2023-09-17 22:44:13.048 
Epoch 43/1000 
	 loss: 4.2138, MinusLogProbMetric: 4.2138, val_loss: 4.2434, val_MinusLogProbMetric: 4.2434

Epoch 43: val_loss did not improve from 4.21282
196/196 - 31s - loss: 4.2138 - MinusLogProbMetric: 4.2138 - val_loss: 4.2434 - val_MinusLogProbMetric: 4.2434 - lr: 0.0010 - 31s/epoch - 157ms/step
Epoch 44/1000
2023-09-17 22:44:44.013 
Epoch 44/1000 
	 loss: 4.2147, MinusLogProbMetric: 4.2147, val_loss: 4.2483, val_MinusLogProbMetric: 4.2483

Epoch 44: val_loss did not improve from 4.21282
196/196 - 31s - loss: 4.2147 - MinusLogProbMetric: 4.2147 - val_loss: 4.2483 - val_MinusLogProbMetric: 4.2483 - lr: 0.0010 - 31s/epoch - 158ms/step
Epoch 45/1000
2023-09-17 22:45:13.923 
Epoch 45/1000 
	 loss: 4.2078, MinusLogProbMetric: 4.2078, val_loss: 4.5277, val_MinusLogProbMetric: 4.5277

Epoch 45: val_loss did not improve from 4.21282
196/196 - 30s - loss: 4.2078 - MinusLogProbMetric: 4.2078 - val_loss: 4.5277 - val_MinusLogProbMetric: 4.5277 - lr: 0.0010 - 30s/epoch - 153ms/step
Epoch 46/1000
2023-09-17 22:45:43.560 
Epoch 46/1000 
	 loss: 4.2186, MinusLogProbMetric: 4.2186, val_loss: 4.1894, val_MinusLogProbMetric: 4.1894

Epoch 46: val_loss improved from 4.21282 to 4.18943, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 30s - loss: 4.2186 - MinusLogProbMetric: 4.2186 - val_loss: 4.1894 - val_MinusLogProbMetric: 4.1894 - lr: 0.0010 - 30s/epoch - 154ms/step
Epoch 47/1000
2023-09-17 22:46:15.578 
Epoch 47/1000 
	 loss: 4.1935, MinusLogProbMetric: 4.1935, val_loss: 4.3763, val_MinusLogProbMetric: 4.3763

Epoch 47: val_loss did not improve from 4.18943
196/196 - 31s - loss: 4.1935 - MinusLogProbMetric: 4.1935 - val_loss: 4.3763 - val_MinusLogProbMetric: 4.3763 - lr: 0.0010 - 31s/epoch - 160ms/step
Epoch 48/1000
2023-09-17 22:46:49.446 
Epoch 48/1000 
	 loss: 4.2193, MinusLogProbMetric: 4.2193, val_loss: 4.2280, val_MinusLogProbMetric: 4.2280

Epoch 48: val_loss did not improve from 4.18943
196/196 - 34s - loss: 4.2193 - MinusLogProbMetric: 4.2193 - val_loss: 4.2280 - val_MinusLogProbMetric: 4.2280 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 49/1000
2023-09-17 22:47:23.888 
Epoch 49/1000 
	 loss: 4.1991, MinusLogProbMetric: 4.1991, val_loss: 4.2217, val_MinusLogProbMetric: 4.2217

Epoch 49: val_loss did not improve from 4.18943
196/196 - 34s - loss: 4.1991 - MinusLogProbMetric: 4.1991 - val_loss: 4.2217 - val_MinusLogProbMetric: 4.2217 - lr: 0.0010 - 34s/epoch - 176ms/step
Epoch 50/1000
2023-09-17 22:47:57.782 
Epoch 50/1000 
	 loss: 4.1950, MinusLogProbMetric: 4.1950, val_loss: 4.2096, val_MinusLogProbMetric: 4.2096

Epoch 50: val_loss did not improve from 4.18943
196/196 - 34s - loss: 4.1950 - MinusLogProbMetric: 4.1950 - val_loss: 4.2096 - val_MinusLogProbMetric: 4.2096 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 51/1000
2023-09-17 22:48:31.422 
Epoch 51/1000 
	 loss: 4.1867, MinusLogProbMetric: 4.1867, val_loss: 4.2729, val_MinusLogProbMetric: 4.2729

Epoch 51: val_loss did not improve from 4.18943
196/196 - 34s - loss: 4.1867 - MinusLogProbMetric: 4.1867 - val_loss: 4.2729 - val_MinusLogProbMetric: 4.2729 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 52/1000
2023-09-17 22:49:04.536 
Epoch 52/1000 
	 loss: 4.2076, MinusLogProbMetric: 4.2076, val_loss: 4.2362, val_MinusLogProbMetric: 4.2362

Epoch 52: val_loss did not improve from 4.18943
196/196 - 33s - loss: 4.2076 - MinusLogProbMetric: 4.2076 - val_loss: 4.2362 - val_MinusLogProbMetric: 4.2362 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 53/1000
2023-09-17 22:49:38.512 
Epoch 53/1000 
	 loss: 4.1724, MinusLogProbMetric: 4.1724, val_loss: 4.2009, val_MinusLogProbMetric: 4.2009

Epoch 53: val_loss did not improve from 4.18943
196/196 - 34s - loss: 4.1724 - MinusLogProbMetric: 4.1724 - val_loss: 4.2009 - val_MinusLogProbMetric: 4.2009 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 54/1000
2023-09-17 22:50:12.809 
Epoch 54/1000 
	 loss: 4.1849, MinusLogProbMetric: 4.1849, val_loss: 4.2604, val_MinusLogProbMetric: 4.2604

Epoch 54: val_loss did not improve from 4.18943
196/196 - 34s - loss: 4.1849 - MinusLogProbMetric: 4.1849 - val_loss: 4.2604 - val_MinusLogProbMetric: 4.2604 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 55/1000
2023-09-17 22:50:46.430 
Epoch 55/1000 
	 loss: 4.1722, MinusLogProbMetric: 4.1722, val_loss: 4.1982, val_MinusLogProbMetric: 4.1982

Epoch 55: val_loss did not improve from 4.18943
196/196 - 34s - loss: 4.1722 - MinusLogProbMetric: 4.1722 - val_loss: 4.1982 - val_MinusLogProbMetric: 4.1982 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 56/1000
2023-09-17 22:51:19.970 
Epoch 56/1000 
	 loss: 4.1829, MinusLogProbMetric: 4.1829, val_loss: 4.2036, val_MinusLogProbMetric: 4.2036

Epoch 56: val_loss did not improve from 4.18943
196/196 - 34s - loss: 4.1829 - MinusLogProbMetric: 4.1829 - val_loss: 4.2036 - val_MinusLogProbMetric: 4.2036 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 57/1000
2023-09-17 22:51:53.808 
Epoch 57/1000 
	 loss: 4.1768, MinusLogProbMetric: 4.1768, val_loss: 4.2204, val_MinusLogProbMetric: 4.2204

Epoch 57: val_loss did not improve from 4.18943
196/196 - 34s - loss: 4.1768 - MinusLogProbMetric: 4.1768 - val_loss: 4.2204 - val_MinusLogProbMetric: 4.2204 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 58/1000
2023-09-17 22:52:27.025 
Epoch 58/1000 
	 loss: 4.1716, MinusLogProbMetric: 4.1716, val_loss: 4.2227, val_MinusLogProbMetric: 4.2227

Epoch 58: val_loss did not improve from 4.18943
196/196 - 33s - loss: 4.1716 - MinusLogProbMetric: 4.1716 - val_loss: 4.2227 - val_MinusLogProbMetric: 4.2227 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 59/1000
2023-09-17 22:53:00.590 
Epoch 59/1000 
	 loss: 4.1694, MinusLogProbMetric: 4.1694, val_loss: 4.1962, val_MinusLogProbMetric: 4.1962

Epoch 59: val_loss did not improve from 4.18943
196/196 - 34s - loss: 4.1694 - MinusLogProbMetric: 4.1694 - val_loss: 4.1962 - val_MinusLogProbMetric: 4.1962 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 60/1000
2023-09-17 22:53:34.380 
Epoch 60/1000 
	 loss: 4.1814, MinusLogProbMetric: 4.1814, val_loss: 4.1994, val_MinusLogProbMetric: 4.1994

Epoch 60: val_loss did not improve from 4.18943
196/196 - 34s - loss: 4.1814 - MinusLogProbMetric: 4.1814 - val_loss: 4.1994 - val_MinusLogProbMetric: 4.1994 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 61/1000
2023-09-17 22:54:07.856 
Epoch 61/1000 
	 loss: 4.1771, MinusLogProbMetric: 4.1771, val_loss: 4.3545, val_MinusLogProbMetric: 4.3545

Epoch 61: val_loss did not improve from 4.18943
196/196 - 33s - loss: 4.1771 - MinusLogProbMetric: 4.1771 - val_loss: 4.3545 - val_MinusLogProbMetric: 4.3545 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 62/1000
2023-09-17 22:54:41.696 
Epoch 62/1000 
	 loss: 4.1686, MinusLogProbMetric: 4.1686, val_loss: 4.1955, val_MinusLogProbMetric: 4.1955

Epoch 62: val_loss did not improve from 4.18943
196/196 - 34s - loss: 4.1686 - MinusLogProbMetric: 4.1686 - val_loss: 4.1955 - val_MinusLogProbMetric: 4.1955 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 63/1000
2023-09-17 22:55:14.914 
Epoch 63/1000 
	 loss: 4.1718, MinusLogProbMetric: 4.1718, val_loss: 4.2654, val_MinusLogProbMetric: 4.2654

Epoch 63: val_loss did not improve from 4.18943
196/196 - 33s - loss: 4.1718 - MinusLogProbMetric: 4.1718 - val_loss: 4.2654 - val_MinusLogProbMetric: 4.2654 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 64/1000
2023-09-17 22:55:47.793 
Epoch 64/1000 
	 loss: 4.1803, MinusLogProbMetric: 4.1803, val_loss: 4.2476, val_MinusLogProbMetric: 4.2476

Epoch 64: val_loss did not improve from 4.18943
196/196 - 33s - loss: 4.1803 - MinusLogProbMetric: 4.1803 - val_loss: 4.2476 - val_MinusLogProbMetric: 4.2476 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 65/1000
2023-09-17 22:56:21.220 
Epoch 65/1000 
	 loss: 4.1533, MinusLogProbMetric: 4.1533, val_loss: 4.2910, val_MinusLogProbMetric: 4.2910

Epoch 65: val_loss did not improve from 4.18943
196/196 - 33s - loss: 4.1533 - MinusLogProbMetric: 4.1533 - val_loss: 4.2910 - val_MinusLogProbMetric: 4.2910 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 66/1000
2023-09-17 22:56:54.710 
Epoch 66/1000 
	 loss: 4.1807, MinusLogProbMetric: 4.1807, val_loss: 4.1888, val_MinusLogProbMetric: 4.1888

Epoch 66: val_loss improved from 4.18943 to 4.18884, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 34s - loss: 4.1807 - MinusLogProbMetric: 4.1807 - val_loss: 4.1888 - val_MinusLogProbMetric: 4.1888 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 67/1000
2023-09-17 22:57:28.593 
Epoch 67/1000 
	 loss: 4.1565, MinusLogProbMetric: 4.1565, val_loss: 4.1935, val_MinusLogProbMetric: 4.1935

Epoch 67: val_loss did not improve from 4.18884
196/196 - 33s - loss: 4.1565 - MinusLogProbMetric: 4.1565 - val_loss: 4.1935 - val_MinusLogProbMetric: 4.1935 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 68/1000
2023-09-17 22:58:02.243 
Epoch 68/1000 
	 loss: 4.1636, MinusLogProbMetric: 4.1636, val_loss: 4.2377, val_MinusLogProbMetric: 4.2377

Epoch 68: val_loss did not improve from 4.18884
196/196 - 34s - loss: 4.1636 - MinusLogProbMetric: 4.1636 - val_loss: 4.2377 - val_MinusLogProbMetric: 4.2377 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 69/1000
2023-09-17 22:58:35.409 
Epoch 69/1000 
	 loss: 4.1684, MinusLogProbMetric: 4.1684, val_loss: 4.1886, val_MinusLogProbMetric: 4.1886

Epoch 69: val_loss improved from 4.18884 to 4.18860, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 34s - loss: 4.1684 - MinusLogProbMetric: 4.1684 - val_loss: 4.1886 - val_MinusLogProbMetric: 4.1886 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 70/1000
2023-09-17 22:59:09.442 
Epoch 70/1000 
	 loss: 4.1582, MinusLogProbMetric: 4.1582, val_loss: 4.2063, val_MinusLogProbMetric: 4.2063

Epoch 70: val_loss did not improve from 4.18860
196/196 - 33s - loss: 4.1582 - MinusLogProbMetric: 4.1582 - val_loss: 4.2063 - val_MinusLogProbMetric: 4.2063 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 71/1000
2023-09-17 22:59:42.608 
Epoch 71/1000 
	 loss: 4.1582, MinusLogProbMetric: 4.1582, val_loss: 4.2406, val_MinusLogProbMetric: 4.2406

Epoch 71: val_loss did not improve from 4.18860
196/196 - 33s - loss: 4.1582 - MinusLogProbMetric: 4.1582 - val_loss: 4.2406 - val_MinusLogProbMetric: 4.2406 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 72/1000
2023-09-17 23:00:15.613 
Epoch 72/1000 
	 loss: 4.1605, MinusLogProbMetric: 4.1605, val_loss: 4.2302, val_MinusLogProbMetric: 4.2302

Epoch 72: val_loss did not improve from 4.18860
196/196 - 33s - loss: 4.1605 - MinusLogProbMetric: 4.1605 - val_loss: 4.2302 - val_MinusLogProbMetric: 4.2302 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 73/1000
2023-09-17 23:00:48.606 
Epoch 73/1000 
	 loss: 4.1532, MinusLogProbMetric: 4.1532, val_loss: 4.2184, val_MinusLogProbMetric: 4.2184

Epoch 73: val_loss did not improve from 4.18860
196/196 - 33s - loss: 4.1532 - MinusLogProbMetric: 4.1532 - val_loss: 4.2184 - val_MinusLogProbMetric: 4.2184 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 74/1000
2023-09-17 23:01:22.824 
Epoch 74/1000 
	 loss: 4.1456, MinusLogProbMetric: 4.1456, val_loss: 4.1750, val_MinusLogProbMetric: 4.1750

Epoch 74: val_loss improved from 4.18860 to 4.17499, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 35s - loss: 4.1456 - MinusLogProbMetric: 4.1456 - val_loss: 4.1750 - val_MinusLogProbMetric: 4.1750 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 75/1000
2023-09-17 23:01:57.115 
Epoch 75/1000 
	 loss: 4.1506, MinusLogProbMetric: 4.1506, val_loss: 4.1726, val_MinusLogProbMetric: 4.1726

Epoch 75: val_loss improved from 4.17499 to 4.17257, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 34s - loss: 4.1506 - MinusLogProbMetric: 4.1506 - val_loss: 4.1726 - val_MinusLogProbMetric: 4.1726 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 76/1000
2023-09-17 23:02:31.320 
Epoch 76/1000 
	 loss: 4.1414, MinusLogProbMetric: 4.1414, val_loss: 4.1871, val_MinusLogProbMetric: 4.1871

Epoch 76: val_loss did not improve from 4.17257
196/196 - 34s - loss: 4.1414 - MinusLogProbMetric: 4.1414 - val_loss: 4.1871 - val_MinusLogProbMetric: 4.1871 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 77/1000
2023-09-17 23:03:04.520 
Epoch 77/1000 
	 loss: 4.1492, MinusLogProbMetric: 4.1492, val_loss: 4.2256, val_MinusLogProbMetric: 4.2256

Epoch 77: val_loss did not improve from 4.17257
196/196 - 33s - loss: 4.1492 - MinusLogProbMetric: 4.1492 - val_loss: 4.2256 - val_MinusLogProbMetric: 4.2256 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 78/1000
2023-09-17 23:03:37.772 
Epoch 78/1000 
	 loss: 4.1516, MinusLogProbMetric: 4.1516, val_loss: 4.1751, val_MinusLogProbMetric: 4.1751

Epoch 78: val_loss did not improve from 4.17257
196/196 - 33s - loss: 4.1516 - MinusLogProbMetric: 4.1516 - val_loss: 4.1751 - val_MinusLogProbMetric: 4.1751 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 79/1000
2023-09-17 23:04:10.781 
Epoch 79/1000 
	 loss: 4.1469, MinusLogProbMetric: 4.1469, val_loss: 4.2134, val_MinusLogProbMetric: 4.2134

Epoch 79: val_loss did not improve from 4.17257
196/196 - 33s - loss: 4.1469 - MinusLogProbMetric: 4.1469 - val_loss: 4.2134 - val_MinusLogProbMetric: 4.2134 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 80/1000
2023-09-17 23:04:44.109 
Epoch 80/1000 
	 loss: 4.1455, MinusLogProbMetric: 4.1455, val_loss: 4.1716, val_MinusLogProbMetric: 4.1716

Epoch 80: val_loss improved from 4.17257 to 4.17162, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 34s - loss: 4.1455 - MinusLogProbMetric: 4.1455 - val_loss: 4.1716 - val_MinusLogProbMetric: 4.1716 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 81/1000
2023-09-17 23:05:18.520 
Epoch 81/1000 
	 loss: 4.1448, MinusLogProbMetric: 4.1448, val_loss: 4.3394, val_MinusLogProbMetric: 4.3394

Epoch 81: val_loss did not improve from 4.17162
196/196 - 34s - loss: 4.1448 - MinusLogProbMetric: 4.1448 - val_loss: 4.3394 - val_MinusLogProbMetric: 4.3394 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 82/1000
2023-09-17 23:05:52.345 
Epoch 82/1000 
	 loss: 4.1441, MinusLogProbMetric: 4.1441, val_loss: 4.1703, val_MinusLogProbMetric: 4.1703

Epoch 82: val_loss improved from 4.17162 to 4.17031, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 34s - loss: 4.1441 - MinusLogProbMetric: 4.1441 - val_loss: 4.1703 - val_MinusLogProbMetric: 4.1703 - lr: 0.0010 - 34s/epoch - 176ms/step
Epoch 83/1000
2023-09-17 23:06:26.432 
Epoch 83/1000 
	 loss: 4.1425, MinusLogProbMetric: 4.1425, val_loss: 4.2875, val_MinusLogProbMetric: 4.2875

Epoch 83: val_loss did not improve from 4.17031
196/196 - 33s - loss: 4.1425 - MinusLogProbMetric: 4.1425 - val_loss: 4.2875 - val_MinusLogProbMetric: 4.2875 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 84/1000
2023-09-17 23:07:00.563 
Epoch 84/1000 
	 loss: 4.1562, MinusLogProbMetric: 4.1562, val_loss: 4.2464, val_MinusLogProbMetric: 4.2464

Epoch 84: val_loss did not improve from 4.17031
196/196 - 34s - loss: 4.1562 - MinusLogProbMetric: 4.1562 - val_loss: 4.2464 - val_MinusLogProbMetric: 4.2464 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 85/1000
2023-09-17 23:07:33.801 
Epoch 85/1000 
	 loss: 4.1511, MinusLogProbMetric: 4.1511, val_loss: 4.2144, val_MinusLogProbMetric: 4.2144

Epoch 85: val_loss did not improve from 4.17031
196/196 - 33s - loss: 4.1511 - MinusLogProbMetric: 4.1511 - val_loss: 4.2144 - val_MinusLogProbMetric: 4.2144 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 86/1000
2023-09-17 23:08:07.447 
Epoch 86/1000 
	 loss: 4.1350, MinusLogProbMetric: 4.1350, val_loss: 4.1579, val_MinusLogProbMetric: 4.1579

Epoch 86: val_loss improved from 4.17031 to 4.15789, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 34s - loss: 4.1350 - MinusLogProbMetric: 4.1350 - val_loss: 4.1579 - val_MinusLogProbMetric: 4.1579 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 87/1000
2023-09-17 23:08:41.293 
Epoch 87/1000 
	 loss: 4.1448, MinusLogProbMetric: 4.1448, val_loss: 4.2002, val_MinusLogProbMetric: 4.2002

Epoch 87: val_loss did not improve from 4.15789
196/196 - 33s - loss: 4.1448 - MinusLogProbMetric: 4.1448 - val_loss: 4.2002 - val_MinusLogProbMetric: 4.2002 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 88/1000
2023-09-17 23:09:14.882 
Epoch 88/1000 
	 loss: 4.1449, MinusLogProbMetric: 4.1449, val_loss: 4.1881, val_MinusLogProbMetric: 4.1881

Epoch 88: val_loss did not improve from 4.15789
196/196 - 34s - loss: 4.1449 - MinusLogProbMetric: 4.1449 - val_loss: 4.1881 - val_MinusLogProbMetric: 4.1881 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 89/1000
2023-09-17 23:09:48.579 
Epoch 89/1000 
	 loss: 4.1417, MinusLogProbMetric: 4.1417, val_loss: 4.2135, val_MinusLogProbMetric: 4.2135

Epoch 89: val_loss did not improve from 4.15789
196/196 - 34s - loss: 4.1417 - MinusLogProbMetric: 4.1417 - val_loss: 4.2135 - val_MinusLogProbMetric: 4.2135 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 90/1000
2023-09-17 23:10:21.926 
Epoch 90/1000 
	 loss: 4.1318, MinusLogProbMetric: 4.1318, val_loss: 4.1808, val_MinusLogProbMetric: 4.1808

Epoch 90: val_loss did not improve from 4.15789
196/196 - 33s - loss: 4.1318 - MinusLogProbMetric: 4.1318 - val_loss: 4.1808 - val_MinusLogProbMetric: 4.1808 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 91/1000
2023-09-17 23:10:55.605 
Epoch 91/1000 
	 loss: 4.1448, MinusLogProbMetric: 4.1448, val_loss: 4.1932, val_MinusLogProbMetric: 4.1932

Epoch 91: val_loss did not improve from 4.15789
196/196 - 34s - loss: 4.1448 - MinusLogProbMetric: 4.1448 - val_loss: 4.1932 - val_MinusLogProbMetric: 4.1932 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 92/1000
2023-09-17 23:11:28.848 
Epoch 92/1000 
	 loss: 4.1368, MinusLogProbMetric: 4.1368, val_loss: 4.2994, val_MinusLogProbMetric: 4.2994

Epoch 92: val_loss did not improve from 4.15789
196/196 - 33s - loss: 4.1368 - MinusLogProbMetric: 4.1368 - val_loss: 4.2994 - val_MinusLogProbMetric: 4.2994 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 93/1000
2023-09-17 23:12:02.421 
Epoch 93/1000 
	 loss: 4.1313, MinusLogProbMetric: 4.1313, val_loss: 4.2380, val_MinusLogProbMetric: 4.2380

Epoch 93: val_loss did not improve from 4.15789
196/196 - 34s - loss: 4.1313 - MinusLogProbMetric: 4.1313 - val_loss: 4.2380 - val_MinusLogProbMetric: 4.2380 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 94/1000
2023-09-17 23:12:35.659 
Epoch 94/1000 
	 loss: 4.1358, MinusLogProbMetric: 4.1358, val_loss: 4.2360, val_MinusLogProbMetric: 4.2360

Epoch 94: val_loss did not improve from 4.15789
196/196 - 33s - loss: 4.1358 - MinusLogProbMetric: 4.1358 - val_loss: 4.2360 - val_MinusLogProbMetric: 4.2360 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 95/1000
2023-09-17 23:13:08.874 
Epoch 95/1000 
	 loss: 4.1291, MinusLogProbMetric: 4.1291, val_loss: 4.1683, val_MinusLogProbMetric: 4.1683

Epoch 95: val_loss did not improve from 4.15789
196/196 - 33s - loss: 4.1291 - MinusLogProbMetric: 4.1291 - val_loss: 4.1683 - val_MinusLogProbMetric: 4.1683 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 96/1000
2023-09-17 23:13:42.560 
Epoch 96/1000 
	 loss: 4.1360, MinusLogProbMetric: 4.1360, val_loss: 4.2636, val_MinusLogProbMetric: 4.2636

Epoch 96: val_loss did not improve from 4.15789
196/196 - 34s - loss: 4.1360 - MinusLogProbMetric: 4.1360 - val_loss: 4.2636 - val_MinusLogProbMetric: 4.2636 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 97/1000
2023-09-17 23:14:15.981 
Epoch 97/1000 
	 loss: 4.1309, MinusLogProbMetric: 4.1309, val_loss: 4.2916, val_MinusLogProbMetric: 4.2916

Epoch 97: val_loss did not improve from 4.15789
196/196 - 33s - loss: 4.1309 - MinusLogProbMetric: 4.1309 - val_loss: 4.2916 - val_MinusLogProbMetric: 4.2916 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 98/1000
2023-09-17 23:14:50.601 
Epoch 98/1000 
	 loss: 4.1346, MinusLogProbMetric: 4.1346, val_loss: 4.2524, val_MinusLogProbMetric: 4.2524

Epoch 98: val_loss did not improve from 4.15789
196/196 - 35s - loss: 4.1346 - MinusLogProbMetric: 4.1346 - val_loss: 4.2524 - val_MinusLogProbMetric: 4.2524 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 99/1000
2023-09-17 23:15:24.214 
Epoch 99/1000 
	 loss: 4.1293, MinusLogProbMetric: 4.1293, val_loss: 4.1758, val_MinusLogProbMetric: 4.1758

Epoch 99: val_loss did not improve from 4.15789
196/196 - 34s - loss: 4.1293 - MinusLogProbMetric: 4.1293 - val_loss: 4.1758 - val_MinusLogProbMetric: 4.1758 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 100/1000
2023-09-17 23:15:57.777 
Epoch 100/1000 
	 loss: 4.1399, MinusLogProbMetric: 4.1399, val_loss: 4.1935, val_MinusLogProbMetric: 4.1935

Epoch 100: val_loss did not improve from 4.15789
196/196 - 34s - loss: 4.1399 - MinusLogProbMetric: 4.1399 - val_loss: 4.1935 - val_MinusLogProbMetric: 4.1935 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 101/1000
2023-09-17 23:16:31.248 
Epoch 101/1000 
	 loss: 4.1236, MinusLogProbMetric: 4.1236, val_loss: 4.2005, val_MinusLogProbMetric: 4.2005

Epoch 101: val_loss did not improve from 4.15789
196/196 - 33s - loss: 4.1236 - MinusLogProbMetric: 4.1236 - val_loss: 4.2005 - val_MinusLogProbMetric: 4.2005 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 102/1000
2023-09-17 23:17:04.620 
Epoch 102/1000 
	 loss: 4.1213, MinusLogProbMetric: 4.1213, val_loss: 4.1635, val_MinusLogProbMetric: 4.1635

Epoch 102: val_loss did not improve from 4.15789
196/196 - 33s - loss: 4.1213 - MinusLogProbMetric: 4.1213 - val_loss: 4.1635 - val_MinusLogProbMetric: 4.1635 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 103/1000
2023-09-17 23:17:38.176 
Epoch 103/1000 
	 loss: 4.1234, MinusLogProbMetric: 4.1234, val_loss: 4.2020, val_MinusLogProbMetric: 4.2020

Epoch 103: val_loss did not improve from 4.15789
196/196 - 34s - loss: 4.1234 - MinusLogProbMetric: 4.1234 - val_loss: 4.2020 - val_MinusLogProbMetric: 4.2020 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 104/1000
2023-09-17 23:18:11.342 
Epoch 104/1000 
	 loss: 4.1300, MinusLogProbMetric: 4.1300, val_loss: 4.1497, val_MinusLogProbMetric: 4.1497

Epoch 104: val_loss improved from 4.15789 to 4.14971, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 34s - loss: 4.1300 - MinusLogProbMetric: 4.1300 - val_loss: 4.1497 - val_MinusLogProbMetric: 4.1497 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 105/1000
2023-09-17 23:18:45.549 
Epoch 105/1000 
	 loss: 4.1262, MinusLogProbMetric: 4.1262, val_loss: 4.1667, val_MinusLogProbMetric: 4.1667

Epoch 105: val_loss did not improve from 4.14971
196/196 - 34s - loss: 4.1262 - MinusLogProbMetric: 4.1262 - val_loss: 4.1667 - val_MinusLogProbMetric: 4.1667 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 106/1000
2023-09-17 23:19:18.585 
Epoch 106/1000 
	 loss: 4.1213, MinusLogProbMetric: 4.1213, val_loss: 4.2126, val_MinusLogProbMetric: 4.2126

Epoch 106: val_loss did not improve from 4.14971
196/196 - 33s - loss: 4.1213 - MinusLogProbMetric: 4.1213 - val_loss: 4.2126 - val_MinusLogProbMetric: 4.2126 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 107/1000
2023-09-17 23:19:51.897 
Epoch 107/1000 
	 loss: 4.1224, MinusLogProbMetric: 4.1224, val_loss: 4.1675, val_MinusLogProbMetric: 4.1675

Epoch 107: val_loss did not improve from 4.14971
196/196 - 33s - loss: 4.1224 - MinusLogProbMetric: 4.1224 - val_loss: 4.1675 - val_MinusLogProbMetric: 4.1675 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 108/1000
2023-09-17 23:20:25.406 
Epoch 108/1000 
	 loss: 4.1206, MinusLogProbMetric: 4.1206, val_loss: 4.1928, val_MinusLogProbMetric: 4.1928

Epoch 108: val_loss did not improve from 4.14971
196/196 - 34s - loss: 4.1206 - MinusLogProbMetric: 4.1206 - val_loss: 4.1928 - val_MinusLogProbMetric: 4.1928 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 109/1000
2023-09-17 23:20:58.780 
Epoch 109/1000 
	 loss: 4.1288, MinusLogProbMetric: 4.1288, val_loss: 4.1932, val_MinusLogProbMetric: 4.1932

Epoch 109: val_loss did not improve from 4.14971
196/196 - 33s - loss: 4.1288 - MinusLogProbMetric: 4.1288 - val_loss: 4.1932 - val_MinusLogProbMetric: 4.1932 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 110/1000
2023-09-17 23:21:33.050 
Epoch 110/1000 
	 loss: 4.1389, MinusLogProbMetric: 4.1389, val_loss: 4.1728, val_MinusLogProbMetric: 4.1728

Epoch 110: val_loss did not improve from 4.14971
196/196 - 34s - loss: 4.1389 - MinusLogProbMetric: 4.1389 - val_loss: 4.1728 - val_MinusLogProbMetric: 4.1728 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 111/1000
2023-09-17 23:22:06.280 
Epoch 111/1000 
	 loss: 4.1193, MinusLogProbMetric: 4.1193, val_loss: 4.1778, val_MinusLogProbMetric: 4.1778

Epoch 111: val_loss did not improve from 4.14971
196/196 - 33s - loss: 4.1193 - MinusLogProbMetric: 4.1193 - val_loss: 4.1778 - val_MinusLogProbMetric: 4.1778 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 112/1000
2023-09-17 23:22:39.966 
Epoch 112/1000 
	 loss: 4.1188, MinusLogProbMetric: 4.1188, val_loss: 4.1457, val_MinusLogProbMetric: 4.1457

Epoch 112: val_loss improved from 4.14971 to 4.14574, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 34s - loss: 4.1188 - MinusLogProbMetric: 4.1188 - val_loss: 4.1457 - val_MinusLogProbMetric: 4.1457 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 113/1000
2023-09-17 23:23:14.097 
Epoch 113/1000 
	 loss: 4.1215, MinusLogProbMetric: 4.1215, val_loss: 4.1773, val_MinusLogProbMetric: 4.1773

Epoch 113: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.1215 - MinusLogProbMetric: 4.1215 - val_loss: 4.1773 - val_MinusLogProbMetric: 4.1773 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 114/1000
2023-09-17 23:23:47.124 
Epoch 114/1000 
	 loss: 4.1258, MinusLogProbMetric: 4.1258, val_loss: 4.1829, val_MinusLogProbMetric: 4.1829

Epoch 114: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.1258 - MinusLogProbMetric: 4.1258 - val_loss: 4.1829 - val_MinusLogProbMetric: 4.1829 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 115/1000
2023-09-17 23:24:20.677 
Epoch 115/1000 
	 loss: 4.1263, MinusLogProbMetric: 4.1263, val_loss: 4.1699, val_MinusLogProbMetric: 4.1699

Epoch 115: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.1263 - MinusLogProbMetric: 4.1263 - val_loss: 4.1699 - val_MinusLogProbMetric: 4.1699 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 116/1000
2023-09-17 23:24:53.873 
Epoch 116/1000 
	 loss: 4.1147, MinusLogProbMetric: 4.1147, val_loss: 4.1515, val_MinusLogProbMetric: 4.1515

Epoch 116: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.1147 - MinusLogProbMetric: 4.1147 - val_loss: 4.1515 - val_MinusLogProbMetric: 4.1515 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 117/1000
2023-09-17 23:25:27.278 
Epoch 117/1000 
	 loss: 4.1142, MinusLogProbMetric: 4.1142, val_loss: 4.1650, val_MinusLogProbMetric: 4.1650

Epoch 117: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.1142 - MinusLogProbMetric: 4.1142 - val_loss: 4.1650 - val_MinusLogProbMetric: 4.1650 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 118/1000
2023-09-17 23:26:00.723 
Epoch 118/1000 
	 loss: 4.1223, MinusLogProbMetric: 4.1223, val_loss: 4.1669, val_MinusLogProbMetric: 4.1669

Epoch 118: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.1223 - MinusLogProbMetric: 4.1223 - val_loss: 4.1669 - val_MinusLogProbMetric: 4.1669 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 119/1000
2023-09-17 23:26:33.949 
Epoch 119/1000 
	 loss: 4.1185, MinusLogProbMetric: 4.1185, val_loss: 4.1799, val_MinusLogProbMetric: 4.1799

Epoch 119: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.1185 - MinusLogProbMetric: 4.1185 - val_loss: 4.1799 - val_MinusLogProbMetric: 4.1799 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 120/1000
2023-09-17 23:27:07.821 
Epoch 120/1000 
	 loss: 4.1148, MinusLogProbMetric: 4.1148, val_loss: 4.1730, val_MinusLogProbMetric: 4.1730

Epoch 120: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.1148 - MinusLogProbMetric: 4.1148 - val_loss: 4.1730 - val_MinusLogProbMetric: 4.1730 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 121/1000
2023-09-17 23:27:41.611 
Epoch 121/1000 
	 loss: 4.1217, MinusLogProbMetric: 4.1217, val_loss: 4.1708, val_MinusLogProbMetric: 4.1708

Epoch 121: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.1217 - MinusLogProbMetric: 4.1217 - val_loss: 4.1708 - val_MinusLogProbMetric: 4.1708 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 122/1000
2023-09-17 23:28:14.823 
Epoch 122/1000 
	 loss: 4.1072, MinusLogProbMetric: 4.1072, val_loss: 4.2027, val_MinusLogProbMetric: 4.2027

Epoch 122: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.1072 - MinusLogProbMetric: 4.1072 - val_loss: 4.2027 - val_MinusLogProbMetric: 4.2027 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 123/1000
2023-09-17 23:28:48.905 
Epoch 123/1000 
	 loss: 4.1207, MinusLogProbMetric: 4.1207, val_loss: 4.1756, val_MinusLogProbMetric: 4.1756

Epoch 123: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.1207 - MinusLogProbMetric: 4.1207 - val_loss: 4.1756 - val_MinusLogProbMetric: 4.1756 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 124/1000
2023-09-17 23:29:22.281 
Epoch 124/1000 
	 loss: 4.1148, MinusLogProbMetric: 4.1148, val_loss: 4.1691, val_MinusLogProbMetric: 4.1691

Epoch 124: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.1148 - MinusLogProbMetric: 4.1148 - val_loss: 4.1691 - val_MinusLogProbMetric: 4.1691 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 125/1000
2023-09-17 23:29:55.874 
Epoch 125/1000 
	 loss: 4.1147, MinusLogProbMetric: 4.1147, val_loss: 4.1945, val_MinusLogProbMetric: 4.1945

Epoch 125: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.1147 - MinusLogProbMetric: 4.1147 - val_loss: 4.1945 - val_MinusLogProbMetric: 4.1945 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 126/1000
2023-09-17 23:30:29.627 
Epoch 126/1000 
	 loss: 4.1195, MinusLogProbMetric: 4.1195, val_loss: 4.1762, val_MinusLogProbMetric: 4.1762

Epoch 126: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.1195 - MinusLogProbMetric: 4.1195 - val_loss: 4.1762 - val_MinusLogProbMetric: 4.1762 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 127/1000
2023-09-17 23:31:03.586 
Epoch 127/1000 
	 loss: 4.1229, MinusLogProbMetric: 4.1229, val_loss: 4.2287, val_MinusLogProbMetric: 4.2287

Epoch 127: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.1229 - MinusLogProbMetric: 4.1229 - val_loss: 4.2287 - val_MinusLogProbMetric: 4.2287 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 128/1000
2023-09-17 23:31:36.708 
Epoch 128/1000 
	 loss: 4.1157, MinusLogProbMetric: 4.1157, val_loss: 4.1628, val_MinusLogProbMetric: 4.1628

Epoch 128: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.1157 - MinusLogProbMetric: 4.1157 - val_loss: 4.1628 - val_MinusLogProbMetric: 4.1628 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 129/1000
2023-09-17 23:32:09.790 
Epoch 129/1000 
	 loss: 4.1124, MinusLogProbMetric: 4.1124, val_loss: 4.1757, val_MinusLogProbMetric: 4.1757

Epoch 129: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.1124 - MinusLogProbMetric: 4.1124 - val_loss: 4.1757 - val_MinusLogProbMetric: 4.1757 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 130/1000
2023-09-17 23:32:43.961 
Epoch 130/1000 
	 loss: 4.1106, MinusLogProbMetric: 4.1106, val_loss: 4.1903, val_MinusLogProbMetric: 4.1903

Epoch 130: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.1106 - MinusLogProbMetric: 4.1106 - val_loss: 4.1903 - val_MinusLogProbMetric: 4.1903 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 131/1000
2023-09-17 23:33:17.558 
Epoch 131/1000 
	 loss: 4.1070, MinusLogProbMetric: 4.1070, val_loss: 4.1800, val_MinusLogProbMetric: 4.1800

Epoch 131: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.1070 - MinusLogProbMetric: 4.1070 - val_loss: 4.1800 - val_MinusLogProbMetric: 4.1800 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 132/1000
2023-09-17 23:33:51.596 
Epoch 132/1000 
	 loss: 4.1004, MinusLogProbMetric: 4.1004, val_loss: 4.1869, val_MinusLogProbMetric: 4.1869

Epoch 132: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.1004 - MinusLogProbMetric: 4.1004 - val_loss: 4.1869 - val_MinusLogProbMetric: 4.1869 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 133/1000
2023-09-17 23:34:24.638 
Epoch 133/1000 
	 loss: 4.1111, MinusLogProbMetric: 4.1111, val_loss: 4.2341, val_MinusLogProbMetric: 4.2341

Epoch 133: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.1111 - MinusLogProbMetric: 4.1111 - val_loss: 4.2341 - val_MinusLogProbMetric: 4.2341 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 134/1000
2023-09-17 23:34:57.998 
Epoch 134/1000 
	 loss: 4.1088, MinusLogProbMetric: 4.1088, val_loss: 4.1660, val_MinusLogProbMetric: 4.1660

Epoch 134: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.1088 - MinusLogProbMetric: 4.1088 - val_loss: 4.1660 - val_MinusLogProbMetric: 4.1660 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 135/1000
2023-09-17 23:35:31.366 
Epoch 135/1000 
	 loss: 4.1079, MinusLogProbMetric: 4.1079, val_loss: 4.1944, val_MinusLogProbMetric: 4.1944

Epoch 135: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.1079 - MinusLogProbMetric: 4.1079 - val_loss: 4.1944 - val_MinusLogProbMetric: 4.1944 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 136/1000
2023-09-17 23:36:06.338 
Epoch 136/1000 
	 loss: 4.1034, MinusLogProbMetric: 4.1034, val_loss: 4.1763, val_MinusLogProbMetric: 4.1763

Epoch 136: val_loss did not improve from 4.14574
196/196 - 35s - loss: 4.1034 - MinusLogProbMetric: 4.1034 - val_loss: 4.1763 - val_MinusLogProbMetric: 4.1763 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 137/1000
2023-09-17 23:36:40.054 
Epoch 137/1000 
	 loss: 4.1180, MinusLogProbMetric: 4.1180, val_loss: 4.1754, val_MinusLogProbMetric: 4.1754

Epoch 137: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.1180 - MinusLogProbMetric: 4.1180 - val_loss: 4.1754 - val_MinusLogProbMetric: 4.1754 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 138/1000
2023-09-17 23:37:13.791 
Epoch 138/1000 
	 loss: 4.1035, MinusLogProbMetric: 4.1035, val_loss: 4.2535, val_MinusLogProbMetric: 4.2535

Epoch 138: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.1035 - MinusLogProbMetric: 4.1035 - val_loss: 4.2535 - val_MinusLogProbMetric: 4.2535 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 139/1000
2023-09-17 23:37:47.799 
Epoch 139/1000 
	 loss: 4.1077, MinusLogProbMetric: 4.1077, val_loss: 4.1708, val_MinusLogProbMetric: 4.1708

Epoch 139: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.1077 - MinusLogProbMetric: 4.1077 - val_loss: 4.1708 - val_MinusLogProbMetric: 4.1708 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 140/1000
2023-09-17 23:38:20.756 
Epoch 140/1000 
	 loss: 4.1154, MinusLogProbMetric: 4.1154, val_loss: 4.2250, val_MinusLogProbMetric: 4.2250

Epoch 140: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.1154 - MinusLogProbMetric: 4.1154 - val_loss: 4.2250 - val_MinusLogProbMetric: 4.2250 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 141/1000
2023-09-17 23:38:54.876 
Epoch 141/1000 
	 loss: 4.0965, MinusLogProbMetric: 4.0965, val_loss: 4.1766, val_MinusLogProbMetric: 4.1766

Epoch 141: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.0965 - MinusLogProbMetric: 4.0965 - val_loss: 4.1766 - val_MinusLogProbMetric: 4.1766 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 142/1000
2023-09-17 23:39:28.316 
Epoch 142/1000 
	 loss: 4.1037, MinusLogProbMetric: 4.1037, val_loss: 4.1793, val_MinusLogProbMetric: 4.1793

Epoch 142: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.1037 - MinusLogProbMetric: 4.1037 - val_loss: 4.1793 - val_MinusLogProbMetric: 4.1793 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 143/1000
2023-09-17 23:40:02.242 
Epoch 143/1000 
	 loss: 4.1034, MinusLogProbMetric: 4.1034, val_loss: 4.1913, val_MinusLogProbMetric: 4.1913

Epoch 143: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.1034 - MinusLogProbMetric: 4.1034 - val_loss: 4.1913 - val_MinusLogProbMetric: 4.1913 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 144/1000
2023-09-17 23:40:35.836 
Epoch 144/1000 
	 loss: 4.1034, MinusLogProbMetric: 4.1034, val_loss: 4.1800, val_MinusLogProbMetric: 4.1800

Epoch 144: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.1034 - MinusLogProbMetric: 4.1034 - val_loss: 4.1800 - val_MinusLogProbMetric: 4.1800 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 145/1000
2023-09-17 23:41:09.306 
Epoch 145/1000 
	 loss: 4.0972, MinusLogProbMetric: 4.0972, val_loss: 4.2009, val_MinusLogProbMetric: 4.2009

Epoch 145: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.0972 - MinusLogProbMetric: 4.0972 - val_loss: 4.2009 - val_MinusLogProbMetric: 4.2009 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 146/1000
2023-09-17 23:41:42.374 
Epoch 146/1000 
	 loss: 4.1077, MinusLogProbMetric: 4.1077, val_loss: 4.2347, val_MinusLogProbMetric: 4.2347

Epoch 146: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.1077 - MinusLogProbMetric: 4.1077 - val_loss: 4.2347 - val_MinusLogProbMetric: 4.2347 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 147/1000
2023-09-17 23:42:15.750 
Epoch 147/1000 
	 loss: 4.1077, MinusLogProbMetric: 4.1077, val_loss: 4.2056, val_MinusLogProbMetric: 4.2056

Epoch 147: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.1077 - MinusLogProbMetric: 4.1077 - val_loss: 4.2056 - val_MinusLogProbMetric: 4.2056 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 148/1000
2023-09-17 23:42:48.815 
Epoch 148/1000 
	 loss: 4.1086, MinusLogProbMetric: 4.1086, val_loss: 4.1683, val_MinusLogProbMetric: 4.1683

Epoch 148: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.1086 - MinusLogProbMetric: 4.1086 - val_loss: 4.1683 - val_MinusLogProbMetric: 4.1683 - lr: 0.0010 - 33s/epoch - 169ms/step
Epoch 149/1000
2023-09-17 23:43:21.734 
Epoch 149/1000 
	 loss: 4.0995, MinusLogProbMetric: 4.0995, val_loss: 4.1823, val_MinusLogProbMetric: 4.1823

Epoch 149: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.0995 - MinusLogProbMetric: 4.0995 - val_loss: 4.1823 - val_MinusLogProbMetric: 4.1823 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 150/1000
2023-09-17 23:43:55.312 
Epoch 150/1000 
	 loss: 4.0966, MinusLogProbMetric: 4.0966, val_loss: 4.1692, val_MinusLogProbMetric: 4.1692

Epoch 150: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.0966 - MinusLogProbMetric: 4.0966 - val_loss: 4.1692 - val_MinusLogProbMetric: 4.1692 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 151/1000
2023-09-17 23:44:28.864 
Epoch 151/1000 
	 loss: 4.1021, MinusLogProbMetric: 4.1021, val_loss: 4.1999, val_MinusLogProbMetric: 4.1999

Epoch 151: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.1021 - MinusLogProbMetric: 4.1021 - val_loss: 4.1999 - val_MinusLogProbMetric: 4.1999 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 152/1000
2023-09-17 23:45:02.423 
Epoch 152/1000 
	 loss: 4.0996, MinusLogProbMetric: 4.0996, val_loss: 4.1615, val_MinusLogProbMetric: 4.1615

Epoch 152: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.0996 - MinusLogProbMetric: 4.0996 - val_loss: 4.1615 - val_MinusLogProbMetric: 4.1615 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 153/1000
2023-09-17 23:45:36.360 
Epoch 153/1000 
	 loss: 4.1052, MinusLogProbMetric: 4.1052, val_loss: 4.1719, val_MinusLogProbMetric: 4.1719

Epoch 153: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.1052 - MinusLogProbMetric: 4.1052 - val_loss: 4.1719 - val_MinusLogProbMetric: 4.1719 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 154/1000
2023-09-17 23:46:09.354 
Epoch 154/1000 
	 loss: 4.0966, MinusLogProbMetric: 4.0966, val_loss: 4.1758, val_MinusLogProbMetric: 4.1758

Epoch 154: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.0966 - MinusLogProbMetric: 4.0966 - val_loss: 4.1758 - val_MinusLogProbMetric: 4.1758 - lr: 0.0010 - 33s/epoch - 168ms/step
Epoch 155/1000
2023-09-17 23:46:42.778 
Epoch 155/1000 
	 loss: 4.0933, MinusLogProbMetric: 4.0933, val_loss: 4.1820, val_MinusLogProbMetric: 4.1820

Epoch 155: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.0933 - MinusLogProbMetric: 4.0933 - val_loss: 4.1820 - val_MinusLogProbMetric: 4.1820 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 156/1000
2023-09-17 23:47:16.164 
Epoch 156/1000 
	 loss: 4.0997, MinusLogProbMetric: 4.0997, val_loss: 4.2075, val_MinusLogProbMetric: 4.2075

Epoch 156: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.0997 - MinusLogProbMetric: 4.0997 - val_loss: 4.2075 - val_MinusLogProbMetric: 4.2075 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 157/1000
2023-09-17 23:47:49.618 
Epoch 157/1000 
	 loss: 4.1014, MinusLogProbMetric: 4.1014, val_loss: 4.1989, val_MinusLogProbMetric: 4.1989

Epoch 157: val_loss did not improve from 4.14574
196/196 - 33s - loss: 4.1014 - MinusLogProbMetric: 4.1014 - val_loss: 4.1989 - val_MinusLogProbMetric: 4.1989 - lr: 0.0010 - 33s/epoch - 171ms/step
Epoch 158/1000
2023-09-17 23:48:23.662 
Epoch 158/1000 
	 loss: 4.0931, MinusLogProbMetric: 4.0931, val_loss: 4.2324, val_MinusLogProbMetric: 4.2324

Epoch 158: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.0931 - MinusLogProbMetric: 4.0931 - val_loss: 4.2324 - val_MinusLogProbMetric: 4.2324 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 159/1000
2023-09-17 23:48:57.380 
Epoch 159/1000 
	 loss: 4.0984, MinusLogProbMetric: 4.0984, val_loss: 4.1578, val_MinusLogProbMetric: 4.1578

Epoch 159: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.0984 - MinusLogProbMetric: 4.0984 - val_loss: 4.1578 - val_MinusLogProbMetric: 4.1578 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 160/1000
2023-09-17 23:49:31.491 
Epoch 160/1000 
	 loss: 4.0930, MinusLogProbMetric: 4.0930, val_loss: 4.2132, val_MinusLogProbMetric: 4.2132

Epoch 160: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.0930 - MinusLogProbMetric: 4.0930 - val_loss: 4.2132 - val_MinusLogProbMetric: 4.2132 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 161/1000
2023-09-17 23:50:05.356 
Epoch 161/1000 
	 loss: 4.1041, MinusLogProbMetric: 4.1041, val_loss: 4.2213, val_MinusLogProbMetric: 4.2213

Epoch 161: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.1041 - MinusLogProbMetric: 4.1041 - val_loss: 4.2213 - val_MinusLogProbMetric: 4.2213 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 162/1000
2023-09-17 23:50:39.130 
Epoch 162/1000 
	 loss: 4.1033, MinusLogProbMetric: 4.1033, val_loss: 4.1880, val_MinusLogProbMetric: 4.1880

Epoch 162: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.1033 - MinusLogProbMetric: 4.1033 - val_loss: 4.1880 - val_MinusLogProbMetric: 4.1880 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 163/1000
2023-09-17 23:51:13.167 
Epoch 163/1000 
	 loss: 4.0609, MinusLogProbMetric: 4.0609, val_loss: 4.1744, val_MinusLogProbMetric: 4.1744

Epoch 163: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.0609 - MinusLogProbMetric: 4.0609 - val_loss: 4.1744 - val_MinusLogProbMetric: 4.1744 - lr: 5.0000e-04 - 34s/epoch - 174ms/step
Epoch 164/1000
2023-09-17 23:51:47.015 
Epoch 164/1000 
	 loss: 4.0635, MinusLogProbMetric: 4.0635, val_loss: 4.1558, val_MinusLogProbMetric: 4.1558

Epoch 164: val_loss did not improve from 4.14574
196/196 - 34s - loss: 4.0635 - MinusLogProbMetric: 4.0635 - val_loss: 4.1558 - val_MinusLogProbMetric: 4.1558 - lr: 5.0000e-04 - 34s/epoch - 173ms/step
Epoch 165/1000
2023-09-17 23:52:20.710 
Epoch 165/1000 
	 loss: 4.0543, MinusLogProbMetric: 4.0543, val_loss: 4.1414, val_MinusLogProbMetric: 4.1414

Epoch 165: val_loss improved from 4.14574 to 4.14136, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 34s - loss: 4.0543 - MinusLogProbMetric: 4.0543 - val_loss: 4.1414 - val_MinusLogProbMetric: 4.1414 - lr: 5.0000e-04 - 34s/epoch - 175ms/step
Epoch 166/1000
2023-09-17 23:52:54.437 
Epoch 166/1000 
	 loss: 4.0563, MinusLogProbMetric: 4.0563, val_loss: 4.1654, val_MinusLogProbMetric: 4.1654

Epoch 166: val_loss did not improve from 4.14136
196/196 - 33s - loss: 4.0563 - MinusLogProbMetric: 4.0563 - val_loss: 4.1654 - val_MinusLogProbMetric: 4.1654 - lr: 5.0000e-04 - 33s/epoch - 169ms/step
Epoch 167/1000
2023-09-17 23:53:27.727 
Epoch 167/1000 
	 loss: 4.0526, MinusLogProbMetric: 4.0526, val_loss: 4.1486, val_MinusLogProbMetric: 4.1486

Epoch 167: val_loss did not improve from 4.14136
196/196 - 33s - loss: 4.0526 - MinusLogProbMetric: 4.0526 - val_loss: 4.1486 - val_MinusLogProbMetric: 4.1486 - lr: 5.0000e-04 - 33s/epoch - 170ms/step
Epoch 168/1000
2023-09-17 23:54:01.329 
Epoch 168/1000 
	 loss: 4.0571, MinusLogProbMetric: 4.0571, val_loss: 4.1364, val_MinusLogProbMetric: 4.1364

Epoch 168: val_loss improved from 4.14136 to 4.13641, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_153/weights/best_weights.h5
196/196 - 34s - loss: 4.0571 - MinusLogProbMetric: 4.0571 - val_loss: 4.1364 - val_MinusLogProbMetric: 4.1364 - lr: 5.0000e-04 - 34s/epoch - 174ms/step
Epoch 169/1000
2023-09-17 23:54:35.224 
Epoch 169/1000 
	 loss: 4.0552, MinusLogProbMetric: 4.0552, val_loss: 4.1484, val_MinusLogProbMetric: 4.1484

Epoch 169: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0552 - MinusLogProbMetric: 4.0552 - val_loss: 4.1484 - val_MinusLogProbMetric: 4.1484 - lr: 5.0000e-04 - 33s/epoch - 170ms/step
Epoch 170/1000
2023-09-17 23:55:08.706 
Epoch 170/1000 
	 loss: 4.0568, MinusLogProbMetric: 4.0568, val_loss: 4.1372, val_MinusLogProbMetric: 4.1372

Epoch 170: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0568 - MinusLogProbMetric: 4.0568 - val_loss: 4.1372 - val_MinusLogProbMetric: 4.1372 - lr: 5.0000e-04 - 33s/epoch - 171ms/step
Epoch 171/1000
2023-09-17 23:55:42.227 
Epoch 171/1000 
	 loss: 4.0558, MinusLogProbMetric: 4.0558, val_loss: 4.1616, val_MinusLogProbMetric: 4.1616

Epoch 171: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0558 - MinusLogProbMetric: 4.0558 - val_loss: 4.1616 - val_MinusLogProbMetric: 4.1616 - lr: 5.0000e-04 - 34s/epoch - 171ms/step
Epoch 172/1000
2023-09-17 23:56:15.626 
Epoch 172/1000 
	 loss: 4.0547, MinusLogProbMetric: 4.0547, val_loss: 4.1654, val_MinusLogProbMetric: 4.1654

Epoch 172: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0547 - MinusLogProbMetric: 4.0547 - val_loss: 4.1654 - val_MinusLogProbMetric: 4.1654 - lr: 5.0000e-04 - 33s/epoch - 170ms/step
Epoch 173/1000
2023-09-17 23:56:49.139 
Epoch 173/1000 
	 loss: 4.0549, MinusLogProbMetric: 4.0549, val_loss: 4.1491, val_MinusLogProbMetric: 4.1491

Epoch 173: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0549 - MinusLogProbMetric: 4.0549 - val_loss: 4.1491 - val_MinusLogProbMetric: 4.1491 - lr: 5.0000e-04 - 34s/epoch - 171ms/step
Epoch 174/1000
2023-09-17 23:57:22.387 
Epoch 174/1000 
	 loss: 4.0531, MinusLogProbMetric: 4.0531, val_loss: 4.1473, val_MinusLogProbMetric: 4.1473

Epoch 174: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0531 - MinusLogProbMetric: 4.0531 - val_loss: 4.1473 - val_MinusLogProbMetric: 4.1473 - lr: 5.0000e-04 - 33s/epoch - 170ms/step
Epoch 175/1000
2023-09-17 23:57:55.934 
Epoch 175/1000 
	 loss: 4.0542, MinusLogProbMetric: 4.0542, val_loss: 4.1519, val_MinusLogProbMetric: 4.1519

Epoch 175: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0542 - MinusLogProbMetric: 4.0542 - val_loss: 4.1519 - val_MinusLogProbMetric: 4.1519 - lr: 5.0000e-04 - 34s/epoch - 171ms/step
Epoch 176/1000
2023-09-17 23:58:29.353 
Epoch 176/1000 
	 loss: 4.0517, MinusLogProbMetric: 4.0517, val_loss: 4.1407, val_MinusLogProbMetric: 4.1407

Epoch 176: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0517 - MinusLogProbMetric: 4.0517 - val_loss: 4.1407 - val_MinusLogProbMetric: 4.1407 - lr: 5.0000e-04 - 33s/epoch - 171ms/step
Epoch 177/1000
2023-09-17 23:59:02.831 
Epoch 177/1000 
	 loss: 4.0521, MinusLogProbMetric: 4.0521, val_loss: 4.1444, val_MinusLogProbMetric: 4.1444

Epoch 177: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0521 - MinusLogProbMetric: 4.0521 - val_loss: 4.1444 - val_MinusLogProbMetric: 4.1444 - lr: 5.0000e-04 - 33s/epoch - 171ms/step
Epoch 178/1000
2023-09-17 23:59:36.407 
Epoch 178/1000 
	 loss: 4.0525, MinusLogProbMetric: 4.0525, val_loss: 4.1612, val_MinusLogProbMetric: 4.1612

Epoch 178: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0525 - MinusLogProbMetric: 4.0525 - val_loss: 4.1612 - val_MinusLogProbMetric: 4.1612 - lr: 5.0000e-04 - 34s/epoch - 171ms/step
Epoch 179/1000
2023-09-18 00:00:09.935 
Epoch 179/1000 
	 loss: 4.0515, MinusLogProbMetric: 4.0515, val_loss: 4.1540, val_MinusLogProbMetric: 4.1540

Epoch 179: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0515 - MinusLogProbMetric: 4.0515 - val_loss: 4.1540 - val_MinusLogProbMetric: 4.1540 - lr: 5.0000e-04 - 34s/epoch - 171ms/step
Epoch 180/1000
2023-09-18 00:00:43.428 
Epoch 180/1000 
	 loss: 4.0565, MinusLogProbMetric: 4.0565, val_loss: 4.1576, val_MinusLogProbMetric: 4.1576

Epoch 180: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0565 - MinusLogProbMetric: 4.0565 - val_loss: 4.1576 - val_MinusLogProbMetric: 4.1576 - lr: 5.0000e-04 - 33s/epoch - 171ms/step
Epoch 181/1000
2023-09-18 00:01:16.946 
Epoch 181/1000 
	 loss: 4.0532, MinusLogProbMetric: 4.0532, val_loss: 4.1622, val_MinusLogProbMetric: 4.1622

Epoch 181: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0532 - MinusLogProbMetric: 4.0532 - val_loss: 4.1622 - val_MinusLogProbMetric: 4.1622 - lr: 5.0000e-04 - 34s/epoch - 171ms/step
Epoch 182/1000
2023-09-18 00:01:50.283 
Epoch 182/1000 
	 loss: 4.0524, MinusLogProbMetric: 4.0524, val_loss: 4.1595, val_MinusLogProbMetric: 4.1595

Epoch 182: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0524 - MinusLogProbMetric: 4.0524 - val_loss: 4.1595 - val_MinusLogProbMetric: 4.1595 - lr: 5.0000e-04 - 33s/epoch - 170ms/step
Epoch 183/1000
2023-09-18 00:02:23.520 
Epoch 183/1000 
	 loss: 4.0561, MinusLogProbMetric: 4.0561, val_loss: 4.1520, val_MinusLogProbMetric: 4.1520

Epoch 183: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0561 - MinusLogProbMetric: 4.0561 - val_loss: 4.1520 - val_MinusLogProbMetric: 4.1520 - lr: 5.0000e-04 - 33s/epoch - 170ms/step
Epoch 184/1000
2023-09-18 00:02:57.233 
Epoch 184/1000 
	 loss: 4.0519, MinusLogProbMetric: 4.0519, val_loss: 4.1504, val_MinusLogProbMetric: 4.1504

Epoch 184: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0519 - MinusLogProbMetric: 4.0519 - val_loss: 4.1504 - val_MinusLogProbMetric: 4.1504 - lr: 5.0000e-04 - 34s/epoch - 172ms/step
Epoch 185/1000
2023-09-18 00:03:30.052 
Epoch 185/1000 
	 loss: 4.0514, MinusLogProbMetric: 4.0514, val_loss: 4.1803, val_MinusLogProbMetric: 4.1803

Epoch 185: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0514 - MinusLogProbMetric: 4.0514 - val_loss: 4.1803 - val_MinusLogProbMetric: 4.1803 - lr: 5.0000e-04 - 33s/epoch - 167ms/step
Epoch 186/1000
2023-09-18 00:04:02.912 
Epoch 186/1000 
	 loss: 4.0499, MinusLogProbMetric: 4.0499, val_loss: 4.1643, val_MinusLogProbMetric: 4.1643

Epoch 186: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0499 - MinusLogProbMetric: 4.0499 - val_loss: 4.1643 - val_MinusLogProbMetric: 4.1643 - lr: 5.0000e-04 - 33s/epoch - 168ms/step
Epoch 187/1000
2023-09-18 00:04:36.331 
Epoch 187/1000 
	 loss: 4.0479, MinusLogProbMetric: 4.0479, val_loss: 4.1633, val_MinusLogProbMetric: 4.1633

Epoch 187: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0479 - MinusLogProbMetric: 4.0479 - val_loss: 4.1633 - val_MinusLogProbMetric: 4.1633 - lr: 5.0000e-04 - 33s/epoch - 170ms/step
Epoch 188/1000
2023-09-18 00:05:09.538 
Epoch 188/1000 
	 loss: 4.0572, MinusLogProbMetric: 4.0572, val_loss: 4.1518, val_MinusLogProbMetric: 4.1518

Epoch 188: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0572 - MinusLogProbMetric: 4.0572 - val_loss: 4.1518 - val_MinusLogProbMetric: 4.1518 - lr: 5.0000e-04 - 33s/epoch - 169ms/step
Epoch 189/1000
2023-09-18 00:05:43.156 
Epoch 189/1000 
	 loss: 4.0499, MinusLogProbMetric: 4.0499, val_loss: 4.1435, val_MinusLogProbMetric: 4.1435

Epoch 189: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0499 - MinusLogProbMetric: 4.0499 - val_loss: 4.1435 - val_MinusLogProbMetric: 4.1435 - lr: 5.0000e-04 - 34s/epoch - 171ms/step
Epoch 190/1000
2023-09-18 00:06:16.369 
Epoch 190/1000 
	 loss: 4.0504, MinusLogProbMetric: 4.0504, val_loss: 4.1545, val_MinusLogProbMetric: 4.1545

Epoch 190: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0504 - MinusLogProbMetric: 4.0504 - val_loss: 4.1545 - val_MinusLogProbMetric: 4.1545 - lr: 5.0000e-04 - 33s/epoch - 169ms/step
Epoch 191/1000
2023-09-18 00:06:50.164 
Epoch 191/1000 
	 loss: 4.0528, MinusLogProbMetric: 4.0528, val_loss: 4.1606, val_MinusLogProbMetric: 4.1606

Epoch 191: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0528 - MinusLogProbMetric: 4.0528 - val_loss: 4.1606 - val_MinusLogProbMetric: 4.1606 - lr: 5.0000e-04 - 34s/epoch - 172ms/step
Epoch 192/1000
2023-09-18 00:07:23.314 
Epoch 192/1000 
	 loss: 4.0476, MinusLogProbMetric: 4.0476, val_loss: 4.1463, val_MinusLogProbMetric: 4.1463

Epoch 192: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0476 - MinusLogProbMetric: 4.0476 - val_loss: 4.1463 - val_MinusLogProbMetric: 4.1463 - lr: 5.0000e-04 - 33s/epoch - 169ms/step
Epoch 193/1000
2023-09-18 00:07:56.898 
Epoch 193/1000 
	 loss: 4.0507, MinusLogProbMetric: 4.0507, val_loss: 4.1577, val_MinusLogProbMetric: 4.1577

Epoch 193: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0507 - MinusLogProbMetric: 4.0507 - val_loss: 4.1577 - val_MinusLogProbMetric: 4.1577 - lr: 5.0000e-04 - 34s/epoch - 171ms/step
Epoch 194/1000
2023-09-18 00:08:30.057 
Epoch 194/1000 
	 loss: 4.0520, MinusLogProbMetric: 4.0520, val_loss: 4.1772, val_MinusLogProbMetric: 4.1772

Epoch 194: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0520 - MinusLogProbMetric: 4.0520 - val_loss: 4.1772 - val_MinusLogProbMetric: 4.1772 - lr: 5.0000e-04 - 33s/epoch - 169ms/step
Epoch 195/1000
2023-09-18 00:09:03.433 
Epoch 195/1000 
	 loss: 4.0515, MinusLogProbMetric: 4.0515, val_loss: 4.1561, val_MinusLogProbMetric: 4.1561

Epoch 195: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0515 - MinusLogProbMetric: 4.0515 - val_loss: 4.1561 - val_MinusLogProbMetric: 4.1561 - lr: 5.0000e-04 - 33s/epoch - 170ms/step
Epoch 196/1000
2023-09-18 00:09:37.098 
Epoch 196/1000 
	 loss: 4.0507, MinusLogProbMetric: 4.0507, val_loss: 4.1451, val_MinusLogProbMetric: 4.1451

Epoch 196: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0507 - MinusLogProbMetric: 4.0507 - val_loss: 4.1451 - val_MinusLogProbMetric: 4.1451 - lr: 5.0000e-04 - 34s/epoch - 172ms/step
Epoch 197/1000
2023-09-18 00:10:10.160 
Epoch 197/1000 
	 loss: 4.0504, MinusLogProbMetric: 4.0504, val_loss: 4.1641, val_MinusLogProbMetric: 4.1641

Epoch 197: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0504 - MinusLogProbMetric: 4.0504 - val_loss: 4.1641 - val_MinusLogProbMetric: 4.1641 - lr: 5.0000e-04 - 33s/epoch - 169ms/step
Epoch 198/1000
2023-09-18 00:10:43.100 
Epoch 198/1000 
	 loss: 4.0501, MinusLogProbMetric: 4.0501, val_loss: 4.1711, val_MinusLogProbMetric: 4.1711

Epoch 198: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0501 - MinusLogProbMetric: 4.0501 - val_loss: 4.1711 - val_MinusLogProbMetric: 4.1711 - lr: 5.0000e-04 - 33s/epoch - 168ms/step
Epoch 199/1000
2023-09-18 00:11:16.214 
Epoch 199/1000 
	 loss: 4.0466, MinusLogProbMetric: 4.0466, val_loss: 4.1553, val_MinusLogProbMetric: 4.1553

Epoch 199: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0466 - MinusLogProbMetric: 4.0466 - val_loss: 4.1553 - val_MinusLogProbMetric: 4.1553 - lr: 5.0000e-04 - 33s/epoch - 169ms/step
Epoch 200/1000
2023-09-18 00:11:49.778 
Epoch 200/1000 
	 loss: 4.0502, MinusLogProbMetric: 4.0502, val_loss: 4.1611, val_MinusLogProbMetric: 4.1611

Epoch 200: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0502 - MinusLogProbMetric: 4.0502 - val_loss: 4.1611 - val_MinusLogProbMetric: 4.1611 - lr: 5.0000e-04 - 34s/epoch - 171ms/step
Epoch 201/1000
2023-09-18 00:12:23.797 
Epoch 201/1000 
	 loss: 4.0464, MinusLogProbMetric: 4.0464, val_loss: 4.1533, val_MinusLogProbMetric: 4.1533

Epoch 201: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0464 - MinusLogProbMetric: 4.0464 - val_loss: 4.1533 - val_MinusLogProbMetric: 4.1533 - lr: 5.0000e-04 - 34s/epoch - 174ms/step
Epoch 202/1000
2023-09-18 00:12:57.313 
Epoch 202/1000 
	 loss: 4.0445, MinusLogProbMetric: 4.0445, val_loss: 4.1634, val_MinusLogProbMetric: 4.1634

Epoch 202: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0445 - MinusLogProbMetric: 4.0445 - val_loss: 4.1634 - val_MinusLogProbMetric: 4.1634 - lr: 5.0000e-04 - 34s/epoch - 171ms/step
Epoch 203/1000
2023-09-18 00:13:31.502 
Epoch 203/1000 
	 loss: 4.0471, MinusLogProbMetric: 4.0471, val_loss: 4.1535, val_MinusLogProbMetric: 4.1535

Epoch 203: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0471 - MinusLogProbMetric: 4.0471 - val_loss: 4.1535 - val_MinusLogProbMetric: 4.1535 - lr: 5.0000e-04 - 34s/epoch - 174ms/step
Epoch 204/1000
2023-09-18 00:14:05.315 
Epoch 204/1000 
	 loss: 4.0526, MinusLogProbMetric: 4.0526, val_loss: 4.1527, val_MinusLogProbMetric: 4.1527

Epoch 204: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0526 - MinusLogProbMetric: 4.0526 - val_loss: 4.1527 - val_MinusLogProbMetric: 4.1527 - lr: 5.0000e-04 - 34s/epoch - 173ms/step
Epoch 205/1000
2023-09-18 00:14:39.476 
Epoch 205/1000 
	 loss: 4.0482, MinusLogProbMetric: 4.0482, val_loss: 4.1672, val_MinusLogProbMetric: 4.1672

Epoch 205: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0482 - MinusLogProbMetric: 4.0482 - val_loss: 4.1672 - val_MinusLogProbMetric: 4.1672 - lr: 5.0000e-04 - 34s/epoch - 174ms/step
Epoch 206/1000
2023-09-18 00:15:13.690 
Epoch 206/1000 
	 loss: 4.0475, MinusLogProbMetric: 4.0475, val_loss: 4.1686, val_MinusLogProbMetric: 4.1686

Epoch 206: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0475 - MinusLogProbMetric: 4.0475 - val_loss: 4.1686 - val_MinusLogProbMetric: 4.1686 - lr: 5.0000e-04 - 34s/epoch - 175ms/step
Epoch 207/1000
2023-09-18 00:15:47.304 
Epoch 207/1000 
	 loss: 4.0457, MinusLogProbMetric: 4.0457, val_loss: 4.1494, val_MinusLogProbMetric: 4.1494

Epoch 207: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0457 - MinusLogProbMetric: 4.0457 - val_loss: 4.1494 - val_MinusLogProbMetric: 4.1494 - lr: 5.0000e-04 - 34s/epoch - 172ms/step
Epoch 208/1000
2023-09-18 00:16:21.195 
Epoch 208/1000 
	 loss: 4.0435, MinusLogProbMetric: 4.0435, val_loss: 4.1812, val_MinusLogProbMetric: 4.1812

Epoch 208: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0435 - MinusLogProbMetric: 4.0435 - val_loss: 4.1812 - val_MinusLogProbMetric: 4.1812 - lr: 5.0000e-04 - 34s/epoch - 173ms/step
Epoch 209/1000
2023-09-18 00:16:54.549 
Epoch 209/1000 
	 loss: 4.0514, MinusLogProbMetric: 4.0514, val_loss: 4.1684, val_MinusLogProbMetric: 4.1684

Epoch 209: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0514 - MinusLogProbMetric: 4.0514 - val_loss: 4.1684 - val_MinusLogProbMetric: 4.1684 - lr: 5.0000e-04 - 33s/epoch - 170ms/step
Epoch 210/1000
2023-09-18 00:17:27.731 
Epoch 210/1000 
	 loss: 4.0503, MinusLogProbMetric: 4.0503, val_loss: 4.1745, val_MinusLogProbMetric: 4.1745

Epoch 210: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0503 - MinusLogProbMetric: 4.0503 - val_loss: 4.1745 - val_MinusLogProbMetric: 4.1745 - lr: 5.0000e-04 - 33s/epoch - 169ms/step
Epoch 211/1000
2023-09-18 00:17:59.279 
Epoch 211/1000 
	 loss: 4.0455, MinusLogProbMetric: 4.0455, val_loss: 4.1618, val_MinusLogProbMetric: 4.1618

Epoch 211: val_loss did not improve from 4.13641
196/196 - 32s - loss: 4.0455 - MinusLogProbMetric: 4.0455 - val_loss: 4.1618 - val_MinusLogProbMetric: 4.1618 - lr: 5.0000e-04 - 32s/epoch - 161ms/step
Epoch 212/1000
2023-09-18 00:18:31.289 
Epoch 212/1000 
	 loss: 4.0468, MinusLogProbMetric: 4.0468, val_loss: 4.1610, val_MinusLogProbMetric: 4.1610

Epoch 212: val_loss did not improve from 4.13641
196/196 - 32s - loss: 4.0468 - MinusLogProbMetric: 4.0468 - val_loss: 4.1610 - val_MinusLogProbMetric: 4.1610 - lr: 5.0000e-04 - 32s/epoch - 163ms/step
Epoch 213/1000
2023-09-18 00:19:00.730 
Epoch 213/1000 
	 loss: 4.0493, MinusLogProbMetric: 4.0493, val_loss: 4.1522, val_MinusLogProbMetric: 4.1522

Epoch 213: val_loss did not improve from 4.13641
196/196 - 29s - loss: 4.0493 - MinusLogProbMetric: 4.0493 - val_loss: 4.1522 - val_MinusLogProbMetric: 4.1522 - lr: 5.0000e-04 - 29s/epoch - 150ms/step
Epoch 214/1000
2023-09-18 00:19:30.590 
Epoch 214/1000 
	 loss: 4.0450, MinusLogProbMetric: 4.0450, val_loss: 4.1561, val_MinusLogProbMetric: 4.1561

Epoch 214: val_loss did not improve from 4.13641
196/196 - 30s - loss: 4.0450 - MinusLogProbMetric: 4.0450 - val_loss: 4.1561 - val_MinusLogProbMetric: 4.1561 - lr: 5.0000e-04 - 30s/epoch - 152ms/step
Epoch 215/1000
2023-09-18 00:20:03.612 
Epoch 215/1000 
	 loss: 4.0475, MinusLogProbMetric: 4.0475, val_loss: 4.1816, val_MinusLogProbMetric: 4.1816

Epoch 215: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0475 - MinusLogProbMetric: 4.0475 - val_loss: 4.1816 - val_MinusLogProbMetric: 4.1816 - lr: 5.0000e-04 - 33s/epoch - 168ms/step
Epoch 216/1000
2023-09-18 00:20:37.273 
Epoch 216/1000 
	 loss: 4.0496, MinusLogProbMetric: 4.0496, val_loss: 4.1729, val_MinusLogProbMetric: 4.1729

Epoch 216: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0496 - MinusLogProbMetric: 4.0496 - val_loss: 4.1729 - val_MinusLogProbMetric: 4.1729 - lr: 5.0000e-04 - 34s/epoch - 172ms/step
Epoch 217/1000
2023-09-18 00:21:11.620 
Epoch 217/1000 
	 loss: 4.0412, MinusLogProbMetric: 4.0412, val_loss: 4.1636, val_MinusLogProbMetric: 4.1636

Epoch 217: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0412 - MinusLogProbMetric: 4.0412 - val_loss: 4.1636 - val_MinusLogProbMetric: 4.1636 - lr: 5.0000e-04 - 34s/epoch - 175ms/step
Epoch 218/1000
2023-09-18 00:21:44.773 
Epoch 218/1000 
	 loss: 4.0461, MinusLogProbMetric: 4.0461, val_loss: 4.1551, val_MinusLogProbMetric: 4.1551

Epoch 218: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0461 - MinusLogProbMetric: 4.0461 - val_loss: 4.1551 - val_MinusLogProbMetric: 4.1551 - lr: 5.0000e-04 - 33s/epoch - 169ms/step
Epoch 219/1000
2023-09-18 00:22:18.176 
Epoch 219/1000 
	 loss: 4.0259, MinusLogProbMetric: 4.0259, val_loss: 4.1484, val_MinusLogProbMetric: 4.1484

Epoch 219: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0259 - MinusLogProbMetric: 4.0259 - val_loss: 4.1484 - val_MinusLogProbMetric: 4.1484 - lr: 2.5000e-04 - 33s/epoch - 170ms/step
Epoch 220/1000
2023-09-18 00:22:52.395 
Epoch 220/1000 
	 loss: 4.0239, MinusLogProbMetric: 4.0239, val_loss: 4.1517, val_MinusLogProbMetric: 4.1517

Epoch 220: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0239 - MinusLogProbMetric: 4.0239 - val_loss: 4.1517 - val_MinusLogProbMetric: 4.1517 - lr: 2.5000e-04 - 34s/epoch - 175ms/step
Epoch 221/1000
2023-09-18 00:23:26.599 
Epoch 221/1000 
	 loss: 4.0261, MinusLogProbMetric: 4.0261, val_loss: 4.1512, val_MinusLogProbMetric: 4.1512

Epoch 221: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0261 - MinusLogProbMetric: 4.0261 - val_loss: 4.1512 - val_MinusLogProbMetric: 4.1512 - lr: 2.5000e-04 - 34s/epoch - 175ms/step
Epoch 222/1000
2023-09-18 00:24:00.645 
Epoch 222/1000 
	 loss: 4.0238, MinusLogProbMetric: 4.0238, val_loss: 4.1618, val_MinusLogProbMetric: 4.1618

Epoch 222: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0238 - MinusLogProbMetric: 4.0238 - val_loss: 4.1618 - val_MinusLogProbMetric: 4.1618 - lr: 2.5000e-04 - 34s/epoch - 174ms/step
Epoch 223/1000
2023-09-18 00:24:34.907 
Epoch 223/1000 
	 loss: 4.0248, MinusLogProbMetric: 4.0248, val_loss: 4.1478, val_MinusLogProbMetric: 4.1478

Epoch 223: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0248 - MinusLogProbMetric: 4.0248 - val_loss: 4.1478 - val_MinusLogProbMetric: 4.1478 - lr: 2.5000e-04 - 34s/epoch - 175ms/step
Epoch 224/1000
2023-09-18 00:25:09.007 
Epoch 224/1000 
	 loss: 4.0240, MinusLogProbMetric: 4.0240, val_loss: 4.1479, val_MinusLogProbMetric: 4.1479

Epoch 224: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0240 - MinusLogProbMetric: 4.0240 - val_loss: 4.1479 - val_MinusLogProbMetric: 4.1479 - lr: 2.5000e-04 - 34s/epoch - 174ms/step
Epoch 225/1000
2023-09-18 00:25:42.987 
Epoch 225/1000 
	 loss: 4.0251, MinusLogProbMetric: 4.0251, val_loss: 4.1595, val_MinusLogProbMetric: 4.1595

Epoch 225: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0251 - MinusLogProbMetric: 4.0251 - val_loss: 4.1595 - val_MinusLogProbMetric: 4.1595 - lr: 2.5000e-04 - 34s/epoch - 173ms/step
Epoch 226/1000
2023-09-18 00:26:16.673 
Epoch 226/1000 
	 loss: 4.0241, MinusLogProbMetric: 4.0241, val_loss: 4.1526, val_MinusLogProbMetric: 4.1526

Epoch 226: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0241 - MinusLogProbMetric: 4.0241 - val_loss: 4.1526 - val_MinusLogProbMetric: 4.1526 - lr: 2.5000e-04 - 34s/epoch - 172ms/step
Epoch 227/1000
2023-09-18 00:26:49.837 
Epoch 227/1000 
	 loss: 4.0241, MinusLogProbMetric: 4.0241, val_loss: 4.1512, val_MinusLogProbMetric: 4.1512

Epoch 227: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0241 - MinusLogProbMetric: 4.0241 - val_loss: 4.1512 - val_MinusLogProbMetric: 4.1512 - lr: 2.5000e-04 - 33s/epoch - 169ms/step
Epoch 228/1000
2023-09-18 00:27:23.718 
Epoch 228/1000 
	 loss: 4.0253, MinusLogProbMetric: 4.0253, val_loss: 4.1542, val_MinusLogProbMetric: 4.1542

Epoch 228: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0253 - MinusLogProbMetric: 4.0253 - val_loss: 4.1542 - val_MinusLogProbMetric: 4.1542 - lr: 2.5000e-04 - 34s/epoch - 173ms/step
Epoch 229/1000
2023-09-18 00:27:57.848 
Epoch 229/1000 
	 loss: 4.0264, MinusLogProbMetric: 4.0264, val_loss: 4.1482, val_MinusLogProbMetric: 4.1482

Epoch 229: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0264 - MinusLogProbMetric: 4.0264 - val_loss: 4.1482 - val_MinusLogProbMetric: 4.1482 - lr: 2.5000e-04 - 34s/epoch - 174ms/step
Epoch 230/1000
2023-09-18 00:28:30.815 
Epoch 230/1000 
	 loss: 4.0231, MinusLogProbMetric: 4.0231, val_loss: 4.1536, val_MinusLogProbMetric: 4.1536

Epoch 230: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0231 - MinusLogProbMetric: 4.0231 - val_loss: 4.1536 - val_MinusLogProbMetric: 4.1536 - lr: 2.5000e-04 - 33s/epoch - 168ms/step
Epoch 231/1000
2023-09-18 00:29:04.711 
Epoch 231/1000 
	 loss: 4.0257, MinusLogProbMetric: 4.0257, val_loss: 4.1499, val_MinusLogProbMetric: 4.1499

Epoch 231: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0257 - MinusLogProbMetric: 4.0257 - val_loss: 4.1499 - val_MinusLogProbMetric: 4.1499 - lr: 2.5000e-04 - 34s/epoch - 173ms/step
Epoch 232/1000
2023-09-18 00:29:38.192 
Epoch 232/1000 
	 loss: 4.0227, MinusLogProbMetric: 4.0227, val_loss: 4.1546, val_MinusLogProbMetric: 4.1546

Epoch 232: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0227 - MinusLogProbMetric: 4.0227 - val_loss: 4.1546 - val_MinusLogProbMetric: 4.1546 - lr: 2.5000e-04 - 33s/epoch - 171ms/step
Epoch 233/1000
2023-09-18 00:30:12.268 
Epoch 233/1000 
	 loss: 4.0224, MinusLogProbMetric: 4.0224, val_loss: 4.1534, val_MinusLogProbMetric: 4.1534

Epoch 233: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0224 - MinusLogProbMetric: 4.0224 - val_loss: 4.1534 - val_MinusLogProbMetric: 4.1534 - lr: 2.5000e-04 - 34s/epoch - 174ms/step
Epoch 234/1000
2023-09-18 00:30:45.360 
Epoch 234/1000 
	 loss: 4.0232, MinusLogProbMetric: 4.0232, val_loss: 4.1553, val_MinusLogProbMetric: 4.1553

Epoch 234: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0232 - MinusLogProbMetric: 4.0232 - val_loss: 4.1553 - val_MinusLogProbMetric: 4.1553 - lr: 2.5000e-04 - 33s/epoch - 169ms/step
Epoch 235/1000
2023-09-18 00:31:18.877 
Epoch 235/1000 
	 loss: 4.0230, MinusLogProbMetric: 4.0230, val_loss: 4.1503, val_MinusLogProbMetric: 4.1503

Epoch 235: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0230 - MinusLogProbMetric: 4.0230 - val_loss: 4.1503 - val_MinusLogProbMetric: 4.1503 - lr: 2.5000e-04 - 34s/epoch - 171ms/step
Epoch 236/1000
2023-09-18 00:31:52.794 
Epoch 236/1000 
	 loss: 4.0229, MinusLogProbMetric: 4.0229, val_loss: 4.1513, val_MinusLogProbMetric: 4.1513

Epoch 236: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0229 - MinusLogProbMetric: 4.0229 - val_loss: 4.1513 - val_MinusLogProbMetric: 4.1513 - lr: 2.5000e-04 - 34s/epoch - 173ms/step
Epoch 237/1000
2023-09-18 00:32:26.027 
Epoch 237/1000 
	 loss: 4.0238, MinusLogProbMetric: 4.0238, val_loss: 4.1514, val_MinusLogProbMetric: 4.1514

Epoch 237: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0238 - MinusLogProbMetric: 4.0238 - val_loss: 4.1514 - val_MinusLogProbMetric: 4.1514 - lr: 2.5000e-04 - 33s/epoch - 170ms/step
Epoch 238/1000
2023-09-18 00:32:59.446 
Epoch 238/1000 
	 loss: 4.0217, MinusLogProbMetric: 4.0217, val_loss: 4.1495, val_MinusLogProbMetric: 4.1495

Epoch 238: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0217 - MinusLogProbMetric: 4.0217 - val_loss: 4.1495 - val_MinusLogProbMetric: 4.1495 - lr: 2.5000e-04 - 33s/epoch - 171ms/step
Epoch 239/1000
2023-09-18 00:33:32.977 
Epoch 239/1000 
	 loss: 4.0208, MinusLogProbMetric: 4.0208, val_loss: 4.1504, val_MinusLogProbMetric: 4.1504

Epoch 239: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0208 - MinusLogProbMetric: 4.0208 - val_loss: 4.1504 - val_MinusLogProbMetric: 4.1504 - lr: 2.5000e-04 - 34s/epoch - 171ms/step
Epoch 240/1000
2023-09-18 00:34:06.247 
Epoch 240/1000 
	 loss: 4.0225, MinusLogProbMetric: 4.0225, val_loss: 4.1524, val_MinusLogProbMetric: 4.1524

Epoch 240: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0225 - MinusLogProbMetric: 4.0225 - val_loss: 4.1524 - val_MinusLogProbMetric: 4.1524 - lr: 2.5000e-04 - 33s/epoch - 170ms/step
Epoch 241/1000
2023-09-18 00:34:39.509 
Epoch 241/1000 
	 loss: 4.0212, MinusLogProbMetric: 4.0212, val_loss: 4.1667, val_MinusLogProbMetric: 4.1667

Epoch 241: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0212 - MinusLogProbMetric: 4.0212 - val_loss: 4.1667 - val_MinusLogProbMetric: 4.1667 - lr: 2.5000e-04 - 33s/epoch - 170ms/step
Epoch 242/1000
2023-09-18 00:35:13.074 
Epoch 242/1000 
	 loss: 4.0217, MinusLogProbMetric: 4.0217, val_loss: 4.1489, val_MinusLogProbMetric: 4.1489

Epoch 242: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0217 - MinusLogProbMetric: 4.0217 - val_loss: 4.1489 - val_MinusLogProbMetric: 4.1489 - lr: 2.5000e-04 - 34s/epoch - 171ms/step
Epoch 243/1000
2023-09-18 00:35:46.401 
Epoch 243/1000 
	 loss: 4.0222, MinusLogProbMetric: 4.0222, val_loss: 4.1608, val_MinusLogProbMetric: 4.1608

Epoch 243: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0222 - MinusLogProbMetric: 4.0222 - val_loss: 4.1608 - val_MinusLogProbMetric: 4.1608 - lr: 2.5000e-04 - 33s/epoch - 170ms/step
Epoch 244/1000
2023-09-18 00:36:19.777 
Epoch 244/1000 
	 loss: 4.0235, MinusLogProbMetric: 4.0235, val_loss: 4.1567, val_MinusLogProbMetric: 4.1567

Epoch 244: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0235 - MinusLogProbMetric: 4.0235 - val_loss: 4.1567 - val_MinusLogProbMetric: 4.1567 - lr: 2.5000e-04 - 33s/epoch - 170ms/step
Epoch 245/1000
2023-09-18 00:36:53.503 
Epoch 245/1000 
	 loss: 4.0214, MinusLogProbMetric: 4.0214, val_loss: 4.1529, val_MinusLogProbMetric: 4.1529

Epoch 245: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0214 - MinusLogProbMetric: 4.0214 - val_loss: 4.1529 - val_MinusLogProbMetric: 4.1529 - lr: 2.5000e-04 - 34s/epoch - 172ms/step
Epoch 246/1000
2023-09-18 00:37:27.290 
Epoch 246/1000 
	 loss: 4.0218, MinusLogProbMetric: 4.0218, val_loss: 4.1597, val_MinusLogProbMetric: 4.1597

Epoch 246: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0218 - MinusLogProbMetric: 4.0218 - val_loss: 4.1597 - val_MinusLogProbMetric: 4.1597 - lr: 2.5000e-04 - 34s/epoch - 172ms/step
Epoch 247/1000
2023-09-18 00:38:00.834 
Epoch 247/1000 
	 loss: 4.0210, MinusLogProbMetric: 4.0210, val_loss: 4.1591, val_MinusLogProbMetric: 4.1591

Epoch 247: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0210 - MinusLogProbMetric: 4.0210 - val_loss: 4.1591 - val_MinusLogProbMetric: 4.1591 - lr: 2.5000e-04 - 34s/epoch - 171ms/step
Epoch 248/1000
2023-09-18 00:38:34.633 
Epoch 248/1000 
	 loss: 4.0197, MinusLogProbMetric: 4.0197, val_loss: 4.1510, val_MinusLogProbMetric: 4.1510

Epoch 248: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0197 - MinusLogProbMetric: 4.0197 - val_loss: 4.1510 - val_MinusLogProbMetric: 4.1510 - lr: 2.5000e-04 - 34s/epoch - 172ms/step
Epoch 249/1000
2023-09-18 00:39:06.481 
Epoch 249/1000 
	 loss: 4.0210, MinusLogProbMetric: 4.0210, val_loss: 4.1599, val_MinusLogProbMetric: 4.1599

Epoch 249: val_loss did not improve from 4.13641
196/196 - 32s - loss: 4.0210 - MinusLogProbMetric: 4.0210 - val_loss: 4.1599 - val_MinusLogProbMetric: 4.1599 - lr: 2.5000e-04 - 32s/epoch - 162ms/step
Epoch 250/1000
2023-09-18 00:39:34.935 
Epoch 250/1000 
	 loss: 4.0216, MinusLogProbMetric: 4.0216, val_loss: 4.1523, val_MinusLogProbMetric: 4.1523

Epoch 250: val_loss did not improve from 4.13641
196/196 - 28s - loss: 4.0216 - MinusLogProbMetric: 4.0216 - val_loss: 4.1523 - val_MinusLogProbMetric: 4.1523 - lr: 2.5000e-04 - 28s/epoch - 145ms/step
Epoch 251/1000
2023-09-18 00:40:08.297 
Epoch 251/1000 
	 loss: 4.0214, MinusLogProbMetric: 4.0214, val_loss: 4.1610, val_MinusLogProbMetric: 4.1610

Epoch 251: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0214 - MinusLogProbMetric: 4.0214 - val_loss: 4.1610 - val_MinusLogProbMetric: 4.1610 - lr: 2.5000e-04 - 33s/epoch - 170ms/step
Epoch 252/1000
2023-09-18 00:40:39.388 
Epoch 252/1000 
	 loss: 4.0186, MinusLogProbMetric: 4.0186, val_loss: 4.1519, val_MinusLogProbMetric: 4.1519

Epoch 252: val_loss did not improve from 4.13641
196/196 - 31s - loss: 4.0186 - MinusLogProbMetric: 4.0186 - val_loss: 4.1519 - val_MinusLogProbMetric: 4.1519 - lr: 2.5000e-04 - 31s/epoch - 159ms/step
Epoch 253/1000
2023-09-18 00:41:09.366 
Epoch 253/1000 
	 loss: 4.0203, MinusLogProbMetric: 4.0203, val_loss: 4.1556, val_MinusLogProbMetric: 4.1556

Epoch 253: val_loss did not improve from 4.13641
196/196 - 30s - loss: 4.0203 - MinusLogProbMetric: 4.0203 - val_loss: 4.1556 - val_MinusLogProbMetric: 4.1556 - lr: 2.5000e-04 - 30s/epoch - 153ms/step
Epoch 254/1000
2023-09-18 00:41:43.350 
Epoch 254/1000 
	 loss: 4.0215, MinusLogProbMetric: 4.0215, val_loss: 4.1554, val_MinusLogProbMetric: 4.1554

Epoch 254: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0215 - MinusLogProbMetric: 4.0215 - val_loss: 4.1554 - val_MinusLogProbMetric: 4.1554 - lr: 2.5000e-04 - 34s/epoch - 173ms/step
Epoch 255/1000
2023-09-18 00:42:17.830 
Epoch 255/1000 
	 loss: 4.0207, MinusLogProbMetric: 4.0207, val_loss: 4.1594, val_MinusLogProbMetric: 4.1594

Epoch 255: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0207 - MinusLogProbMetric: 4.0207 - val_loss: 4.1594 - val_MinusLogProbMetric: 4.1594 - lr: 2.5000e-04 - 34s/epoch - 176ms/step
Epoch 256/1000
2023-09-18 00:42:51.506 
Epoch 256/1000 
	 loss: 4.0224, MinusLogProbMetric: 4.0224, val_loss: 4.1526, val_MinusLogProbMetric: 4.1526

Epoch 256: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0224 - MinusLogProbMetric: 4.0224 - val_loss: 4.1526 - val_MinusLogProbMetric: 4.1526 - lr: 2.5000e-04 - 34s/epoch - 172ms/step
Epoch 257/1000
2023-09-18 00:43:25.067 
Epoch 257/1000 
	 loss: 4.0198, MinusLogProbMetric: 4.0198, val_loss: 4.1496, val_MinusLogProbMetric: 4.1496

Epoch 257: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0198 - MinusLogProbMetric: 4.0198 - val_loss: 4.1496 - val_MinusLogProbMetric: 4.1496 - lr: 2.5000e-04 - 34s/epoch - 171ms/step
Epoch 258/1000
2023-09-18 00:43:58.643 
Epoch 258/1000 
	 loss: 4.0211, MinusLogProbMetric: 4.0211, val_loss: 4.1510, val_MinusLogProbMetric: 4.1510

Epoch 258: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0211 - MinusLogProbMetric: 4.0211 - val_loss: 4.1510 - val_MinusLogProbMetric: 4.1510 - lr: 2.5000e-04 - 34s/epoch - 171ms/step
Epoch 259/1000
2023-09-18 00:44:32.500 
Epoch 259/1000 
	 loss: 4.0193, MinusLogProbMetric: 4.0193, val_loss: 4.1528, val_MinusLogProbMetric: 4.1528

Epoch 259: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0193 - MinusLogProbMetric: 4.0193 - val_loss: 4.1528 - val_MinusLogProbMetric: 4.1528 - lr: 2.5000e-04 - 34s/epoch - 173ms/step
Epoch 260/1000
2023-09-18 00:45:05.861 
Epoch 260/1000 
	 loss: 4.0196, MinusLogProbMetric: 4.0196, val_loss: 4.1587, val_MinusLogProbMetric: 4.1587

Epoch 260: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0196 - MinusLogProbMetric: 4.0196 - val_loss: 4.1587 - val_MinusLogProbMetric: 4.1587 - lr: 2.5000e-04 - 33s/epoch - 170ms/step
Epoch 261/1000
2023-09-18 00:45:39.278 
Epoch 261/1000 
	 loss: 4.0200, MinusLogProbMetric: 4.0200, val_loss: 4.1507, val_MinusLogProbMetric: 4.1507

Epoch 261: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0200 - MinusLogProbMetric: 4.0200 - val_loss: 4.1507 - val_MinusLogProbMetric: 4.1507 - lr: 2.5000e-04 - 33s/epoch - 170ms/step
Epoch 262/1000
2023-09-18 00:46:13.391 
Epoch 262/1000 
	 loss: 4.0180, MinusLogProbMetric: 4.0180, val_loss: 4.1595, val_MinusLogProbMetric: 4.1595

Epoch 262: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0180 - MinusLogProbMetric: 4.0180 - val_loss: 4.1595 - val_MinusLogProbMetric: 4.1595 - lr: 2.5000e-04 - 34s/epoch - 174ms/step
Epoch 263/1000
2023-09-18 00:46:47.343 
Epoch 263/1000 
	 loss: 4.0189, MinusLogProbMetric: 4.0189, val_loss: 4.1587, val_MinusLogProbMetric: 4.1587

Epoch 263: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0189 - MinusLogProbMetric: 4.0189 - val_loss: 4.1587 - val_MinusLogProbMetric: 4.1587 - lr: 2.5000e-04 - 34s/epoch - 173ms/step
Epoch 264/1000
2023-09-18 00:47:21.249 
Epoch 264/1000 
	 loss: 4.0198, MinusLogProbMetric: 4.0198, val_loss: 4.1558, val_MinusLogProbMetric: 4.1558

Epoch 264: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0198 - MinusLogProbMetric: 4.0198 - val_loss: 4.1558 - val_MinusLogProbMetric: 4.1558 - lr: 2.5000e-04 - 34s/epoch - 173ms/step
Epoch 265/1000
2023-09-18 00:47:54.611 
Epoch 265/1000 
	 loss: 4.0179, MinusLogProbMetric: 4.0179, val_loss: 4.1577, val_MinusLogProbMetric: 4.1577

Epoch 265: val_loss did not improve from 4.13641
196/196 - 33s - loss: 4.0179 - MinusLogProbMetric: 4.0179 - val_loss: 4.1577 - val_MinusLogProbMetric: 4.1577 - lr: 2.5000e-04 - 33s/epoch - 170ms/step
Epoch 266/1000
2023-09-18 00:48:28.892 
Epoch 266/1000 
	 loss: 4.0175, MinusLogProbMetric: 4.0175, val_loss: 4.1613, val_MinusLogProbMetric: 4.1613

Epoch 266: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0175 - MinusLogProbMetric: 4.0175 - val_loss: 4.1613 - val_MinusLogProbMetric: 4.1613 - lr: 2.5000e-04 - 34s/epoch - 175ms/step
Epoch 267/1000
2023-09-18 00:49:03.012 
Epoch 267/1000 
	 loss: 4.0180, MinusLogProbMetric: 4.0180, val_loss: 4.1562, val_MinusLogProbMetric: 4.1562

Epoch 267: val_loss did not improve from 4.13641
196/196 - 34s - loss: 4.0180 - MinusLogProbMetric: 4.0180 - val_loss: 4.1562 - val_MinusLogProbMetric: 4.1562 - lr: 2.5000e-04 - 34s/epoch - 174ms/step
Epoch 268/1000
2023-09-18 00:49:37.346 
Epoch 268/1000 
	 loss: 4.0200, MinusLogProbMetric: 4.0200, val_loss: 4.1601, val_MinusLogProbMetric: 4.1601

Epoch 268: val_loss did not improve from 4.13641
Restoring model weights from the end of the best epoch: 168.
196/196 - 35s - loss: 4.0200 - MinusLogProbMetric: 4.0200 - val_loss: 4.1601 - val_MinusLogProbMetric: 4.1601 - lr: 2.5000e-04 - 35s/epoch - 177ms/step
Epoch 268: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 9.45006638718769 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 6.800240297801793 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 4.122116583865136 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7faf11b75e10> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 11.055369527079165 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 5.7023801889736205 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 4.329855711199343 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fae8cac3010> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 933.
Model trained in 9032.25 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

Plots done in 22.19 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 76.86 s.
===========
Run 153/720 done in 9114.11 s.
===========

Directory ../../results/CsplineN_new/run_154/ already exists.
Skipping it.
===========
Run 154/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_155/ already exists.
Skipping it.
===========
Run 155/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_156/ already exists.
Skipping it.
===========
Run 156/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_157/ already exists.
Skipping it.
===========
Run 157/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_158/ already exists.
Skipping it.
===========
Run 158/720 already exists. Skipping it.
===========

===========
Generating train data for run 159.
===========
Train data generated in 0.20 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 8)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_159/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 933}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_159/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 0.60277855,  7.2496796 ,  7.311799  , ...,  6.471478  ,
         4.4766264 ,  7.6941757 ],
       [ 9.891631  ,  5.07585   ,  7.9255137 , ..., 10.410634  ,
         0.19630367,  0.2451933 ],
       [ 9.692471  ,  3.8958035 ,  7.898749  , ...,  9.102936  ,
         0.31555456,  1.1337659 ],
       ...,
       [ 0.69027716,  7.826899  ,  7.581092  , ...,  7.7249126 ,
         4.6991906 ,  7.747929  ],
       [ 5.4378247 ,  7.457948  ,  6.062617  , ...,  6.4751306 ,
         4.9251475 ,  9.483738  ],
       [ 0.8388093 ,  8.2027235 ,  8.194429  , ...,  7.5383434 ,
         4.5117407 ,  7.89007   ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_159/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_159
self.data_kwargs: {'seed': 933}
self.x_data: [[5.358355   6.019778   5.8569536  ... 7.515295   3.9379482  8.654374  ]
 [5.3684006  7.0696135  5.9023     ... 6.403228   4.3043017  8.278582  ]
 [0.5474414  9.273294   8.089687   ... 6.9538503  4.605232   7.7114205 ]
 ...
 [0.0460346  8.452679   7.684837   ... 7.5281396  4.5184097  8.003926  ]
 [0.35366723 9.14325    6.7288957  ... 8.428171   4.626755   7.9396896 ]
 [0.02297392 8.22993    8.40971    ... 8.825319   4.5680537  8.07164   ]]
self.y_data: []
self.ndims: 8
Model defined.
Model: "model_123"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_124 (InputLayer)      [(None, 8)]               0         
                                                                 
 log_prob_layer_13 (LogProbL  (None,)                  517240    
 ayer)                                                           
                                                                 
=================================================================
Total params: 517,240
Trainable params: 517,240
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_13/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_13'")
self.model: <keras.engine.functional.Functional object at 0x7fae5cedff40>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fae4dc5e920>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fae4dc5e920>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7faee8f6e590>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fae8ca37910>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fae8ca37e80>, <keras.callbacks.ModelCheckpoint object at 0x7fae8ca37f40>, <keras.callbacks.EarlyStopping object at 0x7fae8ca37e50>, <keras.callbacks.ReduceLROnPlateau object at 0x7fae8ca37e20>, <keras.callbacks.TerminateOnNaN object at 0x7fae8ca401f0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 0.60277855,  7.2496796 ,  7.311799  , ...,  6.471478  ,
         4.4766264 ,  7.6941757 ],
       [ 9.891631  ,  5.07585   ,  7.9255137 , ..., 10.410634  ,
         0.19630367,  0.2451933 ],
       [ 9.692471  ,  3.8958035 ,  7.898749  , ...,  9.102936  ,
         0.31555456,  1.1337659 ],
       ...,
       [ 0.69027716,  7.826899  ,  7.581092  , ...,  7.7249126 ,
         4.6991906 ,  7.747929  ],
       [ 5.4378247 ,  7.457948  ,  6.062617  , ...,  6.4751306 ,
         4.9251475 ,  9.483738  ],
       [ 0.8388093 ,  8.2027235 ,  8.194429  , ...,  7.5383434 ,
         4.5117407 ,  7.89007   ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_159/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 159/720 with hyperparameters:
timestamp = 2023-09-18 00:51:07.150707
ndims = 8
seed_train = 933
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 517240
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [5.358355  6.019778  5.8569536 3.3511574 3.8962636 7.515295  3.9379482
 8.654374 ]
Epoch 1/1000
2023-09-18 00:55:53.196 
Epoch 1/1000 
	 loss: 30.4806, MinusLogProbMetric: 30.4806, val_loss: 7.9482, val_MinusLogProbMetric: 7.9482

Epoch 1: val_loss improved from inf to 7.94817, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 287s - loss: 30.4806 - MinusLogProbMetric: 30.4806 - val_loss: 7.9482 - val_MinusLogProbMetric: 7.9482 - lr: 0.0010 - 287s/epoch - 1s/step
Epoch 2/1000
2023-09-18 00:57:07.122 
Epoch 2/1000 
	 loss: 6.8764, MinusLogProbMetric: 6.8764, val_loss: 7.0311, val_MinusLogProbMetric: 7.0311

Epoch 2: val_loss improved from 7.94817 to 7.03106, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 73s - loss: 6.8764 - MinusLogProbMetric: 6.8764 - val_loss: 7.0311 - val_MinusLogProbMetric: 7.0311 - lr: 0.0010 - 73s/epoch - 374ms/step
Epoch 3/1000
2023-09-18 00:58:30.120 
Epoch 3/1000 
	 loss: 6.0146, MinusLogProbMetric: 6.0146, val_loss: 5.5716, val_MinusLogProbMetric: 5.5716

Epoch 3: val_loss improved from 7.03106 to 5.57164, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 83s - loss: 6.0146 - MinusLogProbMetric: 6.0146 - val_loss: 5.5716 - val_MinusLogProbMetric: 5.5716 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 4/1000
2023-09-18 00:59:51.977 
Epoch 4/1000 
	 loss: 5.6620, MinusLogProbMetric: 5.6620, val_loss: 5.9161, val_MinusLogProbMetric: 5.9161

Epoch 4: val_loss did not improve from 5.57164
196/196 - 80s - loss: 5.6620 - MinusLogProbMetric: 5.6620 - val_loss: 5.9161 - val_MinusLogProbMetric: 5.9161 - lr: 0.0010 - 80s/epoch - 410ms/step
Epoch 5/1000
2023-09-18 01:01:13.562 
Epoch 5/1000 
	 loss: 5.2922, MinusLogProbMetric: 5.2922, val_loss: 4.9584, val_MinusLogProbMetric: 4.9584

Epoch 5: val_loss improved from 5.57164 to 4.95844, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 83s - loss: 5.2922 - MinusLogProbMetric: 5.2922 - val_loss: 4.9584 - val_MinusLogProbMetric: 4.9584 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 6/1000
2023-09-18 01:02:35.674 
Epoch 6/1000 
	 loss: 5.1762, MinusLogProbMetric: 5.1762, val_loss: 5.0315, val_MinusLogProbMetric: 5.0315

Epoch 6: val_loss did not improve from 4.95844
196/196 - 80s - loss: 5.1762 - MinusLogProbMetric: 5.1762 - val_loss: 5.0315 - val_MinusLogProbMetric: 5.0315 - lr: 0.0010 - 80s/epoch - 411ms/step
Epoch 7/1000
2023-09-18 01:03:56.910 
Epoch 7/1000 
	 loss: 5.0963, MinusLogProbMetric: 5.0963, val_loss: 5.2898, val_MinusLogProbMetric: 5.2898

Epoch 7: val_loss did not improve from 4.95844
196/196 - 81s - loss: 5.0963 - MinusLogProbMetric: 5.0963 - val_loss: 5.2898 - val_MinusLogProbMetric: 5.2898 - lr: 0.0010 - 81s/epoch - 414ms/step
Epoch 8/1000
2023-09-18 01:05:19.185 
Epoch 8/1000 
	 loss: 5.0442, MinusLogProbMetric: 5.0442, val_loss: 4.9178, val_MinusLogProbMetric: 4.9178

Epoch 8: val_loss improved from 4.95844 to 4.91784, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 84s - loss: 5.0442 - MinusLogProbMetric: 5.0442 - val_loss: 4.9178 - val_MinusLogProbMetric: 4.9178 - lr: 0.0010 - 84s/epoch - 428ms/step
Epoch 9/1000
2023-09-18 01:06:42.943 
Epoch 9/1000 
	 loss: 4.8494, MinusLogProbMetric: 4.8494, val_loss: 4.7614, val_MinusLogProbMetric: 4.7614

Epoch 9: val_loss improved from 4.91784 to 4.76139, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 84s - loss: 4.8494 - MinusLogProbMetric: 4.8494 - val_loss: 4.7614 - val_MinusLogProbMetric: 4.7614 - lr: 0.0010 - 84s/epoch - 426ms/step
Epoch 10/1000
2023-09-18 01:08:07.307 
Epoch 10/1000 
	 loss: 4.8035, MinusLogProbMetric: 4.8035, val_loss: 4.7028, val_MinusLogProbMetric: 4.7028

Epoch 10: val_loss improved from 4.76139 to 4.70284, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 84s - loss: 4.8035 - MinusLogProbMetric: 4.8035 - val_loss: 4.7028 - val_MinusLogProbMetric: 4.7028 - lr: 0.0010 - 84s/epoch - 431ms/step
Epoch 11/1000
2023-09-18 01:09:33.040 
Epoch 11/1000 
	 loss: 4.8600, MinusLogProbMetric: 4.8600, val_loss: 4.7517, val_MinusLogProbMetric: 4.7517

Epoch 11: val_loss did not improve from 4.70284
196/196 - 84s - loss: 4.8600 - MinusLogProbMetric: 4.8600 - val_loss: 4.7517 - val_MinusLogProbMetric: 4.7517 - lr: 0.0010 - 84s/epoch - 429ms/step
Epoch 12/1000
2023-09-18 01:10:56.717 
Epoch 12/1000 
	 loss: 4.7565, MinusLogProbMetric: 4.7565, val_loss: 4.7349, val_MinusLogProbMetric: 4.7349

Epoch 12: val_loss did not improve from 4.70284
196/196 - 84s - loss: 4.7565 - MinusLogProbMetric: 4.7565 - val_loss: 4.7349 - val_MinusLogProbMetric: 4.7349 - lr: 0.0010 - 84s/epoch - 427ms/step
Epoch 13/1000
2023-09-18 01:12:20.897 
Epoch 13/1000 
	 loss: 4.6308, MinusLogProbMetric: 4.6308, val_loss: 4.4878, val_MinusLogProbMetric: 4.4878

Epoch 13: val_loss improved from 4.70284 to 4.48780, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 86s - loss: 4.6308 - MinusLogProbMetric: 4.6308 - val_loss: 4.4878 - val_MinusLogProbMetric: 4.4878 - lr: 0.0010 - 86s/epoch - 439ms/step
Epoch 14/1000
2023-09-18 01:13:46.528 
Epoch 14/1000 
	 loss: 4.7412, MinusLogProbMetric: 4.7412, val_loss: 5.3882, val_MinusLogProbMetric: 5.3882

Epoch 14: val_loss did not improve from 4.48780
196/196 - 84s - loss: 4.7412 - MinusLogProbMetric: 4.7412 - val_loss: 5.3882 - val_MinusLogProbMetric: 5.3882 - lr: 0.0010 - 84s/epoch - 427ms/step
Epoch 15/1000
2023-09-18 01:15:10.459 
Epoch 15/1000 
	 loss: 4.6608, MinusLogProbMetric: 4.6608, val_loss: 4.5443, val_MinusLogProbMetric: 4.5443

Epoch 15: val_loss did not improve from 4.48780
196/196 - 84s - loss: 4.6608 - MinusLogProbMetric: 4.6608 - val_loss: 4.5443 - val_MinusLogProbMetric: 4.5443 - lr: 0.0010 - 84s/epoch - 428ms/step
Epoch 16/1000
2023-09-18 01:16:33.695 
Epoch 16/1000 
	 loss: 4.5525, MinusLogProbMetric: 4.5525, val_loss: 4.5413, val_MinusLogProbMetric: 4.5413

Epoch 16: val_loss did not improve from 4.48780
196/196 - 83s - loss: 4.5525 - MinusLogProbMetric: 4.5525 - val_loss: 4.5413 - val_MinusLogProbMetric: 4.5413 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 17/1000
2023-09-18 01:17:56.798 
Epoch 17/1000 
	 loss: 4.5621, MinusLogProbMetric: 4.5621, val_loss: 4.6352, val_MinusLogProbMetric: 4.6352

Epoch 17: val_loss did not improve from 4.48780
196/196 - 83s - loss: 4.5621 - MinusLogProbMetric: 4.5621 - val_loss: 4.6352 - val_MinusLogProbMetric: 4.6352 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 18/1000
2023-09-18 01:19:19.921 
Epoch 18/1000 
	 loss: 4.5282, MinusLogProbMetric: 4.5282, val_loss: 4.4517, val_MinusLogProbMetric: 4.4517

Epoch 18: val_loss improved from 4.48780 to 4.45170, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 85s - loss: 4.5282 - MinusLogProbMetric: 4.5282 - val_loss: 4.4517 - val_MinusLogProbMetric: 4.4517 - lr: 0.0010 - 85s/epoch - 432ms/step
Epoch 19/1000
2023-09-18 01:20:44.589 
Epoch 19/1000 
	 loss: 4.6038, MinusLogProbMetric: 4.6038, val_loss: 4.4654, val_MinusLogProbMetric: 4.4654

Epoch 19: val_loss did not improve from 4.45170
196/196 - 83s - loss: 4.6038 - MinusLogProbMetric: 4.6038 - val_loss: 4.4654 - val_MinusLogProbMetric: 4.4654 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 20/1000
2023-09-18 01:22:03.719 
Epoch 20/1000 
	 loss: 4.4675, MinusLogProbMetric: 4.4675, val_loss: 4.4271, val_MinusLogProbMetric: 4.4271

Epoch 20: val_loss improved from 4.45170 to 4.42712, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 80s - loss: 4.4675 - MinusLogProbMetric: 4.4675 - val_loss: 4.4271 - val_MinusLogProbMetric: 4.4271 - lr: 0.0010 - 80s/epoch - 410ms/step
Epoch 21/1000
2023-09-18 01:23:17.075 
Epoch 21/1000 
	 loss: 4.4633, MinusLogProbMetric: 4.4633, val_loss: 4.5027, val_MinusLogProbMetric: 4.5027

Epoch 21: val_loss did not improve from 4.42712
196/196 - 72s - loss: 4.4633 - MinusLogProbMetric: 4.4633 - val_loss: 4.5027 - val_MinusLogProbMetric: 4.5027 - lr: 0.0010 - 72s/epoch - 368ms/step
Epoch 22/1000
2023-09-18 01:24:39.997 
Epoch 22/1000 
	 loss: 4.5129, MinusLogProbMetric: 4.5129, val_loss: 4.5393, val_MinusLogProbMetric: 4.5393

Epoch 22: val_loss did not improve from 4.42712
196/196 - 83s - loss: 4.5129 - MinusLogProbMetric: 4.5129 - val_loss: 4.5393 - val_MinusLogProbMetric: 4.5393 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 23/1000
2023-09-18 01:26:03.420 
Epoch 23/1000 
	 loss: 4.4304, MinusLogProbMetric: 4.4304, val_loss: 4.4172, val_MinusLogProbMetric: 4.4172

Epoch 23: val_loss improved from 4.42712 to 4.41718, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 85s - loss: 4.4304 - MinusLogProbMetric: 4.4304 - val_loss: 4.4172 - val_MinusLogProbMetric: 4.4172 - lr: 0.0010 - 85s/epoch - 433ms/step
Epoch 24/1000
2023-09-18 01:27:27.809 
Epoch 24/1000 
	 loss: 4.4549, MinusLogProbMetric: 4.4549, val_loss: 4.3553, val_MinusLogProbMetric: 4.3553

Epoch 24: val_loss improved from 4.41718 to 4.35535, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 84s - loss: 4.4549 - MinusLogProbMetric: 4.4549 - val_loss: 4.3553 - val_MinusLogProbMetric: 4.3553 - lr: 0.0010 - 84s/epoch - 430ms/step
Epoch 25/1000
2023-09-18 01:28:51.213 
Epoch 25/1000 
	 loss: 4.3917, MinusLogProbMetric: 4.3917, val_loss: 4.6512, val_MinusLogProbMetric: 4.6512

Epoch 25: val_loss did not improve from 4.35535
196/196 - 82s - loss: 4.3917 - MinusLogProbMetric: 4.3917 - val_loss: 4.6512 - val_MinusLogProbMetric: 4.6512 - lr: 0.0010 - 82s/epoch - 418ms/step
Epoch 26/1000
2023-09-18 01:30:14.072 
Epoch 26/1000 
	 loss: 4.4732, MinusLogProbMetric: 4.4732, val_loss: 4.3257, val_MinusLogProbMetric: 4.3257

Epoch 26: val_loss improved from 4.35535 to 4.32565, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 84s - loss: 4.4732 - MinusLogProbMetric: 4.4732 - val_loss: 4.3257 - val_MinusLogProbMetric: 4.3257 - lr: 0.0010 - 84s/epoch - 430ms/step
Epoch 27/1000
2023-09-18 01:31:38.119 
Epoch 27/1000 
	 loss: 4.3814, MinusLogProbMetric: 4.3814, val_loss: 4.4198, val_MinusLogProbMetric: 4.4198

Epoch 27: val_loss did not improve from 4.32565
196/196 - 83s - loss: 4.3814 - MinusLogProbMetric: 4.3814 - val_loss: 4.4198 - val_MinusLogProbMetric: 4.4198 - lr: 0.0010 - 83s/epoch - 421ms/step
Epoch 28/1000
2023-09-18 01:32:54.177 
Epoch 28/1000 
	 loss: 4.4001, MinusLogProbMetric: 4.4001, val_loss: 4.4819, val_MinusLogProbMetric: 4.4819

Epoch 28: val_loss did not improve from 4.32565
196/196 - 76s - loss: 4.4001 - MinusLogProbMetric: 4.4001 - val_loss: 4.4819 - val_MinusLogProbMetric: 4.4819 - lr: 0.0010 - 76s/epoch - 388ms/step
Epoch 29/1000
2023-09-18 01:34:08.753 
Epoch 29/1000 
	 loss: 4.4030, MinusLogProbMetric: 4.4030, val_loss: 4.6255, val_MinusLogProbMetric: 4.6255

Epoch 29: val_loss did not improve from 4.32565
196/196 - 75s - loss: 4.4030 - MinusLogProbMetric: 4.4030 - val_loss: 4.6255 - val_MinusLogProbMetric: 4.6255 - lr: 0.0010 - 75s/epoch - 380ms/step
Epoch 30/1000
2023-09-18 01:35:30.599 
Epoch 30/1000 
	 loss: 4.3647, MinusLogProbMetric: 4.3647, val_loss: 4.3148, val_MinusLogProbMetric: 4.3148

Epoch 30: val_loss improved from 4.32565 to 4.31483, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 83s - loss: 4.3647 - MinusLogProbMetric: 4.3647 - val_loss: 4.3148 - val_MinusLogProbMetric: 4.3148 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 31/1000
2023-09-18 01:36:56.099 
Epoch 31/1000 
	 loss: 4.3497, MinusLogProbMetric: 4.3497, val_loss: 4.6420, val_MinusLogProbMetric: 4.6420

Epoch 31: val_loss did not improve from 4.31483
196/196 - 84s - loss: 4.3497 - MinusLogProbMetric: 4.3497 - val_loss: 4.6420 - val_MinusLogProbMetric: 4.6420 - lr: 0.0010 - 84s/epoch - 429ms/step
Epoch 32/1000
2023-09-18 01:38:20.223 
Epoch 32/1000 
	 loss: 4.3665, MinusLogProbMetric: 4.3665, val_loss: 4.3617, val_MinusLogProbMetric: 4.3617

Epoch 32: val_loss did not improve from 4.31483
196/196 - 84s - loss: 4.3665 - MinusLogProbMetric: 4.3665 - val_loss: 4.3617 - val_MinusLogProbMetric: 4.3617 - lr: 0.0010 - 84s/epoch - 429ms/step
Epoch 33/1000
2023-09-18 01:39:44.584 
Epoch 33/1000 
	 loss: 4.3364, MinusLogProbMetric: 4.3364, val_loss: 4.2528, val_MinusLogProbMetric: 4.2528

Epoch 33: val_loss improved from 4.31483 to 4.25282, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 86s - loss: 4.3364 - MinusLogProbMetric: 4.3364 - val_loss: 4.2528 - val_MinusLogProbMetric: 4.2528 - lr: 0.0010 - 86s/epoch - 438ms/step
Epoch 34/1000
2023-09-18 01:41:10.419 
Epoch 34/1000 
	 loss: 4.3238, MinusLogProbMetric: 4.3238, val_loss: 4.4447, val_MinusLogProbMetric: 4.4447

Epoch 34: val_loss did not improve from 4.25282
196/196 - 84s - loss: 4.3238 - MinusLogProbMetric: 4.3238 - val_loss: 4.4447 - val_MinusLogProbMetric: 4.4447 - lr: 0.0010 - 84s/epoch - 430ms/step
Epoch 35/1000
2023-09-18 01:42:33.563 
Epoch 35/1000 
	 loss: 4.3377, MinusLogProbMetric: 4.3377, val_loss: 4.2953, val_MinusLogProbMetric: 4.2953

Epoch 35: val_loss did not improve from 4.25282
196/196 - 83s - loss: 4.3377 - MinusLogProbMetric: 4.3377 - val_loss: 4.2953 - val_MinusLogProbMetric: 4.2953 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 36/1000
2023-09-18 01:43:57.444 
Epoch 36/1000 
	 loss: 4.3256, MinusLogProbMetric: 4.3256, val_loss: 4.3785, val_MinusLogProbMetric: 4.3785

Epoch 36: val_loss did not improve from 4.25282
196/196 - 84s - loss: 4.3256 - MinusLogProbMetric: 4.3256 - val_loss: 4.3785 - val_MinusLogProbMetric: 4.3785 - lr: 0.0010 - 84s/epoch - 428ms/step
Epoch 37/1000
2023-09-18 01:45:20.772 
Epoch 37/1000 
	 loss: 4.2971, MinusLogProbMetric: 4.2971, val_loss: 4.3965, val_MinusLogProbMetric: 4.3965

Epoch 37: val_loss did not improve from 4.25282
196/196 - 83s - loss: 4.2971 - MinusLogProbMetric: 4.2971 - val_loss: 4.3965 - val_MinusLogProbMetric: 4.3965 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 38/1000
2023-09-18 01:46:44.877 
Epoch 38/1000 
	 loss: 4.2776, MinusLogProbMetric: 4.2776, val_loss: 4.2517, val_MinusLogProbMetric: 4.2517

Epoch 38: val_loss improved from 4.25282 to 4.25171, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 86s - loss: 4.2776 - MinusLogProbMetric: 4.2776 - val_loss: 4.2517 - val_MinusLogProbMetric: 4.2517 - lr: 0.0010 - 86s/epoch - 437ms/step
Epoch 39/1000
2023-09-18 01:48:09.894 
Epoch 39/1000 
	 loss: 4.2850, MinusLogProbMetric: 4.2850, val_loss: 4.3392, val_MinusLogProbMetric: 4.3392

Epoch 39: val_loss did not improve from 4.25171
196/196 - 83s - loss: 4.2850 - MinusLogProbMetric: 4.2850 - val_loss: 4.3392 - val_MinusLogProbMetric: 4.3392 - lr: 0.0010 - 83s/epoch - 426ms/step
Epoch 40/1000
2023-09-18 01:49:33.445 
Epoch 40/1000 
	 loss: 4.3008, MinusLogProbMetric: 4.3008, val_loss: 4.2739, val_MinusLogProbMetric: 4.2739

Epoch 40: val_loss did not improve from 4.25171
196/196 - 84s - loss: 4.3008 - MinusLogProbMetric: 4.3008 - val_loss: 4.2739 - val_MinusLogProbMetric: 4.2739 - lr: 0.0010 - 84s/epoch - 426ms/step
Epoch 41/1000
2023-09-18 01:50:56.672 
Epoch 41/1000 
	 loss: 4.2567, MinusLogProbMetric: 4.2567, val_loss: 4.2805, val_MinusLogProbMetric: 4.2805

Epoch 41: val_loss did not improve from 4.25171
196/196 - 83s - loss: 4.2567 - MinusLogProbMetric: 4.2567 - val_loss: 4.2805 - val_MinusLogProbMetric: 4.2805 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 42/1000
2023-09-18 01:52:18.050 
Epoch 42/1000 
	 loss: 4.2701, MinusLogProbMetric: 4.2701, val_loss: 4.6318, val_MinusLogProbMetric: 4.6318

Epoch 42: val_loss did not improve from 4.25171
196/196 - 81s - loss: 4.2701 - MinusLogProbMetric: 4.2701 - val_loss: 4.6318 - val_MinusLogProbMetric: 4.6318 - lr: 0.0010 - 81s/epoch - 415ms/step
Epoch 43/1000
2023-09-18 01:53:41.443 
Epoch 43/1000 
	 loss: 4.2849, MinusLogProbMetric: 4.2849, val_loss: 4.2446, val_MinusLogProbMetric: 4.2446

Epoch 43: val_loss improved from 4.25171 to 4.24460, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 85s - loss: 4.2849 - MinusLogProbMetric: 4.2849 - val_loss: 4.2446 - val_MinusLogProbMetric: 4.2446 - lr: 0.0010 - 85s/epoch - 433ms/step
Epoch 44/1000
2023-09-18 01:55:06.837 
Epoch 44/1000 
	 loss: 4.2572, MinusLogProbMetric: 4.2572, val_loss: 4.2650, val_MinusLogProbMetric: 4.2650

Epoch 44: val_loss did not improve from 4.24460
196/196 - 84s - loss: 4.2572 - MinusLogProbMetric: 4.2572 - val_loss: 4.2650 - val_MinusLogProbMetric: 4.2650 - lr: 0.0010 - 84s/epoch - 428ms/step
Epoch 45/1000
2023-09-18 01:56:30.822 
Epoch 45/1000 
	 loss: 4.2783, MinusLogProbMetric: 4.2783, val_loss: 4.2302, val_MinusLogProbMetric: 4.2302

Epoch 45: val_loss improved from 4.24460 to 4.23023, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 85s - loss: 4.2783 - MinusLogProbMetric: 4.2783 - val_loss: 4.2302 - val_MinusLogProbMetric: 4.2302 - lr: 0.0010 - 85s/epoch - 435ms/step
Epoch 46/1000
2023-09-18 01:57:55.990 
Epoch 46/1000 
	 loss: 4.2462, MinusLogProbMetric: 4.2462, val_loss: 4.5323, val_MinusLogProbMetric: 4.5323

Epoch 46: val_loss did not improve from 4.23023
196/196 - 84s - loss: 4.2462 - MinusLogProbMetric: 4.2462 - val_loss: 4.5323 - val_MinusLogProbMetric: 4.5323 - lr: 0.0010 - 84s/epoch - 428ms/step
Epoch 47/1000
2023-09-18 01:59:20.727 
Epoch 47/1000 
	 loss: 4.2382, MinusLogProbMetric: 4.2382, val_loss: 4.2638, val_MinusLogProbMetric: 4.2638

Epoch 47: val_loss did not improve from 4.23023
196/196 - 85s - loss: 4.2382 - MinusLogProbMetric: 4.2382 - val_loss: 4.2638 - val_MinusLogProbMetric: 4.2638 - lr: 0.0010 - 85s/epoch - 432ms/step
Epoch 48/1000
2023-09-18 02:00:43.830 
Epoch 48/1000 
	 loss: 4.2765, MinusLogProbMetric: 4.2765, val_loss: 4.3514, val_MinusLogProbMetric: 4.3514

Epoch 48: val_loss did not improve from 4.23023
196/196 - 83s - loss: 4.2765 - MinusLogProbMetric: 4.2765 - val_loss: 4.3514 - val_MinusLogProbMetric: 4.3514 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 49/1000
2023-09-18 02:02:06.084 
Epoch 49/1000 
	 loss: 4.2258, MinusLogProbMetric: 4.2258, val_loss: 4.3276, val_MinusLogProbMetric: 4.3276

Epoch 49: val_loss did not improve from 4.23023
196/196 - 82s - loss: 4.2258 - MinusLogProbMetric: 4.2258 - val_loss: 4.3276 - val_MinusLogProbMetric: 4.3276 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 50/1000
2023-09-18 02:03:27.869 
Epoch 50/1000 
	 loss: 4.2617, MinusLogProbMetric: 4.2617, val_loss: 4.4081, val_MinusLogProbMetric: 4.4081

Epoch 50: val_loss did not improve from 4.23023
196/196 - 82s - loss: 4.2617 - MinusLogProbMetric: 4.2617 - val_loss: 4.4081 - val_MinusLogProbMetric: 4.4081 - lr: 0.0010 - 82s/epoch - 417ms/step
Epoch 51/1000
2023-09-18 02:04:48.994 
Epoch 51/1000 
	 loss: 4.2441, MinusLogProbMetric: 4.2441, val_loss: 4.3409, val_MinusLogProbMetric: 4.3409

Epoch 51: val_loss did not improve from 4.23023
196/196 - 81s - loss: 4.2441 - MinusLogProbMetric: 4.2441 - val_loss: 4.3409 - val_MinusLogProbMetric: 4.3409 - lr: 0.0010 - 81s/epoch - 414ms/step
Epoch 52/1000
2023-09-18 02:06:10.102 
Epoch 52/1000 
	 loss: 4.2167, MinusLogProbMetric: 4.2167, val_loss: 4.2321, val_MinusLogProbMetric: 4.2321

Epoch 52: val_loss did not improve from 4.23023
196/196 - 81s - loss: 4.2167 - MinusLogProbMetric: 4.2167 - val_loss: 4.2321 - val_MinusLogProbMetric: 4.2321 - lr: 0.0010 - 81s/epoch - 414ms/step
Epoch 53/1000
2023-09-18 02:07:31.679 
Epoch 53/1000 
	 loss: 4.2158, MinusLogProbMetric: 4.2158, val_loss: 4.2516, val_MinusLogProbMetric: 4.2516

Epoch 53: val_loss did not improve from 4.23023
196/196 - 82s - loss: 4.2158 - MinusLogProbMetric: 4.2158 - val_loss: 4.2516 - val_MinusLogProbMetric: 4.2516 - lr: 0.0010 - 82s/epoch - 416ms/step
Epoch 54/1000
2023-09-18 02:08:52.707 
Epoch 54/1000 
	 loss: 4.2425, MinusLogProbMetric: 4.2425, val_loss: 4.4370, val_MinusLogProbMetric: 4.4370

Epoch 54: val_loss did not improve from 4.23023
196/196 - 81s - loss: 4.2425 - MinusLogProbMetric: 4.2425 - val_loss: 4.4370 - val_MinusLogProbMetric: 4.4370 - lr: 0.0010 - 81s/epoch - 413ms/step
Epoch 55/1000
2023-09-18 02:10:12.636 
Epoch 55/1000 
	 loss: 4.2160, MinusLogProbMetric: 4.2160, val_loss: 4.1984, val_MinusLogProbMetric: 4.1984

Epoch 55: val_loss improved from 4.23023 to 4.19845, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 81s - loss: 4.2160 - MinusLogProbMetric: 4.2160 - val_loss: 4.1984 - val_MinusLogProbMetric: 4.1984 - lr: 0.0010 - 81s/epoch - 416ms/step
Epoch 56/1000
2023-09-18 02:11:33.412 
Epoch 56/1000 
	 loss: 4.2412, MinusLogProbMetric: 4.2412, val_loss: 4.2946, val_MinusLogProbMetric: 4.2946

Epoch 56: val_loss did not improve from 4.19845
196/196 - 79s - loss: 4.2412 - MinusLogProbMetric: 4.2412 - val_loss: 4.2946 - val_MinusLogProbMetric: 4.2946 - lr: 0.0010 - 79s/epoch - 404ms/step
Epoch 57/1000
2023-09-18 02:12:52.343 
Epoch 57/1000 
	 loss: 4.2195, MinusLogProbMetric: 4.2195, val_loss: 4.2336, val_MinusLogProbMetric: 4.2336

Epoch 57: val_loss did not improve from 4.19845
196/196 - 79s - loss: 4.2195 - MinusLogProbMetric: 4.2195 - val_loss: 4.2336 - val_MinusLogProbMetric: 4.2336 - lr: 0.0010 - 79s/epoch - 403ms/step
Epoch 58/1000
2023-09-18 02:14:11.539 
Epoch 58/1000 
	 loss: 4.2207, MinusLogProbMetric: 4.2207, val_loss: 4.3087, val_MinusLogProbMetric: 4.3087

Epoch 58: val_loss did not improve from 4.19845
196/196 - 79s - loss: 4.2207 - MinusLogProbMetric: 4.2207 - val_loss: 4.3087 - val_MinusLogProbMetric: 4.3087 - lr: 0.0010 - 79s/epoch - 404ms/step
Epoch 59/1000
2023-09-18 02:15:31.516 
Epoch 59/1000 
	 loss: 4.2185, MinusLogProbMetric: 4.2185, val_loss: 4.2119, val_MinusLogProbMetric: 4.2119

Epoch 59: val_loss did not improve from 4.19845
196/196 - 80s - loss: 4.2185 - MinusLogProbMetric: 4.2185 - val_loss: 4.2119 - val_MinusLogProbMetric: 4.2119 - lr: 0.0010 - 80s/epoch - 408ms/step
Epoch 60/1000
2023-09-18 02:16:48.943 
Epoch 60/1000 
	 loss: 4.2069, MinusLogProbMetric: 4.2069, val_loss: 4.2261, val_MinusLogProbMetric: 4.2261

Epoch 60: val_loss did not improve from 4.19845
196/196 - 77s - loss: 4.2069 - MinusLogProbMetric: 4.2069 - val_loss: 4.2261 - val_MinusLogProbMetric: 4.2261 - lr: 0.0010 - 77s/epoch - 395ms/step
Epoch 61/1000
2023-09-18 02:17:58.534 
Epoch 61/1000 
	 loss: 4.2240, MinusLogProbMetric: 4.2240, val_loss: 4.2990, val_MinusLogProbMetric: 4.2990

Epoch 61: val_loss did not improve from 4.19845
196/196 - 70s - loss: 4.2240 - MinusLogProbMetric: 4.2240 - val_loss: 4.2990 - val_MinusLogProbMetric: 4.2990 - lr: 0.0010 - 70s/epoch - 355ms/step
Epoch 62/1000
2023-09-18 02:19:07.439 
Epoch 62/1000 
	 loss: 4.2105, MinusLogProbMetric: 4.2105, val_loss: 4.2269, val_MinusLogProbMetric: 4.2269

Epoch 62: val_loss did not improve from 4.19845
196/196 - 69s - loss: 4.2105 - MinusLogProbMetric: 4.2105 - val_loss: 4.2269 - val_MinusLogProbMetric: 4.2269 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 63/1000
2023-09-18 02:20:24.022 
Epoch 63/1000 
	 loss: 4.2139, MinusLogProbMetric: 4.2139, val_loss: 4.3028, val_MinusLogProbMetric: 4.3028

Epoch 63: val_loss did not improve from 4.19845
196/196 - 77s - loss: 4.2139 - MinusLogProbMetric: 4.2139 - val_loss: 4.3028 - val_MinusLogProbMetric: 4.3028 - lr: 0.0010 - 77s/epoch - 391ms/step
Epoch 64/1000
2023-09-18 02:21:43.323 
Epoch 64/1000 
	 loss: 4.1902, MinusLogProbMetric: 4.1902, val_loss: 4.2630, val_MinusLogProbMetric: 4.2630

Epoch 64: val_loss did not improve from 4.19845
196/196 - 79s - loss: 4.1902 - MinusLogProbMetric: 4.1902 - val_loss: 4.2630 - val_MinusLogProbMetric: 4.2630 - lr: 0.0010 - 79s/epoch - 405ms/step
Epoch 65/1000
2023-09-18 02:23:02.111 
Epoch 65/1000 
	 loss: 4.1901, MinusLogProbMetric: 4.1901, val_loss: 4.3106, val_MinusLogProbMetric: 4.3106

Epoch 65: val_loss did not improve from 4.19845
196/196 - 79s - loss: 4.1901 - MinusLogProbMetric: 4.1901 - val_loss: 4.3106 - val_MinusLogProbMetric: 4.3106 - lr: 0.0010 - 79s/epoch - 402ms/step
Epoch 66/1000
2023-09-18 02:24:20.649 
Epoch 66/1000 
	 loss: 4.1946, MinusLogProbMetric: 4.1946, val_loss: 4.3739, val_MinusLogProbMetric: 4.3739

Epoch 66: val_loss did not improve from 4.19845
196/196 - 79s - loss: 4.1946 - MinusLogProbMetric: 4.1946 - val_loss: 4.3739 - val_MinusLogProbMetric: 4.3739 - lr: 0.0010 - 79s/epoch - 401ms/step
Epoch 67/1000
2023-09-18 02:25:37.891 
Epoch 67/1000 
	 loss: 4.2025, MinusLogProbMetric: 4.2025, val_loss: 4.3216, val_MinusLogProbMetric: 4.3216

Epoch 67: val_loss did not improve from 4.19845
196/196 - 77s - loss: 4.2025 - MinusLogProbMetric: 4.2025 - val_loss: 4.3216 - val_MinusLogProbMetric: 4.3216 - lr: 0.0010 - 77s/epoch - 394ms/step
Epoch 68/1000
2023-09-18 02:26:56.871 
Epoch 68/1000 
	 loss: 4.2008, MinusLogProbMetric: 4.2008, val_loss: 4.2406, val_MinusLogProbMetric: 4.2406

Epoch 68: val_loss did not improve from 4.19845
196/196 - 79s - loss: 4.2008 - MinusLogProbMetric: 4.2008 - val_loss: 4.2406 - val_MinusLogProbMetric: 4.2406 - lr: 0.0010 - 79s/epoch - 403ms/step
Epoch 69/1000
2023-09-18 02:28:14.779 
Epoch 69/1000 
	 loss: 4.1879, MinusLogProbMetric: 4.1879, val_loss: 4.3221, val_MinusLogProbMetric: 4.3221

Epoch 69: val_loss did not improve from 4.19845
196/196 - 78s - loss: 4.1879 - MinusLogProbMetric: 4.1879 - val_loss: 4.3221 - val_MinusLogProbMetric: 4.3221 - lr: 0.0010 - 78s/epoch - 397ms/step
Epoch 70/1000
2023-09-18 02:29:30.070 
Epoch 70/1000 
	 loss: 4.1951, MinusLogProbMetric: 4.1951, val_loss: 4.2976, val_MinusLogProbMetric: 4.2976

Epoch 70: val_loss did not improve from 4.19845
196/196 - 75s - loss: 4.1951 - MinusLogProbMetric: 4.1951 - val_loss: 4.2976 - val_MinusLogProbMetric: 4.2976 - lr: 0.0010 - 75s/epoch - 384ms/step
Epoch 71/1000
2023-09-18 02:30:40.938 
Epoch 71/1000 
	 loss: 4.1922, MinusLogProbMetric: 4.1922, val_loss: 4.2466, val_MinusLogProbMetric: 4.2466

Epoch 71: val_loss did not improve from 4.19845
196/196 - 71s - loss: 4.1922 - MinusLogProbMetric: 4.1922 - val_loss: 4.2466 - val_MinusLogProbMetric: 4.2466 - lr: 0.0010 - 71s/epoch - 362ms/step
Epoch 72/1000
2023-09-18 02:31:58.141 
Epoch 72/1000 
	 loss: 4.1665, MinusLogProbMetric: 4.1665, val_loss: 4.2805, val_MinusLogProbMetric: 4.2805

Epoch 72: val_loss did not improve from 4.19845
196/196 - 77s - loss: 4.1665 - MinusLogProbMetric: 4.1665 - val_loss: 4.2805 - val_MinusLogProbMetric: 4.2805 - lr: 0.0010 - 77s/epoch - 394ms/step
Epoch 73/1000
2023-09-18 02:33:17.014 
Epoch 73/1000 
	 loss: 4.1881, MinusLogProbMetric: 4.1881, val_loss: 4.2646, val_MinusLogProbMetric: 4.2646

Epoch 73: val_loss did not improve from 4.19845
196/196 - 79s - loss: 4.1881 - MinusLogProbMetric: 4.1881 - val_loss: 4.2646 - val_MinusLogProbMetric: 4.2646 - lr: 0.0010 - 79s/epoch - 402ms/step
Epoch 74/1000
2023-09-18 02:34:34.923 
Epoch 74/1000 
	 loss: 4.1710, MinusLogProbMetric: 4.1710, val_loss: 4.2512, val_MinusLogProbMetric: 4.2512

Epoch 74: val_loss did not improve from 4.19845
196/196 - 78s - loss: 4.1710 - MinusLogProbMetric: 4.1710 - val_loss: 4.2512 - val_MinusLogProbMetric: 4.2512 - lr: 0.0010 - 78s/epoch - 397ms/step
Epoch 75/1000
2023-09-18 02:35:53.145 
Epoch 75/1000 
	 loss: 4.1586, MinusLogProbMetric: 4.1586, val_loss: 4.2895, val_MinusLogProbMetric: 4.2895

Epoch 75: val_loss did not improve from 4.19845
196/196 - 78s - loss: 4.1586 - MinusLogProbMetric: 4.1586 - val_loss: 4.2895 - val_MinusLogProbMetric: 4.2895 - lr: 0.0010 - 78s/epoch - 399ms/step
Epoch 76/1000
2023-09-18 02:37:10.755 
Epoch 76/1000 
	 loss: 4.1902, MinusLogProbMetric: 4.1902, val_loss: 4.3130, val_MinusLogProbMetric: 4.3130

Epoch 76: val_loss did not improve from 4.19845
196/196 - 78s - loss: 4.1902 - MinusLogProbMetric: 4.1902 - val_loss: 4.3130 - val_MinusLogProbMetric: 4.3130 - lr: 0.0010 - 78s/epoch - 396ms/step
Epoch 77/1000
2023-09-18 02:38:30.082 
Epoch 77/1000 
	 loss: 4.1568, MinusLogProbMetric: 4.1568, val_loss: 4.2635, val_MinusLogProbMetric: 4.2635

Epoch 77: val_loss did not improve from 4.19845
196/196 - 79s - loss: 4.1568 - MinusLogProbMetric: 4.1568 - val_loss: 4.2635 - val_MinusLogProbMetric: 4.2635 - lr: 0.0010 - 79s/epoch - 405ms/step
Epoch 78/1000
2023-09-18 02:39:48.155 
Epoch 78/1000 
	 loss: 4.1727, MinusLogProbMetric: 4.1727, val_loss: 4.2093, val_MinusLogProbMetric: 4.2093

Epoch 78: val_loss did not improve from 4.19845
196/196 - 78s - loss: 4.1727 - MinusLogProbMetric: 4.1727 - val_loss: 4.2093 - val_MinusLogProbMetric: 4.2093 - lr: 0.0010 - 78s/epoch - 398ms/step
Epoch 79/1000
2023-09-18 02:41:05.182 
Epoch 79/1000 
	 loss: 4.1503, MinusLogProbMetric: 4.1503, val_loss: 4.2395, val_MinusLogProbMetric: 4.2395

Epoch 79: val_loss did not improve from 4.19845
196/196 - 77s - loss: 4.1503 - MinusLogProbMetric: 4.1503 - val_loss: 4.2395 - val_MinusLogProbMetric: 4.2395 - lr: 0.0010 - 77s/epoch - 393ms/step
Epoch 80/1000
2023-09-18 02:42:22.527 
Epoch 80/1000 
	 loss: 4.1511, MinusLogProbMetric: 4.1511, val_loss: 4.2229, val_MinusLogProbMetric: 4.2229

Epoch 80: val_loss did not improve from 4.19845
196/196 - 77s - loss: 4.1511 - MinusLogProbMetric: 4.1511 - val_loss: 4.2229 - val_MinusLogProbMetric: 4.2229 - lr: 0.0010 - 77s/epoch - 395ms/step
Epoch 81/1000
2023-09-18 02:43:41.006 
Epoch 81/1000 
	 loss: 4.1556, MinusLogProbMetric: 4.1556, val_loss: 4.3714, val_MinusLogProbMetric: 4.3714

Epoch 81: val_loss did not improve from 4.19845
196/196 - 78s - loss: 4.1556 - MinusLogProbMetric: 4.1556 - val_loss: 4.3714 - val_MinusLogProbMetric: 4.3714 - lr: 0.0010 - 78s/epoch - 400ms/step
Epoch 82/1000
2023-09-18 02:44:58.891 
Epoch 82/1000 
	 loss: 4.1663, MinusLogProbMetric: 4.1663, val_loss: 4.1990, val_MinusLogProbMetric: 4.1990

Epoch 82: val_loss did not improve from 4.19845
196/196 - 78s - loss: 4.1663 - MinusLogProbMetric: 4.1663 - val_loss: 4.1990 - val_MinusLogProbMetric: 4.1990 - lr: 0.0010 - 78s/epoch - 397ms/step
Epoch 83/1000
2023-09-18 02:46:16.430 
Epoch 83/1000 
	 loss: 4.1679, MinusLogProbMetric: 4.1679, val_loss: 4.2726, val_MinusLogProbMetric: 4.2726

Epoch 83: val_loss did not improve from 4.19845
196/196 - 78s - loss: 4.1679 - MinusLogProbMetric: 4.1679 - val_loss: 4.2726 - val_MinusLogProbMetric: 4.2726 - lr: 0.0010 - 78s/epoch - 396ms/step
Epoch 84/1000
2023-09-18 02:47:34.657 
Epoch 84/1000 
	 loss: 4.1479, MinusLogProbMetric: 4.1479, val_loss: 4.2098, val_MinusLogProbMetric: 4.2098

Epoch 84: val_loss did not improve from 4.19845
196/196 - 78s - loss: 4.1479 - MinusLogProbMetric: 4.1479 - val_loss: 4.2098 - val_MinusLogProbMetric: 4.2098 - lr: 0.0010 - 78s/epoch - 399ms/step
Epoch 85/1000
2023-09-18 02:48:52.404 
Epoch 85/1000 
	 loss: 4.1561, MinusLogProbMetric: 4.1561, val_loss: 4.2711, val_MinusLogProbMetric: 4.2711

Epoch 85: val_loss did not improve from 4.19845
196/196 - 78s - loss: 4.1561 - MinusLogProbMetric: 4.1561 - val_loss: 4.2711 - val_MinusLogProbMetric: 4.2711 - lr: 0.0010 - 78s/epoch - 397ms/step
Epoch 86/1000
2023-09-18 02:50:08.902 
Epoch 86/1000 
	 loss: 4.1500, MinusLogProbMetric: 4.1500, val_loss: 4.2395, val_MinusLogProbMetric: 4.2395

Epoch 86: val_loss did not improve from 4.19845
196/196 - 76s - loss: 4.1500 - MinusLogProbMetric: 4.1500 - val_loss: 4.2395 - val_MinusLogProbMetric: 4.2395 - lr: 0.0010 - 76s/epoch - 390ms/step
Epoch 87/1000
2023-09-18 02:51:27.714 
Epoch 87/1000 
	 loss: 4.1502, MinusLogProbMetric: 4.1502, val_loss: 4.3094, val_MinusLogProbMetric: 4.3094

Epoch 87: val_loss did not improve from 4.19845
196/196 - 79s - loss: 4.1502 - MinusLogProbMetric: 4.1502 - val_loss: 4.3094 - val_MinusLogProbMetric: 4.3094 - lr: 0.0010 - 79s/epoch - 402ms/step
Epoch 88/1000
2023-09-18 02:52:45.105 
Epoch 88/1000 
	 loss: 4.1453, MinusLogProbMetric: 4.1453, val_loss: 4.2731, val_MinusLogProbMetric: 4.2731

Epoch 88: val_loss did not improve from 4.19845
196/196 - 77s - loss: 4.1453 - MinusLogProbMetric: 4.1453 - val_loss: 4.2731 - val_MinusLogProbMetric: 4.2731 - lr: 0.0010 - 77s/epoch - 395ms/step
Epoch 89/1000
2023-09-18 02:54:03.685 
Epoch 89/1000 
	 loss: 4.1676, MinusLogProbMetric: 4.1676, val_loss: 4.2968, val_MinusLogProbMetric: 4.2968

Epoch 89: val_loss did not improve from 4.19845
196/196 - 79s - loss: 4.1676 - MinusLogProbMetric: 4.1676 - val_loss: 4.2968 - val_MinusLogProbMetric: 4.2968 - lr: 0.0010 - 79s/epoch - 401ms/step
Epoch 90/1000
2023-09-18 02:55:21.556 
Epoch 90/1000 
	 loss: 4.1480, MinusLogProbMetric: 4.1480, val_loss: 4.2820, val_MinusLogProbMetric: 4.2820

Epoch 90: val_loss did not improve from 4.19845
196/196 - 78s - loss: 4.1480 - MinusLogProbMetric: 4.1480 - val_loss: 4.2820 - val_MinusLogProbMetric: 4.2820 - lr: 0.0010 - 78s/epoch - 397ms/step
Epoch 91/1000
2023-09-18 02:56:38.941 
Epoch 91/1000 
	 loss: 4.1476, MinusLogProbMetric: 4.1476, val_loss: 4.2093, val_MinusLogProbMetric: 4.2093

Epoch 91: val_loss did not improve from 4.19845
196/196 - 77s - loss: 4.1476 - MinusLogProbMetric: 4.1476 - val_loss: 4.2093 - val_MinusLogProbMetric: 4.2093 - lr: 0.0010 - 77s/epoch - 395ms/step
Epoch 92/1000
2023-09-18 02:57:48.507 
Epoch 92/1000 
	 loss: 4.1516, MinusLogProbMetric: 4.1516, val_loss: 4.2272, val_MinusLogProbMetric: 4.2272

Epoch 92: val_loss did not improve from 4.19845
196/196 - 70s - loss: 4.1516 - MinusLogProbMetric: 4.1516 - val_loss: 4.2272 - val_MinusLogProbMetric: 4.2272 - lr: 0.0010 - 70s/epoch - 355ms/step
Epoch 93/1000
2023-09-18 02:58:51.166 
Epoch 93/1000 
	 loss: 4.1422, MinusLogProbMetric: 4.1422, val_loss: 4.3057, val_MinusLogProbMetric: 4.3057

Epoch 93: val_loss did not improve from 4.19845
196/196 - 63s - loss: 4.1422 - MinusLogProbMetric: 4.1422 - val_loss: 4.3057 - val_MinusLogProbMetric: 4.3057 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 94/1000
2023-09-18 02:59:57.591 
Epoch 94/1000 
	 loss: 4.1451, MinusLogProbMetric: 4.1451, val_loss: 4.2530, val_MinusLogProbMetric: 4.2530

Epoch 94: val_loss did not improve from 4.19845
196/196 - 66s - loss: 4.1451 - MinusLogProbMetric: 4.1451 - val_loss: 4.2530 - val_MinusLogProbMetric: 4.2530 - lr: 0.0010 - 66s/epoch - 339ms/step
Epoch 95/1000
2023-09-18 03:01:15.093 
Epoch 95/1000 
	 loss: 4.1332, MinusLogProbMetric: 4.1332, val_loss: 4.2354, val_MinusLogProbMetric: 4.2354

Epoch 95: val_loss did not improve from 4.19845
196/196 - 77s - loss: 4.1332 - MinusLogProbMetric: 4.1332 - val_loss: 4.2354 - val_MinusLogProbMetric: 4.2354 - lr: 0.0010 - 77s/epoch - 395ms/step
Epoch 96/1000
2023-09-18 03:02:32.327 
Epoch 96/1000 
	 loss: 4.1239, MinusLogProbMetric: 4.1239, val_loss: 4.2424, val_MinusLogProbMetric: 4.2424

Epoch 96: val_loss did not improve from 4.19845
196/196 - 77s - loss: 4.1239 - MinusLogProbMetric: 4.1239 - val_loss: 4.2424 - val_MinusLogProbMetric: 4.2424 - lr: 0.0010 - 77s/epoch - 394ms/step
Epoch 97/1000
2023-09-18 03:03:48.493 
Epoch 97/1000 
	 loss: 4.1507, MinusLogProbMetric: 4.1507, val_loss: 4.2148, val_MinusLogProbMetric: 4.2148

Epoch 97: val_loss did not improve from 4.19845
196/196 - 76s - loss: 4.1507 - MinusLogProbMetric: 4.1507 - val_loss: 4.2148 - val_MinusLogProbMetric: 4.2148 - lr: 0.0010 - 76s/epoch - 389ms/step
Epoch 98/1000
2023-09-18 03:05:05.819 
Epoch 98/1000 
	 loss: 4.1656, MinusLogProbMetric: 4.1656, val_loss: 4.2339, val_MinusLogProbMetric: 4.2339

Epoch 98: val_loss did not improve from 4.19845
196/196 - 77s - loss: 4.1656 - MinusLogProbMetric: 4.1656 - val_loss: 4.2339 - val_MinusLogProbMetric: 4.2339 - lr: 0.0010 - 77s/epoch - 395ms/step
Epoch 99/1000
2023-09-18 03:06:22.714 
Epoch 99/1000 
	 loss: 4.1333, MinusLogProbMetric: 4.1333, val_loss: 4.2090, val_MinusLogProbMetric: 4.2090

Epoch 99: val_loss did not improve from 4.19845
196/196 - 77s - loss: 4.1333 - MinusLogProbMetric: 4.1333 - val_loss: 4.2090 - val_MinusLogProbMetric: 4.2090 - lr: 0.0010 - 77s/epoch - 392ms/step
Epoch 100/1000
2023-09-18 03:07:40.481 
Epoch 100/1000 
	 loss: 4.1286, MinusLogProbMetric: 4.1286, val_loss: 4.2552, val_MinusLogProbMetric: 4.2552

Epoch 100: val_loss did not improve from 4.19845
196/196 - 78s - loss: 4.1286 - MinusLogProbMetric: 4.1286 - val_loss: 4.2552 - val_MinusLogProbMetric: 4.2552 - lr: 0.0010 - 78s/epoch - 397ms/step
Epoch 101/1000
2023-09-18 03:08:58.209 
Epoch 101/1000 
	 loss: 4.1489, MinusLogProbMetric: 4.1489, val_loss: 4.2419, val_MinusLogProbMetric: 4.2419

Epoch 101: val_loss did not improve from 4.19845
196/196 - 78s - loss: 4.1489 - MinusLogProbMetric: 4.1489 - val_loss: 4.2419 - val_MinusLogProbMetric: 4.2419 - lr: 0.0010 - 78s/epoch - 397ms/step
Epoch 102/1000
2023-09-18 03:10:15.368 
Epoch 102/1000 
	 loss: 4.1336, MinusLogProbMetric: 4.1336, val_loss: 4.1950, val_MinusLogProbMetric: 4.1950

Epoch 102: val_loss improved from 4.19845 to 4.19497, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 79s - loss: 4.1336 - MinusLogProbMetric: 4.1336 - val_loss: 4.1950 - val_MinusLogProbMetric: 4.1950 - lr: 0.0010 - 79s/epoch - 402ms/step
Epoch 103/1000
2023-09-18 03:11:34.018 
Epoch 103/1000 
	 loss: 4.1336, MinusLogProbMetric: 4.1336, val_loss: 4.2750, val_MinusLogProbMetric: 4.2750

Epoch 103: val_loss did not improve from 4.19497
196/196 - 77s - loss: 4.1336 - MinusLogProbMetric: 4.1336 - val_loss: 4.2750 - val_MinusLogProbMetric: 4.2750 - lr: 0.0010 - 77s/epoch - 393ms/step
Epoch 104/1000
2023-09-18 03:12:51.314 
Epoch 104/1000 
	 loss: 4.1469, MinusLogProbMetric: 4.1469, val_loss: 4.2341, val_MinusLogProbMetric: 4.2341

Epoch 104: val_loss did not improve from 4.19497
196/196 - 77s - loss: 4.1469 - MinusLogProbMetric: 4.1469 - val_loss: 4.2341 - val_MinusLogProbMetric: 4.2341 - lr: 0.0010 - 77s/epoch - 394ms/step
Epoch 105/1000
2023-09-18 03:14:09.037 
Epoch 105/1000 
	 loss: 4.1293, MinusLogProbMetric: 4.1293, val_loss: 4.2708, val_MinusLogProbMetric: 4.2708

Epoch 105: val_loss did not improve from 4.19497
196/196 - 78s - loss: 4.1293 - MinusLogProbMetric: 4.1293 - val_loss: 4.2708 - val_MinusLogProbMetric: 4.2708 - lr: 0.0010 - 78s/epoch - 397ms/step
Epoch 106/1000
2023-09-18 03:15:27.682 
Epoch 106/1000 
	 loss: 4.1292, MinusLogProbMetric: 4.1292, val_loss: 4.2513, val_MinusLogProbMetric: 4.2513

Epoch 106: val_loss did not improve from 4.19497
196/196 - 79s - loss: 4.1292 - MinusLogProbMetric: 4.1292 - val_loss: 4.2513 - val_MinusLogProbMetric: 4.2513 - lr: 0.0010 - 79s/epoch - 401ms/step
Epoch 107/1000
2023-09-18 03:16:44.708 
Epoch 107/1000 
	 loss: 4.1128, MinusLogProbMetric: 4.1128, val_loss: 4.1995, val_MinusLogProbMetric: 4.1995

Epoch 107: val_loss did not improve from 4.19497
196/196 - 77s - loss: 4.1128 - MinusLogProbMetric: 4.1128 - val_loss: 4.1995 - val_MinusLogProbMetric: 4.1995 - lr: 0.0010 - 77s/epoch - 393ms/step
Epoch 108/1000
2023-09-18 03:18:01.461 
Epoch 108/1000 
	 loss: 4.1119, MinusLogProbMetric: 4.1119, val_loss: 4.1997, val_MinusLogProbMetric: 4.1997

Epoch 108: val_loss did not improve from 4.19497
196/196 - 77s - loss: 4.1119 - MinusLogProbMetric: 4.1119 - val_loss: 4.1997 - val_MinusLogProbMetric: 4.1997 - lr: 0.0010 - 77s/epoch - 392ms/step
Epoch 109/1000
2023-09-18 03:19:18.922 
Epoch 109/1000 
	 loss: 4.1224, MinusLogProbMetric: 4.1224, val_loss: 4.4423, val_MinusLogProbMetric: 4.4423

Epoch 109: val_loss did not improve from 4.19497
196/196 - 77s - loss: 4.1224 - MinusLogProbMetric: 4.1224 - val_loss: 4.4423 - val_MinusLogProbMetric: 4.4423 - lr: 0.0010 - 77s/epoch - 395ms/step
Epoch 110/1000
2023-09-18 03:20:35.969 
Epoch 110/1000 
	 loss: 4.1522, MinusLogProbMetric: 4.1522, val_loss: 4.2371, val_MinusLogProbMetric: 4.2371

Epoch 110: val_loss did not improve from 4.19497
196/196 - 77s - loss: 4.1522 - MinusLogProbMetric: 4.1522 - val_loss: 4.2371 - val_MinusLogProbMetric: 4.2371 - lr: 0.0010 - 77s/epoch - 393ms/step
Epoch 111/1000
2023-09-18 03:21:52.752 
Epoch 111/1000 
	 loss: 4.1246, MinusLogProbMetric: 4.1246, val_loss: 4.2479, val_MinusLogProbMetric: 4.2479

Epoch 111: val_loss did not improve from 4.19497
196/196 - 77s - loss: 4.1246 - MinusLogProbMetric: 4.1246 - val_loss: 4.2479 - val_MinusLogProbMetric: 4.2479 - lr: 0.0010 - 77s/epoch - 392ms/step
Epoch 112/1000
2023-09-18 03:23:09.180 
Epoch 112/1000 
	 loss: 4.1212, MinusLogProbMetric: 4.1212, val_loss: 4.2363, val_MinusLogProbMetric: 4.2363

Epoch 112: val_loss did not improve from 4.19497
196/196 - 76s - loss: 4.1212 - MinusLogProbMetric: 4.1212 - val_loss: 4.2363 - val_MinusLogProbMetric: 4.2363 - lr: 0.0010 - 76s/epoch - 390ms/step
Epoch 113/1000
2023-09-18 03:24:25.423 
Epoch 113/1000 
	 loss: 4.1131, MinusLogProbMetric: 4.1131, val_loss: 4.1932, val_MinusLogProbMetric: 4.1932

Epoch 113: val_loss improved from 4.19497 to 4.19322, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 78s - loss: 4.1131 - MinusLogProbMetric: 4.1131 - val_loss: 4.1932 - val_MinusLogProbMetric: 4.1932 - lr: 0.0010 - 78s/epoch - 396ms/step
Epoch 114/1000
2023-09-18 03:25:35.735 
Epoch 114/1000 
	 loss: 4.1109, MinusLogProbMetric: 4.1109, val_loss: 4.2319, val_MinusLogProbMetric: 4.2319

Epoch 114: val_loss did not improve from 4.19322
196/196 - 69s - loss: 4.1109 - MinusLogProbMetric: 4.1109 - val_loss: 4.2319 - val_MinusLogProbMetric: 4.2319 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 115/1000
2023-09-18 03:26:52.317 
Epoch 115/1000 
	 loss: 4.1222, MinusLogProbMetric: 4.1222, val_loss: 4.2153, val_MinusLogProbMetric: 4.2153

Epoch 115: val_loss did not improve from 4.19322
196/196 - 77s - loss: 4.1222 - MinusLogProbMetric: 4.1222 - val_loss: 4.2153 - val_MinusLogProbMetric: 4.2153 - lr: 0.0010 - 77s/epoch - 391ms/step
Epoch 116/1000
2023-09-18 03:28:10.918 
Epoch 116/1000 
	 loss: 4.1262, MinusLogProbMetric: 4.1262, val_loss: 4.2191, val_MinusLogProbMetric: 4.2191

Epoch 116: val_loss did not improve from 4.19322
196/196 - 79s - loss: 4.1262 - MinusLogProbMetric: 4.1262 - val_loss: 4.2191 - val_MinusLogProbMetric: 4.2191 - lr: 0.0010 - 79s/epoch - 401ms/step
Epoch 117/1000
2023-09-18 03:29:29.492 
Epoch 117/1000 
	 loss: 4.1150, MinusLogProbMetric: 4.1150, val_loss: 4.2342, val_MinusLogProbMetric: 4.2342

Epoch 117: val_loss did not improve from 4.19322
196/196 - 79s - loss: 4.1150 - MinusLogProbMetric: 4.1150 - val_loss: 4.2342 - val_MinusLogProbMetric: 4.2342 - lr: 0.0010 - 79s/epoch - 401ms/step
Epoch 118/1000
2023-09-18 03:30:48.449 
Epoch 118/1000 
	 loss: 4.1051, MinusLogProbMetric: 4.1051, val_loss: 4.2253, val_MinusLogProbMetric: 4.2253

Epoch 118: val_loss did not improve from 4.19322
196/196 - 79s - loss: 4.1051 - MinusLogProbMetric: 4.1051 - val_loss: 4.2253 - val_MinusLogProbMetric: 4.2253 - lr: 0.0010 - 79s/epoch - 403ms/step
Epoch 119/1000
2023-09-18 03:32:07.618 
Epoch 119/1000 
	 loss: 4.1279, MinusLogProbMetric: 4.1279, val_loss: 4.2275, val_MinusLogProbMetric: 4.2275

Epoch 119: val_loss did not improve from 4.19322
196/196 - 79s - loss: 4.1279 - MinusLogProbMetric: 4.1279 - val_loss: 4.2275 - val_MinusLogProbMetric: 4.2275 - lr: 0.0010 - 79s/epoch - 404ms/step
Epoch 120/1000
2023-09-18 03:33:26.100 
Epoch 120/1000 
	 loss: 4.1120, MinusLogProbMetric: 4.1120, val_loss: 4.1950, val_MinusLogProbMetric: 4.1950

Epoch 120: val_loss did not improve from 4.19322
196/196 - 78s - loss: 4.1120 - MinusLogProbMetric: 4.1120 - val_loss: 4.1950 - val_MinusLogProbMetric: 4.1950 - lr: 0.0010 - 78s/epoch - 400ms/step
Epoch 121/1000
2023-09-18 03:34:44.421 
Epoch 121/1000 
	 loss: 4.1073, MinusLogProbMetric: 4.1073, val_loss: 4.2042, val_MinusLogProbMetric: 4.2042

Epoch 121: val_loss did not improve from 4.19322
196/196 - 78s - loss: 4.1073 - MinusLogProbMetric: 4.1073 - val_loss: 4.2042 - val_MinusLogProbMetric: 4.2042 - lr: 0.0010 - 78s/epoch - 400ms/step
Epoch 122/1000
2023-09-18 03:36:02.519 
Epoch 122/1000 
	 loss: 4.1048, MinusLogProbMetric: 4.1048, val_loss: 4.2302, val_MinusLogProbMetric: 4.2302

Epoch 122: val_loss did not improve from 4.19322
196/196 - 78s - loss: 4.1048 - MinusLogProbMetric: 4.1048 - val_loss: 4.2302 - val_MinusLogProbMetric: 4.2302 - lr: 0.0010 - 78s/epoch - 398ms/step
Epoch 123/1000
2023-09-18 03:37:20.224 
Epoch 123/1000 
	 loss: 4.1126, MinusLogProbMetric: 4.1126, val_loss: 4.1952, val_MinusLogProbMetric: 4.1952

Epoch 123: val_loss did not improve from 4.19322
196/196 - 78s - loss: 4.1126 - MinusLogProbMetric: 4.1126 - val_loss: 4.1952 - val_MinusLogProbMetric: 4.1952 - lr: 0.0010 - 78s/epoch - 396ms/step
Epoch 124/1000
2023-09-18 03:38:38.328 
Epoch 124/1000 
	 loss: 4.1022, MinusLogProbMetric: 4.1022, val_loss: 4.1940, val_MinusLogProbMetric: 4.1940

Epoch 124: val_loss did not improve from 4.19322
196/196 - 78s - loss: 4.1022 - MinusLogProbMetric: 4.1022 - val_loss: 4.1940 - val_MinusLogProbMetric: 4.1940 - lr: 0.0010 - 78s/epoch - 398ms/step
Epoch 125/1000
2023-09-18 03:39:57.153 
Epoch 125/1000 
	 loss: 4.1038, MinusLogProbMetric: 4.1038, val_loss: 4.2060, val_MinusLogProbMetric: 4.2060

Epoch 125: val_loss did not improve from 4.19322
196/196 - 79s - loss: 4.1038 - MinusLogProbMetric: 4.1038 - val_loss: 4.2060 - val_MinusLogProbMetric: 4.2060 - lr: 0.0010 - 79s/epoch - 402ms/step
Epoch 126/1000
2023-09-18 03:41:16.477 
Epoch 126/1000 
	 loss: 4.1067, MinusLogProbMetric: 4.1067, val_loss: 4.2619, val_MinusLogProbMetric: 4.2619

Epoch 126: val_loss did not improve from 4.19322
196/196 - 79s - loss: 4.1067 - MinusLogProbMetric: 4.1067 - val_loss: 4.2619 - val_MinusLogProbMetric: 4.2619 - lr: 0.0010 - 79s/epoch - 405ms/step
Epoch 127/1000
2023-09-18 03:42:35.044 
Epoch 127/1000 
	 loss: 4.1104, MinusLogProbMetric: 4.1104, val_loss: 4.4205, val_MinusLogProbMetric: 4.4205

Epoch 127: val_loss did not improve from 4.19322
196/196 - 79s - loss: 4.1104 - MinusLogProbMetric: 4.1104 - val_loss: 4.4205 - val_MinusLogProbMetric: 4.4205 - lr: 0.0010 - 79s/epoch - 401ms/step
Epoch 128/1000
2023-09-18 03:43:54.382 
Epoch 128/1000 
	 loss: 4.1116, MinusLogProbMetric: 4.1116, val_loss: 4.1896, val_MinusLogProbMetric: 4.1896

Epoch 128: val_loss improved from 4.19322 to 4.18959, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 81s - loss: 4.1116 - MinusLogProbMetric: 4.1116 - val_loss: 4.1896 - val_MinusLogProbMetric: 4.1896 - lr: 0.0010 - 81s/epoch - 412ms/step
Epoch 129/1000
2023-09-18 03:45:14.332 
Epoch 129/1000 
	 loss: 4.1121, MinusLogProbMetric: 4.1121, val_loss: 4.1946, val_MinusLogProbMetric: 4.1946

Epoch 129: val_loss did not improve from 4.18959
196/196 - 79s - loss: 4.1121 - MinusLogProbMetric: 4.1121 - val_loss: 4.1946 - val_MinusLogProbMetric: 4.1946 - lr: 0.0010 - 79s/epoch - 401ms/step
Epoch 130/1000
2023-09-18 03:46:32.175 
Epoch 130/1000 
	 loss: 4.1029, MinusLogProbMetric: 4.1029, val_loss: 4.2807, val_MinusLogProbMetric: 4.2807

Epoch 130: val_loss did not improve from 4.18959
196/196 - 78s - loss: 4.1029 - MinusLogProbMetric: 4.1029 - val_loss: 4.2807 - val_MinusLogProbMetric: 4.2807 - lr: 0.0010 - 78s/epoch - 397ms/step
Epoch 131/1000
2023-09-18 03:47:50.777 
Epoch 131/1000 
	 loss: 4.1057, MinusLogProbMetric: 4.1057, val_loss: 4.2941, val_MinusLogProbMetric: 4.2941

Epoch 131: val_loss did not improve from 4.18959
196/196 - 79s - loss: 4.1057 - MinusLogProbMetric: 4.1057 - val_loss: 4.2941 - val_MinusLogProbMetric: 4.2941 - lr: 0.0010 - 79s/epoch - 401ms/step
Epoch 132/1000
2023-09-18 03:49:09.172 
Epoch 132/1000 
	 loss: 4.1057, MinusLogProbMetric: 4.1057, val_loss: 4.2275, val_MinusLogProbMetric: 4.2275

Epoch 132: val_loss did not improve from 4.18959
196/196 - 78s - loss: 4.1057 - MinusLogProbMetric: 4.1057 - val_loss: 4.2275 - val_MinusLogProbMetric: 4.2275 - lr: 0.0010 - 78s/epoch - 400ms/step
Epoch 133/1000
2023-09-18 03:50:27.594 
Epoch 133/1000 
	 loss: 4.1017, MinusLogProbMetric: 4.1017, val_loss: 4.2493, val_MinusLogProbMetric: 4.2493

Epoch 133: val_loss did not improve from 4.18959
196/196 - 78s - loss: 4.1017 - MinusLogProbMetric: 4.1017 - val_loss: 4.2493 - val_MinusLogProbMetric: 4.2493 - lr: 0.0010 - 78s/epoch - 400ms/step
Epoch 134/1000
2023-09-18 03:51:46.495 
Epoch 134/1000 
	 loss: 4.0935, MinusLogProbMetric: 4.0935, val_loss: 4.1969, val_MinusLogProbMetric: 4.1969

Epoch 134: val_loss did not improve from 4.18959
196/196 - 79s - loss: 4.0935 - MinusLogProbMetric: 4.0935 - val_loss: 4.1969 - val_MinusLogProbMetric: 4.1969 - lr: 0.0010 - 79s/epoch - 403ms/step
Epoch 135/1000
2023-09-18 03:53:04.631 
Epoch 135/1000 
	 loss: 4.0942, MinusLogProbMetric: 4.0942, val_loss: 4.1939, val_MinusLogProbMetric: 4.1939

Epoch 135: val_loss did not improve from 4.18959
196/196 - 78s - loss: 4.0942 - MinusLogProbMetric: 4.0942 - val_loss: 4.1939 - val_MinusLogProbMetric: 4.1939 - lr: 0.0010 - 78s/epoch - 399ms/step
Epoch 136/1000
2023-09-18 03:54:22.425 
Epoch 136/1000 
	 loss: 4.1026, MinusLogProbMetric: 4.1026, val_loss: 4.2102, val_MinusLogProbMetric: 4.2102

Epoch 136: val_loss did not improve from 4.18959
196/196 - 78s - loss: 4.1026 - MinusLogProbMetric: 4.1026 - val_loss: 4.2102 - val_MinusLogProbMetric: 4.2102 - lr: 0.0010 - 78s/epoch - 397ms/step
Epoch 137/1000
2023-09-18 03:55:40.652 
Epoch 137/1000 
	 loss: 4.1036, MinusLogProbMetric: 4.1036, val_loss: 4.2089, val_MinusLogProbMetric: 4.2089

Epoch 137: val_loss did not improve from 4.18959
196/196 - 78s - loss: 4.1036 - MinusLogProbMetric: 4.1036 - val_loss: 4.2089 - val_MinusLogProbMetric: 4.2089 - lr: 0.0010 - 78s/epoch - 399ms/step
Epoch 138/1000
2023-09-18 03:57:00.354 
Epoch 138/1000 
	 loss: 4.0925, MinusLogProbMetric: 4.0925, val_loss: 4.2321, val_MinusLogProbMetric: 4.2321

Epoch 138: val_loss did not improve from 4.18959
196/196 - 80s - loss: 4.0925 - MinusLogProbMetric: 4.0925 - val_loss: 4.2321 - val_MinusLogProbMetric: 4.2321 - lr: 0.0010 - 80s/epoch - 407ms/step
Epoch 139/1000
2023-09-18 03:58:18.686 
Epoch 139/1000 
	 loss: 4.0953, MinusLogProbMetric: 4.0953, val_loss: 4.4422, val_MinusLogProbMetric: 4.4422

Epoch 139: val_loss did not improve from 4.18959
196/196 - 78s - loss: 4.0953 - MinusLogProbMetric: 4.0953 - val_loss: 4.4422 - val_MinusLogProbMetric: 4.4422 - lr: 0.0010 - 78s/epoch - 400ms/step
Epoch 140/1000
2023-09-18 03:59:36.348 
Epoch 140/1000 
	 loss: 4.0878, MinusLogProbMetric: 4.0878, val_loss: 4.2047, val_MinusLogProbMetric: 4.2047

Epoch 140: val_loss did not improve from 4.18959
196/196 - 78s - loss: 4.0878 - MinusLogProbMetric: 4.0878 - val_loss: 4.2047 - val_MinusLogProbMetric: 4.2047 - lr: 0.0010 - 78s/epoch - 396ms/step
Epoch 141/1000
2023-09-18 04:00:54.403 
Epoch 141/1000 
	 loss: 4.0903, MinusLogProbMetric: 4.0903, val_loss: 4.2041, val_MinusLogProbMetric: 4.2041

Epoch 141: val_loss did not improve from 4.18959
196/196 - 78s - loss: 4.0903 - MinusLogProbMetric: 4.0903 - val_loss: 4.2041 - val_MinusLogProbMetric: 4.2041 - lr: 0.0010 - 78s/epoch - 398ms/step
Epoch 142/1000
2023-09-18 04:02:14.156 
Epoch 142/1000 
	 loss: 4.0834, MinusLogProbMetric: 4.0834, val_loss: 4.1954, val_MinusLogProbMetric: 4.1954

Epoch 142: val_loss did not improve from 4.18959
196/196 - 80s - loss: 4.0834 - MinusLogProbMetric: 4.0834 - val_loss: 4.1954 - val_MinusLogProbMetric: 4.1954 - lr: 0.0010 - 80s/epoch - 407ms/step
Epoch 143/1000
2023-09-18 04:03:33.209 
Epoch 143/1000 
	 loss: 4.0887, MinusLogProbMetric: 4.0887, val_loss: 4.2064, val_MinusLogProbMetric: 4.2064

Epoch 143: val_loss did not improve from 4.18959
196/196 - 79s - loss: 4.0887 - MinusLogProbMetric: 4.0887 - val_loss: 4.2064 - val_MinusLogProbMetric: 4.2064 - lr: 0.0010 - 79s/epoch - 403ms/step
Epoch 144/1000
2023-09-18 04:04:55.439 
Epoch 144/1000 
	 loss: 4.0953, MinusLogProbMetric: 4.0953, val_loss: 4.2073, val_MinusLogProbMetric: 4.2073

Epoch 144: val_loss did not improve from 4.18959
196/196 - 82s - loss: 4.0953 - MinusLogProbMetric: 4.0953 - val_loss: 4.2073 - val_MinusLogProbMetric: 4.2073 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 145/1000
2023-09-18 04:06:10.657 
Epoch 145/1000 
	 loss: 4.1024, MinusLogProbMetric: 4.1024, val_loss: 4.3739, val_MinusLogProbMetric: 4.3739

Epoch 145: val_loss did not improve from 4.18959
196/196 - 75s - loss: 4.1024 - MinusLogProbMetric: 4.1024 - val_loss: 4.3739 - val_MinusLogProbMetric: 4.3739 - lr: 0.0010 - 75s/epoch - 384ms/step
Epoch 146/1000
2023-09-18 04:07:20.584 
Epoch 146/1000 
	 loss: 4.0910, MinusLogProbMetric: 4.0910, val_loss: 4.2213, val_MinusLogProbMetric: 4.2213

Epoch 146: val_loss did not improve from 4.18959
196/196 - 70s - loss: 4.0910 - MinusLogProbMetric: 4.0910 - val_loss: 4.2213 - val_MinusLogProbMetric: 4.2213 - lr: 0.0010 - 70s/epoch - 357ms/step
Epoch 147/1000
2023-09-18 04:08:29.964 
Epoch 147/1000 
	 loss: 4.0953, MinusLogProbMetric: 4.0953, val_loss: 4.2675, val_MinusLogProbMetric: 4.2675

Epoch 147: val_loss did not improve from 4.18959
196/196 - 69s - loss: 4.0953 - MinusLogProbMetric: 4.0953 - val_loss: 4.2675 - val_MinusLogProbMetric: 4.2675 - lr: 0.0010 - 69s/epoch - 354ms/step
Epoch 148/1000
2023-09-18 04:09:42.630 
Epoch 148/1000 
	 loss: 4.0898, MinusLogProbMetric: 4.0898, val_loss: 4.3490, val_MinusLogProbMetric: 4.3490

Epoch 148: val_loss did not improve from 4.18959
196/196 - 73s - loss: 4.0898 - MinusLogProbMetric: 4.0898 - val_loss: 4.3490 - val_MinusLogProbMetric: 4.3490 - lr: 0.0010 - 73s/epoch - 371ms/step
Epoch 149/1000
2023-09-18 04:11:06.569 
Epoch 149/1000 
	 loss: 4.0956, MinusLogProbMetric: 4.0956, val_loss: 4.2863, val_MinusLogProbMetric: 4.2863

Epoch 149: val_loss did not improve from 4.18959
196/196 - 84s - loss: 4.0956 - MinusLogProbMetric: 4.0956 - val_loss: 4.2863 - val_MinusLogProbMetric: 4.2863 - lr: 0.0010 - 84s/epoch - 428ms/step
Epoch 150/1000
2023-09-18 04:12:28.777 
Epoch 150/1000 
	 loss: 4.1061, MinusLogProbMetric: 4.1061, val_loss: 4.2284, val_MinusLogProbMetric: 4.2284

Epoch 150: val_loss did not improve from 4.18959
196/196 - 82s - loss: 4.1061 - MinusLogProbMetric: 4.1061 - val_loss: 4.2284 - val_MinusLogProbMetric: 4.2284 - lr: 0.0010 - 82s/epoch - 419ms/step
Epoch 151/1000
2023-09-18 04:13:51.494 
Epoch 151/1000 
	 loss: 4.0849, MinusLogProbMetric: 4.0849, val_loss: 4.2132, val_MinusLogProbMetric: 4.2132

Epoch 151: val_loss did not improve from 4.18959
196/196 - 83s - loss: 4.0849 - MinusLogProbMetric: 4.0849 - val_loss: 4.2132 - val_MinusLogProbMetric: 4.2132 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 152/1000
2023-09-18 04:15:14.724 
Epoch 152/1000 
	 loss: 4.0856, MinusLogProbMetric: 4.0856, val_loss: 4.1998, val_MinusLogProbMetric: 4.1998

Epoch 152: val_loss did not improve from 4.18959
196/196 - 83s - loss: 4.0856 - MinusLogProbMetric: 4.0856 - val_loss: 4.1998 - val_MinusLogProbMetric: 4.1998 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 153/1000
2023-09-18 04:16:39.256 
Epoch 153/1000 
	 loss: 4.0893, MinusLogProbMetric: 4.0893, val_loss: 4.2169, val_MinusLogProbMetric: 4.2169

Epoch 153: val_loss did not improve from 4.18959
196/196 - 85s - loss: 4.0893 - MinusLogProbMetric: 4.0893 - val_loss: 4.2169 - val_MinusLogProbMetric: 4.2169 - lr: 0.0010 - 85s/epoch - 431ms/step
Epoch 154/1000
2023-09-18 04:18:02.758 
Epoch 154/1000 
	 loss: 4.0684, MinusLogProbMetric: 4.0684, val_loss: 4.1952, val_MinusLogProbMetric: 4.1952

Epoch 154: val_loss did not improve from 4.18959
196/196 - 83s - loss: 4.0684 - MinusLogProbMetric: 4.0684 - val_loss: 4.1952 - val_MinusLogProbMetric: 4.1952 - lr: 0.0010 - 83s/epoch - 426ms/step
Epoch 155/1000
2023-09-18 04:19:14.130 
Epoch 155/1000 
	 loss: 4.0758, MinusLogProbMetric: 4.0758, val_loss: 4.2587, val_MinusLogProbMetric: 4.2587

Epoch 155: val_loss did not improve from 4.18959
196/196 - 71s - loss: 4.0758 - MinusLogProbMetric: 4.0758 - val_loss: 4.2587 - val_MinusLogProbMetric: 4.2587 - lr: 0.0010 - 71s/epoch - 364ms/step
Epoch 156/1000
2023-09-18 04:20:22.105 
Epoch 156/1000 
	 loss: 4.0701, MinusLogProbMetric: 4.0701, val_loss: 4.2004, val_MinusLogProbMetric: 4.2004

Epoch 156: val_loss did not improve from 4.18959
196/196 - 68s - loss: 4.0701 - MinusLogProbMetric: 4.0701 - val_loss: 4.2004 - val_MinusLogProbMetric: 4.2004 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 157/1000
2023-09-18 04:21:45.647 
Epoch 157/1000 
	 loss: 4.0848, MinusLogProbMetric: 4.0848, val_loss: 4.2382, val_MinusLogProbMetric: 4.2382

Epoch 157: val_loss did not improve from 4.18959
196/196 - 84s - loss: 4.0848 - MinusLogProbMetric: 4.0848 - val_loss: 4.2382 - val_MinusLogProbMetric: 4.2382 - lr: 0.0010 - 84s/epoch - 426ms/step
Epoch 158/1000
2023-09-18 04:23:09.818 
Epoch 158/1000 
	 loss: 4.0738, MinusLogProbMetric: 4.0738, val_loss: 4.2786, val_MinusLogProbMetric: 4.2786

Epoch 158: val_loss did not improve from 4.18959
196/196 - 84s - loss: 4.0738 - MinusLogProbMetric: 4.0738 - val_loss: 4.2786 - val_MinusLogProbMetric: 4.2786 - lr: 0.0010 - 84s/epoch - 429ms/step
Epoch 159/1000
2023-09-18 04:24:34.345 
Epoch 159/1000 
	 loss: 4.0830, MinusLogProbMetric: 4.0830, val_loss: 4.2162, val_MinusLogProbMetric: 4.2162

Epoch 159: val_loss did not improve from 4.18959
196/196 - 85s - loss: 4.0830 - MinusLogProbMetric: 4.0830 - val_loss: 4.2162 - val_MinusLogProbMetric: 4.2162 - lr: 0.0010 - 85s/epoch - 431ms/step
Epoch 160/1000
2023-09-18 04:25:58.791 
Epoch 160/1000 
	 loss: 4.0879, MinusLogProbMetric: 4.0879, val_loss: 4.2985, val_MinusLogProbMetric: 4.2985

Epoch 160: val_loss did not improve from 4.18959
196/196 - 84s - loss: 4.0879 - MinusLogProbMetric: 4.0879 - val_loss: 4.2985 - val_MinusLogProbMetric: 4.2985 - lr: 0.0010 - 84s/epoch - 431ms/step
Epoch 161/1000
2023-09-18 04:27:23.354 
Epoch 161/1000 
	 loss: 4.0912, MinusLogProbMetric: 4.0912, val_loss: 4.2260, val_MinusLogProbMetric: 4.2260

Epoch 161: val_loss did not improve from 4.18959
196/196 - 85s - loss: 4.0912 - MinusLogProbMetric: 4.0912 - val_loss: 4.2260 - val_MinusLogProbMetric: 4.2260 - lr: 0.0010 - 85s/epoch - 431ms/step
Epoch 162/1000
2023-09-18 04:28:48.021 
Epoch 162/1000 
	 loss: 4.0746, MinusLogProbMetric: 4.0746, val_loss: 4.2495, val_MinusLogProbMetric: 4.2495

Epoch 162: val_loss did not improve from 4.18959
196/196 - 85s - loss: 4.0746 - MinusLogProbMetric: 4.0746 - val_loss: 4.2495 - val_MinusLogProbMetric: 4.2495 - lr: 0.0010 - 85s/epoch - 432ms/step
Epoch 163/1000
2023-09-18 04:30:12.355 
Epoch 163/1000 
	 loss: 4.0678, MinusLogProbMetric: 4.0678, val_loss: 4.2302, val_MinusLogProbMetric: 4.2302

Epoch 163: val_loss did not improve from 4.18959
196/196 - 84s - loss: 4.0678 - MinusLogProbMetric: 4.0678 - val_loss: 4.2302 - val_MinusLogProbMetric: 4.2302 - lr: 0.0010 - 84s/epoch - 430ms/step
Epoch 164/1000
2023-09-18 04:31:37.511 
Epoch 164/1000 
	 loss: 4.0706, MinusLogProbMetric: 4.0706, val_loss: 4.2401, val_MinusLogProbMetric: 4.2401

Epoch 164: val_loss did not improve from 4.18959
196/196 - 85s - loss: 4.0706 - MinusLogProbMetric: 4.0706 - val_loss: 4.2401 - val_MinusLogProbMetric: 4.2401 - lr: 0.0010 - 85s/epoch - 434ms/step
Epoch 165/1000
2023-09-18 04:33:02.175 
Epoch 165/1000 
	 loss: 4.0807, MinusLogProbMetric: 4.0807, val_loss: 4.2705, val_MinusLogProbMetric: 4.2705

Epoch 165: val_loss did not improve from 4.18959
196/196 - 85s - loss: 4.0807 - MinusLogProbMetric: 4.0807 - val_loss: 4.2705 - val_MinusLogProbMetric: 4.2705 - lr: 0.0010 - 85s/epoch - 432ms/step
Epoch 166/1000
2023-09-18 04:34:26.804 
Epoch 166/1000 
	 loss: 4.0759, MinusLogProbMetric: 4.0759, val_loss: 4.2355, val_MinusLogProbMetric: 4.2355

Epoch 166: val_loss did not improve from 4.18959
196/196 - 85s - loss: 4.0759 - MinusLogProbMetric: 4.0759 - val_loss: 4.2355 - val_MinusLogProbMetric: 4.2355 - lr: 0.0010 - 85s/epoch - 432ms/step
Epoch 167/1000
2023-09-18 04:35:51.449 
Epoch 167/1000 
	 loss: 4.0688, MinusLogProbMetric: 4.0688, val_loss: 4.2460, val_MinusLogProbMetric: 4.2460

Epoch 167: val_loss did not improve from 4.18959
196/196 - 85s - loss: 4.0688 - MinusLogProbMetric: 4.0688 - val_loss: 4.2460 - val_MinusLogProbMetric: 4.2460 - lr: 0.0010 - 85s/epoch - 432ms/step
Epoch 168/1000
2023-09-18 04:37:16.430 
Epoch 168/1000 
	 loss: 4.0699, MinusLogProbMetric: 4.0699, val_loss: 4.2726, val_MinusLogProbMetric: 4.2726

Epoch 168: val_loss did not improve from 4.18959
196/196 - 85s - loss: 4.0699 - MinusLogProbMetric: 4.0699 - val_loss: 4.2726 - val_MinusLogProbMetric: 4.2726 - lr: 0.0010 - 85s/epoch - 434ms/step
Epoch 169/1000
2023-09-18 04:38:41.694 
Epoch 169/1000 
	 loss: 4.0723, MinusLogProbMetric: 4.0723, val_loss: 4.2572, val_MinusLogProbMetric: 4.2572

Epoch 169: val_loss did not improve from 4.18959
196/196 - 85s - loss: 4.0723 - MinusLogProbMetric: 4.0723 - val_loss: 4.2572 - val_MinusLogProbMetric: 4.2572 - lr: 0.0010 - 85s/epoch - 435ms/step
Epoch 170/1000
2023-09-18 04:39:53.595 
Epoch 170/1000 
	 loss: 4.0668, MinusLogProbMetric: 4.0668, val_loss: 4.2198, val_MinusLogProbMetric: 4.2198

Epoch 170: val_loss did not improve from 4.18959
196/196 - 72s - loss: 4.0668 - MinusLogProbMetric: 4.0668 - val_loss: 4.2198 - val_MinusLogProbMetric: 4.2198 - lr: 0.0010 - 72s/epoch - 367ms/step
Epoch 171/1000
2023-09-18 04:41:07.344 
Epoch 171/1000 
	 loss: 4.0639, MinusLogProbMetric: 4.0639, val_loss: 4.2266, val_MinusLogProbMetric: 4.2266

Epoch 171: val_loss did not improve from 4.18959
196/196 - 74s - loss: 4.0639 - MinusLogProbMetric: 4.0639 - val_loss: 4.2266 - val_MinusLogProbMetric: 4.2266 - lr: 0.0010 - 74s/epoch - 376ms/step
Epoch 172/1000
2023-09-18 04:42:31.684 
Epoch 172/1000 
	 loss: 4.0571, MinusLogProbMetric: 4.0571, val_loss: 4.1818, val_MinusLogProbMetric: 4.1818

Epoch 172: val_loss improved from 4.18959 to 4.18179, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_159/weights/best_weights.h5
196/196 - 86s - loss: 4.0571 - MinusLogProbMetric: 4.0571 - val_loss: 4.1818 - val_MinusLogProbMetric: 4.1818 - lr: 0.0010 - 86s/epoch - 438ms/step
Epoch 173/1000
2023-09-18 04:43:59.284 
Epoch 173/1000 
	 loss: 4.0674, MinusLogProbMetric: 4.0674, val_loss: 4.2471, val_MinusLogProbMetric: 4.2471

Epoch 173: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0674 - MinusLogProbMetric: 4.0674 - val_loss: 4.2471 - val_MinusLogProbMetric: 4.2471 - lr: 0.0010 - 86s/epoch - 439ms/step
Epoch 174/1000
2023-09-18 04:45:24.879 
Epoch 174/1000 
	 loss: 4.0666, MinusLogProbMetric: 4.0666, val_loss: 4.2456, val_MinusLogProbMetric: 4.2456

Epoch 174: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0666 - MinusLogProbMetric: 4.0666 - val_loss: 4.2456 - val_MinusLogProbMetric: 4.2456 - lr: 0.0010 - 86s/epoch - 437ms/step
Epoch 175/1000
2023-09-18 04:46:50.164 
Epoch 175/1000 
	 loss: 4.0616, MinusLogProbMetric: 4.0616, val_loss: 4.2055, val_MinusLogProbMetric: 4.2055

Epoch 175: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0616 - MinusLogProbMetric: 4.0616 - val_loss: 4.2055 - val_MinusLogProbMetric: 4.2055 - lr: 0.0010 - 85s/epoch - 435ms/step
Epoch 176/1000
2023-09-18 04:48:15.322 
Epoch 176/1000 
	 loss: 4.0769, MinusLogProbMetric: 4.0769, val_loss: 4.2458, val_MinusLogProbMetric: 4.2458

Epoch 176: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0769 - MinusLogProbMetric: 4.0769 - val_loss: 4.2458 - val_MinusLogProbMetric: 4.2458 - lr: 0.0010 - 85s/epoch - 434ms/step
Epoch 177/1000
2023-09-18 04:49:40.226 
Epoch 177/1000 
	 loss: 4.0608, MinusLogProbMetric: 4.0608, val_loss: 4.2718, val_MinusLogProbMetric: 4.2718

Epoch 177: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0608 - MinusLogProbMetric: 4.0608 - val_loss: 4.2718 - val_MinusLogProbMetric: 4.2718 - lr: 0.0010 - 85s/epoch - 433ms/step
Epoch 178/1000
2023-09-18 04:51:05.720 
Epoch 178/1000 
	 loss: 4.0705, MinusLogProbMetric: 4.0705, val_loss: 4.2143, val_MinusLogProbMetric: 4.2143

Epoch 178: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0705 - MinusLogProbMetric: 4.0705 - val_loss: 4.2143 - val_MinusLogProbMetric: 4.2143 - lr: 0.0010 - 85s/epoch - 436ms/step
Epoch 179/1000
2023-09-18 04:52:31.705 
Epoch 179/1000 
	 loss: 4.0587, MinusLogProbMetric: 4.0587, val_loss: 4.2346, val_MinusLogProbMetric: 4.2346

Epoch 179: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0587 - MinusLogProbMetric: 4.0587 - val_loss: 4.2346 - val_MinusLogProbMetric: 4.2346 - lr: 0.0010 - 86s/epoch - 439ms/step
Epoch 180/1000
2023-09-18 04:53:57.240 
Epoch 180/1000 
	 loss: 4.0644, MinusLogProbMetric: 4.0644, val_loss: 4.2779, val_MinusLogProbMetric: 4.2779

Epoch 180: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0644 - MinusLogProbMetric: 4.0644 - val_loss: 4.2779 - val_MinusLogProbMetric: 4.2779 - lr: 0.0010 - 86s/epoch - 436ms/step
Epoch 181/1000
2023-09-18 04:55:22.639 
Epoch 181/1000 
	 loss: 4.0546, MinusLogProbMetric: 4.0546, val_loss: 4.3375, val_MinusLogProbMetric: 4.3375

Epoch 181: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0546 - MinusLogProbMetric: 4.0546 - val_loss: 4.3375 - val_MinusLogProbMetric: 4.3375 - lr: 0.0010 - 85s/epoch - 436ms/step
Epoch 182/1000
2023-09-18 04:56:47.922 
Epoch 182/1000 
	 loss: 4.0748, MinusLogProbMetric: 4.0748, val_loss: 4.2992, val_MinusLogProbMetric: 4.2992

Epoch 182: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0748 - MinusLogProbMetric: 4.0748 - val_loss: 4.2992 - val_MinusLogProbMetric: 4.2992 - lr: 0.0010 - 85s/epoch - 435ms/step
Epoch 183/1000
2023-09-18 04:58:12.659 
Epoch 183/1000 
	 loss: 4.0590, MinusLogProbMetric: 4.0590, val_loss: 4.2313, val_MinusLogProbMetric: 4.2313

Epoch 183: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0590 - MinusLogProbMetric: 4.0590 - val_loss: 4.2313 - val_MinusLogProbMetric: 4.2313 - lr: 0.0010 - 85s/epoch - 432ms/step
Epoch 184/1000
2023-09-18 04:59:38.692 
Epoch 184/1000 
	 loss: 4.0623, MinusLogProbMetric: 4.0623, val_loss: 4.2295, val_MinusLogProbMetric: 4.2295

Epoch 184: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0623 - MinusLogProbMetric: 4.0623 - val_loss: 4.2295 - val_MinusLogProbMetric: 4.2295 - lr: 0.0010 - 86s/epoch - 439ms/step
Epoch 185/1000
2023-09-18 05:01:03.937 
Epoch 185/1000 
	 loss: 4.0662, MinusLogProbMetric: 4.0662, val_loss: 4.2064, val_MinusLogProbMetric: 4.2064

Epoch 185: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0662 - MinusLogProbMetric: 4.0662 - val_loss: 4.2064 - val_MinusLogProbMetric: 4.2064 - lr: 0.0010 - 85s/epoch - 435ms/step
Epoch 186/1000
2023-09-18 05:02:28.933 
Epoch 186/1000 
	 loss: 4.0480, MinusLogProbMetric: 4.0480, val_loss: 4.2861, val_MinusLogProbMetric: 4.2861

Epoch 186: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0480 - MinusLogProbMetric: 4.0480 - val_loss: 4.2861 - val_MinusLogProbMetric: 4.2861 - lr: 0.0010 - 85s/epoch - 434ms/step
Epoch 187/1000
2023-09-18 05:03:53.878 
Epoch 187/1000 
	 loss: 4.0580, MinusLogProbMetric: 4.0580, val_loss: 4.2803, val_MinusLogProbMetric: 4.2803

Epoch 187: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0580 - MinusLogProbMetric: 4.0580 - val_loss: 4.2803 - val_MinusLogProbMetric: 4.2803 - lr: 0.0010 - 85s/epoch - 433ms/step
Epoch 188/1000
2023-09-18 05:05:19.741 
Epoch 188/1000 
	 loss: 4.0741, MinusLogProbMetric: 4.0741, val_loss: 4.3177, val_MinusLogProbMetric: 4.3177

Epoch 188: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0741 - MinusLogProbMetric: 4.0741 - val_loss: 4.3177 - val_MinusLogProbMetric: 4.3177 - lr: 0.0010 - 86s/epoch - 438ms/step
Epoch 189/1000
2023-09-18 05:06:45.130 
Epoch 189/1000 
	 loss: 4.0548, MinusLogProbMetric: 4.0548, val_loss: 4.2455, val_MinusLogProbMetric: 4.2455

Epoch 189: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0548 - MinusLogProbMetric: 4.0548 - val_loss: 4.2455 - val_MinusLogProbMetric: 4.2455 - lr: 0.0010 - 85s/epoch - 436ms/step
Epoch 190/1000
2023-09-18 05:08:10.637 
Epoch 190/1000 
	 loss: 4.0559, MinusLogProbMetric: 4.0559, val_loss: 4.2190, val_MinusLogProbMetric: 4.2190

Epoch 190: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0559 - MinusLogProbMetric: 4.0559 - val_loss: 4.2190 - val_MinusLogProbMetric: 4.2190 - lr: 0.0010 - 85s/epoch - 436ms/step
Epoch 191/1000
2023-09-18 05:09:36.357 
Epoch 191/1000 
	 loss: 4.0525, MinusLogProbMetric: 4.0525, val_loss: 4.2340, val_MinusLogProbMetric: 4.2340

Epoch 191: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0525 - MinusLogProbMetric: 4.0525 - val_loss: 4.2340 - val_MinusLogProbMetric: 4.2340 - lr: 0.0010 - 86s/epoch - 437ms/step
Epoch 192/1000
2023-09-18 05:11:01.837 
Epoch 192/1000 
	 loss: 4.0554, MinusLogProbMetric: 4.0554, val_loss: 4.2261, val_MinusLogProbMetric: 4.2261

Epoch 192: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0554 - MinusLogProbMetric: 4.0554 - val_loss: 4.2261 - val_MinusLogProbMetric: 4.2261 - lr: 0.0010 - 85s/epoch - 436ms/step
Epoch 193/1000
2023-09-18 05:12:27.482 
Epoch 193/1000 
	 loss: 4.0618, MinusLogProbMetric: 4.0618, val_loss: 4.2348, val_MinusLogProbMetric: 4.2348

Epoch 193: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0618 - MinusLogProbMetric: 4.0618 - val_loss: 4.2348 - val_MinusLogProbMetric: 4.2348 - lr: 0.0010 - 86s/epoch - 437ms/step
Epoch 194/1000
2023-09-18 05:13:52.275 
Epoch 194/1000 
	 loss: 4.0671, MinusLogProbMetric: 4.0671, val_loss: 4.2031, val_MinusLogProbMetric: 4.2031

Epoch 194: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0671 - MinusLogProbMetric: 4.0671 - val_loss: 4.2031 - val_MinusLogProbMetric: 4.2031 - lr: 0.0010 - 85s/epoch - 433ms/step
Epoch 195/1000
2023-09-18 05:15:17.830 
Epoch 195/1000 
	 loss: 4.0551, MinusLogProbMetric: 4.0551, val_loss: 4.2130, val_MinusLogProbMetric: 4.2130

Epoch 195: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0551 - MinusLogProbMetric: 4.0551 - val_loss: 4.2130 - val_MinusLogProbMetric: 4.2130 - lr: 0.0010 - 86s/epoch - 436ms/step
Epoch 196/1000
2023-09-18 05:16:42.643 
Epoch 196/1000 
	 loss: 4.0591, MinusLogProbMetric: 4.0591, val_loss: 4.2513, val_MinusLogProbMetric: 4.2513

Epoch 196: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0591 - MinusLogProbMetric: 4.0591 - val_loss: 4.2513 - val_MinusLogProbMetric: 4.2513 - lr: 0.0010 - 85s/epoch - 433ms/step
Epoch 197/1000
2023-09-18 05:18:07.582 
Epoch 197/1000 
	 loss: 4.0535, MinusLogProbMetric: 4.0535, val_loss: 4.2235, val_MinusLogProbMetric: 4.2235

Epoch 197: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0535 - MinusLogProbMetric: 4.0535 - val_loss: 4.2235 - val_MinusLogProbMetric: 4.2235 - lr: 0.0010 - 85s/epoch - 433ms/step
Epoch 198/1000
2023-09-18 05:19:33.343 
Epoch 198/1000 
	 loss: 4.0512, MinusLogProbMetric: 4.0512, val_loss: 4.2372, val_MinusLogProbMetric: 4.2372

Epoch 198: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0512 - MinusLogProbMetric: 4.0512 - val_loss: 4.2372 - val_MinusLogProbMetric: 4.2372 - lr: 0.0010 - 86s/epoch - 438ms/step
Epoch 199/1000
2023-09-18 05:20:58.758 
Epoch 199/1000 
	 loss: 4.0496, MinusLogProbMetric: 4.0496, val_loss: 4.2523, val_MinusLogProbMetric: 4.2523

Epoch 199: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0496 - MinusLogProbMetric: 4.0496 - val_loss: 4.2523 - val_MinusLogProbMetric: 4.2523 - lr: 0.0010 - 85s/epoch - 436ms/step
Epoch 200/1000
2023-09-18 05:22:23.645 
Epoch 200/1000 
	 loss: 4.0413, MinusLogProbMetric: 4.0413, val_loss: 4.2462, val_MinusLogProbMetric: 4.2462

Epoch 200: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0413 - MinusLogProbMetric: 4.0413 - val_loss: 4.2462 - val_MinusLogProbMetric: 4.2462 - lr: 0.0010 - 85s/epoch - 433ms/step
Epoch 201/1000
2023-09-18 05:23:49.004 
Epoch 201/1000 
	 loss: 4.0424, MinusLogProbMetric: 4.0424, val_loss: 4.2109, val_MinusLogProbMetric: 4.2109

Epoch 201: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0424 - MinusLogProbMetric: 4.0424 - val_loss: 4.2109 - val_MinusLogProbMetric: 4.2109 - lr: 0.0010 - 85s/epoch - 436ms/step
Epoch 202/1000
2023-09-18 05:25:14.604 
Epoch 202/1000 
	 loss: 4.0562, MinusLogProbMetric: 4.0562, val_loss: 4.2298, val_MinusLogProbMetric: 4.2298

Epoch 202: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0562 - MinusLogProbMetric: 4.0562 - val_loss: 4.2298 - val_MinusLogProbMetric: 4.2298 - lr: 0.0010 - 86s/epoch - 437ms/step
Epoch 203/1000
2023-09-18 05:26:40.263 
Epoch 203/1000 
	 loss: 4.0483, MinusLogProbMetric: 4.0483, val_loss: 4.2113, val_MinusLogProbMetric: 4.2113

Epoch 203: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0483 - MinusLogProbMetric: 4.0483 - val_loss: 4.2113 - val_MinusLogProbMetric: 4.2113 - lr: 0.0010 - 86s/epoch - 437ms/step
Epoch 204/1000
2023-09-18 05:28:05.605 
Epoch 204/1000 
	 loss: 4.0597, MinusLogProbMetric: 4.0597, val_loss: 4.2277, val_MinusLogProbMetric: 4.2277

Epoch 204: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0597 - MinusLogProbMetric: 4.0597 - val_loss: 4.2277 - val_MinusLogProbMetric: 4.2277 - lr: 0.0010 - 85s/epoch - 435ms/step
Epoch 205/1000
2023-09-18 05:29:31.394 
Epoch 205/1000 
	 loss: 4.0452, MinusLogProbMetric: 4.0452, val_loss: 4.2181, val_MinusLogProbMetric: 4.2181

Epoch 205: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0452 - MinusLogProbMetric: 4.0452 - val_loss: 4.2181 - val_MinusLogProbMetric: 4.2181 - lr: 0.0010 - 86s/epoch - 438ms/step
Epoch 206/1000
2023-09-18 05:30:56.699 
Epoch 206/1000 
	 loss: 4.0538, MinusLogProbMetric: 4.0538, val_loss: 4.2117, val_MinusLogProbMetric: 4.2117

Epoch 206: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0538 - MinusLogProbMetric: 4.0538 - val_loss: 4.2117 - val_MinusLogProbMetric: 4.2117 - lr: 0.0010 - 85s/epoch - 435ms/step
Epoch 207/1000
2023-09-18 05:32:22.201 
Epoch 207/1000 
	 loss: 4.0660, MinusLogProbMetric: 4.0660, val_loss: 4.2474, val_MinusLogProbMetric: 4.2474

Epoch 207: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0660 - MinusLogProbMetric: 4.0660 - val_loss: 4.2474 - val_MinusLogProbMetric: 4.2474 - lr: 0.0010 - 86s/epoch - 436ms/step
Epoch 208/1000
2023-09-18 05:33:48.245 
Epoch 208/1000 
	 loss: 4.0369, MinusLogProbMetric: 4.0369, val_loss: 4.2408, val_MinusLogProbMetric: 4.2408

Epoch 208: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0369 - MinusLogProbMetric: 4.0369 - val_loss: 4.2408 - val_MinusLogProbMetric: 4.2408 - lr: 0.0010 - 86s/epoch - 439ms/step
Epoch 209/1000
2023-09-18 05:35:13.811 
Epoch 209/1000 
	 loss: 4.0576, MinusLogProbMetric: 4.0576, val_loss: 4.4103, val_MinusLogProbMetric: 4.4103

Epoch 209: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0576 - MinusLogProbMetric: 4.0576 - val_loss: 4.4103 - val_MinusLogProbMetric: 4.4103 - lr: 0.0010 - 86s/epoch - 437ms/step
Epoch 210/1000
2023-09-18 05:36:39.180 
Epoch 210/1000 
	 loss: 4.0594, MinusLogProbMetric: 4.0594, val_loss: 4.2608, val_MinusLogProbMetric: 4.2608

Epoch 210: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0594 - MinusLogProbMetric: 4.0594 - val_loss: 4.2608 - val_MinusLogProbMetric: 4.2608 - lr: 0.0010 - 85s/epoch - 436ms/step
Epoch 211/1000
2023-09-18 05:38:05.274 
Epoch 211/1000 
	 loss: 4.0426, MinusLogProbMetric: 4.0426, val_loss: 4.2321, val_MinusLogProbMetric: 4.2321

Epoch 211: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0426 - MinusLogProbMetric: 4.0426 - val_loss: 4.2321 - val_MinusLogProbMetric: 4.2321 - lr: 0.0010 - 86s/epoch - 439ms/step
Epoch 212/1000
2023-09-18 05:39:31.433 
Epoch 212/1000 
	 loss: 4.0372, MinusLogProbMetric: 4.0372, val_loss: 4.3465, val_MinusLogProbMetric: 4.3465

Epoch 212: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0372 - MinusLogProbMetric: 4.0372 - val_loss: 4.3465 - val_MinusLogProbMetric: 4.3465 - lr: 0.0010 - 86s/epoch - 440ms/step
Epoch 213/1000
2023-09-18 05:40:57.294 
Epoch 213/1000 
	 loss: 4.0611, MinusLogProbMetric: 4.0611, val_loss: 4.2884, val_MinusLogProbMetric: 4.2884

Epoch 213: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0611 - MinusLogProbMetric: 4.0611 - val_loss: 4.2884 - val_MinusLogProbMetric: 4.2884 - lr: 0.0010 - 86s/epoch - 438ms/step
Epoch 214/1000
2023-09-18 05:42:22.995 
Epoch 214/1000 
	 loss: 4.0491, MinusLogProbMetric: 4.0491, val_loss: 4.2577, val_MinusLogProbMetric: 4.2577

Epoch 214: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0491 - MinusLogProbMetric: 4.0491 - val_loss: 4.2577 - val_MinusLogProbMetric: 4.2577 - lr: 0.0010 - 86s/epoch - 437ms/step
Epoch 215/1000
2023-09-18 05:43:48.088 
Epoch 215/1000 
	 loss: 4.0409, MinusLogProbMetric: 4.0409, val_loss: 4.2567, val_MinusLogProbMetric: 4.2567

Epoch 215: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0409 - MinusLogProbMetric: 4.0409 - val_loss: 4.2567 - val_MinusLogProbMetric: 4.2567 - lr: 0.0010 - 85s/epoch - 434ms/step
Epoch 216/1000
2023-09-18 05:45:12.706 
Epoch 216/1000 
	 loss: 4.0457, MinusLogProbMetric: 4.0457, val_loss: 4.2566, val_MinusLogProbMetric: 4.2566

Epoch 216: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0457 - MinusLogProbMetric: 4.0457 - val_loss: 4.2566 - val_MinusLogProbMetric: 4.2566 - lr: 0.0010 - 85s/epoch - 432ms/step
Epoch 217/1000
2023-09-18 05:46:38.104 
Epoch 217/1000 
	 loss: 4.0543, MinusLogProbMetric: 4.0543, val_loss: 4.2346, val_MinusLogProbMetric: 4.2346

Epoch 217: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0543 - MinusLogProbMetric: 4.0543 - val_loss: 4.2346 - val_MinusLogProbMetric: 4.2346 - lr: 0.0010 - 85s/epoch - 436ms/step
Epoch 218/1000
2023-09-18 05:48:02.941 
Epoch 218/1000 
	 loss: 4.0428, MinusLogProbMetric: 4.0428, val_loss: 4.2100, val_MinusLogProbMetric: 4.2100

Epoch 218: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0428 - MinusLogProbMetric: 4.0428 - val_loss: 4.2100 - val_MinusLogProbMetric: 4.2100 - lr: 0.0010 - 85s/epoch - 433ms/step
Epoch 219/1000
2023-09-18 05:49:27.322 
Epoch 219/1000 
	 loss: 4.0415, MinusLogProbMetric: 4.0415, val_loss: 4.2555, val_MinusLogProbMetric: 4.2555

Epoch 219: val_loss did not improve from 4.18179
196/196 - 84s - loss: 4.0415 - MinusLogProbMetric: 4.0415 - val_loss: 4.2555 - val_MinusLogProbMetric: 4.2555 - lr: 0.0010 - 84s/epoch - 431ms/step
Epoch 220/1000
2023-09-18 05:50:52.922 
Epoch 220/1000 
	 loss: 4.0350, MinusLogProbMetric: 4.0350, val_loss: 4.2375, val_MinusLogProbMetric: 4.2375

Epoch 220: val_loss did not improve from 4.18179
196/196 - 86s - loss: 4.0350 - MinusLogProbMetric: 4.0350 - val_loss: 4.2375 - val_MinusLogProbMetric: 4.2375 - lr: 0.0010 - 86s/epoch - 437ms/step
Epoch 221/1000
2023-09-18 05:52:17.946 
Epoch 221/1000 
	 loss: 4.0400, MinusLogProbMetric: 4.0400, val_loss: 4.2445, val_MinusLogProbMetric: 4.2445

Epoch 221: val_loss did not improve from 4.18179
196/196 - 85s - loss: 4.0400 - MinusLogProbMetric: 4.0400 - val_loss: 4.2445 - val_MinusLogProbMetric: 4.2445 - lr: 0.0010 - 85s/epoch - 434ms/step
Epoch 222/1000
2023-09-18 05:53:42.398 
Epoch 222/1000 
	 loss: 4.0458, MinusLogProbMetric: 4.0458, val_loss: 4.2208, val_MinusLogProbMetric: 4.2208

Epoch 222: val_loss did not improve from 4.18179
196/196 - 84s - loss: 4.0458 - MinusLogProbMetric: 4.0458 - val_loss: 4.2208 - val_MinusLogProbMetric: 4.2208 - lr: 0.0010 - 84s/epoch - 431ms/step
Epoch 223/1000
2023-09-18 05:54:57.847 
Epoch 223/1000 
	 loss: 3.9829, MinusLogProbMetric: 3.9829, val_loss: 4.2093, val_MinusLogProbMetric: 4.2093

Epoch 223: val_loss did not improve from 4.18179
196/196 - 75s - loss: 3.9829 - MinusLogProbMetric: 3.9829 - val_loss: 4.2093 - val_MinusLogProbMetric: 4.2093 - lr: 5.0000e-04 - 75s/epoch - 385ms/step
Epoch 224/1000
2023-09-18 05:56:13.090 
Epoch 224/1000 
	 loss: 3.9845, MinusLogProbMetric: 3.9845, val_loss: 4.2170, val_MinusLogProbMetric: 4.2170

Epoch 224: val_loss did not improve from 4.18179
196/196 - 75s - loss: 3.9845 - MinusLogProbMetric: 3.9845 - val_loss: 4.2170 - val_MinusLogProbMetric: 4.2170 - lr: 5.0000e-04 - 75s/epoch - 384ms/step
Epoch 225/1000
2023-09-18 05:57:37.258 
Epoch 225/1000 
	 loss: 3.9867, MinusLogProbMetric: 3.9867, val_loss: 4.2304, val_MinusLogProbMetric: 4.2304

Epoch 225: val_loss did not improve from 4.18179
196/196 - 84s - loss: 3.9867 - MinusLogProbMetric: 3.9867 - val_loss: 4.2304 - val_MinusLogProbMetric: 4.2304 - lr: 5.0000e-04 - 84s/epoch - 429ms/step
Epoch 226/1000
2023-09-18 05:59:02.774 
Epoch 226/1000 
	 loss: 3.9816, MinusLogProbMetric: 3.9816, val_loss: 4.2049, val_MinusLogProbMetric: 4.2049

Epoch 226: val_loss did not improve from 4.18179
196/196 - 86s - loss: 3.9816 - MinusLogProbMetric: 3.9816 - val_loss: 4.2049 - val_MinusLogProbMetric: 4.2049 - lr: 5.0000e-04 - 86s/epoch - 436ms/step
Epoch 227/1000
2023-09-18 06:00:28.418 
Epoch 227/1000 
	 loss: 3.9759, MinusLogProbMetric: 3.9759, val_loss: 4.2152, val_MinusLogProbMetric: 4.2152

Epoch 227: val_loss did not improve from 4.18179
196/196 - 86s - loss: 3.9759 - MinusLogProbMetric: 3.9759 - val_loss: 4.2152 - val_MinusLogProbMetric: 4.2152 - lr: 5.0000e-04 - 86s/epoch - 437ms/step
Epoch 228/1000
2023-09-18 06:01:54.154 
Epoch 228/1000 
	 loss: 3.9765, MinusLogProbMetric: 3.9765, val_loss: 4.2238, val_MinusLogProbMetric: 4.2238

Epoch 228: val_loss did not improve from 4.18179
196/196 - 86s - loss: 3.9765 - MinusLogProbMetric: 3.9765 - val_loss: 4.2238 - val_MinusLogProbMetric: 4.2238 - lr: 5.0000e-04 - 86s/epoch - 437ms/step
Epoch 229/1000
2023-09-18 06:03:19.163 
Epoch 229/1000 
	 loss: 3.9763, MinusLogProbMetric: 3.9763, val_loss: 4.2048, val_MinusLogProbMetric: 4.2048

Epoch 229: val_loss did not improve from 4.18179
196/196 - 85s - loss: 3.9763 - MinusLogProbMetric: 3.9763 - val_loss: 4.2048 - val_MinusLogProbMetric: 4.2048 - lr: 5.0000e-04 - 85s/epoch - 434ms/step
Epoch 230/1000
2023-09-18 06:04:42.941 
Epoch 230/1000 
	 loss: 3.9801, MinusLogProbMetric: 3.9801, val_loss: 4.2119, val_MinusLogProbMetric: 4.2119

Epoch 230: val_loss did not improve from 4.18179
196/196 - 84s - loss: 3.9801 - MinusLogProbMetric: 3.9801 - val_loss: 4.2119 - val_MinusLogProbMetric: 4.2119 - lr: 5.0000e-04 - 84s/epoch - 427ms/step
Epoch 231/1000
2023-09-18 06:05:54.681 
Epoch 231/1000 
	 loss: 3.9749, MinusLogProbMetric: 3.9749, val_loss: 4.2378, val_MinusLogProbMetric: 4.2378

Epoch 231: val_loss did not improve from 4.18179
196/196 - 72s - loss: 3.9749 - MinusLogProbMetric: 3.9749 - val_loss: 4.2378 - val_MinusLogProbMetric: 4.2378 - lr: 5.0000e-04 - 72s/epoch - 366ms/step
Epoch 232/1000
2023-09-18 06:07:02.000 
Epoch 232/1000 
	 loss: 3.9712, MinusLogProbMetric: 3.9712, val_loss: 4.2393, val_MinusLogProbMetric: 4.2393

Epoch 232: val_loss did not improve from 4.18179
196/196 - 67s - loss: 3.9712 - MinusLogProbMetric: 3.9712 - val_loss: 4.2393 - val_MinusLogProbMetric: 4.2393 - lr: 5.0000e-04 - 67s/epoch - 343ms/step
Epoch 233/1000
2023-09-18 06:08:21.803 
Epoch 233/1000 
	 loss: 3.9750, MinusLogProbMetric: 3.9750, val_loss: 4.2284, val_MinusLogProbMetric: 4.2284

Epoch 233: val_loss did not improve from 4.18179
196/196 - 80s - loss: 3.9750 - MinusLogProbMetric: 3.9750 - val_loss: 4.2284 - val_MinusLogProbMetric: 4.2284 - lr: 5.0000e-04 - 80s/epoch - 407ms/step
Epoch 234/1000
2023-09-18 06:09:45.084 
Epoch 234/1000 
	 loss: 3.9766, MinusLogProbMetric: 3.9766, val_loss: 4.2302, val_MinusLogProbMetric: 4.2302

Epoch 234: val_loss did not improve from 4.18179
196/196 - 83s - loss: 3.9766 - MinusLogProbMetric: 3.9766 - val_loss: 4.2302 - val_MinusLogProbMetric: 4.2302 - lr: 5.0000e-04 - 83s/epoch - 425ms/step
Epoch 235/1000
2023-09-18 06:11:10.280 
Epoch 235/1000 
	 loss: 3.9717, MinusLogProbMetric: 3.9717, val_loss: 4.2406, val_MinusLogProbMetric: 4.2406

Epoch 235: val_loss did not improve from 4.18179
196/196 - 85s - loss: 3.9717 - MinusLogProbMetric: 3.9717 - val_loss: 4.2406 - val_MinusLogProbMetric: 4.2406 - lr: 5.0000e-04 - 85s/epoch - 435ms/step
Epoch 236/1000
2023-09-18 06:12:35.226 
Epoch 236/1000 
	 loss: 3.9696, MinusLogProbMetric: 3.9696, val_loss: 4.2185, val_MinusLogProbMetric: 4.2185

Epoch 236: val_loss did not improve from 4.18179
196/196 - 85s - loss: 3.9696 - MinusLogProbMetric: 3.9696 - val_loss: 4.2185 - val_MinusLogProbMetric: 4.2185 - lr: 5.0000e-04 - 85s/epoch - 433ms/step
Epoch 237/1000
2023-09-18 06:14:00.589 
Epoch 237/1000 
	 loss: 3.9735, MinusLogProbMetric: 3.9735, val_loss: 4.2760, val_MinusLogProbMetric: 4.2760

Epoch 237: val_loss did not improve from 4.18179
196/196 - 85s - loss: 3.9735 - MinusLogProbMetric: 3.9735 - val_loss: 4.2760 - val_MinusLogProbMetric: 4.2760 - lr: 5.0000e-04 - 85s/epoch - 436ms/step
Epoch 238/1000
2023-09-18 06:15:10.174 
Epoch 238/1000 
	 loss: 3.9765, MinusLogProbMetric: 3.9765, val_loss: 4.2132, val_MinusLogProbMetric: 4.2132

Epoch 238: val_loss did not improve from 4.18179
196/196 - 70s - loss: 3.9765 - MinusLogProbMetric: 3.9765 - val_loss: 4.2132 - val_MinusLogProbMetric: 4.2132 - lr: 5.0000e-04 - 70s/epoch - 355ms/step
Epoch 239/1000
2023-09-18 06:16:17.197 
Epoch 239/1000 
	 loss: 3.9809, MinusLogProbMetric: 3.9809, val_loss: 4.2225, val_MinusLogProbMetric: 4.2225

Epoch 239: val_loss did not improve from 4.18179
196/196 - 67s - loss: 3.9809 - MinusLogProbMetric: 3.9809 - val_loss: 4.2225 - val_MinusLogProbMetric: 4.2225 - lr: 5.0000e-04 - 67s/epoch - 342ms/step
Epoch 240/1000
2023-09-18 06:17:35.114 
Epoch 240/1000 
	 loss: 3.9748, MinusLogProbMetric: 3.9748, val_loss: 4.2191, val_MinusLogProbMetric: 4.2191

Epoch 240: val_loss did not improve from 4.18179
196/196 - 78s - loss: 3.9748 - MinusLogProbMetric: 3.9748 - val_loss: 4.2191 - val_MinusLogProbMetric: 4.2191 - lr: 5.0000e-04 - 78s/epoch - 398ms/step
Epoch 241/1000
2023-09-18 06:18:59.356 
Epoch 241/1000 
	 loss: 3.9698, MinusLogProbMetric: 3.9698, val_loss: 4.2329, val_MinusLogProbMetric: 4.2329

Epoch 241: val_loss did not improve from 4.18179
196/196 - 84s - loss: 3.9698 - MinusLogProbMetric: 3.9698 - val_loss: 4.2329 - val_MinusLogProbMetric: 4.2329 - lr: 5.0000e-04 - 84s/epoch - 430ms/step
Epoch 242/1000
2023-09-18 06:20:24.595 
Epoch 242/1000 
	 loss: 3.9730, MinusLogProbMetric: 3.9730, val_loss: 4.2209, val_MinusLogProbMetric: 4.2209

Epoch 242: val_loss did not improve from 4.18179
196/196 - 85s - loss: 3.9730 - MinusLogProbMetric: 3.9730 - val_loss: 4.2209 - val_MinusLogProbMetric: 4.2209 - lr: 5.0000e-04 - 85s/epoch - 435ms/step
Epoch 243/1000
2023-09-18 06:21:49.877 
Epoch 243/1000 
	 loss: 3.9713, MinusLogProbMetric: 3.9713, val_loss: 4.2429, val_MinusLogProbMetric: 4.2429

Epoch 243: val_loss did not improve from 4.18179
196/196 - 85s - loss: 3.9713 - MinusLogProbMetric: 3.9713 - val_loss: 4.2429 - val_MinusLogProbMetric: 4.2429 - lr: 5.0000e-04 - 85s/epoch - 435ms/step
Epoch 244/1000
2023-09-18 06:23:15.174 
Epoch 244/1000 
	 loss: 3.9730, MinusLogProbMetric: 3.9730, val_loss: 4.2385, val_MinusLogProbMetric: 4.2385

Epoch 244: val_loss did not improve from 4.18179
196/196 - 85s - loss: 3.9730 - MinusLogProbMetric: 3.9730 - val_loss: 4.2385 - val_MinusLogProbMetric: 4.2385 - lr: 5.0000e-04 - 85s/epoch - 435ms/step
Epoch 245/1000
2023-09-18 06:24:40.100 
Epoch 245/1000 
	 loss: 3.9729, MinusLogProbMetric: 3.9729, val_loss: 4.2190, val_MinusLogProbMetric: 4.2190

Epoch 245: val_loss did not improve from 4.18179
196/196 - 85s - loss: 3.9729 - MinusLogProbMetric: 3.9729 - val_loss: 4.2190 - val_MinusLogProbMetric: 4.2190 - lr: 5.0000e-04 - 85s/epoch - 433ms/step
Epoch 246/1000
2023-09-18 06:26:05.019 
Epoch 246/1000 
	 loss: 3.9732, MinusLogProbMetric: 3.9732, val_loss: 4.2379, val_MinusLogProbMetric: 4.2379

Epoch 246: val_loss did not improve from 4.18179
196/196 - 85s - loss: 3.9732 - MinusLogProbMetric: 3.9732 - val_loss: 4.2379 - val_MinusLogProbMetric: 4.2379 - lr: 5.0000e-04 - 85s/epoch - 433ms/step
Epoch 247/1000
2023-09-18 06:27:29.905 
Epoch 247/1000 
	 loss: 3.9687, MinusLogProbMetric: 3.9687, val_loss: 4.2490, val_MinusLogProbMetric: 4.2490

Epoch 247: val_loss did not improve from 4.18179
196/196 - 85s - loss: 3.9687 - MinusLogProbMetric: 3.9687 - val_loss: 4.2490 - val_MinusLogProbMetric: 4.2490 - lr: 5.0000e-04 - 85s/epoch - 433ms/step
Epoch 248/1000
2023-09-18 06:28:55.059 
Epoch 248/1000 
	 loss: 3.9705, MinusLogProbMetric: 3.9705, val_loss: 4.2271, val_MinusLogProbMetric: 4.2271

Epoch 248: val_loss did not improve from 4.18179
196/196 - 85s - loss: 3.9705 - MinusLogProbMetric: 3.9705 - val_loss: 4.2271 - val_MinusLogProbMetric: 4.2271 - lr: 5.0000e-04 - 85s/epoch - 434ms/step
Epoch 249/1000
2023-09-18 06:30:20.656 
Epoch 249/1000 
	 loss: 3.9731, MinusLogProbMetric: 3.9731, val_loss: 4.2190, val_MinusLogProbMetric: 4.2190

Epoch 249: val_loss did not improve from 4.18179
196/196 - 86s - loss: 3.9731 - MinusLogProbMetric: 3.9731 - val_loss: 4.2190 - val_MinusLogProbMetric: 4.2190 - lr: 5.0000e-04 - 86s/epoch - 437ms/step
Epoch 250/1000
2023-09-18 06:31:45.261 
Epoch 250/1000 
	 loss: 3.9694, MinusLogProbMetric: 3.9694, val_loss: 4.2467, val_MinusLogProbMetric: 4.2467

Epoch 250: val_loss did not improve from 4.18179
196/196 - 85s - loss: 3.9694 - MinusLogProbMetric: 3.9694 - val_loss: 4.2467 - val_MinusLogProbMetric: 4.2467 - lr: 5.0000e-04 - 85s/epoch - 432ms/step
Epoch 251/1000
2023-09-18 06:33:09.847 
Epoch 251/1000 
	 loss: 3.9687, MinusLogProbMetric: 3.9687, val_loss: 4.2190, val_MinusLogProbMetric: 4.2190

Epoch 251: val_loss did not improve from 4.18179
196/196 - 85s - loss: 3.9687 - MinusLogProbMetric: 3.9687 - val_loss: 4.2190 - val_MinusLogProbMetric: 4.2190 - lr: 5.0000e-04 - 85s/epoch - 432ms/step
Epoch 252/1000
2023-09-18 06:34:34.868 
Epoch 252/1000 
	 loss: 3.9672, MinusLogProbMetric: 3.9672, val_loss: 4.2654, val_MinusLogProbMetric: 4.2654

Epoch 252: val_loss did not improve from 4.18179
196/196 - 85s - loss: 3.9672 - MinusLogProbMetric: 3.9672 - val_loss: 4.2654 - val_MinusLogProbMetric: 4.2654 - lr: 5.0000e-04 - 85s/epoch - 434ms/step
Epoch 253/1000
2023-09-18 06:35:59.599 
Epoch 253/1000 
	 loss: 3.9668, MinusLogProbMetric: 3.9668, val_loss: 4.2321, val_MinusLogProbMetric: 4.2321

Epoch 253: val_loss did not improve from 4.18179
196/196 - 85s - loss: 3.9668 - MinusLogProbMetric: 3.9668 - val_loss: 4.2321 - val_MinusLogProbMetric: 4.2321 - lr: 5.0000e-04 - 85s/epoch - 432ms/step
Epoch 254/1000
2023-09-18 06:37:24.778 
Epoch 254/1000 
	 loss: 3.9736, MinusLogProbMetric: 3.9736, val_loss: 4.2314, val_MinusLogProbMetric: 4.2314

Epoch 254: val_loss did not improve from 4.18179
196/196 - 85s - loss: 3.9736 - MinusLogProbMetric: 3.9736 - val_loss: 4.2314 - val_MinusLogProbMetric: 4.2314 - lr: 5.0000e-04 - 85s/epoch - 435ms/step
Epoch 255/1000
2023-09-18 06:38:48.892 
Epoch 255/1000 
	 loss: 3.9670, MinusLogProbMetric: 3.9670, val_loss: 4.2413, val_MinusLogProbMetric: 4.2413

Epoch 255: val_loss did not improve from 4.18179
196/196 - 84s - loss: 3.9670 - MinusLogProbMetric: 3.9670 - val_loss: 4.2413 - val_MinusLogProbMetric: 4.2413 - lr: 5.0000e-04 - 84s/epoch - 429ms/step
Epoch 256/1000
2023-09-18 06:40:13.359 
Epoch 256/1000 
	 loss: 3.9606, MinusLogProbMetric: 3.9606, val_loss: 4.2303, val_MinusLogProbMetric: 4.2303

Epoch 256: val_loss did not improve from 4.18179
196/196 - 84s - loss: 3.9606 - MinusLogProbMetric: 3.9606 - val_loss: 4.2303 - val_MinusLogProbMetric: 4.2303 - lr: 5.0000e-04 - 84s/epoch - 431ms/step
Epoch 257/1000
2023-09-18 06:41:38.511 
Epoch 257/1000 
	 loss: 3.9688, MinusLogProbMetric: 3.9688, val_loss: 4.2385, val_MinusLogProbMetric: 4.2385

Epoch 257: val_loss did not improve from 4.18179
196/196 - 85s - loss: 3.9688 - MinusLogProbMetric: 3.9688 - val_loss: 4.2385 - val_MinusLogProbMetric: 4.2385 - lr: 5.0000e-04 - 85s/epoch - 434ms/step
Epoch 258/1000
2023-09-18 06:43:01.658 
Epoch 258/1000 
	 loss: 3.9739, MinusLogProbMetric: 3.9739, val_loss: 4.2336, val_MinusLogProbMetric: 4.2336

Epoch 258: val_loss did not improve from 4.18179
196/196 - 83s - loss: 3.9739 - MinusLogProbMetric: 3.9739 - val_loss: 4.2336 - val_MinusLogProbMetric: 4.2336 - lr: 5.0000e-04 - 83s/epoch - 424ms/step
Epoch 259/1000
2023-09-18 06:44:13.293 
Epoch 259/1000 
	 loss: 3.9690, MinusLogProbMetric: 3.9690, val_loss: 4.2371, val_MinusLogProbMetric: 4.2371

Epoch 259: val_loss did not improve from 4.18179
196/196 - 72s - loss: 3.9690 - MinusLogProbMetric: 3.9690 - val_loss: 4.2371 - val_MinusLogProbMetric: 4.2371 - lr: 5.0000e-04 - 72s/epoch - 365ms/step
Epoch 260/1000
2023-09-18 06:45:19.191 
Epoch 260/1000 
	 loss: 3.9626, MinusLogProbMetric: 3.9626, val_loss: 4.2431, val_MinusLogProbMetric: 4.2431

Epoch 260: val_loss did not improve from 4.18179
196/196 - 66s - loss: 3.9626 - MinusLogProbMetric: 3.9626 - val_loss: 4.2431 - val_MinusLogProbMetric: 4.2431 - lr: 5.0000e-04 - 66s/epoch - 336ms/step
Epoch 261/1000
2023-09-18 06:46:38.837 
Epoch 261/1000 
	 loss: 3.9638, MinusLogProbMetric: 3.9638, val_loss: 4.2639, val_MinusLogProbMetric: 4.2639

Epoch 261: val_loss did not improve from 4.18179
196/196 - 80s - loss: 3.9638 - MinusLogProbMetric: 3.9638 - val_loss: 4.2639 - val_MinusLogProbMetric: 4.2639 - lr: 5.0000e-04 - 80s/epoch - 406ms/step
Epoch 262/1000
2023-09-18 06:48:00.056 
Epoch 262/1000 
	 loss: 3.9737, MinusLogProbMetric: 3.9737, val_loss: 4.2362, val_MinusLogProbMetric: 4.2362

Epoch 262: val_loss did not improve from 4.18179
196/196 - 81s - loss: 3.9737 - MinusLogProbMetric: 3.9737 - val_loss: 4.2362 - val_MinusLogProbMetric: 4.2362 - lr: 5.0000e-04 - 81s/epoch - 414ms/step
Epoch 263/1000
2023-09-18 06:49:24.598 
Epoch 263/1000 
	 loss: 3.9659, MinusLogProbMetric: 3.9659, val_loss: 4.2418, val_MinusLogProbMetric: 4.2418

Epoch 263: val_loss did not improve from 4.18179
196/196 - 85s - loss: 3.9659 - MinusLogProbMetric: 3.9659 - val_loss: 4.2418 - val_MinusLogProbMetric: 4.2418 - lr: 5.0000e-04 - 85s/epoch - 431ms/step
Epoch 264/1000
2023-09-18 06:50:47.962 
Epoch 264/1000 
	 loss: 3.9655, MinusLogProbMetric: 3.9655, val_loss: 4.2836, val_MinusLogProbMetric: 4.2836

Epoch 264: val_loss did not improve from 4.18179
196/196 - 83s - loss: 3.9655 - MinusLogProbMetric: 3.9655 - val_loss: 4.2836 - val_MinusLogProbMetric: 4.2836 - lr: 5.0000e-04 - 83s/epoch - 425ms/step
Epoch 265/1000
2023-09-18 06:52:12.084 
Epoch 265/1000 
	 loss: 3.9647, MinusLogProbMetric: 3.9647, val_loss: 4.2433, val_MinusLogProbMetric: 4.2433

Epoch 265: val_loss did not improve from 4.18179
196/196 - 84s - loss: 3.9647 - MinusLogProbMetric: 3.9647 - val_loss: 4.2433 - val_MinusLogProbMetric: 4.2433 - lr: 5.0000e-04 - 84s/epoch - 429ms/step
Epoch 266/1000
2023-09-18 06:53:36.828 
Epoch 266/1000 
	 loss: 3.9672, MinusLogProbMetric: 3.9672, val_loss: 4.2529, val_MinusLogProbMetric: 4.2529

Epoch 266: val_loss did not improve from 4.18179
196/196 - 85s - loss: 3.9672 - MinusLogProbMetric: 3.9672 - val_loss: 4.2529 - val_MinusLogProbMetric: 4.2529 - lr: 5.0000e-04 - 85s/epoch - 432ms/step
Epoch 267/1000
2023-09-18 06:55:00.892 
Epoch 267/1000 
	 loss: 3.9662, MinusLogProbMetric: 3.9662, val_loss: 4.2552, val_MinusLogProbMetric: 4.2552

Epoch 267: val_loss did not improve from 4.18179
196/196 - 84s - loss: 3.9662 - MinusLogProbMetric: 3.9662 - val_loss: 4.2552 - val_MinusLogProbMetric: 4.2552 - lr: 5.0000e-04 - 84s/epoch - 429ms/step
Epoch 268/1000
2023-09-18 06:56:24.632 
Epoch 268/1000 
	 loss: 3.9662, MinusLogProbMetric: 3.9662, val_loss: 4.2459, val_MinusLogProbMetric: 4.2459

Epoch 268: val_loss did not improve from 4.18179
196/196 - 84s - loss: 3.9662 - MinusLogProbMetric: 3.9662 - val_loss: 4.2459 - val_MinusLogProbMetric: 4.2459 - lr: 5.0000e-04 - 84s/epoch - 427ms/step
Epoch 269/1000
2023-09-18 06:57:48.576 
Epoch 269/1000 
	 loss: 3.9744, MinusLogProbMetric: 3.9744, val_loss: 4.2580, val_MinusLogProbMetric: 4.2580

Epoch 269: val_loss did not improve from 4.18179
196/196 - 84s - loss: 3.9744 - MinusLogProbMetric: 3.9744 - val_loss: 4.2580 - val_MinusLogProbMetric: 4.2580 - lr: 5.0000e-04 - 84s/epoch - 428ms/step
Epoch 270/1000
2023-09-18 06:59:12.779 
Epoch 270/1000 
	 loss: 3.9603, MinusLogProbMetric: 3.9603, val_loss: 4.2757, val_MinusLogProbMetric: 4.2757

Epoch 270: val_loss did not improve from 4.18179
196/196 - 84s - loss: 3.9603 - MinusLogProbMetric: 3.9603 - val_loss: 4.2757 - val_MinusLogProbMetric: 4.2757 - lr: 5.0000e-04 - 84s/epoch - 430ms/step
Epoch 271/1000
2023-09-18 07:00:37.440 
Epoch 271/1000 
	 loss: 3.9668, MinusLogProbMetric: 3.9668, val_loss: 4.2555, val_MinusLogProbMetric: 4.2555

Epoch 271: val_loss did not improve from 4.18179
196/196 - 85s - loss: 3.9668 - MinusLogProbMetric: 3.9668 - val_loss: 4.2555 - val_MinusLogProbMetric: 4.2555 - lr: 5.0000e-04 - 85s/epoch - 432ms/step
Epoch 272/1000
2023-09-18 07:02:01.355 
Epoch 272/1000 
	 loss: 3.9600, MinusLogProbMetric: 3.9600, val_loss: 4.2910, val_MinusLogProbMetric: 4.2910

Epoch 272: val_loss did not improve from 4.18179
Restoring model weights from the end of the best epoch: 172.
196/196 - 85s - loss: 3.9600 - MinusLogProbMetric: 3.9600 - val_loss: 4.2910 - val_MinusLogProbMetric: 4.2910 - lr: 5.0000e-04 - 85s/epoch - 432ms/step
Epoch 272: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 39.171953595941886 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 12.056385822128505 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 11.112066953908652 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fadaacd4b80> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 34.18324459902942 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 12.421146298060194 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 9.748173570958897 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7faea4c340d0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 933.
Model trained in 22255.10 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

Plots done in 9.92 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 160.12 s.
===========
Run 159/720 done in 22427.75 s.
===========

Directory ../../results/CsplineN_new/run_160/ already exists.
Skipping it.
===========
Run 160/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_161/ already exists.
Skipping it.
===========
Run 161/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_162/ already exists.
Skipping it.
===========
Run 162/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_163/ already exists.
Skipping it.
===========
Run 163/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_164/ already exists.
Skipping it.
===========
Run 164/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_165/ already exists.
Skipping it.
===========
Run 165/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_166/ already exists.
Skipping it.
===========
Run 166/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_167/ already exists.
Skipping it.
===========
Run 167/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_168/ already exists.
Skipping it.
===========
Run 168/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_169/ already exists.
Skipping it.
===========
Run 169/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_170/ already exists.
Skipping it.
===========
Run 170/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_171/ already exists.
Skipping it.
===========
Run 171/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_172/ already exists.
Skipping it.
===========
Run 172/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_173/ already exists.
Skipping it.
===========
Run 173/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_174/ already exists.
Skipping it.
===========
Run 174/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_175/ already exists.
Skipping it.
===========
Run 175/720 already exists. Skipping it.
===========

===========
Generating train data for run 176.
===========
Train data generated in 0.13 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 16)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_176/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 187}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_176/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[4.831399  , 5.863554  , 0.1652866 , ..., 6.776286  , 2.0655468 ,
        1.4845017 ],
       [4.0864964 , 5.24693   , 0.13653305, ..., 5.762559  , 2.5860255 ,
        1.364856  ],
       [5.275347  , 8.040183  , 5.6235228 , ..., 9.369459  , 0.6142187 ,
        1.0642337 ],
       ...,
       [5.461225  , 8.116312  , 5.529141  , ..., 9.237533  , 1.256566  ,
        1.0620883 ],
       [4.5966773 , 5.3314133 , 0.2894929 , ..., 7.691963  , 2.0622973 ,
        1.1898649 ],
       [4.9526467 , 6.7362523 , 6.305528  , ..., 9.387884  , 1.0884995 ,
        0.8526704 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_176/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_176
self.data_kwargs: {'seed': 187}
self.x_data: [[ 4.812802    5.5024137   0.1852501  ...  6.472553    2.278431
   1.0939016 ]
 [ 5.542564    7.0347266   6.375047   ...  9.405323   -0.10398155
   0.7335531 ]
 [ 4.965488    6.398319    0.14414716 ...  5.6583366   2.1096616
   1.5241935 ]
 ...
 [ 4.4325466   6.3903317   0.21309651 ...  7.1345162   2.1785538
   1.3028526 ]
 [ 4.137084    6.680504    0.19241284 ...  7.049218    2.1201315
   1.4646225 ]
 [ 4.9299364   5.1759768   0.18408507 ...  7.8870034   1.6553737
   1.2631798 ]]
self.y_data: []
self.ndims: 16
Model defined.
Model: "model_134"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_135 (InputLayer)      [(None, 16)]              0         
                                                                 
 log_prob_layer_14 (LogProbL  (None,)                  2058480   
 ayer)                                                           
                                                                 
=================================================================
Total params: 2,058,480
Trainable params: 2,058,480
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_14/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_14'")
self.model: <keras.engine.functional.Functional object at 0x7faec4e09c30>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7faf1143bd60>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7faf1143bd60>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7faec582e740>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7faec5848550>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_176/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7faec5848ac0>, <keras.callbacks.ModelCheckpoint object at 0x7faec5848b80>, <keras.callbacks.EarlyStopping object at 0x7faec5848df0>, <keras.callbacks.ReduceLROnPlateau object at 0x7faec5848e20>, <keras.callbacks.TerminateOnNaN object at 0x7faec5848a60>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[4.831399  , 5.863554  , 0.1652866 , ..., 6.776286  , 2.0655468 ,
        1.4845017 ],
       [4.0864964 , 5.24693   , 0.13653305, ..., 5.762559  , 2.5860255 ,
        1.364856  ],
       [5.275347  , 8.040183  , 5.6235228 , ..., 9.369459  , 0.6142187 ,
        1.0642337 ],
       ...,
       [5.461225  , 8.116312  , 5.529141  , ..., 9.237533  , 1.256566  ,
        1.0620883 ],
       [4.5966773 , 5.3314133 , 0.2894929 , ..., 7.691963  , 2.0622973 ,
        1.1898649 ],
       [4.9526467 , 6.7362523 , 6.305528  , ..., 9.387884  , 1.0884995 ,
        0.8526704 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_176/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 176/720 with hyperparameters:
timestamp = 2023-09-18 07:04:54.040489
ndims = 16
seed_train = 187
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 2058480
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 4.812802   5.5024137  0.1852501  6.0790067  6.7126174  6.365971
 10.504365   6.889143   4.1779566  4.127769   7.026523   1.1252476
  6.6392775  6.472553   2.278431   1.0939016]
Epoch 1/1000
2023-09-18 07:10:00.219 
Epoch 1/1000 
	 loss: 31.8285, MinusLogProbMetric: 31.8285, val_loss: 10.2704, val_MinusLogProbMetric: 10.2704

Epoch 1: val_loss improved from inf to 10.27037, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_176/weights/best_weights.h5
196/196 - 307s - loss: 31.8285 - MinusLogProbMetric: 31.8285 - val_loss: 10.2704 - val_MinusLogProbMetric: 10.2704 - lr: 0.0010 - 307s/epoch - 2s/step
Epoch 2/1000
2023-09-18 07:11:24.255 
Epoch 2/1000 
	 loss: 8.9754, MinusLogProbMetric: 8.9754, val_loss: 8.1778, val_MinusLogProbMetric: 8.1778

Epoch 2: val_loss improved from 10.27037 to 8.17785, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_176/weights/best_weights.h5
196/196 - 84s - loss: 8.9754 - MinusLogProbMetric: 8.9754 - val_loss: 8.1778 - val_MinusLogProbMetric: 8.1778 - lr: 0.0010 - 84s/epoch - 427ms/step
Epoch 3/1000
2023-09-18 07:12:34.190 
Epoch 3/1000 
	 loss: 7.4311, MinusLogProbMetric: 7.4311, val_loss: 6.5538, val_MinusLogProbMetric: 6.5538

Epoch 3: val_loss improved from 8.17785 to 6.55376, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_176/weights/best_weights.h5
196/196 - 70s - loss: 7.4311 - MinusLogProbMetric: 7.4311 - val_loss: 6.5538 - val_MinusLogProbMetric: 6.5538 - lr: 0.0010 - 70s/epoch - 355ms/step
Epoch 4/1000
2023-09-18 07:13:39.477 
Epoch 4/1000 
	 loss: 7.1767, MinusLogProbMetric: 7.1767, val_loss: 6.5008, val_MinusLogProbMetric: 6.5008

Epoch 4: val_loss improved from 6.55376 to 6.50078, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_176/weights/best_weights.h5
196/196 - 65s - loss: 7.1767 - MinusLogProbMetric: 7.1767 - val_loss: 6.5008 - val_MinusLogProbMetric: 6.5008 - lr: 0.0010 - 65s/epoch - 334ms/step
Epoch 5/1000
2023-09-18 07:14:54.101 
Epoch 5/1000 
	 loss: 6.5162, MinusLogProbMetric: 6.5162, val_loss: 6.1034, val_MinusLogProbMetric: 6.1034

Epoch 5: val_loss improved from 6.50078 to 6.10344, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_176/weights/best_weights.h5
196/196 - 75s - loss: 6.5162 - MinusLogProbMetric: 6.5162 - val_loss: 6.1034 - val_MinusLogProbMetric: 6.1034 - lr: 0.0010 - 75s/epoch - 383ms/step
Epoch 6/1000
2023-09-18 07:16:18.246 
Epoch 6/1000 
	 loss: 6.3690, MinusLogProbMetric: 6.3690, val_loss: 6.2403, val_MinusLogProbMetric: 6.2403

Epoch 6: val_loss did not improve from 6.10344
196/196 - 82s - loss: 6.3690 - MinusLogProbMetric: 6.3690 - val_loss: 6.2403 - val_MinusLogProbMetric: 6.2403 - lr: 0.0010 - 82s/epoch - 421ms/step
Epoch 7/1000
2023-09-18 07:17:41.276 
Epoch 7/1000 
	 loss: 6.1781, MinusLogProbMetric: 6.1781, val_loss: 5.9575, val_MinusLogProbMetric: 5.9575

Epoch 7: val_loss improved from 6.10344 to 5.95746, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_176/weights/best_weights.h5
196/196 - 85s - loss: 6.1781 - MinusLogProbMetric: 6.1781 - val_loss: 5.9575 - val_MinusLogProbMetric: 5.9575 - lr: 0.0010 - 85s/epoch - 432ms/step
Epoch 8/1000
2023-09-18 07:19:05.868 
Epoch 8/1000 
	 loss: 6.0143, MinusLogProbMetric: 6.0143, val_loss: 5.6753, val_MinusLogProbMetric: 5.6753

Epoch 8: val_loss improved from 5.95746 to 5.67527, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_176/weights/best_weights.h5
196/196 - 84s - loss: 6.0143 - MinusLogProbMetric: 6.0143 - val_loss: 5.6753 - val_MinusLogProbMetric: 5.6753 - lr: 0.0010 - 84s/epoch - 430ms/step
Epoch 9/1000
2023-09-18 07:20:29.874 
Epoch 9/1000 
	 loss: 5.9251, MinusLogProbMetric: 5.9251, val_loss: 5.9786, val_MinusLogProbMetric: 5.9786

Epoch 9: val_loss did not improve from 5.67527
196/196 - 83s - loss: 5.9251 - MinusLogProbMetric: 5.9251 - val_loss: 5.9786 - val_MinusLogProbMetric: 5.9786 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 10/1000
2023-09-18 07:21:51.865 
Epoch 10/1000 
	 loss: 5.8823, MinusLogProbMetric: 5.8823, val_loss: 5.6454, val_MinusLogProbMetric: 5.6454

Epoch 10: val_loss improved from 5.67527 to 5.64544, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_176/weights/best_weights.h5
196/196 - 84s - loss: 5.8823 - MinusLogProbMetric: 5.8823 - val_loss: 5.6454 - val_MinusLogProbMetric: 5.6454 - lr: 0.0010 - 84s/epoch - 426ms/step
Epoch 11/1000
2023-09-18 07:23:15.900 
Epoch 11/1000 
	 loss: 5.7531, MinusLogProbMetric: 5.7531, val_loss: 5.5914, val_MinusLogProbMetric: 5.5914

Epoch 11: val_loss improved from 5.64544 to 5.59142, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_176/weights/best_weights.h5
196/196 - 84s - loss: 5.7531 - MinusLogProbMetric: 5.7531 - val_loss: 5.5914 - val_MinusLogProbMetric: 5.5914 - lr: 0.0010 - 84s/epoch - 429ms/step
Epoch 12/1000
2023-09-18 07:24:39.923 
Epoch 12/1000 
	 loss: 5.7593, MinusLogProbMetric: 5.7593, val_loss: 5.8397, val_MinusLogProbMetric: 5.8397

Epoch 12: val_loss did not improve from 5.59142
196/196 - 82s - loss: 5.7593 - MinusLogProbMetric: 5.7593 - val_loss: 5.8397 - val_MinusLogProbMetric: 5.8397 - lr: 0.0010 - 82s/epoch - 421ms/step
Epoch 13/1000
2023-09-18 07:26:02.602 
Epoch 13/1000 
	 loss: 5.6367, MinusLogProbMetric: 5.6367, val_loss: 5.6372, val_MinusLogProbMetric: 5.6372

Epoch 13: val_loss did not improve from 5.59142
196/196 - 83s - loss: 5.6367 - MinusLogProbMetric: 5.6367 - val_loss: 5.6372 - val_MinusLogProbMetric: 5.6372 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 14/1000
2023-09-18 07:27:24.585 
Epoch 14/1000 
	 loss: 5.6171, MinusLogProbMetric: 5.6171, val_loss: 5.6580, val_MinusLogProbMetric: 5.6580

Epoch 14: val_loss did not improve from 5.59142
196/196 - 82s - loss: 5.6171 - MinusLogProbMetric: 5.6171 - val_loss: 5.6580 - val_MinusLogProbMetric: 5.6580 - lr: 0.0010 - 82s/epoch - 418ms/step
Epoch 15/1000
2023-09-18 07:28:38.599 
Epoch 15/1000 
	 loss: 5.5668, MinusLogProbMetric: 5.5668, val_loss: 5.7812, val_MinusLogProbMetric: 5.7812

Epoch 15: val_loss did not improve from 5.59142
196/196 - 74s - loss: 5.5668 - MinusLogProbMetric: 5.5668 - val_loss: 5.7812 - val_MinusLogProbMetric: 5.7812 - lr: 0.0010 - 74s/epoch - 378ms/step
Epoch 16/1000
2023-09-18 07:29:44.657 
Epoch 16/1000 
	 loss: 5.5449, MinusLogProbMetric: 5.5449, val_loss: 5.5371, val_MinusLogProbMetric: 5.5371

Epoch 16: val_loss improved from 5.59142 to 5.53708, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_176/weights/best_weights.h5
196/196 - 67s - loss: 5.5449 - MinusLogProbMetric: 5.5449 - val_loss: 5.5371 - val_MinusLogProbMetric: 5.5371 - lr: 0.0010 - 67s/epoch - 344ms/step
Epoch 17/1000
2023-09-18 07:31:07.075 
Epoch 17/1000 
	 loss: 5.5059, MinusLogProbMetric: 5.5059, val_loss: 5.9166, val_MinusLogProbMetric: 5.9166

Epoch 17: val_loss did not improve from 5.53708
196/196 - 81s - loss: 5.5059 - MinusLogProbMetric: 5.5059 - val_loss: 5.9166 - val_MinusLogProbMetric: 5.9166 - lr: 0.0010 - 81s/epoch - 414ms/step
Epoch 18/1000
2023-09-18 07:32:29.884 
Epoch 18/1000 
	 loss: 5.4925, MinusLogProbMetric: 5.4925, val_loss: 6.2140, val_MinusLogProbMetric: 6.2140

Epoch 18: val_loss did not improve from 5.53708
196/196 - 83s - loss: 5.4925 - MinusLogProbMetric: 5.4925 - val_loss: 6.2140 - val_MinusLogProbMetric: 6.2140 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 19/1000
2023-09-18 07:33:52.280 
Epoch 19/1000 
	 loss: 5.4307, MinusLogProbMetric: 5.4307, val_loss: 5.6941, val_MinusLogProbMetric: 5.6941

Epoch 19: val_loss did not improve from 5.53708
196/196 - 82s - loss: 5.4307 - MinusLogProbMetric: 5.4307 - val_loss: 5.6941 - val_MinusLogProbMetric: 5.6941 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 20/1000
2023-09-18 07:35:15.103 
Epoch 20/1000 
	 loss: 5.4502, MinusLogProbMetric: 5.4502, val_loss: 5.6053, val_MinusLogProbMetric: 5.6053

Epoch 20: val_loss did not improve from 5.53708
196/196 - 83s - loss: 5.4502 - MinusLogProbMetric: 5.4502 - val_loss: 5.6053 - val_MinusLogProbMetric: 5.6053 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 21/1000
2023-09-18 07:36:37.862 
Epoch 21/1000 
	 loss: 5.4182, MinusLogProbMetric: 5.4182, val_loss: 5.5336, val_MinusLogProbMetric: 5.5336

Epoch 21: val_loss improved from 5.53708 to 5.53361, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_176/weights/best_weights.h5
196/196 - 84s - loss: 5.4182 - MinusLogProbMetric: 5.4182 - val_loss: 5.5336 - val_MinusLogProbMetric: 5.5336 - lr: 0.0010 - 84s/epoch - 430ms/step
Epoch 22/1000
2023-09-18 07:38:03.090 
Epoch 22/1000 
	 loss: 5.3715, MinusLogProbMetric: 5.3715, val_loss: 5.5283, val_MinusLogProbMetric: 5.5283

Epoch 22: val_loss improved from 5.53361 to 5.52830, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_176/weights/best_weights.h5
196/196 - 85s - loss: 5.3715 - MinusLogProbMetric: 5.3715 - val_loss: 5.5283 - val_MinusLogProbMetric: 5.5283 - lr: 0.0010 - 85s/epoch - 435ms/step
Epoch 23/1000
2023-09-18 07:39:27.565 
Epoch 23/1000 
	 loss: 5.3640, MinusLogProbMetric: 5.3640, val_loss: 5.7538, val_MinusLogProbMetric: 5.7538

Epoch 23: val_loss did not improve from 5.52830
196/196 - 83s - loss: 5.3640 - MinusLogProbMetric: 5.3640 - val_loss: 5.7538 - val_MinusLogProbMetric: 5.7538 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 24/1000
2023-09-18 07:40:50.479 
Epoch 24/1000 
	 loss: 5.3039, MinusLogProbMetric: 5.3039, val_loss: 5.5754, val_MinusLogProbMetric: 5.5754

Epoch 24: val_loss did not improve from 5.52830
196/196 - 83s - loss: 5.3039 - MinusLogProbMetric: 5.3039 - val_loss: 5.5754 - val_MinusLogProbMetric: 5.5754 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 25/1000
2023-09-18 07:42:13.366 
Epoch 25/1000 
	 loss: 5.2939, MinusLogProbMetric: 5.2939, val_loss: 5.5936, val_MinusLogProbMetric: 5.5936

Epoch 25: val_loss did not improve from 5.52830
196/196 - 83s - loss: 5.2939 - MinusLogProbMetric: 5.2939 - val_loss: 5.5936 - val_MinusLogProbMetric: 5.5936 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 26/1000
2023-09-18 07:43:35.180 
Epoch 26/1000 
	 loss: 5.2657, MinusLogProbMetric: 5.2657, val_loss: 5.4853, val_MinusLogProbMetric: 5.4853

Epoch 26: val_loss improved from 5.52830 to 5.48528, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_176/weights/best_weights.h5
196/196 - 83s - loss: 5.2657 - MinusLogProbMetric: 5.2657 - val_loss: 5.4853 - val_MinusLogProbMetric: 5.4853 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 27/1000
2023-09-18 07:44:59.491 
Epoch 27/1000 
	 loss: 5.2781, MinusLogProbMetric: 5.2781, val_loss: 5.5779, val_MinusLogProbMetric: 5.5779

Epoch 27: val_loss did not improve from 5.48528
196/196 - 83s - loss: 5.2781 - MinusLogProbMetric: 5.2781 - val_loss: 5.5779 - val_MinusLogProbMetric: 5.5779 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 28/1000
2023-09-18 07:46:22.450 
Epoch 28/1000 
	 loss: 5.3020, MinusLogProbMetric: 5.3020, val_loss: 5.5534, val_MinusLogProbMetric: 5.5534

Epoch 28: val_loss did not improve from 5.48528
196/196 - 83s - loss: 5.3020 - MinusLogProbMetric: 5.3020 - val_loss: 5.5534 - val_MinusLogProbMetric: 5.5534 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 29/1000
2023-09-18 07:47:46.393 
Epoch 29/1000 
	 loss: 5.2655, MinusLogProbMetric: 5.2655, val_loss: 5.6227, val_MinusLogProbMetric: 5.6227

Epoch 29: val_loss did not improve from 5.48528
196/196 - 84s - loss: 5.2655 - MinusLogProbMetric: 5.2655 - val_loss: 5.6227 - val_MinusLogProbMetric: 5.6227 - lr: 0.0010 - 84s/epoch - 428ms/step
Epoch 30/1000
2023-09-18 07:49:09.389 
Epoch 30/1000 
	 loss: 5.2454, MinusLogProbMetric: 5.2454, val_loss: 5.5174, val_MinusLogProbMetric: 5.5174

Epoch 30: val_loss did not improve from 5.48528
196/196 - 83s - loss: 5.2454 - MinusLogProbMetric: 5.2454 - val_loss: 5.5174 - val_MinusLogProbMetric: 5.5174 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 31/1000
2023-09-18 07:50:32.077 
Epoch 31/1000 
	 loss: 5.1957, MinusLogProbMetric: 5.1957, val_loss: 5.8232, val_MinusLogProbMetric: 5.8232

Epoch 31: val_loss did not improve from 5.48528
196/196 - 83s - loss: 5.1957 - MinusLogProbMetric: 5.1957 - val_loss: 5.8232 - val_MinusLogProbMetric: 5.8232 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 32/1000
2023-09-18 07:51:55.554 
Epoch 32/1000 
	 loss: 5.2423, MinusLogProbMetric: 5.2423, val_loss: 5.5057, val_MinusLogProbMetric: 5.5057

Epoch 32: val_loss did not improve from 5.48528
196/196 - 83s - loss: 5.2423 - MinusLogProbMetric: 5.2423 - val_loss: 5.5057 - val_MinusLogProbMetric: 5.5057 - lr: 0.0010 - 83s/epoch - 426ms/step
Epoch 33/1000
2023-09-18 07:53:17.839 
Epoch 33/1000 
	 loss: 5.1723, MinusLogProbMetric: 5.1723, val_loss: 5.4677, val_MinusLogProbMetric: 5.4677

Epoch 33: val_loss improved from 5.48528 to 5.46767, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_176/weights/best_weights.h5
196/196 - 84s - loss: 5.1723 - MinusLogProbMetric: 5.1723 - val_loss: 5.4677 - val_MinusLogProbMetric: 5.4677 - lr: 0.0010 - 84s/epoch - 430ms/step
Epoch 34/1000
2023-09-18 07:54:42.196 
Epoch 34/1000 
	 loss: 5.1859, MinusLogProbMetric: 5.1859, val_loss: 5.9039, val_MinusLogProbMetric: 5.9039

Epoch 34: val_loss did not improve from 5.46767
196/196 - 82s - loss: 5.1859 - MinusLogProbMetric: 5.1859 - val_loss: 5.9039 - val_MinusLogProbMetric: 5.9039 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 35/1000
2023-09-18 07:56:04.981 
Epoch 35/1000 
	 loss: 5.1796, MinusLogProbMetric: 5.1796, val_loss: 5.5185, val_MinusLogProbMetric: 5.5185

Epoch 35: val_loss did not improve from 5.46767
196/196 - 83s - loss: 5.1796 - MinusLogProbMetric: 5.1796 - val_loss: 5.5185 - val_MinusLogProbMetric: 5.5185 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 36/1000
2023-09-18 07:57:27.447 
Epoch 36/1000 
	 loss: 5.1618, MinusLogProbMetric: 5.1618, val_loss: 5.6325, val_MinusLogProbMetric: 5.6325

Epoch 36: val_loss did not improve from 5.46767
196/196 - 82s - loss: 5.1618 - MinusLogProbMetric: 5.1618 - val_loss: 5.6325 - val_MinusLogProbMetric: 5.6325 - lr: 0.0010 - 82s/epoch - 421ms/step
Epoch 37/1000
2023-09-18 07:58:49.771 
Epoch 37/1000 
	 loss: 5.1189, MinusLogProbMetric: 5.1189, val_loss: 5.3975, val_MinusLogProbMetric: 5.3975

Epoch 37: val_loss improved from 5.46767 to 5.39754, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_176/weights/best_weights.h5
196/196 - 84s - loss: 5.1189 - MinusLogProbMetric: 5.1189 - val_loss: 5.3975 - val_MinusLogProbMetric: 5.3975 - lr: 0.0010 - 84s/epoch - 427ms/step
Epoch 38/1000
2023-09-18 08:00:12.845 
Epoch 38/1000 
	 loss: 5.1049, MinusLogProbMetric: 5.1049, val_loss: 5.5728, val_MinusLogProbMetric: 5.5728

Epoch 38: val_loss did not improve from 5.39754
196/196 - 82s - loss: 5.1049 - MinusLogProbMetric: 5.1049 - val_loss: 5.5728 - val_MinusLogProbMetric: 5.5728 - lr: 0.0010 - 82s/epoch - 417ms/step
Epoch 39/1000
2023-09-18 08:01:34.030 
Epoch 39/1000 
	 loss: 5.1236, MinusLogProbMetric: 5.1236, val_loss: 5.5162, val_MinusLogProbMetric: 5.5162

Epoch 39: val_loss did not improve from 5.39754
196/196 - 81s - loss: 5.1236 - MinusLogProbMetric: 5.1236 - val_loss: 5.5162 - val_MinusLogProbMetric: 5.5162 - lr: 0.0010 - 81s/epoch - 414ms/step
Epoch 40/1000
2023-09-18 08:02:56.567 
Epoch 40/1000 
	 loss: 5.1291, MinusLogProbMetric: 5.1291, val_loss: 5.5042, val_MinusLogProbMetric: 5.5042

Epoch 40: val_loss did not improve from 5.39754
196/196 - 83s - loss: 5.1291 - MinusLogProbMetric: 5.1291 - val_loss: 5.5042 - val_MinusLogProbMetric: 5.5042 - lr: 0.0010 - 83s/epoch - 421ms/step
Epoch 41/1000
2023-09-18 08:04:18.483 
Epoch 41/1000 
	 loss: 5.1097, MinusLogProbMetric: 5.1097, val_loss: 5.6535, val_MinusLogProbMetric: 5.6535

Epoch 41: val_loss did not improve from 5.39754
196/196 - 82s - loss: 5.1097 - MinusLogProbMetric: 5.1097 - val_loss: 5.6535 - val_MinusLogProbMetric: 5.6535 - lr: 0.0010 - 82s/epoch - 418ms/step
Epoch 42/1000
2023-09-18 08:05:39.390 
Epoch 42/1000 
	 loss: 5.0810, MinusLogProbMetric: 5.0810, val_loss: 5.5581, val_MinusLogProbMetric: 5.5581

Epoch 42: val_loss did not improve from 5.39754
196/196 - 81s - loss: 5.0810 - MinusLogProbMetric: 5.0810 - val_loss: 5.5581 - val_MinusLogProbMetric: 5.5581 - lr: 0.0010 - 81s/epoch - 413ms/step
Epoch 43/1000
2023-09-18 08:07:01.295 
Epoch 43/1000 
	 loss: 5.0501, MinusLogProbMetric: 5.0501, val_loss: 5.4655, val_MinusLogProbMetric: 5.4655

Epoch 43: val_loss did not improve from 5.39754
196/196 - 82s - loss: 5.0501 - MinusLogProbMetric: 5.0501 - val_loss: 5.4655 - val_MinusLogProbMetric: 5.4655 - lr: 0.0010 - 82s/epoch - 418ms/step
Epoch 44/1000
2023-09-18 08:08:23.531 
Epoch 44/1000 
	 loss: 5.0620, MinusLogProbMetric: 5.0620, val_loss: 5.4399, val_MinusLogProbMetric: 5.4399

Epoch 44: val_loss did not improve from 5.39754
196/196 - 82s - loss: 5.0620 - MinusLogProbMetric: 5.0620 - val_loss: 5.4399 - val_MinusLogProbMetric: 5.4399 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 45/1000
2023-09-18 08:09:45.866 
Epoch 45/1000 
	 loss: 5.0502, MinusLogProbMetric: 5.0502, val_loss: 5.4020, val_MinusLogProbMetric: 5.4020

Epoch 45: val_loss did not improve from 5.39754
196/196 - 82s - loss: 5.0502 - MinusLogProbMetric: 5.0502 - val_loss: 5.4020 - val_MinusLogProbMetric: 5.4020 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 46/1000
2023-09-18 08:11:06.551 
Epoch 46/1000 
	 loss: 5.0251, MinusLogProbMetric: 5.0251, val_loss: 5.4558, val_MinusLogProbMetric: 5.4558

Epoch 46: val_loss did not improve from 5.39754
196/196 - 81s - loss: 5.0251 - MinusLogProbMetric: 5.0251 - val_loss: 5.4558 - val_MinusLogProbMetric: 5.4558 - lr: 0.0010 - 81s/epoch - 412ms/step
Epoch 47/1000
2023-09-18 08:12:28.143 
Epoch 47/1000 
	 loss: 5.0550, MinusLogProbMetric: 5.0550, val_loss: 5.5580, val_MinusLogProbMetric: 5.5580

Epoch 47: val_loss did not improve from 5.39754
196/196 - 82s - loss: 5.0550 - MinusLogProbMetric: 5.0550 - val_loss: 5.5580 - val_MinusLogProbMetric: 5.5580 - lr: 0.0010 - 82s/epoch - 416ms/step
Epoch 48/1000
2023-09-18 08:13:50.048 
Epoch 48/1000 
	 loss: 5.0052, MinusLogProbMetric: 5.0052, val_loss: 5.4639, val_MinusLogProbMetric: 5.4639

Epoch 48: val_loss did not improve from 5.39754
196/196 - 82s - loss: 5.0052 - MinusLogProbMetric: 5.0052 - val_loss: 5.4639 - val_MinusLogProbMetric: 5.4639 - lr: 0.0010 - 82s/epoch - 418ms/step
Epoch 49/1000
2023-09-18 08:15:12.936 
Epoch 49/1000 
	 loss: 5.0156, MinusLogProbMetric: 5.0156, val_loss: 5.6160, val_MinusLogProbMetric: 5.6160

Epoch 49: val_loss did not improve from 5.39754
196/196 - 83s - loss: 5.0156 - MinusLogProbMetric: 5.0156 - val_loss: 5.6160 - val_MinusLogProbMetric: 5.6160 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 50/1000
2023-09-18 08:16:35.182 
Epoch 50/1000 
	 loss: 5.0354, MinusLogProbMetric: 5.0354, val_loss: 5.7346, val_MinusLogProbMetric: 5.7346

Epoch 50: val_loss did not improve from 5.39754
196/196 - 82s - loss: 5.0354 - MinusLogProbMetric: 5.0354 - val_loss: 5.7346 - val_MinusLogProbMetric: 5.7346 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 51/1000
2023-09-18 08:17:57.201 
Epoch 51/1000 
	 loss: 4.9935, MinusLogProbMetric: 4.9935, val_loss: 5.4670, val_MinusLogProbMetric: 5.4670

Epoch 51: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.9935 - MinusLogProbMetric: 4.9935 - val_loss: 5.4670 - val_MinusLogProbMetric: 5.4670 - lr: 0.0010 - 82s/epoch - 418ms/step
Epoch 52/1000
2023-09-18 08:19:18.879 
Epoch 52/1000 
	 loss: 5.0664, MinusLogProbMetric: 5.0664, val_loss: 5.9477, val_MinusLogProbMetric: 5.9477

Epoch 52: val_loss did not improve from 5.39754
196/196 - 82s - loss: 5.0664 - MinusLogProbMetric: 5.0664 - val_loss: 5.9477 - val_MinusLogProbMetric: 5.9477 - lr: 0.0010 - 82s/epoch - 417ms/step
Epoch 53/1000
2023-09-18 08:20:41.108 
Epoch 53/1000 
	 loss: 4.9994, MinusLogProbMetric: 4.9994, val_loss: 5.6895, val_MinusLogProbMetric: 5.6895

Epoch 53: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.9994 - MinusLogProbMetric: 4.9994 - val_loss: 5.6895 - val_MinusLogProbMetric: 5.6895 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 54/1000
2023-09-18 08:22:04.292 
Epoch 54/1000 
	 loss: 4.9550, MinusLogProbMetric: 4.9550, val_loss: 5.6740, val_MinusLogProbMetric: 5.6740

Epoch 54: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.9550 - MinusLogProbMetric: 4.9550 - val_loss: 5.6740 - val_MinusLogProbMetric: 5.6740 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 55/1000
2023-09-18 08:23:26.996 
Epoch 55/1000 
	 loss: 4.9614, MinusLogProbMetric: 4.9614, val_loss: 5.5490, val_MinusLogProbMetric: 5.5490

Epoch 55: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.9614 - MinusLogProbMetric: 4.9614 - val_loss: 5.5490 - val_MinusLogProbMetric: 5.5490 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 56/1000
2023-09-18 08:24:49.873 
Epoch 56/1000 
	 loss: 4.9642, MinusLogProbMetric: 4.9642, val_loss: 5.4972, val_MinusLogProbMetric: 5.4972

Epoch 56: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.9642 - MinusLogProbMetric: 4.9642 - val_loss: 5.4972 - val_MinusLogProbMetric: 5.4972 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 57/1000
2023-09-18 08:26:11.875 
Epoch 57/1000 
	 loss: 4.9408, MinusLogProbMetric: 4.9408, val_loss: 5.6179, val_MinusLogProbMetric: 5.6179

Epoch 57: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.9408 - MinusLogProbMetric: 4.9408 - val_loss: 5.6179 - val_MinusLogProbMetric: 5.6179 - lr: 0.0010 - 82s/epoch - 418ms/step
Epoch 58/1000
2023-09-18 08:27:34.342 
Epoch 58/1000 
	 loss: 4.9485, MinusLogProbMetric: 4.9485, val_loss: 5.5457, val_MinusLogProbMetric: 5.5457

Epoch 58: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.9485 - MinusLogProbMetric: 4.9485 - val_loss: 5.5457 - val_MinusLogProbMetric: 5.5457 - lr: 0.0010 - 82s/epoch - 421ms/step
Epoch 59/1000
2023-09-18 08:28:57.116 
Epoch 59/1000 
	 loss: 4.9392, MinusLogProbMetric: 4.9392, val_loss: 5.5258, val_MinusLogProbMetric: 5.5258

Epoch 59: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.9392 - MinusLogProbMetric: 4.9392 - val_loss: 5.5258 - val_MinusLogProbMetric: 5.5258 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 60/1000
2023-09-18 08:30:19.462 
Epoch 60/1000 
	 loss: 4.9283, MinusLogProbMetric: 4.9283, val_loss: 5.6292, val_MinusLogProbMetric: 5.6292

Epoch 60: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.9283 - MinusLogProbMetric: 4.9283 - val_loss: 5.6292 - val_MinusLogProbMetric: 5.6292 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 61/1000
2023-09-18 08:31:42.594 
Epoch 61/1000 
	 loss: 4.9359, MinusLogProbMetric: 4.9359, val_loss: 5.5514, val_MinusLogProbMetric: 5.5514

Epoch 61: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.9359 - MinusLogProbMetric: 4.9359 - val_loss: 5.5514 - val_MinusLogProbMetric: 5.5514 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 62/1000
2023-09-18 08:33:05.641 
Epoch 62/1000 
	 loss: 4.8777, MinusLogProbMetric: 4.8777, val_loss: 5.6871, val_MinusLogProbMetric: 5.6871

Epoch 62: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.8777 - MinusLogProbMetric: 4.8777 - val_loss: 5.6871 - val_MinusLogProbMetric: 5.6871 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 63/1000
2023-09-18 08:34:27.621 
Epoch 63/1000 
	 loss: 4.9092, MinusLogProbMetric: 4.9092, val_loss: 5.4851, val_MinusLogProbMetric: 5.4851

Epoch 63: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.9092 - MinusLogProbMetric: 4.9092 - val_loss: 5.4851 - val_MinusLogProbMetric: 5.4851 - lr: 0.0010 - 82s/epoch - 418ms/step
Epoch 64/1000
2023-09-18 08:35:49.801 
Epoch 64/1000 
	 loss: 4.9048, MinusLogProbMetric: 4.9048, val_loss: 5.5642, val_MinusLogProbMetric: 5.5642

Epoch 64: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.9048 - MinusLogProbMetric: 4.9048 - val_loss: 5.5642 - val_MinusLogProbMetric: 5.5642 - lr: 0.0010 - 82s/epoch - 419ms/step
Epoch 65/1000
2023-09-18 08:37:12.686 
Epoch 65/1000 
	 loss: 4.8759, MinusLogProbMetric: 4.8759, val_loss: 5.5513, val_MinusLogProbMetric: 5.5513

Epoch 65: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.8759 - MinusLogProbMetric: 4.8759 - val_loss: 5.5513 - val_MinusLogProbMetric: 5.5513 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 66/1000
2023-09-18 08:38:35.260 
Epoch 66/1000 
	 loss: 4.8611, MinusLogProbMetric: 4.8611, val_loss: 5.7094, val_MinusLogProbMetric: 5.7094

Epoch 66: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.8611 - MinusLogProbMetric: 4.8611 - val_loss: 5.7094 - val_MinusLogProbMetric: 5.7094 - lr: 0.0010 - 83s/epoch - 421ms/step
Epoch 67/1000
2023-09-18 08:39:55.918 
Epoch 67/1000 
	 loss: 4.8718, MinusLogProbMetric: 4.8718, val_loss: 5.5278, val_MinusLogProbMetric: 5.5278

Epoch 67: val_loss did not improve from 5.39754
196/196 - 81s - loss: 4.8718 - MinusLogProbMetric: 4.8718 - val_loss: 5.5278 - val_MinusLogProbMetric: 5.5278 - lr: 0.0010 - 81s/epoch - 412ms/step
Epoch 68/1000
2023-09-18 08:41:07.577 
Epoch 68/1000 
	 loss: 4.8497, MinusLogProbMetric: 4.8497, val_loss: 5.5154, val_MinusLogProbMetric: 5.5154

Epoch 68: val_loss did not improve from 5.39754
196/196 - 72s - loss: 4.8497 - MinusLogProbMetric: 4.8497 - val_loss: 5.5154 - val_MinusLogProbMetric: 5.5154 - lr: 0.0010 - 72s/epoch - 366ms/step
Epoch 69/1000
2023-09-18 08:42:28.702 
Epoch 69/1000 
	 loss: 4.8365, MinusLogProbMetric: 4.8365, val_loss: 5.6711, val_MinusLogProbMetric: 5.6711

Epoch 69: val_loss did not improve from 5.39754
196/196 - 81s - loss: 4.8365 - MinusLogProbMetric: 4.8365 - val_loss: 5.6711 - val_MinusLogProbMetric: 5.6711 - lr: 0.0010 - 81s/epoch - 414ms/step
Epoch 70/1000
2023-09-18 08:43:49.999 
Epoch 70/1000 
	 loss: 4.8587, MinusLogProbMetric: 4.8587, val_loss: 5.6816, val_MinusLogProbMetric: 5.6816

Epoch 70: val_loss did not improve from 5.39754
196/196 - 81s - loss: 4.8587 - MinusLogProbMetric: 4.8587 - val_loss: 5.6816 - val_MinusLogProbMetric: 5.6816 - lr: 0.0010 - 81s/epoch - 415ms/step
Epoch 71/1000
2023-09-18 08:45:11.635 
Epoch 71/1000 
	 loss: 4.8553, MinusLogProbMetric: 4.8553, val_loss: 5.7945, val_MinusLogProbMetric: 5.7945

Epoch 71: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.8553 - MinusLogProbMetric: 4.8553 - val_loss: 5.7945 - val_MinusLogProbMetric: 5.7945 - lr: 0.0010 - 82s/epoch - 416ms/step
Epoch 72/1000
2023-09-18 08:46:27.277 
Epoch 72/1000 
	 loss: 4.8300, MinusLogProbMetric: 4.8300, val_loss: 5.5614, val_MinusLogProbMetric: 5.5614

Epoch 72: val_loss did not improve from 5.39754
196/196 - 76s - loss: 4.8300 - MinusLogProbMetric: 4.8300 - val_loss: 5.5614 - val_MinusLogProbMetric: 5.5614 - lr: 0.0010 - 76s/epoch - 386ms/step
Epoch 73/1000
2023-09-18 08:47:35.338 
Epoch 73/1000 
	 loss: 4.8058, MinusLogProbMetric: 4.8058, val_loss: 5.5824, val_MinusLogProbMetric: 5.5824

Epoch 73: val_loss did not improve from 5.39754
196/196 - 68s - loss: 4.8058 - MinusLogProbMetric: 4.8058 - val_loss: 5.5824 - val_MinusLogProbMetric: 5.5824 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 74/1000
2023-09-18 08:48:38.075 
Epoch 74/1000 
	 loss: 4.8075, MinusLogProbMetric: 4.8075, val_loss: 5.6128, val_MinusLogProbMetric: 5.6128

Epoch 74: val_loss did not improve from 5.39754
196/196 - 63s - loss: 4.8075 - MinusLogProbMetric: 4.8075 - val_loss: 5.6128 - val_MinusLogProbMetric: 5.6128 - lr: 0.0010 - 63s/epoch - 320ms/step
Epoch 75/1000
2023-09-18 08:49:56.230 
Epoch 75/1000 
	 loss: 4.8085, MinusLogProbMetric: 4.8085, val_loss: 5.6138, val_MinusLogProbMetric: 5.6138

Epoch 75: val_loss did not improve from 5.39754
196/196 - 78s - loss: 4.8085 - MinusLogProbMetric: 4.8085 - val_loss: 5.6138 - val_MinusLogProbMetric: 5.6138 - lr: 0.0010 - 78s/epoch - 399ms/step
Epoch 76/1000
2023-09-18 08:51:15.824 
Epoch 76/1000 
	 loss: 4.8048, MinusLogProbMetric: 4.8048, val_loss: 5.6273, val_MinusLogProbMetric: 5.6273

Epoch 76: val_loss did not improve from 5.39754
196/196 - 80s - loss: 4.8048 - MinusLogProbMetric: 4.8048 - val_loss: 5.6273 - val_MinusLogProbMetric: 5.6273 - lr: 0.0010 - 80s/epoch - 406ms/step
Epoch 77/1000
2023-09-18 08:52:38.053 
Epoch 77/1000 
	 loss: 4.7647, MinusLogProbMetric: 4.7647, val_loss: 5.6157, val_MinusLogProbMetric: 5.6157

Epoch 77: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.7647 - MinusLogProbMetric: 4.7647 - val_loss: 5.6157 - val_MinusLogProbMetric: 5.6157 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 78/1000
2023-09-18 08:53:59.167 
Epoch 78/1000 
	 loss: 4.7646, MinusLogProbMetric: 4.7646, val_loss: 5.6352, val_MinusLogProbMetric: 5.6352

Epoch 78: val_loss did not improve from 5.39754
196/196 - 81s - loss: 4.7646 - MinusLogProbMetric: 4.7646 - val_loss: 5.6352 - val_MinusLogProbMetric: 5.6352 - lr: 0.0010 - 81s/epoch - 414ms/step
Epoch 79/1000
2023-09-18 08:55:21.012 
Epoch 79/1000 
	 loss: 4.7502, MinusLogProbMetric: 4.7502, val_loss: 5.8004, val_MinusLogProbMetric: 5.8004

Epoch 79: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.7502 - MinusLogProbMetric: 4.7502 - val_loss: 5.8004 - val_MinusLogProbMetric: 5.8004 - lr: 0.0010 - 82s/epoch - 418ms/step
Epoch 80/1000
2023-09-18 08:56:43.397 
Epoch 80/1000 
	 loss: 4.7553, MinusLogProbMetric: 4.7553, val_loss: 5.6622, val_MinusLogProbMetric: 5.6622

Epoch 80: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.7553 - MinusLogProbMetric: 4.7553 - val_loss: 5.6622 - val_MinusLogProbMetric: 5.6622 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 81/1000
2023-09-18 08:58:06.176 
Epoch 81/1000 
	 loss: 4.7442, MinusLogProbMetric: 4.7442, val_loss: 5.6963, val_MinusLogProbMetric: 5.6963

Epoch 81: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.7442 - MinusLogProbMetric: 4.7442 - val_loss: 5.6963 - val_MinusLogProbMetric: 5.6963 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 82/1000
2023-09-18 08:59:28.353 
Epoch 82/1000 
	 loss: 4.7307, MinusLogProbMetric: 4.7307, val_loss: 5.6476, val_MinusLogProbMetric: 5.6476

Epoch 82: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.7307 - MinusLogProbMetric: 4.7307 - val_loss: 5.6476 - val_MinusLogProbMetric: 5.6476 - lr: 0.0010 - 82s/epoch - 419ms/step
Epoch 83/1000
2023-09-18 09:00:50.410 
Epoch 83/1000 
	 loss: 4.7390, MinusLogProbMetric: 4.7390, val_loss: 5.6391, val_MinusLogProbMetric: 5.6391

Epoch 83: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.7390 - MinusLogProbMetric: 4.7390 - val_loss: 5.6391 - val_MinusLogProbMetric: 5.6391 - lr: 0.0010 - 82s/epoch - 419ms/step
Epoch 84/1000
2023-09-18 09:02:12.529 
Epoch 84/1000 
	 loss: 4.7429, MinusLogProbMetric: 4.7429, val_loss: 5.6424, val_MinusLogProbMetric: 5.6424

Epoch 84: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.7429 - MinusLogProbMetric: 4.7429 - val_loss: 5.6424 - val_MinusLogProbMetric: 5.6424 - lr: 0.0010 - 82s/epoch - 419ms/step
Epoch 85/1000
2023-09-18 09:03:34.970 
Epoch 85/1000 
	 loss: 4.7450, MinusLogProbMetric: 4.7450, val_loss: 5.7591, val_MinusLogProbMetric: 5.7591

Epoch 85: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.7450 - MinusLogProbMetric: 4.7450 - val_loss: 5.7591 - val_MinusLogProbMetric: 5.7591 - lr: 0.0010 - 82s/epoch - 421ms/step
Epoch 86/1000
2023-09-18 09:04:56.972 
Epoch 86/1000 
	 loss: 4.7136, MinusLogProbMetric: 4.7136, val_loss: 5.7332, val_MinusLogProbMetric: 5.7332

Epoch 86: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.7136 - MinusLogProbMetric: 4.7136 - val_loss: 5.7332 - val_MinusLogProbMetric: 5.7332 - lr: 0.0010 - 82s/epoch - 418ms/step
Epoch 87/1000
2023-09-18 09:06:17.812 
Epoch 87/1000 
	 loss: 4.7704, MinusLogProbMetric: 4.7704, val_loss: 5.8522, val_MinusLogProbMetric: 5.8522

Epoch 87: val_loss did not improve from 5.39754
196/196 - 81s - loss: 4.7704 - MinusLogProbMetric: 4.7704 - val_loss: 5.8522 - val_MinusLogProbMetric: 5.8522 - lr: 0.0010 - 81s/epoch - 412ms/step
Epoch 88/1000
2023-09-18 09:07:38.460 
Epoch 88/1000 
	 loss: 4.5104, MinusLogProbMetric: 4.5104, val_loss: 5.6678, val_MinusLogProbMetric: 5.6678

Epoch 88: val_loss did not improve from 5.39754
196/196 - 81s - loss: 4.5104 - MinusLogProbMetric: 4.5104 - val_loss: 5.6678 - val_MinusLogProbMetric: 5.6678 - lr: 5.0000e-04 - 81s/epoch - 411ms/step
Epoch 89/1000
2023-09-18 09:08:59.948 
Epoch 89/1000 
	 loss: 4.4872, MinusLogProbMetric: 4.4872, val_loss: 5.7203, val_MinusLogProbMetric: 5.7203

Epoch 89: val_loss did not improve from 5.39754
196/196 - 81s - loss: 4.4872 - MinusLogProbMetric: 4.4872 - val_loss: 5.7203 - val_MinusLogProbMetric: 5.7203 - lr: 5.0000e-04 - 81s/epoch - 416ms/step
Epoch 90/1000
2023-09-18 09:10:22.019 
Epoch 90/1000 
	 loss: 4.4810, MinusLogProbMetric: 4.4810, val_loss: 5.7128, val_MinusLogProbMetric: 5.7128

Epoch 90: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.4810 - MinusLogProbMetric: 4.4810 - val_loss: 5.7128 - val_MinusLogProbMetric: 5.7128 - lr: 5.0000e-04 - 82s/epoch - 419ms/step
Epoch 91/1000
2023-09-18 09:11:44.552 
Epoch 91/1000 
	 loss: 4.4682, MinusLogProbMetric: 4.4682, val_loss: 5.7993, val_MinusLogProbMetric: 5.7993

Epoch 91: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.4682 - MinusLogProbMetric: 4.4682 - val_loss: 5.7993 - val_MinusLogProbMetric: 5.7993 - lr: 5.0000e-04 - 83s/epoch - 421ms/step
Epoch 92/1000
2023-09-18 09:13:07.189 
Epoch 92/1000 
	 loss: 4.4584, MinusLogProbMetric: 4.4584, val_loss: 5.7757, val_MinusLogProbMetric: 5.7757

Epoch 92: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.4584 - MinusLogProbMetric: 4.4584 - val_loss: 5.7757 - val_MinusLogProbMetric: 5.7757 - lr: 5.0000e-04 - 83s/epoch - 422ms/step
Epoch 93/1000
2023-09-18 09:14:29.527 
Epoch 93/1000 
	 loss: 4.4444, MinusLogProbMetric: 4.4444, val_loss: 5.8002, val_MinusLogProbMetric: 5.8002

Epoch 93: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.4444 - MinusLogProbMetric: 4.4444 - val_loss: 5.8002 - val_MinusLogProbMetric: 5.8002 - lr: 5.0000e-04 - 82s/epoch - 420ms/step
Epoch 94/1000
2023-09-18 09:15:51.784 
Epoch 94/1000 
	 loss: 4.4377, MinusLogProbMetric: 4.4377, val_loss: 5.8328, val_MinusLogProbMetric: 5.8328

Epoch 94: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.4377 - MinusLogProbMetric: 4.4377 - val_loss: 5.8328 - val_MinusLogProbMetric: 5.8328 - lr: 5.0000e-04 - 82s/epoch - 420ms/step
Epoch 95/1000
2023-09-18 09:17:14.647 
Epoch 95/1000 
	 loss: 4.4409, MinusLogProbMetric: 4.4409, val_loss: 5.8942, val_MinusLogProbMetric: 5.8942

Epoch 95: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.4409 - MinusLogProbMetric: 4.4409 - val_loss: 5.8942 - val_MinusLogProbMetric: 5.8942 - lr: 5.0000e-04 - 83s/epoch - 423ms/step
Epoch 96/1000
2023-09-18 09:18:36.382 
Epoch 96/1000 
	 loss: 4.4244, MinusLogProbMetric: 4.4244, val_loss: 5.8670, val_MinusLogProbMetric: 5.8670

Epoch 96: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.4244 - MinusLogProbMetric: 4.4244 - val_loss: 5.8670 - val_MinusLogProbMetric: 5.8670 - lr: 5.0000e-04 - 82s/epoch - 417ms/step
Epoch 97/1000
2023-09-18 09:19:58.372 
Epoch 97/1000 
	 loss: 4.4291, MinusLogProbMetric: 4.4291, val_loss: 5.8589, val_MinusLogProbMetric: 5.8589

Epoch 97: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.4291 - MinusLogProbMetric: 4.4291 - val_loss: 5.8589 - val_MinusLogProbMetric: 5.8589 - lr: 5.0000e-04 - 82s/epoch - 418ms/step
Epoch 98/1000
2023-09-18 09:21:20.198 
Epoch 98/1000 
	 loss: 4.4207, MinusLogProbMetric: 4.4207, val_loss: 5.8715, val_MinusLogProbMetric: 5.8715

Epoch 98: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.4207 - MinusLogProbMetric: 4.4207 - val_loss: 5.8715 - val_MinusLogProbMetric: 5.8715 - lr: 5.0000e-04 - 82s/epoch - 417ms/step
Epoch 99/1000
2023-09-18 09:22:42.016 
Epoch 99/1000 
	 loss: 4.4240, MinusLogProbMetric: 4.4240, val_loss: 5.9058, val_MinusLogProbMetric: 5.9058

Epoch 99: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.4240 - MinusLogProbMetric: 4.4240 - val_loss: 5.9058 - val_MinusLogProbMetric: 5.9058 - lr: 5.0000e-04 - 82s/epoch - 417ms/step
Epoch 100/1000
2023-09-18 09:24:04.067 
Epoch 100/1000 
	 loss: 4.4010, MinusLogProbMetric: 4.4010, val_loss: 5.9102, val_MinusLogProbMetric: 5.9102

Epoch 100: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.4010 - MinusLogProbMetric: 4.4010 - val_loss: 5.9102 - val_MinusLogProbMetric: 5.9102 - lr: 5.0000e-04 - 82s/epoch - 419ms/step
Epoch 101/1000
2023-09-18 09:25:26.898 
Epoch 101/1000 
	 loss: 4.4092, MinusLogProbMetric: 4.4092, val_loss: 5.8847, val_MinusLogProbMetric: 5.8847

Epoch 101: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.4092 - MinusLogProbMetric: 4.4092 - val_loss: 5.8847 - val_MinusLogProbMetric: 5.8847 - lr: 5.0000e-04 - 83s/epoch - 423ms/step
Epoch 102/1000
2023-09-18 09:26:49.253 
Epoch 102/1000 
	 loss: 4.4079, MinusLogProbMetric: 4.4079, val_loss: 5.9373, val_MinusLogProbMetric: 5.9373

Epoch 102: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.4079 - MinusLogProbMetric: 4.4079 - val_loss: 5.9373 - val_MinusLogProbMetric: 5.9373 - lr: 5.0000e-04 - 82s/epoch - 420ms/step
Epoch 103/1000
2023-09-18 09:28:11.616 
Epoch 103/1000 
	 loss: 4.3947, MinusLogProbMetric: 4.3947, val_loss: 5.9989, val_MinusLogProbMetric: 5.9989

Epoch 103: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.3947 - MinusLogProbMetric: 4.3947 - val_loss: 5.9989 - val_MinusLogProbMetric: 5.9989 - lr: 5.0000e-04 - 82s/epoch - 420ms/step
Epoch 104/1000
2023-09-18 09:29:34.536 
Epoch 104/1000 
	 loss: 4.3846, MinusLogProbMetric: 4.3846, val_loss: 5.9977, val_MinusLogProbMetric: 5.9977

Epoch 104: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.3846 - MinusLogProbMetric: 4.3846 - val_loss: 5.9977 - val_MinusLogProbMetric: 5.9977 - lr: 5.0000e-04 - 83s/epoch - 423ms/step
Epoch 105/1000
2023-09-18 09:30:52.098 
Epoch 105/1000 
	 loss: 4.3964, MinusLogProbMetric: 4.3964, val_loss: 5.9137, val_MinusLogProbMetric: 5.9137

Epoch 105: val_loss did not improve from 5.39754
196/196 - 78s - loss: 4.3964 - MinusLogProbMetric: 4.3964 - val_loss: 5.9137 - val_MinusLogProbMetric: 5.9137 - lr: 5.0000e-04 - 78s/epoch - 396ms/step
Epoch 106/1000
2023-09-18 09:31:58.405 
Epoch 106/1000 
	 loss: 4.3658, MinusLogProbMetric: 4.3658, val_loss: 6.0041, val_MinusLogProbMetric: 6.0041

Epoch 106: val_loss did not improve from 5.39754
196/196 - 66s - loss: 4.3658 - MinusLogProbMetric: 4.3658 - val_loss: 6.0041 - val_MinusLogProbMetric: 6.0041 - lr: 5.0000e-04 - 66s/epoch - 338ms/step
Epoch 107/1000
2023-09-18 09:33:00.923 
Epoch 107/1000 
	 loss: 4.3553, MinusLogProbMetric: 4.3553, val_loss: 6.0818, val_MinusLogProbMetric: 6.0818

Epoch 107: val_loss did not improve from 5.39754
196/196 - 63s - loss: 4.3553 - MinusLogProbMetric: 4.3553 - val_loss: 6.0818 - val_MinusLogProbMetric: 6.0818 - lr: 5.0000e-04 - 63s/epoch - 319ms/step
Epoch 108/1000
2023-09-18 09:34:15.110 
Epoch 108/1000 
	 loss: 4.3668, MinusLogProbMetric: 4.3668, val_loss: 6.0550, val_MinusLogProbMetric: 6.0550

Epoch 108: val_loss did not improve from 5.39754
196/196 - 74s - loss: 4.3668 - MinusLogProbMetric: 4.3668 - val_loss: 6.0550 - val_MinusLogProbMetric: 6.0550 - lr: 5.0000e-04 - 74s/epoch - 378ms/step
Epoch 109/1000
2023-09-18 09:35:34.781 
Epoch 109/1000 
	 loss: 4.3548, MinusLogProbMetric: 4.3548, val_loss: 6.0503, val_MinusLogProbMetric: 6.0503

Epoch 109: val_loss did not improve from 5.39754
196/196 - 80s - loss: 4.3548 - MinusLogProbMetric: 4.3548 - val_loss: 6.0503 - val_MinusLogProbMetric: 6.0503 - lr: 5.0000e-04 - 80s/epoch - 406ms/step
Epoch 110/1000
2023-09-18 09:36:56.799 
Epoch 110/1000 
	 loss: 4.3628, MinusLogProbMetric: 4.3628, val_loss: 6.0582, val_MinusLogProbMetric: 6.0582

Epoch 110: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.3628 - MinusLogProbMetric: 4.3628 - val_loss: 6.0582 - val_MinusLogProbMetric: 6.0582 - lr: 5.0000e-04 - 82s/epoch - 418ms/step
Epoch 111/1000
2023-09-18 09:38:19.355 
Epoch 111/1000 
	 loss: 4.3498, MinusLogProbMetric: 4.3498, val_loss: 6.0871, val_MinusLogProbMetric: 6.0871

Epoch 111: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.3498 - MinusLogProbMetric: 4.3498 - val_loss: 6.0871 - val_MinusLogProbMetric: 6.0871 - lr: 5.0000e-04 - 83s/epoch - 421ms/step
Epoch 112/1000
2023-09-18 09:39:41.802 
Epoch 112/1000 
	 loss: 4.3417, MinusLogProbMetric: 4.3417, val_loss: 6.1385, val_MinusLogProbMetric: 6.1385

Epoch 112: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.3417 - MinusLogProbMetric: 4.3417 - val_loss: 6.1385 - val_MinusLogProbMetric: 6.1385 - lr: 5.0000e-04 - 82s/epoch - 421ms/step
Epoch 113/1000
2023-09-18 09:41:04.430 
Epoch 113/1000 
	 loss: 4.3467, MinusLogProbMetric: 4.3467, val_loss: 6.1040, val_MinusLogProbMetric: 6.1040

Epoch 113: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.3467 - MinusLogProbMetric: 4.3467 - val_loss: 6.1040 - val_MinusLogProbMetric: 6.1040 - lr: 5.0000e-04 - 83s/epoch - 422ms/step
Epoch 114/1000
2023-09-18 09:42:27.588 
Epoch 114/1000 
	 loss: 4.3330, MinusLogProbMetric: 4.3330, val_loss: 6.0791, val_MinusLogProbMetric: 6.0791

Epoch 114: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.3330 - MinusLogProbMetric: 4.3330 - val_loss: 6.0791 - val_MinusLogProbMetric: 6.0791 - lr: 5.0000e-04 - 83s/epoch - 424ms/step
Epoch 115/1000
2023-09-18 09:43:50.584 
Epoch 115/1000 
	 loss: 4.3370, MinusLogProbMetric: 4.3370, val_loss: 6.1360, val_MinusLogProbMetric: 6.1360

Epoch 115: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.3370 - MinusLogProbMetric: 4.3370 - val_loss: 6.1360 - val_MinusLogProbMetric: 6.1360 - lr: 5.0000e-04 - 83s/epoch - 423ms/step
Epoch 116/1000
2023-09-18 09:45:13.722 
Epoch 116/1000 
	 loss: 4.3121, MinusLogProbMetric: 4.3121, val_loss: 6.1595, val_MinusLogProbMetric: 6.1595

Epoch 116: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.3121 - MinusLogProbMetric: 4.3121 - val_loss: 6.1595 - val_MinusLogProbMetric: 6.1595 - lr: 5.0000e-04 - 83s/epoch - 424ms/step
Epoch 117/1000
2023-09-18 09:46:35.901 
Epoch 117/1000 
	 loss: 4.3174, MinusLogProbMetric: 4.3174, val_loss: 6.1912, val_MinusLogProbMetric: 6.1912

Epoch 117: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.3174 - MinusLogProbMetric: 4.3174 - val_loss: 6.1912 - val_MinusLogProbMetric: 6.1912 - lr: 5.0000e-04 - 82s/epoch - 419ms/step
Epoch 118/1000
2023-09-18 09:47:58.874 
Epoch 118/1000 
	 loss: 4.3196, MinusLogProbMetric: 4.3196, val_loss: 6.1906, val_MinusLogProbMetric: 6.1906

Epoch 118: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.3196 - MinusLogProbMetric: 4.3196 - val_loss: 6.1906 - val_MinusLogProbMetric: 6.1906 - lr: 5.0000e-04 - 83s/epoch - 423ms/step
Epoch 119/1000
2023-09-18 09:49:21.223 
Epoch 119/1000 
	 loss: 4.3082, MinusLogProbMetric: 4.3082, val_loss: 6.1674, val_MinusLogProbMetric: 6.1674

Epoch 119: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.3082 - MinusLogProbMetric: 4.3082 - val_loss: 6.1674 - val_MinusLogProbMetric: 6.1674 - lr: 5.0000e-04 - 82s/epoch - 420ms/step
Epoch 120/1000
2023-09-18 09:50:43.905 
Epoch 120/1000 
	 loss: 4.3110, MinusLogProbMetric: 4.3110, val_loss: 6.2064, val_MinusLogProbMetric: 6.2064

Epoch 120: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.3110 - MinusLogProbMetric: 4.3110 - val_loss: 6.2064 - val_MinusLogProbMetric: 6.2064 - lr: 5.0000e-04 - 83s/epoch - 422ms/step
Epoch 121/1000
2023-09-18 09:52:06.815 
Epoch 121/1000 
	 loss: 4.2852, MinusLogProbMetric: 4.2852, val_loss: 6.2591, val_MinusLogProbMetric: 6.2591

Epoch 121: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.2852 - MinusLogProbMetric: 4.2852 - val_loss: 6.2591 - val_MinusLogProbMetric: 6.2591 - lr: 5.0000e-04 - 83s/epoch - 423ms/step
Epoch 122/1000
2023-09-18 09:53:29.320 
Epoch 122/1000 
	 loss: 4.2980, MinusLogProbMetric: 4.2980, val_loss: 6.2456, val_MinusLogProbMetric: 6.2456

Epoch 122: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.2980 - MinusLogProbMetric: 4.2980 - val_loss: 6.2456 - val_MinusLogProbMetric: 6.2456 - lr: 5.0000e-04 - 83s/epoch - 421ms/step
Epoch 123/1000
2023-09-18 09:54:52.443 
Epoch 123/1000 
	 loss: 4.2961, MinusLogProbMetric: 4.2961, val_loss: 6.2780, val_MinusLogProbMetric: 6.2780

Epoch 123: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.2961 - MinusLogProbMetric: 4.2961 - val_loss: 6.2780 - val_MinusLogProbMetric: 6.2780 - lr: 5.0000e-04 - 83s/epoch - 424ms/step
Epoch 124/1000
2023-09-18 09:56:15.968 
Epoch 124/1000 
	 loss: 4.2890, MinusLogProbMetric: 4.2890, val_loss: 6.2377, val_MinusLogProbMetric: 6.2377

Epoch 124: val_loss did not improve from 5.39754
196/196 - 84s - loss: 4.2890 - MinusLogProbMetric: 4.2890 - val_loss: 6.2377 - val_MinusLogProbMetric: 6.2377 - lr: 5.0000e-04 - 84s/epoch - 426ms/step
Epoch 125/1000
2023-09-18 09:57:38.451 
Epoch 125/1000 
	 loss: 4.2893, MinusLogProbMetric: 4.2893, val_loss: 6.2230, val_MinusLogProbMetric: 6.2230

Epoch 125: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.2893 - MinusLogProbMetric: 4.2893 - val_loss: 6.2230 - val_MinusLogProbMetric: 6.2230 - lr: 5.0000e-04 - 82s/epoch - 421ms/step
Epoch 126/1000
2023-09-18 09:59:01.143 
Epoch 126/1000 
	 loss: 4.2755, MinusLogProbMetric: 4.2755, val_loss: 6.2137, val_MinusLogProbMetric: 6.2137

Epoch 126: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.2755 - MinusLogProbMetric: 4.2755 - val_loss: 6.2137 - val_MinusLogProbMetric: 6.2137 - lr: 5.0000e-04 - 83s/epoch - 422ms/step
Epoch 127/1000
2023-09-18 10:00:23.515 
Epoch 127/1000 
	 loss: 4.2679, MinusLogProbMetric: 4.2679, val_loss: 6.2649, val_MinusLogProbMetric: 6.2649

Epoch 127: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.2679 - MinusLogProbMetric: 4.2679 - val_loss: 6.2649 - val_MinusLogProbMetric: 6.2649 - lr: 5.0000e-04 - 82s/epoch - 420ms/step
Epoch 128/1000
2023-09-18 10:01:45.952 
Epoch 128/1000 
	 loss: 4.2522, MinusLogProbMetric: 4.2522, val_loss: 6.2501, val_MinusLogProbMetric: 6.2501

Epoch 128: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.2522 - MinusLogProbMetric: 4.2522 - val_loss: 6.2501 - val_MinusLogProbMetric: 6.2501 - lr: 5.0000e-04 - 82s/epoch - 421ms/step
Epoch 129/1000
2023-09-18 10:03:08.576 
Epoch 129/1000 
	 loss: 4.2833, MinusLogProbMetric: 4.2833, val_loss: 6.2354, val_MinusLogProbMetric: 6.2354

Epoch 129: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.2833 - MinusLogProbMetric: 4.2833 - val_loss: 6.2354 - val_MinusLogProbMetric: 6.2354 - lr: 5.0000e-04 - 83s/epoch - 422ms/step
Epoch 130/1000
2023-09-18 10:04:31.348 
Epoch 130/1000 
	 loss: 4.2512, MinusLogProbMetric: 4.2512, val_loss: 6.3750, val_MinusLogProbMetric: 6.3750

Epoch 130: val_loss did not improve from 5.39754
196/196 - 83s - loss: 4.2512 - MinusLogProbMetric: 4.2512 - val_loss: 6.3750 - val_MinusLogProbMetric: 6.3750 - lr: 5.0000e-04 - 83s/epoch - 422ms/step
Epoch 131/1000
2023-09-18 10:05:51.645 
Epoch 131/1000 
	 loss: 4.2593, MinusLogProbMetric: 4.2593, val_loss: 6.2534, val_MinusLogProbMetric: 6.2534

Epoch 131: val_loss did not improve from 5.39754
196/196 - 80s - loss: 4.2593 - MinusLogProbMetric: 4.2593 - val_loss: 6.2534 - val_MinusLogProbMetric: 6.2534 - lr: 5.0000e-04 - 80s/epoch - 410ms/step
Epoch 132/1000
2023-09-18 10:07:01.506 
Epoch 132/1000 
	 loss: 4.2630, MinusLogProbMetric: 4.2630, val_loss: 6.3515, val_MinusLogProbMetric: 6.3515

Epoch 132: val_loss did not improve from 5.39754
196/196 - 70s - loss: 4.2630 - MinusLogProbMetric: 4.2630 - val_loss: 6.3515 - val_MinusLogProbMetric: 6.3515 - lr: 5.0000e-04 - 70s/epoch - 356ms/step
Epoch 133/1000
2023-09-18 10:08:05.405 
Epoch 133/1000 
	 loss: 4.2575, MinusLogProbMetric: 4.2575, val_loss: 6.3619, val_MinusLogProbMetric: 6.3619

Epoch 133: val_loss did not improve from 5.39754
196/196 - 64s - loss: 4.2575 - MinusLogProbMetric: 4.2575 - val_loss: 6.3619 - val_MinusLogProbMetric: 6.3619 - lr: 5.0000e-04 - 64s/epoch - 326ms/step
Epoch 134/1000
2023-09-18 10:09:23.876 
Epoch 134/1000 
	 loss: 4.2375, MinusLogProbMetric: 4.2375, val_loss: 6.3952, val_MinusLogProbMetric: 6.3952

Epoch 134: val_loss did not improve from 5.39754
196/196 - 78s - loss: 4.2375 - MinusLogProbMetric: 4.2375 - val_loss: 6.3952 - val_MinusLogProbMetric: 6.3952 - lr: 5.0000e-04 - 78s/epoch - 400ms/step
Epoch 135/1000
2023-09-18 10:10:44.865 
Epoch 135/1000 
	 loss: 4.2283, MinusLogProbMetric: 4.2283, val_loss: 6.4270, val_MinusLogProbMetric: 6.4270

Epoch 135: val_loss did not improve from 5.39754
196/196 - 81s - loss: 4.2283 - MinusLogProbMetric: 4.2283 - val_loss: 6.4270 - val_MinusLogProbMetric: 6.4270 - lr: 5.0000e-04 - 81s/epoch - 413ms/step
Epoch 136/1000
2023-09-18 10:12:07.368 
Epoch 136/1000 
	 loss: 4.2443, MinusLogProbMetric: 4.2443, val_loss: 6.2802, val_MinusLogProbMetric: 6.2802

Epoch 136: val_loss did not improve from 5.39754
196/196 - 82s - loss: 4.2443 - MinusLogProbMetric: 4.2443 - val_loss: 6.2802 - val_MinusLogProbMetric: 6.2802 - lr: 5.0000e-04 - 82s/epoch - 421ms/step
Epoch 137/1000
2023-09-18 10:13:29.519 
Epoch 137/1000 
	 loss: 4.2280, MinusLogProbMetric: 4.2280, val_loss: 6.5427, val_MinusLogProbMetric: 6.5427

Epoch 137: val_loss did not improve from 5.39754
Restoring model weights from the end of the best epoch: 37.
196/196 - 83s - loss: 4.2280 - MinusLogProbMetric: 4.2280 - val_loss: 6.5427 - val_MinusLogProbMetric: 6.5427 - lr: 5.0000e-04 - 83s/epoch - 422ms/step
Epoch 137: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 37.734553104033694 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 17.08413321292028 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 13.58759311097674 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7faecc8160e0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 52.58549741702154 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 24.193125857040286 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 17.006202704040334 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7faac8c30280> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 187.
Model trained in 11316.26 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/c_Main_CsplineN.py , Line : 468, Func.Name : prediction_function, Message : X_data_nf: tf.Tensor = DataInputs.dist_2_num[:nsamples_test] # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 166.06 s.
===========
Run 176/720 done in 11493.94 s.
===========

Directory ../../results/CsplineN_new/run_177/ already exists.
Skipping it.
===========
Run 177/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_178/ already exists.
Skipping it.
===========
Run 178/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_179/ already exists.
Skipping it.
===========
Run 179/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_180/ already exists.
Skipping it.
===========
Run 180/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_181/ already exists.
Skipping it.
===========
Run 181/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_182/ already exists.
Skipping it.
===========
Run 182/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_183/ already exists.
Skipping it.
===========
Run 183/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_184/ already exists.
Skipping it.
===========
Run 184/720 already exists. Skipping it.
===========

===========
Generating train data for run 185.
===========
Train data generated in 0.10 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 16)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_185/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 440}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_185/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.9388056 ,  6.6011305 ,  7.1936936 , ...,  9.376897  ,
        -0.20441407,  0.997946  ],
       [ 5.7592807 ,  7.4562755 ,  6.073807  , ...,  8.982617  ,
         1.3178213 ,  0.7693994 ],
       [ 4.825065  ,  5.849577  ,  0.14626749, ...,  6.3837705 ,
         2.132065  ,  1.518469  ],
       ...,
       [ 5.615609  ,  7.2656503 ,  4.8600593 , ...,  9.083482  ,
         0.68300927,  1.0057955 ],
       [ 4.1834145 ,  6.0909553 ,  0.23574165, ...,  7.763974  ,
         1.9834036 ,  1.2137753 ],
       [ 3.9210687 ,  6.0211887 ,  0.28002483, ...,  6.9610376 ,
         1.7232312 ,  1.247894  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_185/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_185
self.data_kwargs: {'seed': 440}
self.x_data: [[5.9069815  7.5444255  6.3762054  ... 9.075856   0.9364161  0.80815375]
 [4.741565   5.111489   0.30516613 ... 6.3444896  2.1198235  1.1959152 ]
 [5.3968034  7.4016695  5.7313123  ... 9.37714    0.68808633 0.8965562 ]
 ...
 [5.630116   6.508466   4.560816   ... 9.354164   0.5113934  0.8420493 ]
 [3.8550687  6.072236   0.15075347 ... 6.0798836  1.9062192  1.6859822 ]
 [5.6194196  7.5907955  5.8847475  ... 9.269651   0.46180454 0.8692333 ]]
self.y_data: []
self.ndims: 16
Model defined.
Model: "model_140"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_141 (InputLayer)      [(None, 16)]              0         
                                                                 
 log_prob_layer_15 (LogProbL  (None,)                  289560    
 ayer)                                                           
                                                                 
=================================================================
Total params: 289,560
Trainable params: 289,560
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_15/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_15'")
self.model: <keras.engine.functional.Functional object at 0x7fb5867446a0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fb586cdd4e0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fb586cdd4e0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7faea5f16980>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fae4d159720>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fae4d159c90>, <keras.callbacks.ModelCheckpoint object at 0x7fae4d159d50>, <keras.callbacks.EarlyStopping object at 0x7fae4d159fc0>, <keras.callbacks.ReduceLROnPlateau object at 0x7fae4d159ff0>, <keras.callbacks.TerminateOnNaN object at 0x7fae4d159c30>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.9388056 ,  6.6011305 ,  7.1936936 , ...,  9.376897  ,
        -0.20441407,  0.997946  ],
       [ 5.7592807 ,  7.4562755 ,  6.073807  , ...,  8.982617  ,
         1.3178213 ,  0.7693994 ],
       [ 4.825065  ,  5.849577  ,  0.14626749, ...,  6.3837705 ,
         2.132065  ,  1.518469  ],
       ...,
       [ 5.615609  ,  7.2656503 ,  4.8600593 , ...,  9.083482  ,
         0.68300927,  1.0057955 ],
       [ 4.1834145 ,  6.0909553 ,  0.23574165, ...,  7.763974  ,
         1.9834036 ,  1.2137753 ],
       [ 3.9210687 ,  6.0211887 ,  0.28002483, ...,  6.9610376 ,
         1.7232312 ,  1.247894  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_185/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 185/720 with hyperparameters:
timestamp = 2023-09-18 10:16:19.168228
ndims = 16
seed_train = 440
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 5
spline_knots = 8
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 289560
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [5.9069815  7.5444255  6.3762054  5.732217   4.629946   6.4001193
 4.3642464  8.792809   9.021455   4.047819   7.801147   5.4133105
 5.6628323  9.075856   0.9364161  0.80815375]
Epoch 1/1000
2023-09-18 10:17:47.795 
Epoch 1/1000 
	 loss: 27.9801, MinusLogProbMetric: 27.9801, val_loss: 9.2440, val_MinusLogProbMetric: 9.2440

Epoch 1: val_loss improved from inf to 9.24401, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 89s - loss: 27.9801 - MinusLogProbMetric: 27.9801 - val_loss: 9.2440 - val_MinusLogProbMetric: 9.2440 - lr: 0.0010 - 89s/epoch - 454ms/step
Epoch 2/1000
2023-09-18 10:18:19.606 
Epoch 2/1000 
	 loss: 8.2057, MinusLogProbMetric: 8.2057, val_loss: 7.7140, val_MinusLogProbMetric: 7.7140

Epoch 2: val_loss improved from 9.24401 to 7.71405, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 32s - loss: 8.2057 - MinusLogProbMetric: 8.2057 - val_loss: 7.7140 - val_MinusLogProbMetric: 7.7140 - lr: 0.0010 - 32s/epoch - 163ms/step
Epoch 3/1000
2023-09-18 10:18:53.252 
Epoch 3/1000 
	 loss: 7.1659, MinusLogProbMetric: 7.1659, val_loss: 7.0337, val_MinusLogProbMetric: 7.0337

Epoch 3: val_loss improved from 7.71405 to 7.03374, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 34s - loss: 7.1659 - MinusLogProbMetric: 7.1659 - val_loss: 7.0337 - val_MinusLogProbMetric: 7.0337 - lr: 0.0010 - 34s/epoch - 171ms/step
Epoch 4/1000
2023-09-18 10:19:29.029 
Epoch 4/1000 
	 loss: 6.8353, MinusLogProbMetric: 6.8353, val_loss: 6.1715, val_MinusLogProbMetric: 6.1715

Epoch 4: val_loss improved from 7.03374 to 6.17151, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 36s - loss: 6.8353 - MinusLogProbMetric: 6.8353 - val_loss: 6.1715 - val_MinusLogProbMetric: 6.1715 - lr: 0.0010 - 36s/epoch - 184ms/step
Epoch 5/1000
2023-09-18 10:20:03.121 
Epoch 5/1000 
	 loss: 6.3573, MinusLogProbMetric: 6.3573, val_loss: 6.3270, val_MinusLogProbMetric: 6.3270

Epoch 5: val_loss did not improve from 6.17151
196/196 - 33s - loss: 6.3573 - MinusLogProbMetric: 6.3573 - val_loss: 6.3270 - val_MinusLogProbMetric: 6.3270 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 6/1000
2023-09-18 10:20:37.609 
Epoch 6/1000 
	 loss: 6.0785, MinusLogProbMetric: 6.0785, val_loss: 6.1189, val_MinusLogProbMetric: 6.1189

Epoch 6: val_loss improved from 6.17151 to 6.11890, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 35s - loss: 6.0785 - MinusLogProbMetric: 6.0785 - val_loss: 6.1189 - val_MinusLogProbMetric: 6.1189 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 7/1000
2023-09-18 10:21:12.840 
Epoch 7/1000 
	 loss: 6.0043, MinusLogProbMetric: 6.0043, val_loss: 5.8564, val_MinusLogProbMetric: 5.8564

Epoch 7: val_loss improved from 6.11890 to 5.85637, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 35s - loss: 6.0043 - MinusLogProbMetric: 6.0043 - val_loss: 5.8564 - val_MinusLogProbMetric: 5.8564 - lr: 0.0010 - 35s/epoch - 181ms/step
Epoch 8/1000
2023-09-18 10:21:48.326 
Epoch 8/1000 
	 loss: 5.8815, MinusLogProbMetric: 5.8815, val_loss: 6.4099, val_MinusLogProbMetric: 6.4099

Epoch 8: val_loss did not improve from 5.85637
196/196 - 35s - loss: 5.8815 - MinusLogProbMetric: 5.8815 - val_loss: 6.4099 - val_MinusLogProbMetric: 6.4099 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 9/1000
2023-09-18 10:22:23.560 
Epoch 9/1000 
	 loss: 5.7948, MinusLogProbMetric: 5.7948, val_loss: 5.8632, val_MinusLogProbMetric: 5.8632

Epoch 9: val_loss did not improve from 5.85637
196/196 - 35s - loss: 5.7948 - MinusLogProbMetric: 5.7948 - val_loss: 5.8632 - val_MinusLogProbMetric: 5.8632 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 10/1000
2023-09-18 10:22:58.589 
Epoch 10/1000 
	 loss: 5.7956, MinusLogProbMetric: 5.7956, val_loss: 5.7026, val_MinusLogProbMetric: 5.7026

Epoch 10: val_loss improved from 5.85637 to 5.70262, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 36s - loss: 5.7956 - MinusLogProbMetric: 5.7956 - val_loss: 5.7026 - val_MinusLogProbMetric: 5.7026 - lr: 0.0010 - 36s/epoch - 181ms/step
Epoch 11/1000
2023-09-18 10:23:34.181 
Epoch 11/1000 
	 loss: 5.7290, MinusLogProbMetric: 5.7290, val_loss: 5.7412, val_MinusLogProbMetric: 5.7412

Epoch 11: val_loss did not improve from 5.70262
196/196 - 35s - loss: 5.7290 - MinusLogProbMetric: 5.7290 - val_loss: 5.7412 - val_MinusLogProbMetric: 5.7412 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 12/1000
2023-09-18 10:24:09.348 
Epoch 12/1000 
	 loss: 5.6059, MinusLogProbMetric: 5.6059, val_loss: 5.7895, val_MinusLogProbMetric: 5.7895

Epoch 12: val_loss did not improve from 5.70262
196/196 - 35s - loss: 5.6059 - MinusLogProbMetric: 5.6059 - val_loss: 5.7895 - val_MinusLogProbMetric: 5.7895 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 13/1000
2023-09-18 10:24:44.320 
Epoch 13/1000 
	 loss: 5.5969, MinusLogProbMetric: 5.5969, val_loss: 5.6097, val_MinusLogProbMetric: 5.6097

Epoch 13: val_loss improved from 5.70262 to 5.60970, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 36s - loss: 5.5969 - MinusLogProbMetric: 5.5969 - val_loss: 5.6097 - val_MinusLogProbMetric: 5.6097 - lr: 0.0010 - 36s/epoch - 181ms/step
Epoch 14/1000
2023-09-18 10:25:20.120 
Epoch 14/1000 
	 loss: 5.5488, MinusLogProbMetric: 5.5488, val_loss: 6.0087, val_MinusLogProbMetric: 6.0087

Epoch 14: val_loss did not improve from 5.60970
196/196 - 35s - loss: 5.5488 - MinusLogProbMetric: 5.5488 - val_loss: 6.0087 - val_MinusLogProbMetric: 6.0087 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 15/1000
2023-09-18 10:25:54.911 
Epoch 15/1000 
	 loss: 5.5670, MinusLogProbMetric: 5.5670, val_loss: 5.4860, val_MinusLogProbMetric: 5.4860

Epoch 15: val_loss improved from 5.60970 to 5.48595, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 35s - loss: 5.5670 - MinusLogProbMetric: 5.5670 - val_loss: 5.4860 - val_MinusLogProbMetric: 5.4860 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 16/1000
2023-09-18 10:26:30.312 
Epoch 16/1000 
	 loss: 5.5053, MinusLogProbMetric: 5.5053, val_loss: 5.5251, val_MinusLogProbMetric: 5.5251

Epoch 16: val_loss did not improve from 5.48595
196/196 - 35s - loss: 5.5053 - MinusLogProbMetric: 5.5053 - val_loss: 5.5251 - val_MinusLogProbMetric: 5.5251 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 17/1000
2023-09-18 10:27:05.286 
Epoch 17/1000 
	 loss: 5.4523, MinusLogProbMetric: 5.4523, val_loss: 5.4297, val_MinusLogProbMetric: 5.4297

Epoch 17: val_loss improved from 5.48595 to 5.42971, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 36s - loss: 5.4523 - MinusLogProbMetric: 5.4523 - val_loss: 5.4297 - val_MinusLogProbMetric: 5.4297 - lr: 0.0010 - 36s/epoch - 181ms/step
Epoch 18/1000
2023-09-18 10:27:41.110 
Epoch 18/1000 
	 loss: 5.4680, MinusLogProbMetric: 5.4680, val_loss: 5.6204, val_MinusLogProbMetric: 5.6204

Epoch 18: val_loss did not improve from 5.42971
196/196 - 35s - loss: 5.4680 - MinusLogProbMetric: 5.4680 - val_loss: 5.6204 - val_MinusLogProbMetric: 5.6204 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 19/1000
2023-09-18 10:28:16.077 
Epoch 19/1000 
	 loss: 5.4361, MinusLogProbMetric: 5.4361, val_loss: 5.8266, val_MinusLogProbMetric: 5.8266

Epoch 19: val_loss did not improve from 5.42971
196/196 - 35s - loss: 5.4361 - MinusLogProbMetric: 5.4361 - val_loss: 5.8266 - val_MinusLogProbMetric: 5.8266 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 20/1000
2023-09-18 10:28:51.366 
Epoch 20/1000 
	 loss: 5.4094, MinusLogProbMetric: 5.4094, val_loss: 5.4432, val_MinusLogProbMetric: 5.4432

Epoch 20: val_loss did not improve from 5.42971
196/196 - 35s - loss: 5.4094 - MinusLogProbMetric: 5.4094 - val_loss: 5.4432 - val_MinusLogProbMetric: 5.4432 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 21/1000
2023-09-18 10:29:26.361 
Epoch 21/1000 
	 loss: 5.4217, MinusLogProbMetric: 5.4217, val_loss: 5.4681, val_MinusLogProbMetric: 5.4681

Epoch 21: val_loss did not improve from 5.42971
196/196 - 35s - loss: 5.4217 - MinusLogProbMetric: 5.4217 - val_loss: 5.4681 - val_MinusLogProbMetric: 5.4681 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 22/1000
2023-09-18 10:30:01.216 
Epoch 22/1000 
	 loss: 5.3649, MinusLogProbMetric: 5.3649, val_loss: 5.3965, val_MinusLogProbMetric: 5.3965

Epoch 22: val_loss improved from 5.42971 to 5.39646, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 35s - loss: 5.3649 - MinusLogProbMetric: 5.3649 - val_loss: 5.3965 - val_MinusLogProbMetric: 5.3965 - lr: 0.0010 - 35s/epoch - 181ms/step
Epoch 23/1000
2023-09-18 10:30:36.740 
Epoch 23/1000 
	 loss: 5.3775, MinusLogProbMetric: 5.3775, val_loss: 5.5012, val_MinusLogProbMetric: 5.5012

Epoch 23: val_loss did not improve from 5.39646
196/196 - 35s - loss: 5.3775 - MinusLogProbMetric: 5.3775 - val_loss: 5.5012 - val_MinusLogProbMetric: 5.5012 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 24/1000
2023-09-18 10:31:11.714 
Epoch 24/1000 
	 loss: 5.3482, MinusLogProbMetric: 5.3482, val_loss: 5.3790, val_MinusLogProbMetric: 5.3790

Epoch 24: val_loss improved from 5.39646 to 5.37904, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 36s - loss: 5.3482 - MinusLogProbMetric: 5.3482 - val_loss: 5.3790 - val_MinusLogProbMetric: 5.3790 - lr: 0.0010 - 36s/epoch - 182ms/step
Epoch 25/1000
2023-09-18 10:31:47.369 
Epoch 25/1000 
	 loss: 5.3563, MinusLogProbMetric: 5.3563, val_loss: 5.4326, val_MinusLogProbMetric: 5.4326

Epoch 25: val_loss did not improve from 5.37904
196/196 - 35s - loss: 5.3563 - MinusLogProbMetric: 5.3563 - val_loss: 5.4326 - val_MinusLogProbMetric: 5.4326 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 26/1000
2023-09-18 10:32:22.151 
Epoch 26/1000 
	 loss: 5.3366, MinusLogProbMetric: 5.3366, val_loss: 5.4026, val_MinusLogProbMetric: 5.4026

Epoch 26: val_loss did not improve from 5.37904
196/196 - 35s - loss: 5.3366 - MinusLogProbMetric: 5.3366 - val_loss: 5.4026 - val_MinusLogProbMetric: 5.4026 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 27/1000
2023-09-18 10:32:57.381 
Epoch 27/1000 
	 loss: 5.3224, MinusLogProbMetric: 5.3224, val_loss: 5.7040, val_MinusLogProbMetric: 5.7040

Epoch 27: val_loss did not improve from 5.37904
196/196 - 35s - loss: 5.3224 - MinusLogProbMetric: 5.3224 - val_loss: 5.7040 - val_MinusLogProbMetric: 5.7040 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 28/1000
2023-09-18 10:33:32.361 
Epoch 28/1000 
	 loss: 5.3118, MinusLogProbMetric: 5.3118, val_loss: 5.3281, val_MinusLogProbMetric: 5.3281

Epoch 28: val_loss improved from 5.37904 to 5.32810, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 36s - loss: 5.3118 - MinusLogProbMetric: 5.3118 - val_loss: 5.3281 - val_MinusLogProbMetric: 5.3281 - lr: 0.0010 - 36s/epoch - 182ms/step
Epoch 29/1000
2023-09-18 10:34:07.695 
Epoch 29/1000 
	 loss: 5.3064, MinusLogProbMetric: 5.3064, val_loss: 5.5680, val_MinusLogProbMetric: 5.5680

Epoch 29: val_loss did not improve from 5.32810
196/196 - 35s - loss: 5.3064 - MinusLogProbMetric: 5.3064 - val_loss: 5.5680 - val_MinusLogProbMetric: 5.5680 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 30/1000
2023-09-18 10:34:42.871 
Epoch 30/1000 
	 loss: 5.3090, MinusLogProbMetric: 5.3090, val_loss: 5.4325, val_MinusLogProbMetric: 5.4325

Epoch 30: val_loss did not improve from 5.32810
196/196 - 35s - loss: 5.3090 - MinusLogProbMetric: 5.3090 - val_loss: 5.4325 - val_MinusLogProbMetric: 5.4325 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 31/1000
2023-09-18 10:35:17.701 
Epoch 31/1000 
	 loss: 5.2927, MinusLogProbMetric: 5.2927, val_loss: 5.3319, val_MinusLogProbMetric: 5.3319

Epoch 31: val_loss did not improve from 5.32810
196/196 - 35s - loss: 5.2927 - MinusLogProbMetric: 5.2927 - val_loss: 5.3319 - val_MinusLogProbMetric: 5.3319 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 32/1000
2023-09-18 10:35:53.036 
Epoch 32/1000 
	 loss: 5.3017, MinusLogProbMetric: 5.3017, val_loss: 5.4335, val_MinusLogProbMetric: 5.4335

Epoch 32: val_loss did not improve from 5.32810
196/196 - 35s - loss: 5.3017 - MinusLogProbMetric: 5.3017 - val_loss: 5.4335 - val_MinusLogProbMetric: 5.4335 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 33/1000
2023-09-18 10:36:28.189 
Epoch 33/1000 
	 loss: 5.2745, MinusLogProbMetric: 5.2745, val_loss: 5.3877, val_MinusLogProbMetric: 5.3877

Epoch 33: val_loss did not improve from 5.32810
196/196 - 35s - loss: 5.2745 - MinusLogProbMetric: 5.2745 - val_loss: 5.3877 - val_MinusLogProbMetric: 5.3877 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 34/1000
2023-09-18 10:37:03.287 
Epoch 34/1000 
	 loss: 5.2898, MinusLogProbMetric: 5.2898, val_loss: 5.3523, val_MinusLogProbMetric: 5.3523

Epoch 34: val_loss did not improve from 5.32810
196/196 - 35s - loss: 5.2898 - MinusLogProbMetric: 5.2898 - val_loss: 5.3523 - val_MinusLogProbMetric: 5.3523 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 35/1000
2023-09-18 10:37:37.967 
Epoch 35/1000 
	 loss: 5.2798, MinusLogProbMetric: 5.2798, val_loss: 5.3434, val_MinusLogProbMetric: 5.3434

Epoch 35: val_loss did not improve from 5.32810
196/196 - 35s - loss: 5.2798 - MinusLogProbMetric: 5.2798 - val_loss: 5.3434 - val_MinusLogProbMetric: 5.3434 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 36/1000
2023-09-18 10:38:12.860 
Epoch 36/1000 
	 loss: 5.2528, MinusLogProbMetric: 5.2528, val_loss: 5.4746, val_MinusLogProbMetric: 5.4746

Epoch 36: val_loss did not improve from 5.32810
196/196 - 35s - loss: 5.2528 - MinusLogProbMetric: 5.2528 - val_loss: 5.4746 - val_MinusLogProbMetric: 5.4746 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 37/1000
2023-09-18 10:38:47.645 
Epoch 37/1000 
	 loss: 5.2633, MinusLogProbMetric: 5.2633, val_loss: 5.3179, val_MinusLogProbMetric: 5.3179

Epoch 37: val_loss improved from 5.32810 to 5.31793, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 35s - loss: 5.2633 - MinusLogProbMetric: 5.2633 - val_loss: 5.3179 - val_MinusLogProbMetric: 5.3179 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 38/1000
2023-09-18 10:39:23.431 
Epoch 38/1000 
	 loss: 5.2383, MinusLogProbMetric: 5.2383, val_loss: 5.3897, val_MinusLogProbMetric: 5.3897

Epoch 38: val_loss did not improve from 5.31793
196/196 - 35s - loss: 5.2383 - MinusLogProbMetric: 5.2383 - val_loss: 5.3897 - val_MinusLogProbMetric: 5.3897 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 39/1000
2023-09-18 10:39:58.511 
Epoch 39/1000 
	 loss: 5.2395, MinusLogProbMetric: 5.2395, val_loss: 5.3354, val_MinusLogProbMetric: 5.3354

Epoch 39: val_loss did not improve from 5.31793
196/196 - 35s - loss: 5.2395 - MinusLogProbMetric: 5.2395 - val_loss: 5.3354 - val_MinusLogProbMetric: 5.3354 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 40/1000
2023-09-18 10:40:33.353 
Epoch 40/1000 
	 loss: 5.2509, MinusLogProbMetric: 5.2509, val_loss: 5.4133, val_MinusLogProbMetric: 5.4133

Epoch 40: val_loss did not improve from 5.31793
196/196 - 35s - loss: 5.2509 - MinusLogProbMetric: 5.2509 - val_loss: 5.4133 - val_MinusLogProbMetric: 5.4133 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 41/1000
2023-09-18 10:41:08.494 
Epoch 41/1000 
	 loss: 5.2430, MinusLogProbMetric: 5.2430, val_loss: 5.5300, val_MinusLogProbMetric: 5.5300

Epoch 41: val_loss did not improve from 5.31793
196/196 - 35s - loss: 5.2430 - MinusLogProbMetric: 5.2430 - val_loss: 5.5300 - val_MinusLogProbMetric: 5.5300 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 42/1000
2023-09-18 10:41:43.465 
Epoch 42/1000 
	 loss: 5.2155, MinusLogProbMetric: 5.2155, val_loss: 5.3196, val_MinusLogProbMetric: 5.3196

Epoch 42: val_loss did not improve from 5.31793
196/196 - 35s - loss: 5.2155 - MinusLogProbMetric: 5.2155 - val_loss: 5.3196 - val_MinusLogProbMetric: 5.3196 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 43/1000
2023-09-18 10:42:18.349 
Epoch 43/1000 
	 loss: 5.2509, MinusLogProbMetric: 5.2509, val_loss: 5.3944, val_MinusLogProbMetric: 5.3944

Epoch 43: val_loss did not improve from 5.31793
196/196 - 35s - loss: 5.2509 - MinusLogProbMetric: 5.2509 - val_loss: 5.3944 - val_MinusLogProbMetric: 5.3944 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 44/1000
2023-09-18 10:42:53.605 
Epoch 44/1000 
	 loss: 5.2219, MinusLogProbMetric: 5.2219, val_loss: 5.5127, val_MinusLogProbMetric: 5.5127

Epoch 44: val_loss did not improve from 5.31793
196/196 - 35s - loss: 5.2219 - MinusLogProbMetric: 5.2219 - val_loss: 5.5127 - val_MinusLogProbMetric: 5.5127 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 45/1000
2023-09-18 10:43:28.374 
Epoch 45/1000 
	 loss: 5.2355, MinusLogProbMetric: 5.2355, val_loss: 5.2817, val_MinusLogProbMetric: 5.2817

Epoch 45: val_loss improved from 5.31793 to 5.28175, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 35s - loss: 5.2355 - MinusLogProbMetric: 5.2355 - val_loss: 5.2817 - val_MinusLogProbMetric: 5.2817 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 46/1000
2023-09-18 10:44:04.202 
Epoch 46/1000 
	 loss: 5.2185, MinusLogProbMetric: 5.2185, val_loss: 5.3541, val_MinusLogProbMetric: 5.3541

Epoch 46: val_loss did not improve from 5.28175
196/196 - 35s - loss: 5.2185 - MinusLogProbMetric: 5.2185 - val_loss: 5.3541 - val_MinusLogProbMetric: 5.3541 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 47/1000
2023-09-18 10:44:39.150 
Epoch 47/1000 
	 loss: 5.2033, MinusLogProbMetric: 5.2033, val_loss: 5.4061, val_MinusLogProbMetric: 5.4061

Epoch 47: val_loss did not improve from 5.28175
196/196 - 35s - loss: 5.2033 - MinusLogProbMetric: 5.2033 - val_loss: 5.4061 - val_MinusLogProbMetric: 5.4061 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 48/1000
2023-09-18 10:45:14.409 
Epoch 48/1000 
	 loss: 5.2183, MinusLogProbMetric: 5.2183, val_loss: 5.3160, val_MinusLogProbMetric: 5.3160

Epoch 48: val_loss did not improve from 5.28175
196/196 - 35s - loss: 5.2183 - MinusLogProbMetric: 5.2183 - val_loss: 5.3160 - val_MinusLogProbMetric: 5.3160 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 49/1000
2023-09-18 10:45:49.182 
Epoch 49/1000 
	 loss: 5.1934, MinusLogProbMetric: 5.1934, val_loss: 5.3542, val_MinusLogProbMetric: 5.3542

Epoch 49: val_loss did not improve from 5.28175
196/196 - 35s - loss: 5.1934 - MinusLogProbMetric: 5.1934 - val_loss: 5.3542 - val_MinusLogProbMetric: 5.3542 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 50/1000
2023-09-18 10:46:24.083 
Epoch 50/1000 
	 loss: 5.2001, MinusLogProbMetric: 5.2001, val_loss: 5.3450, val_MinusLogProbMetric: 5.3450

Epoch 50: val_loss did not improve from 5.28175
196/196 - 35s - loss: 5.2001 - MinusLogProbMetric: 5.2001 - val_loss: 5.3450 - val_MinusLogProbMetric: 5.3450 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 51/1000
2023-09-18 10:46:59.000 
Epoch 51/1000 
	 loss: 5.1921, MinusLogProbMetric: 5.1921, val_loss: 5.2932, val_MinusLogProbMetric: 5.2932

Epoch 51: val_loss did not improve from 5.28175
196/196 - 35s - loss: 5.1921 - MinusLogProbMetric: 5.1921 - val_loss: 5.2932 - val_MinusLogProbMetric: 5.2932 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 52/1000
2023-09-18 10:47:33.677 
Epoch 52/1000 
	 loss: 5.1972, MinusLogProbMetric: 5.1972, val_loss: 5.3757, val_MinusLogProbMetric: 5.3757

Epoch 52: val_loss did not improve from 5.28175
196/196 - 35s - loss: 5.1972 - MinusLogProbMetric: 5.1972 - val_loss: 5.3757 - val_MinusLogProbMetric: 5.3757 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 53/1000
2023-09-18 10:48:08.902 
Epoch 53/1000 
	 loss: 5.1782, MinusLogProbMetric: 5.1782, val_loss: 5.3245, val_MinusLogProbMetric: 5.3245

Epoch 53: val_loss did not improve from 5.28175
196/196 - 35s - loss: 5.1782 - MinusLogProbMetric: 5.1782 - val_loss: 5.3245 - val_MinusLogProbMetric: 5.3245 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 54/1000
2023-09-18 10:48:43.919 
Epoch 54/1000 
	 loss: 5.1871, MinusLogProbMetric: 5.1871, val_loss: 5.3139, val_MinusLogProbMetric: 5.3139

Epoch 54: val_loss did not improve from 5.28175
196/196 - 35s - loss: 5.1871 - MinusLogProbMetric: 5.1871 - val_loss: 5.3139 - val_MinusLogProbMetric: 5.3139 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 55/1000
2023-09-18 10:49:18.914 
Epoch 55/1000 
	 loss: 5.1799, MinusLogProbMetric: 5.1799, val_loss: 5.3355, val_MinusLogProbMetric: 5.3355

Epoch 55: val_loss did not improve from 5.28175
196/196 - 35s - loss: 5.1799 - MinusLogProbMetric: 5.1799 - val_loss: 5.3355 - val_MinusLogProbMetric: 5.3355 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 56/1000
2023-09-18 10:49:53.620 
Epoch 56/1000 
	 loss: 5.1883, MinusLogProbMetric: 5.1883, val_loss: 5.2957, val_MinusLogProbMetric: 5.2957

Epoch 56: val_loss did not improve from 5.28175
196/196 - 35s - loss: 5.1883 - MinusLogProbMetric: 5.1883 - val_loss: 5.2957 - val_MinusLogProbMetric: 5.2957 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 57/1000
2023-09-18 10:50:28.504 
Epoch 57/1000 
	 loss: 5.1788, MinusLogProbMetric: 5.1788, val_loss: 5.3832, val_MinusLogProbMetric: 5.3832

Epoch 57: val_loss did not improve from 5.28175
196/196 - 35s - loss: 5.1788 - MinusLogProbMetric: 5.1788 - val_loss: 5.3832 - val_MinusLogProbMetric: 5.3832 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 58/1000
2023-09-18 10:51:03.093 
Epoch 58/1000 
	 loss: 5.1861, MinusLogProbMetric: 5.1861, val_loss: 5.2699, val_MinusLogProbMetric: 5.2699

Epoch 58: val_loss improved from 5.28175 to 5.26994, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 35s - loss: 5.1861 - MinusLogProbMetric: 5.1861 - val_loss: 5.2699 - val_MinusLogProbMetric: 5.2699 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 59/1000
2023-09-18 10:51:38.003 
Epoch 59/1000 
	 loss: 5.1693, MinusLogProbMetric: 5.1693, val_loss: 5.2610, val_MinusLogProbMetric: 5.2610

Epoch 59: val_loss improved from 5.26994 to 5.26099, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 35s - loss: 5.1693 - MinusLogProbMetric: 5.1693 - val_loss: 5.2610 - val_MinusLogProbMetric: 5.2610 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 60/1000
2023-09-18 10:52:13.672 
Epoch 60/1000 
	 loss: 5.1592, MinusLogProbMetric: 5.1592, val_loss: 5.3009, val_MinusLogProbMetric: 5.3009

Epoch 60: val_loss did not improve from 5.26099
196/196 - 35s - loss: 5.1592 - MinusLogProbMetric: 5.1592 - val_loss: 5.3009 - val_MinusLogProbMetric: 5.3009 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 61/1000
2023-09-18 10:52:48.069 
Epoch 61/1000 
	 loss: 5.1609, MinusLogProbMetric: 5.1609, val_loss: 5.2707, val_MinusLogProbMetric: 5.2707

Epoch 61: val_loss did not improve from 5.26099
196/196 - 34s - loss: 5.1609 - MinusLogProbMetric: 5.1609 - val_loss: 5.2707 - val_MinusLogProbMetric: 5.2707 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 62/1000
2023-09-18 10:53:23.102 
Epoch 62/1000 
	 loss: 5.1639, MinusLogProbMetric: 5.1639, val_loss: 5.3533, val_MinusLogProbMetric: 5.3533

Epoch 62: val_loss did not improve from 5.26099
196/196 - 35s - loss: 5.1639 - MinusLogProbMetric: 5.1639 - val_loss: 5.3533 - val_MinusLogProbMetric: 5.3533 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 63/1000
2023-09-18 10:53:58.192 
Epoch 63/1000 
	 loss: 5.1730, MinusLogProbMetric: 5.1730, val_loss: 5.2681, val_MinusLogProbMetric: 5.2681

Epoch 63: val_loss did not improve from 5.26099
196/196 - 35s - loss: 5.1730 - MinusLogProbMetric: 5.1730 - val_loss: 5.2681 - val_MinusLogProbMetric: 5.2681 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 64/1000
2023-09-18 10:54:33.137 
Epoch 64/1000 
	 loss: 5.1664, MinusLogProbMetric: 5.1664, val_loss: 5.3211, val_MinusLogProbMetric: 5.3211

Epoch 64: val_loss did not improve from 5.26099
196/196 - 35s - loss: 5.1664 - MinusLogProbMetric: 5.1664 - val_loss: 5.3211 - val_MinusLogProbMetric: 5.3211 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 65/1000
2023-09-18 10:55:07.821 
Epoch 65/1000 
	 loss: 5.1696, MinusLogProbMetric: 5.1696, val_loss: 5.2996, val_MinusLogProbMetric: 5.2996

Epoch 65: val_loss did not improve from 5.26099
196/196 - 35s - loss: 5.1696 - MinusLogProbMetric: 5.1696 - val_loss: 5.2996 - val_MinusLogProbMetric: 5.2996 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 66/1000
2023-09-18 10:55:42.908 
Epoch 66/1000 
	 loss: 5.1608, MinusLogProbMetric: 5.1608, val_loss: 5.2882, val_MinusLogProbMetric: 5.2882

Epoch 66: val_loss did not improve from 5.26099
196/196 - 35s - loss: 5.1608 - MinusLogProbMetric: 5.1608 - val_loss: 5.2882 - val_MinusLogProbMetric: 5.2882 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 67/1000
2023-09-18 10:56:18.827 
Epoch 67/1000 
	 loss: 5.1579, MinusLogProbMetric: 5.1579, val_loss: 5.4804, val_MinusLogProbMetric: 5.4804

Epoch 67: val_loss did not improve from 5.26099
196/196 - 36s - loss: 5.1579 - MinusLogProbMetric: 5.1579 - val_loss: 5.4804 - val_MinusLogProbMetric: 5.4804 - lr: 0.0010 - 36s/epoch - 183ms/step
Epoch 68/1000
2023-09-18 10:56:54.794 
Epoch 68/1000 
	 loss: 5.1558, MinusLogProbMetric: 5.1558, val_loss: 5.3465, val_MinusLogProbMetric: 5.3465

Epoch 68: val_loss did not improve from 5.26099
196/196 - 36s - loss: 5.1558 - MinusLogProbMetric: 5.1558 - val_loss: 5.3465 - val_MinusLogProbMetric: 5.3465 - lr: 0.0010 - 36s/epoch - 184ms/step
Epoch 69/1000
2023-09-18 10:57:30.653 
Epoch 69/1000 
	 loss: 5.1374, MinusLogProbMetric: 5.1374, val_loss: 5.2612, val_MinusLogProbMetric: 5.2612

Epoch 69: val_loss did not improve from 5.26099
196/196 - 36s - loss: 5.1374 - MinusLogProbMetric: 5.1374 - val_loss: 5.2612 - val_MinusLogProbMetric: 5.2612 - lr: 0.0010 - 36s/epoch - 183ms/step
Epoch 70/1000
2023-09-18 10:58:05.777 
Epoch 70/1000 
	 loss: 5.1433, MinusLogProbMetric: 5.1433, val_loss: 5.2502, val_MinusLogProbMetric: 5.2502

Epoch 70: val_loss improved from 5.26099 to 5.25020, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 36s - loss: 5.1433 - MinusLogProbMetric: 5.1433 - val_loss: 5.2502 - val_MinusLogProbMetric: 5.2502 - lr: 0.0010 - 36s/epoch - 183ms/step
Epoch 71/1000
2023-09-18 10:58:42.079 
Epoch 71/1000 
	 loss: 5.1411, MinusLogProbMetric: 5.1411, val_loss: 5.2910, val_MinusLogProbMetric: 5.2910

Epoch 71: val_loss did not improve from 5.25020
196/196 - 35s - loss: 5.1411 - MinusLogProbMetric: 5.1411 - val_loss: 5.2910 - val_MinusLogProbMetric: 5.2910 - lr: 0.0010 - 35s/epoch - 181ms/step
Epoch 72/1000
2023-09-18 10:59:17.442 
Epoch 72/1000 
	 loss: 5.1486, MinusLogProbMetric: 5.1486, val_loss: 5.4954, val_MinusLogProbMetric: 5.4954

Epoch 72: val_loss did not improve from 5.25020
196/196 - 35s - loss: 5.1486 - MinusLogProbMetric: 5.1486 - val_loss: 5.4954 - val_MinusLogProbMetric: 5.4954 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 73/1000
2023-09-18 10:59:52.498 
Epoch 73/1000 
	 loss: 5.1572, MinusLogProbMetric: 5.1572, val_loss: 5.3384, val_MinusLogProbMetric: 5.3384

Epoch 73: val_loss did not improve from 5.25020
196/196 - 35s - loss: 5.1572 - MinusLogProbMetric: 5.1572 - val_loss: 5.3384 - val_MinusLogProbMetric: 5.3384 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 74/1000
2023-09-18 11:00:27.699 
Epoch 74/1000 
	 loss: 5.1416, MinusLogProbMetric: 5.1416, val_loss: 5.2883, val_MinusLogProbMetric: 5.2883

Epoch 74: val_loss did not improve from 5.25020
196/196 - 35s - loss: 5.1416 - MinusLogProbMetric: 5.1416 - val_loss: 5.2883 - val_MinusLogProbMetric: 5.2883 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 75/1000
2023-09-18 11:01:02.980 
Epoch 75/1000 
	 loss: 5.1347, MinusLogProbMetric: 5.1347, val_loss: 5.2985, val_MinusLogProbMetric: 5.2985

Epoch 75: val_loss did not improve from 5.25020
196/196 - 35s - loss: 5.1347 - MinusLogProbMetric: 5.1347 - val_loss: 5.2985 - val_MinusLogProbMetric: 5.2985 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 76/1000
2023-09-18 11:01:38.021 
Epoch 76/1000 
	 loss: 5.1356, MinusLogProbMetric: 5.1356, val_loss: 5.3341, val_MinusLogProbMetric: 5.3341

Epoch 76: val_loss did not improve from 5.25020
196/196 - 35s - loss: 5.1356 - MinusLogProbMetric: 5.1356 - val_loss: 5.3341 - val_MinusLogProbMetric: 5.3341 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 77/1000
2023-09-18 11:02:13.209 
Epoch 77/1000 
	 loss: 5.1249, MinusLogProbMetric: 5.1249, val_loss: 5.2464, val_MinusLogProbMetric: 5.2464

Epoch 77: val_loss improved from 5.25020 to 5.24641, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 36s - loss: 5.1249 - MinusLogProbMetric: 5.1249 - val_loss: 5.2464 - val_MinusLogProbMetric: 5.2464 - lr: 0.0010 - 36s/epoch - 183ms/step
Epoch 78/1000
2023-09-18 11:02:48.972 
Epoch 78/1000 
	 loss: 5.1214, MinusLogProbMetric: 5.1214, val_loss: 5.2692, val_MinusLogProbMetric: 5.2692

Epoch 78: val_loss did not improve from 5.24641
196/196 - 35s - loss: 5.1214 - MinusLogProbMetric: 5.1214 - val_loss: 5.2692 - val_MinusLogProbMetric: 5.2692 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 79/1000
2023-09-18 11:03:24.158 
Epoch 79/1000 
	 loss: 5.1357, MinusLogProbMetric: 5.1357, val_loss: 5.3259, val_MinusLogProbMetric: 5.3259

Epoch 79: val_loss did not improve from 5.24641
196/196 - 35s - loss: 5.1357 - MinusLogProbMetric: 5.1357 - val_loss: 5.3259 - val_MinusLogProbMetric: 5.3259 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 80/1000
2023-09-18 11:03:59.688 
Epoch 80/1000 
	 loss: 5.1302, MinusLogProbMetric: 5.1302, val_loss: 5.2407, val_MinusLogProbMetric: 5.2407

Epoch 80: val_loss improved from 5.24641 to 5.24068, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 36s - loss: 5.1302 - MinusLogProbMetric: 5.1302 - val_loss: 5.2407 - val_MinusLogProbMetric: 5.2407 - lr: 0.0010 - 36s/epoch - 184ms/step
Epoch 81/1000
2023-09-18 11:04:35.215 
Epoch 81/1000 
	 loss: 5.1331, MinusLogProbMetric: 5.1331, val_loss: 5.2738, val_MinusLogProbMetric: 5.2738

Epoch 81: val_loss did not improve from 5.24068
196/196 - 35s - loss: 5.1331 - MinusLogProbMetric: 5.1331 - val_loss: 5.2738 - val_MinusLogProbMetric: 5.2738 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 82/1000
2023-09-18 11:05:10.535 
Epoch 82/1000 
	 loss: 5.1269, MinusLogProbMetric: 5.1269, val_loss: 5.2677, val_MinusLogProbMetric: 5.2677

Epoch 82: val_loss did not improve from 5.24068
196/196 - 35s - loss: 5.1269 - MinusLogProbMetric: 5.1269 - val_loss: 5.2677 - val_MinusLogProbMetric: 5.2677 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 83/1000
2023-09-18 11:05:45.711 
Epoch 83/1000 
	 loss: 5.1147, MinusLogProbMetric: 5.1147, val_loss: 5.3647, val_MinusLogProbMetric: 5.3647

Epoch 83: val_loss did not improve from 5.24068
196/196 - 35s - loss: 5.1147 - MinusLogProbMetric: 5.1147 - val_loss: 5.3647 - val_MinusLogProbMetric: 5.3647 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 84/1000
2023-09-18 11:06:20.427 
Epoch 84/1000 
	 loss: 5.1230, MinusLogProbMetric: 5.1230, val_loss: 5.2629, val_MinusLogProbMetric: 5.2629

Epoch 84: val_loss did not improve from 5.24068
196/196 - 35s - loss: 5.1230 - MinusLogProbMetric: 5.1230 - val_loss: 5.2629 - val_MinusLogProbMetric: 5.2629 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 85/1000
2023-09-18 11:06:55.768 
Epoch 85/1000 
	 loss: 5.1286, MinusLogProbMetric: 5.1286, val_loss: 5.2874, val_MinusLogProbMetric: 5.2874

Epoch 85: val_loss did not improve from 5.24068
196/196 - 35s - loss: 5.1286 - MinusLogProbMetric: 5.1286 - val_loss: 5.2874 - val_MinusLogProbMetric: 5.2874 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 86/1000
2023-09-18 11:07:30.743 
Epoch 86/1000 
	 loss: 5.1113, MinusLogProbMetric: 5.1113, val_loss: 5.2414, val_MinusLogProbMetric: 5.2414

Epoch 86: val_loss did not improve from 5.24068
196/196 - 35s - loss: 5.1113 - MinusLogProbMetric: 5.1113 - val_loss: 5.2414 - val_MinusLogProbMetric: 5.2414 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 87/1000
2023-09-18 11:08:05.884 
Epoch 87/1000 
	 loss: 5.1193, MinusLogProbMetric: 5.1193, val_loss: 5.2692, val_MinusLogProbMetric: 5.2692

Epoch 87: val_loss did not improve from 5.24068
196/196 - 35s - loss: 5.1193 - MinusLogProbMetric: 5.1193 - val_loss: 5.2692 - val_MinusLogProbMetric: 5.2692 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 88/1000
2023-09-18 11:08:41.173 
Epoch 88/1000 
	 loss: 5.1105, MinusLogProbMetric: 5.1105, val_loss: 5.3747, val_MinusLogProbMetric: 5.3747

Epoch 88: val_loss did not improve from 5.24068
196/196 - 35s - loss: 5.1105 - MinusLogProbMetric: 5.1105 - val_loss: 5.3747 - val_MinusLogProbMetric: 5.3747 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 89/1000
2023-09-18 11:09:16.112 
Epoch 89/1000 
	 loss: 5.1161, MinusLogProbMetric: 5.1161, val_loss: 5.2389, val_MinusLogProbMetric: 5.2389

Epoch 89: val_loss improved from 5.24068 to 5.23893, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 36s - loss: 5.1161 - MinusLogProbMetric: 5.1161 - val_loss: 5.2389 - val_MinusLogProbMetric: 5.2389 - lr: 0.0010 - 36s/epoch - 181ms/step
Epoch 90/1000
2023-09-18 11:09:51.760 
Epoch 90/1000 
	 loss: 5.1120, MinusLogProbMetric: 5.1120, val_loss: 5.2945, val_MinusLogProbMetric: 5.2945

Epoch 90: val_loss did not improve from 5.23893
196/196 - 35s - loss: 5.1120 - MinusLogProbMetric: 5.1120 - val_loss: 5.2945 - val_MinusLogProbMetric: 5.2945 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 91/1000
2023-09-18 11:10:26.551 
Epoch 91/1000 
	 loss: 5.1198, MinusLogProbMetric: 5.1198, val_loss: 5.2873, val_MinusLogProbMetric: 5.2873

Epoch 91: val_loss did not improve from 5.23893
196/196 - 35s - loss: 5.1198 - MinusLogProbMetric: 5.1198 - val_loss: 5.2873 - val_MinusLogProbMetric: 5.2873 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 92/1000
2023-09-18 11:11:01.405 
Epoch 92/1000 
	 loss: 5.1007, MinusLogProbMetric: 5.1007, val_loss: 5.3272, val_MinusLogProbMetric: 5.3272

Epoch 92: val_loss did not improve from 5.23893
196/196 - 35s - loss: 5.1007 - MinusLogProbMetric: 5.1007 - val_loss: 5.3272 - val_MinusLogProbMetric: 5.3272 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 93/1000
2023-09-18 11:11:36.342 
Epoch 93/1000 
	 loss: 5.1081, MinusLogProbMetric: 5.1081, val_loss: 5.2311, val_MinusLogProbMetric: 5.2311

Epoch 93: val_loss improved from 5.23893 to 5.23112, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 36s - loss: 5.1081 - MinusLogProbMetric: 5.1081 - val_loss: 5.2311 - val_MinusLogProbMetric: 5.2311 - lr: 0.0010 - 36s/epoch - 181ms/step
Epoch 94/1000
2023-09-18 11:12:11.921 
Epoch 94/1000 
	 loss: 5.0979, MinusLogProbMetric: 5.0979, val_loss: 5.3149, val_MinusLogProbMetric: 5.3149

Epoch 94: val_loss did not improve from 5.23112
196/196 - 35s - loss: 5.0979 - MinusLogProbMetric: 5.0979 - val_loss: 5.3149 - val_MinusLogProbMetric: 5.3149 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 95/1000
2023-09-18 11:12:47.217 
Epoch 95/1000 
	 loss: 5.1097, MinusLogProbMetric: 5.1097, val_loss: 5.2913, val_MinusLogProbMetric: 5.2913

Epoch 95: val_loss did not improve from 5.23112
196/196 - 35s - loss: 5.1097 - MinusLogProbMetric: 5.1097 - val_loss: 5.2913 - val_MinusLogProbMetric: 5.2913 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 96/1000
2023-09-18 11:13:22.354 
Epoch 96/1000 
	 loss: 5.1002, MinusLogProbMetric: 5.1002, val_loss: 5.2748, val_MinusLogProbMetric: 5.2748

Epoch 96: val_loss did not improve from 5.23112
196/196 - 35s - loss: 5.1002 - MinusLogProbMetric: 5.1002 - val_loss: 5.2748 - val_MinusLogProbMetric: 5.2748 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 97/1000
2023-09-18 11:13:57.285 
Epoch 97/1000 
	 loss: 5.1008, MinusLogProbMetric: 5.1008, val_loss: 5.3060, val_MinusLogProbMetric: 5.3060

Epoch 97: val_loss did not improve from 5.23112
196/196 - 35s - loss: 5.1008 - MinusLogProbMetric: 5.1008 - val_loss: 5.3060 - val_MinusLogProbMetric: 5.3060 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 98/1000
2023-09-18 11:14:32.358 
Epoch 98/1000 
	 loss: 5.0939, MinusLogProbMetric: 5.0939, val_loss: 5.2553, val_MinusLogProbMetric: 5.2553

Epoch 98: val_loss did not improve from 5.23112
196/196 - 35s - loss: 5.0939 - MinusLogProbMetric: 5.0939 - val_loss: 5.2553 - val_MinusLogProbMetric: 5.2553 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 99/1000
2023-09-18 11:15:07.711 
Epoch 99/1000 
	 loss: 5.1001, MinusLogProbMetric: 5.1001, val_loss: 5.3018, val_MinusLogProbMetric: 5.3018

Epoch 99: val_loss did not improve from 5.23112
196/196 - 35s - loss: 5.1001 - MinusLogProbMetric: 5.1001 - val_loss: 5.3018 - val_MinusLogProbMetric: 5.3018 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 100/1000
2023-09-18 11:15:42.620 
Epoch 100/1000 
	 loss: 5.0965, MinusLogProbMetric: 5.0965, val_loss: 5.2472, val_MinusLogProbMetric: 5.2472

Epoch 100: val_loss did not improve from 5.23112
196/196 - 35s - loss: 5.0965 - MinusLogProbMetric: 5.0965 - val_loss: 5.2472 - val_MinusLogProbMetric: 5.2472 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 101/1000
2023-09-18 11:16:17.706 
Epoch 101/1000 
	 loss: 5.0985, MinusLogProbMetric: 5.0985, val_loss: 5.2586, val_MinusLogProbMetric: 5.2586

Epoch 101: val_loss did not improve from 5.23112
196/196 - 35s - loss: 5.0985 - MinusLogProbMetric: 5.0985 - val_loss: 5.2586 - val_MinusLogProbMetric: 5.2586 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 102/1000
2023-09-18 11:16:52.637 
Epoch 102/1000 
	 loss: 5.0867, MinusLogProbMetric: 5.0867, val_loss: 5.2894, val_MinusLogProbMetric: 5.2894

Epoch 102: val_loss did not improve from 5.23112
196/196 - 35s - loss: 5.0867 - MinusLogProbMetric: 5.0867 - val_loss: 5.2894 - val_MinusLogProbMetric: 5.2894 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 103/1000
2023-09-18 11:17:27.570 
Epoch 103/1000 
	 loss: 5.0971, MinusLogProbMetric: 5.0971, val_loss: 5.2530, val_MinusLogProbMetric: 5.2530

Epoch 103: val_loss did not improve from 5.23112
196/196 - 35s - loss: 5.0971 - MinusLogProbMetric: 5.0971 - val_loss: 5.2530 - val_MinusLogProbMetric: 5.2530 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 104/1000
2023-09-18 11:18:02.582 
Epoch 104/1000 
	 loss: 5.0961, MinusLogProbMetric: 5.0961, val_loss: 5.2467, val_MinusLogProbMetric: 5.2467

Epoch 104: val_loss did not improve from 5.23112
196/196 - 35s - loss: 5.0961 - MinusLogProbMetric: 5.0961 - val_loss: 5.2467 - val_MinusLogProbMetric: 5.2467 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 105/1000
2023-09-18 11:18:37.615 
Epoch 105/1000 
	 loss: 5.0903, MinusLogProbMetric: 5.0903, val_loss: 5.2947, val_MinusLogProbMetric: 5.2947

Epoch 105: val_loss did not improve from 5.23112
196/196 - 35s - loss: 5.0903 - MinusLogProbMetric: 5.0903 - val_loss: 5.2947 - val_MinusLogProbMetric: 5.2947 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 106/1000
2023-09-18 11:19:12.734 
Epoch 106/1000 
	 loss: 5.0837, MinusLogProbMetric: 5.0837, val_loss: 5.2238, val_MinusLogProbMetric: 5.2238

Epoch 106: val_loss improved from 5.23112 to 5.22382, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 36s - loss: 5.0837 - MinusLogProbMetric: 5.0837 - val_loss: 5.2238 - val_MinusLogProbMetric: 5.2238 - lr: 0.0010 - 36s/epoch - 183ms/step
Epoch 107/1000
2023-09-18 11:19:48.401 
Epoch 107/1000 
	 loss: 5.0903, MinusLogProbMetric: 5.0903, val_loss: 5.2616, val_MinusLogProbMetric: 5.2616

Epoch 107: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0903 - MinusLogProbMetric: 5.0903 - val_loss: 5.2616 - val_MinusLogProbMetric: 5.2616 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 108/1000
2023-09-18 11:20:23.875 
Epoch 108/1000 
	 loss: 5.0724, MinusLogProbMetric: 5.0724, val_loss: 5.2584, val_MinusLogProbMetric: 5.2584

Epoch 108: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0724 - MinusLogProbMetric: 5.0724 - val_loss: 5.2584 - val_MinusLogProbMetric: 5.2584 - lr: 0.0010 - 35s/epoch - 181ms/step
Epoch 109/1000
2023-09-18 11:20:58.933 
Epoch 109/1000 
	 loss: 5.0837, MinusLogProbMetric: 5.0837, val_loss: 5.2476, val_MinusLogProbMetric: 5.2476

Epoch 109: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0837 - MinusLogProbMetric: 5.0837 - val_loss: 5.2476 - val_MinusLogProbMetric: 5.2476 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 110/1000
2023-09-18 11:21:33.794 
Epoch 110/1000 
	 loss: 5.0877, MinusLogProbMetric: 5.0877, val_loss: 5.2900, val_MinusLogProbMetric: 5.2900

Epoch 110: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0877 - MinusLogProbMetric: 5.0877 - val_loss: 5.2900 - val_MinusLogProbMetric: 5.2900 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 111/1000
2023-09-18 11:22:09.119 
Epoch 111/1000 
	 loss: 5.0691, MinusLogProbMetric: 5.0691, val_loss: 5.2746, val_MinusLogProbMetric: 5.2746

Epoch 111: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0691 - MinusLogProbMetric: 5.0691 - val_loss: 5.2746 - val_MinusLogProbMetric: 5.2746 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 112/1000
2023-09-18 11:22:44.284 
Epoch 112/1000 
	 loss: 5.0819, MinusLogProbMetric: 5.0819, val_loss: 5.3107, val_MinusLogProbMetric: 5.3107

Epoch 112: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0819 - MinusLogProbMetric: 5.0819 - val_loss: 5.3107 - val_MinusLogProbMetric: 5.3107 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 113/1000
2023-09-18 11:23:19.661 
Epoch 113/1000 
	 loss: 5.0807, MinusLogProbMetric: 5.0807, val_loss: 5.3057, val_MinusLogProbMetric: 5.3057

Epoch 113: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0807 - MinusLogProbMetric: 5.0807 - val_loss: 5.3057 - val_MinusLogProbMetric: 5.3057 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 114/1000
2023-09-18 11:23:54.682 
Epoch 114/1000 
	 loss: 5.0679, MinusLogProbMetric: 5.0679, val_loss: 5.2365, val_MinusLogProbMetric: 5.2365

Epoch 114: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0679 - MinusLogProbMetric: 5.0679 - val_loss: 5.2365 - val_MinusLogProbMetric: 5.2365 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 115/1000
2023-09-18 11:24:29.754 
Epoch 115/1000 
	 loss: 5.0736, MinusLogProbMetric: 5.0736, val_loss: 5.3910, val_MinusLogProbMetric: 5.3910

Epoch 115: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0736 - MinusLogProbMetric: 5.0736 - val_loss: 5.3910 - val_MinusLogProbMetric: 5.3910 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 116/1000
2023-09-18 11:25:04.510 
Epoch 116/1000 
	 loss: 5.0671, MinusLogProbMetric: 5.0671, val_loss: 5.3022, val_MinusLogProbMetric: 5.3022

Epoch 116: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0671 - MinusLogProbMetric: 5.0671 - val_loss: 5.3022 - val_MinusLogProbMetric: 5.3022 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 117/1000
2023-09-18 11:25:40.029 
Epoch 117/1000 
	 loss: 5.0766, MinusLogProbMetric: 5.0766, val_loss: 5.2541, val_MinusLogProbMetric: 5.2541

Epoch 117: val_loss did not improve from 5.22382
196/196 - 36s - loss: 5.0766 - MinusLogProbMetric: 5.0766 - val_loss: 5.2541 - val_MinusLogProbMetric: 5.2541 - lr: 0.0010 - 36s/epoch - 181ms/step
Epoch 118/1000
2023-09-18 11:26:15.123 
Epoch 118/1000 
	 loss: 5.0678, MinusLogProbMetric: 5.0678, val_loss: 5.3067, val_MinusLogProbMetric: 5.3067

Epoch 118: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0678 - MinusLogProbMetric: 5.0678 - val_loss: 5.3067 - val_MinusLogProbMetric: 5.3067 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 119/1000
2023-09-18 11:26:50.277 
Epoch 119/1000 
	 loss: 5.0738, MinusLogProbMetric: 5.0738, val_loss: 5.2501, val_MinusLogProbMetric: 5.2501

Epoch 119: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0738 - MinusLogProbMetric: 5.0738 - val_loss: 5.2501 - val_MinusLogProbMetric: 5.2501 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 120/1000
2023-09-18 11:27:25.270 
Epoch 120/1000 
	 loss: 5.0659, MinusLogProbMetric: 5.0659, val_loss: 5.2990, val_MinusLogProbMetric: 5.2990

Epoch 120: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0659 - MinusLogProbMetric: 5.0659 - val_loss: 5.2990 - val_MinusLogProbMetric: 5.2990 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 121/1000
2023-09-18 11:28:00.261 
Epoch 121/1000 
	 loss: 5.0571, MinusLogProbMetric: 5.0571, val_loss: 5.2377, val_MinusLogProbMetric: 5.2377

Epoch 121: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0571 - MinusLogProbMetric: 5.0571 - val_loss: 5.2377 - val_MinusLogProbMetric: 5.2377 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 122/1000
2023-09-18 11:28:34.961 
Epoch 122/1000 
	 loss: 5.0565, MinusLogProbMetric: 5.0565, val_loss: 5.2596, val_MinusLogProbMetric: 5.2596

Epoch 122: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0565 - MinusLogProbMetric: 5.0565 - val_loss: 5.2596 - val_MinusLogProbMetric: 5.2596 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 123/1000
2023-09-18 11:29:10.037 
Epoch 123/1000 
	 loss: 5.0558, MinusLogProbMetric: 5.0558, val_loss: 5.3347, val_MinusLogProbMetric: 5.3347

Epoch 123: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0558 - MinusLogProbMetric: 5.0558 - val_loss: 5.3347 - val_MinusLogProbMetric: 5.3347 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 124/1000
2023-09-18 11:29:44.754 
Epoch 124/1000 
	 loss: 5.0612, MinusLogProbMetric: 5.0612, val_loss: 5.3611, val_MinusLogProbMetric: 5.3611

Epoch 124: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0612 - MinusLogProbMetric: 5.0612 - val_loss: 5.3611 - val_MinusLogProbMetric: 5.3611 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 125/1000
2023-09-18 11:30:19.512 
Epoch 125/1000 
	 loss: 5.0583, MinusLogProbMetric: 5.0583, val_loss: 5.2777, val_MinusLogProbMetric: 5.2777

Epoch 125: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0583 - MinusLogProbMetric: 5.0583 - val_loss: 5.2777 - val_MinusLogProbMetric: 5.2777 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 126/1000
2023-09-18 11:30:54.691 
Epoch 126/1000 
	 loss: 5.0711, MinusLogProbMetric: 5.0711, val_loss: 5.2653, val_MinusLogProbMetric: 5.2653

Epoch 126: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0711 - MinusLogProbMetric: 5.0711 - val_loss: 5.2653 - val_MinusLogProbMetric: 5.2653 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 127/1000
2023-09-18 11:31:29.654 
Epoch 127/1000 
	 loss: 5.0553, MinusLogProbMetric: 5.0553, val_loss: 5.3347, val_MinusLogProbMetric: 5.3347

Epoch 127: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0553 - MinusLogProbMetric: 5.0553 - val_loss: 5.3347 - val_MinusLogProbMetric: 5.3347 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 128/1000
2023-09-18 11:32:04.527 
Epoch 128/1000 
	 loss: 5.0618, MinusLogProbMetric: 5.0618, val_loss: 5.2935, val_MinusLogProbMetric: 5.2935

Epoch 128: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0618 - MinusLogProbMetric: 5.0618 - val_loss: 5.2935 - val_MinusLogProbMetric: 5.2935 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 129/1000
2023-09-18 11:32:39.415 
Epoch 129/1000 
	 loss: 5.0546, MinusLogProbMetric: 5.0546, val_loss: 5.2908, val_MinusLogProbMetric: 5.2908

Epoch 129: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0546 - MinusLogProbMetric: 5.0546 - val_loss: 5.2908 - val_MinusLogProbMetric: 5.2908 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 130/1000
2023-09-18 11:33:14.752 
Epoch 130/1000 
	 loss: 5.0563, MinusLogProbMetric: 5.0563, val_loss: 5.3678, val_MinusLogProbMetric: 5.3678

Epoch 130: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0563 - MinusLogProbMetric: 5.0563 - val_loss: 5.3678 - val_MinusLogProbMetric: 5.3678 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 131/1000
2023-09-18 11:33:49.868 
Epoch 131/1000 
	 loss: 5.0611, MinusLogProbMetric: 5.0611, val_loss: 5.3106, val_MinusLogProbMetric: 5.3106

Epoch 131: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0611 - MinusLogProbMetric: 5.0611 - val_loss: 5.3106 - val_MinusLogProbMetric: 5.3106 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 132/1000
2023-09-18 11:34:25.035 
Epoch 132/1000 
	 loss: 5.0530, MinusLogProbMetric: 5.0530, val_loss: 5.3203, val_MinusLogProbMetric: 5.3203

Epoch 132: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0530 - MinusLogProbMetric: 5.0530 - val_loss: 5.3203 - val_MinusLogProbMetric: 5.3203 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 133/1000
2023-09-18 11:34:59.946 
Epoch 133/1000 
	 loss: 5.0514, MinusLogProbMetric: 5.0514, val_loss: 5.2746, val_MinusLogProbMetric: 5.2746

Epoch 133: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0514 - MinusLogProbMetric: 5.0514 - val_loss: 5.2746 - val_MinusLogProbMetric: 5.2746 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 134/1000
2023-09-18 11:35:35.057 
Epoch 134/1000 
	 loss: 5.0487, MinusLogProbMetric: 5.0487, val_loss: 5.2525, val_MinusLogProbMetric: 5.2525

Epoch 134: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0487 - MinusLogProbMetric: 5.0487 - val_loss: 5.2525 - val_MinusLogProbMetric: 5.2525 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 135/1000
2023-09-18 11:36:10.054 
Epoch 135/1000 
	 loss: 5.0682, MinusLogProbMetric: 5.0682, val_loss: 5.2711, val_MinusLogProbMetric: 5.2711

Epoch 135: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0682 - MinusLogProbMetric: 5.0682 - val_loss: 5.2711 - val_MinusLogProbMetric: 5.2711 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 136/1000
2023-09-18 11:36:45.055 
Epoch 136/1000 
	 loss: 5.0379, MinusLogProbMetric: 5.0379, val_loss: 5.2955, val_MinusLogProbMetric: 5.2955

Epoch 136: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0379 - MinusLogProbMetric: 5.0379 - val_loss: 5.2955 - val_MinusLogProbMetric: 5.2955 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 137/1000
2023-09-18 11:37:20.141 
Epoch 137/1000 
	 loss: 5.0586, MinusLogProbMetric: 5.0586, val_loss: 5.2363, val_MinusLogProbMetric: 5.2363

Epoch 137: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0586 - MinusLogProbMetric: 5.0586 - val_loss: 5.2363 - val_MinusLogProbMetric: 5.2363 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 138/1000
2023-09-18 11:37:55.371 
Epoch 138/1000 
	 loss: 5.0372, MinusLogProbMetric: 5.0372, val_loss: 5.2491, val_MinusLogProbMetric: 5.2491

Epoch 138: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0372 - MinusLogProbMetric: 5.0372 - val_loss: 5.2491 - val_MinusLogProbMetric: 5.2491 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 139/1000
2023-09-18 11:38:30.454 
Epoch 139/1000 
	 loss: 5.0449, MinusLogProbMetric: 5.0449, val_loss: 5.2668, val_MinusLogProbMetric: 5.2668

Epoch 139: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0449 - MinusLogProbMetric: 5.0449 - val_loss: 5.2668 - val_MinusLogProbMetric: 5.2668 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 140/1000
2023-09-18 11:39:05.680 
Epoch 140/1000 
	 loss: 5.0366, MinusLogProbMetric: 5.0366, val_loss: 5.2402, val_MinusLogProbMetric: 5.2402

Epoch 140: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0366 - MinusLogProbMetric: 5.0366 - val_loss: 5.2402 - val_MinusLogProbMetric: 5.2402 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 141/1000
2023-09-18 11:39:40.570 
Epoch 141/1000 
	 loss: 5.0391, MinusLogProbMetric: 5.0391, val_loss: 5.2917, val_MinusLogProbMetric: 5.2917

Epoch 141: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0391 - MinusLogProbMetric: 5.0391 - val_loss: 5.2917 - val_MinusLogProbMetric: 5.2917 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 142/1000
2023-09-18 11:40:15.666 
Epoch 142/1000 
	 loss: 5.0335, MinusLogProbMetric: 5.0335, val_loss: 5.2342, val_MinusLogProbMetric: 5.2342

Epoch 142: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0335 - MinusLogProbMetric: 5.0335 - val_loss: 5.2342 - val_MinusLogProbMetric: 5.2342 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 143/1000
2023-09-18 11:40:50.939 
Epoch 143/1000 
	 loss: 5.0301, MinusLogProbMetric: 5.0301, val_loss: 5.2581, val_MinusLogProbMetric: 5.2581

Epoch 143: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0301 - MinusLogProbMetric: 5.0301 - val_loss: 5.2581 - val_MinusLogProbMetric: 5.2581 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 144/1000
2023-09-18 11:41:26.020 
Epoch 144/1000 
	 loss: 5.0329, MinusLogProbMetric: 5.0329, val_loss: 5.3107, val_MinusLogProbMetric: 5.3107

Epoch 144: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0329 - MinusLogProbMetric: 5.0329 - val_loss: 5.3107 - val_MinusLogProbMetric: 5.3107 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 145/1000
2023-09-18 11:42:00.903 
Epoch 145/1000 
	 loss: 5.0421, MinusLogProbMetric: 5.0421, val_loss: 5.2530, val_MinusLogProbMetric: 5.2530

Epoch 145: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0421 - MinusLogProbMetric: 5.0421 - val_loss: 5.2530 - val_MinusLogProbMetric: 5.2530 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 146/1000
2023-09-18 11:42:35.886 
Epoch 146/1000 
	 loss: 5.0378, MinusLogProbMetric: 5.0378, val_loss: 5.2670, val_MinusLogProbMetric: 5.2670

Epoch 146: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0378 - MinusLogProbMetric: 5.0378 - val_loss: 5.2670 - val_MinusLogProbMetric: 5.2670 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 147/1000
2023-09-18 11:43:10.717 
Epoch 147/1000 
	 loss: 5.0295, MinusLogProbMetric: 5.0295, val_loss: 5.3131, val_MinusLogProbMetric: 5.3131

Epoch 147: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0295 - MinusLogProbMetric: 5.0295 - val_loss: 5.3131 - val_MinusLogProbMetric: 5.3131 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 148/1000
2023-09-18 11:43:45.681 
Epoch 148/1000 
	 loss: 5.0242, MinusLogProbMetric: 5.0242, val_loss: 5.3054, val_MinusLogProbMetric: 5.3054

Epoch 148: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0242 - MinusLogProbMetric: 5.0242 - val_loss: 5.3054 - val_MinusLogProbMetric: 5.3054 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 149/1000
2023-09-18 11:44:20.677 
Epoch 149/1000 
	 loss: 5.0287, MinusLogProbMetric: 5.0287, val_loss: 5.3492, val_MinusLogProbMetric: 5.3492

Epoch 149: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0287 - MinusLogProbMetric: 5.0287 - val_loss: 5.3492 - val_MinusLogProbMetric: 5.3492 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 150/1000
2023-09-18 11:44:55.784 
Epoch 150/1000 
	 loss: 5.0371, MinusLogProbMetric: 5.0371, val_loss: 5.2845, val_MinusLogProbMetric: 5.2845

Epoch 150: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0371 - MinusLogProbMetric: 5.0371 - val_loss: 5.2845 - val_MinusLogProbMetric: 5.2845 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 151/1000
2023-09-18 11:45:30.760 
Epoch 151/1000 
	 loss: 5.0343, MinusLogProbMetric: 5.0343, val_loss: 5.2473, val_MinusLogProbMetric: 5.2473

Epoch 151: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0343 - MinusLogProbMetric: 5.0343 - val_loss: 5.2473 - val_MinusLogProbMetric: 5.2473 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 152/1000
2023-09-18 11:46:05.777 
Epoch 152/1000 
	 loss: 5.0304, MinusLogProbMetric: 5.0304, val_loss: 5.2776, val_MinusLogProbMetric: 5.2776

Epoch 152: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0304 - MinusLogProbMetric: 5.0304 - val_loss: 5.2776 - val_MinusLogProbMetric: 5.2776 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 153/1000
2023-09-18 11:46:40.795 
Epoch 153/1000 
	 loss: 5.0348, MinusLogProbMetric: 5.0348, val_loss: 5.3187, val_MinusLogProbMetric: 5.3187

Epoch 153: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0348 - MinusLogProbMetric: 5.0348 - val_loss: 5.3187 - val_MinusLogProbMetric: 5.3187 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 154/1000
2023-09-18 11:47:15.866 
Epoch 154/1000 
	 loss: 5.0327, MinusLogProbMetric: 5.0327, val_loss: 5.2732, val_MinusLogProbMetric: 5.2732

Epoch 154: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0327 - MinusLogProbMetric: 5.0327 - val_loss: 5.2732 - val_MinusLogProbMetric: 5.2732 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 155/1000
2023-09-18 11:47:50.898 
Epoch 155/1000 
	 loss: 5.0254, MinusLogProbMetric: 5.0254, val_loss: 5.2548, val_MinusLogProbMetric: 5.2548

Epoch 155: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0254 - MinusLogProbMetric: 5.0254 - val_loss: 5.2548 - val_MinusLogProbMetric: 5.2548 - lr: 0.0010 - 35s/epoch - 179ms/step
Epoch 156/1000
2023-09-18 11:48:26.111 
Epoch 156/1000 
	 loss: 5.0232, MinusLogProbMetric: 5.0232, val_loss: 5.3142, val_MinusLogProbMetric: 5.3142

Epoch 156: val_loss did not improve from 5.22382
196/196 - 35s - loss: 5.0232 - MinusLogProbMetric: 5.0232 - val_loss: 5.3142 - val_MinusLogProbMetric: 5.3142 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 157/1000
2023-09-18 11:49:01.510 
Epoch 157/1000 
	 loss: 4.9640, MinusLogProbMetric: 4.9640, val_loss: 5.2119, val_MinusLogProbMetric: 5.2119

Epoch 157: val_loss improved from 5.22382 to 5.21193, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_185/weights/best_weights.h5
196/196 - 36s - loss: 4.9640 - MinusLogProbMetric: 4.9640 - val_loss: 5.2119 - val_MinusLogProbMetric: 5.2119 - lr: 5.0000e-04 - 36s/epoch - 184ms/step
Epoch 158/1000
2023-09-18 11:49:37.358 
Epoch 158/1000 
	 loss: 4.9650, MinusLogProbMetric: 4.9650, val_loss: 5.2392, val_MinusLogProbMetric: 5.2392

Epoch 158: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9650 - MinusLogProbMetric: 4.9650 - val_loss: 5.2392 - val_MinusLogProbMetric: 5.2392 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 159/1000
2023-09-18 11:50:12.693 
Epoch 159/1000 
	 loss: 4.9588, MinusLogProbMetric: 4.9588, val_loss: 5.2458, val_MinusLogProbMetric: 5.2458

Epoch 159: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9588 - MinusLogProbMetric: 4.9588 - val_loss: 5.2458 - val_MinusLogProbMetric: 5.2458 - lr: 5.0000e-04 - 35s/epoch - 180ms/step
Epoch 160/1000
2023-09-18 11:50:47.884 
Epoch 160/1000 
	 loss: 4.9615, MinusLogProbMetric: 4.9615, val_loss: 5.2474, val_MinusLogProbMetric: 5.2474

Epoch 160: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9615 - MinusLogProbMetric: 4.9615 - val_loss: 5.2474 - val_MinusLogProbMetric: 5.2474 - lr: 5.0000e-04 - 35s/epoch - 180ms/step
Epoch 161/1000
2023-09-18 11:51:23.274 
Epoch 161/1000 
	 loss: 4.9589, MinusLogProbMetric: 4.9589, val_loss: 5.2357, val_MinusLogProbMetric: 5.2357

Epoch 161: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9589 - MinusLogProbMetric: 4.9589 - val_loss: 5.2357 - val_MinusLogProbMetric: 5.2357 - lr: 5.0000e-04 - 35s/epoch - 181ms/step
Epoch 162/1000
2023-09-18 11:51:58.321 
Epoch 162/1000 
	 loss: 4.9548, MinusLogProbMetric: 4.9548, val_loss: 5.2300, val_MinusLogProbMetric: 5.2300

Epoch 162: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9548 - MinusLogProbMetric: 4.9548 - val_loss: 5.2300 - val_MinusLogProbMetric: 5.2300 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 163/1000
2023-09-18 11:52:33.212 
Epoch 163/1000 
	 loss: 4.9554, MinusLogProbMetric: 4.9554, val_loss: 5.2356, val_MinusLogProbMetric: 5.2356

Epoch 163: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9554 - MinusLogProbMetric: 4.9554 - val_loss: 5.2356 - val_MinusLogProbMetric: 5.2356 - lr: 5.0000e-04 - 35s/epoch - 178ms/step
Epoch 164/1000
2023-09-18 11:53:08.256 
Epoch 164/1000 
	 loss: 4.9585, MinusLogProbMetric: 4.9585, val_loss: 5.2232, val_MinusLogProbMetric: 5.2232

Epoch 164: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9585 - MinusLogProbMetric: 4.9585 - val_loss: 5.2232 - val_MinusLogProbMetric: 5.2232 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 165/1000
2023-09-18 11:53:43.398 
Epoch 165/1000 
	 loss: 4.9555, MinusLogProbMetric: 4.9555, val_loss: 5.2522, val_MinusLogProbMetric: 5.2522

Epoch 165: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9555 - MinusLogProbMetric: 4.9555 - val_loss: 5.2522 - val_MinusLogProbMetric: 5.2522 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 166/1000
2023-09-18 11:54:18.427 
Epoch 166/1000 
	 loss: 4.9568, MinusLogProbMetric: 4.9568, val_loss: 5.2445, val_MinusLogProbMetric: 5.2445

Epoch 166: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9568 - MinusLogProbMetric: 4.9568 - val_loss: 5.2445 - val_MinusLogProbMetric: 5.2445 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 167/1000
2023-09-18 11:54:53.557 
Epoch 167/1000 
	 loss: 4.9520, MinusLogProbMetric: 4.9520, val_loss: 5.2411, val_MinusLogProbMetric: 5.2411

Epoch 167: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9520 - MinusLogProbMetric: 4.9520 - val_loss: 5.2411 - val_MinusLogProbMetric: 5.2411 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 168/1000
2023-09-18 11:55:28.557 
Epoch 168/1000 
	 loss: 4.9558, MinusLogProbMetric: 4.9558, val_loss: 5.2353, val_MinusLogProbMetric: 5.2353

Epoch 168: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9558 - MinusLogProbMetric: 4.9558 - val_loss: 5.2353 - val_MinusLogProbMetric: 5.2353 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 169/1000
2023-09-18 11:56:03.611 
Epoch 169/1000 
	 loss: 4.9528, MinusLogProbMetric: 4.9528, val_loss: 5.2395, val_MinusLogProbMetric: 5.2395

Epoch 169: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9528 - MinusLogProbMetric: 4.9528 - val_loss: 5.2395 - val_MinusLogProbMetric: 5.2395 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 170/1000
2023-09-18 11:56:38.626 
Epoch 170/1000 
	 loss: 4.9514, MinusLogProbMetric: 4.9514, val_loss: 5.2571, val_MinusLogProbMetric: 5.2571

Epoch 170: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9514 - MinusLogProbMetric: 4.9514 - val_loss: 5.2571 - val_MinusLogProbMetric: 5.2571 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 171/1000
2023-09-18 11:57:13.905 
Epoch 171/1000 
	 loss: 4.9555, MinusLogProbMetric: 4.9555, val_loss: 5.2517, val_MinusLogProbMetric: 5.2517

Epoch 171: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9555 - MinusLogProbMetric: 4.9555 - val_loss: 5.2517 - val_MinusLogProbMetric: 5.2517 - lr: 5.0000e-04 - 35s/epoch - 180ms/step
Epoch 172/1000
2023-09-18 11:57:49.101 
Epoch 172/1000 
	 loss: 4.9578, MinusLogProbMetric: 4.9578, val_loss: 5.2376, val_MinusLogProbMetric: 5.2376

Epoch 172: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9578 - MinusLogProbMetric: 4.9578 - val_loss: 5.2376 - val_MinusLogProbMetric: 5.2376 - lr: 5.0000e-04 - 35s/epoch - 180ms/step
Epoch 173/1000
2023-09-18 11:58:24.164 
Epoch 173/1000 
	 loss: 4.9529, MinusLogProbMetric: 4.9529, val_loss: 5.2607, val_MinusLogProbMetric: 5.2607

Epoch 173: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9529 - MinusLogProbMetric: 4.9529 - val_loss: 5.2607 - val_MinusLogProbMetric: 5.2607 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 174/1000
2023-09-18 11:58:59.322 
Epoch 174/1000 
	 loss: 4.9502, MinusLogProbMetric: 4.9502, val_loss: 5.2483, val_MinusLogProbMetric: 5.2483

Epoch 174: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9502 - MinusLogProbMetric: 4.9502 - val_loss: 5.2483 - val_MinusLogProbMetric: 5.2483 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 175/1000
2023-09-18 11:59:34.346 
Epoch 175/1000 
	 loss: 4.9523, MinusLogProbMetric: 4.9523, val_loss: 5.2542, val_MinusLogProbMetric: 5.2542

Epoch 175: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9523 - MinusLogProbMetric: 4.9523 - val_loss: 5.2542 - val_MinusLogProbMetric: 5.2542 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 176/1000
2023-09-18 12:00:09.243 
Epoch 176/1000 
	 loss: 4.9529, MinusLogProbMetric: 4.9529, val_loss: 5.2467, val_MinusLogProbMetric: 5.2467

Epoch 176: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9529 - MinusLogProbMetric: 4.9529 - val_loss: 5.2467 - val_MinusLogProbMetric: 5.2467 - lr: 5.0000e-04 - 35s/epoch - 178ms/step
Epoch 177/1000
2023-09-18 12:00:43.842 
Epoch 177/1000 
	 loss: 4.9531, MinusLogProbMetric: 4.9531, val_loss: 5.2650, val_MinusLogProbMetric: 5.2650

Epoch 177: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9531 - MinusLogProbMetric: 4.9531 - val_loss: 5.2650 - val_MinusLogProbMetric: 5.2650 - lr: 5.0000e-04 - 35s/epoch - 177ms/step
Epoch 178/1000
2023-09-18 12:01:18.851 
Epoch 178/1000 
	 loss: 4.9535, MinusLogProbMetric: 4.9535, val_loss: 5.2553, val_MinusLogProbMetric: 5.2553

Epoch 178: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9535 - MinusLogProbMetric: 4.9535 - val_loss: 5.2553 - val_MinusLogProbMetric: 5.2553 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 179/1000
2023-09-18 12:01:54.059 
Epoch 179/1000 
	 loss: 4.9453, MinusLogProbMetric: 4.9453, val_loss: 5.2417, val_MinusLogProbMetric: 5.2417

Epoch 179: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9453 - MinusLogProbMetric: 4.9453 - val_loss: 5.2417 - val_MinusLogProbMetric: 5.2417 - lr: 5.0000e-04 - 35s/epoch - 180ms/step
Epoch 180/1000
2023-09-18 12:02:29.025 
Epoch 180/1000 
	 loss: 4.9483, MinusLogProbMetric: 4.9483, val_loss: 5.2554, val_MinusLogProbMetric: 5.2554

Epoch 180: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9483 - MinusLogProbMetric: 4.9483 - val_loss: 5.2554 - val_MinusLogProbMetric: 5.2554 - lr: 5.0000e-04 - 35s/epoch - 178ms/step
Epoch 181/1000
2023-09-18 12:03:04.244 
Epoch 181/1000 
	 loss: 4.9490, MinusLogProbMetric: 4.9490, val_loss: 5.2374, val_MinusLogProbMetric: 5.2374

Epoch 181: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9490 - MinusLogProbMetric: 4.9490 - val_loss: 5.2374 - val_MinusLogProbMetric: 5.2374 - lr: 5.0000e-04 - 35s/epoch - 180ms/step
Epoch 182/1000
2023-09-18 12:03:39.083 
Epoch 182/1000 
	 loss: 4.9504, MinusLogProbMetric: 4.9504, val_loss: 5.2444, val_MinusLogProbMetric: 5.2444

Epoch 182: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9504 - MinusLogProbMetric: 4.9504 - val_loss: 5.2444 - val_MinusLogProbMetric: 5.2444 - lr: 5.0000e-04 - 35s/epoch - 178ms/step
Epoch 183/1000
2023-09-18 12:04:14.218 
Epoch 183/1000 
	 loss: 4.9489, MinusLogProbMetric: 4.9489, val_loss: 5.2358, val_MinusLogProbMetric: 5.2358

Epoch 183: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9489 - MinusLogProbMetric: 4.9489 - val_loss: 5.2358 - val_MinusLogProbMetric: 5.2358 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 184/1000
2023-09-18 12:04:49.205 
Epoch 184/1000 
	 loss: 4.9478, MinusLogProbMetric: 4.9478, val_loss: 5.2574, val_MinusLogProbMetric: 5.2574

Epoch 184: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9478 - MinusLogProbMetric: 4.9478 - val_loss: 5.2574 - val_MinusLogProbMetric: 5.2574 - lr: 5.0000e-04 - 35s/epoch - 178ms/step
Epoch 185/1000
2023-09-18 12:05:24.287 
Epoch 185/1000 
	 loss: 4.9445, MinusLogProbMetric: 4.9445, val_loss: 5.2473, val_MinusLogProbMetric: 5.2473

Epoch 185: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9445 - MinusLogProbMetric: 4.9445 - val_loss: 5.2473 - val_MinusLogProbMetric: 5.2473 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 186/1000
2023-09-18 12:05:59.455 
Epoch 186/1000 
	 loss: 4.9416, MinusLogProbMetric: 4.9416, val_loss: 5.2490, val_MinusLogProbMetric: 5.2490

Epoch 186: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9416 - MinusLogProbMetric: 4.9416 - val_loss: 5.2490 - val_MinusLogProbMetric: 5.2490 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 187/1000
2023-09-18 12:06:34.343 
Epoch 187/1000 
	 loss: 4.9464, MinusLogProbMetric: 4.9464, val_loss: 5.2635, val_MinusLogProbMetric: 5.2635

Epoch 187: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9464 - MinusLogProbMetric: 4.9464 - val_loss: 5.2635 - val_MinusLogProbMetric: 5.2635 - lr: 5.0000e-04 - 35s/epoch - 178ms/step
Epoch 188/1000
2023-09-18 12:07:09.430 
Epoch 188/1000 
	 loss: 4.9455, MinusLogProbMetric: 4.9455, val_loss: 5.2508, val_MinusLogProbMetric: 5.2508

Epoch 188: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9455 - MinusLogProbMetric: 4.9455 - val_loss: 5.2508 - val_MinusLogProbMetric: 5.2508 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 189/1000
2023-09-18 12:07:44.248 
Epoch 189/1000 
	 loss: 4.9466, MinusLogProbMetric: 4.9466, val_loss: 5.2742, val_MinusLogProbMetric: 5.2742

Epoch 189: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9466 - MinusLogProbMetric: 4.9466 - val_loss: 5.2742 - val_MinusLogProbMetric: 5.2742 - lr: 5.0000e-04 - 35s/epoch - 178ms/step
Epoch 190/1000
2023-09-18 12:08:19.207 
Epoch 190/1000 
	 loss: 4.9402, MinusLogProbMetric: 4.9402, val_loss: 5.2570, val_MinusLogProbMetric: 5.2570

Epoch 190: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9402 - MinusLogProbMetric: 4.9402 - val_loss: 5.2570 - val_MinusLogProbMetric: 5.2570 - lr: 5.0000e-04 - 35s/epoch - 178ms/step
Epoch 191/1000
2023-09-18 12:08:54.404 
Epoch 191/1000 
	 loss: 4.9395, MinusLogProbMetric: 4.9395, val_loss: 5.2485, val_MinusLogProbMetric: 5.2485

Epoch 191: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9395 - MinusLogProbMetric: 4.9395 - val_loss: 5.2485 - val_MinusLogProbMetric: 5.2485 - lr: 5.0000e-04 - 35s/epoch - 180ms/step
Epoch 192/1000
2023-09-18 12:09:29.548 
Epoch 192/1000 
	 loss: 4.9426, MinusLogProbMetric: 4.9426, val_loss: 5.2643, val_MinusLogProbMetric: 5.2643

Epoch 192: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9426 - MinusLogProbMetric: 4.9426 - val_loss: 5.2643 - val_MinusLogProbMetric: 5.2643 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 193/1000
2023-09-18 12:10:04.828 
Epoch 193/1000 
	 loss: 4.9415, MinusLogProbMetric: 4.9415, val_loss: 5.2454, val_MinusLogProbMetric: 5.2454

Epoch 193: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9415 - MinusLogProbMetric: 4.9415 - val_loss: 5.2454 - val_MinusLogProbMetric: 5.2454 - lr: 5.0000e-04 - 35s/epoch - 180ms/step
Epoch 194/1000
2023-09-18 12:10:40.407 
Epoch 194/1000 
	 loss: 4.9407, MinusLogProbMetric: 4.9407, val_loss: 5.2430, val_MinusLogProbMetric: 5.2430

Epoch 194: val_loss did not improve from 5.21193
196/196 - 36s - loss: 4.9407 - MinusLogProbMetric: 4.9407 - val_loss: 5.2430 - val_MinusLogProbMetric: 5.2430 - lr: 5.0000e-04 - 36s/epoch - 181ms/step
Epoch 195/1000
2023-09-18 12:11:15.345 
Epoch 195/1000 
	 loss: 4.9394, MinusLogProbMetric: 4.9394, val_loss: 5.2464, val_MinusLogProbMetric: 5.2464

Epoch 195: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9394 - MinusLogProbMetric: 4.9394 - val_loss: 5.2464 - val_MinusLogProbMetric: 5.2464 - lr: 5.0000e-04 - 35s/epoch - 178ms/step
Epoch 196/1000
2023-09-18 12:11:50.094 
Epoch 196/1000 
	 loss: 4.9406, MinusLogProbMetric: 4.9406, val_loss: 5.2475, val_MinusLogProbMetric: 5.2475

Epoch 196: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9406 - MinusLogProbMetric: 4.9406 - val_loss: 5.2475 - val_MinusLogProbMetric: 5.2475 - lr: 5.0000e-04 - 35s/epoch - 177ms/step
Epoch 197/1000
2023-09-18 12:12:25.176 
Epoch 197/1000 
	 loss: 4.9392, MinusLogProbMetric: 4.9392, val_loss: 5.2655, val_MinusLogProbMetric: 5.2655

Epoch 197: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9392 - MinusLogProbMetric: 4.9392 - val_loss: 5.2655 - val_MinusLogProbMetric: 5.2655 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 198/1000
2023-09-18 12:12:59.822 
Epoch 198/1000 
	 loss: 4.9400, MinusLogProbMetric: 4.9400, val_loss: 5.2499, val_MinusLogProbMetric: 5.2499

Epoch 198: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9400 - MinusLogProbMetric: 4.9400 - val_loss: 5.2499 - val_MinusLogProbMetric: 5.2499 - lr: 5.0000e-04 - 35s/epoch - 177ms/step
Epoch 199/1000
2023-09-18 12:13:34.847 
Epoch 199/1000 
	 loss: 4.9374, MinusLogProbMetric: 4.9374, val_loss: 5.2722, val_MinusLogProbMetric: 5.2722

Epoch 199: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9374 - MinusLogProbMetric: 4.9374 - val_loss: 5.2722 - val_MinusLogProbMetric: 5.2722 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 200/1000
2023-09-18 12:14:09.638 
Epoch 200/1000 
	 loss: 4.9410, MinusLogProbMetric: 4.9410, val_loss: 5.2472, val_MinusLogProbMetric: 5.2472

Epoch 200: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9410 - MinusLogProbMetric: 4.9410 - val_loss: 5.2472 - val_MinusLogProbMetric: 5.2472 - lr: 5.0000e-04 - 35s/epoch - 177ms/step
Epoch 201/1000
2023-09-18 12:14:44.865 
Epoch 201/1000 
	 loss: 4.9395, MinusLogProbMetric: 4.9395, val_loss: 5.2571, val_MinusLogProbMetric: 5.2571

Epoch 201: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9395 - MinusLogProbMetric: 4.9395 - val_loss: 5.2571 - val_MinusLogProbMetric: 5.2571 - lr: 5.0000e-04 - 35s/epoch - 180ms/step
Epoch 202/1000
2023-09-18 12:15:20.280 
Epoch 202/1000 
	 loss: 4.9325, MinusLogProbMetric: 4.9325, val_loss: 5.2456, val_MinusLogProbMetric: 5.2456

Epoch 202: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9325 - MinusLogProbMetric: 4.9325 - val_loss: 5.2456 - val_MinusLogProbMetric: 5.2456 - lr: 5.0000e-04 - 35s/epoch - 181ms/step
Epoch 203/1000
2023-09-18 12:15:55.062 
Epoch 203/1000 
	 loss: 4.9358, MinusLogProbMetric: 4.9358, val_loss: 5.2810, val_MinusLogProbMetric: 5.2810

Epoch 203: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9358 - MinusLogProbMetric: 4.9358 - val_loss: 5.2810 - val_MinusLogProbMetric: 5.2810 - lr: 5.0000e-04 - 35s/epoch - 177ms/step
Epoch 204/1000
2023-09-18 12:16:30.300 
Epoch 204/1000 
	 loss: 4.9313, MinusLogProbMetric: 4.9313, val_loss: 5.2581, val_MinusLogProbMetric: 5.2581

Epoch 204: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9313 - MinusLogProbMetric: 4.9313 - val_loss: 5.2581 - val_MinusLogProbMetric: 5.2581 - lr: 5.0000e-04 - 35s/epoch - 180ms/step
Epoch 205/1000
2023-09-18 12:17:05.341 
Epoch 205/1000 
	 loss: 4.9340, MinusLogProbMetric: 4.9340, val_loss: 5.2584, val_MinusLogProbMetric: 5.2584

Epoch 205: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9340 - MinusLogProbMetric: 4.9340 - val_loss: 5.2584 - val_MinusLogProbMetric: 5.2584 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 206/1000
2023-09-18 12:17:40.350 
Epoch 206/1000 
	 loss: 4.9307, MinusLogProbMetric: 4.9307, val_loss: 5.2390, val_MinusLogProbMetric: 5.2390

Epoch 206: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9307 - MinusLogProbMetric: 4.9307 - val_loss: 5.2390 - val_MinusLogProbMetric: 5.2390 - lr: 5.0000e-04 - 35s/epoch - 179ms/step
Epoch 207/1000
2023-09-18 12:18:14.950 
Epoch 207/1000 
	 loss: 4.9310, MinusLogProbMetric: 4.9310, val_loss: 5.2842, val_MinusLogProbMetric: 5.2842

Epoch 207: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9310 - MinusLogProbMetric: 4.9310 - val_loss: 5.2842 - val_MinusLogProbMetric: 5.2842 - lr: 5.0000e-04 - 35s/epoch - 177ms/step
Epoch 208/1000
2023-09-18 12:18:50.272 
Epoch 208/1000 
	 loss: 4.9044, MinusLogProbMetric: 4.9044, val_loss: 5.2438, val_MinusLogProbMetric: 5.2438

Epoch 208: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9044 - MinusLogProbMetric: 4.9044 - val_loss: 5.2438 - val_MinusLogProbMetric: 5.2438 - lr: 2.5000e-04 - 35s/epoch - 180ms/step
Epoch 209/1000
2023-09-18 12:19:25.117 
Epoch 209/1000 
	 loss: 4.9011, MinusLogProbMetric: 4.9011, val_loss: 5.2528, val_MinusLogProbMetric: 5.2528

Epoch 209: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9011 - MinusLogProbMetric: 4.9011 - val_loss: 5.2528 - val_MinusLogProbMetric: 5.2528 - lr: 2.5000e-04 - 35s/epoch - 178ms/step
Epoch 210/1000
2023-09-18 12:19:59.908 
Epoch 210/1000 
	 loss: 4.9018, MinusLogProbMetric: 4.9018, val_loss: 5.2435, val_MinusLogProbMetric: 5.2435

Epoch 210: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9018 - MinusLogProbMetric: 4.9018 - val_loss: 5.2435 - val_MinusLogProbMetric: 5.2435 - lr: 2.5000e-04 - 35s/epoch - 177ms/step
Epoch 211/1000
2023-09-18 12:20:35.181 
Epoch 211/1000 
	 loss: 4.9001, MinusLogProbMetric: 4.9001, val_loss: 5.2431, val_MinusLogProbMetric: 5.2431

Epoch 211: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9001 - MinusLogProbMetric: 4.9001 - val_loss: 5.2431 - val_MinusLogProbMetric: 5.2431 - lr: 2.5000e-04 - 35s/epoch - 180ms/step
Epoch 212/1000
2023-09-18 12:21:10.064 
Epoch 212/1000 
	 loss: 4.9004, MinusLogProbMetric: 4.9004, val_loss: 5.2523, val_MinusLogProbMetric: 5.2523

Epoch 212: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9004 - MinusLogProbMetric: 4.9004 - val_loss: 5.2523 - val_MinusLogProbMetric: 5.2523 - lr: 2.5000e-04 - 35s/epoch - 178ms/step
Epoch 213/1000
2023-09-18 12:21:45.113 
Epoch 213/1000 
	 loss: 4.9014, MinusLogProbMetric: 4.9014, val_loss: 5.2520, val_MinusLogProbMetric: 5.2520

Epoch 213: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.9014 - MinusLogProbMetric: 4.9014 - val_loss: 5.2520 - val_MinusLogProbMetric: 5.2520 - lr: 2.5000e-04 - 35s/epoch - 179ms/step
Epoch 214/1000
2023-09-18 12:22:17.508 
Epoch 214/1000 
	 loss: 4.9007, MinusLogProbMetric: 4.9007, val_loss: 5.2498, val_MinusLogProbMetric: 5.2498

Epoch 214: val_loss did not improve from 5.21193
196/196 - 32s - loss: 4.9007 - MinusLogProbMetric: 4.9007 - val_loss: 5.2498 - val_MinusLogProbMetric: 5.2498 - lr: 2.5000e-04 - 32s/epoch - 165ms/step
Epoch 215/1000
2023-09-18 12:22:48.977 
Epoch 215/1000 
	 loss: 4.9011, MinusLogProbMetric: 4.9011, val_loss: 5.2525, val_MinusLogProbMetric: 5.2525

Epoch 215: val_loss did not improve from 5.21193
196/196 - 31s - loss: 4.9011 - MinusLogProbMetric: 4.9011 - val_loss: 5.2525 - val_MinusLogProbMetric: 5.2525 - lr: 2.5000e-04 - 31s/epoch - 161ms/step
Epoch 216/1000
2023-09-18 12:23:18.727 
Epoch 216/1000 
	 loss: 4.8971, MinusLogProbMetric: 4.8971, val_loss: 5.2454, val_MinusLogProbMetric: 5.2454

Epoch 216: val_loss did not improve from 5.21193
196/196 - 30s - loss: 4.8971 - MinusLogProbMetric: 4.8971 - val_loss: 5.2454 - val_MinusLogProbMetric: 5.2454 - lr: 2.5000e-04 - 30s/epoch - 152ms/step
Epoch 217/1000
2023-09-18 12:23:53.561 
Epoch 217/1000 
	 loss: 4.8975, MinusLogProbMetric: 4.8975, val_loss: 5.2551, val_MinusLogProbMetric: 5.2551

Epoch 217: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8975 - MinusLogProbMetric: 4.8975 - val_loss: 5.2551 - val_MinusLogProbMetric: 5.2551 - lr: 2.5000e-04 - 35s/epoch - 178ms/step
Epoch 218/1000
2023-09-18 12:24:28.687 
Epoch 218/1000 
	 loss: 4.8984, MinusLogProbMetric: 4.8984, val_loss: 5.2551, val_MinusLogProbMetric: 5.2551

Epoch 218: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8984 - MinusLogProbMetric: 4.8984 - val_loss: 5.2551 - val_MinusLogProbMetric: 5.2551 - lr: 2.5000e-04 - 35s/epoch - 179ms/step
Epoch 219/1000
2023-09-18 12:25:00.936 
Epoch 219/1000 
	 loss: 4.8981, MinusLogProbMetric: 4.8981, val_loss: 5.2467, val_MinusLogProbMetric: 5.2467

Epoch 219: val_loss did not improve from 5.21193
196/196 - 32s - loss: 4.8981 - MinusLogProbMetric: 4.8981 - val_loss: 5.2467 - val_MinusLogProbMetric: 5.2467 - lr: 2.5000e-04 - 32s/epoch - 165ms/step
Epoch 220/1000
2023-09-18 12:25:33.460 
Epoch 220/1000 
	 loss: 4.8987, MinusLogProbMetric: 4.8987, val_loss: 5.2533, val_MinusLogProbMetric: 5.2533

Epoch 220: val_loss did not improve from 5.21193
196/196 - 32s - loss: 4.8987 - MinusLogProbMetric: 4.8987 - val_loss: 5.2533 - val_MinusLogProbMetric: 5.2533 - lr: 2.5000e-04 - 32s/epoch - 166ms/step
Epoch 221/1000
2023-09-18 12:26:06.042 
Epoch 221/1000 
	 loss: 4.8965, MinusLogProbMetric: 4.8965, val_loss: 5.2511, val_MinusLogProbMetric: 5.2511

Epoch 221: val_loss did not improve from 5.21193
196/196 - 33s - loss: 4.8965 - MinusLogProbMetric: 4.8965 - val_loss: 5.2511 - val_MinusLogProbMetric: 5.2511 - lr: 2.5000e-04 - 33s/epoch - 166ms/step
Epoch 222/1000
2023-09-18 12:26:36.589 
Epoch 222/1000 
	 loss: 4.8971, MinusLogProbMetric: 4.8971, val_loss: 5.2506, val_MinusLogProbMetric: 5.2506

Epoch 222: val_loss did not improve from 5.21193
196/196 - 31s - loss: 4.8971 - MinusLogProbMetric: 4.8971 - val_loss: 5.2506 - val_MinusLogProbMetric: 5.2506 - lr: 2.5000e-04 - 31s/epoch - 156ms/step
Epoch 223/1000
2023-09-18 12:27:11.716 
Epoch 223/1000 
	 loss: 4.8983, MinusLogProbMetric: 4.8983, val_loss: 5.2554, val_MinusLogProbMetric: 5.2554

Epoch 223: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8983 - MinusLogProbMetric: 4.8983 - val_loss: 5.2554 - val_MinusLogProbMetric: 5.2554 - lr: 2.5000e-04 - 35s/epoch - 179ms/step
Epoch 224/1000
2023-09-18 12:27:47.311 
Epoch 224/1000 
	 loss: 4.8959, MinusLogProbMetric: 4.8959, val_loss: 5.2494, val_MinusLogProbMetric: 5.2494

Epoch 224: val_loss did not improve from 5.21193
196/196 - 36s - loss: 4.8959 - MinusLogProbMetric: 4.8959 - val_loss: 5.2494 - val_MinusLogProbMetric: 5.2494 - lr: 2.5000e-04 - 36s/epoch - 182ms/step
Epoch 225/1000
2023-09-18 12:28:22.545 
Epoch 225/1000 
	 loss: 4.8958, MinusLogProbMetric: 4.8958, val_loss: 5.2564, val_MinusLogProbMetric: 5.2564

Epoch 225: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8958 - MinusLogProbMetric: 4.8958 - val_loss: 5.2564 - val_MinusLogProbMetric: 5.2564 - lr: 2.5000e-04 - 35s/epoch - 179ms/step
Epoch 226/1000
2023-09-18 12:28:57.834 
Epoch 226/1000 
	 loss: 4.8956, MinusLogProbMetric: 4.8956, val_loss: 5.2520, val_MinusLogProbMetric: 5.2520

Epoch 226: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8956 - MinusLogProbMetric: 4.8956 - val_loss: 5.2520 - val_MinusLogProbMetric: 5.2520 - lr: 2.5000e-04 - 35s/epoch - 180ms/step
Epoch 227/1000
2023-09-18 12:29:33.388 
Epoch 227/1000 
	 loss: 4.8957, MinusLogProbMetric: 4.8957, val_loss: 5.2566, val_MinusLogProbMetric: 5.2566

Epoch 227: val_loss did not improve from 5.21193
196/196 - 36s - loss: 4.8957 - MinusLogProbMetric: 4.8957 - val_loss: 5.2566 - val_MinusLogProbMetric: 5.2566 - lr: 2.5000e-04 - 36s/epoch - 181ms/step
Epoch 228/1000
2023-09-18 12:30:08.921 
Epoch 228/1000 
	 loss: 4.8945, MinusLogProbMetric: 4.8945, val_loss: 5.2535, val_MinusLogProbMetric: 5.2535

Epoch 228: val_loss did not improve from 5.21193
196/196 - 36s - loss: 4.8945 - MinusLogProbMetric: 4.8945 - val_loss: 5.2535 - val_MinusLogProbMetric: 5.2535 - lr: 2.5000e-04 - 36s/epoch - 181ms/step
Epoch 229/1000
2023-09-18 12:30:44.332 
Epoch 229/1000 
	 loss: 4.8934, MinusLogProbMetric: 4.8934, val_loss: 5.2580, val_MinusLogProbMetric: 5.2580

Epoch 229: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8934 - MinusLogProbMetric: 4.8934 - val_loss: 5.2580 - val_MinusLogProbMetric: 5.2580 - lr: 2.5000e-04 - 35s/epoch - 181ms/step
Epoch 230/1000
2023-09-18 12:31:19.690 
Epoch 230/1000 
	 loss: 4.8944, MinusLogProbMetric: 4.8944, val_loss: 5.2589, val_MinusLogProbMetric: 5.2589

Epoch 230: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8944 - MinusLogProbMetric: 4.8944 - val_loss: 5.2589 - val_MinusLogProbMetric: 5.2589 - lr: 2.5000e-04 - 35s/epoch - 180ms/step
Epoch 231/1000
2023-09-18 12:31:55.002 
Epoch 231/1000 
	 loss: 4.8940, MinusLogProbMetric: 4.8940, val_loss: 5.2650, val_MinusLogProbMetric: 5.2650

Epoch 231: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8940 - MinusLogProbMetric: 4.8940 - val_loss: 5.2650 - val_MinusLogProbMetric: 5.2650 - lr: 2.5000e-04 - 35s/epoch - 180ms/step
Epoch 232/1000
2023-09-18 12:32:30.171 
Epoch 232/1000 
	 loss: 4.8952, MinusLogProbMetric: 4.8952, val_loss: 5.2597, val_MinusLogProbMetric: 5.2597

Epoch 232: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8952 - MinusLogProbMetric: 4.8952 - val_loss: 5.2597 - val_MinusLogProbMetric: 5.2597 - lr: 2.5000e-04 - 35s/epoch - 179ms/step
Epoch 233/1000
2023-09-18 12:33:05.291 
Epoch 233/1000 
	 loss: 4.8920, MinusLogProbMetric: 4.8920, val_loss: 5.2499, val_MinusLogProbMetric: 5.2499

Epoch 233: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8920 - MinusLogProbMetric: 4.8920 - val_loss: 5.2499 - val_MinusLogProbMetric: 5.2499 - lr: 2.5000e-04 - 35s/epoch - 179ms/step
Epoch 234/1000
2023-09-18 12:33:41.055 
Epoch 234/1000 
	 loss: 4.8916, MinusLogProbMetric: 4.8916, val_loss: 5.2615, val_MinusLogProbMetric: 5.2615

Epoch 234: val_loss did not improve from 5.21193
196/196 - 36s - loss: 4.8916 - MinusLogProbMetric: 4.8916 - val_loss: 5.2615 - val_MinusLogProbMetric: 5.2615 - lr: 2.5000e-04 - 36s/epoch - 182ms/step
Epoch 235/1000
2023-09-18 12:34:16.466 
Epoch 235/1000 
	 loss: 4.8935, MinusLogProbMetric: 4.8935, val_loss: 5.2575, val_MinusLogProbMetric: 5.2575

Epoch 235: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8935 - MinusLogProbMetric: 4.8935 - val_loss: 5.2575 - val_MinusLogProbMetric: 5.2575 - lr: 2.5000e-04 - 35s/epoch - 181ms/step
Epoch 236/1000
2023-09-18 12:34:52.164 
Epoch 236/1000 
	 loss: 4.8943, MinusLogProbMetric: 4.8943, val_loss: 5.2608, val_MinusLogProbMetric: 5.2608

Epoch 236: val_loss did not improve from 5.21193
196/196 - 36s - loss: 4.8943 - MinusLogProbMetric: 4.8943 - val_loss: 5.2608 - val_MinusLogProbMetric: 5.2608 - lr: 2.5000e-04 - 36s/epoch - 182ms/step
Epoch 237/1000
2023-09-18 12:35:27.468 
Epoch 237/1000 
	 loss: 4.8930, MinusLogProbMetric: 4.8930, val_loss: 5.2613, val_MinusLogProbMetric: 5.2613

Epoch 237: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8930 - MinusLogProbMetric: 4.8930 - val_loss: 5.2613 - val_MinusLogProbMetric: 5.2613 - lr: 2.5000e-04 - 35s/epoch - 180ms/step
Epoch 238/1000
2023-09-18 12:36:02.596 
Epoch 238/1000 
	 loss: 4.8916, MinusLogProbMetric: 4.8916, val_loss: 5.2663, val_MinusLogProbMetric: 5.2663

Epoch 238: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8916 - MinusLogProbMetric: 4.8916 - val_loss: 5.2663 - val_MinusLogProbMetric: 5.2663 - lr: 2.5000e-04 - 35s/epoch - 179ms/step
Epoch 239/1000
2023-09-18 12:36:37.387 
Epoch 239/1000 
	 loss: 4.8917, MinusLogProbMetric: 4.8917, val_loss: 5.2685, val_MinusLogProbMetric: 5.2685

Epoch 239: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8917 - MinusLogProbMetric: 4.8917 - val_loss: 5.2685 - val_MinusLogProbMetric: 5.2685 - lr: 2.5000e-04 - 35s/epoch - 177ms/step
Epoch 240/1000
2023-09-18 12:37:12.376 
Epoch 240/1000 
	 loss: 4.8921, MinusLogProbMetric: 4.8921, val_loss: 5.2678, val_MinusLogProbMetric: 5.2678

Epoch 240: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8921 - MinusLogProbMetric: 4.8921 - val_loss: 5.2678 - val_MinusLogProbMetric: 5.2678 - lr: 2.5000e-04 - 35s/epoch - 178ms/step
Epoch 241/1000
2023-09-18 12:37:47.434 
Epoch 241/1000 
	 loss: 4.8913, MinusLogProbMetric: 4.8913, val_loss: 5.2613, val_MinusLogProbMetric: 5.2613

Epoch 241: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8913 - MinusLogProbMetric: 4.8913 - val_loss: 5.2613 - val_MinusLogProbMetric: 5.2613 - lr: 2.5000e-04 - 35s/epoch - 179ms/step
Epoch 242/1000
2023-09-18 12:38:22.764 
Epoch 242/1000 
	 loss: 4.8918, MinusLogProbMetric: 4.8918, val_loss: 5.2604, val_MinusLogProbMetric: 5.2604

Epoch 242: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8918 - MinusLogProbMetric: 4.8918 - val_loss: 5.2604 - val_MinusLogProbMetric: 5.2604 - lr: 2.5000e-04 - 35s/epoch - 180ms/step
Epoch 243/1000
2023-09-18 12:38:58.156 
Epoch 243/1000 
	 loss: 4.8898, MinusLogProbMetric: 4.8898, val_loss: 5.2671, val_MinusLogProbMetric: 5.2671

Epoch 243: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8898 - MinusLogProbMetric: 4.8898 - val_loss: 5.2671 - val_MinusLogProbMetric: 5.2671 - lr: 2.5000e-04 - 35s/epoch - 181ms/step
Epoch 244/1000
2023-09-18 12:39:33.226 
Epoch 244/1000 
	 loss: 4.8900, MinusLogProbMetric: 4.8900, val_loss: 5.2652, val_MinusLogProbMetric: 5.2652

Epoch 244: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8900 - MinusLogProbMetric: 4.8900 - val_loss: 5.2652 - val_MinusLogProbMetric: 5.2652 - lr: 2.5000e-04 - 35s/epoch - 179ms/step
Epoch 245/1000
2023-09-18 12:40:08.628 
Epoch 245/1000 
	 loss: 4.8910, MinusLogProbMetric: 4.8910, val_loss: 5.2633, val_MinusLogProbMetric: 5.2633

Epoch 245: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8910 - MinusLogProbMetric: 4.8910 - val_loss: 5.2633 - val_MinusLogProbMetric: 5.2633 - lr: 2.5000e-04 - 35s/epoch - 181ms/step
Epoch 246/1000
2023-09-18 12:40:43.995 
Epoch 246/1000 
	 loss: 4.8869, MinusLogProbMetric: 4.8869, val_loss: 5.2680, val_MinusLogProbMetric: 5.2680

Epoch 246: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8869 - MinusLogProbMetric: 4.8869 - val_loss: 5.2680 - val_MinusLogProbMetric: 5.2680 - lr: 2.5000e-04 - 35s/epoch - 180ms/step
Epoch 247/1000
2023-09-18 12:41:19.574 
Epoch 247/1000 
	 loss: 4.8896, MinusLogProbMetric: 4.8896, val_loss: 5.2609, val_MinusLogProbMetric: 5.2609

Epoch 247: val_loss did not improve from 5.21193
196/196 - 36s - loss: 4.8896 - MinusLogProbMetric: 4.8896 - val_loss: 5.2609 - val_MinusLogProbMetric: 5.2609 - lr: 2.5000e-04 - 36s/epoch - 182ms/step
Epoch 248/1000
2023-09-18 12:41:54.812 
Epoch 248/1000 
	 loss: 4.8884, MinusLogProbMetric: 4.8884, val_loss: 5.2679, val_MinusLogProbMetric: 5.2679

Epoch 248: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8884 - MinusLogProbMetric: 4.8884 - val_loss: 5.2679 - val_MinusLogProbMetric: 5.2679 - lr: 2.5000e-04 - 35s/epoch - 180ms/step
Epoch 249/1000
2023-09-18 12:42:30.275 
Epoch 249/1000 
	 loss: 4.8886, MinusLogProbMetric: 4.8886, val_loss: 5.2698, val_MinusLogProbMetric: 5.2698

Epoch 249: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8886 - MinusLogProbMetric: 4.8886 - val_loss: 5.2698 - val_MinusLogProbMetric: 5.2698 - lr: 2.5000e-04 - 35s/epoch - 181ms/step
Epoch 250/1000
2023-09-18 12:43:05.566 
Epoch 250/1000 
	 loss: 4.8871, MinusLogProbMetric: 4.8871, val_loss: 5.2707, val_MinusLogProbMetric: 5.2707

Epoch 250: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8871 - MinusLogProbMetric: 4.8871 - val_loss: 5.2707 - val_MinusLogProbMetric: 5.2707 - lr: 2.5000e-04 - 35s/epoch - 180ms/step
Epoch 251/1000
2023-09-18 12:43:41.056 
Epoch 251/1000 
	 loss: 4.8878, MinusLogProbMetric: 4.8878, val_loss: 5.2744, val_MinusLogProbMetric: 5.2744

Epoch 251: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8878 - MinusLogProbMetric: 4.8878 - val_loss: 5.2744 - val_MinusLogProbMetric: 5.2744 - lr: 2.5000e-04 - 35s/epoch - 181ms/step
Epoch 252/1000
2023-09-18 12:44:16.523 
Epoch 252/1000 
	 loss: 4.8876, MinusLogProbMetric: 4.8876, val_loss: 5.2629, val_MinusLogProbMetric: 5.2629

Epoch 252: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8876 - MinusLogProbMetric: 4.8876 - val_loss: 5.2629 - val_MinusLogProbMetric: 5.2629 - lr: 2.5000e-04 - 35s/epoch - 181ms/step
Epoch 253/1000
2023-09-18 12:44:52.331 
Epoch 253/1000 
	 loss: 4.8870, MinusLogProbMetric: 4.8870, val_loss: 5.2624, val_MinusLogProbMetric: 5.2624

Epoch 253: val_loss did not improve from 5.21193
196/196 - 36s - loss: 4.8870 - MinusLogProbMetric: 4.8870 - val_loss: 5.2624 - val_MinusLogProbMetric: 5.2624 - lr: 2.5000e-04 - 36s/epoch - 183ms/step
Epoch 254/1000
2023-09-18 12:45:27.502 
Epoch 254/1000 
	 loss: 4.8872, MinusLogProbMetric: 4.8872, val_loss: 5.2644, val_MinusLogProbMetric: 5.2644

Epoch 254: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8872 - MinusLogProbMetric: 4.8872 - val_loss: 5.2644 - val_MinusLogProbMetric: 5.2644 - lr: 2.5000e-04 - 35s/epoch - 179ms/step
Epoch 255/1000
2023-09-18 12:46:02.253 
Epoch 255/1000 
	 loss: 4.8873, MinusLogProbMetric: 4.8873, val_loss: 5.2644, val_MinusLogProbMetric: 5.2644

Epoch 255: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8873 - MinusLogProbMetric: 4.8873 - val_loss: 5.2644 - val_MinusLogProbMetric: 5.2644 - lr: 2.5000e-04 - 35s/epoch - 177ms/step
Epoch 256/1000
2023-09-18 12:46:37.019 
Epoch 256/1000 
	 loss: 4.8899, MinusLogProbMetric: 4.8899, val_loss: 5.2648, val_MinusLogProbMetric: 5.2648

Epoch 256: val_loss did not improve from 5.21193
196/196 - 35s - loss: 4.8899 - MinusLogProbMetric: 4.8899 - val_loss: 5.2648 - val_MinusLogProbMetric: 5.2648 - lr: 2.5000e-04 - 35s/epoch - 177ms/step
Epoch 257/1000
2023-09-18 12:47:11.994 
Epoch 257/1000 
	 loss: 4.8859, MinusLogProbMetric: 4.8859, val_loss: 5.2817, val_MinusLogProbMetric: 5.2817

Epoch 257: val_loss did not improve from 5.21193
Restoring model weights from the end of the best epoch: 157.
196/196 - 35s - loss: 4.8859 - MinusLogProbMetric: 4.8859 - val_loss: 5.2817 - val_MinusLogProbMetric: 5.2817 - lr: 2.5000e-04 - 35s/epoch - 180ms/step
Epoch 257: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 13.266533207846805 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 8.301301961997524 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 5.076418497134 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7faeadd99ab0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 20.360690976958722 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 9.90505047980696 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 6.024625607999042 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7faead0e8ca0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 440.
Model trained in 9053.13 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/c_Main_CsplineN.py , Line : 468, Func.Name : prediction_function, Message : X_data_nf: tf.Tensor = DataInputs.dist_2_num[:nsamples_test] # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 65.19 s.
===========
Run 185/720 done in 9121.12 s.
===========

Directory ../../results/CsplineN_new/run_186/ already exists.
Skipping it.
===========
Run 186/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_187/ already exists.
Skipping it.
===========
Run 187/720 already exists. Skipping it.
===========

===========
Generating train data for run 188.
===========
Train data generated in 0.11 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 16)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_188/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 440}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_188/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.9388056 ,  6.6011305 ,  7.1936936 , ...,  9.376897  ,
        -0.20441407,  0.997946  ],
       [ 5.7592807 ,  7.4562755 ,  6.073807  , ...,  8.982617  ,
         1.3178213 ,  0.7693994 ],
       [ 4.825065  ,  5.849577  ,  0.14626749, ...,  6.3837705 ,
         2.132065  ,  1.518469  ],
       ...,
       [ 5.615609  ,  7.2656503 ,  4.8600593 , ...,  9.083482  ,
         0.68300927,  1.0057955 ],
       [ 4.1834145 ,  6.0909553 ,  0.23574165, ...,  7.763974  ,
         1.9834036 ,  1.2137753 ],
       [ 3.9210687 ,  6.0211887 ,  0.28002483, ...,  6.9610376 ,
         1.7232312 ,  1.247894  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_188/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_188
self.data_kwargs: {'seed': 440}
self.x_data: [[5.9069815  7.5444255  6.3762054  ... 9.075856   0.9364161  0.80815375]
 [4.741565   5.111489   0.30516613 ... 6.3444896  2.1198235  1.1959152 ]
 [5.3968034  7.4016695  5.7313123  ... 9.37714    0.68808633 0.8965562 ]
 ...
 [5.630116   6.508466   4.560816   ... 9.354164   0.5113934  0.8420493 ]
 [3.8550687  6.072236   0.15075347 ... 6.0798836  1.9062192  1.6859822 ]
 [5.6194196  7.5907955  5.8847475  ... 9.269651   0.46180454 0.8692333 ]]
self.y_data: []
self.ndims: 16
Model defined.
Model: "model_146"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_147 (InputLayer)      [(None, 16)]              0         
                                                                 
 log_prob_layer_16 (LogProbL  (None,)                  1029240   
 ayer)                                                           
                                                                 
=================================================================
Total params: 1,029,240
Trainable params: 1,029,240
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_16/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_16'")
self.model: <keras.engine.functional.Functional object at 0x7fada9877220>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fada9641f90>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fada9641f90>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fada9c6d630>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fada94ee1d0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_188/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fada94ee740>, <keras.callbacks.ModelCheckpoint object at 0x7fada94ee800>, <keras.callbacks.EarlyStopping object at 0x7fada94eea70>, <keras.callbacks.ReduceLROnPlateau object at 0x7fada94eeaa0>, <keras.callbacks.TerminateOnNaN object at 0x7fada94ee6e0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.9388056 ,  6.6011305 ,  7.1936936 , ...,  9.376897  ,
        -0.20441407,  0.997946  ],
       [ 5.7592807 ,  7.4562755 ,  6.073807  , ...,  8.982617  ,
         1.3178213 ,  0.7693994 ],
       [ 4.825065  ,  5.849577  ,  0.14626749, ...,  6.3837705 ,
         2.132065  ,  1.518469  ],
       ...,
       [ 5.615609  ,  7.2656503 ,  4.8600593 , ...,  9.083482  ,
         0.68300927,  1.0057955 ],
       [ 4.1834145 ,  6.0909553 ,  0.23574165, ...,  7.763974  ,
         1.9834036 ,  1.2137753 ],
       [ 3.9210687 ,  6.0211887 ,  0.28002483, ...,  6.9610376 ,
         1.7232312 ,  1.247894  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_188/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 188/720 with hyperparameters:
timestamp = 2023-09-18 12:48:21.953261
ndims = 16
seed_train = 440
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 5
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 1029240
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [5.9069815  7.5444255  6.3762054  5.732217   4.629946   6.4001193
 4.3642464  8.792809   9.021455   4.047819   7.801147   5.4133105
 5.6628323  9.075856   0.9364161  0.80815375]
Epoch 1/1000
2023-09-18 12:51:14.659 
Epoch 1/1000 
	 loss: 16.7681, MinusLogProbMetric: 16.7681, val_loss: 7.6254, val_MinusLogProbMetric: 7.6254

Epoch 1: val_loss improved from inf to 7.62541, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_188/weights/best_weights.h5
196/196 - 174s - loss: 16.7681 - MinusLogProbMetric: 16.7681 - val_loss: 7.6254 - val_MinusLogProbMetric: 7.6254 - lr: 0.0010 - 174s/epoch - 886ms/step
Epoch 2/1000
2023-09-18 12:52:00.269 
Epoch 2/1000 
	 loss: 6.9679, MinusLogProbMetric: 6.9679, val_loss: 6.6332, val_MinusLogProbMetric: 6.6332

Epoch 2: val_loss improved from 7.62541 to 6.63317, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_188/weights/best_weights.h5
196/196 - 45s - loss: 6.9679 - MinusLogProbMetric: 6.9679 - val_loss: 6.6332 - val_MinusLogProbMetric: 6.6332 - lr: 0.0010 - 45s/epoch - 231ms/step
Epoch 3/1000
2023-09-18 12:52:45.305 
Epoch 3/1000 
	 loss: 6.2080, MinusLogProbMetric: 6.2080, val_loss: 6.3194, val_MinusLogProbMetric: 6.3194

Epoch 3: val_loss improved from 6.63317 to 6.31943, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_188/weights/best_weights.h5
196/196 - 45s - loss: 6.2080 - MinusLogProbMetric: 6.2080 - val_loss: 6.3194 - val_MinusLogProbMetric: 6.3194 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 4/1000
2023-09-18 12:53:30.354 
Epoch 4/1000 
	 loss: 5.9378, MinusLogProbMetric: 5.9378, val_loss: 5.9217, val_MinusLogProbMetric: 5.9217

Epoch 4: val_loss improved from 6.31943 to 5.92174, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_188/weights/best_weights.h5
196/196 - 45s - loss: 5.9378 - MinusLogProbMetric: 5.9378 - val_loss: 5.9217 - val_MinusLogProbMetric: 5.9217 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 5/1000
2023-09-18 12:54:15.308 
Epoch 5/1000 
	 loss: 5.8353, MinusLogProbMetric: 5.8353, val_loss: 6.1457, val_MinusLogProbMetric: 6.1457

Epoch 5: val_loss did not improve from 5.92174
196/196 - 44s - loss: 5.8353 - MinusLogProbMetric: 5.8353 - val_loss: 6.1457 - val_MinusLogProbMetric: 6.1457 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 6/1000
2023-09-18 12:54:59.428 
Epoch 6/1000 
	 loss: 5.7206, MinusLogProbMetric: 5.7206, val_loss: 5.7203, val_MinusLogProbMetric: 5.7203

Epoch 6: val_loss improved from 5.92174 to 5.72031, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_188/weights/best_weights.h5
196/196 - 45s - loss: 5.7206 - MinusLogProbMetric: 5.7206 - val_loss: 5.7203 - val_MinusLogProbMetric: 5.7203 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 7/1000
2023-09-18 12:55:44.210 
Epoch 7/1000 
	 loss: 5.5968, MinusLogProbMetric: 5.5968, val_loss: 5.7239, val_MinusLogProbMetric: 5.7239

Epoch 7: val_loss did not improve from 5.72031
196/196 - 44s - loss: 5.5968 - MinusLogProbMetric: 5.5968 - val_loss: 5.7239 - val_MinusLogProbMetric: 5.7239 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 8/1000
2023-09-18 12:56:28.257 
Epoch 8/1000 
	 loss: 5.5967, MinusLogProbMetric: 5.5967, val_loss: 5.7829, val_MinusLogProbMetric: 5.7829

Epoch 8: val_loss did not improve from 5.72031
196/196 - 44s - loss: 5.5967 - MinusLogProbMetric: 5.5967 - val_loss: 5.7829 - val_MinusLogProbMetric: 5.7829 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 9/1000
2023-09-18 12:57:12.380 
Epoch 9/1000 
	 loss: 5.5232, MinusLogProbMetric: 5.5232, val_loss: 5.7715, val_MinusLogProbMetric: 5.7715

Epoch 9: val_loss did not improve from 5.72031
196/196 - 44s - loss: 5.5232 - MinusLogProbMetric: 5.5232 - val_loss: 5.7715 - val_MinusLogProbMetric: 5.7715 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 10/1000
2023-09-18 12:57:56.297 
Epoch 10/1000 
	 loss: 5.4894, MinusLogProbMetric: 5.4894, val_loss: 5.4656, val_MinusLogProbMetric: 5.4656

Epoch 10: val_loss improved from 5.72031 to 5.46559, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_188/weights/best_weights.h5
196/196 - 45s - loss: 5.4894 - MinusLogProbMetric: 5.4894 - val_loss: 5.4656 - val_MinusLogProbMetric: 5.4656 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 11/1000
2023-09-18 12:58:40.940 
Epoch 11/1000 
	 loss: 5.4587, MinusLogProbMetric: 5.4587, val_loss: 5.3968, val_MinusLogProbMetric: 5.3968

Epoch 11: val_loss improved from 5.46559 to 5.39675, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_188/weights/best_weights.h5
196/196 - 45s - loss: 5.4587 - MinusLogProbMetric: 5.4587 - val_loss: 5.3968 - val_MinusLogProbMetric: 5.3968 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 12/1000
2023-09-18 12:59:25.697 
Epoch 12/1000 
	 loss: 5.4380, MinusLogProbMetric: 5.4380, val_loss: 5.7104, val_MinusLogProbMetric: 5.7104

Epoch 12: val_loss did not improve from 5.39675
196/196 - 44s - loss: 5.4380 - MinusLogProbMetric: 5.4380 - val_loss: 5.7104 - val_MinusLogProbMetric: 5.7104 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 13/1000
2023-09-18 13:00:09.823 
Epoch 13/1000 
	 loss: 5.4058, MinusLogProbMetric: 5.4058, val_loss: 5.5002, val_MinusLogProbMetric: 5.5002

Epoch 13: val_loss did not improve from 5.39675
196/196 - 44s - loss: 5.4058 - MinusLogProbMetric: 5.4058 - val_loss: 5.5002 - val_MinusLogProbMetric: 5.5002 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 14/1000
2023-09-18 13:00:53.917 
Epoch 14/1000 
	 loss: 5.3845, MinusLogProbMetric: 5.3845, val_loss: 5.5587, val_MinusLogProbMetric: 5.5587

Epoch 14: val_loss did not improve from 5.39675
196/196 - 44s - loss: 5.3845 - MinusLogProbMetric: 5.3845 - val_loss: 5.5587 - val_MinusLogProbMetric: 5.5587 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 15/1000
2023-09-18 13:01:38.006 
Epoch 15/1000 
	 loss: 5.3431, MinusLogProbMetric: 5.3431, val_loss: 5.4469, val_MinusLogProbMetric: 5.4469

Epoch 15: val_loss did not improve from 5.39675
196/196 - 44s - loss: 5.3431 - MinusLogProbMetric: 5.3431 - val_loss: 5.4469 - val_MinusLogProbMetric: 5.4469 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 16/1000
2023-09-18 13:02:21.814 
Epoch 16/1000 
	 loss: 5.3203, MinusLogProbMetric: 5.3203, val_loss: 5.4627, val_MinusLogProbMetric: 5.4627

Epoch 16: val_loss did not improve from 5.39675
196/196 - 44s - loss: 5.3203 - MinusLogProbMetric: 5.3203 - val_loss: 5.4627 - val_MinusLogProbMetric: 5.4627 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 17/1000
2023-09-18 13:03:05.900 
Epoch 17/1000 
	 loss: 5.3455, MinusLogProbMetric: 5.3455, val_loss: 5.4404, val_MinusLogProbMetric: 5.4404

Epoch 17: val_loss did not improve from 5.39675
196/196 - 44s - loss: 5.3455 - MinusLogProbMetric: 5.3455 - val_loss: 5.4404 - val_MinusLogProbMetric: 5.4404 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 18/1000
2023-09-18 13:03:50.131 
Epoch 18/1000 
	 loss: 5.3045, MinusLogProbMetric: 5.3045, val_loss: 5.3642, val_MinusLogProbMetric: 5.3642

Epoch 18: val_loss improved from 5.39675 to 5.36423, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_188/weights/best_weights.h5
196/196 - 45s - loss: 5.3045 - MinusLogProbMetric: 5.3045 - val_loss: 5.3642 - val_MinusLogProbMetric: 5.3642 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 19/1000
2023-09-18 13:04:35.660 
Epoch 19/1000 
	 loss: 5.2941, MinusLogProbMetric: 5.2941, val_loss: 5.5738, val_MinusLogProbMetric: 5.5738

Epoch 19: val_loss did not improve from 5.36423
196/196 - 45s - loss: 5.2941 - MinusLogProbMetric: 5.2941 - val_loss: 5.5738 - val_MinusLogProbMetric: 5.5738 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 20/1000
2023-09-18 13:05:19.252 
Epoch 20/1000 
	 loss: 5.2625, MinusLogProbMetric: 5.2625, val_loss: 5.4568, val_MinusLogProbMetric: 5.4568

Epoch 20: val_loss did not improve from 5.36423
196/196 - 44s - loss: 5.2625 - MinusLogProbMetric: 5.2625 - val_loss: 5.4568 - val_MinusLogProbMetric: 5.4568 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 21/1000
2023-09-18 13:06:03.132 
Epoch 21/1000 
	 loss: 5.2418, MinusLogProbMetric: 5.2418, val_loss: 5.4628, val_MinusLogProbMetric: 5.4628

Epoch 21: val_loss did not improve from 5.36423
196/196 - 44s - loss: 5.2418 - MinusLogProbMetric: 5.2418 - val_loss: 5.4628 - val_MinusLogProbMetric: 5.4628 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 22/1000
2023-09-18 13:06:47.250 
Epoch 22/1000 
	 loss: 5.2433, MinusLogProbMetric: 5.2433, val_loss: 5.7157, val_MinusLogProbMetric: 5.7157

Epoch 22: val_loss did not improve from 5.36423
196/196 - 44s - loss: 5.2433 - MinusLogProbMetric: 5.2433 - val_loss: 5.7157 - val_MinusLogProbMetric: 5.7157 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 23/1000
2023-09-18 13:07:31.246 
Epoch 23/1000 
	 loss: 5.2170, MinusLogProbMetric: 5.2170, val_loss: 5.4292, val_MinusLogProbMetric: 5.4292

Epoch 23: val_loss did not improve from 5.36423
196/196 - 44s - loss: 5.2170 - MinusLogProbMetric: 5.2170 - val_loss: 5.4292 - val_MinusLogProbMetric: 5.4292 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 24/1000
2023-09-18 13:08:15.054 
Epoch 24/1000 
	 loss: 5.2177, MinusLogProbMetric: 5.2177, val_loss: 5.5262, val_MinusLogProbMetric: 5.5262

Epoch 24: val_loss did not improve from 5.36423
196/196 - 44s - loss: 5.2177 - MinusLogProbMetric: 5.2177 - val_loss: 5.5262 - val_MinusLogProbMetric: 5.5262 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 25/1000
2023-09-18 13:08:58.345 
Epoch 25/1000 
	 loss: 5.2038, MinusLogProbMetric: 5.2038, val_loss: 5.4026, val_MinusLogProbMetric: 5.4026

Epoch 25: val_loss did not improve from 5.36423
196/196 - 43s - loss: 5.2038 - MinusLogProbMetric: 5.2038 - val_loss: 5.4026 - val_MinusLogProbMetric: 5.4026 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 26/1000
2023-09-18 13:09:35.038 
Epoch 26/1000 
	 loss: 5.1745, MinusLogProbMetric: 5.1745, val_loss: 5.4343, val_MinusLogProbMetric: 5.4343

Epoch 26: val_loss did not improve from 5.36423
196/196 - 37s - loss: 5.1745 - MinusLogProbMetric: 5.1745 - val_loss: 5.4343 - val_MinusLogProbMetric: 5.4343 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 27/1000
2023-09-18 13:10:11.139 
Epoch 27/1000 
	 loss: 5.1841, MinusLogProbMetric: 5.1841, val_loss: 5.4477, val_MinusLogProbMetric: 5.4477

Epoch 27: val_loss did not improve from 5.36423
196/196 - 36s - loss: 5.1841 - MinusLogProbMetric: 5.1841 - val_loss: 5.4477 - val_MinusLogProbMetric: 5.4477 - lr: 0.0010 - 36s/epoch - 184ms/step
Epoch 28/1000
2023-09-18 13:10:48.253 
Epoch 28/1000 
	 loss: 5.1615, MinusLogProbMetric: 5.1615, val_loss: 5.3987, val_MinusLogProbMetric: 5.3987

Epoch 28: val_loss did not improve from 5.36423
196/196 - 37s - loss: 5.1615 - MinusLogProbMetric: 5.1615 - val_loss: 5.3987 - val_MinusLogProbMetric: 5.3987 - lr: 0.0010 - 37s/epoch - 189ms/step
Epoch 29/1000
2023-09-18 13:11:22.137 
Epoch 29/1000 
	 loss: 5.1527, MinusLogProbMetric: 5.1527, val_loss: 5.4057, val_MinusLogProbMetric: 5.4057

Epoch 29: val_loss did not improve from 5.36423
196/196 - 34s - loss: 5.1527 - MinusLogProbMetric: 5.1527 - val_loss: 5.4057 - val_MinusLogProbMetric: 5.4057 - lr: 0.0010 - 34s/epoch - 173ms/step
Epoch 30/1000
2023-09-18 13:11:57.034 
Epoch 30/1000 
	 loss: 5.1557, MinusLogProbMetric: 5.1557, val_loss: 5.4392, val_MinusLogProbMetric: 5.4392

Epoch 30: val_loss did not improve from 5.36423
196/196 - 35s - loss: 5.1557 - MinusLogProbMetric: 5.1557 - val_loss: 5.4392 - val_MinusLogProbMetric: 5.4392 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 31/1000
2023-09-18 13:12:40.662 
Epoch 31/1000 
	 loss: 5.1399, MinusLogProbMetric: 5.1399, val_loss: 5.3692, val_MinusLogProbMetric: 5.3692

Epoch 31: val_loss did not improve from 5.36423
196/196 - 44s - loss: 5.1399 - MinusLogProbMetric: 5.1399 - val_loss: 5.3692 - val_MinusLogProbMetric: 5.3692 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 32/1000
2023-09-18 13:13:25.211 
Epoch 32/1000 
	 loss: 5.1250, MinusLogProbMetric: 5.1250, val_loss: 5.3585, val_MinusLogProbMetric: 5.3585

Epoch 32: val_loss improved from 5.36423 to 5.35847, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_188/weights/best_weights.h5
196/196 - 45s - loss: 5.1250 - MinusLogProbMetric: 5.1250 - val_loss: 5.3585 - val_MinusLogProbMetric: 5.3585 - lr: 0.0010 - 45s/epoch - 231ms/step
Epoch 33/1000
2023-09-18 13:14:09.702 
Epoch 33/1000 
	 loss: 5.1275, MinusLogProbMetric: 5.1275, val_loss: 5.3843, val_MinusLogProbMetric: 5.3843

Epoch 33: val_loss did not improve from 5.35847
196/196 - 44s - loss: 5.1275 - MinusLogProbMetric: 5.1275 - val_loss: 5.3843 - val_MinusLogProbMetric: 5.3843 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 34/1000
2023-09-18 13:14:53.748 
Epoch 34/1000 
	 loss: 5.1096, MinusLogProbMetric: 5.1096, val_loss: 5.3714, val_MinusLogProbMetric: 5.3714

Epoch 34: val_loss did not improve from 5.35847
196/196 - 44s - loss: 5.1096 - MinusLogProbMetric: 5.1096 - val_loss: 5.3714 - val_MinusLogProbMetric: 5.3714 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 35/1000
2023-09-18 13:15:37.740 
Epoch 35/1000 
	 loss: 5.1104, MinusLogProbMetric: 5.1104, val_loss: 5.5031, val_MinusLogProbMetric: 5.5031

Epoch 35: val_loss did not improve from 5.35847
196/196 - 44s - loss: 5.1104 - MinusLogProbMetric: 5.1104 - val_loss: 5.5031 - val_MinusLogProbMetric: 5.5031 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 36/1000
2023-09-18 13:16:21.891 
Epoch 36/1000 
	 loss: 5.0907, MinusLogProbMetric: 5.0907, val_loss: 5.3264, val_MinusLogProbMetric: 5.3264

Epoch 36: val_loss improved from 5.35847 to 5.32644, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_188/weights/best_weights.h5
196/196 - 45s - loss: 5.0907 - MinusLogProbMetric: 5.0907 - val_loss: 5.3264 - val_MinusLogProbMetric: 5.3264 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 37/1000
2023-09-18 13:17:06.942 
Epoch 37/1000 
	 loss: 5.0752, MinusLogProbMetric: 5.0752, val_loss: 5.3504, val_MinusLogProbMetric: 5.3504

Epoch 37: val_loss did not improve from 5.32644
196/196 - 44s - loss: 5.0752 - MinusLogProbMetric: 5.0752 - val_loss: 5.3504 - val_MinusLogProbMetric: 5.3504 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 38/1000
2023-09-18 13:17:50.970 
Epoch 38/1000 
	 loss: 5.0932, MinusLogProbMetric: 5.0932, val_loss: 5.4603, val_MinusLogProbMetric: 5.4603

Epoch 38: val_loss did not improve from 5.32644
196/196 - 44s - loss: 5.0932 - MinusLogProbMetric: 5.0932 - val_loss: 5.4603 - val_MinusLogProbMetric: 5.4603 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 39/1000
2023-09-18 13:18:35.450 
Epoch 39/1000 
	 loss: 5.0696, MinusLogProbMetric: 5.0696, val_loss: 5.3867, val_MinusLogProbMetric: 5.3867

Epoch 39: val_loss did not improve from 5.32644
196/196 - 44s - loss: 5.0696 - MinusLogProbMetric: 5.0696 - val_loss: 5.3867 - val_MinusLogProbMetric: 5.3867 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 40/1000
2023-09-18 13:19:20.134 
Epoch 40/1000 
	 loss: 5.0640, MinusLogProbMetric: 5.0640, val_loss: 5.3762, val_MinusLogProbMetric: 5.3762

Epoch 40: val_loss did not improve from 5.32644
196/196 - 45s - loss: 5.0640 - MinusLogProbMetric: 5.0640 - val_loss: 5.3762 - val_MinusLogProbMetric: 5.3762 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 41/1000
2023-09-18 13:20:04.748 
Epoch 41/1000 
	 loss: 5.0668, MinusLogProbMetric: 5.0668, val_loss: 5.4354, val_MinusLogProbMetric: 5.4354

Epoch 41: val_loss did not improve from 5.32644
196/196 - 45s - loss: 5.0668 - MinusLogProbMetric: 5.0668 - val_loss: 5.4354 - val_MinusLogProbMetric: 5.4354 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 42/1000
2023-09-18 13:20:48.838 
Epoch 42/1000 
	 loss: 5.0625, MinusLogProbMetric: 5.0625, val_loss: 5.4576, val_MinusLogProbMetric: 5.4576

Epoch 42: val_loss did not improve from 5.32644
196/196 - 44s - loss: 5.0625 - MinusLogProbMetric: 5.0625 - val_loss: 5.4576 - val_MinusLogProbMetric: 5.4576 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 43/1000
2023-09-18 13:21:33.090 
Epoch 43/1000 
	 loss: 5.0569, MinusLogProbMetric: 5.0569, val_loss: 5.3622, val_MinusLogProbMetric: 5.3622

Epoch 43: val_loss did not improve from 5.32644
196/196 - 44s - loss: 5.0569 - MinusLogProbMetric: 5.0569 - val_loss: 5.3622 - val_MinusLogProbMetric: 5.3622 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 44/1000
2023-09-18 13:22:17.012 
Epoch 44/1000 
	 loss: 5.0205, MinusLogProbMetric: 5.0205, val_loss: 5.3809, val_MinusLogProbMetric: 5.3809

Epoch 44: val_loss did not improve from 5.32644
196/196 - 44s - loss: 5.0205 - MinusLogProbMetric: 5.0205 - val_loss: 5.3809 - val_MinusLogProbMetric: 5.3809 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 45/1000
2023-09-18 13:23:00.823 
Epoch 45/1000 
	 loss: 5.0322, MinusLogProbMetric: 5.0322, val_loss: 5.4982, val_MinusLogProbMetric: 5.4982

Epoch 45: val_loss did not improve from 5.32644
196/196 - 44s - loss: 5.0322 - MinusLogProbMetric: 5.0322 - val_loss: 5.4982 - val_MinusLogProbMetric: 5.4982 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 46/1000
2023-09-18 13:23:44.615 
Epoch 46/1000 
	 loss: 5.0448, MinusLogProbMetric: 5.0448, val_loss: 5.4719, val_MinusLogProbMetric: 5.4719

Epoch 46: val_loss did not improve from 5.32644
196/196 - 44s - loss: 5.0448 - MinusLogProbMetric: 5.0448 - val_loss: 5.4719 - val_MinusLogProbMetric: 5.4719 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 47/1000
2023-09-18 13:24:28.918 
Epoch 47/1000 
	 loss: 5.0393, MinusLogProbMetric: 5.0393, val_loss: 5.4845, val_MinusLogProbMetric: 5.4845

Epoch 47: val_loss did not improve from 5.32644
196/196 - 44s - loss: 5.0393 - MinusLogProbMetric: 5.0393 - val_loss: 5.4845 - val_MinusLogProbMetric: 5.4845 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 48/1000
2023-09-18 13:25:13.140 
Epoch 48/1000 
	 loss: 5.0074, MinusLogProbMetric: 5.0074, val_loss: 5.3518, val_MinusLogProbMetric: 5.3518

Epoch 48: val_loss did not improve from 5.32644
196/196 - 44s - loss: 5.0074 - MinusLogProbMetric: 5.0074 - val_loss: 5.3518 - val_MinusLogProbMetric: 5.3518 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 49/1000
2023-09-18 13:25:56.719 
Epoch 49/1000 
	 loss: 5.0040, MinusLogProbMetric: 5.0040, val_loss: 5.3826, val_MinusLogProbMetric: 5.3826

Epoch 49: val_loss did not improve from 5.32644
196/196 - 44s - loss: 5.0040 - MinusLogProbMetric: 5.0040 - val_loss: 5.3826 - val_MinusLogProbMetric: 5.3826 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 50/1000
2023-09-18 13:26:40.568 
Epoch 50/1000 
	 loss: 4.9902, MinusLogProbMetric: 4.9902, val_loss: 5.5633, val_MinusLogProbMetric: 5.5633

Epoch 50: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.9902 - MinusLogProbMetric: 4.9902 - val_loss: 5.5633 - val_MinusLogProbMetric: 5.5633 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 51/1000
2023-09-18 13:27:24.373 
Epoch 51/1000 
	 loss: 4.9956, MinusLogProbMetric: 4.9956, val_loss: 5.3955, val_MinusLogProbMetric: 5.3955

Epoch 51: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.9956 - MinusLogProbMetric: 4.9956 - val_loss: 5.3955 - val_MinusLogProbMetric: 5.3955 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 52/1000
2023-09-18 13:28:08.561 
Epoch 52/1000 
	 loss: 4.9943, MinusLogProbMetric: 4.9943, val_loss: 5.4175, val_MinusLogProbMetric: 5.4175

Epoch 52: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.9943 - MinusLogProbMetric: 4.9943 - val_loss: 5.4175 - val_MinusLogProbMetric: 5.4175 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 53/1000
2023-09-18 13:28:52.483 
Epoch 53/1000 
	 loss: 4.9819, MinusLogProbMetric: 4.9819, val_loss: 5.3925, val_MinusLogProbMetric: 5.3925

Epoch 53: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.9819 - MinusLogProbMetric: 4.9819 - val_loss: 5.3925 - val_MinusLogProbMetric: 5.3925 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 54/1000
2023-09-18 13:29:36.735 
Epoch 54/1000 
	 loss: 4.9628, MinusLogProbMetric: 4.9628, val_loss: 5.4991, val_MinusLogProbMetric: 5.4991

Epoch 54: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.9628 - MinusLogProbMetric: 4.9628 - val_loss: 5.4991 - val_MinusLogProbMetric: 5.4991 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 55/1000
2023-09-18 13:30:20.832 
Epoch 55/1000 
	 loss: 4.9682, MinusLogProbMetric: 4.9682, val_loss: 5.4072, val_MinusLogProbMetric: 5.4072

Epoch 55: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.9682 - MinusLogProbMetric: 4.9682 - val_loss: 5.4072 - val_MinusLogProbMetric: 5.4072 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 56/1000
2023-09-18 13:31:05.203 
Epoch 56/1000 
	 loss: 4.9570, MinusLogProbMetric: 4.9570, val_loss: 5.4357, val_MinusLogProbMetric: 5.4357

Epoch 56: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.9570 - MinusLogProbMetric: 4.9570 - val_loss: 5.4357 - val_MinusLogProbMetric: 5.4357 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 57/1000
2023-09-18 13:31:49.510 
Epoch 57/1000 
	 loss: 4.9613, MinusLogProbMetric: 4.9613, val_loss: 5.3962, val_MinusLogProbMetric: 5.3962

Epoch 57: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.9613 - MinusLogProbMetric: 4.9613 - val_loss: 5.3962 - val_MinusLogProbMetric: 5.3962 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 58/1000
2023-09-18 13:32:33.634 
Epoch 58/1000 
	 loss: 4.9310, MinusLogProbMetric: 4.9310, val_loss: 5.3866, val_MinusLogProbMetric: 5.3866

Epoch 58: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.9310 - MinusLogProbMetric: 4.9310 - val_loss: 5.3866 - val_MinusLogProbMetric: 5.3866 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 59/1000
2023-09-18 13:33:17.771 
Epoch 59/1000 
	 loss: 4.9463, MinusLogProbMetric: 4.9463, val_loss: 5.4648, val_MinusLogProbMetric: 5.4648

Epoch 59: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.9463 - MinusLogProbMetric: 4.9463 - val_loss: 5.4648 - val_MinusLogProbMetric: 5.4648 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 60/1000
2023-09-18 13:34:02.048 
Epoch 60/1000 
	 loss: 4.9392, MinusLogProbMetric: 4.9392, val_loss: 5.4230, val_MinusLogProbMetric: 5.4230

Epoch 60: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.9392 - MinusLogProbMetric: 4.9392 - val_loss: 5.4230 - val_MinusLogProbMetric: 5.4230 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 61/1000
2023-09-18 13:34:46.132 
Epoch 61/1000 
	 loss: 4.9230, MinusLogProbMetric: 4.9230, val_loss: 5.4899, val_MinusLogProbMetric: 5.4899

Epoch 61: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.9230 - MinusLogProbMetric: 4.9230 - val_loss: 5.4899 - val_MinusLogProbMetric: 5.4899 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 62/1000
2023-09-18 13:35:29.990 
Epoch 62/1000 
	 loss: 4.9180, MinusLogProbMetric: 4.9180, val_loss: 5.5550, val_MinusLogProbMetric: 5.5550

Epoch 62: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.9180 - MinusLogProbMetric: 4.9180 - val_loss: 5.5550 - val_MinusLogProbMetric: 5.5550 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 63/1000
2023-09-18 13:36:13.678 
Epoch 63/1000 
	 loss: 4.9272, MinusLogProbMetric: 4.9272, val_loss: 5.4450, val_MinusLogProbMetric: 5.4450

Epoch 63: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.9272 - MinusLogProbMetric: 4.9272 - val_loss: 5.4450 - val_MinusLogProbMetric: 5.4450 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 64/1000
2023-09-18 13:36:57.488 
Epoch 64/1000 
	 loss: 4.9096, MinusLogProbMetric: 4.9096, val_loss: 5.4905, val_MinusLogProbMetric: 5.4905

Epoch 64: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.9096 - MinusLogProbMetric: 4.9096 - val_loss: 5.4905 - val_MinusLogProbMetric: 5.4905 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 65/1000
2023-09-18 13:37:41.512 
Epoch 65/1000 
	 loss: 4.9242, MinusLogProbMetric: 4.9242, val_loss: 5.4621, val_MinusLogProbMetric: 5.4621

Epoch 65: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.9242 - MinusLogProbMetric: 4.9242 - val_loss: 5.4621 - val_MinusLogProbMetric: 5.4621 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 66/1000
2023-09-18 13:38:25.559 
Epoch 66/1000 
	 loss: 4.8957, MinusLogProbMetric: 4.8957, val_loss: 5.4358, val_MinusLogProbMetric: 5.4358

Epoch 66: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.8957 - MinusLogProbMetric: 4.8957 - val_loss: 5.4358 - val_MinusLogProbMetric: 5.4358 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 67/1000
2023-09-18 13:39:09.407 
Epoch 67/1000 
	 loss: 4.8912, MinusLogProbMetric: 4.8912, val_loss: 5.4582, val_MinusLogProbMetric: 5.4582

Epoch 67: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.8912 - MinusLogProbMetric: 4.8912 - val_loss: 5.4582 - val_MinusLogProbMetric: 5.4582 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 68/1000
2023-09-18 13:39:53.384 
Epoch 68/1000 
	 loss: 4.8837, MinusLogProbMetric: 4.8837, val_loss: 5.4474, val_MinusLogProbMetric: 5.4474

Epoch 68: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.8837 - MinusLogProbMetric: 4.8837 - val_loss: 5.4474 - val_MinusLogProbMetric: 5.4474 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 69/1000
2023-09-18 13:40:37.101 
Epoch 69/1000 
	 loss: 4.8695, MinusLogProbMetric: 4.8695, val_loss: 5.4949, val_MinusLogProbMetric: 5.4949

Epoch 69: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.8695 - MinusLogProbMetric: 4.8695 - val_loss: 5.4949 - val_MinusLogProbMetric: 5.4949 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 70/1000
2023-09-18 13:41:20.817 
Epoch 70/1000 
	 loss: 4.8627, MinusLogProbMetric: 4.8627, val_loss: 5.4635, val_MinusLogProbMetric: 5.4635

Epoch 70: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.8627 - MinusLogProbMetric: 4.8627 - val_loss: 5.4635 - val_MinusLogProbMetric: 5.4635 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 71/1000
2023-09-18 13:42:04.814 
Epoch 71/1000 
	 loss: 4.8541, MinusLogProbMetric: 4.8541, val_loss: 5.5739, val_MinusLogProbMetric: 5.5739

Epoch 71: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.8541 - MinusLogProbMetric: 4.8541 - val_loss: 5.5739 - val_MinusLogProbMetric: 5.5739 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 72/1000
2023-09-18 13:42:48.013 
Epoch 72/1000 
	 loss: 4.8387, MinusLogProbMetric: 4.8387, val_loss: 5.5238, val_MinusLogProbMetric: 5.5238

Epoch 72: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.8387 - MinusLogProbMetric: 4.8387 - val_loss: 5.5238 - val_MinusLogProbMetric: 5.5238 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 73/1000
2023-09-18 13:43:32.005 
Epoch 73/1000 
	 loss: 4.8503, MinusLogProbMetric: 4.8503, val_loss: 5.5196, val_MinusLogProbMetric: 5.5196

Epoch 73: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.8503 - MinusLogProbMetric: 4.8503 - val_loss: 5.5196 - val_MinusLogProbMetric: 5.5196 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 74/1000
2023-09-18 13:44:15.876 
Epoch 74/1000 
	 loss: 4.8539, MinusLogProbMetric: 4.8539, val_loss: 5.5945, val_MinusLogProbMetric: 5.5945

Epoch 74: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.8539 - MinusLogProbMetric: 4.8539 - val_loss: 5.5945 - val_MinusLogProbMetric: 5.5945 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 75/1000
2023-09-18 13:45:00.252 
Epoch 75/1000 
	 loss: 4.8500, MinusLogProbMetric: 4.8500, val_loss: 5.5619, val_MinusLogProbMetric: 5.5619

Epoch 75: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.8500 - MinusLogProbMetric: 4.8500 - val_loss: 5.5619 - val_MinusLogProbMetric: 5.5619 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 76/1000
2023-09-18 13:45:43.163 
Epoch 76/1000 
	 loss: 4.8562, MinusLogProbMetric: 4.8562, val_loss: 5.5208, val_MinusLogProbMetric: 5.5208

Epoch 76: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.8562 - MinusLogProbMetric: 4.8562 - val_loss: 5.5208 - val_MinusLogProbMetric: 5.5208 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 77/1000
2023-09-18 13:46:19.318 
Epoch 77/1000 
	 loss: 4.8284, MinusLogProbMetric: 4.8284, val_loss: 5.5195, val_MinusLogProbMetric: 5.5195

Epoch 77: val_loss did not improve from 5.32644
196/196 - 36s - loss: 4.8284 - MinusLogProbMetric: 4.8284 - val_loss: 5.5195 - val_MinusLogProbMetric: 5.5195 - lr: 0.0010 - 36s/epoch - 184ms/step
Epoch 78/1000
2023-09-18 13:46:54.149 
Epoch 78/1000 
	 loss: 4.8287, MinusLogProbMetric: 4.8287, val_loss: 5.5608, val_MinusLogProbMetric: 5.5608

Epoch 78: val_loss did not improve from 5.32644
196/196 - 35s - loss: 4.8287 - MinusLogProbMetric: 4.8287 - val_loss: 5.5608 - val_MinusLogProbMetric: 5.5608 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 79/1000
2023-09-18 13:47:29.531 
Epoch 79/1000 
	 loss: 4.8209, MinusLogProbMetric: 4.8209, val_loss: 5.5033, val_MinusLogProbMetric: 5.5033

Epoch 79: val_loss did not improve from 5.32644
196/196 - 35s - loss: 4.8209 - MinusLogProbMetric: 4.8209 - val_loss: 5.5033 - val_MinusLogProbMetric: 5.5033 - lr: 0.0010 - 35s/epoch - 181ms/step
Epoch 80/1000
2023-09-18 13:48:04.422 
Epoch 80/1000 
	 loss: 4.8205, MinusLogProbMetric: 4.8205, val_loss: 5.5753, val_MinusLogProbMetric: 5.5753

Epoch 80: val_loss did not improve from 5.32644
196/196 - 35s - loss: 4.8205 - MinusLogProbMetric: 4.8205 - val_loss: 5.5753 - val_MinusLogProbMetric: 5.5753 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 81/1000
2023-09-18 13:48:46.904 
Epoch 81/1000 
	 loss: 4.8184, MinusLogProbMetric: 4.8184, val_loss: 5.5543, val_MinusLogProbMetric: 5.5543

Epoch 81: val_loss did not improve from 5.32644
196/196 - 42s - loss: 4.8184 - MinusLogProbMetric: 4.8184 - val_loss: 5.5543 - val_MinusLogProbMetric: 5.5543 - lr: 0.0010 - 42s/epoch - 217ms/step
Epoch 82/1000
2023-09-18 13:49:31.411 
Epoch 82/1000 
	 loss: 4.8013, MinusLogProbMetric: 4.8013, val_loss: 5.5640, val_MinusLogProbMetric: 5.5640

Epoch 82: val_loss did not improve from 5.32644
196/196 - 45s - loss: 4.8013 - MinusLogProbMetric: 4.8013 - val_loss: 5.5640 - val_MinusLogProbMetric: 5.5640 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 83/1000
2023-09-18 13:50:12.217 
Epoch 83/1000 
	 loss: 4.7894, MinusLogProbMetric: 4.7894, val_loss: 5.6016, val_MinusLogProbMetric: 5.6016

Epoch 83: val_loss did not improve from 5.32644
196/196 - 41s - loss: 4.7894 - MinusLogProbMetric: 4.7894 - val_loss: 5.6016 - val_MinusLogProbMetric: 5.6016 - lr: 0.0010 - 41s/epoch - 208ms/step
Epoch 84/1000
2023-09-18 13:50:47.639 
Epoch 84/1000 
	 loss: 4.7923, MinusLogProbMetric: 4.7923, val_loss: 5.5480, val_MinusLogProbMetric: 5.5480

Epoch 84: val_loss did not improve from 5.32644
196/196 - 35s - loss: 4.7923 - MinusLogProbMetric: 4.7923 - val_loss: 5.5480 - val_MinusLogProbMetric: 5.5480 - lr: 0.0010 - 35s/epoch - 181ms/step
Epoch 85/1000
2023-09-18 13:51:22.999 
Epoch 85/1000 
	 loss: 4.7779, MinusLogProbMetric: 4.7779, val_loss: 5.5332, val_MinusLogProbMetric: 5.5332

Epoch 85: val_loss did not improve from 5.32644
196/196 - 35s - loss: 4.7779 - MinusLogProbMetric: 4.7779 - val_loss: 5.5332 - val_MinusLogProbMetric: 5.5332 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 86/1000
2023-09-18 13:52:00.382 
Epoch 86/1000 
	 loss: 4.7735, MinusLogProbMetric: 4.7735, val_loss: 5.5873, val_MinusLogProbMetric: 5.5873

Epoch 86: val_loss did not improve from 5.32644
196/196 - 37s - loss: 4.7735 - MinusLogProbMetric: 4.7735 - val_loss: 5.5873 - val_MinusLogProbMetric: 5.5873 - lr: 0.0010 - 37s/epoch - 191ms/step
Epoch 87/1000
2023-09-18 13:52:40.109 
Epoch 87/1000 
	 loss: 4.6327, MinusLogProbMetric: 4.6327, val_loss: 5.5513, val_MinusLogProbMetric: 5.5513

Epoch 87: val_loss did not improve from 5.32644
196/196 - 40s - loss: 4.6327 - MinusLogProbMetric: 4.6327 - val_loss: 5.5513 - val_MinusLogProbMetric: 5.5513 - lr: 5.0000e-04 - 40s/epoch - 203ms/step
Epoch 88/1000
2023-09-18 13:53:17.039 
Epoch 88/1000 
	 loss: 4.6101, MinusLogProbMetric: 4.6101, val_loss: 5.5850, val_MinusLogProbMetric: 5.5850

Epoch 88: val_loss did not improve from 5.32644
196/196 - 37s - loss: 4.6101 - MinusLogProbMetric: 4.6101 - val_loss: 5.5850 - val_MinusLogProbMetric: 5.5850 - lr: 5.0000e-04 - 37s/epoch - 188ms/step
Epoch 89/1000
2023-09-18 13:53:58.272 
Epoch 89/1000 
	 loss: 4.6001, MinusLogProbMetric: 4.6001, val_loss: 5.6103, val_MinusLogProbMetric: 5.6103

Epoch 89: val_loss did not improve from 5.32644
196/196 - 41s - loss: 4.6001 - MinusLogProbMetric: 4.6001 - val_loss: 5.6103 - val_MinusLogProbMetric: 5.6103 - lr: 5.0000e-04 - 41s/epoch - 210ms/step
Epoch 90/1000
2023-09-18 13:54:42.387 
Epoch 90/1000 
	 loss: 4.5998, MinusLogProbMetric: 4.5998, val_loss: 5.6084, val_MinusLogProbMetric: 5.6084

Epoch 90: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.5998 - MinusLogProbMetric: 4.5998 - val_loss: 5.6084 - val_MinusLogProbMetric: 5.6084 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 91/1000
2023-09-18 13:55:24.981 
Epoch 91/1000 
	 loss: 4.5892, MinusLogProbMetric: 4.5892, val_loss: 5.6434, val_MinusLogProbMetric: 5.6434

Epoch 91: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.5892 - MinusLogProbMetric: 4.5892 - val_loss: 5.6434 - val_MinusLogProbMetric: 5.6434 - lr: 5.0000e-04 - 43s/epoch - 217ms/step
Epoch 92/1000
2023-09-18 13:56:08.401 
Epoch 92/1000 
	 loss: 4.5778, MinusLogProbMetric: 4.5778, val_loss: 5.6249, val_MinusLogProbMetric: 5.6249

Epoch 92: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.5778 - MinusLogProbMetric: 4.5778 - val_loss: 5.6249 - val_MinusLogProbMetric: 5.6249 - lr: 5.0000e-04 - 43s/epoch - 222ms/step
Epoch 93/1000
2023-09-18 13:56:52.168 
Epoch 93/1000 
	 loss: 4.5833, MinusLogProbMetric: 4.5833, val_loss: 5.6180, val_MinusLogProbMetric: 5.6180

Epoch 93: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.5833 - MinusLogProbMetric: 4.5833 - val_loss: 5.6180 - val_MinusLogProbMetric: 5.6180 - lr: 5.0000e-04 - 44s/epoch - 223ms/step
Epoch 94/1000
2023-09-18 13:57:35.991 
Epoch 94/1000 
	 loss: 4.5730, MinusLogProbMetric: 4.5730, val_loss: 5.7185, val_MinusLogProbMetric: 5.7185

Epoch 94: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.5730 - MinusLogProbMetric: 4.5730 - val_loss: 5.7185 - val_MinusLogProbMetric: 5.7185 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 95/1000
2023-09-18 13:58:19.515 
Epoch 95/1000 
	 loss: 4.5690, MinusLogProbMetric: 4.5690, val_loss: 5.6691, val_MinusLogProbMetric: 5.6691

Epoch 95: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.5690 - MinusLogProbMetric: 4.5690 - val_loss: 5.6691 - val_MinusLogProbMetric: 5.6691 - lr: 5.0000e-04 - 44s/epoch - 222ms/step
Epoch 96/1000
2023-09-18 13:59:03.395 
Epoch 96/1000 
	 loss: 4.5596, MinusLogProbMetric: 4.5596, val_loss: 5.7199, val_MinusLogProbMetric: 5.7199

Epoch 96: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.5596 - MinusLogProbMetric: 4.5596 - val_loss: 5.7199 - val_MinusLogProbMetric: 5.7199 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 97/1000
2023-09-18 13:59:46.344 
Epoch 97/1000 
	 loss: 4.5579, MinusLogProbMetric: 4.5579, val_loss: 5.6954, val_MinusLogProbMetric: 5.6954

Epoch 97: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.5579 - MinusLogProbMetric: 4.5579 - val_loss: 5.6954 - val_MinusLogProbMetric: 5.6954 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 98/1000
2023-09-18 14:00:29.114 
Epoch 98/1000 
	 loss: 4.5559, MinusLogProbMetric: 4.5559, val_loss: 5.7462, val_MinusLogProbMetric: 5.7462

Epoch 98: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.5559 - MinusLogProbMetric: 4.5559 - val_loss: 5.7462 - val_MinusLogProbMetric: 5.7462 - lr: 5.0000e-04 - 43s/epoch - 218ms/step
Epoch 99/1000
2023-09-18 14:01:11.715 
Epoch 99/1000 
	 loss: 4.5475, MinusLogProbMetric: 4.5475, val_loss: 5.7214, val_MinusLogProbMetric: 5.7214

Epoch 99: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.5475 - MinusLogProbMetric: 4.5475 - val_loss: 5.7214 - val_MinusLogProbMetric: 5.7214 - lr: 5.0000e-04 - 43s/epoch - 217ms/step
Epoch 100/1000
2023-09-18 14:01:55.123 
Epoch 100/1000 
	 loss: 4.5462, MinusLogProbMetric: 4.5462, val_loss: 5.8272, val_MinusLogProbMetric: 5.8272

Epoch 100: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.5462 - MinusLogProbMetric: 4.5462 - val_loss: 5.8272 - val_MinusLogProbMetric: 5.8272 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 101/1000
2023-09-18 14:02:38.349 
Epoch 101/1000 
	 loss: 4.5366, MinusLogProbMetric: 4.5366, val_loss: 5.7864, val_MinusLogProbMetric: 5.7864

Epoch 101: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.5366 - MinusLogProbMetric: 4.5366 - val_loss: 5.7864 - val_MinusLogProbMetric: 5.7864 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 102/1000
2023-09-18 14:03:21.620 
Epoch 102/1000 
	 loss: 4.5379, MinusLogProbMetric: 4.5379, val_loss: 5.8046, val_MinusLogProbMetric: 5.8046

Epoch 102: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.5379 - MinusLogProbMetric: 4.5379 - val_loss: 5.8046 - val_MinusLogProbMetric: 5.8046 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 103/1000
2023-09-18 14:04:04.738 
Epoch 103/1000 
	 loss: 4.5348, MinusLogProbMetric: 4.5348, val_loss: 5.7956, val_MinusLogProbMetric: 5.7956

Epoch 103: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.5348 - MinusLogProbMetric: 4.5348 - val_loss: 5.7956 - val_MinusLogProbMetric: 5.7956 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 104/1000
2023-09-18 14:04:48.129 
Epoch 104/1000 
	 loss: 4.5218, MinusLogProbMetric: 4.5218, val_loss: 5.7581, val_MinusLogProbMetric: 5.7581

Epoch 104: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.5218 - MinusLogProbMetric: 4.5218 - val_loss: 5.7581 - val_MinusLogProbMetric: 5.7581 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 105/1000
2023-09-18 14:05:31.704 
Epoch 105/1000 
	 loss: 4.5250, MinusLogProbMetric: 4.5250, val_loss: 5.7722, val_MinusLogProbMetric: 5.7722

Epoch 105: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.5250 - MinusLogProbMetric: 4.5250 - val_loss: 5.7722 - val_MinusLogProbMetric: 5.7722 - lr: 5.0000e-04 - 44s/epoch - 222ms/step
Epoch 106/1000
2023-09-18 14:06:14.411 
Epoch 106/1000 
	 loss: 4.5209, MinusLogProbMetric: 4.5209, val_loss: 5.8264, val_MinusLogProbMetric: 5.8264

Epoch 106: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.5209 - MinusLogProbMetric: 4.5209 - val_loss: 5.8264 - val_MinusLogProbMetric: 5.8264 - lr: 5.0000e-04 - 43s/epoch - 218ms/step
Epoch 107/1000
2023-09-18 14:06:57.869 
Epoch 107/1000 
	 loss: 4.5147, MinusLogProbMetric: 4.5147, val_loss: 5.7564, val_MinusLogProbMetric: 5.7564

Epoch 107: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.5147 - MinusLogProbMetric: 4.5147 - val_loss: 5.7564 - val_MinusLogProbMetric: 5.7564 - lr: 5.0000e-04 - 43s/epoch - 222ms/step
Epoch 108/1000
2023-09-18 14:07:40.873 
Epoch 108/1000 
	 loss: 4.5091, MinusLogProbMetric: 4.5091, val_loss: 5.8051, val_MinusLogProbMetric: 5.8051

Epoch 108: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.5091 - MinusLogProbMetric: 4.5091 - val_loss: 5.8051 - val_MinusLogProbMetric: 5.8051 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 109/1000
2023-09-18 14:08:24.203 
Epoch 109/1000 
	 loss: 4.5117, MinusLogProbMetric: 4.5117, val_loss: 5.8675, val_MinusLogProbMetric: 5.8675

Epoch 109: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.5117 - MinusLogProbMetric: 4.5117 - val_loss: 5.8675 - val_MinusLogProbMetric: 5.8675 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 110/1000
2023-09-18 14:09:07.396 
Epoch 110/1000 
	 loss: 4.5009, MinusLogProbMetric: 4.5009, val_loss: 5.8143, val_MinusLogProbMetric: 5.8143

Epoch 110: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.5009 - MinusLogProbMetric: 4.5009 - val_loss: 5.8143 - val_MinusLogProbMetric: 5.8143 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 111/1000
2023-09-18 14:09:50.596 
Epoch 111/1000 
	 loss: 4.4996, MinusLogProbMetric: 4.4996, val_loss: 5.8293, val_MinusLogProbMetric: 5.8293

Epoch 111: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4996 - MinusLogProbMetric: 4.4996 - val_loss: 5.8293 - val_MinusLogProbMetric: 5.8293 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 112/1000
2023-09-18 14:10:33.503 
Epoch 112/1000 
	 loss: 4.5088, MinusLogProbMetric: 4.5088, val_loss: 5.7386, val_MinusLogProbMetric: 5.7386

Epoch 112: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.5088 - MinusLogProbMetric: 4.5088 - val_loss: 5.7386 - val_MinusLogProbMetric: 5.7386 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 113/1000
2023-09-18 14:11:17.309 
Epoch 113/1000 
	 loss: 4.5086, MinusLogProbMetric: 4.5086, val_loss: 5.8432, val_MinusLogProbMetric: 5.8432

Epoch 113: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.5086 - MinusLogProbMetric: 4.5086 - val_loss: 5.8432 - val_MinusLogProbMetric: 5.8432 - lr: 5.0000e-04 - 44s/epoch - 223ms/step
Epoch 114/1000
2023-09-18 14:12:00.287 
Epoch 114/1000 
	 loss: 4.4859, MinusLogProbMetric: 4.4859, val_loss: 5.8427, val_MinusLogProbMetric: 5.8427

Epoch 114: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4859 - MinusLogProbMetric: 4.4859 - val_loss: 5.8427 - val_MinusLogProbMetric: 5.8427 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 115/1000
2023-09-18 14:12:42.950 
Epoch 115/1000 
	 loss: 4.4755, MinusLogProbMetric: 4.4755, val_loss: 5.8166, val_MinusLogProbMetric: 5.8166

Epoch 115: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4755 - MinusLogProbMetric: 4.4755 - val_loss: 5.8166 - val_MinusLogProbMetric: 5.8166 - lr: 5.0000e-04 - 43s/epoch - 218ms/step
Epoch 116/1000
2023-09-18 14:13:24.904 
Epoch 116/1000 
	 loss: 4.4779, MinusLogProbMetric: 4.4779, val_loss: 5.9455, val_MinusLogProbMetric: 5.9455

Epoch 116: val_loss did not improve from 5.32644
196/196 - 42s - loss: 4.4779 - MinusLogProbMetric: 4.4779 - val_loss: 5.9455 - val_MinusLogProbMetric: 5.9455 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 117/1000
2023-09-18 14:14:08.434 
Epoch 117/1000 
	 loss: 4.4747, MinusLogProbMetric: 4.4747, val_loss: 5.9018, val_MinusLogProbMetric: 5.9018

Epoch 117: val_loss did not improve from 5.32644
196/196 - 44s - loss: 4.4747 - MinusLogProbMetric: 4.4747 - val_loss: 5.9018 - val_MinusLogProbMetric: 5.9018 - lr: 5.0000e-04 - 44s/epoch - 222ms/step
Epoch 118/1000
2023-09-18 14:14:51.605 
Epoch 118/1000 
	 loss: 4.4710, MinusLogProbMetric: 4.4710, val_loss: 5.8713, val_MinusLogProbMetric: 5.8713

Epoch 118: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4710 - MinusLogProbMetric: 4.4710 - val_loss: 5.8713 - val_MinusLogProbMetric: 5.8713 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 119/1000
2023-09-18 14:15:34.778 
Epoch 119/1000 
	 loss: 4.4589, MinusLogProbMetric: 4.4589, val_loss: 5.9029, val_MinusLogProbMetric: 5.9029

Epoch 119: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4589 - MinusLogProbMetric: 4.4589 - val_loss: 5.9029 - val_MinusLogProbMetric: 5.9029 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 120/1000
2023-09-18 14:16:17.939 
Epoch 120/1000 
	 loss: 4.4571, MinusLogProbMetric: 4.4571, val_loss: 5.9671, val_MinusLogProbMetric: 5.9671

Epoch 120: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4571 - MinusLogProbMetric: 4.4571 - val_loss: 5.9671 - val_MinusLogProbMetric: 5.9671 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 121/1000
2023-09-18 14:17:01.074 
Epoch 121/1000 
	 loss: 4.4545, MinusLogProbMetric: 4.4545, val_loss: 5.9749, val_MinusLogProbMetric: 5.9749

Epoch 121: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4545 - MinusLogProbMetric: 4.4545 - val_loss: 5.9749 - val_MinusLogProbMetric: 5.9749 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 122/1000
2023-09-18 14:17:44.180 
Epoch 122/1000 
	 loss: 4.4454, MinusLogProbMetric: 4.4454, val_loss: 5.9369, val_MinusLogProbMetric: 5.9369

Epoch 122: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4454 - MinusLogProbMetric: 4.4454 - val_loss: 5.9369 - val_MinusLogProbMetric: 5.9369 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 123/1000
2023-09-18 14:18:27.514 
Epoch 123/1000 
	 loss: 4.4516, MinusLogProbMetric: 4.4516, val_loss: 5.9854, val_MinusLogProbMetric: 5.9854

Epoch 123: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4516 - MinusLogProbMetric: 4.4516 - val_loss: 5.9854 - val_MinusLogProbMetric: 5.9854 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 124/1000
2023-09-18 14:19:10.867 
Epoch 124/1000 
	 loss: 4.4515, MinusLogProbMetric: 4.4515, val_loss: 5.9205, val_MinusLogProbMetric: 5.9205

Epoch 124: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4515 - MinusLogProbMetric: 4.4515 - val_loss: 5.9205 - val_MinusLogProbMetric: 5.9205 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 125/1000
2023-09-18 14:19:54.293 
Epoch 125/1000 
	 loss: 4.4538, MinusLogProbMetric: 4.4538, val_loss: 6.0390, val_MinusLogProbMetric: 6.0390

Epoch 125: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4538 - MinusLogProbMetric: 4.4538 - val_loss: 6.0390 - val_MinusLogProbMetric: 6.0390 - lr: 5.0000e-04 - 43s/epoch - 222ms/step
Epoch 126/1000
2023-09-18 14:20:37.408 
Epoch 126/1000 
	 loss: 4.4473, MinusLogProbMetric: 4.4473, val_loss: 5.9123, val_MinusLogProbMetric: 5.9123

Epoch 126: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4473 - MinusLogProbMetric: 4.4473 - val_loss: 5.9123 - val_MinusLogProbMetric: 5.9123 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 127/1000
2023-09-18 14:21:20.361 
Epoch 127/1000 
	 loss: 4.4254, MinusLogProbMetric: 4.4254, val_loss: 6.1268, val_MinusLogProbMetric: 6.1268

Epoch 127: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4254 - MinusLogProbMetric: 4.4254 - val_loss: 6.1268 - val_MinusLogProbMetric: 6.1268 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 128/1000
2023-09-18 14:22:03.816 
Epoch 128/1000 
	 loss: 4.4320, MinusLogProbMetric: 4.4320, val_loss: 5.9617, val_MinusLogProbMetric: 5.9617

Epoch 128: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4320 - MinusLogProbMetric: 4.4320 - val_loss: 5.9617 - val_MinusLogProbMetric: 5.9617 - lr: 5.0000e-04 - 43s/epoch - 222ms/step
Epoch 129/1000
2023-09-18 14:22:46.689 
Epoch 129/1000 
	 loss: 4.4313, MinusLogProbMetric: 4.4313, val_loss: 5.9581, val_MinusLogProbMetric: 5.9581

Epoch 129: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4313 - MinusLogProbMetric: 4.4313 - val_loss: 5.9581 - val_MinusLogProbMetric: 5.9581 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 130/1000
2023-09-18 14:23:29.910 
Epoch 130/1000 
	 loss: 4.4127, MinusLogProbMetric: 4.4127, val_loss: 6.0216, val_MinusLogProbMetric: 6.0216

Epoch 130: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4127 - MinusLogProbMetric: 4.4127 - val_loss: 6.0216 - val_MinusLogProbMetric: 6.0216 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 131/1000
2023-09-18 14:24:12.580 
Epoch 131/1000 
	 loss: 4.4298, MinusLogProbMetric: 4.4298, val_loss: 5.9010, val_MinusLogProbMetric: 5.9010

Epoch 131: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4298 - MinusLogProbMetric: 4.4298 - val_loss: 5.9010 - val_MinusLogProbMetric: 5.9010 - lr: 5.0000e-04 - 43s/epoch - 218ms/step
Epoch 132/1000
2023-09-18 14:24:55.267 
Epoch 132/1000 
	 loss: 4.4278, MinusLogProbMetric: 4.4278, val_loss: 5.9591, val_MinusLogProbMetric: 5.9591

Epoch 132: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4278 - MinusLogProbMetric: 4.4278 - val_loss: 5.9591 - val_MinusLogProbMetric: 5.9591 - lr: 5.0000e-04 - 43s/epoch - 218ms/step
Epoch 133/1000
2023-09-18 14:25:37.841 
Epoch 133/1000 
	 loss: 4.4235, MinusLogProbMetric: 4.4235, val_loss: 6.1350, val_MinusLogProbMetric: 6.1350

Epoch 133: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4235 - MinusLogProbMetric: 4.4235 - val_loss: 6.1350 - val_MinusLogProbMetric: 6.1350 - lr: 5.0000e-04 - 43s/epoch - 217ms/step
Epoch 134/1000
2023-09-18 14:26:20.751 
Epoch 134/1000 
	 loss: 4.4070, MinusLogProbMetric: 4.4070, val_loss: 6.0865, val_MinusLogProbMetric: 6.0865

Epoch 134: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4070 - MinusLogProbMetric: 4.4070 - val_loss: 6.0865 - val_MinusLogProbMetric: 6.0865 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 135/1000
2023-09-18 14:27:03.542 
Epoch 135/1000 
	 loss: 4.4284, MinusLogProbMetric: 4.4284, val_loss: 5.9956, val_MinusLogProbMetric: 5.9956

Epoch 135: val_loss did not improve from 5.32644
196/196 - 43s - loss: 4.4284 - MinusLogProbMetric: 4.4284 - val_loss: 5.9956 - val_MinusLogProbMetric: 5.9956 - lr: 5.0000e-04 - 43s/epoch - 218ms/step
Epoch 136/1000
2023-09-18 14:27:46.430 
Epoch 136/1000 
	 loss: 4.3997, MinusLogProbMetric: 4.3997, val_loss: 6.0538, val_MinusLogProbMetric: 6.0538

Epoch 136: val_loss did not improve from 5.32644
Restoring model weights from the end of the best epoch: 36.
196/196 - 43s - loss: 4.3997 - MinusLogProbMetric: 4.3997 - val_loss: 6.0538 - val_MinusLogProbMetric: 6.0538 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 136: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 20.880213746102527 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 11.159954191884026 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 7.815598387038335 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7faeac9996c0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 29.760062650078908 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 13.767093130154535 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 9.090378931025043 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fafb4facee0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 440.
Model trained in 5964.84 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/c_Main_CsplineN.py , Line : 468, Func.Name : prediction_function, Message : X_data_nf: tf.Tensor = DataInputs.dist_2_num[:nsamples_test] # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 95.22 s.
===========
Run 188/720 done in 6064.50 s.
===========

Directory ../../results/CsplineN_new/run_189/ already exists.
Skipping it.
===========
Run 189/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_190/ already exists.
Skipping it.
===========
Run 190/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_191/ already exists.
Skipping it.
===========
Run 191/720 already exists. Skipping it.
===========

===========
Generating train data for run 192.
===========
Train data generated in 0.12 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 16)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_192/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 440}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_192/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.9388056 ,  6.6011305 ,  7.1936936 , ...,  9.376897  ,
        -0.20441407,  0.997946  ],
       [ 5.7592807 ,  7.4562755 ,  6.073807  , ...,  8.982617  ,
         1.3178213 ,  0.7693994 ],
       [ 4.825065  ,  5.849577  ,  0.14626749, ...,  6.3837705 ,
         2.132065  ,  1.518469  ],
       ...,
       [ 5.615609  ,  7.2656503 ,  4.8600593 , ...,  9.083482  ,
         0.68300927,  1.0057955 ],
       [ 4.1834145 ,  6.0909553 ,  0.23574165, ...,  7.763974  ,
         1.9834036 ,  1.2137753 ],
       [ 3.9210687 ,  6.0211887 ,  0.28002483, ...,  6.9610376 ,
         1.7232312 ,  1.247894  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_192/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_192
self.data_kwargs: {'seed': 440}
self.x_data: [[5.9069815  7.5444255  6.3762054  ... 9.075856   0.9364161  0.80815375]
 [4.741565   5.111489   0.30516613 ... 6.3444896  2.1198235  1.1959152 ]
 [5.3968034  7.4016695  5.7313123  ... 9.37714    0.68808633 0.8965562 ]
 ...
 [5.630116   6.508466   4.560816   ... 9.354164   0.5113934  0.8420493 ]
 [3.8550687  6.072236   0.15075347 ... 6.0798836  1.9062192  1.6859822 ]
 [5.6194196  7.5907955  5.8847475  ... 9.269651   0.46180454 0.8692333 ]]
self.y_data: []
self.ndims: 16
Model defined.
Model: "model_157"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_158 (InputLayer)      [(None, 16)]              0         
                                                                 
 log_prob_layer_17 (LogProbL  (None,)                  2058480   
 ayer)                                                           
                                                                 
=================================================================
Total params: 2,058,480
Trainable params: 2,058,480
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_17/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_17'")
self.model: <keras.engine.functional.Functional object at 0x7fad2013b790>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fad2017dc00>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fad2017dc00>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fada841f8e0>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7faf402df9a0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_192/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7faf402dff10>, <keras.callbacks.ModelCheckpoint object at 0x7faf402dffd0>, <keras.callbacks.EarlyStopping object at 0x7faf402dfee0>, <keras.callbacks.ReduceLROnPlateau object at 0x7faf402dfeb0>, <keras.callbacks.TerminateOnNaN object at 0x7faf4025c280>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.9388056 ,  6.6011305 ,  7.1936936 , ...,  9.376897  ,
        -0.20441407,  0.997946  ],
       [ 5.7592807 ,  7.4562755 ,  6.073807  , ...,  8.982617  ,
         1.3178213 ,  0.7693994 ],
       [ 4.825065  ,  5.849577  ,  0.14626749, ...,  6.3837705 ,
         2.132065  ,  1.518469  ],
       ...,
       [ 5.615609  ,  7.2656503 ,  4.8600593 , ...,  9.083482  ,
         0.68300927,  1.0057955 ],
       [ 4.1834145 ,  6.0909553 ,  0.23574165, ...,  7.763974  ,
         1.9834036 ,  1.2137753 ],
       [ 3.9210687 ,  6.0211887 ,  0.28002483, ...,  6.9610376 ,
         1.7232312 ,  1.247894  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_192/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 192/720 with hyperparameters:
timestamp = 2023-09-18 14:29:32.795469
ndims = 16
seed_train = 440
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 2058480
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [5.9069815  7.5444255  6.3762054  5.732217   4.629946   6.4001193
 4.3642464  8.792809   9.021455   4.047819   7.801147   5.4133105
 5.6628323  9.075856   0.9364161  0.80815375]
Epoch 1/1000
2023-09-18 14:34:10.397 
Epoch 1/1000 
	 loss: 24.0279, MinusLogProbMetric: 24.0279, val_loss: 8.8701, val_MinusLogProbMetric: 8.8701

Epoch 1: val_loss improved from inf to 8.87008, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_192/weights/best_weights.h5
196/196 - 279s - loss: 24.0279 - MinusLogProbMetric: 24.0279 - val_loss: 8.8701 - val_MinusLogProbMetric: 8.8701 - lr: 0.0010 - 279s/epoch - 1s/step
Epoch 2/1000
2023-09-18 14:35:35.820 
Epoch 2/1000 
	 loss: 8.6372, MinusLogProbMetric: 8.6372, val_loss: 7.0480, val_MinusLogProbMetric: 7.0480

Epoch 2: val_loss improved from 8.87008 to 7.04805, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_192/weights/best_weights.h5
196/196 - 85s - loss: 8.6372 - MinusLogProbMetric: 8.6372 - val_loss: 7.0480 - val_MinusLogProbMetric: 7.0480 - lr: 0.0010 - 85s/epoch - 432ms/step
Epoch 3/1000
2023-09-18 14:36:59.391 
Epoch 3/1000 
	 loss: 6.9355, MinusLogProbMetric: 6.9355, val_loss: 6.6562, val_MinusLogProbMetric: 6.6562

Epoch 3: val_loss improved from 7.04805 to 6.65616, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_192/weights/best_weights.h5
196/196 - 84s - loss: 6.9355 - MinusLogProbMetric: 6.9355 - val_loss: 6.6562 - val_MinusLogProbMetric: 6.6562 - lr: 0.0010 - 84s/epoch - 428ms/step
Epoch 4/1000
2023-09-18 14:38:23.329 
Epoch 4/1000 
	 loss: 6.4120, MinusLogProbMetric: 6.4120, val_loss: 6.2686, val_MinusLogProbMetric: 6.2686

Epoch 4: val_loss improved from 6.65616 to 6.26864, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_192/weights/best_weights.h5
196/196 - 84s - loss: 6.4120 - MinusLogProbMetric: 6.4120 - val_loss: 6.2686 - val_MinusLogProbMetric: 6.2686 - lr: 0.0010 - 84s/epoch - 428ms/step
Epoch 5/1000
2023-09-18 14:39:48.426 
Epoch 5/1000 
	 loss: 6.2521, MinusLogProbMetric: 6.2521, val_loss: 6.1163, val_MinusLogProbMetric: 6.1163

Epoch 5: val_loss improved from 6.26864 to 6.11631, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_192/weights/best_weights.h5
196/196 - 85s - loss: 6.2521 - MinusLogProbMetric: 6.2521 - val_loss: 6.1163 - val_MinusLogProbMetric: 6.1163 - lr: 0.0010 - 85s/epoch - 435ms/step
Epoch 6/1000
2023-09-18 14:41:12.475 
Epoch 6/1000 
	 loss: 6.0043, MinusLogProbMetric: 6.0043, val_loss: 6.0044, val_MinusLogProbMetric: 6.0044

Epoch 6: val_loss improved from 6.11631 to 6.00442, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_192/weights/best_weights.h5
196/196 - 84s - loss: 6.0043 - MinusLogProbMetric: 6.0043 - val_loss: 6.0044 - val_MinusLogProbMetric: 6.0044 - lr: 0.0010 - 84s/epoch - 427ms/step
Epoch 7/1000
2023-09-18 14:42:37.131 
Epoch 7/1000 
	 loss: 5.8908, MinusLogProbMetric: 5.8908, val_loss: 5.8195, val_MinusLogProbMetric: 5.8195

Epoch 7: val_loss improved from 6.00442 to 5.81947, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_192/weights/best_weights.h5
196/196 - 85s - loss: 5.8908 - MinusLogProbMetric: 5.8908 - val_loss: 5.8195 - val_MinusLogProbMetric: 5.8195 - lr: 0.0010 - 85s/epoch - 433ms/step
Epoch 8/1000
2023-09-18 14:44:01.356 
Epoch 8/1000 
	 loss: 5.7803, MinusLogProbMetric: 5.7803, val_loss: 5.9565, val_MinusLogProbMetric: 5.9565

Epoch 8: val_loss did not improve from 5.81947
196/196 - 83s - loss: 5.7803 - MinusLogProbMetric: 5.7803 - val_loss: 5.9565 - val_MinusLogProbMetric: 5.9565 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 9/1000
2023-09-18 14:45:24.138 
Epoch 9/1000 
	 loss: 5.6537, MinusLogProbMetric: 5.6537, val_loss: 5.7644, val_MinusLogProbMetric: 5.7644

Epoch 9: val_loss improved from 5.81947 to 5.76441, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_192/weights/best_weights.h5
196/196 - 84s - loss: 5.6537 - MinusLogProbMetric: 5.6537 - val_loss: 5.7644 - val_MinusLogProbMetric: 5.7644 - lr: 0.0010 - 84s/epoch - 430ms/step
Epoch 10/1000
2023-09-18 14:46:48.550 
Epoch 10/1000 
	 loss: 5.6402, MinusLogProbMetric: 5.6402, val_loss: 6.3271, val_MinusLogProbMetric: 6.3271

Epoch 10: val_loss did not improve from 5.76441
196/196 - 83s - loss: 5.6402 - MinusLogProbMetric: 5.6402 - val_loss: 6.3271 - val_MinusLogProbMetric: 6.3271 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 11/1000
2023-09-18 14:48:11.356 
Epoch 11/1000 
	 loss: 5.5904, MinusLogProbMetric: 5.5904, val_loss: 5.6235, val_MinusLogProbMetric: 5.6235

Epoch 11: val_loss improved from 5.76441 to 5.62346, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_192/weights/best_weights.h5
196/196 - 84s - loss: 5.5904 - MinusLogProbMetric: 5.5904 - val_loss: 5.6235 - val_MinusLogProbMetric: 5.6235 - lr: 0.0010 - 84s/epoch - 430ms/step
Epoch 12/1000
2023-09-18 14:49:35.994 
Epoch 12/1000 
	 loss: 5.6208, MinusLogProbMetric: 5.6208, val_loss: 5.8116, val_MinusLogProbMetric: 5.8116

Epoch 12: val_loss did not improve from 5.62346
196/196 - 83s - loss: 5.6208 - MinusLogProbMetric: 5.6208 - val_loss: 5.8116 - val_MinusLogProbMetric: 5.8116 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 13/1000
2023-09-18 14:50:58.403 
Epoch 13/1000 
	 loss: 5.4435, MinusLogProbMetric: 5.4435, val_loss: 5.6280, val_MinusLogProbMetric: 5.6280

Epoch 13: val_loss did not improve from 5.62346
196/196 - 82s - loss: 5.4435 - MinusLogProbMetric: 5.4435 - val_loss: 5.6280 - val_MinusLogProbMetric: 5.6280 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 14/1000
2023-09-18 14:52:20.698 
Epoch 14/1000 
	 loss: 5.4490, MinusLogProbMetric: 5.4490, val_loss: 5.5252, val_MinusLogProbMetric: 5.5252

Epoch 14: val_loss improved from 5.62346 to 5.52521, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_192/weights/best_weights.h5
196/196 - 84s - loss: 5.4490 - MinusLogProbMetric: 5.4490 - val_loss: 5.5252 - val_MinusLogProbMetric: 5.5252 - lr: 0.0010 - 84s/epoch - 428ms/step
Epoch 15/1000
2023-09-18 14:53:45.249 
Epoch 15/1000 
	 loss: 5.3860, MinusLogProbMetric: 5.3860, val_loss: 5.4991, val_MinusLogProbMetric: 5.4991

Epoch 15: val_loss improved from 5.52521 to 5.49907, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_192/weights/best_weights.h5
196/196 - 85s - loss: 5.3860 - MinusLogProbMetric: 5.3860 - val_loss: 5.4991 - val_MinusLogProbMetric: 5.4991 - lr: 0.0010 - 85s/epoch - 431ms/step
Epoch 16/1000
2023-09-18 14:55:08.924 
Epoch 16/1000 
	 loss: 5.3918, MinusLogProbMetric: 5.3918, val_loss: 5.9689, val_MinusLogProbMetric: 5.9689

Epoch 16: val_loss did not improve from 5.49907
196/196 - 82s - loss: 5.3918 - MinusLogProbMetric: 5.3918 - val_loss: 5.9689 - val_MinusLogProbMetric: 5.9689 - lr: 0.0010 - 82s/epoch - 419ms/step
Epoch 17/1000
2023-09-18 14:56:31.912 
Epoch 17/1000 
	 loss: 5.3985, MinusLogProbMetric: 5.3985, val_loss: 5.6442, val_MinusLogProbMetric: 5.6442

Epoch 17: val_loss did not improve from 5.49907
196/196 - 83s - loss: 5.3985 - MinusLogProbMetric: 5.3985 - val_loss: 5.6442 - val_MinusLogProbMetric: 5.6442 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 18/1000
2023-09-18 14:57:55.133 
Epoch 18/1000 
	 loss: 5.3509, MinusLogProbMetric: 5.3509, val_loss: 5.4873, val_MinusLogProbMetric: 5.4873

Epoch 18: val_loss improved from 5.49907 to 5.48727, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_192/weights/best_weights.h5
196/196 - 85s - loss: 5.3509 - MinusLogProbMetric: 5.3509 - val_loss: 5.4873 - val_MinusLogProbMetric: 5.4873 - lr: 0.0010 - 85s/epoch - 432ms/step
Epoch 19/1000
2023-09-18 14:59:19.400 
Epoch 19/1000 
	 loss: 5.3330, MinusLogProbMetric: 5.3330, val_loss: 5.4667, val_MinusLogProbMetric: 5.4667

Epoch 19: val_loss improved from 5.48727 to 5.46665, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_192/weights/best_weights.h5
196/196 - 84s - loss: 5.3330 - MinusLogProbMetric: 5.3330 - val_loss: 5.4667 - val_MinusLogProbMetric: 5.4667 - lr: 0.0010 - 84s/epoch - 430ms/step
Epoch 20/1000
2023-09-18 15:00:43.080 
Epoch 20/1000 
	 loss: 5.3221, MinusLogProbMetric: 5.3221, val_loss: 5.7185, val_MinusLogProbMetric: 5.7185

Epoch 20: val_loss did not improve from 5.46665
196/196 - 82s - loss: 5.3221 - MinusLogProbMetric: 5.3221 - val_loss: 5.7185 - val_MinusLogProbMetric: 5.7185 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 21/1000
2023-09-18 15:02:05.502 
Epoch 21/1000 
	 loss: 5.2895, MinusLogProbMetric: 5.2895, val_loss: 5.6207, val_MinusLogProbMetric: 5.6207

Epoch 21: val_loss did not improve from 5.46665
196/196 - 82s - loss: 5.2895 - MinusLogProbMetric: 5.2895 - val_loss: 5.6207 - val_MinusLogProbMetric: 5.6207 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 22/1000
2023-09-18 15:03:27.343 
Epoch 22/1000 
	 loss: 5.2699, MinusLogProbMetric: 5.2699, val_loss: 5.7731, val_MinusLogProbMetric: 5.7731

Epoch 22: val_loss did not improve from 5.46665
196/196 - 82s - loss: 5.2699 - MinusLogProbMetric: 5.2699 - val_loss: 5.7731 - val_MinusLogProbMetric: 5.7731 - lr: 0.0010 - 82s/epoch - 418ms/step
Epoch 23/1000
2023-09-18 15:04:50.243 
Epoch 23/1000 
	 loss: 5.2369, MinusLogProbMetric: 5.2369, val_loss: 5.8302, val_MinusLogProbMetric: 5.8302

Epoch 23: val_loss did not improve from 5.46665
196/196 - 83s - loss: 5.2369 - MinusLogProbMetric: 5.2369 - val_loss: 5.8302 - val_MinusLogProbMetric: 5.8302 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 24/1000
2023-09-18 15:06:13.174 
Epoch 24/1000 
	 loss: 5.2181, MinusLogProbMetric: 5.2181, val_loss: 5.5202, val_MinusLogProbMetric: 5.5202

Epoch 24: val_loss did not improve from 5.46665
196/196 - 83s - loss: 5.2181 - MinusLogProbMetric: 5.2181 - val_loss: 5.5202 - val_MinusLogProbMetric: 5.5202 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 25/1000
2023-09-18 15:07:36.056 
Epoch 25/1000 
	 loss: 5.2265, MinusLogProbMetric: 5.2265, val_loss: 5.5616, val_MinusLogProbMetric: 5.5616

Epoch 25: val_loss did not improve from 5.46665
196/196 - 83s - loss: 5.2265 - MinusLogProbMetric: 5.2265 - val_loss: 5.5616 - val_MinusLogProbMetric: 5.5616 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 26/1000
2023-09-18 15:08:59.078 
Epoch 26/1000 
	 loss: 5.1569, MinusLogProbMetric: 5.1569, val_loss: 5.4229, val_MinusLogProbMetric: 5.4229

Epoch 26: val_loss improved from 5.46665 to 5.42294, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_192/weights/best_weights.h5
196/196 - 85s - loss: 5.1569 - MinusLogProbMetric: 5.1569 - val_loss: 5.4229 - val_MinusLogProbMetric: 5.4229 - lr: 0.0010 - 85s/epoch - 432ms/step
Epoch 27/1000
2023-09-18 15:10:24.052 
Epoch 27/1000 
	 loss: 5.1912, MinusLogProbMetric: 5.1912, val_loss: 5.4239, val_MinusLogProbMetric: 5.4239

Epoch 27: val_loss did not improve from 5.42294
196/196 - 83s - loss: 5.1912 - MinusLogProbMetric: 5.1912 - val_loss: 5.4239 - val_MinusLogProbMetric: 5.4239 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 28/1000
2023-09-18 15:11:46.601 
Epoch 28/1000 
	 loss: 5.1731, MinusLogProbMetric: 5.1731, val_loss: 5.5071, val_MinusLogProbMetric: 5.5071

Epoch 28: val_loss did not improve from 5.42294
196/196 - 83s - loss: 5.1731 - MinusLogProbMetric: 5.1731 - val_loss: 5.5071 - val_MinusLogProbMetric: 5.5071 - lr: 0.0010 - 83s/epoch - 421ms/step
Epoch 29/1000
2023-09-18 15:13:09.193 
Epoch 29/1000 
	 loss: 5.1354, MinusLogProbMetric: 5.1354, val_loss: 5.7820, val_MinusLogProbMetric: 5.7820

Epoch 29: val_loss did not improve from 5.42294
196/196 - 83s - loss: 5.1354 - MinusLogProbMetric: 5.1354 - val_loss: 5.7820 - val_MinusLogProbMetric: 5.7820 - lr: 0.0010 - 83s/epoch - 421ms/step
Epoch 30/1000
2023-09-18 15:14:31.384 
Epoch 30/1000 
	 loss: 5.1396, MinusLogProbMetric: 5.1396, val_loss: 5.3702, val_MinusLogProbMetric: 5.3702

Epoch 30: val_loss improved from 5.42294 to 5.37020, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_192/weights/best_weights.h5
196/196 - 84s - loss: 5.1396 - MinusLogProbMetric: 5.1396 - val_loss: 5.3702 - val_MinusLogProbMetric: 5.3702 - lr: 0.0010 - 84s/epoch - 427ms/step
Epoch 31/1000
2023-09-18 15:15:54.882 
Epoch 31/1000 
	 loss: 5.1362, MinusLogProbMetric: 5.1362, val_loss: 5.3317, val_MinusLogProbMetric: 5.3317

Epoch 31: val_loss improved from 5.37020 to 5.33165, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_192/weights/best_weights.h5
196/196 - 83s - loss: 5.1362 - MinusLogProbMetric: 5.1362 - val_loss: 5.3317 - val_MinusLogProbMetric: 5.3317 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 32/1000
2023-09-18 15:17:18.390 
Epoch 32/1000 
	 loss: 5.1267, MinusLogProbMetric: 5.1267, val_loss: 5.5262, val_MinusLogProbMetric: 5.5262

Epoch 32: val_loss did not improve from 5.33165
196/196 - 82s - loss: 5.1267 - MinusLogProbMetric: 5.1267 - val_loss: 5.5262 - val_MinusLogProbMetric: 5.5262 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 33/1000
2023-09-18 15:18:40.992 
Epoch 33/1000 
	 loss: 5.1281, MinusLogProbMetric: 5.1281, val_loss: 5.4145, val_MinusLogProbMetric: 5.4145

Epoch 33: val_loss did not improve from 5.33165
196/196 - 83s - loss: 5.1281 - MinusLogProbMetric: 5.1281 - val_loss: 5.4145 - val_MinusLogProbMetric: 5.4145 - lr: 0.0010 - 83s/epoch - 421ms/step
Epoch 34/1000
2023-09-18 15:20:03.045 
Epoch 34/1000 
	 loss: 5.1077, MinusLogProbMetric: 5.1077, val_loss: 5.3522, val_MinusLogProbMetric: 5.3522

Epoch 34: val_loss did not improve from 5.33165
196/196 - 82s - loss: 5.1077 - MinusLogProbMetric: 5.1077 - val_loss: 5.3522 - val_MinusLogProbMetric: 5.3522 - lr: 0.0010 - 82s/epoch - 419ms/step
Epoch 35/1000
2023-09-18 15:21:24.953 
Epoch 35/1000 
	 loss: 5.0668, MinusLogProbMetric: 5.0668, val_loss: 5.4874, val_MinusLogProbMetric: 5.4874

Epoch 35: val_loss did not improve from 5.33165
196/196 - 82s - loss: 5.0668 - MinusLogProbMetric: 5.0668 - val_loss: 5.4874 - val_MinusLogProbMetric: 5.4874 - lr: 0.0010 - 82s/epoch - 418ms/step
Epoch 36/1000
2023-09-18 15:22:47.021 
Epoch 36/1000 
	 loss: 5.0878, MinusLogProbMetric: 5.0878, val_loss: 5.5572, val_MinusLogProbMetric: 5.5572

Epoch 36: val_loss did not improve from 5.33165
196/196 - 82s - loss: 5.0878 - MinusLogProbMetric: 5.0878 - val_loss: 5.5572 - val_MinusLogProbMetric: 5.5572 - lr: 0.0010 - 82s/epoch - 419ms/step
Epoch 37/1000
2023-09-18 15:24:09.377 
Epoch 37/1000 
	 loss: 5.0440, MinusLogProbMetric: 5.0440, val_loss: 5.4717, val_MinusLogProbMetric: 5.4717

Epoch 37: val_loss did not improve from 5.33165
196/196 - 82s - loss: 5.0440 - MinusLogProbMetric: 5.0440 - val_loss: 5.4717 - val_MinusLogProbMetric: 5.4717 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 38/1000
2023-09-18 15:25:30.552 
Epoch 38/1000 
	 loss: 5.0422, MinusLogProbMetric: 5.0422, val_loss: 5.4511, val_MinusLogProbMetric: 5.4511

Epoch 38: val_loss did not improve from 5.33165
196/196 - 81s - loss: 5.0422 - MinusLogProbMetric: 5.0422 - val_loss: 5.4511 - val_MinusLogProbMetric: 5.4511 - lr: 0.0010 - 81s/epoch - 414ms/step
Epoch 39/1000
2023-09-18 15:26:52.892 
Epoch 39/1000 
	 loss: 5.0261, MinusLogProbMetric: 5.0261, val_loss: 5.4887, val_MinusLogProbMetric: 5.4887

Epoch 39: val_loss did not improve from 5.33165
196/196 - 82s - loss: 5.0261 - MinusLogProbMetric: 5.0261 - val_loss: 5.4887 - val_MinusLogProbMetric: 5.4887 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 40/1000
2023-09-18 15:28:14.897 
Epoch 40/1000 
	 loss: 5.0280, MinusLogProbMetric: 5.0280, val_loss: 5.6645, val_MinusLogProbMetric: 5.6645

Epoch 40: val_loss did not improve from 5.33165
196/196 - 82s - loss: 5.0280 - MinusLogProbMetric: 5.0280 - val_loss: 5.6645 - val_MinusLogProbMetric: 5.6645 - lr: 0.0010 - 82s/epoch - 418ms/step
Epoch 41/1000
2023-09-18 15:29:36.576 
Epoch 41/1000 
	 loss: 5.0172, MinusLogProbMetric: 5.0172, val_loss: 5.3797, val_MinusLogProbMetric: 5.3797

Epoch 41: val_loss did not improve from 5.33165
196/196 - 82s - loss: 5.0172 - MinusLogProbMetric: 5.0172 - val_loss: 5.3797 - val_MinusLogProbMetric: 5.3797 - lr: 0.0010 - 82s/epoch - 417ms/step
Epoch 42/1000
2023-09-18 15:30:58.038 
Epoch 42/1000 
	 loss: 5.0170, MinusLogProbMetric: 5.0170, val_loss: 5.4300, val_MinusLogProbMetric: 5.4300

Epoch 42: val_loss did not improve from 5.33165
196/196 - 81s - loss: 5.0170 - MinusLogProbMetric: 5.0170 - val_loss: 5.4300 - val_MinusLogProbMetric: 5.4300 - lr: 0.0010 - 81s/epoch - 416ms/step
Epoch 43/1000
2023-09-18 15:32:19.927 
Epoch 43/1000 
	 loss: 5.0011, MinusLogProbMetric: 5.0011, val_loss: 5.4538, val_MinusLogProbMetric: 5.4538

Epoch 43: val_loss did not improve from 5.33165
196/196 - 82s - loss: 5.0011 - MinusLogProbMetric: 5.0011 - val_loss: 5.4538 - val_MinusLogProbMetric: 5.4538 - lr: 0.0010 - 82s/epoch - 418ms/step
Epoch 44/1000
2023-09-18 15:33:41.523 
Epoch 44/1000 
	 loss: 5.0001, MinusLogProbMetric: 5.0001, val_loss: 5.3823, val_MinusLogProbMetric: 5.3823

Epoch 44: val_loss did not improve from 5.33165
196/196 - 82s - loss: 5.0001 - MinusLogProbMetric: 5.0001 - val_loss: 5.3823 - val_MinusLogProbMetric: 5.3823 - lr: 0.0010 - 82s/epoch - 416ms/step
Epoch 45/1000
2023-09-18 15:35:03.843 
Epoch 45/1000 
	 loss: 4.9558, MinusLogProbMetric: 4.9558, val_loss: 5.4315, val_MinusLogProbMetric: 5.4315

Epoch 45: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.9558 - MinusLogProbMetric: 4.9558 - val_loss: 5.4315 - val_MinusLogProbMetric: 5.4315 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 46/1000
2023-09-18 15:36:25.624 
Epoch 46/1000 
	 loss: 4.9654, MinusLogProbMetric: 4.9654, val_loss: 5.5545, val_MinusLogProbMetric: 5.5545

Epoch 46: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.9654 - MinusLogProbMetric: 4.9654 - val_loss: 5.5545 - val_MinusLogProbMetric: 5.5545 - lr: 0.0010 - 82s/epoch - 417ms/step
Epoch 47/1000
2023-09-18 15:37:47.292 
Epoch 47/1000 
	 loss: 4.9703, MinusLogProbMetric: 4.9703, val_loss: 5.4618, val_MinusLogProbMetric: 5.4618

Epoch 47: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.9703 - MinusLogProbMetric: 4.9703 - val_loss: 5.4618 - val_MinusLogProbMetric: 5.4618 - lr: 0.0010 - 82s/epoch - 417ms/step
Epoch 48/1000
2023-09-18 15:39:08.994 
Epoch 48/1000 
	 loss: 4.9672, MinusLogProbMetric: 4.9672, val_loss: 5.4137, val_MinusLogProbMetric: 5.4137

Epoch 48: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.9672 - MinusLogProbMetric: 4.9672 - val_loss: 5.4137 - val_MinusLogProbMetric: 5.4137 - lr: 0.0010 - 82s/epoch - 417ms/step
Epoch 49/1000
2023-09-18 15:40:31.186 
Epoch 49/1000 
	 loss: 4.9324, MinusLogProbMetric: 4.9324, val_loss: 5.5228, val_MinusLogProbMetric: 5.5228

Epoch 49: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.9324 - MinusLogProbMetric: 4.9324 - val_loss: 5.5228 - val_MinusLogProbMetric: 5.5228 - lr: 0.0010 - 82s/epoch - 419ms/step
Epoch 50/1000
2023-09-18 15:41:52.626 
Epoch 50/1000 
	 loss: 4.9754, MinusLogProbMetric: 4.9754, val_loss: 5.4144, val_MinusLogProbMetric: 5.4144

Epoch 50: val_loss did not improve from 5.33165
196/196 - 81s - loss: 4.9754 - MinusLogProbMetric: 4.9754 - val_loss: 5.4144 - val_MinusLogProbMetric: 5.4144 - lr: 0.0010 - 81s/epoch - 415ms/step
Epoch 51/1000
2023-09-18 15:43:14.286 
Epoch 51/1000 
	 loss: 4.9092, MinusLogProbMetric: 4.9092, val_loss: 5.4334, val_MinusLogProbMetric: 5.4334

Epoch 51: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.9092 - MinusLogProbMetric: 4.9092 - val_loss: 5.4334 - val_MinusLogProbMetric: 5.4334 - lr: 0.0010 - 82s/epoch - 417ms/step
Epoch 52/1000
2023-09-18 15:44:36.885 
Epoch 52/1000 
	 loss: 4.8926, MinusLogProbMetric: 4.8926, val_loss: 5.5502, val_MinusLogProbMetric: 5.5502

Epoch 52: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.8926 - MinusLogProbMetric: 4.8926 - val_loss: 5.5502 - val_MinusLogProbMetric: 5.5502 - lr: 0.0010 - 83s/epoch - 421ms/step
Epoch 53/1000
2023-09-18 15:45:59.481 
Epoch 53/1000 
	 loss: 4.9074, MinusLogProbMetric: 4.9074, val_loss: 5.6053, val_MinusLogProbMetric: 5.6053

Epoch 53: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.9074 - MinusLogProbMetric: 4.9074 - val_loss: 5.6053 - val_MinusLogProbMetric: 5.6053 - lr: 0.0010 - 83s/epoch - 421ms/step
Epoch 54/1000
2023-09-18 15:47:21.708 
Epoch 54/1000 
	 loss: 4.9115, MinusLogProbMetric: 4.9115, val_loss: 5.6263, val_MinusLogProbMetric: 5.6263

Epoch 54: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.9115 - MinusLogProbMetric: 4.9115 - val_loss: 5.6263 - val_MinusLogProbMetric: 5.6263 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 55/1000
2023-09-18 15:48:44.755 
Epoch 55/1000 
	 loss: 4.8946, MinusLogProbMetric: 4.8946, val_loss: 5.5692, val_MinusLogProbMetric: 5.5692

Epoch 55: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.8946 - MinusLogProbMetric: 4.8946 - val_loss: 5.5692 - val_MinusLogProbMetric: 5.5692 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 56/1000
2023-09-18 15:50:07.309 
Epoch 56/1000 
	 loss: 4.8768, MinusLogProbMetric: 4.8768, val_loss: 5.4897, val_MinusLogProbMetric: 5.4897

Epoch 56: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.8768 - MinusLogProbMetric: 4.8768 - val_loss: 5.4897 - val_MinusLogProbMetric: 5.4897 - lr: 0.0010 - 83s/epoch - 421ms/step
Epoch 57/1000
2023-09-18 15:51:29.931 
Epoch 57/1000 
	 loss: 4.8635, MinusLogProbMetric: 4.8635, val_loss: 5.4817, val_MinusLogProbMetric: 5.4817

Epoch 57: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.8635 - MinusLogProbMetric: 4.8635 - val_loss: 5.4817 - val_MinusLogProbMetric: 5.4817 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 58/1000
2023-09-18 15:52:53.685 
Epoch 58/1000 
	 loss: 4.8631, MinusLogProbMetric: 4.8631, val_loss: 5.4826, val_MinusLogProbMetric: 5.4826

Epoch 58: val_loss did not improve from 5.33165
196/196 - 84s - loss: 4.8631 - MinusLogProbMetric: 4.8631 - val_loss: 5.4826 - val_MinusLogProbMetric: 5.4826 - lr: 0.0010 - 84s/epoch - 427ms/step
Epoch 59/1000
2023-09-18 15:54:16.783 
Epoch 59/1000 
	 loss: 4.8593, MinusLogProbMetric: 4.8593, val_loss: 5.5061, val_MinusLogProbMetric: 5.5061

Epoch 59: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.8593 - MinusLogProbMetric: 4.8593 - val_loss: 5.5061 - val_MinusLogProbMetric: 5.5061 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 60/1000
2023-09-18 15:55:39.016 
Epoch 60/1000 
	 loss: 4.8163, MinusLogProbMetric: 4.8163, val_loss: 5.5165, val_MinusLogProbMetric: 5.5165

Epoch 60: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.8163 - MinusLogProbMetric: 4.8163 - val_loss: 5.5165 - val_MinusLogProbMetric: 5.5165 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 61/1000
2023-09-18 15:57:02.561 
Epoch 61/1000 
	 loss: 4.8177, MinusLogProbMetric: 4.8177, val_loss: 5.4739, val_MinusLogProbMetric: 5.4739

Epoch 61: val_loss did not improve from 5.33165
196/196 - 84s - loss: 4.8177 - MinusLogProbMetric: 4.8177 - val_loss: 5.4739 - val_MinusLogProbMetric: 5.4739 - lr: 0.0010 - 84s/epoch - 426ms/step
Epoch 62/1000
2023-09-18 15:58:24.832 
Epoch 62/1000 
	 loss: 4.8032, MinusLogProbMetric: 4.8032, val_loss: 5.6943, val_MinusLogProbMetric: 5.6943

Epoch 62: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.8032 - MinusLogProbMetric: 4.8032 - val_loss: 5.6943 - val_MinusLogProbMetric: 5.6943 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 63/1000
2023-09-18 15:59:47.819 
Epoch 63/1000 
	 loss: 4.8157, MinusLogProbMetric: 4.8157, val_loss: 5.5126, val_MinusLogProbMetric: 5.5126

Epoch 63: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.8157 - MinusLogProbMetric: 4.8157 - val_loss: 5.5126 - val_MinusLogProbMetric: 5.5126 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 64/1000
2023-09-18 16:01:10.935 
Epoch 64/1000 
	 loss: 4.8007, MinusLogProbMetric: 4.8007, val_loss: 5.6691, val_MinusLogProbMetric: 5.6691

Epoch 64: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.8007 - MinusLogProbMetric: 4.8007 - val_loss: 5.6691 - val_MinusLogProbMetric: 5.6691 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 65/1000
2023-09-18 16:02:33.925 
Epoch 65/1000 
	 loss: 4.8351, MinusLogProbMetric: 4.8351, val_loss: 5.6516, val_MinusLogProbMetric: 5.6516

Epoch 65: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.8351 - MinusLogProbMetric: 4.8351 - val_loss: 5.6516 - val_MinusLogProbMetric: 5.6516 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 66/1000
2023-09-18 16:03:56.302 
Epoch 66/1000 
	 loss: 4.8115, MinusLogProbMetric: 4.8115, val_loss: 5.6140, val_MinusLogProbMetric: 5.6140

Epoch 66: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.8115 - MinusLogProbMetric: 4.8115 - val_loss: 5.6140 - val_MinusLogProbMetric: 5.6140 - lr: 0.0010 - 82s/epoch - 420ms/step
Epoch 67/1000
2023-09-18 16:05:19.085 
Epoch 67/1000 
	 loss: 4.7972, MinusLogProbMetric: 4.7972, val_loss: 5.7189, val_MinusLogProbMetric: 5.7189

Epoch 67: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.7972 - MinusLogProbMetric: 4.7972 - val_loss: 5.7189 - val_MinusLogProbMetric: 5.7189 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 68/1000
2023-09-18 16:06:41.928 
Epoch 68/1000 
	 loss: 4.8075, MinusLogProbMetric: 4.8075, val_loss: 5.5442, val_MinusLogProbMetric: 5.5442

Epoch 68: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.8075 - MinusLogProbMetric: 4.8075 - val_loss: 5.5442 - val_MinusLogProbMetric: 5.5442 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 69/1000
2023-09-18 16:08:04.988 
Epoch 69/1000 
	 loss: 4.7419, MinusLogProbMetric: 4.7419, val_loss: 5.5888, val_MinusLogProbMetric: 5.5888

Epoch 69: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.7419 - MinusLogProbMetric: 4.7419 - val_loss: 5.5888 - val_MinusLogProbMetric: 5.5888 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 70/1000
2023-09-18 16:09:28.542 
Epoch 70/1000 
	 loss: 4.7228, MinusLogProbMetric: 4.7228, val_loss: 5.5926, val_MinusLogProbMetric: 5.5926

Epoch 70: val_loss did not improve from 5.33165
196/196 - 84s - loss: 4.7228 - MinusLogProbMetric: 4.7228 - val_loss: 5.5926 - val_MinusLogProbMetric: 5.5926 - lr: 0.0010 - 84s/epoch - 426ms/step
Epoch 71/1000
2023-09-18 16:10:51.649 
Epoch 71/1000 
	 loss: 4.7524, MinusLogProbMetric: 4.7524, val_loss: 5.6776, val_MinusLogProbMetric: 5.6776

Epoch 71: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.7524 - MinusLogProbMetric: 4.7524 - val_loss: 5.6776 - val_MinusLogProbMetric: 5.6776 - lr: 0.0010 - 83s/epoch - 424ms/step
Epoch 72/1000
2023-09-18 16:12:14.268 
Epoch 72/1000 
	 loss: 4.7596, MinusLogProbMetric: 4.7596, val_loss: 5.5869, val_MinusLogProbMetric: 5.5869

Epoch 72: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.7596 - MinusLogProbMetric: 4.7596 - val_loss: 5.5869 - val_MinusLogProbMetric: 5.5869 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 73/1000
2023-09-18 16:13:27.072 
Epoch 73/1000 
	 loss: 4.7263, MinusLogProbMetric: 4.7263, val_loss: 5.7871, val_MinusLogProbMetric: 5.7871

Epoch 73: val_loss did not improve from 5.33165
196/196 - 73s - loss: 4.7263 - MinusLogProbMetric: 4.7263 - val_loss: 5.7871 - val_MinusLogProbMetric: 5.7871 - lr: 0.0010 - 73s/epoch - 371ms/step
Epoch 74/1000
2023-09-18 16:14:32.306 
Epoch 74/1000 
	 loss: 4.7335, MinusLogProbMetric: 4.7335, val_loss: 5.8044, val_MinusLogProbMetric: 5.8044

Epoch 74: val_loss did not improve from 5.33165
196/196 - 65s - loss: 4.7335 - MinusLogProbMetric: 4.7335 - val_loss: 5.8044 - val_MinusLogProbMetric: 5.8044 - lr: 0.0010 - 65s/epoch - 333ms/step
Epoch 75/1000
2023-09-18 16:15:50.751 
Epoch 75/1000 
	 loss: 4.7316, MinusLogProbMetric: 4.7316, val_loss: 5.5918, val_MinusLogProbMetric: 5.5918

Epoch 75: val_loss did not improve from 5.33165
196/196 - 78s - loss: 4.7316 - MinusLogProbMetric: 4.7316 - val_loss: 5.5918 - val_MinusLogProbMetric: 5.5918 - lr: 0.0010 - 78s/epoch - 400ms/step
Epoch 76/1000
2023-09-18 16:17:14.034 
Epoch 76/1000 
	 loss: 4.7251, MinusLogProbMetric: 4.7251, val_loss: 5.6857, val_MinusLogProbMetric: 5.6857

Epoch 76: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.7251 - MinusLogProbMetric: 4.7251 - val_loss: 5.6857 - val_MinusLogProbMetric: 5.6857 - lr: 0.0010 - 83s/epoch - 425ms/step
Epoch 77/1000
2023-09-18 16:18:37.014 
Epoch 77/1000 
	 loss: 4.6943, MinusLogProbMetric: 4.6943, val_loss: 5.6560, val_MinusLogProbMetric: 5.6560

Epoch 77: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.6943 - MinusLogProbMetric: 4.6943 - val_loss: 5.6560 - val_MinusLogProbMetric: 5.6560 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 78/1000
2023-09-18 16:19:59.986 
Epoch 78/1000 
	 loss: 4.7093, MinusLogProbMetric: 4.7093, val_loss: 5.6689, val_MinusLogProbMetric: 5.6689

Epoch 78: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.7093 - MinusLogProbMetric: 4.7093 - val_loss: 5.6689 - val_MinusLogProbMetric: 5.6689 - lr: 0.0010 - 83s/epoch - 423ms/step
Epoch 79/1000
2023-09-18 16:21:23.443 
Epoch 79/1000 
	 loss: 4.7063, MinusLogProbMetric: 4.7063, val_loss: 5.6815, val_MinusLogProbMetric: 5.6815

Epoch 79: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.7063 - MinusLogProbMetric: 4.7063 - val_loss: 5.6815 - val_MinusLogProbMetric: 5.6815 - lr: 0.0010 - 83s/epoch - 426ms/step
Epoch 80/1000
2023-09-18 16:22:46.232 
Epoch 80/1000 
	 loss: 4.6566, MinusLogProbMetric: 4.6566, val_loss: 5.5946, val_MinusLogProbMetric: 5.5946

Epoch 80: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.6566 - MinusLogProbMetric: 4.6566 - val_loss: 5.5946 - val_MinusLogProbMetric: 5.5946 - lr: 0.0010 - 83s/epoch - 422ms/step
Epoch 81/1000
2023-09-18 16:24:07.722 
Epoch 81/1000 
	 loss: 4.7070, MinusLogProbMetric: 4.7070, val_loss: 5.6451, val_MinusLogProbMetric: 5.6451

Epoch 81: val_loss did not improve from 5.33165
196/196 - 81s - loss: 4.7070 - MinusLogProbMetric: 4.7070 - val_loss: 5.6451 - val_MinusLogProbMetric: 5.6451 - lr: 0.0010 - 81s/epoch - 416ms/step
Epoch 82/1000
2023-09-18 16:25:28.927 
Epoch 82/1000 
	 loss: 4.4753, MinusLogProbMetric: 4.4753, val_loss: 5.6745, val_MinusLogProbMetric: 5.6745

Epoch 82: val_loss did not improve from 5.33165
196/196 - 81s - loss: 4.4753 - MinusLogProbMetric: 4.4753 - val_loss: 5.6745 - val_MinusLogProbMetric: 5.6745 - lr: 5.0000e-04 - 81s/epoch - 414ms/step
Epoch 83/1000
2023-09-18 16:26:50.625 
Epoch 83/1000 
	 loss: 4.4349, MinusLogProbMetric: 4.4349, val_loss: 5.7081, val_MinusLogProbMetric: 5.7081

Epoch 83: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.4349 - MinusLogProbMetric: 4.4349 - val_loss: 5.7081 - val_MinusLogProbMetric: 5.7081 - lr: 5.0000e-04 - 82s/epoch - 417ms/step
Epoch 84/1000
2023-09-18 16:28:12.616 
Epoch 84/1000 
	 loss: 4.4265, MinusLogProbMetric: 4.4265, val_loss: 5.7051, val_MinusLogProbMetric: 5.7051

Epoch 84: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.4265 - MinusLogProbMetric: 4.4265 - val_loss: 5.7051 - val_MinusLogProbMetric: 5.7051 - lr: 5.0000e-04 - 82s/epoch - 418ms/step
Epoch 85/1000
2023-09-18 16:29:34.518 
Epoch 85/1000 
	 loss: 4.4164, MinusLogProbMetric: 4.4164, val_loss: 5.7247, val_MinusLogProbMetric: 5.7247

Epoch 85: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.4164 - MinusLogProbMetric: 4.4164 - val_loss: 5.7247 - val_MinusLogProbMetric: 5.7247 - lr: 5.0000e-04 - 82s/epoch - 418ms/step
Epoch 86/1000
2023-09-18 16:30:56.351 
Epoch 86/1000 
	 loss: 4.4080, MinusLogProbMetric: 4.4080, val_loss: 5.7502, val_MinusLogProbMetric: 5.7502

Epoch 86: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.4080 - MinusLogProbMetric: 4.4080 - val_loss: 5.7502 - val_MinusLogProbMetric: 5.7502 - lr: 5.0000e-04 - 82s/epoch - 417ms/step
Epoch 87/1000
2023-09-18 16:32:18.819 
Epoch 87/1000 
	 loss: 4.3966, MinusLogProbMetric: 4.3966, val_loss: 5.8095, val_MinusLogProbMetric: 5.8095

Epoch 87: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.3966 - MinusLogProbMetric: 4.3966 - val_loss: 5.8095 - val_MinusLogProbMetric: 5.8095 - lr: 5.0000e-04 - 82s/epoch - 421ms/step
Epoch 88/1000
2023-09-18 16:33:40.594 
Epoch 88/1000 
	 loss: 4.3923, MinusLogProbMetric: 4.3923, val_loss: 5.7918, val_MinusLogProbMetric: 5.7918

Epoch 88: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.3923 - MinusLogProbMetric: 4.3923 - val_loss: 5.7918 - val_MinusLogProbMetric: 5.7918 - lr: 5.0000e-04 - 82s/epoch - 417ms/step
Epoch 89/1000
2023-09-18 16:35:02.394 
Epoch 89/1000 
	 loss: 4.3767, MinusLogProbMetric: 4.3767, val_loss: 5.7966, val_MinusLogProbMetric: 5.7966

Epoch 89: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.3767 - MinusLogProbMetric: 4.3767 - val_loss: 5.7966 - val_MinusLogProbMetric: 5.7966 - lr: 5.0000e-04 - 82s/epoch - 417ms/step
Epoch 90/1000
2023-09-18 16:36:25.236 
Epoch 90/1000 
	 loss: 4.3878, MinusLogProbMetric: 4.3878, val_loss: 5.8369, val_MinusLogProbMetric: 5.8369

Epoch 90: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.3878 - MinusLogProbMetric: 4.3878 - val_loss: 5.8369 - val_MinusLogProbMetric: 5.8369 - lr: 5.0000e-04 - 83s/epoch - 423ms/step
Epoch 91/1000
2023-09-18 16:37:47.960 
Epoch 91/1000 
	 loss: 4.3740, MinusLogProbMetric: 4.3740, val_loss: 5.8438, val_MinusLogProbMetric: 5.8438

Epoch 91: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.3740 - MinusLogProbMetric: 4.3740 - val_loss: 5.8438 - val_MinusLogProbMetric: 5.8438 - lr: 5.0000e-04 - 83s/epoch - 422ms/step
Epoch 92/1000
2023-09-18 16:39:10.056 
Epoch 92/1000 
	 loss: 4.3637, MinusLogProbMetric: 4.3637, val_loss: 5.8413, val_MinusLogProbMetric: 5.8413

Epoch 92: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.3637 - MinusLogProbMetric: 4.3637 - val_loss: 5.8413 - val_MinusLogProbMetric: 5.8413 - lr: 5.0000e-04 - 82s/epoch - 419ms/step
Epoch 93/1000
2023-09-18 16:40:32.414 
Epoch 93/1000 
	 loss: 4.3660, MinusLogProbMetric: 4.3660, val_loss: 5.9143, val_MinusLogProbMetric: 5.9143

Epoch 93: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.3660 - MinusLogProbMetric: 4.3660 - val_loss: 5.9143 - val_MinusLogProbMetric: 5.9143 - lr: 5.0000e-04 - 82s/epoch - 420ms/step
Epoch 94/1000
2023-09-18 16:41:55.129 
Epoch 94/1000 
	 loss: 4.3613, MinusLogProbMetric: 4.3613, val_loss: 5.8695, val_MinusLogProbMetric: 5.8695

Epoch 94: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.3613 - MinusLogProbMetric: 4.3613 - val_loss: 5.8695 - val_MinusLogProbMetric: 5.8695 - lr: 5.0000e-04 - 83s/epoch - 422ms/step
Epoch 95/1000
2023-09-18 16:43:15.936 
Epoch 95/1000 
	 loss: 4.3627, MinusLogProbMetric: 4.3627, val_loss: 5.9242, val_MinusLogProbMetric: 5.9242

Epoch 95: val_loss did not improve from 5.33165
196/196 - 81s - loss: 4.3627 - MinusLogProbMetric: 4.3627 - val_loss: 5.9242 - val_MinusLogProbMetric: 5.9242 - lr: 5.0000e-04 - 81s/epoch - 412ms/step
Epoch 96/1000
2023-09-18 16:44:38.715 
Epoch 96/1000 
	 loss: 4.3527, MinusLogProbMetric: 4.3527, val_loss: 5.9169, val_MinusLogProbMetric: 5.9169

Epoch 96: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.3527 - MinusLogProbMetric: 4.3527 - val_loss: 5.9169 - val_MinusLogProbMetric: 5.9169 - lr: 5.0000e-04 - 83s/epoch - 422ms/step
Epoch 97/1000
2023-09-18 16:46:00.963 
Epoch 97/1000 
	 loss: 4.3342, MinusLogProbMetric: 4.3342, val_loss: 5.8787, val_MinusLogProbMetric: 5.8787

Epoch 97: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.3342 - MinusLogProbMetric: 4.3342 - val_loss: 5.8787 - val_MinusLogProbMetric: 5.8787 - lr: 5.0000e-04 - 82s/epoch - 420ms/step
Epoch 98/1000
2023-09-18 16:47:21.956 
Epoch 98/1000 
	 loss: 4.3327, MinusLogProbMetric: 4.3327, val_loss: 5.9480, val_MinusLogProbMetric: 5.9480

Epoch 98: val_loss did not improve from 5.33165
196/196 - 81s - loss: 4.3327 - MinusLogProbMetric: 4.3327 - val_loss: 5.9480 - val_MinusLogProbMetric: 5.9480 - lr: 5.0000e-04 - 81s/epoch - 413ms/step
Epoch 99/1000
2023-09-18 16:48:44.388 
Epoch 99/1000 
	 loss: 4.3210, MinusLogProbMetric: 4.3210, val_loss: 5.9524, val_MinusLogProbMetric: 5.9524

Epoch 99: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.3210 - MinusLogProbMetric: 4.3210 - val_loss: 5.9524 - val_MinusLogProbMetric: 5.9524 - lr: 5.0000e-04 - 82s/epoch - 421ms/step
Epoch 100/1000
2023-09-18 16:50:06.733 
Epoch 100/1000 
	 loss: 4.3216, MinusLogProbMetric: 4.3216, val_loss: 6.0301, val_MinusLogProbMetric: 6.0301

Epoch 100: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.3216 - MinusLogProbMetric: 4.3216 - val_loss: 6.0301 - val_MinusLogProbMetric: 6.0301 - lr: 5.0000e-04 - 82s/epoch - 420ms/step
Epoch 101/1000
2023-09-18 16:51:29.391 
Epoch 101/1000 
	 loss: 4.3094, MinusLogProbMetric: 4.3094, val_loss: 5.9770, val_MinusLogProbMetric: 5.9770

Epoch 101: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.3094 - MinusLogProbMetric: 4.3094 - val_loss: 5.9770 - val_MinusLogProbMetric: 5.9770 - lr: 5.0000e-04 - 83s/epoch - 422ms/step
Epoch 102/1000
2023-09-18 16:52:51.511 
Epoch 102/1000 
	 loss: 4.3020, MinusLogProbMetric: 4.3020, val_loss: 6.0132, val_MinusLogProbMetric: 6.0132

Epoch 102: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.3020 - MinusLogProbMetric: 4.3020 - val_loss: 6.0132 - val_MinusLogProbMetric: 6.0132 - lr: 5.0000e-04 - 82s/epoch - 419ms/step
Epoch 103/1000
2023-09-18 16:54:13.443 
Epoch 103/1000 
	 loss: 4.3003, MinusLogProbMetric: 4.3003, val_loss: 5.9794, val_MinusLogProbMetric: 5.9794

Epoch 103: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.3003 - MinusLogProbMetric: 4.3003 - val_loss: 5.9794 - val_MinusLogProbMetric: 5.9794 - lr: 5.0000e-04 - 82s/epoch - 418ms/step
Epoch 104/1000
2023-09-18 16:55:35.777 
Epoch 104/1000 
	 loss: 4.2870, MinusLogProbMetric: 4.2870, val_loss: 5.9948, val_MinusLogProbMetric: 5.9948

Epoch 104: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.2870 - MinusLogProbMetric: 4.2870 - val_loss: 5.9948 - val_MinusLogProbMetric: 5.9948 - lr: 5.0000e-04 - 82s/epoch - 420ms/step
Epoch 105/1000
2023-09-18 16:56:58.065 
Epoch 105/1000 
	 loss: 4.2799, MinusLogProbMetric: 4.2799, val_loss: 6.0285, val_MinusLogProbMetric: 6.0285

Epoch 105: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.2799 - MinusLogProbMetric: 4.2799 - val_loss: 6.0285 - val_MinusLogProbMetric: 6.0285 - lr: 5.0000e-04 - 82s/epoch - 420ms/step
Epoch 106/1000
2023-09-18 16:58:20.525 
Epoch 106/1000 
	 loss: 4.2789, MinusLogProbMetric: 4.2789, val_loss: 6.0700, val_MinusLogProbMetric: 6.0700

Epoch 106: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.2789 - MinusLogProbMetric: 4.2789 - val_loss: 6.0700 - val_MinusLogProbMetric: 6.0700 - lr: 5.0000e-04 - 82s/epoch - 421ms/step
Epoch 107/1000
2023-09-18 16:59:42.876 
Epoch 107/1000 
	 loss: 4.2614, MinusLogProbMetric: 4.2614, val_loss: 6.0121, val_MinusLogProbMetric: 6.0121

Epoch 107: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.2614 - MinusLogProbMetric: 4.2614 - val_loss: 6.0121 - val_MinusLogProbMetric: 6.0121 - lr: 5.0000e-04 - 82s/epoch - 420ms/step
Epoch 108/1000
2023-09-18 17:01:06.104 
Epoch 108/1000 
	 loss: 4.2678, MinusLogProbMetric: 4.2678, val_loss: 6.1633, val_MinusLogProbMetric: 6.1633

Epoch 108: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.2678 - MinusLogProbMetric: 4.2678 - val_loss: 6.1633 - val_MinusLogProbMetric: 6.1633 - lr: 5.0000e-04 - 83s/epoch - 425ms/step
Epoch 109/1000
2023-09-18 17:02:28.322 
Epoch 109/1000 
	 loss: 4.2533, MinusLogProbMetric: 4.2533, val_loss: 6.1139, val_MinusLogProbMetric: 6.1139

Epoch 109: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.2533 - MinusLogProbMetric: 4.2533 - val_loss: 6.1139 - val_MinusLogProbMetric: 6.1139 - lr: 5.0000e-04 - 82s/epoch - 419ms/step
Epoch 110/1000
2023-09-18 17:03:48.200 
Epoch 110/1000 
	 loss: 4.2486, MinusLogProbMetric: 4.2486, val_loss: 6.0930, val_MinusLogProbMetric: 6.0930

Epoch 110: val_loss did not improve from 5.33165
196/196 - 80s - loss: 4.2486 - MinusLogProbMetric: 4.2486 - val_loss: 6.0930 - val_MinusLogProbMetric: 6.0930 - lr: 5.0000e-04 - 80s/epoch - 408ms/step
Epoch 111/1000
2023-09-18 17:04:56.210 
Epoch 111/1000 
	 loss: 4.2461, MinusLogProbMetric: 4.2461, val_loss: 6.1628, val_MinusLogProbMetric: 6.1628

Epoch 111: val_loss did not improve from 5.33165
196/196 - 68s - loss: 4.2461 - MinusLogProbMetric: 4.2461 - val_loss: 6.1628 - val_MinusLogProbMetric: 6.1628 - lr: 5.0000e-04 - 68s/epoch - 347ms/step
Epoch 112/1000
2023-09-18 17:06:05.578 
Epoch 112/1000 
	 loss: 4.2666, MinusLogProbMetric: 4.2666, val_loss: 6.1327, val_MinusLogProbMetric: 6.1327

Epoch 112: val_loss did not improve from 5.33165
196/196 - 69s - loss: 4.2666 - MinusLogProbMetric: 4.2666 - val_loss: 6.1327 - val_MinusLogProbMetric: 6.1327 - lr: 5.0000e-04 - 69s/epoch - 354ms/step
Epoch 113/1000
2023-09-18 17:07:25.801 
Epoch 113/1000 
	 loss: 4.2415, MinusLogProbMetric: 4.2415, val_loss: 6.2923, val_MinusLogProbMetric: 6.2923

Epoch 113: val_loss did not improve from 5.33165
196/196 - 80s - loss: 4.2415 - MinusLogProbMetric: 4.2415 - val_loss: 6.2923 - val_MinusLogProbMetric: 6.2923 - lr: 5.0000e-04 - 80s/epoch - 409ms/step
Epoch 114/1000
2023-09-18 17:08:48.177 
Epoch 114/1000 
	 loss: 4.2403, MinusLogProbMetric: 4.2403, val_loss: 6.1495, val_MinusLogProbMetric: 6.1495

Epoch 114: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.2403 - MinusLogProbMetric: 4.2403 - val_loss: 6.1495 - val_MinusLogProbMetric: 6.1495 - lr: 5.0000e-04 - 82s/epoch - 420ms/step
Epoch 115/1000
2023-09-18 17:10:10.398 
Epoch 115/1000 
	 loss: 4.2329, MinusLogProbMetric: 4.2329, val_loss: 6.2240, val_MinusLogProbMetric: 6.2240

Epoch 115: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.2329 - MinusLogProbMetric: 4.2329 - val_loss: 6.2240 - val_MinusLogProbMetric: 6.2240 - lr: 5.0000e-04 - 82s/epoch - 419ms/step
Epoch 116/1000
2023-09-18 17:11:34.303 
Epoch 116/1000 
	 loss: 4.2344, MinusLogProbMetric: 4.2344, val_loss: 6.2737, val_MinusLogProbMetric: 6.2737

Epoch 116: val_loss did not improve from 5.33165
196/196 - 84s - loss: 4.2344 - MinusLogProbMetric: 4.2344 - val_loss: 6.2737 - val_MinusLogProbMetric: 6.2737 - lr: 5.0000e-04 - 84s/epoch - 428ms/step
Epoch 117/1000
2023-09-18 17:12:55.318 
Epoch 117/1000 
	 loss: 4.1967, MinusLogProbMetric: 4.1967, val_loss: 6.2229, val_MinusLogProbMetric: 6.2229

Epoch 117: val_loss did not improve from 5.33165
196/196 - 81s - loss: 4.1967 - MinusLogProbMetric: 4.1967 - val_loss: 6.2229 - val_MinusLogProbMetric: 6.2229 - lr: 5.0000e-04 - 81s/epoch - 413ms/step
Epoch 118/1000
2023-09-18 17:14:01.085 
Epoch 118/1000 
	 loss: 4.2067, MinusLogProbMetric: 4.2067, val_loss: 6.1983, val_MinusLogProbMetric: 6.1983

Epoch 118: val_loss did not improve from 5.33165
196/196 - 66s - loss: 4.2067 - MinusLogProbMetric: 4.2067 - val_loss: 6.1983 - val_MinusLogProbMetric: 6.1983 - lr: 5.0000e-04 - 66s/epoch - 336ms/step
Epoch 119/1000
2023-09-18 17:15:20.335 
Epoch 119/1000 
	 loss: 4.1948, MinusLogProbMetric: 4.1948, val_loss: 6.2182, val_MinusLogProbMetric: 6.2182

Epoch 119: val_loss did not improve from 5.33165
196/196 - 79s - loss: 4.1948 - MinusLogProbMetric: 4.1948 - val_loss: 6.2182 - val_MinusLogProbMetric: 6.2182 - lr: 5.0000e-04 - 79s/epoch - 404ms/step
Epoch 120/1000
2023-09-18 17:16:42.488 
Epoch 120/1000 
	 loss: 4.1844, MinusLogProbMetric: 4.1844, val_loss: 6.2471, val_MinusLogProbMetric: 6.2471

Epoch 120: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.1844 - MinusLogProbMetric: 4.1844 - val_loss: 6.2471 - val_MinusLogProbMetric: 6.2471 - lr: 5.0000e-04 - 82s/epoch - 419ms/step
Epoch 121/1000
2023-09-18 17:18:03.348 
Epoch 121/1000 
	 loss: 4.1922, MinusLogProbMetric: 4.1922, val_loss: 6.1810, val_MinusLogProbMetric: 6.1810

Epoch 121: val_loss did not improve from 5.33165
196/196 - 81s - loss: 4.1922 - MinusLogProbMetric: 4.1922 - val_loss: 6.1810 - val_MinusLogProbMetric: 6.1810 - lr: 5.0000e-04 - 81s/epoch - 413ms/step
Epoch 122/1000
2023-09-18 17:19:25.451 
Epoch 122/1000 
	 loss: 4.1711, MinusLogProbMetric: 4.1711, val_loss: 6.3054, val_MinusLogProbMetric: 6.3054

Epoch 122: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.1711 - MinusLogProbMetric: 4.1711 - val_loss: 6.3054 - val_MinusLogProbMetric: 6.3054 - lr: 5.0000e-04 - 82s/epoch - 419ms/step
Epoch 123/1000
2023-09-18 17:20:47.545 
Epoch 123/1000 
	 loss: 4.1931, MinusLogProbMetric: 4.1931, val_loss: 6.3971, val_MinusLogProbMetric: 6.3971

Epoch 123: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.1931 - MinusLogProbMetric: 4.1931 - val_loss: 6.3971 - val_MinusLogProbMetric: 6.3971 - lr: 5.0000e-04 - 82s/epoch - 419ms/step
Epoch 124/1000
2023-09-18 17:22:09.487 
Epoch 124/1000 
	 loss: 4.1923, MinusLogProbMetric: 4.1923, val_loss: 6.2998, val_MinusLogProbMetric: 6.2998

Epoch 124: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.1923 - MinusLogProbMetric: 4.1923 - val_loss: 6.2998 - val_MinusLogProbMetric: 6.2998 - lr: 5.0000e-04 - 82s/epoch - 418ms/step
Epoch 125/1000
2023-09-18 17:23:31.395 
Epoch 125/1000 
	 loss: 4.1764, MinusLogProbMetric: 4.1764, val_loss: 6.3120, val_MinusLogProbMetric: 6.3120

Epoch 125: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.1764 - MinusLogProbMetric: 4.1764 - val_loss: 6.3120 - val_MinusLogProbMetric: 6.3120 - lr: 5.0000e-04 - 82s/epoch - 418ms/step
Epoch 126/1000
2023-09-18 17:24:54.178 
Epoch 126/1000 
	 loss: 4.1700, MinusLogProbMetric: 4.1700, val_loss: 6.2652, val_MinusLogProbMetric: 6.2652

Epoch 126: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.1700 - MinusLogProbMetric: 4.1700 - val_loss: 6.2652 - val_MinusLogProbMetric: 6.2652 - lr: 5.0000e-04 - 83s/epoch - 422ms/step
Epoch 127/1000
2023-09-18 17:26:15.805 
Epoch 127/1000 
	 loss: 4.1816, MinusLogProbMetric: 4.1816, val_loss: 6.3148, val_MinusLogProbMetric: 6.3148

Epoch 127: val_loss did not improve from 5.33165
196/196 - 82s - loss: 4.1816 - MinusLogProbMetric: 4.1816 - val_loss: 6.3148 - val_MinusLogProbMetric: 6.3148 - lr: 5.0000e-04 - 82s/epoch - 416ms/step
Epoch 128/1000
2023-09-18 17:27:38.581 
Epoch 128/1000 
	 loss: 4.2442, MinusLogProbMetric: 4.2442, val_loss: 6.2752, val_MinusLogProbMetric: 6.2752

Epoch 128: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.2442 - MinusLogProbMetric: 4.2442 - val_loss: 6.2752 - val_MinusLogProbMetric: 6.2752 - lr: 5.0000e-04 - 83s/epoch - 422ms/step
Epoch 129/1000
2023-09-18 17:29:01.331 
Epoch 129/1000 
	 loss: 4.1423, MinusLogProbMetric: 4.1423, val_loss: 6.3984, val_MinusLogProbMetric: 6.3984

Epoch 129: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.1423 - MinusLogProbMetric: 4.1423 - val_loss: 6.3984 - val_MinusLogProbMetric: 6.3984 - lr: 5.0000e-04 - 83s/epoch - 422ms/step
Epoch 130/1000
2023-09-18 17:30:24.354 
Epoch 130/1000 
	 loss: 4.1751, MinusLogProbMetric: 4.1751, val_loss: 6.3384, val_MinusLogProbMetric: 6.3384

Epoch 130: val_loss did not improve from 5.33165
196/196 - 83s - loss: 4.1751 - MinusLogProbMetric: 4.1751 - val_loss: 6.3384 - val_MinusLogProbMetric: 6.3384 - lr: 5.0000e-04 - 83s/epoch - 424ms/step
Epoch 131/1000
2023-09-18 17:31:45.886 
Epoch 131/1000 
	 loss: 4.1378, MinusLogProbMetric: 4.1378, val_loss: 6.3913, val_MinusLogProbMetric: 6.3913

Epoch 131: val_loss did not improve from 5.33165
Restoring model weights from the end of the best epoch: 31.
196/196 - 82s - loss: 4.1378 - MinusLogProbMetric: 4.1378 - val_loss: 6.3913 - val_MinusLogProbMetric: 6.3913 - lr: 5.0000e-04 - 82s/epoch - 419ms/step
Epoch 131: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 59.53684409405105 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 24.50696138292551 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 17.91354190208949 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7faea5304280> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 67.15206829016097 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 26.623900472884998 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 18.52715768502094 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fb1dc759900> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 440.
Model trained in 10933.75 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/c_Main_CsplineN.py , Line : 468, Func.Name : prediction_function, Message : X_data_nf: tf.Tensor = DataInputs.dist_2_num[:nsamples_test] # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 219.43 s.
===========
Run 192/720 done in 11163.94 s.
===========

Directory ../../results/CsplineN_new/run_193/ already exists.
Skipping it.
===========
Run 193/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_194/ already exists.
Skipping it.
===========
Run 194/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_195/ already exists.
Skipping it.
===========
Run 195/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_196/ already exists.
Skipping it.
===========
Run 196/720 already exists. Skipping it.
===========

===========
Generating train data for run 197.
===========
Train data generated in 0.14 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 16)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_197/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 520}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_197/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[0.38022646, 8.607701  , 8.188467  , ..., 4.120624  , 2.7077272 ,
        7.774094  ],
       [4.8196216 , 5.322764  , 0.23177525, ..., 6.6490507 , 2.2244883 ,
        1.4368625 ],
       [4.372809  , 5.4970036 , 0.2661619 , ..., 6.7417064 , 1.9180639 ,
        1.2820187 ],
       ...,
       [4.698602  , 5.590594  , 0.15122014, ..., 5.903814  , 2.560357  ,
        1.4384264 ],
       [4.78274   , 5.0663724 , 0.21942878, ..., 6.718675  , 1.7440856 ,
        1.1519673 ],
       [5.0597296 , 5.956661  , 0.10863999, ..., 7.41993   , 2.408465  ,
        1.5008225 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_197/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_197
self.data_kwargs: {'seed': 520}
self.x_data: [[ 4.404796    5.4921975   0.23664948 ...  7.564216    2.321595
   1.1917233 ]
 [ 4.5716944   5.8112526   0.21128002 ...  7.4468536   1.9158355
   1.3247035 ]
 [ 4.525824    4.9398046   0.242967   ...  6.9621987   2.4206023
   0.9921393 ]
 ...
 [ 3.9811025   5.683119    0.25731167 ...  6.6038966   2.4554362
   1.1169562 ]
 [ 5.2221084   7.363898    5.392251   ...  9.259994   -0.16446447
   0.8693828 ]
 [ 4.465022    5.5781837   0.23531836 ...  8.510526    1.9942145
   1.1519785 ]]
self.y_data: []
self.ndims: 16
Model defined.
Model: "model_168"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_169 (InputLayer)      [(None, 16)]              0         
                                                                 
 log_prob_layer_18 (LogProbL  (None,)                  579120    
 ayer)                                                           
                                                                 
=================================================================
Total params: 579,120
Trainable params: 579,120
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_18/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_18'")
self.model: <keras.engine.functional.Functional object at 0x7faec576f4c0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7faea55d77c0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7faea55d77c0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fae4d1bceb0>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7faf11961f90>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7faf11962500>, <keras.callbacks.ModelCheckpoint object at 0x7faf119625c0>, <keras.callbacks.EarlyStopping object at 0x7faf11962830>, <keras.callbacks.ReduceLROnPlateau object at 0x7faf11962860>, <keras.callbacks.TerminateOnNaN object at 0x7faf119624a0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[0.38022646, 8.607701  , 8.188467  , ..., 4.120624  , 2.7077272 ,
        7.774094  ],
       [4.8196216 , 5.322764  , 0.23177525, ..., 6.6490507 , 2.2244883 ,
        1.4368625 ],
       [4.372809  , 5.4970036 , 0.2661619 , ..., 6.7417064 , 1.9180639 ,
        1.2820187 ],
       ...,
       [4.698602  , 5.590594  , 0.15122014, ..., 5.903814  , 2.560357  ,
        1.4384264 ],
       [4.78274   , 5.0663724 , 0.21942878, ..., 6.718675  , 1.7440856 ,
        1.1519673 ],
       [5.0597296 , 5.956661  , 0.10863999, ..., 7.41993   , 2.408465  ,
        1.5008225 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_197/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 197/720 with hyperparameters:
timestamp = 2023-09-18 17:35:33.464049
ndims = 16
seed_train = 520
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 8
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 579120
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [4.404796   5.4921975  0.23664948 5.9787536  6.444371   5.747771
 9.516937   6.795833   3.7946396  5.109782   7.171333   0.7853222
 6.670326   7.564216   2.321595   1.1917233 ]
Epoch 1/1000
2023-09-18 17:39:21.779 
Epoch 1/1000 
	 loss: 297.4691, MinusLogProbMetric: 297.4691, val_loss: 244.1501, val_MinusLogProbMetric: 244.1501

Epoch 1: val_loss improved from inf to 244.15010, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 229s - loss: 297.4691 - MinusLogProbMetric: 297.4691 - val_loss: 244.1501 - val_MinusLogProbMetric: 244.1501 - lr: 0.0010 - 229s/epoch - 1s/step
Epoch 2/1000
2023-09-18 17:40:31.276 
Epoch 2/1000 
	 loss: 93.1704, MinusLogProbMetric: 93.1704, val_loss: 49.8302, val_MinusLogProbMetric: 49.8302

Epoch 2: val_loss improved from 244.15010 to 49.83023, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 69s - loss: 93.1704 - MinusLogProbMetric: 93.1704 - val_loss: 49.8302 - val_MinusLogProbMetric: 49.8302 - lr: 0.0010 - 69s/epoch - 353ms/step
Epoch 3/1000
2023-09-18 17:41:28.411 
Epoch 3/1000 
	 loss: 36.8819, MinusLogProbMetric: 36.8819, val_loss: 34.1377, val_MinusLogProbMetric: 34.1377

Epoch 3: val_loss improved from 49.83023 to 34.13768, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 57s - loss: 36.8819 - MinusLogProbMetric: 36.8819 - val_loss: 34.1377 - val_MinusLogProbMetric: 34.1377 - lr: 0.0010 - 57s/epoch - 290ms/step
Epoch 4/1000
2023-09-18 17:42:29.364 
Epoch 4/1000 
	 loss: 23.4406, MinusLogProbMetric: 23.4406, val_loss: 105.4825, val_MinusLogProbMetric: 105.4825

Epoch 4: val_loss did not improve from 34.13768
196/196 - 60s - loss: 23.4406 - MinusLogProbMetric: 23.4406 - val_loss: 105.4825 - val_MinusLogProbMetric: 105.4825 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 5/1000
2023-09-18 17:43:27.206 
Epoch 5/1000 
	 loss: 34.7403, MinusLogProbMetric: 34.7403, val_loss: 17.7035, val_MinusLogProbMetric: 17.7035

Epoch 5: val_loss improved from 34.13768 to 17.70353, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 59s - loss: 34.7403 - MinusLogProbMetric: 34.7403 - val_loss: 17.7035 - val_MinusLogProbMetric: 17.7035 - lr: 0.0010 - 59s/epoch - 300ms/step
Epoch 6/1000
2023-09-18 17:44:36.471 
Epoch 6/1000 
	 loss: 14.7688, MinusLogProbMetric: 14.7688, val_loss: 11.7450, val_MinusLogProbMetric: 11.7450

Epoch 6: val_loss improved from 17.70353 to 11.74502, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 69s - loss: 14.7688 - MinusLogProbMetric: 14.7688 - val_loss: 11.7450 - val_MinusLogProbMetric: 11.7450 - lr: 0.0010 - 69s/epoch - 353ms/step
Epoch 7/1000
2023-09-18 17:45:44.590 
Epoch 7/1000 
	 loss: 11.3620, MinusLogProbMetric: 11.3620, val_loss: 10.4789, val_MinusLogProbMetric: 10.4789

Epoch 7: val_loss improved from 11.74502 to 10.47889, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 68s - loss: 11.3620 - MinusLogProbMetric: 11.3620 - val_loss: 10.4789 - val_MinusLogProbMetric: 10.4789 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 8/1000
2023-09-18 17:46:54.255 
Epoch 8/1000 
	 loss: 9.6787, MinusLogProbMetric: 9.6787, val_loss: 9.5622, val_MinusLogProbMetric: 9.5622

Epoch 8: val_loss improved from 10.47889 to 9.56224, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 9.6787 - MinusLogProbMetric: 9.6787 - val_loss: 9.5622 - val_MinusLogProbMetric: 9.5622 - lr: 0.0010 - 70s/epoch - 356ms/step
Epoch 9/1000
2023-09-18 17:48:03.727 
Epoch 9/1000 
	 loss: 8.6582, MinusLogProbMetric: 8.6582, val_loss: 7.9297, val_MinusLogProbMetric: 7.9297

Epoch 9: val_loss improved from 9.56224 to 7.92966, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 69s - loss: 8.6582 - MinusLogProbMetric: 8.6582 - val_loss: 7.9297 - val_MinusLogProbMetric: 7.9297 - lr: 0.0010 - 69s/epoch - 354ms/step
Epoch 10/1000
2023-09-18 17:49:13.097 
Epoch 10/1000 
	 loss: 8.4720, MinusLogProbMetric: 8.4720, val_loss: 8.1301, val_MinusLogProbMetric: 8.1301

Epoch 10: val_loss did not improve from 7.92966
196/196 - 68s - loss: 8.4720 - MinusLogProbMetric: 8.4720 - val_loss: 8.1301 - val_MinusLogProbMetric: 8.1301 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 11/1000
2023-09-18 17:50:21.384 
Epoch 11/1000 
	 loss: 8.3334, MinusLogProbMetric: 8.3334, val_loss: 7.7204, val_MinusLogProbMetric: 7.7204

Epoch 11: val_loss improved from 7.92966 to 7.72045, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 8.3334 - MinusLogProbMetric: 8.3334 - val_loss: 7.7204 - val_MinusLogProbMetric: 7.7204 - lr: 0.0010 - 70s/epoch - 355ms/step
Epoch 12/1000
2023-09-18 17:51:30.800 
Epoch 12/1000 
	 loss: 8.0113, MinusLogProbMetric: 8.0113, val_loss: 7.8425, val_MinusLogProbMetric: 7.8425

Epoch 12: val_loss did not improve from 7.72045
196/196 - 68s - loss: 8.0113 - MinusLogProbMetric: 8.0113 - val_loss: 7.8425 - val_MinusLogProbMetric: 7.8425 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 13/1000
2023-09-18 17:52:39.164 
Epoch 13/1000 
	 loss: 7.9466, MinusLogProbMetric: 7.9466, val_loss: 8.3089, val_MinusLogProbMetric: 8.3089

Epoch 13: val_loss did not improve from 7.72045
196/196 - 68s - loss: 7.9466 - MinusLogProbMetric: 7.9466 - val_loss: 8.3089 - val_MinusLogProbMetric: 8.3089 - lr: 0.0010 - 68s/epoch - 349ms/step
Epoch 14/1000
2023-09-18 17:53:47.166 
Epoch 14/1000 
	 loss: 7.8170, MinusLogProbMetric: 7.8170, val_loss: 7.8150, val_MinusLogProbMetric: 7.8150

Epoch 14: val_loss did not improve from 7.72045
196/196 - 68s - loss: 7.8170 - MinusLogProbMetric: 7.8170 - val_loss: 7.8150 - val_MinusLogProbMetric: 7.8150 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 15/1000
2023-09-18 17:54:55.033 
Epoch 15/1000 
	 loss: 7.3475, MinusLogProbMetric: 7.3475, val_loss: 8.7757, val_MinusLogProbMetric: 8.7757

Epoch 15: val_loss did not improve from 7.72045
196/196 - 68s - loss: 7.3475 - MinusLogProbMetric: 7.3475 - val_loss: 8.7757 - val_MinusLogProbMetric: 8.7757 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 16/1000
2023-09-18 17:56:03.909 
Epoch 16/1000 
	 loss: 6.9751, MinusLogProbMetric: 6.9751, val_loss: 7.0249, val_MinusLogProbMetric: 7.0249

Epoch 16: val_loss improved from 7.72045 to 7.02492, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 6.9751 - MinusLogProbMetric: 6.9751 - val_loss: 7.0249 - val_MinusLogProbMetric: 7.0249 - lr: 0.0010 - 70s/epoch - 357ms/step
Epoch 17/1000
2023-09-18 17:57:13.471 
Epoch 17/1000 
	 loss: 6.7468, MinusLogProbMetric: 6.7468, val_loss: 6.3853, val_MinusLogProbMetric: 6.3853

Epoch 17: val_loss improved from 7.02492 to 6.38527, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 6.7468 - MinusLogProbMetric: 6.7468 - val_loss: 6.3853 - val_MinusLogProbMetric: 6.3853 - lr: 0.0010 - 70s/epoch - 355ms/step
Epoch 18/1000
2023-09-18 17:58:22.715 
Epoch 18/1000 
	 loss: 6.7795, MinusLogProbMetric: 6.7795, val_loss: 6.3594, val_MinusLogProbMetric: 6.3594

Epoch 18: val_loss improved from 6.38527 to 6.35937, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 69s - loss: 6.7795 - MinusLogProbMetric: 6.7795 - val_loss: 6.3594 - val_MinusLogProbMetric: 6.3594 - lr: 0.0010 - 69s/epoch - 353ms/step
Epoch 19/1000
2023-09-18 17:59:32.047 
Epoch 19/1000 
	 loss: 6.6077, MinusLogProbMetric: 6.6077, val_loss: 6.8185, val_MinusLogProbMetric: 6.8185

Epoch 19: val_loss did not improve from 6.35937
196/196 - 68s - loss: 6.6077 - MinusLogProbMetric: 6.6077 - val_loss: 6.8185 - val_MinusLogProbMetric: 6.8185 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 20/1000
2023-09-18 18:00:40.595 
Epoch 20/1000 
	 loss: 6.4766, MinusLogProbMetric: 6.4766, val_loss: 6.6549, val_MinusLogProbMetric: 6.6549

Epoch 20: val_loss did not improve from 6.35937
196/196 - 69s - loss: 6.4766 - MinusLogProbMetric: 6.4766 - val_loss: 6.6549 - val_MinusLogProbMetric: 6.6549 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 21/1000
2023-09-18 18:01:48.633 
Epoch 21/1000 
	 loss: 6.3997, MinusLogProbMetric: 6.3997, val_loss: 6.1479, val_MinusLogProbMetric: 6.1479

Epoch 21: val_loss improved from 6.35937 to 6.14787, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 69s - loss: 6.3997 - MinusLogProbMetric: 6.3997 - val_loss: 6.1479 - val_MinusLogProbMetric: 6.1479 - lr: 0.0010 - 69s/epoch - 354ms/step
Epoch 22/1000
2023-09-18 18:02:46.874 
Epoch 22/1000 
	 loss: 6.3055, MinusLogProbMetric: 6.3055, val_loss: 6.6522, val_MinusLogProbMetric: 6.6522

Epoch 22: val_loss did not improve from 6.14787
196/196 - 57s - loss: 6.3055 - MinusLogProbMetric: 6.3055 - val_loss: 6.6522 - val_MinusLogProbMetric: 6.6522 - lr: 0.0010 - 57s/epoch - 290ms/step
Epoch 23/1000
2023-09-18 18:03:40.196 
Epoch 23/1000 
	 loss: 6.3014, MinusLogProbMetric: 6.3014, val_loss: 6.0029, val_MinusLogProbMetric: 6.0029

Epoch 23: val_loss improved from 6.14787 to 6.00285, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 54s - loss: 6.3014 - MinusLogProbMetric: 6.3014 - val_loss: 6.0029 - val_MinusLogProbMetric: 6.0029 - lr: 0.0010 - 54s/epoch - 276ms/step
Epoch 24/1000
2023-09-18 18:04:33.540 
Epoch 24/1000 
	 loss: 6.2268, MinusLogProbMetric: 6.2268, val_loss: 6.3563, val_MinusLogProbMetric: 6.3563

Epoch 24: val_loss did not improve from 6.00285
196/196 - 53s - loss: 6.2268 - MinusLogProbMetric: 6.2268 - val_loss: 6.3563 - val_MinusLogProbMetric: 6.3563 - lr: 0.0010 - 53s/epoch - 268ms/step
Epoch 25/1000
2023-09-18 18:05:28.369 
Epoch 25/1000 
	 loss: 7.4103, MinusLogProbMetric: 7.4103, val_loss: 40.0030, val_MinusLogProbMetric: 40.0030

Epoch 25: val_loss did not improve from 6.00285
196/196 - 55s - loss: 7.4103 - MinusLogProbMetric: 7.4103 - val_loss: 40.0030 - val_MinusLogProbMetric: 40.0030 - lr: 0.0010 - 55s/epoch - 280ms/step
Epoch 26/1000
2023-09-18 18:06:25.737 
Epoch 26/1000 
	 loss: 11.6073, MinusLogProbMetric: 11.6073, val_loss: 7.5946, val_MinusLogProbMetric: 7.5946

Epoch 26: val_loss did not improve from 6.00285
196/196 - 57s - loss: 11.6073 - MinusLogProbMetric: 11.6073 - val_loss: 7.5946 - val_MinusLogProbMetric: 7.5946 - lr: 0.0010 - 57s/epoch - 293ms/step
Epoch 27/1000
2023-09-18 18:07:29.390 
Epoch 27/1000 
	 loss: 7.3421, MinusLogProbMetric: 7.3421, val_loss: 7.0281, val_MinusLogProbMetric: 7.0281

Epoch 27: val_loss did not improve from 6.00285
196/196 - 64s - loss: 7.3421 - MinusLogProbMetric: 7.3421 - val_loss: 7.0281 - val_MinusLogProbMetric: 7.0281 - lr: 0.0010 - 64s/epoch - 325ms/step
Epoch 28/1000
2023-09-18 18:08:21.840 
Epoch 28/1000 
	 loss: 6.7283, MinusLogProbMetric: 6.7283, val_loss: 6.6331, val_MinusLogProbMetric: 6.6331

Epoch 28: val_loss did not improve from 6.00285
196/196 - 52s - loss: 6.7283 - MinusLogProbMetric: 6.7283 - val_loss: 6.6331 - val_MinusLogProbMetric: 6.6331 - lr: 0.0010 - 52s/epoch - 268ms/step
Epoch 29/1000
2023-09-18 18:09:14.625 
Epoch 29/1000 
	 loss: 6.5143, MinusLogProbMetric: 6.5143, val_loss: 6.3042, val_MinusLogProbMetric: 6.3042

Epoch 29: val_loss did not improve from 6.00285
196/196 - 53s - loss: 6.5143 - MinusLogProbMetric: 6.5143 - val_loss: 6.3042 - val_MinusLogProbMetric: 6.3042 - lr: 0.0010 - 53s/epoch - 269ms/step
Epoch 30/1000
2023-09-18 18:10:06.976 
Epoch 30/1000 
	 loss: 6.2723, MinusLogProbMetric: 6.2723, val_loss: 6.5315, val_MinusLogProbMetric: 6.5315

Epoch 30: val_loss did not improve from 6.00285
196/196 - 52s - loss: 6.2723 - MinusLogProbMetric: 6.2723 - val_loss: 6.5315 - val_MinusLogProbMetric: 6.5315 - lr: 0.0010 - 52s/epoch - 267ms/step
Epoch 31/1000
2023-09-18 18:11:11.513 
Epoch 31/1000 
	 loss: 6.2196, MinusLogProbMetric: 6.2196, val_loss: 6.3330, val_MinusLogProbMetric: 6.3330

Epoch 31: val_loss did not improve from 6.00285
196/196 - 65s - loss: 6.2196 - MinusLogProbMetric: 6.2196 - val_loss: 6.3330 - val_MinusLogProbMetric: 6.3330 - lr: 0.0010 - 65s/epoch - 329ms/step
Epoch 32/1000
2023-09-18 18:12:17.244 
Epoch 32/1000 
	 loss: 6.1878, MinusLogProbMetric: 6.1878, val_loss: 6.0599, val_MinusLogProbMetric: 6.0599

Epoch 32: val_loss did not improve from 6.00285
196/196 - 66s - loss: 6.1878 - MinusLogProbMetric: 6.1878 - val_loss: 6.0599 - val_MinusLogProbMetric: 6.0599 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 33/1000
2023-09-18 18:13:25.201 
Epoch 33/1000 
	 loss: 6.0365, MinusLogProbMetric: 6.0365, val_loss: 6.5954, val_MinusLogProbMetric: 6.5954

Epoch 33: val_loss did not improve from 6.00285
196/196 - 68s - loss: 6.0365 - MinusLogProbMetric: 6.0365 - val_loss: 6.5954 - val_MinusLogProbMetric: 6.5954 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 34/1000
2023-09-18 18:14:32.798 
Epoch 34/1000 
	 loss: 6.0441, MinusLogProbMetric: 6.0441, val_loss: 6.2527, val_MinusLogProbMetric: 6.2527

Epoch 34: val_loss did not improve from 6.00285
196/196 - 68s - loss: 6.0441 - MinusLogProbMetric: 6.0441 - val_loss: 6.2527 - val_MinusLogProbMetric: 6.2527 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 35/1000
2023-09-18 18:15:40.522 
Epoch 35/1000 
	 loss: 5.9453, MinusLogProbMetric: 5.9453, val_loss: 6.0564, val_MinusLogProbMetric: 6.0564

Epoch 35: val_loss did not improve from 6.00285
196/196 - 68s - loss: 5.9453 - MinusLogProbMetric: 5.9453 - val_loss: 6.0564 - val_MinusLogProbMetric: 6.0564 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 36/1000
2023-09-18 18:16:47.957 
Epoch 36/1000 
	 loss: 5.9170, MinusLogProbMetric: 5.9170, val_loss: 6.1898, val_MinusLogProbMetric: 6.1898

Epoch 36: val_loss did not improve from 6.00285
196/196 - 67s - loss: 5.9170 - MinusLogProbMetric: 5.9170 - val_loss: 6.1898 - val_MinusLogProbMetric: 6.1898 - lr: 0.0010 - 67s/epoch - 344ms/step
Epoch 37/1000
2023-09-18 18:17:55.435 
Epoch 37/1000 
	 loss: 5.8546, MinusLogProbMetric: 5.8546, val_loss: 6.1489, val_MinusLogProbMetric: 6.1489

Epoch 37: val_loss did not improve from 6.00285
196/196 - 67s - loss: 5.8546 - MinusLogProbMetric: 5.8546 - val_loss: 6.1489 - val_MinusLogProbMetric: 6.1489 - lr: 0.0010 - 67s/epoch - 344ms/step
Epoch 38/1000
2023-09-18 18:19:02.875 
Epoch 38/1000 
	 loss: 5.8473, MinusLogProbMetric: 5.8473, val_loss: 6.0087, val_MinusLogProbMetric: 6.0087

Epoch 38: val_loss did not improve from 6.00285
196/196 - 67s - loss: 5.8473 - MinusLogProbMetric: 5.8473 - val_loss: 6.0087 - val_MinusLogProbMetric: 6.0087 - lr: 0.0010 - 67s/epoch - 344ms/step
Epoch 39/1000
2023-09-18 18:20:10.120 
Epoch 39/1000 
	 loss: 5.7724, MinusLogProbMetric: 5.7724, val_loss: 5.8889, val_MinusLogProbMetric: 5.8889

Epoch 39: val_loss improved from 6.00285 to 5.88885, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 68s - loss: 5.7724 - MinusLogProbMetric: 5.7724 - val_loss: 5.8889 - val_MinusLogProbMetric: 5.8889 - lr: 0.0010 - 68s/epoch - 349ms/step
Epoch 40/1000
2023-09-18 18:21:19.050 
Epoch 40/1000 
	 loss: 5.7897, MinusLogProbMetric: 5.7897, val_loss: 6.2601, val_MinusLogProbMetric: 6.2601

Epoch 40: val_loss did not improve from 5.88885
196/196 - 68s - loss: 5.7897 - MinusLogProbMetric: 5.7897 - val_loss: 6.2601 - val_MinusLogProbMetric: 6.2601 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 41/1000
2023-09-18 18:22:26.915 
Epoch 41/1000 
	 loss: 5.7700, MinusLogProbMetric: 5.7700, val_loss: 5.7385, val_MinusLogProbMetric: 5.7385

Epoch 41: val_loss improved from 5.88885 to 5.73846, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 69s - loss: 5.7700 - MinusLogProbMetric: 5.7700 - val_loss: 5.7385 - val_MinusLogProbMetric: 5.7385 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 42/1000
2023-09-18 18:23:33.464 
Epoch 42/1000 
	 loss: 5.7016, MinusLogProbMetric: 5.7016, val_loss: 5.6670, val_MinusLogProbMetric: 5.6670

Epoch 42: val_loss improved from 5.73846 to 5.66697, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 66s - loss: 5.7016 - MinusLogProbMetric: 5.7016 - val_loss: 5.6670 - val_MinusLogProbMetric: 5.6670 - lr: 0.0010 - 66s/epoch - 339ms/step
Epoch 43/1000
2023-09-18 18:24:32.192 
Epoch 43/1000 
	 loss: 5.6988, MinusLogProbMetric: 5.6988, val_loss: 5.8061, val_MinusLogProbMetric: 5.8061

Epoch 43: val_loss did not improve from 5.66697
196/196 - 58s - loss: 5.6988 - MinusLogProbMetric: 5.6988 - val_loss: 5.8061 - val_MinusLogProbMetric: 5.8061 - lr: 0.0010 - 58s/epoch - 294ms/step
Epoch 44/1000
2023-09-18 18:25:30.410 
Epoch 44/1000 
	 loss: 5.7066, MinusLogProbMetric: 5.7066, val_loss: 5.8499, val_MinusLogProbMetric: 5.8499

Epoch 44: val_loss did not improve from 5.66697
196/196 - 58s - loss: 5.7066 - MinusLogProbMetric: 5.7066 - val_loss: 5.8499 - val_MinusLogProbMetric: 5.8499 - lr: 0.0010 - 58s/epoch - 297ms/step
Epoch 45/1000
2023-09-18 18:26:26.305 
Epoch 45/1000 
	 loss: 5.6988, MinusLogProbMetric: 5.6988, val_loss: 5.5957, val_MinusLogProbMetric: 5.5957

Epoch 45: val_loss improved from 5.66697 to 5.59567, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 57s - loss: 5.6988 - MinusLogProbMetric: 5.6988 - val_loss: 5.5957 - val_MinusLogProbMetric: 5.5957 - lr: 0.0010 - 57s/epoch - 290ms/step
Epoch 46/1000
2023-09-18 18:27:31.592 
Epoch 46/1000 
	 loss: 5.6796, MinusLogProbMetric: 5.6796, val_loss: 5.6545, val_MinusLogProbMetric: 5.6545

Epoch 46: val_loss did not improve from 5.59567
196/196 - 64s - loss: 5.6796 - MinusLogProbMetric: 5.6796 - val_loss: 5.6545 - val_MinusLogProbMetric: 5.6545 - lr: 0.0010 - 64s/epoch - 329ms/step
Epoch 47/1000
2023-09-18 18:28:38.329 
Epoch 47/1000 
	 loss: 5.6461, MinusLogProbMetric: 5.6461, val_loss: 5.6356, val_MinusLogProbMetric: 5.6356

Epoch 47: val_loss did not improve from 5.59567
196/196 - 67s - loss: 5.6461 - MinusLogProbMetric: 5.6461 - val_loss: 5.6356 - val_MinusLogProbMetric: 5.6356 - lr: 0.0010 - 67s/epoch - 340ms/step
Epoch 48/1000
2023-09-18 18:29:45.016 
Epoch 48/1000 
	 loss: 5.6033, MinusLogProbMetric: 5.6033, val_loss: 5.7253, val_MinusLogProbMetric: 5.7253

Epoch 48: val_loss did not improve from 5.59567
196/196 - 67s - loss: 5.6033 - MinusLogProbMetric: 5.6033 - val_loss: 5.7253 - val_MinusLogProbMetric: 5.7253 - lr: 0.0010 - 67s/epoch - 340ms/step
Epoch 49/1000
2023-09-18 18:30:51.652 
Epoch 49/1000 
	 loss: 5.6321, MinusLogProbMetric: 5.6321, val_loss: 5.9128, val_MinusLogProbMetric: 5.9128

Epoch 49: val_loss did not improve from 5.59567
196/196 - 67s - loss: 5.6321 - MinusLogProbMetric: 5.6321 - val_loss: 5.9128 - val_MinusLogProbMetric: 5.9128 - lr: 0.0010 - 67s/epoch - 340ms/step
Epoch 50/1000
2023-09-18 18:31:58.932 
Epoch 50/1000 
	 loss: 5.6181, MinusLogProbMetric: 5.6181, val_loss: 5.6943, val_MinusLogProbMetric: 5.6943

Epoch 50: val_loss did not improve from 5.59567
196/196 - 67s - loss: 5.6181 - MinusLogProbMetric: 5.6181 - val_loss: 5.6943 - val_MinusLogProbMetric: 5.6943 - lr: 0.0010 - 67s/epoch - 343ms/step
Epoch 51/1000
2023-09-18 18:33:06.364 
Epoch 51/1000 
	 loss: 5.5940, MinusLogProbMetric: 5.5940, val_loss: 5.5374, val_MinusLogProbMetric: 5.5374

Epoch 51: val_loss improved from 5.59567 to 5.53740, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 69s - loss: 5.5940 - MinusLogProbMetric: 5.5940 - val_loss: 5.5374 - val_MinusLogProbMetric: 5.5374 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 52/1000
2023-09-18 18:34:15.503 
Epoch 52/1000 
	 loss: 5.6117, MinusLogProbMetric: 5.6117, val_loss: 6.0333, val_MinusLogProbMetric: 6.0333

Epoch 52: val_loss did not improve from 5.53740
196/196 - 68s - loss: 5.6117 - MinusLogProbMetric: 5.6117 - val_loss: 6.0333 - val_MinusLogProbMetric: 6.0333 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 53/1000
2023-09-18 18:35:22.635 
Epoch 53/1000 
	 loss: 5.5259, MinusLogProbMetric: 5.5259, val_loss: 5.7476, val_MinusLogProbMetric: 5.7476

Epoch 53: val_loss did not improve from 5.53740
196/196 - 67s - loss: 5.5259 - MinusLogProbMetric: 5.5259 - val_loss: 5.7476 - val_MinusLogProbMetric: 5.7476 - lr: 0.0010 - 67s/epoch - 342ms/step
Epoch 54/1000
2023-09-18 18:36:29.475 
Epoch 54/1000 
	 loss: 5.5596, MinusLogProbMetric: 5.5596, val_loss: 5.5344, val_MinusLogProbMetric: 5.5344

Epoch 54: val_loss improved from 5.53740 to 5.53444, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 68s - loss: 5.5596 - MinusLogProbMetric: 5.5596 - val_loss: 5.5344 - val_MinusLogProbMetric: 5.5344 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 55/1000
2023-09-18 18:37:37.030 
Epoch 55/1000 
	 loss: 5.5388, MinusLogProbMetric: 5.5388, val_loss: 5.7079, val_MinusLogProbMetric: 5.7079

Epoch 55: val_loss did not improve from 5.53444
196/196 - 67s - loss: 5.5388 - MinusLogProbMetric: 5.5388 - val_loss: 5.7079 - val_MinusLogProbMetric: 5.7079 - lr: 0.0010 - 67s/epoch - 340ms/step
Epoch 56/1000
2023-09-18 18:38:43.534 
Epoch 56/1000 
	 loss: 5.5329, MinusLogProbMetric: 5.5329, val_loss: 5.4900, val_MinusLogProbMetric: 5.4900

Epoch 56: val_loss improved from 5.53444 to 5.49003, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 68s - loss: 5.5329 - MinusLogProbMetric: 5.5329 - val_loss: 5.4900 - val_MinusLogProbMetric: 5.4900 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 57/1000
2023-09-18 18:39:50.894 
Epoch 57/1000 
	 loss: 5.5459, MinusLogProbMetric: 5.5459, val_loss: 5.5272, val_MinusLogProbMetric: 5.5272

Epoch 57: val_loss did not improve from 5.49003
196/196 - 66s - loss: 5.5459 - MinusLogProbMetric: 5.5459 - val_loss: 5.5272 - val_MinusLogProbMetric: 5.5272 - lr: 0.0010 - 66s/epoch - 338ms/step
Epoch 58/1000
2023-09-18 18:40:56.849 
Epoch 58/1000 
	 loss: 5.5235, MinusLogProbMetric: 5.5235, val_loss: 5.9536, val_MinusLogProbMetric: 5.9536

Epoch 58: val_loss did not improve from 5.49003
196/196 - 66s - loss: 5.5235 - MinusLogProbMetric: 5.5235 - val_loss: 5.9536 - val_MinusLogProbMetric: 5.9536 - lr: 0.0010 - 66s/epoch - 336ms/step
Epoch 59/1000
2023-09-18 18:42:02.833 
Epoch 59/1000 
	 loss: 5.5554, MinusLogProbMetric: 5.5554, val_loss: 5.4453, val_MinusLogProbMetric: 5.4453

Epoch 59: val_loss improved from 5.49003 to 5.44531, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 67s - loss: 5.5554 - MinusLogProbMetric: 5.5554 - val_loss: 5.4453 - val_MinusLogProbMetric: 5.4453 - lr: 0.0010 - 67s/epoch - 342ms/step
Epoch 60/1000
2023-09-18 18:43:10.622 
Epoch 60/1000 
	 loss: 5.4631, MinusLogProbMetric: 5.4631, val_loss: 5.5483, val_MinusLogProbMetric: 5.5483

Epoch 60: val_loss did not improve from 5.44531
196/196 - 67s - loss: 5.4631 - MinusLogProbMetric: 5.4631 - val_loss: 5.5483 - val_MinusLogProbMetric: 5.5483 - lr: 0.0010 - 67s/epoch - 341ms/step
Epoch 61/1000
2023-09-18 18:44:17.132 
Epoch 61/1000 
	 loss: 5.4944, MinusLogProbMetric: 5.4944, val_loss: 5.4247, val_MinusLogProbMetric: 5.4247

Epoch 61: val_loss improved from 5.44531 to 5.42466, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 68s - loss: 5.4944 - MinusLogProbMetric: 5.4944 - val_loss: 5.4247 - val_MinusLogProbMetric: 5.4247 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 62/1000
2023-09-18 18:45:16.820 
Epoch 62/1000 
	 loss: 5.4906, MinusLogProbMetric: 5.4906, val_loss: 5.7166, val_MinusLogProbMetric: 5.7166

Epoch 62: val_loss did not improve from 5.42466
196/196 - 59s - loss: 5.4906 - MinusLogProbMetric: 5.4906 - val_loss: 5.7166 - val_MinusLogProbMetric: 5.7166 - lr: 0.0010 - 59s/epoch - 299ms/step
Epoch 63/1000
2023-09-18 18:46:14.505 
Epoch 63/1000 
	 loss: 5.4792, MinusLogProbMetric: 5.4792, val_loss: 5.6270, val_MinusLogProbMetric: 5.6270

Epoch 63: val_loss did not improve from 5.42466
196/196 - 58s - loss: 5.4792 - MinusLogProbMetric: 5.4792 - val_loss: 5.6270 - val_MinusLogProbMetric: 5.6270 - lr: 0.0010 - 58s/epoch - 294ms/step
Epoch 64/1000
2023-09-18 18:47:20.885 
Epoch 64/1000 
	 loss: 5.4863, MinusLogProbMetric: 5.4863, val_loss: 5.5095, val_MinusLogProbMetric: 5.5095

Epoch 64: val_loss did not improve from 5.42466
196/196 - 66s - loss: 5.4863 - MinusLogProbMetric: 5.4863 - val_loss: 5.5095 - val_MinusLogProbMetric: 5.5095 - lr: 0.0010 - 66s/epoch - 339ms/step
Epoch 65/1000
2023-09-18 18:48:28.365 
Epoch 65/1000 
	 loss: 5.4862, MinusLogProbMetric: 5.4862, val_loss: 5.4550, val_MinusLogProbMetric: 5.4550

Epoch 65: val_loss did not improve from 5.42466
196/196 - 67s - loss: 5.4862 - MinusLogProbMetric: 5.4862 - val_loss: 5.4550 - val_MinusLogProbMetric: 5.4550 - lr: 0.0010 - 67s/epoch - 344ms/step
Epoch 66/1000
2023-09-18 18:49:35.109 
Epoch 66/1000 
	 loss: 5.4604, MinusLogProbMetric: 5.4604, val_loss: 5.6312, val_MinusLogProbMetric: 5.6312

Epoch 66: val_loss did not improve from 5.42466
196/196 - 67s - loss: 5.4604 - MinusLogProbMetric: 5.4604 - val_loss: 5.6312 - val_MinusLogProbMetric: 5.6312 - lr: 0.0010 - 67s/epoch - 341ms/step
Epoch 67/1000
2023-09-18 18:50:42.396 
Epoch 67/1000 
	 loss: 5.4859, MinusLogProbMetric: 5.4859, val_loss: 5.7786, val_MinusLogProbMetric: 5.7786

Epoch 67: val_loss did not improve from 5.42466
196/196 - 67s - loss: 5.4859 - MinusLogProbMetric: 5.4859 - val_loss: 5.7786 - val_MinusLogProbMetric: 5.7786 - lr: 0.0010 - 67s/epoch - 343ms/step
Epoch 68/1000
2023-09-18 18:51:50.020 
Epoch 68/1000 
	 loss: 5.4343, MinusLogProbMetric: 5.4343, val_loss: 5.5792, val_MinusLogProbMetric: 5.5792

Epoch 68: val_loss did not improve from 5.42466
196/196 - 68s - loss: 5.4343 - MinusLogProbMetric: 5.4343 - val_loss: 5.5792 - val_MinusLogProbMetric: 5.5792 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 69/1000
2023-09-18 18:52:57.299 
Epoch 69/1000 
	 loss: 5.4547, MinusLogProbMetric: 5.4547, val_loss: 5.5101, val_MinusLogProbMetric: 5.5101

Epoch 69: val_loss did not improve from 5.42466
196/196 - 67s - loss: 5.4547 - MinusLogProbMetric: 5.4547 - val_loss: 5.5101 - val_MinusLogProbMetric: 5.5101 - lr: 0.0010 - 67s/epoch - 343ms/step
Epoch 70/1000
2023-09-18 18:54:04.464 
Epoch 70/1000 
	 loss: 5.4571, MinusLogProbMetric: 5.4571, val_loss: 5.6454, val_MinusLogProbMetric: 5.6454

Epoch 70: val_loss did not improve from 5.42466
196/196 - 67s - loss: 5.4571 - MinusLogProbMetric: 5.4571 - val_loss: 5.6454 - val_MinusLogProbMetric: 5.6454 - lr: 0.0010 - 67s/epoch - 343ms/step
Epoch 71/1000
2023-09-18 18:55:12.148 
Epoch 71/1000 
	 loss: 5.4276, MinusLogProbMetric: 5.4276, val_loss: 5.5018, val_MinusLogProbMetric: 5.5018

Epoch 71: val_loss did not improve from 5.42466
196/196 - 68s - loss: 5.4276 - MinusLogProbMetric: 5.4276 - val_loss: 5.5018 - val_MinusLogProbMetric: 5.5018 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 72/1000
2023-09-18 18:56:19.957 
Epoch 72/1000 
	 loss: 5.4563, MinusLogProbMetric: 5.4563, val_loss: 5.5383, val_MinusLogProbMetric: 5.5383

Epoch 72: val_loss did not improve from 5.42466
196/196 - 68s - loss: 5.4563 - MinusLogProbMetric: 5.4563 - val_loss: 5.5383 - val_MinusLogProbMetric: 5.5383 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 73/1000
2023-09-18 18:57:27.963 
Epoch 73/1000 
	 loss: 5.4108, MinusLogProbMetric: 5.4108, val_loss: 5.3690, val_MinusLogProbMetric: 5.3690

Epoch 73: val_loss improved from 5.42466 to 5.36897, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 69s - loss: 5.4108 - MinusLogProbMetric: 5.4108 - val_loss: 5.3690 - val_MinusLogProbMetric: 5.3690 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 74/1000
2023-09-18 18:58:36.928 
Epoch 74/1000 
	 loss: 5.4482, MinusLogProbMetric: 5.4482, val_loss: 5.5089, val_MinusLogProbMetric: 5.5089

Epoch 74: val_loss did not improve from 5.36897
196/196 - 68s - loss: 5.4482 - MinusLogProbMetric: 5.4482 - val_loss: 5.5089 - val_MinusLogProbMetric: 5.5089 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 75/1000
2023-09-18 18:59:45.041 
Epoch 75/1000 
	 loss: 5.4224, MinusLogProbMetric: 5.4224, val_loss: 5.5576, val_MinusLogProbMetric: 5.5576

Epoch 75: val_loss did not improve from 5.36897
196/196 - 68s - loss: 5.4224 - MinusLogProbMetric: 5.4224 - val_loss: 5.5576 - val_MinusLogProbMetric: 5.5576 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 76/1000
2023-09-18 19:00:53.135 
Epoch 76/1000 
	 loss: 5.4065, MinusLogProbMetric: 5.4065, val_loss: 5.5113, val_MinusLogProbMetric: 5.5113

Epoch 76: val_loss did not improve from 5.36897
196/196 - 68s - loss: 5.4065 - MinusLogProbMetric: 5.4065 - val_loss: 5.5113 - val_MinusLogProbMetric: 5.5113 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 77/1000
2023-09-18 19:02:00.634 
Epoch 77/1000 
	 loss: 5.4128, MinusLogProbMetric: 5.4128, val_loss: 5.5305, val_MinusLogProbMetric: 5.5305

Epoch 77: val_loss did not improve from 5.36897
196/196 - 67s - loss: 5.4128 - MinusLogProbMetric: 5.4128 - val_loss: 5.5305 - val_MinusLogProbMetric: 5.5305 - lr: 0.0010 - 67s/epoch - 344ms/step
Epoch 78/1000
2023-09-18 19:03:08.742 
Epoch 78/1000 
	 loss: 5.4060, MinusLogProbMetric: 5.4060, val_loss: 5.5145, val_MinusLogProbMetric: 5.5145

Epoch 78: val_loss did not improve from 5.36897
196/196 - 68s - loss: 5.4060 - MinusLogProbMetric: 5.4060 - val_loss: 5.5145 - val_MinusLogProbMetric: 5.5145 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 79/1000
2023-09-18 19:04:16.700 
Epoch 79/1000 
	 loss: 5.4233, MinusLogProbMetric: 5.4233, val_loss: 5.4994, val_MinusLogProbMetric: 5.4994

Epoch 79: val_loss did not improve from 5.36897
196/196 - 68s - loss: 5.4233 - MinusLogProbMetric: 5.4233 - val_loss: 5.4994 - val_MinusLogProbMetric: 5.4994 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 80/1000
2023-09-18 19:05:23.026 
Epoch 80/1000 
	 loss: 5.4098, MinusLogProbMetric: 5.4098, val_loss: 5.5215, val_MinusLogProbMetric: 5.5215

Epoch 80: val_loss did not improve from 5.36897
196/196 - 66s - loss: 5.4098 - MinusLogProbMetric: 5.4098 - val_loss: 5.5215 - val_MinusLogProbMetric: 5.5215 - lr: 0.0010 - 66s/epoch - 338ms/step
Epoch 81/1000
2023-09-18 19:06:30.061 
Epoch 81/1000 
	 loss: 5.4041, MinusLogProbMetric: 5.4041, val_loss: 5.4553, val_MinusLogProbMetric: 5.4553

Epoch 81: val_loss did not improve from 5.36897
196/196 - 67s - loss: 5.4041 - MinusLogProbMetric: 5.4041 - val_loss: 5.4553 - val_MinusLogProbMetric: 5.4553 - lr: 0.0010 - 67s/epoch - 342ms/step
Epoch 82/1000
2023-09-18 19:07:37.692 
Epoch 82/1000 
	 loss: 5.4148, MinusLogProbMetric: 5.4148, val_loss: 5.6293, val_MinusLogProbMetric: 5.6293

Epoch 82: val_loss did not improve from 5.36897
196/196 - 68s - loss: 5.4148 - MinusLogProbMetric: 5.4148 - val_loss: 5.6293 - val_MinusLogProbMetric: 5.6293 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 83/1000
2023-09-18 19:08:44.203 
Epoch 83/1000 
	 loss: 5.4201, MinusLogProbMetric: 5.4201, val_loss: 5.3942, val_MinusLogProbMetric: 5.3942

Epoch 83: val_loss did not improve from 5.36897
196/196 - 67s - loss: 5.4201 - MinusLogProbMetric: 5.4201 - val_loss: 5.3942 - val_MinusLogProbMetric: 5.3942 - lr: 0.0010 - 67s/epoch - 339ms/step
Epoch 84/1000
2023-09-18 19:09:52.259 
Epoch 84/1000 
	 loss: 5.3808, MinusLogProbMetric: 5.3808, val_loss: 5.3815, val_MinusLogProbMetric: 5.3815

Epoch 84: val_loss did not improve from 5.36897
196/196 - 68s - loss: 5.3808 - MinusLogProbMetric: 5.3808 - val_loss: 5.3815 - val_MinusLogProbMetric: 5.3815 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 85/1000
2023-09-18 19:11:00.411 
Epoch 85/1000 
	 loss: 5.3911, MinusLogProbMetric: 5.3911, val_loss: 5.4692, val_MinusLogProbMetric: 5.4692

Epoch 85: val_loss did not improve from 5.36897
196/196 - 68s - loss: 5.3911 - MinusLogProbMetric: 5.3911 - val_loss: 5.4692 - val_MinusLogProbMetric: 5.4692 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 86/1000
2023-09-18 19:12:07.734 
Epoch 86/1000 
	 loss: 5.3763, MinusLogProbMetric: 5.3763, val_loss: 5.4517, val_MinusLogProbMetric: 5.4517

Epoch 86: val_loss did not improve from 5.36897
196/196 - 67s - loss: 5.3763 - MinusLogProbMetric: 5.3763 - val_loss: 5.4517 - val_MinusLogProbMetric: 5.4517 - lr: 0.0010 - 67s/epoch - 343ms/step
Epoch 87/1000
2023-09-18 19:13:15.276 
Epoch 87/1000 
	 loss: 5.3929, MinusLogProbMetric: 5.3929, val_loss: 5.5555, val_MinusLogProbMetric: 5.5555

Epoch 87: val_loss did not improve from 5.36897
196/196 - 68s - loss: 5.3929 - MinusLogProbMetric: 5.3929 - val_loss: 5.5555 - val_MinusLogProbMetric: 5.5555 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 88/1000
2023-09-18 19:14:23.308 
Epoch 88/1000 
	 loss: 5.3873, MinusLogProbMetric: 5.3873, val_loss: 5.3802, val_MinusLogProbMetric: 5.3802

Epoch 88: val_loss did not improve from 5.36897
196/196 - 68s - loss: 5.3873 - MinusLogProbMetric: 5.3873 - val_loss: 5.3802 - val_MinusLogProbMetric: 5.3802 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 89/1000
2023-09-18 19:15:31.063 
Epoch 89/1000 
	 loss: 5.3916, MinusLogProbMetric: 5.3916, val_loss: 5.4557, val_MinusLogProbMetric: 5.4557

Epoch 89: val_loss did not improve from 5.36897
196/196 - 68s - loss: 5.3916 - MinusLogProbMetric: 5.3916 - val_loss: 5.4557 - val_MinusLogProbMetric: 5.4557 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 90/1000
2023-09-18 19:16:39.122 
Epoch 90/1000 
	 loss: 5.3736, MinusLogProbMetric: 5.3736, val_loss: 5.3930, val_MinusLogProbMetric: 5.3930

Epoch 90: val_loss did not improve from 5.36897
196/196 - 68s - loss: 5.3736 - MinusLogProbMetric: 5.3736 - val_loss: 5.3930 - val_MinusLogProbMetric: 5.3930 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 91/1000
2023-09-18 19:17:46.535 
Epoch 91/1000 
	 loss: 5.3574, MinusLogProbMetric: 5.3574, val_loss: 5.4305, val_MinusLogProbMetric: 5.4305

Epoch 91: val_loss did not improve from 5.36897
196/196 - 67s - loss: 5.3574 - MinusLogProbMetric: 5.3574 - val_loss: 5.4305 - val_MinusLogProbMetric: 5.4305 - lr: 0.0010 - 67s/epoch - 344ms/step
Epoch 92/1000
2023-09-18 19:18:53.720 
Epoch 92/1000 
	 loss: 5.3757, MinusLogProbMetric: 5.3757, val_loss: 5.4678, val_MinusLogProbMetric: 5.4678

Epoch 92: val_loss did not improve from 5.36897
196/196 - 67s - loss: 5.3757 - MinusLogProbMetric: 5.3757 - val_loss: 5.4678 - val_MinusLogProbMetric: 5.4678 - lr: 0.0010 - 67s/epoch - 343ms/step
Epoch 93/1000
2023-09-18 19:19:47.959 
Epoch 93/1000 
	 loss: 5.3984, MinusLogProbMetric: 5.3984, val_loss: 5.4269, val_MinusLogProbMetric: 5.4269

Epoch 93: val_loss did not improve from 5.36897
196/196 - 54s - loss: 5.3984 - MinusLogProbMetric: 5.3984 - val_loss: 5.4269 - val_MinusLogProbMetric: 5.4269 - lr: 0.0010 - 54s/epoch - 277ms/step
Epoch 94/1000
2023-09-18 19:20:40.658 
Epoch 94/1000 
	 loss: 5.3692, MinusLogProbMetric: 5.3692, val_loss: 5.3859, val_MinusLogProbMetric: 5.3859

Epoch 94: val_loss did not improve from 5.36897
196/196 - 53s - loss: 5.3692 - MinusLogProbMetric: 5.3692 - val_loss: 5.3859 - val_MinusLogProbMetric: 5.3859 - lr: 0.0010 - 53s/epoch - 269ms/step
Epoch 95/1000
2023-09-18 19:21:42.525 
Epoch 95/1000 
	 loss: 5.3695, MinusLogProbMetric: 5.3695, val_loss: 5.5629, val_MinusLogProbMetric: 5.5629

Epoch 95: val_loss did not improve from 5.36897
196/196 - 62s - loss: 5.3695 - MinusLogProbMetric: 5.3695 - val_loss: 5.5629 - val_MinusLogProbMetric: 5.5629 - lr: 0.0010 - 62s/epoch - 316ms/step
Epoch 96/1000
2023-09-18 19:22:50.141 
Epoch 96/1000 
	 loss: 5.3662, MinusLogProbMetric: 5.3662, val_loss: 5.6035, val_MinusLogProbMetric: 5.6035

Epoch 96: val_loss did not improve from 5.36897
196/196 - 68s - loss: 5.3662 - MinusLogProbMetric: 5.3662 - val_loss: 5.6035 - val_MinusLogProbMetric: 5.6035 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 97/1000
2023-09-18 19:23:57.994 
Epoch 97/1000 
	 loss: 5.3432, MinusLogProbMetric: 5.3432, val_loss: 5.3976, val_MinusLogProbMetric: 5.3976

Epoch 97: val_loss did not improve from 5.36897
196/196 - 68s - loss: 5.3432 - MinusLogProbMetric: 5.3432 - val_loss: 5.3976 - val_MinusLogProbMetric: 5.3976 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 98/1000
2023-09-18 19:25:06.484 
Epoch 98/1000 
	 loss: 5.3547, MinusLogProbMetric: 5.3547, val_loss: 5.4792, val_MinusLogProbMetric: 5.4792

Epoch 98: val_loss did not improve from 5.36897
196/196 - 68s - loss: 5.3547 - MinusLogProbMetric: 5.3547 - val_loss: 5.4792 - val_MinusLogProbMetric: 5.4792 - lr: 0.0010 - 68s/epoch - 349ms/step
Epoch 99/1000
2023-09-18 19:26:14.402 
Epoch 99/1000 
	 loss: 5.3687, MinusLogProbMetric: 5.3687, val_loss: 5.4427, val_MinusLogProbMetric: 5.4427

Epoch 99: val_loss did not improve from 5.36897
196/196 - 68s - loss: 5.3687 - MinusLogProbMetric: 5.3687 - val_loss: 5.4427 - val_MinusLogProbMetric: 5.4427 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 100/1000
2023-09-18 19:27:22.675 
Epoch 100/1000 
	 loss: 5.3519, MinusLogProbMetric: 5.3519, val_loss: 5.3674, val_MinusLogProbMetric: 5.3674

Epoch 100: val_loss improved from 5.36897 to 5.36736, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.3519 - MinusLogProbMetric: 5.3519 - val_loss: 5.3674 - val_MinusLogProbMetric: 5.3674 - lr: 0.0010 - 70s/epoch - 355ms/step
Epoch 101/1000
2023-09-18 19:28:32.522 
Epoch 101/1000 
	 loss: 5.3336, MinusLogProbMetric: 5.3336, val_loss: 5.4526, val_MinusLogProbMetric: 5.4526

Epoch 101: val_loss did not improve from 5.36736
196/196 - 69s - loss: 5.3336 - MinusLogProbMetric: 5.3336 - val_loss: 5.4526 - val_MinusLogProbMetric: 5.4526 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 102/1000
2023-09-18 19:29:40.953 
Epoch 102/1000 
	 loss: 5.3481, MinusLogProbMetric: 5.3481, val_loss: 5.7765, val_MinusLogProbMetric: 5.7765

Epoch 102: val_loss did not improve from 5.36736
196/196 - 68s - loss: 5.3481 - MinusLogProbMetric: 5.3481 - val_loss: 5.7765 - val_MinusLogProbMetric: 5.7765 - lr: 0.0010 - 68s/epoch - 349ms/step
Epoch 103/1000
2023-09-18 19:30:48.992 
Epoch 103/1000 
	 loss: 5.3646, MinusLogProbMetric: 5.3646, val_loss: 5.4191, val_MinusLogProbMetric: 5.4191

Epoch 103: val_loss did not improve from 5.36736
196/196 - 68s - loss: 5.3646 - MinusLogProbMetric: 5.3646 - val_loss: 5.4191 - val_MinusLogProbMetric: 5.4191 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 104/1000
2023-09-18 19:31:57.895 
Epoch 104/1000 
	 loss: 5.3415, MinusLogProbMetric: 5.3415, val_loss: 5.4587, val_MinusLogProbMetric: 5.4587

Epoch 104: val_loss did not improve from 5.36736
196/196 - 69s - loss: 5.3415 - MinusLogProbMetric: 5.3415 - val_loss: 5.4587 - val_MinusLogProbMetric: 5.4587 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 105/1000
2023-09-18 19:33:06.822 
Epoch 105/1000 
	 loss: 5.3258, MinusLogProbMetric: 5.3258, val_loss: 5.5454, val_MinusLogProbMetric: 5.5454

Epoch 105: val_loss did not improve from 5.36736
196/196 - 69s - loss: 5.3258 - MinusLogProbMetric: 5.3258 - val_loss: 5.5454 - val_MinusLogProbMetric: 5.5454 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 106/1000
2023-09-18 19:34:15.613 
Epoch 106/1000 
	 loss: 5.3274, MinusLogProbMetric: 5.3274, val_loss: 5.3670, val_MinusLogProbMetric: 5.3670

Epoch 106: val_loss improved from 5.36736 to 5.36701, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.3274 - MinusLogProbMetric: 5.3274 - val_loss: 5.3670 - val_MinusLogProbMetric: 5.3670 - lr: 0.0010 - 70s/epoch - 357ms/step
Epoch 107/1000
2023-09-18 19:35:24.548 
Epoch 107/1000 
	 loss: 5.3241, MinusLogProbMetric: 5.3241, val_loss: 5.5743, val_MinusLogProbMetric: 5.5743

Epoch 107: val_loss did not improve from 5.36701
196/196 - 68s - loss: 5.3241 - MinusLogProbMetric: 5.3241 - val_loss: 5.5743 - val_MinusLogProbMetric: 5.5743 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 108/1000
2023-09-18 19:36:32.715 
Epoch 108/1000 
	 loss: 5.3506, MinusLogProbMetric: 5.3506, val_loss: 5.4533, val_MinusLogProbMetric: 5.4533

Epoch 108: val_loss did not improve from 5.36701
196/196 - 68s - loss: 5.3506 - MinusLogProbMetric: 5.3506 - val_loss: 5.4533 - val_MinusLogProbMetric: 5.4533 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 109/1000
2023-09-18 19:37:40.272 
Epoch 109/1000 
	 loss: 5.3201, MinusLogProbMetric: 5.3201, val_loss: 5.5515, val_MinusLogProbMetric: 5.5515

Epoch 109: val_loss did not improve from 5.36701
196/196 - 68s - loss: 5.3201 - MinusLogProbMetric: 5.3201 - val_loss: 5.5515 - val_MinusLogProbMetric: 5.5515 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 110/1000
2023-09-18 19:38:48.237 
Epoch 110/1000 
	 loss: 5.3234, MinusLogProbMetric: 5.3234, val_loss: 5.5317, val_MinusLogProbMetric: 5.5317

Epoch 110: val_loss did not improve from 5.36701
196/196 - 68s - loss: 5.3234 - MinusLogProbMetric: 5.3234 - val_loss: 5.5317 - val_MinusLogProbMetric: 5.5317 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 111/1000
2023-09-18 19:39:56.849 
Epoch 111/1000 
	 loss: 5.3037, MinusLogProbMetric: 5.3037, val_loss: 5.3563, val_MinusLogProbMetric: 5.3563

Epoch 111: val_loss improved from 5.36701 to 5.35627, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.3037 - MinusLogProbMetric: 5.3037 - val_loss: 5.3563 - val_MinusLogProbMetric: 5.3563 - lr: 0.0010 - 70s/epoch - 355ms/step
Epoch 112/1000
2023-09-18 19:41:06.355 
Epoch 112/1000 
	 loss: 5.3153, MinusLogProbMetric: 5.3153, val_loss: 5.4087, val_MinusLogProbMetric: 5.4087

Epoch 112: val_loss did not improve from 5.35627
196/196 - 68s - loss: 5.3153 - MinusLogProbMetric: 5.3153 - val_loss: 5.4087 - val_MinusLogProbMetric: 5.4087 - lr: 0.0010 - 68s/epoch - 349ms/step
Epoch 113/1000
2023-09-18 19:42:14.778 
Epoch 113/1000 
	 loss: 5.3102, MinusLogProbMetric: 5.3102, val_loss: 5.4234, val_MinusLogProbMetric: 5.4234

Epoch 113: val_loss did not improve from 5.35627
196/196 - 68s - loss: 5.3102 - MinusLogProbMetric: 5.3102 - val_loss: 5.4234 - val_MinusLogProbMetric: 5.4234 - lr: 0.0010 - 68s/epoch - 349ms/step
Epoch 114/1000
2023-09-18 19:43:22.781 
Epoch 114/1000 
	 loss: 5.3167, MinusLogProbMetric: 5.3167, val_loss: 5.4852, val_MinusLogProbMetric: 5.4852

Epoch 114: val_loss did not improve from 5.35627
196/196 - 68s - loss: 5.3167 - MinusLogProbMetric: 5.3167 - val_loss: 5.4852 - val_MinusLogProbMetric: 5.4852 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 115/1000
2023-09-18 19:44:30.783 
Epoch 115/1000 
	 loss: 5.3291, MinusLogProbMetric: 5.3291, val_loss: 5.4210, val_MinusLogProbMetric: 5.4210

Epoch 115: val_loss did not improve from 5.35627
196/196 - 68s - loss: 5.3291 - MinusLogProbMetric: 5.3291 - val_loss: 5.4210 - val_MinusLogProbMetric: 5.4210 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 116/1000
2023-09-18 19:45:39.005 
Epoch 116/1000 
	 loss: 5.3121, MinusLogProbMetric: 5.3121, val_loss: 5.4389, val_MinusLogProbMetric: 5.4389

Epoch 116: val_loss did not improve from 5.35627
196/196 - 68s - loss: 5.3121 - MinusLogProbMetric: 5.3121 - val_loss: 5.4389 - val_MinusLogProbMetric: 5.4389 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 117/1000
2023-09-18 19:46:46.667 
Epoch 117/1000 
	 loss: 5.3035, MinusLogProbMetric: 5.3035, val_loss: 5.4025, val_MinusLogProbMetric: 5.4025

Epoch 117: val_loss did not improve from 5.35627
196/196 - 68s - loss: 5.3035 - MinusLogProbMetric: 5.3035 - val_loss: 5.4025 - val_MinusLogProbMetric: 5.4025 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 118/1000
2023-09-18 19:47:55.177 
Epoch 118/1000 
	 loss: 5.2996, MinusLogProbMetric: 5.2996, val_loss: 5.3410, val_MinusLogProbMetric: 5.3410

Epoch 118: val_loss improved from 5.35627 to 5.34098, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.2996 - MinusLogProbMetric: 5.2996 - val_loss: 5.3410 - val_MinusLogProbMetric: 5.3410 - lr: 0.0010 - 70s/epoch - 355ms/step
Epoch 119/1000
2023-09-18 19:49:04.328 
Epoch 119/1000 
	 loss: 5.3047, MinusLogProbMetric: 5.3047, val_loss: 5.4686, val_MinusLogProbMetric: 5.4686

Epoch 119: val_loss did not improve from 5.34098
196/196 - 68s - loss: 5.3047 - MinusLogProbMetric: 5.3047 - val_loss: 5.4686 - val_MinusLogProbMetric: 5.4686 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 120/1000
2023-09-18 19:50:12.739 
Epoch 120/1000 
	 loss: 5.2943, MinusLogProbMetric: 5.2943, val_loss: 5.3752, val_MinusLogProbMetric: 5.3752

Epoch 120: val_loss did not improve from 5.34098
196/196 - 68s - loss: 5.2943 - MinusLogProbMetric: 5.2943 - val_loss: 5.3752 - val_MinusLogProbMetric: 5.3752 - lr: 0.0010 - 68s/epoch - 349ms/step
Epoch 121/1000
2023-09-18 19:51:20.745 
Epoch 121/1000 
	 loss: 5.3010, MinusLogProbMetric: 5.3010, val_loss: 5.4252, val_MinusLogProbMetric: 5.4252

Epoch 121: val_loss did not improve from 5.34098
196/196 - 68s - loss: 5.3010 - MinusLogProbMetric: 5.3010 - val_loss: 5.4252 - val_MinusLogProbMetric: 5.4252 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 122/1000
2023-09-18 19:52:29.045 
Epoch 122/1000 
	 loss: 5.2969, MinusLogProbMetric: 5.2969, val_loss: 5.3817, val_MinusLogProbMetric: 5.3817

Epoch 122: val_loss did not improve from 5.34098
196/196 - 68s - loss: 5.2969 - MinusLogProbMetric: 5.2969 - val_loss: 5.3817 - val_MinusLogProbMetric: 5.3817 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 123/1000
2023-09-18 19:53:37.729 
Epoch 123/1000 
	 loss: 5.2954, MinusLogProbMetric: 5.2954, val_loss: 5.2524, val_MinusLogProbMetric: 5.2524

Epoch 123: val_loss improved from 5.34098 to 5.25239, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.2954 - MinusLogProbMetric: 5.2954 - val_loss: 5.2524 - val_MinusLogProbMetric: 5.2524 - lr: 0.0010 - 70s/epoch - 356ms/step
Epoch 124/1000
2023-09-18 19:54:46.957 
Epoch 124/1000 
	 loss: 5.2857, MinusLogProbMetric: 5.2857, val_loss: 5.4827, val_MinusLogProbMetric: 5.4827

Epoch 124: val_loss did not improve from 5.25239
196/196 - 68s - loss: 5.2857 - MinusLogProbMetric: 5.2857 - val_loss: 5.4827 - val_MinusLogProbMetric: 5.4827 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 125/1000
2023-09-18 19:55:54.720 
Epoch 125/1000 
	 loss: 5.3007, MinusLogProbMetric: 5.3007, val_loss: 5.3269, val_MinusLogProbMetric: 5.3269

Epoch 125: val_loss did not improve from 5.25239
196/196 - 68s - loss: 5.3007 - MinusLogProbMetric: 5.3007 - val_loss: 5.3269 - val_MinusLogProbMetric: 5.3269 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 126/1000
2023-09-18 19:57:03.326 
Epoch 126/1000 
	 loss: 5.2926, MinusLogProbMetric: 5.2926, val_loss: 5.4930, val_MinusLogProbMetric: 5.4930

Epoch 126: val_loss did not improve from 5.25239
196/196 - 69s - loss: 5.2926 - MinusLogProbMetric: 5.2926 - val_loss: 5.4930 - val_MinusLogProbMetric: 5.4930 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 127/1000
2023-09-18 19:58:11.867 
Epoch 127/1000 
	 loss: 5.2973, MinusLogProbMetric: 5.2973, val_loss: 5.2820, val_MinusLogProbMetric: 5.2820

Epoch 127: val_loss did not improve from 5.25239
196/196 - 69s - loss: 5.2973 - MinusLogProbMetric: 5.2973 - val_loss: 5.2820 - val_MinusLogProbMetric: 5.2820 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 128/1000
2023-09-18 19:59:19.681 
Epoch 128/1000 
	 loss: 5.2914, MinusLogProbMetric: 5.2914, val_loss: 5.3560, val_MinusLogProbMetric: 5.3560

Epoch 128: val_loss did not improve from 5.25239
196/196 - 68s - loss: 5.2914 - MinusLogProbMetric: 5.2914 - val_loss: 5.3560 - val_MinusLogProbMetric: 5.3560 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 129/1000
2023-09-18 20:00:28.336 
Epoch 129/1000 
	 loss: 5.2857, MinusLogProbMetric: 5.2857, val_loss: 5.5234, val_MinusLogProbMetric: 5.5234

Epoch 129: val_loss did not improve from 5.25239
196/196 - 69s - loss: 5.2857 - MinusLogProbMetric: 5.2857 - val_loss: 5.5234 - val_MinusLogProbMetric: 5.5234 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 130/1000
2023-09-18 20:01:35.354 
Epoch 130/1000 
	 loss: 5.3021, MinusLogProbMetric: 5.3021, val_loss: 5.3127, val_MinusLogProbMetric: 5.3127

Epoch 130: val_loss did not improve from 5.25239
196/196 - 67s - loss: 5.3021 - MinusLogProbMetric: 5.3021 - val_loss: 5.3127 - val_MinusLogProbMetric: 5.3127 - lr: 0.0010 - 67s/epoch - 342ms/step
Epoch 131/1000
2023-09-18 20:02:35.107 
Epoch 131/1000 
	 loss: 5.2716, MinusLogProbMetric: 5.2716, val_loss: 5.2776, val_MinusLogProbMetric: 5.2776

Epoch 131: val_loss did not improve from 5.25239
196/196 - 60s - loss: 5.2716 - MinusLogProbMetric: 5.2716 - val_loss: 5.2776 - val_MinusLogProbMetric: 5.2776 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 132/1000
2023-09-18 20:03:37.568 
Epoch 132/1000 
	 loss: 5.2618, MinusLogProbMetric: 5.2618, val_loss: 5.3218, val_MinusLogProbMetric: 5.3218

Epoch 132: val_loss did not improve from 5.25239
196/196 - 62s - loss: 5.2618 - MinusLogProbMetric: 5.2618 - val_loss: 5.3218 - val_MinusLogProbMetric: 5.3218 - lr: 0.0010 - 62s/epoch - 319ms/step
Epoch 133/1000
2023-09-18 20:04:42.837 
Epoch 133/1000 
	 loss: 5.2806, MinusLogProbMetric: 5.2806, val_loss: 5.2927, val_MinusLogProbMetric: 5.2927

Epoch 133: val_loss did not improve from 5.25239
196/196 - 65s - loss: 5.2806 - MinusLogProbMetric: 5.2806 - val_loss: 5.2927 - val_MinusLogProbMetric: 5.2927 - lr: 0.0010 - 65s/epoch - 333ms/step
Epoch 134/1000
2023-09-18 20:05:51.084 
Epoch 134/1000 
	 loss: 5.2698, MinusLogProbMetric: 5.2698, val_loss: 5.3359, val_MinusLogProbMetric: 5.3359

Epoch 134: val_loss did not improve from 5.25239
196/196 - 68s - loss: 5.2698 - MinusLogProbMetric: 5.2698 - val_loss: 5.3359 - val_MinusLogProbMetric: 5.3359 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 135/1000
2023-09-18 20:06:59.494 
Epoch 135/1000 
	 loss: 5.2557, MinusLogProbMetric: 5.2557, val_loss: 5.3365, val_MinusLogProbMetric: 5.3365

Epoch 135: val_loss did not improve from 5.25239
196/196 - 68s - loss: 5.2557 - MinusLogProbMetric: 5.2557 - val_loss: 5.3365 - val_MinusLogProbMetric: 5.3365 - lr: 0.0010 - 68s/epoch - 349ms/step
Epoch 136/1000
2023-09-18 20:08:08.030 
Epoch 136/1000 
	 loss: 5.2710, MinusLogProbMetric: 5.2710, val_loss: 5.4159, val_MinusLogProbMetric: 5.4159

Epoch 136: val_loss did not improve from 5.25239
196/196 - 69s - loss: 5.2710 - MinusLogProbMetric: 5.2710 - val_loss: 5.4159 - val_MinusLogProbMetric: 5.4159 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 137/1000
2023-09-18 20:09:15.868 
Epoch 137/1000 
	 loss: 5.2730, MinusLogProbMetric: 5.2730, val_loss: 5.2435, val_MinusLogProbMetric: 5.2435

Epoch 137: val_loss improved from 5.25239 to 5.24352, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 69s - loss: 5.2730 - MinusLogProbMetric: 5.2730 - val_loss: 5.2435 - val_MinusLogProbMetric: 5.2435 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 138/1000
2023-09-18 20:10:25.523 
Epoch 138/1000 
	 loss: 5.2909, MinusLogProbMetric: 5.2909, val_loss: 5.3670, val_MinusLogProbMetric: 5.3670

Epoch 138: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2909 - MinusLogProbMetric: 5.2909 - val_loss: 5.3670 - val_MinusLogProbMetric: 5.3670 - lr: 0.0010 - 68s/epoch - 349ms/step
Epoch 139/1000
2023-09-18 20:11:33.487 
Epoch 139/1000 
	 loss: 5.2828, MinusLogProbMetric: 5.2828, val_loss: 5.4153, val_MinusLogProbMetric: 5.4153

Epoch 139: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2828 - MinusLogProbMetric: 5.2828 - val_loss: 5.4153 - val_MinusLogProbMetric: 5.4153 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 140/1000
2023-09-18 20:12:40.880 
Epoch 140/1000 
	 loss: 5.2688, MinusLogProbMetric: 5.2688, val_loss: 5.3965, val_MinusLogProbMetric: 5.3965

Epoch 140: val_loss did not improve from 5.24352
196/196 - 67s - loss: 5.2688 - MinusLogProbMetric: 5.2688 - val_loss: 5.3965 - val_MinusLogProbMetric: 5.3965 - lr: 0.0010 - 67s/epoch - 344ms/step
Epoch 141/1000
2023-09-18 20:13:48.634 
Epoch 141/1000 
	 loss: 5.2977, MinusLogProbMetric: 5.2977, val_loss: 5.3057, val_MinusLogProbMetric: 5.3057

Epoch 141: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2977 - MinusLogProbMetric: 5.2977 - val_loss: 5.3057 - val_MinusLogProbMetric: 5.3057 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 142/1000
2023-09-18 20:14:56.909 
Epoch 142/1000 
	 loss: 5.2734, MinusLogProbMetric: 5.2734, val_loss: 5.2921, val_MinusLogProbMetric: 5.2921

Epoch 142: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2734 - MinusLogProbMetric: 5.2734 - val_loss: 5.2921 - val_MinusLogProbMetric: 5.2921 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 143/1000
2023-09-18 20:16:05.052 
Epoch 143/1000 
	 loss: 5.2658, MinusLogProbMetric: 5.2658, val_loss: 5.4133, val_MinusLogProbMetric: 5.4133

Epoch 143: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2658 - MinusLogProbMetric: 5.2658 - val_loss: 5.4133 - val_MinusLogProbMetric: 5.4133 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 144/1000
2023-09-18 20:17:12.658 
Epoch 144/1000 
	 loss: 5.2736, MinusLogProbMetric: 5.2736, val_loss: 5.3127, val_MinusLogProbMetric: 5.3127

Epoch 144: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2736 - MinusLogProbMetric: 5.2736 - val_loss: 5.3127 - val_MinusLogProbMetric: 5.3127 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 145/1000
2023-09-18 20:18:20.745 
Epoch 145/1000 
	 loss: 5.2487, MinusLogProbMetric: 5.2487, val_loss: 5.2732, val_MinusLogProbMetric: 5.2732

Epoch 145: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2487 - MinusLogProbMetric: 5.2487 - val_loss: 5.2732 - val_MinusLogProbMetric: 5.2732 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 146/1000
2023-09-18 20:19:28.502 
Epoch 146/1000 
	 loss: 5.2527, MinusLogProbMetric: 5.2527, val_loss: 5.4695, val_MinusLogProbMetric: 5.4695

Epoch 146: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2527 - MinusLogProbMetric: 5.2527 - val_loss: 5.4695 - val_MinusLogProbMetric: 5.4695 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 147/1000
2023-09-18 20:20:36.260 
Epoch 147/1000 
	 loss: 5.2623, MinusLogProbMetric: 5.2623, val_loss: 5.2673, val_MinusLogProbMetric: 5.2673

Epoch 147: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2623 - MinusLogProbMetric: 5.2623 - val_loss: 5.2673 - val_MinusLogProbMetric: 5.2673 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 148/1000
2023-09-18 20:21:44.134 
Epoch 148/1000 
	 loss: 5.2433, MinusLogProbMetric: 5.2433, val_loss: 5.2921, val_MinusLogProbMetric: 5.2921

Epoch 148: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2433 - MinusLogProbMetric: 5.2433 - val_loss: 5.2921 - val_MinusLogProbMetric: 5.2921 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 149/1000
2023-09-18 20:22:52.507 
Epoch 149/1000 
	 loss: 5.2618, MinusLogProbMetric: 5.2618, val_loss: 5.3281, val_MinusLogProbMetric: 5.3281

Epoch 149: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2618 - MinusLogProbMetric: 5.2618 - val_loss: 5.3281 - val_MinusLogProbMetric: 5.3281 - lr: 0.0010 - 68s/epoch - 349ms/step
Epoch 150/1000
2023-09-18 20:24:00.340 
Epoch 150/1000 
	 loss: 5.2828, MinusLogProbMetric: 5.2828, val_loss: 5.3765, val_MinusLogProbMetric: 5.3765

Epoch 150: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2828 - MinusLogProbMetric: 5.2828 - val_loss: 5.3765 - val_MinusLogProbMetric: 5.3765 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 151/1000
2023-09-18 20:25:07.914 
Epoch 151/1000 
	 loss: 5.2432, MinusLogProbMetric: 5.2432, val_loss: 5.2919, val_MinusLogProbMetric: 5.2919

Epoch 151: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2432 - MinusLogProbMetric: 5.2432 - val_loss: 5.2919 - val_MinusLogProbMetric: 5.2919 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 152/1000
2023-09-18 20:26:15.322 
Epoch 152/1000 
	 loss: 5.2605, MinusLogProbMetric: 5.2605, val_loss: 5.4123, val_MinusLogProbMetric: 5.4123

Epoch 152: val_loss did not improve from 5.24352
196/196 - 67s - loss: 5.2605 - MinusLogProbMetric: 5.2605 - val_loss: 5.4123 - val_MinusLogProbMetric: 5.4123 - lr: 0.0010 - 67s/epoch - 344ms/step
Epoch 153/1000
2023-09-18 20:27:23.117 
Epoch 153/1000 
	 loss: 5.2526, MinusLogProbMetric: 5.2526, val_loss: 5.3637, val_MinusLogProbMetric: 5.3637

Epoch 153: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2526 - MinusLogProbMetric: 5.2526 - val_loss: 5.3637 - val_MinusLogProbMetric: 5.3637 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 154/1000
2023-09-18 20:28:30.831 
Epoch 154/1000 
	 loss: 5.2544, MinusLogProbMetric: 5.2544, val_loss: 5.3622, val_MinusLogProbMetric: 5.3622

Epoch 154: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2544 - MinusLogProbMetric: 5.2544 - val_loss: 5.3622 - val_MinusLogProbMetric: 5.3622 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 155/1000
2023-09-18 20:29:38.605 
Epoch 155/1000 
	 loss: 5.2663, MinusLogProbMetric: 5.2663, val_loss: 5.4711, val_MinusLogProbMetric: 5.4711

Epoch 155: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2663 - MinusLogProbMetric: 5.2663 - val_loss: 5.4711 - val_MinusLogProbMetric: 5.4711 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 156/1000
2023-09-18 20:30:46.158 
Epoch 156/1000 
	 loss: 5.2713, MinusLogProbMetric: 5.2713, val_loss: 5.3376, val_MinusLogProbMetric: 5.3376

Epoch 156: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2713 - MinusLogProbMetric: 5.2713 - val_loss: 5.3376 - val_MinusLogProbMetric: 5.3376 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 157/1000
2023-09-18 20:31:53.682 
Epoch 157/1000 
	 loss: 5.2507, MinusLogProbMetric: 5.2507, val_loss: 5.3185, val_MinusLogProbMetric: 5.3185

Epoch 157: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2507 - MinusLogProbMetric: 5.2507 - val_loss: 5.3185 - val_MinusLogProbMetric: 5.3185 - lr: 0.0010 - 68s/epoch - 344ms/step
Epoch 158/1000
2023-09-18 20:33:01.671 
Epoch 158/1000 
	 loss: 5.2594, MinusLogProbMetric: 5.2594, val_loss: 5.2692, val_MinusLogProbMetric: 5.2692

Epoch 158: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2594 - MinusLogProbMetric: 5.2594 - val_loss: 5.2692 - val_MinusLogProbMetric: 5.2692 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 159/1000
2023-09-18 20:33:54.825 
Epoch 159/1000 
	 loss: 5.2517, MinusLogProbMetric: 5.2517, val_loss: 5.3403, val_MinusLogProbMetric: 5.3403

Epoch 159: val_loss did not improve from 5.24352
196/196 - 53s - loss: 5.2517 - MinusLogProbMetric: 5.2517 - val_loss: 5.3403 - val_MinusLogProbMetric: 5.3403 - lr: 0.0010 - 53s/epoch - 271ms/step
Epoch 160/1000
2023-09-18 20:34:49.568 
Epoch 160/1000 
	 loss: 5.2560, MinusLogProbMetric: 5.2560, val_loss: 5.4611, val_MinusLogProbMetric: 5.4611

Epoch 160: val_loss did not improve from 5.24352
196/196 - 55s - loss: 5.2560 - MinusLogProbMetric: 5.2560 - val_loss: 5.4611 - val_MinusLogProbMetric: 5.4611 - lr: 0.0010 - 55s/epoch - 279ms/step
Epoch 161/1000
2023-09-18 20:35:52.171 
Epoch 161/1000 
	 loss: 5.2523, MinusLogProbMetric: 5.2523, val_loss: 5.3905, val_MinusLogProbMetric: 5.3905

Epoch 161: val_loss did not improve from 5.24352
196/196 - 63s - loss: 5.2523 - MinusLogProbMetric: 5.2523 - val_loss: 5.3905 - val_MinusLogProbMetric: 5.3905 - lr: 0.0010 - 63s/epoch - 319ms/step
Epoch 162/1000
2023-09-18 20:36:58.948 
Epoch 162/1000 
	 loss: 5.2398, MinusLogProbMetric: 5.2398, val_loss: 5.3038, val_MinusLogProbMetric: 5.3038

Epoch 162: val_loss did not improve from 5.24352
196/196 - 67s - loss: 5.2398 - MinusLogProbMetric: 5.2398 - val_loss: 5.3038 - val_MinusLogProbMetric: 5.3038 - lr: 0.0010 - 67s/epoch - 341ms/step
Epoch 163/1000
2023-09-18 20:38:06.884 
Epoch 163/1000 
	 loss: 5.2533, MinusLogProbMetric: 5.2533, val_loss: 5.4609, val_MinusLogProbMetric: 5.4609

Epoch 163: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2533 - MinusLogProbMetric: 5.2533 - val_loss: 5.4609 - val_MinusLogProbMetric: 5.4609 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 164/1000
2023-09-18 20:39:15.026 
Epoch 164/1000 
	 loss: 5.2587, MinusLogProbMetric: 5.2587, val_loss: 5.4565, val_MinusLogProbMetric: 5.4565

Epoch 164: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2587 - MinusLogProbMetric: 5.2587 - val_loss: 5.4565 - val_MinusLogProbMetric: 5.4565 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 165/1000
2023-09-18 20:40:23.115 
Epoch 165/1000 
	 loss: 5.2448, MinusLogProbMetric: 5.2448, val_loss: 5.3891, val_MinusLogProbMetric: 5.3891

Epoch 165: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2448 - MinusLogProbMetric: 5.2448 - val_loss: 5.3891 - val_MinusLogProbMetric: 5.3891 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 166/1000
2023-09-18 20:41:30.729 
Epoch 166/1000 
	 loss: 5.2335, MinusLogProbMetric: 5.2335, val_loss: 5.3003, val_MinusLogProbMetric: 5.3003

Epoch 166: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2335 - MinusLogProbMetric: 5.2335 - val_loss: 5.3003 - val_MinusLogProbMetric: 5.3003 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 167/1000
2023-09-18 20:42:38.267 
Epoch 167/1000 
	 loss: 5.2490, MinusLogProbMetric: 5.2490, val_loss: 5.3813, val_MinusLogProbMetric: 5.3813

Epoch 167: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2490 - MinusLogProbMetric: 5.2490 - val_loss: 5.3813 - val_MinusLogProbMetric: 5.3813 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 168/1000
2023-09-18 20:43:46.427 
Epoch 168/1000 
	 loss: 5.2413, MinusLogProbMetric: 5.2413, val_loss: 5.3152, val_MinusLogProbMetric: 5.3152

Epoch 168: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2413 - MinusLogProbMetric: 5.2413 - val_loss: 5.3152 - val_MinusLogProbMetric: 5.3152 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 169/1000
2023-09-18 20:44:54.006 
Epoch 169/1000 
	 loss: 5.2284, MinusLogProbMetric: 5.2284, val_loss: 5.3047, val_MinusLogProbMetric: 5.3047

Epoch 169: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2284 - MinusLogProbMetric: 5.2284 - val_loss: 5.3047 - val_MinusLogProbMetric: 5.3047 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 170/1000
2023-09-18 20:46:01.612 
Epoch 170/1000 
	 loss: 5.2342, MinusLogProbMetric: 5.2342, val_loss: 5.3703, val_MinusLogProbMetric: 5.3703

Epoch 170: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2342 - MinusLogProbMetric: 5.2342 - val_loss: 5.3703 - val_MinusLogProbMetric: 5.3703 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 171/1000
2023-09-18 20:47:09.611 
Epoch 171/1000 
	 loss: 5.2230, MinusLogProbMetric: 5.2230, val_loss: 5.3384, val_MinusLogProbMetric: 5.3384

Epoch 171: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2230 - MinusLogProbMetric: 5.2230 - val_loss: 5.3384 - val_MinusLogProbMetric: 5.3384 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 172/1000
2023-09-18 20:48:17.201 
Epoch 172/1000 
	 loss: 5.2290, MinusLogProbMetric: 5.2290, val_loss: 5.3313, val_MinusLogProbMetric: 5.3313

Epoch 172: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2290 - MinusLogProbMetric: 5.2290 - val_loss: 5.3313 - val_MinusLogProbMetric: 5.3313 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 173/1000
2023-09-18 20:49:24.852 
Epoch 173/1000 
	 loss: 5.2258, MinusLogProbMetric: 5.2258, val_loss: 5.2483, val_MinusLogProbMetric: 5.2483

Epoch 173: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2258 - MinusLogProbMetric: 5.2258 - val_loss: 5.2483 - val_MinusLogProbMetric: 5.2483 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 174/1000
2023-09-18 20:50:32.729 
Epoch 174/1000 
	 loss: 5.2096, MinusLogProbMetric: 5.2096, val_loss: 5.4877, val_MinusLogProbMetric: 5.4877

Epoch 174: val_loss did not improve from 5.24352
196/196 - 68s - loss: 5.2096 - MinusLogProbMetric: 5.2096 - val_loss: 5.4877 - val_MinusLogProbMetric: 5.4877 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 175/1000
2023-09-18 20:51:40.629 
Epoch 175/1000 
	 loss: 5.2285, MinusLogProbMetric: 5.2285, val_loss: 5.2392, val_MinusLogProbMetric: 5.2392

Epoch 175: val_loss improved from 5.24352 to 5.23921, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 69s - loss: 5.2285 - MinusLogProbMetric: 5.2285 - val_loss: 5.2392 - val_MinusLogProbMetric: 5.2392 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 176/1000
2023-09-18 20:52:49.019 
Epoch 176/1000 
	 loss: 5.2319, MinusLogProbMetric: 5.2319, val_loss: 5.2433, val_MinusLogProbMetric: 5.2433

Epoch 176: val_loss did not improve from 5.23921
196/196 - 67s - loss: 5.2319 - MinusLogProbMetric: 5.2319 - val_loss: 5.2433 - val_MinusLogProbMetric: 5.2433 - lr: 0.0010 - 67s/epoch - 343ms/step
Epoch 177/1000
2023-09-18 20:53:57.442 
Epoch 177/1000 
	 loss: 5.2250, MinusLogProbMetric: 5.2250, val_loss: 5.3229, val_MinusLogProbMetric: 5.3229

Epoch 177: val_loss did not improve from 5.23921
196/196 - 68s - loss: 5.2250 - MinusLogProbMetric: 5.2250 - val_loss: 5.3229 - val_MinusLogProbMetric: 5.3229 - lr: 0.0010 - 68s/epoch - 349ms/step
Epoch 178/1000
2023-09-18 20:55:05.081 
Epoch 178/1000 
	 loss: 5.2283, MinusLogProbMetric: 5.2283, val_loss: 5.3917, val_MinusLogProbMetric: 5.3917

Epoch 178: val_loss did not improve from 5.23921
196/196 - 68s - loss: 5.2283 - MinusLogProbMetric: 5.2283 - val_loss: 5.3917 - val_MinusLogProbMetric: 5.3917 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 179/1000
2023-09-18 20:56:13.432 
Epoch 179/1000 
	 loss: 5.2259, MinusLogProbMetric: 5.2259, val_loss: 5.4276, val_MinusLogProbMetric: 5.4276

Epoch 179: val_loss did not improve from 5.23921
196/196 - 68s - loss: 5.2259 - MinusLogProbMetric: 5.2259 - val_loss: 5.4276 - val_MinusLogProbMetric: 5.4276 - lr: 0.0010 - 68s/epoch - 349ms/step
Epoch 180/1000
2023-09-18 20:57:21.585 
Epoch 180/1000 
	 loss: 5.2371, MinusLogProbMetric: 5.2371, val_loss: 5.3828, val_MinusLogProbMetric: 5.3828

Epoch 180: val_loss did not improve from 5.23921
196/196 - 68s - loss: 5.2371 - MinusLogProbMetric: 5.2371 - val_loss: 5.3828 - val_MinusLogProbMetric: 5.3828 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 181/1000
2023-09-18 20:58:29.143 
Epoch 181/1000 
	 loss: 5.2468, MinusLogProbMetric: 5.2468, val_loss: 5.3040, val_MinusLogProbMetric: 5.3040

Epoch 181: val_loss did not improve from 5.23921
196/196 - 68s - loss: 5.2468 - MinusLogProbMetric: 5.2468 - val_loss: 5.3040 - val_MinusLogProbMetric: 5.3040 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 182/1000
2023-09-18 20:59:37.451 
Epoch 182/1000 
	 loss: 5.2345, MinusLogProbMetric: 5.2345, val_loss: 5.2877, val_MinusLogProbMetric: 5.2877

Epoch 182: val_loss did not improve from 5.23921
196/196 - 68s - loss: 5.2345 - MinusLogProbMetric: 5.2345 - val_loss: 5.2877 - val_MinusLogProbMetric: 5.2877 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 183/1000
2023-09-18 21:00:45.607 
Epoch 183/1000 
	 loss: 5.2508, MinusLogProbMetric: 5.2508, val_loss: 5.2850, val_MinusLogProbMetric: 5.2850

Epoch 183: val_loss did not improve from 5.23921
196/196 - 68s - loss: 5.2508 - MinusLogProbMetric: 5.2508 - val_loss: 5.2850 - val_MinusLogProbMetric: 5.2850 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 184/1000
2023-09-18 21:01:53.193 
Epoch 184/1000 
	 loss: 5.2373, MinusLogProbMetric: 5.2373, val_loss: 5.3388, val_MinusLogProbMetric: 5.3388

Epoch 184: val_loss did not improve from 5.23921
196/196 - 68s - loss: 5.2373 - MinusLogProbMetric: 5.2373 - val_loss: 5.3388 - val_MinusLogProbMetric: 5.3388 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 185/1000
2023-09-18 21:03:00.834 
Epoch 185/1000 
	 loss: 5.2365, MinusLogProbMetric: 5.2365, val_loss: 5.3858, val_MinusLogProbMetric: 5.3858

Epoch 185: val_loss did not improve from 5.23921
196/196 - 68s - loss: 5.2365 - MinusLogProbMetric: 5.2365 - val_loss: 5.3858 - val_MinusLogProbMetric: 5.3858 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 186/1000
2023-09-18 21:04:08.859 
Epoch 186/1000 
	 loss: 5.2218, MinusLogProbMetric: 5.2218, val_loss: 5.3073, val_MinusLogProbMetric: 5.3073

Epoch 186: val_loss did not improve from 5.23921
196/196 - 68s - loss: 5.2218 - MinusLogProbMetric: 5.2218 - val_loss: 5.3073 - val_MinusLogProbMetric: 5.3073 - lr: 0.0010 - 68s/epoch - 347ms/step
Epoch 187/1000
2023-09-18 21:05:17.286 
Epoch 187/1000 
	 loss: 5.2290, MinusLogProbMetric: 5.2290, val_loss: 5.4652, val_MinusLogProbMetric: 5.4652

Epoch 187: val_loss did not improve from 5.23921
196/196 - 68s - loss: 5.2290 - MinusLogProbMetric: 5.2290 - val_loss: 5.4652 - val_MinusLogProbMetric: 5.4652 - lr: 0.0010 - 68s/epoch - 349ms/step
Epoch 188/1000
2023-09-18 21:06:25.720 
Epoch 188/1000 
	 loss: 5.2453, MinusLogProbMetric: 5.2453, val_loss: 5.3159, val_MinusLogProbMetric: 5.3159

Epoch 188: val_loss did not improve from 5.23921
196/196 - 68s - loss: 5.2453 - MinusLogProbMetric: 5.2453 - val_loss: 5.3159 - val_MinusLogProbMetric: 5.3159 - lr: 0.0010 - 68s/epoch - 349ms/step
Epoch 189/1000
2023-09-18 21:07:33.030 
Epoch 189/1000 
	 loss: 5.2156, MinusLogProbMetric: 5.2156, val_loss: 5.3055, val_MinusLogProbMetric: 5.3055

Epoch 189: val_loss did not improve from 5.23921
196/196 - 67s - loss: 5.2156 - MinusLogProbMetric: 5.2156 - val_loss: 5.3055 - val_MinusLogProbMetric: 5.3055 - lr: 0.0010 - 67s/epoch - 343ms/step
Epoch 190/1000
2023-09-18 21:08:40.474 
Epoch 190/1000 
	 loss: 5.2209, MinusLogProbMetric: 5.2209, val_loss: 5.3641, val_MinusLogProbMetric: 5.3641

Epoch 190: val_loss did not improve from 5.23921
196/196 - 67s - loss: 5.2209 - MinusLogProbMetric: 5.2209 - val_loss: 5.3641 - val_MinusLogProbMetric: 5.3641 - lr: 0.0010 - 67s/epoch - 344ms/step
Epoch 191/1000
2023-09-18 21:09:47.763 
Epoch 191/1000 
	 loss: 5.2220, MinusLogProbMetric: 5.2220, val_loss: 5.3149, val_MinusLogProbMetric: 5.3149

Epoch 191: val_loss did not improve from 5.23921
196/196 - 67s - loss: 5.2220 - MinusLogProbMetric: 5.2220 - val_loss: 5.3149 - val_MinusLogProbMetric: 5.3149 - lr: 0.0010 - 67s/epoch - 343ms/step
Epoch 192/1000
2023-09-18 21:10:55.520 
Epoch 192/1000 
	 loss: 5.2158, MinusLogProbMetric: 5.2158, val_loss: 5.2637, val_MinusLogProbMetric: 5.2637

Epoch 192: val_loss did not improve from 5.23921
196/196 - 68s - loss: 5.2158 - MinusLogProbMetric: 5.2158 - val_loss: 5.2637 - val_MinusLogProbMetric: 5.2637 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 193/1000
2023-09-18 21:12:05.563 
Epoch 193/1000 
	 loss: 5.2181, MinusLogProbMetric: 5.2181, val_loss: 5.4083, val_MinusLogProbMetric: 5.4083

Epoch 193: val_loss did not improve from 5.23921
196/196 - 70s - loss: 5.2181 - MinusLogProbMetric: 5.2181 - val_loss: 5.4083 - val_MinusLogProbMetric: 5.4083 - lr: 0.0010 - 70s/epoch - 357ms/step
Epoch 194/1000
2023-09-18 21:13:14.867 
Epoch 194/1000 
	 loss: 5.2092, MinusLogProbMetric: 5.2092, val_loss: 5.3434, val_MinusLogProbMetric: 5.3434

Epoch 194: val_loss did not improve from 5.23921
196/196 - 69s - loss: 5.2092 - MinusLogProbMetric: 5.2092 - val_loss: 5.3434 - val_MinusLogProbMetric: 5.3434 - lr: 0.0010 - 69s/epoch - 354ms/step
Epoch 195/1000
2023-09-18 21:14:22.198 
Epoch 195/1000 
	 loss: 5.2333, MinusLogProbMetric: 5.2333, val_loss: 5.2890, val_MinusLogProbMetric: 5.2890

Epoch 195: val_loss did not improve from 5.23921
196/196 - 67s - loss: 5.2333 - MinusLogProbMetric: 5.2333 - val_loss: 5.2890 - val_MinusLogProbMetric: 5.2890 - lr: 0.0010 - 67s/epoch - 343ms/step
Epoch 196/1000
2023-09-18 21:15:22.551 
Epoch 196/1000 
	 loss: 5.2134, MinusLogProbMetric: 5.2134, val_loss: 5.2661, val_MinusLogProbMetric: 5.2661

Epoch 196: val_loss did not improve from 5.23921
196/196 - 60s - loss: 5.2134 - MinusLogProbMetric: 5.2134 - val_loss: 5.2661 - val_MinusLogProbMetric: 5.2661 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 197/1000
2023-09-18 21:16:19.674 
Epoch 197/1000 
	 loss: 5.2489, MinusLogProbMetric: 5.2489, val_loss: 5.3964, val_MinusLogProbMetric: 5.3964

Epoch 197: val_loss did not improve from 5.23921
196/196 - 57s - loss: 5.2489 - MinusLogProbMetric: 5.2489 - val_loss: 5.3964 - val_MinusLogProbMetric: 5.3964 - lr: 0.0010 - 57s/epoch - 291ms/step
Epoch 198/1000
2023-09-18 21:17:22.160 
Epoch 198/1000 
	 loss: 5.2240, MinusLogProbMetric: 5.2240, val_loss: 5.3399, val_MinusLogProbMetric: 5.3399

Epoch 198: val_loss did not improve from 5.23921
196/196 - 62s - loss: 5.2240 - MinusLogProbMetric: 5.2240 - val_loss: 5.3399 - val_MinusLogProbMetric: 5.3399 - lr: 0.0010 - 62s/epoch - 319ms/step
Epoch 199/1000
2023-09-18 21:18:20.002 
Epoch 199/1000 
	 loss: 5.2220, MinusLogProbMetric: 5.2220, val_loss: 5.2693, val_MinusLogProbMetric: 5.2693

Epoch 199: val_loss did not improve from 5.23921
196/196 - 58s - loss: 5.2220 - MinusLogProbMetric: 5.2220 - val_loss: 5.2693 - val_MinusLogProbMetric: 5.2693 - lr: 0.0010 - 58s/epoch - 295ms/step
Epoch 200/1000
2023-09-18 21:19:27.914 
Epoch 200/1000 
	 loss: 5.2098, MinusLogProbMetric: 5.2098, val_loss: 5.2871, val_MinusLogProbMetric: 5.2871

Epoch 200: val_loss did not improve from 5.23921
196/196 - 68s - loss: 5.2098 - MinusLogProbMetric: 5.2098 - val_loss: 5.2871 - val_MinusLogProbMetric: 5.2871 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 201/1000
2023-09-18 21:20:33.602 
Epoch 201/1000 
	 loss: 5.2190, MinusLogProbMetric: 5.2190, val_loss: 5.2736, val_MinusLogProbMetric: 5.2736

Epoch 201: val_loss did not improve from 5.23921
196/196 - 66s - loss: 5.2190 - MinusLogProbMetric: 5.2190 - val_loss: 5.2736 - val_MinusLogProbMetric: 5.2736 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 202/1000
2023-09-18 21:21:41.407 
Epoch 202/1000 
	 loss: 5.2032, MinusLogProbMetric: 5.2032, val_loss: 5.5477, val_MinusLogProbMetric: 5.5477

Epoch 202: val_loss did not improve from 5.23921
196/196 - 68s - loss: 5.2032 - MinusLogProbMetric: 5.2032 - val_loss: 5.5477 - val_MinusLogProbMetric: 5.5477 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 203/1000
2023-09-18 21:22:48.629 
Epoch 203/1000 
	 loss: 5.2208, MinusLogProbMetric: 5.2208, val_loss: 5.3327, val_MinusLogProbMetric: 5.3327

Epoch 203: val_loss did not improve from 5.23921
196/196 - 67s - loss: 5.2208 - MinusLogProbMetric: 5.2208 - val_loss: 5.3327 - val_MinusLogProbMetric: 5.3327 - lr: 0.0010 - 67s/epoch - 343ms/step
Epoch 204/1000
2023-09-18 21:23:56.346 
Epoch 204/1000 
	 loss: 5.2064, MinusLogProbMetric: 5.2064, val_loss: 5.2979, val_MinusLogProbMetric: 5.2979

Epoch 204: val_loss did not improve from 5.23921
196/196 - 68s - loss: 5.2064 - MinusLogProbMetric: 5.2064 - val_loss: 5.2979 - val_MinusLogProbMetric: 5.2979 - lr: 0.0010 - 68s/epoch - 345ms/step
Epoch 205/1000
2023-09-18 21:25:02.162 
Epoch 205/1000 
	 loss: 5.2005, MinusLogProbMetric: 5.2005, val_loss: 5.2484, val_MinusLogProbMetric: 5.2484

Epoch 205: val_loss did not improve from 5.23921
196/196 - 66s - loss: 5.2005 - MinusLogProbMetric: 5.2005 - val_loss: 5.2484 - val_MinusLogProbMetric: 5.2484 - lr: 0.0010 - 66s/epoch - 336ms/step
Epoch 206/1000
2023-09-18 21:25:56.035 
Epoch 206/1000 
	 loss: 5.2116, MinusLogProbMetric: 5.2116, val_loss: 5.2867, val_MinusLogProbMetric: 5.2867

Epoch 206: val_loss did not improve from 5.23921
196/196 - 54s - loss: 5.2116 - MinusLogProbMetric: 5.2116 - val_loss: 5.2867 - val_MinusLogProbMetric: 5.2867 - lr: 0.0010 - 54s/epoch - 275ms/step
Epoch 207/1000
2023-09-18 21:26:49.716 
Epoch 207/1000 
	 loss: 5.2130, MinusLogProbMetric: 5.2130, val_loss: 5.3504, val_MinusLogProbMetric: 5.3504

Epoch 207: val_loss did not improve from 5.23921
196/196 - 54s - loss: 5.2130 - MinusLogProbMetric: 5.2130 - val_loss: 5.3504 - val_MinusLogProbMetric: 5.3504 - lr: 0.0010 - 54s/epoch - 274ms/step
Epoch 208/1000
2023-09-18 21:27:55.399 
Epoch 208/1000 
	 loss: 5.1941, MinusLogProbMetric: 5.1941, val_loss: 5.3604, val_MinusLogProbMetric: 5.3604

Epoch 208: val_loss did not improve from 5.23921
196/196 - 66s - loss: 5.1941 - MinusLogProbMetric: 5.1941 - val_loss: 5.3604 - val_MinusLogProbMetric: 5.3604 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 209/1000
2023-09-18 21:29:01.081 
Epoch 209/1000 
	 loss: 5.2075, MinusLogProbMetric: 5.2075, val_loss: 5.3094, val_MinusLogProbMetric: 5.3094

Epoch 209: val_loss did not improve from 5.23921
196/196 - 66s - loss: 5.2075 - MinusLogProbMetric: 5.2075 - val_loss: 5.3094 - val_MinusLogProbMetric: 5.3094 - lr: 0.0010 - 66s/epoch - 335ms/step
Epoch 210/1000
2023-09-18 21:30:08.444 
Epoch 210/1000 
	 loss: 5.2017, MinusLogProbMetric: 5.2017, val_loss: 5.3151, val_MinusLogProbMetric: 5.3151

Epoch 210: val_loss did not improve from 5.23921
196/196 - 67s - loss: 5.2017 - MinusLogProbMetric: 5.2017 - val_loss: 5.3151 - val_MinusLogProbMetric: 5.3151 - lr: 0.0010 - 67s/epoch - 344ms/step
Epoch 211/1000
2023-09-18 21:31:15.703 
Epoch 211/1000 
	 loss: 5.2115, MinusLogProbMetric: 5.2115, val_loss: 5.4556, val_MinusLogProbMetric: 5.4556

Epoch 211: val_loss did not improve from 5.23921
196/196 - 67s - loss: 5.2115 - MinusLogProbMetric: 5.2115 - val_loss: 5.4556 - val_MinusLogProbMetric: 5.4556 - lr: 0.0010 - 67s/epoch - 343ms/step
Epoch 212/1000
2023-09-18 21:32:22.143 
Epoch 212/1000 
	 loss: 5.2257, MinusLogProbMetric: 5.2257, val_loss: 5.3043, val_MinusLogProbMetric: 5.3043

Epoch 212: val_loss did not improve from 5.23921
196/196 - 66s - loss: 5.2257 - MinusLogProbMetric: 5.2257 - val_loss: 5.3043 - val_MinusLogProbMetric: 5.3043 - lr: 0.0010 - 66s/epoch - 339ms/step
Epoch 213/1000
2023-09-18 21:33:30.402 
Epoch 213/1000 
	 loss: 5.2163, MinusLogProbMetric: 5.2163, val_loss: 5.3591, val_MinusLogProbMetric: 5.3591

Epoch 213: val_loss did not improve from 5.23921
196/196 - 68s - loss: 5.2163 - MinusLogProbMetric: 5.2163 - val_loss: 5.3591 - val_MinusLogProbMetric: 5.3591 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 214/1000
2023-09-18 21:34:34.256 
Epoch 214/1000 
	 loss: 5.2132, MinusLogProbMetric: 5.2132, val_loss: 5.2367, val_MinusLogProbMetric: 5.2367

Epoch 214: val_loss improved from 5.23921 to 5.23672, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 65s - loss: 5.2132 - MinusLogProbMetric: 5.2132 - val_loss: 5.2367 - val_MinusLogProbMetric: 5.2367 - lr: 0.0010 - 65s/epoch - 332ms/step
Epoch 215/1000
2023-09-18 21:35:33.679 
Epoch 215/1000 
	 loss: 5.2242, MinusLogProbMetric: 5.2242, val_loss: 5.2949, val_MinusLogProbMetric: 5.2949

Epoch 215: val_loss did not improve from 5.23672
196/196 - 58s - loss: 5.2242 - MinusLogProbMetric: 5.2242 - val_loss: 5.2949 - val_MinusLogProbMetric: 5.2949 - lr: 0.0010 - 58s/epoch - 297ms/step
Epoch 216/1000
2023-09-18 21:36:37.610 
Epoch 216/1000 
	 loss: 5.1988, MinusLogProbMetric: 5.1988, val_loss: 5.3218, val_MinusLogProbMetric: 5.3218

Epoch 216: val_loss did not improve from 5.23672
196/196 - 64s - loss: 5.1988 - MinusLogProbMetric: 5.1988 - val_loss: 5.3218 - val_MinusLogProbMetric: 5.3218 - lr: 0.0010 - 64s/epoch - 326ms/step
Epoch 217/1000
2023-09-18 21:37:45.500 
Epoch 217/1000 
	 loss: 5.1950, MinusLogProbMetric: 5.1950, val_loss: 5.2573, val_MinusLogProbMetric: 5.2573

Epoch 217: val_loss did not improve from 5.23672
196/196 - 68s - loss: 5.1950 - MinusLogProbMetric: 5.1950 - val_loss: 5.2573 - val_MinusLogProbMetric: 5.2573 - lr: 0.0010 - 68s/epoch - 346ms/step
Epoch 218/1000
2023-09-18 21:38:54.030 
Epoch 218/1000 
	 loss: 5.2089, MinusLogProbMetric: 5.2089, val_loss: 5.2467, val_MinusLogProbMetric: 5.2467

Epoch 218: val_loss did not improve from 5.23672
196/196 - 69s - loss: 5.2089 - MinusLogProbMetric: 5.2089 - val_loss: 5.2467 - val_MinusLogProbMetric: 5.2467 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 219/1000
2023-09-18 21:40:03.178 
Epoch 219/1000 
	 loss: 5.1814, MinusLogProbMetric: 5.1814, val_loss: 5.4232, val_MinusLogProbMetric: 5.4232

Epoch 219: val_loss did not improve from 5.23672
196/196 - 69s - loss: 5.1814 - MinusLogProbMetric: 5.1814 - val_loss: 5.4232 - val_MinusLogProbMetric: 5.4232 - lr: 0.0010 - 69s/epoch - 353ms/step
Epoch 220/1000
2023-09-18 21:41:11.973 
Epoch 220/1000 
	 loss: 5.2109, MinusLogProbMetric: 5.2109, val_loss: 5.4288, val_MinusLogProbMetric: 5.4288

Epoch 220: val_loss did not improve from 5.23672
196/196 - 69s - loss: 5.2109 - MinusLogProbMetric: 5.2109 - val_loss: 5.4288 - val_MinusLogProbMetric: 5.4288 - lr: 0.0010 - 69s/epoch - 351ms/step
Epoch 221/1000
2023-09-18 21:42:21.059 
Epoch 221/1000 
	 loss: 5.2169, MinusLogProbMetric: 5.2169, val_loss: 5.2358, val_MinusLogProbMetric: 5.2358

Epoch 221: val_loss improved from 5.23672 to 5.23582, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.2169 - MinusLogProbMetric: 5.2169 - val_loss: 5.2358 - val_MinusLogProbMetric: 5.2358 - lr: 0.0010 - 70s/epoch - 358ms/step
Epoch 222/1000
2023-09-18 21:43:31.295 
Epoch 222/1000 
	 loss: 5.2055, MinusLogProbMetric: 5.2055, val_loss: 5.3163, val_MinusLogProbMetric: 5.3163

Epoch 222: val_loss did not improve from 5.23582
196/196 - 69s - loss: 5.2055 - MinusLogProbMetric: 5.2055 - val_loss: 5.3163 - val_MinusLogProbMetric: 5.3163 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 223/1000
2023-09-18 21:44:40.309 
Epoch 223/1000 
	 loss: 5.2015, MinusLogProbMetric: 5.2015, val_loss: 5.3336, val_MinusLogProbMetric: 5.3336

Epoch 223: val_loss did not improve from 5.23582
196/196 - 69s - loss: 5.2015 - MinusLogProbMetric: 5.2015 - val_loss: 5.3336 - val_MinusLogProbMetric: 5.3336 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 224/1000
2023-09-18 21:45:49.246 
Epoch 224/1000 
	 loss: 5.2009, MinusLogProbMetric: 5.2009, val_loss: 5.2127, val_MinusLogProbMetric: 5.2127

Epoch 224: val_loss improved from 5.23582 to 5.21267, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.2009 - MinusLogProbMetric: 5.2009 - val_loss: 5.2127 - val_MinusLogProbMetric: 5.2127 - lr: 0.0010 - 70s/epoch - 358ms/step
Epoch 225/1000
2023-09-18 21:46:59.649 
Epoch 225/1000 
	 loss: 5.1986, MinusLogProbMetric: 5.1986, val_loss: 5.2553, val_MinusLogProbMetric: 5.2553

Epoch 225: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1986 - MinusLogProbMetric: 5.1986 - val_loss: 5.2553 - val_MinusLogProbMetric: 5.2553 - lr: 0.0010 - 69s/epoch - 353ms/step
Epoch 226/1000
2023-09-18 21:48:08.929 
Epoch 226/1000 
	 loss: 5.2061, MinusLogProbMetric: 5.2061, val_loss: 5.2851, val_MinusLogProbMetric: 5.2851

Epoch 226: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.2061 - MinusLogProbMetric: 5.2061 - val_loss: 5.2851 - val_MinusLogProbMetric: 5.2851 - lr: 0.0010 - 69s/epoch - 353ms/step
Epoch 227/1000
2023-09-18 21:49:18.272 
Epoch 227/1000 
	 loss: 5.1852, MinusLogProbMetric: 5.1852, val_loss: 5.3416, val_MinusLogProbMetric: 5.3416

Epoch 227: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1852 - MinusLogProbMetric: 5.1852 - val_loss: 5.3416 - val_MinusLogProbMetric: 5.3416 - lr: 0.0010 - 69s/epoch - 354ms/step
Epoch 228/1000
2023-09-18 21:50:27.191 
Epoch 228/1000 
	 loss: 5.1999, MinusLogProbMetric: 5.1999, val_loss: 5.3138, val_MinusLogProbMetric: 5.3138

Epoch 228: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1999 - MinusLogProbMetric: 5.1999 - val_loss: 5.3138 - val_MinusLogProbMetric: 5.3138 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 229/1000
2023-09-18 21:51:35.874 
Epoch 229/1000 
	 loss: 5.1882, MinusLogProbMetric: 5.1882, val_loss: 5.2381, val_MinusLogProbMetric: 5.2381

Epoch 229: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1882 - MinusLogProbMetric: 5.1882 - val_loss: 5.2381 - val_MinusLogProbMetric: 5.2381 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 230/1000
2023-09-18 21:52:44.898 
Epoch 230/1000 
	 loss: 5.1831, MinusLogProbMetric: 5.1831, val_loss: 5.2804, val_MinusLogProbMetric: 5.2804

Epoch 230: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1831 - MinusLogProbMetric: 5.1831 - val_loss: 5.2804 - val_MinusLogProbMetric: 5.2804 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 231/1000
2023-09-18 21:53:53.553 
Epoch 231/1000 
	 loss: 5.1872, MinusLogProbMetric: 5.1872, val_loss: 5.2268, val_MinusLogProbMetric: 5.2268

Epoch 231: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1872 - MinusLogProbMetric: 5.1872 - val_loss: 5.2268 - val_MinusLogProbMetric: 5.2268 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 232/1000
2023-09-18 21:55:02.524 
Epoch 232/1000 
	 loss: 5.1867, MinusLogProbMetric: 5.1867, val_loss: 5.3711, val_MinusLogProbMetric: 5.3711

Epoch 232: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1867 - MinusLogProbMetric: 5.1867 - val_loss: 5.3711 - val_MinusLogProbMetric: 5.3711 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 233/1000
2023-09-18 21:56:11.646 
Epoch 233/1000 
	 loss: 5.1877, MinusLogProbMetric: 5.1877, val_loss: 5.2391, val_MinusLogProbMetric: 5.2391

Epoch 233: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1877 - MinusLogProbMetric: 5.1877 - val_loss: 5.2391 - val_MinusLogProbMetric: 5.2391 - lr: 0.0010 - 69s/epoch - 353ms/step
Epoch 234/1000
2023-09-18 21:57:20.655 
Epoch 234/1000 
	 loss: 5.2015, MinusLogProbMetric: 5.2015, val_loss: 5.2617, val_MinusLogProbMetric: 5.2617

Epoch 234: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.2015 - MinusLogProbMetric: 5.2015 - val_loss: 5.2617 - val_MinusLogProbMetric: 5.2617 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 235/1000
2023-09-18 21:58:29.629 
Epoch 235/1000 
	 loss: 5.1806, MinusLogProbMetric: 5.1806, val_loss: 5.3458, val_MinusLogProbMetric: 5.3458

Epoch 235: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1806 - MinusLogProbMetric: 5.1806 - val_loss: 5.3458 - val_MinusLogProbMetric: 5.3458 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 236/1000
2023-09-18 21:59:39.214 
Epoch 236/1000 
	 loss: 5.1973, MinusLogProbMetric: 5.1973, val_loss: 5.2509, val_MinusLogProbMetric: 5.2509

Epoch 236: val_loss did not improve from 5.21267
196/196 - 70s - loss: 5.1973 - MinusLogProbMetric: 5.1973 - val_loss: 5.2509 - val_MinusLogProbMetric: 5.2509 - lr: 0.0010 - 70s/epoch - 355ms/step
Epoch 237/1000
2023-09-18 22:00:48.062 
Epoch 237/1000 
	 loss: 5.1998, MinusLogProbMetric: 5.1998, val_loss: 5.2313, val_MinusLogProbMetric: 5.2313

Epoch 237: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1998 - MinusLogProbMetric: 5.1998 - val_loss: 5.2313 - val_MinusLogProbMetric: 5.2313 - lr: 0.0010 - 69s/epoch - 351ms/step
Epoch 238/1000
2023-09-18 22:01:56.658 
Epoch 238/1000 
	 loss: 5.1896, MinusLogProbMetric: 5.1896, val_loss: 5.2517, val_MinusLogProbMetric: 5.2517

Epoch 238: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1896 - MinusLogProbMetric: 5.1896 - val_loss: 5.2517 - val_MinusLogProbMetric: 5.2517 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 239/1000
2023-09-18 22:03:05.893 
Epoch 239/1000 
	 loss: 5.1856, MinusLogProbMetric: 5.1856, val_loss: 5.2910, val_MinusLogProbMetric: 5.2910

Epoch 239: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1856 - MinusLogProbMetric: 5.1856 - val_loss: 5.2910 - val_MinusLogProbMetric: 5.2910 - lr: 0.0010 - 69s/epoch - 353ms/step
Epoch 240/1000
2023-09-18 22:04:15.166 
Epoch 240/1000 
	 loss: 5.1900, MinusLogProbMetric: 5.1900, val_loss: 5.2771, val_MinusLogProbMetric: 5.2771

Epoch 240: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1900 - MinusLogProbMetric: 5.1900 - val_loss: 5.2771 - val_MinusLogProbMetric: 5.2771 - lr: 0.0010 - 69s/epoch - 353ms/step
Epoch 241/1000
2023-09-18 22:05:23.395 
Epoch 241/1000 
	 loss: 5.1734, MinusLogProbMetric: 5.1734, val_loss: 5.2811, val_MinusLogProbMetric: 5.2811

Epoch 241: val_loss did not improve from 5.21267
196/196 - 68s - loss: 5.1734 - MinusLogProbMetric: 5.1734 - val_loss: 5.2811 - val_MinusLogProbMetric: 5.2811 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 242/1000
2023-09-18 22:06:32.509 
Epoch 242/1000 
	 loss: 5.1873, MinusLogProbMetric: 5.1873, val_loss: 5.3349, val_MinusLogProbMetric: 5.3349

Epoch 242: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1873 - MinusLogProbMetric: 5.1873 - val_loss: 5.3349 - val_MinusLogProbMetric: 5.3349 - lr: 0.0010 - 69s/epoch - 353ms/step
Epoch 243/1000
2023-09-18 22:07:40.979 
Epoch 243/1000 
	 loss: 5.1773, MinusLogProbMetric: 5.1773, val_loss: 5.2474, val_MinusLogProbMetric: 5.2474

Epoch 243: val_loss did not improve from 5.21267
196/196 - 68s - loss: 5.1773 - MinusLogProbMetric: 5.1773 - val_loss: 5.2474 - val_MinusLogProbMetric: 5.2474 - lr: 0.0010 - 68s/epoch - 349ms/step
Epoch 244/1000
2023-09-18 22:08:46.946 
Epoch 244/1000 
	 loss: 5.1945, MinusLogProbMetric: 5.1945, val_loss: 5.2606, val_MinusLogProbMetric: 5.2606

Epoch 244: val_loss did not improve from 5.21267
196/196 - 66s - loss: 5.1945 - MinusLogProbMetric: 5.1945 - val_loss: 5.2606 - val_MinusLogProbMetric: 5.2606 - lr: 0.0010 - 66s/epoch - 337ms/step
Epoch 245/1000
2023-09-18 22:09:50.350 
Epoch 245/1000 
	 loss: 5.1965, MinusLogProbMetric: 5.1965, val_loss: 5.3096, val_MinusLogProbMetric: 5.3096

Epoch 245: val_loss did not improve from 5.21267
196/196 - 63s - loss: 5.1965 - MinusLogProbMetric: 5.1965 - val_loss: 5.3096 - val_MinusLogProbMetric: 5.3096 - lr: 0.0010 - 63s/epoch - 323ms/step
Epoch 246/1000
2023-09-18 22:10:56.297 
Epoch 246/1000 
	 loss: 5.1957, MinusLogProbMetric: 5.1957, val_loss: 5.3192, val_MinusLogProbMetric: 5.3192

Epoch 246: val_loss did not improve from 5.21267
196/196 - 66s - loss: 5.1957 - MinusLogProbMetric: 5.1957 - val_loss: 5.3192 - val_MinusLogProbMetric: 5.3192 - lr: 0.0010 - 66s/epoch - 336ms/step
Epoch 247/1000
2023-09-18 22:11:52.676 
Epoch 247/1000 
	 loss: 5.1707, MinusLogProbMetric: 5.1707, val_loss: 5.2506, val_MinusLogProbMetric: 5.2506

Epoch 247: val_loss did not improve from 5.21267
196/196 - 56s - loss: 5.1707 - MinusLogProbMetric: 5.1707 - val_loss: 5.2506 - val_MinusLogProbMetric: 5.2506 - lr: 0.0010 - 56s/epoch - 288ms/step
Epoch 248/1000
2023-09-18 22:12:58.471 
Epoch 248/1000 
	 loss: 5.1751, MinusLogProbMetric: 5.1751, val_loss: 5.2416, val_MinusLogProbMetric: 5.2416

Epoch 248: val_loss did not improve from 5.21267
196/196 - 66s - loss: 5.1751 - MinusLogProbMetric: 5.1751 - val_loss: 5.2416 - val_MinusLogProbMetric: 5.2416 - lr: 0.0010 - 66s/epoch - 336ms/step
Epoch 249/1000
2023-09-18 22:14:07.428 
Epoch 249/1000 
	 loss: 5.1891, MinusLogProbMetric: 5.1891, val_loss: 5.3893, val_MinusLogProbMetric: 5.3893

Epoch 249: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1891 - MinusLogProbMetric: 5.1891 - val_loss: 5.3893 - val_MinusLogProbMetric: 5.3893 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 250/1000
2023-09-18 22:15:16.768 
Epoch 250/1000 
	 loss: 5.1752, MinusLogProbMetric: 5.1752, val_loss: 5.2682, val_MinusLogProbMetric: 5.2682

Epoch 250: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1752 - MinusLogProbMetric: 5.1752 - val_loss: 5.2682 - val_MinusLogProbMetric: 5.2682 - lr: 0.0010 - 69s/epoch - 354ms/step
Epoch 251/1000
2023-09-18 22:16:25.447 
Epoch 251/1000 
	 loss: 5.1773, MinusLogProbMetric: 5.1773, val_loss: 5.2879, val_MinusLogProbMetric: 5.2879

Epoch 251: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1773 - MinusLogProbMetric: 5.1773 - val_loss: 5.2879 - val_MinusLogProbMetric: 5.2879 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 252/1000
2023-09-18 22:17:34.198 
Epoch 252/1000 
	 loss: 5.1864, MinusLogProbMetric: 5.1864, val_loss: 5.2326, val_MinusLogProbMetric: 5.2326

Epoch 252: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1864 - MinusLogProbMetric: 5.1864 - val_loss: 5.2326 - val_MinusLogProbMetric: 5.2326 - lr: 0.0010 - 69s/epoch - 351ms/step
Epoch 253/1000
2023-09-18 22:18:42.564 
Epoch 253/1000 
	 loss: 5.1820, MinusLogProbMetric: 5.1820, val_loss: 5.2685, val_MinusLogProbMetric: 5.2685

Epoch 253: val_loss did not improve from 5.21267
196/196 - 68s - loss: 5.1820 - MinusLogProbMetric: 5.1820 - val_loss: 5.2685 - val_MinusLogProbMetric: 5.2685 - lr: 0.0010 - 68s/epoch - 349ms/step
Epoch 254/1000
2023-09-18 22:19:51.020 
Epoch 254/1000 
	 loss: 5.1829, MinusLogProbMetric: 5.1829, val_loss: 5.3518, val_MinusLogProbMetric: 5.3518

Epoch 254: val_loss did not improve from 5.21267
196/196 - 68s - loss: 5.1829 - MinusLogProbMetric: 5.1829 - val_loss: 5.3518 - val_MinusLogProbMetric: 5.3518 - lr: 0.0010 - 68s/epoch - 349ms/step
Epoch 255/1000
2023-09-18 22:20:59.975 
Epoch 255/1000 
	 loss: 5.1796, MinusLogProbMetric: 5.1796, val_loss: 5.3150, val_MinusLogProbMetric: 5.3150

Epoch 255: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1796 - MinusLogProbMetric: 5.1796 - val_loss: 5.3150 - val_MinusLogProbMetric: 5.3150 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 256/1000
2023-09-18 22:22:08.355 
Epoch 256/1000 
	 loss: 5.1903, MinusLogProbMetric: 5.1903, val_loss: 5.2602, val_MinusLogProbMetric: 5.2602

Epoch 256: val_loss did not improve from 5.21267
196/196 - 68s - loss: 5.1903 - MinusLogProbMetric: 5.1903 - val_loss: 5.2602 - val_MinusLogProbMetric: 5.2602 - lr: 0.0010 - 68s/epoch - 349ms/step
Epoch 257/1000
2023-09-18 22:23:17.254 
Epoch 257/1000 
	 loss: 5.1795, MinusLogProbMetric: 5.1795, val_loss: 5.3053, val_MinusLogProbMetric: 5.3053

Epoch 257: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1795 - MinusLogProbMetric: 5.1795 - val_loss: 5.3053 - val_MinusLogProbMetric: 5.3053 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 258/1000
2023-09-18 22:24:25.819 
Epoch 258/1000 
	 loss: 5.1800, MinusLogProbMetric: 5.1800, val_loss: 5.2721, val_MinusLogProbMetric: 5.2721

Epoch 258: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1800 - MinusLogProbMetric: 5.1800 - val_loss: 5.2721 - val_MinusLogProbMetric: 5.2721 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 259/1000
2023-09-18 22:25:34.406 
Epoch 259/1000 
	 loss: 5.1733, MinusLogProbMetric: 5.1733, val_loss: 5.3607, val_MinusLogProbMetric: 5.3607

Epoch 259: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1733 - MinusLogProbMetric: 5.1733 - val_loss: 5.3607 - val_MinusLogProbMetric: 5.3607 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 260/1000
2023-09-18 22:26:43.015 
Epoch 260/1000 
	 loss: 5.1696, MinusLogProbMetric: 5.1696, val_loss: 5.2882, val_MinusLogProbMetric: 5.2882

Epoch 260: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1696 - MinusLogProbMetric: 5.1696 - val_loss: 5.2882 - val_MinusLogProbMetric: 5.2882 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 261/1000
2023-09-18 22:27:51.746 
Epoch 261/1000 
	 loss: 5.1783, MinusLogProbMetric: 5.1783, val_loss: 5.3322, val_MinusLogProbMetric: 5.3322

Epoch 261: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1783 - MinusLogProbMetric: 5.1783 - val_loss: 5.3322 - val_MinusLogProbMetric: 5.3322 - lr: 0.0010 - 69s/epoch - 351ms/step
Epoch 262/1000
2023-09-18 22:29:00.305 
Epoch 262/1000 
	 loss: 5.1809, MinusLogProbMetric: 5.1809, val_loss: 5.2341, val_MinusLogProbMetric: 5.2341

Epoch 262: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1809 - MinusLogProbMetric: 5.1809 - val_loss: 5.2341 - val_MinusLogProbMetric: 5.2341 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 263/1000
2023-09-18 22:30:08.580 
Epoch 263/1000 
	 loss: 5.1807, MinusLogProbMetric: 5.1807, val_loss: 5.2910, val_MinusLogProbMetric: 5.2910

Epoch 263: val_loss did not improve from 5.21267
196/196 - 68s - loss: 5.1807 - MinusLogProbMetric: 5.1807 - val_loss: 5.2910 - val_MinusLogProbMetric: 5.2910 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 264/1000
2023-09-18 22:31:17.087 
Epoch 264/1000 
	 loss: 5.1848, MinusLogProbMetric: 5.1848, val_loss: 5.2227, val_MinusLogProbMetric: 5.2227

Epoch 264: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1848 - MinusLogProbMetric: 5.1848 - val_loss: 5.2227 - val_MinusLogProbMetric: 5.2227 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 265/1000
2023-09-18 22:32:25.247 
Epoch 265/1000 
	 loss: 5.1694, MinusLogProbMetric: 5.1694, val_loss: 5.2570, val_MinusLogProbMetric: 5.2570

Epoch 265: val_loss did not improve from 5.21267
196/196 - 68s - loss: 5.1694 - MinusLogProbMetric: 5.1694 - val_loss: 5.2570 - val_MinusLogProbMetric: 5.2570 - lr: 0.0010 - 68s/epoch - 348ms/step
Epoch 266/1000
2023-09-18 22:33:33.814 
Epoch 266/1000 
	 loss: 5.1866, MinusLogProbMetric: 5.1866, val_loss: 5.2582, val_MinusLogProbMetric: 5.2582

Epoch 266: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1866 - MinusLogProbMetric: 5.1866 - val_loss: 5.2582 - val_MinusLogProbMetric: 5.2582 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 267/1000
2023-09-18 22:34:42.692 
Epoch 267/1000 
	 loss: 5.1694, MinusLogProbMetric: 5.1694, val_loss: 5.2781, val_MinusLogProbMetric: 5.2781

Epoch 267: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1694 - MinusLogProbMetric: 5.1694 - val_loss: 5.2781 - val_MinusLogProbMetric: 5.2781 - lr: 0.0010 - 69s/epoch - 351ms/step
Epoch 268/1000
2023-09-18 22:35:51.350 
Epoch 268/1000 
	 loss: 5.1720, MinusLogProbMetric: 5.1720, val_loss: 5.4022, val_MinusLogProbMetric: 5.4022

Epoch 268: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1720 - MinusLogProbMetric: 5.1720 - val_loss: 5.4022 - val_MinusLogProbMetric: 5.4022 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 269/1000
2023-09-18 22:37:00.380 
Epoch 269/1000 
	 loss: 5.1748, MinusLogProbMetric: 5.1748, val_loss: 5.2499, val_MinusLogProbMetric: 5.2499

Epoch 269: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1748 - MinusLogProbMetric: 5.1748 - val_loss: 5.2499 - val_MinusLogProbMetric: 5.2499 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 270/1000
2023-09-18 22:38:09.399 
Epoch 270/1000 
	 loss: 5.1591, MinusLogProbMetric: 5.1591, val_loss: 5.4146, val_MinusLogProbMetric: 5.4146

Epoch 270: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1591 - MinusLogProbMetric: 5.1591 - val_loss: 5.4146 - val_MinusLogProbMetric: 5.4146 - lr: 0.0010 - 69s/epoch - 352ms/step
Epoch 271/1000
2023-09-18 22:39:18.230 
Epoch 271/1000 
	 loss: 5.1835, MinusLogProbMetric: 5.1835, val_loss: 5.2819, val_MinusLogProbMetric: 5.2819

Epoch 271: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1835 - MinusLogProbMetric: 5.1835 - val_loss: 5.2819 - val_MinusLogProbMetric: 5.2819 - lr: 0.0010 - 69s/epoch - 351ms/step
Epoch 272/1000
2023-09-18 22:40:26.799 
Epoch 272/1000 
	 loss: 5.1762, MinusLogProbMetric: 5.1762, val_loss: 5.3200, val_MinusLogProbMetric: 5.3200

Epoch 272: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1762 - MinusLogProbMetric: 5.1762 - val_loss: 5.3200 - val_MinusLogProbMetric: 5.3200 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 273/1000
2023-09-18 22:41:35.624 
Epoch 273/1000 
	 loss: 5.1685, MinusLogProbMetric: 5.1685, val_loss: 5.2349, val_MinusLogProbMetric: 5.2349

Epoch 273: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1685 - MinusLogProbMetric: 5.1685 - val_loss: 5.2349 - val_MinusLogProbMetric: 5.2349 - lr: 0.0010 - 69s/epoch - 351ms/step
Epoch 274/1000
2023-09-18 22:42:44.274 
Epoch 274/1000 
	 loss: 5.1669, MinusLogProbMetric: 5.1669, val_loss: 5.2747, val_MinusLogProbMetric: 5.2747

Epoch 274: val_loss did not improve from 5.21267
196/196 - 69s - loss: 5.1669 - MinusLogProbMetric: 5.1669 - val_loss: 5.2747 - val_MinusLogProbMetric: 5.2747 - lr: 0.0010 - 69s/epoch - 350ms/step
Epoch 275/1000
2023-09-18 22:43:52.714 
Epoch 275/1000 
	 loss: 5.1068, MinusLogProbMetric: 5.1068, val_loss: 5.2034, val_MinusLogProbMetric: 5.2034

Epoch 275: val_loss improved from 5.21267 to 5.20340, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 69s - loss: 5.1068 - MinusLogProbMetric: 5.1068 - val_loss: 5.2034 - val_MinusLogProbMetric: 5.2034 - lr: 5.0000e-04 - 69s/epoch - 354ms/step
Epoch 276/1000
2023-09-18 22:45:02.384 
Epoch 276/1000 
	 loss: 5.1090, MinusLogProbMetric: 5.1090, val_loss: 5.2284, val_MinusLogProbMetric: 5.2284

Epoch 276: val_loss did not improve from 5.20340
196/196 - 69s - loss: 5.1090 - MinusLogProbMetric: 5.1090 - val_loss: 5.2284 - val_MinusLogProbMetric: 5.2284 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 277/1000
2023-09-18 22:46:11.268 
Epoch 277/1000 
	 loss: 5.0992, MinusLogProbMetric: 5.0992, val_loss: 5.1716, val_MinusLogProbMetric: 5.1716

Epoch 277: val_loss improved from 5.20340 to 5.17164, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0992 - MinusLogProbMetric: 5.0992 - val_loss: 5.1716 - val_MinusLogProbMetric: 5.1716 - lr: 5.0000e-04 - 70s/epoch - 356ms/step
Epoch 278/1000
2023-09-18 22:47:21.160 
Epoch 278/1000 
	 loss: 5.1102, MinusLogProbMetric: 5.1102, val_loss: 5.2012, val_MinusLogProbMetric: 5.2012

Epoch 278: val_loss did not improve from 5.17164
196/196 - 69s - loss: 5.1102 - MinusLogProbMetric: 5.1102 - val_loss: 5.2012 - val_MinusLogProbMetric: 5.2012 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 279/1000
2023-09-18 22:48:29.985 
Epoch 279/1000 
	 loss: 5.0974, MinusLogProbMetric: 5.0974, val_loss: 5.2175, val_MinusLogProbMetric: 5.2175

Epoch 279: val_loss did not improve from 5.17164
196/196 - 69s - loss: 5.0974 - MinusLogProbMetric: 5.0974 - val_loss: 5.2175 - val_MinusLogProbMetric: 5.2175 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 280/1000
2023-09-18 22:49:39.120 
Epoch 280/1000 
	 loss: 5.1030, MinusLogProbMetric: 5.1030, val_loss: 5.2049, val_MinusLogProbMetric: 5.2049

Epoch 280: val_loss did not improve from 5.17164
196/196 - 69s - loss: 5.1030 - MinusLogProbMetric: 5.1030 - val_loss: 5.2049 - val_MinusLogProbMetric: 5.2049 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 281/1000
2023-09-18 22:50:47.837 
Epoch 281/1000 
	 loss: 5.1020, MinusLogProbMetric: 5.1020, val_loss: 5.1837, val_MinusLogProbMetric: 5.1837

Epoch 281: val_loss did not improve from 5.17164
196/196 - 69s - loss: 5.1020 - MinusLogProbMetric: 5.1020 - val_loss: 5.1837 - val_MinusLogProbMetric: 5.1837 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 282/1000
2023-09-18 22:51:56.852 
Epoch 282/1000 
	 loss: 5.0984, MinusLogProbMetric: 5.0984, val_loss: 5.1775, val_MinusLogProbMetric: 5.1775

Epoch 282: val_loss did not improve from 5.17164
196/196 - 69s - loss: 5.0984 - MinusLogProbMetric: 5.0984 - val_loss: 5.1775 - val_MinusLogProbMetric: 5.1775 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 283/1000
2023-09-18 22:53:05.590 
Epoch 283/1000 
	 loss: 5.1018, MinusLogProbMetric: 5.1018, val_loss: 5.1965, val_MinusLogProbMetric: 5.1965

Epoch 283: val_loss did not improve from 5.17164
196/196 - 69s - loss: 5.1018 - MinusLogProbMetric: 5.1018 - val_loss: 5.1965 - val_MinusLogProbMetric: 5.1965 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 284/1000
2023-09-18 22:54:14.317 
Epoch 284/1000 
	 loss: 5.1035, MinusLogProbMetric: 5.1035, val_loss: 5.1922, val_MinusLogProbMetric: 5.1922

Epoch 284: val_loss did not improve from 5.17164
196/196 - 69s - loss: 5.1035 - MinusLogProbMetric: 5.1035 - val_loss: 5.1922 - val_MinusLogProbMetric: 5.1922 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 285/1000
2023-09-18 22:55:22.751 
Epoch 285/1000 
	 loss: 5.0987, MinusLogProbMetric: 5.0987, val_loss: 5.2022, val_MinusLogProbMetric: 5.2022

Epoch 285: val_loss did not improve from 5.17164
196/196 - 68s - loss: 5.0987 - MinusLogProbMetric: 5.0987 - val_loss: 5.2022 - val_MinusLogProbMetric: 5.2022 - lr: 5.0000e-04 - 68s/epoch - 349ms/step
Epoch 286/1000
2023-09-18 22:56:30.987 
Epoch 286/1000 
	 loss: 5.1018, MinusLogProbMetric: 5.1018, val_loss: 5.1706, val_MinusLogProbMetric: 5.1706

Epoch 286: val_loss improved from 5.17164 to 5.17055, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 69s - loss: 5.1018 - MinusLogProbMetric: 5.1018 - val_loss: 5.1706 - val_MinusLogProbMetric: 5.1706 - lr: 5.0000e-04 - 69s/epoch - 354ms/step
Epoch 287/1000
2023-09-18 22:57:40.939 
Epoch 287/1000 
	 loss: 5.0951, MinusLogProbMetric: 5.0951, val_loss: 5.2107, val_MinusLogProbMetric: 5.2107

Epoch 287: val_loss did not improve from 5.17055
196/196 - 69s - loss: 5.0951 - MinusLogProbMetric: 5.0951 - val_loss: 5.2107 - val_MinusLogProbMetric: 5.2107 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 288/1000
2023-09-18 22:58:49.633 
Epoch 288/1000 
	 loss: 5.0969, MinusLogProbMetric: 5.0969, val_loss: 5.2160, val_MinusLogProbMetric: 5.2160

Epoch 288: val_loss did not improve from 5.17055
196/196 - 69s - loss: 5.0969 - MinusLogProbMetric: 5.0969 - val_loss: 5.2160 - val_MinusLogProbMetric: 5.2160 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 289/1000
2023-09-18 22:59:58.182 
Epoch 289/1000 
	 loss: 5.1012, MinusLogProbMetric: 5.1012, val_loss: 5.2158, val_MinusLogProbMetric: 5.2158

Epoch 289: val_loss did not improve from 5.17055
196/196 - 69s - loss: 5.1012 - MinusLogProbMetric: 5.1012 - val_loss: 5.2158 - val_MinusLogProbMetric: 5.2158 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 290/1000
2023-09-18 23:01:07.003 
Epoch 290/1000 
	 loss: 5.1026, MinusLogProbMetric: 5.1026, val_loss: 5.2142, val_MinusLogProbMetric: 5.2142

Epoch 290: val_loss did not improve from 5.17055
196/196 - 69s - loss: 5.1026 - MinusLogProbMetric: 5.1026 - val_loss: 5.2142 - val_MinusLogProbMetric: 5.2142 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 291/1000
2023-09-18 23:02:16.372 
Epoch 291/1000 
	 loss: 5.1001, MinusLogProbMetric: 5.1001, val_loss: 5.1750, val_MinusLogProbMetric: 5.1750

Epoch 291: val_loss did not improve from 5.17055
196/196 - 69s - loss: 5.1001 - MinusLogProbMetric: 5.1001 - val_loss: 5.1750 - val_MinusLogProbMetric: 5.1750 - lr: 5.0000e-04 - 69s/epoch - 354ms/step
Epoch 292/1000
2023-09-18 23:03:24.741 
Epoch 292/1000 
	 loss: 5.0985, MinusLogProbMetric: 5.0985, val_loss: 5.1813, val_MinusLogProbMetric: 5.1813

Epoch 292: val_loss did not improve from 5.17055
196/196 - 68s - loss: 5.0985 - MinusLogProbMetric: 5.0985 - val_loss: 5.1813 - val_MinusLogProbMetric: 5.1813 - lr: 5.0000e-04 - 68s/epoch - 349ms/step
Epoch 293/1000
2023-09-18 23:04:33.580 
Epoch 293/1000 
	 loss: 5.0958, MinusLogProbMetric: 5.0958, val_loss: 5.2265, val_MinusLogProbMetric: 5.2265

Epoch 293: val_loss did not improve from 5.17055
196/196 - 69s - loss: 5.0958 - MinusLogProbMetric: 5.0958 - val_loss: 5.2265 - val_MinusLogProbMetric: 5.2265 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 294/1000
2023-09-18 23:05:42.344 
Epoch 294/1000 
	 loss: 5.0998, MinusLogProbMetric: 5.0998, val_loss: 5.1967, val_MinusLogProbMetric: 5.1967

Epoch 294: val_loss did not improve from 5.17055
196/196 - 69s - loss: 5.0998 - MinusLogProbMetric: 5.0998 - val_loss: 5.1967 - val_MinusLogProbMetric: 5.1967 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 295/1000
2023-09-18 23:06:51.408 
Epoch 295/1000 
	 loss: 5.1011, MinusLogProbMetric: 5.1011, val_loss: 5.1837, val_MinusLogProbMetric: 5.1837

Epoch 295: val_loss did not improve from 5.17055
196/196 - 69s - loss: 5.1011 - MinusLogProbMetric: 5.1011 - val_loss: 5.1837 - val_MinusLogProbMetric: 5.1837 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 296/1000
2023-09-18 23:08:00.276 
Epoch 296/1000 
	 loss: 5.0944, MinusLogProbMetric: 5.0944, val_loss: 5.2172, val_MinusLogProbMetric: 5.2172

Epoch 296: val_loss did not improve from 5.17055
196/196 - 69s - loss: 5.0944 - MinusLogProbMetric: 5.0944 - val_loss: 5.2172 - val_MinusLogProbMetric: 5.2172 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 297/1000
2023-09-18 23:09:05.164 
Epoch 297/1000 
	 loss: 5.0957, MinusLogProbMetric: 5.0957, val_loss: 5.1926, val_MinusLogProbMetric: 5.1926

Epoch 297: val_loss did not improve from 5.17055
196/196 - 65s - loss: 5.0957 - MinusLogProbMetric: 5.0957 - val_loss: 5.1926 - val_MinusLogProbMetric: 5.1926 - lr: 5.0000e-04 - 65s/epoch - 331ms/step
Epoch 298/1000
2023-09-18 23:10:08.386 
Epoch 298/1000 
	 loss: 5.0991, MinusLogProbMetric: 5.0991, val_loss: 5.2133, val_MinusLogProbMetric: 5.2133

Epoch 298: val_loss did not improve from 5.17055
196/196 - 63s - loss: 5.0991 - MinusLogProbMetric: 5.0991 - val_loss: 5.2133 - val_MinusLogProbMetric: 5.2133 - lr: 5.0000e-04 - 63s/epoch - 323ms/step
Epoch 299/1000
2023-09-18 23:11:06.299 
Epoch 299/1000 
	 loss: 5.0991, MinusLogProbMetric: 5.0991, val_loss: 5.1675, val_MinusLogProbMetric: 5.1675

Epoch 299: val_loss improved from 5.17055 to 5.16754, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 59s - loss: 5.0991 - MinusLogProbMetric: 5.0991 - val_loss: 5.1675 - val_MinusLogProbMetric: 5.1675 - lr: 5.0000e-04 - 59s/epoch - 301ms/step
Epoch 300/1000
2023-09-18 23:12:09.787 
Epoch 300/1000 
	 loss: 5.1061, MinusLogProbMetric: 5.1061, val_loss: 5.2014, val_MinusLogProbMetric: 5.2014

Epoch 300: val_loss did not improve from 5.16754
196/196 - 62s - loss: 5.1061 - MinusLogProbMetric: 5.1061 - val_loss: 5.2014 - val_MinusLogProbMetric: 5.2014 - lr: 5.0000e-04 - 62s/epoch - 318ms/step
Epoch 301/1000
2023-09-18 23:13:18.299 
Epoch 301/1000 
	 loss: 5.0977, MinusLogProbMetric: 5.0977, val_loss: 5.1868, val_MinusLogProbMetric: 5.1868

Epoch 301: val_loss did not improve from 5.16754
196/196 - 69s - loss: 5.0977 - MinusLogProbMetric: 5.0977 - val_loss: 5.1868 - val_MinusLogProbMetric: 5.1868 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 302/1000
2023-09-18 23:14:24.543 
Epoch 302/1000 
	 loss: 5.1007, MinusLogProbMetric: 5.1007, val_loss: 5.2088, val_MinusLogProbMetric: 5.2088

Epoch 302: val_loss did not improve from 5.16754
196/196 - 66s - loss: 5.1007 - MinusLogProbMetric: 5.1007 - val_loss: 5.2088 - val_MinusLogProbMetric: 5.2088 - lr: 5.0000e-04 - 66s/epoch - 338ms/step
Epoch 303/1000
2023-09-18 23:15:32.991 
Epoch 303/1000 
	 loss: 5.1016, MinusLogProbMetric: 5.1016, val_loss: 5.1958, val_MinusLogProbMetric: 5.1958

Epoch 303: val_loss did not improve from 5.16754
196/196 - 68s - loss: 5.1016 - MinusLogProbMetric: 5.1016 - val_loss: 5.1958 - val_MinusLogProbMetric: 5.1958 - lr: 5.0000e-04 - 68s/epoch - 349ms/step
Epoch 304/1000
2023-09-18 23:16:41.101 
Epoch 304/1000 
	 loss: 5.1049, MinusLogProbMetric: 5.1049, val_loss: 5.1751, val_MinusLogProbMetric: 5.1751

Epoch 304: val_loss did not improve from 5.16754
196/196 - 68s - loss: 5.1049 - MinusLogProbMetric: 5.1049 - val_loss: 5.1751 - val_MinusLogProbMetric: 5.1751 - lr: 5.0000e-04 - 68s/epoch - 347ms/step
Epoch 305/1000
2023-09-18 23:17:49.498 
Epoch 305/1000 
	 loss: 5.0979, MinusLogProbMetric: 5.0979, val_loss: 5.2118, val_MinusLogProbMetric: 5.2118

Epoch 305: val_loss did not improve from 5.16754
196/196 - 68s - loss: 5.0979 - MinusLogProbMetric: 5.0979 - val_loss: 5.2118 - val_MinusLogProbMetric: 5.2118 - lr: 5.0000e-04 - 68s/epoch - 349ms/step
Epoch 306/1000
2023-09-18 23:18:57.899 
Epoch 306/1000 
	 loss: 5.0973, MinusLogProbMetric: 5.0973, val_loss: 5.1612, val_MinusLogProbMetric: 5.1612

Epoch 306: val_loss improved from 5.16754 to 5.16122, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 69s - loss: 5.0973 - MinusLogProbMetric: 5.0973 - val_loss: 5.1612 - val_MinusLogProbMetric: 5.1612 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 307/1000
2023-09-18 23:20:00.168 
Epoch 307/1000 
	 loss: 5.0958, MinusLogProbMetric: 5.0958, val_loss: 5.2128, val_MinusLogProbMetric: 5.2128

Epoch 307: val_loss did not improve from 5.16122
196/196 - 61s - loss: 5.0958 - MinusLogProbMetric: 5.0958 - val_loss: 5.2128 - val_MinusLogProbMetric: 5.2128 - lr: 5.0000e-04 - 61s/epoch - 314ms/step
Epoch 308/1000
2023-09-18 23:20:59.628 
Epoch 308/1000 
	 loss: 5.0937, MinusLogProbMetric: 5.0937, val_loss: 5.2106, val_MinusLogProbMetric: 5.2106

Epoch 308: val_loss did not improve from 5.16122
196/196 - 59s - loss: 5.0937 - MinusLogProbMetric: 5.0937 - val_loss: 5.2106 - val_MinusLogProbMetric: 5.2106 - lr: 5.0000e-04 - 59s/epoch - 303ms/step
Epoch 309/1000
2023-09-18 23:22:08.133 
Epoch 309/1000 
	 loss: 5.0989, MinusLogProbMetric: 5.0989, val_loss: 5.2200, val_MinusLogProbMetric: 5.2200

Epoch 309: val_loss did not improve from 5.16122
196/196 - 69s - loss: 5.0989 - MinusLogProbMetric: 5.0989 - val_loss: 5.2200 - val_MinusLogProbMetric: 5.2200 - lr: 5.0000e-04 - 69s/epoch - 349ms/step
Epoch 310/1000
2023-09-18 23:23:17.193 
Epoch 310/1000 
	 loss: 5.0997, MinusLogProbMetric: 5.0997, val_loss: 5.1795, val_MinusLogProbMetric: 5.1795

Epoch 310: val_loss did not improve from 5.16122
196/196 - 69s - loss: 5.0997 - MinusLogProbMetric: 5.0997 - val_loss: 5.1795 - val_MinusLogProbMetric: 5.1795 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 311/1000
2023-09-18 23:24:25.653 
Epoch 311/1000 
	 loss: 5.0988, MinusLogProbMetric: 5.0988, val_loss: 5.2047, val_MinusLogProbMetric: 5.2047

Epoch 311: val_loss did not improve from 5.16122
196/196 - 68s - loss: 5.0988 - MinusLogProbMetric: 5.0988 - val_loss: 5.2047 - val_MinusLogProbMetric: 5.2047 - lr: 5.0000e-04 - 68s/epoch - 349ms/step
Epoch 312/1000
2023-09-18 23:25:34.423 
Epoch 312/1000 
	 loss: 5.0982, MinusLogProbMetric: 5.0982, val_loss: 5.1598, val_MinusLogProbMetric: 5.1598

Epoch 312: val_loss improved from 5.16122 to 5.15983, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0982 - MinusLogProbMetric: 5.0982 - val_loss: 5.1598 - val_MinusLogProbMetric: 5.1598 - lr: 5.0000e-04 - 70s/epoch - 356ms/step
Epoch 313/1000
2023-09-18 23:26:44.510 
Epoch 313/1000 
	 loss: 5.0925, MinusLogProbMetric: 5.0925, val_loss: 5.2024, val_MinusLogProbMetric: 5.2024

Epoch 313: val_loss did not improve from 5.15983
196/196 - 69s - loss: 5.0925 - MinusLogProbMetric: 5.0925 - val_loss: 5.2024 - val_MinusLogProbMetric: 5.2024 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 314/1000
2023-09-18 23:27:53.099 
Epoch 314/1000 
	 loss: 5.0970, MinusLogProbMetric: 5.0970, val_loss: 5.1721, val_MinusLogProbMetric: 5.1721

Epoch 314: val_loss did not improve from 5.15983
196/196 - 69s - loss: 5.0970 - MinusLogProbMetric: 5.0970 - val_loss: 5.1721 - val_MinusLogProbMetric: 5.1721 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 315/1000
2023-09-18 23:29:02.414 
Epoch 315/1000 
	 loss: 5.0963, MinusLogProbMetric: 5.0963, val_loss: 5.1958, val_MinusLogProbMetric: 5.1958

Epoch 315: val_loss did not improve from 5.15983
196/196 - 69s - loss: 5.0963 - MinusLogProbMetric: 5.0963 - val_loss: 5.1958 - val_MinusLogProbMetric: 5.1958 - lr: 5.0000e-04 - 69s/epoch - 354ms/step
Epoch 316/1000
2023-09-18 23:30:11.499 
Epoch 316/1000 
	 loss: 5.0999, MinusLogProbMetric: 5.0999, val_loss: 5.1792, val_MinusLogProbMetric: 5.1792

Epoch 316: val_loss did not improve from 5.15983
196/196 - 69s - loss: 5.0999 - MinusLogProbMetric: 5.0999 - val_loss: 5.1792 - val_MinusLogProbMetric: 5.1792 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 317/1000
2023-09-18 23:31:20.422 
Epoch 317/1000 
	 loss: 5.1005, MinusLogProbMetric: 5.1005, val_loss: 5.2219, val_MinusLogProbMetric: 5.2219

Epoch 317: val_loss did not improve from 5.15983
196/196 - 69s - loss: 5.1005 - MinusLogProbMetric: 5.1005 - val_loss: 5.2219 - val_MinusLogProbMetric: 5.2219 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 318/1000
2023-09-18 23:32:29.054 
Epoch 318/1000 
	 loss: 5.0973, MinusLogProbMetric: 5.0973, val_loss: 5.2405, val_MinusLogProbMetric: 5.2405

Epoch 318: val_loss did not improve from 5.15983
196/196 - 69s - loss: 5.0973 - MinusLogProbMetric: 5.0973 - val_loss: 5.2405 - val_MinusLogProbMetric: 5.2405 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 319/1000
2023-09-18 23:33:37.724 
Epoch 319/1000 
	 loss: 5.0958, MinusLogProbMetric: 5.0958, val_loss: 5.1882, val_MinusLogProbMetric: 5.1882

Epoch 319: val_loss did not improve from 5.15983
196/196 - 69s - loss: 5.0958 - MinusLogProbMetric: 5.0958 - val_loss: 5.1882 - val_MinusLogProbMetric: 5.1882 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 320/1000
2023-09-18 23:34:46.786 
Epoch 320/1000 
	 loss: 5.0969, MinusLogProbMetric: 5.0969, val_loss: 5.2037, val_MinusLogProbMetric: 5.2037

Epoch 320: val_loss did not improve from 5.15983
196/196 - 69s - loss: 5.0969 - MinusLogProbMetric: 5.0969 - val_loss: 5.2037 - val_MinusLogProbMetric: 5.2037 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 321/1000
2023-09-18 23:35:55.252 
Epoch 321/1000 
	 loss: 5.0990, MinusLogProbMetric: 5.0990, val_loss: 5.1894, val_MinusLogProbMetric: 5.1894

Epoch 321: val_loss did not improve from 5.15983
196/196 - 68s - loss: 5.0990 - MinusLogProbMetric: 5.0990 - val_loss: 5.1894 - val_MinusLogProbMetric: 5.1894 - lr: 5.0000e-04 - 68s/epoch - 349ms/step
Epoch 322/1000
2023-09-18 23:37:03.959 
Epoch 322/1000 
	 loss: 5.0998, MinusLogProbMetric: 5.0998, val_loss: 5.1588, val_MinusLogProbMetric: 5.1588

Epoch 322: val_loss improved from 5.15983 to 5.15877, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0998 - MinusLogProbMetric: 5.0998 - val_loss: 5.1588 - val_MinusLogProbMetric: 5.1588 - lr: 5.0000e-04 - 70s/epoch - 355ms/step
Epoch 323/1000
2023-09-18 23:38:13.578 
Epoch 323/1000 
	 loss: 5.0970, MinusLogProbMetric: 5.0970, val_loss: 5.1734, val_MinusLogProbMetric: 5.1734

Epoch 323: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0970 - MinusLogProbMetric: 5.0970 - val_loss: 5.1734 - val_MinusLogProbMetric: 5.1734 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 324/1000
2023-09-18 23:39:22.448 
Epoch 324/1000 
	 loss: 5.0889, MinusLogProbMetric: 5.0889, val_loss: 5.1764, val_MinusLogProbMetric: 5.1764

Epoch 324: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0889 - MinusLogProbMetric: 5.0889 - val_loss: 5.1764 - val_MinusLogProbMetric: 5.1764 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 325/1000
2023-09-18 23:40:31.586 
Epoch 325/1000 
	 loss: 5.0985, MinusLogProbMetric: 5.0985, val_loss: 5.2270, val_MinusLogProbMetric: 5.2270

Epoch 325: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0985 - MinusLogProbMetric: 5.0985 - val_loss: 5.2270 - val_MinusLogProbMetric: 5.2270 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 326/1000
2023-09-18 23:41:40.095 
Epoch 326/1000 
	 loss: 5.0887, MinusLogProbMetric: 5.0887, val_loss: 5.1588, val_MinusLogProbMetric: 5.1588

Epoch 326: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0887 - MinusLogProbMetric: 5.0887 - val_loss: 5.1588 - val_MinusLogProbMetric: 5.1588 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 327/1000
2023-09-18 23:42:48.807 
Epoch 327/1000 
	 loss: 5.0913, MinusLogProbMetric: 5.0913, val_loss: 5.1873, val_MinusLogProbMetric: 5.1873

Epoch 327: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0913 - MinusLogProbMetric: 5.0913 - val_loss: 5.1873 - val_MinusLogProbMetric: 5.1873 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 328/1000
2023-09-18 23:43:57.402 
Epoch 328/1000 
	 loss: 5.0948, MinusLogProbMetric: 5.0948, val_loss: 5.1838, val_MinusLogProbMetric: 5.1838

Epoch 328: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0948 - MinusLogProbMetric: 5.0948 - val_loss: 5.1838 - val_MinusLogProbMetric: 5.1838 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 329/1000
2023-09-18 23:45:06.557 
Epoch 329/1000 
	 loss: 5.0889, MinusLogProbMetric: 5.0889, val_loss: 5.1722, val_MinusLogProbMetric: 5.1722

Epoch 329: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0889 - MinusLogProbMetric: 5.0889 - val_loss: 5.1722 - val_MinusLogProbMetric: 5.1722 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 330/1000
2023-09-18 23:46:15.484 
Epoch 330/1000 
	 loss: 5.0992, MinusLogProbMetric: 5.0992, val_loss: 5.1842, val_MinusLogProbMetric: 5.1842

Epoch 330: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0992 - MinusLogProbMetric: 5.0992 - val_loss: 5.1842 - val_MinusLogProbMetric: 5.1842 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 331/1000
2023-09-18 23:47:24.011 
Epoch 331/1000 
	 loss: 5.0945, MinusLogProbMetric: 5.0945, val_loss: 5.1633, val_MinusLogProbMetric: 5.1633

Epoch 331: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0945 - MinusLogProbMetric: 5.0945 - val_loss: 5.1633 - val_MinusLogProbMetric: 5.1633 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 332/1000
2023-09-18 23:48:33.043 
Epoch 332/1000 
	 loss: 5.0905, MinusLogProbMetric: 5.0905, val_loss: 5.1798, val_MinusLogProbMetric: 5.1798

Epoch 332: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0905 - MinusLogProbMetric: 5.0905 - val_loss: 5.1798 - val_MinusLogProbMetric: 5.1798 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 333/1000
2023-09-18 23:49:42.001 
Epoch 333/1000 
	 loss: 5.0978, MinusLogProbMetric: 5.0978, val_loss: 5.1942, val_MinusLogProbMetric: 5.1942

Epoch 333: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0978 - MinusLogProbMetric: 5.0978 - val_loss: 5.1942 - val_MinusLogProbMetric: 5.1942 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 334/1000
2023-09-18 23:50:50.721 
Epoch 334/1000 
	 loss: 5.1011, MinusLogProbMetric: 5.1011, val_loss: 5.2623, val_MinusLogProbMetric: 5.2623

Epoch 334: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.1011 - MinusLogProbMetric: 5.1011 - val_loss: 5.2623 - val_MinusLogProbMetric: 5.2623 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 335/1000
2023-09-18 23:51:59.945 
Epoch 335/1000 
	 loss: 5.1042, MinusLogProbMetric: 5.1042, val_loss: 5.1946, val_MinusLogProbMetric: 5.1946

Epoch 335: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.1042 - MinusLogProbMetric: 5.1042 - val_loss: 5.1946 - val_MinusLogProbMetric: 5.1946 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 336/1000
2023-09-18 23:53:09.365 
Epoch 336/1000 
	 loss: 5.0876, MinusLogProbMetric: 5.0876, val_loss: 5.2099, val_MinusLogProbMetric: 5.2099

Epoch 336: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0876 - MinusLogProbMetric: 5.0876 - val_loss: 5.2099 - val_MinusLogProbMetric: 5.2099 - lr: 5.0000e-04 - 69s/epoch - 354ms/step
Epoch 337/1000
2023-09-18 23:54:18.078 
Epoch 337/1000 
	 loss: 5.0988, MinusLogProbMetric: 5.0988, val_loss: 5.1720, val_MinusLogProbMetric: 5.1720

Epoch 337: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0988 - MinusLogProbMetric: 5.0988 - val_loss: 5.1720 - val_MinusLogProbMetric: 5.1720 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 338/1000
2023-09-18 23:55:27.035 
Epoch 338/1000 
	 loss: 5.0879, MinusLogProbMetric: 5.0879, val_loss: 5.1782, val_MinusLogProbMetric: 5.1782

Epoch 338: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0879 - MinusLogProbMetric: 5.0879 - val_loss: 5.1782 - val_MinusLogProbMetric: 5.1782 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 339/1000
2023-09-18 23:56:35.591 
Epoch 339/1000 
	 loss: 5.0983, MinusLogProbMetric: 5.0983, val_loss: 5.2022, val_MinusLogProbMetric: 5.2022

Epoch 339: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0983 - MinusLogProbMetric: 5.0983 - val_loss: 5.2022 - val_MinusLogProbMetric: 5.2022 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 340/1000
2023-09-18 23:57:44.063 
Epoch 340/1000 
	 loss: 5.0964, MinusLogProbMetric: 5.0964, val_loss: 5.2024, val_MinusLogProbMetric: 5.2024

Epoch 340: val_loss did not improve from 5.15877
196/196 - 68s - loss: 5.0964 - MinusLogProbMetric: 5.0964 - val_loss: 5.2024 - val_MinusLogProbMetric: 5.2024 - lr: 5.0000e-04 - 68s/epoch - 349ms/step
Epoch 341/1000
2023-09-18 23:58:52.391 
Epoch 341/1000 
	 loss: 5.1028, MinusLogProbMetric: 5.1028, val_loss: 5.2367, val_MinusLogProbMetric: 5.2367

Epoch 341: val_loss did not improve from 5.15877
196/196 - 68s - loss: 5.1028 - MinusLogProbMetric: 5.1028 - val_loss: 5.2367 - val_MinusLogProbMetric: 5.2367 - lr: 5.0000e-04 - 68s/epoch - 349ms/step
Epoch 342/1000
2023-09-19 00:00:00.804 
Epoch 342/1000 
	 loss: 5.0924, MinusLogProbMetric: 5.0924, val_loss: 5.1822, val_MinusLogProbMetric: 5.1822

Epoch 342: val_loss did not improve from 5.15877
196/196 - 68s - loss: 5.0924 - MinusLogProbMetric: 5.0924 - val_loss: 5.1822 - val_MinusLogProbMetric: 5.1822 - lr: 5.0000e-04 - 68s/epoch - 349ms/step
Epoch 343/1000
2023-09-19 00:01:09.617 
Epoch 343/1000 
	 loss: 5.0923, MinusLogProbMetric: 5.0923, val_loss: 5.1731, val_MinusLogProbMetric: 5.1731

Epoch 343: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0923 - MinusLogProbMetric: 5.0923 - val_loss: 5.1731 - val_MinusLogProbMetric: 5.1731 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 344/1000
2023-09-19 00:02:18.636 
Epoch 344/1000 
	 loss: 5.0892, MinusLogProbMetric: 5.0892, val_loss: 5.2294, val_MinusLogProbMetric: 5.2294

Epoch 344: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0892 - MinusLogProbMetric: 5.0892 - val_loss: 5.2294 - val_MinusLogProbMetric: 5.2294 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 345/1000
2023-09-19 00:03:27.160 
Epoch 345/1000 
	 loss: 5.0964, MinusLogProbMetric: 5.0964, val_loss: 5.1989, val_MinusLogProbMetric: 5.1989

Epoch 345: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0964 - MinusLogProbMetric: 5.0964 - val_loss: 5.1989 - val_MinusLogProbMetric: 5.1989 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 346/1000
2023-09-19 00:04:35.755 
Epoch 346/1000 
	 loss: 5.0926, MinusLogProbMetric: 5.0926, val_loss: 5.2430, val_MinusLogProbMetric: 5.2430

Epoch 346: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0926 - MinusLogProbMetric: 5.0926 - val_loss: 5.2430 - val_MinusLogProbMetric: 5.2430 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 347/1000
2023-09-19 00:05:37.205 
Epoch 347/1000 
	 loss: 5.0931, MinusLogProbMetric: 5.0931, val_loss: 5.2421, val_MinusLogProbMetric: 5.2421

Epoch 347: val_loss did not improve from 5.15877
196/196 - 61s - loss: 5.0931 - MinusLogProbMetric: 5.0931 - val_loss: 5.2421 - val_MinusLogProbMetric: 5.2421 - lr: 5.0000e-04 - 61s/epoch - 313ms/step
Epoch 348/1000
2023-09-19 00:06:34.543 
Epoch 348/1000 
	 loss: 5.0993, MinusLogProbMetric: 5.0993, val_loss: 5.1897, val_MinusLogProbMetric: 5.1897

Epoch 348: val_loss did not improve from 5.15877
196/196 - 57s - loss: 5.0993 - MinusLogProbMetric: 5.0993 - val_loss: 5.1897 - val_MinusLogProbMetric: 5.1897 - lr: 5.0000e-04 - 57s/epoch - 293ms/step
Epoch 349/1000
2023-09-19 00:07:42.987 
Epoch 349/1000 
	 loss: 5.0961, MinusLogProbMetric: 5.0961, val_loss: 5.2098, val_MinusLogProbMetric: 5.2098

Epoch 349: val_loss did not improve from 5.15877
196/196 - 68s - loss: 5.0961 - MinusLogProbMetric: 5.0961 - val_loss: 5.2098 - val_MinusLogProbMetric: 5.2098 - lr: 5.0000e-04 - 68s/epoch - 349ms/step
Epoch 350/1000
2023-09-19 00:08:52.024 
Epoch 350/1000 
	 loss: 5.0929, MinusLogProbMetric: 5.0929, val_loss: 5.2040, val_MinusLogProbMetric: 5.2040

Epoch 350: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0929 - MinusLogProbMetric: 5.0929 - val_loss: 5.2040 - val_MinusLogProbMetric: 5.2040 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 351/1000
2023-09-19 00:10:00.015 
Epoch 351/1000 
	 loss: 5.0977, MinusLogProbMetric: 5.0977, val_loss: 5.1712, val_MinusLogProbMetric: 5.1712

Epoch 351: val_loss did not improve from 5.15877
196/196 - 68s - loss: 5.0977 - MinusLogProbMetric: 5.0977 - val_loss: 5.1712 - val_MinusLogProbMetric: 5.1712 - lr: 5.0000e-04 - 68s/epoch - 347ms/step
Epoch 352/1000
2023-09-19 00:11:09.347 
Epoch 352/1000 
	 loss: 5.0936, MinusLogProbMetric: 5.0936, val_loss: 5.1865, val_MinusLogProbMetric: 5.1865

Epoch 352: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0936 - MinusLogProbMetric: 5.0936 - val_loss: 5.1865 - val_MinusLogProbMetric: 5.1865 - lr: 5.0000e-04 - 69s/epoch - 354ms/step
Epoch 353/1000
2023-09-19 00:12:18.446 
Epoch 353/1000 
	 loss: 5.0912, MinusLogProbMetric: 5.0912, val_loss: 5.2392, val_MinusLogProbMetric: 5.2392

Epoch 353: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0912 - MinusLogProbMetric: 5.0912 - val_loss: 5.2392 - val_MinusLogProbMetric: 5.2392 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 354/1000
2023-09-19 00:13:27.320 
Epoch 354/1000 
	 loss: 5.0889, MinusLogProbMetric: 5.0889, val_loss: 5.2110, val_MinusLogProbMetric: 5.2110

Epoch 354: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0889 - MinusLogProbMetric: 5.0889 - val_loss: 5.2110 - val_MinusLogProbMetric: 5.2110 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 355/1000
2023-09-19 00:14:36.287 
Epoch 355/1000 
	 loss: 5.0861, MinusLogProbMetric: 5.0861, val_loss: 5.1828, val_MinusLogProbMetric: 5.1828

Epoch 355: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0861 - MinusLogProbMetric: 5.0861 - val_loss: 5.1828 - val_MinusLogProbMetric: 5.1828 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 356/1000
2023-09-19 00:15:45.132 
Epoch 356/1000 
	 loss: 5.0909, MinusLogProbMetric: 5.0909, val_loss: 5.1893, val_MinusLogProbMetric: 5.1893

Epoch 356: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0909 - MinusLogProbMetric: 5.0909 - val_loss: 5.1893 - val_MinusLogProbMetric: 5.1893 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 357/1000
2023-09-19 00:16:54.179 
Epoch 357/1000 
	 loss: 5.0918, MinusLogProbMetric: 5.0918, val_loss: 5.1843, val_MinusLogProbMetric: 5.1843

Epoch 357: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0918 - MinusLogProbMetric: 5.0918 - val_loss: 5.1843 - val_MinusLogProbMetric: 5.1843 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 358/1000
2023-09-19 00:18:03.080 
Epoch 358/1000 
	 loss: 5.0885, MinusLogProbMetric: 5.0885, val_loss: 5.2274, val_MinusLogProbMetric: 5.2274

Epoch 358: val_loss did not improve from 5.15877
196/196 - 69s - loss: 5.0885 - MinusLogProbMetric: 5.0885 - val_loss: 5.2274 - val_MinusLogProbMetric: 5.2274 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 359/1000
2023-09-19 00:19:11.748 
Epoch 359/1000 
	 loss: 5.0887, MinusLogProbMetric: 5.0887, val_loss: 5.1575, val_MinusLogProbMetric: 5.1575

Epoch 359: val_loss improved from 5.15877 to 5.15751, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0887 - MinusLogProbMetric: 5.0887 - val_loss: 5.1575 - val_MinusLogProbMetric: 5.1575 - lr: 5.0000e-04 - 70s/epoch - 356ms/step
Epoch 360/1000
2023-09-19 00:20:21.838 
Epoch 360/1000 
	 loss: 5.0855, MinusLogProbMetric: 5.0855, val_loss: 5.1809, val_MinusLogProbMetric: 5.1809

Epoch 360: val_loss did not improve from 5.15751
196/196 - 69s - loss: 5.0855 - MinusLogProbMetric: 5.0855 - val_loss: 5.1809 - val_MinusLogProbMetric: 5.1809 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 361/1000
2023-09-19 00:21:30.444 
Epoch 361/1000 
	 loss: 5.0900, MinusLogProbMetric: 5.0900, val_loss: 5.1912, val_MinusLogProbMetric: 5.1912

Epoch 361: val_loss did not improve from 5.15751
196/196 - 69s - loss: 5.0900 - MinusLogProbMetric: 5.0900 - val_loss: 5.1912 - val_MinusLogProbMetric: 5.1912 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 362/1000
2023-09-19 00:22:38.928 
Epoch 362/1000 
	 loss: 5.0923, MinusLogProbMetric: 5.0923, val_loss: 5.2188, val_MinusLogProbMetric: 5.2188

Epoch 362: val_loss did not improve from 5.15751
196/196 - 68s - loss: 5.0923 - MinusLogProbMetric: 5.0923 - val_loss: 5.2188 - val_MinusLogProbMetric: 5.2188 - lr: 5.0000e-04 - 68s/epoch - 349ms/step
Epoch 363/1000
2023-09-19 00:23:47.764 
Epoch 363/1000 
	 loss: 5.0948, MinusLogProbMetric: 5.0948, val_loss: 5.1796, val_MinusLogProbMetric: 5.1796

Epoch 363: val_loss did not improve from 5.15751
196/196 - 69s - loss: 5.0948 - MinusLogProbMetric: 5.0948 - val_loss: 5.1796 - val_MinusLogProbMetric: 5.1796 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 364/1000
2023-09-19 00:24:56.546 
Epoch 364/1000 
	 loss: 5.0853, MinusLogProbMetric: 5.0853, val_loss: 5.1889, val_MinusLogProbMetric: 5.1889

Epoch 364: val_loss did not improve from 5.15751
196/196 - 69s - loss: 5.0853 - MinusLogProbMetric: 5.0853 - val_loss: 5.1889 - val_MinusLogProbMetric: 5.1889 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 365/1000
2023-09-19 00:26:05.464 
Epoch 365/1000 
	 loss: 5.0912, MinusLogProbMetric: 5.0912, val_loss: 5.2423, val_MinusLogProbMetric: 5.2423

Epoch 365: val_loss did not improve from 5.15751
196/196 - 69s - loss: 5.0912 - MinusLogProbMetric: 5.0912 - val_loss: 5.2423 - val_MinusLogProbMetric: 5.2423 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 366/1000
2023-09-19 00:27:14.157 
Epoch 366/1000 
	 loss: 5.0905, MinusLogProbMetric: 5.0905, val_loss: 5.1758, val_MinusLogProbMetric: 5.1758

Epoch 366: val_loss did not improve from 5.15751
196/196 - 69s - loss: 5.0905 - MinusLogProbMetric: 5.0905 - val_loss: 5.1758 - val_MinusLogProbMetric: 5.1758 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 367/1000
2023-09-19 00:28:23.414 
Epoch 367/1000 
	 loss: 5.0875, MinusLogProbMetric: 5.0875, val_loss: 5.1863, val_MinusLogProbMetric: 5.1863

Epoch 367: val_loss did not improve from 5.15751
196/196 - 69s - loss: 5.0875 - MinusLogProbMetric: 5.0875 - val_loss: 5.1863 - val_MinusLogProbMetric: 5.1863 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 368/1000
2023-09-19 00:29:32.291 
Epoch 368/1000 
	 loss: 5.0848, MinusLogProbMetric: 5.0848, val_loss: 5.1873, val_MinusLogProbMetric: 5.1873

Epoch 368: val_loss did not improve from 5.15751
196/196 - 69s - loss: 5.0848 - MinusLogProbMetric: 5.0848 - val_loss: 5.1873 - val_MinusLogProbMetric: 5.1873 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 369/1000
2023-09-19 00:30:41.014 
Epoch 369/1000 
	 loss: 5.0909, MinusLogProbMetric: 5.0909, val_loss: 5.1679, val_MinusLogProbMetric: 5.1679

Epoch 369: val_loss did not improve from 5.15751
196/196 - 69s - loss: 5.0909 - MinusLogProbMetric: 5.0909 - val_loss: 5.1679 - val_MinusLogProbMetric: 5.1679 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 370/1000
2023-09-19 00:31:50.295 
Epoch 370/1000 
	 loss: 5.0870, MinusLogProbMetric: 5.0870, val_loss: 5.1694, val_MinusLogProbMetric: 5.1694

Epoch 370: val_loss did not improve from 5.15751
196/196 - 69s - loss: 5.0870 - MinusLogProbMetric: 5.0870 - val_loss: 5.1694 - val_MinusLogProbMetric: 5.1694 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 371/1000
2023-09-19 00:32:59.232 
Epoch 371/1000 
	 loss: 5.0888, MinusLogProbMetric: 5.0888, val_loss: 5.1689, val_MinusLogProbMetric: 5.1689

Epoch 371: val_loss did not improve from 5.15751
196/196 - 69s - loss: 5.0888 - MinusLogProbMetric: 5.0888 - val_loss: 5.1689 - val_MinusLogProbMetric: 5.1689 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 372/1000
2023-09-19 00:34:08.403 
Epoch 372/1000 
	 loss: 5.0925, MinusLogProbMetric: 5.0925, val_loss: 5.1757, val_MinusLogProbMetric: 5.1757

Epoch 372: val_loss did not improve from 5.15751
196/196 - 69s - loss: 5.0925 - MinusLogProbMetric: 5.0925 - val_loss: 5.1757 - val_MinusLogProbMetric: 5.1757 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 373/1000
2023-09-19 00:35:17.164 
Epoch 373/1000 
	 loss: 5.0891, MinusLogProbMetric: 5.0891, val_loss: 5.2014, val_MinusLogProbMetric: 5.2014

Epoch 373: val_loss did not improve from 5.15751
196/196 - 69s - loss: 5.0891 - MinusLogProbMetric: 5.0891 - val_loss: 5.2014 - val_MinusLogProbMetric: 5.2014 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 374/1000
2023-09-19 00:36:26.436 
Epoch 374/1000 
	 loss: 5.0898, MinusLogProbMetric: 5.0898, val_loss: 5.2132, val_MinusLogProbMetric: 5.2132

Epoch 374: val_loss did not improve from 5.15751
196/196 - 69s - loss: 5.0898 - MinusLogProbMetric: 5.0898 - val_loss: 5.2132 - val_MinusLogProbMetric: 5.2132 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 375/1000
2023-09-19 00:37:35.731 
Epoch 375/1000 
	 loss: 5.0932, MinusLogProbMetric: 5.0932, val_loss: 5.1925, val_MinusLogProbMetric: 5.1925

Epoch 375: val_loss did not improve from 5.15751
196/196 - 69s - loss: 5.0932 - MinusLogProbMetric: 5.0932 - val_loss: 5.1925 - val_MinusLogProbMetric: 5.1925 - lr: 5.0000e-04 - 69s/epoch - 354ms/step
Epoch 376/1000
2023-09-19 00:38:45.185 
Epoch 376/1000 
	 loss: 5.0877, MinusLogProbMetric: 5.0877, val_loss: 5.2255, val_MinusLogProbMetric: 5.2255

Epoch 376: val_loss did not improve from 5.15751
196/196 - 69s - loss: 5.0877 - MinusLogProbMetric: 5.0877 - val_loss: 5.2255 - val_MinusLogProbMetric: 5.2255 - lr: 5.0000e-04 - 69s/epoch - 354ms/step
Epoch 377/1000
2023-09-19 00:39:54.584 
Epoch 377/1000 
	 loss: 5.0920, MinusLogProbMetric: 5.0920, val_loss: 5.1721, val_MinusLogProbMetric: 5.1721

Epoch 377: val_loss did not improve from 5.15751
196/196 - 69s - loss: 5.0920 - MinusLogProbMetric: 5.0920 - val_loss: 5.1721 - val_MinusLogProbMetric: 5.1721 - lr: 5.0000e-04 - 69s/epoch - 354ms/step
Epoch 378/1000
2023-09-19 00:41:03.093 
Epoch 378/1000 
	 loss: 5.0851, MinusLogProbMetric: 5.0851, val_loss: 5.1824, val_MinusLogProbMetric: 5.1824

Epoch 378: val_loss did not improve from 5.15751
196/196 - 69s - loss: 5.0851 - MinusLogProbMetric: 5.0851 - val_loss: 5.1824 - val_MinusLogProbMetric: 5.1824 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 379/1000
2023-09-19 00:42:11.919 
Epoch 379/1000 
	 loss: 5.0982, MinusLogProbMetric: 5.0982, val_loss: 5.1881, val_MinusLogProbMetric: 5.1881

Epoch 379: val_loss did not improve from 5.15751
196/196 - 69s - loss: 5.0982 - MinusLogProbMetric: 5.0982 - val_loss: 5.1881 - val_MinusLogProbMetric: 5.1881 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 380/1000
2023-09-19 00:43:20.466 
Epoch 380/1000 
	 loss: 5.0872, MinusLogProbMetric: 5.0872, val_loss: 5.1977, val_MinusLogProbMetric: 5.1977

Epoch 380: val_loss did not improve from 5.15751
196/196 - 69s - loss: 5.0872 - MinusLogProbMetric: 5.0872 - val_loss: 5.1977 - val_MinusLogProbMetric: 5.1977 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 381/1000
2023-09-19 00:44:29.404 
Epoch 381/1000 
	 loss: 5.0869, MinusLogProbMetric: 5.0869, val_loss: 5.1504, val_MinusLogProbMetric: 5.1504

Epoch 381: val_loss improved from 5.15751 to 5.15045, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0869 - MinusLogProbMetric: 5.0869 - val_loss: 5.1504 - val_MinusLogProbMetric: 5.1504 - lr: 5.0000e-04 - 70s/epoch - 357ms/step
Epoch 382/1000
2023-09-19 00:45:39.719 
Epoch 382/1000 
	 loss: 5.0936, MinusLogProbMetric: 5.0936, val_loss: 5.1767, val_MinusLogProbMetric: 5.1767

Epoch 382: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0936 - MinusLogProbMetric: 5.0936 - val_loss: 5.1767 - val_MinusLogProbMetric: 5.1767 - lr: 5.0000e-04 - 69s/epoch - 354ms/step
Epoch 383/1000
2023-09-19 00:46:49.007 
Epoch 383/1000 
	 loss: 5.0828, MinusLogProbMetric: 5.0828, val_loss: 5.1856, val_MinusLogProbMetric: 5.1856

Epoch 383: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0828 - MinusLogProbMetric: 5.0828 - val_loss: 5.1856 - val_MinusLogProbMetric: 5.1856 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 384/1000
2023-09-19 00:47:58.213 
Epoch 384/1000 
	 loss: 5.0892, MinusLogProbMetric: 5.0892, val_loss: 5.2347, val_MinusLogProbMetric: 5.2347

Epoch 384: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0892 - MinusLogProbMetric: 5.0892 - val_loss: 5.2347 - val_MinusLogProbMetric: 5.2347 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 385/1000
2023-09-19 00:49:07.317 
Epoch 385/1000 
	 loss: 5.0883, MinusLogProbMetric: 5.0883, val_loss: 5.1787, val_MinusLogProbMetric: 5.1787

Epoch 385: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0883 - MinusLogProbMetric: 5.0883 - val_loss: 5.1787 - val_MinusLogProbMetric: 5.1787 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 386/1000
2023-09-19 00:50:16.224 
Epoch 386/1000 
	 loss: 5.0857, MinusLogProbMetric: 5.0857, val_loss: 5.1924, val_MinusLogProbMetric: 5.1924

Epoch 386: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0857 - MinusLogProbMetric: 5.0857 - val_loss: 5.1924 - val_MinusLogProbMetric: 5.1924 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 387/1000
2023-09-19 00:51:25.483 
Epoch 387/1000 
	 loss: 5.0880, MinusLogProbMetric: 5.0880, val_loss: 5.1853, val_MinusLogProbMetric: 5.1853

Epoch 387: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0880 - MinusLogProbMetric: 5.0880 - val_loss: 5.1853 - val_MinusLogProbMetric: 5.1853 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 388/1000
2023-09-19 00:52:34.187 
Epoch 388/1000 
	 loss: 5.0867, MinusLogProbMetric: 5.0867, val_loss: 5.1637, val_MinusLogProbMetric: 5.1637

Epoch 388: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0867 - MinusLogProbMetric: 5.0867 - val_loss: 5.1637 - val_MinusLogProbMetric: 5.1637 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 389/1000
2023-09-19 00:53:43.116 
Epoch 389/1000 
	 loss: 5.0896, MinusLogProbMetric: 5.0896, val_loss: 5.1545, val_MinusLogProbMetric: 5.1545

Epoch 389: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0896 - MinusLogProbMetric: 5.0896 - val_loss: 5.1545 - val_MinusLogProbMetric: 5.1545 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 390/1000
2023-09-19 00:54:52.628 
Epoch 390/1000 
	 loss: 5.0935, MinusLogProbMetric: 5.0935, val_loss: 5.1902, val_MinusLogProbMetric: 5.1902

Epoch 390: val_loss did not improve from 5.15045
196/196 - 70s - loss: 5.0935 - MinusLogProbMetric: 5.0935 - val_loss: 5.1902 - val_MinusLogProbMetric: 5.1902 - lr: 5.0000e-04 - 70s/epoch - 355ms/step
Epoch 391/1000
2023-09-19 00:56:01.798 
Epoch 391/1000 
	 loss: 5.0872, MinusLogProbMetric: 5.0872, val_loss: 5.1856, val_MinusLogProbMetric: 5.1856

Epoch 391: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0872 - MinusLogProbMetric: 5.0872 - val_loss: 5.1856 - val_MinusLogProbMetric: 5.1856 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 392/1000
2023-09-19 00:57:11.048 
Epoch 392/1000 
	 loss: 5.0891, MinusLogProbMetric: 5.0891, val_loss: 5.1662, val_MinusLogProbMetric: 5.1662

Epoch 392: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0891 - MinusLogProbMetric: 5.0891 - val_loss: 5.1662 - val_MinusLogProbMetric: 5.1662 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 393/1000
2023-09-19 00:58:20.236 
Epoch 393/1000 
	 loss: 5.0822, MinusLogProbMetric: 5.0822, val_loss: 5.1515, val_MinusLogProbMetric: 5.1515

Epoch 393: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0822 - MinusLogProbMetric: 5.0822 - val_loss: 5.1515 - val_MinusLogProbMetric: 5.1515 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 394/1000
2023-09-19 00:59:29.509 
Epoch 394/1000 
	 loss: 5.0825, MinusLogProbMetric: 5.0825, val_loss: 5.2279, val_MinusLogProbMetric: 5.2279

Epoch 394: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0825 - MinusLogProbMetric: 5.0825 - val_loss: 5.2279 - val_MinusLogProbMetric: 5.2279 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 395/1000
2023-09-19 01:00:38.474 
Epoch 395/1000 
	 loss: 5.0921, MinusLogProbMetric: 5.0921, val_loss: 5.1580, val_MinusLogProbMetric: 5.1580

Epoch 395: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0921 - MinusLogProbMetric: 5.0921 - val_loss: 5.1580 - val_MinusLogProbMetric: 5.1580 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 396/1000
2023-09-19 01:01:47.566 
Epoch 396/1000 
	 loss: 5.0843, MinusLogProbMetric: 5.0843, val_loss: 5.1549, val_MinusLogProbMetric: 5.1549

Epoch 396: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0843 - MinusLogProbMetric: 5.0843 - val_loss: 5.1549 - val_MinusLogProbMetric: 5.1549 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 397/1000
2023-09-19 01:02:56.725 
Epoch 397/1000 
	 loss: 5.0841, MinusLogProbMetric: 5.0841, val_loss: 5.2022, val_MinusLogProbMetric: 5.2022

Epoch 397: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0841 - MinusLogProbMetric: 5.0841 - val_loss: 5.2022 - val_MinusLogProbMetric: 5.2022 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 398/1000
2023-09-19 01:04:05.914 
Epoch 398/1000 
	 loss: 5.0832, MinusLogProbMetric: 5.0832, val_loss: 5.1574, val_MinusLogProbMetric: 5.1574

Epoch 398: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0832 - MinusLogProbMetric: 5.0832 - val_loss: 5.1574 - val_MinusLogProbMetric: 5.1574 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 399/1000
2023-09-19 01:05:15.494 
Epoch 399/1000 
	 loss: 5.0891, MinusLogProbMetric: 5.0891, val_loss: 5.1714, val_MinusLogProbMetric: 5.1714

Epoch 399: val_loss did not improve from 5.15045
196/196 - 70s - loss: 5.0891 - MinusLogProbMetric: 5.0891 - val_loss: 5.1714 - val_MinusLogProbMetric: 5.1714 - lr: 5.0000e-04 - 70s/epoch - 355ms/step
Epoch 400/1000
2023-09-19 01:06:24.683 
Epoch 400/1000 
	 loss: 5.0837, MinusLogProbMetric: 5.0837, val_loss: 5.1931, val_MinusLogProbMetric: 5.1931

Epoch 400: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0837 - MinusLogProbMetric: 5.0837 - val_loss: 5.1931 - val_MinusLogProbMetric: 5.1931 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 401/1000
2023-09-19 01:07:33.914 
Epoch 401/1000 
	 loss: 5.0830, MinusLogProbMetric: 5.0830, val_loss: 5.1873, val_MinusLogProbMetric: 5.1873

Epoch 401: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0830 - MinusLogProbMetric: 5.0830 - val_loss: 5.1873 - val_MinusLogProbMetric: 5.1873 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 402/1000
2023-09-19 01:08:43.219 
Epoch 402/1000 
	 loss: 5.0834, MinusLogProbMetric: 5.0834, val_loss: 5.1787, val_MinusLogProbMetric: 5.1787

Epoch 402: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0834 - MinusLogProbMetric: 5.0834 - val_loss: 5.1787 - val_MinusLogProbMetric: 5.1787 - lr: 5.0000e-04 - 69s/epoch - 354ms/step
Epoch 403/1000
2023-09-19 01:09:52.477 
Epoch 403/1000 
	 loss: 5.0818, MinusLogProbMetric: 5.0818, val_loss: 5.2558, val_MinusLogProbMetric: 5.2558

Epoch 403: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0818 - MinusLogProbMetric: 5.0818 - val_loss: 5.2558 - val_MinusLogProbMetric: 5.2558 - lr: 5.0000e-04 - 69s/epoch - 353ms/step
Epoch 404/1000
2023-09-19 01:11:01.421 
Epoch 404/1000 
	 loss: 5.0899, MinusLogProbMetric: 5.0899, val_loss: 5.2076, val_MinusLogProbMetric: 5.2076

Epoch 404: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0899 - MinusLogProbMetric: 5.0899 - val_loss: 5.2076 - val_MinusLogProbMetric: 5.2076 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 405/1000
2023-09-19 01:12:10.789 
Epoch 405/1000 
	 loss: 5.0833, MinusLogProbMetric: 5.0833, val_loss: 5.1565, val_MinusLogProbMetric: 5.1565

Epoch 405: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0833 - MinusLogProbMetric: 5.0833 - val_loss: 5.1565 - val_MinusLogProbMetric: 5.1565 - lr: 5.0000e-04 - 69s/epoch - 354ms/step
Epoch 406/1000
2023-09-19 01:13:19.295 
Epoch 406/1000 
	 loss: 5.0813, MinusLogProbMetric: 5.0813, val_loss: 5.1876, val_MinusLogProbMetric: 5.1876

Epoch 406: val_loss did not improve from 5.15045
196/196 - 68s - loss: 5.0813 - MinusLogProbMetric: 5.0813 - val_loss: 5.1876 - val_MinusLogProbMetric: 5.1876 - lr: 5.0000e-04 - 68s/epoch - 349ms/step
Epoch 407/1000
2023-09-19 01:14:29.147 
Epoch 407/1000 
	 loss: 5.0832, MinusLogProbMetric: 5.0832, val_loss: 5.1638, val_MinusLogProbMetric: 5.1638

Epoch 407: val_loss did not improve from 5.15045
196/196 - 70s - loss: 5.0832 - MinusLogProbMetric: 5.0832 - val_loss: 5.1638 - val_MinusLogProbMetric: 5.1638 - lr: 5.0000e-04 - 70s/epoch - 356ms/step
Epoch 408/1000
2023-09-19 01:15:36.677 
Epoch 408/1000 
	 loss: 5.0835, MinusLogProbMetric: 5.0835, val_loss: 5.2288, val_MinusLogProbMetric: 5.2288

Epoch 408: val_loss did not improve from 5.15045
196/196 - 68s - loss: 5.0835 - MinusLogProbMetric: 5.0835 - val_loss: 5.2288 - val_MinusLogProbMetric: 5.2288 - lr: 5.0000e-04 - 68s/epoch - 345ms/step
Epoch 409/1000
2023-09-19 01:16:36.167 
Epoch 409/1000 
	 loss: 5.0846, MinusLogProbMetric: 5.0846, val_loss: 5.1883, val_MinusLogProbMetric: 5.1883

Epoch 409: val_loss did not improve from 5.15045
196/196 - 59s - loss: 5.0846 - MinusLogProbMetric: 5.0846 - val_loss: 5.1883 - val_MinusLogProbMetric: 5.1883 - lr: 5.0000e-04 - 59s/epoch - 304ms/step
Epoch 410/1000
2023-09-19 01:17:44.075 
Epoch 410/1000 
	 loss: 5.0898, MinusLogProbMetric: 5.0898, val_loss: 5.1947, val_MinusLogProbMetric: 5.1947

Epoch 410: val_loss did not improve from 5.15045
196/196 - 68s - loss: 5.0898 - MinusLogProbMetric: 5.0898 - val_loss: 5.1947 - val_MinusLogProbMetric: 5.1947 - lr: 5.0000e-04 - 68s/epoch - 346ms/step
Epoch 411/1000
2023-09-19 01:18:52.381 
Epoch 411/1000 
	 loss: 5.0900, MinusLogProbMetric: 5.0900, val_loss: 5.1944, val_MinusLogProbMetric: 5.1944

Epoch 411: val_loss did not improve from 5.15045
196/196 - 68s - loss: 5.0900 - MinusLogProbMetric: 5.0900 - val_loss: 5.1944 - val_MinusLogProbMetric: 5.1944 - lr: 5.0000e-04 - 68s/epoch - 348ms/step
Epoch 412/1000
2023-09-19 01:20:01.270 
Epoch 412/1000 
	 loss: 5.0897, MinusLogProbMetric: 5.0897, val_loss: 5.1659, val_MinusLogProbMetric: 5.1659

Epoch 412: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0897 - MinusLogProbMetric: 5.0897 - val_loss: 5.1659 - val_MinusLogProbMetric: 5.1659 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 413/1000
2023-09-19 01:21:08.386 
Epoch 413/1000 
	 loss: 5.0786, MinusLogProbMetric: 5.0786, val_loss: 5.1913, val_MinusLogProbMetric: 5.1913

Epoch 413: val_loss did not improve from 5.15045
196/196 - 67s - loss: 5.0786 - MinusLogProbMetric: 5.0786 - val_loss: 5.1913 - val_MinusLogProbMetric: 5.1913 - lr: 5.0000e-04 - 67s/epoch - 342ms/step
Epoch 414/1000
2023-09-19 01:22:07.614 
Epoch 414/1000 
	 loss: 5.0812, MinusLogProbMetric: 5.0812, val_loss: 5.1949, val_MinusLogProbMetric: 5.1949

Epoch 414: val_loss did not improve from 5.15045
196/196 - 59s - loss: 5.0812 - MinusLogProbMetric: 5.0812 - val_loss: 5.1949 - val_MinusLogProbMetric: 5.1949 - lr: 5.0000e-04 - 59s/epoch - 302ms/step
Epoch 415/1000
2023-09-19 01:23:11.736 
Epoch 415/1000 
	 loss: 5.0847, MinusLogProbMetric: 5.0847, val_loss: 5.2063, val_MinusLogProbMetric: 5.2063

Epoch 415: val_loss did not improve from 5.15045
196/196 - 64s - loss: 5.0847 - MinusLogProbMetric: 5.0847 - val_loss: 5.2063 - val_MinusLogProbMetric: 5.2063 - lr: 5.0000e-04 - 64s/epoch - 327ms/step
Epoch 416/1000
2023-09-19 01:24:20.377 
Epoch 416/1000 
	 loss: 5.0782, MinusLogProbMetric: 5.0782, val_loss: 5.1824, val_MinusLogProbMetric: 5.1824

Epoch 416: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0782 - MinusLogProbMetric: 5.0782 - val_loss: 5.1824 - val_MinusLogProbMetric: 5.1824 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 417/1000
2023-09-19 01:25:28.297 
Epoch 417/1000 
	 loss: 5.0802, MinusLogProbMetric: 5.0802, val_loss: 5.1649, val_MinusLogProbMetric: 5.1649

Epoch 417: val_loss did not improve from 5.15045
196/196 - 68s - loss: 5.0802 - MinusLogProbMetric: 5.0802 - val_loss: 5.1649 - val_MinusLogProbMetric: 5.1649 - lr: 5.0000e-04 - 68s/epoch - 347ms/step
Epoch 418/1000
2023-09-19 01:26:36.648 
Epoch 418/1000 
	 loss: 5.0733, MinusLogProbMetric: 5.0733, val_loss: 5.1844, val_MinusLogProbMetric: 5.1844

Epoch 418: val_loss did not improve from 5.15045
196/196 - 68s - loss: 5.0733 - MinusLogProbMetric: 5.0733 - val_loss: 5.1844 - val_MinusLogProbMetric: 5.1844 - lr: 5.0000e-04 - 68s/epoch - 349ms/step
Epoch 419/1000
2023-09-19 01:27:45.690 
Epoch 419/1000 
	 loss: 5.0746, MinusLogProbMetric: 5.0746, val_loss: 5.1826, val_MinusLogProbMetric: 5.1826

Epoch 419: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0746 - MinusLogProbMetric: 5.0746 - val_loss: 5.1826 - val_MinusLogProbMetric: 5.1826 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 420/1000
2023-09-19 01:28:54.490 
Epoch 420/1000 
	 loss: 5.0848, MinusLogProbMetric: 5.0848, val_loss: 5.1656, val_MinusLogProbMetric: 5.1656

Epoch 420: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0848 - MinusLogProbMetric: 5.0848 - val_loss: 5.1656 - val_MinusLogProbMetric: 5.1656 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 421/1000
2023-09-19 01:30:02.554 
Epoch 421/1000 
	 loss: 5.0806, MinusLogProbMetric: 5.0806, val_loss: 5.2041, val_MinusLogProbMetric: 5.2041

Epoch 421: val_loss did not improve from 5.15045
196/196 - 68s - loss: 5.0806 - MinusLogProbMetric: 5.0806 - val_loss: 5.2041 - val_MinusLogProbMetric: 5.2041 - lr: 5.0000e-04 - 68s/epoch - 347ms/step
Epoch 422/1000
2023-09-19 01:31:11.518 
Epoch 422/1000 
	 loss: 5.0823, MinusLogProbMetric: 5.0823, val_loss: 5.1854, val_MinusLogProbMetric: 5.1854

Epoch 422: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0823 - MinusLogProbMetric: 5.0823 - val_loss: 5.1854 - val_MinusLogProbMetric: 5.1854 - lr: 5.0000e-04 - 69s/epoch - 352ms/step
Epoch 423/1000
2023-09-19 01:32:19.716 
Epoch 423/1000 
	 loss: 5.0878, MinusLogProbMetric: 5.0878, val_loss: 5.1818, val_MinusLogProbMetric: 5.1818

Epoch 423: val_loss did not improve from 5.15045
196/196 - 68s - loss: 5.0878 - MinusLogProbMetric: 5.0878 - val_loss: 5.1818 - val_MinusLogProbMetric: 5.1818 - lr: 5.0000e-04 - 68s/epoch - 348ms/step
Epoch 424/1000
2023-09-19 01:33:28.312 
Epoch 424/1000 
	 loss: 5.0800, MinusLogProbMetric: 5.0800, val_loss: 5.1573, val_MinusLogProbMetric: 5.1573

Epoch 424: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0800 - MinusLogProbMetric: 5.0800 - val_loss: 5.1573 - val_MinusLogProbMetric: 5.1573 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 425/1000
2023-09-19 01:34:36.754 
Epoch 425/1000 
	 loss: 5.0868, MinusLogProbMetric: 5.0868, val_loss: 5.2225, val_MinusLogProbMetric: 5.2225

Epoch 425: val_loss did not improve from 5.15045
196/196 - 68s - loss: 5.0868 - MinusLogProbMetric: 5.0868 - val_loss: 5.2225 - val_MinusLogProbMetric: 5.2225 - lr: 5.0000e-04 - 68s/epoch - 349ms/step
Epoch 426/1000
2023-09-19 01:35:44.847 
Epoch 426/1000 
	 loss: 5.0827, MinusLogProbMetric: 5.0827, val_loss: 5.1814, val_MinusLogProbMetric: 5.1814

Epoch 426: val_loss did not improve from 5.15045
196/196 - 68s - loss: 5.0827 - MinusLogProbMetric: 5.0827 - val_loss: 5.1814 - val_MinusLogProbMetric: 5.1814 - lr: 5.0000e-04 - 68s/epoch - 347ms/step
Epoch 427/1000
2023-09-19 01:36:53.596 
Epoch 427/1000 
	 loss: 5.0829, MinusLogProbMetric: 5.0829, val_loss: 5.2100, val_MinusLogProbMetric: 5.2100

Epoch 427: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0829 - MinusLogProbMetric: 5.0829 - val_loss: 5.2100 - val_MinusLogProbMetric: 5.2100 - lr: 5.0000e-04 - 69s/epoch - 351ms/step
Epoch 428/1000
2023-09-19 01:38:01.863 
Epoch 428/1000 
	 loss: 5.0891, MinusLogProbMetric: 5.0891, val_loss: 5.1775, val_MinusLogProbMetric: 5.1775

Epoch 428: val_loss did not improve from 5.15045
196/196 - 68s - loss: 5.0891 - MinusLogProbMetric: 5.0891 - val_loss: 5.1775 - val_MinusLogProbMetric: 5.1775 - lr: 5.0000e-04 - 68s/epoch - 348ms/step
Epoch 429/1000
2023-09-19 01:39:10.019 
Epoch 429/1000 
	 loss: 5.0859, MinusLogProbMetric: 5.0859, val_loss: 5.1832, val_MinusLogProbMetric: 5.1832

Epoch 429: val_loss did not improve from 5.15045
196/196 - 68s - loss: 5.0859 - MinusLogProbMetric: 5.0859 - val_loss: 5.1832 - val_MinusLogProbMetric: 5.1832 - lr: 5.0000e-04 - 68s/epoch - 348ms/step
Epoch 430/1000
2023-09-19 01:40:18.383 
Epoch 430/1000 
	 loss: 5.0871, MinusLogProbMetric: 5.0871, val_loss: 5.1901, val_MinusLogProbMetric: 5.1901

Epoch 430: val_loss did not improve from 5.15045
196/196 - 68s - loss: 5.0871 - MinusLogProbMetric: 5.0871 - val_loss: 5.1901 - val_MinusLogProbMetric: 5.1901 - lr: 5.0000e-04 - 68s/epoch - 349ms/step
Epoch 431/1000
2023-09-19 01:41:26.968 
Epoch 431/1000 
	 loss: 5.0857, MinusLogProbMetric: 5.0857, val_loss: 5.1801, val_MinusLogProbMetric: 5.1801

Epoch 431: val_loss did not improve from 5.15045
196/196 - 69s - loss: 5.0857 - MinusLogProbMetric: 5.0857 - val_loss: 5.1801 - val_MinusLogProbMetric: 5.1801 - lr: 5.0000e-04 - 69s/epoch - 350ms/step
Epoch 432/1000
2023-09-19 01:42:35.354 
Epoch 432/1000 
	 loss: 5.0504, MinusLogProbMetric: 5.0504, val_loss: 5.1457, val_MinusLogProbMetric: 5.1457

Epoch 432: val_loss improved from 5.15045 to 5.14572, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0504 - MinusLogProbMetric: 5.0504 - val_loss: 5.1457 - val_MinusLogProbMetric: 5.1457 - lr: 2.5000e-04 - 70s/epoch - 355ms/step
Epoch 433/1000
2023-09-19 01:43:45.470 
Epoch 433/1000 
	 loss: 5.0524, MinusLogProbMetric: 5.0524, val_loss: 5.1509, val_MinusLogProbMetric: 5.1509

Epoch 433: val_loss did not improve from 5.14572
196/196 - 69s - loss: 5.0524 - MinusLogProbMetric: 5.0524 - val_loss: 5.1509 - val_MinusLogProbMetric: 5.1509 - lr: 2.5000e-04 - 69s/epoch - 351ms/step
Epoch 434/1000
2023-09-19 01:44:54.110 
Epoch 434/1000 
	 loss: 5.0522, MinusLogProbMetric: 5.0522, val_loss: 5.1339, val_MinusLogProbMetric: 5.1339

Epoch 434: val_loss improved from 5.14572 to 5.13386, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0522 - MinusLogProbMetric: 5.0522 - val_loss: 5.1339 - val_MinusLogProbMetric: 5.1339 - lr: 2.5000e-04 - 70s/epoch - 357ms/step
Epoch 435/1000
2023-09-19 01:46:04.196 
Epoch 435/1000 
	 loss: 5.0494, MinusLogProbMetric: 5.0494, val_loss: 5.1475, val_MinusLogProbMetric: 5.1475

Epoch 435: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0494 - MinusLogProbMetric: 5.0494 - val_loss: 5.1475 - val_MinusLogProbMetric: 5.1475 - lr: 2.5000e-04 - 69s/epoch - 351ms/step
Epoch 436/1000
2023-09-19 01:47:12.708 
Epoch 436/1000 
	 loss: 5.0513, MinusLogProbMetric: 5.0513, val_loss: 5.1556, val_MinusLogProbMetric: 5.1556

Epoch 436: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0513 - MinusLogProbMetric: 5.0513 - val_loss: 5.1556 - val_MinusLogProbMetric: 5.1556 - lr: 2.5000e-04 - 69s/epoch - 350ms/step
Epoch 437/1000
2023-09-19 01:48:21.511 
Epoch 437/1000 
	 loss: 5.0529, MinusLogProbMetric: 5.0529, val_loss: 5.1497, val_MinusLogProbMetric: 5.1497

Epoch 437: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0529 - MinusLogProbMetric: 5.0529 - val_loss: 5.1497 - val_MinusLogProbMetric: 5.1497 - lr: 2.5000e-04 - 69s/epoch - 351ms/step
Epoch 438/1000
2023-09-19 01:49:29.910 
Epoch 438/1000 
	 loss: 5.0530, MinusLogProbMetric: 5.0530, val_loss: 5.1527, val_MinusLogProbMetric: 5.1527

Epoch 438: val_loss did not improve from 5.13386
196/196 - 68s - loss: 5.0530 - MinusLogProbMetric: 5.0530 - val_loss: 5.1527 - val_MinusLogProbMetric: 5.1527 - lr: 2.5000e-04 - 68s/epoch - 349ms/step
Epoch 439/1000
2023-09-19 01:50:38.384 
Epoch 439/1000 
	 loss: 5.0505, MinusLogProbMetric: 5.0505, val_loss: 5.1534, val_MinusLogProbMetric: 5.1534

Epoch 439: val_loss did not improve from 5.13386
196/196 - 68s - loss: 5.0505 - MinusLogProbMetric: 5.0505 - val_loss: 5.1534 - val_MinusLogProbMetric: 5.1534 - lr: 2.5000e-04 - 68s/epoch - 349ms/step
Epoch 440/1000
2023-09-19 01:51:46.300 
Epoch 440/1000 
	 loss: 5.0510, MinusLogProbMetric: 5.0510, val_loss: 5.1460, val_MinusLogProbMetric: 5.1460

Epoch 440: val_loss did not improve from 5.13386
196/196 - 68s - loss: 5.0510 - MinusLogProbMetric: 5.0510 - val_loss: 5.1460 - val_MinusLogProbMetric: 5.1460 - lr: 2.5000e-04 - 68s/epoch - 346ms/step
Epoch 441/1000
2023-09-19 01:52:55.099 
Epoch 441/1000 
	 loss: 5.0493, MinusLogProbMetric: 5.0493, val_loss: 5.1645, val_MinusLogProbMetric: 5.1645

Epoch 441: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0493 - MinusLogProbMetric: 5.0493 - val_loss: 5.1645 - val_MinusLogProbMetric: 5.1645 - lr: 2.5000e-04 - 69s/epoch - 351ms/step
Epoch 442/1000
2023-09-19 01:54:03.513 
Epoch 442/1000 
	 loss: 5.0511, MinusLogProbMetric: 5.0511, val_loss: 5.1429, val_MinusLogProbMetric: 5.1429

Epoch 442: val_loss did not improve from 5.13386
196/196 - 68s - loss: 5.0511 - MinusLogProbMetric: 5.0511 - val_loss: 5.1429 - val_MinusLogProbMetric: 5.1429 - lr: 2.5000e-04 - 68s/epoch - 349ms/step
Epoch 443/1000
2023-09-19 01:55:12.555 
Epoch 443/1000 
	 loss: 5.0533, MinusLogProbMetric: 5.0533, val_loss: 5.1558, val_MinusLogProbMetric: 5.1558

Epoch 443: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0533 - MinusLogProbMetric: 5.0533 - val_loss: 5.1558 - val_MinusLogProbMetric: 5.1558 - lr: 2.5000e-04 - 69s/epoch - 352ms/step
Epoch 444/1000
2023-09-19 01:56:21.395 
Epoch 444/1000 
	 loss: 5.0518, MinusLogProbMetric: 5.0518, val_loss: 5.1722, val_MinusLogProbMetric: 5.1722

Epoch 444: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0518 - MinusLogProbMetric: 5.0518 - val_loss: 5.1722 - val_MinusLogProbMetric: 5.1722 - lr: 2.5000e-04 - 69s/epoch - 351ms/step
Epoch 445/1000
2023-09-19 01:57:29.983 
Epoch 445/1000 
	 loss: 5.0529, MinusLogProbMetric: 5.0529, val_loss: 5.1556, val_MinusLogProbMetric: 5.1556

Epoch 445: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0529 - MinusLogProbMetric: 5.0529 - val_loss: 5.1556 - val_MinusLogProbMetric: 5.1556 - lr: 2.5000e-04 - 69s/epoch - 350ms/step
Epoch 446/1000
2023-09-19 01:58:37.383 
Epoch 446/1000 
	 loss: 5.0476, MinusLogProbMetric: 5.0476, val_loss: 5.1475, val_MinusLogProbMetric: 5.1475

Epoch 446: val_loss did not improve from 5.13386
196/196 - 67s - loss: 5.0476 - MinusLogProbMetric: 5.0476 - val_loss: 5.1475 - val_MinusLogProbMetric: 5.1475 - lr: 2.5000e-04 - 67s/epoch - 344ms/step
Epoch 447/1000
2023-09-19 01:59:38.608 
Epoch 447/1000 
	 loss: 5.0511, MinusLogProbMetric: 5.0511, val_loss: 5.1456, val_MinusLogProbMetric: 5.1456

Epoch 447: val_loss did not improve from 5.13386
196/196 - 61s - loss: 5.0511 - MinusLogProbMetric: 5.0511 - val_loss: 5.1456 - val_MinusLogProbMetric: 5.1456 - lr: 2.5000e-04 - 61s/epoch - 312ms/step
Epoch 448/1000
2023-09-19 02:00:38.409 
Epoch 448/1000 
	 loss: 5.0521, MinusLogProbMetric: 5.0521, val_loss: 5.1423, val_MinusLogProbMetric: 5.1423

Epoch 448: val_loss did not improve from 5.13386
196/196 - 60s - loss: 5.0521 - MinusLogProbMetric: 5.0521 - val_loss: 5.1423 - val_MinusLogProbMetric: 5.1423 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 449/1000
2023-09-19 02:01:38.623 
Epoch 449/1000 
	 loss: 5.0480, MinusLogProbMetric: 5.0480, val_loss: 5.1493, val_MinusLogProbMetric: 5.1493

Epoch 449: val_loss did not improve from 5.13386
196/196 - 60s - loss: 5.0480 - MinusLogProbMetric: 5.0480 - val_loss: 5.1493 - val_MinusLogProbMetric: 5.1493 - lr: 2.5000e-04 - 60s/epoch - 307ms/step
Epoch 450/1000
2023-09-19 02:02:39.961 
Epoch 450/1000 
	 loss: 5.0552, MinusLogProbMetric: 5.0552, val_loss: 5.1481, val_MinusLogProbMetric: 5.1481

Epoch 450: val_loss did not improve from 5.13386
196/196 - 61s - loss: 5.0552 - MinusLogProbMetric: 5.0552 - val_loss: 5.1481 - val_MinusLogProbMetric: 5.1481 - lr: 2.5000e-04 - 61s/epoch - 313ms/step
Epoch 451/1000
2023-09-19 02:03:47.451 
Epoch 451/1000 
	 loss: 5.0524, MinusLogProbMetric: 5.0524, val_loss: 5.1485, val_MinusLogProbMetric: 5.1485

Epoch 451: val_loss did not improve from 5.13386
196/196 - 67s - loss: 5.0524 - MinusLogProbMetric: 5.0524 - val_loss: 5.1485 - val_MinusLogProbMetric: 5.1485 - lr: 2.5000e-04 - 67s/epoch - 344ms/step
Epoch 452/1000
2023-09-19 02:04:56.072 
Epoch 452/1000 
	 loss: 5.0499, MinusLogProbMetric: 5.0499, val_loss: 5.1634, val_MinusLogProbMetric: 5.1634

Epoch 452: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0499 - MinusLogProbMetric: 5.0499 - val_loss: 5.1634 - val_MinusLogProbMetric: 5.1634 - lr: 2.5000e-04 - 69s/epoch - 350ms/step
Epoch 453/1000
2023-09-19 02:06:04.472 
Epoch 453/1000 
	 loss: 5.0530, MinusLogProbMetric: 5.0530, val_loss: 5.1598, val_MinusLogProbMetric: 5.1598

Epoch 453: val_loss did not improve from 5.13386
196/196 - 68s - loss: 5.0530 - MinusLogProbMetric: 5.0530 - val_loss: 5.1598 - val_MinusLogProbMetric: 5.1598 - lr: 2.5000e-04 - 68s/epoch - 349ms/step
Epoch 454/1000
2023-09-19 02:07:13.307 
Epoch 454/1000 
	 loss: 5.0493, MinusLogProbMetric: 5.0493, val_loss: 5.1616, val_MinusLogProbMetric: 5.1616

Epoch 454: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0493 - MinusLogProbMetric: 5.0493 - val_loss: 5.1616 - val_MinusLogProbMetric: 5.1616 - lr: 2.5000e-04 - 69s/epoch - 351ms/step
Epoch 455/1000
2023-09-19 02:08:21.519 
Epoch 455/1000 
	 loss: 5.0523, MinusLogProbMetric: 5.0523, val_loss: 5.1731, val_MinusLogProbMetric: 5.1731

Epoch 455: val_loss did not improve from 5.13386
196/196 - 68s - loss: 5.0523 - MinusLogProbMetric: 5.0523 - val_loss: 5.1731 - val_MinusLogProbMetric: 5.1731 - lr: 2.5000e-04 - 68s/epoch - 348ms/step
Epoch 456/1000
2023-09-19 02:09:30.154 
Epoch 456/1000 
	 loss: 5.0512, MinusLogProbMetric: 5.0512, val_loss: 5.1423, val_MinusLogProbMetric: 5.1423

Epoch 456: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0512 - MinusLogProbMetric: 5.0512 - val_loss: 5.1423 - val_MinusLogProbMetric: 5.1423 - lr: 2.5000e-04 - 69s/epoch - 350ms/step
Epoch 457/1000
2023-09-19 02:10:38.654 
Epoch 457/1000 
	 loss: 5.0497, MinusLogProbMetric: 5.0497, val_loss: 5.1512, val_MinusLogProbMetric: 5.1512

Epoch 457: val_loss did not improve from 5.13386
196/196 - 68s - loss: 5.0497 - MinusLogProbMetric: 5.0497 - val_loss: 5.1512 - val_MinusLogProbMetric: 5.1512 - lr: 2.5000e-04 - 68s/epoch - 349ms/step
Epoch 458/1000
2023-09-19 02:11:47.176 
Epoch 458/1000 
	 loss: 5.0497, MinusLogProbMetric: 5.0497, val_loss: 5.1550, val_MinusLogProbMetric: 5.1550

Epoch 458: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0497 - MinusLogProbMetric: 5.0497 - val_loss: 5.1550 - val_MinusLogProbMetric: 5.1550 - lr: 2.5000e-04 - 69s/epoch - 350ms/step
Epoch 459/1000
2023-09-19 02:12:55.664 
Epoch 459/1000 
	 loss: 5.0496, MinusLogProbMetric: 5.0496, val_loss: 5.1405, val_MinusLogProbMetric: 5.1405

Epoch 459: val_loss did not improve from 5.13386
196/196 - 68s - loss: 5.0496 - MinusLogProbMetric: 5.0496 - val_loss: 5.1405 - val_MinusLogProbMetric: 5.1405 - lr: 2.5000e-04 - 68s/epoch - 349ms/step
Epoch 460/1000
2023-09-19 02:14:05.017 
Epoch 460/1000 
	 loss: 5.0502, MinusLogProbMetric: 5.0502, val_loss: 5.1446, val_MinusLogProbMetric: 5.1446

Epoch 460: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0502 - MinusLogProbMetric: 5.0502 - val_loss: 5.1446 - val_MinusLogProbMetric: 5.1446 - lr: 2.5000e-04 - 69s/epoch - 354ms/step
Epoch 461/1000
2023-09-19 02:15:13.651 
Epoch 461/1000 
	 loss: 5.0500, MinusLogProbMetric: 5.0500, val_loss: 5.1677, val_MinusLogProbMetric: 5.1677

Epoch 461: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0500 - MinusLogProbMetric: 5.0500 - val_loss: 5.1677 - val_MinusLogProbMetric: 5.1677 - lr: 2.5000e-04 - 69s/epoch - 350ms/step
Epoch 462/1000
2023-09-19 02:16:22.291 
Epoch 462/1000 
	 loss: 5.0487, MinusLogProbMetric: 5.0487, val_loss: 5.1455, val_MinusLogProbMetric: 5.1455

Epoch 462: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0487 - MinusLogProbMetric: 5.0487 - val_loss: 5.1455 - val_MinusLogProbMetric: 5.1455 - lr: 2.5000e-04 - 69s/epoch - 350ms/step
Epoch 463/1000
2023-09-19 02:17:31.258 
Epoch 463/1000 
	 loss: 5.0490, MinusLogProbMetric: 5.0490, val_loss: 5.1395, val_MinusLogProbMetric: 5.1395

Epoch 463: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0490 - MinusLogProbMetric: 5.0490 - val_loss: 5.1395 - val_MinusLogProbMetric: 5.1395 - lr: 2.5000e-04 - 69s/epoch - 352ms/step
Epoch 464/1000
2023-09-19 02:18:39.750 
Epoch 464/1000 
	 loss: 5.0506, MinusLogProbMetric: 5.0506, val_loss: 5.1520, val_MinusLogProbMetric: 5.1520

Epoch 464: val_loss did not improve from 5.13386
196/196 - 68s - loss: 5.0506 - MinusLogProbMetric: 5.0506 - val_loss: 5.1520 - val_MinusLogProbMetric: 5.1520 - lr: 2.5000e-04 - 68s/epoch - 349ms/step
Epoch 465/1000
2023-09-19 02:19:49.070 
Epoch 465/1000 
	 loss: 5.0498, MinusLogProbMetric: 5.0498, val_loss: 5.1559, val_MinusLogProbMetric: 5.1559

Epoch 465: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0498 - MinusLogProbMetric: 5.0498 - val_loss: 5.1559 - val_MinusLogProbMetric: 5.1559 - lr: 2.5000e-04 - 69s/epoch - 354ms/step
Epoch 466/1000
2023-09-19 02:20:57.723 
Epoch 466/1000 
	 loss: 5.0502, MinusLogProbMetric: 5.0502, val_loss: 5.1418, val_MinusLogProbMetric: 5.1418

Epoch 466: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0502 - MinusLogProbMetric: 5.0502 - val_loss: 5.1418 - val_MinusLogProbMetric: 5.1418 - lr: 2.5000e-04 - 69s/epoch - 350ms/step
Epoch 467/1000
2023-09-19 02:22:06.818 
Epoch 467/1000 
	 loss: 5.0484, MinusLogProbMetric: 5.0484, val_loss: 5.1506, val_MinusLogProbMetric: 5.1506

Epoch 467: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0484 - MinusLogProbMetric: 5.0484 - val_loss: 5.1506 - val_MinusLogProbMetric: 5.1506 - lr: 2.5000e-04 - 69s/epoch - 352ms/step
Epoch 468/1000
2023-09-19 02:23:15.802 
Epoch 468/1000 
	 loss: 5.0501, MinusLogProbMetric: 5.0501, val_loss: 5.1460, val_MinusLogProbMetric: 5.1460

Epoch 468: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0501 - MinusLogProbMetric: 5.0501 - val_loss: 5.1460 - val_MinusLogProbMetric: 5.1460 - lr: 2.5000e-04 - 69s/epoch - 352ms/step
Epoch 469/1000
2023-09-19 02:24:24.310 
Epoch 469/1000 
	 loss: 5.0507, MinusLogProbMetric: 5.0507, val_loss: 5.1474, val_MinusLogProbMetric: 5.1474

Epoch 469: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0507 - MinusLogProbMetric: 5.0507 - val_loss: 5.1474 - val_MinusLogProbMetric: 5.1474 - lr: 2.5000e-04 - 69s/epoch - 350ms/step
Epoch 470/1000
2023-09-19 02:25:32.992 
Epoch 470/1000 
	 loss: 5.0500, MinusLogProbMetric: 5.0500, val_loss: 5.1440, val_MinusLogProbMetric: 5.1440

Epoch 470: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0500 - MinusLogProbMetric: 5.0500 - val_loss: 5.1440 - val_MinusLogProbMetric: 5.1440 - lr: 2.5000e-04 - 69s/epoch - 350ms/step
Epoch 471/1000
2023-09-19 02:26:41.253 
Epoch 471/1000 
	 loss: 5.0481, MinusLogProbMetric: 5.0481, val_loss: 5.1529, val_MinusLogProbMetric: 5.1529

Epoch 471: val_loss did not improve from 5.13386
196/196 - 68s - loss: 5.0481 - MinusLogProbMetric: 5.0481 - val_loss: 5.1529 - val_MinusLogProbMetric: 5.1529 - lr: 2.5000e-04 - 68s/epoch - 348ms/step
Epoch 472/1000
2023-09-19 02:27:49.991 
Epoch 472/1000 
	 loss: 5.0512, MinusLogProbMetric: 5.0512, val_loss: 5.1427, val_MinusLogProbMetric: 5.1427

Epoch 472: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0512 - MinusLogProbMetric: 5.0512 - val_loss: 5.1427 - val_MinusLogProbMetric: 5.1427 - lr: 2.5000e-04 - 69s/epoch - 351ms/step
Epoch 473/1000
2023-09-19 02:28:58.769 
Epoch 473/1000 
	 loss: 5.0497, MinusLogProbMetric: 5.0497, val_loss: 5.1571, val_MinusLogProbMetric: 5.1571

Epoch 473: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0497 - MinusLogProbMetric: 5.0497 - val_loss: 5.1571 - val_MinusLogProbMetric: 5.1571 - lr: 2.5000e-04 - 69s/epoch - 351ms/step
Epoch 474/1000
2023-09-19 02:30:07.127 
Epoch 474/1000 
	 loss: 5.0494, MinusLogProbMetric: 5.0494, val_loss: 5.1492, val_MinusLogProbMetric: 5.1492

Epoch 474: val_loss did not improve from 5.13386
196/196 - 68s - loss: 5.0494 - MinusLogProbMetric: 5.0494 - val_loss: 5.1492 - val_MinusLogProbMetric: 5.1492 - lr: 2.5000e-04 - 68s/epoch - 349ms/step
Epoch 475/1000
2023-09-19 02:31:13.455 
Epoch 475/1000 
	 loss: 5.0503, MinusLogProbMetric: 5.0503, val_loss: 5.1555, val_MinusLogProbMetric: 5.1555

Epoch 475: val_loss did not improve from 5.13386
196/196 - 66s - loss: 5.0503 - MinusLogProbMetric: 5.0503 - val_loss: 5.1555 - val_MinusLogProbMetric: 5.1555 - lr: 2.5000e-04 - 66s/epoch - 338ms/step
Epoch 476/1000
2023-09-19 02:32:13.927 
Epoch 476/1000 
	 loss: 5.0495, MinusLogProbMetric: 5.0495, val_loss: 5.1653, val_MinusLogProbMetric: 5.1653

Epoch 476: val_loss did not improve from 5.13386
196/196 - 60s - loss: 5.0495 - MinusLogProbMetric: 5.0495 - val_loss: 5.1653 - val_MinusLogProbMetric: 5.1653 - lr: 2.5000e-04 - 60s/epoch - 309ms/step
Epoch 477/1000
2023-09-19 02:33:20.412 
Epoch 477/1000 
	 loss: 5.0529, MinusLogProbMetric: 5.0529, val_loss: 5.1511, val_MinusLogProbMetric: 5.1511

Epoch 477: val_loss did not improve from 5.13386
196/196 - 66s - loss: 5.0529 - MinusLogProbMetric: 5.0529 - val_loss: 5.1511 - val_MinusLogProbMetric: 5.1511 - lr: 2.5000e-04 - 66s/epoch - 339ms/step
Epoch 478/1000
2023-09-19 02:34:16.130 
Epoch 478/1000 
	 loss: 5.0517, MinusLogProbMetric: 5.0517, val_loss: 5.1403, val_MinusLogProbMetric: 5.1403

Epoch 478: val_loss did not improve from 5.13386
196/196 - 56s - loss: 5.0517 - MinusLogProbMetric: 5.0517 - val_loss: 5.1403 - val_MinusLogProbMetric: 5.1403 - lr: 2.5000e-04 - 56s/epoch - 284ms/step
Epoch 479/1000
2023-09-19 02:35:22.015 
Epoch 479/1000 
	 loss: 5.0491, MinusLogProbMetric: 5.0491, val_loss: 5.1487, val_MinusLogProbMetric: 5.1487

Epoch 479: val_loss did not improve from 5.13386
196/196 - 66s - loss: 5.0491 - MinusLogProbMetric: 5.0491 - val_loss: 5.1487 - val_MinusLogProbMetric: 5.1487 - lr: 2.5000e-04 - 66s/epoch - 336ms/step
Epoch 480/1000
2023-09-19 02:36:29.964 
Epoch 480/1000 
	 loss: 5.0489, MinusLogProbMetric: 5.0489, val_loss: 5.1459, val_MinusLogProbMetric: 5.1459

Epoch 480: val_loss did not improve from 5.13386
196/196 - 68s - loss: 5.0489 - MinusLogProbMetric: 5.0489 - val_loss: 5.1459 - val_MinusLogProbMetric: 5.1459 - lr: 2.5000e-04 - 68s/epoch - 347ms/step
Epoch 481/1000
2023-09-19 02:37:38.557 
Epoch 481/1000 
	 loss: 5.0501, MinusLogProbMetric: 5.0501, val_loss: 5.1534, val_MinusLogProbMetric: 5.1534

Epoch 481: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0501 - MinusLogProbMetric: 5.0501 - val_loss: 5.1534 - val_MinusLogProbMetric: 5.1534 - lr: 2.5000e-04 - 69s/epoch - 350ms/step
Epoch 482/1000
2023-09-19 02:38:47.378 
Epoch 482/1000 
	 loss: 5.0495, MinusLogProbMetric: 5.0495, val_loss: 5.1425, val_MinusLogProbMetric: 5.1425

Epoch 482: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0495 - MinusLogProbMetric: 5.0495 - val_loss: 5.1425 - val_MinusLogProbMetric: 5.1425 - lr: 2.5000e-04 - 69s/epoch - 351ms/step
Epoch 483/1000
2023-09-19 02:39:55.875 
Epoch 483/1000 
	 loss: 5.0489, MinusLogProbMetric: 5.0489, val_loss: 5.1387, val_MinusLogProbMetric: 5.1387

Epoch 483: val_loss did not improve from 5.13386
196/196 - 68s - loss: 5.0489 - MinusLogProbMetric: 5.0489 - val_loss: 5.1387 - val_MinusLogProbMetric: 5.1387 - lr: 2.5000e-04 - 68s/epoch - 349ms/step
Epoch 484/1000
2023-09-19 02:41:04.410 
Epoch 484/1000 
	 loss: 5.0506, MinusLogProbMetric: 5.0506, val_loss: 5.1506, val_MinusLogProbMetric: 5.1506

Epoch 484: val_loss did not improve from 5.13386
196/196 - 69s - loss: 5.0506 - MinusLogProbMetric: 5.0506 - val_loss: 5.1506 - val_MinusLogProbMetric: 5.1506 - lr: 2.5000e-04 - 69s/epoch - 350ms/step
Epoch 485/1000
2023-09-19 02:42:12.932 
Epoch 485/1000 
	 loss: 5.0356, MinusLogProbMetric: 5.0356, val_loss: 5.1336, val_MinusLogProbMetric: 5.1336

Epoch 485: val_loss improved from 5.13386 to 5.13357, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0356 - MinusLogProbMetric: 5.0356 - val_loss: 5.1336 - val_MinusLogProbMetric: 5.1336 - lr: 1.2500e-04 - 70s/epoch - 356ms/step
Epoch 486/1000
2023-09-19 02:43:23.158 
Epoch 486/1000 
	 loss: 5.0348, MinusLogProbMetric: 5.0348, val_loss: 5.1413, val_MinusLogProbMetric: 5.1413

Epoch 486: val_loss did not improve from 5.13357
196/196 - 69s - loss: 5.0348 - MinusLogProbMetric: 5.0348 - val_loss: 5.1413 - val_MinusLogProbMetric: 5.1413 - lr: 1.2500e-04 - 69s/epoch - 352ms/step
Epoch 487/1000
2023-09-19 02:44:31.548 
Epoch 487/1000 
	 loss: 5.0342, MinusLogProbMetric: 5.0342, val_loss: 5.1312, val_MinusLogProbMetric: 5.1312

Epoch 487: val_loss improved from 5.13357 to 5.13125, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0342 - MinusLogProbMetric: 5.0342 - val_loss: 5.1312 - val_MinusLogProbMetric: 5.1312 - lr: 1.2500e-04 - 70s/epoch - 355ms/step
Epoch 488/1000
2023-09-19 02:45:40.937 
Epoch 488/1000 
	 loss: 5.0349, MinusLogProbMetric: 5.0349, val_loss: 5.1332, val_MinusLogProbMetric: 5.1332

Epoch 488: val_loss did not improve from 5.13125
196/196 - 68s - loss: 5.0349 - MinusLogProbMetric: 5.0349 - val_loss: 5.1332 - val_MinusLogProbMetric: 5.1332 - lr: 1.2500e-04 - 68s/epoch - 348ms/step
Epoch 489/1000
2023-09-19 02:46:49.337 
Epoch 489/1000 
	 loss: 5.0326, MinusLogProbMetric: 5.0326, val_loss: 5.1333, val_MinusLogProbMetric: 5.1333

Epoch 489: val_loss did not improve from 5.13125
196/196 - 68s - loss: 5.0326 - MinusLogProbMetric: 5.0326 - val_loss: 5.1333 - val_MinusLogProbMetric: 5.1333 - lr: 1.2500e-04 - 68s/epoch - 349ms/step
Epoch 490/1000
2023-09-19 02:47:57.166 
Epoch 490/1000 
	 loss: 5.0334, MinusLogProbMetric: 5.0334, val_loss: 5.1320, val_MinusLogProbMetric: 5.1320

Epoch 490: val_loss did not improve from 5.13125
196/196 - 68s - loss: 5.0334 - MinusLogProbMetric: 5.0334 - val_loss: 5.1320 - val_MinusLogProbMetric: 5.1320 - lr: 1.2500e-04 - 68s/epoch - 346ms/step
Epoch 491/1000
2023-09-19 02:49:05.753 
Epoch 491/1000 
	 loss: 5.0335, MinusLogProbMetric: 5.0335, val_loss: 5.1301, val_MinusLogProbMetric: 5.1301

Epoch 491: val_loss improved from 5.13125 to 5.13006, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0335 - MinusLogProbMetric: 5.0335 - val_loss: 5.1301 - val_MinusLogProbMetric: 5.1301 - lr: 1.2500e-04 - 70s/epoch - 356ms/step
Epoch 492/1000
2023-09-19 02:50:15.612 
Epoch 492/1000 
	 loss: 5.0349, MinusLogProbMetric: 5.0349, val_loss: 5.1355, val_MinusLogProbMetric: 5.1355

Epoch 492: val_loss did not improve from 5.13006
196/196 - 69s - loss: 5.0349 - MinusLogProbMetric: 5.0349 - val_loss: 5.1355 - val_MinusLogProbMetric: 5.1355 - lr: 1.2500e-04 - 69s/epoch - 350ms/step
Epoch 493/1000
2023-09-19 02:51:23.889 
Epoch 493/1000 
	 loss: 5.0348, MinusLogProbMetric: 5.0348, val_loss: 5.1369, val_MinusLogProbMetric: 5.1369

Epoch 493: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0348 - MinusLogProbMetric: 5.0348 - val_loss: 5.1369 - val_MinusLogProbMetric: 5.1369 - lr: 1.2500e-04 - 68s/epoch - 348ms/step
Epoch 494/1000
2023-09-19 02:52:32.263 
Epoch 494/1000 
	 loss: 5.0341, MinusLogProbMetric: 5.0341, val_loss: 5.1358, val_MinusLogProbMetric: 5.1358

Epoch 494: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0341 - MinusLogProbMetric: 5.0341 - val_loss: 5.1358 - val_MinusLogProbMetric: 5.1358 - lr: 1.2500e-04 - 68s/epoch - 349ms/step
Epoch 495/1000
2023-09-19 02:53:41.077 
Epoch 495/1000 
	 loss: 5.0373, MinusLogProbMetric: 5.0373, val_loss: 5.1319, val_MinusLogProbMetric: 5.1319

Epoch 495: val_loss did not improve from 5.13006
196/196 - 69s - loss: 5.0373 - MinusLogProbMetric: 5.0373 - val_loss: 5.1319 - val_MinusLogProbMetric: 5.1319 - lr: 1.2500e-04 - 69s/epoch - 351ms/step
Epoch 496/1000
2023-09-19 02:54:49.337 
Epoch 496/1000 
	 loss: 5.0338, MinusLogProbMetric: 5.0338, val_loss: 5.1343, val_MinusLogProbMetric: 5.1343

Epoch 496: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0338 - MinusLogProbMetric: 5.0338 - val_loss: 5.1343 - val_MinusLogProbMetric: 5.1343 - lr: 1.2500e-04 - 68s/epoch - 348ms/step
Epoch 497/1000
2023-09-19 02:55:57.816 
Epoch 497/1000 
	 loss: 5.0343, MinusLogProbMetric: 5.0343, val_loss: 5.1330, val_MinusLogProbMetric: 5.1330

Epoch 497: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0343 - MinusLogProbMetric: 5.0343 - val_loss: 5.1330 - val_MinusLogProbMetric: 5.1330 - lr: 1.2500e-04 - 68s/epoch - 349ms/step
Epoch 498/1000
2023-09-19 02:57:03.537 
Epoch 498/1000 
	 loss: 5.0340, MinusLogProbMetric: 5.0340, val_loss: 5.1393, val_MinusLogProbMetric: 5.1393

Epoch 498: val_loss did not improve from 5.13006
196/196 - 66s - loss: 5.0340 - MinusLogProbMetric: 5.0340 - val_loss: 5.1393 - val_MinusLogProbMetric: 5.1393 - lr: 1.2500e-04 - 66s/epoch - 335ms/step
Epoch 499/1000
2023-09-19 02:58:02.548 
Epoch 499/1000 
	 loss: 5.0340, MinusLogProbMetric: 5.0340, val_loss: 5.1356, val_MinusLogProbMetric: 5.1356

Epoch 499: val_loss did not improve from 5.13006
196/196 - 59s - loss: 5.0340 - MinusLogProbMetric: 5.0340 - val_loss: 5.1356 - val_MinusLogProbMetric: 5.1356 - lr: 1.2500e-04 - 59s/epoch - 301ms/step
Epoch 500/1000
2023-09-19 02:58:56.906 
Epoch 500/1000 
	 loss: 5.0337, MinusLogProbMetric: 5.0337, val_loss: 5.1347, val_MinusLogProbMetric: 5.1347

Epoch 500: val_loss did not improve from 5.13006
196/196 - 54s - loss: 5.0337 - MinusLogProbMetric: 5.0337 - val_loss: 5.1347 - val_MinusLogProbMetric: 5.1347 - lr: 1.2500e-04 - 54s/epoch - 277ms/step
Epoch 501/1000
2023-09-19 03:00:01.338 
Epoch 501/1000 
	 loss: 5.0330, MinusLogProbMetric: 5.0330, val_loss: 5.1304, val_MinusLogProbMetric: 5.1304

Epoch 501: val_loss did not improve from 5.13006
196/196 - 64s - loss: 5.0330 - MinusLogProbMetric: 5.0330 - val_loss: 5.1304 - val_MinusLogProbMetric: 5.1304 - lr: 1.2500e-04 - 64s/epoch - 329ms/step
Epoch 502/1000
2023-09-19 03:01:09.037 
Epoch 502/1000 
	 loss: 5.0341, MinusLogProbMetric: 5.0341, val_loss: 5.1343, val_MinusLogProbMetric: 5.1343

Epoch 502: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0341 - MinusLogProbMetric: 5.0341 - val_loss: 5.1343 - val_MinusLogProbMetric: 5.1343 - lr: 1.2500e-04 - 68s/epoch - 345ms/step
Epoch 503/1000
2023-09-19 03:02:15.616 
Epoch 503/1000 
	 loss: 5.0351, MinusLogProbMetric: 5.0351, val_loss: 5.1378, val_MinusLogProbMetric: 5.1378

Epoch 503: val_loss did not improve from 5.13006
196/196 - 67s - loss: 5.0351 - MinusLogProbMetric: 5.0351 - val_loss: 5.1378 - val_MinusLogProbMetric: 5.1378 - lr: 1.2500e-04 - 67s/epoch - 340ms/step
Epoch 504/1000
2023-09-19 03:03:23.190 
Epoch 504/1000 
	 loss: 5.0344, MinusLogProbMetric: 5.0344, val_loss: 5.1349, val_MinusLogProbMetric: 5.1349

Epoch 504: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0344 - MinusLogProbMetric: 5.0344 - val_loss: 5.1349 - val_MinusLogProbMetric: 5.1349 - lr: 1.2500e-04 - 68s/epoch - 345ms/step
Epoch 505/1000
2023-09-19 03:04:30.830 
Epoch 505/1000 
	 loss: 5.0344, MinusLogProbMetric: 5.0344, val_loss: 5.1357, val_MinusLogProbMetric: 5.1357

Epoch 505: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0344 - MinusLogProbMetric: 5.0344 - val_loss: 5.1357 - val_MinusLogProbMetric: 5.1357 - lr: 1.2500e-04 - 68s/epoch - 345ms/step
Epoch 506/1000
2023-09-19 03:05:38.481 
Epoch 506/1000 
	 loss: 5.0364, MinusLogProbMetric: 5.0364, val_loss: 5.1368, val_MinusLogProbMetric: 5.1368

Epoch 506: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0364 - MinusLogProbMetric: 5.0364 - val_loss: 5.1368 - val_MinusLogProbMetric: 5.1368 - lr: 1.2500e-04 - 68s/epoch - 345ms/step
Epoch 507/1000
2023-09-19 03:06:46.928 
Epoch 507/1000 
	 loss: 5.0346, MinusLogProbMetric: 5.0346, val_loss: 5.1360, val_MinusLogProbMetric: 5.1360

Epoch 507: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0346 - MinusLogProbMetric: 5.0346 - val_loss: 5.1360 - val_MinusLogProbMetric: 5.1360 - lr: 1.2500e-04 - 68s/epoch - 349ms/step
Epoch 508/1000
2023-09-19 03:07:54.922 
Epoch 508/1000 
	 loss: 5.0352, MinusLogProbMetric: 5.0352, val_loss: 5.1478, val_MinusLogProbMetric: 5.1478

Epoch 508: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0352 - MinusLogProbMetric: 5.0352 - val_loss: 5.1478 - val_MinusLogProbMetric: 5.1478 - lr: 1.2500e-04 - 68s/epoch - 347ms/step
Epoch 509/1000
2023-09-19 03:09:03.670 
Epoch 509/1000 
	 loss: 5.0345, MinusLogProbMetric: 5.0345, val_loss: 5.1412, val_MinusLogProbMetric: 5.1412

Epoch 509: val_loss did not improve from 5.13006
196/196 - 69s - loss: 5.0345 - MinusLogProbMetric: 5.0345 - val_loss: 5.1412 - val_MinusLogProbMetric: 5.1412 - lr: 1.2500e-04 - 69s/epoch - 351ms/step
Epoch 510/1000
2023-09-19 03:10:11.695 
Epoch 510/1000 
	 loss: 5.0346, MinusLogProbMetric: 5.0346, val_loss: 5.1352, val_MinusLogProbMetric: 5.1352

Epoch 510: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0346 - MinusLogProbMetric: 5.0346 - val_loss: 5.1352 - val_MinusLogProbMetric: 5.1352 - lr: 1.2500e-04 - 68s/epoch - 347ms/step
Epoch 511/1000
2023-09-19 03:11:20.262 
Epoch 511/1000 
	 loss: 5.0339, MinusLogProbMetric: 5.0339, val_loss: 5.1375, val_MinusLogProbMetric: 5.1375

Epoch 511: val_loss did not improve from 5.13006
196/196 - 69s - loss: 5.0339 - MinusLogProbMetric: 5.0339 - val_loss: 5.1375 - val_MinusLogProbMetric: 5.1375 - lr: 1.2500e-04 - 69s/epoch - 350ms/step
Epoch 512/1000
2023-09-19 03:12:28.153 
Epoch 512/1000 
	 loss: 5.0339, MinusLogProbMetric: 5.0339, val_loss: 5.1383, val_MinusLogProbMetric: 5.1383

Epoch 512: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0339 - MinusLogProbMetric: 5.0339 - val_loss: 5.1383 - val_MinusLogProbMetric: 5.1383 - lr: 1.2500e-04 - 68s/epoch - 346ms/step
Epoch 513/1000
2023-09-19 03:13:36.262 
Epoch 513/1000 
	 loss: 5.0353, MinusLogProbMetric: 5.0353, val_loss: 5.1394, val_MinusLogProbMetric: 5.1394

Epoch 513: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0353 - MinusLogProbMetric: 5.0353 - val_loss: 5.1394 - val_MinusLogProbMetric: 5.1394 - lr: 1.2500e-04 - 68s/epoch - 347ms/step
Epoch 514/1000
2023-09-19 03:14:44.808 
Epoch 514/1000 
	 loss: 5.0343, MinusLogProbMetric: 5.0343, val_loss: 5.1312, val_MinusLogProbMetric: 5.1312

Epoch 514: val_loss did not improve from 5.13006
196/196 - 69s - loss: 5.0343 - MinusLogProbMetric: 5.0343 - val_loss: 5.1312 - val_MinusLogProbMetric: 5.1312 - lr: 1.2500e-04 - 69s/epoch - 350ms/step
Epoch 515/1000
2023-09-19 03:15:52.933 
Epoch 515/1000 
	 loss: 5.0333, MinusLogProbMetric: 5.0333, val_loss: 5.1365, val_MinusLogProbMetric: 5.1365

Epoch 515: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0333 - MinusLogProbMetric: 5.0333 - val_loss: 5.1365 - val_MinusLogProbMetric: 5.1365 - lr: 1.2500e-04 - 68s/epoch - 348ms/step
Epoch 516/1000
2023-09-19 03:17:01.411 
Epoch 516/1000 
	 loss: 5.0363, MinusLogProbMetric: 5.0363, val_loss: 5.1392, val_MinusLogProbMetric: 5.1392

Epoch 516: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0363 - MinusLogProbMetric: 5.0363 - val_loss: 5.1392 - val_MinusLogProbMetric: 5.1392 - lr: 1.2500e-04 - 68s/epoch - 349ms/step
Epoch 517/1000
2023-09-19 03:18:09.395 
Epoch 517/1000 
	 loss: 5.0343, MinusLogProbMetric: 5.0343, val_loss: 5.1347, val_MinusLogProbMetric: 5.1347

Epoch 517: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0343 - MinusLogProbMetric: 5.0343 - val_loss: 5.1347 - val_MinusLogProbMetric: 5.1347 - lr: 1.2500e-04 - 68s/epoch - 347ms/step
Epoch 518/1000
2023-09-19 03:19:17.227 
Epoch 518/1000 
	 loss: 5.0330, MinusLogProbMetric: 5.0330, val_loss: 5.1396, val_MinusLogProbMetric: 5.1396

Epoch 518: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0330 - MinusLogProbMetric: 5.0330 - val_loss: 5.1396 - val_MinusLogProbMetric: 5.1396 - lr: 1.2500e-04 - 68s/epoch - 346ms/step
Epoch 519/1000
2023-09-19 03:20:25.107 
Epoch 519/1000 
	 loss: 5.0345, MinusLogProbMetric: 5.0345, val_loss: 5.1374, val_MinusLogProbMetric: 5.1374

Epoch 519: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0345 - MinusLogProbMetric: 5.0345 - val_loss: 5.1374 - val_MinusLogProbMetric: 5.1374 - lr: 1.2500e-04 - 68s/epoch - 346ms/step
Epoch 520/1000
2023-09-19 03:21:33.613 
Epoch 520/1000 
	 loss: 5.0337, MinusLogProbMetric: 5.0337, val_loss: 5.1457, val_MinusLogProbMetric: 5.1457

Epoch 520: val_loss did not improve from 5.13006
196/196 - 69s - loss: 5.0337 - MinusLogProbMetric: 5.0337 - val_loss: 5.1457 - val_MinusLogProbMetric: 5.1457 - lr: 1.2500e-04 - 69s/epoch - 349ms/step
Epoch 521/1000
2023-09-19 03:22:41.371 
Epoch 521/1000 
	 loss: 5.0341, MinusLogProbMetric: 5.0341, val_loss: 5.1341, val_MinusLogProbMetric: 5.1341

Epoch 521: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0341 - MinusLogProbMetric: 5.0341 - val_loss: 5.1341 - val_MinusLogProbMetric: 5.1341 - lr: 1.2500e-04 - 68s/epoch - 346ms/step
Epoch 522/1000
2023-09-19 03:23:49.899 
Epoch 522/1000 
	 loss: 5.0338, MinusLogProbMetric: 5.0338, val_loss: 5.1366, val_MinusLogProbMetric: 5.1366

Epoch 522: val_loss did not improve from 5.13006
196/196 - 69s - loss: 5.0338 - MinusLogProbMetric: 5.0338 - val_loss: 5.1366 - val_MinusLogProbMetric: 5.1366 - lr: 1.2500e-04 - 69s/epoch - 350ms/step
Epoch 523/1000
2023-09-19 03:24:58.244 
Epoch 523/1000 
	 loss: 5.0338, MinusLogProbMetric: 5.0338, val_loss: 5.1344, val_MinusLogProbMetric: 5.1344

Epoch 523: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0338 - MinusLogProbMetric: 5.0338 - val_loss: 5.1344 - val_MinusLogProbMetric: 5.1344 - lr: 1.2500e-04 - 68s/epoch - 349ms/step
Epoch 524/1000
2023-09-19 03:26:02.714 
Epoch 524/1000 
	 loss: 5.0332, MinusLogProbMetric: 5.0332, val_loss: 5.1388, val_MinusLogProbMetric: 5.1388

Epoch 524: val_loss did not improve from 5.13006
196/196 - 64s - loss: 5.0332 - MinusLogProbMetric: 5.0332 - val_loss: 5.1388 - val_MinusLogProbMetric: 5.1388 - lr: 1.2500e-04 - 64s/epoch - 329ms/step
Epoch 525/1000
2023-09-19 03:26:58.104 
Epoch 525/1000 
	 loss: 5.0337, MinusLogProbMetric: 5.0337, val_loss: 5.1349, val_MinusLogProbMetric: 5.1349

Epoch 525: val_loss did not improve from 5.13006
196/196 - 55s - loss: 5.0337 - MinusLogProbMetric: 5.0337 - val_loss: 5.1349 - val_MinusLogProbMetric: 5.1349 - lr: 1.2500e-04 - 55s/epoch - 283ms/step
Epoch 526/1000
2023-09-19 03:27:53.694 
Epoch 526/1000 
	 loss: 5.0341, MinusLogProbMetric: 5.0341, val_loss: 5.1352, val_MinusLogProbMetric: 5.1352

Epoch 526: val_loss did not improve from 5.13006
196/196 - 56s - loss: 5.0341 - MinusLogProbMetric: 5.0341 - val_loss: 5.1352 - val_MinusLogProbMetric: 5.1352 - lr: 1.2500e-04 - 56s/epoch - 284ms/step
Epoch 527/1000
2023-09-19 03:29:03.171 
Epoch 527/1000 
	 loss: 5.0331, MinusLogProbMetric: 5.0331, val_loss: 5.1329, val_MinusLogProbMetric: 5.1329

Epoch 527: val_loss did not improve from 5.13006
196/196 - 69s - loss: 5.0331 - MinusLogProbMetric: 5.0331 - val_loss: 5.1329 - val_MinusLogProbMetric: 5.1329 - lr: 1.2500e-04 - 69s/epoch - 354ms/step
Epoch 528/1000
2023-09-19 03:30:10.257 
Epoch 528/1000 
	 loss: 5.0338, MinusLogProbMetric: 5.0338, val_loss: 5.1364, val_MinusLogProbMetric: 5.1364

Epoch 528: val_loss did not improve from 5.13006
196/196 - 67s - loss: 5.0338 - MinusLogProbMetric: 5.0338 - val_loss: 5.1364 - val_MinusLogProbMetric: 5.1364 - lr: 1.2500e-04 - 67s/epoch - 342ms/step
Epoch 529/1000
2023-09-19 03:31:18.657 
Epoch 529/1000 
	 loss: 5.0328, MinusLogProbMetric: 5.0328, val_loss: 5.1353, val_MinusLogProbMetric: 5.1353

Epoch 529: val_loss did not improve from 5.13006
196/196 - 68s - loss: 5.0328 - MinusLogProbMetric: 5.0328 - val_loss: 5.1353 - val_MinusLogProbMetric: 5.1353 - lr: 1.2500e-04 - 68s/epoch - 349ms/step
Epoch 530/1000
2023-09-19 03:32:27.169 
Epoch 530/1000 
	 loss: 5.0319, MinusLogProbMetric: 5.0319, val_loss: 5.1298, val_MinusLogProbMetric: 5.1298

Epoch 530: val_loss improved from 5.13006 to 5.12981, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0319 - MinusLogProbMetric: 5.0319 - val_loss: 5.1298 - val_MinusLogProbMetric: 5.1298 - lr: 1.2500e-04 - 70s/epoch - 356ms/step
Epoch 531/1000
2023-09-19 03:33:36.449 
Epoch 531/1000 
	 loss: 5.0334, MinusLogProbMetric: 5.0334, val_loss: 5.1336, val_MinusLogProbMetric: 5.1336

Epoch 531: val_loss did not improve from 5.12981
196/196 - 68s - loss: 5.0334 - MinusLogProbMetric: 5.0334 - val_loss: 5.1336 - val_MinusLogProbMetric: 5.1336 - lr: 1.2500e-04 - 68s/epoch - 347ms/step
Epoch 532/1000
2023-09-19 03:34:44.798 
Epoch 532/1000 
	 loss: 5.0319, MinusLogProbMetric: 5.0319, val_loss: 5.1333, val_MinusLogProbMetric: 5.1333

Epoch 532: val_loss did not improve from 5.12981
196/196 - 68s - loss: 5.0319 - MinusLogProbMetric: 5.0319 - val_loss: 5.1333 - val_MinusLogProbMetric: 5.1333 - lr: 1.2500e-04 - 68s/epoch - 349ms/step
Epoch 533/1000
2023-09-19 03:35:52.125 
Epoch 533/1000 
	 loss: 5.0335, MinusLogProbMetric: 5.0335, val_loss: 5.1304, val_MinusLogProbMetric: 5.1304

Epoch 533: val_loss did not improve from 5.12981
196/196 - 67s - loss: 5.0335 - MinusLogProbMetric: 5.0335 - val_loss: 5.1304 - val_MinusLogProbMetric: 5.1304 - lr: 1.2500e-04 - 67s/epoch - 343ms/step
Epoch 534/1000
2023-09-19 03:37:00.167 
Epoch 534/1000 
	 loss: 5.0334, MinusLogProbMetric: 5.0334, val_loss: 5.1329, val_MinusLogProbMetric: 5.1329

Epoch 534: val_loss did not improve from 5.12981
196/196 - 68s - loss: 5.0334 - MinusLogProbMetric: 5.0334 - val_loss: 5.1329 - val_MinusLogProbMetric: 5.1329 - lr: 1.2500e-04 - 68s/epoch - 347ms/step
Epoch 535/1000
2023-09-19 03:38:08.378 
Epoch 535/1000 
	 loss: 5.0341, MinusLogProbMetric: 5.0341, val_loss: 5.1415, val_MinusLogProbMetric: 5.1415

Epoch 535: val_loss did not improve from 5.12981
196/196 - 68s - loss: 5.0341 - MinusLogProbMetric: 5.0341 - val_loss: 5.1415 - val_MinusLogProbMetric: 5.1415 - lr: 1.2500e-04 - 68s/epoch - 348ms/step
Epoch 536/1000
2023-09-19 03:39:16.325 
Epoch 536/1000 
	 loss: 5.0337, MinusLogProbMetric: 5.0337, val_loss: 5.1326, val_MinusLogProbMetric: 5.1326

Epoch 536: val_loss did not improve from 5.12981
196/196 - 68s - loss: 5.0337 - MinusLogProbMetric: 5.0337 - val_loss: 5.1326 - val_MinusLogProbMetric: 5.1326 - lr: 1.2500e-04 - 68s/epoch - 347ms/step
Epoch 537/1000
2023-09-19 03:40:24.654 
Epoch 537/1000 
	 loss: 5.0347, MinusLogProbMetric: 5.0347, val_loss: 5.1326, val_MinusLogProbMetric: 5.1326

Epoch 537: val_loss did not improve from 5.12981
196/196 - 68s - loss: 5.0347 - MinusLogProbMetric: 5.0347 - val_loss: 5.1326 - val_MinusLogProbMetric: 5.1326 - lr: 1.2500e-04 - 68s/epoch - 349ms/step
Epoch 538/1000
2023-09-19 03:41:32.638 
Epoch 538/1000 
	 loss: 5.0328, MinusLogProbMetric: 5.0328, val_loss: 5.1289, val_MinusLogProbMetric: 5.1289

Epoch 538: val_loss improved from 5.12981 to 5.12889, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 69s - loss: 5.0328 - MinusLogProbMetric: 5.0328 - val_loss: 5.1289 - val_MinusLogProbMetric: 5.1289 - lr: 1.2500e-04 - 69s/epoch - 352ms/step
Epoch 539/1000
2023-09-19 03:42:41.570 
Epoch 539/1000 
	 loss: 5.0322, MinusLogProbMetric: 5.0322, val_loss: 5.1428, val_MinusLogProbMetric: 5.1428

Epoch 539: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0322 - MinusLogProbMetric: 5.0322 - val_loss: 5.1428 - val_MinusLogProbMetric: 5.1428 - lr: 1.2500e-04 - 68s/epoch - 346ms/step
Epoch 540/1000
2023-09-19 03:43:49.698 
Epoch 540/1000 
	 loss: 5.0336, MinusLogProbMetric: 5.0336, val_loss: 5.1386, val_MinusLogProbMetric: 5.1386

Epoch 540: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0336 - MinusLogProbMetric: 5.0336 - val_loss: 5.1386 - val_MinusLogProbMetric: 5.1386 - lr: 1.2500e-04 - 68s/epoch - 348ms/step
Epoch 541/1000
2023-09-19 03:44:58.109 
Epoch 541/1000 
	 loss: 5.0341, MinusLogProbMetric: 5.0341, val_loss: 5.1346, val_MinusLogProbMetric: 5.1346

Epoch 541: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0341 - MinusLogProbMetric: 5.0341 - val_loss: 5.1346 - val_MinusLogProbMetric: 5.1346 - lr: 1.2500e-04 - 68s/epoch - 349ms/step
Epoch 542/1000
2023-09-19 03:46:06.051 
Epoch 542/1000 
	 loss: 5.0318, MinusLogProbMetric: 5.0318, val_loss: 5.1344, val_MinusLogProbMetric: 5.1344

Epoch 542: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0318 - MinusLogProbMetric: 5.0318 - val_loss: 5.1344 - val_MinusLogProbMetric: 5.1344 - lr: 1.2500e-04 - 68s/epoch - 347ms/step
Epoch 543/1000
2023-09-19 03:47:13.791 
Epoch 543/1000 
	 loss: 5.0343, MinusLogProbMetric: 5.0343, val_loss: 5.1340, val_MinusLogProbMetric: 5.1340

Epoch 543: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0343 - MinusLogProbMetric: 5.0343 - val_loss: 5.1340 - val_MinusLogProbMetric: 5.1340 - lr: 1.2500e-04 - 68s/epoch - 346ms/step
Epoch 544/1000
2023-09-19 03:48:22.499 
Epoch 544/1000 
	 loss: 5.0331, MinusLogProbMetric: 5.0331, val_loss: 5.1345, val_MinusLogProbMetric: 5.1345

Epoch 544: val_loss did not improve from 5.12889
196/196 - 69s - loss: 5.0331 - MinusLogProbMetric: 5.0331 - val_loss: 5.1345 - val_MinusLogProbMetric: 5.1345 - lr: 1.2500e-04 - 69s/epoch - 351ms/step
Epoch 545/1000
2023-09-19 03:49:31.077 
Epoch 545/1000 
	 loss: 5.0343, MinusLogProbMetric: 5.0343, val_loss: 5.1356, val_MinusLogProbMetric: 5.1356

Epoch 545: val_loss did not improve from 5.12889
196/196 - 69s - loss: 5.0343 - MinusLogProbMetric: 5.0343 - val_loss: 5.1356 - val_MinusLogProbMetric: 5.1356 - lr: 1.2500e-04 - 69s/epoch - 350ms/step
Epoch 546/1000
2023-09-19 03:50:39.508 
Epoch 546/1000 
	 loss: 5.0350, MinusLogProbMetric: 5.0350, val_loss: 5.1325, val_MinusLogProbMetric: 5.1325

Epoch 546: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0350 - MinusLogProbMetric: 5.0350 - val_loss: 5.1325 - val_MinusLogProbMetric: 5.1325 - lr: 1.2500e-04 - 68s/epoch - 349ms/step
Epoch 547/1000
2023-09-19 03:51:47.929 
Epoch 547/1000 
	 loss: 5.0348, MinusLogProbMetric: 5.0348, val_loss: 5.1414, val_MinusLogProbMetric: 5.1414

Epoch 547: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0348 - MinusLogProbMetric: 5.0348 - val_loss: 5.1414 - val_MinusLogProbMetric: 5.1414 - lr: 1.2500e-04 - 68s/epoch - 349ms/step
Epoch 548/1000
2023-09-19 03:52:56.131 
Epoch 548/1000 
	 loss: 5.0340, MinusLogProbMetric: 5.0340, val_loss: 5.1361, val_MinusLogProbMetric: 5.1361

Epoch 548: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0340 - MinusLogProbMetric: 5.0340 - val_loss: 5.1361 - val_MinusLogProbMetric: 5.1361 - lr: 1.2500e-04 - 68s/epoch - 348ms/step
Epoch 549/1000
2023-09-19 03:54:04.958 
Epoch 549/1000 
	 loss: 5.0322, MinusLogProbMetric: 5.0322, val_loss: 5.1355, val_MinusLogProbMetric: 5.1355

Epoch 549: val_loss did not improve from 5.12889
196/196 - 69s - loss: 5.0322 - MinusLogProbMetric: 5.0322 - val_loss: 5.1355 - val_MinusLogProbMetric: 5.1355 - lr: 1.2500e-04 - 69s/epoch - 351ms/step
Epoch 550/1000
2023-09-19 03:55:13.900 
Epoch 550/1000 
	 loss: 5.0319, MinusLogProbMetric: 5.0319, val_loss: 5.1356, val_MinusLogProbMetric: 5.1356

Epoch 550: val_loss did not improve from 5.12889
196/196 - 69s - loss: 5.0319 - MinusLogProbMetric: 5.0319 - val_loss: 5.1356 - val_MinusLogProbMetric: 5.1356 - lr: 1.2500e-04 - 69s/epoch - 352ms/step
Epoch 551/1000
2023-09-19 03:56:22.191 
Epoch 551/1000 
	 loss: 5.0328, MinusLogProbMetric: 5.0328, val_loss: 5.1399, val_MinusLogProbMetric: 5.1399

Epoch 551: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0328 - MinusLogProbMetric: 5.0328 - val_loss: 5.1399 - val_MinusLogProbMetric: 5.1399 - lr: 1.2500e-04 - 68s/epoch - 348ms/step
Epoch 552/1000
2023-09-19 03:57:29.977 
Epoch 552/1000 
	 loss: 5.0344, MinusLogProbMetric: 5.0344, val_loss: 5.1387, val_MinusLogProbMetric: 5.1387

Epoch 552: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0344 - MinusLogProbMetric: 5.0344 - val_loss: 5.1387 - val_MinusLogProbMetric: 5.1387 - lr: 1.2500e-04 - 68s/epoch - 346ms/step
Epoch 553/1000
2023-09-19 03:58:38.612 
Epoch 553/1000 
	 loss: 5.0332, MinusLogProbMetric: 5.0332, val_loss: 5.1344, val_MinusLogProbMetric: 5.1344

Epoch 553: val_loss did not improve from 5.12889
196/196 - 69s - loss: 5.0332 - MinusLogProbMetric: 5.0332 - val_loss: 5.1344 - val_MinusLogProbMetric: 5.1344 - lr: 1.2500e-04 - 69s/epoch - 350ms/step
Epoch 554/1000
2023-09-19 03:59:46.899 
Epoch 554/1000 
	 loss: 5.0349, MinusLogProbMetric: 5.0349, val_loss: 5.1344, val_MinusLogProbMetric: 5.1344

Epoch 554: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0349 - MinusLogProbMetric: 5.0349 - val_loss: 5.1344 - val_MinusLogProbMetric: 5.1344 - lr: 1.2500e-04 - 68s/epoch - 348ms/step
Epoch 555/1000
2023-09-19 04:00:55.107 
Epoch 555/1000 
	 loss: 5.0312, MinusLogProbMetric: 5.0312, val_loss: 5.1377, val_MinusLogProbMetric: 5.1377

Epoch 555: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0312 - MinusLogProbMetric: 5.0312 - val_loss: 5.1377 - val_MinusLogProbMetric: 5.1377 - lr: 1.2500e-04 - 68s/epoch - 348ms/step
Epoch 556/1000
2023-09-19 04:02:03.989 
Epoch 556/1000 
	 loss: 5.0316, MinusLogProbMetric: 5.0316, val_loss: 5.1322, val_MinusLogProbMetric: 5.1322

Epoch 556: val_loss did not improve from 5.12889
196/196 - 69s - loss: 5.0316 - MinusLogProbMetric: 5.0316 - val_loss: 5.1322 - val_MinusLogProbMetric: 5.1322 - lr: 1.2500e-04 - 69s/epoch - 351ms/step
Epoch 557/1000
2023-09-19 04:03:12.032 
Epoch 557/1000 
	 loss: 5.0325, MinusLogProbMetric: 5.0325, val_loss: 5.1402, val_MinusLogProbMetric: 5.1402

Epoch 557: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0325 - MinusLogProbMetric: 5.0325 - val_loss: 5.1402 - val_MinusLogProbMetric: 5.1402 - lr: 1.2500e-04 - 68s/epoch - 347ms/step
Epoch 558/1000
2023-09-19 04:04:19.785 
Epoch 558/1000 
	 loss: 5.0314, MinusLogProbMetric: 5.0314, val_loss: 5.1375, val_MinusLogProbMetric: 5.1375

Epoch 558: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0314 - MinusLogProbMetric: 5.0314 - val_loss: 5.1375 - val_MinusLogProbMetric: 5.1375 - lr: 1.2500e-04 - 68s/epoch - 346ms/step
Epoch 559/1000
2023-09-19 04:05:28.023 
Epoch 559/1000 
	 loss: 5.0319, MinusLogProbMetric: 5.0319, val_loss: 5.1376, val_MinusLogProbMetric: 5.1376

Epoch 559: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0319 - MinusLogProbMetric: 5.0319 - val_loss: 5.1376 - val_MinusLogProbMetric: 5.1376 - lr: 1.2500e-04 - 68s/epoch - 348ms/step
Epoch 560/1000
2023-09-19 04:06:35.754 
Epoch 560/1000 
	 loss: 5.0331, MinusLogProbMetric: 5.0331, val_loss: 5.1315, val_MinusLogProbMetric: 5.1315

Epoch 560: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0331 - MinusLogProbMetric: 5.0331 - val_loss: 5.1315 - val_MinusLogProbMetric: 5.1315 - lr: 1.2500e-04 - 68s/epoch - 346ms/step
Epoch 561/1000
2023-09-19 04:07:43.391 
Epoch 561/1000 
	 loss: 5.0333, MinusLogProbMetric: 5.0333, val_loss: 5.1314, val_MinusLogProbMetric: 5.1314

Epoch 561: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0333 - MinusLogProbMetric: 5.0333 - val_loss: 5.1314 - val_MinusLogProbMetric: 5.1314 - lr: 1.2500e-04 - 68s/epoch - 345ms/step
Epoch 562/1000
2023-09-19 04:08:51.369 
Epoch 562/1000 
	 loss: 5.0327, MinusLogProbMetric: 5.0327, val_loss: 5.1391, val_MinusLogProbMetric: 5.1391

Epoch 562: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0327 - MinusLogProbMetric: 5.0327 - val_loss: 5.1391 - val_MinusLogProbMetric: 5.1391 - lr: 1.2500e-04 - 68s/epoch - 347ms/step
Epoch 563/1000
2023-09-19 04:09:59.684 
Epoch 563/1000 
	 loss: 5.0315, MinusLogProbMetric: 5.0315, val_loss: 5.1379, val_MinusLogProbMetric: 5.1379

Epoch 563: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0315 - MinusLogProbMetric: 5.0315 - val_loss: 5.1379 - val_MinusLogProbMetric: 5.1379 - lr: 1.2500e-04 - 68s/epoch - 349ms/step
Epoch 564/1000
2023-09-19 04:11:08.047 
Epoch 564/1000 
	 loss: 5.0306, MinusLogProbMetric: 5.0306, val_loss: 5.1382, val_MinusLogProbMetric: 5.1382

Epoch 564: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0306 - MinusLogProbMetric: 5.0306 - val_loss: 5.1382 - val_MinusLogProbMetric: 5.1382 - lr: 1.2500e-04 - 68s/epoch - 349ms/step
Epoch 565/1000
2023-09-19 04:12:15.793 
Epoch 565/1000 
	 loss: 5.0319, MinusLogProbMetric: 5.0319, val_loss: 5.1379, val_MinusLogProbMetric: 5.1379

Epoch 565: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0319 - MinusLogProbMetric: 5.0319 - val_loss: 5.1379 - val_MinusLogProbMetric: 5.1379 - lr: 1.2500e-04 - 68s/epoch - 346ms/step
Epoch 566/1000
2023-09-19 04:13:24.105 
Epoch 566/1000 
	 loss: 5.0334, MinusLogProbMetric: 5.0334, val_loss: 5.1363, val_MinusLogProbMetric: 5.1363

Epoch 566: val_loss did not improve from 5.12889
196/196 - 68s - loss: 5.0334 - MinusLogProbMetric: 5.0334 - val_loss: 5.1363 - val_MinusLogProbMetric: 5.1363 - lr: 1.2500e-04 - 68s/epoch - 349ms/step
Epoch 567/1000
2023-09-19 04:14:32.913 
Epoch 567/1000 
	 loss: 5.0326, MinusLogProbMetric: 5.0326, val_loss: 5.1343, val_MinusLogProbMetric: 5.1343

Epoch 567: val_loss did not improve from 5.12889
196/196 - 69s - loss: 5.0326 - MinusLogProbMetric: 5.0326 - val_loss: 5.1343 - val_MinusLogProbMetric: 5.1343 - lr: 1.2500e-04 - 69s/epoch - 351ms/step
Epoch 568/1000
2023-09-19 04:15:40.976 
Epoch 568/1000 
	 loss: 5.0332, MinusLogProbMetric: 5.0332, val_loss: 5.1275, val_MinusLogProbMetric: 5.1275

Epoch 568: val_loss improved from 5.12889 to 5.12746, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 69s - loss: 5.0332 - MinusLogProbMetric: 5.0332 - val_loss: 5.1275 - val_MinusLogProbMetric: 5.1275 - lr: 1.2500e-04 - 69s/epoch - 354ms/step
Epoch 569/1000
2023-09-19 04:16:49.970 
Epoch 569/1000 
	 loss: 5.0316, MinusLogProbMetric: 5.0316, val_loss: 5.1358, val_MinusLogProbMetric: 5.1358

Epoch 569: val_loss did not improve from 5.12746
196/196 - 68s - loss: 5.0316 - MinusLogProbMetric: 5.0316 - val_loss: 5.1358 - val_MinusLogProbMetric: 5.1358 - lr: 1.2500e-04 - 68s/epoch - 345ms/step
Epoch 570/1000
2023-09-19 04:17:57.880 
Epoch 570/1000 
	 loss: 5.0344, MinusLogProbMetric: 5.0344, val_loss: 5.1308, val_MinusLogProbMetric: 5.1308

Epoch 570: val_loss did not improve from 5.12746
196/196 - 68s - loss: 5.0344 - MinusLogProbMetric: 5.0344 - val_loss: 5.1308 - val_MinusLogProbMetric: 5.1308 - lr: 1.2500e-04 - 68s/epoch - 346ms/step
Epoch 571/1000
2023-09-19 04:19:06.542 
Epoch 571/1000 
	 loss: 5.0301, MinusLogProbMetric: 5.0301, val_loss: 5.1370, val_MinusLogProbMetric: 5.1370

Epoch 571: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0301 - MinusLogProbMetric: 5.0301 - val_loss: 5.1370 - val_MinusLogProbMetric: 5.1370 - lr: 1.2500e-04 - 69s/epoch - 350ms/step
Epoch 572/1000
2023-09-19 04:20:14.613 
Epoch 572/1000 
	 loss: 5.0340, MinusLogProbMetric: 5.0340, val_loss: 5.1329, val_MinusLogProbMetric: 5.1329

Epoch 572: val_loss did not improve from 5.12746
196/196 - 68s - loss: 5.0340 - MinusLogProbMetric: 5.0340 - val_loss: 5.1329 - val_MinusLogProbMetric: 5.1329 - lr: 1.2500e-04 - 68s/epoch - 347ms/step
Epoch 573/1000
2023-09-19 04:21:20.499 
Epoch 573/1000 
	 loss: 5.0315, MinusLogProbMetric: 5.0315, val_loss: 5.1344, val_MinusLogProbMetric: 5.1344

Epoch 573: val_loss did not improve from 5.12746
196/196 - 66s - loss: 5.0315 - MinusLogProbMetric: 5.0315 - val_loss: 5.1344 - val_MinusLogProbMetric: 5.1344 - lr: 1.2500e-04 - 66s/epoch - 336ms/step
Epoch 574/1000
2023-09-19 04:22:23.007 
Epoch 574/1000 
	 loss: 5.0319, MinusLogProbMetric: 5.0319, val_loss: 5.1302, val_MinusLogProbMetric: 5.1302

Epoch 574: val_loss did not improve from 5.12746
196/196 - 63s - loss: 5.0319 - MinusLogProbMetric: 5.0319 - val_loss: 5.1302 - val_MinusLogProbMetric: 5.1302 - lr: 1.2500e-04 - 63s/epoch - 319ms/step
Epoch 575/1000
2023-09-19 04:23:24.152 
Epoch 575/1000 
	 loss: 5.0309, MinusLogProbMetric: 5.0309, val_loss: 5.1467, val_MinusLogProbMetric: 5.1467

Epoch 575: val_loss did not improve from 5.12746
196/196 - 61s - loss: 5.0309 - MinusLogProbMetric: 5.0309 - val_loss: 5.1467 - val_MinusLogProbMetric: 5.1467 - lr: 1.2500e-04 - 61s/epoch - 312ms/step
Epoch 576/1000
2023-09-19 04:24:22.589 
Epoch 576/1000 
	 loss: 5.0320, MinusLogProbMetric: 5.0320, val_loss: 5.1384, val_MinusLogProbMetric: 5.1384

Epoch 576: val_loss did not improve from 5.12746
196/196 - 58s - loss: 5.0320 - MinusLogProbMetric: 5.0320 - val_loss: 5.1384 - val_MinusLogProbMetric: 5.1384 - lr: 1.2500e-04 - 58s/epoch - 298ms/step
Epoch 577/1000
2023-09-19 04:25:31.768 
Epoch 577/1000 
	 loss: 5.0328, MinusLogProbMetric: 5.0328, val_loss: 5.1301, val_MinusLogProbMetric: 5.1301

Epoch 577: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0328 - MinusLogProbMetric: 5.0328 - val_loss: 5.1301 - val_MinusLogProbMetric: 5.1301 - lr: 1.2500e-04 - 69s/epoch - 353ms/step
Epoch 578/1000
2023-09-19 04:26:40.577 
Epoch 578/1000 
	 loss: 5.0311, MinusLogProbMetric: 5.0311, val_loss: 5.1330, val_MinusLogProbMetric: 5.1330

Epoch 578: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0311 - MinusLogProbMetric: 5.0311 - val_loss: 5.1330 - val_MinusLogProbMetric: 5.1330 - lr: 1.2500e-04 - 69s/epoch - 351ms/step
Epoch 579/1000
2023-09-19 04:27:49.955 
Epoch 579/1000 
	 loss: 5.0315, MinusLogProbMetric: 5.0315, val_loss: 5.1352, val_MinusLogProbMetric: 5.1352

Epoch 579: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0315 - MinusLogProbMetric: 5.0315 - val_loss: 5.1352 - val_MinusLogProbMetric: 5.1352 - lr: 1.2500e-04 - 69s/epoch - 354ms/step
Epoch 580/1000
2023-09-19 04:28:59.144 
Epoch 580/1000 
	 loss: 5.0314, MinusLogProbMetric: 5.0314, val_loss: 5.1316, val_MinusLogProbMetric: 5.1316

Epoch 580: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0314 - MinusLogProbMetric: 5.0314 - val_loss: 5.1316 - val_MinusLogProbMetric: 5.1316 - lr: 1.2500e-04 - 69s/epoch - 353ms/step
Epoch 581/1000
2023-09-19 04:30:07.597 
Epoch 581/1000 
	 loss: 5.0314, MinusLogProbMetric: 5.0314, val_loss: 5.1432, val_MinusLogProbMetric: 5.1432

Epoch 581: val_loss did not improve from 5.12746
196/196 - 68s - loss: 5.0314 - MinusLogProbMetric: 5.0314 - val_loss: 5.1432 - val_MinusLogProbMetric: 5.1432 - lr: 1.2500e-04 - 68s/epoch - 349ms/step
Epoch 582/1000
2023-09-19 04:31:16.219 
Epoch 582/1000 
	 loss: 5.0324, MinusLogProbMetric: 5.0324, val_loss: 5.1387, val_MinusLogProbMetric: 5.1387

Epoch 582: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0324 - MinusLogProbMetric: 5.0324 - val_loss: 5.1387 - val_MinusLogProbMetric: 5.1387 - lr: 1.2500e-04 - 69s/epoch - 350ms/step
Epoch 583/1000
2023-09-19 04:32:24.815 
Epoch 583/1000 
	 loss: 5.0324, MinusLogProbMetric: 5.0324, val_loss: 5.1396, val_MinusLogProbMetric: 5.1396

Epoch 583: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0324 - MinusLogProbMetric: 5.0324 - val_loss: 5.1396 - val_MinusLogProbMetric: 5.1396 - lr: 1.2500e-04 - 69s/epoch - 350ms/step
Epoch 584/1000
2023-09-19 04:33:33.991 
Epoch 584/1000 
	 loss: 5.0315, MinusLogProbMetric: 5.0315, val_loss: 5.1351, val_MinusLogProbMetric: 5.1351

Epoch 584: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0315 - MinusLogProbMetric: 5.0315 - val_loss: 5.1351 - val_MinusLogProbMetric: 5.1351 - lr: 1.2500e-04 - 69s/epoch - 353ms/step
Epoch 585/1000
2023-09-19 04:34:43.266 
Epoch 585/1000 
	 loss: 5.0312, MinusLogProbMetric: 5.0312, val_loss: 5.1372, val_MinusLogProbMetric: 5.1372

Epoch 585: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0312 - MinusLogProbMetric: 5.0312 - val_loss: 5.1372 - val_MinusLogProbMetric: 5.1372 - lr: 1.2500e-04 - 69s/epoch - 353ms/step
Epoch 586/1000
2023-09-19 04:35:52.377 
Epoch 586/1000 
	 loss: 5.0323, MinusLogProbMetric: 5.0323, val_loss: 5.1442, val_MinusLogProbMetric: 5.1442

Epoch 586: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0323 - MinusLogProbMetric: 5.0323 - val_loss: 5.1442 - val_MinusLogProbMetric: 5.1442 - lr: 1.2500e-04 - 69s/epoch - 353ms/step
Epoch 587/1000
2023-09-19 04:37:01.329 
Epoch 587/1000 
	 loss: 5.0319, MinusLogProbMetric: 5.0319, val_loss: 5.1389, val_MinusLogProbMetric: 5.1389

Epoch 587: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0319 - MinusLogProbMetric: 5.0319 - val_loss: 5.1389 - val_MinusLogProbMetric: 5.1389 - lr: 1.2500e-04 - 69s/epoch - 352ms/step
Epoch 588/1000
2023-09-19 04:38:10.493 
Epoch 588/1000 
	 loss: 5.0322, MinusLogProbMetric: 5.0322, val_loss: 5.1322, val_MinusLogProbMetric: 5.1322

Epoch 588: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0322 - MinusLogProbMetric: 5.0322 - val_loss: 5.1322 - val_MinusLogProbMetric: 5.1322 - lr: 1.2500e-04 - 69s/epoch - 353ms/step
Epoch 589/1000
2023-09-19 04:39:19.021 
Epoch 589/1000 
	 loss: 5.0326, MinusLogProbMetric: 5.0326, val_loss: 5.1287, val_MinusLogProbMetric: 5.1287

Epoch 589: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0326 - MinusLogProbMetric: 5.0326 - val_loss: 5.1287 - val_MinusLogProbMetric: 5.1287 - lr: 1.2500e-04 - 69s/epoch - 350ms/step
Epoch 590/1000
2023-09-19 04:40:27.832 
Epoch 590/1000 
	 loss: 5.0320, MinusLogProbMetric: 5.0320, val_loss: 5.1430, val_MinusLogProbMetric: 5.1430

Epoch 590: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0320 - MinusLogProbMetric: 5.0320 - val_loss: 5.1430 - val_MinusLogProbMetric: 5.1430 - lr: 1.2500e-04 - 69s/epoch - 351ms/step
Epoch 591/1000
2023-09-19 04:41:37.264 
Epoch 591/1000 
	 loss: 5.0327, MinusLogProbMetric: 5.0327, val_loss: 5.1336, val_MinusLogProbMetric: 5.1336

Epoch 591: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0327 - MinusLogProbMetric: 5.0327 - val_loss: 5.1336 - val_MinusLogProbMetric: 5.1336 - lr: 1.2500e-04 - 69s/epoch - 354ms/step
Epoch 592/1000
2023-09-19 04:42:46.244 
Epoch 592/1000 
	 loss: 5.0320, MinusLogProbMetric: 5.0320, val_loss: 5.1353, val_MinusLogProbMetric: 5.1353

Epoch 592: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0320 - MinusLogProbMetric: 5.0320 - val_loss: 5.1353 - val_MinusLogProbMetric: 5.1353 - lr: 1.2500e-04 - 69s/epoch - 352ms/step
Epoch 593/1000
2023-09-19 04:43:54.704 
Epoch 593/1000 
	 loss: 5.0311, MinusLogProbMetric: 5.0311, val_loss: 5.1370, val_MinusLogProbMetric: 5.1370

Epoch 593: val_loss did not improve from 5.12746
196/196 - 68s - loss: 5.0311 - MinusLogProbMetric: 5.0311 - val_loss: 5.1370 - val_MinusLogProbMetric: 5.1370 - lr: 1.2500e-04 - 68s/epoch - 349ms/step
Epoch 594/1000
2023-09-19 04:45:03.800 
Epoch 594/1000 
	 loss: 5.0308, MinusLogProbMetric: 5.0308, val_loss: 5.1345, val_MinusLogProbMetric: 5.1345

Epoch 594: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0308 - MinusLogProbMetric: 5.0308 - val_loss: 5.1345 - val_MinusLogProbMetric: 5.1345 - lr: 1.2500e-04 - 69s/epoch - 353ms/step
Epoch 595/1000
2023-09-19 04:46:12.470 
Epoch 595/1000 
	 loss: 5.0308, MinusLogProbMetric: 5.0308, val_loss: 5.1326, val_MinusLogProbMetric: 5.1326

Epoch 595: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0308 - MinusLogProbMetric: 5.0308 - val_loss: 5.1326 - val_MinusLogProbMetric: 5.1326 - lr: 1.2500e-04 - 69s/epoch - 350ms/step
Epoch 596/1000
2023-09-19 04:47:21.465 
Epoch 596/1000 
	 loss: 5.0311, MinusLogProbMetric: 5.0311, val_loss: 5.1337, val_MinusLogProbMetric: 5.1337

Epoch 596: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0311 - MinusLogProbMetric: 5.0311 - val_loss: 5.1337 - val_MinusLogProbMetric: 5.1337 - lr: 1.2500e-04 - 69s/epoch - 352ms/step
Epoch 597/1000
2023-09-19 04:48:30.752 
Epoch 597/1000 
	 loss: 5.0334, MinusLogProbMetric: 5.0334, val_loss: 5.1308, val_MinusLogProbMetric: 5.1308

Epoch 597: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0334 - MinusLogProbMetric: 5.0334 - val_loss: 5.1308 - val_MinusLogProbMetric: 5.1308 - lr: 1.2500e-04 - 69s/epoch - 353ms/step
Epoch 598/1000
2023-09-19 04:49:39.853 
Epoch 598/1000 
	 loss: 5.0304, MinusLogProbMetric: 5.0304, val_loss: 5.1381, val_MinusLogProbMetric: 5.1381

Epoch 598: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0304 - MinusLogProbMetric: 5.0304 - val_loss: 5.1381 - val_MinusLogProbMetric: 5.1381 - lr: 1.2500e-04 - 69s/epoch - 353ms/step
Epoch 599/1000
2023-09-19 04:50:48.961 
Epoch 599/1000 
	 loss: 5.0298, MinusLogProbMetric: 5.0298, val_loss: 5.1292, val_MinusLogProbMetric: 5.1292

Epoch 599: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0298 - MinusLogProbMetric: 5.0298 - val_loss: 5.1292 - val_MinusLogProbMetric: 5.1292 - lr: 1.2500e-04 - 69s/epoch - 353ms/step
Epoch 600/1000
2023-09-19 04:51:57.826 
Epoch 600/1000 
	 loss: 5.0329, MinusLogProbMetric: 5.0329, val_loss: 5.1407, val_MinusLogProbMetric: 5.1407

Epoch 600: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0329 - MinusLogProbMetric: 5.0329 - val_loss: 5.1407 - val_MinusLogProbMetric: 5.1407 - lr: 1.2500e-04 - 69s/epoch - 351ms/step
Epoch 601/1000
2023-09-19 04:53:06.742 
Epoch 601/1000 
	 loss: 5.0322, MinusLogProbMetric: 5.0322, val_loss: 5.1356, val_MinusLogProbMetric: 5.1356

Epoch 601: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0322 - MinusLogProbMetric: 5.0322 - val_loss: 5.1356 - val_MinusLogProbMetric: 5.1356 - lr: 1.2500e-04 - 69s/epoch - 352ms/step
Epoch 602/1000
2023-09-19 04:54:16.109 
Epoch 602/1000 
	 loss: 5.0337, MinusLogProbMetric: 5.0337, val_loss: 5.1366, val_MinusLogProbMetric: 5.1366

Epoch 602: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0337 - MinusLogProbMetric: 5.0337 - val_loss: 5.1366 - val_MinusLogProbMetric: 5.1366 - lr: 1.2500e-04 - 69s/epoch - 354ms/step
Epoch 603/1000
2023-09-19 04:55:25.391 
Epoch 603/1000 
	 loss: 5.0328, MinusLogProbMetric: 5.0328, val_loss: 5.1343, val_MinusLogProbMetric: 5.1343

Epoch 603: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0328 - MinusLogProbMetric: 5.0328 - val_loss: 5.1343 - val_MinusLogProbMetric: 5.1343 - lr: 1.2500e-04 - 69s/epoch - 353ms/step
Epoch 604/1000
2023-09-19 04:56:34.961 
Epoch 604/1000 
	 loss: 5.0326, MinusLogProbMetric: 5.0326, val_loss: 5.1279, val_MinusLogProbMetric: 5.1279

Epoch 604: val_loss did not improve from 5.12746
196/196 - 70s - loss: 5.0326 - MinusLogProbMetric: 5.0326 - val_loss: 5.1279 - val_MinusLogProbMetric: 5.1279 - lr: 1.2500e-04 - 70s/epoch - 355ms/step
Epoch 605/1000
2023-09-19 04:57:44.398 
Epoch 605/1000 
	 loss: 5.0307, MinusLogProbMetric: 5.0307, val_loss: 5.1311, val_MinusLogProbMetric: 5.1311

Epoch 605: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0307 - MinusLogProbMetric: 5.0307 - val_loss: 5.1311 - val_MinusLogProbMetric: 5.1311 - lr: 1.2500e-04 - 69s/epoch - 354ms/step
Epoch 606/1000
2023-09-19 04:58:53.671 
Epoch 606/1000 
	 loss: 5.0328, MinusLogProbMetric: 5.0328, val_loss: 5.1380, val_MinusLogProbMetric: 5.1380

Epoch 606: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0328 - MinusLogProbMetric: 5.0328 - val_loss: 5.1380 - val_MinusLogProbMetric: 5.1380 - lr: 1.2500e-04 - 69s/epoch - 353ms/step
Epoch 607/1000
2023-09-19 05:00:02.975 
Epoch 607/1000 
	 loss: 5.0316, MinusLogProbMetric: 5.0316, val_loss: 5.1302, val_MinusLogProbMetric: 5.1302

Epoch 607: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0316 - MinusLogProbMetric: 5.0316 - val_loss: 5.1302 - val_MinusLogProbMetric: 5.1302 - lr: 1.2500e-04 - 69s/epoch - 354ms/step
Epoch 608/1000
2023-09-19 05:01:12.295 
Epoch 608/1000 
	 loss: 5.0334, MinusLogProbMetric: 5.0334, val_loss: 5.1359, val_MinusLogProbMetric: 5.1359

Epoch 608: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0334 - MinusLogProbMetric: 5.0334 - val_loss: 5.1359 - val_MinusLogProbMetric: 5.1359 - lr: 1.2500e-04 - 69s/epoch - 354ms/step
Epoch 609/1000
2023-09-19 05:02:21.671 
Epoch 609/1000 
	 loss: 5.0324, MinusLogProbMetric: 5.0324, val_loss: 5.1373, val_MinusLogProbMetric: 5.1373

Epoch 609: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0324 - MinusLogProbMetric: 5.0324 - val_loss: 5.1373 - val_MinusLogProbMetric: 5.1373 - lr: 1.2500e-04 - 69s/epoch - 354ms/step
Epoch 610/1000
2023-09-19 05:03:30.533 
Epoch 610/1000 
	 loss: 5.0317, MinusLogProbMetric: 5.0317, val_loss: 5.1351, val_MinusLogProbMetric: 5.1351

Epoch 610: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0317 - MinusLogProbMetric: 5.0317 - val_loss: 5.1351 - val_MinusLogProbMetric: 5.1351 - lr: 1.2500e-04 - 69s/epoch - 351ms/step
Epoch 611/1000
2023-09-19 05:04:39.295 
Epoch 611/1000 
	 loss: 5.0315, MinusLogProbMetric: 5.0315, val_loss: 5.1338, val_MinusLogProbMetric: 5.1338

Epoch 611: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0315 - MinusLogProbMetric: 5.0315 - val_loss: 5.1338 - val_MinusLogProbMetric: 5.1338 - lr: 1.2500e-04 - 69s/epoch - 351ms/step
Epoch 612/1000
2023-09-19 05:05:48.790 
Epoch 612/1000 
	 loss: 5.0296, MinusLogProbMetric: 5.0296, val_loss: 5.1385, val_MinusLogProbMetric: 5.1385

Epoch 612: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0296 - MinusLogProbMetric: 5.0296 - val_loss: 5.1385 - val_MinusLogProbMetric: 5.1385 - lr: 1.2500e-04 - 69s/epoch - 355ms/step
Epoch 613/1000
2023-09-19 05:06:52.990 
Epoch 613/1000 
	 loss: 5.0315, MinusLogProbMetric: 5.0315, val_loss: 5.1327, val_MinusLogProbMetric: 5.1327

Epoch 613: val_loss did not improve from 5.12746
196/196 - 64s - loss: 5.0315 - MinusLogProbMetric: 5.0315 - val_loss: 5.1327 - val_MinusLogProbMetric: 5.1327 - lr: 1.2500e-04 - 64s/epoch - 328ms/step
Epoch 614/1000
2023-09-19 05:07:53.755 
Epoch 614/1000 
	 loss: 5.0329, MinusLogProbMetric: 5.0329, val_loss: 5.1347, val_MinusLogProbMetric: 5.1347

Epoch 614: val_loss did not improve from 5.12746
196/196 - 61s - loss: 5.0329 - MinusLogProbMetric: 5.0329 - val_loss: 5.1347 - val_MinusLogProbMetric: 5.1347 - lr: 1.2500e-04 - 61s/epoch - 310ms/step
Epoch 615/1000
2023-09-19 05:09:00.146 
Epoch 615/1000 
	 loss: 5.0297, MinusLogProbMetric: 5.0297, val_loss: 5.1350, val_MinusLogProbMetric: 5.1350

Epoch 615: val_loss did not improve from 5.12746
196/196 - 66s - loss: 5.0297 - MinusLogProbMetric: 5.0297 - val_loss: 5.1350 - val_MinusLogProbMetric: 5.1350 - lr: 1.2500e-04 - 66s/epoch - 339ms/step
Epoch 616/1000
2023-09-19 05:10:09.212 
Epoch 616/1000 
	 loss: 5.0310, MinusLogProbMetric: 5.0310, val_loss: 5.1307, val_MinusLogProbMetric: 5.1307

Epoch 616: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0310 - MinusLogProbMetric: 5.0310 - val_loss: 5.1307 - val_MinusLogProbMetric: 5.1307 - lr: 1.2500e-04 - 69s/epoch - 352ms/step
Epoch 617/1000
2023-09-19 05:11:18.734 
Epoch 617/1000 
	 loss: 5.0300, MinusLogProbMetric: 5.0300, val_loss: 5.1403, val_MinusLogProbMetric: 5.1403

Epoch 617: val_loss did not improve from 5.12746
196/196 - 70s - loss: 5.0300 - MinusLogProbMetric: 5.0300 - val_loss: 5.1403 - val_MinusLogProbMetric: 5.1403 - lr: 1.2500e-04 - 70s/epoch - 355ms/step
Epoch 618/1000
2023-09-19 05:12:28.091 
Epoch 618/1000 
	 loss: 5.0322, MinusLogProbMetric: 5.0322, val_loss: 5.1352, val_MinusLogProbMetric: 5.1352

Epoch 618: val_loss did not improve from 5.12746
196/196 - 69s - loss: 5.0322 - MinusLogProbMetric: 5.0322 - val_loss: 5.1352 - val_MinusLogProbMetric: 5.1352 - lr: 1.2500e-04 - 69s/epoch - 354ms/step
Epoch 619/1000
2023-09-19 05:13:37.250 
Epoch 619/1000 
	 loss: 5.0245, MinusLogProbMetric: 5.0245, val_loss: 5.1274, val_MinusLogProbMetric: 5.1274

Epoch 619: val_loss improved from 5.12746 to 5.12741, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0245 - MinusLogProbMetric: 5.0245 - val_loss: 5.1274 - val_MinusLogProbMetric: 5.1274 - lr: 6.2500e-05 - 70s/epoch - 357ms/step
Epoch 620/1000
2023-09-19 05:14:47.091 
Epoch 620/1000 
	 loss: 5.0235, MinusLogProbMetric: 5.0235, val_loss: 5.1303, val_MinusLogProbMetric: 5.1303

Epoch 620: val_loss did not improve from 5.12741
196/196 - 69s - loss: 5.0235 - MinusLogProbMetric: 5.0235 - val_loss: 5.1303 - val_MinusLogProbMetric: 5.1303 - lr: 6.2500e-05 - 69s/epoch - 352ms/step
Epoch 621/1000
2023-09-19 05:15:56.108 
Epoch 621/1000 
	 loss: 5.0240, MinusLogProbMetric: 5.0240, val_loss: 5.1310, val_MinusLogProbMetric: 5.1310

Epoch 621: val_loss did not improve from 5.12741
196/196 - 69s - loss: 5.0240 - MinusLogProbMetric: 5.0240 - val_loss: 5.1310 - val_MinusLogProbMetric: 5.1310 - lr: 6.2500e-05 - 69s/epoch - 352ms/step
Epoch 622/1000
2023-09-19 05:17:04.788 
Epoch 622/1000 
	 loss: 5.0244, MinusLogProbMetric: 5.0244, val_loss: 5.1306, val_MinusLogProbMetric: 5.1306

Epoch 622: val_loss did not improve from 5.12741
196/196 - 69s - loss: 5.0244 - MinusLogProbMetric: 5.0244 - val_loss: 5.1306 - val_MinusLogProbMetric: 5.1306 - lr: 6.2500e-05 - 69s/epoch - 350ms/step
Epoch 623/1000
2023-09-19 05:18:13.474 
Epoch 623/1000 
	 loss: 5.0234, MinusLogProbMetric: 5.0234, val_loss: 5.1267, val_MinusLogProbMetric: 5.1267

Epoch 623: val_loss improved from 5.12741 to 5.12667, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0234 - MinusLogProbMetric: 5.0234 - val_loss: 5.1267 - val_MinusLogProbMetric: 5.1267 - lr: 6.2500e-05 - 70s/epoch - 357ms/step
Epoch 624/1000
2023-09-19 05:19:23.430 
Epoch 624/1000 
	 loss: 5.0241, MinusLogProbMetric: 5.0241, val_loss: 5.1278, val_MinusLogProbMetric: 5.1278

Epoch 624: val_loss did not improve from 5.12667
196/196 - 69s - loss: 5.0241 - MinusLogProbMetric: 5.0241 - val_loss: 5.1278 - val_MinusLogProbMetric: 5.1278 - lr: 6.2500e-05 - 69s/epoch - 351ms/step
Epoch 625/1000
2023-09-19 05:20:32.717 
Epoch 625/1000 
	 loss: 5.0238, MinusLogProbMetric: 5.0238, val_loss: 5.1319, val_MinusLogProbMetric: 5.1319

Epoch 625: val_loss did not improve from 5.12667
196/196 - 69s - loss: 5.0238 - MinusLogProbMetric: 5.0238 - val_loss: 5.1319 - val_MinusLogProbMetric: 5.1319 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 626/1000
2023-09-19 05:21:41.611 
Epoch 626/1000 
	 loss: 5.0236, MinusLogProbMetric: 5.0236, val_loss: 5.1280, val_MinusLogProbMetric: 5.1280

Epoch 626: val_loss did not improve from 5.12667
196/196 - 69s - loss: 5.0236 - MinusLogProbMetric: 5.0236 - val_loss: 5.1280 - val_MinusLogProbMetric: 5.1280 - lr: 6.2500e-05 - 69s/epoch - 351ms/step
Epoch 627/1000
2023-09-19 05:22:50.722 
Epoch 627/1000 
	 loss: 5.0226, MinusLogProbMetric: 5.0226, val_loss: 5.1287, val_MinusLogProbMetric: 5.1287

Epoch 627: val_loss did not improve from 5.12667
196/196 - 69s - loss: 5.0226 - MinusLogProbMetric: 5.0226 - val_loss: 5.1287 - val_MinusLogProbMetric: 5.1287 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 628/1000
2023-09-19 05:23:59.916 
Epoch 628/1000 
	 loss: 5.0239, MinusLogProbMetric: 5.0239, val_loss: 5.1270, val_MinusLogProbMetric: 5.1270

Epoch 628: val_loss did not improve from 5.12667
196/196 - 69s - loss: 5.0239 - MinusLogProbMetric: 5.0239 - val_loss: 5.1270 - val_MinusLogProbMetric: 5.1270 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 629/1000
2023-09-19 05:25:09.307 
Epoch 629/1000 
	 loss: 5.0235, MinusLogProbMetric: 5.0235, val_loss: 5.1305, val_MinusLogProbMetric: 5.1305

Epoch 629: val_loss did not improve from 5.12667
196/196 - 69s - loss: 5.0235 - MinusLogProbMetric: 5.0235 - val_loss: 5.1305 - val_MinusLogProbMetric: 5.1305 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 630/1000
2023-09-19 05:26:18.806 
Epoch 630/1000 
	 loss: 5.0230, MinusLogProbMetric: 5.0230, val_loss: 5.1286, val_MinusLogProbMetric: 5.1286

Epoch 630: val_loss did not improve from 5.12667
196/196 - 69s - loss: 5.0230 - MinusLogProbMetric: 5.0230 - val_loss: 5.1286 - val_MinusLogProbMetric: 5.1286 - lr: 6.2500e-05 - 69s/epoch - 355ms/step
Epoch 631/1000
2023-09-19 05:27:28.344 
Epoch 631/1000 
	 loss: 5.0239, MinusLogProbMetric: 5.0239, val_loss: 5.1302, val_MinusLogProbMetric: 5.1302

Epoch 631: val_loss did not improve from 5.12667
196/196 - 70s - loss: 5.0239 - MinusLogProbMetric: 5.0239 - val_loss: 5.1302 - val_MinusLogProbMetric: 5.1302 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 632/1000
2023-09-19 05:28:37.078 
Epoch 632/1000 
	 loss: 5.0234, MinusLogProbMetric: 5.0234, val_loss: 5.1271, val_MinusLogProbMetric: 5.1271

Epoch 632: val_loss did not improve from 5.12667
196/196 - 69s - loss: 5.0234 - MinusLogProbMetric: 5.0234 - val_loss: 5.1271 - val_MinusLogProbMetric: 5.1271 - lr: 6.2500e-05 - 69s/epoch - 351ms/step
Epoch 633/1000
2023-09-19 05:29:46.222 
Epoch 633/1000 
	 loss: 5.0240, MinusLogProbMetric: 5.0240, val_loss: 5.1313, val_MinusLogProbMetric: 5.1313

Epoch 633: val_loss did not improve from 5.12667
196/196 - 69s - loss: 5.0240 - MinusLogProbMetric: 5.0240 - val_loss: 5.1313 - val_MinusLogProbMetric: 5.1313 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 634/1000
2023-09-19 05:30:55.648 
Epoch 634/1000 
	 loss: 5.0237, MinusLogProbMetric: 5.0237, val_loss: 5.1323, val_MinusLogProbMetric: 5.1323

Epoch 634: val_loss did not improve from 5.12667
196/196 - 69s - loss: 5.0237 - MinusLogProbMetric: 5.0237 - val_loss: 5.1323 - val_MinusLogProbMetric: 5.1323 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 635/1000
2023-09-19 05:32:05.321 
Epoch 635/1000 
	 loss: 5.0244, MinusLogProbMetric: 5.0244, val_loss: 5.1303, val_MinusLogProbMetric: 5.1303

Epoch 635: val_loss did not improve from 5.12667
196/196 - 70s - loss: 5.0244 - MinusLogProbMetric: 5.0244 - val_loss: 5.1303 - val_MinusLogProbMetric: 5.1303 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 636/1000
2023-09-19 05:33:14.846 
Epoch 636/1000 
	 loss: 5.0244, MinusLogProbMetric: 5.0244, val_loss: 5.1284, val_MinusLogProbMetric: 5.1284

Epoch 636: val_loss did not improve from 5.12667
196/196 - 70s - loss: 5.0244 - MinusLogProbMetric: 5.0244 - val_loss: 5.1284 - val_MinusLogProbMetric: 5.1284 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 637/1000
2023-09-19 05:34:24.103 
Epoch 637/1000 
	 loss: 5.0229, MinusLogProbMetric: 5.0229, val_loss: 5.1318, val_MinusLogProbMetric: 5.1318

Epoch 637: val_loss did not improve from 5.12667
196/196 - 69s - loss: 5.0229 - MinusLogProbMetric: 5.0229 - val_loss: 5.1318 - val_MinusLogProbMetric: 5.1318 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 638/1000
2023-09-19 05:35:32.615 
Epoch 638/1000 
	 loss: 5.0246, MinusLogProbMetric: 5.0246, val_loss: 5.1277, val_MinusLogProbMetric: 5.1277

Epoch 638: val_loss did not improve from 5.12667
196/196 - 69s - loss: 5.0246 - MinusLogProbMetric: 5.0246 - val_loss: 5.1277 - val_MinusLogProbMetric: 5.1277 - lr: 6.2500e-05 - 69s/epoch - 350ms/step
Epoch 639/1000
2023-09-19 05:36:41.775 
Epoch 639/1000 
	 loss: 5.0238, MinusLogProbMetric: 5.0238, val_loss: 5.1280, val_MinusLogProbMetric: 5.1280

Epoch 639: val_loss did not improve from 5.12667
196/196 - 69s - loss: 5.0238 - MinusLogProbMetric: 5.0238 - val_loss: 5.1280 - val_MinusLogProbMetric: 5.1280 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 640/1000
2023-09-19 05:37:50.836 
Epoch 640/1000 
	 loss: 5.0248, MinusLogProbMetric: 5.0248, val_loss: 5.1286, val_MinusLogProbMetric: 5.1286

Epoch 640: val_loss did not improve from 5.12667
196/196 - 69s - loss: 5.0248 - MinusLogProbMetric: 5.0248 - val_loss: 5.1286 - val_MinusLogProbMetric: 5.1286 - lr: 6.2500e-05 - 69s/epoch - 352ms/step
Epoch 641/1000
2023-09-19 05:39:00.180 
Epoch 641/1000 
	 loss: 5.0240, MinusLogProbMetric: 5.0240, val_loss: 5.1294, val_MinusLogProbMetric: 5.1294

Epoch 641: val_loss did not improve from 5.12667
196/196 - 69s - loss: 5.0240 - MinusLogProbMetric: 5.0240 - val_loss: 5.1294 - val_MinusLogProbMetric: 5.1294 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 642/1000
2023-09-19 05:40:09.744 
Epoch 642/1000 
	 loss: 5.0239, MinusLogProbMetric: 5.0239, val_loss: 5.1292, val_MinusLogProbMetric: 5.1292

Epoch 642: val_loss did not improve from 5.12667
196/196 - 70s - loss: 5.0239 - MinusLogProbMetric: 5.0239 - val_loss: 5.1292 - val_MinusLogProbMetric: 5.1292 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 643/1000
2023-09-19 05:41:13.331 
Epoch 643/1000 
	 loss: 5.0235, MinusLogProbMetric: 5.0235, val_loss: 5.1289, val_MinusLogProbMetric: 5.1289

Epoch 643: val_loss did not improve from 5.12667
196/196 - 64s - loss: 5.0235 - MinusLogProbMetric: 5.0235 - val_loss: 5.1289 - val_MinusLogProbMetric: 5.1289 - lr: 6.2500e-05 - 64s/epoch - 324ms/step
Epoch 644/1000
2023-09-19 05:42:14.035 
Epoch 644/1000 
	 loss: 5.0245, MinusLogProbMetric: 5.0245, val_loss: 5.1266, val_MinusLogProbMetric: 5.1266

Epoch 644: val_loss improved from 5.12667 to 5.12659, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 62s - loss: 5.0245 - MinusLogProbMetric: 5.0245 - val_loss: 5.1266 - val_MinusLogProbMetric: 5.1266 - lr: 6.2500e-05 - 62s/epoch - 314ms/step
Epoch 645/1000
2023-09-19 05:43:19.570 
Epoch 645/1000 
	 loss: 5.0235, MinusLogProbMetric: 5.0235, val_loss: 5.1284, val_MinusLogProbMetric: 5.1284

Epoch 645: val_loss did not improve from 5.12659
196/196 - 65s - loss: 5.0235 - MinusLogProbMetric: 5.0235 - val_loss: 5.1284 - val_MinusLogProbMetric: 5.1284 - lr: 6.2500e-05 - 65s/epoch - 330ms/step
Epoch 646/1000
2023-09-19 05:44:29.115 
Epoch 646/1000 
	 loss: 5.0232, MinusLogProbMetric: 5.0232, val_loss: 5.1274, val_MinusLogProbMetric: 5.1274

Epoch 646: val_loss did not improve from 5.12659
196/196 - 70s - loss: 5.0232 - MinusLogProbMetric: 5.0232 - val_loss: 5.1274 - val_MinusLogProbMetric: 5.1274 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 647/1000
2023-09-19 05:45:38.533 
Epoch 647/1000 
	 loss: 5.0228, MinusLogProbMetric: 5.0228, val_loss: 5.1298, val_MinusLogProbMetric: 5.1298

Epoch 647: val_loss did not improve from 5.12659
196/196 - 69s - loss: 5.0228 - MinusLogProbMetric: 5.0228 - val_loss: 5.1298 - val_MinusLogProbMetric: 5.1298 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 648/1000
2023-09-19 05:46:48.067 
Epoch 648/1000 
	 loss: 5.0234, MinusLogProbMetric: 5.0234, val_loss: 5.1259, val_MinusLogProbMetric: 5.1259

Epoch 648: val_loss improved from 5.12659 to 5.12594, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 71s - loss: 5.0234 - MinusLogProbMetric: 5.0234 - val_loss: 5.1259 - val_MinusLogProbMetric: 5.1259 - lr: 6.2500e-05 - 71s/epoch - 363ms/step
Epoch 649/1000
2023-09-19 05:47:59.507 
Epoch 649/1000 
	 loss: 5.0230, MinusLogProbMetric: 5.0230, val_loss: 5.1312, val_MinusLogProbMetric: 5.1312

Epoch 649: val_loss did not improve from 5.12594
196/196 - 70s - loss: 5.0230 - MinusLogProbMetric: 5.0230 - val_loss: 5.1312 - val_MinusLogProbMetric: 5.1312 - lr: 6.2500e-05 - 70s/epoch - 356ms/step
Epoch 650/1000
2023-09-19 05:49:08.724 
Epoch 650/1000 
	 loss: 5.0244, MinusLogProbMetric: 5.0244, val_loss: 5.1320, val_MinusLogProbMetric: 5.1320

Epoch 650: val_loss did not improve from 5.12594
196/196 - 69s - loss: 5.0244 - MinusLogProbMetric: 5.0244 - val_loss: 5.1320 - val_MinusLogProbMetric: 5.1320 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 651/1000
2023-09-19 05:50:18.550 
Epoch 651/1000 
	 loss: 5.0236, MinusLogProbMetric: 5.0236, val_loss: 5.1271, val_MinusLogProbMetric: 5.1271

Epoch 651: val_loss did not improve from 5.12594
196/196 - 70s - loss: 5.0236 - MinusLogProbMetric: 5.0236 - val_loss: 5.1271 - val_MinusLogProbMetric: 5.1271 - lr: 6.2500e-05 - 70s/epoch - 356ms/step
Epoch 652/1000
2023-09-19 05:51:27.651 
Epoch 652/1000 
	 loss: 5.0238, MinusLogProbMetric: 5.0238, val_loss: 5.1274, val_MinusLogProbMetric: 5.1274

Epoch 652: val_loss did not improve from 5.12594
196/196 - 69s - loss: 5.0238 - MinusLogProbMetric: 5.0238 - val_loss: 5.1274 - val_MinusLogProbMetric: 5.1274 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 653/1000
2023-09-19 05:52:36.682 
Epoch 653/1000 
	 loss: 5.0235, MinusLogProbMetric: 5.0235, val_loss: 5.1282, val_MinusLogProbMetric: 5.1282

Epoch 653: val_loss did not improve from 5.12594
196/196 - 69s - loss: 5.0235 - MinusLogProbMetric: 5.0235 - val_loss: 5.1282 - val_MinusLogProbMetric: 5.1282 - lr: 6.2500e-05 - 69s/epoch - 352ms/step
Epoch 654/1000
2023-09-19 05:53:46.277 
Epoch 654/1000 
	 loss: 5.0228, MinusLogProbMetric: 5.0228, val_loss: 5.1325, val_MinusLogProbMetric: 5.1325

Epoch 654: val_loss did not improve from 5.12594
196/196 - 70s - loss: 5.0228 - MinusLogProbMetric: 5.0228 - val_loss: 5.1325 - val_MinusLogProbMetric: 5.1325 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 655/1000
2023-09-19 05:54:55.829 
Epoch 655/1000 
	 loss: 5.0239, MinusLogProbMetric: 5.0239, val_loss: 5.1282, val_MinusLogProbMetric: 5.1282

Epoch 655: val_loss did not improve from 5.12594
196/196 - 70s - loss: 5.0239 - MinusLogProbMetric: 5.0239 - val_loss: 5.1282 - val_MinusLogProbMetric: 5.1282 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 656/1000
2023-09-19 05:56:05.464 
Epoch 656/1000 
	 loss: 5.0234, MinusLogProbMetric: 5.0234, val_loss: 5.1286, val_MinusLogProbMetric: 5.1286

Epoch 656: val_loss did not improve from 5.12594
196/196 - 70s - loss: 5.0234 - MinusLogProbMetric: 5.0234 - val_loss: 5.1286 - val_MinusLogProbMetric: 5.1286 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 657/1000
2023-09-19 05:57:15.185 
Epoch 657/1000 
	 loss: 5.0233, MinusLogProbMetric: 5.0233, val_loss: 5.1273, val_MinusLogProbMetric: 5.1273

Epoch 657: val_loss did not improve from 5.12594
196/196 - 70s - loss: 5.0233 - MinusLogProbMetric: 5.0233 - val_loss: 5.1273 - val_MinusLogProbMetric: 5.1273 - lr: 6.2500e-05 - 70s/epoch - 356ms/step
Epoch 658/1000
2023-09-19 05:58:24.693 
Epoch 658/1000 
	 loss: 5.0232, MinusLogProbMetric: 5.0232, val_loss: 5.1272, val_MinusLogProbMetric: 5.1272

Epoch 658: val_loss did not improve from 5.12594
196/196 - 70s - loss: 5.0232 - MinusLogProbMetric: 5.0232 - val_loss: 5.1272 - val_MinusLogProbMetric: 5.1272 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 659/1000
2023-09-19 05:59:33.965 
Epoch 659/1000 
	 loss: 5.0231, MinusLogProbMetric: 5.0231, val_loss: 5.1261, val_MinusLogProbMetric: 5.1261

Epoch 659: val_loss did not improve from 5.12594
196/196 - 69s - loss: 5.0231 - MinusLogProbMetric: 5.0231 - val_loss: 5.1261 - val_MinusLogProbMetric: 5.1261 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 660/1000
2023-09-19 06:00:44.148 
Epoch 660/1000 
	 loss: 5.0234, MinusLogProbMetric: 5.0234, val_loss: 5.1279, val_MinusLogProbMetric: 5.1279

Epoch 660: val_loss did not improve from 5.12594
196/196 - 70s - loss: 5.0234 - MinusLogProbMetric: 5.0234 - val_loss: 5.1279 - val_MinusLogProbMetric: 5.1279 - lr: 6.2500e-05 - 70s/epoch - 358ms/step
Epoch 661/1000
2023-09-19 06:01:53.769 
Epoch 661/1000 
	 loss: 5.0238, MinusLogProbMetric: 5.0238, val_loss: 5.1306, val_MinusLogProbMetric: 5.1306

Epoch 661: val_loss did not improve from 5.12594
196/196 - 70s - loss: 5.0238 - MinusLogProbMetric: 5.0238 - val_loss: 5.1306 - val_MinusLogProbMetric: 5.1306 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 662/1000
2023-09-19 06:03:03.072 
Epoch 662/1000 
	 loss: 5.0232, MinusLogProbMetric: 5.0232, val_loss: 5.1251, val_MinusLogProbMetric: 5.1251

Epoch 662: val_loss improved from 5.12594 to 5.12505, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 71s - loss: 5.0232 - MinusLogProbMetric: 5.0232 - val_loss: 5.1251 - val_MinusLogProbMetric: 5.1251 - lr: 6.2500e-05 - 71s/epoch - 360ms/step
Epoch 663/1000
2023-09-19 06:04:14.083 
Epoch 663/1000 
	 loss: 5.0227, MinusLogProbMetric: 5.0227, val_loss: 5.1304, val_MinusLogProbMetric: 5.1304

Epoch 663: val_loss did not improve from 5.12505
196/196 - 70s - loss: 5.0227 - MinusLogProbMetric: 5.0227 - val_loss: 5.1304 - val_MinusLogProbMetric: 5.1304 - lr: 6.2500e-05 - 70s/epoch - 356ms/step
Epoch 664/1000
2023-09-19 06:05:24.186 
Epoch 664/1000 
	 loss: 5.0236, MinusLogProbMetric: 5.0236, val_loss: 5.1314, val_MinusLogProbMetric: 5.1314

Epoch 664: val_loss did not improve from 5.12505
196/196 - 70s - loss: 5.0236 - MinusLogProbMetric: 5.0236 - val_loss: 5.1314 - val_MinusLogProbMetric: 5.1314 - lr: 6.2500e-05 - 70s/epoch - 358ms/step
Epoch 665/1000
2023-09-19 06:06:33.824 
Epoch 665/1000 
	 loss: 5.0230, MinusLogProbMetric: 5.0230, val_loss: 5.1289, val_MinusLogProbMetric: 5.1289

Epoch 665: val_loss did not improve from 5.12505
196/196 - 70s - loss: 5.0230 - MinusLogProbMetric: 5.0230 - val_loss: 5.1289 - val_MinusLogProbMetric: 5.1289 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 666/1000
2023-09-19 06:07:43.058 
Epoch 666/1000 
	 loss: 5.0235, MinusLogProbMetric: 5.0235, val_loss: 5.1303, val_MinusLogProbMetric: 5.1303

Epoch 666: val_loss did not improve from 5.12505
196/196 - 69s - loss: 5.0235 - MinusLogProbMetric: 5.0235 - val_loss: 5.1303 - val_MinusLogProbMetric: 5.1303 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 667/1000
2023-09-19 06:08:52.329 
Epoch 667/1000 
	 loss: 5.0235, MinusLogProbMetric: 5.0235, val_loss: 5.1294, val_MinusLogProbMetric: 5.1294

Epoch 667: val_loss did not improve from 5.12505
196/196 - 69s - loss: 5.0235 - MinusLogProbMetric: 5.0235 - val_loss: 5.1294 - val_MinusLogProbMetric: 5.1294 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 668/1000
2023-09-19 06:10:01.804 
Epoch 668/1000 
	 loss: 5.0231, MinusLogProbMetric: 5.0231, val_loss: 5.1266, val_MinusLogProbMetric: 5.1266

Epoch 668: val_loss did not improve from 5.12505
196/196 - 69s - loss: 5.0231 - MinusLogProbMetric: 5.0231 - val_loss: 5.1266 - val_MinusLogProbMetric: 5.1266 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 669/1000
2023-09-19 06:11:11.281 
Epoch 669/1000 
	 loss: 5.0233, MinusLogProbMetric: 5.0233, val_loss: 5.1300, val_MinusLogProbMetric: 5.1300

Epoch 669: val_loss did not improve from 5.12505
196/196 - 69s - loss: 5.0233 - MinusLogProbMetric: 5.0233 - val_loss: 5.1300 - val_MinusLogProbMetric: 5.1300 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 670/1000
2023-09-19 06:12:20.649 
Epoch 670/1000 
	 loss: 5.0235, MinusLogProbMetric: 5.0235, val_loss: 5.1292, val_MinusLogProbMetric: 5.1292

Epoch 670: val_loss did not improve from 5.12505
196/196 - 69s - loss: 5.0235 - MinusLogProbMetric: 5.0235 - val_loss: 5.1292 - val_MinusLogProbMetric: 5.1292 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 671/1000
2023-09-19 06:13:29.772 
Epoch 671/1000 
	 loss: 5.0233, MinusLogProbMetric: 5.0233, val_loss: 5.1304, val_MinusLogProbMetric: 5.1304

Epoch 671: val_loss did not improve from 5.12505
196/196 - 69s - loss: 5.0233 - MinusLogProbMetric: 5.0233 - val_loss: 5.1304 - val_MinusLogProbMetric: 5.1304 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 672/1000
2023-09-19 06:14:39.245 
Epoch 672/1000 
	 loss: 5.0246, MinusLogProbMetric: 5.0246, val_loss: 5.1318, val_MinusLogProbMetric: 5.1318

Epoch 672: val_loss did not improve from 5.12505
196/196 - 69s - loss: 5.0246 - MinusLogProbMetric: 5.0246 - val_loss: 5.1318 - val_MinusLogProbMetric: 5.1318 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 673/1000
2023-09-19 06:15:49.178 
Epoch 673/1000 
	 loss: 5.0239, MinusLogProbMetric: 5.0239, val_loss: 5.1269, val_MinusLogProbMetric: 5.1269

Epoch 673: val_loss did not improve from 5.12505
196/196 - 70s - loss: 5.0239 - MinusLogProbMetric: 5.0239 - val_loss: 5.1269 - val_MinusLogProbMetric: 5.1269 - lr: 6.2500e-05 - 70s/epoch - 357ms/step
Epoch 674/1000
2023-09-19 06:16:58.602 
Epoch 674/1000 
	 loss: 5.0230, MinusLogProbMetric: 5.0230, val_loss: 5.1278, val_MinusLogProbMetric: 5.1278

Epoch 674: val_loss did not improve from 5.12505
196/196 - 69s - loss: 5.0230 - MinusLogProbMetric: 5.0230 - val_loss: 5.1278 - val_MinusLogProbMetric: 5.1278 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 675/1000
2023-09-19 06:18:07.758 
Epoch 675/1000 
	 loss: 5.0228, MinusLogProbMetric: 5.0228, val_loss: 5.1298, val_MinusLogProbMetric: 5.1298

Epoch 675: val_loss did not improve from 5.12505
196/196 - 69s - loss: 5.0228 - MinusLogProbMetric: 5.0228 - val_loss: 5.1298 - val_MinusLogProbMetric: 5.1298 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 676/1000
2023-09-19 06:19:17.337 
Epoch 676/1000 
	 loss: 5.0235, MinusLogProbMetric: 5.0235, val_loss: 5.1311, val_MinusLogProbMetric: 5.1311

Epoch 676: val_loss did not improve from 5.12505
196/196 - 70s - loss: 5.0235 - MinusLogProbMetric: 5.0235 - val_loss: 5.1311 - val_MinusLogProbMetric: 5.1311 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 677/1000
2023-09-19 06:20:27.060 
Epoch 677/1000 
	 loss: 5.0230, MinusLogProbMetric: 5.0230, val_loss: 5.1286, val_MinusLogProbMetric: 5.1286

Epoch 677: val_loss did not improve from 5.12505
196/196 - 70s - loss: 5.0230 - MinusLogProbMetric: 5.0230 - val_loss: 5.1286 - val_MinusLogProbMetric: 5.1286 - lr: 6.2500e-05 - 70s/epoch - 356ms/step
Epoch 678/1000
2023-09-19 06:21:36.537 
Epoch 678/1000 
	 loss: 5.0237, MinusLogProbMetric: 5.0237, val_loss: 5.1273, val_MinusLogProbMetric: 5.1273

Epoch 678: val_loss did not improve from 5.12505
196/196 - 69s - loss: 5.0237 - MinusLogProbMetric: 5.0237 - val_loss: 5.1273 - val_MinusLogProbMetric: 5.1273 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 679/1000
2023-09-19 06:22:46.532 
Epoch 679/1000 
	 loss: 5.0234, MinusLogProbMetric: 5.0234, val_loss: 5.1273, val_MinusLogProbMetric: 5.1273

Epoch 679: val_loss did not improve from 5.12505
196/196 - 70s - loss: 5.0234 - MinusLogProbMetric: 5.0234 - val_loss: 5.1273 - val_MinusLogProbMetric: 5.1273 - lr: 6.2500e-05 - 70s/epoch - 357ms/step
Epoch 680/1000
2023-09-19 06:23:55.986 
Epoch 680/1000 
	 loss: 5.0226, MinusLogProbMetric: 5.0226, val_loss: 5.1285, val_MinusLogProbMetric: 5.1285

Epoch 680: val_loss did not improve from 5.12505
196/196 - 69s - loss: 5.0226 - MinusLogProbMetric: 5.0226 - val_loss: 5.1285 - val_MinusLogProbMetric: 5.1285 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 681/1000
2023-09-19 06:25:06.328 
Epoch 681/1000 
	 loss: 5.0230, MinusLogProbMetric: 5.0230, val_loss: 5.1266, val_MinusLogProbMetric: 5.1266

Epoch 681: val_loss did not improve from 5.12505
196/196 - 70s - loss: 5.0230 - MinusLogProbMetric: 5.0230 - val_loss: 5.1266 - val_MinusLogProbMetric: 5.1266 - lr: 6.2500e-05 - 70s/epoch - 359ms/step
Epoch 682/1000
2023-09-19 06:26:16.480 
Epoch 682/1000 
	 loss: 5.0237, MinusLogProbMetric: 5.0237, val_loss: 5.1281, val_MinusLogProbMetric: 5.1281

Epoch 682: val_loss did not improve from 5.12505
196/196 - 70s - loss: 5.0237 - MinusLogProbMetric: 5.0237 - val_loss: 5.1281 - val_MinusLogProbMetric: 5.1281 - lr: 6.2500e-05 - 70s/epoch - 358ms/step
Epoch 683/1000
2023-09-19 06:27:26.232 
Epoch 683/1000 
	 loss: 5.0226, MinusLogProbMetric: 5.0226, val_loss: 5.1290, val_MinusLogProbMetric: 5.1290

Epoch 683: val_loss did not improve from 5.12505
196/196 - 70s - loss: 5.0226 - MinusLogProbMetric: 5.0226 - val_loss: 5.1290 - val_MinusLogProbMetric: 5.1290 - lr: 6.2500e-05 - 70s/epoch - 356ms/step
Epoch 684/1000
2023-09-19 06:28:36.231 
Epoch 684/1000 
	 loss: 5.0227, MinusLogProbMetric: 5.0227, val_loss: 5.1269, val_MinusLogProbMetric: 5.1269

Epoch 684: val_loss did not improve from 5.12505
196/196 - 70s - loss: 5.0227 - MinusLogProbMetric: 5.0227 - val_loss: 5.1269 - val_MinusLogProbMetric: 5.1269 - lr: 6.2500e-05 - 70s/epoch - 357ms/step
Epoch 685/1000
2023-09-19 06:29:46.065 
Epoch 685/1000 
	 loss: 5.0226, MinusLogProbMetric: 5.0226, val_loss: 5.1330, val_MinusLogProbMetric: 5.1330

Epoch 685: val_loss did not improve from 5.12505
196/196 - 70s - loss: 5.0226 - MinusLogProbMetric: 5.0226 - val_loss: 5.1330 - val_MinusLogProbMetric: 5.1330 - lr: 6.2500e-05 - 70s/epoch - 356ms/step
Epoch 686/1000
2023-09-19 06:30:55.645 
Epoch 686/1000 
	 loss: 5.0235, MinusLogProbMetric: 5.0235, val_loss: 5.1295, val_MinusLogProbMetric: 5.1295

Epoch 686: val_loss did not improve from 5.12505
196/196 - 70s - loss: 5.0235 - MinusLogProbMetric: 5.0235 - val_loss: 5.1295 - val_MinusLogProbMetric: 5.1295 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 687/1000
2023-09-19 06:31:52.041 
Epoch 687/1000 
	 loss: 5.0228, MinusLogProbMetric: 5.0228, val_loss: 5.1306, val_MinusLogProbMetric: 5.1306

Epoch 687: val_loss did not improve from 5.12505
196/196 - 56s - loss: 5.0228 - MinusLogProbMetric: 5.0228 - val_loss: 5.1306 - val_MinusLogProbMetric: 5.1306 - lr: 6.2500e-05 - 56s/epoch - 288ms/step
Epoch 688/1000
2023-09-19 06:32:50.824 
Epoch 688/1000 
	 loss: 5.0232, MinusLogProbMetric: 5.0232, val_loss: 5.1279, val_MinusLogProbMetric: 5.1279

Epoch 688: val_loss did not improve from 5.12505
196/196 - 59s - loss: 5.0232 - MinusLogProbMetric: 5.0232 - val_loss: 5.1279 - val_MinusLogProbMetric: 5.1279 - lr: 6.2500e-05 - 59s/epoch - 300ms/step
Epoch 689/1000
2023-09-19 06:33:46.442 
Epoch 689/1000 
	 loss: 5.0229, MinusLogProbMetric: 5.0229, val_loss: 5.1287, val_MinusLogProbMetric: 5.1287

Epoch 689: val_loss did not improve from 5.12505
196/196 - 56s - loss: 5.0229 - MinusLogProbMetric: 5.0229 - val_loss: 5.1287 - val_MinusLogProbMetric: 5.1287 - lr: 6.2500e-05 - 56s/epoch - 284ms/step
Epoch 690/1000
2023-09-19 06:34:45.633 
Epoch 690/1000 
	 loss: 5.0240, MinusLogProbMetric: 5.0240, val_loss: 5.1285, val_MinusLogProbMetric: 5.1285

Epoch 690: val_loss did not improve from 5.12505
196/196 - 59s - loss: 5.0240 - MinusLogProbMetric: 5.0240 - val_loss: 5.1285 - val_MinusLogProbMetric: 5.1285 - lr: 6.2500e-05 - 59s/epoch - 302ms/step
Epoch 691/1000
2023-09-19 06:35:54.111 
Epoch 691/1000 
	 loss: 5.0231, MinusLogProbMetric: 5.0231, val_loss: 5.1290, val_MinusLogProbMetric: 5.1290

Epoch 691: val_loss did not improve from 5.12505
196/196 - 68s - loss: 5.0231 - MinusLogProbMetric: 5.0231 - val_loss: 5.1290 - val_MinusLogProbMetric: 5.1290 - lr: 6.2500e-05 - 68s/epoch - 349ms/step
Epoch 692/1000
2023-09-19 06:36:59.742 
Epoch 692/1000 
	 loss: 5.0232, MinusLogProbMetric: 5.0232, val_loss: 5.1310, val_MinusLogProbMetric: 5.1310

Epoch 692: val_loss did not improve from 5.12505
196/196 - 66s - loss: 5.0232 - MinusLogProbMetric: 5.0232 - val_loss: 5.1310 - val_MinusLogProbMetric: 5.1310 - lr: 6.2500e-05 - 66s/epoch - 335ms/step
Epoch 693/1000
2023-09-19 06:37:59.835 
Epoch 693/1000 
	 loss: 5.0226, MinusLogProbMetric: 5.0226, val_loss: 5.1287, val_MinusLogProbMetric: 5.1287

Epoch 693: val_loss did not improve from 5.12505
196/196 - 60s - loss: 5.0226 - MinusLogProbMetric: 5.0226 - val_loss: 5.1287 - val_MinusLogProbMetric: 5.1287 - lr: 6.2500e-05 - 60s/epoch - 307ms/step
Epoch 694/1000
2023-09-19 06:38:57.825 
Epoch 694/1000 
	 loss: 5.0227, MinusLogProbMetric: 5.0227, val_loss: 5.1294, val_MinusLogProbMetric: 5.1294

Epoch 694: val_loss did not improve from 5.12505
196/196 - 58s - loss: 5.0227 - MinusLogProbMetric: 5.0227 - val_loss: 5.1294 - val_MinusLogProbMetric: 5.1294 - lr: 6.2500e-05 - 58s/epoch - 296ms/step
Epoch 695/1000
2023-09-19 06:40:00.324 
Epoch 695/1000 
	 loss: 5.0233, MinusLogProbMetric: 5.0233, val_loss: 5.1273, val_MinusLogProbMetric: 5.1273

Epoch 695: val_loss did not improve from 5.12505
196/196 - 62s - loss: 5.0233 - MinusLogProbMetric: 5.0233 - val_loss: 5.1273 - val_MinusLogProbMetric: 5.1273 - lr: 6.2500e-05 - 62s/epoch - 319ms/step
Epoch 696/1000
2023-09-19 06:41:10.194 
Epoch 696/1000 
	 loss: 5.0235, MinusLogProbMetric: 5.0235, val_loss: 5.1262, val_MinusLogProbMetric: 5.1262

Epoch 696: val_loss did not improve from 5.12505
196/196 - 70s - loss: 5.0235 - MinusLogProbMetric: 5.0235 - val_loss: 5.1262 - val_MinusLogProbMetric: 5.1262 - lr: 6.2500e-05 - 70s/epoch - 356ms/step
Epoch 697/1000
2023-09-19 06:42:19.023 
Epoch 697/1000 
	 loss: 5.0235, MinusLogProbMetric: 5.0235, val_loss: 5.1336, val_MinusLogProbMetric: 5.1336

Epoch 697: val_loss did not improve from 5.12505
196/196 - 69s - loss: 5.0235 - MinusLogProbMetric: 5.0235 - val_loss: 5.1336 - val_MinusLogProbMetric: 5.1336 - lr: 6.2500e-05 - 69s/epoch - 351ms/step
Epoch 698/1000
2023-09-19 06:43:28.835 
Epoch 698/1000 
	 loss: 5.0235, MinusLogProbMetric: 5.0235, val_loss: 5.1292, val_MinusLogProbMetric: 5.1292

Epoch 698: val_loss did not improve from 5.12505
196/196 - 70s - loss: 5.0235 - MinusLogProbMetric: 5.0235 - val_loss: 5.1292 - val_MinusLogProbMetric: 5.1292 - lr: 6.2500e-05 - 70s/epoch - 356ms/step
Epoch 699/1000
2023-09-19 06:44:38.326 
Epoch 699/1000 
	 loss: 5.0227, MinusLogProbMetric: 5.0227, val_loss: 5.1270, val_MinusLogProbMetric: 5.1270

Epoch 699: val_loss did not improve from 5.12505
196/196 - 69s - loss: 5.0227 - MinusLogProbMetric: 5.0227 - val_loss: 5.1270 - val_MinusLogProbMetric: 5.1270 - lr: 6.2500e-05 - 69s/epoch - 355ms/step
Epoch 700/1000
2023-09-19 06:45:47.601 
Epoch 700/1000 
	 loss: 5.0230, MinusLogProbMetric: 5.0230, val_loss: 5.1269, val_MinusLogProbMetric: 5.1269

Epoch 700: val_loss did not improve from 5.12505
196/196 - 69s - loss: 5.0230 - MinusLogProbMetric: 5.0230 - val_loss: 5.1269 - val_MinusLogProbMetric: 5.1269 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 701/1000
2023-09-19 06:46:56.302 
Epoch 701/1000 
	 loss: 5.0225, MinusLogProbMetric: 5.0225, val_loss: 5.1276, val_MinusLogProbMetric: 5.1276

Epoch 701: val_loss did not improve from 5.12505
196/196 - 69s - loss: 5.0225 - MinusLogProbMetric: 5.0225 - val_loss: 5.1276 - val_MinusLogProbMetric: 5.1276 - lr: 6.2500e-05 - 69s/epoch - 350ms/step
Epoch 702/1000
2023-09-19 06:48:05.551 
Epoch 702/1000 
	 loss: 5.0230, MinusLogProbMetric: 5.0230, val_loss: 5.1286, val_MinusLogProbMetric: 5.1286

Epoch 702: val_loss did not improve from 5.12505
196/196 - 69s - loss: 5.0230 - MinusLogProbMetric: 5.0230 - val_loss: 5.1286 - val_MinusLogProbMetric: 5.1286 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 703/1000
2023-09-19 06:49:15.071 
Epoch 703/1000 
	 loss: 5.0227, MinusLogProbMetric: 5.0227, val_loss: 5.1271, val_MinusLogProbMetric: 5.1271

Epoch 703: val_loss did not improve from 5.12505
196/196 - 70s - loss: 5.0227 - MinusLogProbMetric: 5.0227 - val_loss: 5.1271 - val_MinusLogProbMetric: 5.1271 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 704/1000
2023-09-19 06:50:24.522 
Epoch 704/1000 
	 loss: 5.0225, MinusLogProbMetric: 5.0225, val_loss: 5.1281, val_MinusLogProbMetric: 5.1281

Epoch 704: val_loss did not improve from 5.12505
196/196 - 69s - loss: 5.0225 - MinusLogProbMetric: 5.0225 - val_loss: 5.1281 - val_MinusLogProbMetric: 5.1281 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 705/1000
2023-09-19 06:51:34.179 
Epoch 705/1000 
	 loss: 5.0229, MinusLogProbMetric: 5.0229, val_loss: 5.1324, val_MinusLogProbMetric: 5.1324

Epoch 705: val_loss did not improve from 5.12505
196/196 - 70s - loss: 5.0229 - MinusLogProbMetric: 5.0229 - val_loss: 5.1324 - val_MinusLogProbMetric: 5.1324 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 706/1000
2023-09-19 06:52:43.731 
Epoch 706/1000 
	 loss: 5.0233, MinusLogProbMetric: 5.0233, val_loss: 5.1251, val_MinusLogProbMetric: 5.1251

Epoch 706: val_loss did not improve from 5.12505
196/196 - 70s - loss: 5.0233 - MinusLogProbMetric: 5.0233 - val_loss: 5.1251 - val_MinusLogProbMetric: 5.1251 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 707/1000
2023-09-19 06:53:53.391 
Epoch 707/1000 
	 loss: 5.0222, MinusLogProbMetric: 5.0222, val_loss: 5.1277, val_MinusLogProbMetric: 5.1277

Epoch 707: val_loss did not improve from 5.12505
196/196 - 70s - loss: 5.0222 - MinusLogProbMetric: 5.0222 - val_loss: 5.1277 - val_MinusLogProbMetric: 5.1277 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 708/1000
2023-09-19 06:55:02.936 
Epoch 708/1000 
	 loss: 5.0228, MinusLogProbMetric: 5.0228, val_loss: 5.1294, val_MinusLogProbMetric: 5.1294

Epoch 708: val_loss did not improve from 5.12505
196/196 - 70s - loss: 5.0228 - MinusLogProbMetric: 5.0228 - val_loss: 5.1294 - val_MinusLogProbMetric: 5.1294 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 709/1000
2023-09-19 06:56:12.335 
Epoch 709/1000 
	 loss: 5.0225, MinusLogProbMetric: 5.0225, val_loss: 5.1317, val_MinusLogProbMetric: 5.1317

Epoch 709: val_loss did not improve from 5.12505
196/196 - 69s - loss: 5.0225 - MinusLogProbMetric: 5.0225 - val_loss: 5.1317 - val_MinusLogProbMetric: 5.1317 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 710/1000
2023-09-19 06:57:21.651 
Epoch 710/1000 
	 loss: 5.0225, MinusLogProbMetric: 5.0225, val_loss: 5.1316, val_MinusLogProbMetric: 5.1316

Epoch 710: val_loss did not improve from 5.12505
196/196 - 69s - loss: 5.0225 - MinusLogProbMetric: 5.0225 - val_loss: 5.1316 - val_MinusLogProbMetric: 5.1316 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 711/1000
2023-09-19 06:58:31.009 
Epoch 711/1000 
	 loss: 5.0226, MinusLogProbMetric: 5.0226, val_loss: 5.1249, val_MinusLogProbMetric: 5.1249

Epoch 711: val_loss improved from 5.12505 to 5.12494, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 71s - loss: 5.0226 - MinusLogProbMetric: 5.0226 - val_loss: 5.1249 - val_MinusLogProbMetric: 5.1249 - lr: 6.2500e-05 - 71s/epoch - 361ms/step
Epoch 712/1000
2023-09-19 06:59:41.505 
Epoch 712/1000 
	 loss: 5.0222, MinusLogProbMetric: 5.0222, val_loss: 5.1286, val_MinusLogProbMetric: 5.1286

Epoch 712: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0222 - MinusLogProbMetric: 5.0222 - val_loss: 5.1286 - val_MinusLogProbMetric: 5.1286 - lr: 6.2500e-05 - 69s/epoch - 352ms/step
Epoch 713/1000
2023-09-19 07:00:50.849 
Epoch 713/1000 
	 loss: 5.0226, MinusLogProbMetric: 5.0226, val_loss: 5.1300, val_MinusLogProbMetric: 5.1300

Epoch 713: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0226 - MinusLogProbMetric: 5.0226 - val_loss: 5.1300 - val_MinusLogProbMetric: 5.1300 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 714/1000
2023-09-19 07:02:00.424 
Epoch 714/1000 
	 loss: 5.0226, MinusLogProbMetric: 5.0226, val_loss: 5.1309, val_MinusLogProbMetric: 5.1309

Epoch 714: val_loss did not improve from 5.12494
196/196 - 70s - loss: 5.0226 - MinusLogProbMetric: 5.0226 - val_loss: 5.1309 - val_MinusLogProbMetric: 5.1309 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 715/1000
2023-09-19 07:03:09.453 
Epoch 715/1000 
	 loss: 5.0222, MinusLogProbMetric: 5.0222, val_loss: 5.1263, val_MinusLogProbMetric: 5.1263

Epoch 715: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0222 - MinusLogProbMetric: 5.0222 - val_loss: 5.1263 - val_MinusLogProbMetric: 5.1263 - lr: 6.2500e-05 - 69s/epoch - 352ms/step
Epoch 716/1000
2023-09-19 07:04:18.712 
Epoch 716/1000 
	 loss: 5.0228, MinusLogProbMetric: 5.0228, val_loss: 5.1297, val_MinusLogProbMetric: 5.1297

Epoch 716: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0228 - MinusLogProbMetric: 5.0228 - val_loss: 5.1297 - val_MinusLogProbMetric: 5.1297 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 717/1000
2023-09-19 07:05:27.471 
Epoch 717/1000 
	 loss: 5.0223, MinusLogProbMetric: 5.0223, val_loss: 5.1268, val_MinusLogProbMetric: 5.1268

Epoch 717: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0223 - MinusLogProbMetric: 5.0223 - val_loss: 5.1268 - val_MinusLogProbMetric: 5.1268 - lr: 6.2500e-05 - 69s/epoch - 351ms/step
Epoch 718/1000
2023-09-19 07:06:36.858 
Epoch 718/1000 
	 loss: 5.0225, MinusLogProbMetric: 5.0225, val_loss: 5.1295, val_MinusLogProbMetric: 5.1295

Epoch 718: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0225 - MinusLogProbMetric: 5.0225 - val_loss: 5.1295 - val_MinusLogProbMetric: 5.1295 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 719/1000
2023-09-19 07:07:46.302 
Epoch 719/1000 
	 loss: 5.0224, MinusLogProbMetric: 5.0224, val_loss: 5.1265, val_MinusLogProbMetric: 5.1265

Epoch 719: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0224 - MinusLogProbMetric: 5.0224 - val_loss: 5.1265 - val_MinusLogProbMetric: 5.1265 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 720/1000
2023-09-19 07:08:55.937 
Epoch 720/1000 
	 loss: 5.0229, MinusLogProbMetric: 5.0229, val_loss: 5.1314, val_MinusLogProbMetric: 5.1314

Epoch 720: val_loss did not improve from 5.12494
196/196 - 70s - loss: 5.0229 - MinusLogProbMetric: 5.0229 - val_loss: 5.1314 - val_MinusLogProbMetric: 5.1314 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 721/1000
2023-09-19 07:10:05.332 
Epoch 721/1000 
	 loss: 5.0224, MinusLogProbMetric: 5.0224, val_loss: 5.1288, val_MinusLogProbMetric: 5.1288

Epoch 721: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0224 - MinusLogProbMetric: 5.0224 - val_loss: 5.1288 - val_MinusLogProbMetric: 5.1288 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 722/1000
2023-09-19 07:11:14.735 
Epoch 722/1000 
	 loss: 5.0221, MinusLogProbMetric: 5.0221, val_loss: 5.1289, val_MinusLogProbMetric: 5.1289

Epoch 722: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0221 - MinusLogProbMetric: 5.0221 - val_loss: 5.1289 - val_MinusLogProbMetric: 5.1289 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 723/1000
2023-09-19 07:12:23.948 
Epoch 723/1000 
	 loss: 5.0219, MinusLogProbMetric: 5.0219, val_loss: 5.1267, val_MinusLogProbMetric: 5.1267

Epoch 723: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0219 - MinusLogProbMetric: 5.0219 - val_loss: 5.1267 - val_MinusLogProbMetric: 5.1267 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 724/1000
2023-09-19 07:13:33.359 
Epoch 724/1000 
	 loss: 5.0222, MinusLogProbMetric: 5.0222, val_loss: 5.1296, val_MinusLogProbMetric: 5.1296

Epoch 724: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0222 - MinusLogProbMetric: 5.0222 - val_loss: 5.1296 - val_MinusLogProbMetric: 5.1296 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 725/1000
2023-09-19 07:14:42.513 
Epoch 725/1000 
	 loss: 5.0225, MinusLogProbMetric: 5.0225, val_loss: 5.1258, val_MinusLogProbMetric: 5.1258

Epoch 725: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0225 - MinusLogProbMetric: 5.0225 - val_loss: 5.1258 - val_MinusLogProbMetric: 5.1258 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 726/1000
2023-09-19 07:15:52.420 
Epoch 726/1000 
	 loss: 5.0229, MinusLogProbMetric: 5.0229, val_loss: 5.1317, val_MinusLogProbMetric: 5.1317

Epoch 726: val_loss did not improve from 5.12494
196/196 - 70s - loss: 5.0229 - MinusLogProbMetric: 5.0229 - val_loss: 5.1317 - val_MinusLogProbMetric: 5.1317 - lr: 6.2500e-05 - 70s/epoch - 357ms/step
Epoch 727/1000
2023-09-19 07:17:01.943 
Epoch 727/1000 
	 loss: 5.0226, MinusLogProbMetric: 5.0226, val_loss: 5.1279, val_MinusLogProbMetric: 5.1279

Epoch 727: val_loss did not improve from 5.12494
196/196 - 70s - loss: 5.0226 - MinusLogProbMetric: 5.0226 - val_loss: 5.1279 - val_MinusLogProbMetric: 5.1279 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 728/1000
2023-09-19 07:18:10.963 
Epoch 728/1000 
	 loss: 5.0223, MinusLogProbMetric: 5.0223, val_loss: 5.1266, val_MinusLogProbMetric: 5.1266

Epoch 728: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0223 - MinusLogProbMetric: 5.0223 - val_loss: 5.1266 - val_MinusLogProbMetric: 5.1266 - lr: 6.2500e-05 - 69s/epoch - 352ms/step
Epoch 729/1000
2023-09-19 07:19:20.006 
Epoch 729/1000 
	 loss: 5.0220, MinusLogProbMetric: 5.0220, val_loss: 5.1269, val_MinusLogProbMetric: 5.1269

Epoch 729: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0220 - MinusLogProbMetric: 5.0220 - val_loss: 5.1269 - val_MinusLogProbMetric: 5.1269 - lr: 6.2500e-05 - 69s/epoch - 352ms/step
Epoch 730/1000
2023-09-19 07:20:29.344 
Epoch 730/1000 
	 loss: 5.0227, MinusLogProbMetric: 5.0227, val_loss: 5.1287, val_MinusLogProbMetric: 5.1287

Epoch 730: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0227 - MinusLogProbMetric: 5.0227 - val_loss: 5.1287 - val_MinusLogProbMetric: 5.1287 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 731/1000
2023-09-19 07:21:38.285 
Epoch 731/1000 
	 loss: 5.0229, MinusLogProbMetric: 5.0229, val_loss: 5.1258, val_MinusLogProbMetric: 5.1258

Epoch 731: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0229 - MinusLogProbMetric: 5.0229 - val_loss: 5.1258 - val_MinusLogProbMetric: 5.1258 - lr: 6.2500e-05 - 69s/epoch - 352ms/step
Epoch 732/1000
2023-09-19 07:22:47.570 
Epoch 732/1000 
	 loss: 5.0218, MinusLogProbMetric: 5.0218, val_loss: 5.1330, val_MinusLogProbMetric: 5.1330

Epoch 732: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0218 - MinusLogProbMetric: 5.0218 - val_loss: 5.1330 - val_MinusLogProbMetric: 5.1330 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 733/1000
2023-09-19 07:23:56.666 
Epoch 733/1000 
	 loss: 5.0235, MinusLogProbMetric: 5.0235, val_loss: 5.1274, val_MinusLogProbMetric: 5.1274

Epoch 733: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0235 - MinusLogProbMetric: 5.0235 - val_loss: 5.1274 - val_MinusLogProbMetric: 5.1274 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 734/1000
2023-09-19 07:25:05.794 
Epoch 734/1000 
	 loss: 5.0225, MinusLogProbMetric: 5.0225, val_loss: 5.1301, val_MinusLogProbMetric: 5.1301

Epoch 734: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0225 - MinusLogProbMetric: 5.0225 - val_loss: 5.1301 - val_MinusLogProbMetric: 5.1301 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 735/1000
2023-09-19 07:26:15.421 
Epoch 735/1000 
	 loss: 5.0219, MinusLogProbMetric: 5.0219, val_loss: 5.1272, val_MinusLogProbMetric: 5.1272

Epoch 735: val_loss did not improve from 5.12494
196/196 - 70s - loss: 5.0219 - MinusLogProbMetric: 5.0219 - val_loss: 5.1272 - val_MinusLogProbMetric: 5.1272 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 736/1000
2023-09-19 07:27:24.536 
Epoch 736/1000 
	 loss: 5.0220, MinusLogProbMetric: 5.0220, val_loss: 5.1253, val_MinusLogProbMetric: 5.1253

Epoch 736: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0220 - MinusLogProbMetric: 5.0220 - val_loss: 5.1253 - val_MinusLogProbMetric: 5.1253 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 737/1000
2023-09-19 07:28:33.492 
Epoch 737/1000 
	 loss: 5.0217, MinusLogProbMetric: 5.0217, val_loss: 5.1263, val_MinusLogProbMetric: 5.1263

Epoch 737: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0217 - MinusLogProbMetric: 5.0217 - val_loss: 5.1263 - val_MinusLogProbMetric: 5.1263 - lr: 6.2500e-05 - 69s/epoch - 352ms/step
Epoch 738/1000
2023-09-19 07:29:43.193 
Epoch 738/1000 
	 loss: 5.0222, MinusLogProbMetric: 5.0222, val_loss: 5.1250, val_MinusLogProbMetric: 5.1250

Epoch 738: val_loss did not improve from 5.12494
196/196 - 70s - loss: 5.0222 - MinusLogProbMetric: 5.0222 - val_loss: 5.1250 - val_MinusLogProbMetric: 5.1250 - lr: 6.2500e-05 - 70s/epoch - 356ms/step
Epoch 739/1000
2023-09-19 07:30:52.253 
Epoch 739/1000 
	 loss: 5.0219, MinusLogProbMetric: 5.0219, val_loss: 5.1301, val_MinusLogProbMetric: 5.1301

Epoch 739: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0219 - MinusLogProbMetric: 5.0219 - val_loss: 5.1301 - val_MinusLogProbMetric: 5.1301 - lr: 6.2500e-05 - 69s/epoch - 352ms/step
Epoch 740/1000
2023-09-19 07:32:01.162 
Epoch 740/1000 
	 loss: 5.0217, MinusLogProbMetric: 5.0217, val_loss: 5.1352, val_MinusLogProbMetric: 5.1352

Epoch 740: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0217 - MinusLogProbMetric: 5.0217 - val_loss: 5.1352 - val_MinusLogProbMetric: 5.1352 - lr: 6.2500e-05 - 69s/epoch - 352ms/step
Epoch 741/1000
2023-09-19 07:33:11.129 
Epoch 741/1000 
	 loss: 5.0220, MinusLogProbMetric: 5.0220, val_loss: 5.1281, val_MinusLogProbMetric: 5.1281

Epoch 741: val_loss did not improve from 5.12494
196/196 - 70s - loss: 5.0220 - MinusLogProbMetric: 5.0220 - val_loss: 5.1281 - val_MinusLogProbMetric: 5.1281 - lr: 6.2500e-05 - 70s/epoch - 357ms/step
Epoch 742/1000
2023-09-19 07:34:20.313 
Epoch 742/1000 
	 loss: 5.0220, MinusLogProbMetric: 5.0220, val_loss: 5.1267, val_MinusLogProbMetric: 5.1267

Epoch 742: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0220 - MinusLogProbMetric: 5.0220 - val_loss: 5.1267 - val_MinusLogProbMetric: 5.1267 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 743/1000
2023-09-19 07:35:29.306 
Epoch 743/1000 
	 loss: 5.0224, MinusLogProbMetric: 5.0224, val_loss: 5.1253, val_MinusLogProbMetric: 5.1253

Epoch 743: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0224 - MinusLogProbMetric: 5.0224 - val_loss: 5.1253 - val_MinusLogProbMetric: 5.1253 - lr: 6.2500e-05 - 69s/epoch - 352ms/step
Epoch 744/1000
2023-09-19 07:36:38.897 
Epoch 744/1000 
	 loss: 5.0217, MinusLogProbMetric: 5.0217, val_loss: 5.1313, val_MinusLogProbMetric: 5.1313

Epoch 744: val_loss did not improve from 5.12494
196/196 - 70s - loss: 5.0217 - MinusLogProbMetric: 5.0217 - val_loss: 5.1313 - val_MinusLogProbMetric: 5.1313 - lr: 6.2500e-05 - 70s/epoch - 355ms/step
Epoch 745/1000
2023-09-19 07:37:48.152 
Epoch 745/1000 
	 loss: 5.0218, MinusLogProbMetric: 5.0218, val_loss: 5.1272, val_MinusLogProbMetric: 5.1272

Epoch 745: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0218 - MinusLogProbMetric: 5.0218 - val_loss: 5.1272 - val_MinusLogProbMetric: 5.1272 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 746/1000
2023-09-19 07:38:51.258 
Epoch 746/1000 
	 loss: 5.0219, MinusLogProbMetric: 5.0219, val_loss: 5.1276, val_MinusLogProbMetric: 5.1276

Epoch 746: val_loss did not improve from 5.12494
196/196 - 63s - loss: 5.0219 - MinusLogProbMetric: 5.0219 - val_loss: 5.1276 - val_MinusLogProbMetric: 5.1276 - lr: 6.2500e-05 - 63s/epoch - 322ms/step
Epoch 747/1000
2023-09-19 07:39:48.879 
Epoch 747/1000 
	 loss: 5.0227, MinusLogProbMetric: 5.0227, val_loss: 5.1270, val_MinusLogProbMetric: 5.1270

Epoch 747: val_loss did not improve from 5.12494
196/196 - 58s - loss: 5.0227 - MinusLogProbMetric: 5.0227 - val_loss: 5.1270 - val_MinusLogProbMetric: 5.1270 - lr: 6.2500e-05 - 58s/epoch - 294ms/step
Epoch 748/1000
2023-09-19 07:40:44.908 
Epoch 748/1000 
	 loss: 5.0220, MinusLogProbMetric: 5.0220, val_loss: 5.1290, val_MinusLogProbMetric: 5.1290

Epoch 748: val_loss did not improve from 5.12494
196/196 - 56s - loss: 5.0220 - MinusLogProbMetric: 5.0220 - val_loss: 5.1290 - val_MinusLogProbMetric: 5.1290 - lr: 6.2500e-05 - 56s/epoch - 286ms/step
Epoch 749/1000
2023-09-19 07:41:53.080 
Epoch 749/1000 
	 loss: 5.0220, MinusLogProbMetric: 5.0220, val_loss: 5.1307, val_MinusLogProbMetric: 5.1307

Epoch 749: val_loss did not improve from 5.12494
196/196 - 68s - loss: 5.0220 - MinusLogProbMetric: 5.0220 - val_loss: 5.1307 - val_MinusLogProbMetric: 5.1307 - lr: 6.2500e-05 - 68s/epoch - 348ms/step
Epoch 750/1000
2023-09-19 07:43:01.573 
Epoch 750/1000 
	 loss: 5.0220, MinusLogProbMetric: 5.0220, val_loss: 5.1288, val_MinusLogProbMetric: 5.1288

Epoch 750: val_loss did not improve from 5.12494
196/196 - 68s - loss: 5.0220 - MinusLogProbMetric: 5.0220 - val_loss: 5.1288 - val_MinusLogProbMetric: 5.1288 - lr: 6.2500e-05 - 68s/epoch - 349ms/step
Epoch 751/1000
2023-09-19 07:44:10.536 
Epoch 751/1000 
	 loss: 5.0209, MinusLogProbMetric: 5.0209, val_loss: 5.1277, val_MinusLogProbMetric: 5.1277

Epoch 751: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0209 - MinusLogProbMetric: 5.0209 - val_loss: 5.1277 - val_MinusLogProbMetric: 5.1277 - lr: 6.2500e-05 - 69s/epoch - 352ms/step
Epoch 752/1000
2023-09-19 07:45:19.514 
Epoch 752/1000 
	 loss: 5.0213, MinusLogProbMetric: 5.0213, val_loss: 5.1302, val_MinusLogProbMetric: 5.1302

Epoch 752: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0213 - MinusLogProbMetric: 5.0213 - val_loss: 5.1302 - val_MinusLogProbMetric: 5.1302 - lr: 6.2500e-05 - 69s/epoch - 352ms/step
Epoch 753/1000
2023-09-19 07:46:28.339 
Epoch 753/1000 
	 loss: 5.0222, MinusLogProbMetric: 5.0222, val_loss: 5.1272, val_MinusLogProbMetric: 5.1272

Epoch 753: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0222 - MinusLogProbMetric: 5.0222 - val_loss: 5.1272 - val_MinusLogProbMetric: 5.1272 - lr: 6.2500e-05 - 69s/epoch - 351ms/step
Epoch 754/1000
2023-09-19 07:47:37.321 
Epoch 754/1000 
	 loss: 5.0221, MinusLogProbMetric: 5.0221, val_loss: 5.1278, val_MinusLogProbMetric: 5.1278

Epoch 754: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0221 - MinusLogProbMetric: 5.0221 - val_loss: 5.1278 - val_MinusLogProbMetric: 5.1278 - lr: 6.2500e-05 - 69s/epoch - 352ms/step
Epoch 755/1000
2023-09-19 07:48:46.039 
Epoch 755/1000 
	 loss: 5.0213, MinusLogProbMetric: 5.0213, val_loss: 5.1316, val_MinusLogProbMetric: 5.1316

Epoch 755: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0213 - MinusLogProbMetric: 5.0213 - val_loss: 5.1316 - val_MinusLogProbMetric: 5.1316 - lr: 6.2500e-05 - 69s/epoch - 351ms/step
Epoch 756/1000
2023-09-19 07:49:55.404 
Epoch 756/1000 
	 loss: 5.0219, MinusLogProbMetric: 5.0219, val_loss: 5.1273, val_MinusLogProbMetric: 5.1273

Epoch 756: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0219 - MinusLogProbMetric: 5.0219 - val_loss: 5.1273 - val_MinusLogProbMetric: 5.1273 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 757/1000
2023-09-19 07:51:04.561 
Epoch 757/1000 
	 loss: 5.0212, MinusLogProbMetric: 5.0212, val_loss: 5.1290, val_MinusLogProbMetric: 5.1290

Epoch 757: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0212 - MinusLogProbMetric: 5.0212 - val_loss: 5.1290 - val_MinusLogProbMetric: 5.1290 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 758/1000
2023-09-19 07:52:13.409 
Epoch 758/1000 
	 loss: 5.0215, MinusLogProbMetric: 5.0215, val_loss: 5.1266, val_MinusLogProbMetric: 5.1266

Epoch 758: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0215 - MinusLogProbMetric: 5.0215 - val_loss: 5.1266 - val_MinusLogProbMetric: 5.1266 - lr: 6.2500e-05 - 69s/epoch - 351ms/step
Epoch 759/1000
2023-09-19 07:53:23.117 
Epoch 759/1000 
	 loss: 5.0215, MinusLogProbMetric: 5.0215, val_loss: 5.1259, val_MinusLogProbMetric: 5.1259

Epoch 759: val_loss did not improve from 5.12494
196/196 - 70s - loss: 5.0215 - MinusLogProbMetric: 5.0215 - val_loss: 5.1259 - val_MinusLogProbMetric: 5.1259 - lr: 6.2500e-05 - 70s/epoch - 356ms/step
Epoch 760/1000
2023-09-19 07:54:32.546 
Epoch 760/1000 
	 loss: 5.0217, MinusLogProbMetric: 5.0217, val_loss: 5.1264, val_MinusLogProbMetric: 5.1264

Epoch 760: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0217 - MinusLogProbMetric: 5.0217 - val_loss: 5.1264 - val_MinusLogProbMetric: 5.1264 - lr: 6.2500e-05 - 69s/epoch - 354ms/step
Epoch 761/1000
2023-09-19 07:55:41.795 
Epoch 761/1000 
	 loss: 5.0229, MinusLogProbMetric: 5.0229, val_loss: 5.1259, val_MinusLogProbMetric: 5.1259

Epoch 761: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0229 - MinusLogProbMetric: 5.0229 - val_loss: 5.1259 - val_MinusLogProbMetric: 5.1259 - lr: 6.2500e-05 - 69s/epoch - 353ms/step
Epoch 762/1000
2023-09-19 07:56:51.246 
Epoch 762/1000 
	 loss: 5.0183, MinusLogProbMetric: 5.0183, val_loss: 5.1262, val_MinusLogProbMetric: 5.1262

Epoch 762: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0183 - MinusLogProbMetric: 5.0183 - val_loss: 5.1262 - val_MinusLogProbMetric: 5.1262 - lr: 3.1250e-05 - 69s/epoch - 354ms/step
Epoch 763/1000
2023-09-19 07:58:00.389 
Epoch 763/1000 
	 loss: 5.0185, MinusLogProbMetric: 5.0185, val_loss: 5.1256, val_MinusLogProbMetric: 5.1256

Epoch 763: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0185 - MinusLogProbMetric: 5.0185 - val_loss: 5.1256 - val_MinusLogProbMetric: 5.1256 - lr: 3.1250e-05 - 69s/epoch - 353ms/step
Epoch 764/1000
2023-09-19 07:59:09.776 
Epoch 764/1000 
	 loss: 5.0181, MinusLogProbMetric: 5.0181, val_loss: 5.1287, val_MinusLogProbMetric: 5.1287

Epoch 764: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0181 - MinusLogProbMetric: 5.0181 - val_loss: 5.1287 - val_MinusLogProbMetric: 5.1287 - lr: 3.1250e-05 - 69s/epoch - 354ms/step
Epoch 765/1000
2023-09-19 08:00:18.600 
Epoch 765/1000 
	 loss: 5.0184, MinusLogProbMetric: 5.0184, val_loss: 5.1250, val_MinusLogProbMetric: 5.1250

Epoch 765: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0184 - MinusLogProbMetric: 5.0184 - val_loss: 5.1250 - val_MinusLogProbMetric: 5.1250 - lr: 3.1250e-05 - 69s/epoch - 351ms/step
Epoch 766/1000
2023-09-19 08:01:27.996 
Epoch 766/1000 
	 loss: 5.0187, MinusLogProbMetric: 5.0187, val_loss: 5.1259, val_MinusLogProbMetric: 5.1259

Epoch 766: val_loss did not improve from 5.12494
196/196 - 69s - loss: 5.0187 - MinusLogProbMetric: 5.0187 - val_loss: 5.1259 - val_MinusLogProbMetric: 5.1259 - lr: 3.1250e-05 - 69s/epoch - 354ms/step
Epoch 767/1000
2023-09-19 08:02:35.637 
Epoch 767/1000 
	 loss: 5.0184, MinusLogProbMetric: 5.0184, val_loss: 5.1246, val_MinusLogProbMetric: 5.1246

Epoch 767: val_loss improved from 5.12494 to 5.12462, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 69s - loss: 5.0184 - MinusLogProbMetric: 5.0184 - val_loss: 5.1246 - val_MinusLogProbMetric: 5.1246 - lr: 3.1250e-05 - 69s/epoch - 351ms/step
Epoch 768/1000
2023-09-19 08:03:36.443 
Epoch 768/1000 
	 loss: 5.0185, MinusLogProbMetric: 5.0185, val_loss: 5.1264, val_MinusLogProbMetric: 5.1264

Epoch 768: val_loss did not improve from 5.12462
196/196 - 60s - loss: 5.0185 - MinusLogProbMetric: 5.0185 - val_loss: 5.1264 - val_MinusLogProbMetric: 5.1264 - lr: 3.1250e-05 - 60s/epoch - 304ms/step
Epoch 769/1000
2023-09-19 08:04:31.868 
Epoch 769/1000 
	 loss: 5.0183, MinusLogProbMetric: 5.0183, val_loss: 5.1250, val_MinusLogProbMetric: 5.1250

Epoch 769: val_loss did not improve from 5.12462
196/196 - 55s - loss: 5.0183 - MinusLogProbMetric: 5.0183 - val_loss: 5.1250 - val_MinusLogProbMetric: 5.1250 - lr: 3.1250e-05 - 55s/epoch - 283ms/step
Epoch 770/1000
2023-09-19 08:05:28.388 
Epoch 770/1000 
	 loss: 5.0184, MinusLogProbMetric: 5.0184, val_loss: 5.1263, val_MinusLogProbMetric: 5.1263

Epoch 770: val_loss did not improve from 5.12462
196/196 - 57s - loss: 5.0184 - MinusLogProbMetric: 5.0184 - val_loss: 5.1263 - val_MinusLogProbMetric: 5.1263 - lr: 3.1250e-05 - 57s/epoch - 288ms/step
Epoch 771/1000
2023-09-19 08:06:36.291 
Epoch 771/1000 
	 loss: 5.0184, MinusLogProbMetric: 5.0184, val_loss: 5.1275, val_MinusLogProbMetric: 5.1275

Epoch 771: val_loss did not improve from 5.12462
196/196 - 68s - loss: 5.0184 - MinusLogProbMetric: 5.0184 - val_loss: 5.1275 - val_MinusLogProbMetric: 5.1275 - lr: 3.1250e-05 - 68s/epoch - 346ms/step
Epoch 772/1000
2023-09-19 08:07:42.583 
Epoch 772/1000 
	 loss: 5.0184, MinusLogProbMetric: 5.0184, val_loss: 5.1245, val_MinusLogProbMetric: 5.1245

Epoch 772: val_loss improved from 5.12462 to 5.12454, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 67s - loss: 5.0184 - MinusLogProbMetric: 5.0184 - val_loss: 5.1245 - val_MinusLogProbMetric: 5.1245 - lr: 3.1250e-05 - 67s/epoch - 342ms/step
Epoch 773/1000
2023-09-19 08:08:51.978 
Epoch 773/1000 
	 loss: 5.0186, MinusLogProbMetric: 5.0186, val_loss: 5.1262, val_MinusLogProbMetric: 5.1262

Epoch 773: val_loss did not improve from 5.12454
196/196 - 69s - loss: 5.0186 - MinusLogProbMetric: 5.0186 - val_loss: 5.1262 - val_MinusLogProbMetric: 5.1262 - lr: 3.1250e-05 - 69s/epoch - 350ms/step
Epoch 774/1000
2023-09-19 08:10:00.912 
Epoch 774/1000 
	 loss: 5.0184, MinusLogProbMetric: 5.0184, val_loss: 5.1243, val_MinusLogProbMetric: 5.1243

Epoch 774: val_loss improved from 5.12454 to 5.12427, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0184 - MinusLogProbMetric: 5.0184 - val_loss: 5.1243 - val_MinusLogProbMetric: 5.1243 - lr: 3.1250e-05 - 70s/epoch - 358ms/step
Epoch 775/1000
2023-09-19 08:11:11.011 
Epoch 775/1000 
	 loss: 5.0178, MinusLogProbMetric: 5.0178, val_loss: 5.1252, val_MinusLogProbMetric: 5.1252

Epoch 775: val_loss did not improve from 5.12427
196/196 - 69s - loss: 5.0178 - MinusLogProbMetric: 5.0178 - val_loss: 5.1252 - val_MinusLogProbMetric: 5.1252 - lr: 3.1250e-05 - 69s/epoch - 351ms/step
Epoch 776/1000
2023-09-19 08:12:19.399 
Epoch 776/1000 
	 loss: 5.0184, MinusLogProbMetric: 5.0184, val_loss: 5.1262, val_MinusLogProbMetric: 5.1262

Epoch 776: val_loss did not improve from 5.12427
196/196 - 68s - loss: 5.0184 - MinusLogProbMetric: 5.0184 - val_loss: 5.1262 - val_MinusLogProbMetric: 5.1262 - lr: 3.1250e-05 - 68s/epoch - 349ms/step
Epoch 777/1000
2023-09-19 08:13:27.859 
Epoch 777/1000 
	 loss: 5.0182, MinusLogProbMetric: 5.0182, val_loss: 5.1246, val_MinusLogProbMetric: 5.1246

Epoch 777: val_loss did not improve from 5.12427
196/196 - 68s - loss: 5.0182 - MinusLogProbMetric: 5.0182 - val_loss: 5.1246 - val_MinusLogProbMetric: 5.1246 - lr: 3.1250e-05 - 68s/epoch - 349ms/step
Epoch 778/1000
2023-09-19 08:14:36.477 
Epoch 778/1000 
	 loss: 5.0182, MinusLogProbMetric: 5.0182, val_loss: 5.1250, val_MinusLogProbMetric: 5.1250

Epoch 778: val_loss did not improve from 5.12427
196/196 - 69s - loss: 5.0182 - MinusLogProbMetric: 5.0182 - val_loss: 5.1250 - val_MinusLogProbMetric: 5.1250 - lr: 3.1250e-05 - 69s/epoch - 350ms/step
Epoch 779/1000
2023-09-19 08:15:44.932 
Epoch 779/1000 
	 loss: 5.0180, MinusLogProbMetric: 5.0180, val_loss: 5.1260, val_MinusLogProbMetric: 5.1260

Epoch 779: val_loss did not improve from 5.12427
196/196 - 68s - loss: 5.0180 - MinusLogProbMetric: 5.0180 - val_loss: 5.1260 - val_MinusLogProbMetric: 5.1260 - lr: 3.1250e-05 - 68s/epoch - 349ms/step
Epoch 780/1000
2023-09-19 08:16:53.131 
Epoch 780/1000 
	 loss: 5.0182, MinusLogProbMetric: 5.0182, val_loss: 5.1245, val_MinusLogProbMetric: 5.1245

Epoch 780: val_loss did not improve from 5.12427
196/196 - 68s - loss: 5.0182 - MinusLogProbMetric: 5.0182 - val_loss: 5.1245 - val_MinusLogProbMetric: 5.1245 - lr: 3.1250e-05 - 68s/epoch - 348ms/step
Epoch 781/1000
2023-09-19 08:18:01.774 
Epoch 781/1000 
	 loss: 5.0184, MinusLogProbMetric: 5.0184, val_loss: 5.1265, val_MinusLogProbMetric: 5.1265

Epoch 781: val_loss did not improve from 5.12427
196/196 - 69s - loss: 5.0184 - MinusLogProbMetric: 5.0184 - val_loss: 5.1265 - val_MinusLogProbMetric: 5.1265 - lr: 3.1250e-05 - 69s/epoch - 350ms/step
Epoch 782/1000
2023-09-19 08:19:09.883 
Epoch 782/1000 
	 loss: 5.0184, MinusLogProbMetric: 5.0184, val_loss: 5.1258, val_MinusLogProbMetric: 5.1258

Epoch 782: val_loss did not improve from 5.12427
196/196 - 68s - loss: 5.0184 - MinusLogProbMetric: 5.0184 - val_loss: 5.1258 - val_MinusLogProbMetric: 5.1258 - lr: 3.1250e-05 - 68s/epoch - 347ms/step
Epoch 783/1000
2023-09-19 08:20:18.334 
Epoch 783/1000 
	 loss: 5.0180, MinusLogProbMetric: 5.0180, val_loss: 5.1256, val_MinusLogProbMetric: 5.1256

Epoch 783: val_loss did not improve from 5.12427
196/196 - 68s - loss: 5.0180 - MinusLogProbMetric: 5.0180 - val_loss: 5.1256 - val_MinusLogProbMetric: 5.1256 - lr: 3.1250e-05 - 68s/epoch - 349ms/step
Epoch 784/1000
2023-09-19 08:21:26.932 
Epoch 784/1000 
	 loss: 5.0186, MinusLogProbMetric: 5.0186, val_loss: 5.1247, val_MinusLogProbMetric: 5.1247

Epoch 784: val_loss did not improve from 5.12427
196/196 - 69s - loss: 5.0186 - MinusLogProbMetric: 5.0186 - val_loss: 5.1247 - val_MinusLogProbMetric: 5.1247 - lr: 3.1250e-05 - 69s/epoch - 350ms/step
Epoch 785/1000
2023-09-19 08:22:35.089 
Epoch 785/1000 
	 loss: 5.0183, MinusLogProbMetric: 5.0183, val_loss: 5.1261, val_MinusLogProbMetric: 5.1261

Epoch 785: val_loss did not improve from 5.12427
196/196 - 68s - loss: 5.0183 - MinusLogProbMetric: 5.0183 - val_loss: 5.1261 - val_MinusLogProbMetric: 5.1261 - lr: 3.1250e-05 - 68s/epoch - 348ms/step
Epoch 786/1000
2023-09-19 08:23:43.740 
Epoch 786/1000 
	 loss: 5.0182, MinusLogProbMetric: 5.0182, val_loss: 5.1241, val_MinusLogProbMetric: 5.1241

Epoch 786: val_loss improved from 5.12427 to 5.12413, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0182 - MinusLogProbMetric: 5.0182 - val_loss: 5.1241 - val_MinusLogProbMetric: 5.1241 - lr: 3.1250e-05 - 70s/epoch - 357ms/step
Epoch 787/1000
2023-09-19 08:24:53.586 
Epoch 787/1000 
	 loss: 5.0184, MinusLogProbMetric: 5.0184, val_loss: 5.1287, val_MinusLogProbMetric: 5.1287

Epoch 787: val_loss did not improve from 5.12413
196/196 - 69s - loss: 5.0184 - MinusLogProbMetric: 5.0184 - val_loss: 5.1287 - val_MinusLogProbMetric: 5.1287 - lr: 3.1250e-05 - 69s/epoch - 350ms/step
Epoch 788/1000
2023-09-19 08:25:56.835 
Epoch 788/1000 
	 loss: 5.0184, MinusLogProbMetric: 5.0184, val_loss: 5.1264, val_MinusLogProbMetric: 5.1264

Epoch 788: val_loss did not improve from 5.12413
196/196 - 63s - loss: 5.0184 - MinusLogProbMetric: 5.0184 - val_loss: 5.1264 - val_MinusLogProbMetric: 5.1264 - lr: 3.1250e-05 - 63s/epoch - 323ms/step
Epoch 789/1000
2023-09-19 08:26:57.713 
Epoch 789/1000 
	 loss: 5.0181, MinusLogProbMetric: 5.0181, val_loss: 5.1281, val_MinusLogProbMetric: 5.1281

Epoch 789: val_loss did not improve from 5.12413
196/196 - 61s - loss: 5.0181 - MinusLogProbMetric: 5.0181 - val_loss: 5.1281 - val_MinusLogProbMetric: 5.1281 - lr: 3.1250e-05 - 61s/epoch - 311ms/step
Epoch 790/1000
2023-09-19 08:28:05.677 
Epoch 790/1000 
	 loss: 5.0184, MinusLogProbMetric: 5.0184, val_loss: 5.1256, val_MinusLogProbMetric: 5.1256

Epoch 790: val_loss did not improve from 5.12413
196/196 - 68s - loss: 5.0184 - MinusLogProbMetric: 5.0184 - val_loss: 5.1256 - val_MinusLogProbMetric: 5.1256 - lr: 3.1250e-05 - 68s/epoch - 347ms/step
Epoch 791/1000
2023-09-19 08:29:14.856 
Epoch 791/1000 
	 loss: 5.0183, MinusLogProbMetric: 5.0183, val_loss: 5.1242, val_MinusLogProbMetric: 5.1242

Epoch 791: val_loss did not improve from 5.12413
196/196 - 69s - loss: 5.0183 - MinusLogProbMetric: 5.0183 - val_loss: 5.1242 - val_MinusLogProbMetric: 5.1242 - lr: 3.1250e-05 - 69s/epoch - 353ms/step
Epoch 792/1000
2023-09-19 08:30:23.240 
Epoch 792/1000 
	 loss: 5.0184, MinusLogProbMetric: 5.0184, val_loss: 5.1256, val_MinusLogProbMetric: 5.1256

Epoch 792: val_loss did not improve from 5.12413
196/196 - 68s - loss: 5.0184 - MinusLogProbMetric: 5.0184 - val_loss: 5.1256 - val_MinusLogProbMetric: 5.1256 - lr: 3.1250e-05 - 68s/epoch - 349ms/step
Epoch 793/1000
2023-09-19 08:31:32.090 
Epoch 793/1000 
	 loss: 5.0181, MinusLogProbMetric: 5.0181, val_loss: 5.1260, val_MinusLogProbMetric: 5.1260

Epoch 793: val_loss did not improve from 5.12413
196/196 - 69s - loss: 5.0181 - MinusLogProbMetric: 5.0181 - val_loss: 5.1260 - val_MinusLogProbMetric: 5.1260 - lr: 3.1250e-05 - 69s/epoch - 351ms/step
Epoch 794/1000
2023-09-19 08:32:41.185 
Epoch 794/1000 
	 loss: 5.0183, MinusLogProbMetric: 5.0183, val_loss: 5.1255, val_MinusLogProbMetric: 5.1255

Epoch 794: val_loss did not improve from 5.12413
196/196 - 69s - loss: 5.0183 - MinusLogProbMetric: 5.0183 - val_loss: 5.1255 - val_MinusLogProbMetric: 5.1255 - lr: 3.1250e-05 - 69s/epoch - 353ms/step
Epoch 795/1000
2023-09-19 08:33:49.748 
Epoch 795/1000 
	 loss: 5.0180, MinusLogProbMetric: 5.0180, val_loss: 5.1247, val_MinusLogProbMetric: 5.1247

Epoch 795: val_loss did not improve from 5.12413
196/196 - 69s - loss: 5.0180 - MinusLogProbMetric: 5.0180 - val_loss: 5.1247 - val_MinusLogProbMetric: 5.1247 - lr: 3.1250e-05 - 69s/epoch - 350ms/step
Epoch 796/1000
2023-09-19 08:34:58.397 
Epoch 796/1000 
	 loss: 5.0179, MinusLogProbMetric: 5.0179, val_loss: 5.1240, val_MinusLogProbMetric: 5.1240

Epoch 796: val_loss improved from 5.12413 to 5.12403, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 69s - loss: 5.0179 - MinusLogProbMetric: 5.0179 - val_loss: 5.1240 - val_MinusLogProbMetric: 5.1240 - lr: 3.1250e-05 - 69s/epoch - 354ms/step
Epoch 797/1000
2023-09-19 08:36:08.045 
Epoch 797/1000 
	 loss: 5.0181, MinusLogProbMetric: 5.0181, val_loss: 5.1246, val_MinusLogProbMetric: 5.1246

Epoch 797: val_loss did not improve from 5.12403
196/196 - 69s - loss: 5.0181 - MinusLogProbMetric: 5.0181 - val_loss: 5.1246 - val_MinusLogProbMetric: 5.1246 - lr: 3.1250e-05 - 69s/epoch - 351ms/step
Epoch 798/1000
2023-09-19 08:37:16.527 
Epoch 798/1000 
	 loss: 5.0178, MinusLogProbMetric: 5.0178, val_loss: 5.1250, val_MinusLogProbMetric: 5.1250

Epoch 798: val_loss did not improve from 5.12403
196/196 - 68s - loss: 5.0178 - MinusLogProbMetric: 5.0178 - val_loss: 5.1250 - val_MinusLogProbMetric: 5.1250 - lr: 3.1250e-05 - 68s/epoch - 349ms/step
Epoch 799/1000
2023-09-19 08:38:24.924 
Epoch 799/1000 
	 loss: 5.0180, MinusLogProbMetric: 5.0180, val_loss: 5.1239, val_MinusLogProbMetric: 5.1239

Epoch 799: val_loss improved from 5.12403 to 5.12394, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 69s - loss: 5.0180 - MinusLogProbMetric: 5.0180 - val_loss: 5.1239 - val_MinusLogProbMetric: 5.1239 - lr: 3.1250e-05 - 69s/epoch - 354ms/step
Epoch 800/1000
2023-09-19 08:39:34.701 
Epoch 800/1000 
	 loss: 5.0178, MinusLogProbMetric: 5.0178, val_loss: 5.1276, val_MinusLogProbMetric: 5.1276

Epoch 800: val_loss did not improve from 5.12394
196/196 - 69s - loss: 5.0178 - MinusLogProbMetric: 5.0178 - val_loss: 5.1276 - val_MinusLogProbMetric: 5.1276 - lr: 3.1250e-05 - 69s/epoch - 351ms/step
Epoch 801/1000
2023-09-19 08:40:44.209 
Epoch 801/1000 
	 loss: 5.0180, MinusLogProbMetric: 5.0180, val_loss: 5.1256, val_MinusLogProbMetric: 5.1256

Epoch 801: val_loss did not improve from 5.12394
196/196 - 70s - loss: 5.0180 - MinusLogProbMetric: 5.0180 - val_loss: 5.1256 - val_MinusLogProbMetric: 5.1256 - lr: 3.1250e-05 - 70s/epoch - 355ms/step
Epoch 802/1000
2023-09-19 08:41:52.739 
Epoch 802/1000 
	 loss: 5.0180, MinusLogProbMetric: 5.0180, val_loss: 5.1236, val_MinusLogProbMetric: 5.1236

Epoch 802: val_loss improved from 5.12394 to 5.12357, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0180 - MinusLogProbMetric: 5.0180 - val_loss: 5.1236 - val_MinusLogProbMetric: 5.1236 - lr: 3.1250e-05 - 70s/epoch - 355ms/step
Epoch 803/1000
2023-09-19 08:43:03.375 
Epoch 803/1000 
	 loss: 5.0178, MinusLogProbMetric: 5.0178, val_loss: 5.1244, val_MinusLogProbMetric: 5.1244

Epoch 803: val_loss did not improve from 5.12357
196/196 - 70s - loss: 5.0178 - MinusLogProbMetric: 5.0178 - val_loss: 5.1244 - val_MinusLogProbMetric: 5.1244 - lr: 3.1250e-05 - 70s/epoch - 355ms/step
Epoch 804/1000
2023-09-19 08:44:12.193 
Epoch 804/1000 
	 loss: 5.0177, MinusLogProbMetric: 5.0177, val_loss: 5.1257, val_MinusLogProbMetric: 5.1257

Epoch 804: val_loss did not improve from 5.12357
196/196 - 69s - loss: 5.0177 - MinusLogProbMetric: 5.0177 - val_loss: 5.1257 - val_MinusLogProbMetric: 5.1257 - lr: 3.1250e-05 - 69s/epoch - 351ms/step
Epoch 805/1000
2023-09-19 08:45:20.568 
Epoch 805/1000 
	 loss: 5.0181, MinusLogProbMetric: 5.0181, val_loss: 5.1252, val_MinusLogProbMetric: 5.1252

Epoch 805: val_loss did not improve from 5.12357
196/196 - 68s - loss: 5.0181 - MinusLogProbMetric: 5.0181 - val_loss: 5.1252 - val_MinusLogProbMetric: 5.1252 - lr: 3.1250e-05 - 68s/epoch - 349ms/step
Epoch 806/1000
2023-09-19 08:46:29.394 
Epoch 806/1000 
	 loss: 5.0181, MinusLogProbMetric: 5.0181, val_loss: 5.1237, val_MinusLogProbMetric: 5.1237

Epoch 806: val_loss did not improve from 5.12357
196/196 - 69s - loss: 5.0181 - MinusLogProbMetric: 5.0181 - val_loss: 5.1237 - val_MinusLogProbMetric: 5.1237 - lr: 3.1250e-05 - 69s/epoch - 351ms/step
Epoch 807/1000
2023-09-19 08:47:37.363 
Epoch 807/1000 
	 loss: 5.0179, MinusLogProbMetric: 5.0179, val_loss: 5.1258, val_MinusLogProbMetric: 5.1258

Epoch 807: val_loss did not improve from 5.12357
196/196 - 68s - loss: 5.0179 - MinusLogProbMetric: 5.0179 - val_loss: 5.1258 - val_MinusLogProbMetric: 5.1258 - lr: 3.1250e-05 - 68s/epoch - 347ms/step
Epoch 808/1000
2023-09-19 08:48:45.995 
Epoch 808/1000 
	 loss: 5.0175, MinusLogProbMetric: 5.0175, val_loss: 5.1264, val_MinusLogProbMetric: 5.1264

Epoch 808: val_loss did not improve from 5.12357
196/196 - 69s - loss: 5.0175 - MinusLogProbMetric: 5.0175 - val_loss: 5.1264 - val_MinusLogProbMetric: 5.1264 - lr: 3.1250e-05 - 69s/epoch - 350ms/step
Epoch 809/1000
2023-09-19 08:49:54.654 
Epoch 809/1000 
	 loss: 5.0178, MinusLogProbMetric: 5.0178, val_loss: 5.1274, val_MinusLogProbMetric: 5.1274

Epoch 809: val_loss did not improve from 5.12357
196/196 - 69s - loss: 5.0178 - MinusLogProbMetric: 5.0178 - val_loss: 5.1274 - val_MinusLogProbMetric: 5.1274 - lr: 3.1250e-05 - 69s/epoch - 350ms/step
Epoch 810/1000
2023-09-19 08:51:03.174 
Epoch 810/1000 
	 loss: 5.0181, MinusLogProbMetric: 5.0181, val_loss: 5.1244, val_MinusLogProbMetric: 5.1244

Epoch 810: val_loss did not improve from 5.12357
196/196 - 69s - loss: 5.0181 - MinusLogProbMetric: 5.0181 - val_loss: 5.1244 - val_MinusLogProbMetric: 5.1244 - lr: 3.1250e-05 - 69s/epoch - 350ms/step
Epoch 811/1000
2023-09-19 08:52:12.078 
Epoch 811/1000 
	 loss: 5.0184, MinusLogProbMetric: 5.0184, val_loss: 5.1235, val_MinusLogProbMetric: 5.1235

Epoch 811: val_loss improved from 5.12357 to 5.12351, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0184 - MinusLogProbMetric: 5.0184 - val_loss: 5.1235 - val_MinusLogProbMetric: 5.1235 - lr: 3.1250e-05 - 70s/epoch - 356ms/step
Epoch 812/1000
2023-09-19 08:53:22.092 
Epoch 812/1000 
	 loss: 5.0176, MinusLogProbMetric: 5.0176, val_loss: 5.1253, val_MinusLogProbMetric: 5.1253

Epoch 812: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0176 - MinusLogProbMetric: 5.0176 - val_loss: 5.1253 - val_MinusLogProbMetric: 5.1253 - lr: 3.1250e-05 - 69s/epoch - 352ms/step
Epoch 813/1000
2023-09-19 08:54:30.334 
Epoch 813/1000 
	 loss: 5.0176, MinusLogProbMetric: 5.0176, val_loss: 5.1249, val_MinusLogProbMetric: 5.1249

Epoch 813: val_loss did not improve from 5.12351
196/196 - 68s - loss: 5.0176 - MinusLogProbMetric: 5.0176 - val_loss: 5.1249 - val_MinusLogProbMetric: 5.1249 - lr: 3.1250e-05 - 68s/epoch - 348ms/step
Epoch 814/1000
2023-09-19 08:55:39.180 
Epoch 814/1000 
	 loss: 5.0178, MinusLogProbMetric: 5.0178, val_loss: 5.1238, val_MinusLogProbMetric: 5.1238

Epoch 814: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0178 - MinusLogProbMetric: 5.0178 - val_loss: 5.1238 - val_MinusLogProbMetric: 5.1238 - lr: 3.1250e-05 - 69s/epoch - 351ms/step
Epoch 815/1000
2023-09-19 08:56:48.547 
Epoch 815/1000 
	 loss: 5.0176, MinusLogProbMetric: 5.0176, val_loss: 5.1257, val_MinusLogProbMetric: 5.1257

Epoch 815: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0176 - MinusLogProbMetric: 5.0176 - val_loss: 5.1257 - val_MinusLogProbMetric: 5.1257 - lr: 3.1250e-05 - 69s/epoch - 354ms/step
Epoch 816/1000
2023-09-19 08:57:57.715 
Epoch 816/1000 
	 loss: 5.0180, MinusLogProbMetric: 5.0180, val_loss: 5.1248, val_MinusLogProbMetric: 5.1248

Epoch 816: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0180 - MinusLogProbMetric: 5.0180 - val_loss: 5.1248 - val_MinusLogProbMetric: 5.1248 - lr: 3.1250e-05 - 69s/epoch - 353ms/step
Epoch 817/1000
2023-09-19 08:59:07.112 
Epoch 817/1000 
	 loss: 5.0177, MinusLogProbMetric: 5.0177, val_loss: 5.1257, val_MinusLogProbMetric: 5.1257

Epoch 817: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0177 - MinusLogProbMetric: 5.0177 - val_loss: 5.1257 - val_MinusLogProbMetric: 5.1257 - lr: 3.1250e-05 - 69s/epoch - 354ms/step
Epoch 818/1000
2023-09-19 09:00:16.634 
Epoch 818/1000 
	 loss: 5.0184, MinusLogProbMetric: 5.0184, val_loss: 5.1239, val_MinusLogProbMetric: 5.1239

Epoch 818: val_loss did not improve from 5.12351
196/196 - 70s - loss: 5.0184 - MinusLogProbMetric: 5.0184 - val_loss: 5.1239 - val_MinusLogProbMetric: 5.1239 - lr: 3.1250e-05 - 70s/epoch - 355ms/step
Epoch 819/1000
2023-09-19 09:01:26.630 
Epoch 819/1000 
	 loss: 5.0181, MinusLogProbMetric: 5.0181, val_loss: 5.1240, val_MinusLogProbMetric: 5.1240

Epoch 819: val_loss did not improve from 5.12351
196/196 - 70s - loss: 5.0181 - MinusLogProbMetric: 5.0181 - val_loss: 5.1240 - val_MinusLogProbMetric: 5.1240 - lr: 3.1250e-05 - 70s/epoch - 357ms/step
Epoch 820/1000
2023-09-19 09:02:36.328 
Epoch 820/1000 
	 loss: 5.0176, MinusLogProbMetric: 5.0176, val_loss: 5.1257, val_MinusLogProbMetric: 5.1257

Epoch 820: val_loss did not improve from 5.12351
196/196 - 70s - loss: 5.0176 - MinusLogProbMetric: 5.0176 - val_loss: 5.1257 - val_MinusLogProbMetric: 5.1257 - lr: 3.1250e-05 - 70s/epoch - 356ms/step
Epoch 821/1000
2023-09-19 09:03:46.177 
Epoch 821/1000 
	 loss: 5.0181, MinusLogProbMetric: 5.0181, val_loss: 5.1246, val_MinusLogProbMetric: 5.1246

Epoch 821: val_loss did not improve from 5.12351
196/196 - 70s - loss: 5.0181 - MinusLogProbMetric: 5.0181 - val_loss: 5.1246 - val_MinusLogProbMetric: 5.1246 - lr: 3.1250e-05 - 70s/epoch - 356ms/step
Epoch 822/1000
2023-09-19 09:04:55.841 
Epoch 822/1000 
	 loss: 5.0177, MinusLogProbMetric: 5.0177, val_loss: 5.1241, val_MinusLogProbMetric: 5.1241

Epoch 822: val_loss did not improve from 5.12351
196/196 - 70s - loss: 5.0177 - MinusLogProbMetric: 5.0177 - val_loss: 5.1241 - val_MinusLogProbMetric: 5.1241 - lr: 3.1250e-05 - 70s/epoch - 355ms/step
Epoch 823/1000
2023-09-19 09:06:05.758 
Epoch 823/1000 
	 loss: 5.0177, MinusLogProbMetric: 5.0177, val_loss: 5.1261, val_MinusLogProbMetric: 5.1261

Epoch 823: val_loss did not improve from 5.12351
196/196 - 70s - loss: 5.0177 - MinusLogProbMetric: 5.0177 - val_loss: 5.1261 - val_MinusLogProbMetric: 5.1261 - lr: 3.1250e-05 - 70s/epoch - 357ms/step
Epoch 824/1000
2023-09-19 09:07:15.081 
Epoch 824/1000 
	 loss: 5.0180, MinusLogProbMetric: 5.0180, val_loss: 5.1275, val_MinusLogProbMetric: 5.1275

Epoch 824: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0180 - MinusLogProbMetric: 5.0180 - val_loss: 5.1275 - val_MinusLogProbMetric: 5.1275 - lr: 3.1250e-05 - 69s/epoch - 354ms/step
Epoch 825/1000
2023-09-19 09:08:25.014 
Epoch 825/1000 
	 loss: 5.0176, MinusLogProbMetric: 5.0176, val_loss: 5.1300, val_MinusLogProbMetric: 5.1300

Epoch 825: val_loss did not improve from 5.12351
196/196 - 70s - loss: 5.0176 - MinusLogProbMetric: 5.0176 - val_loss: 5.1300 - val_MinusLogProbMetric: 5.1300 - lr: 3.1250e-05 - 70s/epoch - 357ms/step
Epoch 826/1000
2023-09-19 09:09:33.818 
Epoch 826/1000 
	 loss: 5.0178, MinusLogProbMetric: 5.0178, val_loss: 5.1250, val_MinusLogProbMetric: 5.1250

Epoch 826: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0178 - MinusLogProbMetric: 5.0178 - val_loss: 5.1250 - val_MinusLogProbMetric: 5.1250 - lr: 3.1250e-05 - 69s/epoch - 351ms/step
Epoch 827/1000
2023-09-19 09:10:43.496 
Epoch 827/1000 
	 loss: 5.0181, MinusLogProbMetric: 5.0181, val_loss: 5.1251, val_MinusLogProbMetric: 5.1251

Epoch 827: val_loss did not improve from 5.12351
196/196 - 70s - loss: 5.0181 - MinusLogProbMetric: 5.0181 - val_loss: 5.1251 - val_MinusLogProbMetric: 5.1251 - lr: 3.1250e-05 - 70s/epoch - 355ms/step
Epoch 828/1000
2023-09-19 09:11:52.741 
Epoch 828/1000 
	 loss: 5.0177, MinusLogProbMetric: 5.0177, val_loss: 5.1246, val_MinusLogProbMetric: 5.1246

Epoch 828: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0177 - MinusLogProbMetric: 5.0177 - val_loss: 5.1246 - val_MinusLogProbMetric: 5.1246 - lr: 3.1250e-05 - 69s/epoch - 353ms/step
Epoch 829/1000
2023-09-19 09:13:02.798 
Epoch 829/1000 
	 loss: 5.0178, MinusLogProbMetric: 5.0178, val_loss: 5.1252, val_MinusLogProbMetric: 5.1252

Epoch 829: val_loss did not improve from 5.12351
196/196 - 70s - loss: 5.0178 - MinusLogProbMetric: 5.0178 - val_loss: 5.1252 - val_MinusLogProbMetric: 5.1252 - lr: 3.1250e-05 - 70s/epoch - 357ms/step
Epoch 830/1000
2023-09-19 09:14:12.535 
Epoch 830/1000 
	 loss: 5.0181, MinusLogProbMetric: 5.0181, val_loss: 5.1257, val_MinusLogProbMetric: 5.1257

Epoch 830: val_loss did not improve from 5.12351
196/196 - 70s - loss: 5.0181 - MinusLogProbMetric: 5.0181 - val_loss: 5.1257 - val_MinusLogProbMetric: 5.1257 - lr: 3.1250e-05 - 70s/epoch - 356ms/step
Epoch 831/1000
2023-09-19 09:15:21.777 
Epoch 831/1000 
	 loss: 5.0185, MinusLogProbMetric: 5.0185, val_loss: 5.1239, val_MinusLogProbMetric: 5.1239

Epoch 831: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0185 - MinusLogProbMetric: 5.0185 - val_loss: 5.1239 - val_MinusLogProbMetric: 5.1239 - lr: 3.1250e-05 - 69s/epoch - 353ms/step
Epoch 832/1000
2023-09-19 09:16:30.749 
Epoch 832/1000 
	 loss: 5.0186, MinusLogProbMetric: 5.0186, val_loss: 5.1243, val_MinusLogProbMetric: 5.1243

Epoch 832: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0186 - MinusLogProbMetric: 5.0186 - val_loss: 5.1243 - val_MinusLogProbMetric: 5.1243 - lr: 3.1250e-05 - 69s/epoch - 352ms/step
Epoch 833/1000
2023-09-19 09:17:39.953 
Epoch 833/1000 
	 loss: 5.0176, MinusLogProbMetric: 5.0176, val_loss: 5.1284, val_MinusLogProbMetric: 5.1284

Epoch 833: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0176 - MinusLogProbMetric: 5.0176 - val_loss: 5.1284 - val_MinusLogProbMetric: 5.1284 - lr: 3.1250e-05 - 69s/epoch - 353ms/step
Epoch 834/1000
2023-09-19 09:18:49.514 
Epoch 834/1000 
	 loss: 5.0189, MinusLogProbMetric: 5.0189, val_loss: 5.1266, val_MinusLogProbMetric: 5.1266

Epoch 834: val_loss did not improve from 5.12351
196/196 - 70s - loss: 5.0189 - MinusLogProbMetric: 5.0189 - val_loss: 5.1266 - val_MinusLogProbMetric: 5.1266 - lr: 3.1250e-05 - 70s/epoch - 355ms/step
Epoch 835/1000
2023-09-19 09:19:58.726 
Epoch 835/1000 
	 loss: 5.0179, MinusLogProbMetric: 5.0179, val_loss: 5.1257, val_MinusLogProbMetric: 5.1257

Epoch 835: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0179 - MinusLogProbMetric: 5.0179 - val_loss: 5.1257 - val_MinusLogProbMetric: 5.1257 - lr: 3.1250e-05 - 69s/epoch - 353ms/step
Epoch 836/1000
2023-09-19 09:21:08.490 
Epoch 836/1000 
	 loss: 5.0178, MinusLogProbMetric: 5.0178, val_loss: 5.1248, val_MinusLogProbMetric: 5.1248

Epoch 836: val_loss did not improve from 5.12351
196/196 - 70s - loss: 5.0178 - MinusLogProbMetric: 5.0178 - val_loss: 5.1248 - val_MinusLogProbMetric: 5.1248 - lr: 3.1250e-05 - 70s/epoch - 356ms/step
Epoch 837/1000
2023-09-19 09:22:17.474 
Epoch 837/1000 
	 loss: 5.0178, MinusLogProbMetric: 5.0178, val_loss: 5.1251, val_MinusLogProbMetric: 5.1251

Epoch 837: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0178 - MinusLogProbMetric: 5.0178 - val_loss: 5.1251 - val_MinusLogProbMetric: 5.1251 - lr: 3.1250e-05 - 69s/epoch - 352ms/step
Epoch 838/1000
2023-09-19 09:23:27.192 
Epoch 838/1000 
	 loss: 5.0174, MinusLogProbMetric: 5.0174, val_loss: 5.1260, val_MinusLogProbMetric: 5.1260

Epoch 838: val_loss did not improve from 5.12351
196/196 - 70s - loss: 5.0174 - MinusLogProbMetric: 5.0174 - val_loss: 5.1260 - val_MinusLogProbMetric: 5.1260 - lr: 3.1250e-05 - 70s/epoch - 356ms/step
Epoch 839/1000
2023-09-19 09:24:37.122 
Epoch 839/1000 
	 loss: 5.0181, MinusLogProbMetric: 5.0181, val_loss: 5.1261, val_MinusLogProbMetric: 5.1261

Epoch 839: val_loss did not improve from 5.12351
196/196 - 70s - loss: 5.0181 - MinusLogProbMetric: 5.0181 - val_loss: 5.1261 - val_MinusLogProbMetric: 5.1261 - lr: 3.1250e-05 - 70s/epoch - 357ms/step
Epoch 840/1000
2023-09-19 09:25:45.884 
Epoch 840/1000 
	 loss: 5.0176, MinusLogProbMetric: 5.0176, val_loss: 5.1254, val_MinusLogProbMetric: 5.1254

Epoch 840: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0176 - MinusLogProbMetric: 5.0176 - val_loss: 5.1254 - val_MinusLogProbMetric: 5.1254 - lr: 3.1250e-05 - 69s/epoch - 351ms/step
Epoch 841/1000
2023-09-19 09:26:55.256 
Epoch 841/1000 
	 loss: 5.0179, MinusLogProbMetric: 5.0179, val_loss: 5.1256, val_MinusLogProbMetric: 5.1256

Epoch 841: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0179 - MinusLogProbMetric: 5.0179 - val_loss: 5.1256 - val_MinusLogProbMetric: 5.1256 - lr: 3.1250e-05 - 69s/epoch - 354ms/step
Epoch 842/1000
2023-09-19 09:28:04.875 
Epoch 842/1000 
	 loss: 5.0181, MinusLogProbMetric: 5.0181, val_loss: 5.1249, val_MinusLogProbMetric: 5.1249

Epoch 842: val_loss did not improve from 5.12351
196/196 - 70s - loss: 5.0181 - MinusLogProbMetric: 5.0181 - val_loss: 5.1249 - val_MinusLogProbMetric: 5.1249 - lr: 3.1250e-05 - 70s/epoch - 355ms/step
Epoch 843/1000
2023-09-19 09:29:14.761 
Epoch 843/1000 
	 loss: 5.0182, MinusLogProbMetric: 5.0182, val_loss: 5.1245, val_MinusLogProbMetric: 5.1245

Epoch 843: val_loss did not improve from 5.12351
196/196 - 70s - loss: 5.0182 - MinusLogProbMetric: 5.0182 - val_loss: 5.1245 - val_MinusLogProbMetric: 5.1245 - lr: 3.1250e-05 - 70s/epoch - 357ms/step
Epoch 844/1000
2023-09-19 09:30:24.052 
Epoch 844/1000 
	 loss: 5.0177, MinusLogProbMetric: 5.0177, val_loss: 5.1257, val_MinusLogProbMetric: 5.1257

Epoch 844: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0177 - MinusLogProbMetric: 5.0177 - val_loss: 5.1257 - val_MinusLogProbMetric: 5.1257 - lr: 3.1250e-05 - 69s/epoch - 354ms/step
Epoch 845/1000
2023-09-19 09:31:33.434 
Epoch 845/1000 
	 loss: 5.0178, MinusLogProbMetric: 5.0178, val_loss: 5.1267, val_MinusLogProbMetric: 5.1267

Epoch 845: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0178 - MinusLogProbMetric: 5.0178 - val_loss: 5.1267 - val_MinusLogProbMetric: 5.1267 - lr: 3.1250e-05 - 69s/epoch - 354ms/step
Epoch 846/1000
2023-09-19 09:32:42.843 
Epoch 846/1000 
	 loss: 5.0176, MinusLogProbMetric: 5.0176, val_loss: 5.1250, val_MinusLogProbMetric: 5.1250

Epoch 846: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0176 - MinusLogProbMetric: 5.0176 - val_loss: 5.1250 - val_MinusLogProbMetric: 5.1250 - lr: 3.1250e-05 - 69s/epoch - 354ms/step
Epoch 847/1000
2023-09-19 09:33:51.012 
Epoch 847/1000 
	 loss: 5.0178, MinusLogProbMetric: 5.0178, val_loss: 5.1266, val_MinusLogProbMetric: 5.1266

Epoch 847: val_loss did not improve from 5.12351
196/196 - 68s - loss: 5.0178 - MinusLogProbMetric: 5.0178 - val_loss: 5.1266 - val_MinusLogProbMetric: 5.1266 - lr: 3.1250e-05 - 68s/epoch - 348ms/step
Epoch 848/1000
2023-09-19 09:34:55.640 
Epoch 848/1000 
	 loss: 5.0176, MinusLogProbMetric: 5.0176, val_loss: 5.1263, val_MinusLogProbMetric: 5.1263

Epoch 848: val_loss did not improve from 5.12351
196/196 - 65s - loss: 5.0176 - MinusLogProbMetric: 5.0176 - val_loss: 5.1263 - val_MinusLogProbMetric: 5.1263 - lr: 3.1250e-05 - 65s/epoch - 330ms/step
Epoch 849/1000
2023-09-19 09:35:59.776 
Epoch 849/1000 
	 loss: 5.0181, MinusLogProbMetric: 5.0181, val_loss: 5.1250, val_MinusLogProbMetric: 5.1250

Epoch 849: val_loss did not improve from 5.12351
196/196 - 64s - loss: 5.0181 - MinusLogProbMetric: 5.0181 - val_loss: 5.1250 - val_MinusLogProbMetric: 5.1250 - lr: 3.1250e-05 - 64s/epoch - 327ms/step
Epoch 850/1000
2023-09-19 09:37:08.784 
Epoch 850/1000 
	 loss: 5.0177, MinusLogProbMetric: 5.0177, val_loss: 5.1239, val_MinusLogProbMetric: 5.1239

Epoch 850: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0177 - MinusLogProbMetric: 5.0177 - val_loss: 5.1239 - val_MinusLogProbMetric: 5.1239 - lr: 3.1250e-05 - 69s/epoch - 352ms/step
Epoch 851/1000
2023-09-19 09:38:17.868 
Epoch 851/1000 
	 loss: 5.0171, MinusLogProbMetric: 5.0171, val_loss: 5.1252, val_MinusLogProbMetric: 5.1252

Epoch 851: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0171 - MinusLogProbMetric: 5.0171 - val_loss: 5.1252 - val_MinusLogProbMetric: 5.1252 - lr: 3.1250e-05 - 69s/epoch - 352ms/step
Epoch 852/1000
2023-09-19 09:39:27.108 
Epoch 852/1000 
	 loss: 5.0181, MinusLogProbMetric: 5.0181, val_loss: 5.1252, val_MinusLogProbMetric: 5.1252

Epoch 852: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0181 - MinusLogProbMetric: 5.0181 - val_loss: 5.1252 - val_MinusLogProbMetric: 5.1252 - lr: 3.1250e-05 - 69s/epoch - 353ms/step
Epoch 853/1000
2023-09-19 09:40:36.754 
Epoch 853/1000 
	 loss: 5.0160, MinusLogProbMetric: 5.0160, val_loss: 5.1237, val_MinusLogProbMetric: 5.1237

Epoch 853: val_loss did not improve from 5.12351
196/196 - 70s - loss: 5.0160 - MinusLogProbMetric: 5.0160 - val_loss: 5.1237 - val_MinusLogProbMetric: 5.1237 - lr: 1.5625e-05 - 70s/epoch - 355ms/step
Epoch 854/1000
2023-09-19 09:41:46.018 
Epoch 854/1000 
	 loss: 5.0161, MinusLogProbMetric: 5.0161, val_loss: 5.1239, val_MinusLogProbMetric: 5.1239

Epoch 854: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0161 - MinusLogProbMetric: 5.0161 - val_loss: 5.1239 - val_MinusLogProbMetric: 5.1239 - lr: 1.5625e-05 - 69s/epoch - 353ms/step
Epoch 855/1000
2023-09-19 09:42:55.877 
Epoch 855/1000 
	 loss: 5.0158, MinusLogProbMetric: 5.0158, val_loss: 5.1236, val_MinusLogProbMetric: 5.1236

Epoch 855: val_loss did not improve from 5.12351
196/196 - 70s - loss: 5.0158 - MinusLogProbMetric: 5.0158 - val_loss: 5.1236 - val_MinusLogProbMetric: 5.1236 - lr: 1.5625e-05 - 70s/epoch - 356ms/step
Epoch 856/1000
2023-09-19 09:44:05.410 
Epoch 856/1000 
	 loss: 5.0159, MinusLogProbMetric: 5.0159, val_loss: 5.1243, val_MinusLogProbMetric: 5.1243

Epoch 856: val_loss did not improve from 5.12351
196/196 - 70s - loss: 5.0159 - MinusLogProbMetric: 5.0159 - val_loss: 5.1243 - val_MinusLogProbMetric: 5.1243 - lr: 1.5625e-05 - 70s/epoch - 355ms/step
Epoch 857/1000
2023-09-19 09:45:15.311 
Epoch 857/1000 
	 loss: 5.0158, MinusLogProbMetric: 5.0158, val_loss: 5.1241, val_MinusLogProbMetric: 5.1241

Epoch 857: val_loss did not improve from 5.12351
196/196 - 70s - loss: 5.0158 - MinusLogProbMetric: 5.0158 - val_loss: 5.1241 - val_MinusLogProbMetric: 5.1241 - lr: 1.5625e-05 - 70s/epoch - 357ms/step
Epoch 858/1000
2023-09-19 09:46:24.618 
Epoch 858/1000 
	 loss: 5.0159, MinusLogProbMetric: 5.0159, val_loss: 5.1240, val_MinusLogProbMetric: 5.1240

Epoch 858: val_loss did not improve from 5.12351
196/196 - 69s - loss: 5.0159 - MinusLogProbMetric: 5.0159 - val_loss: 5.1240 - val_MinusLogProbMetric: 5.1240 - lr: 1.5625e-05 - 69s/epoch - 354ms/step
Epoch 859/1000
2023-09-19 09:47:33.859 
Epoch 859/1000 
	 loss: 5.0161, MinusLogProbMetric: 5.0161, val_loss: 5.1233, val_MinusLogProbMetric: 5.1233

Epoch 859: val_loss improved from 5.12351 to 5.12334, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 71s - loss: 5.0161 - MinusLogProbMetric: 5.0161 - val_loss: 5.1233 - val_MinusLogProbMetric: 5.1233 - lr: 1.5625e-05 - 71s/epoch - 360ms/step
Epoch 860/1000
2023-09-19 09:48:44.212 
Epoch 860/1000 
	 loss: 5.0159, MinusLogProbMetric: 5.0159, val_loss: 5.1248, val_MinusLogProbMetric: 5.1248

Epoch 860: val_loss did not improve from 5.12334
196/196 - 69s - loss: 5.0159 - MinusLogProbMetric: 5.0159 - val_loss: 5.1248 - val_MinusLogProbMetric: 5.1248 - lr: 1.5625e-05 - 69s/epoch - 352ms/step
Epoch 861/1000
2023-09-19 09:49:53.678 
Epoch 861/1000 
	 loss: 5.0160, MinusLogProbMetric: 5.0160, val_loss: 5.1239, val_MinusLogProbMetric: 5.1239

Epoch 861: val_loss did not improve from 5.12334
196/196 - 69s - loss: 5.0160 - MinusLogProbMetric: 5.0160 - val_loss: 5.1239 - val_MinusLogProbMetric: 5.1239 - lr: 1.5625e-05 - 69s/epoch - 354ms/step
Epoch 862/1000
2023-09-19 09:51:03.030 
Epoch 862/1000 
	 loss: 5.0159, MinusLogProbMetric: 5.0159, val_loss: 5.1242, val_MinusLogProbMetric: 5.1242

Epoch 862: val_loss did not improve from 5.12334
196/196 - 69s - loss: 5.0159 - MinusLogProbMetric: 5.0159 - val_loss: 5.1242 - val_MinusLogProbMetric: 5.1242 - lr: 1.5625e-05 - 69s/epoch - 354ms/step
Epoch 863/1000
2023-09-19 09:52:12.622 
Epoch 863/1000 
	 loss: 5.0159, MinusLogProbMetric: 5.0159, val_loss: 5.1238, val_MinusLogProbMetric: 5.1238

Epoch 863: val_loss did not improve from 5.12334
196/196 - 70s - loss: 5.0159 - MinusLogProbMetric: 5.0159 - val_loss: 5.1238 - val_MinusLogProbMetric: 5.1238 - lr: 1.5625e-05 - 70s/epoch - 355ms/step
Epoch 864/1000
2023-09-19 09:53:21.787 
Epoch 864/1000 
	 loss: 5.0159, MinusLogProbMetric: 5.0159, val_loss: 5.1248, val_MinusLogProbMetric: 5.1248

Epoch 864: val_loss did not improve from 5.12334
196/196 - 69s - loss: 5.0159 - MinusLogProbMetric: 5.0159 - val_loss: 5.1248 - val_MinusLogProbMetric: 5.1248 - lr: 1.5625e-05 - 69s/epoch - 353ms/step
Epoch 865/1000
2023-09-19 09:54:30.842 
Epoch 865/1000 
	 loss: 5.0161, MinusLogProbMetric: 5.0161, val_loss: 5.1241, val_MinusLogProbMetric: 5.1241

Epoch 865: val_loss did not improve from 5.12334
196/196 - 69s - loss: 5.0161 - MinusLogProbMetric: 5.0161 - val_loss: 5.1241 - val_MinusLogProbMetric: 5.1241 - lr: 1.5625e-05 - 69s/epoch - 352ms/step
Epoch 866/1000
2023-09-19 09:55:39.917 
Epoch 866/1000 
	 loss: 5.0159, MinusLogProbMetric: 5.0159, val_loss: 5.1243, val_MinusLogProbMetric: 5.1243

Epoch 866: val_loss did not improve from 5.12334
196/196 - 69s - loss: 5.0159 - MinusLogProbMetric: 5.0159 - val_loss: 5.1243 - val_MinusLogProbMetric: 5.1243 - lr: 1.5625e-05 - 69s/epoch - 352ms/step
Epoch 867/1000
2023-09-19 09:56:49.149 
Epoch 867/1000 
	 loss: 5.0160, MinusLogProbMetric: 5.0160, val_loss: 5.1241, val_MinusLogProbMetric: 5.1241

Epoch 867: val_loss did not improve from 5.12334
196/196 - 69s - loss: 5.0160 - MinusLogProbMetric: 5.0160 - val_loss: 5.1241 - val_MinusLogProbMetric: 5.1241 - lr: 1.5625e-05 - 69s/epoch - 353ms/step
Epoch 868/1000
2023-09-19 09:57:58.098 
Epoch 868/1000 
	 loss: 5.0158, MinusLogProbMetric: 5.0158, val_loss: 5.1240, val_MinusLogProbMetric: 5.1240

Epoch 868: val_loss did not improve from 5.12334
196/196 - 69s - loss: 5.0158 - MinusLogProbMetric: 5.0158 - val_loss: 5.1240 - val_MinusLogProbMetric: 5.1240 - lr: 1.5625e-05 - 69s/epoch - 352ms/step
Epoch 869/1000
2023-09-19 09:59:07.652 
Epoch 869/1000 
	 loss: 5.0161, MinusLogProbMetric: 5.0161, val_loss: 5.1242, val_MinusLogProbMetric: 5.1242

Epoch 869: val_loss did not improve from 5.12334
196/196 - 70s - loss: 5.0161 - MinusLogProbMetric: 5.0161 - val_loss: 5.1242 - val_MinusLogProbMetric: 5.1242 - lr: 1.5625e-05 - 70s/epoch - 355ms/step
Epoch 870/1000
2023-09-19 10:00:16.996 
Epoch 870/1000 
	 loss: 5.0158, MinusLogProbMetric: 5.0158, val_loss: 5.1242, val_MinusLogProbMetric: 5.1242

Epoch 870: val_loss did not improve from 5.12334
196/196 - 69s - loss: 5.0158 - MinusLogProbMetric: 5.0158 - val_loss: 5.1242 - val_MinusLogProbMetric: 5.1242 - lr: 1.5625e-05 - 69s/epoch - 354ms/step
Epoch 871/1000
2023-09-19 10:01:26.012 
Epoch 871/1000 
	 loss: 5.0159, MinusLogProbMetric: 5.0159, val_loss: 5.1238, val_MinusLogProbMetric: 5.1238

Epoch 871: val_loss did not improve from 5.12334
196/196 - 69s - loss: 5.0159 - MinusLogProbMetric: 5.0159 - val_loss: 5.1238 - val_MinusLogProbMetric: 5.1238 - lr: 1.5625e-05 - 69s/epoch - 352ms/step
Epoch 872/1000
2023-09-19 10:02:35.013 
Epoch 872/1000 
	 loss: 5.0161, MinusLogProbMetric: 5.0161, val_loss: 5.1233, val_MinusLogProbMetric: 5.1233

Epoch 872: val_loss improved from 5.12334 to 5.12332, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0161 - MinusLogProbMetric: 5.0161 - val_loss: 5.1233 - val_MinusLogProbMetric: 5.1233 - lr: 1.5625e-05 - 70s/epoch - 358ms/step
Epoch 873/1000
2023-09-19 10:03:45.434 
Epoch 873/1000 
	 loss: 5.0163, MinusLogProbMetric: 5.0163, val_loss: 5.1236, val_MinusLogProbMetric: 5.1236

Epoch 873: val_loss did not improve from 5.12332
196/196 - 69s - loss: 5.0163 - MinusLogProbMetric: 5.0163 - val_loss: 5.1236 - val_MinusLogProbMetric: 5.1236 - lr: 1.5625e-05 - 69s/epoch - 354ms/step
Epoch 874/1000
2023-09-19 10:04:54.534 
Epoch 874/1000 
	 loss: 5.0159, MinusLogProbMetric: 5.0159, val_loss: 5.1236, val_MinusLogProbMetric: 5.1236

Epoch 874: val_loss did not improve from 5.12332
196/196 - 69s - loss: 5.0159 - MinusLogProbMetric: 5.0159 - val_loss: 5.1236 - val_MinusLogProbMetric: 5.1236 - lr: 1.5625e-05 - 69s/epoch - 353ms/step
Epoch 875/1000
2023-09-19 10:06:03.629 
Epoch 875/1000 
	 loss: 5.0161, MinusLogProbMetric: 5.0161, val_loss: 5.1246, val_MinusLogProbMetric: 5.1246

Epoch 875: val_loss did not improve from 5.12332
196/196 - 69s - loss: 5.0161 - MinusLogProbMetric: 5.0161 - val_loss: 5.1246 - val_MinusLogProbMetric: 5.1246 - lr: 1.5625e-05 - 69s/epoch - 353ms/step
Epoch 876/1000
2023-09-19 10:07:12.638 
Epoch 876/1000 
	 loss: 5.0160, MinusLogProbMetric: 5.0160, val_loss: 5.1235, val_MinusLogProbMetric: 5.1235

Epoch 876: val_loss did not improve from 5.12332
196/196 - 69s - loss: 5.0160 - MinusLogProbMetric: 5.0160 - val_loss: 5.1235 - val_MinusLogProbMetric: 5.1235 - lr: 1.5625e-05 - 69s/epoch - 352ms/step
Epoch 877/1000
2023-09-19 10:08:21.618 
Epoch 877/1000 
	 loss: 5.0156, MinusLogProbMetric: 5.0156, val_loss: 5.1245, val_MinusLogProbMetric: 5.1245

Epoch 877: val_loss did not improve from 5.12332
196/196 - 69s - loss: 5.0156 - MinusLogProbMetric: 5.0156 - val_loss: 5.1245 - val_MinusLogProbMetric: 5.1245 - lr: 1.5625e-05 - 69s/epoch - 352ms/step
Epoch 878/1000
2023-09-19 10:09:30.574 
Epoch 878/1000 
	 loss: 5.0161, MinusLogProbMetric: 5.0161, val_loss: 5.1236, val_MinusLogProbMetric: 5.1236

Epoch 878: val_loss did not improve from 5.12332
196/196 - 69s - loss: 5.0161 - MinusLogProbMetric: 5.0161 - val_loss: 5.1236 - val_MinusLogProbMetric: 5.1236 - lr: 1.5625e-05 - 69s/epoch - 352ms/step
Epoch 879/1000
2023-09-19 10:10:40.113 
Epoch 879/1000 
	 loss: 5.0157, MinusLogProbMetric: 5.0157, val_loss: 5.1234, val_MinusLogProbMetric: 5.1234

Epoch 879: val_loss did not improve from 5.12332
196/196 - 70s - loss: 5.0157 - MinusLogProbMetric: 5.0157 - val_loss: 5.1234 - val_MinusLogProbMetric: 5.1234 - lr: 1.5625e-05 - 70s/epoch - 355ms/step
Epoch 880/1000
2023-09-19 10:11:49.262 
Epoch 880/1000 
	 loss: 5.0158, MinusLogProbMetric: 5.0158, val_loss: 5.1245, val_MinusLogProbMetric: 5.1245

Epoch 880: val_loss did not improve from 5.12332
196/196 - 69s - loss: 5.0158 - MinusLogProbMetric: 5.0158 - val_loss: 5.1245 - val_MinusLogProbMetric: 5.1245 - lr: 1.5625e-05 - 69s/epoch - 353ms/step
Epoch 881/1000
2023-09-19 10:12:57.723 
Epoch 881/1000 
	 loss: 5.0159, MinusLogProbMetric: 5.0159, val_loss: 5.1233, val_MinusLogProbMetric: 5.1233

Epoch 881: val_loss did not improve from 5.12332
196/196 - 68s - loss: 5.0159 - MinusLogProbMetric: 5.0159 - val_loss: 5.1233 - val_MinusLogProbMetric: 5.1233 - lr: 1.5625e-05 - 68s/epoch - 349ms/step
Epoch 882/1000
2023-09-19 10:14:07.120 
Epoch 882/1000 
	 loss: 5.0156, MinusLogProbMetric: 5.0156, val_loss: 5.1244, val_MinusLogProbMetric: 5.1244

Epoch 882: val_loss did not improve from 5.12332
196/196 - 69s - loss: 5.0156 - MinusLogProbMetric: 5.0156 - val_loss: 5.1244 - val_MinusLogProbMetric: 5.1244 - lr: 1.5625e-05 - 69s/epoch - 354ms/step
Epoch 883/1000
2023-09-19 10:15:16.359 
Epoch 883/1000 
	 loss: 5.0159, MinusLogProbMetric: 5.0159, val_loss: 5.1247, val_MinusLogProbMetric: 5.1247

Epoch 883: val_loss did not improve from 5.12332
196/196 - 69s - loss: 5.0159 - MinusLogProbMetric: 5.0159 - val_loss: 5.1247 - val_MinusLogProbMetric: 5.1247 - lr: 1.5625e-05 - 69s/epoch - 353ms/step
Epoch 884/1000
2023-09-19 10:16:25.926 
Epoch 884/1000 
	 loss: 5.0160, MinusLogProbMetric: 5.0160, val_loss: 5.1240, val_MinusLogProbMetric: 5.1240

Epoch 884: val_loss did not improve from 5.12332
196/196 - 70s - loss: 5.0160 - MinusLogProbMetric: 5.0160 - val_loss: 5.1240 - val_MinusLogProbMetric: 5.1240 - lr: 1.5625e-05 - 70s/epoch - 355ms/step
Epoch 885/1000
2023-09-19 10:17:34.802 
Epoch 885/1000 
	 loss: 5.0158, MinusLogProbMetric: 5.0158, val_loss: 5.1244, val_MinusLogProbMetric: 5.1244

Epoch 885: val_loss did not improve from 5.12332
196/196 - 69s - loss: 5.0158 - MinusLogProbMetric: 5.0158 - val_loss: 5.1244 - val_MinusLogProbMetric: 5.1244 - lr: 1.5625e-05 - 69s/epoch - 351ms/step
Epoch 886/1000
2023-09-19 10:18:44.335 
Epoch 886/1000 
	 loss: 5.0162, MinusLogProbMetric: 5.0162, val_loss: 5.1245, val_MinusLogProbMetric: 5.1245

Epoch 886: val_loss did not improve from 5.12332
196/196 - 70s - loss: 5.0162 - MinusLogProbMetric: 5.0162 - val_loss: 5.1245 - val_MinusLogProbMetric: 5.1245 - lr: 1.5625e-05 - 70s/epoch - 355ms/step
Epoch 887/1000
2023-09-19 10:19:53.769 
Epoch 887/1000 
	 loss: 5.0160, MinusLogProbMetric: 5.0160, val_loss: 5.1233, val_MinusLogProbMetric: 5.1233

Epoch 887: val_loss did not improve from 5.12332
196/196 - 69s - loss: 5.0160 - MinusLogProbMetric: 5.0160 - val_loss: 5.1233 - val_MinusLogProbMetric: 5.1233 - lr: 1.5625e-05 - 69s/epoch - 354ms/step
Epoch 888/1000
2023-09-19 10:21:03.342 
Epoch 888/1000 
	 loss: 5.0158, MinusLogProbMetric: 5.0158, val_loss: 5.1245, val_MinusLogProbMetric: 5.1245

Epoch 888: val_loss did not improve from 5.12332
196/196 - 70s - loss: 5.0158 - MinusLogProbMetric: 5.0158 - val_loss: 5.1245 - val_MinusLogProbMetric: 5.1245 - lr: 1.5625e-05 - 70s/epoch - 355ms/step
Epoch 889/1000
2023-09-19 10:22:11.992 
Epoch 889/1000 
	 loss: 5.0163, MinusLogProbMetric: 5.0163, val_loss: 5.1237, val_MinusLogProbMetric: 5.1237

Epoch 889: val_loss did not improve from 5.12332
196/196 - 69s - loss: 5.0163 - MinusLogProbMetric: 5.0163 - val_loss: 5.1237 - val_MinusLogProbMetric: 5.1237 - lr: 1.5625e-05 - 69s/epoch - 350ms/step
Epoch 890/1000
2023-09-19 10:23:21.381 
Epoch 890/1000 
	 loss: 5.0159, MinusLogProbMetric: 5.0159, val_loss: 5.1237, val_MinusLogProbMetric: 5.1237

Epoch 890: val_loss did not improve from 5.12332
196/196 - 69s - loss: 5.0159 - MinusLogProbMetric: 5.0159 - val_loss: 5.1237 - val_MinusLogProbMetric: 5.1237 - lr: 1.5625e-05 - 69s/epoch - 354ms/step
Epoch 891/1000
2023-09-19 10:24:30.658 
Epoch 891/1000 
	 loss: 5.0157, MinusLogProbMetric: 5.0157, val_loss: 5.1242, val_MinusLogProbMetric: 5.1242

Epoch 891: val_loss did not improve from 5.12332
196/196 - 69s - loss: 5.0157 - MinusLogProbMetric: 5.0157 - val_loss: 5.1242 - val_MinusLogProbMetric: 5.1242 - lr: 1.5625e-05 - 69s/epoch - 353ms/step
Epoch 892/1000
2023-09-19 10:25:32.294 
Epoch 892/1000 
	 loss: 5.0159, MinusLogProbMetric: 5.0159, val_loss: 5.1237, val_MinusLogProbMetric: 5.1237

Epoch 892: val_loss did not improve from 5.12332
196/196 - 62s - loss: 5.0159 - MinusLogProbMetric: 5.0159 - val_loss: 5.1237 - val_MinusLogProbMetric: 5.1237 - lr: 1.5625e-05 - 62s/epoch - 314ms/step
Epoch 893/1000
2023-09-19 10:26:37.696 
Epoch 893/1000 
	 loss: 5.0159, MinusLogProbMetric: 5.0159, val_loss: 5.1239, val_MinusLogProbMetric: 5.1239

Epoch 893: val_loss did not improve from 5.12332
196/196 - 65s - loss: 5.0159 - MinusLogProbMetric: 5.0159 - val_loss: 5.1239 - val_MinusLogProbMetric: 5.1239 - lr: 1.5625e-05 - 65s/epoch - 334ms/step
Epoch 894/1000
2023-09-19 10:27:47.071 
Epoch 894/1000 
	 loss: 5.0159, MinusLogProbMetric: 5.0159, val_loss: 5.1238, val_MinusLogProbMetric: 5.1238

Epoch 894: val_loss did not improve from 5.12332
196/196 - 69s - loss: 5.0159 - MinusLogProbMetric: 5.0159 - val_loss: 5.1238 - val_MinusLogProbMetric: 5.1238 - lr: 1.5625e-05 - 69s/epoch - 354ms/step
Epoch 895/1000
2023-09-19 10:28:56.052 
Epoch 895/1000 
	 loss: 5.0159, MinusLogProbMetric: 5.0159, val_loss: 5.1236, val_MinusLogProbMetric: 5.1236

Epoch 895: val_loss did not improve from 5.12332
196/196 - 69s - loss: 5.0159 - MinusLogProbMetric: 5.0159 - val_loss: 5.1236 - val_MinusLogProbMetric: 5.1236 - lr: 1.5625e-05 - 69s/epoch - 352ms/step
Epoch 896/1000
2023-09-19 10:30:05.428 
Epoch 896/1000 
	 loss: 5.0157, MinusLogProbMetric: 5.0157, val_loss: 5.1244, val_MinusLogProbMetric: 5.1244

Epoch 896: val_loss did not improve from 5.12332
196/196 - 69s - loss: 5.0157 - MinusLogProbMetric: 5.0157 - val_loss: 5.1244 - val_MinusLogProbMetric: 5.1244 - lr: 1.5625e-05 - 69s/epoch - 354ms/step
Epoch 897/1000
2023-09-19 10:31:14.863 
Epoch 897/1000 
	 loss: 5.0157, MinusLogProbMetric: 5.0157, val_loss: 5.1244, val_MinusLogProbMetric: 5.1244

Epoch 897: val_loss did not improve from 5.12332
196/196 - 69s - loss: 5.0157 - MinusLogProbMetric: 5.0157 - val_loss: 5.1244 - val_MinusLogProbMetric: 5.1244 - lr: 1.5625e-05 - 69s/epoch - 354ms/step
Epoch 898/1000
2023-09-19 10:32:24.312 
Epoch 898/1000 
	 loss: 5.0158, MinusLogProbMetric: 5.0158, val_loss: 5.1244, val_MinusLogProbMetric: 5.1244

Epoch 898: val_loss did not improve from 5.12332
196/196 - 69s - loss: 5.0158 - MinusLogProbMetric: 5.0158 - val_loss: 5.1244 - val_MinusLogProbMetric: 5.1244 - lr: 1.5625e-05 - 69s/epoch - 354ms/step
Epoch 899/1000
2023-09-19 10:33:34.204 
Epoch 899/1000 
	 loss: 5.0156, MinusLogProbMetric: 5.0156, val_loss: 5.1244, val_MinusLogProbMetric: 5.1244

Epoch 899: val_loss did not improve from 5.12332
196/196 - 70s - loss: 5.0156 - MinusLogProbMetric: 5.0156 - val_loss: 5.1244 - val_MinusLogProbMetric: 5.1244 - lr: 1.5625e-05 - 70s/epoch - 357ms/step
Epoch 900/1000
2023-09-19 10:34:43.741 
Epoch 900/1000 
	 loss: 5.0161, MinusLogProbMetric: 5.0161, val_loss: 5.1239, val_MinusLogProbMetric: 5.1239

Epoch 900: val_loss did not improve from 5.12332
196/196 - 70s - loss: 5.0161 - MinusLogProbMetric: 5.0161 - val_loss: 5.1239 - val_MinusLogProbMetric: 5.1239 - lr: 1.5625e-05 - 70s/epoch - 355ms/step
Epoch 901/1000
2023-09-19 10:35:53.366 
Epoch 901/1000 
	 loss: 5.0156, MinusLogProbMetric: 5.0156, val_loss: 5.1233, val_MinusLogProbMetric: 5.1233

Epoch 901: val_loss improved from 5.12332 to 5.12331, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0156 - MinusLogProbMetric: 5.0156 - val_loss: 5.1233 - val_MinusLogProbMetric: 5.1233 - lr: 1.5625e-05 - 70s/epoch - 360ms/step
Epoch 902/1000
2023-09-19 10:37:04.353 
Epoch 902/1000 
	 loss: 5.0160, MinusLogProbMetric: 5.0160, val_loss: 5.1242, val_MinusLogProbMetric: 5.1242

Epoch 902: val_loss did not improve from 5.12331
196/196 - 70s - loss: 5.0160 - MinusLogProbMetric: 5.0160 - val_loss: 5.1242 - val_MinusLogProbMetric: 5.1242 - lr: 1.5625e-05 - 70s/epoch - 358ms/step
Epoch 903/1000
2023-09-19 10:38:13.453 
Epoch 903/1000 
	 loss: 5.0158, MinusLogProbMetric: 5.0158, val_loss: 5.1239, val_MinusLogProbMetric: 5.1239

Epoch 903: val_loss did not improve from 5.12331
196/196 - 69s - loss: 5.0158 - MinusLogProbMetric: 5.0158 - val_loss: 5.1239 - val_MinusLogProbMetric: 5.1239 - lr: 1.5625e-05 - 69s/epoch - 353ms/step
Epoch 904/1000
2023-09-19 10:39:23.043 
Epoch 904/1000 
	 loss: 5.0156, MinusLogProbMetric: 5.0156, val_loss: 5.1246, val_MinusLogProbMetric: 5.1246

Epoch 904: val_loss did not improve from 5.12331
196/196 - 70s - loss: 5.0156 - MinusLogProbMetric: 5.0156 - val_loss: 5.1246 - val_MinusLogProbMetric: 5.1246 - lr: 1.5625e-05 - 70s/epoch - 355ms/step
Epoch 905/1000
2023-09-19 10:40:32.704 
Epoch 905/1000 
	 loss: 5.0158, MinusLogProbMetric: 5.0158, val_loss: 5.1237, val_MinusLogProbMetric: 5.1237

Epoch 905: val_loss did not improve from 5.12331
196/196 - 70s - loss: 5.0158 - MinusLogProbMetric: 5.0158 - val_loss: 5.1237 - val_MinusLogProbMetric: 5.1237 - lr: 1.5625e-05 - 70s/epoch - 355ms/step
Epoch 906/1000
2023-09-19 10:41:42.500 
Epoch 906/1000 
	 loss: 5.0159, MinusLogProbMetric: 5.0159, val_loss: 5.1244, val_MinusLogProbMetric: 5.1244

Epoch 906: val_loss did not improve from 5.12331
196/196 - 70s - loss: 5.0159 - MinusLogProbMetric: 5.0159 - val_loss: 5.1244 - val_MinusLogProbMetric: 5.1244 - lr: 1.5625e-05 - 70s/epoch - 356ms/step
Epoch 907/1000
2023-09-19 10:42:52.076 
Epoch 907/1000 
	 loss: 5.0158, MinusLogProbMetric: 5.0158, val_loss: 5.1240, val_MinusLogProbMetric: 5.1240

Epoch 907: val_loss did not improve from 5.12331
196/196 - 70s - loss: 5.0158 - MinusLogProbMetric: 5.0158 - val_loss: 5.1240 - val_MinusLogProbMetric: 5.1240 - lr: 1.5625e-05 - 70s/epoch - 355ms/step
Epoch 908/1000
2023-09-19 10:44:01.582 
Epoch 908/1000 
	 loss: 5.0158, MinusLogProbMetric: 5.0158, val_loss: 5.1236, val_MinusLogProbMetric: 5.1236

Epoch 908: val_loss did not improve from 5.12331
196/196 - 70s - loss: 5.0158 - MinusLogProbMetric: 5.0158 - val_loss: 5.1236 - val_MinusLogProbMetric: 5.1236 - lr: 1.5625e-05 - 70s/epoch - 355ms/step
Epoch 909/1000
2023-09-19 10:45:11.036 
Epoch 909/1000 
	 loss: 5.0159, MinusLogProbMetric: 5.0159, val_loss: 5.1244, val_MinusLogProbMetric: 5.1244

Epoch 909: val_loss did not improve from 5.12331
196/196 - 69s - loss: 5.0159 - MinusLogProbMetric: 5.0159 - val_loss: 5.1244 - val_MinusLogProbMetric: 5.1244 - lr: 1.5625e-05 - 69s/epoch - 354ms/step
Epoch 910/1000
2023-09-19 10:46:20.640 
Epoch 910/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1236, val_MinusLogProbMetric: 5.1236

Epoch 910: val_loss did not improve from 5.12331
196/196 - 70s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1236 - val_MinusLogProbMetric: 5.1236 - lr: 7.8125e-06 - 70s/epoch - 355ms/step
Epoch 911/1000
2023-09-19 10:47:29.877 
Epoch 911/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1236, val_MinusLogProbMetric: 5.1236

Epoch 911: val_loss did not improve from 5.12331
196/196 - 69s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1236 - val_MinusLogProbMetric: 5.1236 - lr: 7.8125e-06 - 69s/epoch - 353ms/step
Epoch 912/1000
2023-09-19 10:48:39.253 
Epoch 912/1000 
	 loss: 5.0149, MinusLogProbMetric: 5.0149, val_loss: 5.1231, val_MinusLogProbMetric: 5.1231

Epoch 912: val_loss improved from 5.12331 to 5.12314, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 71s - loss: 5.0149 - MinusLogProbMetric: 5.0149 - val_loss: 5.1231 - val_MinusLogProbMetric: 5.1231 - lr: 7.8125e-06 - 71s/epoch - 360ms/step
Epoch 913/1000
2023-09-19 10:49:49.448 
Epoch 913/1000 
	 loss: 5.0147, MinusLogProbMetric: 5.0147, val_loss: 5.1231, val_MinusLogProbMetric: 5.1231

Epoch 913: val_loss improved from 5.12314 to 5.12309, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0147 - MinusLogProbMetric: 5.0147 - val_loss: 5.1231 - val_MinusLogProbMetric: 5.1231 - lr: 7.8125e-06 - 70s/epoch - 356ms/step
Epoch 914/1000
2023-09-19 10:51:00.153 
Epoch 914/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1233, val_MinusLogProbMetric: 5.1233

Epoch 914: val_loss did not improve from 5.12309
196/196 - 70s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1233 - val_MinusLogProbMetric: 5.1233 - lr: 7.8125e-06 - 70s/epoch - 356ms/step
Epoch 915/1000
2023-09-19 10:52:07.368 
Epoch 915/1000 
	 loss: 5.0149, MinusLogProbMetric: 5.0149, val_loss: 5.1236, val_MinusLogProbMetric: 5.1236

Epoch 915: val_loss did not improve from 5.12309
196/196 - 67s - loss: 5.0149 - MinusLogProbMetric: 5.0149 - val_loss: 5.1236 - val_MinusLogProbMetric: 5.1236 - lr: 7.8125e-06 - 67s/epoch - 343ms/step
Epoch 916/1000
2023-09-19 10:53:08.057 
Epoch 916/1000 
	 loss: 5.0150, MinusLogProbMetric: 5.0150, val_loss: 5.1233, val_MinusLogProbMetric: 5.1233

Epoch 916: val_loss did not improve from 5.12309
196/196 - 61s - loss: 5.0150 - MinusLogProbMetric: 5.0150 - val_loss: 5.1233 - val_MinusLogProbMetric: 5.1233 - lr: 7.8125e-06 - 61s/epoch - 310ms/step
Epoch 917/1000
2023-09-19 10:54:10.591 
Epoch 917/1000 
	 loss: 5.0149, MinusLogProbMetric: 5.0149, val_loss: 5.1230, val_MinusLogProbMetric: 5.1230

Epoch 917: val_loss improved from 5.12309 to 5.12300, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 63s - loss: 5.0149 - MinusLogProbMetric: 5.0149 - val_loss: 5.1230 - val_MinusLogProbMetric: 5.1230 - lr: 7.8125e-06 - 63s/epoch - 324ms/step
Epoch 918/1000
2023-09-19 10:55:12.050 
Epoch 918/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1237, val_MinusLogProbMetric: 5.1237

Epoch 918: val_loss did not improve from 5.12300
196/196 - 61s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1237 - val_MinusLogProbMetric: 5.1237 - lr: 7.8125e-06 - 61s/epoch - 309ms/step
Epoch 919/1000
2023-09-19 10:56:12.150 
Epoch 919/1000 
	 loss: 5.0147, MinusLogProbMetric: 5.0147, val_loss: 5.1231, val_MinusLogProbMetric: 5.1231

Epoch 919: val_loss did not improve from 5.12300
196/196 - 60s - loss: 5.0147 - MinusLogProbMetric: 5.0147 - val_loss: 5.1231 - val_MinusLogProbMetric: 5.1231 - lr: 7.8125e-06 - 60s/epoch - 307ms/step
Epoch 920/1000
2023-09-19 10:57:15.707 
Epoch 920/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1231, val_MinusLogProbMetric: 5.1231

Epoch 920: val_loss did not improve from 5.12300
196/196 - 64s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1231 - val_MinusLogProbMetric: 5.1231 - lr: 7.8125e-06 - 64s/epoch - 324ms/step
Epoch 921/1000
2023-09-19 10:58:23.114 
Epoch 921/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1231, val_MinusLogProbMetric: 5.1231

Epoch 921: val_loss did not improve from 5.12300
196/196 - 67s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1231 - val_MinusLogProbMetric: 5.1231 - lr: 7.8125e-06 - 67s/epoch - 344ms/step
Epoch 922/1000
2023-09-19 10:59:31.956 
Epoch 922/1000 
	 loss: 5.0150, MinusLogProbMetric: 5.0150, val_loss: 5.1233, val_MinusLogProbMetric: 5.1233

Epoch 922: val_loss did not improve from 5.12300
196/196 - 69s - loss: 5.0150 - MinusLogProbMetric: 5.0150 - val_loss: 5.1233 - val_MinusLogProbMetric: 5.1233 - lr: 7.8125e-06 - 69s/epoch - 351ms/step
Epoch 923/1000
2023-09-19 11:00:40.122 
Epoch 923/1000 
	 loss: 5.0146, MinusLogProbMetric: 5.0146, val_loss: 5.1238, val_MinusLogProbMetric: 5.1238

Epoch 923: val_loss did not improve from 5.12300
196/196 - 68s - loss: 5.0146 - MinusLogProbMetric: 5.0146 - val_loss: 5.1238 - val_MinusLogProbMetric: 5.1238 - lr: 7.8125e-06 - 68s/epoch - 348ms/step
Epoch 924/1000
2023-09-19 11:01:49.259 
Epoch 924/1000 
	 loss: 5.0150, MinusLogProbMetric: 5.0150, val_loss: 5.1230, val_MinusLogProbMetric: 5.1230

Epoch 924: val_loss improved from 5.12300 to 5.12296, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0150 - MinusLogProbMetric: 5.0150 - val_loss: 5.1230 - val_MinusLogProbMetric: 5.1230 - lr: 7.8125e-06 - 70s/epoch - 357ms/step
Epoch 925/1000
2023-09-19 11:02:59.076 
Epoch 925/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1236, val_MinusLogProbMetric: 5.1236

Epoch 925: val_loss did not improve from 5.12296
196/196 - 69s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1236 - val_MinusLogProbMetric: 5.1236 - lr: 7.8125e-06 - 69s/epoch - 352ms/step
Epoch 926/1000
2023-09-19 11:04:08.146 
Epoch 926/1000 
	 loss: 5.0149, MinusLogProbMetric: 5.0149, val_loss: 5.1238, val_MinusLogProbMetric: 5.1238

Epoch 926: val_loss did not improve from 5.12296
196/196 - 69s - loss: 5.0149 - MinusLogProbMetric: 5.0149 - val_loss: 5.1238 - val_MinusLogProbMetric: 5.1238 - lr: 7.8125e-06 - 69s/epoch - 352ms/step
Epoch 927/1000
2023-09-19 11:05:16.553 
Epoch 927/1000 
	 loss: 5.0150, MinusLogProbMetric: 5.0150, val_loss: 5.1233, val_MinusLogProbMetric: 5.1233

Epoch 927: val_loss did not improve from 5.12296
196/196 - 68s - loss: 5.0150 - MinusLogProbMetric: 5.0150 - val_loss: 5.1233 - val_MinusLogProbMetric: 5.1233 - lr: 7.8125e-06 - 68s/epoch - 349ms/step
Epoch 928/1000
2023-09-19 11:06:25.431 
Epoch 928/1000 
	 loss: 5.0150, MinusLogProbMetric: 5.0150, val_loss: 5.1233, val_MinusLogProbMetric: 5.1233

Epoch 928: val_loss did not improve from 5.12296
196/196 - 69s - loss: 5.0150 - MinusLogProbMetric: 5.0150 - val_loss: 5.1233 - val_MinusLogProbMetric: 5.1233 - lr: 7.8125e-06 - 69s/epoch - 351ms/step
Epoch 929/1000
2023-09-19 11:07:34.684 
Epoch 929/1000 
	 loss: 5.0147, MinusLogProbMetric: 5.0147, val_loss: 5.1233, val_MinusLogProbMetric: 5.1233

Epoch 929: val_loss did not improve from 5.12296
196/196 - 69s - loss: 5.0147 - MinusLogProbMetric: 5.0147 - val_loss: 5.1233 - val_MinusLogProbMetric: 5.1233 - lr: 7.8125e-06 - 69s/epoch - 353ms/step
Epoch 930/1000
2023-09-19 11:08:43.422 
Epoch 930/1000 
	 loss: 5.0149, MinusLogProbMetric: 5.0149, val_loss: 5.1231, val_MinusLogProbMetric: 5.1231

Epoch 930: val_loss did not improve from 5.12296
196/196 - 69s - loss: 5.0149 - MinusLogProbMetric: 5.0149 - val_loss: 5.1231 - val_MinusLogProbMetric: 5.1231 - lr: 7.8125e-06 - 69s/epoch - 351ms/step
Epoch 931/1000
2023-09-19 11:09:51.981 
Epoch 931/1000 
	 loss: 5.0147, MinusLogProbMetric: 5.0147, val_loss: 5.1228, val_MinusLogProbMetric: 5.1228

Epoch 931: val_loss improved from 5.12296 to 5.12277, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0147 - MinusLogProbMetric: 5.0147 - val_loss: 5.1228 - val_MinusLogProbMetric: 5.1228 - lr: 7.8125e-06 - 70s/epoch - 356ms/step
Epoch 932/1000
2023-09-19 11:11:02.264 
Epoch 932/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1239, val_MinusLogProbMetric: 5.1239

Epoch 932: val_loss did not improve from 5.12277
196/196 - 69s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1239 - val_MinusLogProbMetric: 5.1239 - lr: 7.8125e-06 - 69s/epoch - 352ms/step
Epoch 933/1000
2023-09-19 11:12:11.380 
Epoch 933/1000 
	 loss: 5.0147, MinusLogProbMetric: 5.0147, val_loss: 5.1239, val_MinusLogProbMetric: 5.1239

Epoch 933: val_loss did not improve from 5.12277
196/196 - 69s - loss: 5.0147 - MinusLogProbMetric: 5.0147 - val_loss: 5.1239 - val_MinusLogProbMetric: 5.1239 - lr: 7.8125e-06 - 69s/epoch - 353ms/step
Epoch 934/1000
2023-09-19 11:13:20.297 
Epoch 934/1000 
	 loss: 5.0147, MinusLogProbMetric: 5.0147, val_loss: 5.1228, val_MinusLogProbMetric: 5.1228

Epoch 934: val_loss did not improve from 5.12277
196/196 - 69s - loss: 5.0147 - MinusLogProbMetric: 5.0147 - val_loss: 5.1228 - val_MinusLogProbMetric: 5.1228 - lr: 7.8125e-06 - 69s/epoch - 352ms/step
Epoch 935/1000
2023-09-19 11:14:29.725 
Epoch 935/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1235, val_MinusLogProbMetric: 5.1235

Epoch 935: val_loss did not improve from 5.12277
196/196 - 69s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1235 - val_MinusLogProbMetric: 5.1235 - lr: 7.8125e-06 - 69s/epoch - 354ms/step
Epoch 936/1000
2023-09-19 11:15:38.913 
Epoch 936/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1228, val_MinusLogProbMetric: 5.1228

Epoch 936: val_loss did not improve from 5.12277
196/196 - 69s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1228 - val_MinusLogProbMetric: 5.1228 - lr: 7.8125e-06 - 69s/epoch - 353ms/step
Epoch 937/1000
2023-09-19 11:16:48.039 
Epoch 937/1000 
	 loss: 5.0149, MinusLogProbMetric: 5.0149, val_loss: 5.1231, val_MinusLogProbMetric: 5.1231

Epoch 937: val_loss did not improve from 5.12277
196/196 - 69s - loss: 5.0149 - MinusLogProbMetric: 5.0149 - val_loss: 5.1231 - val_MinusLogProbMetric: 5.1231 - lr: 7.8125e-06 - 69s/epoch - 353ms/step
Epoch 938/1000
2023-09-19 11:17:56.735 
Epoch 938/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1234, val_MinusLogProbMetric: 5.1234

Epoch 938: val_loss did not improve from 5.12277
196/196 - 69s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1234 - val_MinusLogProbMetric: 5.1234 - lr: 7.8125e-06 - 69s/epoch - 350ms/step
Epoch 939/1000
2023-09-19 11:19:05.762 
Epoch 939/1000 
	 loss: 5.0150, MinusLogProbMetric: 5.0150, val_loss: 5.1235, val_MinusLogProbMetric: 5.1235

Epoch 939: val_loss did not improve from 5.12277
196/196 - 69s - loss: 5.0150 - MinusLogProbMetric: 5.0150 - val_loss: 5.1235 - val_MinusLogProbMetric: 5.1235 - lr: 7.8125e-06 - 69s/epoch - 352ms/step
Epoch 940/1000
2023-09-19 11:20:14.710 
Epoch 940/1000 
	 loss: 5.0145, MinusLogProbMetric: 5.0145, val_loss: 5.1231, val_MinusLogProbMetric: 5.1231

Epoch 940: val_loss did not improve from 5.12277
196/196 - 69s - loss: 5.0145 - MinusLogProbMetric: 5.0145 - val_loss: 5.1231 - val_MinusLogProbMetric: 5.1231 - lr: 7.8125e-06 - 69s/epoch - 352ms/step
Epoch 941/1000
2023-09-19 11:21:22.357 
Epoch 941/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1229, val_MinusLogProbMetric: 5.1229

Epoch 941: val_loss did not improve from 5.12277
196/196 - 68s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1229 - val_MinusLogProbMetric: 5.1229 - lr: 7.8125e-06 - 68s/epoch - 345ms/step
Epoch 942/1000
2023-09-19 11:22:23.458 
Epoch 942/1000 
	 loss: 5.0147, MinusLogProbMetric: 5.0147, val_loss: 5.1232, val_MinusLogProbMetric: 5.1232

Epoch 942: val_loss did not improve from 5.12277
196/196 - 61s - loss: 5.0147 - MinusLogProbMetric: 5.0147 - val_loss: 5.1232 - val_MinusLogProbMetric: 5.1232 - lr: 7.8125e-06 - 61s/epoch - 312ms/step
Epoch 943/1000
2023-09-19 11:23:22.582 
Epoch 943/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1232, val_MinusLogProbMetric: 5.1232

Epoch 943: val_loss did not improve from 5.12277
196/196 - 59s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1232 - val_MinusLogProbMetric: 5.1232 - lr: 7.8125e-06 - 59s/epoch - 302ms/step
Epoch 944/1000
2023-09-19 11:24:26.337 
Epoch 944/1000 
	 loss: 5.0149, MinusLogProbMetric: 5.0149, val_loss: 5.1231, val_MinusLogProbMetric: 5.1231

Epoch 944: val_loss did not improve from 5.12277
196/196 - 64s - loss: 5.0149 - MinusLogProbMetric: 5.0149 - val_loss: 5.1231 - val_MinusLogProbMetric: 5.1231 - lr: 7.8125e-06 - 64s/epoch - 325ms/step
Epoch 945/1000
2023-09-19 11:25:35.319 
Epoch 945/1000 
	 loss: 5.0146, MinusLogProbMetric: 5.0146, val_loss: 5.1234, val_MinusLogProbMetric: 5.1234

Epoch 945: val_loss did not improve from 5.12277
196/196 - 69s - loss: 5.0146 - MinusLogProbMetric: 5.0146 - val_loss: 5.1234 - val_MinusLogProbMetric: 5.1234 - lr: 7.8125e-06 - 69s/epoch - 352ms/step
Epoch 946/1000
2023-09-19 11:26:43.304 
Epoch 946/1000 
	 loss: 5.0150, MinusLogProbMetric: 5.0150, val_loss: 5.1234, val_MinusLogProbMetric: 5.1234

Epoch 946: val_loss did not improve from 5.12277
196/196 - 68s - loss: 5.0150 - MinusLogProbMetric: 5.0150 - val_loss: 5.1234 - val_MinusLogProbMetric: 5.1234 - lr: 7.8125e-06 - 68s/epoch - 347ms/step
Epoch 947/1000
2023-09-19 11:27:51.566 
Epoch 947/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1230, val_MinusLogProbMetric: 5.1230

Epoch 947: val_loss did not improve from 5.12277
196/196 - 68s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1230 - val_MinusLogProbMetric: 5.1230 - lr: 7.8125e-06 - 68s/epoch - 348ms/step
Epoch 948/1000
2023-09-19 11:28:59.965 
Epoch 948/1000 
	 loss: 5.0146, MinusLogProbMetric: 5.0146, val_loss: 5.1230, val_MinusLogProbMetric: 5.1230

Epoch 948: val_loss did not improve from 5.12277
196/196 - 68s - loss: 5.0146 - MinusLogProbMetric: 5.0146 - val_loss: 5.1230 - val_MinusLogProbMetric: 5.1230 - lr: 7.8125e-06 - 68s/epoch - 349ms/step
Epoch 949/1000
2023-09-19 11:30:08.462 
Epoch 949/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1226, val_MinusLogProbMetric: 5.1226

Epoch 949: val_loss improved from 5.12277 to 5.12263, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_197/weights/best_weights.h5
196/196 - 70s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1226 - val_MinusLogProbMetric: 5.1226 - lr: 7.8125e-06 - 70s/epoch - 356ms/step
Epoch 950/1000
2023-09-19 11:31:18.644 
Epoch 950/1000 
	 loss: 5.0146, MinusLogProbMetric: 5.0146, val_loss: 5.1233, val_MinusLogProbMetric: 5.1233

Epoch 950: val_loss did not improve from 5.12263
196/196 - 69s - loss: 5.0146 - MinusLogProbMetric: 5.0146 - val_loss: 5.1233 - val_MinusLogProbMetric: 5.1233 - lr: 7.8125e-06 - 69s/epoch - 351ms/step
Epoch 951/1000
2023-09-19 11:32:27.413 
Epoch 951/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1231, val_MinusLogProbMetric: 5.1231

Epoch 951: val_loss did not improve from 5.12263
196/196 - 69s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1231 - val_MinusLogProbMetric: 5.1231 - lr: 7.8125e-06 - 69s/epoch - 351ms/step
Epoch 952/1000
2023-09-19 11:33:35.893 
Epoch 952/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1232, val_MinusLogProbMetric: 5.1232

Epoch 952: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1232 - val_MinusLogProbMetric: 5.1232 - lr: 7.8125e-06 - 68s/epoch - 349ms/step
Epoch 953/1000
2023-09-19 11:34:44.265 
Epoch 953/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1233, val_MinusLogProbMetric: 5.1233

Epoch 953: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1233 - val_MinusLogProbMetric: 5.1233 - lr: 7.8125e-06 - 68s/epoch - 349ms/step
Epoch 954/1000
2023-09-19 11:35:52.815 
Epoch 954/1000 
	 loss: 5.0145, MinusLogProbMetric: 5.0145, val_loss: 5.1230, val_MinusLogProbMetric: 5.1230

Epoch 954: val_loss did not improve from 5.12263
196/196 - 69s - loss: 5.0145 - MinusLogProbMetric: 5.0145 - val_loss: 5.1230 - val_MinusLogProbMetric: 5.1230 - lr: 7.8125e-06 - 69s/epoch - 350ms/step
Epoch 955/1000
2023-09-19 11:37:01.399 
Epoch 955/1000 
	 loss: 5.0145, MinusLogProbMetric: 5.0145, val_loss: 5.1238, val_MinusLogProbMetric: 5.1238

Epoch 955: val_loss did not improve from 5.12263
196/196 - 69s - loss: 5.0145 - MinusLogProbMetric: 5.0145 - val_loss: 5.1238 - val_MinusLogProbMetric: 5.1238 - lr: 7.8125e-06 - 69s/epoch - 350ms/step
Epoch 956/1000
2023-09-19 11:38:10.160 
Epoch 956/1000 
	 loss: 5.0146, MinusLogProbMetric: 5.0146, val_loss: 5.1238, val_MinusLogProbMetric: 5.1238

Epoch 956: val_loss did not improve from 5.12263
196/196 - 69s - loss: 5.0146 - MinusLogProbMetric: 5.0146 - val_loss: 5.1238 - val_MinusLogProbMetric: 5.1238 - lr: 7.8125e-06 - 69s/epoch - 351ms/step
Epoch 957/1000
2023-09-19 11:39:19.075 
Epoch 957/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1236, val_MinusLogProbMetric: 5.1236

Epoch 957: val_loss did not improve from 5.12263
196/196 - 69s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1236 - val_MinusLogProbMetric: 5.1236 - lr: 7.8125e-06 - 69s/epoch - 352ms/step
Epoch 958/1000
2023-09-19 11:40:27.330 
Epoch 958/1000 
	 loss: 5.0147, MinusLogProbMetric: 5.0147, val_loss: 5.1236, val_MinusLogProbMetric: 5.1236

Epoch 958: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0147 - MinusLogProbMetric: 5.0147 - val_loss: 5.1236 - val_MinusLogProbMetric: 5.1236 - lr: 7.8125e-06 - 68s/epoch - 348ms/step
Epoch 959/1000
2023-09-19 11:41:35.367 
Epoch 959/1000 
	 loss: 5.0149, MinusLogProbMetric: 5.0149, val_loss: 5.1233, val_MinusLogProbMetric: 5.1233

Epoch 959: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0149 - MinusLogProbMetric: 5.0149 - val_loss: 5.1233 - val_MinusLogProbMetric: 5.1233 - lr: 7.8125e-06 - 68s/epoch - 347ms/step
Epoch 960/1000
2023-09-19 11:42:44.584 
Epoch 960/1000 
	 loss: 5.0149, MinusLogProbMetric: 5.0149, val_loss: 5.1234, val_MinusLogProbMetric: 5.1234

Epoch 960: val_loss did not improve from 5.12263
196/196 - 69s - loss: 5.0149 - MinusLogProbMetric: 5.0149 - val_loss: 5.1234 - val_MinusLogProbMetric: 5.1234 - lr: 7.8125e-06 - 69s/epoch - 353ms/step
Epoch 961/1000
2023-09-19 11:43:53.068 
Epoch 961/1000 
	 loss: 5.0146, MinusLogProbMetric: 5.0146, val_loss: 5.1235, val_MinusLogProbMetric: 5.1235

Epoch 961: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0146 - MinusLogProbMetric: 5.0146 - val_loss: 5.1235 - val_MinusLogProbMetric: 5.1235 - lr: 7.8125e-06 - 68s/epoch - 349ms/step
Epoch 962/1000
2023-09-19 11:45:01.696 
Epoch 962/1000 
	 loss: 5.0150, MinusLogProbMetric: 5.0150, val_loss: 5.1234, val_MinusLogProbMetric: 5.1234

Epoch 962: val_loss did not improve from 5.12263
196/196 - 69s - loss: 5.0150 - MinusLogProbMetric: 5.0150 - val_loss: 5.1234 - val_MinusLogProbMetric: 5.1234 - lr: 7.8125e-06 - 69s/epoch - 350ms/step
Epoch 963/1000
2023-09-19 11:46:09.981 
Epoch 963/1000 
	 loss: 5.0149, MinusLogProbMetric: 5.0149, val_loss: 5.1243, val_MinusLogProbMetric: 5.1243

Epoch 963: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0149 - MinusLogProbMetric: 5.0149 - val_loss: 5.1243 - val_MinusLogProbMetric: 5.1243 - lr: 7.8125e-06 - 68s/epoch - 348ms/step
Epoch 964/1000
2023-09-19 11:47:18.566 
Epoch 964/1000 
	 loss: 5.0146, MinusLogProbMetric: 5.0146, val_loss: 5.1235, val_MinusLogProbMetric: 5.1235

Epoch 964: val_loss did not improve from 5.12263
196/196 - 69s - loss: 5.0146 - MinusLogProbMetric: 5.0146 - val_loss: 5.1235 - val_MinusLogProbMetric: 5.1235 - lr: 7.8125e-06 - 69s/epoch - 350ms/step
Epoch 965/1000
2023-09-19 11:48:26.837 
Epoch 965/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1234, val_MinusLogProbMetric: 5.1234

Epoch 965: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1234 - val_MinusLogProbMetric: 5.1234 - lr: 7.8125e-06 - 68s/epoch - 348ms/step
Epoch 966/1000
2023-09-19 11:49:35.510 
Epoch 966/1000 
	 loss: 5.0147, MinusLogProbMetric: 5.0147, val_loss: 5.1227, val_MinusLogProbMetric: 5.1227

Epoch 966: val_loss did not improve from 5.12263
196/196 - 69s - loss: 5.0147 - MinusLogProbMetric: 5.0147 - val_loss: 5.1227 - val_MinusLogProbMetric: 5.1227 - lr: 7.8125e-06 - 69s/epoch - 350ms/step
Epoch 967/1000
2023-09-19 11:50:44.665 
Epoch 967/1000 
	 loss: 5.0147, MinusLogProbMetric: 5.0147, val_loss: 5.1237, val_MinusLogProbMetric: 5.1237

Epoch 967: val_loss did not improve from 5.12263
196/196 - 69s - loss: 5.0147 - MinusLogProbMetric: 5.0147 - val_loss: 5.1237 - val_MinusLogProbMetric: 5.1237 - lr: 7.8125e-06 - 69s/epoch - 353ms/step
Epoch 968/1000
2023-09-19 11:51:53.155 
Epoch 968/1000 
	 loss: 5.0147, MinusLogProbMetric: 5.0147, val_loss: 5.1234, val_MinusLogProbMetric: 5.1234

Epoch 968: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0147 - MinusLogProbMetric: 5.0147 - val_loss: 5.1234 - val_MinusLogProbMetric: 5.1234 - lr: 7.8125e-06 - 68s/epoch - 349ms/step
Epoch 969/1000
2023-09-19 11:53:01.028 
Epoch 969/1000 
	 loss: 5.0149, MinusLogProbMetric: 5.0149, val_loss: 5.1234, val_MinusLogProbMetric: 5.1234

Epoch 969: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0149 - MinusLogProbMetric: 5.0149 - val_loss: 5.1234 - val_MinusLogProbMetric: 5.1234 - lr: 7.8125e-06 - 68s/epoch - 346ms/step
Epoch 970/1000
2023-09-19 11:54:09.374 
Epoch 970/1000 
	 loss: 5.0147, MinusLogProbMetric: 5.0147, val_loss: 5.1229, val_MinusLogProbMetric: 5.1229

Epoch 970: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0147 - MinusLogProbMetric: 5.0147 - val_loss: 5.1229 - val_MinusLogProbMetric: 5.1229 - lr: 7.8125e-06 - 68s/epoch - 349ms/step
Epoch 971/1000
2023-09-19 11:55:17.374 
Epoch 971/1000 
	 loss: 5.0149, MinusLogProbMetric: 5.0149, val_loss: 5.1238, val_MinusLogProbMetric: 5.1238

Epoch 971: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0149 - MinusLogProbMetric: 5.0149 - val_loss: 5.1238 - val_MinusLogProbMetric: 5.1238 - lr: 7.8125e-06 - 68s/epoch - 347ms/step
Epoch 972/1000
2023-09-19 11:56:25.617 
Epoch 972/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1234, val_MinusLogProbMetric: 5.1234

Epoch 972: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1234 - val_MinusLogProbMetric: 5.1234 - lr: 7.8125e-06 - 68s/epoch - 348ms/step
Epoch 973/1000
2023-09-19 11:57:34.058 
Epoch 973/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1234, val_MinusLogProbMetric: 5.1234

Epoch 973: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1234 - val_MinusLogProbMetric: 5.1234 - lr: 7.8125e-06 - 68s/epoch - 349ms/step
Epoch 974/1000
2023-09-19 11:58:42.893 
Epoch 974/1000 
	 loss: 5.0149, MinusLogProbMetric: 5.0149, val_loss: 5.1233, val_MinusLogProbMetric: 5.1233

Epoch 974: val_loss did not improve from 5.12263
196/196 - 69s - loss: 5.0149 - MinusLogProbMetric: 5.0149 - val_loss: 5.1233 - val_MinusLogProbMetric: 5.1233 - lr: 7.8125e-06 - 69s/epoch - 351ms/step
Epoch 975/1000
2023-09-19 11:59:51.395 
Epoch 975/1000 
	 loss: 5.0146, MinusLogProbMetric: 5.0146, val_loss: 5.1235, val_MinusLogProbMetric: 5.1235

Epoch 975: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0146 - MinusLogProbMetric: 5.0146 - val_loss: 5.1235 - val_MinusLogProbMetric: 5.1235 - lr: 7.8125e-06 - 68s/epoch - 349ms/step
Epoch 976/1000
2023-09-19 12:01:00.125 
Epoch 976/1000 
	 loss: 5.0146, MinusLogProbMetric: 5.0146, val_loss: 5.1234, val_MinusLogProbMetric: 5.1234

Epoch 976: val_loss did not improve from 5.12263
196/196 - 69s - loss: 5.0146 - MinusLogProbMetric: 5.0146 - val_loss: 5.1234 - val_MinusLogProbMetric: 5.1234 - lr: 7.8125e-06 - 69s/epoch - 351ms/step
Epoch 977/1000
2023-09-19 12:02:08.191 
Epoch 977/1000 
	 loss: 5.0146, MinusLogProbMetric: 5.0146, val_loss: 5.1232, val_MinusLogProbMetric: 5.1232

Epoch 977: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0146 - MinusLogProbMetric: 5.0146 - val_loss: 5.1232 - val_MinusLogProbMetric: 5.1232 - lr: 7.8125e-06 - 68s/epoch - 347ms/step
Epoch 978/1000
2023-09-19 12:03:16.054 
Epoch 978/1000 
	 loss: 5.0147, MinusLogProbMetric: 5.0147, val_loss: 5.1236, val_MinusLogProbMetric: 5.1236

Epoch 978: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0147 - MinusLogProbMetric: 5.0147 - val_loss: 5.1236 - val_MinusLogProbMetric: 5.1236 - lr: 7.8125e-06 - 68s/epoch - 346ms/step
Epoch 979/1000
2023-09-19 12:04:24.081 
Epoch 979/1000 
	 loss: 5.0146, MinusLogProbMetric: 5.0146, val_loss: 5.1237, val_MinusLogProbMetric: 5.1237

Epoch 979: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0146 - MinusLogProbMetric: 5.0146 - val_loss: 5.1237 - val_MinusLogProbMetric: 5.1237 - lr: 7.8125e-06 - 68s/epoch - 347ms/step
Epoch 980/1000
2023-09-19 12:05:32.515 
Epoch 980/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1233, val_MinusLogProbMetric: 5.1233

Epoch 980: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1233 - val_MinusLogProbMetric: 5.1233 - lr: 7.8125e-06 - 68s/epoch - 349ms/step
Epoch 981/1000
2023-09-19 12:06:40.452 
Epoch 981/1000 
	 loss: 5.0147, MinusLogProbMetric: 5.0147, val_loss: 5.1232, val_MinusLogProbMetric: 5.1232

Epoch 981: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0147 - MinusLogProbMetric: 5.0147 - val_loss: 5.1232 - val_MinusLogProbMetric: 5.1232 - lr: 7.8125e-06 - 68s/epoch - 347ms/step
Epoch 982/1000
2023-09-19 12:07:48.595 
Epoch 982/1000 
	 loss: 5.0146, MinusLogProbMetric: 5.0146, val_loss: 5.1235, val_MinusLogProbMetric: 5.1235

Epoch 982: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0146 - MinusLogProbMetric: 5.0146 - val_loss: 5.1235 - val_MinusLogProbMetric: 5.1235 - lr: 7.8125e-06 - 68s/epoch - 348ms/step
Epoch 983/1000
2023-09-19 12:08:56.523 
Epoch 983/1000 
	 loss: 5.0146, MinusLogProbMetric: 5.0146, val_loss: 5.1242, val_MinusLogProbMetric: 5.1242

Epoch 983: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0146 - MinusLogProbMetric: 5.0146 - val_loss: 5.1242 - val_MinusLogProbMetric: 5.1242 - lr: 7.8125e-06 - 68s/epoch - 347ms/step
Epoch 984/1000
2023-09-19 12:10:04.073 
Epoch 984/1000 
	 loss: 5.0147, MinusLogProbMetric: 5.0147, val_loss: 5.1231, val_MinusLogProbMetric: 5.1231

Epoch 984: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0147 - MinusLogProbMetric: 5.0147 - val_loss: 5.1231 - val_MinusLogProbMetric: 5.1231 - lr: 7.8125e-06 - 68s/epoch - 345ms/step
Epoch 985/1000
2023-09-19 12:11:11.714 
Epoch 985/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1233, val_MinusLogProbMetric: 5.1233

Epoch 985: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1233 - val_MinusLogProbMetric: 5.1233 - lr: 7.8125e-06 - 68s/epoch - 345ms/step
Epoch 986/1000
2023-09-19 12:12:20.159 
Epoch 986/1000 
	 loss: 5.0147, MinusLogProbMetric: 5.0147, val_loss: 5.1235, val_MinusLogProbMetric: 5.1235

Epoch 986: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0147 - MinusLogProbMetric: 5.0147 - val_loss: 5.1235 - val_MinusLogProbMetric: 5.1235 - lr: 7.8125e-06 - 68s/epoch - 349ms/step
Epoch 987/1000
2023-09-19 12:13:28.351 
Epoch 987/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1240, val_MinusLogProbMetric: 5.1240

Epoch 987: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1240 - val_MinusLogProbMetric: 5.1240 - lr: 7.8125e-06 - 68s/epoch - 348ms/step
Epoch 988/1000
2023-09-19 12:14:36.567 
Epoch 988/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1230, val_MinusLogProbMetric: 5.1230

Epoch 988: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1230 - val_MinusLogProbMetric: 5.1230 - lr: 7.8125e-06 - 68s/epoch - 348ms/step
Epoch 989/1000
2023-09-19 12:15:44.825 
Epoch 989/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1236, val_MinusLogProbMetric: 5.1236

Epoch 989: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1236 - val_MinusLogProbMetric: 5.1236 - lr: 7.8125e-06 - 68s/epoch - 348ms/step
Epoch 990/1000
2023-09-19 12:16:52.869 
Epoch 990/1000 
	 loss: 5.0149, MinusLogProbMetric: 5.0149, val_loss: 5.1235, val_MinusLogProbMetric: 5.1235

Epoch 990: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0149 - MinusLogProbMetric: 5.0149 - val_loss: 5.1235 - val_MinusLogProbMetric: 5.1235 - lr: 7.8125e-06 - 68s/epoch - 347ms/step
Epoch 991/1000
2023-09-19 12:18:01.160 
Epoch 991/1000 
	 loss: 5.0147, MinusLogProbMetric: 5.0147, val_loss: 5.1239, val_MinusLogProbMetric: 5.1239

Epoch 991: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0147 - MinusLogProbMetric: 5.0147 - val_loss: 5.1239 - val_MinusLogProbMetric: 5.1239 - lr: 7.8125e-06 - 68s/epoch - 348ms/step
Epoch 992/1000
2023-09-19 12:19:08.430 
Epoch 992/1000 
	 loss: 5.0147, MinusLogProbMetric: 5.0147, val_loss: 5.1232, val_MinusLogProbMetric: 5.1232

Epoch 992: val_loss did not improve from 5.12263
196/196 - 67s - loss: 5.0147 - MinusLogProbMetric: 5.0147 - val_loss: 5.1232 - val_MinusLogProbMetric: 5.1232 - lr: 7.8125e-06 - 67s/epoch - 343ms/step
Epoch 993/1000
2023-09-19 12:20:16.580 
Epoch 993/1000 
	 loss: 5.0147, MinusLogProbMetric: 5.0147, val_loss: 5.1242, val_MinusLogProbMetric: 5.1242

Epoch 993: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0147 - MinusLogProbMetric: 5.0147 - val_loss: 5.1242 - val_MinusLogProbMetric: 5.1242 - lr: 7.8125e-06 - 68s/epoch - 348ms/step
Epoch 994/1000
2023-09-19 12:21:24.256 
Epoch 994/1000 
	 loss: 5.0149, MinusLogProbMetric: 5.0149, val_loss: 5.1229, val_MinusLogProbMetric: 5.1229

Epoch 994: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0149 - MinusLogProbMetric: 5.0149 - val_loss: 5.1229 - val_MinusLogProbMetric: 5.1229 - lr: 7.8125e-06 - 68s/epoch - 345ms/step
Epoch 995/1000
2023-09-19 12:22:32.074 
Epoch 995/1000 
	 loss: 5.0146, MinusLogProbMetric: 5.0146, val_loss: 5.1238, val_MinusLogProbMetric: 5.1238

Epoch 995: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0146 - MinusLogProbMetric: 5.0146 - val_loss: 5.1238 - val_MinusLogProbMetric: 5.1238 - lr: 7.8125e-06 - 68s/epoch - 346ms/step
Epoch 996/1000
2023-09-19 12:23:40.187 
Epoch 996/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1228, val_MinusLogProbMetric: 5.1228

Epoch 996: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1228 - val_MinusLogProbMetric: 5.1228 - lr: 7.8125e-06 - 68s/epoch - 347ms/step
Epoch 997/1000
2023-09-19 12:24:47.979 
Epoch 997/1000 
	 loss: 5.0147, MinusLogProbMetric: 5.0147, val_loss: 5.1234, val_MinusLogProbMetric: 5.1234

Epoch 997: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0147 - MinusLogProbMetric: 5.0147 - val_loss: 5.1234 - val_MinusLogProbMetric: 5.1234 - lr: 7.8125e-06 - 68s/epoch - 346ms/step
Epoch 998/1000
2023-09-19 12:25:55.985 
Epoch 998/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.1238, val_MinusLogProbMetric: 5.1238

Epoch 998: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.1238 - val_MinusLogProbMetric: 5.1238 - lr: 7.8125e-06 - 68s/epoch - 347ms/step
Epoch 999/1000
2023-09-19 12:27:03.874 
Epoch 999/1000 
	 loss: 5.0146, MinusLogProbMetric: 5.0146, val_loss: 5.1228, val_MinusLogProbMetric: 5.1228

Epoch 999: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0146 - MinusLogProbMetric: 5.0146 - val_loss: 5.1228 - val_MinusLogProbMetric: 5.1228 - lr: 7.8125e-06 - 68s/epoch - 346ms/step
Epoch 1000/1000
2023-09-19 12:28:11.550 
Epoch 1000/1000 
	 loss: 5.0141, MinusLogProbMetric: 5.0141, val_loss: 5.1232, val_MinusLogProbMetric: 5.1232

Epoch 1000: val_loss did not improve from 5.12263
196/196 - 68s - loss: 5.0141 - MinusLogProbMetric: 5.0141 - val_loss: 5.1232 - val_MinusLogProbMetric: 5.1232 - lr: 3.9063e-06 - 68s/epoch - 345ms/step
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 28.85077111888677 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 14.384692049119622 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 8.646627017995343 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fae19613130> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 37.86188362003304 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 19.145963142858818 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 11.306521696038544 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fae19613d90> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 520.
Model trained in 67958.21 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/c_Main_CsplineN.py , Line : 468, Func.Name : prediction_function, Message : X_data_nf: tf.Tensor = DataInputs.dist_2_num[:nsamples_test] # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 124.33 s.
===========
Run 197/720 done in 68090.05 s.
===========

Directory ../../results/CsplineN_new/run_198/ already exists.
Skipping it.
===========
Run 198/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_199/ already exists.
Skipping it.
===========
Run 199/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_200/ already exists.
Skipping it.
===========
Run 200/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_201/ already exists.
Skipping it.
===========
Run 201/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_202/ already exists.
Skipping it.
===========
Run 202/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_203/ already exists.
Skipping it.
===========
Run 203/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_204/ already exists.
Skipping it.
===========
Run 204/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_205/ already exists.
Skipping it.
===========
Run 205/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_206/ already exists.
Skipping it.
===========
Run 206/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_207/ already exists.
Skipping it.
===========
Run 207/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_208/ already exists.
Skipping it.
===========
Run 208/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_209/ already exists.
Skipping it.
===========
Run 209/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_210/ already exists.
Skipping it.
===========
Run 210/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_211/ already exists.
Skipping it.
===========
Run 211/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_212/ already exists.
Skipping it.
===========
Run 212/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_213/ already exists.
Skipping it.
===========
Run 213/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_214/ already exists.
Skipping it.
===========
Run 214/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_215/ already exists.
Skipping it.
===========
Run 215/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_216/ already exists.
Skipping it.
===========
Run 216/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_217/ already exists.
Skipping it.
===========
Run 217/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_218/ already exists.
Skipping it.
===========
Run 218/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_219/ already exists.
Skipping it.
===========
Run 219/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_220/ already exists.
Skipping it.
===========
Run 220/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_221/ already exists.
Skipping it.
===========
Run 221/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_222/ already exists.
Skipping it.
===========
Run 222/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_223/ already exists.
Skipping it.
===========
Run 223/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_224/ already exists.
Skipping it.
===========
Run 224/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_225/ already exists.
Skipping it.
===========
Run 225/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_226/ already exists.
Skipping it.
===========
Run 226/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_227/ already exists.
Skipping it.
===========
Run 227/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_228/ already exists.
Skipping it.
===========
Run 228/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_229/ already exists.
Skipping it.
===========
Run 229/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_230/ already exists.
Skipping it.
===========
Run 230/720 already exists. Skipping it.
===========

===========
Generating train data for run 231.
===========
Train data generated in 0.12 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 16)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_231/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 926}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_231/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[4.3666077 , 6.1695876 , 0.27122405, ..., 5.577797  , 2.1701648 ,
        1.2868358 ],
       [5.0281353 , 5.7328377 , 0.3051757 , ..., 7.0866113 , 1.7836838 ,
        1.4592106 ],
       [4.2135534 , 5.5750036 , 0.2128448 , ..., 5.702535  , 1.9414682 ,
        1.4426389 ],
       ...,
       [4.785428  , 5.7426505 , 0.23152825, ..., 5.4925036 , 2.6306229 ,
        1.3358337 ],
       [4.0240746 , 5.852261  , 0.27691367, ..., 5.7175026 , 2.0052557 ,
        1.3195817 ],
       [4.512517  , 6.331559  , 0.16687389, ..., 7.565742  , 2.5641623 ,
        1.4620413 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_231/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_231
self.data_kwargs: {'seed': 926}
self.x_data: [[4.3352976  5.207491   0.26835275 ... 6.13532    1.9596003  1.0861415 ]
 [5.689245   6.716931   5.5779715  ... 9.05787    0.6619543  0.7687346 ]
 [5.303978   6.4669     6.316775   ... 9.227701   0.8503313  0.8159978 ]
 ...
 [5.3024693  7.011682   6.1129336  ... 9.28271    0.9590223  0.6377857 ]
 [5.5499325  7.0990925  6.2601123  ... 9.419509   1.4502236  0.9426094 ]
 [5.896061   7.6677456  6.213584   ... 9.470459   1.177044   0.7804839 ]]
self.y_data: []
self.ndims: 16
Model defined.
Model: "model_179"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_180 (InputLayer)      [(None, 16)]              0         
                                                                 
 log_prob_layer_19 (LogProbL  (None,)                  702960    
 ayer)                                                           
                                                                 
=================================================================
Total params: 702,960
Trainable params: 702,960
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_19/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_19'")
self.model: <keras.engine.functional.Functional object at 0x7fad226defb0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fad22797400>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fad22797400>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fad226c1060>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fad22513190>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fad22513700>, <keras.callbacks.ModelCheckpoint object at 0x7fad225137c0>, <keras.callbacks.EarlyStopping object at 0x7fad22513a30>, <keras.callbacks.ReduceLROnPlateau object at 0x7fad22513a60>, <keras.callbacks.TerminateOnNaN object at 0x7fad225136a0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[4.3666077 , 6.1695876 , 0.27122405, ..., 5.577797  , 2.1701648 ,
        1.2868358 ],
       [5.0281353 , 5.7328377 , 0.3051757 , ..., 7.0866113 , 1.7836838 ,
        1.4592106 ],
       [4.2135534 , 5.5750036 , 0.2128448 , ..., 5.702535  , 1.9414682 ,
        1.4426389 ],
       ...,
       [4.785428  , 5.7426505 , 0.23152825, ..., 5.4925036 , 2.6306229 ,
        1.3358337 ],
       [4.0240746 , 5.852261  , 0.27691367, ..., 5.7175026 , 2.0052557 ,
        1.3195817 ],
       [4.512517  , 6.331559  , 0.16687389, ..., 7.565742  , 2.5641623 ,
        1.4620413 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_231/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 231/720 with hyperparameters:
timestamp = 2023-09-19 12:30:24.292110
ndims = 16
seed_train = 926
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 702960
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [4.3352976  5.207491   0.26835275 6.3799963  7.002734   5.8573203
 9.293297   6.9121284  3.8079677  5.572638   6.5406003  0.34338894
 6.946575   6.13532    1.9596003  1.0861415 ]
Epoch 1/1000
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Batch 74: Invalid loss, terminating training
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
2023-09-19 12:35:53.783 
Epoch 1/1000 
	 loss: nan, MinusLogProbMetric: 759.9808, val_loss: nan, val_MinusLogProbMetric: nan

Epoch 1: val_loss did not improve from inf
196/196 - 330s - loss: nan - MinusLogProbMetric: 759.9808 - val_loss: nan - val_MinusLogProbMetric: nan - lr: 0.0010 - 330s/epoch - 2s/step
The loss history contains NaN values.
Training failed: trying again with seed 638742 and lr 0.0003333333333333333.
===========
Generating train data for run 231.
===========
Train data generated in 0.50 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 16)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_231/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 926}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_231/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[4.3666077 , 6.1695876 , 0.27122405, ..., 5.577797  , 2.1701648 ,
        1.2868358 ],
       [5.0281353 , 5.7328377 , 0.3051757 , ..., 7.0866113 , 1.7836838 ,
        1.4592106 ],
       [4.2135534 , 5.5750036 , 0.2128448 , ..., 5.702535  , 1.9414682 ,
        1.4426389 ],
       ...,
       [4.785428  , 5.7426505 , 0.23152825, ..., 5.4925036 , 2.6306229 ,
        1.3358337 ],
       [4.0240746 , 5.852261  , 0.27691367, ..., 5.7175026 , 2.0052557 ,
        1.3195817 ],
       [4.512517  , 6.331559  , 0.16687389, ..., 7.565742  , 2.5641623 ,
        1.4620413 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_231/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_231
self.data_kwargs: {'seed': 926}
self.x_data: [[4.3352976  5.207491   0.26835275 ... 6.13532    1.9596003  1.0861415 ]
 [5.689245   6.716931   5.5779715  ... 9.05787    0.6619543  0.7687346 ]
 [5.303978   6.4669     6.316775   ... 9.227701   0.8503313  0.8159978 ]
 ...
 [5.3024693  7.011682   6.1129336  ... 9.28271    0.9590223  0.6377857 ]
 [5.5499325  7.0990925  6.2601123  ... 9.419509   1.4502236  0.9426094 ]
 [5.896061   7.6677456  6.213584   ... 9.470459   1.177044   0.7804839 ]]
self.y_data: []
self.ndims: 16
Model defined.
Model: "model_190"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_191 (InputLayer)      [(None, 16)]              0         
                                                                 
 log_prob_layer_20 (LogProbL  (None,)                  702960    
 ayer)                                                           
                                                                 
=================================================================
Total params: 702,960
Trainable params: 702,960
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_20/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_20'")
self.model: <keras.engine.functional.Functional object at 0x7fae94ce1ab0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fadab054250>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fadab054250>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7faead9e3b50>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7faeeb928790>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7faeeb928d00>, <keras.callbacks.ModelCheckpoint object at 0x7faeeb928dc0>, <keras.callbacks.EarlyStopping object at 0x7faeeb929030>, <keras.callbacks.ReduceLROnPlateau object at 0x7faeeb929060>, <keras.callbacks.TerminateOnNaN object at 0x7faeeb928ca0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[4.3666077 , 6.1695876 , 0.27122405, ..., 5.577797  , 2.1701648 ,
        1.2868358 ],
       [5.0281353 , 5.7328377 , 0.3051757 , ..., 7.0866113 , 1.7836838 ,
        1.4592106 ],
       [4.2135534 , 5.5750036 , 0.2128448 , ..., 5.702535  , 1.9414682 ,
        1.4426389 ],
       ...,
       [4.785428  , 5.7426505 , 0.23152825, ..., 5.4925036 , 2.6306229 ,
        1.3358337 ],
       [4.0240746 , 5.852261  , 0.27691367, ..., 5.7175026 , 2.0052557 ,
        1.3195817 ],
       [4.512517  , 6.331559  , 0.16687389, ..., 7.565742  , 2.5641623 ,
        1.4620413 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_231/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 231/720 with hyperparameters:
timestamp = 2023-09-19 12:36:09.739413
ndims = 16
seed_train = 926
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 702960
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.0003333333333333333...
Train first sample: [4.3352976  5.207491   0.26835275 6.3799963  7.002734   5.8573203
 9.293297   6.9121284  3.8079677  5.572638   6.5406003  0.34338894
 6.946575   6.13532    1.9596003  1.0861415 ]
Epoch 1/1000
2023-09-19 13:32:34.568 
Epoch 1/1000 
	 loss: 314.3861, MinusLogProbMetric: 314.3861, val_loss: 196.8620, val_MinusLogProbMetric: 196.8620

Epoch 1: val_loss improved from inf to 196.86205, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 3386s - loss: 314.3861 - MinusLogProbMetric: 314.3861 - val_loss: 196.8620 - val_MinusLogProbMetric: 196.8620 - lr: 3.3333e-04 - 3386s/epoch - 17s/step
Epoch 2/1000
2023-09-19 13:33:58.677 
Epoch 2/1000 
	 loss: 70.5477, MinusLogProbMetric: 70.5477, val_loss: 49.4071, val_MinusLogProbMetric: 49.4071

Epoch 2: val_loss improved from 196.86205 to 49.40712, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 84s - loss: 70.5477 - MinusLogProbMetric: 70.5477 - val_loss: 49.4071 - val_MinusLogProbMetric: 49.4071 - lr: 3.3333e-04 - 84s/epoch - 427ms/step
Epoch 3/1000
2023-09-19 13:35:22.028 
Epoch 3/1000 
	 loss: 34.3711, MinusLogProbMetric: 34.3711, val_loss: 64.5910, val_MinusLogProbMetric: 64.5910

Epoch 3: val_loss did not improve from 49.40712
196/196 - 82s - loss: 34.3711 - MinusLogProbMetric: 34.3711 - val_loss: 64.5910 - val_MinusLogProbMetric: 64.5910 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 4/1000
2023-09-19 13:36:44.214 
Epoch 4/1000 
	 loss: 32.1850, MinusLogProbMetric: 32.1850, val_loss: 19.9014, val_MinusLogProbMetric: 19.9014

Epoch 4: val_loss improved from 49.40712 to 19.90143, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 84s - loss: 32.1850 - MinusLogProbMetric: 32.1850 - val_loss: 19.9014 - val_MinusLogProbMetric: 19.9014 - lr: 3.3333e-04 - 84s/epoch - 427ms/step
Epoch 5/1000
2023-09-19 13:38:07.613 
Epoch 5/1000 
	 loss: 18.7949, MinusLogProbMetric: 18.7949, val_loss: 15.9469, val_MinusLogProbMetric: 15.9469

Epoch 5: val_loss improved from 19.90143 to 15.94685, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 18.7949 - MinusLogProbMetric: 18.7949 - val_loss: 15.9469 - val_MinusLogProbMetric: 15.9469 - lr: 3.3333e-04 - 83s/epoch - 425ms/step
Epoch 6/1000
2023-09-19 13:39:30.907 
Epoch 6/1000 
	 loss: 14.9216, MinusLogProbMetric: 14.9216, val_loss: 13.1699, val_MinusLogProbMetric: 13.1699

Epoch 6: val_loss improved from 15.94685 to 13.16994, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 14.9216 - MinusLogProbMetric: 14.9216 - val_loss: 13.1699 - val_MinusLogProbMetric: 13.1699 - lr: 3.3333e-04 - 83s/epoch - 426ms/step
Epoch 7/1000
2023-09-19 13:40:53.578 
Epoch 7/1000 
	 loss: 12.6715, MinusLogProbMetric: 12.6715, val_loss: 11.4831, val_MinusLogProbMetric: 11.4831

Epoch 7: val_loss improved from 13.16994 to 11.48312, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 12.6715 - MinusLogProbMetric: 12.6715 - val_loss: 11.4831 - val_MinusLogProbMetric: 11.4831 - lr: 3.3333e-04 - 83s/epoch - 421ms/step
Epoch 8/1000
2023-09-19 13:42:15.925 
Epoch 8/1000 
	 loss: 11.2287, MinusLogProbMetric: 11.2287, val_loss: 10.6614, val_MinusLogProbMetric: 10.6614

Epoch 8: val_loss improved from 11.48312 to 10.66138, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 11.2287 - MinusLogProbMetric: 11.2287 - val_loss: 10.6614 - val_MinusLogProbMetric: 10.6614 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 9/1000
2023-09-19 13:43:37.758 
Epoch 9/1000 
	 loss: 10.2394, MinusLogProbMetric: 10.2394, val_loss: 9.5870, val_MinusLogProbMetric: 9.5870

Epoch 9: val_loss improved from 10.66138 to 9.58701, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 10.2394 - MinusLogProbMetric: 10.2394 - val_loss: 9.5870 - val_MinusLogProbMetric: 9.5870 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 10/1000
2023-09-19 13:44:59.567 
Epoch 10/1000 
	 loss: 9.3407, MinusLogProbMetric: 9.3407, val_loss: 9.4857, val_MinusLogProbMetric: 9.4857

Epoch 10: val_loss improved from 9.58701 to 9.48570, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 9.3407 - MinusLogProbMetric: 9.3407 - val_loss: 9.4857 - val_MinusLogProbMetric: 9.4857 - lr: 3.3333e-04 - 82s/epoch - 416ms/step
Epoch 11/1000
2023-09-19 13:46:21.465 
Epoch 11/1000 
	 loss: 8.7260, MinusLogProbMetric: 8.7260, val_loss: 8.8144, val_MinusLogProbMetric: 8.8144

Epoch 11: val_loss improved from 9.48570 to 8.81443, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 8.7260 - MinusLogProbMetric: 8.7260 - val_loss: 8.8144 - val_MinusLogProbMetric: 8.8144 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 12/1000
2023-09-19 13:47:43.226 
Epoch 12/1000 
	 loss: 8.2376, MinusLogProbMetric: 8.2376, val_loss: 8.0217, val_MinusLogProbMetric: 8.0217

Epoch 12: val_loss improved from 8.81443 to 8.02168, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 8.2376 - MinusLogProbMetric: 8.2376 - val_loss: 8.0217 - val_MinusLogProbMetric: 8.0217 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 13/1000
2023-09-19 13:49:05.448 
Epoch 13/1000 
	 loss: 7.8372, MinusLogProbMetric: 7.8372, val_loss: 7.9313, val_MinusLogProbMetric: 7.9313

Epoch 13: val_loss improved from 8.02168 to 7.93129, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 7.8372 - MinusLogProbMetric: 7.8372 - val_loss: 7.9313 - val_MinusLogProbMetric: 7.9313 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 14/1000
2023-09-19 13:50:27.027 
Epoch 14/1000 
	 loss: 7.6108, MinusLogProbMetric: 7.6108, val_loss: 7.5694, val_MinusLogProbMetric: 7.5694

Epoch 14: val_loss improved from 7.93129 to 7.56942, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 7.6108 - MinusLogProbMetric: 7.6108 - val_loss: 7.5694 - val_MinusLogProbMetric: 7.5694 - lr: 3.3333e-04 - 82s/epoch - 416ms/step
Epoch 15/1000
2023-09-19 13:51:49.373 
Epoch 15/1000 
	 loss: 7.3685, MinusLogProbMetric: 7.3685, val_loss: 7.3987, val_MinusLogProbMetric: 7.3987

Epoch 15: val_loss improved from 7.56942 to 7.39873, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 7.3685 - MinusLogProbMetric: 7.3685 - val_loss: 7.3987 - val_MinusLogProbMetric: 7.3987 - lr: 3.3333e-04 - 83s/epoch - 422ms/step
Epoch 16/1000
2023-09-19 13:53:11.451 
Epoch 16/1000 
	 loss: 7.1867, MinusLogProbMetric: 7.1867, val_loss: 7.1415, val_MinusLogProbMetric: 7.1415

Epoch 16: val_loss improved from 7.39873 to 7.14154, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 7.1867 - MinusLogProbMetric: 7.1867 - val_loss: 7.1415 - val_MinusLogProbMetric: 7.1415 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 17/1000
2023-09-19 13:54:33.872 
Epoch 17/1000 
	 loss: 7.0632, MinusLogProbMetric: 7.0632, val_loss: 7.0030, val_MinusLogProbMetric: 7.0030

Epoch 17: val_loss improved from 7.14154 to 7.00297, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 7.0632 - MinusLogProbMetric: 7.0632 - val_loss: 7.0030 - val_MinusLogProbMetric: 7.0030 - lr: 3.3333e-04 - 83s/epoch - 421ms/step
Epoch 18/1000
2023-09-19 13:55:55.990 
Epoch 18/1000 
	 loss: 6.9543, MinusLogProbMetric: 6.9543, val_loss: 6.8419, val_MinusLogProbMetric: 6.8419

Epoch 18: val_loss improved from 7.00297 to 6.84194, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 6.9543 - MinusLogProbMetric: 6.9543 - val_loss: 6.8419 - val_MinusLogProbMetric: 6.8419 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 19/1000
2023-09-19 13:57:17.503 
Epoch 19/1000 
	 loss: 6.8156, MinusLogProbMetric: 6.8156, val_loss: 6.8778, val_MinusLogProbMetric: 6.8778

Epoch 19: val_loss did not improve from 6.84194
196/196 - 80s - loss: 6.8156 - MinusLogProbMetric: 6.8156 - val_loss: 6.8778 - val_MinusLogProbMetric: 6.8778 - lr: 3.3333e-04 - 80s/epoch - 409ms/step
Epoch 20/1000
2023-09-19 13:58:37.785 
Epoch 20/1000 
	 loss: 6.7308, MinusLogProbMetric: 6.7308, val_loss: 6.7424, val_MinusLogProbMetric: 6.7424

Epoch 20: val_loss improved from 6.84194 to 6.74238, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 6.7308 - MinusLogProbMetric: 6.7308 - val_loss: 6.7424 - val_MinusLogProbMetric: 6.7424 - lr: 3.3333e-04 - 82s/epoch - 416ms/step
Epoch 21/1000
2023-09-19 13:59:59.378 
Epoch 21/1000 
	 loss: 6.6440, MinusLogProbMetric: 6.6440, val_loss: 6.9401, val_MinusLogProbMetric: 6.9401

Epoch 21: val_loss did not improve from 6.74238
196/196 - 80s - loss: 6.6440 - MinusLogProbMetric: 6.6440 - val_loss: 6.9401 - val_MinusLogProbMetric: 6.9401 - lr: 3.3333e-04 - 80s/epoch - 410ms/step
Epoch 22/1000
2023-09-19 14:01:19.869 
Epoch 22/1000 
	 loss: 6.5733, MinusLogProbMetric: 6.5733, val_loss: 6.8498, val_MinusLogProbMetric: 6.8498

Epoch 22: val_loss did not improve from 6.74238
196/196 - 80s - loss: 6.5733 - MinusLogProbMetric: 6.5733 - val_loss: 6.8498 - val_MinusLogProbMetric: 6.8498 - lr: 3.3333e-04 - 80s/epoch - 411ms/step
Epoch 23/1000
2023-09-19 14:02:40.451 
Epoch 23/1000 
	 loss: 6.4829, MinusLogProbMetric: 6.4829, val_loss: 6.4025, val_MinusLogProbMetric: 6.4025

Epoch 23: val_loss improved from 6.74238 to 6.40252, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 6.4829 - MinusLogProbMetric: 6.4829 - val_loss: 6.4025 - val_MinusLogProbMetric: 6.4025 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 24/1000
2023-09-19 14:04:02.345 
Epoch 24/1000 
	 loss: 6.4587, MinusLogProbMetric: 6.4587, val_loss: 6.5242, val_MinusLogProbMetric: 6.5242

Epoch 24: val_loss did not improve from 6.40252
196/196 - 80s - loss: 6.4587 - MinusLogProbMetric: 6.4587 - val_loss: 6.5242 - val_MinusLogProbMetric: 6.5242 - lr: 3.3333e-04 - 80s/epoch - 410ms/step
Epoch 25/1000
2023-09-19 14:05:22.522 
Epoch 25/1000 
	 loss: 6.3966, MinusLogProbMetric: 6.3966, val_loss: 6.3372, val_MinusLogProbMetric: 6.3372

Epoch 25: val_loss improved from 6.40252 to 6.33724, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 6.3966 - MinusLogProbMetric: 6.3966 - val_loss: 6.3372 - val_MinusLogProbMetric: 6.3372 - lr: 3.3333e-04 - 82s/epoch - 416ms/step
Epoch 26/1000
2023-09-19 14:06:44.015 
Epoch 26/1000 
	 loss: 6.3337, MinusLogProbMetric: 6.3337, val_loss: 6.2941, val_MinusLogProbMetric: 6.2941

Epoch 26: val_loss improved from 6.33724 to 6.29405, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 81s - loss: 6.3337 - MinusLogProbMetric: 6.3337 - val_loss: 6.2941 - val_MinusLogProbMetric: 6.2941 - lr: 3.3333e-04 - 81s/epoch - 416ms/step
Epoch 27/1000
2023-09-19 14:08:05.584 
Epoch 27/1000 
	 loss: 6.3097, MinusLogProbMetric: 6.3097, val_loss: 6.1842, val_MinusLogProbMetric: 6.1842

Epoch 27: val_loss improved from 6.29405 to 6.18424, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 81s - loss: 6.3097 - MinusLogProbMetric: 6.3097 - val_loss: 6.1842 - val_MinusLogProbMetric: 6.1842 - lr: 3.3333e-04 - 81s/epoch - 416ms/step
Epoch 28/1000
2023-09-19 14:09:26.959 
Epoch 28/1000 
	 loss: 6.2498, MinusLogProbMetric: 6.2498, val_loss: 6.0943, val_MinusLogProbMetric: 6.0943

Epoch 28: val_loss improved from 6.18424 to 6.09428, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 6.2498 - MinusLogProbMetric: 6.2498 - val_loss: 6.0943 - val_MinusLogProbMetric: 6.0943 - lr: 3.3333e-04 - 82s/epoch - 416ms/step
Epoch 29/1000
2023-09-19 14:10:49.276 
Epoch 29/1000 
	 loss: 6.2175, MinusLogProbMetric: 6.2175, val_loss: 6.6493, val_MinusLogProbMetric: 6.6493

Epoch 29: val_loss did not improve from 6.09428
196/196 - 81s - loss: 6.2175 - MinusLogProbMetric: 6.2175 - val_loss: 6.6493 - val_MinusLogProbMetric: 6.6493 - lr: 3.3333e-04 - 81s/epoch - 412ms/step
Epoch 30/1000
2023-09-19 14:12:09.283 
Epoch 30/1000 
	 loss: 6.2351, MinusLogProbMetric: 6.2351, val_loss: 6.2504, val_MinusLogProbMetric: 6.2504

Epoch 30: val_loss did not improve from 6.09428
196/196 - 80s - loss: 6.2351 - MinusLogProbMetric: 6.2351 - val_loss: 6.2504 - val_MinusLogProbMetric: 6.2504 - lr: 3.3333e-04 - 80s/epoch - 408ms/step
Epoch 31/1000
2023-09-19 14:13:29.701 
Epoch 31/1000 
	 loss: 6.1757, MinusLogProbMetric: 6.1757, val_loss: 6.2043, val_MinusLogProbMetric: 6.2043

Epoch 31: val_loss did not improve from 6.09428
196/196 - 80s - loss: 6.1757 - MinusLogProbMetric: 6.1757 - val_loss: 6.2043 - val_MinusLogProbMetric: 6.2043 - lr: 3.3333e-04 - 80s/epoch - 410ms/step
Epoch 32/1000
2023-09-19 14:14:50.172 
Epoch 32/1000 
	 loss: 6.1367, MinusLogProbMetric: 6.1367, val_loss: 5.9715, val_MinusLogProbMetric: 5.9715

Epoch 32: val_loss improved from 6.09428 to 5.97152, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 6.1367 - MinusLogProbMetric: 6.1367 - val_loss: 5.9715 - val_MinusLogProbMetric: 5.9715 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 33/1000
2023-09-19 14:16:11.988 
Epoch 33/1000 
	 loss: 6.0848, MinusLogProbMetric: 6.0848, val_loss: 6.3131, val_MinusLogProbMetric: 6.3131

Epoch 33: val_loss did not improve from 5.97152
196/196 - 81s - loss: 6.0848 - MinusLogProbMetric: 6.0848 - val_loss: 6.3131 - val_MinusLogProbMetric: 6.3131 - lr: 3.3333e-04 - 81s/epoch - 411ms/step
Epoch 34/1000
2023-09-19 14:17:31.566 
Epoch 34/1000 
	 loss: 6.1241, MinusLogProbMetric: 6.1241, val_loss: 6.0723, val_MinusLogProbMetric: 6.0723

Epoch 34: val_loss did not improve from 5.97152
196/196 - 80s - loss: 6.1241 - MinusLogProbMetric: 6.1241 - val_loss: 6.0723 - val_MinusLogProbMetric: 6.0723 - lr: 3.3333e-04 - 80s/epoch - 406ms/step
Epoch 35/1000
2023-09-19 14:18:51.627 
Epoch 35/1000 
	 loss: 6.0351, MinusLogProbMetric: 6.0351, val_loss: 6.3202, val_MinusLogProbMetric: 6.3202

Epoch 35: val_loss did not improve from 5.97152
196/196 - 80s - loss: 6.0351 - MinusLogProbMetric: 6.0351 - val_loss: 6.3202 - val_MinusLogProbMetric: 6.3202 - lr: 3.3333e-04 - 80s/epoch - 408ms/step
Epoch 36/1000
2023-09-19 14:20:11.715 
Epoch 36/1000 
	 loss: 6.0286, MinusLogProbMetric: 6.0286, val_loss: 6.0466, val_MinusLogProbMetric: 6.0466

Epoch 36: val_loss did not improve from 5.97152
196/196 - 80s - loss: 6.0286 - MinusLogProbMetric: 6.0286 - val_loss: 6.0466 - val_MinusLogProbMetric: 6.0466 - lr: 3.3333e-04 - 80s/epoch - 409ms/step
Epoch 37/1000
2023-09-19 14:21:31.881 
Epoch 37/1000 
	 loss: 6.0033, MinusLogProbMetric: 6.0033, val_loss: 5.8957, val_MinusLogProbMetric: 5.8957

Epoch 37: val_loss improved from 5.97152 to 5.89570, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 81s - loss: 6.0033 - MinusLogProbMetric: 6.0033 - val_loss: 5.8957 - val_MinusLogProbMetric: 5.8957 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 38/1000
2023-09-19 14:22:53.062 
Epoch 38/1000 
	 loss: 6.0067, MinusLogProbMetric: 6.0067, val_loss: 5.9631, val_MinusLogProbMetric: 5.9631

Epoch 38: val_loss did not improve from 5.89570
196/196 - 80s - loss: 6.0067 - MinusLogProbMetric: 6.0067 - val_loss: 5.9631 - val_MinusLogProbMetric: 5.9631 - lr: 3.3333e-04 - 80s/epoch - 408ms/step
Epoch 39/1000
2023-09-19 14:24:12.828 
Epoch 39/1000 
	 loss: 5.9594, MinusLogProbMetric: 5.9594, val_loss: 6.3126, val_MinusLogProbMetric: 6.3126

Epoch 39: val_loss did not improve from 5.89570
196/196 - 80s - loss: 5.9594 - MinusLogProbMetric: 5.9594 - val_loss: 6.3126 - val_MinusLogProbMetric: 6.3126 - lr: 3.3333e-04 - 80s/epoch - 407ms/step
Epoch 40/1000
2023-09-19 14:25:32.674 
Epoch 40/1000 
	 loss: 5.9571, MinusLogProbMetric: 5.9571, val_loss: 6.1532, val_MinusLogProbMetric: 6.1532

Epoch 40: val_loss did not improve from 5.89570
196/196 - 80s - loss: 5.9571 - MinusLogProbMetric: 5.9571 - val_loss: 6.1532 - val_MinusLogProbMetric: 6.1532 - lr: 3.3333e-04 - 80s/epoch - 407ms/step
Epoch 41/1000
2023-09-19 14:26:48.805 
Epoch 41/1000 
	 loss: 5.9252, MinusLogProbMetric: 5.9252, val_loss: 6.0180, val_MinusLogProbMetric: 6.0180

Epoch 41: val_loss did not improve from 5.89570
196/196 - 76s - loss: 5.9252 - MinusLogProbMetric: 5.9252 - val_loss: 6.0180 - val_MinusLogProbMetric: 6.0180 - lr: 3.3333e-04 - 76s/epoch - 388ms/step
Epoch 42/1000
2023-09-19 14:27:56.895 
Epoch 42/1000 
	 loss: 5.8839, MinusLogProbMetric: 5.8839, val_loss: 5.9481, val_MinusLogProbMetric: 5.9481

Epoch 42: val_loss did not improve from 5.89570
196/196 - 68s - loss: 5.8839 - MinusLogProbMetric: 5.8839 - val_loss: 5.9481 - val_MinusLogProbMetric: 5.9481 - lr: 3.3333e-04 - 68s/epoch - 347ms/step
Epoch 43/1000
2023-09-19 14:29:16.417 
Epoch 43/1000 
	 loss: 5.9188, MinusLogProbMetric: 5.9188, val_loss: 5.9207, val_MinusLogProbMetric: 5.9207

Epoch 43: val_loss did not improve from 5.89570
196/196 - 80s - loss: 5.9188 - MinusLogProbMetric: 5.9188 - val_loss: 5.9207 - val_MinusLogProbMetric: 5.9207 - lr: 3.3333e-04 - 80s/epoch - 406ms/step
Epoch 44/1000
2023-09-19 14:30:37.391 
Epoch 44/1000 
	 loss: 5.8540, MinusLogProbMetric: 5.8540, val_loss: 5.8583, val_MinusLogProbMetric: 5.8583

Epoch 44: val_loss improved from 5.89570 to 5.85833, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 5.8540 - MinusLogProbMetric: 5.8540 - val_loss: 5.8583 - val_MinusLogProbMetric: 5.8583 - lr: 3.3333e-04 - 83s/epoch - 421ms/step
Epoch 45/1000
2023-09-19 14:31:59.832 
Epoch 45/1000 
	 loss: 5.8690, MinusLogProbMetric: 5.8690, val_loss: 5.8696, val_MinusLogProbMetric: 5.8696

Epoch 45: val_loss did not improve from 5.85833
196/196 - 81s - loss: 5.8690 - MinusLogProbMetric: 5.8690 - val_loss: 5.8696 - val_MinusLogProbMetric: 5.8696 - lr: 3.3333e-04 - 81s/epoch - 413ms/step
Epoch 46/1000
2023-09-19 14:33:20.317 
Epoch 46/1000 
	 loss: 5.8635, MinusLogProbMetric: 5.8635, val_loss: 5.8646, val_MinusLogProbMetric: 5.8646

Epoch 46: val_loss did not improve from 5.85833
196/196 - 80s - loss: 5.8635 - MinusLogProbMetric: 5.8635 - val_loss: 5.8646 - val_MinusLogProbMetric: 5.8646 - lr: 3.3333e-04 - 80s/epoch - 411ms/step
Epoch 47/1000
2023-09-19 14:34:41.583 
Epoch 47/1000 
	 loss: 5.8352, MinusLogProbMetric: 5.8352, val_loss: 6.0634, val_MinusLogProbMetric: 6.0634

Epoch 47: val_loss did not improve from 5.85833
196/196 - 81s - loss: 5.8352 - MinusLogProbMetric: 5.8352 - val_loss: 6.0634 - val_MinusLogProbMetric: 6.0634 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 48/1000
2023-09-19 14:36:02.905 
Epoch 48/1000 
	 loss: 5.8272, MinusLogProbMetric: 5.8272, val_loss: 5.8442, val_MinusLogProbMetric: 5.8442

Epoch 48: val_loss improved from 5.85833 to 5.84423, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 5.8272 - MinusLogProbMetric: 5.8272 - val_loss: 5.8442 - val_MinusLogProbMetric: 5.8442 - lr: 3.3333e-04 - 83s/epoch - 423ms/step
Epoch 49/1000
2023-09-19 14:37:24.241 
Epoch 49/1000 
	 loss: 5.8114, MinusLogProbMetric: 5.8114, val_loss: 5.8294, val_MinusLogProbMetric: 5.8294

Epoch 49: val_loss improved from 5.84423 to 5.82938, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 81s - loss: 5.8114 - MinusLogProbMetric: 5.8114 - val_loss: 5.8294 - val_MinusLogProbMetric: 5.8294 - lr: 3.3333e-04 - 81s/epoch - 414ms/step
Epoch 50/1000
2023-09-19 14:38:46.509 
Epoch 50/1000 
	 loss: 5.8458, MinusLogProbMetric: 5.8458, val_loss: 5.7974, val_MinusLogProbMetric: 5.7974

Epoch 50: val_loss improved from 5.82938 to 5.79738, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 5.8458 - MinusLogProbMetric: 5.8458 - val_loss: 5.7974 - val_MinusLogProbMetric: 5.7974 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 51/1000
2023-09-19 14:40:08.989 
Epoch 51/1000 
	 loss: 5.7871, MinusLogProbMetric: 5.7871, val_loss: 5.8325, val_MinusLogProbMetric: 5.8325

Epoch 51: val_loss did not improve from 5.79738
196/196 - 81s - loss: 5.7871 - MinusLogProbMetric: 5.7871 - val_loss: 5.8325 - val_MinusLogProbMetric: 5.8325 - lr: 3.3333e-04 - 81s/epoch - 413ms/step
Epoch 52/1000
2023-09-19 14:41:30.238 
Epoch 52/1000 
	 loss: 5.7860, MinusLogProbMetric: 5.7860, val_loss: 5.9134, val_MinusLogProbMetric: 5.9134

Epoch 52: val_loss did not improve from 5.79738
196/196 - 81s - loss: 5.7860 - MinusLogProbMetric: 5.7860 - val_loss: 5.9134 - val_MinusLogProbMetric: 5.9134 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 53/1000
2023-09-19 14:42:50.721 
Epoch 53/1000 
	 loss: 5.7722, MinusLogProbMetric: 5.7722, val_loss: 5.8173, val_MinusLogProbMetric: 5.8173

Epoch 53: val_loss did not improve from 5.79738
196/196 - 80s - loss: 5.7722 - MinusLogProbMetric: 5.7722 - val_loss: 5.8173 - val_MinusLogProbMetric: 5.8173 - lr: 3.3333e-04 - 80s/epoch - 411ms/step
Epoch 54/1000
2023-09-19 14:44:11.671 
Epoch 54/1000 
	 loss: 5.7497, MinusLogProbMetric: 5.7497, val_loss: 5.8095, val_MinusLogProbMetric: 5.8095

Epoch 54: val_loss did not improve from 5.79738
196/196 - 81s - loss: 5.7497 - MinusLogProbMetric: 5.7497 - val_loss: 5.8095 - val_MinusLogProbMetric: 5.8095 - lr: 3.3333e-04 - 81s/epoch - 413ms/step
Epoch 55/1000
2023-09-19 14:45:31.973 
Epoch 55/1000 
	 loss: 5.7472, MinusLogProbMetric: 5.7472, val_loss: 5.7617, val_MinusLogProbMetric: 5.7617

Epoch 55: val_loss improved from 5.79738 to 5.76166, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 5.7472 - MinusLogProbMetric: 5.7472 - val_loss: 5.7617 - val_MinusLogProbMetric: 5.7617 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 56/1000
2023-09-19 14:46:54.133 
Epoch 56/1000 
	 loss: 5.7341, MinusLogProbMetric: 5.7341, val_loss: 5.7265, val_MinusLogProbMetric: 5.7265

Epoch 56: val_loss improved from 5.76166 to 5.72648, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 5.7341 - MinusLogProbMetric: 5.7341 - val_loss: 5.7265 - val_MinusLogProbMetric: 5.7265 - lr: 3.3333e-04 - 83s/epoch - 421ms/step
Epoch 57/1000
2023-09-19 14:48:14.057 
Epoch 57/1000 
	 loss: 5.7440, MinusLogProbMetric: 5.7440, val_loss: 5.7487, val_MinusLogProbMetric: 5.7487

Epoch 57: val_loss did not improve from 5.72648
196/196 - 78s - loss: 5.7440 - MinusLogProbMetric: 5.7440 - val_loss: 5.7487 - val_MinusLogProbMetric: 5.7487 - lr: 3.3333e-04 - 78s/epoch - 398ms/step
Epoch 58/1000
2023-09-19 14:49:28.304 
Epoch 58/1000 
	 loss: 5.7255, MinusLogProbMetric: 5.7255, val_loss: 5.8664, val_MinusLogProbMetric: 5.8664

Epoch 58: val_loss did not improve from 5.72648
196/196 - 74s - loss: 5.7255 - MinusLogProbMetric: 5.7255 - val_loss: 5.8664 - val_MinusLogProbMetric: 5.8664 - lr: 3.3333e-04 - 74s/epoch - 379ms/step
Epoch 59/1000
2023-09-19 14:50:45.547 
Epoch 59/1000 
	 loss: 5.7005, MinusLogProbMetric: 5.7005, val_loss: 5.7890, val_MinusLogProbMetric: 5.7890

Epoch 59: val_loss did not improve from 5.72648
196/196 - 77s - loss: 5.7005 - MinusLogProbMetric: 5.7005 - val_loss: 5.7890 - val_MinusLogProbMetric: 5.7890 - lr: 3.3333e-04 - 77s/epoch - 394ms/step
Epoch 60/1000
2023-09-19 14:52:07.173 
Epoch 60/1000 
	 loss: 5.7763, MinusLogProbMetric: 5.7763, val_loss: 5.8893, val_MinusLogProbMetric: 5.8893

Epoch 60: val_loss did not improve from 5.72648
196/196 - 82s - loss: 5.7763 - MinusLogProbMetric: 5.7763 - val_loss: 5.8893 - val_MinusLogProbMetric: 5.8893 - lr: 3.3333e-04 - 82s/epoch - 416ms/step
Epoch 61/1000
2023-09-19 14:53:28.913 
Epoch 61/1000 
	 loss: 5.7099, MinusLogProbMetric: 5.7099, val_loss: 5.9573, val_MinusLogProbMetric: 5.9573

Epoch 61: val_loss did not improve from 5.72648
196/196 - 82s - loss: 5.7099 - MinusLogProbMetric: 5.7099 - val_loss: 5.9573 - val_MinusLogProbMetric: 5.9573 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 62/1000
2023-09-19 14:54:50.216 
Epoch 62/1000 
	 loss: 5.6851, MinusLogProbMetric: 5.6851, val_loss: 5.7919, val_MinusLogProbMetric: 5.7919

Epoch 62: val_loss did not improve from 5.72648
196/196 - 81s - loss: 5.6851 - MinusLogProbMetric: 5.6851 - val_loss: 5.7919 - val_MinusLogProbMetric: 5.7919 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 63/1000
2023-09-19 14:56:11.666 
Epoch 63/1000 
	 loss: 5.6817, MinusLogProbMetric: 5.6817, val_loss: 5.6450, val_MinusLogProbMetric: 5.6450

Epoch 63: val_loss improved from 5.72648 to 5.64498, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 5.6817 - MinusLogProbMetric: 5.6817 - val_loss: 5.6450 - val_MinusLogProbMetric: 5.6450 - lr: 3.3333e-04 - 83s/epoch - 422ms/step
Epoch 64/1000
2023-09-19 14:57:34.263 
Epoch 64/1000 
	 loss: 5.6817, MinusLogProbMetric: 5.6817, val_loss: 5.6833, val_MinusLogProbMetric: 5.6833

Epoch 64: val_loss did not improve from 5.64498
196/196 - 81s - loss: 5.6817 - MinusLogProbMetric: 5.6817 - val_loss: 5.6833 - val_MinusLogProbMetric: 5.6833 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 65/1000
2023-09-19 14:58:55.762 
Epoch 65/1000 
	 loss: 5.6814, MinusLogProbMetric: 5.6814, val_loss: 5.6415, val_MinusLogProbMetric: 5.6415

Epoch 65: val_loss improved from 5.64498 to 5.64149, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 5.6814 - MinusLogProbMetric: 5.6814 - val_loss: 5.6415 - val_MinusLogProbMetric: 5.6415 - lr: 3.3333e-04 - 83s/epoch - 423ms/step
Epoch 66/1000
2023-09-19 15:00:18.392 
Epoch 66/1000 
	 loss: 5.6683, MinusLogProbMetric: 5.6683, val_loss: 5.7169, val_MinusLogProbMetric: 5.7169

Epoch 66: val_loss did not improve from 5.64149
196/196 - 81s - loss: 5.6683 - MinusLogProbMetric: 5.6683 - val_loss: 5.7169 - val_MinusLogProbMetric: 5.7169 - lr: 3.3333e-04 - 81s/epoch - 414ms/step
Epoch 67/1000
2023-09-19 15:01:39.424 
Epoch 67/1000 
	 loss: 5.6626, MinusLogProbMetric: 5.6626, val_loss: 5.6555, val_MinusLogProbMetric: 5.6555

Epoch 67: val_loss did not improve from 5.64149
196/196 - 81s - loss: 5.6626 - MinusLogProbMetric: 5.6626 - val_loss: 5.6555 - val_MinusLogProbMetric: 5.6555 - lr: 3.3333e-04 - 81s/epoch - 413ms/step
Epoch 68/1000
2023-09-19 15:03:01.145 
Epoch 68/1000 
	 loss: 5.6477, MinusLogProbMetric: 5.6477, val_loss: 5.6619, val_MinusLogProbMetric: 5.6619

Epoch 68: val_loss did not improve from 5.64149
196/196 - 82s - loss: 5.6477 - MinusLogProbMetric: 5.6477 - val_loss: 5.6619 - val_MinusLogProbMetric: 5.6619 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 69/1000
2023-09-19 15:04:22.448 
Epoch 69/1000 
	 loss: 5.6282, MinusLogProbMetric: 5.6282, val_loss: 5.8533, val_MinusLogProbMetric: 5.8533

Epoch 69: val_loss did not improve from 5.64149
196/196 - 81s - loss: 5.6282 - MinusLogProbMetric: 5.6282 - val_loss: 5.8533 - val_MinusLogProbMetric: 5.8533 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 70/1000
2023-09-19 15:05:43.732 
Epoch 70/1000 
	 loss: 5.6477, MinusLogProbMetric: 5.6477, val_loss: 5.8080, val_MinusLogProbMetric: 5.8080

Epoch 70: val_loss did not improve from 5.64149
196/196 - 81s - loss: 5.6477 - MinusLogProbMetric: 5.6477 - val_loss: 5.8080 - val_MinusLogProbMetric: 5.8080 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 71/1000
2023-09-19 15:07:04.709 
Epoch 71/1000 
	 loss: 5.6290, MinusLogProbMetric: 5.6290, val_loss: 5.7356, val_MinusLogProbMetric: 5.7356

Epoch 71: val_loss did not improve from 5.64149
196/196 - 81s - loss: 5.6290 - MinusLogProbMetric: 5.6290 - val_loss: 5.7356 - val_MinusLogProbMetric: 5.7356 - lr: 3.3333e-04 - 81s/epoch - 413ms/step
Epoch 72/1000
2023-09-19 15:08:25.848 
Epoch 72/1000 
	 loss: 5.6296, MinusLogProbMetric: 5.6296, val_loss: 5.7299, val_MinusLogProbMetric: 5.7299

Epoch 72: val_loss did not improve from 5.64149
196/196 - 81s - loss: 5.6296 - MinusLogProbMetric: 5.6296 - val_loss: 5.7299 - val_MinusLogProbMetric: 5.7299 - lr: 3.3333e-04 - 81s/epoch - 414ms/step
Epoch 73/1000
2023-09-19 15:09:46.819 
Epoch 73/1000 
	 loss: 5.6452, MinusLogProbMetric: 5.6452, val_loss: 5.7224, val_MinusLogProbMetric: 5.7224

Epoch 73: val_loss did not improve from 5.64149
196/196 - 81s - loss: 5.6452 - MinusLogProbMetric: 5.6452 - val_loss: 5.7224 - val_MinusLogProbMetric: 5.7224 - lr: 3.3333e-04 - 81s/epoch - 413ms/step
Epoch 74/1000
2023-09-19 15:11:07.977 
Epoch 74/1000 
	 loss: 5.6093, MinusLogProbMetric: 5.6093, val_loss: 5.6828, val_MinusLogProbMetric: 5.6828

Epoch 74: val_loss did not improve from 5.64149
196/196 - 81s - loss: 5.6093 - MinusLogProbMetric: 5.6093 - val_loss: 5.6828 - val_MinusLogProbMetric: 5.6828 - lr: 3.3333e-04 - 81s/epoch - 414ms/step
Epoch 75/1000
2023-09-19 15:12:28.830 
Epoch 75/1000 
	 loss: 5.5968, MinusLogProbMetric: 5.5968, val_loss: 5.6206, val_MinusLogProbMetric: 5.6206

Epoch 75: val_loss improved from 5.64149 to 5.62061, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 5.5968 - MinusLogProbMetric: 5.5968 - val_loss: 5.6206 - val_MinusLogProbMetric: 5.6206 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 76/1000
2023-09-19 15:13:50.141 
Epoch 76/1000 
	 loss: 5.5886, MinusLogProbMetric: 5.5886, val_loss: 5.6260, val_MinusLogProbMetric: 5.6260

Epoch 76: val_loss did not improve from 5.62061
196/196 - 80s - loss: 5.5886 - MinusLogProbMetric: 5.5886 - val_loss: 5.6260 - val_MinusLogProbMetric: 5.6260 - lr: 3.3333e-04 - 80s/epoch - 408ms/step
Epoch 77/1000
2023-09-19 15:15:09.955 
Epoch 77/1000 
	 loss: 5.5793, MinusLogProbMetric: 5.5793, val_loss: 5.5717, val_MinusLogProbMetric: 5.5717

Epoch 77: val_loss improved from 5.62061 to 5.57170, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 81s - loss: 5.5793 - MinusLogProbMetric: 5.5793 - val_loss: 5.5717 - val_MinusLogProbMetric: 5.5717 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 78/1000
2023-09-19 15:16:32.830 
Epoch 78/1000 
	 loss: 5.5788, MinusLogProbMetric: 5.5788, val_loss: 5.9816, val_MinusLogProbMetric: 5.9816

Epoch 78: val_loss did not improve from 5.57170
196/196 - 81s - loss: 5.5788 - MinusLogProbMetric: 5.5788 - val_loss: 5.9816 - val_MinusLogProbMetric: 5.9816 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 79/1000
2023-09-19 15:17:54.517 
Epoch 79/1000 
	 loss: 5.6202, MinusLogProbMetric: 5.6202, val_loss: 5.6777, val_MinusLogProbMetric: 5.6777

Epoch 79: val_loss did not improve from 5.57170
196/196 - 82s - loss: 5.6202 - MinusLogProbMetric: 5.6202 - val_loss: 5.6777 - val_MinusLogProbMetric: 5.6777 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 80/1000
2023-09-19 15:19:16.654 
Epoch 80/1000 
	 loss: 5.6027, MinusLogProbMetric: 5.6027, val_loss: 5.7250, val_MinusLogProbMetric: 5.7250

Epoch 80: val_loss did not improve from 5.57170
196/196 - 82s - loss: 5.6027 - MinusLogProbMetric: 5.6027 - val_loss: 5.7250 - val_MinusLogProbMetric: 5.7250 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 81/1000
2023-09-19 15:20:31.259 
Epoch 81/1000 
	 loss: 5.5827, MinusLogProbMetric: 5.5827, val_loss: 5.6379, val_MinusLogProbMetric: 5.6379

Epoch 81: val_loss did not improve from 5.57170
196/196 - 75s - loss: 5.5827 - MinusLogProbMetric: 5.5827 - val_loss: 5.6379 - val_MinusLogProbMetric: 5.6379 - lr: 3.3333e-04 - 75s/epoch - 380ms/step
Epoch 82/1000
2023-09-19 15:21:42.789 
Epoch 82/1000 
	 loss: 5.5703, MinusLogProbMetric: 5.5703, val_loss: 5.8230, val_MinusLogProbMetric: 5.8230

Epoch 82: val_loss did not improve from 5.57170
196/196 - 72s - loss: 5.5703 - MinusLogProbMetric: 5.5703 - val_loss: 5.8230 - val_MinusLogProbMetric: 5.8230 - lr: 3.3333e-04 - 72s/epoch - 365ms/step
Epoch 83/1000
2023-09-19 15:23:03.965 
Epoch 83/1000 
	 loss: 5.5839, MinusLogProbMetric: 5.5839, val_loss: 5.5425, val_MinusLogProbMetric: 5.5425

Epoch 83: val_loss improved from 5.57170 to 5.54254, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 5.5839 - MinusLogProbMetric: 5.5839 - val_loss: 5.5425 - val_MinusLogProbMetric: 5.5425 - lr: 3.3333e-04 - 83s/epoch - 423ms/step
Epoch 84/1000
2023-09-19 15:24:26.488 
Epoch 84/1000 
	 loss: 5.5712, MinusLogProbMetric: 5.5712, val_loss: 5.9145, val_MinusLogProbMetric: 5.9145

Epoch 84: val_loss did not improve from 5.54254
196/196 - 81s - loss: 5.5712 - MinusLogProbMetric: 5.5712 - val_loss: 5.9145 - val_MinusLogProbMetric: 5.9145 - lr: 3.3333e-04 - 81s/epoch - 412ms/step
Epoch 85/1000
2023-09-19 15:25:47.367 
Epoch 85/1000 
	 loss: 5.5450, MinusLogProbMetric: 5.5450, val_loss: 5.6418, val_MinusLogProbMetric: 5.6418

Epoch 85: val_loss did not improve from 5.54254
196/196 - 81s - loss: 5.5450 - MinusLogProbMetric: 5.5450 - val_loss: 5.6418 - val_MinusLogProbMetric: 5.6418 - lr: 3.3333e-04 - 81s/epoch - 413ms/step
Epoch 86/1000
2023-09-19 15:27:08.264 
Epoch 86/1000 
	 loss: 5.5532, MinusLogProbMetric: 5.5532, val_loss: 5.7138, val_MinusLogProbMetric: 5.7138

Epoch 86: val_loss did not improve from 5.54254
196/196 - 81s - loss: 5.5532 - MinusLogProbMetric: 5.5532 - val_loss: 5.7138 - val_MinusLogProbMetric: 5.7138 - lr: 3.3333e-04 - 81s/epoch - 413ms/step
Epoch 87/1000
2023-09-19 15:28:29.361 
Epoch 87/1000 
	 loss: 5.5435, MinusLogProbMetric: 5.5435, val_loss: 5.6415, val_MinusLogProbMetric: 5.6415

Epoch 87: val_loss did not improve from 5.54254
196/196 - 81s - loss: 5.5435 - MinusLogProbMetric: 5.5435 - val_loss: 5.6415 - val_MinusLogProbMetric: 5.6415 - lr: 3.3333e-04 - 81s/epoch - 414ms/step
Epoch 88/1000
2023-09-19 15:29:50.550 
Epoch 88/1000 
	 loss: 5.5651, MinusLogProbMetric: 5.5651, val_loss: 5.5564, val_MinusLogProbMetric: 5.5564

Epoch 88: val_loss did not improve from 5.54254
196/196 - 81s - loss: 5.5651 - MinusLogProbMetric: 5.5651 - val_loss: 5.5564 - val_MinusLogProbMetric: 5.5564 - lr: 3.3333e-04 - 81s/epoch - 414ms/step
Epoch 89/1000
2023-09-19 15:31:11.714 
Epoch 89/1000 
	 loss: 5.5588, MinusLogProbMetric: 5.5588, val_loss: 5.5554, val_MinusLogProbMetric: 5.5554

Epoch 89: val_loss did not improve from 5.54254
196/196 - 81s - loss: 5.5588 - MinusLogProbMetric: 5.5588 - val_loss: 5.5554 - val_MinusLogProbMetric: 5.5554 - lr: 3.3333e-04 - 81s/epoch - 414ms/step
Epoch 90/1000
2023-09-19 15:32:33.024 
Epoch 90/1000 
	 loss: 5.5609, MinusLogProbMetric: 5.5609, val_loss: 5.7848, val_MinusLogProbMetric: 5.7848

Epoch 90: val_loss did not improve from 5.54254
196/196 - 81s - loss: 5.5609 - MinusLogProbMetric: 5.5609 - val_loss: 5.7848 - val_MinusLogProbMetric: 5.7848 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 91/1000
2023-09-19 15:33:53.683 
Epoch 91/1000 
	 loss: 5.5257, MinusLogProbMetric: 5.5257, val_loss: 5.5765, val_MinusLogProbMetric: 5.5765

Epoch 91: val_loss did not improve from 5.54254
196/196 - 81s - loss: 5.5257 - MinusLogProbMetric: 5.5257 - val_loss: 5.5765 - val_MinusLogProbMetric: 5.5765 - lr: 3.3333e-04 - 81s/epoch - 411ms/step
Epoch 92/1000
2023-09-19 15:35:14.911 
Epoch 92/1000 
	 loss: 5.5606, MinusLogProbMetric: 5.5606, val_loss: 5.6250, val_MinusLogProbMetric: 5.6250

Epoch 92: val_loss did not improve from 5.54254
196/196 - 81s - loss: 5.5606 - MinusLogProbMetric: 5.5606 - val_loss: 5.6250 - val_MinusLogProbMetric: 5.6250 - lr: 3.3333e-04 - 81s/epoch - 414ms/step
Epoch 93/1000
2023-09-19 15:36:35.920 
Epoch 93/1000 
	 loss: 5.5006, MinusLogProbMetric: 5.5006, val_loss: 5.4766, val_MinusLogProbMetric: 5.4766

Epoch 93: val_loss improved from 5.54254 to 5.47657, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 5.5006 - MinusLogProbMetric: 5.5006 - val_loss: 5.4766 - val_MinusLogProbMetric: 5.4766 - lr: 3.3333e-04 - 83s/epoch - 422ms/step
Epoch 94/1000
2023-09-19 15:37:59.512 
Epoch 94/1000 
	 loss: 5.5067, MinusLogProbMetric: 5.5067, val_loss: 5.4821, val_MinusLogProbMetric: 5.4821

Epoch 94: val_loss did not improve from 5.47657
196/196 - 82s - loss: 5.5067 - MinusLogProbMetric: 5.5067 - val_loss: 5.4821 - val_MinusLogProbMetric: 5.4821 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 95/1000
2023-09-19 15:39:20.798 
Epoch 95/1000 
	 loss: 5.5058, MinusLogProbMetric: 5.5058, val_loss: 5.6494, val_MinusLogProbMetric: 5.6494

Epoch 95: val_loss did not improve from 5.47657
196/196 - 81s - loss: 5.5058 - MinusLogProbMetric: 5.5058 - val_loss: 5.6494 - val_MinusLogProbMetric: 5.6494 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 96/1000
2023-09-19 15:40:42.032 
Epoch 96/1000 
	 loss: 5.5091, MinusLogProbMetric: 5.5091, val_loss: 5.8011, val_MinusLogProbMetric: 5.8011

Epoch 96: val_loss did not improve from 5.47657
196/196 - 81s - loss: 5.5091 - MinusLogProbMetric: 5.5091 - val_loss: 5.8011 - val_MinusLogProbMetric: 5.8011 - lr: 3.3333e-04 - 81s/epoch - 414ms/step
Epoch 97/1000
2023-09-19 15:42:03.341 
Epoch 97/1000 
	 loss: 5.5060, MinusLogProbMetric: 5.5060, val_loss: 5.5128, val_MinusLogProbMetric: 5.5128

Epoch 97: val_loss did not improve from 5.47657
196/196 - 81s - loss: 5.5060 - MinusLogProbMetric: 5.5060 - val_loss: 5.5128 - val_MinusLogProbMetric: 5.5128 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 98/1000
2023-09-19 15:43:24.442 
Epoch 98/1000 
	 loss: 5.4977, MinusLogProbMetric: 5.4977, val_loss: 5.5587, val_MinusLogProbMetric: 5.5587

Epoch 98: val_loss did not improve from 5.47657
196/196 - 81s - loss: 5.4977 - MinusLogProbMetric: 5.4977 - val_loss: 5.5587 - val_MinusLogProbMetric: 5.5587 - lr: 3.3333e-04 - 81s/epoch - 414ms/step
Epoch 99/1000
2023-09-19 15:44:46.535 
Epoch 99/1000 
	 loss: 5.5006, MinusLogProbMetric: 5.5006, val_loss: 5.5445, val_MinusLogProbMetric: 5.5445

Epoch 99: val_loss did not improve from 5.47657
196/196 - 82s - loss: 5.5006 - MinusLogProbMetric: 5.5006 - val_loss: 5.5445 - val_MinusLogProbMetric: 5.5445 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 100/1000
2023-09-19 15:46:09.863 
Epoch 100/1000 
	 loss: 5.4891, MinusLogProbMetric: 5.4891, val_loss: 5.6751, val_MinusLogProbMetric: 5.6751

Epoch 100: val_loss did not improve from 5.47657
196/196 - 83s - loss: 5.4891 - MinusLogProbMetric: 5.4891 - val_loss: 5.6751 - val_MinusLogProbMetric: 5.6751 - lr: 3.3333e-04 - 83s/epoch - 425ms/step
Epoch 101/1000
2023-09-19 15:47:33.233 
Epoch 101/1000 
	 loss: 5.4889, MinusLogProbMetric: 5.4889, val_loss: 5.7295, val_MinusLogProbMetric: 5.7295

Epoch 101: val_loss did not improve from 5.47657
196/196 - 83s - loss: 5.4889 - MinusLogProbMetric: 5.4889 - val_loss: 5.7295 - val_MinusLogProbMetric: 5.7295 - lr: 3.3333e-04 - 83s/epoch - 425ms/step
Epoch 102/1000
2023-09-19 15:48:56.014 
Epoch 102/1000 
	 loss: 5.5042, MinusLogProbMetric: 5.5042, val_loss: 5.5972, val_MinusLogProbMetric: 5.5972

Epoch 102: val_loss did not improve from 5.47657
196/196 - 83s - loss: 5.5042 - MinusLogProbMetric: 5.5042 - val_loss: 5.5972 - val_MinusLogProbMetric: 5.5972 - lr: 3.3333e-04 - 83s/epoch - 422ms/step
Epoch 103/1000
2023-09-19 15:50:19.764 
Epoch 103/1000 
	 loss: 5.4641, MinusLogProbMetric: 5.4641, val_loss: 5.4881, val_MinusLogProbMetric: 5.4881

Epoch 103: val_loss did not improve from 5.47657
196/196 - 84s - loss: 5.4641 - MinusLogProbMetric: 5.4641 - val_loss: 5.4881 - val_MinusLogProbMetric: 5.4881 - lr: 3.3333e-04 - 84s/epoch - 427ms/step
Epoch 104/1000
2023-09-19 15:51:43.287 
Epoch 104/1000 
	 loss: 5.4735, MinusLogProbMetric: 5.4735, val_loss: 5.6321, val_MinusLogProbMetric: 5.6321

Epoch 104: val_loss did not improve from 5.47657
196/196 - 84s - loss: 5.4735 - MinusLogProbMetric: 5.4735 - val_loss: 5.6321 - val_MinusLogProbMetric: 5.6321 - lr: 3.3333e-04 - 84s/epoch - 426ms/step
Epoch 105/1000
2023-09-19 15:53:06.552 
Epoch 105/1000 
	 loss: 5.4907, MinusLogProbMetric: 5.4907, val_loss: 5.4892, val_MinusLogProbMetric: 5.4892

Epoch 105: val_loss did not improve from 5.47657
196/196 - 83s - loss: 5.4907 - MinusLogProbMetric: 5.4907 - val_loss: 5.4892 - val_MinusLogProbMetric: 5.4892 - lr: 3.3333e-04 - 83s/epoch - 425ms/step
Epoch 106/1000
2023-09-19 15:54:29.803 
Epoch 106/1000 
	 loss: 5.4610, MinusLogProbMetric: 5.4610, val_loss: 5.4286, val_MinusLogProbMetric: 5.4286

Epoch 106: val_loss improved from 5.47657 to 5.42857, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 85s - loss: 5.4610 - MinusLogProbMetric: 5.4610 - val_loss: 5.4286 - val_MinusLogProbMetric: 5.4286 - lr: 3.3333e-04 - 85s/epoch - 432ms/step
Epoch 107/1000
2023-09-19 15:55:55.181 
Epoch 107/1000 
	 loss: 5.4812, MinusLogProbMetric: 5.4812, val_loss: 5.4533, val_MinusLogProbMetric: 5.4533

Epoch 107: val_loss did not improve from 5.42857
196/196 - 84s - loss: 5.4812 - MinusLogProbMetric: 5.4812 - val_loss: 5.4533 - val_MinusLogProbMetric: 5.4533 - lr: 3.3333e-04 - 84s/epoch - 428ms/step
Epoch 108/1000
2023-09-19 15:57:18.389 
Epoch 108/1000 
	 loss: 5.4631, MinusLogProbMetric: 5.4631, val_loss: 5.6657, val_MinusLogProbMetric: 5.6657

Epoch 108: val_loss did not improve from 5.42857
196/196 - 83s - loss: 5.4631 - MinusLogProbMetric: 5.4631 - val_loss: 5.6657 - val_MinusLogProbMetric: 5.6657 - lr: 3.3333e-04 - 83s/epoch - 425ms/step
Epoch 109/1000
2023-09-19 15:58:42.512 
Epoch 109/1000 
	 loss: 5.4604, MinusLogProbMetric: 5.4604, val_loss: 5.4877, val_MinusLogProbMetric: 5.4877

Epoch 109: val_loss did not improve from 5.42857
196/196 - 84s - loss: 5.4604 - MinusLogProbMetric: 5.4604 - val_loss: 5.4877 - val_MinusLogProbMetric: 5.4877 - lr: 3.3333e-04 - 84s/epoch - 429ms/step
Epoch 110/1000
2023-09-19 16:00:06.577 
Epoch 110/1000 
	 loss: 5.4653, MinusLogProbMetric: 5.4653, val_loss: 5.4901, val_MinusLogProbMetric: 5.4901

Epoch 110: val_loss did not improve from 5.42857
196/196 - 84s - loss: 5.4653 - MinusLogProbMetric: 5.4653 - val_loss: 5.4901 - val_MinusLogProbMetric: 5.4901 - lr: 3.3333e-04 - 84s/epoch - 429ms/step
Epoch 111/1000
2023-09-19 16:01:30.536 
Epoch 111/1000 
	 loss: 5.4434, MinusLogProbMetric: 5.4434, val_loss: 5.5580, val_MinusLogProbMetric: 5.5580

Epoch 111: val_loss did not improve from 5.42857
196/196 - 84s - loss: 5.4434 - MinusLogProbMetric: 5.4434 - val_loss: 5.5580 - val_MinusLogProbMetric: 5.5580 - lr: 3.3333e-04 - 84s/epoch - 428ms/step
Epoch 112/1000
2023-09-19 16:02:54.316 
Epoch 112/1000 
	 loss: 5.4723, MinusLogProbMetric: 5.4723, val_loss: 5.5518, val_MinusLogProbMetric: 5.5518

Epoch 112: val_loss did not improve from 5.42857
196/196 - 84s - loss: 5.4723 - MinusLogProbMetric: 5.4723 - val_loss: 5.5518 - val_MinusLogProbMetric: 5.5518 - lr: 3.3333e-04 - 84s/epoch - 427ms/step
Epoch 113/1000
2023-09-19 16:04:17.324 
Epoch 113/1000 
	 loss: 5.4444, MinusLogProbMetric: 5.4444, val_loss: 5.5902, val_MinusLogProbMetric: 5.5902

Epoch 113: val_loss did not improve from 5.42857
196/196 - 83s - loss: 5.4444 - MinusLogProbMetric: 5.4444 - val_loss: 5.5902 - val_MinusLogProbMetric: 5.5902 - lr: 3.3333e-04 - 83s/epoch - 424ms/step
Epoch 114/1000
2023-09-19 16:05:41.054 
Epoch 114/1000 
	 loss: 5.4435, MinusLogProbMetric: 5.4435, val_loss: 5.6830, val_MinusLogProbMetric: 5.6830

Epoch 114: val_loss did not improve from 5.42857
196/196 - 84s - loss: 5.4435 - MinusLogProbMetric: 5.4435 - val_loss: 5.6830 - val_MinusLogProbMetric: 5.6830 - lr: 3.3333e-04 - 84s/epoch - 427ms/step
Epoch 115/1000
2023-09-19 16:07:05.409 
Epoch 115/1000 
	 loss: 5.4545, MinusLogProbMetric: 5.4545, val_loss: 5.4814, val_MinusLogProbMetric: 5.4814

Epoch 115: val_loss did not improve from 5.42857
196/196 - 84s - loss: 5.4545 - MinusLogProbMetric: 5.4545 - val_loss: 5.4814 - val_MinusLogProbMetric: 5.4814 - lr: 3.3333e-04 - 84s/epoch - 430ms/step
Epoch 116/1000
2023-09-19 16:08:29.067 
Epoch 116/1000 
	 loss: 5.4346, MinusLogProbMetric: 5.4346, val_loss: 5.4947, val_MinusLogProbMetric: 5.4947

Epoch 116: val_loss did not improve from 5.42857
196/196 - 84s - loss: 5.4346 - MinusLogProbMetric: 5.4346 - val_loss: 5.4947 - val_MinusLogProbMetric: 5.4947 - lr: 3.3333e-04 - 84s/epoch - 427ms/step
Epoch 117/1000
2023-09-19 16:09:52.805 
Epoch 117/1000 
	 loss: 5.4956, MinusLogProbMetric: 5.4956, val_loss: 5.5683, val_MinusLogProbMetric: 5.5683

Epoch 117: val_loss did not improve from 5.42857
196/196 - 84s - loss: 5.4956 - MinusLogProbMetric: 5.4956 - val_loss: 5.5683 - val_MinusLogProbMetric: 5.5683 - lr: 3.3333e-04 - 84s/epoch - 427ms/step
Epoch 118/1000
2023-09-19 16:11:16.188 
Epoch 118/1000 
	 loss: 5.4817, MinusLogProbMetric: 5.4817, val_loss: 5.5542, val_MinusLogProbMetric: 5.5542

Epoch 118: val_loss did not improve from 5.42857
196/196 - 83s - loss: 5.4817 - MinusLogProbMetric: 5.4817 - val_loss: 5.5542 - val_MinusLogProbMetric: 5.5542 - lr: 3.3333e-04 - 83s/epoch - 425ms/step
Epoch 119/1000
2023-09-19 16:12:39.070 
Epoch 119/1000 
	 loss: 5.4480, MinusLogProbMetric: 5.4480, val_loss: 5.5153, val_MinusLogProbMetric: 5.5153

Epoch 119: val_loss did not improve from 5.42857
196/196 - 83s - loss: 5.4480 - MinusLogProbMetric: 5.4480 - val_loss: 5.5153 - val_MinusLogProbMetric: 5.5153 - lr: 3.3333e-04 - 83s/epoch - 423ms/step
Epoch 120/1000
2023-09-19 16:13:58.577 
Epoch 120/1000 
	 loss: 5.4435, MinusLogProbMetric: 5.4435, val_loss: 5.5761, val_MinusLogProbMetric: 5.5761

Epoch 120: val_loss did not improve from 5.42857
196/196 - 80s - loss: 5.4435 - MinusLogProbMetric: 5.4435 - val_loss: 5.5761 - val_MinusLogProbMetric: 5.5761 - lr: 3.3333e-04 - 80s/epoch - 406ms/step
Epoch 121/1000
2023-09-19 16:15:14.268 
Epoch 121/1000 
	 loss: 5.4482, MinusLogProbMetric: 5.4482, val_loss: 5.4617, val_MinusLogProbMetric: 5.4617

Epoch 121: val_loss did not improve from 5.42857
196/196 - 76s - loss: 5.4482 - MinusLogProbMetric: 5.4482 - val_loss: 5.4617 - val_MinusLogProbMetric: 5.4617 - lr: 3.3333e-04 - 76s/epoch - 386ms/step
Epoch 122/1000
2023-09-19 16:16:32.832 
Epoch 122/1000 
	 loss: 5.4334, MinusLogProbMetric: 5.4334, val_loss: 5.6822, val_MinusLogProbMetric: 5.6822

Epoch 122: val_loss did not improve from 5.42857
196/196 - 79s - loss: 5.4334 - MinusLogProbMetric: 5.4334 - val_loss: 5.6822 - val_MinusLogProbMetric: 5.6822 - lr: 3.3333e-04 - 79s/epoch - 401ms/step
Epoch 123/1000
2023-09-19 16:17:54.992 
Epoch 123/1000 
	 loss: 5.4318, MinusLogProbMetric: 5.4318, val_loss: 5.5107, val_MinusLogProbMetric: 5.5107

Epoch 123: val_loss did not improve from 5.42857
196/196 - 82s - loss: 5.4318 - MinusLogProbMetric: 5.4318 - val_loss: 5.5107 - val_MinusLogProbMetric: 5.5107 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 124/1000
2023-09-19 16:19:17.778 
Epoch 124/1000 
	 loss: 5.4462, MinusLogProbMetric: 5.4462, val_loss: 5.4677, val_MinusLogProbMetric: 5.4677

Epoch 124: val_loss did not improve from 5.42857
196/196 - 83s - loss: 5.4462 - MinusLogProbMetric: 5.4462 - val_loss: 5.4677 - val_MinusLogProbMetric: 5.4677 - lr: 3.3333e-04 - 83s/epoch - 422ms/step
Epoch 125/1000
2023-09-19 16:20:40.157 
Epoch 125/1000 
	 loss: 5.4041, MinusLogProbMetric: 5.4041, val_loss: 5.4130, val_MinusLogProbMetric: 5.4130

Epoch 125: val_loss improved from 5.42857 to 5.41295, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 84s - loss: 5.4041 - MinusLogProbMetric: 5.4041 - val_loss: 5.4130 - val_MinusLogProbMetric: 5.4130 - lr: 3.3333e-04 - 84s/epoch - 427ms/step
Epoch 126/1000
2023-09-19 16:22:03.587 
Epoch 126/1000 
	 loss: 5.4390, MinusLogProbMetric: 5.4390, val_loss: 5.6179, val_MinusLogProbMetric: 5.6179

Epoch 126: val_loss did not improve from 5.41295
196/196 - 82s - loss: 5.4390 - MinusLogProbMetric: 5.4390 - val_loss: 5.6179 - val_MinusLogProbMetric: 5.6179 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 127/1000
2023-09-19 16:23:26.342 
Epoch 127/1000 
	 loss: 5.4473, MinusLogProbMetric: 5.4473, val_loss: 5.5646, val_MinusLogProbMetric: 5.5646

Epoch 127: val_loss did not improve from 5.41295
196/196 - 83s - loss: 5.4473 - MinusLogProbMetric: 5.4473 - val_loss: 5.5646 - val_MinusLogProbMetric: 5.5646 - lr: 3.3333e-04 - 83s/epoch - 422ms/step
Epoch 128/1000
2023-09-19 16:24:49.081 
Epoch 128/1000 
	 loss: 5.4180, MinusLogProbMetric: 5.4180, val_loss: 5.5321, val_MinusLogProbMetric: 5.5321

Epoch 128: val_loss did not improve from 5.41295
196/196 - 83s - loss: 5.4180 - MinusLogProbMetric: 5.4180 - val_loss: 5.5321 - val_MinusLogProbMetric: 5.5321 - lr: 3.3333e-04 - 83s/epoch - 422ms/step
Epoch 129/1000
2023-09-19 16:26:11.201 
Epoch 129/1000 
	 loss: 5.4057, MinusLogProbMetric: 5.4057, val_loss: 5.4847, val_MinusLogProbMetric: 5.4847

Epoch 129: val_loss did not improve from 5.41295
196/196 - 82s - loss: 5.4057 - MinusLogProbMetric: 5.4057 - val_loss: 5.4847 - val_MinusLogProbMetric: 5.4847 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 130/1000
2023-09-19 16:27:32.493 
Epoch 130/1000 
	 loss: 5.4216, MinusLogProbMetric: 5.4216, val_loss: 5.4826, val_MinusLogProbMetric: 5.4826

Epoch 130: val_loss did not improve from 5.41295
196/196 - 81s - loss: 5.4216 - MinusLogProbMetric: 5.4216 - val_loss: 5.4826 - val_MinusLogProbMetric: 5.4826 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 131/1000
2023-09-19 16:28:54.908 
Epoch 131/1000 
	 loss: 5.4032, MinusLogProbMetric: 5.4032, val_loss: 5.5173, val_MinusLogProbMetric: 5.5173

Epoch 131: val_loss did not improve from 5.41295
196/196 - 82s - loss: 5.4032 - MinusLogProbMetric: 5.4032 - val_loss: 5.5173 - val_MinusLogProbMetric: 5.5173 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 132/1000
2023-09-19 16:30:16.744 
Epoch 132/1000 
	 loss: 5.4293, MinusLogProbMetric: 5.4293, val_loss: 5.4408, val_MinusLogProbMetric: 5.4408

Epoch 132: val_loss did not improve from 5.41295
196/196 - 82s - loss: 5.4293 - MinusLogProbMetric: 5.4293 - val_loss: 5.4408 - val_MinusLogProbMetric: 5.4408 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 133/1000
2023-09-19 16:31:38.836 
Epoch 133/1000 
	 loss: 5.4014, MinusLogProbMetric: 5.4014, val_loss: 5.4780, val_MinusLogProbMetric: 5.4780

Epoch 133: val_loss did not improve from 5.41295
196/196 - 82s - loss: 5.4014 - MinusLogProbMetric: 5.4014 - val_loss: 5.4780 - val_MinusLogProbMetric: 5.4780 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 134/1000
2023-09-19 16:33:01.376 
Epoch 134/1000 
	 loss: 5.3857, MinusLogProbMetric: 5.3857, val_loss: 5.4368, val_MinusLogProbMetric: 5.4368

Epoch 134: val_loss did not improve from 5.41295
196/196 - 83s - loss: 5.3857 - MinusLogProbMetric: 5.3857 - val_loss: 5.4368 - val_MinusLogProbMetric: 5.4368 - lr: 3.3333e-04 - 83s/epoch - 421ms/step
Epoch 135/1000
2023-09-19 16:34:22.843 
Epoch 135/1000 
	 loss: 5.4175, MinusLogProbMetric: 5.4175, val_loss: 5.4731, val_MinusLogProbMetric: 5.4731

Epoch 135: val_loss did not improve from 5.41295
196/196 - 81s - loss: 5.4175 - MinusLogProbMetric: 5.4175 - val_loss: 5.4731 - val_MinusLogProbMetric: 5.4731 - lr: 3.3333e-04 - 81s/epoch - 416ms/step
Epoch 136/1000
2023-09-19 16:35:44.803 
Epoch 136/1000 
	 loss: 5.3909, MinusLogProbMetric: 5.3909, val_loss: 5.4143, val_MinusLogProbMetric: 5.4143

Epoch 136: val_loss did not improve from 5.41295
196/196 - 82s - loss: 5.3909 - MinusLogProbMetric: 5.3909 - val_loss: 5.4143 - val_MinusLogProbMetric: 5.4143 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 137/1000
2023-09-19 16:37:06.816 
Epoch 137/1000 
	 loss: 5.4030, MinusLogProbMetric: 5.4030, val_loss: 5.4000, val_MinusLogProbMetric: 5.4000

Epoch 137: val_loss improved from 5.41295 to 5.39996, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 5.4030 - MinusLogProbMetric: 5.4030 - val_loss: 5.4000 - val_MinusLogProbMetric: 5.4000 - lr: 3.3333e-04 - 83s/epoch - 425ms/step
Epoch 138/1000
2023-09-19 16:38:30.285 
Epoch 138/1000 
	 loss: 5.3919, MinusLogProbMetric: 5.3919, val_loss: 5.6401, val_MinusLogProbMetric: 5.6401

Epoch 138: val_loss did not improve from 5.39996
196/196 - 82s - loss: 5.3919 - MinusLogProbMetric: 5.3919 - val_loss: 5.6401 - val_MinusLogProbMetric: 5.6401 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 139/1000
2023-09-19 16:39:52.640 
Epoch 139/1000 
	 loss: 5.4006, MinusLogProbMetric: 5.4006, val_loss: 5.4153, val_MinusLogProbMetric: 5.4153

Epoch 139: val_loss did not improve from 5.39996
196/196 - 82s - loss: 5.4006 - MinusLogProbMetric: 5.4006 - val_loss: 5.4153 - val_MinusLogProbMetric: 5.4153 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 140/1000
2023-09-19 16:41:15.016 
Epoch 140/1000 
	 loss: 5.3939, MinusLogProbMetric: 5.3939, val_loss: 5.5593, val_MinusLogProbMetric: 5.5593

Epoch 140: val_loss did not improve from 5.39996
196/196 - 82s - loss: 5.3939 - MinusLogProbMetric: 5.3939 - val_loss: 5.5593 - val_MinusLogProbMetric: 5.5593 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 141/1000
2023-09-19 16:42:37.048 
Epoch 141/1000 
	 loss: 5.3986, MinusLogProbMetric: 5.3986, val_loss: 5.4455, val_MinusLogProbMetric: 5.4455

Epoch 141: val_loss did not improve from 5.39996
196/196 - 82s - loss: 5.3986 - MinusLogProbMetric: 5.3986 - val_loss: 5.4455 - val_MinusLogProbMetric: 5.4455 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 142/1000
2023-09-19 16:43:59.994 
Epoch 142/1000 
	 loss: 5.4191, MinusLogProbMetric: 5.4191, val_loss: 5.4213, val_MinusLogProbMetric: 5.4213

Epoch 142: val_loss did not improve from 5.39996
196/196 - 83s - loss: 5.4191 - MinusLogProbMetric: 5.4191 - val_loss: 5.4213 - val_MinusLogProbMetric: 5.4213 - lr: 3.3333e-04 - 83s/epoch - 423ms/step
Epoch 143/1000
2023-09-19 16:45:15.757 
Epoch 143/1000 
	 loss: 5.3826, MinusLogProbMetric: 5.3826, val_loss: 5.5668, val_MinusLogProbMetric: 5.5668

Epoch 143: val_loss did not improve from 5.39996
196/196 - 76s - loss: 5.3826 - MinusLogProbMetric: 5.3826 - val_loss: 5.5668 - val_MinusLogProbMetric: 5.5668 - lr: 3.3333e-04 - 76s/epoch - 387ms/step
Epoch 144/1000
2023-09-19 16:46:21.217 
Epoch 144/1000 
	 loss: 5.4132, MinusLogProbMetric: 5.4132, val_loss: 5.4427, val_MinusLogProbMetric: 5.4427

Epoch 144: val_loss did not improve from 5.39996
196/196 - 65s - loss: 5.4132 - MinusLogProbMetric: 5.4132 - val_loss: 5.4427 - val_MinusLogProbMetric: 5.4427 - lr: 3.3333e-04 - 65s/epoch - 334ms/step
Epoch 145/1000
2023-09-19 16:47:36.742 
Epoch 145/1000 
	 loss: 5.3894, MinusLogProbMetric: 5.3894, val_loss: 5.4310, val_MinusLogProbMetric: 5.4310

Epoch 145: val_loss did not improve from 5.39996
196/196 - 76s - loss: 5.3894 - MinusLogProbMetric: 5.3894 - val_loss: 5.4310 - val_MinusLogProbMetric: 5.4310 - lr: 3.3333e-04 - 76s/epoch - 385ms/step
Epoch 146/1000
2023-09-19 16:48:58.004 
Epoch 146/1000 
	 loss: 5.3709, MinusLogProbMetric: 5.3709, val_loss: 5.4885, val_MinusLogProbMetric: 5.4885

Epoch 146: val_loss did not improve from 5.39996
196/196 - 81s - loss: 5.3709 - MinusLogProbMetric: 5.3709 - val_loss: 5.4885 - val_MinusLogProbMetric: 5.4885 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 147/1000
2023-09-19 16:50:19.486 
Epoch 147/1000 
	 loss: 5.3843, MinusLogProbMetric: 5.3843, val_loss: 5.4112, val_MinusLogProbMetric: 5.4112

Epoch 147: val_loss did not improve from 5.39996
196/196 - 81s - loss: 5.3843 - MinusLogProbMetric: 5.3843 - val_loss: 5.4112 - val_MinusLogProbMetric: 5.4112 - lr: 3.3333e-04 - 81s/epoch - 416ms/step
Epoch 148/1000
2023-09-19 16:51:41.098 
Epoch 148/1000 
	 loss: 5.3923, MinusLogProbMetric: 5.3923, val_loss: 5.5919, val_MinusLogProbMetric: 5.5919

Epoch 148: val_loss did not improve from 5.39996
196/196 - 82s - loss: 5.3923 - MinusLogProbMetric: 5.3923 - val_loss: 5.5919 - val_MinusLogProbMetric: 5.5919 - lr: 3.3333e-04 - 82s/epoch - 416ms/step
Epoch 149/1000
2023-09-19 16:53:02.579 
Epoch 149/1000 
	 loss: 5.3720, MinusLogProbMetric: 5.3720, val_loss: 5.4973, val_MinusLogProbMetric: 5.4973

Epoch 149: val_loss did not improve from 5.39996
196/196 - 81s - loss: 5.3720 - MinusLogProbMetric: 5.3720 - val_loss: 5.4973 - val_MinusLogProbMetric: 5.4973 - lr: 3.3333e-04 - 81s/epoch - 416ms/step
Epoch 150/1000
2023-09-19 16:54:24.519 
Epoch 150/1000 
	 loss: 5.3682, MinusLogProbMetric: 5.3682, val_loss: 5.3516, val_MinusLogProbMetric: 5.3516

Epoch 150: val_loss improved from 5.39996 to 5.35164, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 5.3682 - MinusLogProbMetric: 5.3682 - val_loss: 5.3516 - val_MinusLogProbMetric: 5.3516 - lr: 3.3333e-04 - 83s/epoch - 426ms/step
Epoch 151/1000
2023-09-19 16:55:47.879 
Epoch 151/1000 
	 loss: 5.3812, MinusLogProbMetric: 5.3812, val_loss: 5.3985, val_MinusLogProbMetric: 5.3985

Epoch 151: val_loss did not improve from 5.35164
196/196 - 82s - loss: 5.3812 - MinusLogProbMetric: 5.3812 - val_loss: 5.3985 - val_MinusLogProbMetric: 5.3985 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 152/1000
2023-09-19 16:57:10.027 
Epoch 152/1000 
	 loss: 5.4020, MinusLogProbMetric: 5.4020, val_loss: 5.5815, val_MinusLogProbMetric: 5.5815

Epoch 152: val_loss did not improve from 5.35164
196/196 - 82s - loss: 5.4020 - MinusLogProbMetric: 5.4020 - val_loss: 5.5815 - val_MinusLogProbMetric: 5.5815 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 153/1000
2023-09-19 16:58:31.784 
Epoch 153/1000 
	 loss: 5.3693, MinusLogProbMetric: 5.3693, val_loss: 5.3852, val_MinusLogProbMetric: 5.3852

Epoch 153: val_loss did not improve from 5.35164
196/196 - 82s - loss: 5.3693 - MinusLogProbMetric: 5.3693 - val_loss: 5.3852 - val_MinusLogProbMetric: 5.3852 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 154/1000
2023-09-19 16:59:54.528 
Epoch 154/1000 
	 loss: 5.3568, MinusLogProbMetric: 5.3568, val_loss: 5.4332, val_MinusLogProbMetric: 5.4332

Epoch 154: val_loss did not improve from 5.35164
196/196 - 83s - loss: 5.3568 - MinusLogProbMetric: 5.3568 - val_loss: 5.4332 - val_MinusLogProbMetric: 5.4332 - lr: 3.3333e-04 - 83s/epoch - 422ms/step
Epoch 155/1000
2023-09-19 17:01:16.642 
Epoch 155/1000 
	 loss: 5.3816, MinusLogProbMetric: 5.3816, val_loss: 5.6449, val_MinusLogProbMetric: 5.6449

Epoch 155: val_loss did not improve from 5.35164
196/196 - 82s - loss: 5.3816 - MinusLogProbMetric: 5.3816 - val_loss: 5.6449 - val_MinusLogProbMetric: 5.6449 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 156/1000
2023-09-19 17:02:38.721 
Epoch 156/1000 
	 loss: 5.3704, MinusLogProbMetric: 5.3704, val_loss: 5.4558, val_MinusLogProbMetric: 5.4558

Epoch 156: val_loss did not improve from 5.35164
196/196 - 82s - loss: 5.3704 - MinusLogProbMetric: 5.3704 - val_loss: 5.4558 - val_MinusLogProbMetric: 5.4558 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 157/1000
2023-09-19 17:04:01.270 
Epoch 157/1000 
	 loss: 5.3461, MinusLogProbMetric: 5.3461, val_loss: 5.3951, val_MinusLogProbMetric: 5.3951

Epoch 157: val_loss did not improve from 5.35164
196/196 - 83s - loss: 5.3461 - MinusLogProbMetric: 5.3461 - val_loss: 5.3951 - val_MinusLogProbMetric: 5.3951 - lr: 3.3333e-04 - 83s/epoch - 421ms/step
Epoch 158/1000
2023-09-19 17:05:22.789 
Epoch 158/1000 
	 loss: 5.3658, MinusLogProbMetric: 5.3658, val_loss: 5.4912, val_MinusLogProbMetric: 5.4912

Epoch 158: val_loss did not improve from 5.35164
196/196 - 82s - loss: 5.3658 - MinusLogProbMetric: 5.3658 - val_loss: 5.4912 - val_MinusLogProbMetric: 5.4912 - lr: 3.3333e-04 - 82s/epoch - 416ms/step
Epoch 159/1000
2023-09-19 17:06:44.750 
Epoch 159/1000 
	 loss: 5.3867, MinusLogProbMetric: 5.3867, val_loss: 5.4488, val_MinusLogProbMetric: 5.4488

Epoch 159: val_loss did not improve from 5.35164
196/196 - 82s - loss: 5.3867 - MinusLogProbMetric: 5.3867 - val_loss: 5.4488 - val_MinusLogProbMetric: 5.4488 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 160/1000
2023-09-19 17:08:07.392 
Epoch 160/1000 
	 loss: 5.3775, MinusLogProbMetric: 5.3775, val_loss: 5.3288, val_MinusLogProbMetric: 5.3288

Epoch 160: val_loss improved from 5.35164 to 5.32885, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 84s - loss: 5.3775 - MinusLogProbMetric: 5.3775 - val_loss: 5.3288 - val_MinusLogProbMetric: 5.3288 - lr: 3.3333e-04 - 84s/epoch - 430ms/step
Epoch 161/1000
2023-09-19 17:09:30.725 
Epoch 161/1000 
	 loss: 5.3497, MinusLogProbMetric: 5.3497, val_loss: 5.3456, val_MinusLogProbMetric: 5.3456

Epoch 161: val_loss did not improve from 5.32885
196/196 - 82s - loss: 5.3497 - MinusLogProbMetric: 5.3497 - val_loss: 5.3456 - val_MinusLogProbMetric: 5.3456 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 162/1000
2023-09-19 17:10:42.099 
Epoch 162/1000 
	 loss: 5.3554, MinusLogProbMetric: 5.3554, val_loss: 5.5060, val_MinusLogProbMetric: 5.5060

Epoch 162: val_loss did not improve from 5.32885
196/196 - 71s - loss: 5.3554 - MinusLogProbMetric: 5.3554 - val_loss: 5.5060 - val_MinusLogProbMetric: 5.5060 - lr: 3.3333e-04 - 71s/epoch - 364ms/step
Epoch 163/1000
2023-09-19 17:11:47.039 
Epoch 163/1000 
	 loss: 5.3659, MinusLogProbMetric: 5.3659, val_loss: 5.3603, val_MinusLogProbMetric: 5.3603

Epoch 163: val_loss did not improve from 5.32885
196/196 - 65s - loss: 5.3659 - MinusLogProbMetric: 5.3659 - val_loss: 5.3603 - val_MinusLogProbMetric: 5.3603 - lr: 3.3333e-04 - 65s/epoch - 331ms/step
Epoch 164/1000
2023-09-19 17:13:07.962 
Epoch 164/1000 
	 loss: 5.3711, MinusLogProbMetric: 5.3711, val_loss: 5.4014, val_MinusLogProbMetric: 5.4014

Epoch 164: val_loss did not improve from 5.32885
196/196 - 81s - loss: 5.3711 - MinusLogProbMetric: 5.3711 - val_loss: 5.4014 - val_MinusLogProbMetric: 5.4014 - lr: 3.3333e-04 - 81s/epoch - 413ms/step
Epoch 165/1000
2023-09-19 17:14:28.970 
Epoch 165/1000 
	 loss: 5.3646, MinusLogProbMetric: 5.3646, val_loss: 5.3998, val_MinusLogProbMetric: 5.3998

Epoch 165: val_loss did not improve from 5.32885
196/196 - 81s - loss: 5.3646 - MinusLogProbMetric: 5.3646 - val_loss: 5.3998 - val_MinusLogProbMetric: 5.3998 - lr: 3.3333e-04 - 81s/epoch - 413ms/step
Epoch 166/1000
2023-09-19 17:15:51.042 
Epoch 166/1000 
	 loss: 5.3674, MinusLogProbMetric: 5.3674, val_loss: 5.6645, val_MinusLogProbMetric: 5.6645

Epoch 166: val_loss did not improve from 5.32885
196/196 - 82s - loss: 5.3674 - MinusLogProbMetric: 5.3674 - val_loss: 5.6645 - val_MinusLogProbMetric: 5.6645 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 167/1000
2023-09-19 17:17:13.132 
Epoch 167/1000 
	 loss: 5.3727, MinusLogProbMetric: 5.3727, val_loss: 5.4089, val_MinusLogProbMetric: 5.4089

Epoch 167: val_loss did not improve from 5.32885
196/196 - 82s - loss: 5.3727 - MinusLogProbMetric: 5.3727 - val_loss: 5.4089 - val_MinusLogProbMetric: 5.4089 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 168/1000
2023-09-19 17:18:35.846 
Epoch 168/1000 
	 loss: 5.3515, MinusLogProbMetric: 5.3515, val_loss: 5.5243, val_MinusLogProbMetric: 5.5243

Epoch 168: val_loss did not improve from 5.32885
196/196 - 83s - loss: 5.3515 - MinusLogProbMetric: 5.3515 - val_loss: 5.5243 - val_MinusLogProbMetric: 5.5243 - lr: 3.3333e-04 - 83s/epoch - 422ms/step
Epoch 169/1000
2023-09-19 17:19:57.603 
Epoch 169/1000 
	 loss: 5.3615, MinusLogProbMetric: 5.3615, val_loss: 5.4668, val_MinusLogProbMetric: 5.4668

Epoch 169: val_loss did not improve from 5.32885
196/196 - 82s - loss: 5.3615 - MinusLogProbMetric: 5.3615 - val_loss: 5.4668 - val_MinusLogProbMetric: 5.4668 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 170/1000
2023-09-19 17:21:19.442 
Epoch 170/1000 
	 loss: 5.3565, MinusLogProbMetric: 5.3565, val_loss: 5.5492, val_MinusLogProbMetric: 5.5492

Epoch 170: val_loss did not improve from 5.32885
196/196 - 82s - loss: 5.3565 - MinusLogProbMetric: 5.3565 - val_loss: 5.5492 - val_MinusLogProbMetric: 5.5492 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 171/1000
2023-09-19 17:22:41.594 
Epoch 171/1000 
	 loss: 5.3676, MinusLogProbMetric: 5.3676, val_loss: 5.4049, val_MinusLogProbMetric: 5.4049

Epoch 171: val_loss did not improve from 5.32885
196/196 - 82s - loss: 5.3676 - MinusLogProbMetric: 5.3676 - val_loss: 5.4049 - val_MinusLogProbMetric: 5.4049 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 172/1000
2023-09-19 17:24:03.256 
Epoch 172/1000 
	 loss: 5.3569, MinusLogProbMetric: 5.3569, val_loss: 5.4271, val_MinusLogProbMetric: 5.4271

Epoch 172: val_loss did not improve from 5.32885
196/196 - 82s - loss: 5.3569 - MinusLogProbMetric: 5.3569 - val_loss: 5.4271 - val_MinusLogProbMetric: 5.4271 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 173/1000
2023-09-19 17:25:25.734 
Epoch 173/1000 
	 loss: 5.3338, MinusLogProbMetric: 5.3338, val_loss: 5.3727, val_MinusLogProbMetric: 5.3727

Epoch 173: val_loss did not improve from 5.32885
196/196 - 82s - loss: 5.3338 - MinusLogProbMetric: 5.3338 - val_loss: 5.3727 - val_MinusLogProbMetric: 5.3727 - lr: 3.3333e-04 - 82s/epoch - 421ms/step
Epoch 174/1000
2023-09-19 17:26:48.176 
Epoch 174/1000 
	 loss: 5.3337, MinusLogProbMetric: 5.3337, val_loss: 5.4265, val_MinusLogProbMetric: 5.4265

Epoch 174: val_loss did not improve from 5.32885
196/196 - 82s - loss: 5.3337 - MinusLogProbMetric: 5.3337 - val_loss: 5.4265 - val_MinusLogProbMetric: 5.4265 - lr: 3.3333e-04 - 82s/epoch - 421ms/step
Epoch 175/1000
2023-09-19 17:28:11.088 
Epoch 175/1000 
	 loss: 5.3482, MinusLogProbMetric: 5.3482, val_loss: 5.4242, val_MinusLogProbMetric: 5.4242

Epoch 175: val_loss did not improve from 5.32885
196/196 - 83s - loss: 5.3482 - MinusLogProbMetric: 5.3482 - val_loss: 5.4242 - val_MinusLogProbMetric: 5.4242 - lr: 3.3333e-04 - 83s/epoch - 423ms/step
Epoch 176/1000
2023-09-19 17:29:33.914 
Epoch 176/1000 
	 loss: 5.3332, MinusLogProbMetric: 5.3332, val_loss: 5.3437, val_MinusLogProbMetric: 5.3437

Epoch 176: val_loss did not improve from 5.32885
196/196 - 83s - loss: 5.3332 - MinusLogProbMetric: 5.3332 - val_loss: 5.3437 - val_MinusLogProbMetric: 5.3437 - lr: 3.3333e-04 - 83s/epoch - 423ms/step
Epoch 177/1000
2023-09-19 17:30:56.810 
Epoch 177/1000 
	 loss: 5.3343, MinusLogProbMetric: 5.3343, val_loss: 5.3416, val_MinusLogProbMetric: 5.3416

Epoch 177: val_loss did not improve from 5.32885
196/196 - 83s - loss: 5.3343 - MinusLogProbMetric: 5.3343 - val_loss: 5.3416 - val_MinusLogProbMetric: 5.3416 - lr: 3.3333e-04 - 83s/epoch - 423ms/step
Epoch 178/1000
2023-09-19 17:32:19.153 
Epoch 178/1000 
	 loss: 5.3443, MinusLogProbMetric: 5.3443, val_loss: 5.4265, val_MinusLogProbMetric: 5.4265

Epoch 178: val_loss did not improve from 5.32885
196/196 - 82s - loss: 5.3443 - MinusLogProbMetric: 5.3443 - val_loss: 5.4265 - val_MinusLogProbMetric: 5.4265 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 179/1000
2023-09-19 17:33:40.597 
Epoch 179/1000 
	 loss: 5.3031, MinusLogProbMetric: 5.3031, val_loss: 5.3567, val_MinusLogProbMetric: 5.3567

Epoch 179: val_loss did not improve from 5.32885
196/196 - 81s - loss: 5.3031 - MinusLogProbMetric: 5.3031 - val_loss: 5.3567 - val_MinusLogProbMetric: 5.3567 - lr: 3.3333e-04 - 81s/epoch - 416ms/step
Epoch 180/1000
2023-09-19 17:35:03.010 
Epoch 180/1000 
	 loss: 5.3454, MinusLogProbMetric: 5.3454, val_loss: 5.3981, val_MinusLogProbMetric: 5.3981

Epoch 180: val_loss did not improve from 5.32885
196/196 - 82s - loss: 5.3454 - MinusLogProbMetric: 5.3454 - val_loss: 5.3981 - val_MinusLogProbMetric: 5.3981 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 181/1000
2023-09-19 17:36:24.721 
Epoch 181/1000 
	 loss: 5.3525, MinusLogProbMetric: 5.3525, val_loss: 5.4750, val_MinusLogProbMetric: 5.4750

Epoch 181: val_loss did not improve from 5.32885
196/196 - 82s - loss: 5.3525 - MinusLogProbMetric: 5.3525 - val_loss: 5.4750 - val_MinusLogProbMetric: 5.4750 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 182/1000
2023-09-19 17:37:46.450 
Epoch 182/1000 
	 loss: 5.3286, MinusLogProbMetric: 5.3286, val_loss: 5.3416, val_MinusLogProbMetric: 5.3416

Epoch 182: val_loss did not improve from 5.32885
196/196 - 82s - loss: 5.3286 - MinusLogProbMetric: 5.3286 - val_loss: 5.3416 - val_MinusLogProbMetric: 5.3416 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 183/1000
2023-09-19 17:39:08.326 
Epoch 183/1000 
	 loss: 5.3210, MinusLogProbMetric: 5.3210, val_loss: 5.3559, val_MinusLogProbMetric: 5.3559

Epoch 183: val_loss did not improve from 5.32885
196/196 - 82s - loss: 5.3210 - MinusLogProbMetric: 5.3210 - val_loss: 5.3559 - val_MinusLogProbMetric: 5.3559 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 184/1000
2023-09-19 17:40:29.995 
Epoch 184/1000 
	 loss: 5.3351, MinusLogProbMetric: 5.3351, val_loss: 5.4264, val_MinusLogProbMetric: 5.4264

Epoch 184: val_loss did not improve from 5.32885
196/196 - 82s - loss: 5.3351 - MinusLogProbMetric: 5.3351 - val_loss: 5.4264 - val_MinusLogProbMetric: 5.4264 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 185/1000
2023-09-19 17:41:51.839 
Epoch 185/1000 
	 loss: 5.3505, MinusLogProbMetric: 5.3505, val_loss: 5.3984, val_MinusLogProbMetric: 5.3984

Epoch 185: val_loss did not improve from 5.32885
196/196 - 82s - loss: 5.3505 - MinusLogProbMetric: 5.3505 - val_loss: 5.3984 - val_MinusLogProbMetric: 5.3984 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 186/1000
2023-09-19 17:43:13.569 
Epoch 186/1000 
	 loss: 5.3249, MinusLogProbMetric: 5.3249, val_loss: 5.4105, val_MinusLogProbMetric: 5.4105

Epoch 186: val_loss did not improve from 5.32885
196/196 - 82s - loss: 5.3249 - MinusLogProbMetric: 5.3249 - val_loss: 5.4105 - val_MinusLogProbMetric: 5.4105 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 187/1000
2023-09-19 17:44:35.291 
Epoch 187/1000 
	 loss: 5.3157, MinusLogProbMetric: 5.3157, val_loss: 5.2967, val_MinusLogProbMetric: 5.2967

Epoch 187: val_loss improved from 5.32885 to 5.29671, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 5.3157 - MinusLogProbMetric: 5.3157 - val_loss: 5.2967 - val_MinusLogProbMetric: 5.2967 - lr: 3.3333e-04 - 83s/epoch - 425ms/step
Epoch 188/1000
2023-09-19 17:45:58.810 
Epoch 188/1000 
	 loss: 5.3269, MinusLogProbMetric: 5.3269, val_loss: 5.3366, val_MinusLogProbMetric: 5.3366

Epoch 188: val_loss did not improve from 5.29671
196/196 - 82s - loss: 5.3269 - MinusLogProbMetric: 5.3269 - val_loss: 5.3366 - val_MinusLogProbMetric: 5.3366 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 189/1000
2023-09-19 17:47:20.677 
Epoch 189/1000 
	 loss: 5.3256, MinusLogProbMetric: 5.3256, val_loss: 5.4449, val_MinusLogProbMetric: 5.4449

Epoch 189: val_loss did not improve from 5.29671
196/196 - 82s - loss: 5.3256 - MinusLogProbMetric: 5.3256 - val_loss: 5.4449 - val_MinusLogProbMetric: 5.4449 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 190/1000
2023-09-19 17:48:38.876 
Epoch 190/1000 
	 loss: 5.3275, MinusLogProbMetric: 5.3275, val_loss: 5.3732, val_MinusLogProbMetric: 5.3732

Epoch 190: val_loss did not improve from 5.29671
196/196 - 78s - loss: 5.3275 - MinusLogProbMetric: 5.3275 - val_loss: 5.3732 - val_MinusLogProbMetric: 5.3732 - lr: 3.3333e-04 - 78s/epoch - 399ms/step
Epoch 191/1000
2023-09-19 17:49:45.402 
Epoch 191/1000 
	 loss: 5.3138, MinusLogProbMetric: 5.3138, val_loss: 5.4497, val_MinusLogProbMetric: 5.4497

Epoch 191: val_loss did not improve from 5.29671
196/196 - 67s - loss: 5.3138 - MinusLogProbMetric: 5.3138 - val_loss: 5.4497 - val_MinusLogProbMetric: 5.4497 - lr: 3.3333e-04 - 67s/epoch - 339ms/step
Epoch 192/1000
2023-09-19 17:50:57.430 
Epoch 192/1000 
	 loss: 5.3094, MinusLogProbMetric: 5.3094, val_loss: 5.5869, val_MinusLogProbMetric: 5.5869

Epoch 192: val_loss did not improve from 5.29671
196/196 - 72s - loss: 5.3094 - MinusLogProbMetric: 5.3094 - val_loss: 5.5869 - val_MinusLogProbMetric: 5.5869 - lr: 3.3333e-04 - 72s/epoch - 367ms/step
Epoch 193/1000
2023-09-19 17:52:11.268 
Epoch 193/1000 
	 loss: 5.3124, MinusLogProbMetric: 5.3124, val_loss: 5.4158, val_MinusLogProbMetric: 5.4158

Epoch 193: val_loss did not improve from 5.29671
196/196 - 74s - loss: 5.3124 - MinusLogProbMetric: 5.3124 - val_loss: 5.4158 - val_MinusLogProbMetric: 5.4158 - lr: 3.3333e-04 - 74s/epoch - 377ms/step
Epoch 194/1000
2023-09-19 17:53:31.325 
Epoch 194/1000 
	 loss: 5.3176, MinusLogProbMetric: 5.3176, val_loss: 5.3821, val_MinusLogProbMetric: 5.3821

Epoch 194: val_loss did not improve from 5.29671
196/196 - 80s - loss: 5.3176 - MinusLogProbMetric: 5.3176 - val_loss: 5.3821 - val_MinusLogProbMetric: 5.3821 - lr: 3.3333e-04 - 80s/epoch - 408ms/step
Epoch 195/1000
2023-09-19 17:54:53.046 
Epoch 195/1000 
	 loss: 5.3212, MinusLogProbMetric: 5.3212, val_loss: 5.4044, val_MinusLogProbMetric: 5.4044

Epoch 195: val_loss did not improve from 5.29671
196/196 - 82s - loss: 5.3212 - MinusLogProbMetric: 5.3212 - val_loss: 5.4044 - val_MinusLogProbMetric: 5.4044 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 196/1000
2023-09-19 17:56:14.179 
Epoch 196/1000 
	 loss: 5.3368, MinusLogProbMetric: 5.3368, val_loss: 5.3723, val_MinusLogProbMetric: 5.3723

Epoch 196: val_loss did not improve from 5.29671
196/196 - 81s - loss: 5.3368 - MinusLogProbMetric: 5.3368 - val_loss: 5.3723 - val_MinusLogProbMetric: 5.3723 - lr: 3.3333e-04 - 81s/epoch - 414ms/step
Epoch 197/1000
2023-09-19 17:57:36.496 
Epoch 197/1000 
	 loss: 5.3171, MinusLogProbMetric: 5.3171, val_loss: 5.3516, val_MinusLogProbMetric: 5.3516

Epoch 197: val_loss did not improve from 5.29671
196/196 - 82s - loss: 5.3171 - MinusLogProbMetric: 5.3171 - val_loss: 5.3516 - val_MinusLogProbMetric: 5.3516 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 198/1000
2023-09-19 17:58:57.946 
Epoch 198/1000 
	 loss: 5.2882, MinusLogProbMetric: 5.2882, val_loss: 5.3731, val_MinusLogProbMetric: 5.3731

Epoch 198: val_loss did not improve from 5.29671
196/196 - 81s - loss: 5.2882 - MinusLogProbMetric: 5.2882 - val_loss: 5.3731 - val_MinusLogProbMetric: 5.3731 - lr: 3.3333e-04 - 81s/epoch - 416ms/step
Epoch 199/1000
2023-09-19 18:00:20.214 
Epoch 199/1000 
	 loss: 5.3198, MinusLogProbMetric: 5.3198, val_loss: 5.4603, val_MinusLogProbMetric: 5.4603

Epoch 199: val_loss did not improve from 5.29671
196/196 - 82s - loss: 5.3198 - MinusLogProbMetric: 5.3198 - val_loss: 5.4603 - val_MinusLogProbMetric: 5.4603 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 200/1000
2023-09-19 18:01:42.533 
Epoch 200/1000 
	 loss: 5.3046, MinusLogProbMetric: 5.3046, val_loss: 5.4019, val_MinusLogProbMetric: 5.4019

Epoch 200: val_loss did not improve from 5.29671
196/196 - 82s - loss: 5.3046 - MinusLogProbMetric: 5.3046 - val_loss: 5.4019 - val_MinusLogProbMetric: 5.4019 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 201/1000
2023-09-19 18:03:04.180 
Epoch 201/1000 
	 loss: 5.3210, MinusLogProbMetric: 5.3210, val_loss: 5.4377, val_MinusLogProbMetric: 5.4377

Epoch 201: val_loss did not improve from 5.29671
196/196 - 82s - loss: 5.3210 - MinusLogProbMetric: 5.3210 - val_loss: 5.4377 - val_MinusLogProbMetric: 5.4377 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 202/1000
2023-09-19 18:04:26.582 
Epoch 202/1000 
	 loss: 5.3244, MinusLogProbMetric: 5.3244, val_loss: 5.4083, val_MinusLogProbMetric: 5.4083

Epoch 202: val_loss did not improve from 5.29671
196/196 - 82s - loss: 5.3244 - MinusLogProbMetric: 5.3244 - val_loss: 5.4083 - val_MinusLogProbMetric: 5.4083 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 203/1000
2023-09-19 18:05:49.545 
Epoch 203/1000 
	 loss: 5.3205, MinusLogProbMetric: 5.3205, val_loss: 5.3785, val_MinusLogProbMetric: 5.3785

Epoch 203: val_loss did not improve from 5.29671
196/196 - 83s - loss: 5.3205 - MinusLogProbMetric: 5.3205 - val_loss: 5.3785 - val_MinusLogProbMetric: 5.3785 - lr: 3.3333e-04 - 83s/epoch - 423ms/step
Epoch 204/1000
2023-09-19 18:07:11.695 
Epoch 204/1000 
	 loss: 5.3180, MinusLogProbMetric: 5.3180, val_loss: 5.3779, val_MinusLogProbMetric: 5.3779

Epoch 204: val_loss did not improve from 5.29671
196/196 - 82s - loss: 5.3180 - MinusLogProbMetric: 5.3180 - val_loss: 5.3779 - val_MinusLogProbMetric: 5.3779 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 205/1000
2023-09-19 18:08:34.140 
Epoch 205/1000 
	 loss: 5.3008, MinusLogProbMetric: 5.3008, val_loss: 5.6311, val_MinusLogProbMetric: 5.6311

Epoch 205: val_loss did not improve from 5.29671
196/196 - 82s - loss: 5.3008 - MinusLogProbMetric: 5.3008 - val_loss: 5.6311 - val_MinusLogProbMetric: 5.6311 - lr: 3.3333e-04 - 82s/epoch - 421ms/step
Epoch 206/1000
2023-09-19 18:09:56.413 
Epoch 206/1000 
	 loss: 5.3089, MinusLogProbMetric: 5.3089, val_loss: 5.2984, val_MinusLogProbMetric: 5.2984

Epoch 206: val_loss did not improve from 5.29671
196/196 - 82s - loss: 5.3089 - MinusLogProbMetric: 5.3089 - val_loss: 5.2984 - val_MinusLogProbMetric: 5.2984 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 207/1000
2023-09-19 18:11:19.063 
Epoch 207/1000 
	 loss: 5.2785, MinusLogProbMetric: 5.2785, val_loss: 5.4299, val_MinusLogProbMetric: 5.4299

Epoch 207: val_loss did not improve from 5.29671
196/196 - 83s - loss: 5.2785 - MinusLogProbMetric: 5.2785 - val_loss: 5.4299 - val_MinusLogProbMetric: 5.4299 - lr: 3.3333e-04 - 83s/epoch - 422ms/step
Epoch 208/1000
2023-09-19 18:12:40.800 
Epoch 208/1000 
	 loss: 5.3208, MinusLogProbMetric: 5.3208, val_loss: 5.3724, val_MinusLogProbMetric: 5.3724

Epoch 208: val_loss did not improve from 5.29671
196/196 - 82s - loss: 5.3208 - MinusLogProbMetric: 5.3208 - val_loss: 5.3724 - val_MinusLogProbMetric: 5.3724 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 209/1000
2023-09-19 18:14:02.642 
Epoch 209/1000 
	 loss: 5.3063, MinusLogProbMetric: 5.3063, val_loss: 5.4861, val_MinusLogProbMetric: 5.4861

Epoch 209: val_loss did not improve from 5.29671
196/196 - 82s - loss: 5.3063 - MinusLogProbMetric: 5.3063 - val_loss: 5.4861 - val_MinusLogProbMetric: 5.4861 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 210/1000
2023-09-19 18:15:24.022 
Epoch 210/1000 
	 loss: 5.3123, MinusLogProbMetric: 5.3123, val_loss: 5.4100, val_MinusLogProbMetric: 5.4100

Epoch 210: val_loss did not improve from 5.29671
196/196 - 81s - loss: 5.3123 - MinusLogProbMetric: 5.3123 - val_loss: 5.4100 - val_MinusLogProbMetric: 5.4100 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 211/1000
2023-09-19 18:16:45.267 
Epoch 211/1000 
	 loss: 5.3015, MinusLogProbMetric: 5.3015, val_loss: 5.3678, val_MinusLogProbMetric: 5.3678

Epoch 211: val_loss did not improve from 5.29671
196/196 - 81s - loss: 5.3015 - MinusLogProbMetric: 5.3015 - val_loss: 5.3678 - val_MinusLogProbMetric: 5.3678 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 212/1000
2023-09-19 18:18:07.705 
Epoch 212/1000 
	 loss: 5.2892, MinusLogProbMetric: 5.2892, val_loss: 5.3731, val_MinusLogProbMetric: 5.3731

Epoch 212: val_loss did not improve from 5.29671
196/196 - 82s - loss: 5.2892 - MinusLogProbMetric: 5.2892 - val_loss: 5.3731 - val_MinusLogProbMetric: 5.3731 - lr: 3.3333e-04 - 82s/epoch - 421ms/step
Epoch 213/1000
2023-09-19 18:19:28.393 
Epoch 213/1000 
	 loss: 5.3107, MinusLogProbMetric: 5.3107, val_loss: 5.3661, val_MinusLogProbMetric: 5.3661

Epoch 213: val_loss did not improve from 5.29671
196/196 - 81s - loss: 5.3107 - MinusLogProbMetric: 5.3107 - val_loss: 5.3661 - val_MinusLogProbMetric: 5.3661 - lr: 3.3333e-04 - 81s/epoch - 412ms/step
Epoch 214/1000
2023-09-19 18:20:45.835 
Epoch 214/1000 
	 loss: 5.2936, MinusLogProbMetric: 5.2936, val_loss: 5.2866, val_MinusLogProbMetric: 5.2866

Epoch 214: val_loss improved from 5.29671 to 5.28660, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 79s - loss: 5.2936 - MinusLogProbMetric: 5.2936 - val_loss: 5.2866 - val_MinusLogProbMetric: 5.2866 - lr: 3.3333e-04 - 79s/epoch - 401ms/step
Epoch 215/1000
2023-09-19 18:21:57.114 
Epoch 215/1000 
	 loss: 5.2812, MinusLogProbMetric: 5.2812, val_loss: 5.3620, val_MinusLogProbMetric: 5.3620

Epoch 215: val_loss did not improve from 5.28660
196/196 - 70s - loss: 5.2812 - MinusLogProbMetric: 5.2812 - val_loss: 5.3620 - val_MinusLogProbMetric: 5.3620 - lr: 3.3333e-04 - 70s/epoch - 357ms/step
Epoch 216/1000
2023-09-19 18:23:12.734 
Epoch 216/1000 
	 loss: 5.3024, MinusLogProbMetric: 5.3024, val_loss: 5.4445, val_MinusLogProbMetric: 5.4445

Epoch 216: val_loss did not improve from 5.28660
196/196 - 76s - loss: 5.3024 - MinusLogProbMetric: 5.3024 - val_loss: 5.4445 - val_MinusLogProbMetric: 5.4445 - lr: 3.3333e-04 - 76s/epoch - 386ms/step
Epoch 217/1000
2023-09-19 18:24:34.371 
Epoch 217/1000 
	 loss: 5.2988, MinusLogProbMetric: 5.2988, val_loss: 5.3884, val_MinusLogProbMetric: 5.3884

Epoch 217: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2988 - MinusLogProbMetric: 5.2988 - val_loss: 5.3884 - val_MinusLogProbMetric: 5.3884 - lr: 3.3333e-04 - 82s/epoch - 416ms/step
Epoch 218/1000
2023-09-19 18:25:57.071 
Epoch 218/1000 
	 loss: 5.3001, MinusLogProbMetric: 5.3001, val_loss: 5.3488, val_MinusLogProbMetric: 5.3488

Epoch 218: val_loss did not improve from 5.28660
196/196 - 83s - loss: 5.3001 - MinusLogProbMetric: 5.3001 - val_loss: 5.3488 - val_MinusLogProbMetric: 5.3488 - lr: 3.3333e-04 - 83s/epoch - 422ms/step
Epoch 219/1000
2023-09-19 18:27:19.433 
Epoch 219/1000 
	 loss: 5.2697, MinusLogProbMetric: 5.2697, val_loss: 5.3651, val_MinusLogProbMetric: 5.3651

Epoch 219: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2697 - MinusLogProbMetric: 5.2697 - val_loss: 5.3651 - val_MinusLogProbMetric: 5.3651 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 220/1000
2023-09-19 18:28:41.511 
Epoch 220/1000 
	 loss: 5.2980, MinusLogProbMetric: 5.2980, val_loss: 5.4065, val_MinusLogProbMetric: 5.4065

Epoch 220: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2980 - MinusLogProbMetric: 5.2980 - val_loss: 5.4065 - val_MinusLogProbMetric: 5.4065 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 221/1000
2023-09-19 18:30:04.386 
Epoch 221/1000 
	 loss: 5.2928, MinusLogProbMetric: 5.2928, val_loss: 5.3930, val_MinusLogProbMetric: 5.3930

Epoch 221: val_loss did not improve from 5.28660
196/196 - 83s - loss: 5.2928 - MinusLogProbMetric: 5.2928 - val_loss: 5.3930 - val_MinusLogProbMetric: 5.3930 - lr: 3.3333e-04 - 83s/epoch - 423ms/step
Epoch 222/1000
2023-09-19 18:31:26.648 
Epoch 222/1000 
	 loss: 5.2978, MinusLogProbMetric: 5.2978, val_loss: 5.2983, val_MinusLogProbMetric: 5.2983

Epoch 222: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2978 - MinusLogProbMetric: 5.2978 - val_loss: 5.2983 - val_MinusLogProbMetric: 5.2983 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 223/1000
2023-09-19 18:32:48.268 
Epoch 223/1000 
	 loss: 5.2874, MinusLogProbMetric: 5.2874, val_loss: 5.3180, val_MinusLogProbMetric: 5.3180

Epoch 223: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2874 - MinusLogProbMetric: 5.2874 - val_loss: 5.3180 - val_MinusLogProbMetric: 5.3180 - lr: 3.3333e-04 - 82s/epoch - 416ms/step
Epoch 224/1000
2023-09-19 18:34:09.548 
Epoch 224/1000 
	 loss: 5.2854, MinusLogProbMetric: 5.2854, val_loss: 5.4398, val_MinusLogProbMetric: 5.4398

Epoch 224: val_loss did not improve from 5.28660
196/196 - 81s - loss: 5.2854 - MinusLogProbMetric: 5.2854 - val_loss: 5.4398 - val_MinusLogProbMetric: 5.4398 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 225/1000
2023-09-19 18:35:30.935 
Epoch 225/1000 
	 loss: 5.2816, MinusLogProbMetric: 5.2816, val_loss: 5.3045, val_MinusLogProbMetric: 5.3045

Epoch 225: val_loss did not improve from 5.28660
196/196 - 81s - loss: 5.2816 - MinusLogProbMetric: 5.2816 - val_loss: 5.3045 - val_MinusLogProbMetric: 5.3045 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 226/1000
2023-09-19 18:36:52.314 
Epoch 226/1000 
	 loss: 5.2907, MinusLogProbMetric: 5.2907, val_loss: 5.4014, val_MinusLogProbMetric: 5.4014

Epoch 226: val_loss did not improve from 5.28660
196/196 - 81s - loss: 5.2907 - MinusLogProbMetric: 5.2907 - val_loss: 5.4014 - val_MinusLogProbMetric: 5.4014 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 227/1000
2023-09-19 18:38:14.049 
Epoch 227/1000 
	 loss: 5.3050, MinusLogProbMetric: 5.3050, val_loss: 5.3616, val_MinusLogProbMetric: 5.3616

Epoch 227: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.3050 - MinusLogProbMetric: 5.3050 - val_loss: 5.3616 - val_MinusLogProbMetric: 5.3616 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 228/1000
2023-09-19 18:39:35.879 
Epoch 228/1000 
	 loss: 5.2837, MinusLogProbMetric: 5.2837, val_loss: 5.3673, val_MinusLogProbMetric: 5.3673

Epoch 228: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2837 - MinusLogProbMetric: 5.2837 - val_loss: 5.3673 - val_MinusLogProbMetric: 5.3673 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 229/1000
2023-09-19 18:40:57.476 
Epoch 229/1000 
	 loss: 5.2861, MinusLogProbMetric: 5.2861, val_loss: 5.6162, val_MinusLogProbMetric: 5.6162

Epoch 229: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2861 - MinusLogProbMetric: 5.2861 - val_loss: 5.6162 - val_MinusLogProbMetric: 5.6162 - lr: 3.3333e-04 - 82s/epoch - 416ms/step
Epoch 230/1000
2023-09-19 18:42:19.122 
Epoch 230/1000 
	 loss: 5.2912, MinusLogProbMetric: 5.2912, val_loss: 5.3816, val_MinusLogProbMetric: 5.3816

Epoch 230: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2912 - MinusLogProbMetric: 5.2912 - val_loss: 5.3816 - val_MinusLogProbMetric: 5.3816 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 231/1000
2023-09-19 18:43:41.102 
Epoch 231/1000 
	 loss: 5.2879, MinusLogProbMetric: 5.2879, val_loss: 5.3512, val_MinusLogProbMetric: 5.3512

Epoch 231: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2879 - MinusLogProbMetric: 5.2879 - val_loss: 5.3512 - val_MinusLogProbMetric: 5.3512 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 232/1000
2023-09-19 18:45:03.361 
Epoch 232/1000 
	 loss: 5.3018, MinusLogProbMetric: 5.3018, val_loss: 5.3722, val_MinusLogProbMetric: 5.3722

Epoch 232: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.3018 - MinusLogProbMetric: 5.3018 - val_loss: 5.3722 - val_MinusLogProbMetric: 5.3722 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 233/1000
2023-09-19 18:46:25.072 
Epoch 233/1000 
	 loss: 5.2692, MinusLogProbMetric: 5.2692, val_loss: 5.5221, val_MinusLogProbMetric: 5.5221

Epoch 233: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2692 - MinusLogProbMetric: 5.2692 - val_loss: 5.5221 - val_MinusLogProbMetric: 5.5221 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 234/1000
2023-09-19 18:47:46.903 
Epoch 234/1000 
	 loss: 5.2896, MinusLogProbMetric: 5.2896, val_loss: 5.3273, val_MinusLogProbMetric: 5.3273

Epoch 234: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2896 - MinusLogProbMetric: 5.2896 - val_loss: 5.3273 - val_MinusLogProbMetric: 5.3273 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 235/1000
2023-09-19 18:49:08.973 
Epoch 235/1000 
	 loss: 5.2868, MinusLogProbMetric: 5.2868, val_loss: 5.3619, val_MinusLogProbMetric: 5.3619

Epoch 235: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2868 - MinusLogProbMetric: 5.2868 - val_loss: 5.3619 - val_MinusLogProbMetric: 5.3619 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 236/1000
2023-09-19 18:50:31.452 
Epoch 236/1000 
	 loss: 5.2673, MinusLogProbMetric: 5.2673, val_loss: 5.4052, val_MinusLogProbMetric: 5.4052

Epoch 236: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2673 - MinusLogProbMetric: 5.2673 - val_loss: 5.4052 - val_MinusLogProbMetric: 5.4052 - lr: 3.3333e-04 - 82s/epoch - 421ms/step
Epoch 237/1000
2023-09-19 18:51:52.764 
Epoch 237/1000 
	 loss: 5.2918, MinusLogProbMetric: 5.2918, val_loss: 5.3279, val_MinusLogProbMetric: 5.3279

Epoch 237: val_loss did not improve from 5.28660
196/196 - 81s - loss: 5.2918 - MinusLogProbMetric: 5.2918 - val_loss: 5.3279 - val_MinusLogProbMetric: 5.3279 - lr: 3.3333e-04 - 81s/epoch - 415ms/step
Epoch 238/1000
2023-09-19 18:53:15.094 
Epoch 238/1000 
	 loss: 5.2944, MinusLogProbMetric: 5.2944, val_loss: 5.3435, val_MinusLogProbMetric: 5.3435

Epoch 238: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2944 - MinusLogProbMetric: 5.2944 - val_loss: 5.3435 - val_MinusLogProbMetric: 5.3435 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 239/1000
2023-09-19 18:54:36.551 
Epoch 239/1000 
	 loss: 5.2818, MinusLogProbMetric: 5.2818, val_loss: 5.4821, val_MinusLogProbMetric: 5.4821

Epoch 239: val_loss did not improve from 5.28660
196/196 - 81s - loss: 5.2818 - MinusLogProbMetric: 5.2818 - val_loss: 5.4821 - val_MinusLogProbMetric: 5.4821 - lr: 3.3333e-04 - 81s/epoch - 416ms/step
Epoch 240/1000
2023-09-19 18:55:58.681 
Epoch 240/1000 
	 loss: 5.2814, MinusLogProbMetric: 5.2814, val_loss: 5.4338, val_MinusLogProbMetric: 5.4338

Epoch 240: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2814 - MinusLogProbMetric: 5.2814 - val_loss: 5.4338 - val_MinusLogProbMetric: 5.4338 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 241/1000
2023-09-19 18:57:19.685 
Epoch 241/1000 
	 loss: 5.2745, MinusLogProbMetric: 5.2745, val_loss: 5.4861, val_MinusLogProbMetric: 5.4861

Epoch 241: val_loss did not improve from 5.28660
196/196 - 81s - loss: 5.2745 - MinusLogProbMetric: 5.2745 - val_loss: 5.4861 - val_MinusLogProbMetric: 5.4861 - lr: 3.3333e-04 - 81s/epoch - 413ms/step
Epoch 242/1000
2023-09-19 18:58:41.862 
Epoch 242/1000 
	 loss: 5.3232, MinusLogProbMetric: 5.3232, val_loss: 5.5750, val_MinusLogProbMetric: 5.5750

Epoch 242: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.3232 - MinusLogProbMetric: 5.3232 - val_loss: 5.5750 - val_MinusLogProbMetric: 5.5750 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 243/1000
2023-09-19 19:00:03.625 
Epoch 243/1000 
	 loss: 5.2821, MinusLogProbMetric: 5.2821, val_loss: 5.3320, val_MinusLogProbMetric: 5.3320

Epoch 243: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2821 - MinusLogProbMetric: 5.2821 - val_loss: 5.3320 - val_MinusLogProbMetric: 5.3320 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 244/1000
2023-09-19 19:01:25.283 
Epoch 244/1000 
	 loss: 5.2647, MinusLogProbMetric: 5.2647, val_loss: 5.3234, val_MinusLogProbMetric: 5.3234

Epoch 244: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2647 - MinusLogProbMetric: 5.2647 - val_loss: 5.3234 - val_MinusLogProbMetric: 5.3234 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 245/1000
2023-09-19 19:02:47.028 
Epoch 245/1000 
	 loss: 5.2773, MinusLogProbMetric: 5.2773, val_loss: 5.3292, val_MinusLogProbMetric: 5.3292

Epoch 245: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2773 - MinusLogProbMetric: 5.2773 - val_loss: 5.3292 - val_MinusLogProbMetric: 5.3292 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 246/1000
2023-09-19 19:04:08.758 
Epoch 246/1000 
	 loss: 5.2658, MinusLogProbMetric: 5.2658, val_loss: 5.4366, val_MinusLogProbMetric: 5.4366

Epoch 246: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2658 - MinusLogProbMetric: 5.2658 - val_loss: 5.4366 - val_MinusLogProbMetric: 5.4366 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 247/1000
2023-09-19 19:05:30.543 
Epoch 247/1000 
	 loss: 5.2800, MinusLogProbMetric: 5.2800, val_loss: 5.4577, val_MinusLogProbMetric: 5.4577

Epoch 247: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2800 - MinusLogProbMetric: 5.2800 - val_loss: 5.4577 - val_MinusLogProbMetric: 5.4577 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 248/1000
2023-09-19 19:06:51.730 
Epoch 248/1000 
	 loss: 5.2795, MinusLogProbMetric: 5.2795, val_loss: 5.3833, val_MinusLogProbMetric: 5.3833

Epoch 248: val_loss did not improve from 5.28660
196/196 - 81s - loss: 5.2795 - MinusLogProbMetric: 5.2795 - val_loss: 5.3833 - val_MinusLogProbMetric: 5.3833 - lr: 3.3333e-04 - 81s/epoch - 414ms/step
Epoch 249/1000
2023-09-19 19:08:13.958 
Epoch 249/1000 
	 loss: 5.2642, MinusLogProbMetric: 5.2642, val_loss: 5.3404, val_MinusLogProbMetric: 5.3404

Epoch 249: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2642 - MinusLogProbMetric: 5.2642 - val_loss: 5.3404 - val_MinusLogProbMetric: 5.3404 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 250/1000
2023-09-19 19:09:36.500 
Epoch 250/1000 
	 loss: 5.2533, MinusLogProbMetric: 5.2533, val_loss: 5.3462, val_MinusLogProbMetric: 5.3462

Epoch 250: val_loss did not improve from 5.28660
196/196 - 83s - loss: 5.2533 - MinusLogProbMetric: 5.2533 - val_loss: 5.3462 - val_MinusLogProbMetric: 5.3462 - lr: 3.3333e-04 - 83s/epoch - 421ms/step
Epoch 251/1000
2023-09-19 19:10:58.392 
Epoch 251/1000 
	 loss: 5.2674, MinusLogProbMetric: 5.2674, val_loss: 5.3432, val_MinusLogProbMetric: 5.3432

Epoch 251: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2674 - MinusLogProbMetric: 5.2674 - val_loss: 5.3432 - val_MinusLogProbMetric: 5.3432 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 252/1000
2023-09-19 19:12:20.495 
Epoch 252/1000 
	 loss: 5.2701, MinusLogProbMetric: 5.2701, val_loss: 5.3335, val_MinusLogProbMetric: 5.3335

Epoch 252: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2701 - MinusLogProbMetric: 5.2701 - val_loss: 5.3335 - val_MinusLogProbMetric: 5.3335 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 253/1000
2023-09-19 19:13:42.209 
Epoch 253/1000 
	 loss: 5.2706, MinusLogProbMetric: 5.2706, val_loss: 5.3221, val_MinusLogProbMetric: 5.3221

Epoch 253: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2706 - MinusLogProbMetric: 5.2706 - val_loss: 5.3221 - val_MinusLogProbMetric: 5.3221 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 254/1000
2023-09-19 19:15:04.091 
Epoch 254/1000 
	 loss: 5.2576, MinusLogProbMetric: 5.2576, val_loss: 5.3491, val_MinusLogProbMetric: 5.3491

Epoch 254: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2576 - MinusLogProbMetric: 5.2576 - val_loss: 5.3491 - val_MinusLogProbMetric: 5.3491 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 255/1000
2023-09-19 19:16:26.106 
Epoch 255/1000 
	 loss: 5.2688, MinusLogProbMetric: 5.2688, val_loss: 5.4800, val_MinusLogProbMetric: 5.4800

Epoch 255: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2688 - MinusLogProbMetric: 5.2688 - val_loss: 5.4800 - val_MinusLogProbMetric: 5.4800 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 256/1000
2023-09-19 19:17:48.190 
Epoch 256/1000 
	 loss: 5.2714, MinusLogProbMetric: 5.2714, val_loss: 5.3312, val_MinusLogProbMetric: 5.3312

Epoch 256: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2714 - MinusLogProbMetric: 5.2714 - val_loss: 5.3312 - val_MinusLogProbMetric: 5.3312 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 257/1000
2023-09-19 19:19:10.195 
Epoch 257/1000 
	 loss: 5.2635, MinusLogProbMetric: 5.2635, val_loss: 5.3512, val_MinusLogProbMetric: 5.3512

Epoch 257: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2635 - MinusLogProbMetric: 5.2635 - val_loss: 5.3512 - val_MinusLogProbMetric: 5.3512 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 258/1000
2023-09-19 19:20:32.614 
Epoch 258/1000 
	 loss: 5.2776, MinusLogProbMetric: 5.2776, val_loss: 5.4799, val_MinusLogProbMetric: 5.4799

Epoch 258: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2776 - MinusLogProbMetric: 5.2776 - val_loss: 5.4799 - val_MinusLogProbMetric: 5.4799 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 259/1000
2023-09-19 19:21:54.444 
Epoch 259/1000 
	 loss: 5.2695, MinusLogProbMetric: 5.2695, val_loss: 5.3251, val_MinusLogProbMetric: 5.3251

Epoch 259: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2695 - MinusLogProbMetric: 5.2695 - val_loss: 5.3251 - val_MinusLogProbMetric: 5.3251 - lr: 3.3333e-04 - 82s/epoch - 417ms/step
Epoch 260/1000
2023-09-19 19:23:16.808 
Epoch 260/1000 
	 loss: 5.2700, MinusLogProbMetric: 5.2700, val_loss: 5.5020, val_MinusLogProbMetric: 5.5020

Epoch 260: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2700 - MinusLogProbMetric: 5.2700 - val_loss: 5.5020 - val_MinusLogProbMetric: 5.5020 - lr: 3.3333e-04 - 82s/epoch - 420ms/step
Epoch 261/1000
2023-09-19 19:24:38.765 
Epoch 261/1000 
	 loss: 5.2708, MinusLogProbMetric: 5.2708, val_loss: 5.4337, val_MinusLogProbMetric: 5.4337

Epoch 261: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2708 - MinusLogProbMetric: 5.2708 - val_loss: 5.4337 - val_MinusLogProbMetric: 5.4337 - lr: 3.3333e-04 - 82s/epoch - 418ms/step
Epoch 262/1000
2023-09-19 19:25:53.027 
Epoch 262/1000 
	 loss: 5.2707, MinusLogProbMetric: 5.2707, val_loss: 5.3131, val_MinusLogProbMetric: 5.3131

Epoch 262: val_loss did not improve from 5.28660
196/196 - 74s - loss: 5.2707 - MinusLogProbMetric: 5.2707 - val_loss: 5.3131 - val_MinusLogProbMetric: 5.3131 - lr: 3.3333e-04 - 74s/epoch - 379ms/step
Epoch 263/1000
2023-09-19 19:27:05.026 
Epoch 263/1000 
	 loss: 5.2521, MinusLogProbMetric: 5.2521, val_loss: 5.4231, val_MinusLogProbMetric: 5.4231

Epoch 263: val_loss did not improve from 5.28660
196/196 - 72s - loss: 5.2521 - MinusLogProbMetric: 5.2521 - val_loss: 5.4231 - val_MinusLogProbMetric: 5.4231 - lr: 3.3333e-04 - 72s/epoch - 367ms/step
Epoch 264/1000
2023-09-19 19:28:26.559 
Epoch 264/1000 
	 loss: 5.2617, MinusLogProbMetric: 5.2617, val_loss: 5.4426, val_MinusLogProbMetric: 5.4426

Epoch 264: val_loss did not improve from 5.28660
196/196 - 82s - loss: 5.2617 - MinusLogProbMetric: 5.2617 - val_loss: 5.4426 - val_MinusLogProbMetric: 5.4426 - lr: 3.3333e-04 - 82s/epoch - 416ms/step
Epoch 265/1000
2023-09-19 19:29:49.286 
Epoch 265/1000 
	 loss: 5.1748, MinusLogProbMetric: 5.1748, val_loss: 5.2807, val_MinusLogProbMetric: 5.2807

Epoch 265: val_loss improved from 5.28660 to 5.28073, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 84s - loss: 5.1748 - MinusLogProbMetric: 5.1748 - val_loss: 5.2807 - val_MinusLogProbMetric: 5.2807 - lr: 1.6667e-04 - 84s/epoch - 430ms/step
Epoch 266/1000
2023-09-19 19:31:14.027 
Epoch 266/1000 
	 loss: 5.1723, MinusLogProbMetric: 5.1723, val_loss: 5.2428, val_MinusLogProbMetric: 5.2428

Epoch 266: val_loss improved from 5.28073 to 5.24279, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 85s - loss: 5.1723 - MinusLogProbMetric: 5.1723 - val_loss: 5.2428 - val_MinusLogProbMetric: 5.2428 - lr: 1.6667e-04 - 85s/epoch - 435ms/step
Epoch 267/1000
2023-09-19 19:32:38.252 
Epoch 267/1000 
	 loss: 5.1728, MinusLogProbMetric: 5.1728, val_loss: 5.3068, val_MinusLogProbMetric: 5.3068

Epoch 267: val_loss did not improve from 5.24279
196/196 - 82s - loss: 5.1728 - MinusLogProbMetric: 5.1728 - val_loss: 5.3068 - val_MinusLogProbMetric: 5.3068 - lr: 1.6667e-04 - 82s/epoch - 420ms/step
Epoch 268/1000
2023-09-19 19:34:00.547 
Epoch 268/1000 
	 loss: 5.1759, MinusLogProbMetric: 5.1759, val_loss: 5.2344, val_MinusLogProbMetric: 5.2344

Epoch 268: val_loss improved from 5.24279 to 5.23443, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 84s - loss: 5.1759 - MinusLogProbMetric: 5.1759 - val_loss: 5.2344 - val_MinusLogProbMetric: 5.2344 - lr: 1.6667e-04 - 84s/epoch - 428ms/step
Epoch 269/1000
2023-09-19 19:35:25.406 
Epoch 269/1000 
	 loss: 5.1758, MinusLogProbMetric: 5.1758, val_loss: 5.2594, val_MinusLogProbMetric: 5.2594

Epoch 269: val_loss did not improve from 5.23443
196/196 - 83s - loss: 5.1758 - MinusLogProbMetric: 5.1758 - val_loss: 5.2594 - val_MinusLogProbMetric: 5.2594 - lr: 1.6667e-04 - 83s/epoch - 425ms/step
Epoch 270/1000
2023-09-19 19:36:48.084 
Epoch 270/1000 
	 loss: 5.1665, MinusLogProbMetric: 5.1665, val_loss: 5.2626, val_MinusLogProbMetric: 5.2626

Epoch 270: val_loss did not improve from 5.23443
196/196 - 83s - loss: 5.1665 - MinusLogProbMetric: 5.1665 - val_loss: 5.2626 - val_MinusLogProbMetric: 5.2626 - lr: 1.6667e-04 - 83s/epoch - 422ms/step
Epoch 271/1000
2023-09-19 19:38:10.792 
Epoch 271/1000 
	 loss: 5.1717, MinusLogProbMetric: 5.1717, val_loss: 5.2322, val_MinusLogProbMetric: 5.2322

Epoch 271: val_loss improved from 5.23443 to 5.23224, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 84s - loss: 5.1717 - MinusLogProbMetric: 5.1717 - val_loss: 5.2322 - val_MinusLogProbMetric: 5.2322 - lr: 1.6667e-04 - 84s/epoch - 430ms/step
Epoch 272/1000
2023-09-19 19:39:35.574 
Epoch 272/1000 
	 loss: 5.1689, MinusLogProbMetric: 5.1689, val_loss: 5.2319, val_MinusLogProbMetric: 5.2319

Epoch 272: val_loss improved from 5.23224 to 5.23188, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 85s - loss: 5.1689 - MinusLogProbMetric: 5.1689 - val_loss: 5.2319 - val_MinusLogProbMetric: 5.2319 - lr: 1.6667e-04 - 85s/epoch - 432ms/step
Epoch 273/1000
2023-09-19 19:41:00.135 
Epoch 273/1000 
	 loss: 5.1788, MinusLogProbMetric: 5.1788, val_loss: 5.2807, val_MinusLogProbMetric: 5.2807

Epoch 273: val_loss did not improve from 5.23188
196/196 - 83s - loss: 5.1788 - MinusLogProbMetric: 5.1788 - val_loss: 5.2807 - val_MinusLogProbMetric: 5.2807 - lr: 1.6667e-04 - 83s/epoch - 423ms/step
Epoch 274/1000
2023-09-19 19:42:22.735 
Epoch 274/1000 
	 loss: 5.1849, MinusLogProbMetric: 5.1849, val_loss: 5.2735, val_MinusLogProbMetric: 5.2735

Epoch 274: val_loss did not improve from 5.23188
196/196 - 83s - loss: 5.1849 - MinusLogProbMetric: 5.1849 - val_loss: 5.2735 - val_MinusLogProbMetric: 5.2735 - lr: 1.6667e-04 - 83s/epoch - 421ms/step
Epoch 275/1000
2023-09-19 19:43:45.972 
Epoch 275/1000 
	 loss: 5.1767, MinusLogProbMetric: 5.1767, val_loss: 5.2695, val_MinusLogProbMetric: 5.2695

Epoch 275: val_loss did not improve from 5.23188
196/196 - 83s - loss: 5.1767 - MinusLogProbMetric: 5.1767 - val_loss: 5.2695 - val_MinusLogProbMetric: 5.2695 - lr: 1.6667e-04 - 83s/epoch - 425ms/step
Epoch 276/1000
2023-09-19 19:45:09.873 
Epoch 276/1000 
	 loss: 5.1837, MinusLogProbMetric: 5.1837, val_loss: 5.2265, val_MinusLogProbMetric: 5.2265

Epoch 276: val_loss improved from 5.23188 to 5.22647, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 86s - loss: 5.1837 - MinusLogProbMetric: 5.1837 - val_loss: 5.2265 - val_MinusLogProbMetric: 5.2265 - lr: 1.6667e-04 - 86s/epoch - 437ms/step
Epoch 277/1000
2023-09-19 19:46:34.255 
Epoch 277/1000 
	 loss: 5.1698, MinusLogProbMetric: 5.1698, val_loss: 5.2731, val_MinusLogProbMetric: 5.2731

Epoch 277: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1698 - MinusLogProbMetric: 5.1698 - val_loss: 5.2731 - val_MinusLogProbMetric: 5.2731 - lr: 1.6667e-04 - 83s/epoch - 422ms/step
Epoch 278/1000
2023-09-19 19:47:57.421 
Epoch 278/1000 
	 loss: 5.1699, MinusLogProbMetric: 5.1699, val_loss: 5.2688, val_MinusLogProbMetric: 5.2688

Epoch 278: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1699 - MinusLogProbMetric: 5.1699 - val_loss: 5.2688 - val_MinusLogProbMetric: 5.2688 - lr: 1.6667e-04 - 83s/epoch - 424ms/step
Epoch 279/1000
2023-09-19 19:49:20.672 
Epoch 279/1000 
	 loss: 5.1662, MinusLogProbMetric: 5.1662, val_loss: 5.2457, val_MinusLogProbMetric: 5.2457

Epoch 279: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1662 - MinusLogProbMetric: 5.1662 - val_loss: 5.2457 - val_MinusLogProbMetric: 5.2457 - lr: 1.6667e-04 - 83s/epoch - 425ms/step
Epoch 280/1000
2023-09-19 19:50:43.840 
Epoch 280/1000 
	 loss: 5.1626, MinusLogProbMetric: 5.1626, val_loss: 5.2941, val_MinusLogProbMetric: 5.2941

Epoch 280: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1626 - MinusLogProbMetric: 5.1626 - val_loss: 5.2941 - val_MinusLogProbMetric: 5.2941 - lr: 1.6667e-04 - 83s/epoch - 424ms/step
Epoch 281/1000
2023-09-19 19:52:05.542 
Epoch 281/1000 
	 loss: 5.1707, MinusLogProbMetric: 5.1707, val_loss: 5.2641, val_MinusLogProbMetric: 5.2641

Epoch 281: val_loss did not improve from 5.22647
196/196 - 82s - loss: 5.1707 - MinusLogProbMetric: 5.1707 - val_loss: 5.2641 - val_MinusLogProbMetric: 5.2641 - lr: 1.6667e-04 - 82s/epoch - 417ms/step
Epoch 282/1000
2023-09-19 19:53:27.942 
Epoch 282/1000 
	 loss: 5.1689, MinusLogProbMetric: 5.1689, val_loss: 5.2616, val_MinusLogProbMetric: 5.2616

Epoch 282: val_loss did not improve from 5.22647
196/196 - 82s - loss: 5.1689 - MinusLogProbMetric: 5.1689 - val_loss: 5.2616 - val_MinusLogProbMetric: 5.2616 - lr: 1.6667e-04 - 82s/epoch - 420ms/step
Epoch 283/1000
2023-09-19 19:54:50.514 
Epoch 283/1000 
	 loss: 5.1660, MinusLogProbMetric: 5.1660, val_loss: 5.2351, val_MinusLogProbMetric: 5.2351

Epoch 283: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1660 - MinusLogProbMetric: 5.1660 - val_loss: 5.2351 - val_MinusLogProbMetric: 5.2351 - lr: 1.6667e-04 - 83s/epoch - 421ms/step
Epoch 284/1000
2023-09-19 19:56:13.826 
Epoch 284/1000 
	 loss: 5.1722, MinusLogProbMetric: 5.1722, val_loss: 5.2889, val_MinusLogProbMetric: 5.2889

Epoch 284: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1722 - MinusLogProbMetric: 5.1722 - val_loss: 5.2889 - val_MinusLogProbMetric: 5.2889 - lr: 1.6667e-04 - 83s/epoch - 425ms/step
Epoch 285/1000
2023-09-19 19:57:37.063 
Epoch 285/1000 
	 loss: 5.1713, MinusLogProbMetric: 5.1713, val_loss: 5.2512, val_MinusLogProbMetric: 5.2512

Epoch 285: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1713 - MinusLogProbMetric: 5.1713 - val_loss: 5.2512 - val_MinusLogProbMetric: 5.2512 - lr: 1.6667e-04 - 83s/epoch - 425ms/step
Epoch 286/1000
2023-09-19 19:59:00.088 
Epoch 286/1000 
	 loss: 5.1653, MinusLogProbMetric: 5.1653, val_loss: 5.2592, val_MinusLogProbMetric: 5.2592

Epoch 286: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1653 - MinusLogProbMetric: 5.1653 - val_loss: 5.2592 - val_MinusLogProbMetric: 5.2592 - lr: 1.6667e-04 - 83s/epoch - 424ms/step
Epoch 287/1000
2023-09-19 20:00:23.550 
Epoch 287/1000 
	 loss: 5.1754, MinusLogProbMetric: 5.1754, val_loss: 5.2696, val_MinusLogProbMetric: 5.2696

Epoch 287: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1754 - MinusLogProbMetric: 5.1754 - val_loss: 5.2696 - val_MinusLogProbMetric: 5.2696 - lr: 1.6667e-04 - 83s/epoch - 426ms/step
Epoch 288/1000
2023-09-19 20:01:46.677 
Epoch 288/1000 
	 loss: 5.1656, MinusLogProbMetric: 5.1656, val_loss: 5.2490, val_MinusLogProbMetric: 5.2490

Epoch 288: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1656 - MinusLogProbMetric: 5.1656 - val_loss: 5.2490 - val_MinusLogProbMetric: 5.2490 - lr: 1.6667e-04 - 83s/epoch - 424ms/step
Epoch 289/1000
2023-09-19 20:03:10.219 
Epoch 289/1000 
	 loss: 5.1746, MinusLogProbMetric: 5.1746, val_loss: 5.3416, val_MinusLogProbMetric: 5.3416

Epoch 289: val_loss did not improve from 5.22647
196/196 - 84s - loss: 5.1746 - MinusLogProbMetric: 5.1746 - val_loss: 5.3416 - val_MinusLogProbMetric: 5.3416 - lr: 1.6667e-04 - 84s/epoch - 426ms/step
Epoch 290/1000
2023-09-19 20:04:33.518 
Epoch 290/1000 
	 loss: 5.1748, MinusLogProbMetric: 5.1748, val_loss: 5.2752, val_MinusLogProbMetric: 5.2752

Epoch 290: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1748 - MinusLogProbMetric: 5.1748 - val_loss: 5.2752 - val_MinusLogProbMetric: 5.2752 - lr: 1.6667e-04 - 83s/epoch - 425ms/step
Epoch 291/1000
2023-09-19 20:05:55.456 
Epoch 291/1000 
	 loss: 5.1696, MinusLogProbMetric: 5.1696, val_loss: 5.2866, val_MinusLogProbMetric: 5.2866

Epoch 291: val_loss did not improve from 5.22647
196/196 - 82s - loss: 5.1696 - MinusLogProbMetric: 5.1696 - val_loss: 5.2866 - val_MinusLogProbMetric: 5.2866 - lr: 1.6667e-04 - 82s/epoch - 418ms/step
Epoch 292/1000
2023-09-19 20:07:18.127 
Epoch 292/1000 
	 loss: 5.1713, MinusLogProbMetric: 5.1713, val_loss: 5.2613, val_MinusLogProbMetric: 5.2613

Epoch 292: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1713 - MinusLogProbMetric: 5.1713 - val_loss: 5.2613 - val_MinusLogProbMetric: 5.2613 - lr: 1.6667e-04 - 83s/epoch - 422ms/step
Epoch 293/1000
2023-09-19 20:08:40.477 
Epoch 293/1000 
	 loss: 5.1763, MinusLogProbMetric: 5.1763, val_loss: 5.2688, val_MinusLogProbMetric: 5.2688

Epoch 293: val_loss did not improve from 5.22647
196/196 - 82s - loss: 5.1763 - MinusLogProbMetric: 5.1763 - val_loss: 5.2688 - val_MinusLogProbMetric: 5.2688 - lr: 1.6667e-04 - 82s/epoch - 420ms/step
Epoch 294/1000
2023-09-19 20:10:02.959 
Epoch 294/1000 
	 loss: 5.1641, MinusLogProbMetric: 5.1641, val_loss: 5.2598, val_MinusLogProbMetric: 5.2598

Epoch 294: val_loss did not improve from 5.22647
196/196 - 82s - loss: 5.1641 - MinusLogProbMetric: 5.1641 - val_loss: 5.2598 - val_MinusLogProbMetric: 5.2598 - lr: 1.6667e-04 - 82s/epoch - 421ms/step
Epoch 295/1000
2023-09-19 20:11:26.247 
Epoch 295/1000 
	 loss: 5.1678, MinusLogProbMetric: 5.1678, val_loss: 5.2536, val_MinusLogProbMetric: 5.2536

Epoch 295: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1678 - MinusLogProbMetric: 5.1678 - val_loss: 5.2536 - val_MinusLogProbMetric: 5.2536 - lr: 1.6667e-04 - 83s/epoch - 425ms/step
Epoch 296/1000
2023-09-19 20:12:48.605 
Epoch 296/1000 
	 loss: 5.1709, MinusLogProbMetric: 5.1709, val_loss: 5.2413, val_MinusLogProbMetric: 5.2413

Epoch 296: val_loss did not improve from 5.22647
196/196 - 82s - loss: 5.1709 - MinusLogProbMetric: 5.1709 - val_loss: 5.2413 - val_MinusLogProbMetric: 5.2413 - lr: 1.6667e-04 - 82s/epoch - 420ms/step
Epoch 297/1000
2023-09-19 20:14:11.430 
Epoch 297/1000 
	 loss: 5.1655, MinusLogProbMetric: 5.1655, val_loss: 5.3024, val_MinusLogProbMetric: 5.3024

Epoch 297: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1655 - MinusLogProbMetric: 5.1655 - val_loss: 5.3024 - val_MinusLogProbMetric: 5.3024 - lr: 1.6667e-04 - 83s/epoch - 423ms/step
Epoch 298/1000
2023-09-19 20:15:34.428 
Epoch 298/1000 
	 loss: 5.1707, MinusLogProbMetric: 5.1707, val_loss: 5.2804, val_MinusLogProbMetric: 5.2804

Epoch 298: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1707 - MinusLogProbMetric: 5.1707 - val_loss: 5.2804 - val_MinusLogProbMetric: 5.2804 - lr: 1.6667e-04 - 83s/epoch - 423ms/step
Epoch 299/1000
2023-09-19 20:16:56.702 
Epoch 299/1000 
	 loss: 5.1734, MinusLogProbMetric: 5.1734, val_loss: 5.2574, val_MinusLogProbMetric: 5.2574

Epoch 299: val_loss did not improve from 5.22647
196/196 - 82s - loss: 5.1734 - MinusLogProbMetric: 5.1734 - val_loss: 5.2574 - val_MinusLogProbMetric: 5.2574 - lr: 1.6667e-04 - 82s/epoch - 420ms/step
Epoch 300/1000
2023-09-19 20:18:20.182 
Epoch 300/1000 
	 loss: 5.1652, MinusLogProbMetric: 5.1652, val_loss: 5.2577, val_MinusLogProbMetric: 5.2577

Epoch 300: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1652 - MinusLogProbMetric: 5.1652 - val_loss: 5.2577 - val_MinusLogProbMetric: 5.2577 - lr: 1.6667e-04 - 83s/epoch - 426ms/step
Epoch 301/1000
2023-09-19 20:19:43.485 
Epoch 301/1000 
	 loss: 5.1744, MinusLogProbMetric: 5.1744, val_loss: 5.2294, val_MinusLogProbMetric: 5.2294

Epoch 301: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1744 - MinusLogProbMetric: 5.1744 - val_loss: 5.2294 - val_MinusLogProbMetric: 5.2294 - lr: 1.6667e-04 - 83s/epoch - 425ms/step
Epoch 302/1000
2023-09-19 20:21:05.758 
Epoch 302/1000 
	 loss: 5.1641, MinusLogProbMetric: 5.1641, val_loss: 5.2488, val_MinusLogProbMetric: 5.2488

Epoch 302: val_loss did not improve from 5.22647
196/196 - 82s - loss: 5.1641 - MinusLogProbMetric: 5.1641 - val_loss: 5.2488 - val_MinusLogProbMetric: 5.2488 - lr: 1.6667e-04 - 82s/epoch - 420ms/step
Epoch 303/1000
2023-09-19 20:22:28.319 
Epoch 303/1000 
	 loss: 5.1658, MinusLogProbMetric: 5.1658, val_loss: 5.2606, val_MinusLogProbMetric: 5.2606

Epoch 303: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1658 - MinusLogProbMetric: 5.1658 - val_loss: 5.2606 - val_MinusLogProbMetric: 5.2606 - lr: 1.6667e-04 - 83s/epoch - 421ms/step
Epoch 304/1000
2023-09-19 20:23:51.898 
Epoch 304/1000 
	 loss: 5.1673, MinusLogProbMetric: 5.1673, val_loss: 5.2529, val_MinusLogProbMetric: 5.2529

Epoch 304: val_loss did not improve from 5.22647
196/196 - 84s - loss: 5.1673 - MinusLogProbMetric: 5.1673 - val_loss: 5.2529 - val_MinusLogProbMetric: 5.2529 - lr: 1.6667e-04 - 84s/epoch - 426ms/step
Epoch 305/1000
2023-09-19 20:25:15.284 
Epoch 305/1000 
	 loss: 5.1679, MinusLogProbMetric: 5.1679, val_loss: 5.2464, val_MinusLogProbMetric: 5.2464

Epoch 305: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1679 - MinusLogProbMetric: 5.1679 - val_loss: 5.2464 - val_MinusLogProbMetric: 5.2464 - lr: 1.6667e-04 - 83s/epoch - 425ms/step
Epoch 306/1000
2023-09-19 20:26:39.311 
Epoch 306/1000 
	 loss: 5.1697, MinusLogProbMetric: 5.1697, val_loss: 5.2482, val_MinusLogProbMetric: 5.2482

Epoch 306: val_loss did not improve from 5.22647
196/196 - 84s - loss: 5.1697 - MinusLogProbMetric: 5.1697 - val_loss: 5.2482 - val_MinusLogProbMetric: 5.2482 - lr: 1.6667e-04 - 84s/epoch - 429ms/step
Epoch 307/1000
2023-09-19 20:28:02.800 
Epoch 307/1000 
	 loss: 5.1676, MinusLogProbMetric: 5.1676, val_loss: 5.2856, val_MinusLogProbMetric: 5.2856

Epoch 307: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1676 - MinusLogProbMetric: 5.1676 - val_loss: 5.2856 - val_MinusLogProbMetric: 5.2856 - lr: 1.6667e-04 - 83s/epoch - 426ms/step
Epoch 308/1000
2023-09-19 20:29:26.091 
Epoch 308/1000 
	 loss: 5.1754, MinusLogProbMetric: 5.1754, val_loss: 5.3701, val_MinusLogProbMetric: 5.3701

Epoch 308: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1754 - MinusLogProbMetric: 5.1754 - val_loss: 5.3701 - val_MinusLogProbMetric: 5.3701 - lr: 1.6667e-04 - 83s/epoch - 425ms/step
Epoch 309/1000
2023-09-19 20:30:49.777 
Epoch 309/1000 
	 loss: 5.1670, MinusLogProbMetric: 5.1670, val_loss: 5.2446, val_MinusLogProbMetric: 5.2446

Epoch 309: val_loss did not improve from 5.22647
196/196 - 84s - loss: 5.1670 - MinusLogProbMetric: 5.1670 - val_loss: 5.2446 - val_MinusLogProbMetric: 5.2446 - lr: 1.6667e-04 - 84s/epoch - 427ms/step
Epoch 310/1000
2023-09-19 20:32:12.668 
Epoch 310/1000 
	 loss: 5.1683, MinusLogProbMetric: 5.1683, val_loss: 5.3365, val_MinusLogProbMetric: 5.3365

Epoch 310: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1683 - MinusLogProbMetric: 5.1683 - val_loss: 5.3365 - val_MinusLogProbMetric: 5.3365 - lr: 1.6667e-04 - 83s/epoch - 423ms/step
Epoch 311/1000
2023-09-19 20:33:35.973 
Epoch 311/1000 
	 loss: 5.1647, MinusLogProbMetric: 5.1647, val_loss: 5.2724, val_MinusLogProbMetric: 5.2724

Epoch 311: val_loss did not improve from 5.22647
196/196 - 83s - loss: 5.1647 - MinusLogProbMetric: 5.1647 - val_loss: 5.2724 - val_MinusLogProbMetric: 5.2724 - lr: 1.6667e-04 - 83s/epoch - 425ms/step
Epoch 312/1000
2023-09-19 20:34:57.594 
Epoch 312/1000 
	 loss: 5.1734, MinusLogProbMetric: 5.1734, val_loss: 5.2353, val_MinusLogProbMetric: 5.2353

Epoch 312: val_loss did not improve from 5.22647
196/196 - 82s - loss: 5.1734 - MinusLogProbMetric: 5.1734 - val_loss: 5.2353 - val_MinusLogProbMetric: 5.2353 - lr: 1.6667e-04 - 82s/epoch - 416ms/step
Epoch 313/1000
2023-09-19 20:36:19.883 
Epoch 313/1000 
	 loss: 5.1635, MinusLogProbMetric: 5.1635, val_loss: 5.2229, val_MinusLogProbMetric: 5.2229

Epoch 313: val_loss improved from 5.22647 to 5.22294, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 84s - loss: 5.1635 - MinusLogProbMetric: 5.1635 - val_loss: 5.2229 - val_MinusLogProbMetric: 5.2229 - lr: 1.6667e-04 - 84s/epoch - 427ms/step
Epoch 314/1000
2023-09-19 20:37:44.030 
Epoch 314/1000 
	 loss: 5.1601, MinusLogProbMetric: 5.1601, val_loss: 5.2286, val_MinusLogProbMetric: 5.2286

Epoch 314: val_loss did not improve from 5.22294
196/196 - 83s - loss: 5.1601 - MinusLogProbMetric: 5.1601 - val_loss: 5.2286 - val_MinusLogProbMetric: 5.2286 - lr: 1.6667e-04 - 83s/epoch - 422ms/step
Epoch 315/1000
2023-09-19 20:39:06.809 
Epoch 315/1000 
	 loss: 5.1594, MinusLogProbMetric: 5.1594, val_loss: 5.3416, val_MinusLogProbMetric: 5.3416

Epoch 315: val_loss did not improve from 5.22294
196/196 - 83s - loss: 5.1594 - MinusLogProbMetric: 5.1594 - val_loss: 5.3416 - val_MinusLogProbMetric: 5.3416 - lr: 1.6667e-04 - 83s/epoch - 422ms/step
Epoch 316/1000
2023-09-19 20:40:29.807 
Epoch 316/1000 
	 loss: 5.1648, MinusLogProbMetric: 5.1648, val_loss: 5.2242, val_MinusLogProbMetric: 5.2242

Epoch 316: val_loss did not improve from 5.22294
196/196 - 83s - loss: 5.1648 - MinusLogProbMetric: 5.1648 - val_loss: 5.2242 - val_MinusLogProbMetric: 5.2242 - lr: 1.6667e-04 - 83s/epoch - 423ms/step
Epoch 317/1000
2023-09-19 20:41:52.954 
Epoch 317/1000 
	 loss: 5.1624, MinusLogProbMetric: 5.1624, val_loss: 5.2307, val_MinusLogProbMetric: 5.2307

Epoch 317: val_loss did not improve from 5.22294
196/196 - 83s - loss: 5.1624 - MinusLogProbMetric: 5.1624 - val_loss: 5.2307 - val_MinusLogProbMetric: 5.2307 - lr: 1.6667e-04 - 83s/epoch - 424ms/step
Epoch 318/1000
2023-09-19 20:43:16.272 
Epoch 318/1000 
	 loss: 5.1621, MinusLogProbMetric: 5.1621, val_loss: 5.2471, val_MinusLogProbMetric: 5.2471

Epoch 318: val_loss did not improve from 5.22294
196/196 - 83s - loss: 5.1621 - MinusLogProbMetric: 5.1621 - val_loss: 5.2471 - val_MinusLogProbMetric: 5.2471 - lr: 1.6667e-04 - 83s/epoch - 425ms/step
Epoch 319/1000
2023-09-19 20:44:38.441 
Epoch 319/1000 
	 loss: 5.1668, MinusLogProbMetric: 5.1668, val_loss: 5.2562, val_MinusLogProbMetric: 5.2562

Epoch 319: val_loss did not improve from 5.22294
196/196 - 82s - loss: 5.1668 - MinusLogProbMetric: 5.1668 - val_loss: 5.2562 - val_MinusLogProbMetric: 5.2562 - lr: 1.6667e-04 - 82s/epoch - 419ms/step
Epoch 320/1000
2023-09-19 20:46:00.770 
Epoch 320/1000 
	 loss: 5.1587, MinusLogProbMetric: 5.1587, val_loss: 5.2353, val_MinusLogProbMetric: 5.2353

Epoch 320: val_loss did not improve from 5.22294
196/196 - 82s - loss: 5.1587 - MinusLogProbMetric: 5.1587 - val_loss: 5.2353 - val_MinusLogProbMetric: 5.2353 - lr: 1.6667e-04 - 82s/epoch - 420ms/step
Epoch 321/1000
2023-09-19 20:47:23.119 
Epoch 321/1000 
	 loss: 5.1647, MinusLogProbMetric: 5.1647, val_loss: 5.3065, val_MinusLogProbMetric: 5.3065

Epoch 321: val_loss did not improve from 5.22294
196/196 - 82s - loss: 5.1647 - MinusLogProbMetric: 5.1647 - val_loss: 5.3065 - val_MinusLogProbMetric: 5.3065 - lr: 1.6667e-04 - 82s/epoch - 420ms/step
Epoch 322/1000
2023-09-19 20:48:46.258 
Epoch 322/1000 
	 loss: 5.1614, MinusLogProbMetric: 5.1614, val_loss: 5.2694, val_MinusLogProbMetric: 5.2694

Epoch 322: val_loss did not improve from 5.22294
196/196 - 83s - loss: 5.1614 - MinusLogProbMetric: 5.1614 - val_loss: 5.2694 - val_MinusLogProbMetric: 5.2694 - lr: 1.6667e-04 - 83s/epoch - 424ms/step
Epoch 323/1000
2023-09-19 20:50:08.604 
Epoch 323/1000 
	 loss: 5.1646, MinusLogProbMetric: 5.1646, val_loss: 5.2399, val_MinusLogProbMetric: 5.2399

Epoch 323: val_loss did not improve from 5.22294
196/196 - 82s - loss: 5.1646 - MinusLogProbMetric: 5.1646 - val_loss: 5.2399 - val_MinusLogProbMetric: 5.2399 - lr: 1.6667e-04 - 82s/epoch - 420ms/step
Epoch 324/1000
2023-09-19 20:51:31.012 
Epoch 324/1000 
	 loss: 5.1599, MinusLogProbMetric: 5.1599, val_loss: 5.2387, val_MinusLogProbMetric: 5.2387

Epoch 324: val_loss did not improve from 5.22294
196/196 - 82s - loss: 5.1599 - MinusLogProbMetric: 5.1599 - val_loss: 5.2387 - val_MinusLogProbMetric: 5.2387 - lr: 1.6667e-04 - 82s/epoch - 420ms/step
Epoch 325/1000
2023-09-19 20:52:44.773 
Epoch 325/1000 
	 loss: 5.1582, MinusLogProbMetric: 5.1582, val_loss: 5.2188, val_MinusLogProbMetric: 5.2188

Epoch 325: val_loss improved from 5.22294 to 5.21881, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 75s - loss: 5.1582 - MinusLogProbMetric: 5.1582 - val_loss: 5.2188 - val_MinusLogProbMetric: 5.2188 - lr: 1.6667e-04 - 75s/epoch - 384ms/step
Epoch 326/1000
2023-09-19 20:54:03.998 
Epoch 326/1000 
	 loss: 5.1535, MinusLogProbMetric: 5.1535, val_loss: 5.2479, val_MinusLogProbMetric: 5.2479

Epoch 326: val_loss did not improve from 5.21881
196/196 - 78s - loss: 5.1535 - MinusLogProbMetric: 5.1535 - val_loss: 5.2479 - val_MinusLogProbMetric: 5.2479 - lr: 1.6667e-04 - 78s/epoch - 397ms/step
Epoch 327/1000
2023-09-19 20:55:27.685 
Epoch 327/1000 
	 loss: 5.1519, MinusLogProbMetric: 5.1519, val_loss: 5.2414, val_MinusLogProbMetric: 5.2414

Epoch 327: val_loss did not improve from 5.21881
196/196 - 84s - loss: 5.1519 - MinusLogProbMetric: 5.1519 - val_loss: 5.2414 - val_MinusLogProbMetric: 5.2414 - lr: 1.6667e-04 - 84s/epoch - 427ms/step
Epoch 328/1000
2023-09-19 20:56:50.281 
Epoch 328/1000 
	 loss: 5.1635, MinusLogProbMetric: 5.1635, val_loss: 5.2625, val_MinusLogProbMetric: 5.2625

Epoch 328: val_loss did not improve from 5.21881
196/196 - 83s - loss: 5.1635 - MinusLogProbMetric: 5.1635 - val_loss: 5.2625 - val_MinusLogProbMetric: 5.2625 - lr: 1.6667e-04 - 83s/epoch - 421ms/step
Epoch 329/1000
2023-09-19 20:58:12.741 
Epoch 329/1000 
	 loss: 5.1634, MinusLogProbMetric: 5.1634, val_loss: 5.2430, val_MinusLogProbMetric: 5.2430

Epoch 329: val_loss did not improve from 5.21881
196/196 - 82s - loss: 5.1634 - MinusLogProbMetric: 5.1634 - val_loss: 5.2430 - val_MinusLogProbMetric: 5.2430 - lr: 1.6667e-04 - 82s/epoch - 421ms/step
Epoch 330/1000
2023-09-19 20:59:35.974 
Epoch 330/1000 
	 loss: 5.1557, MinusLogProbMetric: 5.1557, val_loss: 5.2284, val_MinusLogProbMetric: 5.2284

Epoch 330: val_loss did not improve from 5.21881
196/196 - 83s - loss: 5.1557 - MinusLogProbMetric: 5.1557 - val_loss: 5.2284 - val_MinusLogProbMetric: 5.2284 - lr: 1.6667e-04 - 83s/epoch - 425ms/step
Epoch 331/1000
2023-09-19 21:00:58.125 
Epoch 331/1000 
	 loss: 5.1546, MinusLogProbMetric: 5.1546, val_loss: 5.2880, val_MinusLogProbMetric: 5.2880

Epoch 331: val_loss did not improve from 5.21881
196/196 - 82s - loss: 5.1546 - MinusLogProbMetric: 5.1546 - val_loss: 5.2880 - val_MinusLogProbMetric: 5.2880 - lr: 1.6667e-04 - 82s/epoch - 419ms/step
Epoch 332/1000
2023-09-19 21:02:20.025 
Epoch 332/1000 
	 loss: 5.1589, MinusLogProbMetric: 5.1589, val_loss: 5.2575, val_MinusLogProbMetric: 5.2575

Epoch 332: val_loss did not improve from 5.21881
196/196 - 82s - loss: 5.1589 - MinusLogProbMetric: 5.1589 - val_loss: 5.2575 - val_MinusLogProbMetric: 5.2575 - lr: 1.6667e-04 - 82s/epoch - 418ms/step
Epoch 333/1000
2023-09-19 21:03:36.797 
Epoch 333/1000 
	 loss: 5.1581, MinusLogProbMetric: 5.1581, val_loss: 5.2765, val_MinusLogProbMetric: 5.2765

Epoch 333: val_loss did not improve from 5.21881
196/196 - 77s - loss: 5.1581 - MinusLogProbMetric: 5.1581 - val_loss: 5.2765 - val_MinusLogProbMetric: 5.2765 - lr: 1.6667e-04 - 77s/epoch - 392ms/step
Epoch 334/1000
2023-09-19 21:04:50.121 
Epoch 334/1000 
	 loss: 5.1566, MinusLogProbMetric: 5.1566, val_loss: 5.2492, val_MinusLogProbMetric: 5.2492

Epoch 334: val_loss did not improve from 5.21881
196/196 - 73s - loss: 5.1566 - MinusLogProbMetric: 5.1566 - val_loss: 5.2492 - val_MinusLogProbMetric: 5.2492 - lr: 1.6667e-04 - 73s/epoch - 374ms/step
Epoch 335/1000
2023-09-19 21:06:11.950 
Epoch 335/1000 
	 loss: 5.1596, MinusLogProbMetric: 5.1596, val_loss: 5.2134, val_MinusLogProbMetric: 5.2134

Epoch 335: val_loss improved from 5.21881 to 5.21339, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 5.1596 - MinusLogProbMetric: 5.1596 - val_loss: 5.2134 - val_MinusLogProbMetric: 5.2134 - lr: 1.6667e-04 - 83s/epoch - 425ms/step
Epoch 336/1000
2023-09-19 21:07:36.433 
Epoch 336/1000 
	 loss: 5.1524, MinusLogProbMetric: 5.1524, val_loss: 5.2168, val_MinusLogProbMetric: 5.2168

Epoch 336: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1524 - MinusLogProbMetric: 5.1524 - val_loss: 5.2168 - val_MinusLogProbMetric: 5.2168 - lr: 1.6667e-04 - 83s/epoch - 423ms/step
Epoch 337/1000
2023-09-19 21:08:58.966 
Epoch 337/1000 
	 loss: 5.1579, MinusLogProbMetric: 5.1579, val_loss: 5.2455, val_MinusLogProbMetric: 5.2455

Epoch 337: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1579 - MinusLogProbMetric: 5.1579 - val_loss: 5.2455 - val_MinusLogProbMetric: 5.2455 - lr: 1.6667e-04 - 83s/epoch - 421ms/step
Epoch 338/1000
2023-09-19 21:10:20.902 
Epoch 338/1000 
	 loss: 5.1632, MinusLogProbMetric: 5.1632, val_loss: 5.2299, val_MinusLogProbMetric: 5.2299

Epoch 338: val_loss did not improve from 5.21339
196/196 - 82s - loss: 5.1632 - MinusLogProbMetric: 5.1632 - val_loss: 5.2299 - val_MinusLogProbMetric: 5.2299 - lr: 1.6667e-04 - 82s/epoch - 418ms/step
Epoch 339/1000
2023-09-19 21:11:43.386 
Epoch 339/1000 
	 loss: 5.1605, MinusLogProbMetric: 5.1605, val_loss: 5.2248, val_MinusLogProbMetric: 5.2248

Epoch 339: val_loss did not improve from 5.21339
196/196 - 82s - loss: 5.1605 - MinusLogProbMetric: 5.1605 - val_loss: 5.2248 - val_MinusLogProbMetric: 5.2248 - lr: 1.6667e-04 - 82s/epoch - 421ms/step
Epoch 340/1000
2023-09-19 21:13:05.411 
Epoch 340/1000 
	 loss: 5.1561, MinusLogProbMetric: 5.1561, val_loss: 5.3145, val_MinusLogProbMetric: 5.3145

Epoch 340: val_loss did not improve from 5.21339
196/196 - 82s - loss: 5.1561 - MinusLogProbMetric: 5.1561 - val_loss: 5.3145 - val_MinusLogProbMetric: 5.3145 - lr: 1.6667e-04 - 82s/epoch - 418ms/step
Epoch 341/1000
2023-09-19 21:14:26.719 
Epoch 341/1000 
	 loss: 5.1614, MinusLogProbMetric: 5.1614, val_loss: 5.3009, val_MinusLogProbMetric: 5.3009

Epoch 341: val_loss did not improve from 5.21339
196/196 - 81s - loss: 5.1614 - MinusLogProbMetric: 5.1614 - val_loss: 5.3009 - val_MinusLogProbMetric: 5.3009 - lr: 1.6667e-04 - 81s/epoch - 415ms/step
Epoch 342/1000
2023-09-19 21:15:49.003 
Epoch 342/1000 
	 loss: 5.1604, MinusLogProbMetric: 5.1604, val_loss: 5.2419, val_MinusLogProbMetric: 5.2419

Epoch 342: val_loss did not improve from 5.21339
196/196 - 82s - loss: 5.1604 - MinusLogProbMetric: 5.1604 - val_loss: 5.2419 - val_MinusLogProbMetric: 5.2419 - lr: 1.6667e-04 - 82s/epoch - 420ms/step
Epoch 343/1000
2023-09-19 21:17:11.045 
Epoch 343/1000 
	 loss: 5.1577, MinusLogProbMetric: 5.1577, val_loss: 5.2652, val_MinusLogProbMetric: 5.2652

Epoch 343: val_loss did not improve from 5.21339
196/196 - 82s - loss: 5.1577 - MinusLogProbMetric: 5.1577 - val_loss: 5.2652 - val_MinusLogProbMetric: 5.2652 - lr: 1.6667e-04 - 82s/epoch - 419ms/step
Epoch 344/1000
2023-09-19 21:18:31.989 
Epoch 344/1000 
	 loss: 5.1609, MinusLogProbMetric: 5.1609, val_loss: 5.2843, val_MinusLogProbMetric: 5.2843

Epoch 344: val_loss did not improve from 5.21339
196/196 - 81s - loss: 5.1609 - MinusLogProbMetric: 5.1609 - val_loss: 5.2843 - val_MinusLogProbMetric: 5.2843 - lr: 1.6667e-04 - 81s/epoch - 413ms/step
Epoch 345/1000
2023-09-19 21:19:53.780 
Epoch 345/1000 
	 loss: 5.1539, MinusLogProbMetric: 5.1539, val_loss: 5.2384, val_MinusLogProbMetric: 5.2384

Epoch 345: val_loss did not improve from 5.21339
196/196 - 82s - loss: 5.1539 - MinusLogProbMetric: 5.1539 - val_loss: 5.2384 - val_MinusLogProbMetric: 5.2384 - lr: 1.6667e-04 - 82s/epoch - 417ms/step
Epoch 346/1000
2023-09-19 21:21:16.708 
Epoch 346/1000 
	 loss: 5.1577, MinusLogProbMetric: 5.1577, val_loss: 5.2300, val_MinusLogProbMetric: 5.2300

Epoch 346: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1577 - MinusLogProbMetric: 5.1577 - val_loss: 5.2300 - val_MinusLogProbMetric: 5.2300 - lr: 1.6667e-04 - 83s/epoch - 423ms/step
Epoch 347/1000
2023-09-19 21:22:37.887 
Epoch 347/1000 
	 loss: 5.1514, MinusLogProbMetric: 5.1514, val_loss: 5.2244, val_MinusLogProbMetric: 5.2244

Epoch 347: val_loss did not improve from 5.21339
196/196 - 81s - loss: 5.1514 - MinusLogProbMetric: 5.1514 - val_loss: 5.2244 - val_MinusLogProbMetric: 5.2244 - lr: 1.6667e-04 - 81s/epoch - 414ms/step
Epoch 348/1000
2023-09-19 21:23:59.541 
Epoch 348/1000 
	 loss: 5.1490, MinusLogProbMetric: 5.1490, val_loss: 5.2558, val_MinusLogProbMetric: 5.2558

Epoch 348: val_loss did not improve from 5.21339
196/196 - 82s - loss: 5.1490 - MinusLogProbMetric: 5.1490 - val_loss: 5.2558 - val_MinusLogProbMetric: 5.2558 - lr: 1.6667e-04 - 82s/epoch - 417ms/step
Epoch 349/1000
2023-09-19 21:25:21.354 
Epoch 349/1000 
	 loss: 5.1496, MinusLogProbMetric: 5.1496, val_loss: 5.2157, val_MinusLogProbMetric: 5.2157

Epoch 349: val_loss did not improve from 5.21339
196/196 - 82s - loss: 5.1496 - MinusLogProbMetric: 5.1496 - val_loss: 5.2157 - val_MinusLogProbMetric: 5.2157 - lr: 1.6667e-04 - 82s/epoch - 417ms/step
Epoch 350/1000
2023-09-19 21:26:43.926 
Epoch 350/1000 
	 loss: 5.1519, MinusLogProbMetric: 5.1519, val_loss: 5.2241, val_MinusLogProbMetric: 5.2241

Epoch 350: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1519 - MinusLogProbMetric: 5.1519 - val_loss: 5.2241 - val_MinusLogProbMetric: 5.2241 - lr: 1.6667e-04 - 83s/epoch - 421ms/step
Epoch 351/1000
2023-09-19 21:28:07.249 
Epoch 351/1000 
	 loss: 5.1536, MinusLogProbMetric: 5.1536, val_loss: 5.2218, val_MinusLogProbMetric: 5.2218

Epoch 351: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1536 - MinusLogProbMetric: 5.1536 - val_loss: 5.2218 - val_MinusLogProbMetric: 5.2218 - lr: 1.6667e-04 - 83s/epoch - 425ms/step
Epoch 352/1000
2023-09-19 21:29:29.582 
Epoch 352/1000 
	 loss: 5.1531, MinusLogProbMetric: 5.1531, val_loss: 5.2393, val_MinusLogProbMetric: 5.2393

Epoch 352: val_loss did not improve from 5.21339
196/196 - 82s - loss: 5.1531 - MinusLogProbMetric: 5.1531 - val_loss: 5.2393 - val_MinusLogProbMetric: 5.2393 - lr: 1.6667e-04 - 82s/epoch - 420ms/step
Epoch 353/1000
2023-09-19 21:30:52.411 
Epoch 353/1000 
	 loss: 5.1475, MinusLogProbMetric: 5.1475, val_loss: 5.2415, val_MinusLogProbMetric: 5.2415

Epoch 353: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1475 - MinusLogProbMetric: 5.1475 - val_loss: 5.2415 - val_MinusLogProbMetric: 5.2415 - lr: 1.6667e-04 - 83s/epoch - 423ms/step
Epoch 354/1000
2023-09-19 21:32:15.073 
Epoch 354/1000 
	 loss: 5.1622, MinusLogProbMetric: 5.1622, val_loss: 5.2620, val_MinusLogProbMetric: 5.2620

Epoch 354: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1622 - MinusLogProbMetric: 5.1622 - val_loss: 5.2620 - val_MinusLogProbMetric: 5.2620 - lr: 1.6667e-04 - 83s/epoch - 422ms/step
Epoch 355/1000
2023-09-19 21:33:37.302 
Epoch 355/1000 
	 loss: 5.1511, MinusLogProbMetric: 5.1511, val_loss: 5.2295, val_MinusLogProbMetric: 5.2295

Epoch 355: val_loss did not improve from 5.21339
196/196 - 82s - loss: 5.1511 - MinusLogProbMetric: 5.1511 - val_loss: 5.2295 - val_MinusLogProbMetric: 5.2295 - lr: 1.6667e-04 - 82s/epoch - 420ms/step
Epoch 356/1000
2023-09-19 21:34:59.692 
Epoch 356/1000 
	 loss: 5.1566, MinusLogProbMetric: 5.1566, val_loss: 5.2867, val_MinusLogProbMetric: 5.2867

Epoch 356: val_loss did not improve from 5.21339
196/196 - 82s - loss: 5.1566 - MinusLogProbMetric: 5.1566 - val_loss: 5.2867 - val_MinusLogProbMetric: 5.2867 - lr: 1.6667e-04 - 82s/epoch - 420ms/step
Epoch 357/1000
2023-09-19 21:36:22.495 
Epoch 357/1000 
	 loss: 5.1524, MinusLogProbMetric: 5.1524, val_loss: 5.2379, val_MinusLogProbMetric: 5.2379

Epoch 357: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1524 - MinusLogProbMetric: 5.1524 - val_loss: 5.2379 - val_MinusLogProbMetric: 5.2379 - lr: 1.6667e-04 - 83s/epoch - 422ms/step
Epoch 358/1000
2023-09-19 21:37:43.947 
Epoch 358/1000 
	 loss: 5.1462, MinusLogProbMetric: 5.1462, val_loss: 5.2353, val_MinusLogProbMetric: 5.2353

Epoch 358: val_loss did not improve from 5.21339
196/196 - 81s - loss: 5.1462 - MinusLogProbMetric: 5.1462 - val_loss: 5.2353 - val_MinusLogProbMetric: 5.2353 - lr: 1.6667e-04 - 81s/epoch - 416ms/step
Epoch 359/1000
2023-09-19 21:39:06.644 
Epoch 359/1000 
	 loss: 5.1548, MinusLogProbMetric: 5.1548, val_loss: 5.2380, val_MinusLogProbMetric: 5.2380

Epoch 359: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1548 - MinusLogProbMetric: 5.1548 - val_loss: 5.2380 - val_MinusLogProbMetric: 5.2380 - lr: 1.6667e-04 - 83s/epoch - 422ms/step
Epoch 360/1000
2023-09-19 21:40:29.066 
Epoch 360/1000 
	 loss: 5.1534, MinusLogProbMetric: 5.1534, val_loss: 5.2412, val_MinusLogProbMetric: 5.2412

Epoch 360: val_loss did not improve from 5.21339
196/196 - 82s - loss: 5.1534 - MinusLogProbMetric: 5.1534 - val_loss: 5.2412 - val_MinusLogProbMetric: 5.2412 - lr: 1.6667e-04 - 82s/epoch - 421ms/step
Epoch 361/1000
2023-09-19 21:41:51.515 
Epoch 361/1000 
	 loss: 5.1485, MinusLogProbMetric: 5.1485, val_loss: 5.2138, val_MinusLogProbMetric: 5.2138

Epoch 361: val_loss did not improve from 5.21339
196/196 - 82s - loss: 5.1485 - MinusLogProbMetric: 5.1485 - val_loss: 5.2138 - val_MinusLogProbMetric: 5.2138 - lr: 1.6667e-04 - 82s/epoch - 421ms/step
Epoch 362/1000
2023-09-19 21:43:14.110 
Epoch 362/1000 
	 loss: 5.1512, MinusLogProbMetric: 5.1512, val_loss: 5.2233, val_MinusLogProbMetric: 5.2233

Epoch 362: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1512 - MinusLogProbMetric: 5.1512 - val_loss: 5.2233 - val_MinusLogProbMetric: 5.2233 - lr: 1.6667e-04 - 83s/epoch - 421ms/step
Epoch 363/1000
2023-09-19 21:44:36.887 
Epoch 363/1000 
	 loss: 5.1488, MinusLogProbMetric: 5.1488, val_loss: 5.2630, val_MinusLogProbMetric: 5.2630

Epoch 363: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1488 - MinusLogProbMetric: 5.1488 - val_loss: 5.2630 - val_MinusLogProbMetric: 5.2630 - lr: 1.6667e-04 - 83s/epoch - 422ms/step
Epoch 364/1000
2023-09-19 21:45:58.696 
Epoch 364/1000 
	 loss: 5.1528, MinusLogProbMetric: 5.1528, val_loss: 5.2419, val_MinusLogProbMetric: 5.2419

Epoch 364: val_loss did not improve from 5.21339
196/196 - 82s - loss: 5.1528 - MinusLogProbMetric: 5.1528 - val_loss: 5.2419 - val_MinusLogProbMetric: 5.2419 - lr: 1.6667e-04 - 82s/epoch - 417ms/step
Epoch 365/1000
2023-09-19 21:47:21.285 
Epoch 365/1000 
	 loss: 5.1533, MinusLogProbMetric: 5.1533, val_loss: 5.2548, val_MinusLogProbMetric: 5.2548

Epoch 365: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1533 - MinusLogProbMetric: 5.1533 - val_loss: 5.2548 - val_MinusLogProbMetric: 5.2548 - lr: 1.6667e-04 - 83s/epoch - 421ms/step
Epoch 366/1000
2023-09-19 21:48:44.533 
Epoch 366/1000 
	 loss: 5.1550, MinusLogProbMetric: 5.1550, val_loss: 5.2538, val_MinusLogProbMetric: 5.2538

Epoch 366: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1550 - MinusLogProbMetric: 5.1550 - val_loss: 5.2538 - val_MinusLogProbMetric: 5.2538 - lr: 1.6667e-04 - 83s/epoch - 425ms/step
Epoch 367/1000
2023-09-19 21:50:06.784 
Epoch 367/1000 
	 loss: 5.1462, MinusLogProbMetric: 5.1462, val_loss: 5.2239, val_MinusLogProbMetric: 5.2239

Epoch 367: val_loss did not improve from 5.21339
196/196 - 82s - loss: 5.1462 - MinusLogProbMetric: 5.1462 - val_loss: 5.2239 - val_MinusLogProbMetric: 5.2239 - lr: 1.6667e-04 - 82s/epoch - 420ms/step
Epoch 368/1000
2023-09-19 21:51:28.574 
Epoch 368/1000 
	 loss: 5.1526, MinusLogProbMetric: 5.1526, val_loss: 5.2288, val_MinusLogProbMetric: 5.2288

Epoch 368: val_loss did not improve from 5.21339
196/196 - 82s - loss: 5.1526 - MinusLogProbMetric: 5.1526 - val_loss: 5.2288 - val_MinusLogProbMetric: 5.2288 - lr: 1.6667e-04 - 82s/epoch - 417ms/step
Epoch 369/1000
2023-09-19 21:52:50.491 
Epoch 369/1000 
	 loss: 5.1481, MinusLogProbMetric: 5.1481, val_loss: 5.2531, val_MinusLogProbMetric: 5.2531

Epoch 369: val_loss did not improve from 5.21339
196/196 - 82s - loss: 5.1481 - MinusLogProbMetric: 5.1481 - val_loss: 5.2531 - val_MinusLogProbMetric: 5.2531 - lr: 1.6667e-04 - 82s/epoch - 418ms/step
Epoch 370/1000
2023-09-19 21:54:11.501 
Epoch 370/1000 
	 loss: 5.1564, MinusLogProbMetric: 5.1564, val_loss: 5.2484, val_MinusLogProbMetric: 5.2484

Epoch 370: val_loss did not improve from 5.21339
196/196 - 81s - loss: 5.1564 - MinusLogProbMetric: 5.1564 - val_loss: 5.2484 - val_MinusLogProbMetric: 5.2484 - lr: 1.6667e-04 - 81s/epoch - 413ms/step
Epoch 371/1000
2023-09-19 21:55:34.358 
Epoch 371/1000 
	 loss: 5.1561, MinusLogProbMetric: 5.1561, val_loss: 5.2571, val_MinusLogProbMetric: 5.2571

Epoch 371: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1561 - MinusLogProbMetric: 5.1561 - val_loss: 5.2571 - val_MinusLogProbMetric: 5.2571 - lr: 1.6667e-04 - 83s/epoch - 423ms/step
Epoch 372/1000
2023-09-19 21:56:56.921 
Epoch 372/1000 
	 loss: 5.1530, MinusLogProbMetric: 5.1530, val_loss: 5.2979, val_MinusLogProbMetric: 5.2979

Epoch 372: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1530 - MinusLogProbMetric: 5.1530 - val_loss: 5.2979 - val_MinusLogProbMetric: 5.2979 - lr: 1.6667e-04 - 83s/epoch - 421ms/step
Epoch 373/1000
2023-09-19 21:58:19.845 
Epoch 373/1000 
	 loss: 5.1501, MinusLogProbMetric: 5.1501, val_loss: 5.2176, val_MinusLogProbMetric: 5.2176

Epoch 373: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1501 - MinusLogProbMetric: 5.1501 - val_loss: 5.2176 - val_MinusLogProbMetric: 5.2176 - lr: 1.6667e-04 - 83s/epoch - 423ms/step
Epoch 374/1000
2023-09-19 21:59:42.560 
Epoch 374/1000 
	 loss: 5.1505, MinusLogProbMetric: 5.1505, val_loss: 5.2337, val_MinusLogProbMetric: 5.2337

Epoch 374: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1505 - MinusLogProbMetric: 5.1505 - val_loss: 5.2337 - val_MinusLogProbMetric: 5.2337 - lr: 1.6667e-04 - 83s/epoch - 422ms/step
Epoch 375/1000
2023-09-19 22:01:05.649 
Epoch 375/1000 
	 loss: 5.1538, MinusLogProbMetric: 5.1538, val_loss: 5.2551, val_MinusLogProbMetric: 5.2551

Epoch 375: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1538 - MinusLogProbMetric: 5.1538 - val_loss: 5.2551 - val_MinusLogProbMetric: 5.2551 - lr: 1.6667e-04 - 83s/epoch - 424ms/step
Epoch 376/1000
2023-09-19 22:02:28.581 
Epoch 376/1000 
	 loss: 5.1521, MinusLogProbMetric: 5.1521, val_loss: 5.2404, val_MinusLogProbMetric: 5.2404

Epoch 376: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1521 - MinusLogProbMetric: 5.1521 - val_loss: 5.2404 - val_MinusLogProbMetric: 5.2404 - lr: 1.6667e-04 - 83s/epoch - 423ms/step
Epoch 377/1000
2023-09-19 22:03:51.955 
Epoch 377/1000 
	 loss: 5.1545, MinusLogProbMetric: 5.1545, val_loss: 5.2437, val_MinusLogProbMetric: 5.2437

Epoch 377: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1545 - MinusLogProbMetric: 5.1545 - val_loss: 5.2437 - val_MinusLogProbMetric: 5.2437 - lr: 1.6667e-04 - 83s/epoch - 425ms/step
Epoch 378/1000
2023-09-19 22:05:15.772 
Epoch 378/1000 
	 loss: 5.1486, MinusLogProbMetric: 5.1486, val_loss: 5.2260, val_MinusLogProbMetric: 5.2260

Epoch 378: val_loss did not improve from 5.21339
196/196 - 84s - loss: 5.1486 - MinusLogProbMetric: 5.1486 - val_loss: 5.2260 - val_MinusLogProbMetric: 5.2260 - lr: 1.6667e-04 - 84s/epoch - 428ms/step
Epoch 379/1000
2023-09-19 22:06:39.354 
Epoch 379/1000 
	 loss: 5.1481, MinusLogProbMetric: 5.1481, val_loss: 5.2220, val_MinusLogProbMetric: 5.2220

Epoch 379: val_loss did not improve from 5.21339
196/196 - 84s - loss: 5.1481 - MinusLogProbMetric: 5.1481 - val_loss: 5.2220 - val_MinusLogProbMetric: 5.2220 - lr: 1.6667e-04 - 84s/epoch - 426ms/step
Epoch 380/1000
2023-09-19 22:08:01.978 
Epoch 380/1000 
	 loss: 5.1396, MinusLogProbMetric: 5.1396, val_loss: 5.2286, val_MinusLogProbMetric: 5.2286

Epoch 380: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1396 - MinusLogProbMetric: 5.1396 - val_loss: 5.2286 - val_MinusLogProbMetric: 5.2286 - lr: 1.6667e-04 - 83s/epoch - 422ms/step
Epoch 381/1000
2023-09-19 22:09:24.388 
Epoch 381/1000 
	 loss: 5.1513, MinusLogProbMetric: 5.1513, val_loss: 5.2445, val_MinusLogProbMetric: 5.2445

Epoch 381: val_loss did not improve from 5.21339
196/196 - 82s - loss: 5.1513 - MinusLogProbMetric: 5.1513 - val_loss: 5.2445 - val_MinusLogProbMetric: 5.2445 - lr: 1.6667e-04 - 82s/epoch - 420ms/step
Epoch 382/1000
2023-09-19 22:10:46.867 
Epoch 382/1000 
	 loss: 5.1441, MinusLogProbMetric: 5.1441, val_loss: 5.2174, val_MinusLogProbMetric: 5.2174

Epoch 382: val_loss did not improve from 5.21339
196/196 - 82s - loss: 5.1441 - MinusLogProbMetric: 5.1441 - val_loss: 5.2174 - val_MinusLogProbMetric: 5.2174 - lr: 1.6667e-04 - 82s/epoch - 421ms/step
Epoch 383/1000
2023-09-19 22:12:09.518 
Epoch 383/1000 
	 loss: 5.1481, MinusLogProbMetric: 5.1481, val_loss: 5.2172, val_MinusLogProbMetric: 5.2172

Epoch 383: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1481 - MinusLogProbMetric: 5.1481 - val_loss: 5.2172 - val_MinusLogProbMetric: 5.2172 - lr: 1.6667e-04 - 83s/epoch - 422ms/step
Epoch 384/1000
2023-09-19 22:13:32.599 
Epoch 384/1000 
	 loss: 5.1475, MinusLogProbMetric: 5.1475, val_loss: 5.2594, val_MinusLogProbMetric: 5.2594

Epoch 384: val_loss did not improve from 5.21339
196/196 - 83s - loss: 5.1475 - MinusLogProbMetric: 5.1475 - val_loss: 5.2594 - val_MinusLogProbMetric: 5.2594 - lr: 1.6667e-04 - 83s/epoch - 424ms/step
Epoch 385/1000
2023-09-19 22:14:54.499 
Epoch 385/1000 
	 loss: 5.1454, MinusLogProbMetric: 5.1454, val_loss: 5.2537, val_MinusLogProbMetric: 5.2537

Epoch 385: val_loss did not improve from 5.21339
196/196 - 82s - loss: 5.1454 - MinusLogProbMetric: 5.1454 - val_loss: 5.2537 - val_MinusLogProbMetric: 5.2537 - lr: 1.6667e-04 - 82s/epoch - 418ms/step
Epoch 386/1000
2023-09-19 22:16:15.743 
Epoch 386/1000 
	 loss: 5.1178, MinusLogProbMetric: 5.1178, val_loss: 5.2408, val_MinusLogProbMetric: 5.2408

Epoch 386: val_loss did not improve from 5.21339
196/196 - 81s - loss: 5.1178 - MinusLogProbMetric: 5.1178 - val_loss: 5.2408 - val_MinusLogProbMetric: 5.2408 - lr: 8.3333e-05 - 81s/epoch - 414ms/step
Epoch 387/1000
2023-09-19 22:17:37.830 
Epoch 387/1000 
	 loss: 5.1136, MinusLogProbMetric: 5.1136, val_loss: 5.2026, val_MinusLogProbMetric: 5.2026

Epoch 387: val_loss improved from 5.21339 to 5.20262, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 84s - loss: 5.1136 - MinusLogProbMetric: 5.1136 - val_loss: 5.2026 - val_MinusLogProbMetric: 5.2026 - lr: 8.3333e-05 - 84s/epoch - 427ms/step
Epoch 388/1000
2023-09-19 22:19:01.711 
Epoch 388/1000 
	 loss: 5.1111, MinusLogProbMetric: 5.1111, val_loss: 5.2128, val_MinusLogProbMetric: 5.2128

Epoch 388: val_loss did not improve from 5.20262
196/196 - 82s - loss: 5.1111 - MinusLogProbMetric: 5.1111 - val_loss: 5.2128 - val_MinusLogProbMetric: 5.2128 - lr: 8.3333e-05 - 82s/epoch - 420ms/step
Epoch 389/1000
2023-09-19 22:20:23.885 
Epoch 389/1000 
	 loss: 5.1142, MinusLogProbMetric: 5.1142, val_loss: 5.2143, val_MinusLogProbMetric: 5.2143

Epoch 389: val_loss did not improve from 5.20262
196/196 - 82s - loss: 5.1142 - MinusLogProbMetric: 5.1142 - val_loss: 5.2143 - val_MinusLogProbMetric: 5.2143 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 390/1000
2023-09-19 22:21:46.804 
Epoch 390/1000 
	 loss: 5.1111, MinusLogProbMetric: 5.1111, val_loss: 5.1933, val_MinusLogProbMetric: 5.1933

Epoch 390: val_loss improved from 5.20262 to 5.19329, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 85s - loss: 5.1111 - MinusLogProbMetric: 5.1111 - val_loss: 5.1933 - val_MinusLogProbMetric: 5.1933 - lr: 8.3333e-05 - 85s/epoch - 431ms/step
Epoch 391/1000
2023-09-19 22:23:11.462 
Epoch 391/1000 
	 loss: 5.1136, MinusLogProbMetric: 5.1136, val_loss: 5.2073, val_MinusLogProbMetric: 5.2073

Epoch 391: val_loss did not improve from 5.19329
196/196 - 83s - loss: 5.1136 - MinusLogProbMetric: 5.1136 - val_loss: 5.2073 - val_MinusLogProbMetric: 5.2073 - lr: 8.3333e-05 - 83s/epoch - 424ms/step
Epoch 392/1000
2023-09-19 22:24:34.343 
Epoch 392/1000 
	 loss: 5.1111, MinusLogProbMetric: 5.1111, val_loss: 5.2000, val_MinusLogProbMetric: 5.2000

Epoch 392: val_loss did not improve from 5.19329
196/196 - 83s - loss: 5.1111 - MinusLogProbMetric: 5.1111 - val_loss: 5.2000 - val_MinusLogProbMetric: 5.2000 - lr: 8.3333e-05 - 83s/epoch - 423ms/step
Epoch 393/1000
2023-09-19 22:25:56.983 
Epoch 393/1000 
	 loss: 5.1121, MinusLogProbMetric: 5.1121, val_loss: 5.2046, val_MinusLogProbMetric: 5.2046

Epoch 393: val_loss did not improve from 5.19329
196/196 - 83s - loss: 5.1121 - MinusLogProbMetric: 5.1121 - val_loss: 5.2046 - val_MinusLogProbMetric: 5.2046 - lr: 8.3333e-05 - 83s/epoch - 422ms/step
Epoch 394/1000
2023-09-19 22:27:19.362 
Epoch 394/1000 
	 loss: 5.1135, MinusLogProbMetric: 5.1135, val_loss: 5.1982, val_MinusLogProbMetric: 5.1982

Epoch 394: val_loss did not improve from 5.19329
196/196 - 82s - loss: 5.1135 - MinusLogProbMetric: 5.1135 - val_loss: 5.1982 - val_MinusLogProbMetric: 5.1982 - lr: 8.3333e-05 - 82s/epoch - 420ms/step
Epoch 395/1000
2023-09-19 22:28:41.962 
Epoch 395/1000 
	 loss: 5.1113, MinusLogProbMetric: 5.1113, val_loss: 5.2002, val_MinusLogProbMetric: 5.2002

Epoch 395: val_loss did not improve from 5.19329
196/196 - 83s - loss: 5.1113 - MinusLogProbMetric: 5.1113 - val_loss: 5.2002 - val_MinusLogProbMetric: 5.2002 - lr: 8.3333e-05 - 83s/epoch - 421ms/step
Epoch 396/1000
2023-09-19 22:30:03.937 
Epoch 396/1000 
	 loss: 5.1135, MinusLogProbMetric: 5.1135, val_loss: 5.1964, val_MinusLogProbMetric: 5.1964

Epoch 396: val_loss did not improve from 5.19329
196/196 - 82s - loss: 5.1135 - MinusLogProbMetric: 5.1135 - val_loss: 5.1964 - val_MinusLogProbMetric: 5.1964 - lr: 8.3333e-05 - 82s/epoch - 418ms/step
Epoch 397/1000
2023-09-19 22:31:26.393 
Epoch 397/1000 
	 loss: 5.1138, MinusLogProbMetric: 5.1138, val_loss: 5.1995, val_MinusLogProbMetric: 5.1995

Epoch 397: val_loss did not improve from 5.19329
196/196 - 82s - loss: 5.1138 - MinusLogProbMetric: 5.1138 - val_loss: 5.1995 - val_MinusLogProbMetric: 5.1995 - lr: 8.3333e-05 - 82s/epoch - 421ms/step
Epoch 398/1000
2023-09-19 22:32:48.765 
Epoch 398/1000 
	 loss: 5.1109, MinusLogProbMetric: 5.1109, val_loss: 5.2015, val_MinusLogProbMetric: 5.2015

Epoch 398: val_loss did not improve from 5.19329
196/196 - 82s - loss: 5.1109 - MinusLogProbMetric: 5.1109 - val_loss: 5.2015 - val_MinusLogProbMetric: 5.2015 - lr: 8.3333e-05 - 82s/epoch - 420ms/step
Epoch 399/1000
2023-09-19 22:34:10.910 
Epoch 399/1000 
	 loss: 5.1083, MinusLogProbMetric: 5.1083, val_loss: 5.1894, val_MinusLogProbMetric: 5.1894

Epoch 399: val_loss improved from 5.19329 to 5.18938, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 84s - loss: 5.1083 - MinusLogProbMetric: 5.1083 - val_loss: 5.1894 - val_MinusLogProbMetric: 5.1894 - lr: 8.3333e-05 - 84s/epoch - 427ms/step
Epoch 400/1000
2023-09-19 22:35:34.749 
Epoch 400/1000 
	 loss: 5.1108, MinusLogProbMetric: 5.1108, val_loss: 5.1992, val_MinusLogProbMetric: 5.1992

Epoch 400: val_loss did not improve from 5.18938
196/196 - 82s - loss: 5.1108 - MinusLogProbMetric: 5.1108 - val_loss: 5.1992 - val_MinusLogProbMetric: 5.1992 - lr: 8.3333e-05 - 82s/epoch - 420ms/step
Epoch 401/1000
2023-09-19 22:36:55.840 
Epoch 401/1000 
	 loss: 5.1117, MinusLogProbMetric: 5.1117, val_loss: 5.2120, val_MinusLogProbMetric: 5.2120

Epoch 401: val_loss did not improve from 5.18938
196/196 - 81s - loss: 5.1117 - MinusLogProbMetric: 5.1117 - val_loss: 5.2120 - val_MinusLogProbMetric: 5.2120 - lr: 8.3333e-05 - 81s/epoch - 414ms/step
Epoch 402/1000
2023-09-19 22:38:09.936 
Epoch 402/1000 
	 loss: 5.1140, MinusLogProbMetric: 5.1140, val_loss: 5.2176, val_MinusLogProbMetric: 5.2176

Epoch 402: val_loss did not improve from 5.18938
196/196 - 74s - loss: 5.1140 - MinusLogProbMetric: 5.1140 - val_loss: 5.2176 - val_MinusLogProbMetric: 5.2176 - lr: 8.3333e-05 - 74s/epoch - 378ms/step
Epoch 403/1000
2023-09-19 22:39:32.025 
Epoch 403/1000 
	 loss: 5.1106, MinusLogProbMetric: 5.1106, val_loss: 5.2024, val_MinusLogProbMetric: 5.2024

Epoch 403: val_loss did not improve from 5.18938
196/196 - 82s - loss: 5.1106 - MinusLogProbMetric: 5.1106 - val_loss: 5.2024 - val_MinusLogProbMetric: 5.2024 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 404/1000
2023-09-19 22:40:54.362 
Epoch 404/1000 
	 loss: 5.1119, MinusLogProbMetric: 5.1119, val_loss: 5.1946, val_MinusLogProbMetric: 5.1946

Epoch 404: val_loss did not improve from 5.18938
196/196 - 82s - loss: 5.1119 - MinusLogProbMetric: 5.1119 - val_loss: 5.1946 - val_MinusLogProbMetric: 5.1946 - lr: 8.3333e-05 - 82s/epoch - 420ms/step
Epoch 405/1000
2023-09-19 22:42:16.934 
Epoch 405/1000 
	 loss: 5.1127, MinusLogProbMetric: 5.1127, val_loss: 5.2000, val_MinusLogProbMetric: 5.2000

Epoch 405: val_loss did not improve from 5.18938
196/196 - 83s - loss: 5.1127 - MinusLogProbMetric: 5.1127 - val_loss: 5.2000 - val_MinusLogProbMetric: 5.2000 - lr: 8.3333e-05 - 83s/epoch - 421ms/step
Epoch 406/1000
2023-09-19 22:43:39.387 
Epoch 406/1000 
	 loss: 5.1100, MinusLogProbMetric: 5.1100, val_loss: 5.1955, val_MinusLogProbMetric: 5.1955

Epoch 406: val_loss did not improve from 5.18938
196/196 - 82s - loss: 5.1100 - MinusLogProbMetric: 5.1100 - val_loss: 5.1955 - val_MinusLogProbMetric: 5.1955 - lr: 8.3333e-05 - 82s/epoch - 421ms/step
Epoch 407/1000
2023-09-19 22:45:01.353 
Epoch 407/1000 
	 loss: 5.1071, MinusLogProbMetric: 5.1071, val_loss: 5.1988, val_MinusLogProbMetric: 5.1988

Epoch 407: val_loss did not improve from 5.18938
196/196 - 82s - loss: 5.1071 - MinusLogProbMetric: 5.1071 - val_loss: 5.1988 - val_MinusLogProbMetric: 5.1988 - lr: 8.3333e-05 - 82s/epoch - 418ms/step
Epoch 408/1000
2023-09-19 22:46:23.467 
Epoch 408/1000 
	 loss: 5.1093, MinusLogProbMetric: 5.1093, val_loss: 5.1952, val_MinusLogProbMetric: 5.1952

Epoch 408: val_loss did not improve from 5.18938
196/196 - 82s - loss: 5.1093 - MinusLogProbMetric: 5.1093 - val_loss: 5.1952 - val_MinusLogProbMetric: 5.1952 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 409/1000
2023-09-19 22:47:45.497 
Epoch 409/1000 
	 loss: 5.1117, MinusLogProbMetric: 5.1117, val_loss: 5.2051, val_MinusLogProbMetric: 5.2051

Epoch 409: val_loss did not improve from 5.18938
196/196 - 82s - loss: 5.1117 - MinusLogProbMetric: 5.1117 - val_loss: 5.2051 - val_MinusLogProbMetric: 5.2051 - lr: 8.3333e-05 - 82s/epoch - 418ms/step
Epoch 410/1000
2023-09-19 22:49:08.197 
Epoch 410/1000 
	 loss: 5.1132, MinusLogProbMetric: 5.1132, val_loss: 5.1936, val_MinusLogProbMetric: 5.1936

Epoch 410: val_loss did not improve from 5.18938
196/196 - 83s - loss: 5.1132 - MinusLogProbMetric: 5.1132 - val_loss: 5.1936 - val_MinusLogProbMetric: 5.1936 - lr: 8.3333e-05 - 83s/epoch - 422ms/step
Epoch 411/1000
2023-09-19 22:50:29.718 
Epoch 411/1000 
	 loss: 5.1123, MinusLogProbMetric: 5.1123, val_loss: 5.1999, val_MinusLogProbMetric: 5.1999

Epoch 411: val_loss did not improve from 5.18938
196/196 - 82s - loss: 5.1123 - MinusLogProbMetric: 5.1123 - val_loss: 5.1999 - val_MinusLogProbMetric: 5.1999 - lr: 8.3333e-05 - 82s/epoch - 416ms/step
Epoch 412/1000
2023-09-19 22:51:51.579 
Epoch 412/1000 
	 loss: 5.1107, MinusLogProbMetric: 5.1107, val_loss: 5.2037, val_MinusLogProbMetric: 5.2037

Epoch 412: val_loss did not improve from 5.18938
196/196 - 82s - loss: 5.1107 - MinusLogProbMetric: 5.1107 - val_loss: 5.2037 - val_MinusLogProbMetric: 5.2037 - lr: 8.3333e-05 - 82s/epoch - 418ms/step
Epoch 413/1000
2023-09-19 22:53:14.319 
Epoch 413/1000 
	 loss: 5.1072, MinusLogProbMetric: 5.1072, val_loss: 5.2008, val_MinusLogProbMetric: 5.2008

Epoch 413: val_loss did not improve from 5.18938
196/196 - 83s - loss: 5.1072 - MinusLogProbMetric: 5.1072 - val_loss: 5.2008 - val_MinusLogProbMetric: 5.2008 - lr: 8.3333e-05 - 83s/epoch - 422ms/step
Epoch 414/1000
2023-09-19 22:54:36.024 
Epoch 414/1000 
	 loss: 5.1088, MinusLogProbMetric: 5.1088, val_loss: 5.1971, val_MinusLogProbMetric: 5.1971

Epoch 414: val_loss did not improve from 5.18938
196/196 - 82s - loss: 5.1088 - MinusLogProbMetric: 5.1088 - val_loss: 5.1971 - val_MinusLogProbMetric: 5.1971 - lr: 8.3333e-05 - 82s/epoch - 417ms/step
Epoch 415/1000
2023-09-19 22:55:57.754 
Epoch 415/1000 
	 loss: 5.1143, MinusLogProbMetric: 5.1143, val_loss: 5.2385, val_MinusLogProbMetric: 5.2385

Epoch 415: val_loss did not improve from 5.18938
196/196 - 82s - loss: 5.1143 - MinusLogProbMetric: 5.1143 - val_loss: 5.2385 - val_MinusLogProbMetric: 5.2385 - lr: 8.3333e-05 - 82s/epoch - 417ms/step
Epoch 416/1000
2023-09-19 22:57:16.575 
Epoch 416/1000 
	 loss: 5.1125, MinusLogProbMetric: 5.1125, val_loss: 5.2010, val_MinusLogProbMetric: 5.2010

Epoch 416: val_loss did not improve from 5.18938
196/196 - 79s - loss: 5.1125 - MinusLogProbMetric: 5.1125 - val_loss: 5.2010 - val_MinusLogProbMetric: 5.2010 - lr: 8.3333e-05 - 79s/epoch - 402ms/step
Epoch 417/1000
2023-09-19 22:58:27.731 
Epoch 417/1000 
	 loss: 5.1084, MinusLogProbMetric: 5.1084, val_loss: 5.1943, val_MinusLogProbMetric: 5.1943

Epoch 417: val_loss did not improve from 5.18938
196/196 - 71s - loss: 5.1084 - MinusLogProbMetric: 5.1084 - val_loss: 5.1943 - val_MinusLogProbMetric: 5.1943 - lr: 8.3333e-05 - 71s/epoch - 363ms/step
Epoch 418/1000
2023-09-19 22:59:38.788 
Epoch 418/1000 
	 loss: 5.1118, MinusLogProbMetric: 5.1118, val_loss: 5.2336, val_MinusLogProbMetric: 5.2336

Epoch 418: val_loss did not improve from 5.18938
196/196 - 71s - loss: 5.1118 - MinusLogProbMetric: 5.1118 - val_loss: 5.2336 - val_MinusLogProbMetric: 5.2336 - lr: 8.3333e-05 - 71s/epoch - 363ms/step
Epoch 419/1000
2023-09-19 23:00:59.599 
Epoch 419/1000 
	 loss: 5.1112, MinusLogProbMetric: 5.1112, val_loss: 5.2029, val_MinusLogProbMetric: 5.2029

Epoch 419: val_loss did not improve from 5.18938
196/196 - 81s - loss: 5.1112 - MinusLogProbMetric: 5.1112 - val_loss: 5.2029 - val_MinusLogProbMetric: 5.2029 - lr: 8.3333e-05 - 81s/epoch - 412ms/step
Epoch 420/1000
2023-09-19 23:02:18.521 
Epoch 420/1000 
	 loss: 5.1062, MinusLogProbMetric: 5.1062, val_loss: 5.2046, val_MinusLogProbMetric: 5.2046

Epoch 420: val_loss did not improve from 5.18938
196/196 - 79s - loss: 5.1062 - MinusLogProbMetric: 5.1062 - val_loss: 5.2046 - val_MinusLogProbMetric: 5.2046 - lr: 8.3333e-05 - 79s/epoch - 403ms/step
Epoch 421/1000
2023-09-19 23:03:38.413 
Epoch 421/1000 
	 loss: 5.1101, MinusLogProbMetric: 5.1101, val_loss: 5.2020, val_MinusLogProbMetric: 5.2020

Epoch 421: val_loss did not improve from 5.18938
196/196 - 80s - loss: 5.1101 - MinusLogProbMetric: 5.1101 - val_loss: 5.2020 - val_MinusLogProbMetric: 5.2020 - lr: 8.3333e-05 - 80s/epoch - 408ms/step
Epoch 422/1000
2023-09-19 23:05:01.722 
Epoch 422/1000 
	 loss: 5.1107, MinusLogProbMetric: 5.1107, val_loss: 5.1890, val_MinusLogProbMetric: 5.1890

Epoch 422: val_loss improved from 5.18938 to 5.18900, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 85s - loss: 5.1107 - MinusLogProbMetric: 5.1107 - val_loss: 5.1890 - val_MinusLogProbMetric: 5.1890 - lr: 8.3333e-05 - 85s/epoch - 432ms/step
Epoch 423/1000
2023-09-19 23:06:23.444 
Epoch 423/1000 
	 loss: 5.1052, MinusLogProbMetric: 5.1052, val_loss: 5.2025, val_MinusLogProbMetric: 5.2025

Epoch 423: val_loss did not improve from 5.18900
196/196 - 80s - loss: 5.1052 - MinusLogProbMetric: 5.1052 - val_loss: 5.2025 - val_MinusLogProbMetric: 5.2025 - lr: 8.3333e-05 - 80s/epoch - 409ms/step
Epoch 424/1000
2023-09-19 23:07:44.158 
Epoch 424/1000 
	 loss: 5.1068, MinusLogProbMetric: 5.1068, val_loss: 5.1998, val_MinusLogProbMetric: 5.1998

Epoch 424: val_loss did not improve from 5.18900
196/196 - 81s - loss: 5.1068 - MinusLogProbMetric: 5.1068 - val_loss: 5.1998 - val_MinusLogProbMetric: 5.1998 - lr: 8.3333e-05 - 81s/epoch - 412ms/step
Epoch 425/1000
2023-09-19 23:09:06.915 
Epoch 425/1000 
	 loss: 5.1135, MinusLogProbMetric: 5.1135, val_loss: 5.1953, val_MinusLogProbMetric: 5.1953

Epoch 425: val_loss did not improve from 5.18900
196/196 - 83s - loss: 5.1135 - MinusLogProbMetric: 5.1135 - val_loss: 5.1953 - val_MinusLogProbMetric: 5.1953 - lr: 8.3333e-05 - 83s/epoch - 422ms/step
Epoch 426/1000
2023-09-19 23:10:28.709 
Epoch 426/1000 
	 loss: 5.1065, MinusLogProbMetric: 5.1065, val_loss: 5.2041, val_MinusLogProbMetric: 5.2041

Epoch 426: val_loss did not improve from 5.18900
196/196 - 82s - loss: 5.1065 - MinusLogProbMetric: 5.1065 - val_loss: 5.2041 - val_MinusLogProbMetric: 5.2041 - lr: 8.3333e-05 - 82s/epoch - 417ms/step
Epoch 427/1000
2023-09-19 23:11:47.305 
Epoch 427/1000 
	 loss: 5.1072, MinusLogProbMetric: 5.1072, val_loss: 5.1912, val_MinusLogProbMetric: 5.1912

Epoch 427: val_loss did not improve from 5.18900
196/196 - 79s - loss: 5.1072 - MinusLogProbMetric: 5.1072 - val_loss: 5.1912 - val_MinusLogProbMetric: 5.1912 - lr: 8.3333e-05 - 79s/epoch - 401ms/step
Epoch 428/1000
2023-09-19 23:13:09.462 
Epoch 428/1000 
	 loss: 5.1140, MinusLogProbMetric: 5.1140, val_loss: 5.2181, val_MinusLogProbMetric: 5.2181

Epoch 428: val_loss did not improve from 5.18900
196/196 - 82s - loss: 5.1140 - MinusLogProbMetric: 5.1140 - val_loss: 5.2181 - val_MinusLogProbMetric: 5.2181 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 429/1000
2023-09-19 23:14:31.665 
Epoch 429/1000 
	 loss: 5.1105, MinusLogProbMetric: 5.1105, val_loss: 5.1866, val_MinusLogProbMetric: 5.1866

Epoch 429: val_loss improved from 5.18900 to 5.18659, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 84s - loss: 5.1105 - MinusLogProbMetric: 5.1105 - val_loss: 5.1866 - val_MinusLogProbMetric: 5.1866 - lr: 8.3333e-05 - 84s/epoch - 427ms/step
Epoch 430/1000
2023-09-19 23:15:55.397 
Epoch 430/1000 
	 loss: 5.1090, MinusLogProbMetric: 5.1090, val_loss: 5.2046, val_MinusLogProbMetric: 5.2046

Epoch 430: val_loss did not improve from 5.18659
196/196 - 82s - loss: 5.1090 - MinusLogProbMetric: 5.1090 - val_loss: 5.2046 - val_MinusLogProbMetric: 5.2046 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 431/1000
2023-09-19 23:17:17.605 
Epoch 431/1000 
	 loss: 5.1104, MinusLogProbMetric: 5.1104, val_loss: 5.2149, val_MinusLogProbMetric: 5.2149

Epoch 431: val_loss did not improve from 5.18659
196/196 - 82s - loss: 5.1104 - MinusLogProbMetric: 5.1104 - val_loss: 5.2149 - val_MinusLogProbMetric: 5.2149 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 432/1000
2023-09-19 23:18:39.726 
Epoch 432/1000 
	 loss: 5.1064, MinusLogProbMetric: 5.1064, val_loss: 5.2010, val_MinusLogProbMetric: 5.2010

Epoch 432: val_loss did not improve from 5.18659
196/196 - 82s - loss: 5.1064 - MinusLogProbMetric: 5.1064 - val_loss: 5.2010 - val_MinusLogProbMetric: 5.2010 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 433/1000
2023-09-19 23:20:02.493 
Epoch 433/1000 
	 loss: 5.1094, MinusLogProbMetric: 5.1094, val_loss: 5.2195, val_MinusLogProbMetric: 5.2195

Epoch 433: val_loss did not improve from 5.18659
196/196 - 83s - loss: 5.1094 - MinusLogProbMetric: 5.1094 - val_loss: 5.2195 - val_MinusLogProbMetric: 5.2195 - lr: 8.3333e-05 - 83s/epoch - 422ms/step
Epoch 434/1000
2023-09-19 23:21:24.385 
Epoch 434/1000 
	 loss: 5.1084, MinusLogProbMetric: 5.1084, val_loss: 5.2087, val_MinusLogProbMetric: 5.2087

Epoch 434: val_loss did not improve from 5.18659
196/196 - 82s - loss: 5.1084 - MinusLogProbMetric: 5.1084 - val_loss: 5.2087 - val_MinusLogProbMetric: 5.2087 - lr: 8.3333e-05 - 82s/epoch - 418ms/step
Epoch 435/1000
2023-09-19 23:22:46.902 
Epoch 435/1000 
	 loss: 5.1119, MinusLogProbMetric: 5.1119, val_loss: 5.2420, val_MinusLogProbMetric: 5.2420

Epoch 435: val_loss did not improve from 5.18659
196/196 - 83s - loss: 5.1119 - MinusLogProbMetric: 5.1119 - val_loss: 5.2420 - val_MinusLogProbMetric: 5.2420 - lr: 8.3333e-05 - 83s/epoch - 421ms/step
Epoch 436/1000
2023-09-19 23:24:09.449 
Epoch 436/1000 
	 loss: 5.1112, MinusLogProbMetric: 5.1112, val_loss: 5.1943, val_MinusLogProbMetric: 5.1943

Epoch 436: val_loss did not improve from 5.18659
196/196 - 83s - loss: 5.1112 - MinusLogProbMetric: 5.1112 - val_loss: 5.1943 - val_MinusLogProbMetric: 5.1943 - lr: 8.3333e-05 - 83s/epoch - 421ms/step
Epoch 437/1000
2023-09-19 23:25:31.106 
Epoch 437/1000 
	 loss: 5.1091, MinusLogProbMetric: 5.1091, val_loss: 5.2073, val_MinusLogProbMetric: 5.2073

Epoch 437: val_loss did not improve from 5.18659
196/196 - 82s - loss: 5.1091 - MinusLogProbMetric: 5.1091 - val_loss: 5.2073 - val_MinusLogProbMetric: 5.2073 - lr: 8.3333e-05 - 82s/epoch - 417ms/step
Epoch 438/1000
2023-09-19 23:26:53.566 
Epoch 438/1000 
	 loss: 5.1092, MinusLogProbMetric: 5.1092, val_loss: 5.1815, val_MinusLogProbMetric: 5.1815

Epoch 438: val_loss improved from 5.18659 to 5.18146, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 84s - loss: 5.1092 - MinusLogProbMetric: 5.1092 - val_loss: 5.1815 - val_MinusLogProbMetric: 5.1815 - lr: 8.3333e-05 - 84s/epoch - 429ms/step
Epoch 439/1000
2023-09-19 23:28:17.428 
Epoch 439/1000 
	 loss: 5.1062, MinusLogProbMetric: 5.1062, val_loss: 5.1897, val_MinusLogProbMetric: 5.1897

Epoch 439: val_loss did not improve from 5.18146
196/196 - 82s - loss: 5.1062 - MinusLogProbMetric: 5.1062 - val_loss: 5.1897 - val_MinusLogProbMetric: 5.1897 - lr: 8.3333e-05 - 82s/epoch - 420ms/step
Epoch 440/1000
2023-09-19 23:29:38.949 
Epoch 440/1000 
	 loss: 5.1060, MinusLogProbMetric: 5.1060, val_loss: 5.1996, val_MinusLogProbMetric: 5.1996

Epoch 440: val_loss did not improve from 5.18146
196/196 - 82s - loss: 5.1060 - MinusLogProbMetric: 5.1060 - val_loss: 5.1996 - val_MinusLogProbMetric: 5.1996 - lr: 8.3333e-05 - 82s/epoch - 416ms/step
Epoch 441/1000
2023-09-19 23:31:00.215 
Epoch 441/1000 
	 loss: 5.1109, MinusLogProbMetric: 5.1109, val_loss: 5.1988, val_MinusLogProbMetric: 5.1988

Epoch 441: val_loss did not improve from 5.18146
196/196 - 81s - loss: 5.1109 - MinusLogProbMetric: 5.1109 - val_loss: 5.1988 - val_MinusLogProbMetric: 5.1988 - lr: 8.3333e-05 - 81s/epoch - 415ms/step
Epoch 442/1000
2023-09-19 23:32:21.607 
Epoch 442/1000 
	 loss: 5.1055, MinusLogProbMetric: 5.1055, val_loss: 5.2189, val_MinusLogProbMetric: 5.2189

Epoch 442: val_loss did not improve from 5.18146
196/196 - 81s - loss: 5.1055 - MinusLogProbMetric: 5.1055 - val_loss: 5.2189 - val_MinusLogProbMetric: 5.2189 - lr: 8.3333e-05 - 81s/epoch - 415ms/step
Epoch 443/1000
2023-09-19 23:33:42.983 
Epoch 443/1000 
	 loss: 5.1031, MinusLogProbMetric: 5.1031, val_loss: 5.2015, val_MinusLogProbMetric: 5.2015

Epoch 443: val_loss did not improve from 5.18146
196/196 - 81s - loss: 5.1031 - MinusLogProbMetric: 5.1031 - val_loss: 5.2015 - val_MinusLogProbMetric: 5.2015 - lr: 8.3333e-05 - 81s/epoch - 415ms/step
Epoch 444/1000
2023-09-19 23:35:05.244 
Epoch 444/1000 
	 loss: 5.1037, MinusLogProbMetric: 5.1037, val_loss: 5.1909, val_MinusLogProbMetric: 5.1909

Epoch 444: val_loss did not improve from 5.18146
196/196 - 82s - loss: 5.1037 - MinusLogProbMetric: 5.1037 - val_loss: 5.1909 - val_MinusLogProbMetric: 5.1909 - lr: 8.3333e-05 - 82s/epoch - 420ms/step
Epoch 445/1000
2023-09-19 23:36:27.572 
Epoch 445/1000 
	 loss: 5.1079, MinusLogProbMetric: 5.1079, val_loss: 5.2063, val_MinusLogProbMetric: 5.2063

Epoch 445: val_loss did not improve from 5.18146
196/196 - 82s - loss: 5.1079 - MinusLogProbMetric: 5.1079 - val_loss: 5.2063 - val_MinusLogProbMetric: 5.2063 - lr: 8.3333e-05 - 82s/epoch - 420ms/step
Epoch 446/1000
2023-09-19 23:37:49.642 
Epoch 446/1000 
	 loss: 5.1061, MinusLogProbMetric: 5.1061, val_loss: 5.1921, val_MinusLogProbMetric: 5.1921

Epoch 446: val_loss did not improve from 5.18146
196/196 - 82s - loss: 5.1061 - MinusLogProbMetric: 5.1061 - val_loss: 5.1921 - val_MinusLogProbMetric: 5.1921 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 447/1000
2023-09-19 23:39:11.910 
Epoch 447/1000 
	 loss: 5.1087, MinusLogProbMetric: 5.1087, val_loss: 5.2115, val_MinusLogProbMetric: 5.2115

Epoch 447: val_loss did not improve from 5.18146
196/196 - 82s - loss: 5.1087 - MinusLogProbMetric: 5.1087 - val_loss: 5.2115 - val_MinusLogProbMetric: 5.2115 - lr: 8.3333e-05 - 82s/epoch - 420ms/step
Epoch 448/1000
2023-09-19 23:40:33.864 
Epoch 448/1000 
	 loss: 5.1070, MinusLogProbMetric: 5.1070, val_loss: 5.1831, val_MinusLogProbMetric: 5.1831

Epoch 448: val_loss did not improve from 5.18146
196/196 - 82s - loss: 5.1070 - MinusLogProbMetric: 5.1070 - val_loss: 5.1831 - val_MinusLogProbMetric: 5.1831 - lr: 8.3333e-05 - 82s/epoch - 418ms/step
Epoch 449/1000
2023-09-19 23:41:55.325 
Epoch 449/1000 
	 loss: 5.1068, MinusLogProbMetric: 5.1068, val_loss: 5.1926, val_MinusLogProbMetric: 5.1926

Epoch 449: val_loss did not improve from 5.18146
196/196 - 81s - loss: 5.1068 - MinusLogProbMetric: 5.1068 - val_loss: 5.1926 - val_MinusLogProbMetric: 5.1926 - lr: 8.3333e-05 - 81s/epoch - 416ms/step
Epoch 450/1000
2023-09-19 23:43:16.660 
Epoch 450/1000 
	 loss: 5.1059, MinusLogProbMetric: 5.1059, val_loss: 5.2130, val_MinusLogProbMetric: 5.2130

Epoch 450: val_loss did not improve from 5.18146
196/196 - 81s - loss: 5.1059 - MinusLogProbMetric: 5.1059 - val_loss: 5.2130 - val_MinusLogProbMetric: 5.2130 - lr: 8.3333e-05 - 81s/epoch - 415ms/step
Epoch 451/1000
2023-09-19 23:44:38.687 
Epoch 451/1000 
	 loss: 5.1065, MinusLogProbMetric: 5.1065, val_loss: 5.1952, val_MinusLogProbMetric: 5.1952

Epoch 451: val_loss did not improve from 5.18146
196/196 - 82s - loss: 5.1065 - MinusLogProbMetric: 5.1065 - val_loss: 5.1952 - val_MinusLogProbMetric: 5.1952 - lr: 8.3333e-05 - 82s/epoch - 418ms/step
Epoch 452/1000
2023-09-19 23:46:00.737 
Epoch 452/1000 
	 loss: 5.1069, MinusLogProbMetric: 5.1069, val_loss: 5.1956, val_MinusLogProbMetric: 5.1956

Epoch 452: val_loss did not improve from 5.18146
196/196 - 82s - loss: 5.1069 - MinusLogProbMetric: 5.1069 - val_loss: 5.1956 - val_MinusLogProbMetric: 5.1956 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 453/1000
2023-09-19 23:47:22.424 
Epoch 453/1000 
	 loss: 5.1075, MinusLogProbMetric: 5.1075, val_loss: 5.1882, val_MinusLogProbMetric: 5.1882

Epoch 453: val_loss did not improve from 5.18146
196/196 - 82s - loss: 5.1075 - MinusLogProbMetric: 5.1075 - val_loss: 5.1882 - val_MinusLogProbMetric: 5.1882 - lr: 8.3333e-05 - 82s/epoch - 417ms/step
Epoch 454/1000
2023-09-19 23:48:44.479 
Epoch 454/1000 
	 loss: 5.1088, MinusLogProbMetric: 5.1088, val_loss: 5.1951, val_MinusLogProbMetric: 5.1951

Epoch 454: val_loss did not improve from 5.18146
196/196 - 82s - loss: 5.1088 - MinusLogProbMetric: 5.1088 - val_loss: 5.1951 - val_MinusLogProbMetric: 5.1951 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 455/1000
2023-09-19 23:50:06.153 
Epoch 455/1000 
	 loss: 5.1063, MinusLogProbMetric: 5.1063, val_loss: 5.2032, val_MinusLogProbMetric: 5.2032

Epoch 455: val_loss did not improve from 5.18146
196/196 - 82s - loss: 5.1063 - MinusLogProbMetric: 5.1063 - val_loss: 5.2032 - val_MinusLogProbMetric: 5.2032 - lr: 8.3333e-05 - 82s/epoch - 417ms/step
Epoch 456/1000
2023-09-19 23:51:29.068 
Epoch 456/1000 
	 loss: 5.1032, MinusLogProbMetric: 5.1032, val_loss: 5.2102, val_MinusLogProbMetric: 5.2102

Epoch 456: val_loss did not improve from 5.18146
196/196 - 83s - loss: 5.1032 - MinusLogProbMetric: 5.1032 - val_loss: 5.2102 - val_MinusLogProbMetric: 5.2102 - lr: 8.3333e-05 - 83s/epoch - 423ms/step
Epoch 457/1000
2023-09-19 23:52:51.201 
Epoch 457/1000 
	 loss: 5.1062, MinusLogProbMetric: 5.1062, val_loss: 5.2067, val_MinusLogProbMetric: 5.2067

Epoch 457: val_loss did not improve from 5.18146
196/196 - 82s - loss: 5.1062 - MinusLogProbMetric: 5.1062 - val_loss: 5.2067 - val_MinusLogProbMetric: 5.2067 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 458/1000
2023-09-19 23:54:12.772 
Epoch 458/1000 
	 loss: 5.1033, MinusLogProbMetric: 5.1033, val_loss: 5.2276, val_MinusLogProbMetric: 5.2276

Epoch 458: val_loss did not improve from 5.18146
196/196 - 82s - loss: 5.1033 - MinusLogProbMetric: 5.1033 - val_loss: 5.2276 - val_MinusLogProbMetric: 5.2276 - lr: 8.3333e-05 - 82s/epoch - 416ms/step
Epoch 459/1000
2023-09-19 23:55:34.128 
Epoch 459/1000 
	 loss: 5.1105, MinusLogProbMetric: 5.1105, val_loss: 5.1811, val_MinusLogProbMetric: 5.1811

Epoch 459: val_loss improved from 5.18146 to 5.18111, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 5.1105 - MinusLogProbMetric: 5.1105 - val_loss: 5.1811 - val_MinusLogProbMetric: 5.1811 - lr: 8.3333e-05 - 83s/epoch - 423ms/step
Epoch 460/1000
2023-09-19 23:56:57.468 
Epoch 460/1000 
	 loss: 5.1034, MinusLogProbMetric: 5.1034, val_loss: 5.1956, val_MinusLogProbMetric: 5.1956

Epoch 460: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1034 - MinusLogProbMetric: 5.1034 - val_loss: 5.1956 - val_MinusLogProbMetric: 5.1956 - lr: 8.3333e-05 - 82s/epoch - 418ms/step
Epoch 461/1000
2023-09-19 23:58:19.918 
Epoch 461/1000 
	 loss: 5.1064, MinusLogProbMetric: 5.1064, val_loss: 5.1929, val_MinusLogProbMetric: 5.1929

Epoch 461: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1064 - MinusLogProbMetric: 5.1064 - val_loss: 5.1929 - val_MinusLogProbMetric: 5.1929 - lr: 8.3333e-05 - 82s/epoch - 421ms/step
Epoch 462/1000
2023-09-19 23:59:42.184 
Epoch 462/1000 
	 loss: 5.1030, MinusLogProbMetric: 5.1030, val_loss: 5.2045, val_MinusLogProbMetric: 5.2045

Epoch 462: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1030 - MinusLogProbMetric: 5.1030 - val_loss: 5.2045 - val_MinusLogProbMetric: 5.2045 - lr: 8.3333e-05 - 82s/epoch - 420ms/step
Epoch 463/1000
2023-09-20 00:01:04.775 
Epoch 463/1000 
	 loss: 5.1075, MinusLogProbMetric: 5.1075, val_loss: 5.2006, val_MinusLogProbMetric: 5.2006

Epoch 463: val_loss did not improve from 5.18111
196/196 - 83s - loss: 5.1075 - MinusLogProbMetric: 5.1075 - val_loss: 5.2006 - val_MinusLogProbMetric: 5.2006 - lr: 8.3333e-05 - 83s/epoch - 421ms/step
Epoch 464/1000
2023-09-20 00:02:27.134 
Epoch 464/1000 
	 loss: 5.1046, MinusLogProbMetric: 5.1046, val_loss: 5.2079, val_MinusLogProbMetric: 5.2079

Epoch 464: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1046 - MinusLogProbMetric: 5.1046 - val_loss: 5.2079 - val_MinusLogProbMetric: 5.2079 - lr: 8.3333e-05 - 82s/epoch - 420ms/step
Epoch 465/1000
2023-09-20 00:03:49.532 
Epoch 465/1000 
	 loss: 5.1099, MinusLogProbMetric: 5.1099, val_loss: 5.1894, val_MinusLogProbMetric: 5.1894

Epoch 465: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1099 - MinusLogProbMetric: 5.1099 - val_loss: 5.1894 - val_MinusLogProbMetric: 5.1894 - lr: 8.3333e-05 - 82s/epoch - 420ms/step
Epoch 466/1000
2023-09-20 00:05:11.778 
Epoch 466/1000 
	 loss: 5.1048, MinusLogProbMetric: 5.1048, val_loss: 5.2500, val_MinusLogProbMetric: 5.2500

Epoch 466: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1048 - MinusLogProbMetric: 5.1048 - val_loss: 5.2500 - val_MinusLogProbMetric: 5.2500 - lr: 8.3333e-05 - 82s/epoch - 420ms/step
Epoch 467/1000
2023-09-20 00:06:33.717 
Epoch 467/1000 
	 loss: 5.1082, MinusLogProbMetric: 5.1082, val_loss: 5.1968, val_MinusLogProbMetric: 5.1968

Epoch 467: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1082 - MinusLogProbMetric: 5.1082 - val_loss: 5.1968 - val_MinusLogProbMetric: 5.1968 - lr: 8.3333e-05 - 82s/epoch - 418ms/step
Epoch 468/1000
2023-09-20 00:07:55.532 
Epoch 468/1000 
	 loss: 5.0994, MinusLogProbMetric: 5.0994, val_loss: 5.1911, val_MinusLogProbMetric: 5.1911

Epoch 468: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.0994 - MinusLogProbMetric: 5.0994 - val_loss: 5.1911 - val_MinusLogProbMetric: 5.1911 - lr: 8.3333e-05 - 82s/epoch - 417ms/step
Epoch 469/1000
2023-09-20 00:09:18.053 
Epoch 469/1000 
	 loss: 5.1052, MinusLogProbMetric: 5.1052, val_loss: 5.1853, val_MinusLogProbMetric: 5.1853

Epoch 469: val_loss did not improve from 5.18111
196/196 - 83s - loss: 5.1052 - MinusLogProbMetric: 5.1052 - val_loss: 5.1853 - val_MinusLogProbMetric: 5.1853 - lr: 8.3333e-05 - 83s/epoch - 421ms/step
Epoch 470/1000
2023-09-20 00:10:40.167 
Epoch 470/1000 
	 loss: 5.1021, MinusLogProbMetric: 5.1021, val_loss: 5.1854, val_MinusLogProbMetric: 5.1854

Epoch 470: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1021 - MinusLogProbMetric: 5.1021 - val_loss: 5.1854 - val_MinusLogProbMetric: 5.1854 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 471/1000
2023-09-20 00:12:01.105 
Epoch 471/1000 
	 loss: 5.1025, MinusLogProbMetric: 5.1025, val_loss: 5.2135, val_MinusLogProbMetric: 5.2135

Epoch 471: val_loss did not improve from 5.18111
196/196 - 81s - loss: 5.1025 - MinusLogProbMetric: 5.1025 - val_loss: 5.2135 - val_MinusLogProbMetric: 5.2135 - lr: 8.3333e-05 - 81s/epoch - 413ms/step
Epoch 472/1000
2023-09-20 00:13:18.846 
Epoch 472/1000 
	 loss: 5.1024, MinusLogProbMetric: 5.1024, val_loss: 5.2025, val_MinusLogProbMetric: 5.2025

Epoch 472: val_loss did not improve from 5.18111
196/196 - 78s - loss: 5.1024 - MinusLogProbMetric: 5.1024 - val_loss: 5.2025 - val_MinusLogProbMetric: 5.2025 - lr: 8.3333e-05 - 78s/epoch - 397ms/step
Epoch 473/1000
2023-09-20 00:14:31.462 
Epoch 473/1000 
	 loss: 5.1069, MinusLogProbMetric: 5.1069, val_loss: 5.1934, val_MinusLogProbMetric: 5.1934

Epoch 473: val_loss did not improve from 5.18111
196/196 - 73s - loss: 5.1069 - MinusLogProbMetric: 5.1069 - val_loss: 5.1934 - val_MinusLogProbMetric: 5.1934 - lr: 8.3333e-05 - 73s/epoch - 370ms/step
Epoch 474/1000
2023-09-20 00:15:51.558 
Epoch 474/1000 
	 loss: 5.1045, MinusLogProbMetric: 5.1045, val_loss: 5.2172, val_MinusLogProbMetric: 5.2172

Epoch 474: val_loss did not improve from 5.18111
196/196 - 80s - loss: 5.1045 - MinusLogProbMetric: 5.1045 - val_loss: 5.2172 - val_MinusLogProbMetric: 5.2172 - lr: 8.3333e-05 - 80s/epoch - 409ms/step
Epoch 475/1000
2023-09-20 00:17:06.615 
Epoch 475/1000 
	 loss: 5.1054, MinusLogProbMetric: 5.1054, val_loss: 5.1941, val_MinusLogProbMetric: 5.1941

Epoch 475: val_loss did not improve from 5.18111
196/196 - 75s - loss: 5.1054 - MinusLogProbMetric: 5.1054 - val_loss: 5.1941 - val_MinusLogProbMetric: 5.1941 - lr: 8.3333e-05 - 75s/epoch - 383ms/step
Epoch 476/1000
2023-09-20 00:18:29.567 
Epoch 476/1000 
	 loss: 5.1007, MinusLogProbMetric: 5.1007, val_loss: 5.2006, val_MinusLogProbMetric: 5.2006

Epoch 476: val_loss did not improve from 5.18111
196/196 - 83s - loss: 5.1007 - MinusLogProbMetric: 5.1007 - val_loss: 5.2006 - val_MinusLogProbMetric: 5.2006 - lr: 8.3333e-05 - 83s/epoch - 423ms/step
Epoch 477/1000
2023-09-20 00:19:51.814 
Epoch 477/1000 
	 loss: 5.1046, MinusLogProbMetric: 5.1046, val_loss: 5.1873, val_MinusLogProbMetric: 5.1873

Epoch 477: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1046 - MinusLogProbMetric: 5.1046 - val_loss: 5.1873 - val_MinusLogProbMetric: 5.1873 - lr: 8.3333e-05 - 82s/epoch - 420ms/step
Epoch 478/1000
2023-09-20 00:21:13.111 
Epoch 478/1000 
	 loss: 5.1055, MinusLogProbMetric: 5.1055, val_loss: 5.2127, val_MinusLogProbMetric: 5.2127

Epoch 478: val_loss did not improve from 5.18111
196/196 - 81s - loss: 5.1055 - MinusLogProbMetric: 5.1055 - val_loss: 5.2127 - val_MinusLogProbMetric: 5.2127 - lr: 8.3333e-05 - 81s/epoch - 415ms/step
Epoch 479/1000
2023-09-20 00:22:35.094 
Epoch 479/1000 
	 loss: 5.1058, MinusLogProbMetric: 5.1058, val_loss: 5.1854, val_MinusLogProbMetric: 5.1854

Epoch 479: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1058 - MinusLogProbMetric: 5.1058 - val_loss: 5.1854 - val_MinusLogProbMetric: 5.1854 - lr: 8.3333e-05 - 82s/epoch - 418ms/step
Epoch 480/1000
2023-09-20 00:23:58.030 
Epoch 480/1000 
	 loss: 5.1061, MinusLogProbMetric: 5.1061, val_loss: 5.1872, val_MinusLogProbMetric: 5.1872

Epoch 480: val_loss did not improve from 5.18111
196/196 - 83s - loss: 5.1061 - MinusLogProbMetric: 5.1061 - val_loss: 5.1872 - val_MinusLogProbMetric: 5.1872 - lr: 8.3333e-05 - 83s/epoch - 423ms/step
Epoch 481/1000
2023-09-20 00:25:20.637 
Epoch 481/1000 
	 loss: 5.1012, MinusLogProbMetric: 5.1012, val_loss: 5.1876, val_MinusLogProbMetric: 5.1876

Epoch 481: val_loss did not improve from 5.18111
196/196 - 83s - loss: 5.1012 - MinusLogProbMetric: 5.1012 - val_loss: 5.1876 - val_MinusLogProbMetric: 5.1876 - lr: 8.3333e-05 - 83s/epoch - 421ms/step
Epoch 482/1000
2023-09-20 00:26:42.259 
Epoch 482/1000 
	 loss: 5.1029, MinusLogProbMetric: 5.1029, val_loss: 5.2283, val_MinusLogProbMetric: 5.2283

Epoch 482: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1029 - MinusLogProbMetric: 5.1029 - val_loss: 5.2283 - val_MinusLogProbMetric: 5.2283 - lr: 8.3333e-05 - 82s/epoch - 416ms/step
Epoch 483/1000
2023-09-20 00:28:04.359 
Epoch 483/1000 
	 loss: 5.1029, MinusLogProbMetric: 5.1029, val_loss: 5.1948, val_MinusLogProbMetric: 5.1948

Epoch 483: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1029 - MinusLogProbMetric: 5.1029 - val_loss: 5.1948 - val_MinusLogProbMetric: 5.1948 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 484/1000
2023-09-20 00:29:26.633 
Epoch 484/1000 
	 loss: 5.1077, MinusLogProbMetric: 5.1077, val_loss: 5.2008, val_MinusLogProbMetric: 5.2008

Epoch 484: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1077 - MinusLogProbMetric: 5.1077 - val_loss: 5.2008 - val_MinusLogProbMetric: 5.2008 - lr: 8.3333e-05 - 82s/epoch - 420ms/step
Epoch 485/1000
2023-09-20 00:30:48.697 
Epoch 485/1000 
	 loss: 5.1052, MinusLogProbMetric: 5.1052, val_loss: 5.1980, val_MinusLogProbMetric: 5.1980

Epoch 485: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1052 - MinusLogProbMetric: 5.1052 - val_loss: 5.1980 - val_MinusLogProbMetric: 5.1980 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 486/1000
2023-09-20 00:32:11.116 
Epoch 486/1000 
	 loss: 5.1026, MinusLogProbMetric: 5.1026, val_loss: 5.2027, val_MinusLogProbMetric: 5.2027

Epoch 486: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1026 - MinusLogProbMetric: 5.1026 - val_loss: 5.2027 - val_MinusLogProbMetric: 5.2027 - lr: 8.3333e-05 - 82s/epoch - 421ms/step
Epoch 487/1000
2023-09-20 00:33:33.544 
Epoch 487/1000 
	 loss: 5.1020, MinusLogProbMetric: 5.1020, val_loss: 5.1968, val_MinusLogProbMetric: 5.1968

Epoch 487: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1020 - MinusLogProbMetric: 5.1020 - val_loss: 5.1968 - val_MinusLogProbMetric: 5.1968 - lr: 8.3333e-05 - 82s/epoch - 421ms/step
Epoch 488/1000
2023-09-20 00:34:55.363 
Epoch 488/1000 
	 loss: 5.1054, MinusLogProbMetric: 5.1054, val_loss: 5.1979, val_MinusLogProbMetric: 5.1979

Epoch 488: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1054 - MinusLogProbMetric: 5.1054 - val_loss: 5.1979 - val_MinusLogProbMetric: 5.1979 - lr: 8.3333e-05 - 82s/epoch - 417ms/step
Epoch 489/1000
2023-09-20 00:36:17.307 
Epoch 489/1000 
	 loss: 5.1057, MinusLogProbMetric: 5.1057, val_loss: 5.1946, val_MinusLogProbMetric: 5.1946

Epoch 489: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1057 - MinusLogProbMetric: 5.1057 - val_loss: 5.1946 - val_MinusLogProbMetric: 5.1946 - lr: 8.3333e-05 - 82s/epoch - 418ms/step
Epoch 490/1000
2023-09-20 00:37:39.430 
Epoch 490/1000 
	 loss: 5.1029, MinusLogProbMetric: 5.1029, val_loss: 5.2144, val_MinusLogProbMetric: 5.2144

Epoch 490: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1029 - MinusLogProbMetric: 5.1029 - val_loss: 5.2144 - val_MinusLogProbMetric: 5.2144 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 491/1000
2023-09-20 00:39:01.238 
Epoch 491/1000 
	 loss: 5.1054, MinusLogProbMetric: 5.1054, val_loss: 5.2069, val_MinusLogProbMetric: 5.2069

Epoch 491: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1054 - MinusLogProbMetric: 5.1054 - val_loss: 5.2069 - val_MinusLogProbMetric: 5.2069 - lr: 8.3333e-05 - 82s/epoch - 417ms/step
Epoch 492/1000
2023-09-20 00:40:22.551 
Epoch 492/1000 
	 loss: 5.1051, MinusLogProbMetric: 5.1051, val_loss: 5.2094, val_MinusLogProbMetric: 5.2094

Epoch 492: val_loss did not improve from 5.18111
196/196 - 81s - loss: 5.1051 - MinusLogProbMetric: 5.1051 - val_loss: 5.2094 - val_MinusLogProbMetric: 5.2094 - lr: 8.3333e-05 - 81s/epoch - 415ms/step
Epoch 493/1000
2023-09-20 00:41:44.872 
Epoch 493/1000 
	 loss: 5.1069, MinusLogProbMetric: 5.1069, val_loss: 5.2114, val_MinusLogProbMetric: 5.2114

Epoch 493: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1069 - MinusLogProbMetric: 5.1069 - val_loss: 5.2114 - val_MinusLogProbMetric: 5.2114 - lr: 8.3333e-05 - 82s/epoch - 420ms/step
Epoch 494/1000
2023-09-20 00:43:06.975 
Epoch 494/1000 
	 loss: 5.1064, MinusLogProbMetric: 5.1064, val_loss: 5.1894, val_MinusLogProbMetric: 5.1894

Epoch 494: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1064 - MinusLogProbMetric: 5.1064 - val_loss: 5.1894 - val_MinusLogProbMetric: 5.1894 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 495/1000
2023-09-20 00:44:29.106 
Epoch 495/1000 
	 loss: 5.1066, MinusLogProbMetric: 5.1066, val_loss: 5.1977, val_MinusLogProbMetric: 5.1977

Epoch 495: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1066 - MinusLogProbMetric: 5.1066 - val_loss: 5.1977 - val_MinusLogProbMetric: 5.1977 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 496/1000
2023-09-20 00:45:50.420 
Epoch 496/1000 
	 loss: 5.1047, MinusLogProbMetric: 5.1047, val_loss: 5.2238, val_MinusLogProbMetric: 5.2238

Epoch 496: val_loss did not improve from 5.18111
196/196 - 81s - loss: 5.1047 - MinusLogProbMetric: 5.1047 - val_loss: 5.2238 - val_MinusLogProbMetric: 5.2238 - lr: 8.3333e-05 - 81s/epoch - 415ms/step
Epoch 497/1000
2023-09-20 00:47:12.078 
Epoch 497/1000 
	 loss: 5.1033, MinusLogProbMetric: 5.1033, val_loss: 5.1976, val_MinusLogProbMetric: 5.1976

Epoch 497: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1033 - MinusLogProbMetric: 5.1033 - val_loss: 5.1976 - val_MinusLogProbMetric: 5.1976 - lr: 8.3333e-05 - 82s/epoch - 417ms/step
Epoch 498/1000
2023-09-20 00:48:34.287 
Epoch 498/1000 
	 loss: 5.1004, MinusLogProbMetric: 5.1004, val_loss: 5.2021, val_MinusLogProbMetric: 5.2021

Epoch 498: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1004 - MinusLogProbMetric: 5.1004 - val_loss: 5.2021 - val_MinusLogProbMetric: 5.2021 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 499/1000
2023-09-20 00:49:56.282 
Epoch 499/1000 
	 loss: 5.0984, MinusLogProbMetric: 5.0984, val_loss: 5.2180, val_MinusLogProbMetric: 5.2180

Epoch 499: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.0984 - MinusLogProbMetric: 5.0984 - val_loss: 5.2180 - val_MinusLogProbMetric: 5.2180 - lr: 8.3333e-05 - 82s/epoch - 418ms/step
Epoch 500/1000
2023-09-20 00:51:18.336 
Epoch 500/1000 
	 loss: 5.1051, MinusLogProbMetric: 5.1051, val_loss: 5.1853, val_MinusLogProbMetric: 5.1853

Epoch 500: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1051 - MinusLogProbMetric: 5.1051 - val_loss: 5.1853 - val_MinusLogProbMetric: 5.1853 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 501/1000
2023-09-20 00:52:40.765 
Epoch 501/1000 
	 loss: 5.1047, MinusLogProbMetric: 5.1047, val_loss: 5.1967, val_MinusLogProbMetric: 5.1967

Epoch 501: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1047 - MinusLogProbMetric: 5.1047 - val_loss: 5.1967 - val_MinusLogProbMetric: 5.1967 - lr: 8.3333e-05 - 82s/epoch - 421ms/step
Epoch 502/1000
2023-09-20 00:54:02.870 
Epoch 502/1000 
	 loss: 5.1017, MinusLogProbMetric: 5.1017, val_loss: 5.1943, val_MinusLogProbMetric: 5.1943

Epoch 502: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1017 - MinusLogProbMetric: 5.1017 - val_loss: 5.1943 - val_MinusLogProbMetric: 5.1943 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 503/1000
2023-09-20 00:55:25.343 
Epoch 503/1000 
	 loss: 5.1069, MinusLogProbMetric: 5.1069, val_loss: 5.2103, val_MinusLogProbMetric: 5.2103

Epoch 503: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1069 - MinusLogProbMetric: 5.1069 - val_loss: 5.2103 - val_MinusLogProbMetric: 5.2103 - lr: 8.3333e-05 - 82s/epoch - 421ms/step
Epoch 504/1000
2023-09-20 00:56:46.753 
Epoch 504/1000 
	 loss: 5.1015, MinusLogProbMetric: 5.1015, val_loss: 5.2091, val_MinusLogProbMetric: 5.2091

Epoch 504: val_loss did not improve from 5.18111
196/196 - 81s - loss: 5.1015 - MinusLogProbMetric: 5.1015 - val_loss: 5.2091 - val_MinusLogProbMetric: 5.2091 - lr: 8.3333e-05 - 81s/epoch - 415ms/step
Epoch 505/1000
2023-09-20 00:58:08.975 
Epoch 505/1000 
	 loss: 5.1051, MinusLogProbMetric: 5.1051, val_loss: 5.1937, val_MinusLogProbMetric: 5.1937

Epoch 505: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1051 - MinusLogProbMetric: 5.1051 - val_loss: 5.1937 - val_MinusLogProbMetric: 5.1937 - lr: 8.3333e-05 - 82s/epoch - 419ms/step
Epoch 506/1000
2023-09-20 00:59:31.315 
Epoch 506/1000 
	 loss: 5.1021, MinusLogProbMetric: 5.1021, val_loss: 5.2482, val_MinusLogProbMetric: 5.2482

Epoch 506: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1021 - MinusLogProbMetric: 5.1021 - val_loss: 5.2482 - val_MinusLogProbMetric: 5.2482 - lr: 8.3333e-05 - 82s/epoch - 420ms/step
Epoch 507/1000
2023-09-20 01:00:52.087 
Epoch 507/1000 
	 loss: 5.1067, MinusLogProbMetric: 5.1067, val_loss: 5.1995, val_MinusLogProbMetric: 5.1995

Epoch 507: val_loss did not improve from 5.18111
196/196 - 81s - loss: 5.1067 - MinusLogProbMetric: 5.1067 - val_loss: 5.1995 - val_MinusLogProbMetric: 5.1995 - lr: 8.3333e-05 - 81s/epoch - 412ms/step
Epoch 508/1000
2023-09-20 01:02:13.774 
Epoch 508/1000 
	 loss: 5.1039, MinusLogProbMetric: 5.1039, val_loss: 5.2130, val_MinusLogProbMetric: 5.2130

Epoch 508: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1039 - MinusLogProbMetric: 5.1039 - val_loss: 5.2130 - val_MinusLogProbMetric: 5.2130 - lr: 8.3333e-05 - 82s/epoch - 417ms/step
Epoch 509/1000
2023-09-20 01:03:35.327 
Epoch 509/1000 
	 loss: 5.1034, MinusLogProbMetric: 5.1034, val_loss: 5.2123, val_MinusLogProbMetric: 5.2123

Epoch 509: val_loss did not improve from 5.18111
196/196 - 82s - loss: 5.1034 - MinusLogProbMetric: 5.1034 - val_loss: 5.2123 - val_MinusLogProbMetric: 5.2123 - lr: 8.3333e-05 - 82s/epoch - 416ms/step
Epoch 510/1000
2023-09-20 01:04:56.039 
Epoch 510/1000 
	 loss: 5.0850, MinusLogProbMetric: 5.0850, val_loss: 5.1767, val_MinusLogProbMetric: 5.1767

Epoch 510: val_loss improved from 5.18111 to 5.17669, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 5.0850 - MinusLogProbMetric: 5.0850 - val_loss: 5.1767 - val_MinusLogProbMetric: 5.1767 - lr: 4.1667e-05 - 83s/epoch - 422ms/step
Epoch 511/1000
2023-09-20 01:06:19.968 
Epoch 511/1000 
	 loss: 5.0872, MinusLogProbMetric: 5.0872, val_loss: 5.1805, val_MinusLogProbMetric: 5.1805

Epoch 511: val_loss did not improve from 5.17669
196/196 - 82s - loss: 5.0872 - MinusLogProbMetric: 5.0872 - val_loss: 5.1805 - val_MinusLogProbMetric: 5.1805 - lr: 4.1667e-05 - 82s/epoch - 418ms/step
Epoch 512/1000
2023-09-20 01:07:41.509 
Epoch 512/1000 
	 loss: 5.0839, MinusLogProbMetric: 5.0839, val_loss: 5.1752, val_MinusLogProbMetric: 5.1752

Epoch 512: val_loss improved from 5.17669 to 5.17521, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 5.0839 - MinusLogProbMetric: 5.0839 - val_loss: 5.1752 - val_MinusLogProbMetric: 5.1752 - lr: 4.1667e-05 - 83s/epoch - 424ms/step
Epoch 513/1000
2023-09-20 01:09:04.512 
Epoch 513/1000 
	 loss: 5.0896, MinusLogProbMetric: 5.0896, val_loss: 5.1768, val_MinusLogProbMetric: 5.1768

Epoch 513: val_loss did not improve from 5.17521
196/196 - 81s - loss: 5.0896 - MinusLogProbMetric: 5.0896 - val_loss: 5.1768 - val_MinusLogProbMetric: 5.1768 - lr: 4.1667e-05 - 81s/epoch - 416ms/step
Epoch 514/1000
2023-09-20 01:10:26.331 
Epoch 514/1000 
	 loss: 5.0843, MinusLogProbMetric: 5.0843, val_loss: 5.1905, val_MinusLogProbMetric: 5.1905

Epoch 514: val_loss did not improve from 5.17521
196/196 - 82s - loss: 5.0843 - MinusLogProbMetric: 5.0843 - val_loss: 5.1905 - val_MinusLogProbMetric: 5.1905 - lr: 4.1667e-05 - 82s/epoch - 417ms/step
Epoch 515/1000
2023-09-20 01:11:47.642 
Epoch 515/1000 
	 loss: 5.0851, MinusLogProbMetric: 5.0851, val_loss: 5.1856, val_MinusLogProbMetric: 5.1856

Epoch 515: val_loss did not improve from 5.17521
196/196 - 81s - loss: 5.0851 - MinusLogProbMetric: 5.0851 - val_loss: 5.1856 - val_MinusLogProbMetric: 5.1856 - lr: 4.1667e-05 - 81s/epoch - 415ms/step
Epoch 516/1000
2023-09-20 01:13:09.451 
Epoch 516/1000 
	 loss: 5.0839, MinusLogProbMetric: 5.0839, val_loss: 5.1759, val_MinusLogProbMetric: 5.1759

Epoch 516: val_loss did not improve from 5.17521
196/196 - 82s - loss: 5.0839 - MinusLogProbMetric: 5.0839 - val_loss: 5.1759 - val_MinusLogProbMetric: 5.1759 - lr: 4.1667e-05 - 82s/epoch - 417ms/step
Epoch 517/1000
2023-09-20 01:14:30.830 
Epoch 517/1000 
	 loss: 5.0850, MinusLogProbMetric: 5.0850, val_loss: 5.1866, val_MinusLogProbMetric: 5.1866

Epoch 517: val_loss did not improve from 5.17521
196/196 - 81s - loss: 5.0850 - MinusLogProbMetric: 5.0850 - val_loss: 5.1866 - val_MinusLogProbMetric: 5.1866 - lr: 4.1667e-05 - 81s/epoch - 415ms/step
Epoch 518/1000
2023-09-20 01:15:52.035 
Epoch 518/1000 
	 loss: 5.0844, MinusLogProbMetric: 5.0844, val_loss: 5.1761, val_MinusLogProbMetric: 5.1761

Epoch 518: val_loss did not improve from 5.17521
196/196 - 81s - loss: 5.0844 - MinusLogProbMetric: 5.0844 - val_loss: 5.1761 - val_MinusLogProbMetric: 5.1761 - lr: 4.1667e-05 - 81s/epoch - 414ms/step
Epoch 519/1000
2023-09-20 01:17:14.634 
Epoch 519/1000 
	 loss: 5.0843, MinusLogProbMetric: 5.0843, val_loss: 5.1784, val_MinusLogProbMetric: 5.1784

Epoch 519: val_loss did not improve from 5.17521
196/196 - 83s - loss: 5.0843 - MinusLogProbMetric: 5.0843 - val_loss: 5.1784 - val_MinusLogProbMetric: 5.1784 - lr: 4.1667e-05 - 83s/epoch - 421ms/step
Epoch 520/1000
2023-09-20 01:18:36.105 
Epoch 520/1000 
	 loss: 5.0843, MinusLogProbMetric: 5.0843, val_loss: 5.1815, val_MinusLogProbMetric: 5.1815

Epoch 520: val_loss did not improve from 5.17521
196/196 - 81s - loss: 5.0843 - MinusLogProbMetric: 5.0843 - val_loss: 5.1815 - val_MinusLogProbMetric: 5.1815 - lr: 4.1667e-05 - 81s/epoch - 416ms/step
Epoch 521/1000
2023-09-20 01:19:58.667 
Epoch 521/1000 
	 loss: 5.0829, MinusLogProbMetric: 5.0829, val_loss: 5.1803, val_MinusLogProbMetric: 5.1803

Epoch 521: val_loss did not improve from 5.17521
196/196 - 83s - loss: 5.0829 - MinusLogProbMetric: 5.0829 - val_loss: 5.1803 - val_MinusLogProbMetric: 5.1803 - lr: 4.1667e-05 - 83s/epoch - 421ms/step
Epoch 522/1000
2023-09-20 01:21:19.950 
Epoch 522/1000 
	 loss: 5.0843, MinusLogProbMetric: 5.0843, val_loss: 5.1829, val_MinusLogProbMetric: 5.1829

Epoch 522: val_loss did not improve from 5.17521
196/196 - 81s - loss: 5.0843 - MinusLogProbMetric: 5.0843 - val_loss: 5.1829 - val_MinusLogProbMetric: 5.1829 - lr: 4.1667e-05 - 81s/epoch - 415ms/step
Epoch 523/1000
2023-09-20 01:22:41.946 
Epoch 523/1000 
	 loss: 5.0851, MinusLogProbMetric: 5.0851, val_loss: 5.1759, val_MinusLogProbMetric: 5.1759

Epoch 523: val_loss did not improve from 5.17521
196/196 - 82s - loss: 5.0851 - MinusLogProbMetric: 5.0851 - val_loss: 5.1759 - val_MinusLogProbMetric: 5.1759 - lr: 4.1667e-05 - 82s/epoch - 418ms/step
Epoch 524/1000
2023-09-20 01:24:04.481 
Epoch 524/1000 
	 loss: 5.0867, MinusLogProbMetric: 5.0867, val_loss: 5.1797, val_MinusLogProbMetric: 5.1797

Epoch 524: val_loss did not improve from 5.17521
196/196 - 83s - loss: 5.0867 - MinusLogProbMetric: 5.0867 - val_loss: 5.1797 - val_MinusLogProbMetric: 5.1797 - lr: 4.1667e-05 - 83s/epoch - 421ms/step
Epoch 525/1000
2023-09-20 01:25:26.885 
Epoch 525/1000 
	 loss: 5.0847, MinusLogProbMetric: 5.0847, val_loss: 5.1782, val_MinusLogProbMetric: 5.1782

Epoch 525: val_loss did not improve from 5.17521
196/196 - 82s - loss: 5.0847 - MinusLogProbMetric: 5.0847 - val_loss: 5.1782 - val_MinusLogProbMetric: 5.1782 - lr: 4.1667e-05 - 82s/epoch - 420ms/step
Epoch 526/1000
2023-09-20 01:26:49.226 
Epoch 526/1000 
	 loss: 5.0838, MinusLogProbMetric: 5.0838, val_loss: 5.1804, val_MinusLogProbMetric: 5.1804

Epoch 526: val_loss did not improve from 5.17521
196/196 - 82s - loss: 5.0838 - MinusLogProbMetric: 5.0838 - val_loss: 5.1804 - val_MinusLogProbMetric: 5.1804 - lr: 4.1667e-05 - 82s/epoch - 420ms/step
Epoch 527/1000
2023-09-20 01:28:12.035 
Epoch 527/1000 
	 loss: 5.0856, MinusLogProbMetric: 5.0856, val_loss: 5.1894, val_MinusLogProbMetric: 5.1894

Epoch 527: val_loss did not improve from 5.17521
196/196 - 83s - loss: 5.0856 - MinusLogProbMetric: 5.0856 - val_loss: 5.1894 - val_MinusLogProbMetric: 5.1894 - lr: 4.1667e-05 - 83s/epoch - 422ms/step
Epoch 528/1000
2023-09-20 01:29:33.185 
Epoch 528/1000 
	 loss: 5.0857, MinusLogProbMetric: 5.0857, val_loss: 5.1807, val_MinusLogProbMetric: 5.1807

Epoch 528: val_loss did not improve from 5.17521
196/196 - 81s - loss: 5.0857 - MinusLogProbMetric: 5.0857 - val_loss: 5.1807 - val_MinusLogProbMetric: 5.1807 - lr: 4.1667e-05 - 81s/epoch - 414ms/step
Epoch 529/1000
2023-09-20 01:30:54.905 
Epoch 529/1000 
	 loss: 5.0831, MinusLogProbMetric: 5.0831, val_loss: 5.1810, val_MinusLogProbMetric: 5.1810

Epoch 529: val_loss did not improve from 5.17521
196/196 - 82s - loss: 5.0831 - MinusLogProbMetric: 5.0831 - val_loss: 5.1810 - val_MinusLogProbMetric: 5.1810 - lr: 4.1667e-05 - 82s/epoch - 417ms/step
Epoch 530/1000
2023-09-20 01:32:16.416 
Epoch 530/1000 
	 loss: 5.0827, MinusLogProbMetric: 5.0827, val_loss: 5.1808, val_MinusLogProbMetric: 5.1808

Epoch 530: val_loss did not improve from 5.17521
196/196 - 82s - loss: 5.0827 - MinusLogProbMetric: 5.0827 - val_loss: 5.1808 - val_MinusLogProbMetric: 5.1808 - lr: 4.1667e-05 - 82s/epoch - 416ms/step
Epoch 531/1000
2023-09-20 01:33:38.182 
Epoch 531/1000 
	 loss: 5.0841, MinusLogProbMetric: 5.0841, val_loss: 5.1750, val_MinusLogProbMetric: 5.1750

Epoch 531: val_loss improved from 5.17521 to 5.17501, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 5.0841 - MinusLogProbMetric: 5.0841 - val_loss: 5.1750 - val_MinusLogProbMetric: 5.1750 - lr: 4.1667e-05 - 83s/epoch - 426ms/step
Epoch 532/1000
2023-09-20 01:35:01.879 
Epoch 532/1000 
	 loss: 5.0871, MinusLogProbMetric: 5.0871, val_loss: 5.1776, val_MinusLogProbMetric: 5.1776

Epoch 532: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0871 - MinusLogProbMetric: 5.0871 - val_loss: 5.1776 - val_MinusLogProbMetric: 5.1776 - lr: 4.1667e-05 - 82s/epoch - 419ms/step
Epoch 533/1000
2023-09-20 01:36:23.039 
Epoch 533/1000 
	 loss: 5.0842, MinusLogProbMetric: 5.0842, val_loss: 5.1819, val_MinusLogProbMetric: 5.1819

Epoch 533: val_loss did not improve from 5.17501
196/196 - 81s - loss: 5.0842 - MinusLogProbMetric: 5.0842 - val_loss: 5.1819 - val_MinusLogProbMetric: 5.1819 - lr: 4.1667e-05 - 81s/epoch - 414ms/step
Epoch 534/1000
2023-09-20 01:37:45.564 
Epoch 534/1000 
	 loss: 5.0824, MinusLogProbMetric: 5.0824, val_loss: 5.1819, val_MinusLogProbMetric: 5.1819

Epoch 534: val_loss did not improve from 5.17501
196/196 - 83s - loss: 5.0824 - MinusLogProbMetric: 5.0824 - val_loss: 5.1819 - val_MinusLogProbMetric: 5.1819 - lr: 4.1667e-05 - 83s/epoch - 421ms/step
Epoch 535/1000
2023-09-20 01:39:06.586 
Epoch 535/1000 
	 loss: 5.0835, MinusLogProbMetric: 5.0835, val_loss: 5.1818, val_MinusLogProbMetric: 5.1818

Epoch 535: val_loss did not improve from 5.17501
196/196 - 81s - loss: 5.0835 - MinusLogProbMetric: 5.0835 - val_loss: 5.1818 - val_MinusLogProbMetric: 5.1818 - lr: 4.1667e-05 - 81s/epoch - 413ms/step
Epoch 536/1000
2023-09-20 01:40:28.878 
Epoch 536/1000 
	 loss: 5.0841, MinusLogProbMetric: 5.0841, val_loss: 5.1761, val_MinusLogProbMetric: 5.1761

Epoch 536: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0841 - MinusLogProbMetric: 5.0841 - val_loss: 5.1761 - val_MinusLogProbMetric: 5.1761 - lr: 4.1667e-05 - 82s/epoch - 420ms/step
Epoch 537/1000
2023-09-20 01:41:51.196 
Epoch 537/1000 
	 loss: 5.0841, MinusLogProbMetric: 5.0841, val_loss: 5.1868, val_MinusLogProbMetric: 5.1868

Epoch 537: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0841 - MinusLogProbMetric: 5.0841 - val_loss: 5.1868 - val_MinusLogProbMetric: 5.1868 - lr: 4.1667e-05 - 82s/epoch - 420ms/step
Epoch 538/1000
2023-09-20 01:43:13.556 
Epoch 538/1000 
	 loss: 5.0847, MinusLogProbMetric: 5.0847, val_loss: 5.1813, val_MinusLogProbMetric: 5.1813

Epoch 538: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0847 - MinusLogProbMetric: 5.0847 - val_loss: 5.1813 - val_MinusLogProbMetric: 5.1813 - lr: 4.1667e-05 - 82s/epoch - 420ms/step
Epoch 539/1000
2023-09-20 01:44:35.370 
Epoch 539/1000 
	 loss: 5.0840, MinusLogProbMetric: 5.0840, val_loss: 5.1830, val_MinusLogProbMetric: 5.1830

Epoch 539: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0840 - MinusLogProbMetric: 5.0840 - val_loss: 5.1830 - val_MinusLogProbMetric: 5.1830 - lr: 4.1667e-05 - 82s/epoch - 417ms/step
Epoch 540/1000
2023-09-20 01:45:57.563 
Epoch 540/1000 
	 loss: 5.0844, MinusLogProbMetric: 5.0844, val_loss: 5.1812, val_MinusLogProbMetric: 5.1812

Epoch 540: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0844 - MinusLogProbMetric: 5.0844 - val_loss: 5.1812 - val_MinusLogProbMetric: 5.1812 - lr: 4.1667e-05 - 82s/epoch - 419ms/step
Epoch 541/1000
2023-09-20 01:47:19.521 
Epoch 541/1000 
	 loss: 5.0840, MinusLogProbMetric: 5.0840, val_loss: 5.1790, val_MinusLogProbMetric: 5.1790

Epoch 541: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0840 - MinusLogProbMetric: 5.0840 - val_loss: 5.1790 - val_MinusLogProbMetric: 5.1790 - lr: 4.1667e-05 - 82s/epoch - 418ms/step
Epoch 542/1000
2023-09-20 01:48:41.173 
Epoch 542/1000 
	 loss: 5.0835, MinusLogProbMetric: 5.0835, val_loss: 5.1839, val_MinusLogProbMetric: 5.1839

Epoch 542: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0835 - MinusLogProbMetric: 5.0835 - val_loss: 5.1839 - val_MinusLogProbMetric: 5.1839 - lr: 4.1667e-05 - 82s/epoch - 417ms/step
Epoch 543/1000
2023-09-20 01:50:02.497 
Epoch 543/1000 
	 loss: 5.0849, MinusLogProbMetric: 5.0849, val_loss: 5.1801, val_MinusLogProbMetric: 5.1801

Epoch 543: val_loss did not improve from 5.17501
196/196 - 81s - loss: 5.0849 - MinusLogProbMetric: 5.0849 - val_loss: 5.1801 - val_MinusLogProbMetric: 5.1801 - lr: 4.1667e-05 - 81s/epoch - 415ms/step
Epoch 544/1000
2023-09-20 01:51:23.856 
Epoch 544/1000 
	 loss: 5.0834, MinusLogProbMetric: 5.0834, val_loss: 5.1830, val_MinusLogProbMetric: 5.1830

Epoch 544: val_loss did not improve from 5.17501
196/196 - 81s - loss: 5.0834 - MinusLogProbMetric: 5.0834 - val_loss: 5.1830 - val_MinusLogProbMetric: 5.1830 - lr: 4.1667e-05 - 81s/epoch - 415ms/step
Epoch 545/1000
2023-09-20 01:52:45.440 
Epoch 545/1000 
	 loss: 5.0849, MinusLogProbMetric: 5.0849, val_loss: 5.1793, val_MinusLogProbMetric: 5.1793

Epoch 545: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0849 - MinusLogProbMetric: 5.0849 - val_loss: 5.1793 - val_MinusLogProbMetric: 5.1793 - lr: 4.1667e-05 - 82s/epoch - 416ms/step
Epoch 546/1000
2023-09-20 01:54:07.748 
Epoch 546/1000 
	 loss: 5.0838, MinusLogProbMetric: 5.0838, val_loss: 5.1828, val_MinusLogProbMetric: 5.1828

Epoch 546: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0838 - MinusLogProbMetric: 5.0838 - val_loss: 5.1828 - val_MinusLogProbMetric: 5.1828 - lr: 4.1667e-05 - 82s/epoch - 420ms/step
Epoch 547/1000
2023-09-20 01:55:28.644 
Epoch 547/1000 
	 loss: 5.0822, MinusLogProbMetric: 5.0822, val_loss: 5.1772, val_MinusLogProbMetric: 5.1772

Epoch 547: val_loss did not improve from 5.17501
196/196 - 81s - loss: 5.0822 - MinusLogProbMetric: 5.0822 - val_loss: 5.1772 - val_MinusLogProbMetric: 5.1772 - lr: 4.1667e-05 - 81s/epoch - 413ms/step
Epoch 548/1000
2023-09-20 01:56:50.737 
Epoch 548/1000 
	 loss: 5.0843, MinusLogProbMetric: 5.0843, val_loss: 5.1814, val_MinusLogProbMetric: 5.1814

Epoch 548: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0843 - MinusLogProbMetric: 5.0843 - val_loss: 5.1814 - val_MinusLogProbMetric: 5.1814 - lr: 4.1667e-05 - 82s/epoch - 419ms/step
Epoch 549/1000
2023-09-20 01:58:11.140 
Epoch 549/1000 
	 loss: 5.0819, MinusLogProbMetric: 5.0819, val_loss: 5.1779, val_MinusLogProbMetric: 5.1779

Epoch 549: val_loss did not improve from 5.17501
196/196 - 80s - loss: 5.0819 - MinusLogProbMetric: 5.0819 - val_loss: 5.1779 - val_MinusLogProbMetric: 5.1779 - lr: 4.1667e-05 - 80s/epoch - 410ms/step
Epoch 550/1000
2023-09-20 01:59:33.008 
Epoch 550/1000 
	 loss: 5.0845, MinusLogProbMetric: 5.0845, val_loss: 5.1829, val_MinusLogProbMetric: 5.1829

Epoch 550: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0845 - MinusLogProbMetric: 5.0845 - val_loss: 5.1829 - val_MinusLogProbMetric: 5.1829 - lr: 4.1667e-05 - 82s/epoch - 418ms/step
Epoch 551/1000
2023-09-20 02:00:55.260 
Epoch 551/1000 
	 loss: 5.0845, MinusLogProbMetric: 5.0845, val_loss: 5.1915, val_MinusLogProbMetric: 5.1915

Epoch 551: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0845 - MinusLogProbMetric: 5.0845 - val_loss: 5.1915 - val_MinusLogProbMetric: 5.1915 - lr: 4.1667e-05 - 82s/epoch - 420ms/step
Epoch 552/1000
2023-09-20 02:02:16.801 
Epoch 552/1000 
	 loss: 5.0852, MinusLogProbMetric: 5.0852, val_loss: 5.1828, val_MinusLogProbMetric: 5.1828

Epoch 552: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0852 - MinusLogProbMetric: 5.0852 - val_loss: 5.1828 - val_MinusLogProbMetric: 5.1828 - lr: 4.1667e-05 - 82s/epoch - 416ms/step
Epoch 553/1000
2023-09-20 02:03:39.194 
Epoch 553/1000 
	 loss: 5.0823, MinusLogProbMetric: 5.0823, val_loss: 5.1757, val_MinusLogProbMetric: 5.1757

Epoch 553: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0823 - MinusLogProbMetric: 5.0823 - val_loss: 5.1757 - val_MinusLogProbMetric: 5.1757 - lr: 4.1667e-05 - 82s/epoch - 420ms/step
Epoch 554/1000
2023-09-20 02:05:01.142 
Epoch 554/1000 
	 loss: 5.0850, MinusLogProbMetric: 5.0850, val_loss: 5.1871, val_MinusLogProbMetric: 5.1871

Epoch 554: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0850 - MinusLogProbMetric: 5.0850 - val_loss: 5.1871 - val_MinusLogProbMetric: 5.1871 - lr: 4.1667e-05 - 82s/epoch - 418ms/step
Epoch 555/1000
2023-09-20 02:06:22.748 
Epoch 555/1000 
	 loss: 5.0826, MinusLogProbMetric: 5.0826, val_loss: 5.1795, val_MinusLogProbMetric: 5.1795

Epoch 555: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0826 - MinusLogProbMetric: 5.0826 - val_loss: 5.1795 - val_MinusLogProbMetric: 5.1795 - lr: 4.1667e-05 - 82s/epoch - 416ms/step
Epoch 556/1000
2023-09-20 02:07:44.609 
Epoch 556/1000 
	 loss: 5.0834, MinusLogProbMetric: 5.0834, val_loss: 5.1828, val_MinusLogProbMetric: 5.1828

Epoch 556: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0834 - MinusLogProbMetric: 5.0834 - val_loss: 5.1828 - val_MinusLogProbMetric: 5.1828 - lr: 4.1667e-05 - 82s/epoch - 418ms/step
Epoch 557/1000
2023-09-20 02:09:06.400 
Epoch 557/1000 
	 loss: 5.0827, MinusLogProbMetric: 5.0827, val_loss: 5.1802, val_MinusLogProbMetric: 5.1802

Epoch 557: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0827 - MinusLogProbMetric: 5.0827 - val_loss: 5.1802 - val_MinusLogProbMetric: 5.1802 - lr: 4.1667e-05 - 82s/epoch - 417ms/step
Epoch 558/1000
2023-09-20 02:10:28.112 
Epoch 558/1000 
	 loss: 5.0826, MinusLogProbMetric: 5.0826, val_loss: 5.1822, val_MinusLogProbMetric: 5.1822

Epoch 558: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0826 - MinusLogProbMetric: 5.0826 - val_loss: 5.1822 - val_MinusLogProbMetric: 5.1822 - lr: 4.1667e-05 - 82s/epoch - 417ms/step
Epoch 559/1000
2023-09-20 02:11:50.040 
Epoch 559/1000 
	 loss: 5.0834, MinusLogProbMetric: 5.0834, val_loss: 5.1758, val_MinusLogProbMetric: 5.1758

Epoch 559: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0834 - MinusLogProbMetric: 5.0834 - val_loss: 5.1758 - val_MinusLogProbMetric: 5.1758 - lr: 4.1667e-05 - 82s/epoch - 418ms/step
Epoch 560/1000
2023-09-20 02:13:11.270 
Epoch 560/1000 
	 loss: 5.0814, MinusLogProbMetric: 5.0814, val_loss: 5.1833, val_MinusLogProbMetric: 5.1833

Epoch 560: val_loss did not improve from 5.17501
196/196 - 81s - loss: 5.0814 - MinusLogProbMetric: 5.0814 - val_loss: 5.1833 - val_MinusLogProbMetric: 5.1833 - lr: 4.1667e-05 - 81s/epoch - 414ms/step
Epoch 561/1000
2023-09-20 02:14:34.005 
Epoch 561/1000 
	 loss: 5.0829, MinusLogProbMetric: 5.0829, val_loss: 5.1837, val_MinusLogProbMetric: 5.1837

Epoch 561: val_loss did not improve from 5.17501
196/196 - 83s - loss: 5.0829 - MinusLogProbMetric: 5.0829 - val_loss: 5.1837 - val_MinusLogProbMetric: 5.1837 - lr: 4.1667e-05 - 83s/epoch - 422ms/step
Epoch 562/1000
2023-09-20 02:15:55.232 
Epoch 562/1000 
	 loss: 5.0825, MinusLogProbMetric: 5.0825, val_loss: 5.1827, val_MinusLogProbMetric: 5.1827

Epoch 562: val_loss did not improve from 5.17501
196/196 - 81s - loss: 5.0825 - MinusLogProbMetric: 5.0825 - val_loss: 5.1827 - val_MinusLogProbMetric: 5.1827 - lr: 4.1667e-05 - 81s/epoch - 414ms/step
Epoch 563/1000
2023-09-20 02:17:17.258 
Epoch 563/1000 
	 loss: 5.0820, MinusLogProbMetric: 5.0820, val_loss: 5.1816, val_MinusLogProbMetric: 5.1816

Epoch 563: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0820 - MinusLogProbMetric: 5.0820 - val_loss: 5.1816 - val_MinusLogProbMetric: 5.1816 - lr: 4.1667e-05 - 82s/epoch - 418ms/step
Epoch 564/1000
2023-09-20 02:18:39.030 
Epoch 564/1000 
	 loss: 5.0834, MinusLogProbMetric: 5.0834, val_loss: 5.1889, val_MinusLogProbMetric: 5.1889

Epoch 564: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0834 - MinusLogProbMetric: 5.0834 - val_loss: 5.1889 - val_MinusLogProbMetric: 5.1889 - lr: 4.1667e-05 - 82s/epoch - 417ms/step
Epoch 565/1000
2023-09-20 02:20:00.273 
Epoch 565/1000 
	 loss: 5.0827, MinusLogProbMetric: 5.0827, val_loss: 5.1828, val_MinusLogProbMetric: 5.1828

Epoch 565: val_loss did not improve from 5.17501
196/196 - 81s - loss: 5.0827 - MinusLogProbMetric: 5.0827 - val_loss: 5.1828 - val_MinusLogProbMetric: 5.1828 - lr: 4.1667e-05 - 81s/epoch - 414ms/step
Epoch 566/1000
2023-09-20 02:21:22.245 
Epoch 566/1000 
	 loss: 5.0822, MinusLogProbMetric: 5.0822, val_loss: 5.1780, val_MinusLogProbMetric: 5.1780

Epoch 566: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0822 - MinusLogProbMetric: 5.0822 - val_loss: 5.1780 - val_MinusLogProbMetric: 5.1780 - lr: 4.1667e-05 - 82s/epoch - 418ms/step
Epoch 567/1000
2023-09-20 02:22:43.886 
Epoch 567/1000 
	 loss: 5.0846, MinusLogProbMetric: 5.0846, val_loss: 5.1875, val_MinusLogProbMetric: 5.1875

Epoch 567: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0846 - MinusLogProbMetric: 5.0846 - val_loss: 5.1875 - val_MinusLogProbMetric: 5.1875 - lr: 4.1667e-05 - 82s/epoch - 417ms/step
Epoch 568/1000
2023-09-20 02:24:05.872 
Epoch 568/1000 
	 loss: 5.0830, MinusLogProbMetric: 5.0830, val_loss: 5.1820, val_MinusLogProbMetric: 5.1820

Epoch 568: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0830 - MinusLogProbMetric: 5.0830 - val_loss: 5.1820 - val_MinusLogProbMetric: 5.1820 - lr: 4.1667e-05 - 82s/epoch - 418ms/step
Epoch 569/1000
2023-09-20 02:25:27.380 
Epoch 569/1000 
	 loss: 5.0813, MinusLogProbMetric: 5.0813, val_loss: 5.1776, val_MinusLogProbMetric: 5.1776

Epoch 569: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0813 - MinusLogProbMetric: 5.0813 - val_loss: 5.1776 - val_MinusLogProbMetric: 5.1776 - lr: 4.1667e-05 - 82s/epoch - 416ms/step
Epoch 570/1000
2023-09-20 02:26:49.420 
Epoch 570/1000 
	 loss: 5.0815, MinusLogProbMetric: 5.0815, val_loss: 5.1820, val_MinusLogProbMetric: 5.1820

Epoch 570: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0815 - MinusLogProbMetric: 5.0815 - val_loss: 5.1820 - val_MinusLogProbMetric: 5.1820 - lr: 4.1667e-05 - 82s/epoch - 419ms/step
Epoch 571/1000
2023-09-20 02:28:12.265 
Epoch 571/1000 
	 loss: 5.0822, MinusLogProbMetric: 5.0822, val_loss: 5.1779, val_MinusLogProbMetric: 5.1779

Epoch 571: val_loss did not improve from 5.17501
196/196 - 83s - loss: 5.0822 - MinusLogProbMetric: 5.0822 - val_loss: 5.1779 - val_MinusLogProbMetric: 5.1779 - lr: 4.1667e-05 - 83s/epoch - 423ms/step
Epoch 572/1000
2023-09-20 02:29:34.032 
Epoch 572/1000 
	 loss: 5.0821, MinusLogProbMetric: 5.0821, val_loss: 5.1877, val_MinusLogProbMetric: 5.1877

Epoch 572: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0821 - MinusLogProbMetric: 5.0821 - val_loss: 5.1877 - val_MinusLogProbMetric: 5.1877 - lr: 4.1667e-05 - 82s/epoch - 417ms/step
Epoch 573/1000
2023-09-20 02:30:55.299 
Epoch 573/1000 
	 loss: 5.0822, MinusLogProbMetric: 5.0822, val_loss: 5.1802, val_MinusLogProbMetric: 5.1802

Epoch 573: val_loss did not improve from 5.17501
196/196 - 81s - loss: 5.0822 - MinusLogProbMetric: 5.0822 - val_loss: 5.1802 - val_MinusLogProbMetric: 5.1802 - lr: 4.1667e-05 - 81s/epoch - 415ms/step
Epoch 574/1000
2023-09-20 02:32:16.607 
Epoch 574/1000 
	 loss: 5.0813, MinusLogProbMetric: 5.0813, val_loss: 5.1823, val_MinusLogProbMetric: 5.1823

Epoch 574: val_loss did not improve from 5.17501
196/196 - 81s - loss: 5.0813 - MinusLogProbMetric: 5.0813 - val_loss: 5.1823 - val_MinusLogProbMetric: 5.1823 - lr: 4.1667e-05 - 81s/epoch - 415ms/step
Epoch 575/1000
2023-09-20 02:33:38.336 
Epoch 575/1000 
	 loss: 5.0817, MinusLogProbMetric: 5.0817, val_loss: 5.1799, val_MinusLogProbMetric: 5.1799

Epoch 575: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0817 - MinusLogProbMetric: 5.0817 - val_loss: 5.1799 - val_MinusLogProbMetric: 5.1799 - lr: 4.1667e-05 - 82s/epoch - 417ms/step
Epoch 576/1000
2023-09-20 02:35:00.458 
Epoch 576/1000 
	 loss: 5.0808, MinusLogProbMetric: 5.0808, val_loss: 5.1810, val_MinusLogProbMetric: 5.1810

Epoch 576: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0808 - MinusLogProbMetric: 5.0808 - val_loss: 5.1810 - val_MinusLogProbMetric: 5.1810 - lr: 4.1667e-05 - 82s/epoch - 419ms/step
Epoch 577/1000
2023-09-20 02:36:22.492 
Epoch 577/1000 
	 loss: 5.0822, MinusLogProbMetric: 5.0822, val_loss: 5.1845, val_MinusLogProbMetric: 5.1845

Epoch 577: val_loss did not improve from 5.17501
196/196 - 82s - loss: 5.0822 - MinusLogProbMetric: 5.0822 - val_loss: 5.1845 - val_MinusLogProbMetric: 5.1845 - lr: 4.1667e-05 - 82s/epoch - 419ms/step
Epoch 578/1000
2023-09-20 02:37:39.655 
Epoch 578/1000 
	 loss: 5.0814, MinusLogProbMetric: 5.0814, val_loss: 5.1784, val_MinusLogProbMetric: 5.1784

Epoch 578: val_loss did not improve from 5.17501
196/196 - 77s - loss: 5.0814 - MinusLogProbMetric: 5.0814 - val_loss: 5.1784 - val_MinusLogProbMetric: 5.1784 - lr: 4.1667e-05 - 77s/epoch - 394ms/step
Epoch 579/1000
2023-09-20 02:38:51.203 
Epoch 579/1000 
	 loss: 5.0816, MinusLogProbMetric: 5.0816, val_loss: 5.1889, val_MinusLogProbMetric: 5.1889

Epoch 579: val_loss did not improve from 5.17501
196/196 - 72s - loss: 5.0816 - MinusLogProbMetric: 5.0816 - val_loss: 5.1889 - val_MinusLogProbMetric: 5.1889 - lr: 4.1667e-05 - 72s/epoch - 365ms/step
Epoch 580/1000
2023-09-20 02:39:56.940 
Epoch 580/1000 
	 loss: 5.0808, MinusLogProbMetric: 5.0808, val_loss: 5.1799, val_MinusLogProbMetric: 5.1799

Epoch 580: val_loss did not improve from 5.17501
196/196 - 66s - loss: 5.0808 - MinusLogProbMetric: 5.0808 - val_loss: 5.1799 - val_MinusLogProbMetric: 5.1799 - lr: 4.1667e-05 - 66s/epoch - 335ms/step
Epoch 581/1000
2023-09-20 02:41:08.236 
Epoch 581/1000 
	 loss: 5.0804, MinusLogProbMetric: 5.0804, val_loss: 5.1810, val_MinusLogProbMetric: 5.1810

Epoch 581: val_loss did not improve from 5.17501
196/196 - 71s - loss: 5.0804 - MinusLogProbMetric: 5.0804 - val_loss: 5.1810 - val_MinusLogProbMetric: 5.1810 - lr: 4.1667e-05 - 71s/epoch - 364ms/step
Epoch 582/1000
2023-09-20 02:42:28.216 
Epoch 582/1000 
	 loss: 5.0742, MinusLogProbMetric: 5.0742, val_loss: 5.1760, val_MinusLogProbMetric: 5.1760

Epoch 582: val_loss did not improve from 5.17501
196/196 - 80s - loss: 5.0742 - MinusLogProbMetric: 5.0742 - val_loss: 5.1760 - val_MinusLogProbMetric: 5.1760 - lr: 2.0833e-05 - 80s/epoch - 408ms/step
Epoch 583/1000
2023-09-20 02:43:48.461 
Epoch 583/1000 
	 loss: 5.0748, MinusLogProbMetric: 5.0748, val_loss: 5.1739, val_MinusLogProbMetric: 5.1739

Epoch 583: val_loss improved from 5.17501 to 5.17395, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 5.0748 - MinusLogProbMetric: 5.0748 - val_loss: 5.1739 - val_MinusLogProbMetric: 5.1739 - lr: 2.0833e-05 - 82s/epoch - 417ms/step
Epoch 584/1000
2023-09-20 02:45:10.406 
Epoch 584/1000 
	 loss: 5.0743, MinusLogProbMetric: 5.0743, val_loss: 5.1718, val_MinusLogProbMetric: 5.1718

Epoch 584: val_loss improved from 5.17395 to 5.17185, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 5.0743 - MinusLogProbMetric: 5.0743 - val_loss: 5.1718 - val_MinusLogProbMetric: 5.1718 - lr: 2.0833e-05 - 82s/epoch - 418ms/step
Epoch 585/1000
2023-09-20 02:46:32.455 
Epoch 585/1000 
	 loss: 5.0737, MinusLogProbMetric: 5.0737, val_loss: 5.1741, val_MinusLogProbMetric: 5.1741

Epoch 585: val_loss did not improve from 5.17185
196/196 - 81s - loss: 5.0737 - MinusLogProbMetric: 5.0737 - val_loss: 5.1741 - val_MinusLogProbMetric: 5.1741 - lr: 2.0833e-05 - 81s/epoch - 412ms/step
Epoch 586/1000
2023-09-20 02:47:53.280 
Epoch 586/1000 
	 loss: 5.0733, MinusLogProbMetric: 5.0733, val_loss: 5.1717, val_MinusLogProbMetric: 5.1717

Epoch 586: val_loss improved from 5.17185 to 5.17173, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 5.0733 - MinusLogProbMetric: 5.0733 - val_loss: 5.1717 - val_MinusLogProbMetric: 5.1717 - lr: 2.0833e-05 - 82s/epoch - 419ms/step
Epoch 587/1000
2023-09-20 02:49:15.419 
Epoch 587/1000 
	 loss: 5.0735, MinusLogProbMetric: 5.0735, val_loss: 5.1737, val_MinusLogProbMetric: 5.1737

Epoch 587: val_loss did not improve from 5.17173
196/196 - 81s - loss: 5.0735 - MinusLogProbMetric: 5.0735 - val_loss: 5.1737 - val_MinusLogProbMetric: 5.1737 - lr: 2.0833e-05 - 81s/epoch - 413ms/step
Epoch 588/1000
2023-09-20 02:50:35.346 
Epoch 588/1000 
	 loss: 5.0733, MinusLogProbMetric: 5.0733, val_loss: 5.1749, val_MinusLogProbMetric: 5.1749

Epoch 588: val_loss did not improve from 5.17173
196/196 - 80s - loss: 5.0733 - MinusLogProbMetric: 5.0733 - val_loss: 5.1749 - val_MinusLogProbMetric: 5.1749 - lr: 2.0833e-05 - 80s/epoch - 408ms/step
Epoch 589/1000
2023-09-20 02:51:56.136 
Epoch 589/1000 
	 loss: 5.0736, MinusLogProbMetric: 5.0736, val_loss: 5.1747, val_MinusLogProbMetric: 5.1747

Epoch 589: val_loss did not improve from 5.17173
196/196 - 81s - loss: 5.0736 - MinusLogProbMetric: 5.0736 - val_loss: 5.1747 - val_MinusLogProbMetric: 5.1747 - lr: 2.0833e-05 - 81s/epoch - 412ms/step
Epoch 590/1000
2023-09-20 02:53:15.578 
Epoch 590/1000 
	 loss: 5.0726, MinusLogProbMetric: 5.0726, val_loss: 5.1717, val_MinusLogProbMetric: 5.1717

Epoch 590: val_loss improved from 5.17173 to 5.17173, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 80s - loss: 5.0726 - MinusLogProbMetric: 5.0726 - val_loss: 5.1717 - val_MinusLogProbMetric: 5.1717 - lr: 2.0833e-05 - 80s/epoch - 410ms/step
Epoch 591/1000
2023-09-20 02:54:37.162 
Epoch 591/1000 
	 loss: 5.0731, MinusLogProbMetric: 5.0731, val_loss: 5.1734, val_MinusLogProbMetric: 5.1734

Epoch 591: val_loss did not improve from 5.17173
196/196 - 81s - loss: 5.0731 - MinusLogProbMetric: 5.0731 - val_loss: 5.1734 - val_MinusLogProbMetric: 5.1734 - lr: 2.0833e-05 - 81s/epoch - 412ms/step
Epoch 592/1000
2023-09-20 02:55:58.559 
Epoch 592/1000 
	 loss: 5.0739, MinusLogProbMetric: 5.0739, val_loss: 5.1738, val_MinusLogProbMetric: 5.1738

Epoch 592: val_loss did not improve from 5.17173
196/196 - 81s - loss: 5.0739 - MinusLogProbMetric: 5.0739 - val_loss: 5.1738 - val_MinusLogProbMetric: 5.1738 - lr: 2.0833e-05 - 81s/epoch - 415ms/step
Epoch 593/1000
2023-09-20 02:57:19.805 
Epoch 593/1000 
	 loss: 5.0742, MinusLogProbMetric: 5.0742, val_loss: 5.1746, val_MinusLogProbMetric: 5.1746

Epoch 593: val_loss did not improve from 5.17173
196/196 - 81s - loss: 5.0742 - MinusLogProbMetric: 5.0742 - val_loss: 5.1746 - val_MinusLogProbMetric: 5.1746 - lr: 2.0833e-05 - 81s/epoch - 414ms/step
Epoch 594/1000
2023-09-20 02:58:40.063 
Epoch 594/1000 
	 loss: 5.0740, MinusLogProbMetric: 5.0740, val_loss: 5.1770, val_MinusLogProbMetric: 5.1770

Epoch 594: val_loss did not improve from 5.17173
196/196 - 80s - loss: 5.0740 - MinusLogProbMetric: 5.0740 - val_loss: 5.1770 - val_MinusLogProbMetric: 5.1770 - lr: 2.0833e-05 - 80s/epoch - 410ms/step
Epoch 595/1000
2023-09-20 03:00:00.370 
Epoch 595/1000 
	 loss: 5.0739, MinusLogProbMetric: 5.0739, val_loss: 5.1772, val_MinusLogProbMetric: 5.1772

Epoch 595: val_loss did not improve from 5.17173
196/196 - 80s - loss: 5.0739 - MinusLogProbMetric: 5.0739 - val_loss: 5.1772 - val_MinusLogProbMetric: 5.1772 - lr: 2.0833e-05 - 80s/epoch - 409ms/step
Epoch 596/1000
2023-09-20 03:01:20.621 
Epoch 596/1000 
	 loss: 5.0736, MinusLogProbMetric: 5.0736, val_loss: 5.1737, val_MinusLogProbMetric: 5.1737

Epoch 596: val_loss did not improve from 5.17173
196/196 - 80s - loss: 5.0736 - MinusLogProbMetric: 5.0736 - val_loss: 5.1737 - val_MinusLogProbMetric: 5.1737 - lr: 2.0833e-05 - 80s/epoch - 409ms/step
Epoch 597/1000
2023-09-20 03:02:41.231 
Epoch 597/1000 
	 loss: 5.0728, MinusLogProbMetric: 5.0728, val_loss: 5.1765, val_MinusLogProbMetric: 5.1765

Epoch 597: val_loss did not improve from 5.17173
196/196 - 81s - loss: 5.0728 - MinusLogProbMetric: 5.0728 - val_loss: 5.1765 - val_MinusLogProbMetric: 5.1765 - lr: 2.0833e-05 - 81s/epoch - 411ms/step
Epoch 598/1000
2023-09-20 03:04:01.013 
Epoch 598/1000 
	 loss: 5.0741, MinusLogProbMetric: 5.0741, val_loss: 5.1757, val_MinusLogProbMetric: 5.1757

Epoch 598: val_loss did not improve from 5.17173
196/196 - 80s - loss: 5.0741 - MinusLogProbMetric: 5.0741 - val_loss: 5.1757 - val_MinusLogProbMetric: 5.1757 - lr: 2.0833e-05 - 80s/epoch - 407ms/step
Epoch 599/1000
2023-09-20 03:05:21.655 
Epoch 599/1000 
	 loss: 5.0737, MinusLogProbMetric: 5.0737, val_loss: 5.1737, val_MinusLogProbMetric: 5.1737

Epoch 599: val_loss did not improve from 5.17173
196/196 - 81s - loss: 5.0737 - MinusLogProbMetric: 5.0737 - val_loss: 5.1737 - val_MinusLogProbMetric: 5.1737 - lr: 2.0833e-05 - 81s/epoch - 411ms/step
Epoch 600/1000
2023-09-20 03:06:41.900 
Epoch 600/1000 
	 loss: 5.0725, MinusLogProbMetric: 5.0725, val_loss: 5.1744, val_MinusLogProbMetric: 5.1744

Epoch 600: val_loss did not improve from 5.17173
196/196 - 80s - loss: 5.0725 - MinusLogProbMetric: 5.0725 - val_loss: 5.1744 - val_MinusLogProbMetric: 5.1744 - lr: 2.0833e-05 - 80s/epoch - 409ms/step
Epoch 601/1000
2023-09-20 03:08:02.408 
Epoch 601/1000 
	 loss: 5.0739, MinusLogProbMetric: 5.0739, val_loss: 5.1748, val_MinusLogProbMetric: 5.1748

Epoch 601: val_loss did not improve from 5.17173
196/196 - 81s - loss: 5.0739 - MinusLogProbMetric: 5.0739 - val_loss: 5.1748 - val_MinusLogProbMetric: 5.1748 - lr: 2.0833e-05 - 81s/epoch - 411ms/step
Epoch 602/1000
2023-09-20 03:09:23.119 
Epoch 602/1000 
	 loss: 5.0730, MinusLogProbMetric: 5.0730, val_loss: 5.1702, val_MinusLogProbMetric: 5.1702

Epoch 602: val_loss improved from 5.17173 to 5.17021, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 5.0730 - MinusLogProbMetric: 5.0730 - val_loss: 5.1702 - val_MinusLogProbMetric: 5.1702 - lr: 2.0833e-05 - 82s/epoch - 419ms/step
Epoch 603/1000
2023-09-20 03:10:44.586 
Epoch 603/1000 
	 loss: 5.0730, MinusLogProbMetric: 5.0730, val_loss: 5.1727, val_MinusLogProbMetric: 5.1727

Epoch 603: val_loss did not improve from 5.17021
196/196 - 80s - loss: 5.0730 - MinusLogProbMetric: 5.0730 - val_loss: 5.1727 - val_MinusLogProbMetric: 5.1727 - lr: 2.0833e-05 - 80s/epoch - 409ms/step
Epoch 604/1000
2023-09-20 03:12:05.365 
Epoch 604/1000 
	 loss: 5.0738, MinusLogProbMetric: 5.0738, val_loss: 5.1721, val_MinusLogProbMetric: 5.1721

Epoch 604: val_loss did not improve from 5.17021
196/196 - 81s - loss: 5.0738 - MinusLogProbMetric: 5.0738 - val_loss: 5.1721 - val_MinusLogProbMetric: 5.1721 - lr: 2.0833e-05 - 81s/epoch - 412ms/step
Epoch 605/1000
2023-09-20 03:13:25.806 
Epoch 605/1000 
	 loss: 5.0741, MinusLogProbMetric: 5.0741, val_loss: 5.1739, val_MinusLogProbMetric: 5.1739

Epoch 605: val_loss did not improve from 5.17021
196/196 - 80s - loss: 5.0741 - MinusLogProbMetric: 5.0741 - val_loss: 5.1739 - val_MinusLogProbMetric: 5.1739 - lr: 2.0833e-05 - 80s/epoch - 410ms/step
Epoch 606/1000
2023-09-20 03:14:46.557 
Epoch 606/1000 
	 loss: 5.0734, MinusLogProbMetric: 5.0734, val_loss: 5.1787, val_MinusLogProbMetric: 5.1787

Epoch 606: val_loss did not improve from 5.17021
196/196 - 81s - loss: 5.0734 - MinusLogProbMetric: 5.0734 - val_loss: 5.1787 - val_MinusLogProbMetric: 5.1787 - lr: 2.0833e-05 - 81s/epoch - 412ms/step
Epoch 607/1000
2023-09-20 03:16:06.875 
Epoch 607/1000 
	 loss: 5.0729, MinusLogProbMetric: 5.0729, val_loss: 5.1726, val_MinusLogProbMetric: 5.1726

Epoch 607: val_loss did not improve from 5.17021
196/196 - 80s - loss: 5.0729 - MinusLogProbMetric: 5.0729 - val_loss: 5.1726 - val_MinusLogProbMetric: 5.1726 - lr: 2.0833e-05 - 80s/epoch - 410ms/step
Epoch 608/1000
2023-09-20 03:17:26.588 
Epoch 608/1000 
	 loss: 5.0739, MinusLogProbMetric: 5.0739, val_loss: 5.1760, val_MinusLogProbMetric: 5.1760

Epoch 608: val_loss did not improve from 5.17021
196/196 - 80s - loss: 5.0739 - MinusLogProbMetric: 5.0739 - val_loss: 5.1760 - val_MinusLogProbMetric: 5.1760 - lr: 2.0833e-05 - 80s/epoch - 407ms/step
Epoch 609/1000
2023-09-20 03:18:46.146 
Epoch 609/1000 
	 loss: 5.0726, MinusLogProbMetric: 5.0726, val_loss: 5.1752, val_MinusLogProbMetric: 5.1752

Epoch 609: val_loss did not improve from 5.17021
196/196 - 80s - loss: 5.0726 - MinusLogProbMetric: 5.0726 - val_loss: 5.1752 - val_MinusLogProbMetric: 5.1752 - lr: 2.0833e-05 - 80s/epoch - 406ms/step
Epoch 610/1000
2023-09-20 03:20:06.136 
Epoch 610/1000 
	 loss: 5.0730, MinusLogProbMetric: 5.0730, val_loss: 5.1709, val_MinusLogProbMetric: 5.1709

Epoch 610: val_loss did not improve from 5.17021
196/196 - 80s - loss: 5.0730 - MinusLogProbMetric: 5.0730 - val_loss: 5.1709 - val_MinusLogProbMetric: 5.1709 - lr: 2.0833e-05 - 80s/epoch - 408ms/step
Epoch 611/1000
2023-09-20 03:21:27.125 
Epoch 611/1000 
	 loss: 5.0725, MinusLogProbMetric: 5.0725, val_loss: 5.1729, val_MinusLogProbMetric: 5.1729

Epoch 611: val_loss did not improve from 5.17021
196/196 - 81s - loss: 5.0725 - MinusLogProbMetric: 5.0725 - val_loss: 5.1729 - val_MinusLogProbMetric: 5.1729 - lr: 2.0833e-05 - 81s/epoch - 413ms/step
Epoch 612/1000
2023-09-20 03:22:47.269 
Epoch 612/1000 
	 loss: 5.0723, MinusLogProbMetric: 5.0723, val_loss: 5.1758, val_MinusLogProbMetric: 5.1758

Epoch 612: val_loss did not improve from 5.17021
196/196 - 80s - loss: 5.0723 - MinusLogProbMetric: 5.0723 - val_loss: 5.1758 - val_MinusLogProbMetric: 5.1758 - lr: 2.0833e-05 - 80s/epoch - 409ms/step
Epoch 613/1000
2023-09-20 03:24:08.047 
Epoch 613/1000 
	 loss: 5.0730, MinusLogProbMetric: 5.0730, val_loss: 5.1719, val_MinusLogProbMetric: 5.1719

Epoch 613: val_loss did not improve from 5.17021
196/196 - 81s - loss: 5.0730 - MinusLogProbMetric: 5.0730 - val_loss: 5.1719 - val_MinusLogProbMetric: 5.1719 - lr: 2.0833e-05 - 81s/epoch - 412ms/step
Epoch 614/1000
2023-09-20 03:25:28.420 
Epoch 614/1000 
	 loss: 5.0728, MinusLogProbMetric: 5.0728, val_loss: 5.1782, val_MinusLogProbMetric: 5.1782

Epoch 614: val_loss did not improve from 5.17021
196/196 - 80s - loss: 5.0728 - MinusLogProbMetric: 5.0728 - val_loss: 5.1782 - val_MinusLogProbMetric: 5.1782 - lr: 2.0833e-05 - 80s/epoch - 410ms/step
Epoch 615/1000
2023-09-20 03:26:49.373 
Epoch 615/1000 
	 loss: 5.0728, MinusLogProbMetric: 5.0728, val_loss: 5.1716, val_MinusLogProbMetric: 5.1716

Epoch 615: val_loss did not improve from 5.17021
196/196 - 81s - loss: 5.0728 - MinusLogProbMetric: 5.0728 - val_loss: 5.1716 - val_MinusLogProbMetric: 5.1716 - lr: 2.0833e-05 - 81s/epoch - 413ms/step
Epoch 616/1000
2023-09-20 03:28:10.457 
Epoch 616/1000 
	 loss: 5.0734, MinusLogProbMetric: 5.0734, val_loss: 5.1775, val_MinusLogProbMetric: 5.1775

Epoch 616: val_loss did not improve from 5.17021
196/196 - 81s - loss: 5.0734 - MinusLogProbMetric: 5.0734 - val_loss: 5.1775 - val_MinusLogProbMetric: 5.1775 - lr: 2.0833e-05 - 81s/epoch - 414ms/step
Epoch 617/1000
2023-09-20 03:29:31.483 
Epoch 617/1000 
	 loss: 5.0729, MinusLogProbMetric: 5.0729, val_loss: 5.1705, val_MinusLogProbMetric: 5.1705

Epoch 617: val_loss did not improve from 5.17021
196/196 - 81s - loss: 5.0729 - MinusLogProbMetric: 5.0729 - val_loss: 5.1705 - val_MinusLogProbMetric: 5.1705 - lr: 2.0833e-05 - 81s/epoch - 413ms/step
Epoch 618/1000
2023-09-20 03:30:52.121 
Epoch 618/1000 
	 loss: 5.0726, MinusLogProbMetric: 5.0726, val_loss: 5.1728, val_MinusLogProbMetric: 5.1728

Epoch 618: val_loss did not improve from 5.17021
196/196 - 81s - loss: 5.0726 - MinusLogProbMetric: 5.0726 - val_loss: 5.1728 - val_MinusLogProbMetric: 5.1728 - lr: 2.0833e-05 - 81s/epoch - 411ms/step
Epoch 619/1000
2023-09-20 03:32:13.099 
Epoch 619/1000 
	 loss: 5.0739, MinusLogProbMetric: 5.0739, val_loss: 5.1769, val_MinusLogProbMetric: 5.1769

Epoch 619: val_loss did not improve from 5.17021
196/196 - 81s - loss: 5.0739 - MinusLogProbMetric: 5.0739 - val_loss: 5.1769 - val_MinusLogProbMetric: 5.1769 - lr: 2.0833e-05 - 81s/epoch - 413ms/step
Epoch 620/1000
2023-09-20 03:33:33.983 
Epoch 620/1000 
	 loss: 5.0721, MinusLogProbMetric: 5.0721, val_loss: 5.1721, val_MinusLogProbMetric: 5.1721

Epoch 620: val_loss did not improve from 5.17021
196/196 - 81s - loss: 5.0721 - MinusLogProbMetric: 5.0721 - val_loss: 5.1721 - val_MinusLogProbMetric: 5.1721 - lr: 2.0833e-05 - 81s/epoch - 413ms/step
Epoch 621/1000
2023-09-20 03:34:53.526 
Epoch 621/1000 
	 loss: 5.0727, MinusLogProbMetric: 5.0727, val_loss: 5.1724, val_MinusLogProbMetric: 5.1724

Epoch 621: val_loss did not improve from 5.17021
196/196 - 80s - loss: 5.0727 - MinusLogProbMetric: 5.0727 - val_loss: 5.1724 - val_MinusLogProbMetric: 5.1724 - lr: 2.0833e-05 - 80s/epoch - 406ms/step
Epoch 622/1000
2023-09-20 03:36:12.964 
Epoch 622/1000 
	 loss: 5.0729, MinusLogProbMetric: 5.0729, val_loss: 5.1719, val_MinusLogProbMetric: 5.1719

Epoch 622: val_loss did not improve from 5.17021
196/196 - 79s - loss: 5.0729 - MinusLogProbMetric: 5.0729 - val_loss: 5.1719 - val_MinusLogProbMetric: 5.1719 - lr: 2.0833e-05 - 79s/epoch - 405ms/step
Epoch 623/1000
2023-09-20 03:37:31.439 
Epoch 623/1000 
	 loss: 5.0720, MinusLogProbMetric: 5.0720, val_loss: 5.1707, val_MinusLogProbMetric: 5.1707

Epoch 623: val_loss did not improve from 5.17021
196/196 - 78s - loss: 5.0720 - MinusLogProbMetric: 5.0720 - val_loss: 5.1707 - val_MinusLogProbMetric: 5.1707 - lr: 2.0833e-05 - 78s/epoch - 400ms/step
Epoch 624/1000
2023-09-20 03:38:50.550 
Epoch 624/1000 
	 loss: 5.0729, MinusLogProbMetric: 5.0729, val_loss: 5.1707, val_MinusLogProbMetric: 5.1707

Epoch 624: val_loss did not improve from 5.17021
196/196 - 79s - loss: 5.0729 - MinusLogProbMetric: 5.0729 - val_loss: 5.1707 - val_MinusLogProbMetric: 5.1707 - lr: 2.0833e-05 - 79s/epoch - 404ms/step
Epoch 625/1000
2023-09-20 03:40:09.996 
Epoch 625/1000 
	 loss: 5.0727, MinusLogProbMetric: 5.0727, val_loss: 5.1734, val_MinusLogProbMetric: 5.1734

Epoch 625: val_loss did not improve from 5.17021
196/196 - 79s - loss: 5.0727 - MinusLogProbMetric: 5.0727 - val_loss: 5.1734 - val_MinusLogProbMetric: 5.1734 - lr: 2.0833e-05 - 79s/epoch - 405ms/step
Epoch 626/1000
2023-09-20 03:41:30.262 
Epoch 626/1000 
	 loss: 5.0732, MinusLogProbMetric: 5.0732, val_loss: 5.1734, val_MinusLogProbMetric: 5.1734

Epoch 626: val_loss did not improve from 5.17021
196/196 - 80s - loss: 5.0732 - MinusLogProbMetric: 5.0732 - val_loss: 5.1734 - val_MinusLogProbMetric: 5.1734 - lr: 2.0833e-05 - 80s/epoch - 410ms/step
Epoch 627/1000
2023-09-20 03:42:50.055 
Epoch 627/1000 
	 loss: 5.0732, MinusLogProbMetric: 5.0732, val_loss: 5.1728, val_MinusLogProbMetric: 5.1728

Epoch 627: val_loss did not improve from 5.17021
196/196 - 80s - loss: 5.0732 - MinusLogProbMetric: 5.0732 - val_loss: 5.1728 - val_MinusLogProbMetric: 5.1728 - lr: 2.0833e-05 - 80s/epoch - 407ms/step
Epoch 628/1000
2023-09-20 03:44:10.427 
Epoch 628/1000 
	 loss: 5.0723, MinusLogProbMetric: 5.0723, val_loss: 5.1740, val_MinusLogProbMetric: 5.1740

Epoch 628: val_loss did not improve from 5.17021
196/196 - 80s - loss: 5.0723 - MinusLogProbMetric: 5.0723 - val_loss: 5.1740 - val_MinusLogProbMetric: 5.1740 - lr: 2.0833e-05 - 80s/epoch - 410ms/step
Epoch 629/1000
2023-09-20 03:45:30.173 
Epoch 629/1000 
	 loss: 5.0716, MinusLogProbMetric: 5.0716, val_loss: 5.1740, val_MinusLogProbMetric: 5.1740

Epoch 629: val_loss did not improve from 5.17021
196/196 - 80s - loss: 5.0716 - MinusLogProbMetric: 5.0716 - val_loss: 5.1740 - val_MinusLogProbMetric: 5.1740 - lr: 2.0833e-05 - 80s/epoch - 407ms/step
Epoch 630/1000
2023-09-20 03:46:48.988 
Epoch 630/1000 
	 loss: 5.0731, MinusLogProbMetric: 5.0731, val_loss: 5.1721, val_MinusLogProbMetric: 5.1721

Epoch 630: val_loss did not improve from 5.17021
196/196 - 79s - loss: 5.0731 - MinusLogProbMetric: 5.0731 - val_loss: 5.1721 - val_MinusLogProbMetric: 5.1721 - lr: 2.0833e-05 - 79s/epoch - 402ms/step
Epoch 631/1000
2023-09-20 03:48:08.404 
Epoch 631/1000 
	 loss: 5.0727, MinusLogProbMetric: 5.0727, val_loss: 5.1736, val_MinusLogProbMetric: 5.1736

Epoch 631: val_loss did not improve from 5.17021
196/196 - 79s - loss: 5.0727 - MinusLogProbMetric: 5.0727 - val_loss: 5.1736 - val_MinusLogProbMetric: 5.1736 - lr: 2.0833e-05 - 79s/epoch - 405ms/step
Epoch 632/1000
2023-09-20 03:49:27.896 
Epoch 632/1000 
	 loss: 5.0734, MinusLogProbMetric: 5.0734, val_loss: 5.1720, val_MinusLogProbMetric: 5.1720

Epoch 632: val_loss did not improve from 5.17021
196/196 - 79s - loss: 5.0734 - MinusLogProbMetric: 5.0734 - val_loss: 5.1720 - val_MinusLogProbMetric: 5.1720 - lr: 2.0833e-05 - 79s/epoch - 406ms/step
Epoch 633/1000
2023-09-20 03:50:47.540 
Epoch 633/1000 
	 loss: 5.0732, MinusLogProbMetric: 5.0732, val_loss: 5.1760, val_MinusLogProbMetric: 5.1760

Epoch 633: val_loss did not improve from 5.17021
196/196 - 80s - loss: 5.0732 - MinusLogProbMetric: 5.0732 - val_loss: 5.1760 - val_MinusLogProbMetric: 5.1760 - lr: 2.0833e-05 - 80s/epoch - 406ms/step
Epoch 634/1000
2023-09-20 03:52:07.869 
Epoch 634/1000 
	 loss: 5.0733, MinusLogProbMetric: 5.0733, val_loss: 5.1762, val_MinusLogProbMetric: 5.1762

Epoch 634: val_loss did not improve from 5.17021
196/196 - 80s - loss: 5.0733 - MinusLogProbMetric: 5.0733 - val_loss: 5.1762 - val_MinusLogProbMetric: 5.1762 - lr: 2.0833e-05 - 80s/epoch - 410ms/step
Epoch 635/1000
2023-09-20 03:53:29.019 
Epoch 635/1000 
	 loss: 5.0714, MinusLogProbMetric: 5.0714, val_loss: 5.1715, val_MinusLogProbMetric: 5.1715

Epoch 635: val_loss did not improve from 5.17021
196/196 - 81s - loss: 5.0714 - MinusLogProbMetric: 5.0714 - val_loss: 5.1715 - val_MinusLogProbMetric: 5.1715 - lr: 2.0833e-05 - 81s/epoch - 414ms/step
Epoch 636/1000
2023-09-20 03:54:49.604 
Epoch 636/1000 
	 loss: 5.0732, MinusLogProbMetric: 5.0732, val_loss: 5.1717, val_MinusLogProbMetric: 5.1717

Epoch 636: val_loss did not improve from 5.17021
196/196 - 81s - loss: 5.0732 - MinusLogProbMetric: 5.0732 - val_loss: 5.1717 - val_MinusLogProbMetric: 5.1717 - lr: 2.0833e-05 - 81s/epoch - 411ms/step
Epoch 637/1000
2023-09-20 03:56:11.287 
Epoch 637/1000 
	 loss: 5.0735, MinusLogProbMetric: 5.0735, val_loss: 5.1772, val_MinusLogProbMetric: 5.1772

Epoch 637: val_loss did not improve from 5.17021
196/196 - 82s - loss: 5.0735 - MinusLogProbMetric: 5.0735 - val_loss: 5.1772 - val_MinusLogProbMetric: 5.1772 - lr: 2.0833e-05 - 82s/epoch - 417ms/step
Epoch 638/1000
2023-09-20 03:57:32.226 
Epoch 638/1000 
	 loss: 5.0732, MinusLogProbMetric: 5.0732, val_loss: 5.1726, val_MinusLogProbMetric: 5.1726

Epoch 638: val_loss did not improve from 5.17021
196/196 - 81s - loss: 5.0732 - MinusLogProbMetric: 5.0732 - val_loss: 5.1726 - val_MinusLogProbMetric: 5.1726 - lr: 2.0833e-05 - 81s/epoch - 413ms/step
Epoch 639/1000
2023-09-20 03:58:54.000 
Epoch 639/1000 
	 loss: 5.0724, MinusLogProbMetric: 5.0724, val_loss: 5.1731, val_MinusLogProbMetric: 5.1731

Epoch 639: val_loss did not improve from 5.17021
196/196 - 82s - loss: 5.0724 - MinusLogProbMetric: 5.0724 - val_loss: 5.1731 - val_MinusLogProbMetric: 5.1731 - lr: 2.0833e-05 - 82s/epoch - 417ms/step
Epoch 640/1000
2023-09-20 04:00:15.896 
Epoch 640/1000 
	 loss: 5.0713, MinusLogProbMetric: 5.0713, val_loss: 5.1709, val_MinusLogProbMetric: 5.1709

Epoch 640: val_loss did not improve from 5.17021
196/196 - 82s - loss: 5.0713 - MinusLogProbMetric: 5.0713 - val_loss: 5.1709 - val_MinusLogProbMetric: 5.1709 - lr: 2.0833e-05 - 82s/epoch - 418ms/step
Epoch 641/1000
2023-09-20 04:01:37.834 
Epoch 641/1000 
	 loss: 5.0727, MinusLogProbMetric: 5.0727, val_loss: 5.1779, val_MinusLogProbMetric: 5.1779

Epoch 641: val_loss did not improve from 5.17021
196/196 - 82s - loss: 5.0727 - MinusLogProbMetric: 5.0727 - val_loss: 5.1779 - val_MinusLogProbMetric: 5.1779 - lr: 2.0833e-05 - 82s/epoch - 418ms/step
Epoch 642/1000
2023-09-20 04:02:59.117 
Epoch 642/1000 
	 loss: 5.0733, MinusLogProbMetric: 5.0733, val_loss: 5.1713, val_MinusLogProbMetric: 5.1713

Epoch 642: val_loss did not improve from 5.17021
196/196 - 81s - loss: 5.0733 - MinusLogProbMetric: 5.0733 - val_loss: 5.1713 - val_MinusLogProbMetric: 5.1713 - lr: 2.0833e-05 - 81s/epoch - 415ms/step
Epoch 643/1000
2023-09-20 04:04:20.174 
Epoch 643/1000 
	 loss: 5.0732, MinusLogProbMetric: 5.0732, val_loss: 5.1705, val_MinusLogProbMetric: 5.1705

Epoch 643: val_loss did not improve from 5.17021
196/196 - 81s - loss: 5.0732 - MinusLogProbMetric: 5.0732 - val_loss: 5.1705 - val_MinusLogProbMetric: 5.1705 - lr: 2.0833e-05 - 81s/epoch - 414ms/step
Epoch 644/1000
2023-09-20 04:05:41.365 
Epoch 644/1000 
	 loss: 5.0722, MinusLogProbMetric: 5.0722, val_loss: 5.1713, val_MinusLogProbMetric: 5.1713

Epoch 644: val_loss did not improve from 5.17021
196/196 - 81s - loss: 5.0722 - MinusLogProbMetric: 5.0722 - val_loss: 5.1713 - val_MinusLogProbMetric: 5.1713 - lr: 2.0833e-05 - 81s/epoch - 414ms/step
Epoch 645/1000
2023-09-20 04:07:02.629 
Epoch 645/1000 
	 loss: 5.0729, MinusLogProbMetric: 5.0729, val_loss: 5.1717, val_MinusLogProbMetric: 5.1717

Epoch 645: val_loss did not improve from 5.17021
196/196 - 81s - loss: 5.0729 - MinusLogProbMetric: 5.0729 - val_loss: 5.1717 - val_MinusLogProbMetric: 5.1717 - lr: 2.0833e-05 - 81s/epoch - 415ms/step
Epoch 646/1000
2023-09-20 04:08:23.701 
Epoch 646/1000 
	 loss: 5.0724, MinusLogProbMetric: 5.0724, val_loss: 5.1737, val_MinusLogProbMetric: 5.1737

Epoch 646: val_loss did not improve from 5.17021
196/196 - 81s - loss: 5.0724 - MinusLogProbMetric: 5.0724 - val_loss: 5.1737 - val_MinusLogProbMetric: 5.1737 - lr: 2.0833e-05 - 81s/epoch - 414ms/step
Epoch 647/1000
2023-09-20 04:09:45.143 
Epoch 647/1000 
	 loss: 5.0732, MinusLogProbMetric: 5.0732, val_loss: 5.1732, val_MinusLogProbMetric: 5.1732

Epoch 647: val_loss did not improve from 5.17021
196/196 - 81s - loss: 5.0732 - MinusLogProbMetric: 5.0732 - val_loss: 5.1732 - val_MinusLogProbMetric: 5.1732 - lr: 2.0833e-05 - 81s/epoch - 416ms/step
Epoch 648/1000
2023-09-20 04:11:05.644 
Epoch 648/1000 
	 loss: 5.0723, MinusLogProbMetric: 5.0723, val_loss: 5.1739, val_MinusLogProbMetric: 5.1739

Epoch 648: val_loss did not improve from 5.17021
196/196 - 80s - loss: 5.0723 - MinusLogProbMetric: 5.0723 - val_loss: 5.1739 - val_MinusLogProbMetric: 5.1739 - lr: 2.0833e-05 - 80s/epoch - 411ms/step
Epoch 649/1000
2023-09-20 04:12:26.650 
Epoch 649/1000 
	 loss: 5.0725, MinusLogProbMetric: 5.0725, val_loss: 5.1707, val_MinusLogProbMetric: 5.1707

Epoch 649: val_loss did not improve from 5.17021
196/196 - 81s - loss: 5.0725 - MinusLogProbMetric: 5.0725 - val_loss: 5.1707 - val_MinusLogProbMetric: 5.1707 - lr: 2.0833e-05 - 81s/epoch - 413ms/step
Epoch 650/1000
2023-09-20 04:13:46.330 
Epoch 650/1000 
	 loss: 5.0724, MinusLogProbMetric: 5.0724, val_loss: 5.1710, val_MinusLogProbMetric: 5.1710

Epoch 650: val_loss did not improve from 5.17021
196/196 - 80s - loss: 5.0724 - MinusLogProbMetric: 5.0724 - val_loss: 5.1710 - val_MinusLogProbMetric: 5.1710 - lr: 2.0833e-05 - 80s/epoch - 407ms/step
Epoch 651/1000
2023-09-20 04:15:06.063 
Epoch 651/1000 
	 loss: 5.0714, MinusLogProbMetric: 5.0714, val_loss: 5.1755, val_MinusLogProbMetric: 5.1755

Epoch 651: val_loss did not improve from 5.17021
196/196 - 80s - loss: 5.0714 - MinusLogProbMetric: 5.0714 - val_loss: 5.1755 - val_MinusLogProbMetric: 5.1755 - lr: 2.0833e-05 - 80s/epoch - 407ms/step
Epoch 652/1000
2023-09-20 04:16:26.156 
Epoch 652/1000 
	 loss: 5.0721, MinusLogProbMetric: 5.0721, val_loss: 5.1710, val_MinusLogProbMetric: 5.1710

Epoch 652: val_loss did not improve from 5.17021
196/196 - 80s - loss: 5.0721 - MinusLogProbMetric: 5.0721 - val_loss: 5.1710 - val_MinusLogProbMetric: 5.1710 - lr: 2.0833e-05 - 80s/epoch - 409ms/step
Epoch 653/1000
2023-09-20 04:17:45.924 
Epoch 653/1000 
	 loss: 5.0682, MinusLogProbMetric: 5.0682, val_loss: 5.1694, val_MinusLogProbMetric: 5.1694

Epoch 653: val_loss improved from 5.17021 to 5.16938, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 81s - loss: 5.0682 - MinusLogProbMetric: 5.0682 - val_loss: 5.1694 - val_MinusLogProbMetric: 5.1694 - lr: 1.0417e-05 - 81s/epoch - 414ms/step
Epoch 654/1000
2023-09-20 04:19:07.378 
Epoch 654/1000 
	 loss: 5.0677, MinusLogProbMetric: 5.0677, val_loss: 5.1709, val_MinusLogProbMetric: 5.1709

Epoch 654: val_loss did not improve from 5.16938
196/196 - 80s - loss: 5.0677 - MinusLogProbMetric: 5.0677 - val_loss: 5.1709 - val_MinusLogProbMetric: 5.1709 - lr: 1.0417e-05 - 80s/epoch - 409ms/step
Epoch 655/1000
2023-09-20 04:20:27.715 
Epoch 655/1000 
	 loss: 5.0681, MinusLogProbMetric: 5.0681, val_loss: 5.1708, val_MinusLogProbMetric: 5.1708

Epoch 655: val_loss did not improve from 5.16938
196/196 - 80s - loss: 5.0681 - MinusLogProbMetric: 5.0681 - val_loss: 5.1708 - val_MinusLogProbMetric: 5.1708 - lr: 1.0417e-05 - 80s/epoch - 410ms/step
Epoch 656/1000
2023-09-20 04:21:47.599 
Epoch 656/1000 
	 loss: 5.0681, MinusLogProbMetric: 5.0681, val_loss: 5.1696, val_MinusLogProbMetric: 5.1696

Epoch 656: val_loss did not improve from 5.16938
196/196 - 80s - loss: 5.0681 - MinusLogProbMetric: 5.0681 - val_loss: 5.1696 - val_MinusLogProbMetric: 5.1696 - lr: 1.0417e-05 - 80s/epoch - 408ms/step
Epoch 657/1000
2023-09-20 04:23:06.699 
Epoch 657/1000 
	 loss: 5.0684, MinusLogProbMetric: 5.0684, val_loss: 5.1704, val_MinusLogProbMetric: 5.1704

Epoch 657: val_loss did not improve from 5.16938
196/196 - 79s - loss: 5.0684 - MinusLogProbMetric: 5.0684 - val_loss: 5.1704 - val_MinusLogProbMetric: 5.1704 - lr: 1.0417e-05 - 79s/epoch - 404ms/step
Epoch 658/1000
2023-09-20 04:24:26.343 
Epoch 658/1000 
	 loss: 5.0683, MinusLogProbMetric: 5.0683, val_loss: 5.1721, val_MinusLogProbMetric: 5.1721

Epoch 658: val_loss did not improve from 5.16938
196/196 - 80s - loss: 5.0683 - MinusLogProbMetric: 5.0683 - val_loss: 5.1721 - val_MinusLogProbMetric: 5.1721 - lr: 1.0417e-05 - 80s/epoch - 406ms/step
Epoch 659/1000
2023-09-20 04:25:46.057 
Epoch 659/1000 
	 loss: 5.0679, MinusLogProbMetric: 5.0679, val_loss: 5.1698, val_MinusLogProbMetric: 5.1698

Epoch 659: val_loss did not improve from 5.16938
196/196 - 80s - loss: 5.0679 - MinusLogProbMetric: 5.0679 - val_loss: 5.1698 - val_MinusLogProbMetric: 5.1698 - lr: 1.0417e-05 - 80s/epoch - 407ms/step
Epoch 660/1000
2023-09-20 04:27:05.711 
Epoch 660/1000 
	 loss: 5.0679, MinusLogProbMetric: 5.0679, val_loss: 5.1696, val_MinusLogProbMetric: 5.1696

Epoch 660: val_loss did not improve from 5.16938
196/196 - 80s - loss: 5.0679 - MinusLogProbMetric: 5.0679 - val_loss: 5.1696 - val_MinusLogProbMetric: 5.1696 - lr: 1.0417e-05 - 80s/epoch - 406ms/step
Epoch 661/1000
2023-09-20 04:28:25.285 
Epoch 661/1000 
	 loss: 5.0683, MinusLogProbMetric: 5.0683, val_loss: 5.1705, val_MinusLogProbMetric: 5.1705

Epoch 661: val_loss did not improve from 5.16938
196/196 - 80s - loss: 5.0683 - MinusLogProbMetric: 5.0683 - val_loss: 5.1705 - val_MinusLogProbMetric: 5.1705 - lr: 1.0417e-05 - 80s/epoch - 406ms/step
Epoch 662/1000
2023-09-20 04:29:44.542 
Epoch 662/1000 
	 loss: 5.0676, MinusLogProbMetric: 5.0676, val_loss: 5.1693, val_MinusLogProbMetric: 5.1693

Epoch 662: val_loss improved from 5.16938 to 5.16926, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 81s - loss: 5.0676 - MinusLogProbMetric: 5.0676 - val_loss: 5.1693 - val_MinusLogProbMetric: 5.1693 - lr: 1.0417e-05 - 81s/epoch - 413ms/step
Epoch 663/1000
2023-09-20 04:31:05.980 
Epoch 663/1000 
	 loss: 5.0680, MinusLogProbMetric: 5.0680, val_loss: 5.1718, val_MinusLogProbMetric: 5.1718

Epoch 663: val_loss did not improve from 5.16926
196/196 - 80s - loss: 5.0680 - MinusLogProbMetric: 5.0680 - val_loss: 5.1718 - val_MinusLogProbMetric: 5.1718 - lr: 1.0417e-05 - 80s/epoch - 407ms/step
Epoch 664/1000
2023-09-20 04:32:26.130 
Epoch 664/1000 
	 loss: 5.0680, MinusLogProbMetric: 5.0680, val_loss: 5.1697, val_MinusLogProbMetric: 5.1697

Epoch 664: val_loss did not improve from 5.16926
196/196 - 80s - loss: 5.0680 - MinusLogProbMetric: 5.0680 - val_loss: 5.1697 - val_MinusLogProbMetric: 5.1697 - lr: 1.0417e-05 - 80s/epoch - 409ms/step
Epoch 665/1000
2023-09-20 04:33:45.466 
Epoch 665/1000 
	 loss: 5.0682, MinusLogProbMetric: 5.0682, val_loss: 5.1694, val_MinusLogProbMetric: 5.1694

Epoch 665: val_loss did not improve from 5.16926
196/196 - 79s - loss: 5.0682 - MinusLogProbMetric: 5.0682 - val_loss: 5.1694 - val_MinusLogProbMetric: 5.1694 - lr: 1.0417e-05 - 79s/epoch - 405ms/step
Epoch 666/1000
2023-09-20 04:35:05.902 
Epoch 666/1000 
	 loss: 5.0680, MinusLogProbMetric: 5.0680, val_loss: 5.1700, val_MinusLogProbMetric: 5.1700

Epoch 666: val_loss did not improve from 5.16926
196/196 - 80s - loss: 5.0680 - MinusLogProbMetric: 5.0680 - val_loss: 5.1700 - val_MinusLogProbMetric: 5.1700 - lr: 1.0417e-05 - 80s/epoch - 410ms/step
Epoch 667/1000
2023-09-20 04:36:25.566 
Epoch 667/1000 
	 loss: 5.0682, MinusLogProbMetric: 5.0682, val_loss: 5.1694, val_MinusLogProbMetric: 5.1694

Epoch 667: val_loss did not improve from 5.16926
196/196 - 80s - loss: 5.0682 - MinusLogProbMetric: 5.0682 - val_loss: 5.1694 - val_MinusLogProbMetric: 5.1694 - lr: 1.0417e-05 - 80s/epoch - 406ms/step
Epoch 668/1000
2023-09-20 04:37:46.044 
Epoch 668/1000 
	 loss: 5.0681, MinusLogProbMetric: 5.0681, val_loss: 5.1695, val_MinusLogProbMetric: 5.1695

Epoch 668: val_loss did not improve from 5.16926
196/196 - 80s - loss: 5.0681 - MinusLogProbMetric: 5.0681 - val_loss: 5.1695 - val_MinusLogProbMetric: 5.1695 - lr: 1.0417e-05 - 80s/epoch - 411ms/step
Epoch 669/1000
2023-09-20 04:39:05.662 
Epoch 669/1000 
	 loss: 5.0676, MinusLogProbMetric: 5.0676, val_loss: 5.1708, val_MinusLogProbMetric: 5.1708

Epoch 669: val_loss did not improve from 5.16926
196/196 - 80s - loss: 5.0676 - MinusLogProbMetric: 5.0676 - val_loss: 5.1708 - val_MinusLogProbMetric: 5.1708 - lr: 1.0417e-05 - 80s/epoch - 406ms/step
Epoch 670/1000
2023-09-20 04:40:25.929 
Epoch 670/1000 
	 loss: 5.0683, MinusLogProbMetric: 5.0683, val_loss: 5.1701, val_MinusLogProbMetric: 5.1701

Epoch 670: val_loss did not improve from 5.16926
196/196 - 80s - loss: 5.0683 - MinusLogProbMetric: 5.0683 - val_loss: 5.1701 - val_MinusLogProbMetric: 5.1701 - lr: 1.0417e-05 - 80s/epoch - 410ms/step
Epoch 671/1000
2023-09-20 04:41:45.802 
Epoch 671/1000 
	 loss: 5.0677, MinusLogProbMetric: 5.0677, val_loss: 5.1700, val_MinusLogProbMetric: 5.1700

Epoch 671: val_loss did not improve from 5.16926
196/196 - 80s - loss: 5.0677 - MinusLogProbMetric: 5.0677 - val_loss: 5.1700 - val_MinusLogProbMetric: 5.1700 - lr: 1.0417e-05 - 80s/epoch - 408ms/step
Epoch 672/1000
2023-09-20 04:43:00.715 
Epoch 672/1000 
	 loss: 5.0678, MinusLogProbMetric: 5.0678, val_loss: 5.1693, val_MinusLogProbMetric: 5.1693

Epoch 672: val_loss improved from 5.16926 to 5.16925, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 76s - loss: 5.0678 - MinusLogProbMetric: 5.0678 - val_loss: 5.1693 - val_MinusLogProbMetric: 5.1693 - lr: 1.0417e-05 - 76s/epoch - 387ms/step
Epoch 673/1000
2023-09-20 04:44:11.078 
Epoch 673/1000 
	 loss: 5.0682, MinusLogProbMetric: 5.0682, val_loss: 5.1699, val_MinusLogProbMetric: 5.1699

Epoch 673: val_loss did not improve from 5.16925
196/196 - 70s - loss: 5.0682 - MinusLogProbMetric: 5.0682 - val_loss: 5.1699 - val_MinusLogProbMetric: 5.1699 - lr: 1.0417e-05 - 70s/epoch - 355ms/step
Epoch 674/1000
2023-09-20 04:45:19.128 
Epoch 674/1000 
	 loss: 5.0681, MinusLogProbMetric: 5.0681, val_loss: 5.1698, val_MinusLogProbMetric: 5.1698

Epoch 674: val_loss did not improve from 5.16925
196/196 - 68s - loss: 5.0681 - MinusLogProbMetric: 5.0681 - val_loss: 5.1698 - val_MinusLogProbMetric: 5.1698 - lr: 1.0417e-05 - 68s/epoch - 347ms/step
Epoch 675/1000
2023-09-20 04:46:29.285 
Epoch 675/1000 
	 loss: 5.0678, MinusLogProbMetric: 5.0678, val_loss: 5.1696, val_MinusLogProbMetric: 5.1696

Epoch 675: val_loss did not improve from 5.16925
196/196 - 70s - loss: 5.0678 - MinusLogProbMetric: 5.0678 - val_loss: 5.1696 - val_MinusLogProbMetric: 5.1696 - lr: 1.0417e-05 - 70s/epoch - 358ms/step
Epoch 676/1000
2023-09-20 04:47:41.456 
Epoch 676/1000 
	 loss: 5.0685, MinusLogProbMetric: 5.0685, val_loss: 5.1684, val_MinusLogProbMetric: 5.1684

Epoch 676: val_loss improved from 5.16925 to 5.16838, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 73s - loss: 5.0685 - MinusLogProbMetric: 5.0685 - val_loss: 5.1684 - val_MinusLogProbMetric: 5.1684 - lr: 1.0417e-05 - 73s/epoch - 375ms/step
Epoch 677/1000
2023-09-20 04:48:50.969 
Epoch 677/1000 
	 loss: 5.0678, MinusLogProbMetric: 5.0678, val_loss: 5.1687, val_MinusLogProbMetric: 5.1687

Epoch 677: val_loss did not improve from 5.16838
196/196 - 68s - loss: 5.0678 - MinusLogProbMetric: 5.0678 - val_loss: 5.1687 - val_MinusLogProbMetric: 5.1687 - lr: 1.0417e-05 - 68s/epoch - 348ms/step
Epoch 678/1000
2023-09-20 04:50:03.736 
Epoch 678/1000 
	 loss: 5.0679, MinusLogProbMetric: 5.0679, val_loss: 5.1706, val_MinusLogProbMetric: 5.1706

Epoch 678: val_loss did not improve from 5.16838
196/196 - 73s - loss: 5.0679 - MinusLogProbMetric: 5.0679 - val_loss: 5.1706 - val_MinusLogProbMetric: 5.1706 - lr: 1.0417e-05 - 73s/epoch - 371ms/step
Epoch 679/1000
2023-09-20 04:51:23.458 
Epoch 679/1000 
	 loss: 5.0678, MinusLogProbMetric: 5.0678, val_loss: 5.1687, val_MinusLogProbMetric: 5.1687

Epoch 679: val_loss did not improve from 5.16838
196/196 - 80s - loss: 5.0678 - MinusLogProbMetric: 5.0678 - val_loss: 5.1687 - val_MinusLogProbMetric: 5.1687 - lr: 1.0417e-05 - 80s/epoch - 407ms/step
Epoch 680/1000
2023-09-20 04:52:45.341 
Epoch 680/1000 
	 loss: 5.0680, MinusLogProbMetric: 5.0680, val_loss: 5.1686, val_MinusLogProbMetric: 5.1686

Epoch 680: val_loss did not improve from 5.16838
196/196 - 82s - loss: 5.0680 - MinusLogProbMetric: 5.0680 - val_loss: 5.1686 - val_MinusLogProbMetric: 5.1686 - lr: 1.0417e-05 - 82s/epoch - 418ms/step
Epoch 681/1000
2023-09-20 04:53:58.622 
Epoch 681/1000 
	 loss: 5.0676, MinusLogProbMetric: 5.0676, val_loss: 5.1703, val_MinusLogProbMetric: 5.1703

Epoch 681: val_loss did not improve from 5.16838
196/196 - 73s - loss: 5.0676 - MinusLogProbMetric: 5.0676 - val_loss: 5.1703 - val_MinusLogProbMetric: 5.1703 - lr: 1.0417e-05 - 73s/epoch - 374ms/step
Epoch 682/1000
2023-09-20 04:55:08.889 
Epoch 682/1000 
	 loss: 5.0681, MinusLogProbMetric: 5.0681, val_loss: 5.1702, val_MinusLogProbMetric: 5.1702

Epoch 682: val_loss did not improve from 5.16838
196/196 - 70s - loss: 5.0681 - MinusLogProbMetric: 5.0681 - val_loss: 5.1702 - val_MinusLogProbMetric: 5.1702 - lr: 1.0417e-05 - 70s/epoch - 358ms/step
Epoch 683/1000
2023-09-20 04:56:29.191 
Epoch 683/1000 
	 loss: 5.0679, MinusLogProbMetric: 5.0679, val_loss: 5.1720, val_MinusLogProbMetric: 5.1720

Epoch 683: val_loss did not improve from 5.16838
196/196 - 80s - loss: 5.0679 - MinusLogProbMetric: 5.0679 - val_loss: 5.1720 - val_MinusLogProbMetric: 5.1720 - lr: 1.0417e-05 - 80s/epoch - 410ms/step
Epoch 684/1000
2023-09-20 04:57:48.927 
Epoch 684/1000 
	 loss: 5.0678, MinusLogProbMetric: 5.0678, val_loss: 5.1692, val_MinusLogProbMetric: 5.1692

Epoch 684: val_loss did not improve from 5.16838
196/196 - 80s - loss: 5.0678 - MinusLogProbMetric: 5.0678 - val_loss: 5.1692 - val_MinusLogProbMetric: 5.1692 - lr: 1.0417e-05 - 80s/epoch - 407ms/step
Epoch 685/1000
2023-09-20 04:59:09.392 
Epoch 685/1000 
	 loss: 5.0681, MinusLogProbMetric: 5.0681, val_loss: 5.1687, val_MinusLogProbMetric: 5.1687

Epoch 685: val_loss did not improve from 5.16838
196/196 - 80s - loss: 5.0681 - MinusLogProbMetric: 5.0681 - val_loss: 5.1687 - val_MinusLogProbMetric: 5.1687 - lr: 1.0417e-05 - 80s/epoch - 410ms/step
Epoch 686/1000
2023-09-20 05:00:30.326 
Epoch 686/1000 
	 loss: 5.0680, MinusLogProbMetric: 5.0680, val_loss: 5.1686, val_MinusLogProbMetric: 5.1686

Epoch 686: val_loss did not improve from 5.16838
196/196 - 81s - loss: 5.0680 - MinusLogProbMetric: 5.0680 - val_loss: 5.1686 - val_MinusLogProbMetric: 5.1686 - lr: 1.0417e-05 - 81s/epoch - 413ms/step
Epoch 687/1000
2023-09-20 05:01:51.861 
Epoch 687/1000 
	 loss: 5.0677, MinusLogProbMetric: 5.0677, val_loss: 5.1708, val_MinusLogProbMetric: 5.1708

Epoch 687: val_loss did not improve from 5.16838
196/196 - 82s - loss: 5.0677 - MinusLogProbMetric: 5.0677 - val_loss: 5.1708 - val_MinusLogProbMetric: 5.1708 - lr: 1.0417e-05 - 82s/epoch - 416ms/step
Epoch 688/1000
2023-09-20 05:03:12.842 
Epoch 688/1000 
	 loss: 5.0675, MinusLogProbMetric: 5.0675, val_loss: 5.1704, val_MinusLogProbMetric: 5.1704

Epoch 688: val_loss did not improve from 5.16838
196/196 - 81s - loss: 5.0675 - MinusLogProbMetric: 5.0675 - val_loss: 5.1704 - val_MinusLogProbMetric: 5.1704 - lr: 1.0417e-05 - 81s/epoch - 413ms/step
Epoch 689/1000
2023-09-20 05:04:33.521 
Epoch 689/1000 
	 loss: 5.0673, MinusLogProbMetric: 5.0673, val_loss: 5.1700, val_MinusLogProbMetric: 5.1700

Epoch 689: val_loss did not improve from 5.16838
196/196 - 81s - loss: 5.0673 - MinusLogProbMetric: 5.0673 - val_loss: 5.1700 - val_MinusLogProbMetric: 5.1700 - lr: 1.0417e-05 - 81s/epoch - 412ms/step
Epoch 690/1000
2023-09-20 05:05:54.557 
Epoch 690/1000 
	 loss: 5.0675, MinusLogProbMetric: 5.0675, val_loss: 5.1705, val_MinusLogProbMetric: 5.1705

Epoch 690: val_loss did not improve from 5.16838
196/196 - 81s - loss: 5.0675 - MinusLogProbMetric: 5.0675 - val_loss: 5.1705 - val_MinusLogProbMetric: 5.1705 - lr: 1.0417e-05 - 81s/epoch - 413ms/step
Epoch 691/1000
2023-09-20 05:07:15.661 
Epoch 691/1000 
	 loss: 5.0677, MinusLogProbMetric: 5.0677, val_loss: 5.1705, val_MinusLogProbMetric: 5.1705

Epoch 691: val_loss did not improve from 5.16838
196/196 - 81s - loss: 5.0677 - MinusLogProbMetric: 5.0677 - val_loss: 5.1705 - val_MinusLogProbMetric: 5.1705 - lr: 1.0417e-05 - 81s/epoch - 414ms/step
Epoch 692/1000
2023-09-20 05:08:36.803 
Epoch 692/1000 
	 loss: 5.0678, MinusLogProbMetric: 5.0678, val_loss: 5.1686, val_MinusLogProbMetric: 5.1686

Epoch 692: val_loss did not improve from 5.16838
196/196 - 81s - loss: 5.0678 - MinusLogProbMetric: 5.0678 - val_loss: 5.1686 - val_MinusLogProbMetric: 5.1686 - lr: 1.0417e-05 - 81s/epoch - 414ms/step
Epoch 693/1000
2023-09-20 05:09:57.131 
Epoch 693/1000 
	 loss: 5.0674, MinusLogProbMetric: 5.0674, val_loss: 5.1683, val_MinusLogProbMetric: 5.1683

Epoch 693: val_loss improved from 5.16838 to 5.16825, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 5.0674 - MinusLogProbMetric: 5.0674 - val_loss: 5.1683 - val_MinusLogProbMetric: 5.1683 - lr: 1.0417e-05 - 82s/epoch - 417ms/step
Epoch 694/1000
2023-09-20 05:11:19.615 
Epoch 694/1000 
	 loss: 5.0681, MinusLogProbMetric: 5.0681, val_loss: 5.1691, val_MinusLogProbMetric: 5.1691

Epoch 694: val_loss did not improve from 5.16825
196/196 - 81s - loss: 5.0681 - MinusLogProbMetric: 5.0681 - val_loss: 5.1691 - val_MinusLogProbMetric: 5.1691 - lr: 1.0417e-05 - 81s/epoch - 414ms/step
Epoch 695/1000
2023-09-20 05:12:40.447 
Epoch 695/1000 
	 loss: 5.0677, MinusLogProbMetric: 5.0677, val_loss: 5.1694, val_MinusLogProbMetric: 5.1694

Epoch 695: val_loss did not improve from 5.16825
196/196 - 81s - loss: 5.0677 - MinusLogProbMetric: 5.0677 - val_loss: 5.1694 - val_MinusLogProbMetric: 5.1694 - lr: 1.0417e-05 - 81s/epoch - 412ms/step
Epoch 696/1000
2023-09-20 05:14:01.539 
Epoch 696/1000 
	 loss: 5.0679, MinusLogProbMetric: 5.0679, val_loss: 5.1692, val_MinusLogProbMetric: 5.1692

Epoch 696: val_loss did not improve from 5.16825
196/196 - 81s - loss: 5.0679 - MinusLogProbMetric: 5.0679 - val_loss: 5.1692 - val_MinusLogProbMetric: 5.1692 - lr: 1.0417e-05 - 81s/epoch - 414ms/step
Epoch 697/1000
2023-09-20 05:15:22.119 
Epoch 697/1000 
	 loss: 5.0681, MinusLogProbMetric: 5.0681, val_loss: 5.1748, val_MinusLogProbMetric: 5.1748

Epoch 697: val_loss did not improve from 5.16825
196/196 - 81s - loss: 5.0681 - MinusLogProbMetric: 5.0681 - val_loss: 5.1748 - val_MinusLogProbMetric: 5.1748 - lr: 1.0417e-05 - 81s/epoch - 411ms/step
Epoch 698/1000
2023-09-20 05:16:41.834 
Epoch 698/1000 
	 loss: 5.0680, MinusLogProbMetric: 5.0680, val_loss: 5.1692, val_MinusLogProbMetric: 5.1692

Epoch 698: val_loss did not improve from 5.16825
196/196 - 80s - loss: 5.0680 - MinusLogProbMetric: 5.0680 - val_loss: 5.1692 - val_MinusLogProbMetric: 5.1692 - lr: 1.0417e-05 - 80s/epoch - 407ms/step
Epoch 699/1000
2023-09-20 05:18:03.015 
Epoch 699/1000 
	 loss: 5.0680, MinusLogProbMetric: 5.0680, val_loss: 5.1686, val_MinusLogProbMetric: 5.1686

Epoch 699: val_loss did not improve from 5.16825
196/196 - 81s - loss: 5.0680 - MinusLogProbMetric: 5.0680 - val_loss: 5.1686 - val_MinusLogProbMetric: 5.1686 - lr: 1.0417e-05 - 81s/epoch - 415ms/step
Epoch 700/1000
2023-09-20 05:19:23.718 
Epoch 700/1000 
	 loss: 5.0679, MinusLogProbMetric: 5.0679, val_loss: 5.1693, val_MinusLogProbMetric: 5.1693

Epoch 700: val_loss did not improve from 5.16825
196/196 - 81s - loss: 5.0679 - MinusLogProbMetric: 5.0679 - val_loss: 5.1693 - val_MinusLogProbMetric: 5.1693 - lr: 1.0417e-05 - 81s/epoch - 411ms/step
Epoch 701/1000
2023-09-20 05:20:44.978 
Epoch 701/1000 
	 loss: 5.0682, MinusLogProbMetric: 5.0682, val_loss: 5.1708, val_MinusLogProbMetric: 5.1708

Epoch 701: val_loss did not improve from 5.16825
196/196 - 81s - loss: 5.0682 - MinusLogProbMetric: 5.0682 - val_loss: 5.1708 - val_MinusLogProbMetric: 5.1708 - lr: 1.0417e-05 - 81s/epoch - 415ms/step
Epoch 702/1000
2023-09-20 05:22:05.483 
Epoch 702/1000 
	 loss: 5.0681, MinusLogProbMetric: 5.0681, val_loss: 5.1682, val_MinusLogProbMetric: 5.1682

Epoch 702: val_loss improved from 5.16825 to 5.16818, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 81s - loss: 5.0681 - MinusLogProbMetric: 5.0681 - val_loss: 5.1682 - val_MinusLogProbMetric: 5.1682 - lr: 1.0417e-05 - 81s/epoch - 415ms/step
Epoch 703/1000
2023-09-20 05:23:26.785 
Epoch 703/1000 
	 loss: 5.0678, MinusLogProbMetric: 5.0678, val_loss: 5.1683, val_MinusLogProbMetric: 5.1683

Epoch 703: val_loss did not improve from 5.16818
196/196 - 81s - loss: 5.0678 - MinusLogProbMetric: 5.0678 - val_loss: 5.1683 - val_MinusLogProbMetric: 5.1683 - lr: 1.0417e-05 - 81s/epoch - 411ms/step
Epoch 704/1000
2023-09-20 05:24:47.400 
Epoch 704/1000 
	 loss: 5.0672, MinusLogProbMetric: 5.0672, val_loss: 5.1710, val_MinusLogProbMetric: 5.1710

Epoch 704: val_loss did not improve from 5.16818
196/196 - 81s - loss: 5.0672 - MinusLogProbMetric: 5.0672 - val_loss: 5.1710 - val_MinusLogProbMetric: 5.1710 - lr: 1.0417e-05 - 81s/epoch - 411ms/step
Epoch 705/1000
2023-09-20 05:26:08.334 
Epoch 705/1000 
	 loss: 5.0680, MinusLogProbMetric: 5.0680, val_loss: 5.1697, val_MinusLogProbMetric: 5.1697

Epoch 705: val_loss did not improve from 5.16818
196/196 - 81s - loss: 5.0680 - MinusLogProbMetric: 5.0680 - val_loss: 5.1697 - val_MinusLogProbMetric: 5.1697 - lr: 1.0417e-05 - 81s/epoch - 413ms/step
Epoch 706/1000
2023-09-20 05:27:19.715 
Epoch 706/1000 
	 loss: 5.0676, MinusLogProbMetric: 5.0676, val_loss: 5.1696, val_MinusLogProbMetric: 5.1696

Epoch 706: val_loss did not improve from 5.16818
196/196 - 71s - loss: 5.0676 - MinusLogProbMetric: 5.0676 - val_loss: 5.1696 - val_MinusLogProbMetric: 5.1696 - lr: 1.0417e-05 - 71s/epoch - 364ms/step
Epoch 707/1000
2023-09-20 05:28:30.976 
Epoch 707/1000 
	 loss: 5.0673, MinusLogProbMetric: 5.0673, val_loss: 5.1697, val_MinusLogProbMetric: 5.1697

Epoch 707: val_loss did not improve from 5.16818
196/196 - 71s - loss: 5.0673 - MinusLogProbMetric: 5.0673 - val_loss: 5.1697 - val_MinusLogProbMetric: 5.1697 - lr: 1.0417e-05 - 71s/epoch - 364ms/step
Epoch 708/1000
2023-09-20 05:29:51.709 
Epoch 708/1000 
	 loss: 5.0677, MinusLogProbMetric: 5.0677, val_loss: 5.1698, val_MinusLogProbMetric: 5.1698

Epoch 708: val_loss did not improve from 5.16818
196/196 - 81s - loss: 5.0677 - MinusLogProbMetric: 5.0677 - val_loss: 5.1698 - val_MinusLogProbMetric: 5.1698 - lr: 1.0417e-05 - 81s/epoch - 412ms/step
Epoch 709/1000
2023-09-20 05:31:12.288 
Epoch 709/1000 
	 loss: 5.0679, MinusLogProbMetric: 5.0679, val_loss: 5.1700, val_MinusLogProbMetric: 5.1700

Epoch 709: val_loss did not improve from 5.16818
196/196 - 81s - loss: 5.0679 - MinusLogProbMetric: 5.0679 - val_loss: 5.1700 - val_MinusLogProbMetric: 5.1700 - lr: 1.0417e-05 - 81s/epoch - 411ms/step
Epoch 710/1000
2023-09-20 05:32:33.357 
Epoch 710/1000 
	 loss: 5.0675, MinusLogProbMetric: 5.0675, val_loss: 5.1682, val_MinusLogProbMetric: 5.1682

Epoch 710: val_loss did not improve from 5.16818
196/196 - 81s - loss: 5.0675 - MinusLogProbMetric: 5.0675 - val_loss: 5.1682 - val_MinusLogProbMetric: 5.1682 - lr: 1.0417e-05 - 81s/epoch - 414ms/step
Epoch 711/1000
2023-09-20 05:33:53.385 
Epoch 711/1000 
	 loss: 5.0677, MinusLogProbMetric: 5.0677, val_loss: 5.1679, val_MinusLogProbMetric: 5.1679

Epoch 711: val_loss improved from 5.16818 to 5.16792, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 81s - loss: 5.0677 - MinusLogProbMetric: 5.0677 - val_loss: 5.1679 - val_MinusLogProbMetric: 5.1679 - lr: 1.0417e-05 - 81s/epoch - 415ms/step
Epoch 712/1000
2023-09-20 05:35:15.500 
Epoch 712/1000 
	 loss: 5.0668, MinusLogProbMetric: 5.0668, val_loss: 5.1675, val_MinusLogProbMetric: 5.1675

Epoch 712: val_loss improved from 5.16792 to 5.16746, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 82s - loss: 5.0668 - MinusLogProbMetric: 5.0668 - val_loss: 5.1675 - val_MinusLogProbMetric: 5.1675 - lr: 1.0417e-05 - 82s/epoch - 420ms/step
Epoch 713/1000
2023-09-20 05:36:37.169 
Epoch 713/1000 
	 loss: 5.0675, MinusLogProbMetric: 5.0675, val_loss: 5.1687, val_MinusLogProbMetric: 5.1687

Epoch 713: val_loss did not improve from 5.16746
196/196 - 80s - loss: 5.0675 - MinusLogProbMetric: 5.0675 - val_loss: 5.1687 - val_MinusLogProbMetric: 5.1687 - lr: 1.0417e-05 - 80s/epoch - 409ms/step
Epoch 714/1000
2023-09-20 05:37:58.096 
Epoch 714/1000 
	 loss: 5.0678, MinusLogProbMetric: 5.0678, val_loss: 5.1710, val_MinusLogProbMetric: 5.1710

Epoch 714: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0678 - MinusLogProbMetric: 5.0678 - val_loss: 5.1710 - val_MinusLogProbMetric: 5.1710 - lr: 1.0417e-05 - 81s/epoch - 413ms/step
Epoch 715/1000
2023-09-20 05:39:18.680 
Epoch 715/1000 
	 loss: 5.0678, MinusLogProbMetric: 5.0678, val_loss: 5.1718, val_MinusLogProbMetric: 5.1718

Epoch 715: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0678 - MinusLogProbMetric: 5.0678 - val_loss: 5.1718 - val_MinusLogProbMetric: 5.1718 - lr: 1.0417e-05 - 81s/epoch - 411ms/step
Epoch 716/1000
2023-09-20 05:40:39.530 
Epoch 716/1000 
	 loss: 5.0674, MinusLogProbMetric: 5.0674, val_loss: 5.1698, val_MinusLogProbMetric: 5.1698

Epoch 716: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0674 - MinusLogProbMetric: 5.0674 - val_loss: 5.1698 - val_MinusLogProbMetric: 5.1698 - lr: 1.0417e-05 - 81s/epoch - 412ms/step
Epoch 717/1000
2023-09-20 05:42:00.199 
Epoch 717/1000 
	 loss: 5.0674, MinusLogProbMetric: 5.0674, val_loss: 5.1723, val_MinusLogProbMetric: 5.1723

Epoch 717: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0674 - MinusLogProbMetric: 5.0674 - val_loss: 5.1723 - val_MinusLogProbMetric: 5.1723 - lr: 1.0417e-05 - 81s/epoch - 412ms/step
Epoch 718/1000
2023-09-20 05:43:19.996 
Epoch 718/1000 
	 loss: 5.0674, MinusLogProbMetric: 5.0674, val_loss: 5.1702, val_MinusLogProbMetric: 5.1702

Epoch 718: val_loss did not improve from 5.16746
196/196 - 80s - loss: 5.0674 - MinusLogProbMetric: 5.0674 - val_loss: 5.1702 - val_MinusLogProbMetric: 5.1702 - lr: 1.0417e-05 - 80s/epoch - 407ms/step
Epoch 719/1000
2023-09-20 05:44:39.839 
Epoch 719/1000 
	 loss: 5.0673, MinusLogProbMetric: 5.0673, val_loss: 5.1695, val_MinusLogProbMetric: 5.1695

Epoch 719: val_loss did not improve from 5.16746
196/196 - 80s - loss: 5.0673 - MinusLogProbMetric: 5.0673 - val_loss: 5.1695 - val_MinusLogProbMetric: 5.1695 - lr: 1.0417e-05 - 80s/epoch - 407ms/step
Epoch 720/1000
2023-09-20 05:45:59.953 
Epoch 720/1000 
	 loss: 5.0672, MinusLogProbMetric: 5.0672, val_loss: 5.1696, val_MinusLogProbMetric: 5.1696

Epoch 720: val_loss did not improve from 5.16746
196/196 - 80s - loss: 5.0672 - MinusLogProbMetric: 5.0672 - val_loss: 5.1696 - val_MinusLogProbMetric: 5.1696 - lr: 1.0417e-05 - 80s/epoch - 409ms/step
Epoch 721/1000
2023-09-20 05:47:15.715 
Epoch 721/1000 
	 loss: 5.0673, MinusLogProbMetric: 5.0673, val_loss: 5.1697, val_MinusLogProbMetric: 5.1697

Epoch 721: val_loss did not improve from 5.16746
196/196 - 76s - loss: 5.0673 - MinusLogProbMetric: 5.0673 - val_loss: 5.1697 - val_MinusLogProbMetric: 5.1697 - lr: 1.0417e-05 - 76s/epoch - 387ms/step
Epoch 722/1000
2023-09-20 05:48:30.425 
Epoch 722/1000 
	 loss: 5.0676, MinusLogProbMetric: 5.0676, val_loss: 5.1684, val_MinusLogProbMetric: 5.1684

Epoch 722: val_loss did not improve from 5.16746
196/196 - 75s - loss: 5.0676 - MinusLogProbMetric: 5.0676 - val_loss: 5.1684 - val_MinusLogProbMetric: 5.1684 - lr: 1.0417e-05 - 75s/epoch - 381ms/step
Epoch 723/1000
2023-09-20 05:49:50.876 
Epoch 723/1000 
	 loss: 5.0675, MinusLogProbMetric: 5.0675, val_loss: 5.1700, val_MinusLogProbMetric: 5.1700

Epoch 723: val_loss did not improve from 5.16746
196/196 - 80s - loss: 5.0675 - MinusLogProbMetric: 5.0675 - val_loss: 5.1700 - val_MinusLogProbMetric: 5.1700 - lr: 1.0417e-05 - 80s/epoch - 410ms/step
Epoch 724/1000
2023-09-20 05:51:11.396 
Epoch 724/1000 
	 loss: 5.0680, MinusLogProbMetric: 5.0680, val_loss: 5.1688, val_MinusLogProbMetric: 5.1688

Epoch 724: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0680 - MinusLogProbMetric: 5.0680 - val_loss: 5.1688 - val_MinusLogProbMetric: 5.1688 - lr: 1.0417e-05 - 81s/epoch - 411ms/step
Epoch 725/1000
2023-09-20 05:52:32.775 
Epoch 725/1000 
	 loss: 5.0681, MinusLogProbMetric: 5.0681, val_loss: 5.1694, val_MinusLogProbMetric: 5.1694

Epoch 725: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0681 - MinusLogProbMetric: 5.0681 - val_loss: 5.1694 - val_MinusLogProbMetric: 5.1694 - lr: 1.0417e-05 - 81s/epoch - 415ms/step
Epoch 726/1000
2023-09-20 05:53:52.624 
Epoch 726/1000 
	 loss: 5.0674, MinusLogProbMetric: 5.0674, val_loss: 5.1689, val_MinusLogProbMetric: 5.1689

Epoch 726: val_loss did not improve from 5.16746
196/196 - 80s - loss: 5.0674 - MinusLogProbMetric: 5.0674 - val_loss: 5.1689 - val_MinusLogProbMetric: 5.1689 - lr: 1.0417e-05 - 80s/epoch - 407ms/step
Epoch 727/1000
2023-09-20 05:55:13.170 
Epoch 727/1000 
	 loss: 5.0673, MinusLogProbMetric: 5.0673, val_loss: 5.1682, val_MinusLogProbMetric: 5.1682

Epoch 727: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0673 - MinusLogProbMetric: 5.0673 - val_loss: 5.1682 - val_MinusLogProbMetric: 5.1682 - lr: 1.0417e-05 - 81s/epoch - 411ms/step
Epoch 728/1000
2023-09-20 05:56:33.835 
Epoch 728/1000 
	 loss: 5.0674, MinusLogProbMetric: 5.0674, val_loss: 5.1683, val_MinusLogProbMetric: 5.1683

Epoch 728: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0674 - MinusLogProbMetric: 5.0674 - val_loss: 5.1683 - val_MinusLogProbMetric: 5.1683 - lr: 1.0417e-05 - 81s/epoch - 412ms/step
Epoch 729/1000
2023-09-20 05:57:55.172 
Epoch 729/1000 
	 loss: 5.0674, MinusLogProbMetric: 5.0674, val_loss: 5.1687, val_MinusLogProbMetric: 5.1687

Epoch 729: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0674 - MinusLogProbMetric: 5.0674 - val_loss: 5.1687 - val_MinusLogProbMetric: 5.1687 - lr: 1.0417e-05 - 81s/epoch - 415ms/step
Epoch 730/1000
2023-09-20 05:59:15.952 
Epoch 730/1000 
	 loss: 5.0681, MinusLogProbMetric: 5.0681, val_loss: 5.1687, val_MinusLogProbMetric: 5.1687

Epoch 730: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0681 - MinusLogProbMetric: 5.0681 - val_loss: 5.1687 - val_MinusLogProbMetric: 5.1687 - lr: 1.0417e-05 - 81s/epoch - 412ms/step
Epoch 731/1000
2023-09-20 06:00:37.176 
Epoch 731/1000 
	 loss: 5.0678, MinusLogProbMetric: 5.0678, val_loss: 5.1703, val_MinusLogProbMetric: 5.1703

Epoch 731: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0678 - MinusLogProbMetric: 5.0678 - val_loss: 5.1703 - val_MinusLogProbMetric: 5.1703 - lr: 1.0417e-05 - 81s/epoch - 414ms/step
Epoch 732/1000
2023-09-20 06:01:57.701 
Epoch 732/1000 
	 loss: 5.0675, MinusLogProbMetric: 5.0675, val_loss: 5.1710, val_MinusLogProbMetric: 5.1710

Epoch 732: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0675 - MinusLogProbMetric: 5.0675 - val_loss: 5.1710 - val_MinusLogProbMetric: 5.1710 - lr: 1.0417e-05 - 81s/epoch - 411ms/step
Epoch 733/1000
2023-09-20 06:03:17.978 
Epoch 733/1000 
	 loss: 5.0669, MinusLogProbMetric: 5.0669, val_loss: 5.1718, val_MinusLogProbMetric: 5.1718

Epoch 733: val_loss did not improve from 5.16746
196/196 - 80s - loss: 5.0669 - MinusLogProbMetric: 5.0669 - val_loss: 5.1718 - val_MinusLogProbMetric: 5.1718 - lr: 1.0417e-05 - 80s/epoch - 410ms/step
Epoch 734/1000
2023-09-20 06:04:37.984 
Epoch 734/1000 
	 loss: 5.0674, MinusLogProbMetric: 5.0674, val_loss: 5.1692, val_MinusLogProbMetric: 5.1692

Epoch 734: val_loss did not improve from 5.16746
196/196 - 80s - loss: 5.0674 - MinusLogProbMetric: 5.0674 - val_loss: 5.1692 - val_MinusLogProbMetric: 5.1692 - lr: 1.0417e-05 - 80s/epoch - 408ms/step
Epoch 735/1000
2023-09-20 06:05:57.619 
Epoch 735/1000 
	 loss: 5.0675, MinusLogProbMetric: 5.0675, val_loss: 5.1692, val_MinusLogProbMetric: 5.1692

Epoch 735: val_loss did not improve from 5.16746
196/196 - 80s - loss: 5.0675 - MinusLogProbMetric: 5.0675 - val_loss: 5.1692 - val_MinusLogProbMetric: 5.1692 - lr: 1.0417e-05 - 80s/epoch - 406ms/step
Epoch 736/1000
2023-09-20 06:07:18.282 
Epoch 736/1000 
	 loss: 5.0672, MinusLogProbMetric: 5.0672, val_loss: 5.1692, val_MinusLogProbMetric: 5.1692

Epoch 736: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0672 - MinusLogProbMetric: 5.0672 - val_loss: 5.1692 - val_MinusLogProbMetric: 5.1692 - lr: 1.0417e-05 - 81s/epoch - 412ms/step
Epoch 737/1000
2023-09-20 06:08:38.849 
Epoch 737/1000 
	 loss: 5.0669, MinusLogProbMetric: 5.0669, val_loss: 5.1698, val_MinusLogProbMetric: 5.1698

Epoch 737: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0669 - MinusLogProbMetric: 5.0669 - val_loss: 5.1698 - val_MinusLogProbMetric: 5.1698 - lr: 1.0417e-05 - 81s/epoch - 411ms/step
Epoch 738/1000
2023-09-20 06:09:59.704 
Epoch 738/1000 
	 loss: 5.0667, MinusLogProbMetric: 5.0667, val_loss: 5.1708, val_MinusLogProbMetric: 5.1708

Epoch 738: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0667 - MinusLogProbMetric: 5.0667 - val_loss: 5.1708 - val_MinusLogProbMetric: 5.1708 - lr: 1.0417e-05 - 81s/epoch - 413ms/step
Epoch 739/1000
2023-09-20 06:11:20.026 
Epoch 739/1000 
	 loss: 5.0670, MinusLogProbMetric: 5.0670, val_loss: 5.1698, val_MinusLogProbMetric: 5.1698

Epoch 739: val_loss did not improve from 5.16746
196/196 - 80s - loss: 5.0670 - MinusLogProbMetric: 5.0670 - val_loss: 5.1698 - val_MinusLogProbMetric: 5.1698 - lr: 1.0417e-05 - 80s/epoch - 410ms/step
Epoch 740/1000
2023-09-20 06:12:40.264 
Epoch 740/1000 
	 loss: 5.0674, MinusLogProbMetric: 5.0674, val_loss: 5.1701, val_MinusLogProbMetric: 5.1701

Epoch 740: val_loss did not improve from 5.16746
196/196 - 80s - loss: 5.0674 - MinusLogProbMetric: 5.0674 - val_loss: 5.1701 - val_MinusLogProbMetric: 5.1701 - lr: 1.0417e-05 - 80s/epoch - 409ms/step
Epoch 741/1000
2023-09-20 06:13:53.910 
Epoch 741/1000 
	 loss: 5.0675, MinusLogProbMetric: 5.0675, val_loss: 5.1709, val_MinusLogProbMetric: 5.1709

Epoch 741: val_loss did not improve from 5.16746
196/196 - 74s - loss: 5.0675 - MinusLogProbMetric: 5.0675 - val_loss: 5.1709 - val_MinusLogProbMetric: 5.1709 - lr: 1.0417e-05 - 74s/epoch - 376ms/step
Epoch 742/1000
2023-09-20 06:15:04.038 
Epoch 742/1000 
	 loss: 5.0671, MinusLogProbMetric: 5.0671, val_loss: 5.1699, val_MinusLogProbMetric: 5.1699

Epoch 742: val_loss did not improve from 5.16746
196/196 - 70s - loss: 5.0671 - MinusLogProbMetric: 5.0671 - val_loss: 5.1699 - val_MinusLogProbMetric: 5.1699 - lr: 1.0417e-05 - 70s/epoch - 358ms/step
Epoch 743/1000
2023-09-20 06:16:25.330 
Epoch 743/1000 
	 loss: 5.0677, MinusLogProbMetric: 5.0677, val_loss: 5.1690, val_MinusLogProbMetric: 5.1690

Epoch 743: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0677 - MinusLogProbMetric: 5.0677 - val_loss: 5.1690 - val_MinusLogProbMetric: 5.1690 - lr: 1.0417e-05 - 81s/epoch - 415ms/step
Epoch 744/1000
2023-09-20 06:17:45.245 
Epoch 744/1000 
	 loss: 5.0668, MinusLogProbMetric: 5.0668, val_loss: 5.1691, val_MinusLogProbMetric: 5.1691

Epoch 744: val_loss did not improve from 5.16746
196/196 - 80s - loss: 5.0668 - MinusLogProbMetric: 5.0668 - val_loss: 5.1691 - val_MinusLogProbMetric: 5.1691 - lr: 1.0417e-05 - 80s/epoch - 408ms/step
Epoch 745/1000
2023-09-20 06:19:05.954 
Epoch 745/1000 
	 loss: 5.0674, MinusLogProbMetric: 5.0674, val_loss: 5.1704, val_MinusLogProbMetric: 5.1704

Epoch 745: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0674 - MinusLogProbMetric: 5.0674 - val_loss: 5.1704 - val_MinusLogProbMetric: 5.1704 - lr: 1.0417e-05 - 81s/epoch - 412ms/step
Epoch 746/1000
2023-09-20 06:20:25.903 
Epoch 746/1000 
	 loss: 5.0673, MinusLogProbMetric: 5.0673, val_loss: 5.1704, val_MinusLogProbMetric: 5.1704

Epoch 746: val_loss did not improve from 5.16746
196/196 - 80s - loss: 5.0673 - MinusLogProbMetric: 5.0673 - val_loss: 5.1704 - val_MinusLogProbMetric: 5.1704 - lr: 1.0417e-05 - 80s/epoch - 408ms/step
Epoch 747/1000
2023-09-20 06:21:46.833 
Epoch 747/1000 
	 loss: 5.0675, MinusLogProbMetric: 5.0675, val_loss: 5.1709, val_MinusLogProbMetric: 5.1709

Epoch 747: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0675 - MinusLogProbMetric: 5.0675 - val_loss: 5.1709 - val_MinusLogProbMetric: 5.1709 - lr: 1.0417e-05 - 81s/epoch - 413ms/step
Epoch 748/1000
2023-09-20 06:23:04.112 
Epoch 748/1000 
	 loss: 5.0673, MinusLogProbMetric: 5.0673, val_loss: 5.1697, val_MinusLogProbMetric: 5.1697

Epoch 748: val_loss did not improve from 5.16746
196/196 - 77s - loss: 5.0673 - MinusLogProbMetric: 5.0673 - val_loss: 5.1697 - val_MinusLogProbMetric: 5.1697 - lr: 1.0417e-05 - 77s/epoch - 394ms/step
Epoch 749/1000
2023-09-20 06:24:15.235 
Epoch 749/1000 
	 loss: 5.0669, MinusLogProbMetric: 5.0669, val_loss: 5.1728, val_MinusLogProbMetric: 5.1728

Epoch 749: val_loss did not improve from 5.16746
196/196 - 71s - loss: 5.0669 - MinusLogProbMetric: 5.0669 - val_loss: 5.1728 - val_MinusLogProbMetric: 5.1728 - lr: 1.0417e-05 - 71s/epoch - 363ms/step
Epoch 750/1000
2023-09-20 06:25:36.284 
Epoch 750/1000 
	 loss: 5.0678, MinusLogProbMetric: 5.0678, val_loss: 5.1687, val_MinusLogProbMetric: 5.1687

Epoch 750: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0678 - MinusLogProbMetric: 5.0678 - val_loss: 5.1687 - val_MinusLogProbMetric: 5.1687 - lr: 1.0417e-05 - 81s/epoch - 413ms/step
Epoch 751/1000
2023-09-20 06:26:55.862 
Epoch 751/1000 
	 loss: 5.0670, MinusLogProbMetric: 5.0670, val_loss: 5.1685, val_MinusLogProbMetric: 5.1685

Epoch 751: val_loss did not improve from 5.16746
196/196 - 80s - loss: 5.0670 - MinusLogProbMetric: 5.0670 - val_loss: 5.1685 - val_MinusLogProbMetric: 5.1685 - lr: 1.0417e-05 - 80s/epoch - 406ms/step
Epoch 752/1000
2023-09-20 06:28:07.813 
Epoch 752/1000 
	 loss: 5.0667, MinusLogProbMetric: 5.0667, val_loss: 5.1704, val_MinusLogProbMetric: 5.1704

Epoch 752: val_loss did not improve from 5.16746
196/196 - 72s - loss: 5.0667 - MinusLogProbMetric: 5.0667 - val_loss: 5.1704 - val_MinusLogProbMetric: 5.1704 - lr: 1.0417e-05 - 72s/epoch - 367ms/step
Epoch 753/1000
2023-09-20 06:29:23.623 
Epoch 753/1000 
	 loss: 5.0669, MinusLogProbMetric: 5.0669, val_loss: 5.1688, val_MinusLogProbMetric: 5.1688

Epoch 753: val_loss did not improve from 5.16746
196/196 - 76s - loss: 5.0669 - MinusLogProbMetric: 5.0669 - val_loss: 5.1688 - val_MinusLogProbMetric: 5.1688 - lr: 1.0417e-05 - 76s/epoch - 387ms/step
Epoch 754/1000
2023-09-20 06:30:44.785 
Epoch 754/1000 
	 loss: 5.0673, MinusLogProbMetric: 5.0673, val_loss: 5.1712, val_MinusLogProbMetric: 5.1712

Epoch 754: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0673 - MinusLogProbMetric: 5.0673 - val_loss: 5.1712 - val_MinusLogProbMetric: 5.1712 - lr: 1.0417e-05 - 81s/epoch - 414ms/step
Epoch 755/1000
2023-09-20 06:32:06.346 
Epoch 755/1000 
	 loss: 5.0671, MinusLogProbMetric: 5.0671, val_loss: 5.1747, val_MinusLogProbMetric: 5.1747

Epoch 755: val_loss did not improve from 5.16746
196/196 - 82s - loss: 5.0671 - MinusLogProbMetric: 5.0671 - val_loss: 5.1747 - val_MinusLogProbMetric: 5.1747 - lr: 1.0417e-05 - 82s/epoch - 416ms/step
Epoch 756/1000
2023-09-20 06:33:27.615 
Epoch 756/1000 
	 loss: 5.0671, MinusLogProbMetric: 5.0671, val_loss: 5.1713, val_MinusLogProbMetric: 5.1713

Epoch 756: val_loss did not improve from 5.16746
196/196 - 81s - loss: 5.0671 - MinusLogProbMetric: 5.0671 - val_loss: 5.1713 - val_MinusLogProbMetric: 5.1713 - lr: 1.0417e-05 - 81s/epoch - 415ms/step
Epoch 757/1000
2023-09-20 06:34:51.260 
Epoch 757/1000 
	 loss: 5.0675, MinusLogProbMetric: 5.0675, val_loss: 5.1680, val_MinusLogProbMetric: 5.1680

Epoch 757: val_loss did not improve from 5.16746
196/196 - 84s - loss: 5.0675 - MinusLogProbMetric: 5.0675 - val_loss: 5.1680 - val_MinusLogProbMetric: 5.1680 - lr: 1.0417e-05 - 84s/epoch - 427ms/step
Epoch 758/1000
2023-09-20 06:36:14.197 
Epoch 758/1000 
	 loss: 5.0675, MinusLogProbMetric: 5.0675, val_loss: 5.1710, val_MinusLogProbMetric: 5.1710

Epoch 758: val_loss did not improve from 5.16746
196/196 - 83s - loss: 5.0675 - MinusLogProbMetric: 5.0675 - val_loss: 5.1710 - val_MinusLogProbMetric: 5.1710 - lr: 1.0417e-05 - 83s/epoch - 423ms/step
Epoch 759/1000
2023-09-20 06:37:37.805 
Epoch 759/1000 
	 loss: 5.0670, MinusLogProbMetric: 5.0670, val_loss: 5.1714, val_MinusLogProbMetric: 5.1714

Epoch 759: val_loss did not improve from 5.16746
196/196 - 84s - loss: 5.0670 - MinusLogProbMetric: 5.0670 - val_loss: 5.1714 - val_MinusLogProbMetric: 5.1714 - lr: 1.0417e-05 - 84s/epoch - 427ms/step
Epoch 760/1000
2023-09-20 06:39:00.142 
Epoch 760/1000 
	 loss: 5.0670, MinusLogProbMetric: 5.0670, val_loss: 5.1713, val_MinusLogProbMetric: 5.1713

Epoch 760: val_loss did not improve from 5.16746
196/196 - 82s - loss: 5.0670 - MinusLogProbMetric: 5.0670 - val_loss: 5.1713 - val_MinusLogProbMetric: 5.1713 - lr: 1.0417e-05 - 82s/epoch - 420ms/step
Epoch 761/1000
2023-09-20 06:40:08.172 
Epoch 761/1000 
	 loss: 5.0670, MinusLogProbMetric: 5.0670, val_loss: 5.1694, val_MinusLogProbMetric: 5.1694

Epoch 761: val_loss did not improve from 5.16746
196/196 - 68s - loss: 5.0670 - MinusLogProbMetric: 5.0670 - val_loss: 5.1694 - val_MinusLogProbMetric: 5.1694 - lr: 1.0417e-05 - 68s/epoch - 347ms/step
Epoch 762/1000
2023-09-20 06:41:21.468 
Epoch 762/1000 
	 loss: 5.0666, MinusLogProbMetric: 5.0666, val_loss: 5.1706, val_MinusLogProbMetric: 5.1706

Epoch 762: val_loss did not improve from 5.16746
196/196 - 73s - loss: 5.0666 - MinusLogProbMetric: 5.0666 - val_loss: 5.1706 - val_MinusLogProbMetric: 5.1706 - lr: 1.0417e-05 - 73s/epoch - 374ms/step
Epoch 763/1000
2023-09-20 06:42:44.764 
Epoch 763/1000 
	 loss: 5.0655, MinusLogProbMetric: 5.0655, val_loss: 5.1686, val_MinusLogProbMetric: 5.1686

Epoch 763: val_loss did not improve from 5.16746
196/196 - 83s - loss: 5.0655 - MinusLogProbMetric: 5.0655 - val_loss: 5.1686 - val_MinusLogProbMetric: 5.1686 - lr: 5.2083e-06 - 83s/epoch - 425ms/step
Epoch 764/1000
2023-09-20 06:44:09.217 
Epoch 764/1000 
	 loss: 5.0648, MinusLogProbMetric: 5.0648, val_loss: 5.1683, val_MinusLogProbMetric: 5.1683

Epoch 764: val_loss did not improve from 5.16746
196/196 - 84s - loss: 5.0648 - MinusLogProbMetric: 5.0648 - val_loss: 5.1683 - val_MinusLogProbMetric: 5.1683 - lr: 5.2083e-06 - 84s/epoch - 431ms/step
Epoch 765/1000
2023-09-20 06:45:33.738 
Epoch 765/1000 
	 loss: 5.0647, MinusLogProbMetric: 5.0647, val_loss: 5.1680, val_MinusLogProbMetric: 5.1680

Epoch 765: val_loss did not improve from 5.16746
196/196 - 85s - loss: 5.0647 - MinusLogProbMetric: 5.0647 - val_loss: 5.1680 - val_MinusLogProbMetric: 5.1680 - lr: 5.2083e-06 - 85s/epoch - 431ms/step
Epoch 766/1000
2023-09-20 06:46:57.413 
Epoch 766/1000 
	 loss: 5.0652, MinusLogProbMetric: 5.0652, val_loss: 5.1685, val_MinusLogProbMetric: 5.1685

Epoch 766: val_loss did not improve from 5.16746
196/196 - 84s - loss: 5.0652 - MinusLogProbMetric: 5.0652 - val_loss: 5.1685 - val_MinusLogProbMetric: 5.1685 - lr: 5.2083e-06 - 84s/epoch - 427ms/step
Epoch 767/1000
2023-09-20 06:48:21.075 
Epoch 767/1000 
	 loss: 5.0651, MinusLogProbMetric: 5.0651, val_loss: 5.1696, val_MinusLogProbMetric: 5.1696

Epoch 767: val_loss did not improve from 5.16746
196/196 - 84s - loss: 5.0651 - MinusLogProbMetric: 5.0651 - val_loss: 5.1696 - val_MinusLogProbMetric: 5.1696 - lr: 5.2083e-06 - 84s/epoch - 427ms/step
Epoch 768/1000
2023-09-20 06:49:44.291 
Epoch 768/1000 
	 loss: 5.0649, MinusLogProbMetric: 5.0649, val_loss: 5.1687, val_MinusLogProbMetric: 5.1687

Epoch 768: val_loss did not improve from 5.16746
196/196 - 83s - loss: 5.0649 - MinusLogProbMetric: 5.0649 - val_loss: 5.1687 - val_MinusLogProbMetric: 5.1687 - lr: 5.2083e-06 - 83s/epoch - 425ms/step
Epoch 769/1000
2023-09-20 06:51:07.892 
Epoch 769/1000 
	 loss: 5.0648, MinusLogProbMetric: 5.0648, val_loss: 5.1677, val_MinusLogProbMetric: 5.1677

Epoch 769: val_loss did not improve from 5.16746
196/196 - 84s - loss: 5.0648 - MinusLogProbMetric: 5.0648 - val_loss: 5.1677 - val_MinusLogProbMetric: 5.1677 - lr: 5.2083e-06 - 84s/epoch - 427ms/step
Epoch 770/1000
2023-09-20 06:52:27.433 
Epoch 770/1000 
	 loss: 5.0649, MinusLogProbMetric: 5.0649, val_loss: 5.1686, val_MinusLogProbMetric: 5.1686

Epoch 770: val_loss did not improve from 5.16746
196/196 - 80s - loss: 5.0649 - MinusLogProbMetric: 5.0649 - val_loss: 5.1686 - val_MinusLogProbMetric: 5.1686 - lr: 5.2083e-06 - 80s/epoch - 406ms/step
Epoch 771/1000
2023-09-20 06:53:37.898 
Epoch 771/1000 
	 loss: 5.0648, MinusLogProbMetric: 5.0648, val_loss: 5.1691, val_MinusLogProbMetric: 5.1691

Epoch 771: val_loss did not improve from 5.16746
196/196 - 70s - loss: 5.0648 - MinusLogProbMetric: 5.0648 - val_loss: 5.1691 - val_MinusLogProbMetric: 5.1691 - lr: 5.2083e-06 - 70s/epoch - 359ms/step
Epoch 772/1000
2023-09-20 06:55:01.583 
Epoch 772/1000 
	 loss: 5.0650, MinusLogProbMetric: 5.0650, val_loss: 5.1683, val_MinusLogProbMetric: 5.1683

Epoch 772: val_loss did not improve from 5.16746
196/196 - 84s - loss: 5.0650 - MinusLogProbMetric: 5.0650 - val_loss: 5.1683 - val_MinusLogProbMetric: 5.1683 - lr: 5.2083e-06 - 84s/epoch - 427ms/step
Epoch 773/1000
2023-09-20 06:56:25.504 
Epoch 773/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1691, val_MinusLogProbMetric: 5.1691

Epoch 773: val_loss did not improve from 5.16746
196/196 - 84s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1691 - val_MinusLogProbMetric: 5.1691 - lr: 5.2083e-06 - 84s/epoch - 428ms/step
Epoch 774/1000
2023-09-20 06:57:49.213 
Epoch 774/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1694, val_MinusLogProbMetric: 5.1694

Epoch 774: val_loss did not improve from 5.16746
196/196 - 84s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1694 - val_MinusLogProbMetric: 5.1694 - lr: 5.2083e-06 - 84s/epoch - 427ms/step
Epoch 775/1000
2023-09-20 06:59:13.422 
Epoch 775/1000 
	 loss: 5.0643, MinusLogProbMetric: 5.0643, val_loss: 5.1678, val_MinusLogProbMetric: 5.1678

Epoch 775: val_loss did not improve from 5.16746
196/196 - 84s - loss: 5.0643 - MinusLogProbMetric: 5.0643 - val_loss: 5.1678 - val_MinusLogProbMetric: 5.1678 - lr: 5.2083e-06 - 84s/epoch - 430ms/step
Epoch 776/1000
2023-09-20 07:00:37.263 
Epoch 776/1000 
	 loss: 5.0647, MinusLogProbMetric: 5.0647, val_loss: 5.1682, val_MinusLogProbMetric: 5.1682

Epoch 776: val_loss did not improve from 5.16746
196/196 - 84s - loss: 5.0647 - MinusLogProbMetric: 5.0647 - val_loss: 5.1682 - val_MinusLogProbMetric: 5.1682 - lr: 5.2083e-06 - 84s/epoch - 428ms/step
Epoch 777/1000
2023-09-20 07:02:00.755 
Epoch 777/1000 
	 loss: 5.0647, MinusLogProbMetric: 5.0647, val_loss: 5.1696, val_MinusLogProbMetric: 5.1696

Epoch 777: val_loss did not improve from 5.16746
196/196 - 83s - loss: 5.0647 - MinusLogProbMetric: 5.0647 - val_loss: 5.1696 - val_MinusLogProbMetric: 5.1696 - lr: 5.2083e-06 - 83s/epoch - 426ms/step
Epoch 778/1000
2023-09-20 07:03:23.923 
Epoch 778/1000 
	 loss: 5.0648, MinusLogProbMetric: 5.0648, val_loss: 5.1695, val_MinusLogProbMetric: 5.1695

Epoch 778: val_loss did not improve from 5.16746
196/196 - 83s - loss: 5.0648 - MinusLogProbMetric: 5.0648 - val_loss: 5.1695 - val_MinusLogProbMetric: 5.1695 - lr: 5.2083e-06 - 83s/epoch - 424ms/step
Epoch 779/1000
2023-09-20 07:04:47.669 
Epoch 779/1000 
	 loss: 5.0650, MinusLogProbMetric: 5.0650, val_loss: 5.1686, val_MinusLogProbMetric: 5.1686

Epoch 779: val_loss did not improve from 5.16746
196/196 - 84s - loss: 5.0650 - MinusLogProbMetric: 5.0650 - val_loss: 5.1686 - val_MinusLogProbMetric: 5.1686 - lr: 5.2083e-06 - 84s/epoch - 427ms/step
Epoch 780/1000
2023-09-20 07:06:11.194 
Epoch 780/1000 
	 loss: 5.0647, MinusLogProbMetric: 5.0647, val_loss: 5.1683, val_MinusLogProbMetric: 5.1683

Epoch 780: val_loss did not improve from 5.16746
196/196 - 84s - loss: 5.0647 - MinusLogProbMetric: 5.0647 - val_loss: 5.1683 - val_MinusLogProbMetric: 5.1683 - lr: 5.2083e-06 - 84s/epoch - 426ms/step
Epoch 781/1000
2023-09-20 07:07:35.248 
Epoch 781/1000 
	 loss: 5.0651, MinusLogProbMetric: 5.0651, val_loss: 5.1677, val_MinusLogProbMetric: 5.1677

Epoch 781: val_loss did not improve from 5.16746
196/196 - 84s - loss: 5.0651 - MinusLogProbMetric: 5.0651 - val_loss: 5.1677 - val_MinusLogProbMetric: 5.1677 - lr: 5.2083e-06 - 84s/epoch - 429ms/step
Epoch 782/1000
2023-09-20 07:08:58.243 
Epoch 782/1000 
	 loss: 5.0649, MinusLogProbMetric: 5.0649, val_loss: 5.1680, val_MinusLogProbMetric: 5.1680

Epoch 782: val_loss did not improve from 5.16746
196/196 - 83s - loss: 5.0649 - MinusLogProbMetric: 5.0649 - val_loss: 5.1680 - val_MinusLogProbMetric: 5.1680 - lr: 5.2083e-06 - 83s/epoch - 423ms/step
Epoch 783/1000
2023-09-20 07:10:21.967 
Epoch 783/1000 
	 loss: 5.0648, MinusLogProbMetric: 5.0648, val_loss: 5.1680, val_MinusLogProbMetric: 5.1680

Epoch 783: val_loss did not improve from 5.16746
196/196 - 84s - loss: 5.0648 - MinusLogProbMetric: 5.0648 - val_loss: 5.1680 - val_MinusLogProbMetric: 5.1680 - lr: 5.2083e-06 - 84s/epoch - 427ms/step
Epoch 784/1000
2023-09-20 07:11:40.476 
Epoch 784/1000 
	 loss: 5.0647, MinusLogProbMetric: 5.0647, val_loss: 5.1700, val_MinusLogProbMetric: 5.1700

Epoch 784: val_loss did not improve from 5.16746
196/196 - 79s - loss: 5.0647 - MinusLogProbMetric: 5.0647 - val_loss: 5.1700 - val_MinusLogProbMetric: 5.1700 - lr: 5.2083e-06 - 79s/epoch - 401ms/step
Epoch 785/1000
2023-09-20 07:12:52.759 
Epoch 785/1000 
	 loss: 5.0643, MinusLogProbMetric: 5.0643, val_loss: 5.1693, val_MinusLogProbMetric: 5.1693

Epoch 785: val_loss did not improve from 5.16746
196/196 - 72s - loss: 5.0643 - MinusLogProbMetric: 5.0643 - val_loss: 5.1693 - val_MinusLogProbMetric: 5.1693 - lr: 5.2083e-06 - 72s/epoch - 369ms/step
Epoch 786/1000
2023-09-20 07:14:04.776 
Epoch 786/1000 
	 loss: 5.0649, MinusLogProbMetric: 5.0649, val_loss: 5.1694, val_MinusLogProbMetric: 5.1694

Epoch 786: val_loss did not improve from 5.16746
196/196 - 72s - loss: 5.0649 - MinusLogProbMetric: 5.0649 - val_loss: 5.1694 - val_MinusLogProbMetric: 5.1694 - lr: 5.2083e-06 - 72s/epoch - 367ms/step
Epoch 787/1000
2023-09-20 07:15:14.786 
Epoch 787/1000 
	 loss: 5.0652, MinusLogProbMetric: 5.0652, val_loss: 5.1676, val_MinusLogProbMetric: 5.1676

Epoch 787: val_loss did not improve from 5.16746
196/196 - 70s - loss: 5.0652 - MinusLogProbMetric: 5.0652 - val_loss: 5.1676 - val_MinusLogProbMetric: 5.1676 - lr: 5.2083e-06 - 70s/epoch - 357ms/step
Epoch 788/1000
2023-09-20 07:16:24.370 
Epoch 788/1000 
	 loss: 5.0646, MinusLogProbMetric: 5.0646, val_loss: 5.1673, val_MinusLogProbMetric: 5.1673

Epoch 788: val_loss improved from 5.16746 to 5.16728, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 71s - loss: 5.0646 - MinusLogProbMetric: 5.0646 - val_loss: 5.1673 - val_MinusLogProbMetric: 5.1673 - lr: 5.2083e-06 - 71s/epoch - 363ms/step
Epoch 789/1000
2023-09-20 07:17:48.812 
Epoch 789/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1698, val_MinusLogProbMetric: 5.1698

Epoch 789: val_loss did not improve from 5.16728
196/196 - 83s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1698 - val_MinusLogProbMetric: 5.1698 - lr: 5.2083e-06 - 83s/epoch - 423ms/step
Epoch 790/1000
2023-09-20 07:19:12.812 
Epoch 790/1000 
	 loss: 5.0648, MinusLogProbMetric: 5.0648, val_loss: 5.1683, val_MinusLogProbMetric: 5.1683

Epoch 790: val_loss did not improve from 5.16728
196/196 - 84s - loss: 5.0648 - MinusLogProbMetric: 5.0648 - val_loss: 5.1683 - val_MinusLogProbMetric: 5.1683 - lr: 5.2083e-06 - 84s/epoch - 429ms/step
Epoch 791/1000
2023-09-20 07:20:36.545 
Epoch 791/1000 
	 loss: 5.0648, MinusLogProbMetric: 5.0648, val_loss: 5.1677, val_MinusLogProbMetric: 5.1677

Epoch 791: val_loss did not improve from 5.16728
196/196 - 84s - loss: 5.0648 - MinusLogProbMetric: 5.0648 - val_loss: 5.1677 - val_MinusLogProbMetric: 5.1677 - lr: 5.2083e-06 - 84s/epoch - 427ms/step
Epoch 792/1000
2023-09-20 07:22:00.097 
Epoch 792/1000 
	 loss: 5.0648, MinusLogProbMetric: 5.0648, val_loss: 5.1684, val_MinusLogProbMetric: 5.1684

Epoch 792: val_loss did not improve from 5.16728
196/196 - 84s - loss: 5.0648 - MinusLogProbMetric: 5.0648 - val_loss: 5.1684 - val_MinusLogProbMetric: 5.1684 - lr: 5.2083e-06 - 84s/epoch - 426ms/step
Epoch 793/1000
2023-09-20 07:23:19.041 
Epoch 793/1000 
	 loss: 5.0648, MinusLogProbMetric: 5.0648, val_loss: 5.1683, val_MinusLogProbMetric: 5.1683

Epoch 793: val_loss did not improve from 5.16728
196/196 - 79s - loss: 5.0648 - MinusLogProbMetric: 5.0648 - val_loss: 5.1683 - val_MinusLogProbMetric: 5.1683 - lr: 5.2083e-06 - 79s/epoch - 403ms/step
Epoch 794/1000
2023-09-20 07:24:25.567 
Epoch 794/1000 
	 loss: 5.0650, MinusLogProbMetric: 5.0650, val_loss: 5.1686, val_MinusLogProbMetric: 5.1686

Epoch 794: val_loss did not improve from 5.16728
196/196 - 67s - loss: 5.0650 - MinusLogProbMetric: 5.0650 - val_loss: 5.1686 - val_MinusLogProbMetric: 5.1686 - lr: 5.2083e-06 - 67s/epoch - 339ms/step
Epoch 795/1000
2023-09-20 07:25:47.125 
Epoch 795/1000 
	 loss: 5.0648, MinusLogProbMetric: 5.0648, val_loss: 5.1677, val_MinusLogProbMetric: 5.1677

Epoch 795: val_loss did not improve from 5.16728
196/196 - 82s - loss: 5.0648 - MinusLogProbMetric: 5.0648 - val_loss: 5.1677 - val_MinusLogProbMetric: 5.1677 - lr: 5.2083e-06 - 82s/epoch - 416ms/step
Epoch 796/1000
2023-09-20 07:27:09.649 
Epoch 796/1000 
	 loss: 5.0643, MinusLogProbMetric: 5.0643, val_loss: 5.1687, val_MinusLogProbMetric: 5.1687

Epoch 796: val_loss did not improve from 5.16728
196/196 - 83s - loss: 5.0643 - MinusLogProbMetric: 5.0643 - val_loss: 5.1687 - val_MinusLogProbMetric: 5.1687 - lr: 5.2083e-06 - 83s/epoch - 421ms/step
Epoch 797/1000
2023-09-20 07:28:32.582 
Epoch 797/1000 
	 loss: 5.0649, MinusLogProbMetric: 5.0649, val_loss: 5.1683, val_MinusLogProbMetric: 5.1683

Epoch 797: val_loss did not improve from 5.16728
196/196 - 83s - loss: 5.0649 - MinusLogProbMetric: 5.0649 - val_loss: 5.1683 - val_MinusLogProbMetric: 5.1683 - lr: 5.2083e-06 - 83s/epoch - 423ms/step
Epoch 798/1000
2023-09-20 07:29:56.259 
Epoch 798/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1689, val_MinusLogProbMetric: 5.1689

Epoch 798: val_loss did not improve from 5.16728
196/196 - 84s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1689 - val_MinusLogProbMetric: 5.1689 - lr: 5.2083e-06 - 84s/epoch - 427ms/step
Epoch 799/1000
2023-09-20 07:31:19.595 
Epoch 799/1000 
	 loss: 5.0649, MinusLogProbMetric: 5.0649, val_loss: 5.1675, val_MinusLogProbMetric: 5.1675

Epoch 799: val_loss did not improve from 5.16728
196/196 - 83s - loss: 5.0649 - MinusLogProbMetric: 5.0649 - val_loss: 5.1675 - val_MinusLogProbMetric: 5.1675 - lr: 5.2083e-06 - 83s/epoch - 425ms/step
Epoch 800/1000
2023-09-20 07:32:43.129 
Epoch 800/1000 
	 loss: 5.0649, MinusLogProbMetric: 5.0649, val_loss: 5.1683, val_MinusLogProbMetric: 5.1683

Epoch 800: val_loss did not improve from 5.16728
196/196 - 84s - loss: 5.0649 - MinusLogProbMetric: 5.0649 - val_loss: 5.1683 - val_MinusLogProbMetric: 5.1683 - lr: 5.2083e-06 - 84s/epoch - 426ms/step
Epoch 801/1000
2023-09-20 07:34:06.529 
Epoch 801/1000 
	 loss: 5.0650, MinusLogProbMetric: 5.0650, val_loss: 5.1687, val_MinusLogProbMetric: 5.1687

Epoch 801: val_loss did not improve from 5.16728
196/196 - 83s - loss: 5.0650 - MinusLogProbMetric: 5.0650 - val_loss: 5.1687 - val_MinusLogProbMetric: 5.1687 - lr: 5.2083e-06 - 83s/epoch - 426ms/step
Epoch 802/1000
2023-09-20 07:35:29.439 
Epoch 802/1000 
	 loss: 5.0650, MinusLogProbMetric: 5.0650, val_loss: 5.1683, val_MinusLogProbMetric: 5.1683

Epoch 802: val_loss did not improve from 5.16728
196/196 - 83s - loss: 5.0650 - MinusLogProbMetric: 5.0650 - val_loss: 5.1683 - val_MinusLogProbMetric: 5.1683 - lr: 5.2083e-06 - 83s/epoch - 423ms/step
Epoch 803/1000
2023-09-20 07:36:52.099 
Epoch 803/1000 
	 loss: 5.0654, MinusLogProbMetric: 5.0654, val_loss: 5.1679, val_MinusLogProbMetric: 5.1679

Epoch 803: val_loss did not improve from 5.16728
196/196 - 83s - loss: 5.0654 - MinusLogProbMetric: 5.0654 - val_loss: 5.1679 - val_MinusLogProbMetric: 5.1679 - lr: 5.2083e-06 - 83s/epoch - 422ms/step
Epoch 804/1000
2023-09-20 07:38:14.613 
Epoch 804/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1698, val_MinusLogProbMetric: 5.1698

Epoch 804: val_loss did not improve from 5.16728
196/196 - 83s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1698 - val_MinusLogProbMetric: 5.1698 - lr: 5.2083e-06 - 83s/epoch - 421ms/step
Epoch 805/1000
2023-09-20 07:39:37.189 
Epoch 805/1000 
	 loss: 5.0649, MinusLogProbMetric: 5.0649, val_loss: 5.1683, val_MinusLogProbMetric: 5.1683

Epoch 805: val_loss did not improve from 5.16728
196/196 - 83s - loss: 5.0649 - MinusLogProbMetric: 5.0649 - val_loss: 5.1683 - val_MinusLogProbMetric: 5.1683 - lr: 5.2083e-06 - 83s/epoch - 421ms/step
Epoch 806/1000
2023-09-20 07:40:58.600 
Epoch 806/1000 
	 loss: 5.0647, MinusLogProbMetric: 5.0647, val_loss: 5.1691, val_MinusLogProbMetric: 5.1691

Epoch 806: val_loss did not improve from 5.16728
196/196 - 81s - loss: 5.0647 - MinusLogProbMetric: 5.0647 - val_loss: 5.1691 - val_MinusLogProbMetric: 5.1691 - lr: 5.2083e-06 - 81s/epoch - 415ms/step
Epoch 807/1000
2023-09-20 07:42:20.672 
Epoch 807/1000 
	 loss: 5.0644, MinusLogProbMetric: 5.0644, val_loss: 5.1672, val_MinusLogProbMetric: 5.1672

Epoch 807: val_loss improved from 5.16728 to 5.16719, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 83s - loss: 5.0644 - MinusLogProbMetric: 5.0644 - val_loss: 5.1672 - val_MinusLogProbMetric: 5.1672 - lr: 5.2083e-06 - 83s/epoch - 425ms/step
Epoch 808/1000
2023-09-20 07:43:44.721 
Epoch 808/1000 
	 loss: 5.0644, MinusLogProbMetric: 5.0644, val_loss: 5.1685, val_MinusLogProbMetric: 5.1685

Epoch 808: val_loss did not improve from 5.16719
196/196 - 83s - loss: 5.0644 - MinusLogProbMetric: 5.0644 - val_loss: 5.1685 - val_MinusLogProbMetric: 5.1685 - lr: 5.2083e-06 - 83s/epoch - 423ms/step
Epoch 809/1000
2023-09-20 07:45:07.067 
Epoch 809/1000 
	 loss: 5.0644, MinusLogProbMetric: 5.0644, val_loss: 5.1687, val_MinusLogProbMetric: 5.1687

Epoch 809: val_loss did not improve from 5.16719
196/196 - 82s - loss: 5.0644 - MinusLogProbMetric: 5.0644 - val_loss: 5.1687 - val_MinusLogProbMetric: 5.1687 - lr: 5.2083e-06 - 82s/epoch - 420ms/step
Epoch 810/1000
2023-09-20 07:46:28.716 
Epoch 810/1000 
	 loss: 5.0648, MinusLogProbMetric: 5.0648, val_loss: 5.1690, val_MinusLogProbMetric: 5.1690

Epoch 810: val_loss did not improve from 5.16719
196/196 - 82s - loss: 5.0648 - MinusLogProbMetric: 5.0648 - val_loss: 5.1690 - val_MinusLogProbMetric: 5.1690 - lr: 5.2083e-06 - 82s/epoch - 417ms/step
Epoch 811/1000
2023-09-20 07:47:49.668 
Epoch 811/1000 
	 loss: 5.0648, MinusLogProbMetric: 5.0648, val_loss: 5.1693, val_MinusLogProbMetric: 5.1693

Epoch 811: val_loss did not improve from 5.16719
196/196 - 81s - loss: 5.0648 - MinusLogProbMetric: 5.0648 - val_loss: 5.1693 - val_MinusLogProbMetric: 5.1693 - lr: 5.2083e-06 - 81s/epoch - 413ms/step
Epoch 812/1000
2023-09-20 07:49:11.099 
Epoch 812/1000 
	 loss: 5.0646, MinusLogProbMetric: 5.0646, val_loss: 5.1681, val_MinusLogProbMetric: 5.1681

Epoch 812: val_loss did not improve from 5.16719
196/196 - 81s - loss: 5.0646 - MinusLogProbMetric: 5.0646 - val_loss: 5.1681 - val_MinusLogProbMetric: 5.1681 - lr: 5.2083e-06 - 81s/epoch - 415ms/step
Epoch 813/1000
2023-09-20 07:50:33.284 
Epoch 813/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1679, val_MinusLogProbMetric: 5.1679

Epoch 813: val_loss did not improve from 5.16719
196/196 - 82s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1679 - val_MinusLogProbMetric: 5.1679 - lr: 5.2083e-06 - 82s/epoch - 419ms/step
Epoch 814/1000
2023-09-20 07:51:55.561 
Epoch 814/1000 
	 loss: 5.0649, MinusLogProbMetric: 5.0649, val_loss: 5.1676, val_MinusLogProbMetric: 5.1676

Epoch 814: val_loss did not improve from 5.16719
196/196 - 82s - loss: 5.0649 - MinusLogProbMetric: 5.0649 - val_loss: 5.1676 - val_MinusLogProbMetric: 5.1676 - lr: 5.2083e-06 - 82s/epoch - 420ms/step
Epoch 815/1000
2023-09-20 07:53:18.065 
Epoch 815/1000 
	 loss: 5.0647, MinusLogProbMetric: 5.0647, val_loss: 5.1679, val_MinusLogProbMetric: 5.1679

Epoch 815: val_loss did not improve from 5.16719
196/196 - 82s - loss: 5.0647 - MinusLogProbMetric: 5.0647 - val_loss: 5.1679 - val_MinusLogProbMetric: 5.1679 - lr: 5.2083e-06 - 82s/epoch - 421ms/step
Epoch 816/1000
2023-09-20 07:54:41.342 
Epoch 816/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1681, val_MinusLogProbMetric: 5.1681

Epoch 816: val_loss did not improve from 5.16719
196/196 - 83s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1681 - val_MinusLogProbMetric: 5.1681 - lr: 5.2083e-06 - 83s/epoch - 425ms/step
Epoch 817/1000
2023-09-20 07:56:03.003 
Epoch 817/1000 
	 loss: 5.0647, MinusLogProbMetric: 5.0647, val_loss: 5.1688, val_MinusLogProbMetric: 5.1688

Epoch 817: val_loss did not improve from 5.16719
196/196 - 82s - loss: 5.0647 - MinusLogProbMetric: 5.0647 - val_loss: 5.1688 - val_MinusLogProbMetric: 5.1688 - lr: 5.2083e-06 - 82s/epoch - 417ms/step
Epoch 818/1000
2023-09-20 07:57:24.749 
Epoch 818/1000 
	 loss: 5.0648, MinusLogProbMetric: 5.0648, val_loss: 5.1683, val_MinusLogProbMetric: 5.1683

Epoch 818: val_loss did not improve from 5.16719
196/196 - 82s - loss: 5.0648 - MinusLogProbMetric: 5.0648 - val_loss: 5.1683 - val_MinusLogProbMetric: 5.1683 - lr: 5.2083e-06 - 82s/epoch - 417ms/step
Epoch 819/1000
2023-09-20 07:58:47.616 
Epoch 819/1000 
	 loss: 5.0643, MinusLogProbMetric: 5.0643, val_loss: 5.1677, val_MinusLogProbMetric: 5.1677

Epoch 819: val_loss did not improve from 5.16719
196/196 - 83s - loss: 5.0643 - MinusLogProbMetric: 5.0643 - val_loss: 5.1677 - val_MinusLogProbMetric: 5.1677 - lr: 5.2083e-06 - 83s/epoch - 423ms/step
Epoch 820/1000
2023-09-20 08:00:09.733 
Epoch 820/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1688, val_MinusLogProbMetric: 5.1688

Epoch 820: val_loss did not improve from 5.16719
196/196 - 82s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1688 - val_MinusLogProbMetric: 5.1688 - lr: 5.2083e-06 - 82s/epoch - 419ms/step
Epoch 821/1000
2023-09-20 08:01:32.108 
Epoch 821/1000 
	 loss: 5.0646, MinusLogProbMetric: 5.0646, val_loss: 5.1685, val_MinusLogProbMetric: 5.1685

Epoch 821: val_loss did not improve from 5.16719
196/196 - 82s - loss: 5.0646 - MinusLogProbMetric: 5.0646 - val_loss: 5.1685 - val_MinusLogProbMetric: 5.1685 - lr: 5.2083e-06 - 82s/epoch - 420ms/step
Epoch 822/1000
2023-09-20 08:02:54.641 
Epoch 822/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1686, val_MinusLogProbMetric: 5.1686

Epoch 822: val_loss did not improve from 5.16719
196/196 - 83s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1686 - val_MinusLogProbMetric: 5.1686 - lr: 5.2083e-06 - 83s/epoch - 421ms/step
Epoch 823/1000
2023-09-20 08:04:16.915 
Epoch 823/1000 
	 loss: 5.0649, MinusLogProbMetric: 5.0649, val_loss: 5.1676, val_MinusLogProbMetric: 5.1676

Epoch 823: val_loss did not improve from 5.16719
196/196 - 82s - loss: 5.0649 - MinusLogProbMetric: 5.0649 - val_loss: 5.1676 - val_MinusLogProbMetric: 5.1676 - lr: 5.2083e-06 - 82s/epoch - 420ms/step
Epoch 824/1000
2023-09-20 08:05:39.136 
Epoch 824/1000 
	 loss: 5.0646, MinusLogProbMetric: 5.0646, val_loss: 5.1689, val_MinusLogProbMetric: 5.1689

Epoch 824: val_loss did not improve from 5.16719
196/196 - 82s - loss: 5.0646 - MinusLogProbMetric: 5.0646 - val_loss: 5.1689 - val_MinusLogProbMetric: 5.1689 - lr: 5.2083e-06 - 82s/epoch - 419ms/step
Epoch 825/1000
2023-09-20 08:07:02.006 
Epoch 825/1000 
	 loss: 5.0647, MinusLogProbMetric: 5.0647, val_loss: 5.1682, val_MinusLogProbMetric: 5.1682

Epoch 825: val_loss did not improve from 5.16719
196/196 - 83s - loss: 5.0647 - MinusLogProbMetric: 5.0647 - val_loss: 5.1682 - val_MinusLogProbMetric: 5.1682 - lr: 5.2083e-06 - 83s/epoch - 423ms/step
Epoch 826/1000
2023-09-20 08:08:24.222 
Epoch 826/1000 
	 loss: 5.0648, MinusLogProbMetric: 5.0648, val_loss: 5.1683, val_MinusLogProbMetric: 5.1683

Epoch 826: val_loss did not improve from 5.16719
196/196 - 82s - loss: 5.0648 - MinusLogProbMetric: 5.0648 - val_loss: 5.1683 - val_MinusLogProbMetric: 5.1683 - lr: 5.2083e-06 - 82s/epoch - 419ms/step
Epoch 827/1000
2023-09-20 08:09:46.728 
Epoch 827/1000 
	 loss: 5.0649, MinusLogProbMetric: 5.0649, val_loss: 5.1684, val_MinusLogProbMetric: 5.1684

Epoch 827: val_loss did not improve from 5.16719
196/196 - 83s - loss: 5.0649 - MinusLogProbMetric: 5.0649 - val_loss: 5.1684 - val_MinusLogProbMetric: 5.1684 - lr: 5.2083e-06 - 83s/epoch - 421ms/step
Epoch 828/1000
2023-09-20 08:11:09.529 
Epoch 828/1000 
	 loss: 5.0642, MinusLogProbMetric: 5.0642, val_loss: 5.1687, val_MinusLogProbMetric: 5.1687

Epoch 828: val_loss did not improve from 5.16719
196/196 - 83s - loss: 5.0642 - MinusLogProbMetric: 5.0642 - val_loss: 5.1687 - val_MinusLogProbMetric: 5.1687 - lr: 5.2083e-06 - 83s/epoch - 422ms/step
Epoch 829/1000
2023-09-20 08:12:31.641 
Epoch 829/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1679, val_MinusLogProbMetric: 5.1679

Epoch 829: val_loss did not improve from 5.16719
196/196 - 82s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1679 - val_MinusLogProbMetric: 5.1679 - lr: 5.2083e-06 - 82s/epoch - 419ms/step
Epoch 830/1000
2023-09-20 08:13:54.116 
Epoch 830/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1681, val_MinusLogProbMetric: 5.1681

Epoch 830: val_loss did not improve from 5.16719
196/196 - 82s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1681 - val_MinusLogProbMetric: 5.1681 - lr: 5.2083e-06 - 82s/epoch - 421ms/step
Epoch 831/1000
2023-09-20 08:15:16.199 
Epoch 831/1000 
	 loss: 5.0644, MinusLogProbMetric: 5.0644, val_loss: 5.1685, val_MinusLogProbMetric: 5.1685

Epoch 831: val_loss did not improve from 5.16719
196/196 - 82s - loss: 5.0644 - MinusLogProbMetric: 5.0644 - val_loss: 5.1685 - val_MinusLogProbMetric: 5.1685 - lr: 5.2083e-06 - 82s/epoch - 419ms/step
Epoch 832/1000
2023-09-20 08:16:38.892 
Epoch 832/1000 
	 loss: 5.0644, MinusLogProbMetric: 5.0644, val_loss: 5.1683, val_MinusLogProbMetric: 5.1683

Epoch 832: val_loss did not improve from 5.16719
196/196 - 83s - loss: 5.0644 - MinusLogProbMetric: 5.0644 - val_loss: 5.1683 - val_MinusLogProbMetric: 5.1683 - lr: 5.2083e-06 - 83s/epoch - 422ms/step
Epoch 833/1000
2023-09-20 08:18:00.218 
Epoch 833/1000 
	 loss: 5.0650, MinusLogProbMetric: 5.0650, val_loss: 5.1668, val_MinusLogProbMetric: 5.1668

Epoch 833: val_loss improved from 5.16719 to 5.16677, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 84s - loss: 5.0650 - MinusLogProbMetric: 5.0650 - val_loss: 5.1668 - val_MinusLogProbMetric: 5.1668 - lr: 5.2083e-06 - 84s/epoch - 426ms/step
Epoch 834/1000
2023-09-20 08:19:24.760 
Epoch 834/1000 
	 loss: 5.0644, MinusLogProbMetric: 5.0644, val_loss: 5.1675, val_MinusLogProbMetric: 5.1675

Epoch 834: val_loss did not improve from 5.16677
196/196 - 82s - loss: 5.0644 - MinusLogProbMetric: 5.0644 - val_loss: 5.1675 - val_MinusLogProbMetric: 5.1675 - lr: 5.2083e-06 - 82s/epoch - 420ms/step
Epoch 835/1000
2023-09-20 08:20:47.297 
Epoch 835/1000 
	 loss: 5.0642, MinusLogProbMetric: 5.0642, val_loss: 5.1683, val_MinusLogProbMetric: 5.1683

Epoch 835: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0642 - MinusLogProbMetric: 5.0642 - val_loss: 5.1683 - val_MinusLogProbMetric: 5.1683 - lr: 5.2083e-06 - 83s/epoch - 421ms/step
Epoch 836/1000
2023-09-20 08:22:09.800 
Epoch 836/1000 
	 loss: 5.0643, MinusLogProbMetric: 5.0643, val_loss: 5.1679, val_MinusLogProbMetric: 5.1679

Epoch 836: val_loss did not improve from 5.16677
196/196 - 82s - loss: 5.0643 - MinusLogProbMetric: 5.0643 - val_loss: 5.1679 - val_MinusLogProbMetric: 5.1679 - lr: 5.2083e-06 - 82s/epoch - 421ms/step
Epoch 837/1000
2023-09-20 08:23:31.737 
Epoch 837/1000 
	 loss: 5.0643, MinusLogProbMetric: 5.0643, val_loss: 5.1693, val_MinusLogProbMetric: 5.1693

Epoch 837: val_loss did not improve from 5.16677
196/196 - 82s - loss: 5.0643 - MinusLogProbMetric: 5.0643 - val_loss: 5.1693 - val_MinusLogProbMetric: 5.1693 - lr: 5.2083e-06 - 82s/epoch - 418ms/step
Epoch 838/1000
2023-09-20 08:24:54.603 
Epoch 838/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1680, val_MinusLogProbMetric: 5.1680

Epoch 838: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1680 - val_MinusLogProbMetric: 5.1680 - lr: 5.2083e-06 - 83s/epoch - 423ms/step
Epoch 839/1000
2023-09-20 08:26:17.261 
Epoch 839/1000 
	 loss: 5.0641, MinusLogProbMetric: 5.0641, val_loss: 5.1684, val_MinusLogProbMetric: 5.1684

Epoch 839: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0641 - MinusLogProbMetric: 5.0641 - val_loss: 5.1684 - val_MinusLogProbMetric: 5.1684 - lr: 5.2083e-06 - 83s/epoch - 422ms/step
Epoch 840/1000
2023-09-20 08:27:39.137 
Epoch 840/1000 
	 loss: 5.0642, MinusLogProbMetric: 5.0642, val_loss: 5.1678, val_MinusLogProbMetric: 5.1678

Epoch 840: val_loss did not improve from 5.16677
196/196 - 82s - loss: 5.0642 - MinusLogProbMetric: 5.0642 - val_loss: 5.1678 - val_MinusLogProbMetric: 5.1678 - lr: 5.2083e-06 - 82s/epoch - 418ms/step
Epoch 841/1000
2023-09-20 08:29:01.760 
Epoch 841/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1693, val_MinusLogProbMetric: 5.1693

Epoch 841: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1693 - val_MinusLogProbMetric: 5.1693 - lr: 5.2083e-06 - 83s/epoch - 422ms/step
Epoch 842/1000
2023-09-20 08:30:24.060 
Epoch 842/1000 
	 loss: 5.0646, MinusLogProbMetric: 5.0646, val_loss: 5.1679, val_MinusLogProbMetric: 5.1679

Epoch 842: val_loss did not improve from 5.16677
196/196 - 82s - loss: 5.0646 - MinusLogProbMetric: 5.0646 - val_loss: 5.1679 - val_MinusLogProbMetric: 5.1679 - lr: 5.2083e-06 - 82s/epoch - 420ms/step
Epoch 843/1000
2023-09-20 08:31:46.747 
Epoch 843/1000 
	 loss: 5.0642, MinusLogProbMetric: 5.0642, val_loss: 5.1684, val_MinusLogProbMetric: 5.1684

Epoch 843: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0642 - MinusLogProbMetric: 5.0642 - val_loss: 5.1684 - val_MinusLogProbMetric: 5.1684 - lr: 5.2083e-06 - 83s/epoch - 422ms/step
Epoch 844/1000
2023-09-20 08:33:09.729 
Epoch 844/1000 
	 loss: 5.0643, MinusLogProbMetric: 5.0643, val_loss: 5.1689, val_MinusLogProbMetric: 5.1689

Epoch 844: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0643 - MinusLogProbMetric: 5.0643 - val_loss: 5.1689 - val_MinusLogProbMetric: 5.1689 - lr: 5.2083e-06 - 83s/epoch - 423ms/step
Epoch 845/1000
2023-09-20 08:34:31.914 
Epoch 845/1000 
	 loss: 5.0643, MinusLogProbMetric: 5.0643, val_loss: 5.1678, val_MinusLogProbMetric: 5.1678

Epoch 845: val_loss did not improve from 5.16677
196/196 - 82s - loss: 5.0643 - MinusLogProbMetric: 5.0643 - val_loss: 5.1678 - val_MinusLogProbMetric: 5.1678 - lr: 5.2083e-06 - 82s/epoch - 419ms/step
Epoch 846/1000
2023-09-20 08:35:54.851 
Epoch 846/1000 
	 loss: 5.0640, MinusLogProbMetric: 5.0640, val_loss: 5.1678, val_MinusLogProbMetric: 5.1678

Epoch 846: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0640 - MinusLogProbMetric: 5.0640 - val_loss: 5.1678 - val_MinusLogProbMetric: 5.1678 - lr: 5.2083e-06 - 83s/epoch - 423ms/step
Epoch 847/1000
2023-09-20 08:37:17.607 
Epoch 847/1000 
	 loss: 5.0643, MinusLogProbMetric: 5.0643, val_loss: 5.1686, val_MinusLogProbMetric: 5.1686

Epoch 847: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0643 - MinusLogProbMetric: 5.0643 - val_loss: 5.1686 - val_MinusLogProbMetric: 5.1686 - lr: 5.2083e-06 - 83s/epoch - 422ms/step
Epoch 848/1000
2023-09-20 08:38:40.102 
Epoch 848/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1675, val_MinusLogProbMetric: 5.1675

Epoch 848: val_loss did not improve from 5.16677
196/196 - 82s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1675 - val_MinusLogProbMetric: 5.1675 - lr: 5.2083e-06 - 82s/epoch - 421ms/step
Epoch 849/1000
2023-09-20 08:40:02.524 
Epoch 849/1000 
	 loss: 5.0641, MinusLogProbMetric: 5.0641, val_loss: 5.1686, val_MinusLogProbMetric: 5.1686

Epoch 849: val_loss did not improve from 5.16677
196/196 - 82s - loss: 5.0641 - MinusLogProbMetric: 5.0641 - val_loss: 5.1686 - val_MinusLogProbMetric: 5.1686 - lr: 5.2083e-06 - 82s/epoch - 421ms/step
Epoch 850/1000
2023-09-20 08:41:25.353 
Epoch 850/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1677, val_MinusLogProbMetric: 5.1677

Epoch 850: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1677 - val_MinusLogProbMetric: 5.1677 - lr: 5.2083e-06 - 83s/epoch - 423ms/step
Epoch 851/1000
2023-09-20 08:42:48.506 
Epoch 851/1000 
	 loss: 5.0641, MinusLogProbMetric: 5.0641, val_loss: 5.1688, val_MinusLogProbMetric: 5.1688

Epoch 851: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0641 - MinusLogProbMetric: 5.0641 - val_loss: 5.1688 - val_MinusLogProbMetric: 5.1688 - lr: 5.2083e-06 - 83s/epoch - 424ms/step
Epoch 852/1000
2023-09-20 08:44:11.948 
Epoch 852/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1677, val_MinusLogProbMetric: 5.1677

Epoch 852: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1677 - val_MinusLogProbMetric: 5.1677 - lr: 5.2083e-06 - 83s/epoch - 426ms/step
Epoch 853/1000
2023-09-20 08:45:34.389 
Epoch 853/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1675, val_MinusLogProbMetric: 5.1675

Epoch 853: val_loss did not improve from 5.16677
196/196 - 82s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1675 - val_MinusLogProbMetric: 5.1675 - lr: 5.2083e-06 - 82s/epoch - 421ms/step
Epoch 854/1000
2023-09-20 08:46:56.894 
Epoch 854/1000 
	 loss: 5.0642, MinusLogProbMetric: 5.0642, val_loss: 5.1677, val_MinusLogProbMetric: 5.1677

Epoch 854: val_loss did not improve from 5.16677
196/196 - 82s - loss: 5.0642 - MinusLogProbMetric: 5.0642 - val_loss: 5.1677 - val_MinusLogProbMetric: 5.1677 - lr: 5.2083e-06 - 82s/epoch - 421ms/step
Epoch 855/1000
2023-09-20 08:48:19.126 
Epoch 855/1000 
	 loss: 5.0643, MinusLogProbMetric: 5.0643, val_loss: 5.1675, val_MinusLogProbMetric: 5.1675

Epoch 855: val_loss did not improve from 5.16677
196/196 - 82s - loss: 5.0643 - MinusLogProbMetric: 5.0643 - val_loss: 5.1675 - val_MinusLogProbMetric: 5.1675 - lr: 5.2083e-06 - 82s/epoch - 420ms/step
Epoch 856/1000
2023-09-20 08:49:41.021 
Epoch 856/1000 
	 loss: 5.0642, MinusLogProbMetric: 5.0642, val_loss: 5.1684, val_MinusLogProbMetric: 5.1684

Epoch 856: val_loss did not improve from 5.16677
196/196 - 82s - loss: 5.0642 - MinusLogProbMetric: 5.0642 - val_loss: 5.1684 - val_MinusLogProbMetric: 5.1684 - lr: 5.2083e-06 - 82s/epoch - 418ms/step
Epoch 857/1000
2023-09-20 08:51:03.705 
Epoch 857/1000 
	 loss: 5.0640, MinusLogProbMetric: 5.0640, val_loss: 5.1671, val_MinusLogProbMetric: 5.1671

Epoch 857: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0640 - MinusLogProbMetric: 5.0640 - val_loss: 5.1671 - val_MinusLogProbMetric: 5.1671 - lr: 5.2083e-06 - 83s/epoch - 422ms/step
Epoch 858/1000
2023-09-20 08:52:26.833 
Epoch 858/1000 
	 loss: 5.0642, MinusLogProbMetric: 5.0642, val_loss: 5.1672, val_MinusLogProbMetric: 5.1672

Epoch 858: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0642 - MinusLogProbMetric: 5.0642 - val_loss: 5.1672 - val_MinusLogProbMetric: 5.1672 - lr: 5.2083e-06 - 83s/epoch - 424ms/step
Epoch 859/1000
2023-09-20 08:53:49.634 
Epoch 859/1000 
	 loss: 5.0641, MinusLogProbMetric: 5.0641, val_loss: 5.1675, val_MinusLogProbMetric: 5.1675

Epoch 859: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0641 - MinusLogProbMetric: 5.0641 - val_loss: 5.1675 - val_MinusLogProbMetric: 5.1675 - lr: 5.2083e-06 - 83s/epoch - 422ms/step
Epoch 860/1000
2023-09-20 08:55:12.957 
Epoch 860/1000 
	 loss: 5.0641, MinusLogProbMetric: 5.0641, val_loss: 5.1681, val_MinusLogProbMetric: 5.1681

Epoch 860: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0641 - MinusLogProbMetric: 5.0641 - val_loss: 5.1681 - val_MinusLogProbMetric: 5.1681 - lr: 5.2083e-06 - 83s/epoch - 425ms/step
Epoch 861/1000
2023-09-20 08:56:35.723 
Epoch 861/1000 
	 loss: 5.0644, MinusLogProbMetric: 5.0644, val_loss: 5.1678, val_MinusLogProbMetric: 5.1678

Epoch 861: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0644 - MinusLogProbMetric: 5.0644 - val_loss: 5.1678 - val_MinusLogProbMetric: 5.1678 - lr: 5.2083e-06 - 83s/epoch - 422ms/step
Epoch 862/1000
2023-09-20 08:57:59.539 
Epoch 862/1000 
	 loss: 5.0639, MinusLogProbMetric: 5.0639, val_loss: 5.1691, val_MinusLogProbMetric: 5.1691

Epoch 862: val_loss did not improve from 5.16677
196/196 - 84s - loss: 5.0639 - MinusLogProbMetric: 5.0639 - val_loss: 5.1691 - val_MinusLogProbMetric: 5.1691 - lr: 5.2083e-06 - 84s/epoch - 428ms/step
Epoch 863/1000
2023-09-20 08:59:21.184 
Epoch 863/1000 
	 loss: 5.0644, MinusLogProbMetric: 5.0644, val_loss: 5.1685, val_MinusLogProbMetric: 5.1685

Epoch 863: val_loss did not improve from 5.16677
196/196 - 82s - loss: 5.0644 - MinusLogProbMetric: 5.0644 - val_loss: 5.1685 - val_MinusLogProbMetric: 5.1685 - lr: 5.2083e-06 - 82s/epoch - 417ms/step
Epoch 864/1000
2023-09-20 09:00:43.806 
Epoch 864/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1679, val_MinusLogProbMetric: 5.1679

Epoch 864: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1679 - val_MinusLogProbMetric: 5.1679 - lr: 5.2083e-06 - 83s/epoch - 422ms/step
Epoch 865/1000
2023-09-20 09:02:07.053 
Epoch 865/1000 
	 loss: 5.0642, MinusLogProbMetric: 5.0642, val_loss: 5.1678, val_MinusLogProbMetric: 5.1678

Epoch 865: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0642 - MinusLogProbMetric: 5.0642 - val_loss: 5.1678 - val_MinusLogProbMetric: 5.1678 - lr: 5.2083e-06 - 83s/epoch - 425ms/step
Epoch 866/1000
2023-09-20 09:03:30.525 
Epoch 866/1000 
	 loss: 5.0644, MinusLogProbMetric: 5.0644, val_loss: 5.1684, val_MinusLogProbMetric: 5.1684

Epoch 866: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0644 - MinusLogProbMetric: 5.0644 - val_loss: 5.1684 - val_MinusLogProbMetric: 5.1684 - lr: 5.2083e-06 - 83s/epoch - 426ms/step
Epoch 867/1000
2023-09-20 09:04:52.549 
Epoch 867/1000 
	 loss: 5.0643, MinusLogProbMetric: 5.0643, val_loss: 5.1675, val_MinusLogProbMetric: 5.1675

Epoch 867: val_loss did not improve from 5.16677
196/196 - 82s - loss: 5.0643 - MinusLogProbMetric: 5.0643 - val_loss: 5.1675 - val_MinusLogProbMetric: 5.1675 - lr: 5.2083e-06 - 82s/epoch - 418ms/step
Epoch 868/1000
2023-09-20 09:06:15.735 
Epoch 868/1000 
	 loss: 5.0648, MinusLogProbMetric: 5.0648, val_loss: 5.1678, val_MinusLogProbMetric: 5.1678

Epoch 868: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0648 - MinusLogProbMetric: 5.0648 - val_loss: 5.1678 - val_MinusLogProbMetric: 5.1678 - lr: 5.2083e-06 - 83s/epoch - 424ms/step
Epoch 869/1000
2023-09-20 09:07:38.721 
Epoch 869/1000 
	 loss: 5.0644, MinusLogProbMetric: 5.0644, val_loss: 5.1689, val_MinusLogProbMetric: 5.1689

Epoch 869: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0644 - MinusLogProbMetric: 5.0644 - val_loss: 5.1689 - val_MinusLogProbMetric: 5.1689 - lr: 5.2083e-06 - 83s/epoch - 423ms/step
Epoch 870/1000
2023-09-20 09:09:01.781 
Epoch 870/1000 
	 loss: 5.0650, MinusLogProbMetric: 5.0650, val_loss: 5.1678, val_MinusLogProbMetric: 5.1678

Epoch 870: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0650 - MinusLogProbMetric: 5.0650 - val_loss: 5.1678 - val_MinusLogProbMetric: 5.1678 - lr: 5.2083e-06 - 83s/epoch - 424ms/step
Epoch 871/1000
2023-09-20 09:10:26.584 
Epoch 871/1000 
	 loss: 5.0644, MinusLogProbMetric: 5.0644, val_loss: 5.1676, val_MinusLogProbMetric: 5.1676

Epoch 871: val_loss did not improve from 5.16677
196/196 - 85s - loss: 5.0644 - MinusLogProbMetric: 5.0644 - val_loss: 5.1676 - val_MinusLogProbMetric: 5.1676 - lr: 5.2083e-06 - 85s/epoch - 433ms/step
Epoch 872/1000
2023-09-20 09:11:49.515 
Epoch 872/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1671, val_MinusLogProbMetric: 5.1671

Epoch 872: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1671 - val_MinusLogProbMetric: 5.1671 - lr: 5.2083e-06 - 83s/epoch - 423ms/step
Epoch 873/1000
2023-09-20 09:13:12.866 
Epoch 873/1000 
	 loss: 5.0641, MinusLogProbMetric: 5.0641, val_loss: 5.1692, val_MinusLogProbMetric: 5.1692

Epoch 873: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0641 - MinusLogProbMetric: 5.0641 - val_loss: 5.1692 - val_MinusLogProbMetric: 5.1692 - lr: 5.2083e-06 - 83s/epoch - 425ms/step
Epoch 874/1000
2023-09-20 09:14:35.832 
Epoch 874/1000 
	 loss: 5.0641, MinusLogProbMetric: 5.0641, val_loss: 5.1671, val_MinusLogProbMetric: 5.1671

Epoch 874: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0641 - MinusLogProbMetric: 5.0641 - val_loss: 5.1671 - val_MinusLogProbMetric: 5.1671 - lr: 5.2083e-06 - 83s/epoch - 423ms/step
Epoch 875/1000
2023-09-20 09:16:00.039 
Epoch 875/1000 
	 loss: 5.0638, MinusLogProbMetric: 5.0638, val_loss: 5.1681, val_MinusLogProbMetric: 5.1681

Epoch 875: val_loss did not improve from 5.16677
196/196 - 84s - loss: 5.0638 - MinusLogProbMetric: 5.0638 - val_loss: 5.1681 - val_MinusLogProbMetric: 5.1681 - lr: 5.2083e-06 - 84s/epoch - 430ms/step
Epoch 876/1000
2023-09-20 09:17:23.911 
Epoch 876/1000 
	 loss: 5.0641, MinusLogProbMetric: 5.0641, val_loss: 5.1674, val_MinusLogProbMetric: 5.1674

Epoch 876: val_loss did not improve from 5.16677
196/196 - 84s - loss: 5.0641 - MinusLogProbMetric: 5.0641 - val_loss: 5.1674 - val_MinusLogProbMetric: 5.1674 - lr: 5.2083e-06 - 84s/epoch - 428ms/step
Epoch 877/1000
2023-09-20 09:18:47.585 
Epoch 877/1000 
	 loss: 5.0642, MinusLogProbMetric: 5.0642, val_loss: 5.1673, val_MinusLogProbMetric: 5.1673

Epoch 877: val_loss did not improve from 5.16677
196/196 - 84s - loss: 5.0642 - MinusLogProbMetric: 5.0642 - val_loss: 5.1673 - val_MinusLogProbMetric: 5.1673 - lr: 5.2083e-06 - 84s/epoch - 427ms/step
Epoch 878/1000
2023-09-20 09:20:11.322 
Epoch 878/1000 
	 loss: 5.0641, MinusLogProbMetric: 5.0641, val_loss: 5.1678, val_MinusLogProbMetric: 5.1678

Epoch 878: val_loss did not improve from 5.16677
196/196 - 84s - loss: 5.0641 - MinusLogProbMetric: 5.0641 - val_loss: 5.1678 - val_MinusLogProbMetric: 5.1678 - lr: 5.2083e-06 - 84s/epoch - 427ms/step
Epoch 879/1000
2023-09-20 09:21:34.098 
Epoch 879/1000 
	 loss: 5.0644, MinusLogProbMetric: 5.0644, val_loss: 5.1683, val_MinusLogProbMetric: 5.1683

Epoch 879: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0644 - MinusLogProbMetric: 5.0644 - val_loss: 5.1683 - val_MinusLogProbMetric: 5.1683 - lr: 5.2083e-06 - 83s/epoch - 422ms/step
Epoch 880/1000
2023-09-20 09:22:57.512 
Epoch 880/1000 
	 loss: 5.0646, MinusLogProbMetric: 5.0646, val_loss: 5.1671, val_MinusLogProbMetric: 5.1671

Epoch 880: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0646 - MinusLogProbMetric: 5.0646 - val_loss: 5.1671 - val_MinusLogProbMetric: 5.1671 - lr: 5.2083e-06 - 83s/epoch - 426ms/step
Epoch 881/1000
2023-09-20 09:24:20.604 
Epoch 881/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1669, val_MinusLogProbMetric: 5.1669

Epoch 881: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1669 - val_MinusLogProbMetric: 5.1669 - lr: 5.2083e-06 - 83s/epoch - 424ms/step
Epoch 882/1000
2023-09-20 09:25:43.439 
Epoch 882/1000 
	 loss: 5.0643, MinusLogProbMetric: 5.0643, val_loss: 5.1677, val_MinusLogProbMetric: 5.1677

Epoch 882: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0643 - MinusLogProbMetric: 5.0643 - val_loss: 5.1677 - val_MinusLogProbMetric: 5.1677 - lr: 5.2083e-06 - 83s/epoch - 423ms/step
Epoch 883/1000
2023-09-20 09:27:06.958 
Epoch 883/1000 
	 loss: 5.0646, MinusLogProbMetric: 5.0646, val_loss: 5.1684, val_MinusLogProbMetric: 5.1684

Epoch 883: val_loss did not improve from 5.16677
196/196 - 84s - loss: 5.0646 - MinusLogProbMetric: 5.0646 - val_loss: 5.1684 - val_MinusLogProbMetric: 5.1684 - lr: 5.2083e-06 - 84s/epoch - 426ms/step
Epoch 884/1000
2023-09-20 09:28:30.273 
Epoch 884/1000 
	 loss: 5.0632, MinusLogProbMetric: 5.0632, val_loss: 5.1674, val_MinusLogProbMetric: 5.1674

Epoch 884: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0632 - MinusLogProbMetric: 5.0632 - val_loss: 5.1674 - val_MinusLogProbMetric: 5.1674 - lr: 2.6042e-06 - 83s/epoch - 425ms/step
Epoch 885/1000
2023-09-20 09:29:53.227 
Epoch 885/1000 
	 loss: 5.0633, MinusLogProbMetric: 5.0633, val_loss: 5.1674, val_MinusLogProbMetric: 5.1674

Epoch 885: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0633 - MinusLogProbMetric: 5.0633 - val_loss: 5.1674 - val_MinusLogProbMetric: 5.1674 - lr: 2.6042e-06 - 83s/epoch - 423ms/step
Epoch 886/1000
2023-09-20 09:31:16.208 
Epoch 886/1000 
	 loss: 5.0630, MinusLogProbMetric: 5.0630, val_loss: 5.1670, val_MinusLogProbMetric: 5.1670

Epoch 886: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0630 - MinusLogProbMetric: 5.0630 - val_loss: 5.1670 - val_MinusLogProbMetric: 5.1670 - lr: 2.6042e-06 - 83s/epoch - 423ms/step
Epoch 887/1000
2023-09-20 09:32:40.581 
Epoch 887/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1676, val_MinusLogProbMetric: 5.1676

Epoch 887: val_loss did not improve from 5.16677
196/196 - 84s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1676 - val_MinusLogProbMetric: 5.1676 - lr: 2.6042e-06 - 84s/epoch - 430ms/step
Epoch 888/1000
2023-09-20 09:34:04.304 
Epoch 888/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1673, val_MinusLogProbMetric: 5.1673

Epoch 888: val_loss did not improve from 5.16677
196/196 - 84s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1673 - val_MinusLogProbMetric: 5.1673 - lr: 2.6042e-06 - 84s/epoch - 427ms/step
Epoch 889/1000
2023-09-20 09:35:27.958 
Epoch 889/1000 
	 loss: 5.0631, MinusLogProbMetric: 5.0631, val_loss: 5.1681, val_MinusLogProbMetric: 5.1681

Epoch 889: val_loss did not improve from 5.16677
196/196 - 84s - loss: 5.0631 - MinusLogProbMetric: 5.0631 - val_loss: 5.1681 - val_MinusLogProbMetric: 5.1681 - lr: 2.6042e-06 - 84s/epoch - 427ms/step
Epoch 890/1000
2023-09-20 09:36:51.637 
Epoch 890/1000 
	 loss: 5.0631, MinusLogProbMetric: 5.0631, val_loss: 5.1669, val_MinusLogProbMetric: 5.1669

Epoch 890: val_loss did not improve from 5.16677
196/196 - 84s - loss: 5.0631 - MinusLogProbMetric: 5.0631 - val_loss: 5.1669 - val_MinusLogProbMetric: 5.1669 - lr: 2.6042e-06 - 84s/epoch - 427ms/step
Epoch 891/1000
2023-09-20 09:38:15.477 
Epoch 891/1000 
	 loss: 5.0631, MinusLogProbMetric: 5.0631, val_loss: 5.1671, val_MinusLogProbMetric: 5.1671

Epoch 891: val_loss did not improve from 5.16677
196/196 - 84s - loss: 5.0631 - MinusLogProbMetric: 5.0631 - val_loss: 5.1671 - val_MinusLogProbMetric: 5.1671 - lr: 2.6042e-06 - 84s/epoch - 428ms/step
Epoch 892/1000
2023-09-20 09:39:38.936 
Epoch 892/1000 
	 loss: 5.0630, MinusLogProbMetric: 5.0630, val_loss: 5.1676, val_MinusLogProbMetric: 5.1676

Epoch 892: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0630 - MinusLogProbMetric: 5.0630 - val_loss: 5.1676 - val_MinusLogProbMetric: 5.1676 - lr: 2.6042e-06 - 83s/epoch - 426ms/step
Epoch 893/1000
2023-09-20 09:41:02.387 
Epoch 893/1000 
	 loss: 5.0630, MinusLogProbMetric: 5.0630, val_loss: 5.1682, val_MinusLogProbMetric: 5.1682

Epoch 893: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0630 - MinusLogProbMetric: 5.0630 - val_loss: 5.1682 - val_MinusLogProbMetric: 5.1682 - lr: 2.6042e-06 - 83s/epoch - 426ms/step
Epoch 894/1000
2023-09-20 09:42:25.186 
Epoch 894/1000 
	 loss: 5.0632, MinusLogProbMetric: 5.0632, val_loss: 5.1669, val_MinusLogProbMetric: 5.1669

Epoch 894: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0632 - MinusLogProbMetric: 5.0632 - val_loss: 5.1669 - val_MinusLogProbMetric: 5.1669 - lr: 2.6042e-06 - 83s/epoch - 422ms/step
Epoch 895/1000
2023-09-20 09:43:48.166 
Epoch 895/1000 
	 loss: 5.0633, MinusLogProbMetric: 5.0633, val_loss: 5.1674, val_MinusLogProbMetric: 5.1674

Epoch 895: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0633 - MinusLogProbMetric: 5.0633 - val_loss: 5.1674 - val_MinusLogProbMetric: 5.1674 - lr: 2.6042e-06 - 83s/epoch - 423ms/step
Epoch 896/1000
2023-09-20 09:45:11.035 
Epoch 896/1000 
	 loss: 5.0631, MinusLogProbMetric: 5.0631, val_loss: 5.1670, val_MinusLogProbMetric: 5.1670

Epoch 896: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0631 - MinusLogProbMetric: 5.0631 - val_loss: 5.1670 - val_MinusLogProbMetric: 5.1670 - lr: 2.6042e-06 - 83s/epoch - 423ms/step
Epoch 897/1000
2023-09-20 09:46:33.743 
Epoch 897/1000 
	 loss: 5.0630, MinusLogProbMetric: 5.0630, val_loss: 5.1678, val_MinusLogProbMetric: 5.1678

Epoch 897: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0630 - MinusLogProbMetric: 5.0630 - val_loss: 5.1678 - val_MinusLogProbMetric: 5.1678 - lr: 2.6042e-06 - 83s/epoch - 422ms/step
Epoch 898/1000
2023-09-20 09:47:56.699 
Epoch 898/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1678, val_MinusLogProbMetric: 5.1678

Epoch 898: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1678 - val_MinusLogProbMetric: 5.1678 - lr: 2.6042e-06 - 83s/epoch - 423ms/step
Epoch 899/1000
2023-09-20 09:49:19.390 
Epoch 899/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1673, val_MinusLogProbMetric: 5.1673

Epoch 899: val_loss did not improve from 5.16677
196/196 - 83s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1673 - val_MinusLogProbMetric: 5.1673 - lr: 2.6042e-06 - 83s/epoch - 422ms/step
Epoch 900/1000
2023-09-20 09:50:42.535 
Epoch 900/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1666, val_MinusLogProbMetric: 5.1666

Epoch 900: val_loss improved from 5.16677 to 5.16657, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 84s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1666 - val_MinusLogProbMetric: 5.1666 - lr: 2.6042e-06 - 84s/epoch - 431ms/step
Epoch 901/1000
2023-09-20 09:51:58.517 
Epoch 901/1000 
	 loss: 5.0631, MinusLogProbMetric: 5.0631, val_loss: 5.1673, val_MinusLogProbMetric: 5.1673

Epoch 901: val_loss did not improve from 5.16657
196/196 - 75s - loss: 5.0631 - MinusLogProbMetric: 5.0631 - val_loss: 5.1673 - val_MinusLogProbMetric: 5.1673 - lr: 2.6042e-06 - 75s/epoch - 381ms/step
Epoch 902/1000
2023-09-20 09:53:07.767 
Epoch 902/1000 
	 loss: 5.0630, MinusLogProbMetric: 5.0630, val_loss: 5.1678, val_MinusLogProbMetric: 5.1678

Epoch 902: val_loss did not improve from 5.16657
196/196 - 69s - loss: 5.0630 - MinusLogProbMetric: 5.0630 - val_loss: 5.1678 - val_MinusLogProbMetric: 5.1678 - lr: 2.6042e-06 - 69s/epoch - 353ms/step
Epoch 903/1000
2023-09-20 09:54:23.312 
Epoch 903/1000 
	 loss: 5.0627, MinusLogProbMetric: 5.0627, val_loss: 5.1671, val_MinusLogProbMetric: 5.1671

Epoch 903: val_loss did not improve from 5.16657
196/196 - 76s - loss: 5.0627 - MinusLogProbMetric: 5.0627 - val_loss: 5.1671 - val_MinusLogProbMetric: 5.1671 - lr: 2.6042e-06 - 76s/epoch - 385ms/step
Epoch 904/1000
2023-09-20 09:55:29.391 
Epoch 904/1000 
	 loss: 5.0632, MinusLogProbMetric: 5.0632, val_loss: 5.1672, val_MinusLogProbMetric: 5.1672

Epoch 904: val_loss did not improve from 5.16657
196/196 - 66s - loss: 5.0632 - MinusLogProbMetric: 5.0632 - val_loss: 5.1672 - val_MinusLogProbMetric: 5.1672 - lr: 2.6042e-06 - 66s/epoch - 337ms/step
Epoch 905/1000
2023-09-20 09:56:50.963 
Epoch 905/1000 
	 loss: 5.0631, MinusLogProbMetric: 5.0631, val_loss: 5.1675, val_MinusLogProbMetric: 5.1675

Epoch 905: val_loss did not improve from 5.16657
196/196 - 82s - loss: 5.0631 - MinusLogProbMetric: 5.0631 - val_loss: 5.1675 - val_MinusLogProbMetric: 5.1675 - lr: 2.6042e-06 - 82s/epoch - 416ms/step
Epoch 906/1000
2023-09-20 09:58:12.535 
Epoch 906/1000 
	 loss: 5.0630, MinusLogProbMetric: 5.0630, val_loss: 5.1673, val_MinusLogProbMetric: 5.1673

Epoch 906: val_loss did not improve from 5.16657
196/196 - 82s - loss: 5.0630 - MinusLogProbMetric: 5.0630 - val_loss: 5.1673 - val_MinusLogProbMetric: 5.1673 - lr: 2.6042e-06 - 82s/epoch - 416ms/step
Epoch 907/1000
2023-09-20 09:59:35.995 
Epoch 907/1000 
	 loss: 5.0630, MinusLogProbMetric: 5.0630, val_loss: 5.1664, val_MinusLogProbMetric: 5.1664

Epoch 907: val_loss improved from 5.16657 to 5.16643, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 85s - loss: 5.0630 - MinusLogProbMetric: 5.0630 - val_loss: 5.1664 - val_MinusLogProbMetric: 5.1664 - lr: 2.6042e-06 - 85s/epoch - 433ms/step
Epoch 908/1000
2023-09-20 10:01:01.065 
Epoch 908/1000 
	 loss: 5.0628, MinusLogProbMetric: 5.0628, val_loss: 5.1669, val_MinusLogProbMetric: 5.1669

Epoch 908: val_loss did not improve from 5.16643
196/196 - 84s - loss: 5.0628 - MinusLogProbMetric: 5.0628 - val_loss: 5.1669 - val_MinusLogProbMetric: 5.1669 - lr: 2.6042e-06 - 84s/epoch - 427ms/step
Epoch 909/1000
2023-09-20 10:02:23.523 
Epoch 909/1000 
	 loss: 5.0633, MinusLogProbMetric: 5.0633, val_loss: 5.1675, val_MinusLogProbMetric: 5.1675

Epoch 909: val_loss did not improve from 5.16643
196/196 - 82s - loss: 5.0633 - MinusLogProbMetric: 5.0633 - val_loss: 5.1675 - val_MinusLogProbMetric: 5.1675 - lr: 2.6042e-06 - 82s/epoch - 421ms/step
Epoch 910/1000
2023-09-20 10:03:31.014 
Epoch 910/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1675, val_MinusLogProbMetric: 5.1675

Epoch 910: val_loss did not improve from 5.16643
196/196 - 67s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1675 - val_MinusLogProbMetric: 5.1675 - lr: 2.6042e-06 - 67s/epoch - 344ms/step
Epoch 911/1000
2023-09-20 10:04:34.953 
Epoch 911/1000 
	 loss: 5.0630, MinusLogProbMetric: 5.0630, val_loss: 5.1673, val_MinusLogProbMetric: 5.1673

Epoch 911: val_loss did not improve from 5.16643
196/196 - 64s - loss: 5.0630 - MinusLogProbMetric: 5.0630 - val_loss: 5.1673 - val_MinusLogProbMetric: 5.1673 - lr: 2.6042e-06 - 64s/epoch - 326ms/step
Epoch 912/1000
2023-09-20 10:05:53.674 
Epoch 912/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1677, val_MinusLogProbMetric: 5.1677

Epoch 912: val_loss did not improve from 5.16643
196/196 - 79s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1677 - val_MinusLogProbMetric: 5.1677 - lr: 2.6042e-06 - 79s/epoch - 402ms/step
Epoch 913/1000
2023-09-20 10:07:01.051 
Epoch 913/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1673, val_MinusLogProbMetric: 5.1673

Epoch 913: val_loss did not improve from 5.16643
196/196 - 67s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1673 - val_MinusLogProbMetric: 5.1673 - lr: 2.6042e-06 - 67s/epoch - 344ms/step
Epoch 914/1000
2023-09-20 10:08:06.896 
Epoch 914/1000 
	 loss: 5.0630, MinusLogProbMetric: 5.0630, val_loss: 5.1673, val_MinusLogProbMetric: 5.1673

Epoch 914: val_loss did not improve from 5.16643
196/196 - 66s - loss: 5.0630 - MinusLogProbMetric: 5.0630 - val_loss: 5.1673 - val_MinusLogProbMetric: 5.1673 - lr: 2.6042e-06 - 66s/epoch - 336ms/step
Epoch 915/1000
2023-09-20 10:09:27.509 
Epoch 915/1000 
	 loss: 5.0631, MinusLogProbMetric: 5.0631, val_loss: 5.1681, val_MinusLogProbMetric: 5.1681

Epoch 915: val_loss did not improve from 5.16643
196/196 - 81s - loss: 5.0631 - MinusLogProbMetric: 5.0631 - val_loss: 5.1681 - val_MinusLogProbMetric: 5.1681 - lr: 2.6042e-06 - 81s/epoch - 411ms/step
Epoch 916/1000
2023-09-20 10:10:43.515 
Epoch 916/1000 
	 loss: 5.0634, MinusLogProbMetric: 5.0634, val_loss: 5.1665, val_MinusLogProbMetric: 5.1665

Epoch 916: val_loss did not improve from 5.16643
196/196 - 76s - loss: 5.0634 - MinusLogProbMetric: 5.0634 - val_loss: 5.1665 - val_MinusLogProbMetric: 5.1665 - lr: 2.6042e-06 - 76s/epoch - 388ms/step
Epoch 917/1000
2023-09-20 10:11:48.577 
Epoch 917/1000 
	 loss: 5.0633, MinusLogProbMetric: 5.0633, val_loss: 5.1667, val_MinusLogProbMetric: 5.1667

Epoch 917: val_loss did not improve from 5.16643
196/196 - 65s - loss: 5.0633 - MinusLogProbMetric: 5.0633 - val_loss: 5.1667 - val_MinusLogProbMetric: 5.1667 - lr: 2.6042e-06 - 65s/epoch - 332ms/step
Epoch 918/1000
2023-09-20 10:13:08.441 
Epoch 918/1000 
	 loss: 5.0633, MinusLogProbMetric: 5.0633, val_loss: 5.1676, val_MinusLogProbMetric: 5.1676

Epoch 918: val_loss did not improve from 5.16643
196/196 - 80s - loss: 5.0633 - MinusLogProbMetric: 5.0633 - val_loss: 5.1676 - val_MinusLogProbMetric: 5.1676 - lr: 2.6042e-06 - 80s/epoch - 407ms/step
Epoch 919/1000
2023-09-20 10:14:30.107 
Epoch 919/1000 
	 loss: 5.0630, MinusLogProbMetric: 5.0630, val_loss: 5.1672, val_MinusLogProbMetric: 5.1672

Epoch 919: val_loss did not improve from 5.16643
196/196 - 82s - loss: 5.0630 - MinusLogProbMetric: 5.0630 - val_loss: 5.1672 - val_MinusLogProbMetric: 5.1672 - lr: 2.6042e-06 - 82s/epoch - 417ms/step
Epoch 920/1000
2023-09-20 10:15:53.080 
Epoch 920/1000 
	 loss: 5.0632, MinusLogProbMetric: 5.0632, val_loss: 5.1671, val_MinusLogProbMetric: 5.1671

Epoch 920: val_loss did not improve from 5.16643
196/196 - 83s - loss: 5.0632 - MinusLogProbMetric: 5.0632 - val_loss: 5.1671 - val_MinusLogProbMetric: 5.1671 - lr: 2.6042e-06 - 83s/epoch - 423ms/step
Epoch 921/1000
2023-09-20 10:17:15.974 
Epoch 921/1000 
	 loss: 5.0627, MinusLogProbMetric: 5.0627, val_loss: 5.1663, val_MinusLogProbMetric: 5.1663

Epoch 921: val_loss improved from 5.16643 to 5.16632, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 84s - loss: 5.0627 - MinusLogProbMetric: 5.0627 - val_loss: 5.1663 - val_MinusLogProbMetric: 5.1663 - lr: 2.6042e-06 - 84s/epoch - 430ms/step
Epoch 922/1000
2023-09-20 10:18:40.305 
Epoch 922/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1673, val_MinusLogProbMetric: 5.1673

Epoch 922: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1673 - val_MinusLogProbMetric: 5.1673 - lr: 2.6042e-06 - 83s/epoch - 424ms/step
Epoch 923/1000
2023-09-20 10:19:50.907 
Epoch 923/1000 
	 loss: 5.0632, MinusLogProbMetric: 5.0632, val_loss: 5.1673, val_MinusLogProbMetric: 5.1673

Epoch 923: val_loss did not improve from 5.16632
196/196 - 71s - loss: 5.0632 - MinusLogProbMetric: 5.0632 - val_loss: 5.1673 - val_MinusLogProbMetric: 5.1673 - lr: 2.6042e-06 - 71s/epoch - 360ms/step
Epoch 924/1000
2023-09-20 10:21:02.373 
Epoch 924/1000 
	 loss: 5.0631, MinusLogProbMetric: 5.0631, val_loss: 5.1668, val_MinusLogProbMetric: 5.1668

Epoch 924: val_loss did not improve from 5.16632
196/196 - 71s - loss: 5.0631 - MinusLogProbMetric: 5.0631 - val_loss: 5.1668 - val_MinusLogProbMetric: 5.1668 - lr: 2.6042e-06 - 71s/epoch - 365ms/step
Epoch 925/1000
2023-09-20 10:22:23.666 
Epoch 925/1000 
	 loss: 5.0632, MinusLogProbMetric: 5.0632, val_loss: 5.1671, val_MinusLogProbMetric: 5.1671

Epoch 925: val_loss did not improve from 5.16632
196/196 - 81s - loss: 5.0632 - MinusLogProbMetric: 5.0632 - val_loss: 5.1671 - val_MinusLogProbMetric: 5.1671 - lr: 2.6042e-06 - 81s/epoch - 415ms/step
Epoch 926/1000
2023-09-20 10:23:46.946 
Epoch 926/1000 
	 loss: 5.0631, MinusLogProbMetric: 5.0631, val_loss: 5.1675, val_MinusLogProbMetric: 5.1675

Epoch 926: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0631 - MinusLogProbMetric: 5.0631 - val_loss: 5.1675 - val_MinusLogProbMetric: 5.1675 - lr: 2.6042e-06 - 83s/epoch - 425ms/step
Epoch 927/1000
2023-09-20 10:25:10.124 
Epoch 927/1000 
	 loss: 5.0628, MinusLogProbMetric: 5.0628, val_loss: 5.1670, val_MinusLogProbMetric: 5.1670

Epoch 927: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0628 - MinusLogProbMetric: 5.0628 - val_loss: 5.1670 - val_MinusLogProbMetric: 5.1670 - lr: 2.6042e-06 - 83s/epoch - 424ms/step
Epoch 928/1000
2023-09-20 10:26:33.444 
Epoch 928/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1671, val_MinusLogProbMetric: 5.1671

Epoch 928: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1671 - val_MinusLogProbMetric: 5.1671 - lr: 2.6042e-06 - 83s/epoch - 425ms/step
Epoch 929/1000
2023-09-20 10:27:55.784 
Epoch 929/1000 
	 loss: 5.0630, MinusLogProbMetric: 5.0630, val_loss: 5.1673, val_MinusLogProbMetric: 5.1673

Epoch 929: val_loss did not improve from 5.16632
196/196 - 82s - loss: 5.0630 - MinusLogProbMetric: 5.0630 - val_loss: 5.1673 - val_MinusLogProbMetric: 5.1673 - lr: 2.6042e-06 - 82s/epoch - 420ms/step
Epoch 930/1000
2023-09-20 10:29:15.903 
Epoch 930/1000 
	 loss: 5.0628, MinusLogProbMetric: 5.0628, val_loss: 5.1670, val_MinusLogProbMetric: 5.1670

Epoch 930: val_loss did not improve from 5.16632
196/196 - 80s - loss: 5.0628 - MinusLogProbMetric: 5.0628 - val_loss: 5.1670 - val_MinusLogProbMetric: 5.1670 - lr: 2.6042e-06 - 80s/epoch - 409ms/step
Epoch 931/1000
2023-09-20 10:30:24.628 
Epoch 931/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1672, val_MinusLogProbMetric: 5.1672

Epoch 931: val_loss did not improve from 5.16632
196/196 - 69s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1672 - val_MinusLogProbMetric: 5.1672 - lr: 2.6042e-06 - 69s/epoch - 351ms/step
Epoch 932/1000
2023-09-20 10:31:33.995 
Epoch 932/1000 
	 loss: 5.0631, MinusLogProbMetric: 5.0631, val_loss: 5.1668, val_MinusLogProbMetric: 5.1668

Epoch 932: val_loss did not improve from 5.16632
196/196 - 69s - loss: 5.0631 - MinusLogProbMetric: 5.0631 - val_loss: 5.1668 - val_MinusLogProbMetric: 5.1668 - lr: 2.6042e-06 - 69s/epoch - 354ms/step
Epoch 933/1000
2023-09-20 10:32:48.524 
Epoch 933/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1673, val_MinusLogProbMetric: 5.1673

Epoch 933: val_loss did not improve from 5.16632
196/196 - 75s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1673 - val_MinusLogProbMetric: 5.1673 - lr: 2.6042e-06 - 75s/epoch - 380ms/step
Epoch 934/1000
2023-09-20 10:33:52.029 
Epoch 934/1000 
	 loss: 5.0631, MinusLogProbMetric: 5.0631, val_loss: 5.1678, val_MinusLogProbMetric: 5.1678

Epoch 934: val_loss did not improve from 5.16632
196/196 - 64s - loss: 5.0631 - MinusLogProbMetric: 5.0631 - val_loss: 5.1678 - val_MinusLogProbMetric: 5.1678 - lr: 2.6042e-06 - 64s/epoch - 324ms/step
Epoch 935/1000
2023-09-20 10:35:04.750 
Epoch 935/1000 
	 loss: 5.0633, MinusLogProbMetric: 5.0633, val_loss: 5.1670, val_MinusLogProbMetric: 5.1670

Epoch 935: val_loss did not improve from 5.16632
196/196 - 73s - loss: 5.0633 - MinusLogProbMetric: 5.0633 - val_loss: 5.1670 - val_MinusLogProbMetric: 5.1670 - lr: 2.6042e-06 - 73s/epoch - 371ms/step
Epoch 936/1000
2023-09-20 10:36:27.792 
Epoch 936/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1675, val_MinusLogProbMetric: 5.1675

Epoch 936: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1675 - val_MinusLogProbMetric: 5.1675 - lr: 2.6042e-06 - 83s/epoch - 424ms/step
Epoch 937/1000
2023-09-20 10:37:48.151 
Epoch 937/1000 
	 loss: 5.0633, MinusLogProbMetric: 5.0633, val_loss: 5.1672, val_MinusLogProbMetric: 5.1672

Epoch 937: val_loss did not improve from 5.16632
196/196 - 80s - loss: 5.0633 - MinusLogProbMetric: 5.0633 - val_loss: 5.1672 - val_MinusLogProbMetric: 5.1672 - lr: 2.6042e-06 - 80s/epoch - 410ms/step
Epoch 938/1000
2023-09-20 10:39:10.818 
Epoch 938/1000 
	 loss: 5.0630, MinusLogProbMetric: 5.0630, val_loss: 5.1663, val_MinusLogProbMetric: 5.1663

Epoch 938: val_loss improved from 5.16632 to 5.16632, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 84s - loss: 5.0630 - MinusLogProbMetric: 5.0630 - val_loss: 5.1663 - val_MinusLogProbMetric: 5.1663 - lr: 2.6042e-06 - 84s/epoch - 428ms/step
Epoch 939/1000
2023-09-20 10:40:34.806 
Epoch 939/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1669, val_MinusLogProbMetric: 5.1669

Epoch 939: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1669 - val_MinusLogProbMetric: 5.1669 - lr: 2.6042e-06 - 83s/epoch - 422ms/step
Epoch 940/1000
2023-09-20 10:41:58.047 
Epoch 940/1000 
	 loss: 5.0628, MinusLogProbMetric: 5.0628, val_loss: 5.1672, val_MinusLogProbMetric: 5.1672

Epoch 940: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0628 - MinusLogProbMetric: 5.0628 - val_loss: 5.1672 - val_MinusLogProbMetric: 5.1672 - lr: 2.6042e-06 - 83s/epoch - 425ms/step
Epoch 941/1000
2023-09-20 10:43:20.018 
Epoch 941/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1668, val_MinusLogProbMetric: 5.1668

Epoch 941: val_loss did not improve from 5.16632
196/196 - 82s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1668 - val_MinusLogProbMetric: 5.1668 - lr: 2.6042e-06 - 82s/epoch - 418ms/step
Epoch 942/1000
2023-09-20 10:44:42.779 
Epoch 942/1000 
	 loss: 5.0634, MinusLogProbMetric: 5.0634, val_loss: 5.1669, val_MinusLogProbMetric: 5.1669

Epoch 942: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0634 - MinusLogProbMetric: 5.0634 - val_loss: 5.1669 - val_MinusLogProbMetric: 5.1669 - lr: 2.6042e-06 - 83s/epoch - 422ms/step
Epoch 943/1000
2023-09-20 10:46:05.843 
Epoch 943/1000 
	 loss: 5.0633, MinusLogProbMetric: 5.0633, val_loss: 5.1669, val_MinusLogProbMetric: 5.1669

Epoch 943: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0633 - MinusLogProbMetric: 5.0633 - val_loss: 5.1669 - val_MinusLogProbMetric: 5.1669 - lr: 2.6042e-06 - 83s/epoch - 424ms/step
Epoch 944/1000
2023-09-20 10:47:28.352 
Epoch 944/1000 
	 loss: 5.0631, MinusLogProbMetric: 5.0631, val_loss: 5.1670, val_MinusLogProbMetric: 5.1670

Epoch 944: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0631 - MinusLogProbMetric: 5.0631 - val_loss: 5.1670 - val_MinusLogProbMetric: 5.1670 - lr: 2.6042e-06 - 83s/epoch - 421ms/step
Epoch 945/1000
2023-09-20 10:48:51.382 
Epoch 945/1000 
	 loss: 5.0630, MinusLogProbMetric: 5.0630, val_loss: 5.1666, val_MinusLogProbMetric: 5.1666

Epoch 945: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0630 - MinusLogProbMetric: 5.0630 - val_loss: 5.1666 - val_MinusLogProbMetric: 5.1666 - lr: 2.6042e-06 - 83s/epoch - 424ms/step
Epoch 946/1000
2023-09-20 10:50:14.731 
Epoch 946/1000 
	 loss: 5.0628, MinusLogProbMetric: 5.0628, val_loss: 5.1674, val_MinusLogProbMetric: 5.1674

Epoch 946: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0628 - MinusLogProbMetric: 5.0628 - val_loss: 5.1674 - val_MinusLogProbMetric: 5.1674 - lr: 2.6042e-06 - 83s/epoch - 425ms/step
Epoch 947/1000
2023-09-20 10:51:35.824 
Epoch 947/1000 
	 loss: 5.0630, MinusLogProbMetric: 5.0630, val_loss: 5.1667, val_MinusLogProbMetric: 5.1667

Epoch 947: val_loss did not improve from 5.16632
196/196 - 81s - loss: 5.0630 - MinusLogProbMetric: 5.0630 - val_loss: 5.1667 - val_MinusLogProbMetric: 5.1667 - lr: 2.6042e-06 - 81s/epoch - 414ms/step
Epoch 948/1000
2023-09-20 10:52:58.544 
Epoch 948/1000 
	 loss: 5.0631, MinusLogProbMetric: 5.0631, val_loss: 5.1665, val_MinusLogProbMetric: 5.1665

Epoch 948: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0631 - MinusLogProbMetric: 5.0631 - val_loss: 5.1665 - val_MinusLogProbMetric: 5.1665 - lr: 2.6042e-06 - 83s/epoch - 422ms/step
Epoch 949/1000
2023-09-20 10:54:22.202 
Epoch 949/1000 
	 loss: 5.0631, MinusLogProbMetric: 5.0631, val_loss: 5.1669, val_MinusLogProbMetric: 5.1669

Epoch 949: val_loss did not improve from 5.16632
196/196 - 84s - loss: 5.0631 - MinusLogProbMetric: 5.0631 - val_loss: 5.1669 - val_MinusLogProbMetric: 5.1669 - lr: 2.6042e-06 - 84s/epoch - 427ms/step
Epoch 950/1000
2023-09-20 10:55:45.746 
Epoch 950/1000 
	 loss: 5.0630, MinusLogProbMetric: 5.0630, val_loss: 5.1671, val_MinusLogProbMetric: 5.1671

Epoch 950: val_loss did not improve from 5.16632
196/196 - 84s - loss: 5.0630 - MinusLogProbMetric: 5.0630 - val_loss: 5.1671 - val_MinusLogProbMetric: 5.1671 - lr: 2.6042e-06 - 84s/epoch - 426ms/step
Epoch 951/1000
2023-09-20 10:57:08.735 
Epoch 951/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1669, val_MinusLogProbMetric: 5.1669

Epoch 951: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1669 - val_MinusLogProbMetric: 5.1669 - lr: 2.6042e-06 - 83s/epoch - 423ms/step
Epoch 952/1000
2023-09-20 10:58:30.777 
Epoch 952/1000 
	 loss: 5.0630, MinusLogProbMetric: 5.0630, val_loss: 5.1667, val_MinusLogProbMetric: 5.1667

Epoch 952: val_loss did not improve from 5.16632
196/196 - 82s - loss: 5.0630 - MinusLogProbMetric: 5.0630 - val_loss: 5.1667 - val_MinusLogProbMetric: 5.1667 - lr: 2.6042e-06 - 82s/epoch - 419ms/step
Epoch 953/1000
2023-09-20 10:59:52.800 
Epoch 953/1000 
	 loss: 5.0628, MinusLogProbMetric: 5.0628, val_loss: 5.1664, val_MinusLogProbMetric: 5.1664

Epoch 953: val_loss did not improve from 5.16632
196/196 - 82s - loss: 5.0628 - MinusLogProbMetric: 5.0628 - val_loss: 5.1664 - val_MinusLogProbMetric: 5.1664 - lr: 2.6042e-06 - 82s/epoch - 418ms/step
Epoch 954/1000
2023-09-20 11:01:15.513 
Epoch 954/1000 
	 loss: 5.0628, MinusLogProbMetric: 5.0628, val_loss: 5.1675, val_MinusLogProbMetric: 5.1675

Epoch 954: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0628 - MinusLogProbMetric: 5.0628 - val_loss: 5.1675 - val_MinusLogProbMetric: 5.1675 - lr: 2.6042e-06 - 83s/epoch - 422ms/step
Epoch 955/1000
2023-09-20 11:02:38.143 
Epoch 955/1000 
	 loss: 5.0631, MinusLogProbMetric: 5.0631, val_loss: 5.1667, val_MinusLogProbMetric: 5.1667

Epoch 955: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0631 - MinusLogProbMetric: 5.0631 - val_loss: 5.1667 - val_MinusLogProbMetric: 5.1667 - lr: 2.6042e-06 - 83s/epoch - 422ms/step
Epoch 956/1000
2023-09-20 11:04:00.713 
Epoch 956/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1667, val_MinusLogProbMetric: 5.1667

Epoch 956: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1667 - val_MinusLogProbMetric: 5.1667 - lr: 2.6042e-06 - 83s/epoch - 421ms/step
Epoch 957/1000
2023-09-20 11:05:23.163 
Epoch 957/1000 
	 loss: 5.0627, MinusLogProbMetric: 5.0627, val_loss: 5.1668, val_MinusLogProbMetric: 5.1668

Epoch 957: val_loss did not improve from 5.16632
196/196 - 82s - loss: 5.0627 - MinusLogProbMetric: 5.0627 - val_loss: 5.1668 - val_MinusLogProbMetric: 5.1668 - lr: 2.6042e-06 - 82s/epoch - 421ms/step
Epoch 958/1000
2023-09-20 11:06:45.912 
Epoch 958/1000 
	 loss: 5.0632, MinusLogProbMetric: 5.0632, val_loss: 5.1665, val_MinusLogProbMetric: 5.1665

Epoch 958: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0632 - MinusLogProbMetric: 5.0632 - val_loss: 5.1665 - val_MinusLogProbMetric: 5.1665 - lr: 2.6042e-06 - 83s/epoch - 422ms/step
Epoch 959/1000
2023-09-20 11:08:08.583 
Epoch 959/1000 
	 loss: 5.0626, MinusLogProbMetric: 5.0626, val_loss: 5.1674, val_MinusLogProbMetric: 5.1674

Epoch 959: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0626 - MinusLogProbMetric: 5.0626 - val_loss: 5.1674 - val_MinusLogProbMetric: 5.1674 - lr: 2.6042e-06 - 83s/epoch - 422ms/step
Epoch 960/1000
2023-09-20 11:09:31.226 
Epoch 960/1000 
	 loss: 5.0628, MinusLogProbMetric: 5.0628, val_loss: 5.1670, val_MinusLogProbMetric: 5.1670

Epoch 960: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0628 - MinusLogProbMetric: 5.0628 - val_loss: 5.1670 - val_MinusLogProbMetric: 5.1670 - lr: 2.6042e-06 - 83s/epoch - 422ms/step
Epoch 961/1000
2023-09-20 11:10:53.405 
Epoch 961/1000 
	 loss: 5.0633, MinusLogProbMetric: 5.0633, val_loss: 5.1674, val_MinusLogProbMetric: 5.1674

Epoch 961: val_loss did not improve from 5.16632
196/196 - 82s - loss: 5.0633 - MinusLogProbMetric: 5.0633 - val_loss: 5.1674 - val_MinusLogProbMetric: 5.1674 - lr: 2.6042e-06 - 82s/epoch - 419ms/step
Epoch 962/1000
2023-09-20 11:12:16.083 
Epoch 962/1000 
	 loss: 5.0628, MinusLogProbMetric: 5.0628, val_loss: 5.1673, val_MinusLogProbMetric: 5.1673

Epoch 962: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0628 - MinusLogProbMetric: 5.0628 - val_loss: 5.1673 - val_MinusLogProbMetric: 5.1673 - lr: 2.6042e-06 - 83s/epoch - 422ms/step
Epoch 963/1000
2023-09-20 11:13:39.389 
Epoch 963/1000 
	 loss: 5.0628, MinusLogProbMetric: 5.0628, val_loss: 5.1671, val_MinusLogProbMetric: 5.1671

Epoch 963: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0628 - MinusLogProbMetric: 5.0628 - val_loss: 5.1671 - val_MinusLogProbMetric: 5.1671 - lr: 2.6042e-06 - 83s/epoch - 425ms/step
Epoch 964/1000
2023-09-20 11:15:01.951 
Epoch 964/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1676, val_MinusLogProbMetric: 5.1676

Epoch 964: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1676 - val_MinusLogProbMetric: 5.1676 - lr: 2.6042e-06 - 83s/epoch - 421ms/step
Epoch 965/1000
2023-09-20 11:16:25.288 
Epoch 965/1000 
	 loss: 5.0630, MinusLogProbMetric: 5.0630, val_loss: 5.1669, val_MinusLogProbMetric: 5.1669

Epoch 965: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0630 - MinusLogProbMetric: 5.0630 - val_loss: 5.1669 - val_MinusLogProbMetric: 5.1669 - lr: 2.6042e-06 - 83s/epoch - 425ms/step
Epoch 966/1000
2023-09-20 11:17:48.041 
Epoch 966/1000 
	 loss: 5.0628, MinusLogProbMetric: 5.0628, val_loss: 5.1672, val_MinusLogProbMetric: 5.1672

Epoch 966: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0628 - MinusLogProbMetric: 5.0628 - val_loss: 5.1672 - val_MinusLogProbMetric: 5.1672 - lr: 2.6042e-06 - 83s/epoch - 422ms/step
Epoch 967/1000
2023-09-20 11:19:11.037 
Epoch 967/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1669, val_MinusLogProbMetric: 5.1669

Epoch 967: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1669 - val_MinusLogProbMetric: 5.1669 - lr: 2.6042e-06 - 83s/epoch - 423ms/step
Epoch 968/1000
2023-09-20 11:20:33.550 
Epoch 968/1000 
	 loss: 5.0624, MinusLogProbMetric: 5.0624, val_loss: 5.1673, val_MinusLogProbMetric: 5.1673

Epoch 968: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0624 - MinusLogProbMetric: 5.0624 - val_loss: 5.1673 - val_MinusLogProbMetric: 5.1673 - lr: 2.6042e-06 - 83s/epoch - 421ms/step
Epoch 969/1000
2023-09-20 11:21:55.602 
Epoch 969/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1670, val_MinusLogProbMetric: 5.1670

Epoch 969: val_loss did not improve from 5.16632
196/196 - 82s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1670 - val_MinusLogProbMetric: 5.1670 - lr: 2.6042e-06 - 82s/epoch - 419ms/step
Epoch 970/1000
2023-09-20 11:23:18.803 
Epoch 970/1000 
	 loss: 5.0627, MinusLogProbMetric: 5.0627, val_loss: 5.1671, val_MinusLogProbMetric: 5.1671

Epoch 970: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0627 - MinusLogProbMetric: 5.0627 - val_loss: 5.1671 - val_MinusLogProbMetric: 5.1671 - lr: 2.6042e-06 - 83s/epoch - 424ms/step
Epoch 971/1000
2023-09-20 11:24:41.906 
Epoch 971/1000 
	 loss: 5.0627, MinusLogProbMetric: 5.0627, val_loss: 5.1671, val_MinusLogProbMetric: 5.1671

Epoch 971: val_loss did not improve from 5.16632
196/196 - 83s - loss: 5.0627 - MinusLogProbMetric: 5.0627 - val_loss: 5.1671 - val_MinusLogProbMetric: 5.1671 - lr: 2.6042e-06 - 83s/epoch - 424ms/step
Epoch 972/1000
2023-09-20 11:26:04.736 
Epoch 972/1000 
	 loss: 5.0622, MinusLogProbMetric: 5.0622, val_loss: 5.1659, val_MinusLogProbMetric: 5.1659

Epoch 972: val_loss improved from 5.16632 to 5.16590, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_231/weights/best_weights.h5
196/196 - 84s - loss: 5.0622 - MinusLogProbMetric: 5.0622 - val_loss: 5.1659 - val_MinusLogProbMetric: 5.1659 - lr: 1.3021e-06 - 84s/epoch - 430ms/step
Epoch 973/1000
2023-09-20 11:27:29.441 
Epoch 973/1000 
	 loss: 5.0622, MinusLogProbMetric: 5.0622, val_loss: 5.1663, val_MinusLogProbMetric: 5.1663

Epoch 973: val_loss did not improve from 5.16590
196/196 - 83s - loss: 5.0622 - MinusLogProbMetric: 5.0622 - val_loss: 5.1663 - val_MinusLogProbMetric: 5.1663 - lr: 1.3021e-06 - 83s/epoch - 424ms/step
Epoch 974/1000
2023-09-20 11:28:51.990 
Epoch 974/1000 
	 loss: 5.0623, MinusLogProbMetric: 5.0623, val_loss: 5.1667, val_MinusLogProbMetric: 5.1667

Epoch 974: val_loss did not improve from 5.16590
196/196 - 83s - loss: 5.0623 - MinusLogProbMetric: 5.0623 - val_loss: 5.1667 - val_MinusLogProbMetric: 5.1667 - lr: 1.3021e-06 - 83s/epoch - 421ms/step
Epoch 975/1000
2023-09-20 11:30:14.322 
Epoch 975/1000 
	 loss: 5.0620, MinusLogProbMetric: 5.0620, val_loss: 5.1665, val_MinusLogProbMetric: 5.1665

Epoch 975: val_loss did not improve from 5.16590
196/196 - 82s - loss: 5.0620 - MinusLogProbMetric: 5.0620 - val_loss: 5.1665 - val_MinusLogProbMetric: 5.1665 - lr: 1.3021e-06 - 82s/epoch - 420ms/step
Epoch 976/1000
2023-09-20 11:31:37.275 
Epoch 976/1000 
	 loss: 5.0626, MinusLogProbMetric: 5.0626, val_loss: 5.1669, val_MinusLogProbMetric: 5.1669

Epoch 976: val_loss did not improve from 5.16590
196/196 - 83s - loss: 5.0626 - MinusLogProbMetric: 5.0626 - val_loss: 5.1669 - val_MinusLogProbMetric: 5.1669 - lr: 1.3021e-06 - 83s/epoch - 423ms/step
Epoch 977/1000
2023-09-20 11:32:59.640 
Epoch 977/1000 
	 loss: 5.0625, MinusLogProbMetric: 5.0625, val_loss: 5.1669, val_MinusLogProbMetric: 5.1669

Epoch 977: val_loss did not improve from 5.16590
196/196 - 82s - loss: 5.0625 - MinusLogProbMetric: 5.0625 - val_loss: 5.1669 - val_MinusLogProbMetric: 5.1669 - lr: 1.3021e-06 - 82s/epoch - 420ms/step
Epoch 978/1000
2023-09-20 11:34:23.423 
Epoch 978/1000 
	 loss: 5.0622, MinusLogProbMetric: 5.0622, val_loss: 5.1669, val_MinusLogProbMetric: 5.1669

Epoch 978: val_loss did not improve from 5.16590
196/196 - 84s - loss: 5.0622 - MinusLogProbMetric: 5.0622 - val_loss: 5.1669 - val_MinusLogProbMetric: 5.1669 - lr: 1.3021e-06 - 84s/epoch - 427ms/step
Epoch 979/1000
2023-09-20 11:35:46.764 
Epoch 979/1000 
	 loss: 5.0622, MinusLogProbMetric: 5.0622, val_loss: 5.1664, val_MinusLogProbMetric: 5.1664

Epoch 979: val_loss did not improve from 5.16590
196/196 - 83s - loss: 5.0622 - MinusLogProbMetric: 5.0622 - val_loss: 5.1664 - val_MinusLogProbMetric: 5.1664 - lr: 1.3021e-06 - 83s/epoch - 425ms/step
Epoch 980/1000
2023-09-20 11:37:09.999 
Epoch 980/1000 
	 loss: 5.0621, MinusLogProbMetric: 5.0621, val_loss: 5.1668, val_MinusLogProbMetric: 5.1668

Epoch 980: val_loss did not improve from 5.16590
196/196 - 83s - loss: 5.0621 - MinusLogProbMetric: 5.0621 - val_loss: 5.1668 - val_MinusLogProbMetric: 5.1668 - lr: 1.3021e-06 - 83s/epoch - 425ms/step
Epoch 981/1000
2023-09-20 11:38:32.833 
Epoch 981/1000 
	 loss: 5.0622, MinusLogProbMetric: 5.0622, val_loss: 5.1667, val_MinusLogProbMetric: 5.1667

Epoch 981: val_loss did not improve from 5.16590
196/196 - 83s - loss: 5.0622 - MinusLogProbMetric: 5.0622 - val_loss: 5.1667 - val_MinusLogProbMetric: 5.1667 - lr: 1.3021e-06 - 83s/epoch - 423ms/step
Epoch 982/1000
2023-09-20 11:39:55.137 
Epoch 982/1000 
	 loss: 5.0624, MinusLogProbMetric: 5.0624, val_loss: 5.1668, val_MinusLogProbMetric: 5.1668

Epoch 982: val_loss did not improve from 5.16590
196/196 - 82s - loss: 5.0624 - MinusLogProbMetric: 5.0624 - val_loss: 5.1668 - val_MinusLogProbMetric: 5.1668 - lr: 1.3021e-06 - 82s/epoch - 420ms/step
Epoch 983/1000
2023-09-20 11:41:17.844 
Epoch 983/1000 
	 loss: 5.0623, MinusLogProbMetric: 5.0623, val_loss: 5.1666, val_MinusLogProbMetric: 5.1666

Epoch 983: val_loss did not improve from 5.16590
196/196 - 83s - loss: 5.0623 - MinusLogProbMetric: 5.0623 - val_loss: 5.1666 - val_MinusLogProbMetric: 5.1666 - lr: 1.3021e-06 - 83s/epoch - 422ms/step
Epoch 984/1000
2023-09-20 11:42:40.371 
Epoch 984/1000 
	 loss: 5.0624, MinusLogProbMetric: 5.0624, val_loss: 5.1665, val_MinusLogProbMetric: 5.1665

Epoch 984: val_loss did not improve from 5.16590
196/196 - 83s - loss: 5.0624 - MinusLogProbMetric: 5.0624 - val_loss: 5.1665 - val_MinusLogProbMetric: 5.1665 - lr: 1.3021e-06 - 83s/epoch - 421ms/step
Epoch 985/1000
2023-09-20 11:44:02.463 
Epoch 985/1000 
	 loss: 5.0622, MinusLogProbMetric: 5.0622, val_loss: 5.1666, val_MinusLogProbMetric: 5.1666

Epoch 985: val_loss did not improve from 5.16590
196/196 - 82s - loss: 5.0622 - MinusLogProbMetric: 5.0622 - val_loss: 5.1666 - val_MinusLogProbMetric: 5.1666 - lr: 1.3021e-06 - 82s/epoch - 419ms/step
Epoch 986/1000
2023-09-20 11:45:26.124 
Epoch 986/1000 
	 loss: 5.0623, MinusLogProbMetric: 5.0623, val_loss: 5.1665, val_MinusLogProbMetric: 5.1665

Epoch 986: val_loss did not improve from 5.16590
196/196 - 84s - loss: 5.0623 - MinusLogProbMetric: 5.0623 - val_loss: 5.1665 - val_MinusLogProbMetric: 5.1665 - lr: 1.3021e-06 - 84s/epoch - 427ms/step
Epoch 987/1000
2023-09-20 11:46:48.805 
Epoch 987/1000 
	 loss: 5.0624, MinusLogProbMetric: 5.0624, val_loss: 5.1665, val_MinusLogProbMetric: 5.1665

Epoch 987: val_loss did not improve from 5.16590
196/196 - 83s - loss: 5.0624 - MinusLogProbMetric: 5.0624 - val_loss: 5.1665 - val_MinusLogProbMetric: 5.1665 - lr: 1.3021e-06 - 83s/epoch - 422ms/step
Epoch 988/1000
2023-09-20 11:48:12.453 
Epoch 988/1000 
	 loss: 5.0623, MinusLogProbMetric: 5.0623, val_loss: 5.1672, val_MinusLogProbMetric: 5.1672

Epoch 988: val_loss did not improve from 5.16590
196/196 - 84s - loss: 5.0623 - MinusLogProbMetric: 5.0623 - val_loss: 5.1672 - val_MinusLogProbMetric: 5.1672 - lr: 1.3021e-06 - 84s/epoch - 427ms/step
Epoch 989/1000
2023-09-20 11:49:35.446 
Epoch 989/1000 
	 loss: 5.0624, MinusLogProbMetric: 5.0624, val_loss: 5.1670, val_MinusLogProbMetric: 5.1670

Epoch 989: val_loss did not improve from 5.16590
196/196 - 83s - loss: 5.0624 - MinusLogProbMetric: 5.0624 - val_loss: 5.1670 - val_MinusLogProbMetric: 5.1670 - lr: 1.3021e-06 - 83s/epoch - 423ms/step
Epoch 990/1000
2023-09-20 11:50:57.756 
Epoch 990/1000 
	 loss: 5.0621, MinusLogProbMetric: 5.0621, val_loss: 5.1669, val_MinusLogProbMetric: 5.1669

Epoch 990: val_loss did not improve from 5.16590
196/196 - 82s - loss: 5.0621 - MinusLogProbMetric: 5.0621 - val_loss: 5.1669 - val_MinusLogProbMetric: 5.1669 - lr: 1.3021e-06 - 82s/epoch - 420ms/step
Epoch 991/1000
2023-09-20 11:52:21.450 
Epoch 991/1000 
	 loss: 5.0621, MinusLogProbMetric: 5.0621, val_loss: 5.1668, val_MinusLogProbMetric: 5.1668

Epoch 991: val_loss did not improve from 5.16590
196/196 - 84s - loss: 5.0621 - MinusLogProbMetric: 5.0621 - val_loss: 5.1668 - val_MinusLogProbMetric: 5.1668 - lr: 1.3021e-06 - 84s/epoch - 427ms/step
Epoch 992/1000
2023-09-20 11:53:44.641 
Epoch 992/1000 
	 loss: 5.0623, MinusLogProbMetric: 5.0623, val_loss: 5.1672, val_MinusLogProbMetric: 5.1672

Epoch 992: val_loss did not improve from 5.16590
196/196 - 83s - loss: 5.0623 - MinusLogProbMetric: 5.0623 - val_loss: 5.1672 - val_MinusLogProbMetric: 5.1672 - lr: 1.3021e-06 - 83s/epoch - 424ms/step
Epoch 993/1000
2023-09-20 11:55:07.800 
Epoch 993/1000 
	 loss: 5.0623, MinusLogProbMetric: 5.0623, val_loss: 5.1665, val_MinusLogProbMetric: 5.1665

Epoch 993: val_loss did not improve from 5.16590
196/196 - 83s - loss: 5.0623 - MinusLogProbMetric: 5.0623 - val_loss: 5.1665 - val_MinusLogProbMetric: 5.1665 - lr: 1.3021e-06 - 83s/epoch - 424ms/step
Epoch 994/1000
2023-09-20 11:56:31.346 
Epoch 994/1000 
	 loss: 5.0626, MinusLogProbMetric: 5.0626, val_loss: 5.1670, val_MinusLogProbMetric: 5.1670

Epoch 994: val_loss did not improve from 5.16590
196/196 - 84s - loss: 5.0626 - MinusLogProbMetric: 5.0626 - val_loss: 5.1670 - val_MinusLogProbMetric: 5.1670 - lr: 1.3021e-06 - 84s/epoch - 426ms/step
Epoch 995/1000
2023-09-20 11:57:54.210 
Epoch 995/1000 
	 loss: 5.0621, MinusLogProbMetric: 5.0621, val_loss: 5.1670, val_MinusLogProbMetric: 5.1670

Epoch 995: val_loss did not improve from 5.16590
196/196 - 83s - loss: 5.0621 - MinusLogProbMetric: 5.0621 - val_loss: 5.1670 - val_MinusLogProbMetric: 5.1670 - lr: 1.3021e-06 - 83s/epoch - 423ms/step
Epoch 996/1000
2023-09-20 11:59:17.487 
Epoch 996/1000 
	 loss: 5.0622, MinusLogProbMetric: 5.0622, val_loss: 5.1667, val_MinusLogProbMetric: 5.1667

Epoch 996: val_loss did not improve from 5.16590
196/196 - 83s - loss: 5.0622 - MinusLogProbMetric: 5.0622 - val_loss: 5.1667 - val_MinusLogProbMetric: 5.1667 - lr: 1.3021e-06 - 83s/epoch - 425ms/step
Epoch 997/1000
2023-09-20 12:00:40.325 
Epoch 997/1000 
	 loss: 5.0622, MinusLogProbMetric: 5.0622, val_loss: 5.1668, val_MinusLogProbMetric: 5.1668

Epoch 997: val_loss did not improve from 5.16590
196/196 - 83s - loss: 5.0622 - MinusLogProbMetric: 5.0622 - val_loss: 5.1668 - val_MinusLogProbMetric: 5.1668 - lr: 1.3021e-06 - 83s/epoch - 423ms/step
Epoch 998/1000
2023-09-20 12:02:02.727 
Epoch 998/1000 
	 loss: 5.0624, MinusLogProbMetric: 5.0624, val_loss: 5.1666, val_MinusLogProbMetric: 5.1666

Epoch 998: val_loss did not improve from 5.16590
196/196 - 83s - loss: 5.0624 - MinusLogProbMetric: 5.0624 - val_loss: 5.1666 - val_MinusLogProbMetric: 5.1666 - lr: 1.3021e-06 - 83s/epoch - 421ms/step
Epoch 999/1000
2023-09-20 12:03:24.359 
Epoch 999/1000 
	 loss: 5.0623, MinusLogProbMetric: 5.0623, val_loss: 5.1666, val_MinusLogProbMetric: 5.1666

Epoch 999: val_loss did not improve from 5.16590
196/196 - 82s - loss: 5.0623 - MinusLogProbMetric: 5.0623 - val_loss: 5.1666 - val_MinusLogProbMetric: 5.1666 - lr: 1.3021e-06 - 82s/epoch - 416ms/step
Epoch 1000/1000
2023-09-20 12:04:45.515 
Epoch 1000/1000 
	 loss: 5.0623, MinusLogProbMetric: 5.0623, val_loss: 5.1667, val_MinusLogProbMetric: 5.1667

Epoch 1000: val_loss did not improve from 5.16590
196/196 - 81s - loss: 5.0623 - MinusLogProbMetric: 5.0623 - val_loss: 5.1667 - val_MinusLogProbMetric: 5.1667 - lr: 1.3021e-06 - 81s/epoch - 414ms/step
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 56.68327830708586 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 23.19499310106039 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 16.010092871030793 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7faa84a69360> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 56.77605567290448 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 22.040533194085583 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 17.504908356117085 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fb1dc67a170> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 926.
Model trained in 84515.91 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/c_Main_CsplineN.py , Line : 468, Func.Name : prediction_function, Message : X_data_nf: tf.Tensor = DataInputs.dist_2_num[:nsamples_test] # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 197.14 s.
===========
Run 231/720 done in 85066.80 s.
===========

Directory ../../results/CsplineN_new/run_232/ already exists.
Skipping it.
===========
Run 232/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_233/ already exists.
Skipping it.
===========
Run 233/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_234/ already exists.
Skipping it.
===========
Run 234/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_235/ already exists.
Skipping it.
===========
Run 235/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_236/ already exists.
Skipping it.
===========
Run 236/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_237/ already exists.
Skipping it.
===========
Run 237/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_238/ already exists.
Skipping it.
===========
Run 238/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_239/ already exists.
Skipping it.
===========
Run 239/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_240/ already exists.
Skipping it.
===========
Run 240/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_241/ already exists.
Skipping it.
===========
Run 241/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_242/ already exists.
Skipping it.
===========
Run 242/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_243/ already exists.
Skipping it.
===========
Run 243/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_244/ already exists.
Skipping it.
===========
Run 244/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_245/ already exists.
Skipping it.
===========
Run 245/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_246/ already exists.
Skipping it.
===========
Run 246/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_247/ already exists.
Skipping it.
===========
Run 247/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_248/ already exists.
Skipping it.
===========
Run 248/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_249/ already exists.
Skipping it.
===========
Run 249/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_250/ already exists.
Skipping it.
===========
Run 250/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_251/ already exists.
Skipping it.
===========
Run 251/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_252/ already exists.
Skipping it.
===========
Run 252/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_253/ already exists.
Skipping it.
===========
Run 253/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_254/ already exists.
Skipping it.
===========
Run 254/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_255/ already exists.
Skipping it.
===========
Run 255/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_256/ already exists.
Skipping it.
===========
Run 256/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_257/ already exists.
Skipping it.
===========
Run 257/720 already exists. Skipping it.
===========

===========
Generating train data for run 258.
===========
Train data generated in 0.16 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_258/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 377}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_258/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.1831715 ,  3.2834203 ,  8.308094  , ...,  7.3133397 ,
         2.7002556 ,  1.7567806 ],
       [ 6.1308765 ,  7.147402  ,  6.0903115 , ...,  4.022617  ,
         2.6618268 ,  7.627545  ],
       [ 2.7429156 ,  3.6509063 ,  7.295548  , ...,  7.086021  ,
         2.8938296 ,  1.8224454 ],
       ...,
       [ 2.1098776 ,  4.1337423 ,  8.041495  , ...,  7.2043395 ,
         2.3724499 ,  1.8449893 ],
       [ 4.759076  ,  5.6016526 , -0.17659053, ...,  1.2483898 ,
         6.6213574 ,  1.391019  ],
       [ 4.6478305 ,  5.6608987 ,  0.05425403, ...,  1.0307544 ,
         6.027231  ,  1.3217621 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_258/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_258
self.data_kwargs: {'seed': 377}
self.x_data: [[5.416377   7.151266   6.5657053  ... 3.613302   2.6304417  8.037386  ]
 [4.297167   5.832213   0.12875912 ... 1.4317983  6.415448   1.3533646 ]
 [6.2353234  7.1795187  6.219724   ... 4.5891814  2.66546    7.551563  ]
 ...
 [1.8237456  4.102903   7.5608215  ... 7.136859   2.564185   1.5539532 ]
 [2.2305896  4.6568003  8.321339   ... 7.0577617  2.6189713  1.518045  ]
 [5.653481   7.1263475  6.929123   ... 4.292566   2.643216   7.404443  ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_196"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_197 (InputLayer)      [(None, 32)]              0         
                                                                 
 log_prob_layer_21 (LogProbL  (None,)                  1152560   
 ayer)                                                           
                                                                 
=================================================================
Total params: 1,152,560
Trainable params: 1,152,560
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_21/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_21'")
self.model: <keras.engine.functional.Functional object at 0x7faad0d5ff40>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fae4c65d660>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fae4c65d660>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fae5c5f9810>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7faeea8952a0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_258/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7faeea894a30>, <keras.callbacks.ModelCheckpoint object at 0x7faeea894700>, <keras.callbacks.EarlyStopping object at 0x7faeea894250>, <keras.callbacks.ReduceLROnPlateau object at 0x7faeea894190>, <keras.callbacks.TerminateOnNaN object at 0x7faeea895a50>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.1831715 ,  3.2834203 ,  8.308094  , ...,  7.3133397 ,
         2.7002556 ,  1.7567806 ],
       [ 6.1308765 ,  7.147402  ,  6.0903115 , ...,  4.022617  ,
         2.6618268 ,  7.627545  ],
       [ 2.7429156 ,  3.6509063 ,  7.295548  , ...,  7.086021  ,
         2.8938296 ,  1.8224454 ],
       ...,
       [ 2.1098776 ,  4.1337423 ,  8.041495  , ...,  7.2043395 ,
         2.3724499 ,  1.8449893 ],
       [ 4.759076  ,  5.6016526 , -0.17659053, ...,  1.2483898 ,
         6.6213574 ,  1.391019  ],
       [ 4.6478305 ,  5.6608987 ,  0.05425403, ...,  1.0307544 ,
         6.027231  ,  1.3217621 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_258/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 258/720 with hyperparameters:
timestamp = 2023-09-20 12:08:06.882735
ndims = 32
seed_train = 377
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 5
spline_knots = 8
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 1152560
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 5.416377    7.151266    6.5657053   5.44807     3.870332    6.1800294
  2.9008856   8.441634    9.391678    4.1002183   7.382605    5.3625755
  5.5868373   9.949682    0.82923275  1.9832962  -0.10069095  8.219267
  8.539603    9.221239    9.5321455   8.239499    4.945965    8.152974
 -0.16393006  6.303131    0.6036788   9.50227     6.1976576   3.613302
  2.6304417   8.037386  ]
Epoch 1/1000
2023-09-20 12:10:05.938 
Epoch 1/1000 
	 loss: 50.0104, MinusLogProbMetric: 50.0104, val_loss: 25.2372, val_MinusLogProbMetric: 25.2372

Epoch 1: val_loss improved from inf to 25.23717, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_258/weights/best_weights.h5
196/196 - 120s - loss: 50.0104 - MinusLogProbMetric: 50.0104 - val_loss: 25.2372 - val_MinusLogProbMetric: 25.2372 - lr: 0.0010 - 120s/epoch - 611ms/step
Epoch 2/1000
2023-09-20 12:10:43.412 
Epoch 2/1000 
	 loss: 23.5079, MinusLogProbMetric: 23.5079, val_loss: 22.6176, val_MinusLogProbMetric: 22.6176

Epoch 2: val_loss improved from 25.23717 to 22.61764, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_258/weights/best_weights.h5
196/196 - 37s - loss: 23.5079 - MinusLogProbMetric: 23.5079 - val_loss: 22.6176 - val_MinusLogProbMetric: 22.6176 - lr: 0.0010 - 37s/epoch - 190ms/step
Epoch 3/1000
2023-09-20 12:11:20.568 
Epoch 3/1000 
	 loss: 21.3639, MinusLogProbMetric: 21.3639, val_loss: 22.0056, val_MinusLogProbMetric: 22.0056

Epoch 3: val_loss improved from 22.61764 to 22.00559, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_258/weights/best_weights.h5
196/196 - 37s - loss: 21.3639 - MinusLogProbMetric: 21.3639 - val_loss: 22.0056 - val_MinusLogProbMetric: 22.0056 - lr: 0.0010 - 37s/epoch - 190ms/step
Epoch 4/1000
2023-09-20 12:11:57.682 
Epoch 4/1000 
	 loss: 20.4418, MinusLogProbMetric: 20.4418, val_loss: 20.0930, val_MinusLogProbMetric: 20.0930

Epoch 4: val_loss improved from 22.00559 to 20.09295, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_258/weights/best_weights.h5
196/196 - 37s - loss: 20.4418 - MinusLogProbMetric: 20.4418 - val_loss: 20.0930 - val_MinusLogProbMetric: 20.0930 - lr: 0.0010 - 37s/epoch - 189ms/step
Epoch 5/1000
2023-09-20 12:12:34.797 
Epoch 5/1000 
	 loss: 19.6325, MinusLogProbMetric: 19.6325, val_loss: 20.7440, val_MinusLogProbMetric: 20.7440

Epoch 5: val_loss did not improve from 20.09295
196/196 - 37s - loss: 19.6325 - MinusLogProbMetric: 19.6325 - val_loss: 20.7440 - val_MinusLogProbMetric: 20.7440 - lr: 0.0010 - 37s/epoch - 186ms/step
Epoch 6/1000
2023-09-20 12:13:11.278 
Epoch 6/1000 
	 loss: 19.4420, MinusLogProbMetric: 19.4420, val_loss: 18.8737, val_MinusLogProbMetric: 18.8737

Epoch 6: val_loss improved from 20.09295 to 18.87367, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_258/weights/best_weights.h5
196/196 - 37s - loss: 19.4420 - MinusLogProbMetric: 19.4420 - val_loss: 18.8737 - val_MinusLogProbMetric: 18.8737 - lr: 0.0010 - 37s/epoch - 189ms/step
Epoch 7/1000
2023-09-20 12:13:49.415 
Epoch 7/1000 
	 loss: 19.0551, MinusLogProbMetric: 19.0551, val_loss: 19.2233, val_MinusLogProbMetric: 19.2233

Epoch 7: val_loss did not improve from 18.87367
196/196 - 38s - loss: 19.0551 - MinusLogProbMetric: 19.0551 - val_loss: 19.2233 - val_MinusLogProbMetric: 19.2233 - lr: 0.0010 - 38s/epoch - 191ms/step
Epoch 8/1000
2023-09-20 12:14:26.709 
Epoch 8/1000 
	 loss: 18.7496, MinusLogProbMetric: 18.7496, val_loss: 21.8991, val_MinusLogProbMetric: 21.8991

Epoch 8: val_loss did not improve from 18.87367
196/196 - 37s - loss: 18.7496 - MinusLogProbMetric: 18.7496 - val_loss: 21.8991 - val_MinusLogProbMetric: 21.8991 - lr: 0.0010 - 37s/epoch - 190ms/step
Epoch 9/1000
2023-09-20 12:15:03.526 
Epoch 9/1000 
	 loss: 18.6721, MinusLogProbMetric: 18.6721, val_loss: 18.2656, val_MinusLogProbMetric: 18.2656

Epoch 9: val_loss improved from 18.87367 to 18.26559, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_258/weights/best_weights.h5
196/196 - 38s - loss: 18.6721 - MinusLogProbMetric: 18.6721 - val_loss: 18.2656 - val_MinusLogProbMetric: 18.2656 - lr: 0.0010 - 38s/epoch - 192ms/step
Epoch 10/1000
2023-09-20 12:15:40.804 
Epoch 10/1000 
	 loss: 18.4303, MinusLogProbMetric: 18.4303, val_loss: 18.2431, val_MinusLogProbMetric: 18.2431

Epoch 10: val_loss improved from 18.26559 to 18.24306, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_258/weights/best_weights.h5
196/196 - 37s - loss: 18.4303 - MinusLogProbMetric: 18.4303 - val_loss: 18.2431 - val_MinusLogProbMetric: 18.2431 - lr: 0.0010 - 37s/epoch - 189ms/step
Epoch 11/1000
2023-09-20 12:16:17.836 
Epoch 11/1000 
	 loss: 18.3643, MinusLogProbMetric: 18.3643, val_loss: 18.3833, val_MinusLogProbMetric: 18.3833

Epoch 11: val_loss did not improve from 18.24306
196/196 - 36s - loss: 18.3643 - MinusLogProbMetric: 18.3643 - val_loss: 18.3833 - val_MinusLogProbMetric: 18.3833 - lr: 0.0010 - 36s/epoch - 185ms/step
Epoch 12/1000
2023-09-20 12:16:54.402 
Epoch 12/1000 
	 loss: 18.2431, MinusLogProbMetric: 18.2431, val_loss: 18.3384, val_MinusLogProbMetric: 18.3384

Epoch 12: val_loss did not improve from 18.24306
196/196 - 37s - loss: 18.2431 - MinusLogProbMetric: 18.2431 - val_loss: 18.3384 - val_MinusLogProbMetric: 18.3384 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 13/1000
2023-09-20 12:17:31.470 
Epoch 13/1000 
	 loss: 18.2061, MinusLogProbMetric: 18.2061, val_loss: 18.2705, val_MinusLogProbMetric: 18.2705

Epoch 13: val_loss did not improve from 18.24306
196/196 - 37s - loss: 18.2061 - MinusLogProbMetric: 18.2061 - val_loss: 18.2705 - val_MinusLogProbMetric: 18.2705 - lr: 0.0010 - 37s/epoch - 189ms/step
Epoch 14/1000
2023-09-20 12:18:08.230 
Epoch 14/1000 
	 loss: 17.9710, MinusLogProbMetric: 17.9710, val_loss: 18.2867, val_MinusLogProbMetric: 18.2867

Epoch 14: val_loss did not improve from 18.24306
196/196 - 37s - loss: 17.9710 - MinusLogProbMetric: 17.9710 - val_loss: 18.2867 - val_MinusLogProbMetric: 18.2867 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 15/1000
2023-09-20 12:18:44.654 
Epoch 15/1000 
	 loss: 17.9938, MinusLogProbMetric: 17.9938, val_loss: 17.7380, val_MinusLogProbMetric: 17.7380

Epoch 15: val_loss improved from 18.24306 to 17.73799, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_258/weights/best_weights.h5
196/196 - 37s - loss: 17.9938 - MinusLogProbMetric: 17.9938 - val_loss: 17.7380 - val_MinusLogProbMetric: 17.7380 - lr: 0.0010 - 37s/epoch - 189ms/step
Epoch 16/1000
2023-09-20 12:19:22.195 
Epoch 16/1000 
	 loss: 17.9616, MinusLogProbMetric: 17.9616, val_loss: 17.8819, val_MinusLogProbMetric: 17.8819

Epoch 16: val_loss did not improve from 17.73799
196/196 - 37s - loss: 17.9616 - MinusLogProbMetric: 17.9616 - val_loss: 17.8819 - val_MinusLogProbMetric: 17.8819 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 17/1000
2023-09-20 12:19:59.126 
Epoch 17/1000 
	 loss: 17.8326, MinusLogProbMetric: 17.8326, val_loss: 17.9894, val_MinusLogProbMetric: 17.9894

Epoch 17: val_loss did not improve from 17.73799
196/196 - 37s - loss: 17.8326 - MinusLogProbMetric: 17.8326 - val_loss: 17.9894 - val_MinusLogProbMetric: 17.9894 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 18/1000
2023-09-20 12:20:35.747 
Epoch 18/1000 
	 loss: 17.7530, MinusLogProbMetric: 17.7530, val_loss: 18.3184, val_MinusLogProbMetric: 18.3184

Epoch 18: val_loss did not improve from 17.73799
196/196 - 37s - loss: 17.7530 - MinusLogProbMetric: 17.7530 - val_loss: 18.3184 - val_MinusLogProbMetric: 18.3184 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 19/1000
2023-09-20 12:21:12.329 
Epoch 19/1000 
	 loss: 17.7365, MinusLogProbMetric: 17.7365, val_loss: 17.6042, val_MinusLogProbMetric: 17.6042

Epoch 19: val_loss improved from 17.73799 to 17.60422, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_258/weights/best_weights.h5
196/196 - 37s - loss: 17.7365 - MinusLogProbMetric: 17.7365 - val_loss: 17.6042 - val_MinusLogProbMetric: 17.6042 - lr: 0.0010 - 37s/epoch - 190ms/step
Epoch 20/1000
2023-09-20 12:21:49.427 
Epoch 20/1000 
	 loss: 17.6881, MinusLogProbMetric: 17.6881, val_loss: 17.6057, val_MinusLogProbMetric: 17.6057

Epoch 20: val_loss did not improve from 17.60422
196/196 - 36s - loss: 17.6881 - MinusLogProbMetric: 17.6881 - val_loss: 17.6057 - val_MinusLogProbMetric: 17.6057 - lr: 0.0010 - 36s/epoch - 186ms/step
Epoch 21/1000
2023-09-20 12:22:26.189 
Epoch 21/1000 
	 loss: 17.6581, MinusLogProbMetric: 17.6581, val_loss: 17.6669, val_MinusLogProbMetric: 17.6669

Epoch 21: val_loss did not improve from 17.60422
196/196 - 37s - loss: 17.6581 - MinusLogProbMetric: 17.6581 - val_loss: 17.6669 - val_MinusLogProbMetric: 17.6669 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 22/1000
2023-09-20 12:23:02.743 
Epoch 22/1000 
	 loss: 17.6837, MinusLogProbMetric: 17.6837, val_loss: 18.8811, val_MinusLogProbMetric: 18.8811

Epoch 22: val_loss did not improve from 17.60422
196/196 - 37s - loss: 17.6837 - MinusLogProbMetric: 17.6837 - val_loss: 18.8811 - val_MinusLogProbMetric: 18.8811 - lr: 0.0010 - 37s/epoch - 186ms/step
Epoch 23/1000
2023-09-20 12:23:39.027 
Epoch 23/1000 
	 loss: 17.6202, MinusLogProbMetric: 17.6202, val_loss: 17.9870, val_MinusLogProbMetric: 17.9870

Epoch 23: val_loss did not improve from 17.60422
196/196 - 36s - loss: 17.6202 - MinusLogProbMetric: 17.6202 - val_loss: 17.9870 - val_MinusLogProbMetric: 17.9870 - lr: 0.0010 - 36s/epoch - 185ms/step
Epoch 24/1000
2023-09-20 12:24:15.692 
Epoch 24/1000 
	 loss: 17.5855, MinusLogProbMetric: 17.5855, val_loss: 17.5013, val_MinusLogProbMetric: 17.5013

Epoch 24: val_loss improved from 17.60422 to 17.50134, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_258/weights/best_weights.h5
196/196 - 37s - loss: 17.5855 - MinusLogProbMetric: 17.5855 - val_loss: 17.5013 - val_MinusLogProbMetric: 17.5013 - lr: 0.0010 - 37s/epoch - 191ms/step
Epoch 25/1000
2023-09-20 12:24:52.859 
Epoch 25/1000 
	 loss: 17.4949, MinusLogProbMetric: 17.4949, val_loss: 17.4160, val_MinusLogProbMetric: 17.4160

Epoch 25: val_loss improved from 17.50134 to 17.41596, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_258/weights/best_weights.h5
196/196 - 37s - loss: 17.4949 - MinusLogProbMetric: 17.4949 - val_loss: 17.4160 - val_MinusLogProbMetric: 17.4160 - lr: 0.0010 - 37s/epoch - 190ms/step
Epoch 26/1000
2023-09-20 12:25:30.590 
Epoch 26/1000 
	 loss: 17.4397, MinusLogProbMetric: 17.4397, val_loss: 17.3422, val_MinusLogProbMetric: 17.3422

Epoch 26: val_loss improved from 17.41596 to 17.34222, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_258/weights/best_weights.h5
196/196 - 38s - loss: 17.4397 - MinusLogProbMetric: 17.4397 - val_loss: 17.3422 - val_MinusLogProbMetric: 17.3422 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 27/1000
2023-09-20 12:26:07.846 
Epoch 27/1000 
	 loss: 17.4148, MinusLogProbMetric: 17.4148, val_loss: 17.8690, val_MinusLogProbMetric: 17.8690

Epoch 27: val_loss did not improve from 17.34222
196/196 - 36s - loss: 17.4148 - MinusLogProbMetric: 17.4148 - val_loss: 17.8690 - val_MinusLogProbMetric: 17.8690 - lr: 0.0010 - 36s/epoch - 186ms/step
Epoch 28/1000
2023-09-20 12:26:44.340 
Epoch 28/1000 
	 loss: 17.4099, MinusLogProbMetric: 17.4099, val_loss: 17.2972, val_MinusLogProbMetric: 17.2972

Epoch 28: val_loss improved from 17.34222 to 17.29718, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_258/weights/best_weights.h5
196/196 - 37s - loss: 17.4099 - MinusLogProbMetric: 17.4099 - val_loss: 17.2972 - val_MinusLogProbMetric: 17.2972 - lr: 0.0010 - 37s/epoch - 190ms/step
Epoch 29/1000
2023-09-20 12:27:21.629 
Epoch 29/1000 
	 loss: 17.3802, MinusLogProbMetric: 17.3802, val_loss: 17.4501, val_MinusLogProbMetric: 17.4501

Epoch 29: val_loss did not improve from 17.29718
196/196 - 37s - loss: 17.3802 - MinusLogProbMetric: 17.3802 - val_loss: 17.4501 - val_MinusLogProbMetric: 17.4501 - lr: 0.0010 - 37s/epoch - 186ms/step
Epoch 30/1000
2023-09-20 12:27:58.570 
Epoch 30/1000 
	 loss: 17.3443, MinusLogProbMetric: 17.3443, val_loss: 17.4226, val_MinusLogProbMetric: 17.4226

Epoch 30: val_loss did not improve from 17.29718
196/196 - 37s - loss: 17.3443 - MinusLogProbMetric: 17.3443 - val_loss: 17.4226 - val_MinusLogProbMetric: 17.4226 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 31/1000
2023-09-20 12:28:34.991 
Epoch 31/1000 
	 loss: 17.3037, MinusLogProbMetric: 17.3037, val_loss: 17.4669, val_MinusLogProbMetric: 17.4669

Epoch 31: val_loss did not improve from 17.29718
196/196 - 36s - loss: 17.3037 - MinusLogProbMetric: 17.3037 - val_loss: 17.4669 - val_MinusLogProbMetric: 17.4669 - lr: 0.0010 - 36s/epoch - 186ms/step
Epoch 32/1000
2023-09-20 12:29:11.797 
Epoch 32/1000 
	 loss: 17.2649, MinusLogProbMetric: 17.2649, val_loss: 18.3473, val_MinusLogProbMetric: 18.3473

Epoch 32: val_loss did not improve from 17.29718
196/196 - 37s - loss: 17.2649 - MinusLogProbMetric: 17.2649 - val_loss: 18.3473 - val_MinusLogProbMetric: 18.3473 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 33/1000
2023-09-20 12:29:48.572 
Epoch 33/1000 
	 loss: 17.2788, MinusLogProbMetric: 17.2788, val_loss: 17.8539, val_MinusLogProbMetric: 17.8539

Epoch 33: val_loss did not improve from 17.29718
196/196 - 37s - loss: 17.2788 - MinusLogProbMetric: 17.2788 - val_loss: 17.8539 - val_MinusLogProbMetric: 17.8539 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 34/1000
2023-09-20 12:30:25.121 
Epoch 34/1000 
	 loss: 17.2413, MinusLogProbMetric: 17.2413, val_loss: 17.7837, val_MinusLogProbMetric: 17.7837

Epoch 34: val_loss did not improve from 17.29718
196/196 - 37s - loss: 17.2413 - MinusLogProbMetric: 17.2413 - val_loss: 17.7837 - val_MinusLogProbMetric: 17.7837 - lr: 0.0010 - 37s/epoch - 186ms/step
Epoch 35/1000
2023-09-20 12:31:01.875 
Epoch 35/1000 
	 loss: 17.1623, MinusLogProbMetric: 17.1623, val_loss: 17.4910, val_MinusLogProbMetric: 17.4910

Epoch 35: val_loss did not improve from 17.29718
196/196 - 37s - loss: 17.1623 - MinusLogProbMetric: 17.1623 - val_loss: 17.4910 - val_MinusLogProbMetric: 17.4910 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 36/1000
2023-09-20 12:31:38.454 
Epoch 36/1000 
	 loss: 17.1967, MinusLogProbMetric: 17.1967, val_loss: 17.7487, val_MinusLogProbMetric: 17.7487

Epoch 36: val_loss did not improve from 17.29718
196/196 - 37s - loss: 17.1967 - MinusLogProbMetric: 17.1967 - val_loss: 17.7487 - val_MinusLogProbMetric: 17.7487 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 37/1000
2023-09-20 12:32:15.086 
Epoch 37/1000 
	 loss: 17.1543, MinusLogProbMetric: 17.1543, val_loss: 17.5366, val_MinusLogProbMetric: 17.5366

Epoch 37: val_loss did not improve from 17.29718
196/196 - 37s - loss: 17.1543 - MinusLogProbMetric: 17.1543 - val_loss: 17.5366 - val_MinusLogProbMetric: 17.5366 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 38/1000
2023-09-20 12:32:51.389 
Epoch 38/1000 
	 loss: 17.1174, MinusLogProbMetric: 17.1174, val_loss: 17.6234, val_MinusLogProbMetric: 17.6234

Epoch 38: val_loss did not improve from 17.29718
196/196 - 36s - loss: 17.1174 - MinusLogProbMetric: 17.1174 - val_loss: 17.6234 - val_MinusLogProbMetric: 17.6234 - lr: 0.0010 - 36s/epoch - 185ms/step
Epoch 39/1000
2023-09-20 12:33:28.049 
Epoch 39/1000 
	 loss: 17.1197, MinusLogProbMetric: 17.1197, val_loss: 17.4281, val_MinusLogProbMetric: 17.4281

Epoch 39: val_loss did not improve from 17.29718
196/196 - 37s - loss: 17.1197 - MinusLogProbMetric: 17.1197 - val_loss: 17.4281 - val_MinusLogProbMetric: 17.4281 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 40/1000
2023-09-20 12:34:04.573 
Epoch 40/1000 
	 loss: 17.0327, MinusLogProbMetric: 17.0327, val_loss: 17.2730, val_MinusLogProbMetric: 17.2730

Epoch 40: val_loss improved from 17.29718 to 17.27303, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_258/weights/best_weights.h5
196/196 - 37s - loss: 17.0327 - MinusLogProbMetric: 17.0327 - val_loss: 17.2730 - val_MinusLogProbMetric: 17.2730 - lr: 0.0010 - 37s/epoch - 190ms/step
Epoch 41/1000
2023-09-20 12:34:42.168 
Epoch 41/1000 
	 loss: 17.0292, MinusLogProbMetric: 17.0292, val_loss: 19.9171, val_MinusLogProbMetric: 19.9171

Epoch 41: val_loss did not improve from 17.27303
196/196 - 37s - loss: 17.0292 - MinusLogProbMetric: 17.0292 - val_loss: 19.9171 - val_MinusLogProbMetric: 19.9171 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 42/1000
2023-09-20 12:35:19.117 
Epoch 42/1000 
	 loss: 17.1346, MinusLogProbMetric: 17.1346, val_loss: 17.4477, val_MinusLogProbMetric: 17.4477

Epoch 42: val_loss did not improve from 17.27303
196/196 - 37s - loss: 17.1346 - MinusLogProbMetric: 17.1346 - val_loss: 17.4477 - val_MinusLogProbMetric: 17.4477 - lr: 0.0010 - 37s/epoch - 189ms/step
Epoch 43/1000
2023-09-20 12:35:56.105 
Epoch 43/1000 
	 loss: 17.0568, MinusLogProbMetric: 17.0568, val_loss: 17.5863, val_MinusLogProbMetric: 17.5863

Epoch 43: val_loss did not improve from 17.27303
196/196 - 37s - loss: 17.0568 - MinusLogProbMetric: 17.0568 - val_loss: 17.5863 - val_MinusLogProbMetric: 17.5863 - lr: 0.0010 - 37s/epoch - 189ms/step
Epoch 44/1000
2023-09-20 12:36:32.624 
Epoch 44/1000 
	 loss: 16.9992, MinusLogProbMetric: 16.9992, val_loss: 18.1393, val_MinusLogProbMetric: 18.1393

Epoch 44: val_loss did not improve from 17.27303
196/196 - 37s - loss: 16.9992 - MinusLogProbMetric: 16.9992 - val_loss: 18.1393 - val_MinusLogProbMetric: 18.1393 - lr: 0.0010 - 37s/epoch - 186ms/step
Epoch 45/1000
2023-09-20 12:37:09.294 
Epoch 45/1000 
	 loss: 17.0497, MinusLogProbMetric: 17.0497, val_loss: 17.2785, val_MinusLogProbMetric: 17.2785

Epoch 45: val_loss did not improve from 17.27303
196/196 - 37s - loss: 17.0497 - MinusLogProbMetric: 17.0497 - val_loss: 17.2785 - val_MinusLogProbMetric: 17.2785 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 46/1000
2023-09-20 12:37:45.842 
Epoch 46/1000 
	 loss: 16.9607, MinusLogProbMetric: 16.9607, val_loss: 17.4139, val_MinusLogProbMetric: 17.4139

Epoch 46: val_loss did not improve from 17.27303
196/196 - 37s - loss: 16.9607 - MinusLogProbMetric: 16.9607 - val_loss: 17.4139 - val_MinusLogProbMetric: 17.4139 - lr: 0.0010 - 37s/epoch - 186ms/step
Epoch 47/1000
2023-09-20 12:38:22.792 
Epoch 47/1000 
	 loss: 16.9133, MinusLogProbMetric: 16.9133, val_loss: 17.1971, val_MinusLogProbMetric: 17.1971

Epoch 47: val_loss improved from 17.27303 to 17.19705, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_258/weights/best_weights.h5
196/196 - 38s - loss: 16.9133 - MinusLogProbMetric: 16.9133 - val_loss: 17.1971 - val_MinusLogProbMetric: 17.1971 - lr: 0.0010 - 38s/epoch - 192ms/step
Epoch 48/1000
2023-09-20 12:38:59.901 
Epoch 48/1000 
	 loss: 16.9270, MinusLogProbMetric: 16.9270, val_loss: 17.7543, val_MinusLogProbMetric: 17.7543

Epoch 48: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.9270 - MinusLogProbMetric: 16.9270 - val_loss: 17.7543 - val_MinusLogProbMetric: 17.7543 - lr: 0.0010 - 36s/epoch - 186ms/step
Epoch 49/1000
2023-09-20 12:39:36.309 
Epoch 49/1000 
	 loss: 16.9022, MinusLogProbMetric: 16.9022, val_loss: 17.2357, val_MinusLogProbMetric: 17.2357

Epoch 49: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.9022 - MinusLogProbMetric: 16.9022 - val_loss: 17.2357 - val_MinusLogProbMetric: 17.2357 - lr: 0.0010 - 36s/epoch - 186ms/step
Epoch 50/1000
2023-09-20 12:40:12.639 
Epoch 50/1000 
	 loss: 16.8983, MinusLogProbMetric: 16.8983, val_loss: 17.3251, val_MinusLogProbMetric: 17.3251

Epoch 50: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.8983 - MinusLogProbMetric: 16.8983 - val_loss: 17.3251 - val_MinusLogProbMetric: 17.3251 - lr: 0.0010 - 36s/epoch - 185ms/step
Epoch 51/1000
2023-09-20 12:40:49.185 
Epoch 51/1000 
	 loss: 16.8834, MinusLogProbMetric: 16.8834, val_loss: 17.7491, val_MinusLogProbMetric: 17.7491

Epoch 51: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.8834 - MinusLogProbMetric: 16.8834 - val_loss: 17.7491 - val_MinusLogProbMetric: 17.7491 - lr: 0.0010 - 37s/epoch - 186ms/step
Epoch 52/1000
2023-09-20 12:41:25.898 
Epoch 52/1000 
	 loss: 16.8769, MinusLogProbMetric: 16.8769, val_loss: 17.2813, val_MinusLogProbMetric: 17.2813

Epoch 52: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.8769 - MinusLogProbMetric: 16.8769 - val_loss: 17.2813 - val_MinusLogProbMetric: 17.2813 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 53/1000
2023-09-20 12:42:02.603 
Epoch 53/1000 
	 loss: 16.8104, MinusLogProbMetric: 16.8104, val_loss: 17.4207, val_MinusLogProbMetric: 17.4207

Epoch 53: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.8104 - MinusLogProbMetric: 16.8104 - val_loss: 17.4207 - val_MinusLogProbMetric: 17.4207 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 54/1000
2023-09-20 12:42:39.131 
Epoch 54/1000 
	 loss: 16.8258, MinusLogProbMetric: 16.8258, val_loss: 17.2661, val_MinusLogProbMetric: 17.2661

Epoch 54: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.8258 - MinusLogProbMetric: 16.8258 - val_loss: 17.2661 - val_MinusLogProbMetric: 17.2661 - lr: 0.0010 - 37s/epoch - 186ms/step
Epoch 55/1000
2023-09-20 12:43:15.743 
Epoch 55/1000 
	 loss: 16.8004, MinusLogProbMetric: 16.8004, val_loss: 17.3167, val_MinusLogProbMetric: 17.3167

Epoch 55: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.8004 - MinusLogProbMetric: 16.8004 - val_loss: 17.3167 - val_MinusLogProbMetric: 17.3167 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 56/1000
2023-09-20 12:43:52.349 
Epoch 56/1000 
	 loss: 16.8428, MinusLogProbMetric: 16.8428, val_loss: 17.4319, val_MinusLogProbMetric: 17.4319

Epoch 56: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.8428 - MinusLogProbMetric: 16.8428 - val_loss: 17.4319 - val_MinusLogProbMetric: 17.4319 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 57/1000
2023-09-20 12:44:29.085 
Epoch 57/1000 
	 loss: 16.8049, MinusLogProbMetric: 16.8049, val_loss: 17.2440, val_MinusLogProbMetric: 17.2440

Epoch 57: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.8049 - MinusLogProbMetric: 16.8049 - val_loss: 17.2440 - val_MinusLogProbMetric: 17.2440 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 58/1000
2023-09-20 12:45:05.445 
Epoch 58/1000 
	 loss: 16.7508, MinusLogProbMetric: 16.7508, val_loss: 17.6716, val_MinusLogProbMetric: 17.6716

Epoch 58: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.7508 - MinusLogProbMetric: 16.7508 - val_loss: 17.6716 - val_MinusLogProbMetric: 17.6716 - lr: 0.0010 - 36s/epoch - 185ms/step
Epoch 59/1000
2023-09-20 12:45:42.229 
Epoch 59/1000 
	 loss: 16.7594, MinusLogProbMetric: 16.7594, val_loss: 17.5014, val_MinusLogProbMetric: 17.5014

Epoch 59: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.7594 - MinusLogProbMetric: 16.7594 - val_loss: 17.5014 - val_MinusLogProbMetric: 17.5014 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 60/1000
2023-09-20 12:46:18.673 
Epoch 60/1000 
	 loss: 16.7764, MinusLogProbMetric: 16.7764, val_loss: 17.2531, val_MinusLogProbMetric: 17.2531

Epoch 60: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.7764 - MinusLogProbMetric: 16.7764 - val_loss: 17.2531 - val_MinusLogProbMetric: 17.2531 - lr: 0.0010 - 36s/epoch - 186ms/step
Epoch 61/1000
2023-09-20 12:46:55.470 
Epoch 61/1000 
	 loss: 16.7230, MinusLogProbMetric: 16.7230, val_loss: 17.3674, val_MinusLogProbMetric: 17.3674

Epoch 61: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.7230 - MinusLogProbMetric: 16.7230 - val_loss: 17.3674 - val_MinusLogProbMetric: 17.3674 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 62/1000
2023-09-20 12:47:31.626 
Epoch 62/1000 
	 loss: 16.7301, MinusLogProbMetric: 16.7301, val_loss: 17.3768, val_MinusLogProbMetric: 17.3768

Epoch 62: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.7301 - MinusLogProbMetric: 16.7301 - val_loss: 17.3768 - val_MinusLogProbMetric: 17.3768 - lr: 0.0010 - 36s/epoch - 184ms/step
Epoch 63/1000
2023-09-20 12:48:08.426 
Epoch 63/1000 
	 loss: 16.7102, MinusLogProbMetric: 16.7102, val_loss: 17.3376, val_MinusLogProbMetric: 17.3376

Epoch 63: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.7102 - MinusLogProbMetric: 16.7102 - val_loss: 17.3376 - val_MinusLogProbMetric: 17.3376 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 64/1000
2023-09-20 12:48:44.974 
Epoch 64/1000 
	 loss: 16.7313, MinusLogProbMetric: 16.7313, val_loss: 17.2274, val_MinusLogProbMetric: 17.2274

Epoch 64: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.7313 - MinusLogProbMetric: 16.7313 - val_loss: 17.2274 - val_MinusLogProbMetric: 17.2274 - lr: 0.0010 - 37s/epoch - 186ms/step
Epoch 65/1000
2023-09-20 12:49:21.644 
Epoch 65/1000 
	 loss: 16.6640, MinusLogProbMetric: 16.6640, val_loss: 17.3537, val_MinusLogProbMetric: 17.3537

Epoch 65: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.6640 - MinusLogProbMetric: 16.6640 - val_loss: 17.3537 - val_MinusLogProbMetric: 17.3537 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 66/1000
2023-09-20 12:49:58.301 
Epoch 66/1000 
	 loss: 16.6789, MinusLogProbMetric: 16.6789, val_loss: 17.3401, val_MinusLogProbMetric: 17.3401

Epoch 66: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.6789 - MinusLogProbMetric: 16.6789 - val_loss: 17.3401 - val_MinusLogProbMetric: 17.3401 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 67/1000
2023-09-20 12:50:35.005 
Epoch 67/1000 
	 loss: 16.6609, MinusLogProbMetric: 16.6609, val_loss: 17.4518, val_MinusLogProbMetric: 17.4518

Epoch 67: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.6609 - MinusLogProbMetric: 16.6609 - val_loss: 17.4518 - val_MinusLogProbMetric: 17.4518 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 68/1000
2023-09-20 12:51:11.724 
Epoch 68/1000 
	 loss: 16.6988, MinusLogProbMetric: 16.6988, val_loss: 17.3255, val_MinusLogProbMetric: 17.3255

Epoch 68: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.6988 - MinusLogProbMetric: 16.6988 - val_loss: 17.3255 - val_MinusLogProbMetric: 17.3255 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 69/1000
2023-09-20 12:51:48.301 
Epoch 69/1000 
	 loss: 16.6583, MinusLogProbMetric: 16.6583, val_loss: 17.2543, val_MinusLogProbMetric: 17.2543

Epoch 69: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.6583 - MinusLogProbMetric: 16.6583 - val_loss: 17.2543 - val_MinusLogProbMetric: 17.2543 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 70/1000
2023-09-20 12:52:25.079 
Epoch 70/1000 
	 loss: 16.6237, MinusLogProbMetric: 16.6237, val_loss: 17.3581, val_MinusLogProbMetric: 17.3581

Epoch 70: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.6237 - MinusLogProbMetric: 16.6237 - val_loss: 17.3581 - val_MinusLogProbMetric: 17.3581 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 71/1000
2023-09-20 12:53:01.977 
Epoch 71/1000 
	 loss: 16.6103, MinusLogProbMetric: 16.6103, val_loss: 17.2267, val_MinusLogProbMetric: 17.2267

Epoch 71: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.6103 - MinusLogProbMetric: 16.6103 - val_loss: 17.2267 - val_MinusLogProbMetric: 17.2267 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 72/1000
2023-09-20 12:53:38.263 
Epoch 72/1000 
	 loss: 16.5983, MinusLogProbMetric: 16.5983, val_loss: 17.8321, val_MinusLogProbMetric: 17.8321

Epoch 72: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.5983 - MinusLogProbMetric: 16.5983 - val_loss: 17.8321 - val_MinusLogProbMetric: 17.8321 - lr: 0.0010 - 36s/epoch - 185ms/step
Epoch 73/1000
2023-09-20 12:54:15.045 
Epoch 73/1000 
	 loss: 16.5932, MinusLogProbMetric: 16.5932, val_loss: 17.2530, val_MinusLogProbMetric: 17.2530

Epoch 73: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.5932 - MinusLogProbMetric: 16.5932 - val_loss: 17.2530 - val_MinusLogProbMetric: 17.2530 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 74/1000
2023-09-20 12:54:51.522 
Epoch 74/1000 
	 loss: 16.6109, MinusLogProbMetric: 16.6109, val_loss: 17.5387, val_MinusLogProbMetric: 17.5387

Epoch 74: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.6109 - MinusLogProbMetric: 16.6109 - val_loss: 17.5387 - val_MinusLogProbMetric: 17.5387 - lr: 0.0010 - 36s/epoch - 186ms/step
Epoch 75/1000
2023-09-20 12:55:28.060 
Epoch 75/1000 
	 loss: 16.5613, MinusLogProbMetric: 16.5613, val_loss: 17.2921, val_MinusLogProbMetric: 17.2921

Epoch 75: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.5613 - MinusLogProbMetric: 16.5613 - val_loss: 17.2921 - val_MinusLogProbMetric: 17.2921 - lr: 0.0010 - 37s/epoch - 186ms/step
Epoch 76/1000
2023-09-20 12:56:04.576 
Epoch 76/1000 
	 loss: 16.5558, MinusLogProbMetric: 16.5558, val_loss: 17.4179, val_MinusLogProbMetric: 17.4179

Epoch 76: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.5558 - MinusLogProbMetric: 16.5558 - val_loss: 17.4179 - val_MinusLogProbMetric: 17.4179 - lr: 0.0010 - 37s/epoch - 186ms/step
Epoch 77/1000
2023-09-20 12:56:41.129 
Epoch 77/1000 
	 loss: 16.5316, MinusLogProbMetric: 16.5316, val_loss: 17.3292, val_MinusLogProbMetric: 17.3292

Epoch 77: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.5316 - MinusLogProbMetric: 16.5316 - val_loss: 17.3292 - val_MinusLogProbMetric: 17.3292 - lr: 0.0010 - 37s/epoch - 186ms/step
Epoch 78/1000
2023-09-20 12:57:17.478 
Epoch 78/1000 
	 loss: 16.5238, MinusLogProbMetric: 16.5238, val_loss: 17.5778, val_MinusLogProbMetric: 17.5778

Epoch 78: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.5238 - MinusLogProbMetric: 16.5238 - val_loss: 17.5778 - val_MinusLogProbMetric: 17.5778 - lr: 0.0010 - 36s/epoch - 185ms/step
Epoch 79/1000
2023-09-20 12:57:54.052 
Epoch 79/1000 
	 loss: 16.5272, MinusLogProbMetric: 16.5272, val_loss: 17.4731, val_MinusLogProbMetric: 17.4731

Epoch 79: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.5272 - MinusLogProbMetric: 16.5272 - val_loss: 17.4731 - val_MinusLogProbMetric: 17.4731 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 80/1000
2023-09-20 12:58:30.279 
Epoch 80/1000 
	 loss: 16.5537, MinusLogProbMetric: 16.5537, val_loss: 17.7812, val_MinusLogProbMetric: 17.7812

Epoch 80: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.5537 - MinusLogProbMetric: 16.5537 - val_loss: 17.7812 - val_MinusLogProbMetric: 17.7812 - lr: 0.0010 - 36s/epoch - 185ms/step
Epoch 81/1000
2023-09-20 12:59:06.697 
Epoch 81/1000 
	 loss: 16.4953, MinusLogProbMetric: 16.4953, val_loss: 17.2939, val_MinusLogProbMetric: 17.2939

Epoch 81: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.4953 - MinusLogProbMetric: 16.4953 - val_loss: 17.2939 - val_MinusLogProbMetric: 17.2939 - lr: 0.0010 - 36s/epoch - 186ms/step
Epoch 82/1000
2023-09-20 12:59:43.121 
Epoch 82/1000 
	 loss: 16.4485, MinusLogProbMetric: 16.4485, val_loss: 17.3806, val_MinusLogProbMetric: 17.3806

Epoch 82: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.4485 - MinusLogProbMetric: 16.4485 - val_loss: 17.3806 - val_MinusLogProbMetric: 17.3806 - lr: 0.0010 - 36s/epoch - 186ms/step
Epoch 83/1000
2023-09-20 13:00:19.775 
Epoch 83/1000 
	 loss: 16.5012, MinusLogProbMetric: 16.5012, val_loss: 17.2619, val_MinusLogProbMetric: 17.2619

Epoch 83: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.5012 - MinusLogProbMetric: 16.5012 - val_loss: 17.2619 - val_MinusLogProbMetric: 17.2619 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 84/1000
2023-09-20 13:00:56.350 
Epoch 84/1000 
	 loss: 16.4738, MinusLogProbMetric: 16.4738, val_loss: 17.3935, val_MinusLogProbMetric: 17.3935

Epoch 84: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.4738 - MinusLogProbMetric: 16.4738 - val_loss: 17.3935 - val_MinusLogProbMetric: 17.3935 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 85/1000
2023-09-20 13:01:32.928 
Epoch 85/1000 
	 loss: 16.4324, MinusLogProbMetric: 16.4324, val_loss: 17.6584, val_MinusLogProbMetric: 17.6584

Epoch 85: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.4324 - MinusLogProbMetric: 16.4324 - val_loss: 17.6584 - val_MinusLogProbMetric: 17.6584 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 86/1000
2023-09-20 13:02:09.670 
Epoch 86/1000 
	 loss: 16.4567, MinusLogProbMetric: 16.4567, val_loss: 17.4812, val_MinusLogProbMetric: 17.4812

Epoch 86: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.4567 - MinusLogProbMetric: 16.4567 - val_loss: 17.4812 - val_MinusLogProbMetric: 17.4812 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 87/1000
2023-09-20 13:02:45.916 
Epoch 87/1000 
	 loss: 16.4265, MinusLogProbMetric: 16.4265, val_loss: 17.5484, val_MinusLogProbMetric: 17.5484

Epoch 87: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.4265 - MinusLogProbMetric: 16.4265 - val_loss: 17.5484 - val_MinusLogProbMetric: 17.5484 - lr: 0.0010 - 36s/epoch - 185ms/step
Epoch 88/1000
2023-09-20 13:03:22.801 
Epoch 88/1000 
	 loss: 16.4098, MinusLogProbMetric: 16.4098, val_loss: 17.4817, val_MinusLogProbMetric: 17.4817

Epoch 88: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.4098 - MinusLogProbMetric: 16.4098 - val_loss: 17.4817 - val_MinusLogProbMetric: 17.4817 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 89/1000
2023-09-20 13:03:59.306 
Epoch 89/1000 
	 loss: 16.3925, MinusLogProbMetric: 16.3925, val_loss: 17.3580, val_MinusLogProbMetric: 17.3580

Epoch 89: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.3925 - MinusLogProbMetric: 16.3925 - val_loss: 17.3580 - val_MinusLogProbMetric: 17.3580 - lr: 0.0010 - 37s/epoch - 186ms/step
Epoch 90/1000
2023-09-20 13:04:35.844 
Epoch 90/1000 
	 loss: 16.4403, MinusLogProbMetric: 16.4403, val_loss: 17.3754, val_MinusLogProbMetric: 17.3754

Epoch 90: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.4403 - MinusLogProbMetric: 16.4403 - val_loss: 17.3754 - val_MinusLogProbMetric: 17.3754 - lr: 0.0010 - 37s/epoch - 186ms/step
Epoch 91/1000
2023-09-20 13:05:12.455 
Epoch 91/1000 
	 loss: 16.4351, MinusLogProbMetric: 16.4351, val_loss: 17.4540, val_MinusLogProbMetric: 17.4540

Epoch 91: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.4351 - MinusLogProbMetric: 16.4351 - val_loss: 17.4540 - val_MinusLogProbMetric: 17.4540 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 92/1000
2023-09-20 13:05:48.837 
Epoch 92/1000 
	 loss: 16.3349, MinusLogProbMetric: 16.3349, val_loss: 17.7381, val_MinusLogProbMetric: 17.7381

Epoch 92: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.3349 - MinusLogProbMetric: 16.3349 - val_loss: 17.7381 - val_MinusLogProbMetric: 17.7381 - lr: 0.0010 - 36s/epoch - 186ms/step
Epoch 93/1000
2023-09-20 13:06:25.419 
Epoch 93/1000 
	 loss: 16.3716, MinusLogProbMetric: 16.3716, val_loss: 17.2938, val_MinusLogProbMetric: 17.2938

Epoch 93: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.3716 - MinusLogProbMetric: 16.3716 - val_loss: 17.2938 - val_MinusLogProbMetric: 17.2938 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 94/1000
2023-09-20 13:07:01.799 
Epoch 94/1000 
	 loss: 16.3674, MinusLogProbMetric: 16.3674, val_loss: 17.5582, val_MinusLogProbMetric: 17.5582

Epoch 94: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.3674 - MinusLogProbMetric: 16.3674 - val_loss: 17.5582 - val_MinusLogProbMetric: 17.5582 - lr: 0.0010 - 36s/epoch - 186ms/step
Epoch 95/1000
2023-09-20 13:07:38.587 
Epoch 95/1000 
	 loss: 16.3555, MinusLogProbMetric: 16.3555, val_loss: 17.3474, val_MinusLogProbMetric: 17.3474

Epoch 95: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.3555 - MinusLogProbMetric: 16.3555 - val_loss: 17.3474 - val_MinusLogProbMetric: 17.3474 - lr: 0.0010 - 37s/epoch - 188ms/step
Epoch 96/1000
2023-09-20 13:08:15.135 
Epoch 96/1000 
	 loss: 16.3602, MinusLogProbMetric: 16.3602, val_loss: 17.4760, val_MinusLogProbMetric: 17.4760

Epoch 96: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.3602 - MinusLogProbMetric: 16.3602 - val_loss: 17.4760 - val_MinusLogProbMetric: 17.4760 - lr: 0.0010 - 37s/epoch - 186ms/step
Epoch 97/1000
2023-09-20 13:08:51.758 
Epoch 97/1000 
	 loss: 16.3017, MinusLogProbMetric: 16.3017, val_loss: 17.3834, val_MinusLogProbMetric: 17.3834

Epoch 97: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.3017 - MinusLogProbMetric: 16.3017 - val_loss: 17.3834 - val_MinusLogProbMetric: 17.3834 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 98/1000
2023-09-20 13:09:28.399 
Epoch 98/1000 
	 loss: 16.0801, MinusLogProbMetric: 16.0801, val_loss: 17.3012, val_MinusLogProbMetric: 17.3012

Epoch 98: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.0801 - MinusLogProbMetric: 16.0801 - val_loss: 17.3012 - val_MinusLogProbMetric: 17.3012 - lr: 5.0000e-04 - 37s/epoch - 187ms/step
Epoch 99/1000
2023-09-20 13:10:04.834 
Epoch 99/1000 
	 loss: 16.0438, MinusLogProbMetric: 16.0438, val_loss: 17.3462, val_MinusLogProbMetric: 17.3462

Epoch 99: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.0438 - MinusLogProbMetric: 16.0438 - val_loss: 17.3462 - val_MinusLogProbMetric: 17.3462 - lr: 5.0000e-04 - 36s/epoch - 186ms/step
Epoch 100/1000
2023-09-20 13:10:41.308 
Epoch 100/1000 
	 loss: 16.0279, MinusLogProbMetric: 16.0279, val_loss: 17.4802, val_MinusLogProbMetric: 17.4802

Epoch 100: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.0279 - MinusLogProbMetric: 16.0279 - val_loss: 17.4802 - val_MinusLogProbMetric: 17.4802 - lr: 5.0000e-04 - 36s/epoch - 186ms/step
Epoch 101/1000
2023-09-20 13:11:17.484 
Epoch 101/1000 
	 loss: 16.0300, MinusLogProbMetric: 16.0300, val_loss: 17.3173, val_MinusLogProbMetric: 17.3173

Epoch 101: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.0300 - MinusLogProbMetric: 16.0300 - val_loss: 17.3173 - val_MinusLogProbMetric: 17.3173 - lr: 5.0000e-04 - 36s/epoch - 185ms/step
Epoch 102/1000
2023-09-20 13:11:53.926 
Epoch 102/1000 
	 loss: 16.0275, MinusLogProbMetric: 16.0275, val_loss: 17.3872, val_MinusLogProbMetric: 17.3872

Epoch 102: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.0275 - MinusLogProbMetric: 16.0275 - val_loss: 17.3872 - val_MinusLogProbMetric: 17.3872 - lr: 5.0000e-04 - 36s/epoch - 186ms/step
Epoch 103/1000
2023-09-20 13:12:30.384 
Epoch 103/1000 
	 loss: 16.0274, MinusLogProbMetric: 16.0274, val_loss: 17.4232, val_MinusLogProbMetric: 17.4232

Epoch 103: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.0274 - MinusLogProbMetric: 16.0274 - val_loss: 17.4232 - val_MinusLogProbMetric: 17.4232 - lr: 5.0000e-04 - 36s/epoch - 186ms/step
Epoch 104/1000
2023-09-20 13:13:06.871 
Epoch 104/1000 
	 loss: 16.0163, MinusLogProbMetric: 16.0163, val_loss: 17.5395, val_MinusLogProbMetric: 17.5395

Epoch 104: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.0163 - MinusLogProbMetric: 16.0163 - val_loss: 17.5395 - val_MinusLogProbMetric: 17.5395 - lr: 5.0000e-04 - 36s/epoch - 186ms/step
Epoch 105/1000
2023-09-20 13:13:43.240 
Epoch 105/1000 
	 loss: 16.0174, MinusLogProbMetric: 16.0174, val_loss: 17.4002, val_MinusLogProbMetric: 17.4002

Epoch 105: val_loss did not improve from 17.19705
196/196 - 36s - loss: 16.0174 - MinusLogProbMetric: 16.0174 - val_loss: 17.4002 - val_MinusLogProbMetric: 17.4002 - lr: 5.0000e-04 - 36s/epoch - 186ms/step
Epoch 106/1000
2023-09-20 13:14:19.616 
Epoch 106/1000 
	 loss: 15.9957, MinusLogProbMetric: 15.9957, val_loss: 17.3946, val_MinusLogProbMetric: 17.3946

Epoch 106: val_loss did not improve from 17.19705
196/196 - 36s - loss: 15.9957 - MinusLogProbMetric: 15.9957 - val_loss: 17.3946 - val_MinusLogProbMetric: 17.3946 - lr: 5.0000e-04 - 36s/epoch - 186ms/step
Epoch 107/1000
2023-09-20 13:14:55.757 
Epoch 107/1000 
	 loss: 15.9966, MinusLogProbMetric: 15.9966, val_loss: 17.4722, val_MinusLogProbMetric: 17.4722

Epoch 107: val_loss did not improve from 17.19705
196/196 - 36s - loss: 15.9966 - MinusLogProbMetric: 15.9966 - val_loss: 17.4722 - val_MinusLogProbMetric: 17.4722 - lr: 5.0000e-04 - 36s/epoch - 184ms/step
Epoch 108/1000
2023-09-20 13:15:32.446 
Epoch 108/1000 
	 loss: 16.0012, MinusLogProbMetric: 16.0012, val_loss: 17.5999, val_MinusLogProbMetric: 17.5999

Epoch 108: val_loss did not improve from 17.19705
196/196 - 37s - loss: 16.0012 - MinusLogProbMetric: 16.0012 - val_loss: 17.5999 - val_MinusLogProbMetric: 17.5999 - lr: 5.0000e-04 - 37s/epoch - 187ms/step
Epoch 109/1000
2023-09-20 13:16:08.951 
Epoch 109/1000 
	 loss: 15.9730, MinusLogProbMetric: 15.9730, val_loss: 17.4514, val_MinusLogProbMetric: 17.4514

Epoch 109: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.9730 - MinusLogProbMetric: 15.9730 - val_loss: 17.4514 - val_MinusLogProbMetric: 17.4514 - lr: 5.0000e-04 - 37s/epoch - 186ms/step
Epoch 110/1000
2023-09-20 13:16:45.402 
Epoch 110/1000 
	 loss: 15.9806, MinusLogProbMetric: 15.9806, val_loss: 17.4975, val_MinusLogProbMetric: 17.4975

Epoch 110: val_loss did not improve from 17.19705
196/196 - 36s - loss: 15.9806 - MinusLogProbMetric: 15.9806 - val_loss: 17.4975 - val_MinusLogProbMetric: 17.4975 - lr: 5.0000e-04 - 36s/epoch - 186ms/step
Epoch 111/1000
2023-09-20 13:17:21.921 
Epoch 111/1000 
	 loss: 15.9672, MinusLogProbMetric: 15.9672, val_loss: 17.6473, val_MinusLogProbMetric: 17.6473

Epoch 111: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.9672 - MinusLogProbMetric: 15.9672 - val_loss: 17.6473 - val_MinusLogProbMetric: 17.6473 - lr: 5.0000e-04 - 37s/epoch - 186ms/step
Epoch 112/1000
2023-09-20 13:17:58.390 
Epoch 112/1000 
	 loss: 15.9818, MinusLogProbMetric: 15.9818, val_loss: 17.4703, val_MinusLogProbMetric: 17.4703

Epoch 112: val_loss did not improve from 17.19705
196/196 - 36s - loss: 15.9818 - MinusLogProbMetric: 15.9818 - val_loss: 17.4703 - val_MinusLogProbMetric: 17.4703 - lr: 5.0000e-04 - 36s/epoch - 186ms/step
Epoch 113/1000
2023-09-20 13:18:35.045 
Epoch 113/1000 
	 loss: 15.9653, MinusLogProbMetric: 15.9653, val_loss: 17.4818, val_MinusLogProbMetric: 17.4818

Epoch 113: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.9653 - MinusLogProbMetric: 15.9653 - val_loss: 17.4818 - val_MinusLogProbMetric: 17.4818 - lr: 5.0000e-04 - 37s/epoch - 187ms/step
Epoch 114/1000
2023-09-20 13:19:11.542 
Epoch 114/1000 
	 loss: 15.9860, MinusLogProbMetric: 15.9860, val_loss: 17.4978, val_MinusLogProbMetric: 17.4978

Epoch 114: val_loss did not improve from 17.19705
196/196 - 36s - loss: 15.9860 - MinusLogProbMetric: 15.9860 - val_loss: 17.4978 - val_MinusLogProbMetric: 17.4978 - lr: 5.0000e-04 - 36s/epoch - 186ms/step
Epoch 115/1000
2023-09-20 13:19:47.884 
Epoch 115/1000 
	 loss: 15.9702, MinusLogProbMetric: 15.9702, val_loss: 17.5441, val_MinusLogProbMetric: 17.5441

Epoch 115: val_loss did not improve from 17.19705
196/196 - 36s - loss: 15.9702 - MinusLogProbMetric: 15.9702 - val_loss: 17.5441 - val_MinusLogProbMetric: 17.5441 - lr: 5.0000e-04 - 36s/epoch - 185ms/step
Epoch 116/1000
2023-09-20 13:20:24.396 
Epoch 116/1000 
	 loss: 15.9323, MinusLogProbMetric: 15.9323, val_loss: 17.5670, val_MinusLogProbMetric: 17.5670

Epoch 116: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.9323 - MinusLogProbMetric: 15.9323 - val_loss: 17.5670 - val_MinusLogProbMetric: 17.5670 - lr: 5.0000e-04 - 37s/epoch - 186ms/step
Epoch 117/1000
2023-09-20 13:21:00.953 
Epoch 117/1000 
	 loss: 15.9558, MinusLogProbMetric: 15.9558, val_loss: 17.4560, val_MinusLogProbMetric: 17.4560

Epoch 117: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.9558 - MinusLogProbMetric: 15.9558 - val_loss: 17.4560 - val_MinusLogProbMetric: 17.4560 - lr: 5.0000e-04 - 37s/epoch - 186ms/step
Epoch 118/1000
2023-09-20 13:21:37.059 
Epoch 118/1000 
	 loss: 15.9175, MinusLogProbMetric: 15.9175, val_loss: 17.5158, val_MinusLogProbMetric: 17.5158

Epoch 118: val_loss did not improve from 17.19705
196/196 - 36s - loss: 15.9175 - MinusLogProbMetric: 15.9175 - val_loss: 17.5158 - val_MinusLogProbMetric: 17.5158 - lr: 5.0000e-04 - 36s/epoch - 184ms/step
Epoch 119/1000
2023-09-20 13:22:13.543 
Epoch 119/1000 
	 loss: 15.9382, MinusLogProbMetric: 15.9382, val_loss: 17.4895, val_MinusLogProbMetric: 17.4895

Epoch 119: val_loss did not improve from 17.19705
196/196 - 36s - loss: 15.9382 - MinusLogProbMetric: 15.9382 - val_loss: 17.4895 - val_MinusLogProbMetric: 17.4895 - lr: 5.0000e-04 - 36s/epoch - 186ms/step
Epoch 120/1000
2023-09-20 13:22:50.060 
Epoch 120/1000 
	 loss: 15.9158, MinusLogProbMetric: 15.9158, val_loss: 17.5372, val_MinusLogProbMetric: 17.5372

Epoch 120: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.9158 - MinusLogProbMetric: 15.9158 - val_loss: 17.5372 - val_MinusLogProbMetric: 17.5372 - lr: 5.0000e-04 - 37s/epoch - 186ms/step
Epoch 121/1000
2023-09-20 13:23:26.675 
Epoch 121/1000 
	 loss: 15.9466, MinusLogProbMetric: 15.9466, val_loss: 17.5560, val_MinusLogProbMetric: 17.5560

Epoch 121: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.9466 - MinusLogProbMetric: 15.9466 - val_loss: 17.5560 - val_MinusLogProbMetric: 17.5560 - lr: 5.0000e-04 - 37s/epoch - 187ms/step
Epoch 122/1000
2023-09-20 13:24:03.300 
Epoch 122/1000 
	 loss: 15.9114, MinusLogProbMetric: 15.9114, val_loss: 17.5551, val_MinusLogProbMetric: 17.5551

Epoch 122: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.9114 - MinusLogProbMetric: 15.9114 - val_loss: 17.5551 - val_MinusLogProbMetric: 17.5551 - lr: 5.0000e-04 - 37s/epoch - 187ms/step
Epoch 123/1000
2023-09-20 13:24:39.446 
Epoch 123/1000 
	 loss: 15.8911, MinusLogProbMetric: 15.8911, val_loss: 17.5751, val_MinusLogProbMetric: 17.5751

Epoch 123: val_loss did not improve from 17.19705
196/196 - 36s - loss: 15.8911 - MinusLogProbMetric: 15.8911 - val_loss: 17.5751 - val_MinusLogProbMetric: 17.5751 - lr: 5.0000e-04 - 36s/epoch - 184ms/step
Epoch 124/1000
2023-09-20 13:25:16.005 
Epoch 124/1000 
	 loss: 15.8945, MinusLogProbMetric: 15.8945, val_loss: 17.5654, val_MinusLogProbMetric: 17.5654

Epoch 124: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.8945 - MinusLogProbMetric: 15.8945 - val_loss: 17.5654 - val_MinusLogProbMetric: 17.5654 - lr: 5.0000e-04 - 37s/epoch - 187ms/step
Epoch 125/1000
2023-09-20 13:25:52.751 
Epoch 125/1000 
	 loss: 15.9024, MinusLogProbMetric: 15.9024, val_loss: 17.5271, val_MinusLogProbMetric: 17.5271

Epoch 125: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.9024 - MinusLogProbMetric: 15.9024 - val_loss: 17.5271 - val_MinusLogProbMetric: 17.5271 - lr: 5.0000e-04 - 37s/epoch - 187ms/step
Epoch 126/1000
2023-09-20 13:26:29.038 
Epoch 126/1000 
	 loss: 15.9008, MinusLogProbMetric: 15.9008, val_loss: 17.6010, val_MinusLogProbMetric: 17.6010

Epoch 126: val_loss did not improve from 17.19705
196/196 - 36s - loss: 15.9008 - MinusLogProbMetric: 15.9008 - val_loss: 17.6010 - val_MinusLogProbMetric: 17.6010 - lr: 5.0000e-04 - 36s/epoch - 185ms/step
Epoch 127/1000
2023-09-20 13:27:05.377 
Epoch 127/1000 
	 loss: 15.9058, MinusLogProbMetric: 15.9058, val_loss: 17.6488, val_MinusLogProbMetric: 17.6488

Epoch 127: val_loss did not improve from 17.19705
196/196 - 36s - loss: 15.9058 - MinusLogProbMetric: 15.9058 - val_loss: 17.6488 - val_MinusLogProbMetric: 17.6488 - lr: 5.0000e-04 - 36s/epoch - 185ms/step
Epoch 128/1000
2023-09-20 13:27:41.573 
Epoch 128/1000 
	 loss: 15.8756, MinusLogProbMetric: 15.8756, val_loss: 17.6988, val_MinusLogProbMetric: 17.6988

Epoch 128: val_loss did not improve from 17.19705
196/196 - 36s - loss: 15.8756 - MinusLogProbMetric: 15.8756 - val_loss: 17.6988 - val_MinusLogProbMetric: 17.6988 - lr: 5.0000e-04 - 36s/epoch - 185ms/step
Epoch 129/1000
2023-09-20 13:28:18.074 
Epoch 129/1000 
	 loss: 15.8552, MinusLogProbMetric: 15.8552, val_loss: 17.6785, val_MinusLogProbMetric: 17.6785

Epoch 129: val_loss did not improve from 17.19705
196/196 - 36s - loss: 15.8552 - MinusLogProbMetric: 15.8552 - val_loss: 17.6785 - val_MinusLogProbMetric: 17.6785 - lr: 5.0000e-04 - 36s/epoch - 186ms/step
Epoch 130/1000
2023-09-20 13:28:54.493 
Epoch 130/1000 
	 loss: 15.8618, MinusLogProbMetric: 15.8618, val_loss: 17.5951, val_MinusLogProbMetric: 17.5951

Epoch 130: val_loss did not improve from 17.19705
196/196 - 36s - loss: 15.8618 - MinusLogProbMetric: 15.8618 - val_loss: 17.5951 - val_MinusLogProbMetric: 17.5951 - lr: 5.0000e-04 - 36s/epoch - 186ms/step
Epoch 131/1000
2023-09-20 13:29:31.151 
Epoch 131/1000 
	 loss: 15.8438, MinusLogProbMetric: 15.8438, val_loss: 17.8398, val_MinusLogProbMetric: 17.8398

Epoch 131: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.8438 - MinusLogProbMetric: 15.8438 - val_loss: 17.8398 - val_MinusLogProbMetric: 17.8398 - lr: 5.0000e-04 - 37s/epoch - 187ms/step
Epoch 132/1000
2023-09-20 13:30:07.727 
Epoch 132/1000 
	 loss: 15.8743, MinusLogProbMetric: 15.8743, val_loss: 17.6145, val_MinusLogProbMetric: 17.6145

Epoch 132: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.8743 - MinusLogProbMetric: 15.8743 - val_loss: 17.6145 - val_MinusLogProbMetric: 17.6145 - lr: 5.0000e-04 - 37s/epoch - 187ms/step
Epoch 133/1000
2023-09-20 13:30:44.090 
Epoch 133/1000 
	 loss: 15.8534, MinusLogProbMetric: 15.8534, val_loss: 17.6071, val_MinusLogProbMetric: 17.6071

Epoch 133: val_loss did not improve from 17.19705
196/196 - 36s - loss: 15.8534 - MinusLogProbMetric: 15.8534 - val_loss: 17.6071 - val_MinusLogProbMetric: 17.6071 - lr: 5.0000e-04 - 36s/epoch - 186ms/step
Epoch 134/1000
2023-09-20 13:31:20.917 
Epoch 134/1000 
	 loss: 15.8304, MinusLogProbMetric: 15.8304, val_loss: 17.5952, val_MinusLogProbMetric: 17.5952

Epoch 134: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.8304 - MinusLogProbMetric: 15.8304 - val_loss: 17.5952 - val_MinusLogProbMetric: 17.5952 - lr: 5.0000e-04 - 37s/epoch - 188ms/step
Epoch 135/1000
2023-09-20 13:31:57.560 
Epoch 135/1000 
	 loss: 15.8432, MinusLogProbMetric: 15.8432, val_loss: 17.6433, val_MinusLogProbMetric: 17.6433

Epoch 135: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.8432 - MinusLogProbMetric: 15.8432 - val_loss: 17.6433 - val_MinusLogProbMetric: 17.6433 - lr: 5.0000e-04 - 37s/epoch - 187ms/step
Epoch 136/1000
2023-09-20 13:32:34.299 
Epoch 136/1000 
	 loss: 15.8200, MinusLogProbMetric: 15.8200, val_loss: 17.7767, val_MinusLogProbMetric: 17.7767

Epoch 136: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.8200 - MinusLogProbMetric: 15.8200 - val_loss: 17.7767 - val_MinusLogProbMetric: 17.7767 - lr: 5.0000e-04 - 37s/epoch - 187ms/step
Epoch 137/1000
2023-09-20 13:33:10.941 
Epoch 137/1000 
	 loss: 15.8462, MinusLogProbMetric: 15.8462, val_loss: 17.6385, val_MinusLogProbMetric: 17.6385

Epoch 137: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.8462 - MinusLogProbMetric: 15.8462 - val_loss: 17.6385 - val_MinusLogProbMetric: 17.6385 - lr: 5.0000e-04 - 37s/epoch - 187ms/step
Epoch 138/1000
2023-09-20 13:33:47.502 
Epoch 138/1000 
	 loss: 15.8230, MinusLogProbMetric: 15.8230, val_loss: 17.6998, val_MinusLogProbMetric: 17.6998

Epoch 138: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.8230 - MinusLogProbMetric: 15.8230 - val_loss: 17.6998 - val_MinusLogProbMetric: 17.6998 - lr: 5.0000e-04 - 37s/epoch - 187ms/step
Epoch 139/1000
2023-09-20 13:34:23.962 
Epoch 139/1000 
	 loss: 15.8061, MinusLogProbMetric: 15.8061, val_loss: 17.6320, val_MinusLogProbMetric: 17.6320

Epoch 139: val_loss did not improve from 17.19705
196/196 - 36s - loss: 15.8061 - MinusLogProbMetric: 15.8061 - val_loss: 17.6320 - val_MinusLogProbMetric: 17.6320 - lr: 5.0000e-04 - 36s/epoch - 186ms/step
Epoch 140/1000
2023-09-20 13:35:00.328 
Epoch 140/1000 
	 loss: 15.8026, MinusLogProbMetric: 15.8026, val_loss: 18.1497, val_MinusLogProbMetric: 18.1497

Epoch 140: val_loss did not improve from 17.19705
196/196 - 36s - loss: 15.8026 - MinusLogProbMetric: 15.8026 - val_loss: 18.1497 - val_MinusLogProbMetric: 18.1497 - lr: 5.0000e-04 - 36s/epoch - 186ms/step
Epoch 141/1000
2023-09-20 13:35:37.182 
Epoch 141/1000 
	 loss: 15.8313, MinusLogProbMetric: 15.8313, val_loss: 17.6293, val_MinusLogProbMetric: 17.6293

Epoch 141: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.8313 - MinusLogProbMetric: 15.8313 - val_loss: 17.6293 - val_MinusLogProbMetric: 17.6293 - lr: 5.0000e-04 - 37s/epoch - 188ms/step
Epoch 142/1000
2023-09-20 13:36:14.013 
Epoch 142/1000 
	 loss: 15.7779, MinusLogProbMetric: 15.7779, val_loss: 17.6963, val_MinusLogProbMetric: 17.6963

Epoch 142: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.7779 - MinusLogProbMetric: 15.7779 - val_loss: 17.6963 - val_MinusLogProbMetric: 17.6963 - lr: 5.0000e-04 - 37s/epoch - 188ms/step
Epoch 143/1000
2023-09-20 13:36:50.674 
Epoch 143/1000 
	 loss: 15.7931, MinusLogProbMetric: 15.7931, val_loss: 17.7595, val_MinusLogProbMetric: 17.7595

Epoch 143: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.7931 - MinusLogProbMetric: 15.7931 - val_loss: 17.7595 - val_MinusLogProbMetric: 17.7595 - lr: 5.0000e-04 - 37s/epoch - 187ms/step
Epoch 144/1000
2023-09-20 13:37:27.348 
Epoch 144/1000 
	 loss: 15.7918, MinusLogProbMetric: 15.7918, val_loss: 17.7372, val_MinusLogProbMetric: 17.7372

Epoch 144: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.7918 - MinusLogProbMetric: 15.7918 - val_loss: 17.7372 - val_MinusLogProbMetric: 17.7372 - lr: 5.0000e-04 - 37s/epoch - 187ms/step
Epoch 145/1000
2023-09-20 13:38:04.006 
Epoch 145/1000 
	 loss: 15.7674, MinusLogProbMetric: 15.7674, val_loss: 17.7199, val_MinusLogProbMetric: 17.7199

Epoch 145: val_loss did not improve from 17.19705
196/196 - 37s - loss: 15.7674 - MinusLogProbMetric: 15.7674 - val_loss: 17.7199 - val_MinusLogProbMetric: 17.7199 - lr: 5.0000e-04 - 37s/epoch - 187ms/step
Epoch 146/1000
2023-09-20 13:38:40.292 
Epoch 146/1000 
	 loss: 15.7759, MinusLogProbMetric: 15.7759, val_loss: 17.6797, val_MinusLogProbMetric: 17.6797

Epoch 146: val_loss did not improve from 17.19705
196/196 - 36s - loss: 15.7759 - MinusLogProbMetric: 15.7759 - val_loss: 17.6797 - val_MinusLogProbMetric: 17.6797 - lr: 5.0000e-04 - 36s/epoch - 185ms/step
Epoch 147/1000
2023-09-20 13:39:17.121 
Epoch 147/1000 
	 loss: 15.7571, MinusLogProbMetric: 15.7571, val_loss: 17.8663, val_MinusLogProbMetric: 17.8663

Epoch 147: val_loss did not improve from 17.19705
Restoring model weights from the end of the best epoch: 47.
196/196 - 37s - loss: 15.7571 - MinusLogProbMetric: 15.7571 - val_loss: 17.8663 - val_MinusLogProbMetric: 17.8663 - lr: 5.0000e-04 - 37s/epoch - 190ms/step
Epoch 147: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 18.45160741894506 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 10.04864112706855 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 7.195638312958181 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7faa8488bc70> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 33.76684951293282 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 14.072851016186178 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 9.13919719401747 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7faac9836d40> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 377.
Model trained in 5470.70 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/c_Main_CsplineN.py , Line : 468, Func.Name : prediction_function, Message : X_data_nf: tf.Tensor = DataInputs.dist_2_num[:nsamples_test] # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 95.19 s.
===========
Run 258/720 done in 5569.77 s.
===========

===========
Generating train data for run 259.
===========
Train data generated in 0.12 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_259/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 377}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_259/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.1831715 ,  3.2834203 ,  8.308094  , ...,  7.3133397 ,
         2.7002556 ,  1.7567806 ],
       [ 6.1308765 ,  7.147402  ,  6.0903115 , ...,  4.022617  ,
         2.6618268 ,  7.627545  ],
       [ 2.7429156 ,  3.6509063 ,  7.295548  , ...,  7.086021  ,
         2.8938296 ,  1.8224454 ],
       ...,
       [ 2.1098776 ,  4.1337423 ,  8.041495  , ...,  7.2043395 ,
         2.3724499 ,  1.8449893 ],
       [ 4.759076  ,  5.6016526 , -0.17659053, ...,  1.2483898 ,
         6.6213574 ,  1.391019  ],
       [ 4.6478305 ,  5.6608987 ,  0.05425403, ...,  1.0307544 ,
         6.027231  ,  1.3217621 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_259/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_259
self.data_kwargs: {'seed': 377}
self.x_data: [[5.416377   7.151266   6.5657053  ... 3.613302   2.6304417  8.037386  ]
 [4.297167   5.832213   0.12875912 ... 1.4317983  6.415448   1.3533646 ]
 [6.2353234  7.1795187  6.219724   ... 4.5891814  2.66546    7.551563  ]
 ...
 [1.8237456  4.102903   7.5608215  ... 7.136859   2.564185   1.5539532 ]
 [2.2305896  4.6568003  8.321339   ... 7.0577617  2.6189713  1.518045  ]
 [5.653481   7.1263475  6.929123   ... 4.292566   2.643216   7.404443  ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_202"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_203 (InputLayer)      [(None, 32)]              0         
                                                                 
 log_prob_layer_22 (LogProbL  (None,)                  537200    
 ayer)                                                           
                                                                 
=================================================================
Total params: 537,200
Trainable params: 537,200
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_22/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_22'")
self.model: <keras.engine.functional.Functional object at 0x7fb03048cb50>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7faab42ba7d0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7faab42ba7d0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7faad0ccb910>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fad209494e0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fad20949a50>, <keras.callbacks.ModelCheckpoint object at 0x7fad20949b10>, <keras.callbacks.EarlyStopping object at 0x7fad20949d80>, <keras.callbacks.ReduceLROnPlateau object at 0x7fad20949db0>, <keras.callbacks.TerminateOnNaN object at 0x7fad209499f0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.1831715 ,  3.2834203 ,  8.308094  , ...,  7.3133397 ,
         2.7002556 ,  1.7567806 ],
       [ 6.1308765 ,  7.147402  ,  6.0903115 , ...,  4.022617  ,
         2.6618268 ,  7.627545  ],
       [ 2.7429156 ,  3.6509063 ,  7.295548  , ...,  7.086021  ,
         2.8938296 ,  1.8224454 ],
       ...,
       [ 2.1098776 ,  4.1337423 ,  8.041495  , ...,  7.2043395 ,
         2.3724499 ,  1.8449893 ],
       [ 4.759076  ,  5.6016526 , -0.17659053, ...,  1.2483898 ,
         6.6213574 ,  1.391019  ],
       [ 4.6478305 ,  5.6608987 ,  0.05425403, ...,  1.0307544 ,
         6.027231  ,  1.3217621 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_259/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 259/720 with hyperparameters:
timestamp = 2023-09-20 13:40:56.969620
ndims = 32
seed_train = 377
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 5
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 537200
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 5.416377    7.151266    6.5657053   5.44807     3.870332    6.1800294
  2.9008856   8.441634    9.391678    4.1002183   7.382605    5.3625755
  5.5868373   9.949682    0.82923275  1.9832962  -0.10069095  8.219267
  8.539603    9.221239    9.5321455   8.239499    4.945965    8.152974
 -0.16393006  6.303131    0.6036788   9.50227     6.1976576   3.613302
  2.6304417   8.037386  ]
Epoch 1/1000
2023-09-20 13:43:19.072 
Epoch 1/1000 
	 loss: 124.1471, MinusLogProbMetric: 124.1471, val_loss: 32.0501, val_MinusLogProbMetric: 32.0501

Epoch 1: val_loss improved from inf to 32.05015, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 143s - loss: 124.1471 - MinusLogProbMetric: 124.1471 - val_loss: 32.0501 - val_MinusLogProbMetric: 32.0501 - lr: 0.0010 - 143s/epoch - 728ms/step
Epoch 2/1000
2023-09-20 13:44:03.278 
Epoch 2/1000 
	 loss: 28.1854, MinusLogProbMetric: 28.1854, val_loss: 25.6226, val_MinusLogProbMetric: 25.6226

Epoch 2: val_loss improved from 32.05015 to 25.62263, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 28.1854 - MinusLogProbMetric: 28.1854 - val_loss: 25.6226 - val_MinusLogProbMetric: 25.6226 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 3/1000
2023-09-20 13:44:47.147 
Epoch 3/1000 
	 loss: 24.5614, MinusLogProbMetric: 24.5614, val_loss: 23.8644, val_MinusLogProbMetric: 23.8644

Epoch 3: val_loss improved from 25.62263 to 23.86440, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 24.5614 - MinusLogProbMetric: 24.5614 - val_loss: 23.8644 - val_MinusLogProbMetric: 23.8644 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 4/1000
2023-09-20 13:45:31.585 
Epoch 4/1000 
	 loss: 23.1189, MinusLogProbMetric: 23.1189, val_loss: 22.7924, val_MinusLogProbMetric: 22.7924

Epoch 4: val_loss improved from 23.86440 to 22.79244, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 23.1189 - MinusLogProbMetric: 23.1189 - val_loss: 22.7924 - val_MinusLogProbMetric: 22.7924 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 5/1000
2023-09-20 13:46:15.639 
Epoch 5/1000 
	 loss: 22.1118, MinusLogProbMetric: 22.1118, val_loss: 21.5732, val_MinusLogProbMetric: 21.5732

Epoch 5: val_loss improved from 22.79244 to 21.57323, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 45s - loss: 22.1118 - MinusLogProbMetric: 22.1118 - val_loss: 21.5732 - val_MinusLogProbMetric: 21.5732 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 6/1000
2023-09-20 13:47:00.198 
Epoch 6/1000 
	 loss: 21.4695, MinusLogProbMetric: 21.4695, val_loss: 20.8640, val_MinusLogProbMetric: 20.8640

Epoch 6: val_loss improved from 21.57323 to 20.86399, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 21.4695 - MinusLogProbMetric: 21.4695 - val_loss: 20.8640 - val_MinusLogProbMetric: 20.8640 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 7/1000
2023-09-20 13:47:43.838 
Epoch 7/1000 
	 loss: 21.1258, MinusLogProbMetric: 21.1258, val_loss: 20.5715, val_MinusLogProbMetric: 20.5715

Epoch 7: val_loss improved from 20.86399 to 20.57148, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 21.1258 - MinusLogProbMetric: 21.1258 - val_loss: 20.5715 - val_MinusLogProbMetric: 20.5715 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 8/1000
2023-09-20 13:48:26.961 
Epoch 8/1000 
	 loss: 20.6173, MinusLogProbMetric: 20.6173, val_loss: 20.1186, val_MinusLogProbMetric: 20.1186

Epoch 8: val_loss improved from 20.57148 to 20.11856, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 43s - loss: 20.6173 - MinusLogProbMetric: 20.6173 - val_loss: 20.1186 - val_MinusLogProbMetric: 20.1186 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 9/1000
2023-09-20 13:49:04.474 
Epoch 9/1000 
	 loss: 20.4601, MinusLogProbMetric: 20.4601, val_loss: 20.3471, val_MinusLogProbMetric: 20.3471

Epoch 9: val_loss did not improve from 20.11856
196/196 - 36s - loss: 20.4601 - MinusLogProbMetric: 20.4601 - val_loss: 20.3471 - val_MinusLogProbMetric: 20.3471 - lr: 0.0010 - 36s/epoch - 186ms/step
Epoch 10/1000
2023-09-20 13:49:39.527 
Epoch 10/1000 
	 loss: 20.1570, MinusLogProbMetric: 20.1570, val_loss: 19.7622, val_MinusLogProbMetric: 19.7622

Epoch 10: val_loss improved from 20.11856 to 19.76222, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 36s - loss: 20.1570 - MinusLogProbMetric: 20.1570 - val_loss: 19.7622 - val_MinusLogProbMetric: 19.7622 - lr: 0.0010 - 36s/epoch - 186ms/step
Epoch 11/1000
2023-09-20 13:50:15.603 
Epoch 11/1000 
	 loss: 20.0443, MinusLogProbMetric: 20.0443, val_loss: 19.6735, val_MinusLogProbMetric: 19.6735

Epoch 11: val_loss improved from 19.76222 to 19.67347, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 35s - loss: 20.0443 - MinusLogProbMetric: 20.0443 - val_loss: 19.6735 - val_MinusLogProbMetric: 19.6735 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 12/1000
2023-09-20 13:50:50.347 
Epoch 12/1000 
	 loss: 19.6371, MinusLogProbMetric: 19.6371, val_loss: 20.3364, val_MinusLogProbMetric: 20.3364

Epoch 12: val_loss did not improve from 19.67347
196/196 - 34s - loss: 19.6371 - MinusLogProbMetric: 19.6371 - val_loss: 20.3364 - val_MinusLogProbMetric: 20.3364 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 13/1000
2023-09-20 13:51:24.985 
Epoch 13/1000 
	 loss: 19.6318, MinusLogProbMetric: 19.6318, val_loss: 19.5426, val_MinusLogProbMetric: 19.5426

Epoch 13: val_loss improved from 19.67347 to 19.54264, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 35s - loss: 19.6318 - MinusLogProbMetric: 19.6318 - val_loss: 19.5426 - val_MinusLogProbMetric: 19.5426 - lr: 0.0010 - 35s/epoch - 180ms/step
Epoch 14/1000
2023-09-20 13:52:01.373 
Epoch 14/1000 
	 loss: 19.4641, MinusLogProbMetric: 19.4641, val_loss: 19.2944, val_MinusLogProbMetric: 19.2944

Epoch 14: val_loss improved from 19.54264 to 19.29443, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 37s - loss: 19.4641 - MinusLogProbMetric: 19.4641 - val_loss: 19.2944 - val_MinusLogProbMetric: 19.2944 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 15/1000
2023-09-20 13:52:36.609 
Epoch 15/1000 
	 loss: 19.2380, MinusLogProbMetric: 19.2380, val_loss: 21.5239, val_MinusLogProbMetric: 21.5239

Epoch 15: val_loss did not improve from 19.29443
196/196 - 34s - loss: 19.2380 - MinusLogProbMetric: 19.2380 - val_loss: 21.5239 - val_MinusLogProbMetric: 21.5239 - lr: 0.0010 - 34s/epoch - 175ms/step
Epoch 16/1000
2023-09-20 13:53:15.819 
Epoch 16/1000 
	 loss: 19.1096, MinusLogProbMetric: 19.1096, val_loss: 19.1718, val_MinusLogProbMetric: 19.1718

Epoch 16: val_loss improved from 19.29443 to 19.17185, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 40s - loss: 19.1096 - MinusLogProbMetric: 19.1096 - val_loss: 19.1718 - val_MinusLogProbMetric: 19.1718 - lr: 0.0010 - 40s/epoch - 204ms/step
Epoch 17/1000
2023-09-20 13:53:58.353 
Epoch 17/1000 
	 loss: 19.0894, MinusLogProbMetric: 19.0894, val_loss: 18.6231, val_MinusLogProbMetric: 18.6231

Epoch 17: val_loss improved from 19.17185 to 18.62309, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 43s - loss: 19.0894 - MinusLogProbMetric: 19.0894 - val_loss: 18.6231 - val_MinusLogProbMetric: 18.6231 - lr: 0.0010 - 43s/epoch - 217ms/step
Epoch 18/1000
2023-09-20 13:54:42.323 
Epoch 18/1000 
	 loss: 18.9261, MinusLogProbMetric: 18.9261, val_loss: 19.0054, val_MinusLogProbMetric: 19.0054

Epoch 18: val_loss did not improve from 18.62309
196/196 - 43s - loss: 18.9261 - MinusLogProbMetric: 18.9261 - val_loss: 19.0054 - val_MinusLogProbMetric: 19.0054 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 19/1000
2023-09-20 13:55:25.535 
Epoch 19/1000 
	 loss: 18.8385, MinusLogProbMetric: 18.8385, val_loss: 20.1912, val_MinusLogProbMetric: 20.1912

Epoch 19: val_loss did not improve from 18.62309
196/196 - 43s - loss: 18.8385 - MinusLogProbMetric: 18.8385 - val_loss: 20.1912 - val_MinusLogProbMetric: 20.1912 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 20/1000
2023-09-20 13:56:08.815 
Epoch 20/1000 
	 loss: 18.8147, MinusLogProbMetric: 18.8147, val_loss: 18.3706, val_MinusLogProbMetric: 18.3706

Epoch 20: val_loss improved from 18.62309 to 18.37060, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 18.8147 - MinusLogProbMetric: 18.8147 - val_loss: 18.3706 - val_MinusLogProbMetric: 18.3706 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 21/1000
2023-09-20 13:56:52.642 
Epoch 21/1000 
	 loss: 18.6764, MinusLogProbMetric: 18.6764, val_loss: 18.7047, val_MinusLogProbMetric: 18.7047

Epoch 21: val_loss did not improve from 18.37060
196/196 - 43s - loss: 18.6764 - MinusLogProbMetric: 18.6764 - val_loss: 18.7047 - val_MinusLogProbMetric: 18.7047 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 22/1000
2023-09-20 13:57:36.004 
Epoch 22/1000 
	 loss: 18.6265, MinusLogProbMetric: 18.6265, val_loss: 18.6739, val_MinusLogProbMetric: 18.6739

Epoch 22: val_loss did not improve from 18.37060
196/196 - 43s - loss: 18.6265 - MinusLogProbMetric: 18.6265 - val_loss: 18.6739 - val_MinusLogProbMetric: 18.6739 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 23/1000
2023-09-20 13:58:19.083 
Epoch 23/1000 
	 loss: 18.6801, MinusLogProbMetric: 18.6801, val_loss: 18.6559, val_MinusLogProbMetric: 18.6559

Epoch 23: val_loss did not improve from 18.37060
196/196 - 43s - loss: 18.6801 - MinusLogProbMetric: 18.6801 - val_loss: 18.6559 - val_MinusLogProbMetric: 18.6559 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 24/1000
2023-09-20 13:59:02.000 
Epoch 24/1000 
	 loss: 18.4815, MinusLogProbMetric: 18.4815, val_loss: 18.2731, val_MinusLogProbMetric: 18.2731

Epoch 24: val_loss improved from 18.37060 to 18.27312, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 18.4815 - MinusLogProbMetric: 18.4815 - val_loss: 18.2731 - val_MinusLogProbMetric: 18.2731 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 25/1000
2023-09-20 13:59:45.933 
Epoch 25/1000 
	 loss: 18.3576, MinusLogProbMetric: 18.3576, val_loss: 18.2081, val_MinusLogProbMetric: 18.2081

Epoch 25: val_loss improved from 18.27312 to 18.20812, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 18.3576 - MinusLogProbMetric: 18.3576 - val_loss: 18.2081 - val_MinusLogProbMetric: 18.2081 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 26/1000
2023-09-20 14:00:30.096 
Epoch 26/1000 
	 loss: 18.4282, MinusLogProbMetric: 18.4282, val_loss: 18.0404, val_MinusLogProbMetric: 18.0404

Epoch 26: val_loss improved from 18.20812 to 18.04035, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 18.4282 - MinusLogProbMetric: 18.4282 - val_loss: 18.0404 - val_MinusLogProbMetric: 18.0404 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 27/1000
2023-09-20 14:01:13.742 
Epoch 27/1000 
	 loss: 18.4424, MinusLogProbMetric: 18.4424, val_loss: 18.4557, val_MinusLogProbMetric: 18.4557

Epoch 27: val_loss did not improve from 18.04035
196/196 - 43s - loss: 18.4424 - MinusLogProbMetric: 18.4424 - val_loss: 18.4557 - val_MinusLogProbMetric: 18.4557 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 28/1000
2023-09-20 14:01:56.835 
Epoch 28/1000 
	 loss: 18.3345, MinusLogProbMetric: 18.3345, val_loss: 18.5403, val_MinusLogProbMetric: 18.5403

Epoch 28: val_loss did not improve from 18.04035
196/196 - 43s - loss: 18.3345 - MinusLogProbMetric: 18.3345 - val_loss: 18.5403 - val_MinusLogProbMetric: 18.5403 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 29/1000
2023-09-20 14:02:40.083 
Epoch 29/1000 
	 loss: 18.1345, MinusLogProbMetric: 18.1345, val_loss: 18.2326, val_MinusLogProbMetric: 18.2326

Epoch 29: val_loss did not improve from 18.04035
196/196 - 43s - loss: 18.1345 - MinusLogProbMetric: 18.1345 - val_loss: 18.2326 - val_MinusLogProbMetric: 18.2326 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 30/1000
2023-09-20 14:03:23.279 
Epoch 30/1000 
	 loss: 18.1973, MinusLogProbMetric: 18.1973, val_loss: 18.5178, val_MinusLogProbMetric: 18.5178

Epoch 30: val_loss did not improve from 18.04035
196/196 - 43s - loss: 18.1973 - MinusLogProbMetric: 18.1973 - val_loss: 18.5178 - val_MinusLogProbMetric: 18.5178 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 31/1000
2023-09-20 14:04:05.994 
Epoch 31/1000 
	 loss: 18.2057, MinusLogProbMetric: 18.2057, val_loss: 18.2999, val_MinusLogProbMetric: 18.2999

Epoch 31: val_loss did not improve from 18.04035
196/196 - 43s - loss: 18.2057 - MinusLogProbMetric: 18.2057 - val_loss: 18.2999 - val_MinusLogProbMetric: 18.2999 - lr: 0.0010 - 43s/epoch - 218ms/step
Epoch 32/1000
2023-09-20 14:04:49.396 
Epoch 32/1000 
	 loss: 18.1395, MinusLogProbMetric: 18.1395, val_loss: 17.9898, val_MinusLogProbMetric: 17.9898

Epoch 32: val_loss improved from 18.04035 to 17.98981, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 18.1395 - MinusLogProbMetric: 18.1395 - val_loss: 17.9898 - val_MinusLogProbMetric: 17.9898 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 33/1000
2023-09-20 14:05:33.211 
Epoch 33/1000 
	 loss: 18.0931, MinusLogProbMetric: 18.0931, val_loss: 18.2320, val_MinusLogProbMetric: 18.2320

Epoch 33: val_loss did not improve from 17.98981
196/196 - 43s - loss: 18.0931 - MinusLogProbMetric: 18.0931 - val_loss: 18.2320 - val_MinusLogProbMetric: 18.2320 - lr: 0.0010 - 43s/epoch - 218ms/step
Epoch 34/1000
2023-09-20 14:06:16.445 
Epoch 34/1000 
	 loss: 18.0767, MinusLogProbMetric: 18.0767, val_loss: 17.9363, val_MinusLogProbMetric: 17.9363

Epoch 34: val_loss improved from 17.98981 to 17.93633, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 18.0767 - MinusLogProbMetric: 18.0767 - val_loss: 17.9363 - val_MinusLogProbMetric: 17.9363 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 35/1000
2023-09-20 14:07:00.869 
Epoch 35/1000 
	 loss: 18.1257, MinusLogProbMetric: 18.1257, val_loss: 18.4707, val_MinusLogProbMetric: 18.4707

Epoch 35: val_loss did not improve from 17.93633
196/196 - 44s - loss: 18.1257 - MinusLogProbMetric: 18.1257 - val_loss: 18.4707 - val_MinusLogProbMetric: 18.4707 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 36/1000
2023-09-20 14:07:44.160 
Epoch 36/1000 
	 loss: 17.9564, MinusLogProbMetric: 17.9564, val_loss: 17.8638, val_MinusLogProbMetric: 17.8638

Epoch 36: val_loss improved from 17.93633 to 17.86379, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 17.9564 - MinusLogProbMetric: 17.9564 - val_loss: 17.8638 - val_MinusLogProbMetric: 17.8638 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 37/1000
2023-09-20 14:08:28.619 
Epoch 37/1000 
	 loss: 17.9593, MinusLogProbMetric: 17.9593, val_loss: 17.9018, val_MinusLogProbMetric: 17.9018

Epoch 37: val_loss did not improve from 17.86379
196/196 - 43s - loss: 17.9593 - MinusLogProbMetric: 17.9593 - val_loss: 17.9018 - val_MinusLogProbMetric: 17.9018 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 38/1000
2023-09-20 14:09:11.977 
Epoch 38/1000 
	 loss: 17.9812, MinusLogProbMetric: 17.9812, val_loss: 19.6907, val_MinusLogProbMetric: 19.6907

Epoch 38: val_loss did not improve from 17.86379
196/196 - 43s - loss: 17.9812 - MinusLogProbMetric: 17.9812 - val_loss: 19.6907 - val_MinusLogProbMetric: 19.6907 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 39/1000
2023-09-20 14:09:55.049 
Epoch 39/1000 
	 loss: 17.9610, MinusLogProbMetric: 17.9610, val_loss: 17.6342, val_MinusLogProbMetric: 17.6342

Epoch 39: val_loss improved from 17.86379 to 17.63423, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 17.9610 - MinusLogProbMetric: 17.9610 - val_loss: 17.6342 - val_MinusLogProbMetric: 17.6342 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 40/1000
2023-09-20 14:10:39.100 
Epoch 40/1000 
	 loss: 17.8313, MinusLogProbMetric: 17.8313, val_loss: 18.3601, val_MinusLogProbMetric: 18.3601

Epoch 40: val_loss did not improve from 17.63423
196/196 - 43s - loss: 17.8313 - MinusLogProbMetric: 17.8313 - val_loss: 18.3601 - val_MinusLogProbMetric: 18.3601 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 41/1000
2023-09-20 14:11:22.458 
Epoch 41/1000 
	 loss: 17.8576, MinusLogProbMetric: 17.8576, val_loss: 17.8019, val_MinusLogProbMetric: 17.8019

Epoch 41: val_loss did not improve from 17.63423
196/196 - 43s - loss: 17.8576 - MinusLogProbMetric: 17.8576 - val_loss: 17.8019 - val_MinusLogProbMetric: 17.8019 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 42/1000
2023-09-20 14:12:05.766 
Epoch 42/1000 
	 loss: 17.9271, MinusLogProbMetric: 17.9271, val_loss: 17.7364, val_MinusLogProbMetric: 17.7364

Epoch 42: val_loss did not improve from 17.63423
196/196 - 43s - loss: 17.9271 - MinusLogProbMetric: 17.9271 - val_loss: 17.7364 - val_MinusLogProbMetric: 17.7364 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 43/1000
2023-09-20 14:12:48.991 
Epoch 43/1000 
	 loss: 17.7830, MinusLogProbMetric: 17.7830, val_loss: 17.7736, val_MinusLogProbMetric: 17.7736

Epoch 43: val_loss did not improve from 17.63423
196/196 - 43s - loss: 17.7830 - MinusLogProbMetric: 17.7830 - val_loss: 17.7736 - val_MinusLogProbMetric: 17.7736 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 44/1000
2023-09-20 14:13:31.674 
Epoch 44/1000 
	 loss: 17.8579, MinusLogProbMetric: 17.8579, val_loss: 18.4710, val_MinusLogProbMetric: 18.4710

Epoch 44: val_loss did not improve from 17.63423
196/196 - 43s - loss: 17.8579 - MinusLogProbMetric: 17.8579 - val_loss: 18.4710 - val_MinusLogProbMetric: 18.4710 - lr: 0.0010 - 43s/epoch - 218ms/step
Epoch 45/1000
2023-09-20 14:14:14.783 
Epoch 45/1000 
	 loss: 17.7404, MinusLogProbMetric: 17.7404, val_loss: 20.1786, val_MinusLogProbMetric: 20.1786

Epoch 45: val_loss did not improve from 17.63423
196/196 - 43s - loss: 17.7404 - MinusLogProbMetric: 17.7404 - val_loss: 20.1786 - val_MinusLogProbMetric: 20.1786 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 46/1000
2023-09-20 14:14:58.159 
Epoch 46/1000 
	 loss: 17.7879, MinusLogProbMetric: 17.7879, val_loss: 17.6576, val_MinusLogProbMetric: 17.6576

Epoch 46: val_loss did not improve from 17.63423
196/196 - 43s - loss: 17.7879 - MinusLogProbMetric: 17.7879 - val_loss: 17.6576 - val_MinusLogProbMetric: 17.6576 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 47/1000
2023-09-20 14:15:41.447 
Epoch 47/1000 
	 loss: 17.7936, MinusLogProbMetric: 17.7936, val_loss: 17.5883, val_MinusLogProbMetric: 17.5883

Epoch 47: val_loss improved from 17.63423 to 17.58834, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 17.7936 - MinusLogProbMetric: 17.7936 - val_loss: 17.5883 - val_MinusLogProbMetric: 17.5883 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 48/1000
2023-09-20 14:16:25.342 
Epoch 48/1000 
	 loss: 17.7201, MinusLogProbMetric: 17.7201, val_loss: 17.6536, val_MinusLogProbMetric: 17.6536

Epoch 48: val_loss did not improve from 17.58834
196/196 - 43s - loss: 17.7201 - MinusLogProbMetric: 17.7201 - val_loss: 17.6536 - val_MinusLogProbMetric: 17.6536 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 49/1000
2023-09-20 14:17:08.677 
Epoch 49/1000 
	 loss: 17.7085, MinusLogProbMetric: 17.7085, val_loss: 17.7535, val_MinusLogProbMetric: 17.7535

Epoch 49: val_loss did not improve from 17.58834
196/196 - 43s - loss: 17.7085 - MinusLogProbMetric: 17.7085 - val_loss: 17.7535 - val_MinusLogProbMetric: 17.7535 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 50/1000
2023-09-20 14:17:52.054 
Epoch 50/1000 
	 loss: 17.6751, MinusLogProbMetric: 17.6751, val_loss: 17.4521, val_MinusLogProbMetric: 17.4521

Epoch 50: val_loss improved from 17.58834 to 17.45215, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 17.6751 - MinusLogProbMetric: 17.6751 - val_loss: 17.4521 - val_MinusLogProbMetric: 17.4521 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 51/1000
2023-09-20 14:18:35.847 
Epoch 51/1000 
	 loss: 17.6532, MinusLogProbMetric: 17.6532, val_loss: 17.7892, val_MinusLogProbMetric: 17.7892

Epoch 51: val_loss did not improve from 17.45215
196/196 - 43s - loss: 17.6532 - MinusLogProbMetric: 17.6532 - val_loss: 17.7892 - val_MinusLogProbMetric: 17.7892 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 52/1000
2023-09-20 14:19:18.911 
Epoch 52/1000 
	 loss: 17.7073, MinusLogProbMetric: 17.7073, val_loss: 17.5193, val_MinusLogProbMetric: 17.5193

Epoch 52: val_loss did not improve from 17.45215
196/196 - 43s - loss: 17.7073 - MinusLogProbMetric: 17.7073 - val_loss: 17.5193 - val_MinusLogProbMetric: 17.5193 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 53/1000
2023-09-20 14:20:02.522 
Epoch 53/1000 
	 loss: 17.6544, MinusLogProbMetric: 17.6544, val_loss: 17.9408, val_MinusLogProbMetric: 17.9408

Epoch 53: val_loss did not improve from 17.45215
196/196 - 44s - loss: 17.6544 - MinusLogProbMetric: 17.6544 - val_loss: 17.9408 - val_MinusLogProbMetric: 17.9408 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 54/1000
2023-09-20 14:20:45.566 
Epoch 54/1000 
	 loss: 17.6194, MinusLogProbMetric: 17.6194, val_loss: 17.5887, val_MinusLogProbMetric: 17.5887

Epoch 54: val_loss did not improve from 17.45215
196/196 - 43s - loss: 17.6194 - MinusLogProbMetric: 17.6194 - val_loss: 17.5887 - val_MinusLogProbMetric: 17.5887 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 55/1000
2023-09-20 14:21:28.995 
Epoch 55/1000 
	 loss: 17.6307, MinusLogProbMetric: 17.6307, val_loss: 17.8584, val_MinusLogProbMetric: 17.8584

Epoch 55: val_loss did not improve from 17.45215
196/196 - 43s - loss: 17.6307 - MinusLogProbMetric: 17.6307 - val_loss: 17.8584 - val_MinusLogProbMetric: 17.8584 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 56/1000
2023-09-20 14:22:11.830 
Epoch 56/1000 
	 loss: 17.6075, MinusLogProbMetric: 17.6075, val_loss: 17.8914, val_MinusLogProbMetric: 17.8914

Epoch 56: val_loss did not improve from 17.45215
196/196 - 43s - loss: 17.6075 - MinusLogProbMetric: 17.6075 - val_loss: 17.8914 - val_MinusLogProbMetric: 17.8914 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 57/1000
2023-09-20 14:22:54.788 
Epoch 57/1000 
	 loss: 17.6246, MinusLogProbMetric: 17.6246, val_loss: 17.5020, val_MinusLogProbMetric: 17.5020

Epoch 57: val_loss did not improve from 17.45215
196/196 - 43s - loss: 17.6246 - MinusLogProbMetric: 17.6246 - val_loss: 17.5020 - val_MinusLogProbMetric: 17.5020 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 58/1000
2023-09-20 14:23:37.978 
Epoch 58/1000 
	 loss: 17.4984, MinusLogProbMetric: 17.4984, val_loss: 17.5675, val_MinusLogProbMetric: 17.5675

Epoch 58: val_loss did not improve from 17.45215
196/196 - 43s - loss: 17.4984 - MinusLogProbMetric: 17.4984 - val_loss: 17.5675 - val_MinusLogProbMetric: 17.5675 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 59/1000
2023-09-20 14:24:21.320 
Epoch 59/1000 
	 loss: 17.5502, MinusLogProbMetric: 17.5502, val_loss: 17.7134, val_MinusLogProbMetric: 17.7134

Epoch 59: val_loss did not improve from 17.45215
196/196 - 43s - loss: 17.5502 - MinusLogProbMetric: 17.5502 - val_loss: 17.7134 - val_MinusLogProbMetric: 17.7134 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 60/1000
2023-09-20 14:25:04.449 
Epoch 60/1000 
	 loss: 17.5745, MinusLogProbMetric: 17.5745, val_loss: 17.3621, val_MinusLogProbMetric: 17.3621

Epoch 60: val_loss improved from 17.45215 to 17.36208, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 17.5745 - MinusLogProbMetric: 17.5745 - val_loss: 17.3621 - val_MinusLogProbMetric: 17.3621 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 61/1000
2023-09-20 14:25:48.514 
Epoch 61/1000 
	 loss: 17.4883, MinusLogProbMetric: 17.4883, val_loss: 19.0197, val_MinusLogProbMetric: 19.0197

Epoch 61: val_loss did not improve from 17.36208
196/196 - 43s - loss: 17.4883 - MinusLogProbMetric: 17.4883 - val_loss: 19.0197 - val_MinusLogProbMetric: 19.0197 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 62/1000
2023-09-20 14:26:31.911 
Epoch 62/1000 
	 loss: 17.6071, MinusLogProbMetric: 17.6071, val_loss: 17.6579, val_MinusLogProbMetric: 17.6579

Epoch 62: val_loss did not improve from 17.36208
196/196 - 43s - loss: 17.6071 - MinusLogProbMetric: 17.6071 - val_loss: 17.6579 - val_MinusLogProbMetric: 17.6579 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 63/1000
2023-09-20 14:27:14.915 
Epoch 63/1000 
	 loss: 17.5477, MinusLogProbMetric: 17.5477, val_loss: 17.3936, val_MinusLogProbMetric: 17.3936

Epoch 63: val_loss did not improve from 17.36208
196/196 - 43s - loss: 17.5477 - MinusLogProbMetric: 17.5477 - val_loss: 17.3936 - val_MinusLogProbMetric: 17.3936 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 64/1000
2023-09-20 14:27:57.750 
Epoch 64/1000 
	 loss: 17.4425, MinusLogProbMetric: 17.4425, val_loss: 17.4255, val_MinusLogProbMetric: 17.4255

Epoch 64: val_loss did not improve from 17.36208
196/196 - 43s - loss: 17.4425 - MinusLogProbMetric: 17.4425 - val_loss: 17.4255 - val_MinusLogProbMetric: 17.4255 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 65/1000
2023-09-20 14:28:40.646 
Epoch 65/1000 
	 loss: 17.5008, MinusLogProbMetric: 17.5008, val_loss: 17.9074, val_MinusLogProbMetric: 17.9074

Epoch 65: val_loss did not improve from 17.36208
196/196 - 43s - loss: 17.5008 - MinusLogProbMetric: 17.5008 - val_loss: 17.9074 - val_MinusLogProbMetric: 17.9074 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 66/1000
2023-09-20 14:29:23.383 
Epoch 66/1000 
	 loss: 17.5812, MinusLogProbMetric: 17.5812, val_loss: 17.5642, val_MinusLogProbMetric: 17.5642

Epoch 66: val_loss did not improve from 17.36208
196/196 - 43s - loss: 17.5812 - MinusLogProbMetric: 17.5812 - val_loss: 17.5642 - val_MinusLogProbMetric: 17.5642 - lr: 0.0010 - 43s/epoch - 218ms/step
Epoch 67/1000
2023-09-20 14:30:07.002 
Epoch 67/1000 
	 loss: 17.4630, MinusLogProbMetric: 17.4630, val_loss: 17.2890, val_MinusLogProbMetric: 17.2890

Epoch 67: val_loss improved from 17.36208 to 17.28900, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 17.4630 - MinusLogProbMetric: 17.4630 - val_loss: 17.2890 - val_MinusLogProbMetric: 17.2890 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 68/1000
2023-09-20 14:30:50.730 
Epoch 68/1000 
	 loss: 17.4380, MinusLogProbMetric: 17.4380, val_loss: 17.8349, val_MinusLogProbMetric: 17.8349

Epoch 68: val_loss did not improve from 17.28900
196/196 - 43s - loss: 17.4380 - MinusLogProbMetric: 17.4380 - val_loss: 17.8349 - val_MinusLogProbMetric: 17.8349 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 69/1000
2023-09-20 14:31:34.088 
Epoch 69/1000 
	 loss: 17.4761, MinusLogProbMetric: 17.4761, val_loss: 17.7611, val_MinusLogProbMetric: 17.7611

Epoch 69: val_loss did not improve from 17.28900
196/196 - 43s - loss: 17.4761 - MinusLogProbMetric: 17.4761 - val_loss: 17.7611 - val_MinusLogProbMetric: 17.7611 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 70/1000
2023-09-20 14:32:17.213 
Epoch 70/1000 
	 loss: 17.4030, MinusLogProbMetric: 17.4030, val_loss: 20.2480, val_MinusLogProbMetric: 20.2480

Epoch 70: val_loss did not improve from 17.28900
196/196 - 43s - loss: 17.4030 - MinusLogProbMetric: 17.4030 - val_loss: 20.2480 - val_MinusLogProbMetric: 20.2480 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 71/1000
2023-09-20 14:33:00.006 
Epoch 71/1000 
	 loss: 17.4662, MinusLogProbMetric: 17.4662, val_loss: 18.5266, val_MinusLogProbMetric: 18.5266

Epoch 71: val_loss did not improve from 17.28900
196/196 - 43s - loss: 17.4662 - MinusLogProbMetric: 17.4662 - val_loss: 18.5266 - val_MinusLogProbMetric: 18.5266 - lr: 0.0010 - 43s/epoch - 218ms/step
Epoch 72/1000
2023-09-20 14:33:43.382 
Epoch 72/1000 
	 loss: 17.3991, MinusLogProbMetric: 17.3991, val_loss: 17.4987, val_MinusLogProbMetric: 17.4987

Epoch 72: val_loss did not improve from 17.28900
196/196 - 43s - loss: 17.3991 - MinusLogProbMetric: 17.3991 - val_loss: 17.4987 - val_MinusLogProbMetric: 17.4987 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 73/1000
2023-09-20 14:34:26.842 
Epoch 73/1000 
	 loss: 17.4635, MinusLogProbMetric: 17.4635, val_loss: 17.7206, val_MinusLogProbMetric: 17.7206

Epoch 73: val_loss did not improve from 17.28900
196/196 - 43s - loss: 17.4635 - MinusLogProbMetric: 17.4635 - val_loss: 17.7206 - val_MinusLogProbMetric: 17.7206 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 74/1000
2023-09-20 14:35:10.012 
Epoch 74/1000 
	 loss: 17.3698, MinusLogProbMetric: 17.3698, val_loss: 17.5281, val_MinusLogProbMetric: 17.5281

Epoch 74: val_loss did not improve from 17.28900
196/196 - 43s - loss: 17.3698 - MinusLogProbMetric: 17.3698 - val_loss: 17.5281 - val_MinusLogProbMetric: 17.5281 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 75/1000
2023-09-20 14:35:53.169 
Epoch 75/1000 
	 loss: 17.3556, MinusLogProbMetric: 17.3556, val_loss: 17.2792, val_MinusLogProbMetric: 17.2792

Epoch 75: val_loss improved from 17.28900 to 17.27919, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 17.3556 - MinusLogProbMetric: 17.3556 - val_loss: 17.2792 - val_MinusLogProbMetric: 17.2792 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 76/1000
2023-09-20 14:36:37.430 
Epoch 76/1000 
	 loss: 17.3730, MinusLogProbMetric: 17.3730, val_loss: 17.4966, val_MinusLogProbMetric: 17.4966

Epoch 76: val_loss did not improve from 17.27919
196/196 - 43s - loss: 17.3730 - MinusLogProbMetric: 17.3730 - val_loss: 17.4966 - val_MinusLogProbMetric: 17.4966 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 77/1000
2023-09-20 14:37:20.564 
Epoch 77/1000 
	 loss: 17.3448, MinusLogProbMetric: 17.3448, val_loss: 17.6006, val_MinusLogProbMetric: 17.6006

Epoch 77: val_loss did not improve from 17.27919
196/196 - 43s - loss: 17.3448 - MinusLogProbMetric: 17.3448 - val_loss: 17.6006 - val_MinusLogProbMetric: 17.6006 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 78/1000
2023-09-20 14:38:03.886 
Epoch 78/1000 
	 loss: 17.3814, MinusLogProbMetric: 17.3814, val_loss: 18.0589, val_MinusLogProbMetric: 18.0589

Epoch 78: val_loss did not improve from 17.27919
196/196 - 43s - loss: 17.3814 - MinusLogProbMetric: 17.3814 - val_loss: 18.0589 - val_MinusLogProbMetric: 18.0589 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 79/1000
2023-09-20 14:38:47.355 
Epoch 79/1000 
	 loss: 17.3500, MinusLogProbMetric: 17.3500, val_loss: 18.2188, val_MinusLogProbMetric: 18.2188

Epoch 79: val_loss did not improve from 17.27919
196/196 - 43s - loss: 17.3500 - MinusLogProbMetric: 17.3500 - val_loss: 18.2188 - val_MinusLogProbMetric: 18.2188 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 80/1000
2023-09-20 14:39:30.755 
Epoch 80/1000 
	 loss: 17.3630, MinusLogProbMetric: 17.3630, val_loss: 17.5759, val_MinusLogProbMetric: 17.5759

Epoch 80: val_loss did not improve from 17.27919
196/196 - 43s - loss: 17.3630 - MinusLogProbMetric: 17.3630 - val_loss: 17.5759 - val_MinusLogProbMetric: 17.5759 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 81/1000
2023-09-20 14:40:14.151 
Epoch 81/1000 
	 loss: 17.2818, MinusLogProbMetric: 17.2818, val_loss: 17.3836, val_MinusLogProbMetric: 17.3836

Epoch 81: val_loss did not improve from 17.27919
196/196 - 43s - loss: 17.2818 - MinusLogProbMetric: 17.2818 - val_loss: 17.3836 - val_MinusLogProbMetric: 17.3836 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 82/1000
2023-09-20 14:40:57.294 
Epoch 82/1000 
	 loss: 17.3220, MinusLogProbMetric: 17.3220, val_loss: 17.6425, val_MinusLogProbMetric: 17.6425

Epoch 82: val_loss did not improve from 17.27919
196/196 - 43s - loss: 17.3220 - MinusLogProbMetric: 17.3220 - val_loss: 17.6425 - val_MinusLogProbMetric: 17.6425 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 83/1000
2023-09-20 14:41:40.787 
Epoch 83/1000 
	 loss: 17.3236, MinusLogProbMetric: 17.3236, val_loss: 17.3777, val_MinusLogProbMetric: 17.3777

Epoch 83: val_loss did not improve from 17.27919
196/196 - 43s - loss: 17.3236 - MinusLogProbMetric: 17.3236 - val_loss: 17.3777 - val_MinusLogProbMetric: 17.3777 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 84/1000
2023-09-20 14:42:23.994 
Epoch 84/1000 
	 loss: 17.3542, MinusLogProbMetric: 17.3542, val_loss: 17.3788, val_MinusLogProbMetric: 17.3788

Epoch 84: val_loss did not improve from 17.27919
196/196 - 43s - loss: 17.3542 - MinusLogProbMetric: 17.3542 - val_loss: 17.3788 - val_MinusLogProbMetric: 17.3788 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 85/1000
2023-09-20 14:43:07.127 
Epoch 85/1000 
	 loss: 17.3013, MinusLogProbMetric: 17.3013, val_loss: 17.4499, val_MinusLogProbMetric: 17.4499

Epoch 85: val_loss did not improve from 17.27919
196/196 - 43s - loss: 17.3013 - MinusLogProbMetric: 17.3013 - val_loss: 17.4499 - val_MinusLogProbMetric: 17.4499 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 86/1000
2023-09-20 14:43:49.948 
Epoch 86/1000 
	 loss: 17.3066, MinusLogProbMetric: 17.3066, val_loss: 17.1958, val_MinusLogProbMetric: 17.1958

Epoch 86: val_loss improved from 17.27919 to 17.19581, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 17.3066 - MinusLogProbMetric: 17.3066 - val_loss: 17.1958 - val_MinusLogProbMetric: 17.1958 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 87/1000
2023-09-20 14:44:34.243 
Epoch 87/1000 
	 loss: 17.2697, MinusLogProbMetric: 17.2697, val_loss: 18.2653, val_MinusLogProbMetric: 18.2653

Epoch 87: val_loss did not improve from 17.19581
196/196 - 43s - loss: 17.2697 - MinusLogProbMetric: 17.2697 - val_loss: 18.2653 - val_MinusLogProbMetric: 18.2653 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 88/1000
2023-09-20 14:45:17.561 
Epoch 88/1000 
	 loss: 17.3151, MinusLogProbMetric: 17.3151, val_loss: 17.3501, val_MinusLogProbMetric: 17.3501

Epoch 88: val_loss did not improve from 17.19581
196/196 - 43s - loss: 17.3151 - MinusLogProbMetric: 17.3151 - val_loss: 17.3501 - val_MinusLogProbMetric: 17.3501 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 89/1000
2023-09-20 14:46:01.256 
Epoch 89/1000 
	 loss: 17.2446, MinusLogProbMetric: 17.2446, val_loss: 17.3934, val_MinusLogProbMetric: 17.3934

Epoch 89: val_loss did not improve from 17.19581
196/196 - 44s - loss: 17.2446 - MinusLogProbMetric: 17.2446 - val_loss: 17.3934 - val_MinusLogProbMetric: 17.3934 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 90/1000
2023-09-20 14:46:45.364 
Epoch 90/1000 
	 loss: 17.2725, MinusLogProbMetric: 17.2725, val_loss: 17.2771, val_MinusLogProbMetric: 17.2771

Epoch 90: val_loss did not improve from 17.19581
196/196 - 44s - loss: 17.2725 - MinusLogProbMetric: 17.2725 - val_loss: 17.2771 - val_MinusLogProbMetric: 17.2771 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 91/1000
2023-09-20 14:47:28.676 
Epoch 91/1000 
	 loss: 17.2231, MinusLogProbMetric: 17.2231, val_loss: 17.2358, val_MinusLogProbMetric: 17.2358

Epoch 91: val_loss did not improve from 17.19581
196/196 - 43s - loss: 17.2231 - MinusLogProbMetric: 17.2231 - val_loss: 17.2358 - val_MinusLogProbMetric: 17.2358 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 92/1000
2023-09-20 14:48:12.104 
Epoch 92/1000 
	 loss: 17.2744, MinusLogProbMetric: 17.2744, val_loss: 17.6578, val_MinusLogProbMetric: 17.6578

Epoch 92: val_loss did not improve from 17.19581
196/196 - 43s - loss: 17.2744 - MinusLogProbMetric: 17.2744 - val_loss: 17.6578 - val_MinusLogProbMetric: 17.6578 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 93/1000
2023-09-20 14:48:55.634 
Epoch 93/1000 
	 loss: 17.2606, MinusLogProbMetric: 17.2606, val_loss: 17.2966, val_MinusLogProbMetric: 17.2966

Epoch 93: val_loss did not improve from 17.19581
196/196 - 44s - loss: 17.2606 - MinusLogProbMetric: 17.2606 - val_loss: 17.2966 - val_MinusLogProbMetric: 17.2966 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 94/1000
2023-09-20 14:49:39.004 
Epoch 94/1000 
	 loss: 17.2386, MinusLogProbMetric: 17.2386, val_loss: 17.3340, val_MinusLogProbMetric: 17.3340

Epoch 94: val_loss did not improve from 17.19581
196/196 - 43s - loss: 17.2386 - MinusLogProbMetric: 17.2386 - val_loss: 17.3340 - val_MinusLogProbMetric: 17.3340 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 95/1000
2023-09-20 14:50:22.148 
Epoch 95/1000 
	 loss: 17.2675, MinusLogProbMetric: 17.2675, val_loss: 17.3104, val_MinusLogProbMetric: 17.3104

Epoch 95: val_loss did not improve from 17.19581
196/196 - 43s - loss: 17.2675 - MinusLogProbMetric: 17.2675 - val_loss: 17.3104 - val_MinusLogProbMetric: 17.3104 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 96/1000
2023-09-20 14:51:05.791 
Epoch 96/1000 
	 loss: 17.1913, MinusLogProbMetric: 17.1913, val_loss: 17.3175, val_MinusLogProbMetric: 17.3175

Epoch 96: val_loss did not improve from 17.19581
196/196 - 44s - loss: 17.1913 - MinusLogProbMetric: 17.1913 - val_loss: 17.3175 - val_MinusLogProbMetric: 17.3175 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 97/1000
2023-09-20 14:51:49.481 
Epoch 97/1000 
	 loss: 17.2333, MinusLogProbMetric: 17.2333, val_loss: 17.2104, val_MinusLogProbMetric: 17.2104

Epoch 97: val_loss did not improve from 17.19581
196/196 - 44s - loss: 17.2333 - MinusLogProbMetric: 17.2333 - val_loss: 17.2104 - val_MinusLogProbMetric: 17.2104 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 98/1000
2023-09-20 14:52:33.413 
Epoch 98/1000 
	 loss: 17.2066, MinusLogProbMetric: 17.2066, val_loss: 17.3068, val_MinusLogProbMetric: 17.3068

Epoch 98: val_loss did not improve from 17.19581
196/196 - 44s - loss: 17.2066 - MinusLogProbMetric: 17.2066 - val_loss: 17.3068 - val_MinusLogProbMetric: 17.3068 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 99/1000
2023-09-20 14:53:16.823 
Epoch 99/1000 
	 loss: 17.1820, MinusLogProbMetric: 17.1820, val_loss: 17.2459, val_MinusLogProbMetric: 17.2459

Epoch 99: val_loss did not improve from 17.19581
196/196 - 43s - loss: 17.1820 - MinusLogProbMetric: 17.1820 - val_loss: 17.2459 - val_MinusLogProbMetric: 17.2459 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 100/1000
2023-09-20 14:53:59.655 
Epoch 100/1000 
	 loss: 17.1786, MinusLogProbMetric: 17.1786, val_loss: 17.2063, val_MinusLogProbMetric: 17.2063

Epoch 100: val_loss did not improve from 17.19581
196/196 - 43s - loss: 17.1786 - MinusLogProbMetric: 17.1786 - val_loss: 17.2063 - val_MinusLogProbMetric: 17.2063 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 101/1000
2023-09-20 14:54:42.945 
Epoch 101/1000 
	 loss: 17.2132, MinusLogProbMetric: 17.2132, val_loss: 17.1507, val_MinusLogProbMetric: 17.1507

Epoch 101: val_loss improved from 17.19581 to 17.15068, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 17.2132 - MinusLogProbMetric: 17.2132 - val_loss: 17.1507 - val_MinusLogProbMetric: 17.1507 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 102/1000
2023-09-20 14:55:27.134 
Epoch 102/1000 
	 loss: 17.1949, MinusLogProbMetric: 17.1949, val_loss: 17.3111, val_MinusLogProbMetric: 17.3111

Epoch 102: val_loss did not improve from 17.15068
196/196 - 43s - loss: 17.1949 - MinusLogProbMetric: 17.1949 - val_loss: 17.3111 - val_MinusLogProbMetric: 17.3111 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 103/1000
2023-09-20 14:56:10.488 
Epoch 103/1000 
	 loss: 17.2066, MinusLogProbMetric: 17.2066, val_loss: 17.3149, val_MinusLogProbMetric: 17.3149

Epoch 103: val_loss did not improve from 17.15068
196/196 - 43s - loss: 17.2066 - MinusLogProbMetric: 17.2066 - val_loss: 17.3149 - val_MinusLogProbMetric: 17.3149 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 104/1000
2023-09-20 14:56:54.129 
Epoch 104/1000 
	 loss: 17.1731, MinusLogProbMetric: 17.1731, val_loss: 17.1819, val_MinusLogProbMetric: 17.1819

Epoch 104: val_loss did not improve from 17.15068
196/196 - 44s - loss: 17.1731 - MinusLogProbMetric: 17.1731 - val_loss: 17.1819 - val_MinusLogProbMetric: 17.1819 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 105/1000
2023-09-20 14:57:37.139 
Epoch 105/1000 
	 loss: 17.1649, MinusLogProbMetric: 17.1649, val_loss: 17.1001, val_MinusLogProbMetric: 17.1001

Epoch 105: val_loss improved from 17.15068 to 17.10008, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 17.1649 - MinusLogProbMetric: 17.1649 - val_loss: 17.1001 - val_MinusLogProbMetric: 17.1001 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 106/1000
2023-09-20 14:58:21.349 
Epoch 106/1000 
	 loss: 17.1500, MinusLogProbMetric: 17.1500, val_loss: 17.3250, val_MinusLogProbMetric: 17.3250

Epoch 106: val_loss did not improve from 17.10008
196/196 - 43s - loss: 17.1500 - MinusLogProbMetric: 17.1500 - val_loss: 17.3250 - val_MinusLogProbMetric: 17.3250 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 107/1000
2023-09-20 14:59:04.734 
Epoch 107/1000 
	 loss: 17.2775, MinusLogProbMetric: 17.2775, val_loss: 17.1205, val_MinusLogProbMetric: 17.1205

Epoch 107: val_loss did not improve from 17.10008
196/196 - 43s - loss: 17.2775 - MinusLogProbMetric: 17.2775 - val_loss: 17.1205 - val_MinusLogProbMetric: 17.1205 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 108/1000
2023-09-20 14:59:47.409 
Epoch 108/1000 
	 loss: 17.1122, MinusLogProbMetric: 17.1122, val_loss: 17.0984, val_MinusLogProbMetric: 17.0984

Epoch 108: val_loss improved from 17.10008 to 17.09836, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 17.1122 - MinusLogProbMetric: 17.1122 - val_loss: 17.0984 - val_MinusLogProbMetric: 17.0984 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 109/1000
2023-09-20 15:00:31.402 
Epoch 109/1000 
	 loss: 17.0964, MinusLogProbMetric: 17.0964, val_loss: 17.2118, val_MinusLogProbMetric: 17.2118

Epoch 109: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.0964 - MinusLogProbMetric: 17.0964 - val_loss: 17.2118 - val_MinusLogProbMetric: 17.2118 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 110/1000
2023-09-20 15:01:14.319 
Epoch 110/1000 
	 loss: 17.1606, MinusLogProbMetric: 17.1606, val_loss: 17.1800, val_MinusLogProbMetric: 17.1800

Epoch 110: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.1606 - MinusLogProbMetric: 17.1606 - val_loss: 17.1800 - val_MinusLogProbMetric: 17.1800 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 111/1000
2023-09-20 15:01:57.688 
Epoch 111/1000 
	 loss: 17.1529, MinusLogProbMetric: 17.1529, val_loss: 17.2265, val_MinusLogProbMetric: 17.2265

Epoch 111: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.1529 - MinusLogProbMetric: 17.1529 - val_loss: 17.2265 - val_MinusLogProbMetric: 17.2265 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 112/1000
2023-09-20 15:02:40.956 
Epoch 112/1000 
	 loss: 17.1804, MinusLogProbMetric: 17.1804, val_loss: 17.6610, val_MinusLogProbMetric: 17.6610

Epoch 112: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.1804 - MinusLogProbMetric: 17.1804 - val_loss: 17.6610 - val_MinusLogProbMetric: 17.6610 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 113/1000
2023-09-20 15:03:24.037 
Epoch 113/1000 
	 loss: 17.2227, MinusLogProbMetric: 17.2227, val_loss: 17.1738, val_MinusLogProbMetric: 17.1738

Epoch 113: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.2227 - MinusLogProbMetric: 17.2227 - val_loss: 17.1738 - val_MinusLogProbMetric: 17.1738 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 114/1000
2023-09-20 15:04:07.247 
Epoch 114/1000 
	 loss: 17.1598, MinusLogProbMetric: 17.1598, val_loss: 17.2389, val_MinusLogProbMetric: 17.2389

Epoch 114: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.1598 - MinusLogProbMetric: 17.1598 - val_loss: 17.2389 - val_MinusLogProbMetric: 17.2389 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 115/1000
2023-09-20 15:04:50.436 
Epoch 115/1000 
	 loss: 17.1132, MinusLogProbMetric: 17.1132, val_loss: 17.3474, val_MinusLogProbMetric: 17.3474

Epoch 115: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.1132 - MinusLogProbMetric: 17.1132 - val_loss: 17.3474 - val_MinusLogProbMetric: 17.3474 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 116/1000
2023-09-20 15:05:33.491 
Epoch 116/1000 
	 loss: 17.1088, MinusLogProbMetric: 17.1088, val_loss: 17.1815, val_MinusLogProbMetric: 17.1815

Epoch 116: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.1088 - MinusLogProbMetric: 17.1088 - val_loss: 17.1815 - val_MinusLogProbMetric: 17.1815 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 117/1000
2023-09-20 15:06:16.926 
Epoch 117/1000 
	 loss: 17.1128, MinusLogProbMetric: 17.1128, val_loss: 17.2232, val_MinusLogProbMetric: 17.2232

Epoch 117: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.1128 - MinusLogProbMetric: 17.1128 - val_loss: 17.2232 - val_MinusLogProbMetric: 17.2232 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 118/1000
2023-09-20 15:07:00.278 
Epoch 118/1000 
	 loss: 17.0743, MinusLogProbMetric: 17.0743, val_loss: 17.2371, val_MinusLogProbMetric: 17.2371

Epoch 118: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.0743 - MinusLogProbMetric: 17.0743 - val_loss: 17.2371 - val_MinusLogProbMetric: 17.2371 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 119/1000
2023-09-20 15:07:43.408 
Epoch 119/1000 
	 loss: 17.0405, MinusLogProbMetric: 17.0405, val_loss: 17.1808, val_MinusLogProbMetric: 17.1808

Epoch 119: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.0405 - MinusLogProbMetric: 17.0405 - val_loss: 17.1808 - val_MinusLogProbMetric: 17.1808 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 120/1000
2023-09-20 15:08:26.336 
Epoch 120/1000 
	 loss: 17.1025, MinusLogProbMetric: 17.1025, val_loss: 17.1909, val_MinusLogProbMetric: 17.1909

Epoch 120: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.1025 - MinusLogProbMetric: 17.1025 - val_loss: 17.1909 - val_MinusLogProbMetric: 17.1909 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 121/1000
2023-09-20 15:09:09.250 
Epoch 121/1000 
	 loss: 17.0577, MinusLogProbMetric: 17.0577, val_loss: 17.2280, val_MinusLogProbMetric: 17.2280

Epoch 121: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.0577 - MinusLogProbMetric: 17.0577 - val_loss: 17.2280 - val_MinusLogProbMetric: 17.2280 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 122/1000
2023-09-20 15:09:52.601 
Epoch 122/1000 
	 loss: 17.0599, MinusLogProbMetric: 17.0599, val_loss: 17.1379, val_MinusLogProbMetric: 17.1379

Epoch 122: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.0599 - MinusLogProbMetric: 17.0599 - val_loss: 17.1379 - val_MinusLogProbMetric: 17.1379 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 123/1000
2023-09-20 15:10:35.546 
Epoch 123/1000 
	 loss: 17.1278, MinusLogProbMetric: 17.1278, val_loss: 17.2531, val_MinusLogProbMetric: 17.2531

Epoch 123: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.1278 - MinusLogProbMetric: 17.1278 - val_loss: 17.2531 - val_MinusLogProbMetric: 17.2531 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 124/1000
2023-09-20 15:11:18.608 
Epoch 124/1000 
	 loss: 17.0301, MinusLogProbMetric: 17.0301, val_loss: 17.3763, val_MinusLogProbMetric: 17.3763

Epoch 124: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.0301 - MinusLogProbMetric: 17.0301 - val_loss: 17.3763 - val_MinusLogProbMetric: 17.3763 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 125/1000
2023-09-20 15:12:01.739 
Epoch 125/1000 
	 loss: 17.0840, MinusLogProbMetric: 17.0840, val_loss: 17.1713, val_MinusLogProbMetric: 17.1713

Epoch 125: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.0840 - MinusLogProbMetric: 17.0840 - val_loss: 17.1713 - val_MinusLogProbMetric: 17.1713 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 126/1000
2023-09-20 15:12:45.100 
Epoch 126/1000 
	 loss: 17.1257, MinusLogProbMetric: 17.1257, val_loss: 17.3565, val_MinusLogProbMetric: 17.3565

Epoch 126: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.1257 - MinusLogProbMetric: 17.1257 - val_loss: 17.3565 - val_MinusLogProbMetric: 17.3565 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 127/1000
2023-09-20 15:13:28.210 
Epoch 127/1000 
	 loss: 17.0558, MinusLogProbMetric: 17.0558, val_loss: 17.5395, val_MinusLogProbMetric: 17.5395

Epoch 127: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.0558 - MinusLogProbMetric: 17.0558 - val_loss: 17.5395 - val_MinusLogProbMetric: 17.5395 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 128/1000
2023-09-20 15:14:11.510 
Epoch 128/1000 
	 loss: 17.0761, MinusLogProbMetric: 17.0761, val_loss: 17.2879, val_MinusLogProbMetric: 17.2879

Epoch 128: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.0761 - MinusLogProbMetric: 17.0761 - val_loss: 17.2879 - val_MinusLogProbMetric: 17.2879 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 129/1000
2023-09-20 15:14:54.946 
Epoch 129/1000 
	 loss: 17.0262, MinusLogProbMetric: 17.0262, val_loss: 17.1560, val_MinusLogProbMetric: 17.1560

Epoch 129: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.0262 - MinusLogProbMetric: 17.0262 - val_loss: 17.1560 - val_MinusLogProbMetric: 17.1560 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 130/1000
2023-09-20 15:15:38.209 
Epoch 130/1000 
	 loss: 17.1126, MinusLogProbMetric: 17.1126, val_loss: 17.1626, val_MinusLogProbMetric: 17.1626

Epoch 130: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.1126 - MinusLogProbMetric: 17.1126 - val_loss: 17.1626 - val_MinusLogProbMetric: 17.1626 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 131/1000
2023-09-20 15:16:21.079 
Epoch 131/1000 
	 loss: 17.0474, MinusLogProbMetric: 17.0474, val_loss: 17.1671, val_MinusLogProbMetric: 17.1671

Epoch 131: val_loss did not improve from 17.09836
196/196 - 43s - loss: 17.0474 - MinusLogProbMetric: 17.0474 - val_loss: 17.1671 - val_MinusLogProbMetric: 17.1671 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 132/1000
2023-09-20 15:17:04.418 
Epoch 132/1000 
	 loss: 17.0316, MinusLogProbMetric: 17.0316, val_loss: 17.0162, val_MinusLogProbMetric: 17.0162

Epoch 132: val_loss improved from 17.09836 to 17.01625, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 17.0316 - MinusLogProbMetric: 17.0316 - val_loss: 17.0162 - val_MinusLogProbMetric: 17.0162 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 133/1000
2023-09-20 15:17:48.184 
Epoch 133/1000 
	 loss: 17.0077, MinusLogProbMetric: 17.0077, val_loss: 17.1610, val_MinusLogProbMetric: 17.1610

Epoch 133: val_loss did not improve from 17.01625
196/196 - 43s - loss: 17.0077 - MinusLogProbMetric: 17.0077 - val_loss: 17.1610 - val_MinusLogProbMetric: 17.1610 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 134/1000
2023-09-20 15:18:31.617 
Epoch 134/1000 
	 loss: 17.0075, MinusLogProbMetric: 17.0075, val_loss: 17.1125, val_MinusLogProbMetric: 17.1125

Epoch 134: val_loss did not improve from 17.01625
196/196 - 43s - loss: 17.0075 - MinusLogProbMetric: 17.0075 - val_loss: 17.1125 - val_MinusLogProbMetric: 17.1125 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 135/1000
2023-09-20 15:19:14.702 
Epoch 135/1000 
	 loss: 17.0724, MinusLogProbMetric: 17.0724, val_loss: 17.8985, val_MinusLogProbMetric: 17.8985

Epoch 135: val_loss did not improve from 17.01625
196/196 - 43s - loss: 17.0724 - MinusLogProbMetric: 17.0724 - val_loss: 17.8985 - val_MinusLogProbMetric: 17.8985 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 136/1000
2023-09-20 15:19:57.756 
Epoch 136/1000 
	 loss: 17.0297, MinusLogProbMetric: 17.0297, val_loss: 17.2768, val_MinusLogProbMetric: 17.2768

Epoch 136: val_loss did not improve from 17.01625
196/196 - 43s - loss: 17.0297 - MinusLogProbMetric: 17.0297 - val_loss: 17.2768 - val_MinusLogProbMetric: 17.2768 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 137/1000
2023-09-20 15:20:41.048 
Epoch 137/1000 
	 loss: 16.9920, MinusLogProbMetric: 16.9920, val_loss: 17.6670, val_MinusLogProbMetric: 17.6670

Epoch 137: val_loss did not improve from 17.01625
196/196 - 43s - loss: 16.9920 - MinusLogProbMetric: 16.9920 - val_loss: 17.6670 - val_MinusLogProbMetric: 17.6670 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 138/1000
2023-09-20 15:21:24.340 
Epoch 138/1000 
	 loss: 17.0445, MinusLogProbMetric: 17.0445, val_loss: 17.0781, val_MinusLogProbMetric: 17.0781

Epoch 138: val_loss did not improve from 17.01625
196/196 - 43s - loss: 17.0445 - MinusLogProbMetric: 17.0445 - val_loss: 17.0781 - val_MinusLogProbMetric: 17.0781 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 139/1000
2023-09-20 15:22:07.049 
Epoch 139/1000 
	 loss: 17.0163, MinusLogProbMetric: 17.0163, val_loss: 17.2906, val_MinusLogProbMetric: 17.2906

Epoch 139: val_loss did not improve from 17.01625
196/196 - 43s - loss: 17.0163 - MinusLogProbMetric: 17.0163 - val_loss: 17.2906 - val_MinusLogProbMetric: 17.2906 - lr: 0.0010 - 43s/epoch - 218ms/step
Epoch 140/1000
2023-09-20 15:22:50.050 
Epoch 140/1000 
	 loss: 16.9699, MinusLogProbMetric: 16.9699, val_loss: 17.1004, val_MinusLogProbMetric: 17.1004

Epoch 140: val_loss did not improve from 17.01625
196/196 - 43s - loss: 16.9699 - MinusLogProbMetric: 16.9699 - val_loss: 17.1004 - val_MinusLogProbMetric: 17.1004 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 141/1000
2023-09-20 15:23:33.530 
Epoch 141/1000 
	 loss: 17.0114, MinusLogProbMetric: 17.0114, val_loss: 17.0551, val_MinusLogProbMetric: 17.0551

Epoch 141: val_loss did not improve from 17.01625
196/196 - 43s - loss: 17.0114 - MinusLogProbMetric: 17.0114 - val_loss: 17.0551 - val_MinusLogProbMetric: 17.0551 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 142/1000
2023-09-20 15:24:16.549 
Epoch 142/1000 
	 loss: 16.9988, MinusLogProbMetric: 16.9988, val_loss: 17.6972, val_MinusLogProbMetric: 17.6972

Epoch 142: val_loss did not improve from 17.01625
196/196 - 43s - loss: 16.9988 - MinusLogProbMetric: 16.9988 - val_loss: 17.6972 - val_MinusLogProbMetric: 17.6972 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 143/1000
2023-09-20 15:24:59.697 
Epoch 143/1000 
	 loss: 16.9910, MinusLogProbMetric: 16.9910, val_loss: 17.0576, val_MinusLogProbMetric: 17.0576

Epoch 143: val_loss did not improve from 17.01625
196/196 - 43s - loss: 16.9910 - MinusLogProbMetric: 16.9910 - val_loss: 17.0576 - val_MinusLogProbMetric: 17.0576 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 144/1000
2023-09-20 15:25:42.973 
Epoch 144/1000 
	 loss: 16.9840, MinusLogProbMetric: 16.9840, val_loss: 17.0922, val_MinusLogProbMetric: 17.0922

Epoch 144: val_loss did not improve from 17.01625
196/196 - 43s - loss: 16.9840 - MinusLogProbMetric: 16.9840 - val_loss: 17.0922 - val_MinusLogProbMetric: 17.0922 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 145/1000
2023-09-20 15:26:26.018 
Epoch 145/1000 
	 loss: 17.0276, MinusLogProbMetric: 17.0276, val_loss: 17.2677, val_MinusLogProbMetric: 17.2677

Epoch 145: val_loss did not improve from 17.01625
196/196 - 43s - loss: 17.0276 - MinusLogProbMetric: 17.0276 - val_loss: 17.2677 - val_MinusLogProbMetric: 17.2677 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 146/1000
2023-09-20 15:27:09.107 
Epoch 146/1000 
	 loss: 16.9633, MinusLogProbMetric: 16.9633, val_loss: 17.2516, val_MinusLogProbMetric: 17.2516

Epoch 146: val_loss did not improve from 17.01625
196/196 - 43s - loss: 16.9633 - MinusLogProbMetric: 16.9633 - val_loss: 17.2516 - val_MinusLogProbMetric: 17.2516 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 147/1000
2023-09-20 15:27:52.374 
Epoch 147/1000 
	 loss: 16.9935, MinusLogProbMetric: 16.9935, val_loss: 16.9277, val_MinusLogProbMetric: 16.9277

Epoch 147: val_loss improved from 17.01625 to 16.92766, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 16.9935 - MinusLogProbMetric: 16.9935 - val_loss: 16.9277 - val_MinusLogProbMetric: 16.9277 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 148/1000
2023-09-20 15:28:36.336 
Epoch 148/1000 
	 loss: 16.9631, MinusLogProbMetric: 16.9631, val_loss: 16.9310, val_MinusLogProbMetric: 16.9310

Epoch 148: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.9631 - MinusLogProbMetric: 16.9631 - val_loss: 16.9310 - val_MinusLogProbMetric: 16.9310 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 149/1000
2023-09-20 15:29:19.750 
Epoch 149/1000 
	 loss: 16.9553, MinusLogProbMetric: 16.9553, val_loss: 17.1200, val_MinusLogProbMetric: 17.1200

Epoch 149: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.9553 - MinusLogProbMetric: 16.9553 - val_loss: 17.1200 - val_MinusLogProbMetric: 17.1200 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 150/1000
2023-09-20 15:30:02.956 
Epoch 150/1000 
	 loss: 16.9956, MinusLogProbMetric: 16.9956, val_loss: 17.0856, val_MinusLogProbMetric: 17.0856

Epoch 150: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.9956 - MinusLogProbMetric: 16.9956 - val_loss: 17.0856 - val_MinusLogProbMetric: 17.0856 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 151/1000
2023-09-20 15:30:46.065 
Epoch 151/1000 
	 loss: 16.9467, MinusLogProbMetric: 16.9467, val_loss: 16.9858, val_MinusLogProbMetric: 16.9858

Epoch 151: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.9467 - MinusLogProbMetric: 16.9467 - val_loss: 16.9858 - val_MinusLogProbMetric: 16.9858 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 152/1000
2023-09-20 15:31:29.425 
Epoch 152/1000 
	 loss: 17.0224, MinusLogProbMetric: 17.0224, val_loss: 17.0988, val_MinusLogProbMetric: 17.0988

Epoch 152: val_loss did not improve from 16.92766
196/196 - 43s - loss: 17.0224 - MinusLogProbMetric: 17.0224 - val_loss: 17.0988 - val_MinusLogProbMetric: 17.0988 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 153/1000
2023-09-20 15:32:11.197 
Epoch 153/1000 
	 loss: 16.9311, MinusLogProbMetric: 16.9311, val_loss: 17.2915, val_MinusLogProbMetric: 17.2915

Epoch 153: val_loss did not improve from 16.92766
196/196 - 42s - loss: 16.9311 - MinusLogProbMetric: 16.9311 - val_loss: 17.2915 - val_MinusLogProbMetric: 17.2915 - lr: 0.0010 - 42s/epoch - 213ms/step
Epoch 154/1000
2023-09-20 15:32:47.468 
Epoch 154/1000 
	 loss: 16.9845, MinusLogProbMetric: 16.9845, val_loss: 17.1898, val_MinusLogProbMetric: 17.1898

Epoch 154: val_loss did not improve from 16.92766
196/196 - 36s - loss: 16.9845 - MinusLogProbMetric: 16.9845 - val_loss: 17.1898 - val_MinusLogProbMetric: 17.1898 - lr: 0.0010 - 36s/epoch - 185ms/step
Epoch 155/1000
2023-09-20 15:33:22.914 
Epoch 155/1000 
	 loss: 16.9589, MinusLogProbMetric: 16.9589, val_loss: 17.0757, val_MinusLogProbMetric: 17.0757

Epoch 155: val_loss did not improve from 16.92766
196/196 - 35s - loss: 16.9589 - MinusLogProbMetric: 16.9589 - val_loss: 17.0757 - val_MinusLogProbMetric: 17.0757 - lr: 0.0010 - 35s/epoch - 181ms/step
Epoch 156/1000
2023-09-20 15:33:59.209 
Epoch 156/1000 
	 loss: 16.9283, MinusLogProbMetric: 16.9283, val_loss: 17.9460, val_MinusLogProbMetric: 17.9460

Epoch 156: val_loss did not improve from 16.92766
196/196 - 36s - loss: 16.9283 - MinusLogProbMetric: 16.9283 - val_loss: 17.9460 - val_MinusLogProbMetric: 17.9460 - lr: 0.0010 - 36s/epoch - 185ms/step
Epoch 157/1000
2023-09-20 15:34:35.249 
Epoch 157/1000 
	 loss: 16.9631, MinusLogProbMetric: 16.9631, val_loss: 17.3803, val_MinusLogProbMetric: 17.3803

Epoch 157: val_loss did not improve from 16.92766
196/196 - 36s - loss: 16.9631 - MinusLogProbMetric: 16.9631 - val_loss: 17.3803 - val_MinusLogProbMetric: 17.3803 - lr: 0.0010 - 36s/epoch - 184ms/step
Epoch 158/1000
2023-09-20 15:35:12.852 
Epoch 158/1000 
	 loss: 16.9761, MinusLogProbMetric: 16.9761, val_loss: 17.1154, val_MinusLogProbMetric: 17.1154

Epoch 158: val_loss did not improve from 16.92766
196/196 - 38s - loss: 16.9761 - MinusLogProbMetric: 16.9761 - val_loss: 17.1154 - val_MinusLogProbMetric: 17.1154 - lr: 0.0010 - 38s/epoch - 192ms/step
Epoch 159/1000
2023-09-20 15:35:49.587 
Epoch 159/1000 
	 loss: 16.9468, MinusLogProbMetric: 16.9468, val_loss: 17.3982, val_MinusLogProbMetric: 17.3982

Epoch 159: val_loss did not improve from 16.92766
196/196 - 37s - loss: 16.9468 - MinusLogProbMetric: 16.9468 - val_loss: 17.3982 - val_MinusLogProbMetric: 17.3982 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 160/1000
2023-09-20 15:36:26.259 
Epoch 160/1000 
	 loss: 16.9473, MinusLogProbMetric: 16.9473, val_loss: 17.0586, val_MinusLogProbMetric: 17.0586

Epoch 160: val_loss did not improve from 16.92766
196/196 - 37s - loss: 16.9473 - MinusLogProbMetric: 16.9473 - val_loss: 17.0586 - val_MinusLogProbMetric: 17.0586 - lr: 0.0010 - 37s/epoch - 187ms/step
Epoch 161/1000
2023-09-20 15:37:01.041 
Epoch 161/1000 
	 loss: 16.9345, MinusLogProbMetric: 16.9345, val_loss: 17.1776, val_MinusLogProbMetric: 17.1776

Epoch 161: val_loss did not improve from 16.92766
196/196 - 35s - loss: 16.9345 - MinusLogProbMetric: 16.9345 - val_loss: 17.1776 - val_MinusLogProbMetric: 17.1776 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 162/1000
2023-09-20 15:37:39.493 
Epoch 162/1000 
	 loss: 16.9080, MinusLogProbMetric: 16.9080, val_loss: 17.1230, val_MinusLogProbMetric: 17.1230

Epoch 162: val_loss did not improve from 16.92766
196/196 - 38s - loss: 16.9080 - MinusLogProbMetric: 16.9080 - val_loss: 17.1230 - val_MinusLogProbMetric: 17.1230 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 163/1000
2023-09-20 15:38:17.283 
Epoch 163/1000 
	 loss: 16.9462, MinusLogProbMetric: 16.9462, val_loss: 16.9919, val_MinusLogProbMetric: 16.9919

Epoch 163: val_loss did not improve from 16.92766
196/196 - 38s - loss: 16.9462 - MinusLogProbMetric: 16.9462 - val_loss: 16.9919 - val_MinusLogProbMetric: 16.9919 - lr: 0.0010 - 38s/epoch - 193ms/step
Epoch 164/1000
2023-09-20 15:38:54.798 
Epoch 164/1000 
	 loss: 16.9116, MinusLogProbMetric: 16.9116, val_loss: 17.0578, val_MinusLogProbMetric: 17.0578

Epoch 164: val_loss did not improve from 16.92766
196/196 - 38s - loss: 16.9116 - MinusLogProbMetric: 16.9116 - val_loss: 17.0578 - val_MinusLogProbMetric: 17.0578 - lr: 0.0010 - 38s/epoch - 191ms/step
Epoch 165/1000
2023-09-20 15:39:35.752 
Epoch 165/1000 
	 loss: 16.8998, MinusLogProbMetric: 16.8998, val_loss: 17.2174, val_MinusLogProbMetric: 17.2174

Epoch 165: val_loss did not improve from 16.92766
196/196 - 41s - loss: 16.8998 - MinusLogProbMetric: 16.8998 - val_loss: 17.2174 - val_MinusLogProbMetric: 17.2174 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 166/1000
2023-09-20 15:40:14.143 
Epoch 166/1000 
	 loss: 16.9391, MinusLogProbMetric: 16.9391, val_loss: 17.0768, val_MinusLogProbMetric: 17.0768

Epoch 166: val_loss did not improve from 16.92766
196/196 - 38s - loss: 16.9391 - MinusLogProbMetric: 16.9391 - val_loss: 17.0768 - val_MinusLogProbMetric: 17.0768 - lr: 0.0010 - 38s/epoch - 196ms/step
Epoch 167/1000
2023-09-20 15:40:56.408 
Epoch 167/1000 
	 loss: 16.9527, MinusLogProbMetric: 16.9527, val_loss: 17.2570, val_MinusLogProbMetric: 17.2570

Epoch 167: val_loss did not improve from 16.92766
196/196 - 42s - loss: 16.9527 - MinusLogProbMetric: 16.9527 - val_loss: 17.2570 - val_MinusLogProbMetric: 17.2570 - lr: 0.0010 - 42s/epoch - 216ms/step
Epoch 168/1000
2023-09-20 15:41:37.800 
Epoch 168/1000 
	 loss: 16.8856, MinusLogProbMetric: 16.8856, val_loss: 17.0704, val_MinusLogProbMetric: 17.0704

Epoch 168: val_loss did not improve from 16.92766
196/196 - 41s - loss: 16.8856 - MinusLogProbMetric: 16.8856 - val_loss: 17.0704 - val_MinusLogProbMetric: 17.0704 - lr: 0.0010 - 41s/epoch - 211ms/step
Epoch 169/1000
2023-09-20 15:42:20.867 
Epoch 169/1000 
	 loss: 16.9356, MinusLogProbMetric: 16.9356, val_loss: 16.9985, val_MinusLogProbMetric: 16.9985

Epoch 169: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.9356 - MinusLogProbMetric: 16.9356 - val_loss: 16.9985 - val_MinusLogProbMetric: 16.9985 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 170/1000
2023-09-20 15:43:03.910 
Epoch 170/1000 
	 loss: 16.9198, MinusLogProbMetric: 16.9198, val_loss: 17.3370, val_MinusLogProbMetric: 17.3370

Epoch 170: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.9198 - MinusLogProbMetric: 16.9198 - val_loss: 17.3370 - val_MinusLogProbMetric: 17.3370 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 171/1000
2023-09-20 15:43:47.183 
Epoch 171/1000 
	 loss: 16.9290, MinusLogProbMetric: 16.9290, val_loss: 17.0719, val_MinusLogProbMetric: 17.0719

Epoch 171: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.9290 - MinusLogProbMetric: 16.9290 - val_loss: 17.0719 - val_MinusLogProbMetric: 17.0719 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 172/1000
2023-09-20 15:44:29.892 
Epoch 172/1000 
	 loss: 16.9132, MinusLogProbMetric: 16.9132, val_loss: 17.0469, val_MinusLogProbMetric: 17.0469

Epoch 172: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.9132 - MinusLogProbMetric: 16.9132 - val_loss: 17.0469 - val_MinusLogProbMetric: 17.0469 - lr: 0.0010 - 43s/epoch - 218ms/step
Epoch 173/1000
2023-09-20 15:45:12.986 
Epoch 173/1000 
	 loss: 16.8833, MinusLogProbMetric: 16.8833, val_loss: 17.0057, val_MinusLogProbMetric: 17.0057

Epoch 173: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.8833 - MinusLogProbMetric: 16.8833 - val_loss: 17.0057 - val_MinusLogProbMetric: 17.0057 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 174/1000
2023-09-20 15:45:56.270 
Epoch 174/1000 
	 loss: 16.8906, MinusLogProbMetric: 16.8906, val_loss: 17.1307, val_MinusLogProbMetric: 17.1307

Epoch 174: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.8906 - MinusLogProbMetric: 16.8906 - val_loss: 17.1307 - val_MinusLogProbMetric: 17.1307 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 175/1000
2023-09-20 15:46:39.524 
Epoch 175/1000 
	 loss: 16.8838, MinusLogProbMetric: 16.8838, val_loss: 16.9486, val_MinusLogProbMetric: 16.9486

Epoch 175: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.8838 - MinusLogProbMetric: 16.8838 - val_loss: 16.9486 - val_MinusLogProbMetric: 16.9486 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 176/1000
2023-09-20 15:47:22.711 
Epoch 176/1000 
	 loss: 16.8679, MinusLogProbMetric: 16.8679, val_loss: 17.0282, val_MinusLogProbMetric: 17.0282

Epoch 176: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.8679 - MinusLogProbMetric: 16.8679 - val_loss: 17.0282 - val_MinusLogProbMetric: 17.0282 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 177/1000
2023-09-20 15:48:05.943 
Epoch 177/1000 
	 loss: 16.9241, MinusLogProbMetric: 16.9241, val_loss: 16.9907, val_MinusLogProbMetric: 16.9907

Epoch 177: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.9241 - MinusLogProbMetric: 16.9241 - val_loss: 16.9907 - val_MinusLogProbMetric: 16.9907 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 178/1000
2023-09-20 15:48:48.830 
Epoch 178/1000 
	 loss: 16.8673, MinusLogProbMetric: 16.8673, val_loss: 17.2433, val_MinusLogProbMetric: 17.2433

Epoch 178: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.8673 - MinusLogProbMetric: 16.8673 - val_loss: 17.2433 - val_MinusLogProbMetric: 17.2433 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 179/1000
2023-09-20 15:49:31.725 
Epoch 179/1000 
	 loss: 16.8884, MinusLogProbMetric: 16.8884, val_loss: 17.2409, val_MinusLogProbMetric: 17.2409

Epoch 179: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.8884 - MinusLogProbMetric: 16.8884 - val_loss: 17.2409 - val_MinusLogProbMetric: 17.2409 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 180/1000
2023-09-20 15:50:14.413 
Epoch 180/1000 
	 loss: 16.8686, MinusLogProbMetric: 16.8686, val_loss: 17.0330, val_MinusLogProbMetric: 17.0330

Epoch 180: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.8686 - MinusLogProbMetric: 16.8686 - val_loss: 17.0330 - val_MinusLogProbMetric: 17.0330 - lr: 0.0010 - 43s/epoch - 218ms/step
Epoch 181/1000
2023-09-20 15:50:57.263 
Epoch 181/1000 
	 loss: 16.8845, MinusLogProbMetric: 16.8845, val_loss: 17.0275, val_MinusLogProbMetric: 17.0275

Epoch 181: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.8845 - MinusLogProbMetric: 16.8845 - val_loss: 17.0275 - val_MinusLogProbMetric: 17.0275 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 182/1000
2023-09-20 15:51:40.524 
Epoch 182/1000 
	 loss: 16.9064, MinusLogProbMetric: 16.9064, val_loss: 17.2735, val_MinusLogProbMetric: 17.2735

Epoch 182: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.9064 - MinusLogProbMetric: 16.9064 - val_loss: 17.2735 - val_MinusLogProbMetric: 17.2735 - lr: 0.0010 - 43s/epoch - 221ms/step
Epoch 183/1000
2023-09-20 15:52:23.994 
Epoch 183/1000 
	 loss: 16.8948, MinusLogProbMetric: 16.8948, val_loss: 17.1300, val_MinusLogProbMetric: 17.1300

Epoch 183: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.8948 - MinusLogProbMetric: 16.8948 - val_loss: 17.1300 - val_MinusLogProbMetric: 17.1300 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 184/1000
2023-09-20 15:53:07.100 
Epoch 184/1000 
	 loss: 16.8967, MinusLogProbMetric: 16.8967, val_loss: 17.0986, val_MinusLogProbMetric: 17.0986

Epoch 184: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.8967 - MinusLogProbMetric: 16.8967 - val_loss: 17.0986 - val_MinusLogProbMetric: 17.0986 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 185/1000
2023-09-20 15:53:49.807 
Epoch 185/1000 
	 loss: 16.8852, MinusLogProbMetric: 16.8852, val_loss: 16.9620, val_MinusLogProbMetric: 16.9620

Epoch 185: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.8852 - MinusLogProbMetric: 16.8852 - val_loss: 16.9620 - val_MinusLogProbMetric: 16.9620 - lr: 0.0010 - 43s/epoch - 218ms/step
Epoch 186/1000
2023-09-20 15:54:32.403 
Epoch 186/1000 
	 loss: 16.8466, MinusLogProbMetric: 16.8466, val_loss: 17.1291, val_MinusLogProbMetric: 17.1291

Epoch 186: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.8466 - MinusLogProbMetric: 16.8466 - val_loss: 17.1291 - val_MinusLogProbMetric: 17.1291 - lr: 0.0010 - 43s/epoch - 217ms/step
Epoch 187/1000
2023-09-20 15:55:15.258 
Epoch 187/1000 
	 loss: 16.8641, MinusLogProbMetric: 16.8641, val_loss: 17.1691, val_MinusLogProbMetric: 17.1691

Epoch 187: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.8641 - MinusLogProbMetric: 16.8641 - val_loss: 17.1691 - val_MinusLogProbMetric: 17.1691 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 188/1000
2023-09-20 15:55:57.891 
Epoch 188/1000 
	 loss: 16.8830, MinusLogProbMetric: 16.8830, val_loss: 16.9688, val_MinusLogProbMetric: 16.9688

Epoch 188: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.8830 - MinusLogProbMetric: 16.8830 - val_loss: 16.9688 - val_MinusLogProbMetric: 16.9688 - lr: 0.0010 - 43s/epoch - 217ms/step
Epoch 189/1000
2023-09-20 15:56:40.848 
Epoch 189/1000 
	 loss: 16.8434, MinusLogProbMetric: 16.8434, val_loss: 17.0286, val_MinusLogProbMetric: 17.0286

Epoch 189: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.8434 - MinusLogProbMetric: 16.8434 - val_loss: 17.0286 - val_MinusLogProbMetric: 17.0286 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 190/1000
2023-09-20 15:57:23.188 
Epoch 190/1000 
	 loss: 16.8709, MinusLogProbMetric: 16.8709, val_loss: 17.1972, val_MinusLogProbMetric: 17.1972

Epoch 190: val_loss did not improve from 16.92766
196/196 - 42s - loss: 16.8709 - MinusLogProbMetric: 16.8709 - val_loss: 17.1972 - val_MinusLogProbMetric: 17.1972 - lr: 0.0010 - 42s/epoch - 216ms/step
Epoch 191/1000
2023-09-20 15:58:05.505 
Epoch 191/1000 
	 loss: 16.8526, MinusLogProbMetric: 16.8526, val_loss: 17.0753, val_MinusLogProbMetric: 17.0753

Epoch 191: val_loss did not improve from 16.92766
196/196 - 42s - loss: 16.8526 - MinusLogProbMetric: 16.8526 - val_loss: 17.0753 - val_MinusLogProbMetric: 17.0753 - lr: 0.0010 - 42s/epoch - 216ms/step
Epoch 192/1000
2023-09-20 15:58:47.899 
Epoch 192/1000 
	 loss: 16.8783, MinusLogProbMetric: 16.8783, val_loss: 17.0047, val_MinusLogProbMetric: 17.0047

Epoch 192: val_loss did not improve from 16.92766
196/196 - 42s - loss: 16.8783 - MinusLogProbMetric: 16.8783 - val_loss: 17.0047 - val_MinusLogProbMetric: 17.0047 - lr: 0.0010 - 42s/epoch - 216ms/step
Epoch 193/1000
2023-09-20 15:59:29.910 
Epoch 193/1000 
	 loss: 16.8339, MinusLogProbMetric: 16.8339, val_loss: 17.1221, val_MinusLogProbMetric: 17.1221

Epoch 193: val_loss did not improve from 16.92766
196/196 - 42s - loss: 16.8339 - MinusLogProbMetric: 16.8339 - val_loss: 17.1221 - val_MinusLogProbMetric: 17.1221 - lr: 0.0010 - 42s/epoch - 214ms/step
Epoch 194/1000
2023-09-20 16:00:12.625 
Epoch 194/1000 
	 loss: 16.8377, MinusLogProbMetric: 16.8377, val_loss: 17.0322, val_MinusLogProbMetric: 17.0322

Epoch 194: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.8377 - MinusLogProbMetric: 16.8377 - val_loss: 17.0322 - val_MinusLogProbMetric: 17.0322 - lr: 0.0010 - 43s/epoch - 218ms/step
Epoch 195/1000
2023-09-20 16:00:55.147 
Epoch 195/1000 
	 loss: 16.8426, MinusLogProbMetric: 16.8426, val_loss: 16.9518, val_MinusLogProbMetric: 16.9518

Epoch 195: val_loss did not improve from 16.92766
196/196 - 43s - loss: 16.8426 - MinusLogProbMetric: 16.8426 - val_loss: 16.9518 - val_MinusLogProbMetric: 16.9518 - lr: 0.0010 - 43s/epoch - 217ms/step
Epoch 196/1000
2023-09-20 16:01:37.398 
Epoch 196/1000 
	 loss: 16.8633, MinusLogProbMetric: 16.8633, val_loss: 17.0084, val_MinusLogProbMetric: 17.0084

Epoch 196: val_loss did not improve from 16.92766
196/196 - 42s - loss: 16.8633 - MinusLogProbMetric: 16.8633 - val_loss: 17.0084 - val_MinusLogProbMetric: 17.0084 - lr: 0.0010 - 42s/epoch - 216ms/step
Epoch 197/1000
2023-09-20 16:02:19.310 
Epoch 197/1000 
	 loss: 16.8564, MinusLogProbMetric: 16.8564, val_loss: 17.0317, val_MinusLogProbMetric: 17.0317

Epoch 197: val_loss did not improve from 16.92766
196/196 - 42s - loss: 16.8564 - MinusLogProbMetric: 16.8564 - val_loss: 17.0317 - val_MinusLogProbMetric: 17.0317 - lr: 0.0010 - 42s/epoch - 214ms/step
Epoch 198/1000
2023-09-20 16:03:01.524 
Epoch 198/1000 
	 loss: 16.6265, MinusLogProbMetric: 16.6265, val_loss: 16.8356, val_MinusLogProbMetric: 16.8356

Epoch 198: val_loss improved from 16.92766 to 16.83561, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 43s - loss: 16.6265 - MinusLogProbMetric: 16.6265 - val_loss: 16.8356 - val_MinusLogProbMetric: 16.8356 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 199/1000
2023-09-20 16:03:45.432 
Epoch 199/1000 
	 loss: 16.6171, MinusLogProbMetric: 16.6171, val_loss: 16.8186, val_MinusLogProbMetric: 16.8186

Epoch 199: val_loss improved from 16.83561 to 16.81859, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 16.6171 - MinusLogProbMetric: 16.6171 - val_loss: 16.8186 - val_MinusLogProbMetric: 16.8186 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 200/1000
2023-09-20 16:04:29.446 
Epoch 200/1000 
	 loss: 16.6051, MinusLogProbMetric: 16.6051, val_loss: 16.8480, val_MinusLogProbMetric: 16.8480

Epoch 200: val_loss did not improve from 16.81859
196/196 - 43s - loss: 16.6051 - MinusLogProbMetric: 16.6051 - val_loss: 16.8480 - val_MinusLogProbMetric: 16.8480 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 201/1000
2023-09-20 16:05:12.504 
Epoch 201/1000 
	 loss: 16.6018, MinusLogProbMetric: 16.6018, val_loss: 16.9229, val_MinusLogProbMetric: 16.9229

Epoch 201: val_loss did not improve from 16.81859
196/196 - 43s - loss: 16.6018 - MinusLogProbMetric: 16.6018 - val_loss: 16.9229 - val_MinusLogProbMetric: 16.9229 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 202/1000
2023-09-20 16:05:54.618 
Epoch 202/1000 
	 loss: 16.6093, MinusLogProbMetric: 16.6093, val_loss: 16.9788, val_MinusLogProbMetric: 16.9788

Epoch 202: val_loss did not improve from 16.81859
196/196 - 42s - loss: 16.6093 - MinusLogProbMetric: 16.6093 - val_loss: 16.9788 - val_MinusLogProbMetric: 16.9788 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 203/1000
2023-09-20 16:06:37.081 
Epoch 203/1000 
	 loss: 16.6227, MinusLogProbMetric: 16.6227, val_loss: 16.8016, val_MinusLogProbMetric: 16.8016

Epoch 203: val_loss improved from 16.81859 to 16.80157, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 43s - loss: 16.6227 - MinusLogProbMetric: 16.6227 - val_loss: 16.8016 - val_MinusLogProbMetric: 16.8016 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 204/1000
2023-09-20 16:07:19.847 
Epoch 204/1000 
	 loss: 16.6126, MinusLogProbMetric: 16.6126, val_loss: 17.0521, val_MinusLogProbMetric: 17.0521

Epoch 204: val_loss did not improve from 16.80157
196/196 - 42s - loss: 16.6126 - MinusLogProbMetric: 16.6126 - val_loss: 17.0521 - val_MinusLogProbMetric: 17.0521 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 205/1000
2023-09-20 16:08:01.810 
Epoch 205/1000 
	 loss: 16.6112, MinusLogProbMetric: 16.6112, val_loss: 16.7748, val_MinusLogProbMetric: 16.7748

Epoch 205: val_loss improved from 16.80157 to 16.77482, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 43s - loss: 16.6112 - MinusLogProbMetric: 16.6112 - val_loss: 16.7748 - val_MinusLogProbMetric: 16.7748 - lr: 5.0000e-04 - 43s/epoch - 220ms/step
Epoch 206/1000
2023-09-20 16:08:45.235 
Epoch 206/1000 
	 loss: 16.5986, MinusLogProbMetric: 16.5986, val_loss: 16.8024, val_MinusLogProbMetric: 16.8024

Epoch 206: val_loss did not improve from 16.77482
196/196 - 42s - loss: 16.5986 - MinusLogProbMetric: 16.5986 - val_loss: 16.8024 - val_MinusLogProbMetric: 16.8024 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 207/1000
2023-09-20 16:09:27.312 
Epoch 207/1000 
	 loss: 16.6064, MinusLogProbMetric: 16.6064, val_loss: 16.8937, val_MinusLogProbMetric: 16.8937

Epoch 207: val_loss did not improve from 16.77482
196/196 - 42s - loss: 16.6064 - MinusLogProbMetric: 16.6064 - val_loss: 16.8937 - val_MinusLogProbMetric: 16.8937 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 208/1000
2023-09-20 16:10:09.672 
Epoch 208/1000 
	 loss: 16.6085, MinusLogProbMetric: 16.6085, val_loss: 16.8413, val_MinusLogProbMetric: 16.8413

Epoch 208: val_loss did not improve from 16.77482
196/196 - 42s - loss: 16.6085 - MinusLogProbMetric: 16.6085 - val_loss: 16.8413 - val_MinusLogProbMetric: 16.8413 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 209/1000
2023-09-20 16:10:51.639 
Epoch 209/1000 
	 loss: 16.6118, MinusLogProbMetric: 16.6118, val_loss: 16.9651, val_MinusLogProbMetric: 16.9651

Epoch 209: val_loss did not improve from 16.77482
196/196 - 42s - loss: 16.6118 - MinusLogProbMetric: 16.6118 - val_loss: 16.9651 - val_MinusLogProbMetric: 16.9651 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 210/1000
2023-09-20 16:11:33.595 
Epoch 210/1000 
	 loss: 16.6038, MinusLogProbMetric: 16.6038, val_loss: 16.8163, val_MinusLogProbMetric: 16.8163

Epoch 210: val_loss did not improve from 16.77482
196/196 - 42s - loss: 16.6038 - MinusLogProbMetric: 16.6038 - val_loss: 16.8163 - val_MinusLogProbMetric: 16.8163 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 211/1000
2023-09-20 16:12:16.023 
Epoch 211/1000 
	 loss: 16.6236, MinusLogProbMetric: 16.6236, val_loss: 16.8111, val_MinusLogProbMetric: 16.8111

Epoch 211: val_loss did not improve from 16.77482
196/196 - 42s - loss: 16.6236 - MinusLogProbMetric: 16.6236 - val_loss: 16.8111 - val_MinusLogProbMetric: 16.8111 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 212/1000
2023-09-20 16:12:58.073 
Epoch 212/1000 
	 loss: 16.5907, MinusLogProbMetric: 16.5907, val_loss: 16.9317, val_MinusLogProbMetric: 16.9317

Epoch 212: val_loss did not improve from 16.77482
196/196 - 42s - loss: 16.5907 - MinusLogProbMetric: 16.5907 - val_loss: 16.9317 - val_MinusLogProbMetric: 16.9317 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 213/1000
2023-09-20 16:13:40.566 
Epoch 213/1000 
	 loss: 16.6189, MinusLogProbMetric: 16.6189, val_loss: 16.8730, val_MinusLogProbMetric: 16.8730

Epoch 213: val_loss did not improve from 16.77482
196/196 - 42s - loss: 16.6189 - MinusLogProbMetric: 16.6189 - val_loss: 16.8730 - val_MinusLogProbMetric: 16.8730 - lr: 5.0000e-04 - 42s/epoch - 217ms/step
Epoch 214/1000
2023-09-20 16:14:22.615 
Epoch 214/1000 
	 loss: 16.6081, MinusLogProbMetric: 16.6081, val_loss: 16.7969, val_MinusLogProbMetric: 16.7969

Epoch 214: val_loss did not improve from 16.77482
196/196 - 42s - loss: 16.6081 - MinusLogProbMetric: 16.6081 - val_loss: 16.7969 - val_MinusLogProbMetric: 16.7969 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 215/1000
2023-09-20 16:15:04.567 
Epoch 215/1000 
	 loss: 16.5979, MinusLogProbMetric: 16.5979, val_loss: 16.9250, val_MinusLogProbMetric: 16.9250

Epoch 215: val_loss did not improve from 16.77482
196/196 - 42s - loss: 16.5979 - MinusLogProbMetric: 16.5979 - val_loss: 16.9250 - val_MinusLogProbMetric: 16.9250 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 216/1000
2023-09-20 16:15:46.566 
Epoch 216/1000 
	 loss: 16.6050, MinusLogProbMetric: 16.6050, val_loss: 16.8447, val_MinusLogProbMetric: 16.8447

Epoch 216: val_loss did not improve from 16.77482
196/196 - 42s - loss: 16.6050 - MinusLogProbMetric: 16.6050 - val_loss: 16.8447 - val_MinusLogProbMetric: 16.8447 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 217/1000
2023-09-20 16:16:28.707 
Epoch 217/1000 
	 loss: 16.5873, MinusLogProbMetric: 16.5873, val_loss: 16.9103, val_MinusLogProbMetric: 16.9103

Epoch 217: val_loss did not improve from 16.77482
196/196 - 42s - loss: 16.5873 - MinusLogProbMetric: 16.5873 - val_loss: 16.9103 - val_MinusLogProbMetric: 16.9103 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 218/1000
2023-09-20 16:17:10.925 
Epoch 218/1000 
	 loss: 16.5942, MinusLogProbMetric: 16.5942, val_loss: 16.7725, val_MinusLogProbMetric: 16.7725

Epoch 218: val_loss improved from 16.77482 to 16.77255, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 43s - loss: 16.5942 - MinusLogProbMetric: 16.5942 - val_loss: 16.7725 - val_MinusLogProbMetric: 16.7725 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 219/1000
2023-09-20 16:17:53.623 
Epoch 219/1000 
	 loss: 16.5908, MinusLogProbMetric: 16.5908, val_loss: 16.8429, val_MinusLogProbMetric: 16.8429

Epoch 219: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5908 - MinusLogProbMetric: 16.5908 - val_loss: 16.8429 - val_MinusLogProbMetric: 16.8429 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 220/1000
2023-09-20 16:18:35.779 
Epoch 220/1000 
	 loss: 16.5788, MinusLogProbMetric: 16.5788, val_loss: 16.8622, val_MinusLogProbMetric: 16.8622

Epoch 220: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5788 - MinusLogProbMetric: 16.5788 - val_loss: 16.8622 - val_MinusLogProbMetric: 16.8622 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 221/1000
2023-09-20 16:19:17.801 
Epoch 221/1000 
	 loss: 16.5953, MinusLogProbMetric: 16.5953, val_loss: 16.8638, val_MinusLogProbMetric: 16.8638

Epoch 221: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5953 - MinusLogProbMetric: 16.5953 - val_loss: 16.8638 - val_MinusLogProbMetric: 16.8638 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 222/1000
2023-09-20 16:19:59.812 
Epoch 222/1000 
	 loss: 16.6147, MinusLogProbMetric: 16.6147, val_loss: 16.9751, val_MinusLogProbMetric: 16.9751

Epoch 222: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.6147 - MinusLogProbMetric: 16.6147 - val_loss: 16.9751 - val_MinusLogProbMetric: 16.9751 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 223/1000
2023-09-20 16:20:41.650 
Epoch 223/1000 
	 loss: 16.5913, MinusLogProbMetric: 16.5913, val_loss: 16.8525, val_MinusLogProbMetric: 16.8525

Epoch 223: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5913 - MinusLogProbMetric: 16.5913 - val_loss: 16.8525 - val_MinusLogProbMetric: 16.8525 - lr: 5.0000e-04 - 42s/epoch - 213ms/step
Epoch 224/1000
2023-09-20 16:21:23.791 
Epoch 224/1000 
	 loss: 16.5925, MinusLogProbMetric: 16.5925, val_loss: 16.9316, val_MinusLogProbMetric: 16.9316

Epoch 224: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5925 - MinusLogProbMetric: 16.5925 - val_loss: 16.9316 - val_MinusLogProbMetric: 16.9316 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 225/1000
2023-09-20 16:22:05.859 
Epoch 225/1000 
	 loss: 16.6175, MinusLogProbMetric: 16.6175, val_loss: 16.8823, val_MinusLogProbMetric: 16.8823

Epoch 225: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.6175 - MinusLogProbMetric: 16.6175 - val_loss: 16.8823 - val_MinusLogProbMetric: 16.8823 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 226/1000
2023-09-20 16:22:48.278 
Epoch 226/1000 
	 loss: 16.6100, MinusLogProbMetric: 16.6100, val_loss: 16.8029, val_MinusLogProbMetric: 16.8029

Epoch 226: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.6100 - MinusLogProbMetric: 16.6100 - val_loss: 16.8029 - val_MinusLogProbMetric: 16.8029 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 227/1000
2023-09-20 16:23:30.571 
Epoch 227/1000 
	 loss: 16.5964, MinusLogProbMetric: 16.5964, val_loss: 16.8773, val_MinusLogProbMetric: 16.8773

Epoch 227: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5964 - MinusLogProbMetric: 16.5964 - val_loss: 16.8773 - val_MinusLogProbMetric: 16.8773 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 228/1000
2023-09-20 16:24:12.390 
Epoch 228/1000 
	 loss: 16.5853, MinusLogProbMetric: 16.5853, val_loss: 16.8999, val_MinusLogProbMetric: 16.8999

Epoch 228: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5853 - MinusLogProbMetric: 16.5853 - val_loss: 16.8999 - val_MinusLogProbMetric: 16.8999 - lr: 5.0000e-04 - 42s/epoch - 213ms/step
Epoch 229/1000
2023-09-20 16:24:54.653 
Epoch 229/1000 
	 loss: 16.5820, MinusLogProbMetric: 16.5820, val_loss: 16.8727, val_MinusLogProbMetric: 16.8727

Epoch 229: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5820 - MinusLogProbMetric: 16.5820 - val_loss: 16.8727 - val_MinusLogProbMetric: 16.8727 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 230/1000
2023-09-20 16:25:36.638 
Epoch 230/1000 
	 loss: 16.5921, MinusLogProbMetric: 16.5921, val_loss: 16.8371, val_MinusLogProbMetric: 16.8371

Epoch 230: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5921 - MinusLogProbMetric: 16.5921 - val_loss: 16.8371 - val_MinusLogProbMetric: 16.8371 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 231/1000
2023-09-20 16:26:18.531 
Epoch 231/1000 
	 loss: 16.5754, MinusLogProbMetric: 16.5754, val_loss: 16.8804, val_MinusLogProbMetric: 16.8804

Epoch 231: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5754 - MinusLogProbMetric: 16.5754 - val_loss: 16.8804 - val_MinusLogProbMetric: 16.8804 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 232/1000
2023-09-20 16:27:00.876 
Epoch 232/1000 
	 loss: 16.5940, MinusLogProbMetric: 16.5940, val_loss: 16.8003, val_MinusLogProbMetric: 16.8003

Epoch 232: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5940 - MinusLogProbMetric: 16.5940 - val_loss: 16.8003 - val_MinusLogProbMetric: 16.8003 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 233/1000
2023-09-20 16:27:43.149 
Epoch 233/1000 
	 loss: 16.5939, MinusLogProbMetric: 16.5939, val_loss: 16.9319, val_MinusLogProbMetric: 16.9319

Epoch 233: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5939 - MinusLogProbMetric: 16.5939 - val_loss: 16.9319 - val_MinusLogProbMetric: 16.9319 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 234/1000
2023-09-20 16:28:25.567 
Epoch 234/1000 
	 loss: 16.6113, MinusLogProbMetric: 16.6113, val_loss: 16.9459, val_MinusLogProbMetric: 16.9459

Epoch 234: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.6113 - MinusLogProbMetric: 16.6113 - val_loss: 16.9459 - val_MinusLogProbMetric: 16.9459 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 235/1000
2023-09-20 16:29:07.033 
Epoch 235/1000 
	 loss: 16.5817, MinusLogProbMetric: 16.5817, val_loss: 16.8463, val_MinusLogProbMetric: 16.8463

Epoch 235: val_loss did not improve from 16.77255
196/196 - 41s - loss: 16.5817 - MinusLogProbMetric: 16.5817 - val_loss: 16.8463 - val_MinusLogProbMetric: 16.8463 - lr: 5.0000e-04 - 41s/epoch - 212ms/step
Epoch 236/1000
2023-09-20 16:29:49.524 
Epoch 236/1000 
	 loss: 16.5864, MinusLogProbMetric: 16.5864, val_loss: 16.8478, val_MinusLogProbMetric: 16.8478

Epoch 236: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5864 - MinusLogProbMetric: 16.5864 - val_loss: 16.8478 - val_MinusLogProbMetric: 16.8478 - lr: 5.0000e-04 - 42s/epoch - 217ms/step
Epoch 237/1000
2023-09-20 16:30:31.969 
Epoch 237/1000 
	 loss: 16.5870, MinusLogProbMetric: 16.5870, val_loss: 16.7889, val_MinusLogProbMetric: 16.7889

Epoch 237: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5870 - MinusLogProbMetric: 16.5870 - val_loss: 16.7889 - val_MinusLogProbMetric: 16.7889 - lr: 5.0000e-04 - 42s/epoch - 217ms/step
Epoch 238/1000
2023-09-20 16:31:14.399 
Epoch 238/1000 
	 loss: 16.5942, MinusLogProbMetric: 16.5942, val_loss: 16.8919, val_MinusLogProbMetric: 16.8919

Epoch 238: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5942 - MinusLogProbMetric: 16.5942 - val_loss: 16.8919 - val_MinusLogProbMetric: 16.8919 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 239/1000
2023-09-20 16:31:57.153 
Epoch 239/1000 
	 loss: 16.5824, MinusLogProbMetric: 16.5824, val_loss: 16.7764, val_MinusLogProbMetric: 16.7764

Epoch 239: val_loss did not improve from 16.77255
196/196 - 43s - loss: 16.5824 - MinusLogProbMetric: 16.5824 - val_loss: 16.7764 - val_MinusLogProbMetric: 16.7764 - lr: 5.0000e-04 - 43s/epoch - 218ms/step
Epoch 240/1000
2023-09-20 16:32:39.315 
Epoch 240/1000 
	 loss: 16.5936, MinusLogProbMetric: 16.5936, val_loss: 16.8785, val_MinusLogProbMetric: 16.8785

Epoch 240: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5936 - MinusLogProbMetric: 16.5936 - val_loss: 16.8785 - val_MinusLogProbMetric: 16.8785 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 241/1000
2023-09-20 16:33:21.550 
Epoch 241/1000 
	 loss: 16.5734, MinusLogProbMetric: 16.5734, val_loss: 16.9140, val_MinusLogProbMetric: 16.9140

Epoch 241: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5734 - MinusLogProbMetric: 16.5734 - val_loss: 16.9140 - val_MinusLogProbMetric: 16.9140 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 242/1000
2023-09-20 16:34:03.532 
Epoch 242/1000 
	 loss: 16.5952, MinusLogProbMetric: 16.5952, val_loss: 16.8448, val_MinusLogProbMetric: 16.8448

Epoch 242: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5952 - MinusLogProbMetric: 16.5952 - val_loss: 16.8448 - val_MinusLogProbMetric: 16.8448 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 243/1000
2023-09-20 16:34:45.747 
Epoch 243/1000 
	 loss: 16.5889, MinusLogProbMetric: 16.5889, val_loss: 16.8335, val_MinusLogProbMetric: 16.8335

Epoch 243: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5889 - MinusLogProbMetric: 16.5889 - val_loss: 16.8335 - val_MinusLogProbMetric: 16.8335 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 244/1000
2023-09-20 16:35:27.749 
Epoch 244/1000 
	 loss: 16.6013, MinusLogProbMetric: 16.6013, val_loss: 17.0033, val_MinusLogProbMetric: 17.0033

Epoch 244: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.6013 - MinusLogProbMetric: 16.6013 - val_loss: 17.0033 - val_MinusLogProbMetric: 17.0033 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 245/1000
2023-09-20 16:36:10.107 
Epoch 245/1000 
	 loss: 16.5775, MinusLogProbMetric: 16.5775, val_loss: 16.8164, val_MinusLogProbMetric: 16.8164

Epoch 245: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5775 - MinusLogProbMetric: 16.5775 - val_loss: 16.8164 - val_MinusLogProbMetric: 16.8164 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 246/1000
2023-09-20 16:36:51.984 
Epoch 246/1000 
	 loss: 16.5862, MinusLogProbMetric: 16.5862, val_loss: 16.7808, val_MinusLogProbMetric: 16.7808

Epoch 246: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5862 - MinusLogProbMetric: 16.5862 - val_loss: 16.7808 - val_MinusLogProbMetric: 16.7808 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 247/1000
2023-09-20 16:37:34.016 
Epoch 247/1000 
	 loss: 16.5738, MinusLogProbMetric: 16.5738, val_loss: 17.0227, val_MinusLogProbMetric: 17.0227

Epoch 247: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5738 - MinusLogProbMetric: 16.5738 - val_loss: 17.0227 - val_MinusLogProbMetric: 17.0227 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 248/1000
2023-09-20 16:38:16.116 
Epoch 248/1000 
	 loss: 16.5906, MinusLogProbMetric: 16.5906, val_loss: 16.8303, val_MinusLogProbMetric: 16.8303

Epoch 248: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5906 - MinusLogProbMetric: 16.5906 - val_loss: 16.8303 - val_MinusLogProbMetric: 16.8303 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 249/1000
2023-09-20 16:38:58.200 
Epoch 249/1000 
	 loss: 16.5834, MinusLogProbMetric: 16.5834, val_loss: 16.7943, val_MinusLogProbMetric: 16.7943

Epoch 249: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5834 - MinusLogProbMetric: 16.5834 - val_loss: 16.7943 - val_MinusLogProbMetric: 16.7943 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 250/1000
2023-09-20 16:39:40.181 
Epoch 250/1000 
	 loss: 16.5638, MinusLogProbMetric: 16.5638, val_loss: 16.8220, val_MinusLogProbMetric: 16.8220

Epoch 250: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5638 - MinusLogProbMetric: 16.5638 - val_loss: 16.8220 - val_MinusLogProbMetric: 16.8220 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 251/1000
2023-09-20 16:40:22.437 
Epoch 251/1000 
	 loss: 16.5980, MinusLogProbMetric: 16.5980, val_loss: 16.8147, val_MinusLogProbMetric: 16.8147

Epoch 251: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5980 - MinusLogProbMetric: 16.5980 - val_loss: 16.8147 - val_MinusLogProbMetric: 16.8147 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 252/1000
2023-09-20 16:41:04.573 
Epoch 252/1000 
	 loss: 16.5698, MinusLogProbMetric: 16.5698, val_loss: 16.7794, val_MinusLogProbMetric: 16.7794

Epoch 252: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5698 - MinusLogProbMetric: 16.5698 - val_loss: 16.7794 - val_MinusLogProbMetric: 16.7794 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 253/1000
2023-09-20 16:41:46.515 
Epoch 253/1000 
	 loss: 16.5935, MinusLogProbMetric: 16.5935, val_loss: 16.9424, val_MinusLogProbMetric: 16.9424

Epoch 253: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5935 - MinusLogProbMetric: 16.5935 - val_loss: 16.9424 - val_MinusLogProbMetric: 16.9424 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 254/1000
2023-09-20 16:42:28.312 
Epoch 254/1000 
	 loss: 16.5890, MinusLogProbMetric: 16.5890, val_loss: 16.8218, val_MinusLogProbMetric: 16.8218

Epoch 254: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5890 - MinusLogProbMetric: 16.5890 - val_loss: 16.8218 - val_MinusLogProbMetric: 16.8218 - lr: 5.0000e-04 - 42s/epoch - 213ms/step
Epoch 255/1000
2023-09-20 16:43:10.708 
Epoch 255/1000 
	 loss: 16.5670, MinusLogProbMetric: 16.5670, val_loss: 16.8537, val_MinusLogProbMetric: 16.8537

Epoch 255: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5670 - MinusLogProbMetric: 16.5670 - val_loss: 16.8537 - val_MinusLogProbMetric: 16.8537 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 256/1000
2023-09-20 16:43:52.917 
Epoch 256/1000 
	 loss: 16.5785, MinusLogProbMetric: 16.5785, val_loss: 16.8555, val_MinusLogProbMetric: 16.8555

Epoch 256: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5785 - MinusLogProbMetric: 16.5785 - val_loss: 16.8555 - val_MinusLogProbMetric: 16.8555 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 257/1000
2023-09-20 16:44:35.117 
Epoch 257/1000 
	 loss: 16.5751, MinusLogProbMetric: 16.5751, val_loss: 16.9410, val_MinusLogProbMetric: 16.9410

Epoch 257: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5751 - MinusLogProbMetric: 16.5751 - val_loss: 16.9410 - val_MinusLogProbMetric: 16.9410 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 258/1000
2023-09-20 16:45:17.119 
Epoch 258/1000 
	 loss: 16.5848, MinusLogProbMetric: 16.5848, val_loss: 16.8557, val_MinusLogProbMetric: 16.8557

Epoch 258: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5848 - MinusLogProbMetric: 16.5848 - val_loss: 16.8557 - val_MinusLogProbMetric: 16.8557 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 259/1000
2023-09-20 16:45:58.724 
Epoch 259/1000 
	 loss: 16.5558, MinusLogProbMetric: 16.5558, val_loss: 16.8470, val_MinusLogProbMetric: 16.8470

Epoch 259: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5558 - MinusLogProbMetric: 16.5558 - val_loss: 16.8470 - val_MinusLogProbMetric: 16.8470 - lr: 5.0000e-04 - 42s/epoch - 212ms/step
Epoch 260/1000
2023-09-20 16:46:40.821 
Epoch 260/1000 
	 loss: 16.5714, MinusLogProbMetric: 16.5714, val_loss: 16.8095, val_MinusLogProbMetric: 16.8095

Epoch 260: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5714 - MinusLogProbMetric: 16.5714 - val_loss: 16.8095 - val_MinusLogProbMetric: 16.8095 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 261/1000
2023-09-20 16:47:22.852 
Epoch 261/1000 
	 loss: 16.5613, MinusLogProbMetric: 16.5613, val_loss: 16.9158, val_MinusLogProbMetric: 16.9158

Epoch 261: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5613 - MinusLogProbMetric: 16.5613 - val_loss: 16.9158 - val_MinusLogProbMetric: 16.9158 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 262/1000
2023-09-20 16:48:05.136 
Epoch 262/1000 
	 loss: 16.5775, MinusLogProbMetric: 16.5775, val_loss: 16.8217, val_MinusLogProbMetric: 16.8217

Epoch 262: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5775 - MinusLogProbMetric: 16.5775 - val_loss: 16.8217 - val_MinusLogProbMetric: 16.8217 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 263/1000
2023-09-20 16:48:47.276 
Epoch 263/1000 
	 loss: 16.5624, MinusLogProbMetric: 16.5624, val_loss: 16.8092, val_MinusLogProbMetric: 16.8092

Epoch 263: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5624 - MinusLogProbMetric: 16.5624 - val_loss: 16.8092 - val_MinusLogProbMetric: 16.8092 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 264/1000
2023-09-20 16:49:29.891 
Epoch 264/1000 
	 loss: 16.5682, MinusLogProbMetric: 16.5682, val_loss: 16.8438, val_MinusLogProbMetric: 16.8438

Epoch 264: val_loss did not improve from 16.77255
196/196 - 43s - loss: 16.5682 - MinusLogProbMetric: 16.5682 - val_loss: 16.8438 - val_MinusLogProbMetric: 16.8438 - lr: 5.0000e-04 - 43s/epoch - 217ms/step
Epoch 265/1000
2023-09-20 16:50:12.005 
Epoch 265/1000 
	 loss: 16.5628, MinusLogProbMetric: 16.5628, val_loss: 16.7727, val_MinusLogProbMetric: 16.7727

Epoch 265: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5628 - MinusLogProbMetric: 16.5628 - val_loss: 16.7727 - val_MinusLogProbMetric: 16.7727 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 266/1000
2023-09-20 16:50:54.020 
Epoch 266/1000 
	 loss: 16.5640, MinusLogProbMetric: 16.5640, val_loss: 16.9071, val_MinusLogProbMetric: 16.9071

Epoch 266: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5640 - MinusLogProbMetric: 16.5640 - val_loss: 16.9071 - val_MinusLogProbMetric: 16.9071 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 267/1000
2023-09-20 16:51:35.705 
Epoch 267/1000 
	 loss: 16.5802, MinusLogProbMetric: 16.5802, val_loss: 16.7988, val_MinusLogProbMetric: 16.7988

Epoch 267: val_loss did not improve from 16.77255
196/196 - 42s - loss: 16.5802 - MinusLogProbMetric: 16.5802 - val_loss: 16.7988 - val_MinusLogProbMetric: 16.7988 - lr: 5.0000e-04 - 42s/epoch - 213ms/step
Epoch 268/1000
2023-09-20 16:52:17.708 
Epoch 268/1000 
	 loss: 16.5570, MinusLogProbMetric: 16.5570, val_loss: 16.7519, val_MinusLogProbMetric: 16.7519

Epoch 268: val_loss improved from 16.77255 to 16.75192, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 43s - loss: 16.5570 - MinusLogProbMetric: 16.5570 - val_loss: 16.7519 - val_MinusLogProbMetric: 16.7519 - lr: 5.0000e-04 - 43s/epoch - 218ms/step
Epoch 269/1000
2023-09-20 16:53:00.422 
Epoch 269/1000 
	 loss: 16.5683, MinusLogProbMetric: 16.5683, val_loss: 16.8500, val_MinusLogProbMetric: 16.8500

Epoch 269: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5683 - MinusLogProbMetric: 16.5683 - val_loss: 16.8500 - val_MinusLogProbMetric: 16.8500 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 270/1000
2023-09-20 16:53:43.061 
Epoch 270/1000 
	 loss: 16.5606, MinusLogProbMetric: 16.5606, val_loss: 17.0423, val_MinusLogProbMetric: 17.0423

Epoch 270: val_loss did not improve from 16.75192
196/196 - 43s - loss: 16.5606 - MinusLogProbMetric: 16.5606 - val_loss: 17.0423 - val_MinusLogProbMetric: 17.0423 - lr: 5.0000e-04 - 43s/epoch - 218ms/step
Epoch 271/1000
2023-09-20 16:54:25.310 
Epoch 271/1000 
	 loss: 16.5611, MinusLogProbMetric: 16.5611, val_loss: 16.9650, val_MinusLogProbMetric: 16.9650

Epoch 271: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5611 - MinusLogProbMetric: 16.5611 - val_loss: 16.9650 - val_MinusLogProbMetric: 16.9650 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 272/1000
2023-09-20 16:55:07.395 
Epoch 272/1000 
	 loss: 16.5786, MinusLogProbMetric: 16.5786, val_loss: 16.8361, val_MinusLogProbMetric: 16.8361

Epoch 272: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5786 - MinusLogProbMetric: 16.5786 - val_loss: 16.8361 - val_MinusLogProbMetric: 16.8361 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 273/1000
2023-09-20 16:55:49.437 
Epoch 273/1000 
	 loss: 16.5696, MinusLogProbMetric: 16.5696, val_loss: 16.7894, val_MinusLogProbMetric: 16.7894

Epoch 273: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5696 - MinusLogProbMetric: 16.5696 - val_loss: 16.7894 - val_MinusLogProbMetric: 16.7894 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 274/1000
2023-09-20 16:56:31.557 
Epoch 274/1000 
	 loss: 16.5572, MinusLogProbMetric: 16.5572, val_loss: 17.3055, val_MinusLogProbMetric: 17.3055

Epoch 274: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5572 - MinusLogProbMetric: 16.5572 - val_loss: 17.3055 - val_MinusLogProbMetric: 17.3055 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 275/1000
2023-09-20 16:57:13.339 
Epoch 275/1000 
	 loss: 16.5867, MinusLogProbMetric: 16.5867, val_loss: 16.7547, val_MinusLogProbMetric: 16.7547

Epoch 275: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5867 - MinusLogProbMetric: 16.5867 - val_loss: 16.7547 - val_MinusLogProbMetric: 16.7547 - lr: 5.0000e-04 - 42s/epoch - 213ms/step
Epoch 276/1000
2023-09-20 16:57:55.577 
Epoch 276/1000 
	 loss: 16.5576, MinusLogProbMetric: 16.5576, val_loss: 16.9021, val_MinusLogProbMetric: 16.9021

Epoch 276: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5576 - MinusLogProbMetric: 16.5576 - val_loss: 16.9021 - val_MinusLogProbMetric: 16.9021 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 277/1000
2023-09-20 16:58:38.029 
Epoch 277/1000 
	 loss: 16.5887, MinusLogProbMetric: 16.5887, val_loss: 16.8628, val_MinusLogProbMetric: 16.8628

Epoch 277: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5887 - MinusLogProbMetric: 16.5887 - val_loss: 16.8628 - val_MinusLogProbMetric: 16.8628 - lr: 5.0000e-04 - 42s/epoch - 217ms/step
Epoch 278/1000
2023-09-20 16:59:20.498 
Epoch 278/1000 
	 loss: 16.5579, MinusLogProbMetric: 16.5579, val_loss: 16.8835, val_MinusLogProbMetric: 16.8835

Epoch 278: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5579 - MinusLogProbMetric: 16.5579 - val_loss: 16.8835 - val_MinusLogProbMetric: 16.8835 - lr: 5.0000e-04 - 42s/epoch - 217ms/step
Epoch 279/1000
2023-09-20 17:00:02.365 
Epoch 279/1000 
	 loss: 16.5461, MinusLogProbMetric: 16.5461, val_loss: 16.7776, val_MinusLogProbMetric: 16.7776

Epoch 279: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5461 - MinusLogProbMetric: 16.5461 - val_loss: 16.7776 - val_MinusLogProbMetric: 16.7776 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 280/1000
2023-09-20 17:00:43.784 
Epoch 280/1000 
	 loss: 16.5579, MinusLogProbMetric: 16.5579, val_loss: 17.1127, val_MinusLogProbMetric: 17.1127

Epoch 280: val_loss did not improve from 16.75192
196/196 - 41s - loss: 16.5579 - MinusLogProbMetric: 16.5579 - val_loss: 17.1127 - val_MinusLogProbMetric: 17.1127 - lr: 5.0000e-04 - 41s/epoch - 211ms/step
Epoch 281/1000
2023-09-20 17:01:25.992 
Epoch 281/1000 
	 loss: 16.5555, MinusLogProbMetric: 16.5555, val_loss: 16.8323, val_MinusLogProbMetric: 16.8323

Epoch 281: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5555 - MinusLogProbMetric: 16.5555 - val_loss: 16.8323 - val_MinusLogProbMetric: 16.8323 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 282/1000
2023-09-20 17:02:07.843 
Epoch 282/1000 
	 loss: 16.5609, MinusLogProbMetric: 16.5609, val_loss: 16.8040, val_MinusLogProbMetric: 16.8040

Epoch 282: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5609 - MinusLogProbMetric: 16.5609 - val_loss: 16.8040 - val_MinusLogProbMetric: 16.8040 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 283/1000
2023-09-20 17:02:50.033 
Epoch 283/1000 
	 loss: 16.5548, MinusLogProbMetric: 16.5548, val_loss: 16.8342, val_MinusLogProbMetric: 16.8342

Epoch 283: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5548 - MinusLogProbMetric: 16.5548 - val_loss: 16.8342 - val_MinusLogProbMetric: 16.8342 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 284/1000
2023-09-20 17:03:32.287 
Epoch 284/1000 
	 loss: 16.5630, MinusLogProbMetric: 16.5630, val_loss: 17.0098, val_MinusLogProbMetric: 17.0098

Epoch 284: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5630 - MinusLogProbMetric: 16.5630 - val_loss: 17.0098 - val_MinusLogProbMetric: 17.0098 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 285/1000
2023-09-20 17:04:14.435 
Epoch 285/1000 
	 loss: 16.5512, MinusLogProbMetric: 16.5512, val_loss: 16.8558, val_MinusLogProbMetric: 16.8558

Epoch 285: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5512 - MinusLogProbMetric: 16.5512 - val_loss: 16.8558 - val_MinusLogProbMetric: 16.8558 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 286/1000
2023-09-20 17:04:56.929 
Epoch 286/1000 
	 loss: 16.5575, MinusLogProbMetric: 16.5575, val_loss: 16.8543, val_MinusLogProbMetric: 16.8543

Epoch 286: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5575 - MinusLogProbMetric: 16.5575 - val_loss: 16.8543 - val_MinusLogProbMetric: 16.8543 - lr: 5.0000e-04 - 42s/epoch - 217ms/step
Epoch 287/1000
2023-09-20 17:05:39.243 
Epoch 287/1000 
	 loss: 16.5569, MinusLogProbMetric: 16.5569, val_loss: 16.8927, val_MinusLogProbMetric: 16.8927

Epoch 287: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5569 - MinusLogProbMetric: 16.5569 - val_loss: 16.8927 - val_MinusLogProbMetric: 16.8927 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 288/1000
2023-09-20 17:06:21.694 
Epoch 288/1000 
	 loss: 16.5804, MinusLogProbMetric: 16.5804, val_loss: 16.9069, val_MinusLogProbMetric: 16.9069

Epoch 288: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5804 - MinusLogProbMetric: 16.5804 - val_loss: 16.9069 - val_MinusLogProbMetric: 16.9069 - lr: 5.0000e-04 - 42s/epoch - 217ms/step
Epoch 289/1000
2023-09-20 17:07:03.730 
Epoch 289/1000 
	 loss: 16.5465, MinusLogProbMetric: 16.5465, val_loss: 16.7955, val_MinusLogProbMetric: 16.7955

Epoch 289: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5465 - MinusLogProbMetric: 16.5465 - val_loss: 16.7955 - val_MinusLogProbMetric: 16.7955 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 290/1000
2023-09-20 17:07:45.638 
Epoch 290/1000 
	 loss: 16.5475, MinusLogProbMetric: 16.5475, val_loss: 16.8325, val_MinusLogProbMetric: 16.8325

Epoch 290: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5475 - MinusLogProbMetric: 16.5475 - val_loss: 16.8325 - val_MinusLogProbMetric: 16.8325 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 291/1000
2023-09-20 17:08:27.570 
Epoch 291/1000 
	 loss: 16.5738, MinusLogProbMetric: 16.5738, val_loss: 16.7887, val_MinusLogProbMetric: 16.7887

Epoch 291: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5738 - MinusLogProbMetric: 16.5738 - val_loss: 16.7887 - val_MinusLogProbMetric: 16.7887 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 292/1000
2023-09-20 17:09:09.859 
Epoch 292/1000 
	 loss: 16.5526, MinusLogProbMetric: 16.5526, val_loss: 16.8602, val_MinusLogProbMetric: 16.8602

Epoch 292: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5526 - MinusLogProbMetric: 16.5526 - val_loss: 16.8602 - val_MinusLogProbMetric: 16.8602 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 293/1000
2023-09-20 17:09:52.435 
Epoch 293/1000 
	 loss: 16.5486, MinusLogProbMetric: 16.5486, val_loss: 16.8163, val_MinusLogProbMetric: 16.8163

Epoch 293: val_loss did not improve from 16.75192
196/196 - 43s - loss: 16.5486 - MinusLogProbMetric: 16.5486 - val_loss: 16.8163 - val_MinusLogProbMetric: 16.8163 - lr: 5.0000e-04 - 43s/epoch - 217ms/step
Epoch 294/1000
2023-09-20 17:10:35.264 
Epoch 294/1000 
	 loss: 16.5580, MinusLogProbMetric: 16.5580, val_loss: 16.8674, val_MinusLogProbMetric: 16.8674

Epoch 294: val_loss did not improve from 16.75192
196/196 - 43s - loss: 16.5580 - MinusLogProbMetric: 16.5580 - val_loss: 16.8674 - val_MinusLogProbMetric: 16.8674 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 295/1000
2023-09-20 17:11:17.773 
Epoch 295/1000 
	 loss: 16.5563, MinusLogProbMetric: 16.5563, val_loss: 16.8967, val_MinusLogProbMetric: 16.8967

Epoch 295: val_loss did not improve from 16.75192
196/196 - 43s - loss: 16.5563 - MinusLogProbMetric: 16.5563 - val_loss: 16.8967 - val_MinusLogProbMetric: 16.8967 - lr: 5.0000e-04 - 43s/epoch - 217ms/step
Epoch 296/1000
2023-09-20 17:11:59.770 
Epoch 296/1000 
	 loss: 16.5520, MinusLogProbMetric: 16.5520, val_loss: 16.8103, val_MinusLogProbMetric: 16.8103

Epoch 296: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5520 - MinusLogProbMetric: 16.5520 - val_loss: 16.8103 - val_MinusLogProbMetric: 16.8103 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 297/1000
2023-09-20 17:12:42.049 
Epoch 297/1000 
	 loss: 16.5519, MinusLogProbMetric: 16.5519, val_loss: 16.9729, val_MinusLogProbMetric: 16.9729

Epoch 297: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5519 - MinusLogProbMetric: 16.5519 - val_loss: 16.9729 - val_MinusLogProbMetric: 16.9729 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 298/1000
2023-09-20 17:13:23.564 
Epoch 298/1000 
	 loss: 16.5451, MinusLogProbMetric: 16.5451, val_loss: 16.9645, val_MinusLogProbMetric: 16.9645

Epoch 298: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5451 - MinusLogProbMetric: 16.5451 - val_loss: 16.9645 - val_MinusLogProbMetric: 16.9645 - lr: 5.0000e-04 - 42s/epoch - 212ms/step
Epoch 299/1000
2023-09-20 17:14:05.253 
Epoch 299/1000 
	 loss: 16.5529, MinusLogProbMetric: 16.5529, val_loss: 16.8115, val_MinusLogProbMetric: 16.8115

Epoch 299: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5529 - MinusLogProbMetric: 16.5529 - val_loss: 16.8115 - val_MinusLogProbMetric: 16.8115 - lr: 5.0000e-04 - 42s/epoch - 213ms/step
Epoch 300/1000
2023-09-20 17:14:47.202 
Epoch 300/1000 
	 loss: 16.5315, MinusLogProbMetric: 16.5315, val_loss: 16.8333, val_MinusLogProbMetric: 16.8333

Epoch 300: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5315 - MinusLogProbMetric: 16.5315 - val_loss: 16.8333 - val_MinusLogProbMetric: 16.8333 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 301/1000
2023-09-20 17:15:29.126 
Epoch 301/1000 
	 loss: 16.5471, MinusLogProbMetric: 16.5471, val_loss: 16.8242, val_MinusLogProbMetric: 16.8242

Epoch 301: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5471 - MinusLogProbMetric: 16.5471 - val_loss: 16.8242 - val_MinusLogProbMetric: 16.8242 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 302/1000
2023-09-20 17:16:11.322 
Epoch 302/1000 
	 loss: 16.5451, MinusLogProbMetric: 16.5451, val_loss: 16.8039, val_MinusLogProbMetric: 16.8039

Epoch 302: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5451 - MinusLogProbMetric: 16.5451 - val_loss: 16.8039 - val_MinusLogProbMetric: 16.8039 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 303/1000
2023-09-20 17:16:53.695 
Epoch 303/1000 
	 loss: 16.5447, MinusLogProbMetric: 16.5447, val_loss: 16.9517, val_MinusLogProbMetric: 16.9517

Epoch 303: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5447 - MinusLogProbMetric: 16.5447 - val_loss: 16.9517 - val_MinusLogProbMetric: 16.9517 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 304/1000
2023-09-20 17:17:35.778 
Epoch 304/1000 
	 loss: 16.5668, MinusLogProbMetric: 16.5668, val_loss: 16.7819, val_MinusLogProbMetric: 16.7819

Epoch 304: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5668 - MinusLogProbMetric: 16.5668 - val_loss: 16.7819 - val_MinusLogProbMetric: 16.7819 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 305/1000
2023-09-20 17:18:18.059 
Epoch 305/1000 
	 loss: 16.5478, MinusLogProbMetric: 16.5478, val_loss: 16.8107, val_MinusLogProbMetric: 16.8107

Epoch 305: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5478 - MinusLogProbMetric: 16.5478 - val_loss: 16.8107 - val_MinusLogProbMetric: 16.8107 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 306/1000
2023-09-20 17:19:00.204 
Epoch 306/1000 
	 loss: 16.5478, MinusLogProbMetric: 16.5478, val_loss: 16.7917, val_MinusLogProbMetric: 16.7917

Epoch 306: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5478 - MinusLogProbMetric: 16.5478 - val_loss: 16.7917 - val_MinusLogProbMetric: 16.7917 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 307/1000
2023-09-20 17:19:41.822 
Epoch 307/1000 
	 loss: 16.5509, MinusLogProbMetric: 16.5509, val_loss: 16.8535, val_MinusLogProbMetric: 16.8535

Epoch 307: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5509 - MinusLogProbMetric: 16.5509 - val_loss: 16.8535 - val_MinusLogProbMetric: 16.8535 - lr: 5.0000e-04 - 42s/epoch - 212ms/step
Epoch 308/1000
2023-09-20 17:20:23.865 
Epoch 308/1000 
	 loss: 16.5479, MinusLogProbMetric: 16.5479, val_loss: 17.0776, val_MinusLogProbMetric: 17.0776

Epoch 308: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5479 - MinusLogProbMetric: 16.5479 - val_loss: 17.0776 - val_MinusLogProbMetric: 17.0776 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 309/1000
2023-09-20 17:21:05.435 
Epoch 309/1000 
	 loss: 16.5512, MinusLogProbMetric: 16.5512, val_loss: 16.8378, val_MinusLogProbMetric: 16.8378

Epoch 309: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5512 - MinusLogProbMetric: 16.5512 - val_loss: 16.8378 - val_MinusLogProbMetric: 16.8378 - lr: 5.0000e-04 - 42s/epoch - 212ms/step
Epoch 310/1000
2023-09-20 17:21:47.449 
Epoch 310/1000 
	 loss: 16.5509, MinusLogProbMetric: 16.5509, val_loss: 16.8503, val_MinusLogProbMetric: 16.8503

Epoch 310: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5509 - MinusLogProbMetric: 16.5509 - val_loss: 16.8503 - val_MinusLogProbMetric: 16.8503 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 311/1000
2023-09-20 17:22:29.424 
Epoch 311/1000 
	 loss: 16.5433, MinusLogProbMetric: 16.5433, val_loss: 16.8368, val_MinusLogProbMetric: 16.8368

Epoch 311: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5433 - MinusLogProbMetric: 16.5433 - val_loss: 16.8368 - val_MinusLogProbMetric: 16.8368 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 312/1000
2023-09-20 17:23:11.383 
Epoch 312/1000 
	 loss: 16.5201, MinusLogProbMetric: 16.5201, val_loss: 16.8185, val_MinusLogProbMetric: 16.8185

Epoch 312: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5201 - MinusLogProbMetric: 16.5201 - val_loss: 16.8185 - val_MinusLogProbMetric: 16.8185 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 313/1000
2023-09-20 17:23:53.195 
Epoch 313/1000 
	 loss: 16.5317, MinusLogProbMetric: 16.5317, val_loss: 16.9997, val_MinusLogProbMetric: 16.9997

Epoch 313: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5317 - MinusLogProbMetric: 16.5317 - val_loss: 16.9997 - val_MinusLogProbMetric: 16.9997 - lr: 5.0000e-04 - 42s/epoch - 213ms/step
Epoch 314/1000
2023-09-20 17:24:35.005 
Epoch 314/1000 
	 loss: 16.5406, MinusLogProbMetric: 16.5406, val_loss: 16.8399, val_MinusLogProbMetric: 16.8399

Epoch 314: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5406 - MinusLogProbMetric: 16.5406 - val_loss: 16.8399 - val_MinusLogProbMetric: 16.8399 - lr: 5.0000e-04 - 42s/epoch - 213ms/step
Epoch 315/1000
2023-09-20 17:25:17.147 
Epoch 315/1000 
	 loss: 16.5380, MinusLogProbMetric: 16.5380, val_loss: 16.7980, val_MinusLogProbMetric: 16.7980

Epoch 315: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5380 - MinusLogProbMetric: 16.5380 - val_loss: 16.7980 - val_MinusLogProbMetric: 16.7980 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 316/1000
2023-09-20 17:25:59.136 
Epoch 316/1000 
	 loss: 16.5413, MinusLogProbMetric: 16.5413, val_loss: 16.7809, val_MinusLogProbMetric: 16.7809

Epoch 316: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5413 - MinusLogProbMetric: 16.5413 - val_loss: 16.7809 - val_MinusLogProbMetric: 16.7809 - lr: 5.0000e-04 - 42s/epoch - 214ms/step
Epoch 317/1000
2023-09-20 17:26:41.372 
Epoch 317/1000 
	 loss: 16.5348, MinusLogProbMetric: 16.5348, val_loss: 16.8496, val_MinusLogProbMetric: 16.8496

Epoch 317: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5348 - MinusLogProbMetric: 16.5348 - val_loss: 16.8496 - val_MinusLogProbMetric: 16.8496 - lr: 5.0000e-04 - 42s/epoch - 215ms/step
Epoch 318/1000
2023-09-20 17:27:23.803 
Epoch 318/1000 
	 loss: 16.5377, MinusLogProbMetric: 16.5377, val_loss: 16.8650, val_MinusLogProbMetric: 16.8650

Epoch 318: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.5377 - MinusLogProbMetric: 16.5377 - val_loss: 16.8650 - val_MinusLogProbMetric: 16.8650 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 319/1000
2023-09-20 17:28:06.012 
Epoch 319/1000 
	 loss: 16.4478, MinusLogProbMetric: 16.4478, val_loss: 16.7735, val_MinusLogProbMetric: 16.7735

Epoch 319: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.4478 - MinusLogProbMetric: 16.4478 - val_loss: 16.7735 - val_MinusLogProbMetric: 16.7735 - lr: 2.5000e-04 - 42s/epoch - 215ms/step
Epoch 320/1000
2023-09-20 17:28:48.332 
Epoch 320/1000 
	 loss: 16.4546, MinusLogProbMetric: 16.4546, val_loss: 16.7787, val_MinusLogProbMetric: 16.7787

Epoch 320: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.4546 - MinusLogProbMetric: 16.4546 - val_loss: 16.7787 - val_MinusLogProbMetric: 16.7787 - lr: 2.5000e-04 - 42s/epoch - 216ms/step
Epoch 321/1000
2023-09-20 17:29:30.289 
Epoch 321/1000 
	 loss: 16.4434, MinusLogProbMetric: 16.4434, val_loss: 16.8219, val_MinusLogProbMetric: 16.8219

Epoch 321: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.4434 - MinusLogProbMetric: 16.4434 - val_loss: 16.8219 - val_MinusLogProbMetric: 16.8219 - lr: 2.5000e-04 - 42s/epoch - 214ms/step
Epoch 322/1000
2023-09-20 17:30:12.504 
Epoch 322/1000 
	 loss: 16.4478, MinusLogProbMetric: 16.4478, val_loss: 16.7566, val_MinusLogProbMetric: 16.7566

Epoch 322: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.4478 - MinusLogProbMetric: 16.4478 - val_loss: 16.7566 - val_MinusLogProbMetric: 16.7566 - lr: 2.5000e-04 - 42s/epoch - 215ms/step
Epoch 323/1000
2023-09-20 17:30:54.578 
Epoch 323/1000 
	 loss: 16.4391, MinusLogProbMetric: 16.4391, val_loss: 16.7609, val_MinusLogProbMetric: 16.7609

Epoch 323: val_loss did not improve from 16.75192
196/196 - 42s - loss: 16.4391 - MinusLogProbMetric: 16.4391 - val_loss: 16.7609 - val_MinusLogProbMetric: 16.7609 - lr: 2.5000e-04 - 42s/epoch - 215ms/step
Epoch 324/1000
2023-09-20 17:31:36.849 
Epoch 324/1000 
	 loss: 16.4460, MinusLogProbMetric: 16.4460, val_loss: 16.7479, val_MinusLogProbMetric: 16.7479

Epoch 324: val_loss improved from 16.75192 to 16.74788, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 43s - loss: 16.4460 - MinusLogProbMetric: 16.4460 - val_loss: 16.7479 - val_MinusLogProbMetric: 16.7479 - lr: 2.5000e-04 - 43s/epoch - 219ms/step
Epoch 325/1000
2023-09-20 17:32:19.959 
Epoch 325/1000 
	 loss: 16.4454, MinusLogProbMetric: 16.4454, val_loss: 16.7272, val_MinusLogProbMetric: 16.7272

Epoch 325: val_loss improved from 16.74788 to 16.72723, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 44s - loss: 16.4454 - MinusLogProbMetric: 16.4454 - val_loss: 16.7272 - val_MinusLogProbMetric: 16.7272 - lr: 2.5000e-04 - 44s/epoch - 223ms/step
Epoch 326/1000
2023-09-20 17:33:03.326 
Epoch 326/1000 
	 loss: 16.4405, MinusLogProbMetric: 16.4405, val_loss: 16.7372, val_MinusLogProbMetric: 16.7372

Epoch 326: val_loss did not improve from 16.72723
196/196 - 42s - loss: 16.4405 - MinusLogProbMetric: 16.4405 - val_loss: 16.7372 - val_MinusLogProbMetric: 16.7372 - lr: 2.5000e-04 - 42s/epoch - 215ms/step
Epoch 327/1000
2023-09-20 17:33:45.702 
Epoch 327/1000 
	 loss: 16.4471, MinusLogProbMetric: 16.4471, val_loss: 16.8352, val_MinusLogProbMetric: 16.8352

Epoch 327: val_loss did not improve from 16.72723
196/196 - 42s - loss: 16.4471 - MinusLogProbMetric: 16.4471 - val_loss: 16.8352 - val_MinusLogProbMetric: 16.8352 - lr: 2.5000e-04 - 42s/epoch - 216ms/step
Epoch 328/1000
2023-09-20 17:34:28.159 
Epoch 328/1000 
	 loss: 16.4395, MinusLogProbMetric: 16.4395, val_loss: 16.7923, val_MinusLogProbMetric: 16.7923

Epoch 328: val_loss did not improve from 16.72723
196/196 - 42s - loss: 16.4395 - MinusLogProbMetric: 16.4395 - val_loss: 16.7923 - val_MinusLogProbMetric: 16.7923 - lr: 2.5000e-04 - 42s/epoch - 217ms/step
Epoch 329/1000
2023-09-20 17:35:10.563 
Epoch 329/1000 
	 loss: 16.4390, MinusLogProbMetric: 16.4390, val_loss: 16.8782, val_MinusLogProbMetric: 16.8782

Epoch 329: val_loss did not improve from 16.72723
196/196 - 42s - loss: 16.4390 - MinusLogProbMetric: 16.4390 - val_loss: 16.8782 - val_MinusLogProbMetric: 16.8782 - lr: 2.5000e-04 - 42s/epoch - 216ms/step
Epoch 330/1000
2023-09-20 17:35:53.162 
Epoch 330/1000 
	 loss: 16.4514, MinusLogProbMetric: 16.4514, val_loss: 16.7969, val_MinusLogProbMetric: 16.7969

Epoch 330: val_loss did not improve from 16.72723
196/196 - 43s - loss: 16.4514 - MinusLogProbMetric: 16.4514 - val_loss: 16.7969 - val_MinusLogProbMetric: 16.7969 - lr: 2.5000e-04 - 43s/epoch - 217ms/step
Epoch 331/1000
2023-09-20 17:36:35.449 
Epoch 331/1000 
	 loss: 16.4424, MinusLogProbMetric: 16.4424, val_loss: 16.7256, val_MinusLogProbMetric: 16.7256

Epoch 331: val_loss improved from 16.72723 to 16.72564, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 43s - loss: 16.4424 - MinusLogProbMetric: 16.4424 - val_loss: 16.7256 - val_MinusLogProbMetric: 16.7256 - lr: 2.5000e-04 - 43s/epoch - 220ms/step
Epoch 332/1000
2023-09-20 17:37:18.267 
Epoch 332/1000 
	 loss: 16.4449, MinusLogProbMetric: 16.4449, val_loss: 16.7582, val_MinusLogProbMetric: 16.7582

Epoch 332: val_loss did not improve from 16.72564
196/196 - 42s - loss: 16.4449 - MinusLogProbMetric: 16.4449 - val_loss: 16.7582 - val_MinusLogProbMetric: 16.7582 - lr: 2.5000e-04 - 42s/epoch - 214ms/step
Epoch 333/1000
2023-09-20 17:38:00.731 
Epoch 333/1000 
	 loss: 16.4561, MinusLogProbMetric: 16.4561, val_loss: 16.8162, val_MinusLogProbMetric: 16.8162

Epoch 333: val_loss did not improve from 16.72564
196/196 - 42s - loss: 16.4561 - MinusLogProbMetric: 16.4561 - val_loss: 16.8162 - val_MinusLogProbMetric: 16.8162 - lr: 2.5000e-04 - 42s/epoch - 217ms/step
Epoch 334/1000
2023-09-20 17:38:42.843 
Epoch 334/1000 
	 loss: 16.4464, MinusLogProbMetric: 16.4464, val_loss: 16.8017, val_MinusLogProbMetric: 16.8017

Epoch 334: val_loss did not improve from 16.72564
196/196 - 42s - loss: 16.4464 - MinusLogProbMetric: 16.4464 - val_loss: 16.8017 - val_MinusLogProbMetric: 16.8017 - lr: 2.5000e-04 - 42s/epoch - 215ms/step
Epoch 335/1000
2023-09-20 17:39:25.115 
Epoch 335/1000 
	 loss: 16.4553, MinusLogProbMetric: 16.4553, val_loss: 16.7468, val_MinusLogProbMetric: 16.7468

Epoch 335: val_loss did not improve from 16.72564
196/196 - 42s - loss: 16.4553 - MinusLogProbMetric: 16.4553 - val_loss: 16.7468 - val_MinusLogProbMetric: 16.7468 - lr: 2.5000e-04 - 42s/epoch - 216ms/step
Epoch 336/1000
2023-09-20 17:40:07.298 
Epoch 336/1000 
	 loss: 16.4444, MinusLogProbMetric: 16.4444, val_loss: 16.8026, val_MinusLogProbMetric: 16.8026

Epoch 336: val_loss did not improve from 16.72564
196/196 - 42s - loss: 16.4444 - MinusLogProbMetric: 16.4444 - val_loss: 16.8026 - val_MinusLogProbMetric: 16.8026 - lr: 2.5000e-04 - 42s/epoch - 215ms/step
Epoch 337/1000
2023-09-20 17:40:49.557 
Epoch 337/1000 
	 loss: 16.4409, MinusLogProbMetric: 16.4409, val_loss: 16.8329, val_MinusLogProbMetric: 16.8329

Epoch 337: val_loss did not improve from 16.72564
196/196 - 42s - loss: 16.4409 - MinusLogProbMetric: 16.4409 - val_loss: 16.8329 - val_MinusLogProbMetric: 16.8329 - lr: 2.5000e-04 - 42s/epoch - 216ms/step
Epoch 338/1000
2023-09-20 17:41:31.563 
Epoch 338/1000 
	 loss: 16.4391, MinusLogProbMetric: 16.4391, val_loss: 16.7722, val_MinusLogProbMetric: 16.7722

Epoch 338: val_loss did not improve from 16.72564
196/196 - 42s - loss: 16.4391 - MinusLogProbMetric: 16.4391 - val_loss: 16.7722 - val_MinusLogProbMetric: 16.7722 - lr: 2.5000e-04 - 42s/epoch - 214ms/step
Epoch 339/1000
2023-09-20 17:42:13.771 
Epoch 339/1000 
	 loss: 16.4369, MinusLogProbMetric: 16.4369, val_loss: 16.7813, val_MinusLogProbMetric: 16.7813

Epoch 339: val_loss did not improve from 16.72564
196/196 - 42s - loss: 16.4369 - MinusLogProbMetric: 16.4369 - val_loss: 16.7813 - val_MinusLogProbMetric: 16.7813 - lr: 2.5000e-04 - 42s/epoch - 215ms/step
Epoch 340/1000
2023-09-20 17:42:55.883 
Epoch 340/1000 
	 loss: 16.4434, MinusLogProbMetric: 16.4434, val_loss: 16.7472, val_MinusLogProbMetric: 16.7472

Epoch 340: val_loss did not improve from 16.72564
196/196 - 42s - loss: 16.4434 - MinusLogProbMetric: 16.4434 - val_loss: 16.7472 - val_MinusLogProbMetric: 16.7472 - lr: 2.5000e-04 - 42s/epoch - 215ms/step
Epoch 341/1000
2023-09-20 17:43:37.637 
Epoch 341/1000 
	 loss: 16.4453, MinusLogProbMetric: 16.4453, val_loss: 16.7512, val_MinusLogProbMetric: 16.7512

Epoch 341: val_loss did not improve from 16.72564
196/196 - 42s - loss: 16.4453 - MinusLogProbMetric: 16.4453 - val_loss: 16.7512 - val_MinusLogProbMetric: 16.7512 - lr: 2.5000e-04 - 42s/epoch - 213ms/step
Epoch 342/1000
2023-09-20 17:44:19.475 
Epoch 342/1000 
	 loss: 16.4411, MinusLogProbMetric: 16.4411, val_loss: 16.7817, val_MinusLogProbMetric: 16.7817

Epoch 342: val_loss did not improve from 16.72564
196/196 - 42s - loss: 16.4411 - MinusLogProbMetric: 16.4411 - val_loss: 16.7817 - val_MinusLogProbMetric: 16.7817 - lr: 2.5000e-04 - 42s/epoch - 213ms/step
Epoch 343/1000
2023-09-20 17:45:01.692 
Epoch 343/1000 
	 loss: 16.4365, MinusLogProbMetric: 16.4365, val_loss: 16.7457, val_MinusLogProbMetric: 16.7457

Epoch 343: val_loss did not improve from 16.72564
196/196 - 42s - loss: 16.4365 - MinusLogProbMetric: 16.4365 - val_loss: 16.7457 - val_MinusLogProbMetric: 16.7457 - lr: 2.5000e-04 - 42s/epoch - 215ms/step
Epoch 344/1000
2023-09-20 17:45:44.158 
Epoch 344/1000 
	 loss: 16.4314, MinusLogProbMetric: 16.4314, val_loss: 16.7617, val_MinusLogProbMetric: 16.7617

Epoch 344: val_loss did not improve from 16.72564
196/196 - 42s - loss: 16.4314 - MinusLogProbMetric: 16.4314 - val_loss: 16.7617 - val_MinusLogProbMetric: 16.7617 - lr: 2.5000e-04 - 42s/epoch - 217ms/step
Epoch 345/1000
2023-09-20 17:46:26.508 
Epoch 345/1000 
	 loss: 16.4438, MinusLogProbMetric: 16.4438, val_loss: 16.7479, val_MinusLogProbMetric: 16.7479

Epoch 345: val_loss did not improve from 16.72564
196/196 - 42s - loss: 16.4438 - MinusLogProbMetric: 16.4438 - val_loss: 16.7479 - val_MinusLogProbMetric: 16.7479 - lr: 2.5000e-04 - 42s/epoch - 216ms/step
Epoch 346/1000
2023-09-20 17:47:08.566 
Epoch 346/1000 
	 loss: 16.4413, MinusLogProbMetric: 16.4413, val_loss: 16.7962, val_MinusLogProbMetric: 16.7962

Epoch 346: val_loss did not improve from 16.72564
196/196 - 42s - loss: 16.4413 - MinusLogProbMetric: 16.4413 - val_loss: 16.7962 - val_MinusLogProbMetric: 16.7962 - lr: 2.5000e-04 - 42s/epoch - 215ms/step
Epoch 347/1000
2023-09-20 17:47:51.037 
Epoch 347/1000 
	 loss: 16.4321, MinusLogProbMetric: 16.4321, val_loss: 16.7341, val_MinusLogProbMetric: 16.7341

Epoch 347: val_loss did not improve from 16.72564
196/196 - 42s - loss: 16.4321 - MinusLogProbMetric: 16.4321 - val_loss: 16.7341 - val_MinusLogProbMetric: 16.7341 - lr: 2.5000e-04 - 42s/epoch - 217ms/step
Epoch 348/1000
2023-09-20 17:48:33.540 
Epoch 348/1000 
	 loss: 16.4384, MinusLogProbMetric: 16.4384, val_loss: 16.7681, val_MinusLogProbMetric: 16.7681

Epoch 348: val_loss did not improve from 16.72564
196/196 - 43s - loss: 16.4384 - MinusLogProbMetric: 16.4384 - val_loss: 16.7681 - val_MinusLogProbMetric: 16.7681 - lr: 2.5000e-04 - 43s/epoch - 217ms/step
Epoch 349/1000
2023-09-20 17:49:16.654 
Epoch 349/1000 
	 loss: 16.4380, MinusLogProbMetric: 16.4380, val_loss: 16.7616, val_MinusLogProbMetric: 16.7616

Epoch 349: val_loss did not improve from 16.72564
196/196 - 43s - loss: 16.4380 - MinusLogProbMetric: 16.4380 - val_loss: 16.7616 - val_MinusLogProbMetric: 16.7616 - lr: 2.5000e-04 - 43s/epoch - 220ms/step
Epoch 350/1000
2023-09-20 17:49:58.675 
Epoch 350/1000 
	 loss: 16.4330, MinusLogProbMetric: 16.4330, val_loss: 16.7778, val_MinusLogProbMetric: 16.7778

Epoch 350: val_loss did not improve from 16.72564
196/196 - 42s - loss: 16.4330 - MinusLogProbMetric: 16.4330 - val_loss: 16.7778 - val_MinusLogProbMetric: 16.7778 - lr: 2.5000e-04 - 42s/epoch - 214ms/step
Epoch 351/1000
2023-09-20 17:50:40.885 
Epoch 351/1000 
	 loss: 16.4536, MinusLogProbMetric: 16.4536, val_loss: 16.7539, val_MinusLogProbMetric: 16.7539

Epoch 351: val_loss did not improve from 16.72564
196/196 - 42s - loss: 16.4536 - MinusLogProbMetric: 16.4536 - val_loss: 16.7539 - val_MinusLogProbMetric: 16.7539 - lr: 2.5000e-04 - 42s/epoch - 215ms/step
Epoch 352/1000
2023-09-20 17:51:22.845 
Epoch 352/1000 
	 loss: 16.4369, MinusLogProbMetric: 16.4369, val_loss: 16.7544, val_MinusLogProbMetric: 16.7544

Epoch 352: val_loss did not improve from 16.72564
196/196 - 42s - loss: 16.4369 - MinusLogProbMetric: 16.4369 - val_loss: 16.7544 - val_MinusLogProbMetric: 16.7544 - lr: 2.5000e-04 - 42s/epoch - 214ms/step
Epoch 353/1000
2023-09-20 17:52:04.730 
Epoch 353/1000 
	 loss: 16.4397, MinusLogProbMetric: 16.4397, val_loss: 16.7249, val_MinusLogProbMetric: 16.7249

Epoch 353: val_loss improved from 16.72564 to 16.72489, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 43s - loss: 16.4397 - MinusLogProbMetric: 16.4397 - val_loss: 16.7249 - val_MinusLogProbMetric: 16.7249 - lr: 2.5000e-04 - 43s/epoch - 218ms/step
Epoch 354/1000
2023-09-20 17:52:47.576 
Epoch 354/1000 
	 loss: 16.4357, MinusLogProbMetric: 16.4357, val_loss: 16.8312, val_MinusLogProbMetric: 16.8312

Epoch 354: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4357 - MinusLogProbMetric: 16.4357 - val_loss: 16.8312 - val_MinusLogProbMetric: 16.8312 - lr: 2.5000e-04 - 42s/epoch - 214ms/step
Epoch 355/1000
2023-09-20 17:53:29.996 
Epoch 355/1000 
	 loss: 16.4348, MinusLogProbMetric: 16.4348, val_loss: 16.8131, val_MinusLogProbMetric: 16.8131

Epoch 355: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4348 - MinusLogProbMetric: 16.4348 - val_loss: 16.8131 - val_MinusLogProbMetric: 16.8131 - lr: 2.5000e-04 - 42s/epoch - 216ms/step
Epoch 356/1000
2023-09-20 17:54:12.606 
Epoch 356/1000 
	 loss: 16.4406, MinusLogProbMetric: 16.4406, val_loss: 16.7964, val_MinusLogProbMetric: 16.7964

Epoch 356: val_loss did not improve from 16.72489
196/196 - 43s - loss: 16.4406 - MinusLogProbMetric: 16.4406 - val_loss: 16.7964 - val_MinusLogProbMetric: 16.7964 - lr: 2.5000e-04 - 43s/epoch - 217ms/step
Epoch 357/1000
2023-09-20 17:54:54.977 
Epoch 357/1000 
	 loss: 16.4472, MinusLogProbMetric: 16.4472, val_loss: 16.7458, val_MinusLogProbMetric: 16.7458

Epoch 357: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4472 - MinusLogProbMetric: 16.4472 - val_loss: 16.7458 - val_MinusLogProbMetric: 16.7458 - lr: 2.5000e-04 - 42s/epoch - 216ms/step
Epoch 358/1000
2023-09-20 17:55:37.047 
Epoch 358/1000 
	 loss: 16.4446, MinusLogProbMetric: 16.4446, val_loss: 16.7685, val_MinusLogProbMetric: 16.7685

Epoch 358: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4446 - MinusLogProbMetric: 16.4446 - val_loss: 16.7685 - val_MinusLogProbMetric: 16.7685 - lr: 2.5000e-04 - 42s/epoch - 215ms/step
Epoch 359/1000
2023-09-20 17:56:14.259 
Epoch 359/1000 
	 loss: 16.4371, MinusLogProbMetric: 16.4371, val_loss: 16.7342, val_MinusLogProbMetric: 16.7342

Epoch 359: val_loss did not improve from 16.72489
196/196 - 37s - loss: 16.4371 - MinusLogProbMetric: 16.4371 - val_loss: 16.7342 - val_MinusLogProbMetric: 16.7342 - lr: 2.5000e-04 - 37s/epoch - 190ms/step
Epoch 360/1000
2023-09-20 17:56:48.393 
Epoch 360/1000 
	 loss: 16.4376, MinusLogProbMetric: 16.4376, val_loss: 16.7850, val_MinusLogProbMetric: 16.7850

Epoch 360: val_loss did not improve from 16.72489
196/196 - 34s - loss: 16.4376 - MinusLogProbMetric: 16.4376 - val_loss: 16.7850 - val_MinusLogProbMetric: 16.7850 - lr: 2.5000e-04 - 34s/epoch - 174ms/step
Epoch 361/1000
2023-09-20 17:57:21.133 
Epoch 361/1000 
	 loss: 16.4348, MinusLogProbMetric: 16.4348, val_loss: 16.7529, val_MinusLogProbMetric: 16.7529

Epoch 361: val_loss did not improve from 16.72489
196/196 - 33s - loss: 16.4348 - MinusLogProbMetric: 16.4348 - val_loss: 16.7529 - val_MinusLogProbMetric: 16.7529 - lr: 2.5000e-04 - 33s/epoch - 167ms/step
Epoch 362/1000
2023-09-20 17:57:53.648 
Epoch 362/1000 
	 loss: 16.4348, MinusLogProbMetric: 16.4348, val_loss: 16.7693, val_MinusLogProbMetric: 16.7693

Epoch 362: val_loss did not improve from 16.72489
196/196 - 33s - loss: 16.4348 - MinusLogProbMetric: 16.4348 - val_loss: 16.7693 - val_MinusLogProbMetric: 16.7693 - lr: 2.5000e-04 - 33s/epoch - 166ms/step
Epoch 363/1000
2023-09-20 17:58:34.546 
Epoch 363/1000 
	 loss: 16.4259, MinusLogProbMetric: 16.4259, val_loss: 16.7932, val_MinusLogProbMetric: 16.7932

Epoch 363: val_loss did not improve from 16.72489
196/196 - 41s - loss: 16.4259 - MinusLogProbMetric: 16.4259 - val_loss: 16.7932 - val_MinusLogProbMetric: 16.7932 - lr: 2.5000e-04 - 41s/epoch - 209ms/step
Epoch 364/1000
2023-09-20 17:59:10.916 
Epoch 364/1000 
	 loss: 16.4351, MinusLogProbMetric: 16.4351, val_loss: 16.8135, val_MinusLogProbMetric: 16.8135

Epoch 364: val_loss did not improve from 16.72489
196/196 - 36s - loss: 16.4351 - MinusLogProbMetric: 16.4351 - val_loss: 16.8135 - val_MinusLogProbMetric: 16.8135 - lr: 2.5000e-04 - 36s/epoch - 186ms/step
Epoch 365/1000
2023-09-20 17:59:44.261 
Epoch 365/1000 
	 loss: 16.4295, MinusLogProbMetric: 16.4295, val_loss: 16.7410, val_MinusLogProbMetric: 16.7410

Epoch 365: val_loss did not improve from 16.72489
196/196 - 33s - loss: 16.4295 - MinusLogProbMetric: 16.4295 - val_loss: 16.7410 - val_MinusLogProbMetric: 16.7410 - lr: 2.5000e-04 - 33s/epoch - 170ms/step
Epoch 366/1000
2023-09-20 18:00:18.178 
Epoch 366/1000 
	 loss: 16.4406, MinusLogProbMetric: 16.4406, val_loss: 16.7603, val_MinusLogProbMetric: 16.7603

Epoch 366: val_loss did not improve from 16.72489
196/196 - 34s - loss: 16.4406 - MinusLogProbMetric: 16.4406 - val_loss: 16.7603 - val_MinusLogProbMetric: 16.7603 - lr: 2.5000e-04 - 34s/epoch - 173ms/step
Epoch 367/1000
2023-09-20 18:00:57.645 
Epoch 367/1000 
	 loss: 16.4321, MinusLogProbMetric: 16.4321, val_loss: 16.7991, val_MinusLogProbMetric: 16.7991

Epoch 367: val_loss did not improve from 16.72489
196/196 - 39s - loss: 16.4321 - MinusLogProbMetric: 16.4321 - val_loss: 16.7991 - val_MinusLogProbMetric: 16.7991 - lr: 2.5000e-04 - 39s/epoch - 201ms/step
Epoch 368/1000
2023-09-20 18:01:39.905 
Epoch 368/1000 
	 loss: 16.4288, MinusLogProbMetric: 16.4288, val_loss: 16.7542, val_MinusLogProbMetric: 16.7542

Epoch 368: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4288 - MinusLogProbMetric: 16.4288 - val_loss: 16.7542 - val_MinusLogProbMetric: 16.7542 - lr: 2.5000e-04 - 42s/epoch - 216ms/step
Epoch 369/1000
2023-09-20 18:02:19.898 
Epoch 369/1000 
	 loss: 16.4308, MinusLogProbMetric: 16.4308, val_loss: 16.7505, val_MinusLogProbMetric: 16.7505

Epoch 369: val_loss did not improve from 16.72489
196/196 - 40s - loss: 16.4308 - MinusLogProbMetric: 16.4308 - val_loss: 16.7505 - val_MinusLogProbMetric: 16.7505 - lr: 2.5000e-04 - 40s/epoch - 204ms/step
Epoch 370/1000
2023-09-20 18:03:01.769 
Epoch 370/1000 
	 loss: 16.4306, MinusLogProbMetric: 16.4306, val_loss: 16.7648, val_MinusLogProbMetric: 16.7648

Epoch 370: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4306 - MinusLogProbMetric: 16.4306 - val_loss: 16.7648 - val_MinusLogProbMetric: 16.7648 - lr: 2.5000e-04 - 42s/epoch - 214ms/step
Epoch 371/1000
2023-09-20 18:03:43.482 
Epoch 371/1000 
	 loss: 16.4263, MinusLogProbMetric: 16.4263, val_loss: 16.7538, val_MinusLogProbMetric: 16.7538

Epoch 371: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4263 - MinusLogProbMetric: 16.4263 - val_loss: 16.7538 - val_MinusLogProbMetric: 16.7538 - lr: 2.5000e-04 - 42s/epoch - 213ms/step
Epoch 372/1000
2023-09-20 18:04:25.314 
Epoch 372/1000 
	 loss: 16.4288, MinusLogProbMetric: 16.4288, val_loss: 16.7390, val_MinusLogProbMetric: 16.7390

Epoch 372: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4288 - MinusLogProbMetric: 16.4288 - val_loss: 16.7390 - val_MinusLogProbMetric: 16.7390 - lr: 2.5000e-04 - 42s/epoch - 213ms/step
Epoch 373/1000
2023-09-20 18:05:07.149 
Epoch 373/1000 
	 loss: 16.4273, MinusLogProbMetric: 16.4273, val_loss: 16.7498, val_MinusLogProbMetric: 16.7498

Epoch 373: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4273 - MinusLogProbMetric: 16.4273 - val_loss: 16.7498 - val_MinusLogProbMetric: 16.7498 - lr: 2.5000e-04 - 42s/epoch - 213ms/step
Epoch 374/1000
2023-09-20 18:05:48.940 
Epoch 374/1000 
	 loss: 16.4247, MinusLogProbMetric: 16.4247, val_loss: 16.7580, val_MinusLogProbMetric: 16.7580

Epoch 374: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4247 - MinusLogProbMetric: 16.4247 - val_loss: 16.7580 - val_MinusLogProbMetric: 16.7580 - lr: 2.5000e-04 - 42s/epoch - 213ms/step
Epoch 375/1000
2023-09-20 18:06:30.987 
Epoch 375/1000 
	 loss: 16.4348, MinusLogProbMetric: 16.4348, val_loss: 16.7495, val_MinusLogProbMetric: 16.7495

Epoch 375: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4348 - MinusLogProbMetric: 16.4348 - val_loss: 16.7495 - val_MinusLogProbMetric: 16.7495 - lr: 2.5000e-04 - 42s/epoch - 215ms/step
Epoch 376/1000
2023-09-20 18:07:12.891 
Epoch 376/1000 
	 loss: 16.4355, MinusLogProbMetric: 16.4355, val_loss: 16.7583, val_MinusLogProbMetric: 16.7583

Epoch 376: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4355 - MinusLogProbMetric: 16.4355 - val_loss: 16.7583 - val_MinusLogProbMetric: 16.7583 - lr: 2.5000e-04 - 42s/epoch - 214ms/step
Epoch 377/1000
2023-09-20 18:07:55.079 
Epoch 377/1000 
	 loss: 16.4349, MinusLogProbMetric: 16.4349, val_loss: 16.7442, val_MinusLogProbMetric: 16.7442

Epoch 377: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4349 - MinusLogProbMetric: 16.4349 - val_loss: 16.7442 - val_MinusLogProbMetric: 16.7442 - lr: 2.5000e-04 - 42s/epoch - 215ms/step
Epoch 378/1000
2023-09-20 18:08:37.050 
Epoch 378/1000 
	 loss: 16.4416, MinusLogProbMetric: 16.4416, val_loss: 16.8457, val_MinusLogProbMetric: 16.8457

Epoch 378: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4416 - MinusLogProbMetric: 16.4416 - val_loss: 16.8457 - val_MinusLogProbMetric: 16.8457 - lr: 2.5000e-04 - 42s/epoch - 214ms/step
Epoch 379/1000
2023-09-20 18:09:18.822 
Epoch 379/1000 
	 loss: 16.4407, MinusLogProbMetric: 16.4407, val_loss: 16.7587, val_MinusLogProbMetric: 16.7587

Epoch 379: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4407 - MinusLogProbMetric: 16.4407 - val_loss: 16.7587 - val_MinusLogProbMetric: 16.7587 - lr: 2.5000e-04 - 42s/epoch - 213ms/step
Epoch 380/1000
2023-09-20 18:10:00.718 
Epoch 380/1000 
	 loss: 16.4322, MinusLogProbMetric: 16.4322, val_loss: 16.7673, val_MinusLogProbMetric: 16.7673

Epoch 380: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4322 - MinusLogProbMetric: 16.4322 - val_loss: 16.7673 - val_MinusLogProbMetric: 16.7673 - lr: 2.5000e-04 - 42s/epoch - 214ms/step
Epoch 381/1000
2023-09-20 18:10:42.592 
Epoch 381/1000 
	 loss: 16.4293, MinusLogProbMetric: 16.4293, val_loss: 16.7655, val_MinusLogProbMetric: 16.7655

Epoch 381: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4293 - MinusLogProbMetric: 16.4293 - val_loss: 16.7655 - val_MinusLogProbMetric: 16.7655 - lr: 2.5000e-04 - 42s/epoch - 214ms/step
Epoch 382/1000
2023-09-20 18:11:23.545 
Epoch 382/1000 
	 loss: 16.4253, MinusLogProbMetric: 16.4253, val_loss: 16.7538, val_MinusLogProbMetric: 16.7538

Epoch 382: val_loss did not improve from 16.72489
196/196 - 41s - loss: 16.4253 - MinusLogProbMetric: 16.4253 - val_loss: 16.7538 - val_MinusLogProbMetric: 16.7538 - lr: 2.5000e-04 - 41s/epoch - 209ms/step
Epoch 383/1000
2023-09-20 18:12:04.909 
Epoch 383/1000 
	 loss: 16.4272, MinusLogProbMetric: 16.4272, val_loss: 16.7593, val_MinusLogProbMetric: 16.7593

Epoch 383: val_loss did not improve from 16.72489
196/196 - 41s - loss: 16.4272 - MinusLogProbMetric: 16.4272 - val_loss: 16.7593 - val_MinusLogProbMetric: 16.7593 - lr: 2.5000e-04 - 41s/epoch - 211ms/step
Epoch 384/1000
2023-09-20 18:12:47.025 
Epoch 384/1000 
	 loss: 16.4379, MinusLogProbMetric: 16.4379, val_loss: 16.7623, val_MinusLogProbMetric: 16.7623

Epoch 384: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4379 - MinusLogProbMetric: 16.4379 - val_loss: 16.7623 - val_MinusLogProbMetric: 16.7623 - lr: 2.5000e-04 - 42s/epoch - 215ms/step
Epoch 385/1000
2023-09-20 18:13:28.559 
Epoch 385/1000 
	 loss: 16.4252, MinusLogProbMetric: 16.4252, val_loss: 16.7583, val_MinusLogProbMetric: 16.7583

Epoch 385: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4252 - MinusLogProbMetric: 16.4252 - val_loss: 16.7583 - val_MinusLogProbMetric: 16.7583 - lr: 2.5000e-04 - 42s/epoch - 212ms/step
Epoch 386/1000
2023-09-20 18:14:10.492 
Epoch 386/1000 
	 loss: 16.4284, MinusLogProbMetric: 16.4284, val_loss: 16.7647, val_MinusLogProbMetric: 16.7647

Epoch 386: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4284 - MinusLogProbMetric: 16.4284 - val_loss: 16.7647 - val_MinusLogProbMetric: 16.7647 - lr: 2.5000e-04 - 42s/epoch - 214ms/step
Epoch 387/1000
2023-09-20 18:14:52.374 
Epoch 387/1000 
	 loss: 16.4273, MinusLogProbMetric: 16.4273, val_loss: 16.7475, val_MinusLogProbMetric: 16.7475

Epoch 387: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4273 - MinusLogProbMetric: 16.4273 - val_loss: 16.7475 - val_MinusLogProbMetric: 16.7475 - lr: 2.5000e-04 - 42s/epoch - 214ms/step
Epoch 388/1000
2023-09-20 18:15:34.260 
Epoch 388/1000 
	 loss: 16.4306, MinusLogProbMetric: 16.4306, val_loss: 16.7697, val_MinusLogProbMetric: 16.7697

Epoch 388: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4306 - MinusLogProbMetric: 16.4306 - val_loss: 16.7697 - val_MinusLogProbMetric: 16.7697 - lr: 2.5000e-04 - 42s/epoch - 214ms/step
Epoch 389/1000
2023-09-20 18:16:15.835 
Epoch 389/1000 
	 loss: 16.4367, MinusLogProbMetric: 16.4367, val_loss: 16.7894, val_MinusLogProbMetric: 16.7894

Epoch 389: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4367 - MinusLogProbMetric: 16.4367 - val_loss: 16.7894 - val_MinusLogProbMetric: 16.7894 - lr: 2.5000e-04 - 42s/epoch - 212ms/step
Epoch 390/1000
2023-09-20 18:16:57.730 
Epoch 390/1000 
	 loss: 16.4238, MinusLogProbMetric: 16.4238, val_loss: 16.7581, val_MinusLogProbMetric: 16.7581

Epoch 390: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4238 - MinusLogProbMetric: 16.4238 - val_loss: 16.7581 - val_MinusLogProbMetric: 16.7581 - lr: 2.5000e-04 - 42s/epoch - 214ms/step
Epoch 391/1000
2023-09-20 18:17:40.152 
Epoch 391/1000 
	 loss: 16.4228, MinusLogProbMetric: 16.4228, val_loss: 16.7774, val_MinusLogProbMetric: 16.7774

Epoch 391: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4228 - MinusLogProbMetric: 16.4228 - val_loss: 16.7774 - val_MinusLogProbMetric: 16.7774 - lr: 2.5000e-04 - 42s/epoch - 216ms/step
Epoch 392/1000
2023-09-20 18:18:22.191 
Epoch 392/1000 
	 loss: 16.4217, MinusLogProbMetric: 16.4217, val_loss: 16.8104, val_MinusLogProbMetric: 16.8104

Epoch 392: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4217 - MinusLogProbMetric: 16.4217 - val_loss: 16.8104 - val_MinusLogProbMetric: 16.8104 - lr: 2.5000e-04 - 42s/epoch - 214ms/step
Epoch 393/1000
2023-09-20 18:19:03.416 
Epoch 393/1000 
	 loss: 16.4229, MinusLogProbMetric: 16.4229, val_loss: 16.7418, val_MinusLogProbMetric: 16.7418

Epoch 393: val_loss did not improve from 16.72489
196/196 - 41s - loss: 16.4229 - MinusLogProbMetric: 16.4229 - val_loss: 16.7418 - val_MinusLogProbMetric: 16.7418 - lr: 2.5000e-04 - 41s/epoch - 210ms/step
Epoch 394/1000
2023-09-20 18:19:44.965 
Epoch 394/1000 
	 loss: 16.4167, MinusLogProbMetric: 16.4167, val_loss: 16.7388, val_MinusLogProbMetric: 16.7388

Epoch 394: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4167 - MinusLogProbMetric: 16.4167 - val_loss: 16.7388 - val_MinusLogProbMetric: 16.7388 - lr: 2.5000e-04 - 42s/epoch - 212ms/step
Epoch 395/1000
2023-09-20 18:20:26.493 
Epoch 395/1000 
	 loss: 16.4258, MinusLogProbMetric: 16.4258, val_loss: 16.8382, val_MinusLogProbMetric: 16.8382

Epoch 395: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4258 - MinusLogProbMetric: 16.4258 - val_loss: 16.8382 - val_MinusLogProbMetric: 16.8382 - lr: 2.5000e-04 - 42s/epoch - 212ms/step
Epoch 396/1000
2023-09-20 18:21:08.229 
Epoch 396/1000 
	 loss: 16.4357, MinusLogProbMetric: 16.4357, val_loss: 16.7591, val_MinusLogProbMetric: 16.7591

Epoch 396: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4357 - MinusLogProbMetric: 16.4357 - val_loss: 16.7591 - val_MinusLogProbMetric: 16.7591 - lr: 2.5000e-04 - 42s/epoch - 213ms/step
Epoch 397/1000
2023-09-20 18:21:49.679 
Epoch 397/1000 
	 loss: 16.4238, MinusLogProbMetric: 16.4238, val_loss: 16.7636, val_MinusLogProbMetric: 16.7636

Epoch 397: val_loss did not improve from 16.72489
196/196 - 41s - loss: 16.4238 - MinusLogProbMetric: 16.4238 - val_loss: 16.7636 - val_MinusLogProbMetric: 16.7636 - lr: 2.5000e-04 - 41s/epoch - 211ms/step
Epoch 398/1000
2023-09-20 18:22:31.539 
Epoch 398/1000 
	 loss: 16.4240, MinusLogProbMetric: 16.4240, val_loss: 16.7548, val_MinusLogProbMetric: 16.7548

Epoch 398: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4240 - MinusLogProbMetric: 16.4240 - val_loss: 16.7548 - val_MinusLogProbMetric: 16.7548 - lr: 2.5000e-04 - 42s/epoch - 214ms/step
Epoch 399/1000
2023-09-20 18:23:13.178 
Epoch 399/1000 
	 loss: 16.4190, MinusLogProbMetric: 16.4190, val_loss: 16.8004, val_MinusLogProbMetric: 16.8004

Epoch 399: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4190 - MinusLogProbMetric: 16.4190 - val_loss: 16.8004 - val_MinusLogProbMetric: 16.8004 - lr: 2.5000e-04 - 42s/epoch - 212ms/step
Epoch 400/1000
2023-09-20 18:23:55.031 
Epoch 400/1000 
	 loss: 16.4326, MinusLogProbMetric: 16.4326, val_loss: 16.7615, val_MinusLogProbMetric: 16.7615

Epoch 400: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4326 - MinusLogProbMetric: 16.4326 - val_loss: 16.7615 - val_MinusLogProbMetric: 16.7615 - lr: 2.5000e-04 - 42s/epoch - 213ms/step
Epoch 401/1000
2023-09-20 18:24:37.334 
Epoch 401/1000 
	 loss: 16.4153, MinusLogProbMetric: 16.4153, val_loss: 16.7931, val_MinusLogProbMetric: 16.7931

Epoch 401: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4153 - MinusLogProbMetric: 16.4153 - val_loss: 16.7931 - val_MinusLogProbMetric: 16.7931 - lr: 2.5000e-04 - 42s/epoch - 216ms/step
Epoch 402/1000
2023-09-20 18:25:19.142 
Epoch 402/1000 
	 loss: 16.4205, MinusLogProbMetric: 16.4205, val_loss: 16.7874, val_MinusLogProbMetric: 16.7874

Epoch 402: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4205 - MinusLogProbMetric: 16.4205 - val_loss: 16.7874 - val_MinusLogProbMetric: 16.7874 - lr: 2.5000e-04 - 42s/epoch - 213ms/step
Epoch 403/1000
2023-09-20 18:26:01.315 
Epoch 403/1000 
	 loss: 16.4206, MinusLogProbMetric: 16.4206, val_loss: 16.7737, val_MinusLogProbMetric: 16.7737

Epoch 403: val_loss did not improve from 16.72489
196/196 - 42s - loss: 16.4206 - MinusLogProbMetric: 16.4206 - val_loss: 16.7737 - val_MinusLogProbMetric: 16.7737 - lr: 2.5000e-04 - 42s/epoch - 215ms/step
Epoch 404/1000
2023-09-20 18:26:42.810 
Epoch 404/1000 
	 loss: 16.3862, MinusLogProbMetric: 16.3862, val_loss: 16.7196, val_MinusLogProbMetric: 16.7196

Epoch 404: val_loss improved from 16.72489 to 16.71958, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 42s - loss: 16.3862 - MinusLogProbMetric: 16.3862 - val_loss: 16.7196 - val_MinusLogProbMetric: 16.7196 - lr: 1.2500e-04 - 42s/epoch - 216ms/step
Epoch 405/1000
2023-09-20 18:27:25.282 
Epoch 405/1000 
	 loss: 16.3818, MinusLogProbMetric: 16.3818, val_loss: 16.7395, val_MinusLogProbMetric: 16.7395

Epoch 405: val_loss did not improve from 16.71958
196/196 - 42s - loss: 16.3818 - MinusLogProbMetric: 16.3818 - val_loss: 16.7395 - val_MinusLogProbMetric: 16.7395 - lr: 1.2500e-04 - 42s/epoch - 212ms/step
Epoch 406/1000
2023-09-20 18:28:07.651 
Epoch 406/1000 
	 loss: 16.3825, MinusLogProbMetric: 16.3825, val_loss: 16.7253, val_MinusLogProbMetric: 16.7253

Epoch 406: val_loss did not improve from 16.71958
196/196 - 42s - loss: 16.3825 - MinusLogProbMetric: 16.3825 - val_loss: 16.7253 - val_MinusLogProbMetric: 16.7253 - lr: 1.2500e-04 - 42s/epoch - 216ms/step
Epoch 407/1000
2023-09-20 18:28:49.648 
Epoch 407/1000 
	 loss: 16.3825, MinusLogProbMetric: 16.3825, val_loss: 16.7382, val_MinusLogProbMetric: 16.7382

Epoch 407: val_loss did not improve from 16.71958
196/196 - 42s - loss: 16.3825 - MinusLogProbMetric: 16.3825 - val_loss: 16.7382 - val_MinusLogProbMetric: 16.7382 - lr: 1.2500e-04 - 42s/epoch - 214ms/step
Epoch 408/1000
2023-09-20 18:29:31.488 
Epoch 408/1000 
	 loss: 16.3844, MinusLogProbMetric: 16.3844, val_loss: 16.7340, val_MinusLogProbMetric: 16.7340

Epoch 408: val_loss did not improve from 16.71958
196/196 - 42s - loss: 16.3844 - MinusLogProbMetric: 16.3844 - val_loss: 16.7340 - val_MinusLogProbMetric: 16.7340 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 409/1000
2023-09-20 18:30:13.192 
Epoch 409/1000 
	 loss: 16.3818, MinusLogProbMetric: 16.3818, val_loss: 16.7231, val_MinusLogProbMetric: 16.7231

Epoch 409: val_loss did not improve from 16.71958
196/196 - 42s - loss: 16.3818 - MinusLogProbMetric: 16.3818 - val_loss: 16.7231 - val_MinusLogProbMetric: 16.7231 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 410/1000
2023-09-20 18:30:54.915 
Epoch 410/1000 
	 loss: 16.3815, MinusLogProbMetric: 16.3815, val_loss: 16.7243, val_MinusLogProbMetric: 16.7243

Epoch 410: val_loss did not improve from 16.71958
196/196 - 42s - loss: 16.3815 - MinusLogProbMetric: 16.3815 - val_loss: 16.7243 - val_MinusLogProbMetric: 16.7243 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 411/1000
2023-09-20 18:31:36.138 
Epoch 411/1000 
	 loss: 16.3849, MinusLogProbMetric: 16.3849, val_loss: 16.7282, val_MinusLogProbMetric: 16.7282

Epoch 411: val_loss did not improve from 16.71958
196/196 - 41s - loss: 16.3849 - MinusLogProbMetric: 16.3849 - val_loss: 16.7282 - val_MinusLogProbMetric: 16.7282 - lr: 1.2500e-04 - 41s/epoch - 210ms/step
Epoch 412/1000
2023-09-20 18:32:17.923 
Epoch 412/1000 
	 loss: 16.3833, MinusLogProbMetric: 16.3833, val_loss: 16.7484, val_MinusLogProbMetric: 16.7484

Epoch 412: val_loss did not improve from 16.71958
196/196 - 42s - loss: 16.3833 - MinusLogProbMetric: 16.3833 - val_loss: 16.7484 - val_MinusLogProbMetric: 16.7484 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 413/1000
2023-09-20 18:32:59.925 
Epoch 413/1000 
	 loss: 16.3877, MinusLogProbMetric: 16.3877, val_loss: 16.7286, val_MinusLogProbMetric: 16.7286

Epoch 413: val_loss did not improve from 16.71958
196/196 - 42s - loss: 16.3877 - MinusLogProbMetric: 16.3877 - val_loss: 16.7286 - val_MinusLogProbMetric: 16.7286 - lr: 1.2500e-04 - 42s/epoch - 214ms/step
Epoch 414/1000
2023-09-20 18:33:41.591 
Epoch 414/1000 
	 loss: 16.3772, MinusLogProbMetric: 16.3772, val_loss: 16.7371, val_MinusLogProbMetric: 16.7371

Epoch 414: val_loss did not improve from 16.71958
196/196 - 42s - loss: 16.3772 - MinusLogProbMetric: 16.3772 - val_loss: 16.7371 - val_MinusLogProbMetric: 16.7371 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 415/1000
2023-09-20 18:34:23.551 
Epoch 415/1000 
	 loss: 16.3820, MinusLogProbMetric: 16.3820, val_loss: 16.7276, val_MinusLogProbMetric: 16.7276

Epoch 415: val_loss did not improve from 16.71958
196/196 - 42s - loss: 16.3820 - MinusLogProbMetric: 16.3820 - val_loss: 16.7276 - val_MinusLogProbMetric: 16.7276 - lr: 1.2500e-04 - 42s/epoch - 214ms/step
Epoch 416/1000
2023-09-20 18:35:05.719 
Epoch 416/1000 
	 loss: 16.3830, MinusLogProbMetric: 16.3830, val_loss: 16.7255, val_MinusLogProbMetric: 16.7255

Epoch 416: val_loss did not improve from 16.71958
196/196 - 42s - loss: 16.3830 - MinusLogProbMetric: 16.3830 - val_loss: 16.7255 - val_MinusLogProbMetric: 16.7255 - lr: 1.2500e-04 - 42s/epoch - 215ms/step
Epoch 417/1000
2023-09-20 18:35:47.790 
Epoch 417/1000 
	 loss: 16.3789, MinusLogProbMetric: 16.3789, val_loss: 16.7432, val_MinusLogProbMetric: 16.7432

Epoch 417: val_loss did not improve from 16.71958
196/196 - 42s - loss: 16.3789 - MinusLogProbMetric: 16.3789 - val_loss: 16.7432 - val_MinusLogProbMetric: 16.7432 - lr: 1.2500e-04 - 42s/epoch - 215ms/step
Epoch 418/1000
2023-09-20 18:36:29.573 
Epoch 418/1000 
	 loss: 16.3804, MinusLogProbMetric: 16.3804, val_loss: 16.7169, val_MinusLogProbMetric: 16.7169

Epoch 418: val_loss improved from 16.71958 to 16.71688, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 43s - loss: 16.3804 - MinusLogProbMetric: 16.3804 - val_loss: 16.7169 - val_MinusLogProbMetric: 16.7169 - lr: 1.2500e-04 - 43s/epoch - 217ms/step
Epoch 419/1000
2023-09-20 18:37:11.918 
Epoch 419/1000 
	 loss: 16.3835, MinusLogProbMetric: 16.3835, val_loss: 16.7256, val_MinusLogProbMetric: 16.7256

Epoch 419: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3835 - MinusLogProbMetric: 16.3835 - val_loss: 16.7256 - val_MinusLogProbMetric: 16.7256 - lr: 1.2500e-04 - 42s/epoch - 212ms/step
Epoch 420/1000
2023-09-20 18:37:53.964 
Epoch 420/1000 
	 loss: 16.3865, MinusLogProbMetric: 16.3865, val_loss: 16.7861, val_MinusLogProbMetric: 16.7861

Epoch 420: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3865 - MinusLogProbMetric: 16.3865 - val_loss: 16.7861 - val_MinusLogProbMetric: 16.7861 - lr: 1.2500e-04 - 42s/epoch - 214ms/step
Epoch 421/1000
2023-09-20 18:38:35.655 
Epoch 421/1000 
	 loss: 16.3781, MinusLogProbMetric: 16.3781, val_loss: 16.7403, val_MinusLogProbMetric: 16.7403

Epoch 421: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3781 - MinusLogProbMetric: 16.3781 - val_loss: 16.7403 - val_MinusLogProbMetric: 16.7403 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 422/1000
2023-09-20 18:39:17.130 
Epoch 422/1000 
	 loss: 16.3792, MinusLogProbMetric: 16.3792, val_loss: 16.7326, val_MinusLogProbMetric: 16.7326

Epoch 422: val_loss did not improve from 16.71688
196/196 - 41s - loss: 16.3792 - MinusLogProbMetric: 16.3792 - val_loss: 16.7326 - val_MinusLogProbMetric: 16.7326 - lr: 1.2500e-04 - 41s/epoch - 212ms/step
Epoch 423/1000
2023-09-20 18:39:59.211 
Epoch 423/1000 
	 loss: 16.3849, MinusLogProbMetric: 16.3849, val_loss: 16.7402, val_MinusLogProbMetric: 16.7402

Epoch 423: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3849 - MinusLogProbMetric: 16.3849 - val_loss: 16.7402 - val_MinusLogProbMetric: 16.7402 - lr: 1.2500e-04 - 42s/epoch - 215ms/step
Epoch 424/1000
2023-09-20 18:40:40.982 
Epoch 424/1000 
	 loss: 16.3785, MinusLogProbMetric: 16.3785, val_loss: 16.7194, val_MinusLogProbMetric: 16.7194

Epoch 424: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3785 - MinusLogProbMetric: 16.3785 - val_loss: 16.7194 - val_MinusLogProbMetric: 16.7194 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 425/1000
2023-09-20 18:41:23.227 
Epoch 425/1000 
	 loss: 16.3783, MinusLogProbMetric: 16.3783, val_loss: 16.7285, val_MinusLogProbMetric: 16.7285

Epoch 425: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3783 - MinusLogProbMetric: 16.3783 - val_loss: 16.7285 - val_MinusLogProbMetric: 16.7285 - lr: 1.2500e-04 - 42s/epoch - 216ms/step
Epoch 426/1000
2023-09-20 18:42:05.480 
Epoch 426/1000 
	 loss: 16.3828, MinusLogProbMetric: 16.3828, val_loss: 16.7637, val_MinusLogProbMetric: 16.7637

Epoch 426: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3828 - MinusLogProbMetric: 16.3828 - val_loss: 16.7637 - val_MinusLogProbMetric: 16.7637 - lr: 1.2500e-04 - 42s/epoch - 216ms/step
Epoch 427/1000
2023-09-20 18:42:46.572 
Epoch 427/1000 
	 loss: 16.3787, MinusLogProbMetric: 16.3787, val_loss: 16.7265, val_MinusLogProbMetric: 16.7265

Epoch 427: val_loss did not improve from 16.71688
196/196 - 41s - loss: 16.3787 - MinusLogProbMetric: 16.3787 - val_loss: 16.7265 - val_MinusLogProbMetric: 16.7265 - lr: 1.2500e-04 - 41s/epoch - 210ms/step
Epoch 428/1000
2023-09-20 18:43:28.825 
Epoch 428/1000 
	 loss: 16.3798, MinusLogProbMetric: 16.3798, val_loss: 16.7369, val_MinusLogProbMetric: 16.7369

Epoch 428: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3798 - MinusLogProbMetric: 16.3798 - val_loss: 16.7369 - val_MinusLogProbMetric: 16.7369 - lr: 1.2500e-04 - 42s/epoch - 216ms/step
Epoch 429/1000
2023-09-20 18:44:10.749 
Epoch 429/1000 
	 loss: 16.3777, MinusLogProbMetric: 16.3777, val_loss: 16.7236, val_MinusLogProbMetric: 16.7236

Epoch 429: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3777 - MinusLogProbMetric: 16.3777 - val_loss: 16.7236 - val_MinusLogProbMetric: 16.7236 - lr: 1.2500e-04 - 42s/epoch - 214ms/step
Epoch 430/1000
2023-09-20 18:44:52.847 
Epoch 430/1000 
	 loss: 16.3835, MinusLogProbMetric: 16.3835, val_loss: 16.7371, val_MinusLogProbMetric: 16.7371

Epoch 430: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3835 - MinusLogProbMetric: 16.3835 - val_loss: 16.7371 - val_MinusLogProbMetric: 16.7371 - lr: 1.2500e-04 - 42s/epoch - 215ms/step
Epoch 431/1000
2023-09-20 18:45:34.515 
Epoch 431/1000 
	 loss: 16.3846, MinusLogProbMetric: 16.3846, val_loss: 16.7207, val_MinusLogProbMetric: 16.7207

Epoch 431: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3846 - MinusLogProbMetric: 16.3846 - val_loss: 16.7207 - val_MinusLogProbMetric: 16.7207 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 432/1000
2023-09-20 18:46:16.259 
Epoch 432/1000 
	 loss: 16.3782, MinusLogProbMetric: 16.3782, val_loss: 16.7310, val_MinusLogProbMetric: 16.7310

Epoch 432: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3782 - MinusLogProbMetric: 16.3782 - val_loss: 16.7310 - val_MinusLogProbMetric: 16.7310 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 433/1000
2023-09-20 18:46:57.899 
Epoch 433/1000 
	 loss: 16.3848, MinusLogProbMetric: 16.3848, val_loss: 16.7380, val_MinusLogProbMetric: 16.7380

Epoch 433: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3848 - MinusLogProbMetric: 16.3848 - val_loss: 16.7380 - val_MinusLogProbMetric: 16.7380 - lr: 1.2500e-04 - 42s/epoch - 212ms/step
Epoch 434/1000
2023-09-20 18:47:39.813 
Epoch 434/1000 
	 loss: 16.3772, MinusLogProbMetric: 16.3772, val_loss: 16.7336, val_MinusLogProbMetric: 16.7336

Epoch 434: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3772 - MinusLogProbMetric: 16.3772 - val_loss: 16.7336 - val_MinusLogProbMetric: 16.7336 - lr: 1.2500e-04 - 42s/epoch - 214ms/step
Epoch 435/1000
2023-09-20 18:48:21.503 
Epoch 435/1000 
	 loss: 16.3886, MinusLogProbMetric: 16.3886, val_loss: 16.7283, val_MinusLogProbMetric: 16.7283

Epoch 435: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3886 - MinusLogProbMetric: 16.3886 - val_loss: 16.7283 - val_MinusLogProbMetric: 16.7283 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 436/1000
2023-09-20 18:49:03.390 
Epoch 436/1000 
	 loss: 16.3827, MinusLogProbMetric: 16.3827, val_loss: 16.7604, val_MinusLogProbMetric: 16.7604

Epoch 436: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3827 - MinusLogProbMetric: 16.3827 - val_loss: 16.7604 - val_MinusLogProbMetric: 16.7604 - lr: 1.2500e-04 - 42s/epoch - 214ms/step
Epoch 437/1000
2023-09-20 18:49:44.947 
Epoch 437/1000 
	 loss: 16.3828, MinusLogProbMetric: 16.3828, val_loss: 16.7249, val_MinusLogProbMetric: 16.7249

Epoch 437: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3828 - MinusLogProbMetric: 16.3828 - val_loss: 16.7249 - val_MinusLogProbMetric: 16.7249 - lr: 1.2500e-04 - 42s/epoch - 212ms/step
Epoch 438/1000
2023-09-20 18:50:26.691 
Epoch 438/1000 
	 loss: 16.3797, MinusLogProbMetric: 16.3797, val_loss: 16.7310, val_MinusLogProbMetric: 16.7310

Epoch 438: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3797 - MinusLogProbMetric: 16.3797 - val_loss: 16.7310 - val_MinusLogProbMetric: 16.7310 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 439/1000
2023-09-20 18:51:07.922 
Epoch 439/1000 
	 loss: 16.3828, MinusLogProbMetric: 16.3828, val_loss: 16.7478, val_MinusLogProbMetric: 16.7478

Epoch 439: val_loss did not improve from 16.71688
196/196 - 41s - loss: 16.3828 - MinusLogProbMetric: 16.3828 - val_loss: 16.7478 - val_MinusLogProbMetric: 16.7478 - lr: 1.2500e-04 - 41s/epoch - 210ms/step
Epoch 440/1000
2023-09-20 18:51:49.138 
Epoch 440/1000 
	 loss: 16.3805, MinusLogProbMetric: 16.3805, val_loss: 16.7302, val_MinusLogProbMetric: 16.7302

Epoch 440: val_loss did not improve from 16.71688
196/196 - 41s - loss: 16.3805 - MinusLogProbMetric: 16.3805 - val_loss: 16.7302 - val_MinusLogProbMetric: 16.7302 - lr: 1.2500e-04 - 41s/epoch - 210ms/step
Epoch 441/1000
2023-09-20 18:52:30.606 
Epoch 441/1000 
	 loss: 16.3860, MinusLogProbMetric: 16.3860, val_loss: 16.7392, val_MinusLogProbMetric: 16.7392

Epoch 441: val_loss did not improve from 16.71688
196/196 - 41s - loss: 16.3860 - MinusLogProbMetric: 16.3860 - val_loss: 16.7392 - val_MinusLogProbMetric: 16.7392 - lr: 1.2500e-04 - 41s/epoch - 212ms/step
Epoch 442/1000
2023-09-20 18:53:12.180 
Epoch 442/1000 
	 loss: 16.3788, MinusLogProbMetric: 16.3788, val_loss: 16.7470, val_MinusLogProbMetric: 16.7470

Epoch 442: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3788 - MinusLogProbMetric: 16.3788 - val_loss: 16.7470 - val_MinusLogProbMetric: 16.7470 - lr: 1.2500e-04 - 42s/epoch - 212ms/step
Epoch 443/1000
2023-09-20 18:53:54.375 
Epoch 443/1000 
	 loss: 16.3790, MinusLogProbMetric: 16.3790, val_loss: 16.7400, val_MinusLogProbMetric: 16.7400

Epoch 443: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3790 - MinusLogProbMetric: 16.3790 - val_loss: 16.7400 - val_MinusLogProbMetric: 16.7400 - lr: 1.2500e-04 - 42s/epoch - 215ms/step
Epoch 444/1000
2023-09-20 18:54:36.006 
Epoch 444/1000 
	 loss: 16.3811, MinusLogProbMetric: 16.3811, val_loss: 16.7341, val_MinusLogProbMetric: 16.7341

Epoch 444: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3811 - MinusLogProbMetric: 16.3811 - val_loss: 16.7341 - val_MinusLogProbMetric: 16.7341 - lr: 1.2500e-04 - 42s/epoch - 212ms/step
Epoch 445/1000
2023-09-20 18:55:17.846 
Epoch 445/1000 
	 loss: 16.3772, MinusLogProbMetric: 16.3772, val_loss: 16.7394, val_MinusLogProbMetric: 16.7394

Epoch 445: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3772 - MinusLogProbMetric: 16.3772 - val_loss: 16.7394 - val_MinusLogProbMetric: 16.7394 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 446/1000
2023-09-20 18:55:59.064 
Epoch 446/1000 
	 loss: 16.3780, MinusLogProbMetric: 16.3780, val_loss: 16.7472, val_MinusLogProbMetric: 16.7472

Epoch 446: val_loss did not improve from 16.71688
196/196 - 41s - loss: 16.3780 - MinusLogProbMetric: 16.3780 - val_loss: 16.7472 - val_MinusLogProbMetric: 16.7472 - lr: 1.2500e-04 - 41s/epoch - 210ms/step
Epoch 447/1000
2023-09-20 18:56:40.531 
Epoch 447/1000 
	 loss: 16.3802, MinusLogProbMetric: 16.3802, val_loss: 16.7345, val_MinusLogProbMetric: 16.7345

Epoch 447: val_loss did not improve from 16.71688
196/196 - 41s - loss: 16.3802 - MinusLogProbMetric: 16.3802 - val_loss: 16.7345 - val_MinusLogProbMetric: 16.7345 - lr: 1.2500e-04 - 41s/epoch - 212ms/step
Epoch 448/1000
2023-09-20 18:57:21.912 
Epoch 448/1000 
	 loss: 16.3817, MinusLogProbMetric: 16.3817, val_loss: 16.7227, val_MinusLogProbMetric: 16.7227

Epoch 448: val_loss did not improve from 16.71688
196/196 - 41s - loss: 16.3817 - MinusLogProbMetric: 16.3817 - val_loss: 16.7227 - val_MinusLogProbMetric: 16.7227 - lr: 1.2500e-04 - 41s/epoch - 211ms/step
Epoch 449/1000
2023-09-20 18:58:03.907 
Epoch 449/1000 
	 loss: 16.3778, MinusLogProbMetric: 16.3778, val_loss: 16.7464, val_MinusLogProbMetric: 16.7464

Epoch 449: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3778 - MinusLogProbMetric: 16.3778 - val_loss: 16.7464 - val_MinusLogProbMetric: 16.7464 - lr: 1.2500e-04 - 42s/epoch - 214ms/step
Epoch 450/1000
2023-09-20 18:58:45.088 
Epoch 450/1000 
	 loss: 16.3777, MinusLogProbMetric: 16.3777, val_loss: 16.7276, val_MinusLogProbMetric: 16.7276

Epoch 450: val_loss did not improve from 16.71688
196/196 - 41s - loss: 16.3777 - MinusLogProbMetric: 16.3777 - val_loss: 16.7276 - val_MinusLogProbMetric: 16.7276 - lr: 1.2500e-04 - 41s/epoch - 210ms/step
Epoch 451/1000
2023-09-20 18:59:26.869 
Epoch 451/1000 
	 loss: 16.3788, MinusLogProbMetric: 16.3788, val_loss: 16.7363, val_MinusLogProbMetric: 16.7363

Epoch 451: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3788 - MinusLogProbMetric: 16.3788 - val_loss: 16.7363 - val_MinusLogProbMetric: 16.7363 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 452/1000
2023-09-20 19:00:08.583 
Epoch 452/1000 
	 loss: 16.3757, MinusLogProbMetric: 16.3757, val_loss: 16.7405, val_MinusLogProbMetric: 16.7405

Epoch 452: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3757 - MinusLogProbMetric: 16.3757 - val_loss: 16.7405 - val_MinusLogProbMetric: 16.7405 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 453/1000
2023-09-20 19:00:50.870 
Epoch 453/1000 
	 loss: 16.3760, MinusLogProbMetric: 16.3760, val_loss: 16.7413, val_MinusLogProbMetric: 16.7413

Epoch 453: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3760 - MinusLogProbMetric: 16.3760 - val_loss: 16.7413 - val_MinusLogProbMetric: 16.7413 - lr: 1.2500e-04 - 42s/epoch - 216ms/step
Epoch 454/1000
2023-09-20 19:01:32.944 
Epoch 454/1000 
	 loss: 16.3755, MinusLogProbMetric: 16.3755, val_loss: 16.7403, val_MinusLogProbMetric: 16.7403

Epoch 454: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3755 - MinusLogProbMetric: 16.3755 - val_loss: 16.7403 - val_MinusLogProbMetric: 16.7403 - lr: 1.2500e-04 - 42s/epoch - 215ms/step
Epoch 455/1000
2023-09-20 19:02:14.467 
Epoch 455/1000 
	 loss: 16.3730, MinusLogProbMetric: 16.3730, val_loss: 16.7473, val_MinusLogProbMetric: 16.7473

Epoch 455: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3730 - MinusLogProbMetric: 16.3730 - val_loss: 16.7473 - val_MinusLogProbMetric: 16.7473 - lr: 1.2500e-04 - 42s/epoch - 212ms/step
Epoch 456/1000
2023-09-20 19:02:56.392 
Epoch 456/1000 
	 loss: 16.3783, MinusLogProbMetric: 16.3783, val_loss: 16.7570, val_MinusLogProbMetric: 16.7570

Epoch 456: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3783 - MinusLogProbMetric: 16.3783 - val_loss: 16.7570 - val_MinusLogProbMetric: 16.7570 - lr: 1.2500e-04 - 42s/epoch - 214ms/step
Epoch 457/1000
2023-09-20 19:03:38.430 
Epoch 457/1000 
	 loss: 16.3800, MinusLogProbMetric: 16.3800, val_loss: 16.7329, val_MinusLogProbMetric: 16.7329

Epoch 457: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3800 - MinusLogProbMetric: 16.3800 - val_loss: 16.7329 - val_MinusLogProbMetric: 16.7329 - lr: 1.2500e-04 - 42s/epoch - 214ms/step
Epoch 458/1000
2023-09-20 19:04:20.674 
Epoch 458/1000 
	 loss: 16.3759, MinusLogProbMetric: 16.3759, val_loss: 16.7317, val_MinusLogProbMetric: 16.7317

Epoch 458: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3759 - MinusLogProbMetric: 16.3759 - val_loss: 16.7317 - val_MinusLogProbMetric: 16.7317 - lr: 1.2500e-04 - 42s/epoch - 215ms/step
Epoch 459/1000
2023-09-20 19:05:02.438 
Epoch 459/1000 
	 loss: 16.3776, MinusLogProbMetric: 16.3776, val_loss: 16.7325, val_MinusLogProbMetric: 16.7325

Epoch 459: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3776 - MinusLogProbMetric: 16.3776 - val_loss: 16.7325 - val_MinusLogProbMetric: 16.7325 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 460/1000
2023-09-20 19:05:44.101 
Epoch 460/1000 
	 loss: 16.3751, MinusLogProbMetric: 16.3751, val_loss: 16.7251, val_MinusLogProbMetric: 16.7251

Epoch 460: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3751 - MinusLogProbMetric: 16.3751 - val_loss: 16.7251 - val_MinusLogProbMetric: 16.7251 - lr: 1.2500e-04 - 42s/epoch - 213ms/step
Epoch 461/1000
2023-09-20 19:06:26.001 
Epoch 461/1000 
	 loss: 16.3773, MinusLogProbMetric: 16.3773, val_loss: 16.7293, val_MinusLogProbMetric: 16.7293

Epoch 461: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3773 - MinusLogProbMetric: 16.3773 - val_loss: 16.7293 - val_MinusLogProbMetric: 16.7293 - lr: 1.2500e-04 - 42s/epoch - 214ms/step
Epoch 462/1000
2023-09-20 19:07:08.024 
Epoch 462/1000 
	 loss: 16.3821, MinusLogProbMetric: 16.3821, val_loss: 16.7587, val_MinusLogProbMetric: 16.7587

Epoch 462: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3821 - MinusLogProbMetric: 16.3821 - val_loss: 16.7587 - val_MinusLogProbMetric: 16.7587 - lr: 1.2500e-04 - 42s/epoch - 214ms/step
Epoch 463/1000
2023-09-20 19:07:49.584 
Epoch 463/1000 
	 loss: 16.3753, MinusLogProbMetric: 16.3753, val_loss: 16.7326, val_MinusLogProbMetric: 16.7326

Epoch 463: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3753 - MinusLogProbMetric: 16.3753 - val_loss: 16.7326 - val_MinusLogProbMetric: 16.7326 - lr: 1.2500e-04 - 42s/epoch - 212ms/step
Epoch 464/1000
2023-09-20 19:08:31.581 
Epoch 464/1000 
	 loss: 16.3748, MinusLogProbMetric: 16.3748, val_loss: 16.7566, val_MinusLogProbMetric: 16.7566

Epoch 464: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3748 - MinusLogProbMetric: 16.3748 - val_loss: 16.7566 - val_MinusLogProbMetric: 16.7566 - lr: 1.2500e-04 - 42s/epoch - 214ms/step
Epoch 465/1000
2023-09-20 19:09:13.078 
Epoch 465/1000 
	 loss: 16.3803, MinusLogProbMetric: 16.3803, val_loss: 16.7749, val_MinusLogProbMetric: 16.7749

Epoch 465: val_loss did not improve from 16.71688
196/196 - 41s - loss: 16.3803 - MinusLogProbMetric: 16.3803 - val_loss: 16.7749 - val_MinusLogProbMetric: 16.7749 - lr: 1.2500e-04 - 41s/epoch - 212ms/step
Epoch 466/1000
2023-09-20 19:09:55.035 
Epoch 466/1000 
	 loss: 16.3756, MinusLogProbMetric: 16.3756, val_loss: 16.7486, val_MinusLogProbMetric: 16.7486

Epoch 466: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3756 - MinusLogProbMetric: 16.3756 - val_loss: 16.7486 - val_MinusLogProbMetric: 16.7486 - lr: 1.2500e-04 - 42s/epoch - 214ms/step
Epoch 467/1000
2023-09-20 19:10:36.459 
Epoch 467/1000 
	 loss: 16.3769, MinusLogProbMetric: 16.3769, val_loss: 16.7223, val_MinusLogProbMetric: 16.7223

Epoch 467: val_loss did not improve from 16.71688
196/196 - 41s - loss: 16.3769 - MinusLogProbMetric: 16.3769 - val_loss: 16.7223 - val_MinusLogProbMetric: 16.7223 - lr: 1.2500e-04 - 41s/epoch - 211ms/step
Epoch 468/1000
2023-09-20 19:11:18.109 
Epoch 468/1000 
	 loss: 16.3746, MinusLogProbMetric: 16.3746, val_loss: 16.7789, val_MinusLogProbMetric: 16.7789

Epoch 468: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3746 - MinusLogProbMetric: 16.3746 - val_loss: 16.7789 - val_MinusLogProbMetric: 16.7789 - lr: 1.2500e-04 - 42s/epoch - 212ms/step
Epoch 469/1000
2023-09-20 19:11:59.869 
Epoch 469/1000 
	 loss: 16.3578, MinusLogProbMetric: 16.3578, val_loss: 16.7259, val_MinusLogProbMetric: 16.7259

Epoch 469: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3578 - MinusLogProbMetric: 16.3578 - val_loss: 16.7259 - val_MinusLogProbMetric: 16.7259 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 470/1000
2023-09-20 19:12:41.895 
Epoch 470/1000 
	 loss: 16.3566, MinusLogProbMetric: 16.3566, val_loss: 16.7258, val_MinusLogProbMetric: 16.7258

Epoch 470: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3566 - MinusLogProbMetric: 16.3566 - val_loss: 16.7258 - val_MinusLogProbMetric: 16.7258 - lr: 6.2500e-05 - 42s/epoch - 214ms/step
Epoch 471/1000
2023-09-20 19:13:23.991 
Epoch 471/1000 
	 loss: 16.3574, MinusLogProbMetric: 16.3574, val_loss: 16.7252, val_MinusLogProbMetric: 16.7252

Epoch 471: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3574 - MinusLogProbMetric: 16.3574 - val_loss: 16.7252 - val_MinusLogProbMetric: 16.7252 - lr: 6.2500e-05 - 42s/epoch - 215ms/step
Epoch 472/1000
2023-09-20 19:14:06.203 
Epoch 472/1000 
	 loss: 16.3553, MinusLogProbMetric: 16.3553, val_loss: 16.7209, val_MinusLogProbMetric: 16.7209

Epoch 472: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3553 - MinusLogProbMetric: 16.3553 - val_loss: 16.7209 - val_MinusLogProbMetric: 16.7209 - lr: 6.2500e-05 - 42s/epoch - 215ms/step
Epoch 473/1000
2023-09-20 19:14:48.412 
Epoch 473/1000 
	 loss: 16.3563, MinusLogProbMetric: 16.3563, val_loss: 16.7330, val_MinusLogProbMetric: 16.7330

Epoch 473: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3563 - MinusLogProbMetric: 16.3563 - val_loss: 16.7330 - val_MinusLogProbMetric: 16.7330 - lr: 6.2500e-05 - 42s/epoch - 215ms/step
Epoch 474/1000
2023-09-20 19:15:30.489 
Epoch 474/1000 
	 loss: 16.3556, MinusLogProbMetric: 16.3556, val_loss: 16.7184, val_MinusLogProbMetric: 16.7184

Epoch 474: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3556 - MinusLogProbMetric: 16.3556 - val_loss: 16.7184 - val_MinusLogProbMetric: 16.7184 - lr: 6.2500e-05 - 42s/epoch - 215ms/step
Epoch 475/1000
2023-09-20 19:16:12.126 
Epoch 475/1000 
	 loss: 16.3543, MinusLogProbMetric: 16.3543, val_loss: 16.7215, val_MinusLogProbMetric: 16.7215

Epoch 475: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3543 - MinusLogProbMetric: 16.3543 - val_loss: 16.7215 - val_MinusLogProbMetric: 16.7215 - lr: 6.2500e-05 - 42s/epoch - 212ms/step
Epoch 476/1000
2023-09-20 19:16:54.114 
Epoch 476/1000 
	 loss: 16.3551, MinusLogProbMetric: 16.3551, val_loss: 16.7224, val_MinusLogProbMetric: 16.7224

Epoch 476: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3551 - MinusLogProbMetric: 16.3551 - val_loss: 16.7224 - val_MinusLogProbMetric: 16.7224 - lr: 6.2500e-05 - 42s/epoch - 214ms/step
Epoch 477/1000
2023-09-20 19:17:35.780 
Epoch 477/1000 
	 loss: 16.3546, MinusLogProbMetric: 16.3546, val_loss: 16.7219, val_MinusLogProbMetric: 16.7219

Epoch 477: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3546 - MinusLogProbMetric: 16.3546 - val_loss: 16.7219 - val_MinusLogProbMetric: 16.7219 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 478/1000
2023-09-20 19:18:17.883 
Epoch 478/1000 
	 loss: 16.3544, MinusLogProbMetric: 16.3544, val_loss: 16.7233, val_MinusLogProbMetric: 16.7233

Epoch 478: val_loss did not improve from 16.71688
196/196 - 42s - loss: 16.3544 - MinusLogProbMetric: 16.3544 - val_loss: 16.7233 - val_MinusLogProbMetric: 16.7233 - lr: 6.2500e-05 - 42s/epoch - 215ms/step
Epoch 479/1000
2023-09-20 19:18:59.516 
Epoch 479/1000 
	 loss: 16.3541, MinusLogProbMetric: 16.3541, val_loss: 16.7144, val_MinusLogProbMetric: 16.7144

Epoch 479: val_loss improved from 16.71688 to 16.71440, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_259/weights/best_weights.h5
196/196 - 42s - loss: 16.3541 - MinusLogProbMetric: 16.3541 - val_loss: 16.7144 - val_MinusLogProbMetric: 16.7144 - lr: 6.2500e-05 - 42s/epoch - 216ms/step
Epoch 480/1000
2023-09-20 19:19:42.172 
Epoch 480/1000 
	 loss: 16.3542, MinusLogProbMetric: 16.3542, val_loss: 16.7172, val_MinusLogProbMetric: 16.7172

Epoch 480: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3542 - MinusLogProbMetric: 16.3542 - val_loss: 16.7172 - val_MinusLogProbMetric: 16.7172 - lr: 6.2500e-05 - 42s/epoch - 214ms/step
Epoch 481/1000
2023-09-20 19:20:23.911 
Epoch 481/1000 
	 loss: 16.3552, MinusLogProbMetric: 16.3552, val_loss: 16.7197, val_MinusLogProbMetric: 16.7197

Epoch 481: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3552 - MinusLogProbMetric: 16.3552 - val_loss: 16.7197 - val_MinusLogProbMetric: 16.7197 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 482/1000
2023-09-20 19:21:05.599 
Epoch 482/1000 
	 loss: 16.3536, MinusLogProbMetric: 16.3536, val_loss: 16.7315, val_MinusLogProbMetric: 16.7315

Epoch 482: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3536 - MinusLogProbMetric: 16.3536 - val_loss: 16.7315 - val_MinusLogProbMetric: 16.7315 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 483/1000
2023-09-20 19:21:47.402 
Epoch 483/1000 
	 loss: 16.3549, MinusLogProbMetric: 16.3549, val_loss: 16.7247, val_MinusLogProbMetric: 16.7247

Epoch 483: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3549 - MinusLogProbMetric: 16.3549 - val_loss: 16.7247 - val_MinusLogProbMetric: 16.7247 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 484/1000
2023-09-20 19:22:29.072 
Epoch 484/1000 
	 loss: 16.3562, MinusLogProbMetric: 16.3562, val_loss: 16.7178, val_MinusLogProbMetric: 16.7178

Epoch 484: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3562 - MinusLogProbMetric: 16.3562 - val_loss: 16.7178 - val_MinusLogProbMetric: 16.7178 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 485/1000
2023-09-20 19:23:11.136 
Epoch 485/1000 
	 loss: 16.3556, MinusLogProbMetric: 16.3556, val_loss: 16.7261, val_MinusLogProbMetric: 16.7261

Epoch 485: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3556 - MinusLogProbMetric: 16.3556 - val_loss: 16.7261 - val_MinusLogProbMetric: 16.7261 - lr: 6.2500e-05 - 42s/epoch - 215ms/step
Epoch 486/1000
2023-09-20 19:23:52.855 
Epoch 486/1000 
	 loss: 16.3559, MinusLogProbMetric: 16.3559, val_loss: 16.7392, val_MinusLogProbMetric: 16.7392

Epoch 486: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3559 - MinusLogProbMetric: 16.3559 - val_loss: 16.7392 - val_MinusLogProbMetric: 16.7392 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 487/1000
2023-09-20 19:24:34.453 
Epoch 487/1000 
	 loss: 16.3546, MinusLogProbMetric: 16.3546, val_loss: 16.7218, val_MinusLogProbMetric: 16.7218

Epoch 487: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3546 - MinusLogProbMetric: 16.3546 - val_loss: 16.7218 - val_MinusLogProbMetric: 16.7218 - lr: 6.2500e-05 - 42s/epoch - 212ms/step
Epoch 488/1000
2023-09-20 19:25:16.070 
Epoch 488/1000 
	 loss: 16.3547, MinusLogProbMetric: 16.3547, val_loss: 16.7244, val_MinusLogProbMetric: 16.7244

Epoch 488: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3547 - MinusLogProbMetric: 16.3547 - val_loss: 16.7244 - val_MinusLogProbMetric: 16.7244 - lr: 6.2500e-05 - 42s/epoch - 212ms/step
Epoch 489/1000
2023-09-20 19:25:58.284 
Epoch 489/1000 
	 loss: 16.3548, MinusLogProbMetric: 16.3548, val_loss: 16.7291, val_MinusLogProbMetric: 16.7291

Epoch 489: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3548 - MinusLogProbMetric: 16.3548 - val_loss: 16.7291 - val_MinusLogProbMetric: 16.7291 - lr: 6.2500e-05 - 42s/epoch - 215ms/step
Epoch 490/1000
2023-09-20 19:26:39.875 
Epoch 490/1000 
	 loss: 16.3558, MinusLogProbMetric: 16.3558, val_loss: 16.7223, val_MinusLogProbMetric: 16.7223

Epoch 490: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3558 - MinusLogProbMetric: 16.3558 - val_loss: 16.7223 - val_MinusLogProbMetric: 16.7223 - lr: 6.2500e-05 - 42s/epoch - 212ms/step
Epoch 491/1000
2023-09-20 19:27:22.190 
Epoch 491/1000 
	 loss: 16.3531, MinusLogProbMetric: 16.3531, val_loss: 16.7267, val_MinusLogProbMetric: 16.7267

Epoch 491: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3531 - MinusLogProbMetric: 16.3531 - val_loss: 16.7267 - val_MinusLogProbMetric: 16.7267 - lr: 6.2500e-05 - 42s/epoch - 216ms/step
Epoch 492/1000
2023-09-20 19:28:04.246 
Epoch 492/1000 
	 loss: 16.3548, MinusLogProbMetric: 16.3548, val_loss: 16.7268, val_MinusLogProbMetric: 16.7268

Epoch 492: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3548 - MinusLogProbMetric: 16.3548 - val_loss: 16.7268 - val_MinusLogProbMetric: 16.7268 - lr: 6.2500e-05 - 42s/epoch - 215ms/step
Epoch 493/1000
2023-09-20 19:28:45.986 
Epoch 493/1000 
	 loss: 16.3553, MinusLogProbMetric: 16.3553, val_loss: 16.7241, val_MinusLogProbMetric: 16.7241

Epoch 493: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3553 - MinusLogProbMetric: 16.3553 - val_loss: 16.7241 - val_MinusLogProbMetric: 16.7241 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 494/1000
2023-09-20 19:29:27.660 
Epoch 494/1000 
	 loss: 16.3553, MinusLogProbMetric: 16.3553, val_loss: 16.7221, val_MinusLogProbMetric: 16.7221

Epoch 494: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3553 - MinusLogProbMetric: 16.3553 - val_loss: 16.7221 - val_MinusLogProbMetric: 16.7221 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 495/1000
2023-09-20 19:30:09.326 
Epoch 495/1000 
	 loss: 16.3534, MinusLogProbMetric: 16.3534, val_loss: 16.7179, val_MinusLogProbMetric: 16.7179

Epoch 495: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3534 - MinusLogProbMetric: 16.3534 - val_loss: 16.7179 - val_MinusLogProbMetric: 16.7179 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 496/1000
2023-09-20 19:30:51.333 
Epoch 496/1000 
	 loss: 16.3561, MinusLogProbMetric: 16.3561, val_loss: 16.7251, val_MinusLogProbMetric: 16.7251

Epoch 496: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3561 - MinusLogProbMetric: 16.3561 - val_loss: 16.7251 - val_MinusLogProbMetric: 16.7251 - lr: 6.2500e-05 - 42s/epoch - 214ms/step
Epoch 497/1000
2023-09-20 19:31:33.028 
Epoch 497/1000 
	 loss: 16.3525, MinusLogProbMetric: 16.3525, val_loss: 16.7218, val_MinusLogProbMetric: 16.7218

Epoch 497: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3525 - MinusLogProbMetric: 16.3525 - val_loss: 16.7218 - val_MinusLogProbMetric: 16.7218 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 498/1000
2023-09-20 19:32:14.818 
Epoch 498/1000 
	 loss: 16.3537, MinusLogProbMetric: 16.3537, val_loss: 16.7248, val_MinusLogProbMetric: 16.7248

Epoch 498: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3537 - MinusLogProbMetric: 16.3537 - val_loss: 16.7248 - val_MinusLogProbMetric: 16.7248 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 499/1000
2023-09-20 19:32:57.041 
Epoch 499/1000 
	 loss: 16.3532, MinusLogProbMetric: 16.3532, val_loss: 16.7247, val_MinusLogProbMetric: 16.7247

Epoch 499: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3532 - MinusLogProbMetric: 16.3532 - val_loss: 16.7247 - val_MinusLogProbMetric: 16.7247 - lr: 6.2500e-05 - 42s/epoch - 215ms/step
Epoch 500/1000
2023-09-20 19:33:38.763 
Epoch 500/1000 
	 loss: 16.3535, MinusLogProbMetric: 16.3535, val_loss: 16.7329, val_MinusLogProbMetric: 16.7329

Epoch 500: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3535 - MinusLogProbMetric: 16.3535 - val_loss: 16.7329 - val_MinusLogProbMetric: 16.7329 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 501/1000
2023-09-20 19:34:20.847 
Epoch 501/1000 
	 loss: 16.3526, MinusLogProbMetric: 16.3526, val_loss: 16.7241, val_MinusLogProbMetric: 16.7241

Epoch 501: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3526 - MinusLogProbMetric: 16.3526 - val_loss: 16.7241 - val_MinusLogProbMetric: 16.7241 - lr: 6.2500e-05 - 42s/epoch - 215ms/step
Epoch 502/1000
2023-09-20 19:35:02.909 
Epoch 502/1000 
	 loss: 16.3515, MinusLogProbMetric: 16.3515, val_loss: 16.7233, val_MinusLogProbMetric: 16.7233

Epoch 502: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3515 - MinusLogProbMetric: 16.3515 - val_loss: 16.7233 - val_MinusLogProbMetric: 16.7233 - lr: 6.2500e-05 - 42s/epoch - 215ms/step
Epoch 503/1000
2023-09-20 19:35:44.758 
Epoch 503/1000 
	 loss: 16.3521, MinusLogProbMetric: 16.3521, val_loss: 16.7196, val_MinusLogProbMetric: 16.7196

Epoch 503: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3521 - MinusLogProbMetric: 16.3521 - val_loss: 16.7196 - val_MinusLogProbMetric: 16.7196 - lr: 6.2500e-05 - 42s/epoch - 214ms/step
Epoch 504/1000
2023-09-20 19:36:26.359 
Epoch 504/1000 
	 loss: 16.3522, MinusLogProbMetric: 16.3522, val_loss: 16.7207, val_MinusLogProbMetric: 16.7207

Epoch 504: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3522 - MinusLogProbMetric: 16.3522 - val_loss: 16.7207 - val_MinusLogProbMetric: 16.7207 - lr: 6.2500e-05 - 42s/epoch - 212ms/step
Epoch 505/1000
2023-09-20 19:37:07.849 
Epoch 505/1000 
	 loss: 16.3525, MinusLogProbMetric: 16.3525, val_loss: 16.7223, val_MinusLogProbMetric: 16.7223

Epoch 505: val_loss did not improve from 16.71440
196/196 - 41s - loss: 16.3525 - MinusLogProbMetric: 16.3525 - val_loss: 16.7223 - val_MinusLogProbMetric: 16.7223 - lr: 6.2500e-05 - 41s/epoch - 212ms/step
Epoch 506/1000
2023-09-20 19:37:49.922 
Epoch 506/1000 
	 loss: 16.3512, MinusLogProbMetric: 16.3512, val_loss: 16.7297, val_MinusLogProbMetric: 16.7297

Epoch 506: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3512 - MinusLogProbMetric: 16.3512 - val_loss: 16.7297 - val_MinusLogProbMetric: 16.7297 - lr: 6.2500e-05 - 42s/epoch - 215ms/step
Epoch 507/1000
2023-09-20 19:38:31.912 
Epoch 507/1000 
	 loss: 16.3532, MinusLogProbMetric: 16.3532, val_loss: 16.7307, val_MinusLogProbMetric: 16.7307

Epoch 507: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3532 - MinusLogProbMetric: 16.3532 - val_loss: 16.7307 - val_MinusLogProbMetric: 16.7307 - lr: 6.2500e-05 - 42s/epoch - 214ms/step
Epoch 508/1000
2023-09-20 19:39:13.416 
Epoch 508/1000 
	 loss: 16.3555, MinusLogProbMetric: 16.3555, val_loss: 16.7373, val_MinusLogProbMetric: 16.7373

Epoch 508: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3555 - MinusLogProbMetric: 16.3555 - val_loss: 16.7373 - val_MinusLogProbMetric: 16.7373 - lr: 6.2500e-05 - 42s/epoch - 212ms/step
Epoch 509/1000
2023-09-20 19:39:55.107 
Epoch 509/1000 
	 loss: 16.3542, MinusLogProbMetric: 16.3542, val_loss: 16.7318, val_MinusLogProbMetric: 16.7318

Epoch 509: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3542 - MinusLogProbMetric: 16.3542 - val_loss: 16.7318 - val_MinusLogProbMetric: 16.7318 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 510/1000
2023-09-20 19:40:36.966 
Epoch 510/1000 
	 loss: 16.3525, MinusLogProbMetric: 16.3525, val_loss: 16.7241, val_MinusLogProbMetric: 16.7241

Epoch 510: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3525 - MinusLogProbMetric: 16.3525 - val_loss: 16.7241 - val_MinusLogProbMetric: 16.7241 - lr: 6.2500e-05 - 42s/epoch - 214ms/step
Epoch 511/1000
2023-09-20 19:41:18.633 
Epoch 511/1000 
	 loss: 16.3525, MinusLogProbMetric: 16.3525, val_loss: 16.7199, val_MinusLogProbMetric: 16.7199

Epoch 511: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3525 - MinusLogProbMetric: 16.3525 - val_loss: 16.7199 - val_MinusLogProbMetric: 16.7199 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 512/1000
2023-09-20 19:42:00.396 
Epoch 512/1000 
	 loss: 16.3522, MinusLogProbMetric: 16.3522, val_loss: 16.7383, val_MinusLogProbMetric: 16.7383

Epoch 512: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3522 - MinusLogProbMetric: 16.3522 - val_loss: 16.7383 - val_MinusLogProbMetric: 16.7383 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 513/1000
2023-09-20 19:42:41.694 
Epoch 513/1000 
	 loss: 16.3535, MinusLogProbMetric: 16.3535, val_loss: 16.7259, val_MinusLogProbMetric: 16.7259

Epoch 513: val_loss did not improve from 16.71440
196/196 - 41s - loss: 16.3535 - MinusLogProbMetric: 16.3535 - val_loss: 16.7259 - val_MinusLogProbMetric: 16.7259 - lr: 6.2500e-05 - 41s/epoch - 211ms/step
Epoch 514/1000
2023-09-20 19:43:23.205 
Epoch 514/1000 
	 loss: 16.3519, MinusLogProbMetric: 16.3519, val_loss: 16.7229, val_MinusLogProbMetric: 16.7229

Epoch 514: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3519 - MinusLogProbMetric: 16.3519 - val_loss: 16.7229 - val_MinusLogProbMetric: 16.7229 - lr: 6.2500e-05 - 42s/epoch - 212ms/step
Epoch 515/1000
2023-09-20 19:44:05.131 
Epoch 515/1000 
	 loss: 16.3512, MinusLogProbMetric: 16.3512, val_loss: 16.7238, val_MinusLogProbMetric: 16.7238

Epoch 515: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3512 - MinusLogProbMetric: 16.3512 - val_loss: 16.7238 - val_MinusLogProbMetric: 16.7238 - lr: 6.2500e-05 - 42s/epoch - 214ms/step
Epoch 516/1000
2023-09-20 19:44:46.929 
Epoch 516/1000 
	 loss: 16.3512, MinusLogProbMetric: 16.3512, val_loss: 16.7187, val_MinusLogProbMetric: 16.7187

Epoch 516: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3512 - MinusLogProbMetric: 16.3512 - val_loss: 16.7187 - val_MinusLogProbMetric: 16.7187 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 517/1000
2023-09-20 19:45:28.451 
Epoch 517/1000 
	 loss: 16.3509, MinusLogProbMetric: 16.3509, val_loss: 16.7223, val_MinusLogProbMetric: 16.7223

Epoch 517: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3509 - MinusLogProbMetric: 16.3509 - val_loss: 16.7223 - val_MinusLogProbMetric: 16.7223 - lr: 6.2500e-05 - 42s/epoch - 212ms/step
Epoch 518/1000
2023-09-20 19:46:10.519 
Epoch 518/1000 
	 loss: 16.3526, MinusLogProbMetric: 16.3526, val_loss: 16.7206, val_MinusLogProbMetric: 16.7206

Epoch 518: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3526 - MinusLogProbMetric: 16.3526 - val_loss: 16.7206 - val_MinusLogProbMetric: 16.7206 - lr: 6.2500e-05 - 42s/epoch - 215ms/step
Epoch 519/1000
2023-09-20 19:46:52.605 
Epoch 519/1000 
	 loss: 16.3514, MinusLogProbMetric: 16.3514, val_loss: 16.7194, val_MinusLogProbMetric: 16.7194

Epoch 519: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3514 - MinusLogProbMetric: 16.3514 - val_loss: 16.7194 - val_MinusLogProbMetric: 16.7194 - lr: 6.2500e-05 - 42s/epoch - 215ms/step
Epoch 520/1000
2023-09-20 19:47:34.083 
Epoch 520/1000 
	 loss: 16.3509, MinusLogProbMetric: 16.3509, val_loss: 16.7381, val_MinusLogProbMetric: 16.7381

Epoch 520: val_loss did not improve from 16.71440
196/196 - 41s - loss: 16.3509 - MinusLogProbMetric: 16.3509 - val_loss: 16.7381 - val_MinusLogProbMetric: 16.7381 - lr: 6.2500e-05 - 41s/epoch - 212ms/step
Epoch 521/1000
2023-09-20 19:48:15.728 
Epoch 521/1000 
	 loss: 16.3523, MinusLogProbMetric: 16.3523, val_loss: 16.7180, val_MinusLogProbMetric: 16.7180

Epoch 521: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3523 - MinusLogProbMetric: 16.3523 - val_loss: 16.7180 - val_MinusLogProbMetric: 16.7180 - lr: 6.2500e-05 - 42s/epoch - 212ms/step
Epoch 522/1000
2023-09-20 19:48:57.605 
Epoch 522/1000 
	 loss: 16.3527, MinusLogProbMetric: 16.3527, val_loss: 16.7208, val_MinusLogProbMetric: 16.7208

Epoch 522: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3527 - MinusLogProbMetric: 16.3527 - val_loss: 16.7208 - val_MinusLogProbMetric: 16.7208 - lr: 6.2500e-05 - 42s/epoch - 214ms/step
Epoch 523/1000
2023-09-20 19:49:39.287 
Epoch 523/1000 
	 loss: 16.3519, MinusLogProbMetric: 16.3519, val_loss: 16.7231, val_MinusLogProbMetric: 16.7231

Epoch 523: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3519 - MinusLogProbMetric: 16.3519 - val_loss: 16.7231 - val_MinusLogProbMetric: 16.7231 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 524/1000
2023-09-20 19:50:21.624 
Epoch 524/1000 
	 loss: 16.3504, MinusLogProbMetric: 16.3504, val_loss: 16.7331, val_MinusLogProbMetric: 16.7331

Epoch 524: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3504 - MinusLogProbMetric: 16.3504 - val_loss: 16.7331 - val_MinusLogProbMetric: 16.7331 - lr: 6.2500e-05 - 42s/epoch - 216ms/step
Epoch 525/1000
2023-09-20 19:51:03.490 
Epoch 525/1000 
	 loss: 16.3524, MinusLogProbMetric: 16.3524, val_loss: 16.7254, val_MinusLogProbMetric: 16.7254

Epoch 525: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3524 - MinusLogProbMetric: 16.3524 - val_loss: 16.7254 - val_MinusLogProbMetric: 16.7254 - lr: 6.2500e-05 - 42s/epoch - 214ms/step
Epoch 526/1000
2023-09-20 19:51:44.650 
Epoch 526/1000 
	 loss: 16.3502, MinusLogProbMetric: 16.3502, val_loss: 16.7407, val_MinusLogProbMetric: 16.7407

Epoch 526: val_loss did not improve from 16.71440
196/196 - 41s - loss: 16.3502 - MinusLogProbMetric: 16.3502 - val_loss: 16.7407 - val_MinusLogProbMetric: 16.7407 - lr: 6.2500e-05 - 41s/epoch - 210ms/step
Epoch 527/1000
2023-09-20 19:52:26.451 
Epoch 527/1000 
	 loss: 16.3510, MinusLogProbMetric: 16.3510, val_loss: 16.7409, val_MinusLogProbMetric: 16.7409

Epoch 527: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3510 - MinusLogProbMetric: 16.3510 - val_loss: 16.7409 - val_MinusLogProbMetric: 16.7409 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 528/1000
2023-09-20 19:53:07.839 
Epoch 528/1000 
	 loss: 16.3517, MinusLogProbMetric: 16.3517, val_loss: 16.7272, val_MinusLogProbMetric: 16.7272

Epoch 528: val_loss did not improve from 16.71440
196/196 - 41s - loss: 16.3517 - MinusLogProbMetric: 16.3517 - val_loss: 16.7272 - val_MinusLogProbMetric: 16.7272 - lr: 6.2500e-05 - 41s/epoch - 211ms/step
Epoch 529/1000
2023-09-20 19:53:49.556 
Epoch 529/1000 
	 loss: 16.3496, MinusLogProbMetric: 16.3496, val_loss: 16.7265, val_MinusLogProbMetric: 16.7265

Epoch 529: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3496 - MinusLogProbMetric: 16.3496 - val_loss: 16.7265 - val_MinusLogProbMetric: 16.7265 - lr: 6.2500e-05 - 42s/epoch - 213ms/step
Epoch 530/1000
2023-09-20 19:54:31.008 
Epoch 530/1000 
	 loss: 16.3427, MinusLogProbMetric: 16.3427, val_loss: 16.7178, val_MinusLogProbMetric: 16.7178

Epoch 530: val_loss did not improve from 16.71440
196/196 - 41s - loss: 16.3427 - MinusLogProbMetric: 16.3427 - val_loss: 16.7178 - val_MinusLogProbMetric: 16.7178 - lr: 3.1250e-05 - 41s/epoch - 211ms/step
Epoch 531/1000
2023-09-20 19:55:12.475 
Epoch 531/1000 
	 loss: 16.3415, MinusLogProbMetric: 16.3415, val_loss: 16.7182, val_MinusLogProbMetric: 16.7182

Epoch 531: val_loss did not improve from 16.71440
196/196 - 41s - loss: 16.3415 - MinusLogProbMetric: 16.3415 - val_loss: 16.7182 - val_MinusLogProbMetric: 16.7182 - lr: 3.1250e-05 - 41s/epoch - 212ms/step
Epoch 532/1000
2023-09-20 19:55:54.505 
Epoch 532/1000 
	 loss: 16.3419, MinusLogProbMetric: 16.3419, val_loss: 16.7181, val_MinusLogProbMetric: 16.7181

Epoch 532: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3419 - MinusLogProbMetric: 16.3419 - val_loss: 16.7181 - val_MinusLogProbMetric: 16.7181 - lr: 3.1250e-05 - 42s/epoch - 214ms/step
Epoch 533/1000
2023-09-20 19:56:36.547 
Epoch 533/1000 
	 loss: 16.3412, MinusLogProbMetric: 16.3412, val_loss: 16.7173, val_MinusLogProbMetric: 16.7173

Epoch 533: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3412 - MinusLogProbMetric: 16.3412 - val_loss: 16.7173 - val_MinusLogProbMetric: 16.7173 - lr: 3.1250e-05 - 42s/epoch - 214ms/step
Epoch 534/1000
2023-09-20 19:57:18.233 
Epoch 534/1000 
	 loss: 16.3408, MinusLogProbMetric: 16.3408, val_loss: 16.7152, val_MinusLogProbMetric: 16.7152

Epoch 534: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3408 - MinusLogProbMetric: 16.3408 - val_loss: 16.7152 - val_MinusLogProbMetric: 16.7152 - lr: 3.1250e-05 - 42s/epoch - 213ms/step
Epoch 535/1000
2023-09-20 19:57:59.648 
Epoch 535/1000 
	 loss: 16.3413, MinusLogProbMetric: 16.3413, val_loss: 16.7175, val_MinusLogProbMetric: 16.7175

Epoch 535: val_loss did not improve from 16.71440
196/196 - 41s - loss: 16.3413 - MinusLogProbMetric: 16.3413 - val_loss: 16.7175 - val_MinusLogProbMetric: 16.7175 - lr: 3.1250e-05 - 41s/epoch - 211ms/step
Epoch 536/1000
2023-09-20 19:58:41.144 
Epoch 536/1000 
	 loss: 16.3415, MinusLogProbMetric: 16.3415, val_loss: 16.7168, val_MinusLogProbMetric: 16.7168

Epoch 536: val_loss did not improve from 16.71440
196/196 - 41s - loss: 16.3415 - MinusLogProbMetric: 16.3415 - val_loss: 16.7168 - val_MinusLogProbMetric: 16.7168 - lr: 3.1250e-05 - 41s/epoch - 212ms/step
Epoch 537/1000
2023-09-20 19:59:23.266 
Epoch 537/1000 
	 loss: 16.3418, MinusLogProbMetric: 16.3418, val_loss: 16.7240, val_MinusLogProbMetric: 16.7240

Epoch 537: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3418 - MinusLogProbMetric: 16.3418 - val_loss: 16.7240 - val_MinusLogProbMetric: 16.7240 - lr: 3.1250e-05 - 42s/epoch - 215ms/step
Epoch 538/1000
2023-09-20 20:00:05.079 
Epoch 538/1000 
	 loss: 16.3412, MinusLogProbMetric: 16.3412, val_loss: 16.7197, val_MinusLogProbMetric: 16.7197

Epoch 538: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3412 - MinusLogProbMetric: 16.3412 - val_loss: 16.7197 - val_MinusLogProbMetric: 16.7197 - lr: 3.1250e-05 - 42s/epoch - 213ms/step
Epoch 539/1000
2023-09-20 20:00:47.260 
Epoch 539/1000 
	 loss: 16.3410, MinusLogProbMetric: 16.3410, val_loss: 16.7208, val_MinusLogProbMetric: 16.7208

Epoch 539: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3410 - MinusLogProbMetric: 16.3410 - val_loss: 16.7208 - val_MinusLogProbMetric: 16.7208 - lr: 3.1250e-05 - 42s/epoch - 215ms/step
Epoch 540/1000
2023-09-20 20:01:29.294 
Epoch 540/1000 
	 loss: 16.3417, MinusLogProbMetric: 16.3417, val_loss: 16.7241, val_MinusLogProbMetric: 16.7241

Epoch 540: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3417 - MinusLogProbMetric: 16.3417 - val_loss: 16.7241 - val_MinusLogProbMetric: 16.7241 - lr: 3.1250e-05 - 42s/epoch - 214ms/step
Epoch 541/1000
2023-09-20 20:02:11.565 
Epoch 541/1000 
	 loss: 16.3410, MinusLogProbMetric: 16.3410, val_loss: 16.7168, val_MinusLogProbMetric: 16.7168

Epoch 541: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3410 - MinusLogProbMetric: 16.3410 - val_loss: 16.7168 - val_MinusLogProbMetric: 16.7168 - lr: 3.1250e-05 - 42s/epoch - 216ms/step
Epoch 542/1000
2023-09-20 20:02:53.835 
Epoch 542/1000 
	 loss: 16.3426, MinusLogProbMetric: 16.3426, val_loss: 16.7202, val_MinusLogProbMetric: 16.7202

Epoch 542: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3426 - MinusLogProbMetric: 16.3426 - val_loss: 16.7202 - val_MinusLogProbMetric: 16.7202 - lr: 3.1250e-05 - 42s/epoch - 216ms/step
Epoch 543/1000
2023-09-20 20:03:35.549 
Epoch 543/1000 
	 loss: 16.3417, MinusLogProbMetric: 16.3417, val_loss: 16.7203, val_MinusLogProbMetric: 16.7203

Epoch 543: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3417 - MinusLogProbMetric: 16.3417 - val_loss: 16.7203 - val_MinusLogProbMetric: 16.7203 - lr: 3.1250e-05 - 42s/epoch - 213ms/step
Epoch 544/1000
2023-09-20 20:04:17.390 
Epoch 544/1000 
	 loss: 16.3400, MinusLogProbMetric: 16.3400, val_loss: 16.7213, val_MinusLogProbMetric: 16.7213

Epoch 544: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3400 - MinusLogProbMetric: 16.3400 - val_loss: 16.7213 - val_MinusLogProbMetric: 16.7213 - lr: 3.1250e-05 - 42s/epoch - 213ms/step
Epoch 545/1000
2023-09-20 20:04:59.111 
Epoch 545/1000 
	 loss: 16.3413, MinusLogProbMetric: 16.3413, val_loss: 16.7183, val_MinusLogProbMetric: 16.7183

Epoch 545: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3413 - MinusLogProbMetric: 16.3413 - val_loss: 16.7183 - val_MinusLogProbMetric: 16.7183 - lr: 3.1250e-05 - 42s/epoch - 213ms/step
Epoch 546/1000
2023-09-20 20:05:40.676 
Epoch 546/1000 
	 loss: 16.3406, MinusLogProbMetric: 16.3406, val_loss: 16.7228, val_MinusLogProbMetric: 16.7228

Epoch 546: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3406 - MinusLogProbMetric: 16.3406 - val_loss: 16.7228 - val_MinusLogProbMetric: 16.7228 - lr: 3.1250e-05 - 42s/epoch - 212ms/step
Epoch 547/1000
2023-09-20 20:06:22.697 
Epoch 547/1000 
	 loss: 16.3421, MinusLogProbMetric: 16.3421, val_loss: 16.7201, val_MinusLogProbMetric: 16.7201

Epoch 547: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3421 - MinusLogProbMetric: 16.3421 - val_loss: 16.7201 - val_MinusLogProbMetric: 16.7201 - lr: 3.1250e-05 - 42s/epoch - 214ms/step
Epoch 548/1000
2023-09-20 20:07:04.864 
Epoch 548/1000 
	 loss: 16.3414, MinusLogProbMetric: 16.3414, val_loss: 16.7224, val_MinusLogProbMetric: 16.7224

Epoch 548: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3414 - MinusLogProbMetric: 16.3414 - val_loss: 16.7224 - val_MinusLogProbMetric: 16.7224 - lr: 3.1250e-05 - 42s/epoch - 215ms/step
Epoch 549/1000
2023-09-20 20:07:46.781 
Epoch 549/1000 
	 loss: 16.3416, MinusLogProbMetric: 16.3416, val_loss: 16.7213, val_MinusLogProbMetric: 16.7213

Epoch 549: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3416 - MinusLogProbMetric: 16.3416 - val_loss: 16.7213 - val_MinusLogProbMetric: 16.7213 - lr: 3.1250e-05 - 42s/epoch - 214ms/step
Epoch 550/1000
2023-09-20 20:08:28.772 
Epoch 550/1000 
	 loss: 16.3421, MinusLogProbMetric: 16.3421, val_loss: 16.7191, val_MinusLogProbMetric: 16.7191

Epoch 550: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3421 - MinusLogProbMetric: 16.3421 - val_loss: 16.7191 - val_MinusLogProbMetric: 16.7191 - lr: 3.1250e-05 - 42s/epoch - 214ms/step
Epoch 551/1000
2023-09-20 20:09:10.275 
Epoch 551/1000 
	 loss: 16.3413, MinusLogProbMetric: 16.3413, val_loss: 16.7184, val_MinusLogProbMetric: 16.7184

Epoch 551: val_loss did not improve from 16.71440
196/196 - 41s - loss: 16.3413 - MinusLogProbMetric: 16.3413 - val_loss: 16.7184 - val_MinusLogProbMetric: 16.7184 - lr: 3.1250e-05 - 41s/epoch - 212ms/step
Epoch 552/1000
2023-09-20 20:09:52.386 
Epoch 552/1000 
	 loss: 16.3409, MinusLogProbMetric: 16.3409, val_loss: 16.7188, val_MinusLogProbMetric: 16.7188

Epoch 552: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3409 - MinusLogProbMetric: 16.3409 - val_loss: 16.7188 - val_MinusLogProbMetric: 16.7188 - lr: 3.1250e-05 - 42s/epoch - 215ms/step
Epoch 553/1000
2023-09-20 20:10:34.045 
Epoch 553/1000 
	 loss: 16.3403, MinusLogProbMetric: 16.3403, val_loss: 16.7179, val_MinusLogProbMetric: 16.7179

Epoch 553: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3403 - MinusLogProbMetric: 16.3403 - val_loss: 16.7179 - val_MinusLogProbMetric: 16.7179 - lr: 3.1250e-05 - 42s/epoch - 213ms/step
Epoch 554/1000
2023-09-20 20:11:15.865 
Epoch 554/1000 
	 loss: 16.3395, MinusLogProbMetric: 16.3395, val_loss: 16.7196, val_MinusLogProbMetric: 16.7196

Epoch 554: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3395 - MinusLogProbMetric: 16.3395 - val_loss: 16.7196 - val_MinusLogProbMetric: 16.7196 - lr: 3.1250e-05 - 42s/epoch - 213ms/step
Epoch 555/1000
2023-09-20 20:11:57.493 
Epoch 555/1000 
	 loss: 16.3406, MinusLogProbMetric: 16.3406, val_loss: 16.7199, val_MinusLogProbMetric: 16.7199

Epoch 555: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3406 - MinusLogProbMetric: 16.3406 - val_loss: 16.7199 - val_MinusLogProbMetric: 16.7199 - lr: 3.1250e-05 - 42s/epoch - 212ms/step
Epoch 556/1000
2023-09-20 20:12:39.332 
Epoch 556/1000 
	 loss: 16.3413, MinusLogProbMetric: 16.3413, val_loss: 16.7222, val_MinusLogProbMetric: 16.7222

Epoch 556: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3413 - MinusLogProbMetric: 16.3413 - val_loss: 16.7222 - val_MinusLogProbMetric: 16.7222 - lr: 3.1250e-05 - 42s/epoch - 213ms/step
Epoch 557/1000
2023-09-20 20:13:20.890 
Epoch 557/1000 
	 loss: 16.3408, MinusLogProbMetric: 16.3408, val_loss: 16.7189, val_MinusLogProbMetric: 16.7189

Epoch 557: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3408 - MinusLogProbMetric: 16.3408 - val_loss: 16.7189 - val_MinusLogProbMetric: 16.7189 - lr: 3.1250e-05 - 42s/epoch - 212ms/step
Epoch 558/1000
2023-09-20 20:14:02.812 
Epoch 558/1000 
	 loss: 16.3401, MinusLogProbMetric: 16.3401, val_loss: 16.7200, val_MinusLogProbMetric: 16.7200

Epoch 558: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3401 - MinusLogProbMetric: 16.3401 - val_loss: 16.7200 - val_MinusLogProbMetric: 16.7200 - lr: 3.1250e-05 - 42s/epoch - 214ms/step
Epoch 559/1000
2023-09-20 20:14:44.485 
Epoch 559/1000 
	 loss: 16.3414, MinusLogProbMetric: 16.3414, val_loss: 16.7179, val_MinusLogProbMetric: 16.7179

Epoch 559: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3414 - MinusLogProbMetric: 16.3414 - val_loss: 16.7179 - val_MinusLogProbMetric: 16.7179 - lr: 3.1250e-05 - 42s/epoch - 213ms/step
Epoch 560/1000
2023-09-20 20:15:26.399 
Epoch 560/1000 
	 loss: 16.3406, MinusLogProbMetric: 16.3406, val_loss: 16.7201, val_MinusLogProbMetric: 16.7201

Epoch 560: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3406 - MinusLogProbMetric: 16.3406 - val_loss: 16.7201 - val_MinusLogProbMetric: 16.7201 - lr: 3.1250e-05 - 42s/epoch - 214ms/step
Epoch 561/1000
2023-09-20 20:16:07.962 
Epoch 561/1000 
	 loss: 16.3403, MinusLogProbMetric: 16.3403, val_loss: 16.7188, val_MinusLogProbMetric: 16.7188

Epoch 561: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3403 - MinusLogProbMetric: 16.3403 - val_loss: 16.7188 - val_MinusLogProbMetric: 16.7188 - lr: 3.1250e-05 - 42s/epoch - 212ms/step
Epoch 562/1000
2023-09-20 20:16:50.198 
Epoch 562/1000 
	 loss: 16.3410, MinusLogProbMetric: 16.3410, val_loss: 16.7197, val_MinusLogProbMetric: 16.7197

Epoch 562: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3410 - MinusLogProbMetric: 16.3410 - val_loss: 16.7197 - val_MinusLogProbMetric: 16.7197 - lr: 3.1250e-05 - 42s/epoch - 215ms/step
Epoch 563/1000
2023-09-20 20:17:31.689 
Epoch 563/1000 
	 loss: 16.3409, MinusLogProbMetric: 16.3409, val_loss: 16.7183, val_MinusLogProbMetric: 16.7183

Epoch 563: val_loss did not improve from 16.71440
196/196 - 41s - loss: 16.3409 - MinusLogProbMetric: 16.3409 - val_loss: 16.7183 - val_MinusLogProbMetric: 16.7183 - lr: 3.1250e-05 - 41s/epoch - 212ms/step
Epoch 564/1000
2023-09-20 20:18:13.630 
Epoch 564/1000 
	 loss: 16.3401, MinusLogProbMetric: 16.3401, val_loss: 16.7211, val_MinusLogProbMetric: 16.7211

Epoch 564: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3401 - MinusLogProbMetric: 16.3401 - val_loss: 16.7211 - val_MinusLogProbMetric: 16.7211 - lr: 3.1250e-05 - 42s/epoch - 214ms/step
Epoch 565/1000
2023-09-20 20:18:55.846 
Epoch 565/1000 
	 loss: 16.3415, MinusLogProbMetric: 16.3415, val_loss: 16.7232, val_MinusLogProbMetric: 16.7232

Epoch 565: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3415 - MinusLogProbMetric: 16.3415 - val_loss: 16.7232 - val_MinusLogProbMetric: 16.7232 - lr: 3.1250e-05 - 42s/epoch - 215ms/step
Epoch 566/1000
2023-09-20 20:19:37.888 
Epoch 566/1000 
	 loss: 16.3416, MinusLogProbMetric: 16.3416, val_loss: 16.7237, val_MinusLogProbMetric: 16.7237

Epoch 566: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3416 - MinusLogProbMetric: 16.3416 - val_loss: 16.7237 - val_MinusLogProbMetric: 16.7237 - lr: 3.1250e-05 - 42s/epoch - 214ms/step
Epoch 567/1000
2023-09-20 20:20:19.843 
Epoch 567/1000 
	 loss: 16.3404, MinusLogProbMetric: 16.3404, val_loss: 16.7208, val_MinusLogProbMetric: 16.7208

Epoch 567: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3404 - MinusLogProbMetric: 16.3404 - val_loss: 16.7208 - val_MinusLogProbMetric: 16.7208 - lr: 3.1250e-05 - 42s/epoch - 214ms/step
Epoch 568/1000
2023-09-20 20:21:01.797 
Epoch 568/1000 
	 loss: 16.3425, MinusLogProbMetric: 16.3425, val_loss: 16.7231, val_MinusLogProbMetric: 16.7231

Epoch 568: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3425 - MinusLogProbMetric: 16.3425 - val_loss: 16.7231 - val_MinusLogProbMetric: 16.7231 - lr: 3.1250e-05 - 42s/epoch - 214ms/step
Epoch 569/1000
2023-09-20 20:21:43.627 
Epoch 569/1000 
	 loss: 16.3416, MinusLogProbMetric: 16.3416, val_loss: 16.7232, val_MinusLogProbMetric: 16.7232

Epoch 569: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3416 - MinusLogProbMetric: 16.3416 - val_loss: 16.7232 - val_MinusLogProbMetric: 16.7232 - lr: 3.1250e-05 - 42s/epoch - 213ms/step
Epoch 570/1000
2023-09-20 20:22:25.662 
Epoch 570/1000 
	 loss: 16.3408, MinusLogProbMetric: 16.3408, val_loss: 16.7194, val_MinusLogProbMetric: 16.7194

Epoch 570: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3408 - MinusLogProbMetric: 16.3408 - val_loss: 16.7194 - val_MinusLogProbMetric: 16.7194 - lr: 3.1250e-05 - 42s/epoch - 214ms/step
Epoch 571/1000
2023-09-20 20:23:08.007 
Epoch 571/1000 
	 loss: 16.3411, MinusLogProbMetric: 16.3411, val_loss: 16.7208, val_MinusLogProbMetric: 16.7208

Epoch 571: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3411 - MinusLogProbMetric: 16.3411 - val_loss: 16.7208 - val_MinusLogProbMetric: 16.7208 - lr: 3.1250e-05 - 42s/epoch - 216ms/step
Epoch 572/1000
2023-09-20 20:23:49.582 
Epoch 572/1000 
	 loss: 16.3420, MinusLogProbMetric: 16.3420, val_loss: 16.7237, val_MinusLogProbMetric: 16.7237

Epoch 572: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3420 - MinusLogProbMetric: 16.3420 - val_loss: 16.7237 - val_MinusLogProbMetric: 16.7237 - lr: 3.1250e-05 - 42s/epoch - 212ms/step
Epoch 573/1000
2023-09-20 20:24:31.840 
Epoch 573/1000 
	 loss: 16.3405, MinusLogProbMetric: 16.3405, val_loss: 16.7189, val_MinusLogProbMetric: 16.7189

Epoch 573: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3405 - MinusLogProbMetric: 16.3405 - val_loss: 16.7189 - val_MinusLogProbMetric: 16.7189 - lr: 3.1250e-05 - 42s/epoch - 216ms/step
Epoch 574/1000
2023-09-20 20:25:13.466 
Epoch 574/1000 
	 loss: 16.3396, MinusLogProbMetric: 16.3396, val_loss: 16.7219, val_MinusLogProbMetric: 16.7219

Epoch 574: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3396 - MinusLogProbMetric: 16.3396 - val_loss: 16.7219 - val_MinusLogProbMetric: 16.7219 - lr: 3.1250e-05 - 42s/epoch - 212ms/step
Epoch 575/1000
2023-09-20 20:25:55.597 
Epoch 575/1000 
	 loss: 16.3397, MinusLogProbMetric: 16.3397, val_loss: 16.7221, val_MinusLogProbMetric: 16.7221

Epoch 575: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3397 - MinusLogProbMetric: 16.3397 - val_loss: 16.7221 - val_MinusLogProbMetric: 16.7221 - lr: 3.1250e-05 - 42s/epoch - 215ms/step
Epoch 576/1000
2023-09-20 20:26:37.410 
Epoch 576/1000 
	 loss: 16.3403, MinusLogProbMetric: 16.3403, val_loss: 16.7247, val_MinusLogProbMetric: 16.7247

Epoch 576: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3403 - MinusLogProbMetric: 16.3403 - val_loss: 16.7247 - val_MinusLogProbMetric: 16.7247 - lr: 3.1250e-05 - 42s/epoch - 213ms/step
Epoch 577/1000
2023-09-20 20:27:19.474 
Epoch 577/1000 
	 loss: 16.3400, MinusLogProbMetric: 16.3400, val_loss: 16.7202, val_MinusLogProbMetric: 16.7202

Epoch 577: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3400 - MinusLogProbMetric: 16.3400 - val_loss: 16.7202 - val_MinusLogProbMetric: 16.7202 - lr: 3.1250e-05 - 42s/epoch - 215ms/step
Epoch 578/1000
2023-09-20 20:28:01.417 
Epoch 578/1000 
	 loss: 16.3404, MinusLogProbMetric: 16.3404, val_loss: 16.7188, val_MinusLogProbMetric: 16.7188

Epoch 578: val_loss did not improve from 16.71440
196/196 - 42s - loss: 16.3404 - MinusLogProbMetric: 16.3404 - val_loss: 16.7188 - val_MinusLogProbMetric: 16.7188 - lr: 3.1250e-05 - 42s/epoch - 214ms/step
Epoch 579/1000
2023-09-20 20:28:42.392 
Epoch 579/1000 
	 loss: 16.3402, MinusLogProbMetric: 16.3402, val_loss: 16.7223, val_MinusLogProbMetric: 16.7223

Epoch 579: val_loss did not improve from 16.71440
Restoring model weights from the end of the best epoch: 479.
196/196 - 41s - loss: 16.3402 - MinusLogProbMetric: 16.3402 - val_loss: 16.7223 - val_MinusLogProbMetric: 16.7223 - lr: 3.1250e-05 - 41s/epoch - 211ms/step
Epoch 579: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 19.410677068168297 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 10.891695073107257 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 7.137029410107061 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7faa9ce8ff40> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 35.73079449986108 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 16.380793274845928 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 11.219788700109348 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:AutoGraph could not transform <function FNMetric.Test_tf.<locals>.compute_test at 0x7fad20efee60> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('batched_test', 'dtype', 'ndims', 'niter', 'self'), but source function had ('dtype',)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Training succeeded with seed 377.
Model trained in 24465.95 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
===========
Failed computing metrics
===========

                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/c_Main_CsplineN.py , Line : 468, Func.Name : prediction_function, Message : X_data_nf: tf.Tensor = DataInputs.dist_2_num[:nsamples_test] # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/CsplineN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 103.13 s.
===========
Run 259/720 done in 24573.29 s.
===========

Directory ../../results/CsplineN_new/run_260/ already exists.
Skipping it.
===========
Run 260/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_261/ already exists.
Skipping it.
===========
Run 261/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_262/ already exists.
Skipping it.
===========
Run 262/720 already exists. Skipping it.
===========

===========
Generating train data for run 263.
===========
Train data generated in 0.11 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_263/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 377}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_263/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.1831715 ,  3.2834203 ,  8.308094  , ...,  7.3133397 ,
         2.7002556 ,  1.7567806 ],
       [ 6.1308765 ,  7.147402  ,  6.0903115 , ...,  4.022617  ,
         2.6618268 ,  7.627545  ],
       [ 2.7429156 ,  3.6509063 ,  7.295548  , ...,  7.086021  ,
         2.8938296 ,  1.8224454 ],
       ...,
       [ 2.1098776 ,  4.1337423 ,  8.041495  , ...,  7.2043395 ,
         2.3724499 ,  1.8449893 ],
       [ 4.759076  ,  5.6016526 , -0.17659053, ...,  1.2483898 ,
         6.6213574 ,  1.391019  ],
       [ 4.6478305 ,  5.6608987 ,  0.05425403, ...,  1.0307544 ,
         6.027231  ,  1.3217621 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_263/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_263
self.data_kwargs: {'seed': 377}
self.x_data: [[5.416377   7.151266   6.5657053  ... 3.613302   2.6304417  8.037386  ]
 [4.297167   5.832213   0.12875912 ... 1.4317983  6.415448   1.3533646 ]
 [6.2353234  7.1795187  6.219724   ... 4.5891814  2.66546    7.551563  ]
 ...
 [1.8237456  4.102903   7.5608215  ... 7.136859   2.564185   1.5539532 ]
 [2.2305896  4.6568003  8.321339   ... 7.0577617  2.6189713  1.518045  ]
 [5.653481   7.1263475  6.929123   ... 4.292566   2.643216   7.404443  ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_213"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_214 (InputLayer)      [(None, 32)]              0         
                                                                 
 log_prob_layer_23 (LogProbL  (None,)                  1074400   
 ayer)                                                           
                                                                 
=================================================================
Total params: 1,074,400
Trainable params: 1,074,400
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_23/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_23'")
self.model: <keras.engine.functional.Functional object at 0x7fac92563940>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fb1e60d0d00>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fb1e60d0d00>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fac933d7610>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fac92591c60>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fac925921d0>, <keras.callbacks.ModelCheckpoint object at 0x7fac92592290>, <keras.callbacks.EarlyStopping object at 0x7fac92592500>, <keras.callbacks.ReduceLROnPlateau object at 0x7fac92592530>, <keras.callbacks.TerminateOnNaN object at 0x7fac92592170>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.1831715 ,  3.2834203 ,  8.308094  , ...,  7.3133397 ,
         2.7002556 ,  1.7567806 ],
       [ 6.1308765 ,  7.147402  ,  6.0903115 , ...,  4.022617  ,
         2.6618268 ,  7.627545  ],
       [ 2.7429156 ,  3.6509063 ,  7.295548  , ...,  7.086021  ,
         2.8938296 ,  1.8224454 ],
       ...,
       [ 2.1098776 ,  4.1337423 ,  8.041495  , ...,  7.2043395 ,
         2.3724499 ,  1.8449893 ],
       [ 4.759076  ,  5.6016526 , -0.17659053, ...,  1.2483898 ,
         6.6213574 ,  1.391019  ],
       [ 4.6478305 ,  5.6608987 ,  0.05425403, ...,  1.0307544 ,
         6.027231  ,  1.3217621 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_263/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 263/720 with hyperparameters:
timestamp = 2023-09-20 20:30:35.597006
ndims = 32
seed_train = 377
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 1074400
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 5.416377    7.151266    6.5657053   5.44807     3.870332    6.1800294
  2.9008856   8.441634    9.391678    4.1002183   7.382605    5.3625755
  5.5868373   9.949682    0.82923275  1.9832962  -0.10069095  8.219267
  8.539603    9.221239    9.5321455   8.239499    4.945965    8.152974
 -0.16393006  6.303131    0.6036788   9.50227     6.1976576   3.613302
  2.6304417   8.037386  ]
Epoch 1/1000
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Batch 35: Invalid loss, terminating training
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
2023-09-20 20:34:33.484 
Epoch 1/1000 
	 loss: nan, MinusLogProbMetric: 2260.3521, val_loss: nan, val_MinusLogProbMetric: nan

Epoch 1: val_loss did not improve from inf
196/196 - 238s - loss: nan - MinusLogProbMetric: 2260.3521 - val_loss: nan - val_MinusLogProbMetric: nan - lr: 0.0010 - 238s/epoch - 1s/step
The loss history contains NaN values.
Training failed: trying again with seed 326159 and lr 0.0003333333333333333.
===========
Generating train data for run 263.
===========
Train data generated in 0.25 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_263/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 377}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_263/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.1831715 ,  3.2834203 ,  8.308094  , ...,  7.3133397 ,
         2.7002556 ,  1.7567806 ],
       [ 6.1308765 ,  7.147402  ,  6.0903115 , ...,  4.022617  ,
         2.6618268 ,  7.627545  ],
       [ 2.7429156 ,  3.6509063 ,  7.295548  , ...,  7.086021  ,
         2.8938296 ,  1.8224454 ],
       ...,
       [ 2.1098776 ,  4.1337423 ,  8.041495  , ...,  7.2043395 ,
         2.3724499 ,  1.8449893 ],
       [ 4.759076  ,  5.6016526 , -0.17659053, ...,  1.2483898 ,
         6.6213574 ,  1.391019  ],
       [ 4.6478305 ,  5.6608987 ,  0.05425403, ...,  1.0307544 ,
         6.027231  ,  1.3217621 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_263/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_263
self.data_kwargs: {'seed': 377}
self.x_data: [[5.416377   7.151266   6.5657053  ... 3.613302   2.6304417  8.037386  ]
 [4.297167   5.832213   0.12875912 ... 1.4317983  6.415448   1.3533646 ]
 [6.2353234  7.1795187  6.219724   ... 4.5891814  2.66546    7.551563  ]
 ...
 [1.8237456  4.102903   7.5608215  ... 7.136859   2.564185   1.5539532 ]
 [2.2305896  4.6568003  8.321339   ... 7.0577617  2.6189713  1.518045  ]
 [5.653481   7.1263475  6.929123   ... 4.292566   2.643216   7.404443  ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_224"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_225 (InputLayer)      [(None, 32)]              0         
                                                                 
 log_prob_layer_24 (LogProbL  (None,)                  1074400   
 ayer)                                                           
                                                                 
=================================================================
Total params: 1,074,400
Trainable params: 1,074,400
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_24/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_24'")
self.model: <keras.engine.functional.Functional object at 0x7faed4d5f700>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fad1082ab30>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fad1082ab30>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7faac0245b70>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7faab43aba90>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7faab43abfa0>, <keras.callbacks.ModelCheckpoint object at 0x7faab43abfd0>, <keras.callbacks.EarlyStopping object at 0x7faa7e610340>, <keras.callbacks.ReduceLROnPlateau object at 0x7faa7e6103a0>, <keras.callbacks.TerminateOnNaN object at 0x7faa7e610370>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.1831715 ,  3.2834203 ,  8.308094  , ...,  7.3133397 ,
         2.7002556 ,  1.7567806 ],
       [ 6.1308765 ,  7.147402  ,  6.0903115 , ...,  4.022617  ,
         2.6618268 ,  7.627545  ],
       [ 2.7429156 ,  3.6509063 ,  7.295548  , ...,  7.086021  ,
         2.8938296 ,  1.8224454 ],
       ...,
       [ 2.1098776 ,  4.1337423 ,  8.041495  , ...,  7.2043395 ,
         2.3724499 ,  1.8449893 ],
       [ 4.759076  ,  5.6016526 , -0.17659053, ...,  1.2483898 ,
         6.6213574 ,  1.391019  ],
       [ 4.6478305 ,  5.6608987 ,  0.05425403, ...,  1.0307544 ,
         6.027231  ,  1.3217621 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_263/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 263/720 with hyperparameters:
timestamp = 2023-09-20 20:34:47.330885
ndims = 32
seed_train = 377
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 1074400
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.0003333333333333333...
Train first sample: [ 5.416377    7.151266    6.5657053   5.44807     3.870332    6.1800294
  2.9008856   8.441634    9.391678    4.1002183   7.382605    5.3625755
  5.5868373   9.949682    0.82923275  1.9832962  -0.10069095  8.219267
  8.539603    9.221239    9.5321455   8.239499    4.945965    8.152974
 -0.16393006  6.303131    0.6036788   9.50227     6.1976576   3.613302
  2.6304417   8.037386  ]
Epoch 1/1000
Warning: The fraction of NaNs in loss is below threshold. Removing them from average.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Batch 176: Invalid loss, terminating training
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
2023-09-20 20:39:26.781 
Epoch 1/1000 
	 loss: nan, MinusLogProbMetric: 1511.3657, val_loss: nan, val_MinusLogProbMetric: nan

Epoch 1: val_loss did not improve from inf
196/196 - 279s - loss: nan - MinusLogProbMetric: 1511.3657 - val_loss: nan - val_MinusLogProbMetric: nan - lr: 3.3333e-04 - 279s/epoch - 1s/step
The loss history contains NaN values.
Training failed: trying again with seed 326159 and lr 0.0001111111111111111.
===========
Generating train data for run 263.
===========
Train data generated in 0.26 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_263/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 377}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0001111111111111111, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_263/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.1831715 ,  3.2834203 ,  8.308094  , ...,  7.3133397 ,
         2.7002556 ,  1.7567806 ],
       [ 6.1308765 ,  7.147402  ,  6.0903115 , ...,  4.022617  ,
         2.6618268 ,  7.627545  ],
       [ 2.7429156 ,  3.6509063 ,  7.295548  , ...,  7.086021  ,
         2.8938296 ,  1.8224454 ],
       ...,
       [ 2.1098776 ,  4.1337423 ,  8.041495  , ...,  7.2043395 ,
         2.3724499 ,  1.8449893 ],
       [ 4.759076  ,  5.6016526 , -0.17659053, ...,  1.2483898 ,
         6.6213574 ,  1.391019  ],
       [ 4.6478305 ,  5.6608987 ,  0.05425403, ...,  1.0307544 ,
         6.027231  ,  1.3217621 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_263/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_263
self.data_kwargs: {'seed': 377}
self.x_data: [[5.416377   7.151266   6.5657053  ... 3.613302   2.6304417  8.037386  ]
 [4.297167   5.832213   0.12875912 ... 1.4317983  6.415448   1.3533646 ]
 [6.2353234  7.1795187  6.219724   ... 4.5891814  2.66546    7.551563  ]
 ...
 [1.8237456  4.102903   7.5608215  ... 7.136859   2.564185   1.5539532 ]
 [2.2305896  4.6568003  8.321339   ... 7.0577617  2.6189713  1.518045  ]
 [5.653481   7.1263475  6.929123   ... 4.292566   2.643216   7.404443  ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_235"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_236 (InputLayer)      [(None, 32)]              0         
                                                                 
 log_prob_layer_25 (LogProbL  (None,)                  1074400   
 ayer)                                                           
                                                                 
=================================================================
Total params: 1,074,400
Trainable params: 1,074,400
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_25/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_25'")
self.model: <keras.engine.functional.Functional object at 0x7fac914cf670>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0001111111111111111, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fac91effb50>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0001111111111111111, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fac91effb50>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7faaf05d8880>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fac914fea40>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fac914fefb0>, <keras.callbacks.ModelCheckpoint object at 0x7fac914ff070>, <keras.callbacks.EarlyStopping object at 0x7fac914ff2e0>, <keras.callbacks.ReduceLROnPlateau object at 0x7fac914ff310>, <keras.callbacks.TerminateOnNaN object at 0x7fac914fef50>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.1831715 ,  3.2834203 ,  8.308094  , ...,  7.3133397 ,
         2.7002556 ,  1.7567806 ],
       [ 6.1308765 ,  7.147402  ,  6.0903115 , ...,  4.022617  ,
         2.6618268 ,  7.627545  ],
       [ 2.7429156 ,  3.6509063 ,  7.295548  , ...,  7.086021  ,
         2.8938296 ,  1.8224454 ],
       ...,
       [ 2.1098776 ,  4.1337423 ,  8.041495  , ...,  7.2043395 ,
         2.3724499 ,  1.8449893 ],
       [ 4.759076  ,  5.6016526 , -0.17659053, ...,  1.2483898 ,
         6.6213574 ,  1.391019  ],
       [ 4.6478305 ,  5.6608987 ,  0.05425403, ...,  1.0307544 ,
         6.027231  ,  1.3217621 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_263/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 263/720 with hyperparameters:
timestamp = 2023-09-20 20:39:40.910294
ndims = 32
seed_train = 377
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 1074400
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.0001111111111111111...
Train first sample: [ 5.416377    7.151266    6.5657053   5.44807     3.870332    6.1800294
  2.9008856   8.441634    9.391678    4.1002183   7.382605    5.3625755
  5.5868373   9.949682    0.82923275  1.9832962  -0.10069095  8.219267
  8.539603    9.221239    9.5321455   8.239499    4.945965    8.152974
 -0.16393006  6.303131    0.6036788   9.50227     6.1976576   3.613302
  2.6304417   8.037386  ]
Epoch 1/1000
2023-09-20 20:44:30.873 
Epoch 1/1000 
	 loss: 1759.5168, MinusLogProbMetric: 1759.5168, val_loss: 900.3741, val_MinusLogProbMetric: 900.3741

Epoch 1: val_loss improved from inf to 900.37415, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 291s - loss: 1759.5168 - MinusLogProbMetric: 1759.5168 - val_loss: 900.3741 - val_MinusLogProbMetric: 900.3741 - lr: 1.1111e-04 - 291s/epoch - 1s/step
Epoch 2/1000
2023-09-20 20:45:52.538 
Epoch 2/1000 
	 loss: 586.7465, MinusLogProbMetric: 586.7465, val_loss: 621.1857, val_MinusLogProbMetric: 621.1857

Epoch 2: val_loss improved from 900.37415 to 621.18573, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 586.7465 - MinusLogProbMetric: 586.7465 - val_loss: 621.1857 - val_MinusLogProbMetric: 621.1857 - lr: 1.1111e-04 - 81s/epoch - 416ms/step
Epoch 3/1000
2023-09-20 20:47:15.071 
Epoch 3/1000 
	 loss: 468.8114, MinusLogProbMetric: 468.8114, val_loss: 386.9010, val_MinusLogProbMetric: 386.9010

Epoch 3: val_loss improved from 621.18573 to 386.90097, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 468.8114 - MinusLogProbMetric: 468.8114 - val_loss: 386.9010 - val_MinusLogProbMetric: 386.9010 - lr: 1.1111e-04 - 82s/epoch - 421ms/step
Epoch 4/1000
2023-09-20 20:48:36.617 
Epoch 4/1000 
	 loss: 387.9765, MinusLogProbMetric: 387.9765, val_loss: 373.5339, val_MinusLogProbMetric: 373.5339

Epoch 4: val_loss improved from 386.90097 to 373.53387, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 387.9765 - MinusLogProbMetric: 387.9765 - val_loss: 373.5339 - val_MinusLogProbMetric: 373.5339 - lr: 1.1111e-04 - 82s/epoch - 416ms/step
Epoch 5/1000
2023-09-20 20:49:58.481 
Epoch 5/1000 
	 loss: 363.1374, MinusLogProbMetric: 363.1374, val_loss: 355.2154, val_MinusLogProbMetric: 355.2154

Epoch 5: val_loss improved from 373.53387 to 355.21536, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 363.1374 - MinusLogProbMetric: 363.1374 - val_loss: 355.2154 - val_MinusLogProbMetric: 355.2154 - lr: 1.1111e-04 - 82s/epoch - 418ms/step
Epoch 6/1000
2023-09-20 20:51:19.442 
Epoch 6/1000 
	 loss: 319.1642, MinusLogProbMetric: 319.1642, val_loss: 512.9724, val_MinusLogProbMetric: 512.9724

Epoch 6: val_loss did not improve from 355.21536
196/196 - 80s - loss: 319.1642 - MinusLogProbMetric: 319.1642 - val_loss: 512.9724 - val_MinusLogProbMetric: 512.9724 - lr: 1.1111e-04 - 80s/epoch - 406ms/step
Epoch 7/1000
Warning: The fraction of NaNs in loss is below threshold. Removing them from average.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Batch 16: Invalid loss, terminating training
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
2023-09-20 20:51:31.140 
Epoch 7/1000 
	 loss: nan, MinusLogProbMetric: 752.7917, val_loss: nan, val_MinusLogProbMetric: nan

Epoch 7: val_loss did not improve from 355.21536
196/196 - 12s - loss: nan - MinusLogProbMetric: 752.7917 - val_loss: nan - val_MinusLogProbMetric: nan - lr: 1.1111e-04 - 12s/epoch - 60ms/step
The loss history contains NaN values.
Training failed: trying again with seed 326159 and lr 3.703703703703703e-05.
===========
Generating train data for run 263.
===========
Train data generated in 0.33 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_263/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 377}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 3.703703703703703e-05, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_263/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.1831715 ,  3.2834203 ,  8.308094  , ...,  7.3133397 ,
         2.7002556 ,  1.7567806 ],
       [ 6.1308765 ,  7.147402  ,  6.0903115 , ...,  4.022617  ,
         2.6618268 ,  7.627545  ],
       [ 2.7429156 ,  3.6509063 ,  7.295548  , ...,  7.086021  ,
         2.8938296 ,  1.8224454 ],
       ...,
       [ 2.1098776 ,  4.1337423 ,  8.041495  , ...,  7.2043395 ,
         2.3724499 ,  1.8449893 ],
       [ 4.759076  ,  5.6016526 , -0.17659053, ...,  1.2483898 ,
         6.6213574 ,  1.391019  ],
       [ 4.6478305 ,  5.6608987 ,  0.05425403, ...,  1.0307544 ,
         6.027231  ,  1.3217621 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_263/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_263
self.data_kwargs: {'seed': 377}
self.x_data: [[5.416377   7.151266   6.5657053  ... 3.613302   2.6304417  8.037386  ]
 [4.297167   5.832213   0.12875912 ... 1.4317983  6.415448   1.3533646 ]
 [6.2353234  7.1795187  6.219724   ... 4.5891814  2.66546    7.551563  ]
 ...
 [1.8237456  4.102903   7.5608215  ... 7.136859   2.564185   1.5539532 ]
 [2.2305896  4.6568003  8.321339   ... 7.0577617  2.6189713  1.518045  ]
 [5.653481   7.1263475  6.929123   ... 4.292566   2.643216   7.404443  ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_246"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_247 (InputLayer)      [(None, 32)]              0         
                                                                 
 log_prob_layer_26 (LogProbL  (None,)                  1074400   
 ayer)                                                           
                                                                 
=================================================================
Total params: 1,074,400
Trainable params: 1,074,400
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_26/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_26'")
self.model: <keras.engine.functional.Functional object at 0x7fb5c1657e80>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 3.703703703703703e-05, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fadaad10d90>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 3.703703703703703e-05, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fadaad10d90>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fae1947c940>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7faa7eb043a0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7faa7eb04910>, <keras.callbacks.ModelCheckpoint object at 0x7faa7eb049d0>, <keras.callbacks.EarlyStopping object at 0x7faa7eb04c40>, <keras.callbacks.ReduceLROnPlateau object at 0x7faa7eb04c70>, <keras.callbacks.TerminateOnNaN object at 0x7faa7eb048b0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.1831715 ,  3.2834203 ,  8.308094  , ...,  7.3133397 ,
         2.7002556 ,  1.7567806 ],
       [ 6.1308765 ,  7.147402  ,  6.0903115 , ...,  4.022617  ,
         2.6618268 ,  7.627545  ],
       [ 2.7429156 ,  3.6509063 ,  7.295548  , ...,  7.086021  ,
         2.8938296 ,  1.8224454 ],
       ...,
       [ 2.1098776 ,  4.1337423 ,  8.041495  , ...,  7.2043395 ,
         2.3724499 ,  1.8449893 ],
       [ 4.759076  ,  5.6016526 , -0.17659053, ...,  1.2483898 ,
         6.6213574 ,  1.391019  ],
       [ 4.6478305 ,  5.6608987 ,  0.05425403, ...,  1.0307544 ,
         6.027231  ,  1.3217621 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
Found and loaded existing weights.
No history found. Generating new history.
===============
Running 263/720 with hyperparameters:
timestamp = 2023-09-20 20:51:45.720624
ndims = 32
seed_train = 377
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 1074400
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 3.703703703703703e-05...
Train first sample: [ 5.416377    7.151266    6.5657053   5.44807     3.870332    6.1800294
  2.9008856   8.441634    9.391678    4.1002183   7.382605    5.3625755
  5.5868373   9.949682    0.82923275  1.9832962  -0.10069095  8.219267
  8.539603    9.221239    9.5321455   8.239499    4.945965    8.152974
 -0.16393006  6.303131    0.6036788   9.50227     6.1976576   3.613302
  2.6304417   8.037386  ]
Epoch 1/1000
2023-09-20 20:56:07.340 
Epoch 1/1000 
	 loss: 297.5015, MinusLogProbMetric: 297.5015, val_loss: 261.4758, val_MinusLogProbMetric: 261.4758

Epoch 1: val_loss improved from inf to 261.47580, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 263s - loss: 297.5015 - MinusLogProbMetric: 297.5015 - val_loss: 261.4758 - val_MinusLogProbMetric: 261.4758 - lr: 3.7037e-05 - 263s/epoch - 1s/step
Epoch 2/1000
2023-09-20 20:57:29.202 
Epoch 2/1000 
	 loss: 260.9264, MinusLogProbMetric: 260.9264, val_loss: 241.6257, val_MinusLogProbMetric: 241.6257

Epoch 2: val_loss improved from 261.47580 to 241.62569, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 260.9264 - MinusLogProbMetric: 260.9264 - val_loss: 241.6257 - val_MinusLogProbMetric: 241.6257 - lr: 3.7037e-05 - 81s/epoch - 415ms/step
Epoch 3/1000
2023-09-20 20:58:51.644 
Epoch 3/1000 
	 loss: 254.1171, MinusLogProbMetric: 254.1171, val_loss: 253.8737, val_MinusLogProbMetric: 253.8737

Epoch 3: val_loss did not improve from 241.62569
196/196 - 81s - loss: 254.1171 - MinusLogProbMetric: 254.1171 - val_loss: 253.8737 - val_MinusLogProbMetric: 253.8737 - lr: 3.7037e-05 - 81s/epoch - 414ms/step
Epoch 4/1000
2023-09-20 21:00:12.331 
Epoch 4/1000 
	 loss: 246.3562, MinusLogProbMetric: 246.3562, val_loss: 223.3521, val_MinusLogProbMetric: 223.3521

Epoch 4: val_loss improved from 241.62569 to 223.35211, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 246.3562 - MinusLogProbMetric: 246.3562 - val_loss: 223.3521 - val_MinusLogProbMetric: 223.3521 - lr: 3.7037e-05 - 82s/epoch - 420ms/step
Epoch 5/1000
2023-09-20 21:01:33.781 
Epoch 5/1000 
	 loss: 255.7789, MinusLogProbMetric: 255.7789, val_loss: 272.9828, val_MinusLogProbMetric: 272.9828

Epoch 5: val_loss did not improve from 223.35211
196/196 - 80s - loss: 255.7789 - MinusLogProbMetric: 255.7789 - val_loss: 272.9828 - val_MinusLogProbMetric: 272.9828 - lr: 3.7037e-05 - 80s/epoch - 407ms/step
Epoch 6/1000
2023-09-20 21:02:54.673 
Epoch 6/1000 
	 loss: 282.9562, MinusLogProbMetric: 282.9562, val_loss: 228.6125, val_MinusLogProbMetric: 228.6125

Epoch 6: val_loss did not improve from 223.35211
196/196 - 81s - loss: 282.9562 - MinusLogProbMetric: 282.9562 - val_loss: 228.6125 - val_MinusLogProbMetric: 228.6125 - lr: 3.7037e-05 - 81s/epoch - 413ms/step
Epoch 7/1000
2023-09-20 21:04:15.162 
Epoch 7/1000 
	 loss: 216.6559, MinusLogProbMetric: 216.6559, val_loss: 203.8064, val_MinusLogProbMetric: 203.8064

Epoch 7: val_loss improved from 223.35211 to 203.80635, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 216.6559 - MinusLogProbMetric: 216.6559 - val_loss: 203.8064 - val_MinusLogProbMetric: 203.8064 - lr: 3.7037e-05 - 82s/epoch - 420ms/step
Epoch 8/1000
2023-09-20 21:05:35.776 
Epoch 8/1000 
	 loss: 191.6128, MinusLogProbMetric: 191.6128, val_loss: 195.9581, val_MinusLogProbMetric: 195.9581

Epoch 8: val_loss improved from 203.80635 to 195.95808, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 191.6128 - MinusLogProbMetric: 191.6128 - val_loss: 195.9581 - val_MinusLogProbMetric: 195.9581 - lr: 3.7037e-05 - 81s/epoch - 413ms/step
Epoch 9/1000
2023-09-20 21:06:56.886 
Epoch 9/1000 
	 loss: 187.4960, MinusLogProbMetric: 187.4960, val_loss: 171.7082, val_MinusLogProbMetric: 171.7082

Epoch 9: val_loss improved from 195.95808 to 171.70821, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 187.4960 - MinusLogProbMetric: 187.4960 - val_loss: 171.7082 - val_MinusLogProbMetric: 171.7082 - lr: 3.7037e-05 - 81s/epoch - 414ms/step
Epoch 10/1000
2023-09-20 21:08:19.318 
Epoch 10/1000 
	 loss: 164.7229, MinusLogProbMetric: 164.7229, val_loss: 160.6608, val_MinusLogProbMetric: 160.6608

Epoch 10: val_loss improved from 171.70821 to 160.66081, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 164.7229 - MinusLogProbMetric: 164.7229 - val_loss: 160.6608 - val_MinusLogProbMetric: 160.6608 - lr: 3.7037e-05 - 82s/epoch - 417ms/step
Epoch 11/1000
2023-09-20 21:09:40.927 
Epoch 11/1000 
	 loss: 156.9574, MinusLogProbMetric: 156.9574, val_loss: 151.5603, val_MinusLogProbMetric: 151.5603

Epoch 11: val_loss improved from 160.66081 to 151.56035, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 156.9574 - MinusLogProbMetric: 156.9574 - val_loss: 151.5603 - val_MinusLogProbMetric: 151.5603 - lr: 3.7037e-05 - 82s/epoch - 416ms/step
Epoch 12/1000
2023-09-20 21:11:02.317 
Epoch 12/1000 
	 loss: 147.8600, MinusLogProbMetric: 147.8600, val_loss: 143.2227, val_MinusLogProbMetric: 143.2227

Epoch 12: val_loss improved from 151.56035 to 143.22267, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 147.8600 - MinusLogProbMetric: 147.8600 - val_loss: 143.2227 - val_MinusLogProbMetric: 143.2227 - lr: 3.7037e-05 - 81s/epoch - 415ms/step
Epoch 13/1000
2023-09-20 21:12:23.931 
Epoch 13/1000 
	 loss: 141.0490, MinusLogProbMetric: 141.0490, val_loss: 137.8080, val_MinusLogProbMetric: 137.8080

Epoch 13: val_loss improved from 143.22267 to 137.80803, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 141.0490 - MinusLogProbMetric: 141.0490 - val_loss: 137.8080 - val_MinusLogProbMetric: 137.8080 - lr: 3.7037e-05 - 82s/epoch - 416ms/step
Epoch 14/1000
2023-09-20 21:13:43.978 
Epoch 14/1000 
	 loss: 135.7061, MinusLogProbMetric: 135.7061, val_loss: 132.3858, val_MinusLogProbMetric: 132.3858

Epoch 14: val_loss improved from 137.80803 to 132.38576, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 135.7061 - MinusLogProbMetric: 135.7061 - val_loss: 132.3858 - val_MinusLogProbMetric: 132.3858 - lr: 3.7037e-05 - 80s/epoch - 410ms/step
Epoch 15/1000
2023-09-20 21:15:05.285 
Epoch 15/1000 
	 loss: 130.9121, MinusLogProbMetric: 130.9121, val_loss: 127.7189, val_MinusLogProbMetric: 127.7189

Epoch 15: val_loss improved from 132.38576 to 127.71886, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 130.9121 - MinusLogProbMetric: 130.9121 - val_loss: 127.7189 - val_MinusLogProbMetric: 127.7189 - lr: 3.7037e-05 - 81s/epoch - 413ms/step
Epoch 16/1000
2023-09-20 21:16:25.975 
Epoch 16/1000 
	 loss: 125.8745, MinusLogProbMetric: 125.8745, val_loss: 123.1890, val_MinusLogProbMetric: 123.1890

Epoch 16: val_loss improved from 127.71886 to 123.18904, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 125.8745 - MinusLogProbMetric: 125.8745 - val_loss: 123.1890 - val_MinusLogProbMetric: 123.1890 - lr: 3.7037e-05 - 81s/epoch - 413ms/step
Epoch 17/1000
2023-09-20 21:17:46.966 
Epoch 17/1000 
	 loss: 122.8302, MinusLogProbMetric: 122.8302, val_loss: 119.7653, val_MinusLogProbMetric: 119.7653

Epoch 17: val_loss improved from 123.18904 to 119.76525, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 122.8302 - MinusLogProbMetric: 122.8302 - val_loss: 119.7653 - val_MinusLogProbMetric: 119.7653 - lr: 3.7037e-05 - 81s/epoch - 413ms/step
Epoch 18/1000
2023-09-20 21:19:09.251 
Epoch 18/1000 
	 loss: 117.2029, MinusLogProbMetric: 117.2029, val_loss: 115.0466, val_MinusLogProbMetric: 115.0466

Epoch 18: val_loss improved from 119.76525 to 115.04662, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 117.2029 - MinusLogProbMetric: 117.2029 - val_loss: 115.0466 - val_MinusLogProbMetric: 115.0466 - lr: 3.7037e-05 - 83s/epoch - 422ms/step
Epoch 19/1000
2023-09-20 21:20:31.798 
Epoch 19/1000 
	 loss: 113.7718, MinusLogProbMetric: 113.7718, val_loss: 111.3488, val_MinusLogProbMetric: 111.3488

Epoch 19: val_loss improved from 115.04662 to 111.34878, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 113.7718 - MinusLogProbMetric: 113.7718 - val_loss: 111.3488 - val_MinusLogProbMetric: 111.3488 - lr: 3.7037e-05 - 82s/epoch - 418ms/step
Epoch 20/1000
2023-09-20 21:21:53.395 
Epoch 20/1000 
	 loss: 109.7641, MinusLogProbMetric: 109.7641, val_loss: 109.0073, val_MinusLogProbMetric: 109.0073

Epoch 20: val_loss improved from 111.34878 to 109.00731, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 109.7641 - MinusLogProbMetric: 109.7641 - val_loss: 109.0073 - val_MinusLogProbMetric: 109.0073 - lr: 3.7037e-05 - 82s/epoch - 417ms/step
Epoch 21/1000
2023-09-20 21:23:15.545 
Epoch 21/1000 
	 loss: 118.7943, MinusLogProbMetric: 118.7943, val_loss: 136.7372, val_MinusLogProbMetric: 136.7372

Epoch 21: val_loss did not improve from 109.00731
196/196 - 81s - loss: 118.7943 - MinusLogProbMetric: 118.7943 - val_loss: 136.7372 - val_MinusLogProbMetric: 136.7372 - lr: 3.7037e-05 - 81s/epoch - 412ms/step
Epoch 22/1000
2023-09-20 21:24:35.286 
Epoch 22/1000 
	 loss: 122.2281, MinusLogProbMetric: 122.2281, val_loss: 112.5465, val_MinusLogProbMetric: 112.5465

Epoch 22: val_loss did not improve from 109.00731
196/196 - 80s - loss: 122.2281 - MinusLogProbMetric: 122.2281 - val_loss: 112.5465 - val_MinusLogProbMetric: 112.5465 - lr: 3.7037e-05 - 80s/epoch - 407ms/step
Epoch 23/1000
2023-09-20 21:25:55.317 
Epoch 23/1000 
	 loss: 107.6214, MinusLogProbMetric: 107.6214, val_loss: 104.1668, val_MinusLogProbMetric: 104.1668

Epoch 23: val_loss improved from 109.00731 to 104.16682, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 107.6214 - MinusLogProbMetric: 107.6214 - val_loss: 104.1668 - val_MinusLogProbMetric: 104.1668 - lr: 3.7037e-05 - 81s/epoch - 415ms/step
Epoch 24/1000
2023-09-20 21:27:16.522 
Epoch 24/1000 
	 loss: 103.9528, MinusLogProbMetric: 103.9528, val_loss: 104.6145, val_MinusLogProbMetric: 104.6145

Epoch 24: val_loss did not improve from 104.16682
196/196 - 80s - loss: 103.9528 - MinusLogProbMetric: 103.9528 - val_loss: 104.6145 - val_MinusLogProbMetric: 104.6145 - lr: 3.7037e-05 - 80s/epoch - 408ms/step
Epoch 25/1000
2023-09-20 21:28:37.051 
Epoch 25/1000 
	 loss: 100.1506, MinusLogProbMetric: 100.1506, val_loss: 98.5333, val_MinusLogProbMetric: 98.5333

Epoch 25: val_loss improved from 104.16682 to 98.53329, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 100.1506 - MinusLogProbMetric: 100.1506 - val_loss: 98.5333 - val_MinusLogProbMetric: 98.5333 - lr: 3.7037e-05 - 82s/epoch - 420ms/step
Epoch 26/1000
2023-09-20 21:29:59.839 
Epoch 26/1000 
	 loss: 97.3311, MinusLogProbMetric: 97.3311, val_loss: 96.0312, val_MinusLogProbMetric: 96.0312

Epoch 26: val_loss improved from 98.53329 to 96.03120, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 97.3311 - MinusLogProbMetric: 97.3311 - val_loss: 96.0312 - val_MinusLogProbMetric: 96.0312 - lr: 3.7037e-05 - 82s/epoch - 419ms/step
Epoch 27/1000
2023-09-20 21:31:20.814 
Epoch 27/1000 
	 loss: 95.5731, MinusLogProbMetric: 95.5731, val_loss: 98.3481, val_MinusLogProbMetric: 98.3481

Epoch 27: val_loss did not improve from 96.03120
196/196 - 80s - loss: 95.5731 - MinusLogProbMetric: 95.5731 - val_loss: 98.3481 - val_MinusLogProbMetric: 98.3481 - lr: 3.7037e-05 - 80s/epoch - 407ms/step
Epoch 28/1000
2023-09-20 21:32:41.383 
Epoch 28/1000 
	 loss: 99.1998, MinusLogProbMetric: 99.1998, val_loss: 115.9322, val_MinusLogProbMetric: 115.9322

Epoch 28: val_loss did not improve from 96.03120
196/196 - 81s - loss: 99.1998 - MinusLogProbMetric: 99.1998 - val_loss: 115.9322 - val_MinusLogProbMetric: 115.9322 - lr: 3.7037e-05 - 81s/epoch - 411ms/step
Epoch 29/1000
2023-09-20 21:34:02.060 
Epoch 29/1000 
	 loss: 97.4065, MinusLogProbMetric: 97.4065, val_loss: 93.8048, val_MinusLogProbMetric: 93.8048

Epoch 29: val_loss improved from 96.03120 to 93.80479, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 97.4065 - MinusLogProbMetric: 97.4065 - val_loss: 93.8048 - val_MinusLogProbMetric: 93.8048 - lr: 3.7037e-05 - 82s/epoch - 418ms/step
Epoch 30/1000
2023-09-20 21:35:22.878 
Epoch 30/1000 
	 loss: 92.1128, MinusLogProbMetric: 92.1128, val_loss: 90.7030, val_MinusLogProbMetric: 90.7030

Epoch 30: val_loss improved from 93.80479 to 90.70303, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 92.1128 - MinusLogProbMetric: 92.1128 - val_loss: 90.7030 - val_MinusLogProbMetric: 90.7030 - lr: 3.7037e-05 - 81s/epoch - 414ms/step
Epoch 31/1000
2023-09-20 21:36:42.486 
Epoch 31/1000 
	 loss: 93.8360, MinusLogProbMetric: 93.8360, val_loss: 97.2162, val_MinusLogProbMetric: 97.2162

Epoch 31: val_loss did not improve from 90.70303
196/196 - 78s - loss: 93.8360 - MinusLogProbMetric: 93.8360 - val_loss: 97.2162 - val_MinusLogProbMetric: 97.2162 - lr: 3.7037e-05 - 78s/epoch - 398ms/step
Epoch 32/1000
2023-09-20 21:38:02.747 
Epoch 32/1000 
	 loss: 102.0730, MinusLogProbMetric: 102.0730, val_loss: 90.6717, val_MinusLogProbMetric: 90.6717

Epoch 32: val_loss improved from 90.70303 to 90.67173, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 102.0730 - MinusLogProbMetric: 102.0730 - val_loss: 90.6717 - val_MinusLogProbMetric: 90.6717 - lr: 3.7037e-05 - 82s/epoch - 418ms/step
Epoch 33/1000
2023-09-20 21:39:24.292 
Epoch 33/1000 
	 loss: 88.1134, MinusLogProbMetric: 88.1134, val_loss: 91.6250, val_MinusLogProbMetric: 91.6250

Epoch 33: val_loss did not improve from 90.67173
196/196 - 80s - loss: 88.1134 - MinusLogProbMetric: 88.1134 - val_loss: 91.6250 - val_MinusLogProbMetric: 91.6250 - lr: 3.7037e-05 - 80s/epoch - 408ms/step
Epoch 34/1000
2023-09-20 21:40:43.307 
Epoch 34/1000 
	 loss: 88.1578, MinusLogProbMetric: 88.1578, val_loss: 89.2284, val_MinusLogProbMetric: 89.2284

Epoch 34: val_loss improved from 90.67173 to 89.22840, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 88.1578 - MinusLogProbMetric: 88.1578 - val_loss: 89.2284 - val_MinusLogProbMetric: 89.2284 - lr: 3.7037e-05 - 80s/epoch - 410ms/step
Epoch 35/1000
2023-09-20 21:42:04.624 
Epoch 35/1000 
	 loss: 86.2572, MinusLogProbMetric: 86.2572, val_loss: 85.8427, val_MinusLogProbMetric: 85.8427

Epoch 35: val_loss improved from 89.22840 to 85.84270, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 86.2572 - MinusLogProbMetric: 86.2572 - val_loss: 85.8427 - val_MinusLogProbMetric: 85.8427 - lr: 3.7037e-05 - 81s/epoch - 415ms/step
Epoch 36/1000
2023-09-20 21:43:26.204 
Epoch 36/1000 
	 loss: 83.8736, MinusLogProbMetric: 83.8736, val_loss: 84.4110, val_MinusLogProbMetric: 84.4110

Epoch 36: val_loss improved from 85.84270 to 84.41105, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 83.8736 - MinusLogProbMetric: 83.8736 - val_loss: 84.4110 - val_MinusLogProbMetric: 84.4110 - lr: 3.7037e-05 - 82s/epoch - 418ms/step
Epoch 37/1000
2023-09-20 21:44:48.031 
Epoch 37/1000 
	 loss: 83.5051, MinusLogProbMetric: 83.5051, val_loss: 83.2838, val_MinusLogProbMetric: 83.2838

Epoch 37: val_loss improved from 84.41105 to 83.28383, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 83.5051 - MinusLogProbMetric: 83.5051 - val_loss: 83.2838 - val_MinusLogProbMetric: 83.2838 - lr: 3.7037e-05 - 81s/epoch - 416ms/step
Epoch 38/1000
2023-09-20 21:46:09.659 
Epoch 38/1000 
	 loss: 81.0166, MinusLogProbMetric: 81.0166, val_loss: 81.1543, val_MinusLogProbMetric: 81.1543

Epoch 38: val_loss improved from 83.28383 to 81.15433, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 81.0166 - MinusLogProbMetric: 81.0166 - val_loss: 81.1543 - val_MinusLogProbMetric: 81.1543 - lr: 3.7037e-05 - 82s/epoch - 417ms/step
Epoch 39/1000
2023-09-20 21:47:31.084 
Epoch 39/1000 
	 loss: 80.2772, MinusLogProbMetric: 80.2772, val_loss: 79.6095, val_MinusLogProbMetric: 79.6095

Epoch 39: val_loss improved from 81.15433 to 79.60954, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 80.2772 - MinusLogProbMetric: 80.2772 - val_loss: 79.6095 - val_MinusLogProbMetric: 79.6095 - lr: 3.7037e-05 - 82s/epoch - 416ms/step
Epoch 40/1000
2023-09-20 21:48:52.435 
Epoch 40/1000 
	 loss: 81.8366, MinusLogProbMetric: 81.8366, val_loss: 78.7388, val_MinusLogProbMetric: 78.7388

Epoch 40: val_loss improved from 79.60954 to 78.73879, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 81.8366 - MinusLogProbMetric: 81.8366 - val_loss: 78.7388 - val_MinusLogProbMetric: 78.7388 - lr: 3.7037e-05 - 81s/epoch - 415ms/step
Epoch 41/1000
2023-09-20 21:50:14.007 
Epoch 41/1000 
	 loss: 78.6936, MinusLogProbMetric: 78.6936, val_loss: 77.0418, val_MinusLogProbMetric: 77.0418

Epoch 41: val_loss improved from 78.73879 to 77.04182, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 78.6936 - MinusLogProbMetric: 78.6936 - val_loss: 77.0418 - val_MinusLogProbMetric: 77.0418 - lr: 3.7037e-05 - 81s/epoch - 415ms/step
Epoch 42/1000
2023-09-20 21:51:33.975 
Epoch 42/1000 
	 loss: 77.1459, MinusLogProbMetric: 77.1459, val_loss: 76.9564, val_MinusLogProbMetric: 76.9564

Epoch 42: val_loss improved from 77.04182 to 76.95639, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 77.1459 - MinusLogProbMetric: 77.1459 - val_loss: 76.9564 - val_MinusLogProbMetric: 76.9564 - lr: 3.7037e-05 - 80s/epoch - 409ms/step
Epoch 43/1000
2023-09-20 21:52:55.177 
Epoch 43/1000 
	 loss: 74.8169, MinusLogProbMetric: 74.8169, val_loss: 74.1237, val_MinusLogProbMetric: 74.1237

Epoch 43: val_loss improved from 76.95639 to 74.12366, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 74.8169 - MinusLogProbMetric: 74.8169 - val_loss: 74.1237 - val_MinusLogProbMetric: 74.1237 - lr: 3.7037e-05 - 81s/epoch - 414ms/step
Epoch 44/1000
2023-09-20 21:54:16.350 
Epoch 44/1000 
	 loss: 75.5574, MinusLogProbMetric: 75.5574, val_loss: 73.5065, val_MinusLogProbMetric: 73.5065

Epoch 44: val_loss improved from 74.12366 to 73.50648, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 75.5574 - MinusLogProbMetric: 75.5574 - val_loss: 73.5065 - val_MinusLogProbMetric: 73.5065 - lr: 3.7037e-05 - 81s/epoch - 413ms/step
Epoch 45/1000
2023-09-20 21:55:37.787 
Epoch 45/1000 
	 loss: 100.3670, MinusLogProbMetric: 100.3670, val_loss: 85.2707, val_MinusLogProbMetric: 85.2707

Epoch 45: val_loss did not improve from 73.50648
196/196 - 80s - loss: 100.3670 - MinusLogProbMetric: 100.3670 - val_loss: 85.2707 - val_MinusLogProbMetric: 85.2707 - lr: 3.7037e-05 - 80s/epoch - 408ms/step
Epoch 46/1000
2023-09-20 21:56:58.076 
Epoch 46/1000 
	 loss: 81.0110, MinusLogProbMetric: 81.0110, val_loss: 78.5792, val_MinusLogProbMetric: 78.5792

Epoch 46: val_loss did not improve from 73.50648
196/196 - 80s - loss: 81.0110 - MinusLogProbMetric: 81.0110 - val_loss: 78.5792 - val_MinusLogProbMetric: 78.5792 - lr: 3.7037e-05 - 80s/epoch - 410ms/step
Epoch 47/1000
2023-09-20 21:58:19.094 
Epoch 47/1000 
	 loss: 76.6122, MinusLogProbMetric: 76.6122, val_loss: 77.3474, val_MinusLogProbMetric: 77.3474

Epoch 47: val_loss did not improve from 73.50648
196/196 - 81s - loss: 76.6122 - MinusLogProbMetric: 76.6122 - val_loss: 77.3474 - val_MinusLogProbMetric: 77.3474 - lr: 3.7037e-05 - 81s/epoch - 413ms/step
Epoch 48/1000
2023-09-20 21:59:39.617 
Epoch 48/1000 
	 loss: 73.9006, MinusLogProbMetric: 73.9006, val_loss: 73.8542, val_MinusLogProbMetric: 73.8542

Epoch 48: val_loss did not improve from 73.50648
196/196 - 81s - loss: 73.9006 - MinusLogProbMetric: 73.9006 - val_loss: 73.8542 - val_MinusLogProbMetric: 73.8542 - lr: 3.7037e-05 - 81s/epoch - 411ms/step
Epoch 49/1000
2023-09-20 22:00:59.463 
Epoch 49/1000 
	 loss: 72.8980, MinusLogProbMetric: 72.8980, val_loss: 71.1419, val_MinusLogProbMetric: 71.1419

Epoch 49: val_loss improved from 73.50648 to 71.14186, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 72.8980 - MinusLogProbMetric: 72.8980 - val_loss: 71.1419 - val_MinusLogProbMetric: 71.1419 - lr: 3.7037e-05 - 81s/epoch - 415ms/step
Epoch 50/1000
2023-09-20 22:02:21.902 
Epoch 50/1000 
	 loss: 74.2981, MinusLogProbMetric: 74.2981, val_loss: 70.9595, val_MinusLogProbMetric: 70.9595

Epoch 50: val_loss improved from 71.14186 to 70.95952, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 74.2981 - MinusLogProbMetric: 74.2981 - val_loss: 70.9595 - val_MinusLogProbMetric: 70.9595 - lr: 3.7037e-05 - 82s/epoch - 420ms/step
Epoch 51/1000
2023-09-20 22:03:43.223 
Epoch 51/1000 
	 loss: 70.6800, MinusLogProbMetric: 70.6800, val_loss: 70.4374, val_MinusLogProbMetric: 70.4374

Epoch 51: val_loss improved from 70.95952 to 70.43745, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 70.6800 - MinusLogProbMetric: 70.6800 - val_loss: 70.4374 - val_MinusLogProbMetric: 70.4374 - lr: 3.7037e-05 - 83s/epoch - 423ms/step
Epoch 52/1000
2023-09-20 22:05:06.371 
Epoch 52/1000 
	 loss: 68.8735, MinusLogProbMetric: 68.8735, val_loss: 71.3601, val_MinusLogProbMetric: 71.3601

Epoch 52: val_loss did not improve from 70.43745
196/196 - 80s - loss: 68.8735 - MinusLogProbMetric: 68.8735 - val_loss: 71.3601 - val_MinusLogProbMetric: 71.3601 - lr: 3.7037e-05 - 80s/epoch - 409ms/step
Epoch 53/1000
2023-09-20 22:06:26.716 
Epoch 53/1000 
	 loss: 68.5853, MinusLogProbMetric: 68.5853, val_loss: 68.5215, val_MinusLogProbMetric: 68.5215

Epoch 53: val_loss improved from 70.43745 to 68.52148, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 68.5853 - MinusLogProbMetric: 68.5853 - val_loss: 68.5215 - val_MinusLogProbMetric: 68.5215 - lr: 3.7037e-05 - 82s/epoch - 416ms/step
Epoch 54/1000
2023-09-20 22:07:47.724 
Epoch 54/1000 
	 loss: 67.2344, MinusLogProbMetric: 67.2344, val_loss: 67.9689, val_MinusLogProbMetric: 67.9689

Epoch 54: val_loss improved from 68.52148 to 67.96888, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 67.2344 - MinusLogProbMetric: 67.2344 - val_loss: 67.9689 - val_MinusLogProbMetric: 67.9689 - lr: 3.7037e-05 - 81s/epoch - 413ms/step
Epoch 55/1000
2023-09-20 22:09:07.648 
Epoch 55/1000 
	 loss: 67.2505, MinusLogProbMetric: 67.2505, val_loss: 65.4776, val_MinusLogProbMetric: 65.4776

Epoch 55: val_loss improved from 67.96888 to 65.47762, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 67.2505 - MinusLogProbMetric: 67.2505 - val_loss: 65.4776 - val_MinusLogProbMetric: 65.4776 - lr: 3.7037e-05 - 80s/epoch - 409ms/step
Epoch 56/1000
2023-09-20 22:10:27.771 
Epoch 56/1000 
	 loss: 65.2879, MinusLogProbMetric: 65.2879, val_loss: 66.2186, val_MinusLogProbMetric: 66.2186

Epoch 56: val_loss did not improve from 65.47762
196/196 - 79s - loss: 65.2879 - MinusLogProbMetric: 65.2879 - val_loss: 66.2186 - val_MinusLogProbMetric: 66.2186 - lr: 3.7037e-05 - 79s/epoch - 401ms/step
Epoch 57/1000
2023-09-20 22:11:47.818 
Epoch 57/1000 
	 loss: 65.2132, MinusLogProbMetric: 65.2132, val_loss: 64.2803, val_MinusLogProbMetric: 64.2803

Epoch 57: val_loss improved from 65.47762 to 64.28031, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 65.2132 - MinusLogProbMetric: 65.2132 - val_loss: 64.2803 - val_MinusLogProbMetric: 64.2803 - lr: 3.7037e-05 - 81s/epoch - 414ms/step
Epoch 58/1000
2023-09-20 22:13:08.579 
Epoch 58/1000 
	 loss: 63.8957, MinusLogProbMetric: 63.8957, val_loss: 63.0694, val_MinusLogProbMetric: 63.0694

Epoch 58: val_loss improved from 64.28031 to 63.06937, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 63.8957 - MinusLogProbMetric: 63.8957 - val_loss: 63.0694 - val_MinusLogProbMetric: 63.0694 - lr: 3.7037e-05 - 81s/epoch - 415ms/step
Epoch 59/1000
2023-09-20 22:14:30.421 
Epoch 59/1000 
	 loss: 64.3681, MinusLogProbMetric: 64.3681, val_loss: 62.5050, val_MinusLogProbMetric: 62.5050

Epoch 59: val_loss improved from 63.06937 to 62.50497, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 64.3681 - MinusLogProbMetric: 64.3681 - val_loss: 62.5050 - val_MinusLogProbMetric: 62.5050 - lr: 3.7037e-05 - 81s/epoch - 415ms/step
Epoch 60/1000
2023-09-20 22:15:51.415 
Epoch 60/1000 
	 loss: 70.7031, MinusLogProbMetric: 70.7031, val_loss: 66.3267, val_MinusLogProbMetric: 66.3267

Epoch 60: val_loss did not improve from 62.50497
196/196 - 80s - loss: 70.7031 - MinusLogProbMetric: 70.7031 - val_loss: 66.3267 - val_MinusLogProbMetric: 66.3267 - lr: 3.7037e-05 - 80s/epoch - 406ms/step
Epoch 61/1000
Warning: The fraction of NaNs in loss is below threshold. Removing them from average.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Batch 47: Invalid loss, terminating training
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
2023-09-20 22:16:14.978 
Epoch 61/1000 
	 loss: nan, MinusLogProbMetric: 221.7231, val_loss: nan, val_MinusLogProbMetric: nan

Epoch 61: val_loss did not improve from 62.50497
196/196 - 24s - loss: nan - MinusLogProbMetric: 221.7231 - val_loss: nan - val_MinusLogProbMetric: nan - lr: 3.7037e-05 - 24s/epoch - 120ms/step
The loss history contains NaN values.
Training failed: trying again with seed 326159 and lr 1.2345679012345677e-05.
===========
Generating train data for run 263.
===========
Train data generated in 0.31 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_263/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 377}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 1.2345679012345677e-05, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_263/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.1831715 ,  3.2834203 ,  8.308094  , ...,  7.3133397 ,
         2.7002556 ,  1.7567806 ],
       [ 6.1308765 ,  7.147402  ,  6.0903115 , ...,  4.022617  ,
         2.6618268 ,  7.627545  ],
       [ 2.7429156 ,  3.6509063 ,  7.295548  , ...,  7.086021  ,
         2.8938296 ,  1.8224454 ],
       ...,
       [ 2.1098776 ,  4.1337423 ,  8.041495  , ...,  7.2043395 ,
         2.3724499 ,  1.8449893 ],
       [ 4.759076  ,  5.6016526 , -0.17659053, ...,  1.2483898 ,
         6.6213574 ,  1.391019  ],
       [ 4.6478305 ,  5.6608987 ,  0.05425403, ...,  1.0307544 ,
         6.027231  ,  1.3217621 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_263/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_263
self.data_kwargs: {'seed': 377}
self.x_data: [[5.416377   7.151266   6.5657053  ... 3.613302   2.6304417  8.037386  ]
 [4.297167   5.832213   0.12875912 ... 1.4317983  6.415448   1.3533646 ]
 [6.2353234  7.1795187  6.219724   ... 4.5891814  2.66546    7.551563  ]
 ...
 [1.8237456  4.102903   7.5608215  ... 7.136859   2.564185   1.5539532 ]
 [2.2305896  4.6568003  8.321339   ... 7.0577617  2.6189713  1.518045  ]
 [5.653481   7.1263475  6.929123   ... 4.292566   2.643216   7.404443  ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_257"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_258 (InputLayer)      [(None, 32)]              0         
                                                                 
 log_prob_layer_27 (LogProbL  (None,)                  1074400   
 ayer)                                                           
                                                                 
=================================================================
Total params: 1,074,400
Trainable params: 1,074,400
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_27/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_27'")
self.model: <keras.engine.functional.Functional object at 0x7faa6cdeef50>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 1.2345679012345677e-05, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7faa949d6020>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 1.2345679012345677e-05, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7faa949d6020>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7faa6cda2530>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7faa8539b130>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7faa8539b6a0>, <keras.callbacks.ModelCheckpoint object at 0x7faa8539b760>, <keras.callbacks.EarlyStopping object at 0x7faa8539b9d0>, <keras.callbacks.ReduceLROnPlateau object at 0x7faa8539ba00>, <keras.callbacks.TerminateOnNaN object at 0x7faa8539b640>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.1831715 ,  3.2834203 ,  8.308094  , ...,  7.3133397 ,
         2.7002556 ,  1.7567806 ],
       [ 6.1308765 ,  7.147402  ,  6.0903115 , ...,  4.022617  ,
         2.6618268 ,  7.627545  ],
       [ 2.7429156 ,  3.6509063 ,  7.295548  , ...,  7.086021  ,
         2.8938296 ,  1.8224454 ],
       ...,
       [ 2.1098776 ,  4.1337423 ,  8.041495  , ...,  7.2043395 ,
         2.3724499 ,  1.8449893 ],
       [ 4.759076  ,  5.6016526 , -0.17659053, ...,  1.2483898 ,
         6.6213574 ,  1.391019  ],
       [ 4.6478305 ,  5.6608987 ,  0.05425403, ...,  1.0307544 ,
         6.027231  ,  1.3217621 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
Found and loaded existing weights.
No history found. Generating new history.
===============
Running 263/720 with hyperparameters:
timestamp = 2023-09-20 22:16:29.011997
ndims = 32
seed_train = 377
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 1074400
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 1.2345679012345677e-05...
Train first sample: [ 5.416377    7.151266    6.5657053   5.44807     3.870332    6.1800294
  2.9008856   8.441634    9.391678    4.1002183   7.382605    5.3625755
  5.5868373   9.949682    0.82923275  1.9832962  -0.10069095  8.219267
  8.539603    9.221239    9.5321455   8.239499    4.945965    8.152974
 -0.16393006  6.303131    0.6036788   9.50227     6.1976576   3.613302
  2.6304417   8.037386  ]
Epoch 1/1000
2023-09-20 22:21:25.786 
Epoch 1/1000 
	 loss: 61.7360, MinusLogProbMetric: 61.7360, val_loss: 59.3099, val_MinusLogProbMetric: 59.3099

Epoch 1: val_loss improved from inf to 59.30994, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 300s - loss: 61.7360 - MinusLogProbMetric: 61.7360 - val_loss: 59.3099 - val_MinusLogProbMetric: 59.3099 - lr: 1.2346e-05 - 300s/epoch - 2s/step
Epoch 2/1000
2023-09-20 22:22:53.360 
Epoch 2/1000 
	 loss: 60.3870, MinusLogProbMetric: 60.3870, val_loss: 68.5009, val_MinusLogProbMetric: 68.5009

Epoch 2: val_loss did not improve from 59.30994
196/196 - 84s - loss: 60.3870 - MinusLogProbMetric: 60.3870 - val_loss: 68.5009 - val_MinusLogProbMetric: 68.5009 - lr: 1.2346e-05 - 84s/epoch - 427ms/step
Epoch 3/1000
2023-09-20 22:24:16.281 
Epoch 3/1000 
	 loss: 59.2489, MinusLogProbMetric: 59.2489, val_loss: 55.0624, val_MinusLogProbMetric: 55.0624

Epoch 3: val_loss improved from 59.30994 to 55.06240, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 85s - loss: 59.2489 - MinusLogProbMetric: 59.2489 - val_loss: 55.0624 - val_MinusLogProbMetric: 55.0624 - lr: 1.2346e-05 - 85s/epoch - 431ms/step
Epoch 4/1000
2023-09-20 22:25:40.281 
Epoch 4/1000 
	 loss: 55.1287, MinusLogProbMetric: 55.1287, val_loss: 60.1264, val_MinusLogProbMetric: 60.1264

Epoch 4: val_loss did not improve from 55.06240
196/196 - 82s - loss: 55.1287 - MinusLogProbMetric: 55.1287 - val_loss: 60.1264 - val_MinusLogProbMetric: 60.1264 - lr: 1.2346e-05 - 82s/epoch - 420ms/step
Epoch 5/1000
2023-09-20 22:27:02.570 
Epoch 5/1000 
	 loss: 59.8516, MinusLogProbMetric: 59.8516, val_loss: 56.6173, val_MinusLogProbMetric: 56.6173

Epoch 5: val_loss did not improve from 55.06240
196/196 - 82s - loss: 59.8516 - MinusLogProbMetric: 59.8516 - val_loss: 56.6173 - val_MinusLogProbMetric: 56.6173 - lr: 1.2346e-05 - 82s/epoch - 420ms/step
Epoch 6/1000
2023-09-20 22:28:22.747 
Epoch 6/1000 
	 loss: 53.0677, MinusLogProbMetric: 53.0677, val_loss: 51.1227, val_MinusLogProbMetric: 51.1227

Epoch 6: val_loss improved from 55.06240 to 51.12273, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 53.0677 - MinusLogProbMetric: 53.0677 - val_loss: 51.1227 - val_MinusLogProbMetric: 51.1227 - lr: 1.2346e-05 - 82s/epoch - 416ms/step
Epoch 7/1000
2023-09-20 22:29:46.810 
Epoch 7/1000 
	 loss: 53.4303, MinusLogProbMetric: 53.4303, val_loss: 50.4070, val_MinusLogProbMetric: 50.4070

Epoch 7: val_loss improved from 51.12273 to 50.40700, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 53.4303 - MinusLogProbMetric: 53.4303 - val_loss: 50.4070 - val_MinusLogProbMetric: 50.4070 - lr: 1.2346e-05 - 84s/epoch - 429ms/step
Epoch 8/1000
2023-09-20 22:31:10.148 
Epoch 8/1000 
	 loss: 50.5075, MinusLogProbMetric: 50.5075, val_loss: 49.2094, val_MinusLogProbMetric: 49.2094

Epoch 8: val_loss improved from 50.40700 to 49.20940, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 50.5075 - MinusLogProbMetric: 50.5075 - val_loss: 49.2094 - val_MinusLogProbMetric: 49.2094 - lr: 1.2346e-05 - 83s/epoch - 425ms/step
Epoch 9/1000
2023-09-20 22:32:31.375 
Epoch 9/1000 
	 loss: 55.3740, MinusLogProbMetric: 55.3740, val_loss: 52.4644, val_MinusLogProbMetric: 52.4644

Epoch 9: val_loss did not improve from 49.20940
196/196 - 80s - loss: 55.3740 - MinusLogProbMetric: 55.3740 - val_loss: 52.4644 - val_MinusLogProbMetric: 52.4644 - lr: 1.2346e-05 - 80s/epoch - 407ms/step
Epoch 10/1000
2023-09-20 22:33:53.339 
Epoch 10/1000 
	 loss: 68.7488, MinusLogProbMetric: 68.7488, val_loss: 63.9566, val_MinusLogProbMetric: 63.9566

Epoch 10: val_loss did not improve from 49.20940
196/196 - 82s - loss: 68.7488 - MinusLogProbMetric: 68.7488 - val_loss: 63.9566 - val_MinusLogProbMetric: 63.9566 - lr: 1.2346e-05 - 82s/epoch - 418ms/step
Epoch 11/1000
2023-09-20 22:35:16.214 
Epoch 11/1000 
	 loss: 83.1293, MinusLogProbMetric: 83.1293, val_loss: 82.8921, val_MinusLogProbMetric: 82.8921

Epoch 11: val_loss did not improve from 49.20940
196/196 - 83s - loss: 83.1293 - MinusLogProbMetric: 83.1293 - val_loss: 82.8921 - val_MinusLogProbMetric: 82.8921 - lr: 1.2346e-05 - 83s/epoch - 423ms/step
Epoch 12/1000
2023-09-20 22:36:37.352 
Epoch 12/1000 
	 loss: 66.8016, MinusLogProbMetric: 66.8016, val_loss: 59.6912, val_MinusLogProbMetric: 59.6912

Epoch 12: val_loss did not improve from 49.20940
196/196 - 81s - loss: 66.8016 - MinusLogProbMetric: 66.8016 - val_loss: 59.6912 - val_MinusLogProbMetric: 59.6912 - lr: 1.2346e-05 - 81s/epoch - 414ms/step
Epoch 13/1000
2023-09-20 22:38:00.328 
Epoch 13/1000 
	 loss: 62.9031, MinusLogProbMetric: 62.9031, val_loss: 55.9245, val_MinusLogProbMetric: 55.9245

Epoch 13: val_loss did not improve from 49.20940
196/196 - 83s - loss: 62.9031 - MinusLogProbMetric: 62.9031 - val_loss: 55.9245 - val_MinusLogProbMetric: 55.9245 - lr: 1.2346e-05 - 83s/epoch - 423ms/step
Epoch 14/1000
2023-09-20 22:39:22.772 
Epoch 14/1000 
	 loss: 60.8982, MinusLogProbMetric: 60.8982, val_loss: 56.4595, val_MinusLogProbMetric: 56.4595

Epoch 14: val_loss did not improve from 49.20940
196/196 - 82s - loss: 60.8982 - MinusLogProbMetric: 60.8982 - val_loss: 56.4595 - val_MinusLogProbMetric: 56.4595 - lr: 1.2346e-05 - 82s/epoch - 421ms/step
Epoch 15/1000
2023-09-20 22:40:44.607 
Epoch 15/1000 
	 loss: 57.9940, MinusLogProbMetric: 57.9940, val_loss: 51.2828, val_MinusLogProbMetric: 51.2828

Epoch 15: val_loss did not improve from 49.20940
196/196 - 82s - loss: 57.9940 - MinusLogProbMetric: 57.9940 - val_loss: 51.2828 - val_MinusLogProbMetric: 51.2828 - lr: 1.2346e-05 - 82s/epoch - 418ms/step
Epoch 16/1000
2023-09-20 22:42:06.669 
Epoch 16/1000 
	 loss: 107.1288, MinusLogProbMetric: 107.1288, val_loss: 98.2490, val_MinusLogProbMetric: 98.2490

Epoch 16: val_loss did not improve from 49.20940
196/196 - 82s - loss: 107.1288 - MinusLogProbMetric: 107.1288 - val_loss: 98.2490 - val_MinusLogProbMetric: 98.2490 - lr: 1.2346e-05 - 82s/epoch - 419ms/step
Epoch 17/1000
2023-09-20 22:43:28.930 
Epoch 17/1000 
	 loss: 87.7414, MinusLogProbMetric: 87.7414, val_loss: 77.0478, val_MinusLogProbMetric: 77.0478

Epoch 17: val_loss did not improve from 49.20940
196/196 - 82s - loss: 87.7414 - MinusLogProbMetric: 87.7414 - val_loss: 77.0478 - val_MinusLogProbMetric: 77.0478 - lr: 1.2346e-05 - 82s/epoch - 420ms/step
Epoch 18/1000
2023-09-20 22:44:48.481 
Epoch 18/1000 
	 loss: 76.8306, MinusLogProbMetric: 76.8306, val_loss: 73.5116, val_MinusLogProbMetric: 73.5116

Epoch 18: val_loss did not improve from 49.20940
196/196 - 80s - loss: 76.8306 - MinusLogProbMetric: 76.8306 - val_loss: 73.5116 - val_MinusLogProbMetric: 73.5116 - lr: 1.2346e-05 - 80s/epoch - 406ms/step
Epoch 19/1000
2023-09-20 22:46:10.199 
Epoch 19/1000 
	 loss: 69.4333, MinusLogProbMetric: 69.4333, val_loss: 65.3471, val_MinusLogProbMetric: 65.3471

Epoch 19: val_loss did not improve from 49.20940
196/196 - 82s - loss: 69.4333 - MinusLogProbMetric: 69.4333 - val_loss: 65.3471 - val_MinusLogProbMetric: 65.3471 - lr: 1.2346e-05 - 82s/epoch - 417ms/step
Epoch 20/1000
2023-09-20 22:47:33.217 
Epoch 20/1000 
	 loss: 66.9114, MinusLogProbMetric: 66.9114, val_loss: 62.7526, val_MinusLogProbMetric: 62.7526

Epoch 20: val_loss did not improve from 49.20940
196/196 - 83s - loss: 66.9114 - MinusLogProbMetric: 66.9114 - val_loss: 62.7526 - val_MinusLogProbMetric: 62.7526 - lr: 1.2346e-05 - 83s/epoch - 424ms/step
Epoch 21/1000
2023-09-20 22:48:56.113 
Epoch 21/1000 
	 loss: 64.0653, MinusLogProbMetric: 64.0653, val_loss: 139.0397, val_MinusLogProbMetric: 139.0397

Epoch 21: val_loss did not improve from 49.20940
196/196 - 83s - loss: 64.0653 - MinusLogProbMetric: 64.0653 - val_loss: 139.0397 - val_MinusLogProbMetric: 139.0397 - lr: 1.2346e-05 - 83s/epoch - 423ms/step
Epoch 22/1000
2023-09-20 22:50:17.668 
Epoch 22/1000 
	 loss: 85.8772, MinusLogProbMetric: 85.8772, val_loss: 71.2073, val_MinusLogProbMetric: 71.2073

Epoch 22: val_loss did not improve from 49.20940
196/196 - 82s - loss: 85.8772 - MinusLogProbMetric: 85.8772 - val_loss: 71.2073 - val_MinusLogProbMetric: 71.2073 - lr: 1.2346e-05 - 82s/epoch - 416ms/step
Epoch 23/1000
2023-09-20 22:51:39.263 
Epoch 23/1000 
	 loss: 63.9072, MinusLogProbMetric: 63.9072, val_loss: 61.1522, val_MinusLogProbMetric: 61.1522

Epoch 23: val_loss did not improve from 49.20940
196/196 - 82s - loss: 63.9072 - MinusLogProbMetric: 63.9072 - val_loss: 61.1522 - val_MinusLogProbMetric: 61.1522 - lr: 1.2346e-05 - 82s/epoch - 416ms/step
Epoch 24/1000
2023-09-20 22:53:01.463 
Epoch 24/1000 
	 loss: 59.0448, MinusLogProbMetric: 59.0448, val_loss: 77.1411, val_MinusLogProbMetric: 77.1411

Epoch 24: val_loss did not improve from 49.20940
196/196 - 82s - loss: 59.0448 - MinusLogProbMetric: 59.0448 - val_loss: 77.1411 - val_MinusLogProbMetric: 77.1411 - lr: 1.2346e-05 - 82s/epoch - 419ms/step
Epoch 25/1000
2023-09-20 22:54:23.385 
Epoch 25/1000 
	 loss: 61.3937, MinusLogProbMetric: 61.3937, val_loss: 56.8724, val_MinusLogProbMetric: 56.8724

Epoch 25: val_loss did not improve from 49.20940
196/196 - 82s - loss: 61.3937 - MinusLogProbMetric: 61.3937 - val_loss: 56.8724 - val_MinusLogProbMetric: 56.8724 - lr: 1.2346e-05 - 82s/epoch - 418ms/step
Epoch 26/1000
2023-09-20 22:55:45.679 
Epoch 26/1000 
	 loss: 55.6612, MinusLogProbMetric: 55.6612, val_loss: 54.6238, val_MinusLogProbMetric: 54.6238

Epoch 26: val_loss did not improve from 49.20940
196/196 - 82s - loss: 55.6612 - MinusLogProbMetric: 55.6612 - val_loss: 54.6238 - val_MinusLogProbMetric: 54.6238 - lr: 1.2346e-05 - 82s/epoch - 420ms/step
Epoch 27/1000
2023-09-20 22:57:08.782 
Epoch 27/1000 
	 loss: 76.7426, MinusLogProbMetric: 76.7426, val_loss: 64.4653, val_MinusLogProbMetric: 64.4653

Epoch 27: val_loss did not improve from 49.20940
196/196 - 83s - loss: 76.7426 - MinusLogProbMetric: 76.7426 - val_loss: 64.4653 - val_MinusLogProbMetric: 64.4653 - lr: 1.2346e-05 - 83s/epoch - 424ms/step
Epoch 28/1000
2023-09-20 22:58:31.410 
Epoch 28/1000 
	 loss: 60.4633, MinusLogProbMetric: 60.4633, val_loss: 56.7563, val_MinusLogProbMetric: 56.7563

Epoch 28: val_loss did not improve from 49.20940
196/196 - 83s - loss: 60.4633 - MinusLogProbMetric: 60.4633 - val_loss: 56.7563 - val_MinusLogProbMetric: 56.7563 - lr: 1.2346e-05 - 83s/epoch - 422ms/step
Epoch 29/1000
2023-09-20 22:59:53.034 
Epoch 29/1000 
	 loss: 54.1811, MinusLogProbMetric: 54.1811, val_loss: 52.6107, val_MinusLogProbMetric: 52.6107

Epoch 29: val_loss did not improve from 49.20940
196/196 - 82s - loss: 54.1811 - MinusLogProbMetric: 54.1811 - val_loss: 52.6107 - val_MinusLogProbMetric: 52.6107 - lr: 1.2346e-05 - 82s/epoch - 416ms/step
Epoch 30/1000
2023-09-20 23:01:15.179 
Epoch 30/1000 
	 loss: 52.0033, MinusLogProbMetric: 52.0033, val_loss: 51.3546, val_MinusLogProbMetric: 51.3546

Epoch 30: val_loss did not improve from 49.20940
196/196 - 82s - loss: 52.0033 - MinusLogProbMetric: 52.0033 - val_loss: 51.3546 - val_MinusLogProbMetric: 51.3546 - lr: 1.2346e-05 - 82s/epoch - 419ms/step
Epoch 31/1000
2023-09-20 23:02:36.670 
Epoch 31/1000 
	 loss: 50.8011, MinusLogProbMetric: 50.8011, val_loss: 50.2020, val_MinusLogProbMetric: 50.2020

Epoch 31: val_loss did not improve from 49.20940
196/196 - 81s - loss: 50.8011 - MinusLogProbMetric: 50.8011 - val_loss: 50.2020 - val_MinusLogProbMetric: 50.2020 - lr: 1.2346e-05 - 81s/epoch - 416ms/step
Epoch 32/1000
2023-09-20 23:03:58.038 
Epoch 32/1000 
	 loss: 49.7198, MinusLogProbMetric: 49.7198, val_loss: 49.4061, val_MinusLogProbMetric: 49.4061

Epoch 32: val_loss did not improve from 49.20940
196/196 - 81s - loss: 49.7198 - MinusLogProbMetric: 49.7198 - val_loss: 49.4061 - val_MinusLogProbMetric: 49.4061 - lr: 1.2346e-05 - 81s/epoch - 415ms/step
Epoch 33/1000
2023-09-20 23:05:21.391 
Epoch 33/1000 
	 loss: 49.0158, MinusLogProbMetric: 49.0158, val_loss: 48.6102, val_MinusLogProbMetric: 48.6102

Epoch 33: val_loss improved from 49.20940 to 48.61023, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 85s - loss: 49.0158 - MinusLogProbMetric: 49.0158 - val_loss: 48.6102 - val_MinusLogProbMetric: 48.6102 - lr: 1.2346e-05 - 85s/epoch - 431ms/step
Epoch 34/1000
2023-09-20 23:06:44.174 
Epoch 34/1000 
	 loss: 48.3578, MinusLogProbMetric: 48.3578, val_loss: 48.1258, val_MinusLogProbMetric: 48.1258

Epoch 34: val_loss improved from 48.61023 to 48.12576, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 48.3578 - MinusLogProbMetric: 48.3578 - val_loss: 48.1258 - val_MinusLogProbMetric: 48.1258 - lr: 1.2346e-05 - 83s/epoch - 424ms/step
Epoch 35/1000
2023-09-20 23:08:07.913 
Epoch 35/1000 
	 loss: 47.7373, MinusLogProbMetric: 47.7373, val_loss: 47.5400, val_MinusLogProbMetric: 47.5400

Epoch 35: val_loss improved from 48.12576 to 47.54001, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 47.7373 - MinusLogProbMetric: 47.7373 - val_loss: 47.5400 - val_MinusLogProbMetric: 47.5400 - lr: 1.2346e-05 - 84s/epoch - 427ms/step
Epoch 36/1000
2023-09-20 23:09:30.516 
Epoch 36/1000 
	 loss: 47.3109, MinusLogProbMetric: 47.3109, val_loss: 46.9659, val_MinusLogProbMetric: 46.9659

Epoch 36: val_loss improved from 47.54001 to 46.96594, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 47.3109 - MinusLogProbMetric: 47.3109 - val_loss: 46.9659 - val_MinusLogProbMetric: 46.9659 - lr: 1.2346e-05 - 83s/epoch - 422ms/step
Epoch 37/1000
2023-09-20 23:10:53.965 
Epoch 37/1000 
	 loss: 46.7531, MinusLogProbMetric: 46.7531, val_loss: 46.5335, val_MinusLogProbMetric: 46.5335

Epoch 37: val_loss improved from 46.96594 to 46.53352, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 46.7531 - MinusLogProbMetric: 46.7531 - val_loss: 46.5335 - val_MinusLogProbMetric: 46.5335 - lr: 1.2346e-05 - 83s/epoch - 426ms/step
Epoch 38/1000
2023-09-20 23:12:17.354 
Epoch 38/1000 
	 loss: 46.4382, MinusLogProbMetric: 46.4382, val_loss: 46.1927, val_MinusLogProbMetric: 46.1927

Epoch 38: val_loss improved from 46.53352 to 46.19271, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 46.4382 - MinusLogProbMetric: 46.4382 - val_loss: 46.1927 - val_MinusLogProbMetric: 46.1927 - lr: 1.2346e-05 - 83s/epoch - 424ms/step
Epoch 39/1000
2023-09-20 23:13:41.366 
Epoch 39/1000 
	 loss: 46.2138, MinusLogProbMetric: 46.2138, val_loss: 45.7958, val_MinusLogProbMetric: 45.7958

Epoch 39: val_loss improved from 46.19271 to 45.79576, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 85s - loss: 46.2138 - MinusLogProbMetric: 46.2138 - val_loss: 45.7958 - val_MinusLogProbMetric: 45.7958 - lr: 1.2346e-05 - 85s/epoch - 435ms/step
Epoch 40/1000
2023-09-20 23:15:06.484 
Epoch 40/1000 
	 loss: 45.7783, MinusLogProbMetric: 45.7783, val_loss: 45.6316, val_MinusLogProbMetric: 45.6316

Epoch 40: val_loss improved from 45.79576 to 45.63163, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 45.7783 - MinusLogProbMetric: 45.7783 - val_loss: 45.6316 - val_MinusLogProbMetric: 45.6316 - lr: 1.2346e-05 - 84s/epoch - 430ms/step
Epoch 41/1000
2023-09-20 23:16:30.459 
Epoch 41/1000 
	 loss: 45.1421, MinusLogProbMetric: 45.1421, val_loss: 44.9479, val_MinusLogProbMetric: 44.9479

Epoch 41: val_loss improved from 45.63163 to 44.94793, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 85s - loss: 45.1421 - MinusLogProbMetric: 45.1421 - val_loss: 44.9479 - val_MinusLogProbMetric: 44.9479 - lr: 1.2346e-05 - 85s/epoch - 433ms/step
Epoch 42/1000
2023-09-20 23:17:55.652 
Epoch 42/1000 
	 loss: 44.7470, MinusLogProbMetric: 44.7470, val_loss: 44.5666, val_MinusLogProbMetric: 44.5666

Epoch 42: val_loss improved from 44.94793 to 44.56656, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 44.7470 - MinusLogProbMetric: 44.7470 - val_loss: 44.5666 - val_MinusLogProbMetric: 44.5666 - lr: 1.2346e-05 - 84s/epoch - 429ms/step
Epoch 43/1000
2023-09-20 23:19:19.944 
Epoch 43/1000 
	 loss: 44.3620, MinusLogProbMetric: 44.3620, val_loss: 44.1355, val_MinusLogProbMetric: 44.1355

Epoch 43: val_loss improved from 44.56656 to 44.13552, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 44.3620 - MinusLogProbMetric: 44.3620 - val_loss: 44.1355 - val_MinusLogProbMetric: 44.1355 - lr: 1.2346e-05 - 84s/epoch - 429ms/step
Epoch 44/1000
2023-09-20 23:20:42.289 
Epoch 44/1000 
	 loss: 44.0239, MinusLogProbMetric: 44.0239, val_loss: 43.8357, val_MinusLogProbMetric: 43.8357

Epoch 44: val_loss improved from 44.13552 to 43.83571, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 44.0239 - MinusLogProbMetric: 44.0239 - val_loss: 43.8357 - val_MinusLogProbMetric: 43.8357 - lr: 1.2346e-05 - 82s/epoch - 418ms/step
Epoch 45/1000
2023-09-20 23:22:06.101 
Epoch 45/1000 
	 loss: 43.7422, MinusLogProbMetric: 43.7422, val_loss: 43.7204, val_MinusLogProbMetric: 43.7204

Epoch 45: val_loss improved from 43.83571 to 43.72041, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 43.7422 - MinusLogProbMetric: 43.7422 - val_loss: 43.7204 - val_MinusLogProbMetric: 43.7204 - lr: 1.2346e-05 - 84s/epoch - 430ms/step
Epoch 46/1000
2023-09-20 23:23:30.505 
Epoch 46/1000 
	 loss: 43.3373, MinusLogProbMetric: 43.3373, val_loss: 43.2033, val_MinusLogProbMetric: 43.2033

Epoch 46: val_loss improved from 43.72041 to 43.20332, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 43.3373 - MinusLogProbMetric: 43.3373 - val_loss: 43.2033 - val_MinusLogProbMetric: 43.2033 - lr: 1.2346e-05 - 84s/epoch - 431ms/step
Epoch 47/1000
2023-09-20 23:24:53.455 
Epoch 47/1000 
	 loss: 42.9202, MinusLogProbMetric: 42.9202, val_loss: 43.2834, val_MinusLogProbMetric: 43.2834

Epoch 47: val_loss did not improve from 43.20332
196/196 - 81s - loss: 42.9202 - MinusLogProbMetric: 42.9202 - val_loss: 43.2834 - val_MinusLogProbMetric: 43.2834 - lr: 1.2346e-05 - 81s/epoch - 415ms/step
Epoch 48/1000
2023-09-20 23:26:16.423 
Epoch 48/1000 
	 loss: 47.9374, MinusLogProbMetric: 47.9374, val_loss: 45.0205, val_MinusLogProbMetric: 45.0205

Epoch 48: val_loss did not improve from 43.20332
196/196 - 83s - loss: 47.9374 - MinusLogProbMetric: 47.9374 - val_loss: 45.0205 - val_MinusLogProbMetric: 45.0205 - lr: 1.2346e-05 - 83s/epoch - 423ms/step
Epoch 49/1000
2023-09-20 23:27:38.605 
Epoch 49/1000 
	 loss: 44.0746, MinusLogProbMetric: 44.0746, val_loss: 43.4363, val_MinusLogProbMetric: 43.4363

Epoch 49: val_loss did not improve from 43.20332
196/196 - 82s - loss: 44.0746 - MinusLogProbMetric: 44.0746 - val_loss: 43.4363 - val_MinusLogProbMetric: 43.4363 - lr: 1.2346e-05 - 82s/epoch - 419ms/step
Epoch 50/1000
2023-09-20 23:29:00.495 
Epoch 50/1000 
	 loss: 43.4826, MinusLogProbMetric: 43.4826, val_loss: 43.0436, val_MinusLogProbMetric: 43.0436

Epoch 50: val_loss improved from 43.20332 to 43.04364, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 43.4826 - MinusLogProbMetric: 43.4826 - val_loss: 43.0436 - val_MinusLogProbMetric: 43.0436 - lr: 1.2346e-05 - 84s/epoch - 427ms/step
Epoch 51/1000
2023-09-20 23:30:24.261 
Epoch 51/1000 
	 loss: 42.7490, MinusLogProbMetric: 42.7490, val_loss: 42.5463, val_MinusLogProbMetric: 42.5463

Epoch 51: val_loss improved from 43.04364 to 42.54634, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 42.7490 - MinusLogProbMetric: 42.7490 - val_loss: 42.5463 - val_MinusLogProbMetric: 42.5463 - lr: 1.2346e-05 - 83s/epoch - 425ms/step
Epoch 52/1000
2023-09-20 23:31:47.351 
Epoch 52/1000 
	 loss: 42.3981, MinusLogProbMetric: 42.3981, val_loss: 42.2586, val_MinusLogProbMetric: 42.2586

Epoch 52: val_loss improved from 42.54634 to 42.25858, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 42.3981 - MinusLogProbMetric: 42.3981 - val_loss: 42.2586 - val_MinusLogProbMetric: 42.2586 - lr: 1.2346e-05 - 83s/epoch - 424ms/step
Epoch 53/1000
2023-09-20 23:33:09.911 
Epoch 53/1000 
	 loss: 42.0522, MinusLogProbMetric: 42.0522, val_loss: 41.8135, val_MinusLogProbMetric: 41.8135

Epoch 53: val_loss improved from 42.25858 to 41.81355, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 42.0522 - MinusLogProbMetric: 42.0522 - val_loss: 41.8135 - val_MinusLogProbMetric: 41.8135 - lr: 1.2346e-05 - 83s/epoch - 423ms/step
Epoch 54/1000
2023-09-20 23:34:32.327 
Epoch 54/1000 
	 loss: 41.7260, MinusLogProbMetric: 41.7260, val_loss: 41.5201, val_MinusLogProbMetric: 41.5201

Epoch 54: val_loss improved from 41.81355 to 41.52005, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 41.7260 - MinusLogProbMetric: 41.7260 - val_loss: 41.5201 - val_MinusLogProbMetric: 41.5201 - lr: 1.2346e-05 - 82s/epoch - 420ms/step
Epoch 55/1000
2023-09-20 23:35:55.476 
Epoch 55/1000 
	 loss: 41.3817, MinusLogProbMetric: 41.3817, val_loss: 41.4132, val_MinusLogProbMetric: 41.4132

Epoch 55: val_loss improved from 41.52005 to 41.41317, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 41.3817 - MinusLogProbMetric: 41.3817 - val_loss: 41.4132 - val_MinusLogProbMetric: 41.4132 - lr: 1.2346e-05 - 83s/epoch - 423ms/step
Epoch 56/1000
2023-09-20 23:37:20.445 
Epoch 56/1000 
	 loss: 40.9725, MinusLogProbMetric: 40.9725, val_loss: 40.7269, val_MinusLogProbMetric: 40.7269

Epoch 56: val_loss improved from 41.41317 to 40.72692, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 85s - loss: 40.9725 - MinusLogProbMetric: 40.9725 - val_loss: 40.7269 - val_MinusLogProbMetric: 40.7269 - lr: 1.2346e-05 - 85s/epoch - 434ms/step
Epoch 57/1000
2023-09-20 23:38:44.920 
Epoch 57/1000 
	 loss: 40.6431, MinusLogProbMetric: 40.6431, val_loss: 40.3997, val_MinusLogProbMetric: 40.3997

Epoch 57: val_loss improved from 40.72692 to 40.39969, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 85s - loss: 40.6431 - MinusLogProbMetric: 40.6431 - val_loss: 40.3997 - val_MinusLogProbMetric: 40.3997 - lr: 1.2346e-05 - 85s/epoch - 431ms/step
Epoch 58/1000
2023-09-20 23:40:09.324 
Epoch 58/1000 
	 loss: 40.2285, MinusLogProbMetric: 40.2285, val_loss: 40.1966, val_MinusLogProbMetric: 40.1966

Epoch 58: val_loss improved from 40.39969 to 40.19659, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 40.2285 - MinusLogProbMetric: 40.2285 - val_loss: 40.1966 - val_MinusLogProbMetric: 40.1966 - lr: 1.2346e-05 - 84s/epoch - 431ms/step
Epoch 59/1000
2023-09-20 23:41:32.135 
Epoch 59/1000 
	 loss: 39.9662, MinusLogProbMetric: 39.9662, val_loss: 39.9058, val_MinusLogProbMetric: 39.9058

Epoch 59: val_loss improved from 40.19659 to 39.90577, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 39.9662 - MinusLogProbMetric: 39.9662 - val_loss: 39.9058 - val_MinusLogProbMetric: 39.9058 - lr: 1.2346e-05 - 82s/epoch - 420ms/step
Epoch 60/1000
2023-09-20 23:42:56.012 
Epoch 60/1000 
	 loss: 39.7666, MinusLogProbMetric: 39.7666, val_loss: 39.7596, val_MinusLogProbMetric: 39.7596

Epoch 60: val_loss improved from 39.90577 to 39.75956, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 39.7666 - MinusLogProbMetric: 39.7666 - val_loss: 39.7596 - val_MinusLogProbMetric: 39.7596 - lr: 1.2346e-05 - 84s/epoch - 429ms/step
Epoch 61/1000
2023-09-20 23:44:20.445 
Epoch 61/1000 
	 loss: 39.5140, MinusLogProbMetric: 39.5140, val_loss: 39.4342, val_MinusLogProbMetric: 39.4342

Epoch 61: val_loss improved from 39.75956 to 39.43419, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 85s - loss: 39.5140 - MinusLogProbMetric: 39.5140 - val_loss: 39.4342 - val_MinusLogProbMetric: 39.4342 - lr: 1.2346e-05 - 85s/epoch - 431ms/step
Epoch 62/1000
2023-09-20 23:45:42.704 
Epoch 62/1000 
	 loss: 39.9494, MinusLogProbMetric: 39.9494, val_loss: 39.4348, val_MinusLogProbMetric: 39.4348

Epoch 62: val_loss did not improve from 39.43419
196/196 - 81s - loss: 39.9494 - MinusLogProbMetric: 39.9494 - val_loss: 39.4348 - val_MinusLogProbMetric: 39.4348 - lr: 1.2346e-05 - 81s/epoch - 411ms/step
Epoch 63/1000
2023-09-20 23:47:03.546 
Epoch 63/1000 
	 loss: 39.0993, MinusLogProbMetric: 39.0993, val_loss: 38.9493, val_MinusLogProbMetric: 38.9493

Epoch 63: val_loss improved from 39.43419 to 38.94927, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 39.0993 - MinusLogProbMetric: 39.0993 - val_loss: 38.9493 - val_MinusLogProbMetric: 38.9493 - lr: 1.2346e-05 - 83s/epoch - 425ms/step
Epoch 64/1000
2023-09-20 23:48:29.268 
Epoch 64/1000 
	 loss: 38.8872, MinusLogProbMetric: 38.8872, val_loss: 38.7579, val_MinusLogProbMetric: 38.7579

Epoch 64: val_loss improved from 38.94927 to 38.75787, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 85s - loss: 38.8872 - MinusLogProbMetric: 38.8872 - val_loss: 38.7579 - val_MinusLogProbMetric: 38.7579 - lr: 1.2346e-05 - 85s/epoch - 432ms/step
Epoch 65/1000
2023-09-20 23:49:52.640 
Epoch 65/1000 
	 loss: 38.5758, MinusLogProbMetric: 38.5758, val_loss: 38.5328, val_MinusLogProbMetric: 38.5328

Epoch 65: val_loss improved from 38.75787 to 38.53279, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 85s - loss: 38.5758 - MinusLogProbMetric: 38.5758 - val_loss: 38.5328 - val_MinusLogProbMetric: 38.5328 - lr: 1.2346e-05 - 85s/epoch - 433ms/step
Epoch 66/1000
2023-09-20 23:51:18.017 
Epoch 66/1000 
	 loss: 46.8611, MinusLogProbMetric: 46.8611, val_loss: 47.8024, val_MinusLogProbMetric: 47.8024

Epoch 66: val_loss did not improve from 38.53279
196/196 - 83s - loss: 46.8611 - MinusLogProbMetric: 46.8611 - val_loss: 47.8024 - val_MinusLogProbMetric: 47.8024 - lr: 1.2346e-05 - 83s/epoch - 421ms/step
Epoch 67/1000
2023-09-20 23:52:40.195 
Epoch 67/1000 
	 loss: 42.2727, MinusLogProbMetric: 42.2727, val_loss: 39.7308, val_MinusLogProbMetric: 39.7308

Epoch 67: val_loss did not improve from 38.53279
196/196 - 82s - loss: 42.2727 - MinusLogProbMetric: 42.2727 - val_loss: 39.7308 - val_MinusLogProbMetric: 39.7308 - lr: 1.2346e-05 - 82s/epoch - 419ms/step
Epoch 68/1000
2023-09-20 23:54:01.731 
Epoch 68/1000 
	 loss: 39.0837, MinusLogProbMetric: 39.0837, val_loss: 38.6311, val_MinusLogProbMetric: 38.6311

Epoch 68: val_loss did not improve from 38.53279
196/196 - 82s - loss: 39.0837 - MinusLogProbMetric: 39.0837 - val_loss: 38.6311 - val_MinusLogProbMetric: 38.6311 - lr: 1.2346e-05 - 82s/epoch - 416ms/step
Epoch 69/1000
2023-09-20 23:55:23.937 
Epoch 69/1000 
	 loss: 38.3108, MinusLogProbMetric: 38.3108, val_loss: 38.0476, val_MinusLogProbMetric: 38.0476

Epoch 69: val_loss improved from 38.53279 to 38.04765, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 38.3108 - MinusLogProbMetric: 38.3108 - val_loss: 38.0476 - val_MinusLogProbMetric: 38.0476 - lr: 1.2346e-05 - 84s/epoch - 427ms/step
Epoch 70/1000
2023-09-20 23:56:47.554 
Epoch 70/1000 
	 loss: 37.9548, MinusLogProbMetric: 37.9548, val_loss: 38.3362, val_MinusLogProbMetric: 38.3362

Epoch 70: val_loss did not improve from 38.04765
196/196 - 82s - loss: 37.9548 - MinusLogProbMetric: 37.9548 - val_loss: 38.3362 - val_MinusLogProbMetric: 38.3362 - lr: 1.2346e-05 - 82s/epoch - 419ms/step
Epoch 71/1000
2023-09-20 23:58:11.071 
Epoch 71/1000 
	 loss: 37.7494, MinusLogProbMetric: 37.7494, val_loss: 37.5026, val_MinusLogProbMetric: 37.5026

Epoch 71: val_loss improved from 38.04765 to 37.50256, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 85s - loss: 37.7494 - MinusLogProbMetric: 37.7494 - val_loss: 37.5026 - val_MinusLogProbMetric: 37.5026 - lr: 1.2346e-05 - 85s/epoch - 433ms/step
Epoch 72/1000
2023-09-20 23:59:34.445 
Epoch 72/1000 
	 loss: 37.3709, MinusLogProbMetric: 37.3709, val_loss: 37.3709, val_MinusLogProbMetric: 37.3709

Epoch 72: val_loss improved from 37.50256 to 37.37090, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 37.3709 - MinusLogProbMetric: 37.3709 - val_loss: 37.3709 - val_MinusLogProbMetric: 37.3709 - lr: 1.2346e-05 - 83s/epoch - 425ms/step
Epoch 73/1000
2023-09-21 00:00:57.301 
Epoch 73/1000 
	 loss: 37.2553, MinusLogProbMetric: 37.2553, val_loss: 37.1367, val_MinusLogProbMetric: 37.1367

Epoch 73: val_loss improved from 37.37090 to 37.13670, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 37.2553 - MinusLogProbMetric: 37.2553 - val_loss: 37.1367 - val_MinusLogProbMetric: 37.1367 - lr: 1.2346e-05 - 83s/epoch - 424ms/step
Epoch 74/1000
2023-09-21 00:02:20.732 
Epoch 74/1000 
	 loss: 36.9881, MinusLogProbMetric: 36.9881, val_loss: 36.9407, val_MinusLogProbMetric: 36.9407

Epoch 74: val_loss improved from 37.13670 to 36.94071, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 36.9881 - MinusLogProbMetric: 36.9881 - val_loss: 36.9407 - val_MinusLogProbMetric: 36.9407 - lr: 1.2346e-05 - 83s/epoch - 425ms/step
Epoch 75/1000
2023-09-21 00:03:42.915 
Epoch 75/1000 
	 loss: 36.8097, MinusLogProbMetric: 36.8097, val_loss: 36.9487, val_MinusLogProbMetric: 36.9487

Epoch 75: val_loss did not improve from 36.94071
196/196 - 81s - loss: 36.8097 - MinusLogProbMetric: 36.8097 - val_loss: 36.9487 - val_MinusLogProbMetric: 36.9487 - lr: 1.2346e-05 - 81s/epoch - 412ms/step
Epoch 76/1000
2023-09-21 00:05:05.704 
Epoch 76/1000 
	 loss: 36.6838, MinusLogProbMetric: 36.6838, val_loss: 36.6509, val_MinusLogProbMetric: 36.6509

Epoch 76: val_loss improved from 36.94071 to 36.65090, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 85s - loss: 36.6838 - MinusLogProbMetric: 36.6838 - val_loss: 36.6509 - val_MinusLogProbMetric: 36.6509 - lr: 1.2346e-05 - 85s/epoch - 432ms/step
Epoch 77/1000
2023-09-21 00:06:29.849 
Epoch 77/1000 
	 loss: 36.4751, MinusLogProbMetric: 36.4751, val_loss: 36.3980, val_MinusLogProbMetric: 36.3980

Epoch 77: val_loss improved from 36.65090 to 36.39798, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 36.4751 - MinusLogProbMetric: 36.4751 - val_loss: 36.3980 - val_MinusLogProbMetric: 36.3980 - lr: 1.2346e-05 - 84s/epoch - 428ms/step
Epoch 78/1000
2023-09-21 00:07:53.861 
Epoch 78/1000 
	 loss: 36.3291, MinusLogProbMetric: 36.3291, val_loss: 36.2950, val_MinusLogProbMetric: 36.2950

Epoch 78: val_loss improved from 36.39798 to 36.29501, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 36.3291 - MinusLogProbMetric: 36.3291 - val_loss: 36.2950 - val_MinusLogProbMetric: 36.2950 - lr: 1.2346e-05 - 84s/epoch - 427ms/step
Epoch 79/1000
2023-09-21 00:09:17.291 
Epoch 79/1000 
	 loss: 36.1555, MinusLogProbMetric: 36.1555, val_loss: 36.1323, val_MinusLogProbMetric: 36.1323

Epoch 79: val_loss improved from 36.29501 to 36.13226, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 36.1555 - MinusLogProbMetric: 36.1555 - val_loss: 36.1323 - val_MinusLogProbMetric: 36.1323 - lr: 1.2346e-05 - 84s/epoch - 426ms/step
Epoch 80/1000
2023-09-21 00:10:40.091 
Epoch 80/1000 
	 loss: 36.0088, MinusLogProbMetric: 36.0088, val_loss: 36.0184, val_MinusLogProbMetric: 36.0184

Epoch 80: val_loss improved from 36.13226 to 36.01839, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 36.0088 - MinusLogProbMetric: 36.0088 - val_loss: 36.0184 - val_MinusLogProbMetric: 36.0184 - lr: 1.2346e-05 - 83s/epoch - 423ms/step
Epoch 81/1000
2023-09-21 00:12:03.685 
Epoch 81/1000 
	 loss: 36.0529, MinusLogProbMetric: 36.0529, val_loss: 52.6542, val_MinusLogProbMetric: 52.6542

Epoch 81: val_loss did not improve from 36.01839
196/196 - 82s - loss: 36.0529 - MinusLogProbMetric: 36.0529 - val_loss: 52.6542 - val_MinusLogProbMetric: 52.6542 - lr: 1.2346e-05 - 82s/epoch - 418ms/step
Epoch 82/1000
2023-09-21 00:13:25.548 
Epoch 82/1000 
	 loss: 38.1152, MinusLogProbMetric: 38.1152, val_loss: 35.9126, val_MinusLogProbMetric: 35.9126

Epoch 82: val_loss improved from 36.01839 to 35.91262, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 38.1152 - MinusLogProbMetric: 38.1152 - val_loss: 35.9126 - val_MinusLogProbMetric: 35.9126 - lr: 1.2346e-05 - 83s/epoch - 424ms/step
Epoch 83/1000
2023-09-21 00:14:49.414 
Epoch 83/1000 
	 loss: 35.7184, MinusLogProbMetric: 35.7184, val_loss: 35.6610, val_MinusLogProbMetric: 35.6610

Epoch 83: val_loss improved from 35.91262 to 35.66100, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 35.7184 - MinusLogProbMetric: 35.7184 - val_loss: 35.6610 - val_MinusLogProbMetric: 35.6610 - lr: 1.2346e-05 - 84s/epoch - 431ms/step
Epoch 84/1000
2023-09-21 00:16:12.471 
Epoch 84/1000 
	 loss: 35.5750, MinusLogProbMetric: 35.5750, val_loss: 35.9704, val_MinusLogProbMetric: 35.9704

Epoch 84: val_loss did not improve from 35.66100
196/196 - 81s - loss: 35.5750 - MinusLogProbMetric: 35.5750 - val_loss: 35.9704 - val_MinusLogProbMetric: 35.9704 - lr: 1.2346e-05 - 81s/epoch - 414ms/step
Epoch 85/1000
2023-09-21 00:17:33.546 
Epoch 85/1000 
	 loss: 35.4185, MinusLogProbMetric: 35.4185, val_loss: 35.4197, val_MinusLogProbMetric: 35.4197

Epoch 85: val_loss improved from 35.66100 to 35.41971, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 35.4185 - MinusLogProbMetric: 35.4185 - val_loss: 35.4197 - val_MinusLogProbMetric: 35.4197 - lr: 1.2346e-05 - 82s/epoch - 421ms/step
Epoch 86/1000
2023-09-21 00:18:56.677 
Epoch 86/1000 
	 loss: 35.2893, MinusLogProbMetric: 35.2893, val_loss: 35.2755, val_MinusLogProbMetric: 35.2755

Epoch 86: val_loss improved from 35.41971 to 35.27549, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 35.2893 - MinusLogProbMetric: 35.2893 - val_loss: 35.2755 - val_MinusLogProbMetric: 35.2755 - lr: 1.2346e-05 - 83s/epoch - 425ms/step
Epoch 87/1000
2023-09-21 00:20:12.480 
Epoch 87/1000 
	 loss: 35.4211, MinusLogProbMetric: 35.4211, val_loss: 35.1644, val_MinusLogProbMetric: 35.1644

Epoch 87: val_loss improved from 35.27549 to 35.16437, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 75s - loss: 35.4211 - MinusLogProbMetric: 35.4211 - val_loss: 35.1644 - val_MinusLogProbMetric: 35.1644 - lr: 1.2346e-05 - 75s/epoch - 385ms/step
Epoch 88/1000
2023-09-21 00:21:19.539 
Epoch 88/1000 
	 loss: 35.0322, MinusLogProbMetric: 35.0322, val_loss: 35.0291, val_MinusLogProbMetric: 35.0291

Epoch 88: val_loss improved from 35.16437 to 35.02913, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 67s - loss: 35.0322 - MinusLogProbMetric: 35.0322 - val_loss: 35.0291 - val_MinusLogProbMetric: 35.0291 - lr: 1.2346e-05 - 67s/epoch - 342ms/step
Epoch 89/1000
2023-09-21 00:22:35.882 
Epoch 89/1000 
	 loss: 35.0289, MinusLogProbMetric: 35.0289, val_loss: 34.8771, val_MinusLogProbMetric: 34.8771

Epoch 89: val_loss improved from 35.02913 to 34.87715, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 77s - loss: 35.0289 - MinusLogProbMetric: 35.0289 - val_loss: 34.8771 - val_MinusLogProbMetric: 34.8771 - lr: 1.2346e-05 - 77s/epoch - 391ms/step
Epoch 90/1000
2023-09-21 00:23:47.480 
Epoch 90/1000 
	 loss: 34.8531, MinusLogProbMetric: 34.8531, val_loss: 34.8802, val_MinusLogProbMetric: 34.8802

Epoch 90: val_loss did not improve from 34.87715
196/196 - 70s - loss: 34.8531 - MinusLogProbMetric: 34.8531 - val_loss: 34.8802 - val_MinusLogProbMetric: 34.8802 - lr: 1.2346e-05 - 70s/epoch - 358ms/step
Epoch 91/1000
2023-09-21 00:24:55.141 
Epoch 91/1000 
	 loss: 34.7587, MinusLogProbMetric: 34.7587, val_loss: 35.0808, val_MinusLogProbMetric: 35.0808

Epoch 91: val_loss did not improve from 34.87715
196/196 - 68s - loss: 34.7587 - MinusLogProbMetric: 34.7587 - val_loss: 35.0808 - val_MinusLogProbMetric: 35.0808 - lr: 1.2346e-05 - 68s/epoch - 345ms/step
Epoch 92/1000
2023-09-21 00:26:14.571 
Epoch 92/1000 
	 loss: 34.6166, MinusLogProbMetric: 34.6166, val_loss: 34.6396, val_MinusLogProbMetric: 34.6396

Epoch 92: val_loss improved from 34.87715 to 34.63963, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 34.6166 - MinusLogProbMetric: 34.6166 - val_loss: 34.6396 - val_MinusLogProbMetric: 34.6396 - lr: 1.2346e-05 - 81s/epoch - 412ms/step
Epoch 93/1000
2023-09-21 00:27:35.586 
Epoch 93/1000 
	 loss: 34.5126, MinusLogProbMetric: 34.5126, val_loss: 34.5068, val_MinusLogProbMetric: 34.5068

Epoch 93: val_loss improved from 34.63963 to 34.50684, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 34.5126 - MinusLogProbMetric: 34.5126 - val_loss: 34.5068 - val_MinusLogProbMetric: 34.5068 - lr: 1.2346e-05 - 81s/epoch - 414ms/step
Epoch 94/1000
2023-09-21 00:28:58.769 
Epoch 94/1000 
	 loss: 34.3637, MinusLogProbMetric: 34.3637, val_loss: 34.3487, val_MinusLogProbMetric: 34.3487

Epoch 94: val_loss improved from 34.50684 to 34.34869, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 34.3637 - MinusLogProbMetric: 34.3637 - val_loss: 34.3487 - val_MinusLogProbMetric: 34.3487 - lr: 1.2346e-05 - 83s/epoch - 424ms/step
Epoch 95/1000
2023-09-21 00:30:22.194 
Epoch 95/1000 
	 loss: 34.3905, MinusLogProbMetric: 34.3905, val_loss: 34.2857, val_MinusLogProbMetric: 34.2857

Epoch 95: val_loss improved from 34.34869 to 34.28574, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 34.3905 - MinusLogProbMetric: 34.3905 - val_loss: 34.2857 - val_MinusLogProbMetric: 34.2857 - lr: 1.2346e-05 - 84s/epoch - 427ms/step
Epoch 96/1000
2023-09-21 00:31:44.509 
Epoch 96/1000 
	 loss: 34.2759, MinusLogProbMetric: 34.2759, val_loss: 34.2102, val_MinusLogProbMetric: 34.2102

Epoch 96: val_loss improved from 34.28574 to 34.21020, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 34.2759 - MinusLogProbMetric: 34.2759 - val_loss: 34.2102 - val_MinusLogProbMetric: 34.2102 - lr: 1.2346e-05 - 82s/epoch - 419ms/step
Epoch 97/1000
2023-09-21 00:33:07.240 
Epoch 97/1000 
	 loss: 34.1909, MinusLogProbMetric: 34.1909, val_loss: 34.2955, val_MinusLogProbMetric: 34.2955

Epoch 97: val_loss did not improve from 34.21020
196/196 - 81s - loss: 34.1909 - MinusLogProbMetric: 34.1909 - val_loss: 34.2955 - val_MinusLogProbMetric: 34.2955 - lr: 1.2346e-05 - 81s/epoch - 415ms/step
Epoch 98/1000
2023-09-21 00:34:29.534 
Epoch 98/1000 
	 loss: 34.0265, MinusLogProbMetric: 34.0265, val_loss: 33.9741, val_MinusLogProbMetric: 33.9741

Epoch 98: val_loss improved from 34.21020 to 33.97413, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 34.0265 - MinusLogProbMetric: 34.0265 - val_loss: 33.9741 - val_MinusLogProbMetric: 33.9741 - lr: 1.2346e-05 - 84s/epoch - 429ms/step
Epoch 99/1000
2023-09-21 00:35:52.449 
Epoch 99/1000 
	 loss: 33.9119, MinusLogProbMetric: 33.9119, val_loss: 33.8846, val_MinusLogProbMetric: 33.8846

Epoch 99: val_loss improved from 33.97413 to 33.88461, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 33.9119 - MinusLogProbMetric: 33.9119 - val_loss: 33.8846 - val_MinusLogProbMetric: 33.8846 - lr: 1.2346e-05 - 83s/epoch - 424ms/step
Epoch 100/1000
2023-09-21 00:37:15.216 
Epoch 100/1000 
	 loss: 33.7972, MinusLogProbMetric: 33.7972, val_loss: 33.8295, val_MinusLogProbMetric: 33.8295

Epoch 100: val_loss improved from 33.88461 to 33.82948, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 33.7972 - MinusLogProbMetric: 33.7972 - val_loss: 33.8295 - val_MinusLogProbMetric: 33.8295 - lr: 1.2346e-05 - 83s/epoch - 421ms/step
Epoch 101/1000
2023-09-21 00:38:38.427 
Epoch 101/1000 
	 loss: 33.6923, MinusLogProbMetric: 33.6923, val_loss: 33.6721, val_MinusLogProbMetric: 33.6721

Epoch 101: val_loss improved from 33.82948 to 33.67208, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 33.6923 - MinusLogProbMetric: 33.6923 - val_loss: 33.6721 - val_MinusLogProbMetric: 33.6721 - lr: 1.2346e-05 - 83s/epoch - 424ms/step
Epoch 102/1000
2023-09-21 00:40:02.059 
Epoch 102/1000 
	 loss: 33.5838, MinusLogProbMetric: 33.5838, val_loss: 33.7857, val_MinusLogProbMetric: 33.7857

Epoch 102: val_loss did not improve from 33.67208
196/196 - 82s - loss: 33.5838 - MinusLogProbMetric: 33.5838 - val_loss: 33.7857 - val_MinusLogProbMetric: 33.7857 - lr: 1.2346e-05 - 82s/epoch - 419ms/step
Epoch 103/1000
2023-09-21 00:41:23.735 
Epoch 103/1000 
	 loss: 33.9582, MinusLogProbMetric: 33.9582, val_loss: 33.5921, val_MinusLogProbMetric: 33.5921

Epoch 103: val_loss improved from 33.67208 to 33.59211, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 33.9582 - MinusLogProbMetric: 33.9582 - val_loss: 33.5921 - val_MinusLogProbMetric: 33.5921 - lr: 1.2346e-05 - 84s/epoch - 426ms/step
Epoch 104/1000
2023-09-21 00:42:47.587 
Epoch 104/1000 
	 loss: 33.5023, MinusLogProbMetric: 33.5023, val_loss: 33.4529, val_MinusLogProbMetric: 33.4529

Epoch 104: val_loss improved from 33.59211 to 33.45285, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 33.5023 - MinusLogProbMetric: 33.5023 - val_loss: 33.4529 - val_MinusLogProbMetric: 33.4529 - lr: 1.2346e-05 - 83s/epoch - 426ms/step
Epoch 105/1000
2023-09-21 00:44:10.473 
Epoch 105/1000 
	 loss: 33.2673, MinusLogProbMetric: 33.2673, val_loss: 33.1799, val_MinusLogProbMetric: 33.1799

Epoch 105: val_loss improved from 33.45285 to 33.17989, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 33.2673 - MinusLogProbMetric: 33.2673 - val_loss: 33.1799 - val_MinusLogProbMetric: 33.1799 - lr: 1.2346e-05 - 83s/epoch - 422ms/step
Epoch 106/1000
2023-09-21 00:45:33.593 
Epoch 106/1000 
	 loss: 33.2086, MinusLogProbMetric: 33.2086, val_loss: 33.0452, val_MinusLogProbMetric: 33.0452

Epoch 106: val_loss improved from 33.17989 to 33.04522, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 33.2086 - MinusLogProbMetric: 33.2086 - val_loss: 33.0452 - val_MinusLogProbMetric: 33.0452 - lr: 1.2346e-05 - 83s/epoch - 425ms/step
Epoch 107/1000
2023-09-21 00:46:55.476 
Epoch 107/1000 
	 loss: 32.9583, MinusLogProbMetric: 32.9583, val_loss: 33.0242, val_MinusLogProbMetric: 33.0242

Epoch 107: val_loss improved from 33.04522 to 33.02422, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 32.9583 - MinusLogProbMetric: 32.9583 - val_loss: 33.0242 - val_MinusLogProbMetric: 33.0242 - lr: 1.2346e-05 - 82s/epoch - 419ms/step
Epoch 108/1000
2023-09-21 00:48:19.165 
Epoch 108/1000 
	 loss: 33.0292, MinusLogProbMetric: 33.0292, val_loss: 32.9642, val_MinusLogProbMetric: 32.9642

Epoch 108: val_loss improved from 33.02422 to 32.96423, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 33.0292 - MinusLogProbMetric: 33.0292 - val_loss: 32.9642 - val_MinusLogProbMetric: 32.9642 - lr: 1.2346e-05 - 84s/epoch - 427ms/step
Epoch 109/1000
2023-09-21 00:49:42.551 
Epoch 109/1000 
	 loss: 32.8206, MinusLogProbMetric: 32.8206, val_loss: 32.8609, val_MinusLogProbMetric: 32.8609

Epoch 109: val_loss improved from 32.96423 to 32.86092, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 32.8206 - MinusLogProbMetric: 32.8206 - val_loss: 32.8609 - val_MinusLogProbMetric: 32.8609 - lr: 1.2346e-05 - 83s/epoch - 423ms/step
Epoch 110/1000
2023-09-21 00:51:03.793 
Epoch 110/1000 
	 loss: 32.7432, MinusLogProbMetric: 32.7432, val_loss: 32.7295, val_MinusLogProbMetric: 32.7295

Epoch 110: val_loss improved from 32.86092 to 32.72946, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 32.7432 - MinusLogProbMetric: 32.7432 - val_loss: 32.7295 - val_MinusLogProbMetric: 32.7295 - lr: 1.2346e-05 - 81s/epoch - 415ms/step
Epoch 111/1000
2023-09-21 00:52:27.755 
Epoch 111/1000 
	 loss: 32.6083, MinusLogProbMetric: 32.6083, val_loss: 32.7283, val_MinusLogProbMetric: 32.7283

Epoch 111: val_loss improved from 32.72946 to 32.72829, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 32.6083 - MinusLogProbMetric: 32.6083 - val_loss: 32.7283 - val_MinusLogProbMetric: 32.7283 - lr: 1.2346e-05 - 84s/epoch - 427ms/step
Epoch 112/1000
2023-09-21 00:53:48.963 
Epoch 112/1000 
	 loss: 32.5478, MinusLogProbMetric: 32.5478, val_loss: 32.5375, val_MinusLogProbMetric: 32.5375

Epoch 112: val_loss improved from 32.72829 to 32.53749, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 32.5478 - MinusLogProbMetric: 32.5478 - val_loss: 32.5375 - val_MinusLogProbMetric: 32.5375 - lr: 1.2346e-05 - 82s/epoch - 417ms/step
Epoch 113/1000
2023-09-21 00:55:10.850 
Epoch 113/1000 
	 loss: 32.4185, MinusLogProbMetric: 32.4185, val_loss: 32.5999, val_MinusLogProbMetric: 32.5999

Epoch 113: val_loss did not improve from 32.53749
196/196 - 80s - loss: 32.4185 - MinusLogProbMetric: 32.4185 - val_loss: 32.5999 - val_MinusLogProbMetric: 32.5999 - lr: 1.2346e-05 - 80s/epoch - 409ms/step
Epoch 114/1000
2023-09-21 00:56:30.303 
Epoch 114/1000 
	 loss: 32.3464, MinusLogProbMetric: 32.3464, val_loss: 32.4623, val_MinusLogProbMetric: 32.4623

Epoch 114: val_loss improved from 32.53749 to 32.46231, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 32.3464 - MinusLogProbMetric: 32.3464 - val_loss: 32.4623 - val_MinusLogProbMetric: 32.4623 - lr: 1.2346e-05 - 81s/epoch - 413ms/step
Epoch 115/1000
2023-09-21 00:57:54.136 
Epoch 115/1000 
	 loss: 32.3028, MinusLogProbMetric: 32.3028, val_loss: 32.4196, val_MinusLogProbMetric: 32.4196

Epoch 115: val_loss improved from 32.46231 to 32.41956, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 32.3028 - MinusLogProbMetric: 32.3028 - val_loss: 32.4196 - val_MinusLogProbMetric: 32.4196 - lr: 1.2346e-05 - 84s/epoch - 429ms/step
Epoch 116/1000
2023-09-21 00:59:16.758 
Epoch 116/1000 
	 loss: 32.2145, MinusLogProbMetric: 32.2145, val_loss: 32.2545, val_MinusLogProbMetric: 32.2545

Epoch 116: val_loss improved from 32.41956 to 32.25455, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 32.2145 - MinusLogProbMetric: 32.2145 - val_loss: 32.2545 - val_MinusLogProbMetric: 32.2545 - lr: 1.2346e-05 - 82s/epoch - 420ms/step
Epoch 117/1000
2023-09-21 01:00:40.041 
Epoch 117/1000 
	 loss: 32.1352, MinusLogProbMetric: 32.1352, val_loss: 32.1598, val_MinusLogProbMetric: 32.1598

Epoch 117: val_loss improved from 32.25455 to 32.15983, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 32.1352 - MinusLogProbMetric: 32.1352 - val_loss: 32.1598 - val_MinusLogProbMetric: 32.1598 - lr: 1.2346e-05 - 84s/epoch - 426ms/step
Epoch 118/1000
2023-09-21 01:02:04.260 
Epoch 118/1000 
	 loss: 32.0975, MinusLogProbMetric: 32.0975, val_loss: 32.0393, val_MinusLogProbMetric: 32.0393

Epoch 118: val_loss improved from 32.15983 to 32.03934, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 32.0975 - MinusLogProbMetric: 32.0975 - val_loss: 32.0393 - val_MinusLogProbMetric: 32.0393 - lr: 1.2346e-05 - 84s/epoch - 429ms/step
Epoch 119/1000
2023-09-21 01:03:28.549 
Epoch 119/1000 
	 loss: 31.9487, MinusLogProbMetric: 31.9487, val_loss: 32.1577, val_MinusLogProbMetric: 32.1577

Epoch 119: val_loss did not improve from 32.03934
196/196 - 83s - loss: 31.9487 - MinusLogProbMetric: 31.9487 - val_loss: 32.1577 - val_MinusLogProbMetric: 32.1577 - lr: 1.2346e-05 - 83s/epoch - 422ms/step
Epoch 120/1000
2023-09-21 01:04:50.468 
Epoch 120/1000 
	 loss: 31.8797, MinusLogProbMetric: 31.8797, val_loss: 31.9427, val_MinusLogProbMetric: 31.9427

Epoch 120: val_loss improved from 32.03934 to 31.94271, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 31.8797 - MinusLogProbMetric: 31.8797 - val_loss: 31.9427 - val_MinusLogProbMetric: 31.9427 - lr: 1.2346e-05 - 84s/epoch - 428ms/step
Epoch 121/1000
2023-09-21 01:06:13.529 
Epoch 121/1000 
	 loss: 31.8868, MinusLogProbMetric: 31.8868, val_loss: 32.1593, val_MinusLogProbMetric: 32.1593

Epoch 121: val_loss did not improve from 31.94271
196/196 - 81s - loss: 31.8868 - MinusLogProbMetric: 31.8868 - val_loss: 32.1593 - val_MinusLogProbMetric: 32.1593 - lr: 1.2346e-05 - 81s/epoch - 414ms/step
Epoch 122/1000
2023-09-21 01:07:35.419 
Epoch 122/1000 
	 loss: 31.7844, MinusLogProbMetric: 31.7844, val_loss: 31.7911, val_MinusLogProbMetric: 31.7911

Epoch 122: val_loss improved from 31.94271 to 31.79113, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 31.7844 - MinusLogProbMetric: 31.7844 - val_loss: 31.7911 - val_MinusLogProbMetric: 31.7911 - lr: 1.2346e-05 - 84s/epoch - 426ms/step
Epoch 123/1000
2023-09-21 01:08:59.686 
Epoch 123/1000 
	 loss: 31.6792, MinusLogProbMetric: 31.6792, val_loss: 31.7224, val_MinusLogProbMetric: 31.7224

Epoch 123: val_loss improved from 31.79113 to 31.72241, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 31.6792 - MinusLogProbMetric: 31.6792 - val_loss: 31.7224 - val_MinusLogProbMetric: 31.7224 - lr: 1.2346e-05 - 84s/epoch - 430ms/step
Epoch 124/1000
2023-09-21 01:10:20.337 
Epoch 124/1000 
	 loss: 31.6013, MinusLogProbMetric: 31.6013, val_loss: 31.6651, val_MinusLogProbMetric: 31.6651

Epoch 124: val_loss improved from 31.72241 to 31.66513, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 31.6013 - MinusLogProbMetric: 31.6013 - val_loss: 31.6651 - val_MinusLogProbMetric: 31.6651 - lr: 1.2346e-05 - 80s/epoch - 410ms/step
Epoch 125/1000
2023-09-21 01:11:42.425 
Epoch 125/1000 
	 loss: 31.5364, MinusLogProbMetric: 31.5364, val_loss: 31.5467, val_MinusLogProbMetric: 31.5467

Epoch 125: val_loss improved from 31.66513 to 31.54671, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 31.5364 - MinusLogProbMetric: 31.5364 - val_loss: 31.5467 - val_MinusLogProbMetric: 31.5467 - lr: 1.2346e-05 - 82s/epoch - 420ms/step
Epoch 126/1000
2023-09-21 01:13:06.844 
Epoch 126/1000 
	 loss: 31.4729, MinusLogProbMetric: 31.4729, val_loss: 31.4770, val_MinusLogProbMetric: 31.4770

Epoch 126: val_loss improved from 31.54671 to 31.47695, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 31.4729 - MinusLogProbMetric: 31.4729 - val_loss: 31.4770 - val_MinusLogProbMetric: 31.4770 - lr: 1.2346e-05 - 84s/epoch - 431ms/step
Epoch 127/1000
2023-09-21 01:14:29.762 
Epoch 127/1000 
	 loss: 31.3715, MinusLogProbMetric: 31.3715, val_loss: 31.4491, val_MinusLogProbMetric: 31.4491

Epoch 127: val_loss improved from 31.47695 to 31.44913, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 31.3715 - MinusLogProbMetric: 31.3715 - val_loss: 31.4491 - val_MinusLogProbMetric: 31.4491 - lr: 1.2346e-05 - 83s/epoch - 423ms/step
Epoch 128/1000
2023-09-21 01:15:53.391 
Epoch 128/1000 
	 loss: 31.3313, MinusLogProbMetric: 31.3313, val_loss: 31.4382, val_MinusLogProbMetric: 31.4382

Epoch 128: val_loss improved from 31.44913 to 31.43824, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 31.3313 - MinusLogProbMetric: 31.3313 - val_loss: 31.4382 - val_MinusLogProbMetric: 31.4382 - lr: 1.2346e-05 - 84s/epoch - 428ms/step
Epoch 129/1000
2023-09-21 01:17:14.707 
Epoch 129/1000 
	 loss: 31.3212, MinusLogProbMetric: 31.3212, val_loss: 31.3344, val_MinusLogProbMetric: 31.3344

Epoch 129: val_loss improved from 31.43824 to 31.33437, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 31.3212 - MinusLogProbMetric: 31.3212 - val_loss: 31.3344 - val_MinusLogProbMetric: 31.3344 - lr: 1.2346e-05 - 81s/epoch - 414ms/step
Epoch 130/1000
2023-09-21 01:18:38.845 
Epoch 130/1000 
	 loss: 31.2115, MinusLogProbMetric: 31.2115, val_loss: 31.2016, val_MinusLogProbMetric: 31.2016

Epoch 130: val_loss improved from 31.33437 to 31.20161, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 31.2115 - MinusLogProbMetric: 31.2115 - val_loss: 31.2016 - val_MinusLogProbMetric: 31.2016 - lr: 1.2346e-05 - 84s/epoch - 428ms/step
Epoch 131/1000
2023-09-21 01:20:03.003 
Epoch 131/1000 
	 loss: 31.2552, MinusLogProbMetric: 31.2552, val_loss: 31.2959, val_MinusLogProbMetric: 31.2959

Epoch 131: val_loss did not improve from 31.20161
196/196 - 83s - loss: 31.2552 - MinusLogProbMetric: 31.2552 - val_loss: 31.2959 - val_MinusLogProbMetric: 31.2959 - lr: 1.2346e-05 - 83s/epoch - 421ms/step
Epoch 132/1000
2023-09-21 01:21:24.269 
Epoch 132/1000 
	 loss: 31.2277, MinusLogProbMetric: 31.2277, val_loss: 31.7739, val_MinusLogProbMetric: 31.7739

Epoch 132: val_loss did not improve from 31.20161
196/196 - 81s - loss: 31.2277 - MinusLogProbMetric: 31.2277 - val_loss: 31.7739 - val_MinusLogProbMetric: 31.7739 - lr: 1.2346e-05 - 81s/epoch - 415ms/step
Epoch 133/1000
2023-09-21 01:22:46.264 
Epoch 133/1000 
	 loss: 31.6203, MinusLogProbMetric: 31.6203, val_loss: 31.2850, val_MinusLogProbMetric: 31.2850

Epoch 133: val_loss did not improve from 31.20161
196/196 - 82s - loss: 31.6203 - MinusLogProbMetric: 31.6203 - val_loss: 31.2850 - val_MinusLogProbMetric: 31.2850 - lr: 1.2346e-05 - 82s/epoch - 418ms/step
Epoch 134/1000
2023-09-21 01:24:08.041 
Epoch 134/1000 
	 loss: 30.9732, MinusLogProbMetric: 30.9732, val_loss: 31.0457, val_MinusLogProbMetric: 31.0457

Epoch 134: val_loss improved from 31.20161 to 31.04571, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 30.9732 - MinusLogProbMetric: 30.9732 - val_loss: 31.0457 - val_MinusLogProbMetric: 31.0457 - lr: 1.2346e-05 - 83s/epoch - 426ms/step
Epoch 135/1000
2023-09-21 01:25:30.109 
Epoch 135/1000 
	 loss: 30.9110, MinusLogProbMetric: 30.9110, val_loss: 30.9642, val_MinusLogProbMetric: 30.9642

Epoch 135: val_loss improved from 31.04571 to 30.96424, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 30.9110 - MinusLogProbMetric: 30.9110 - val_loss: 30.9642 - val_MinusLogProbMetric: 30.9642 - lr: 1.2346e-05 - 82s/epoch - 416ms/step
Epoch 136/1000
2023-09-21 01:26:52.710 
Epoch 136/1000 
	 loss: 30.8313, MinusLogProbMetric: 30.8313, val_loss: 30.9953, val_MinusLogProbMetric: 30.9953

Epoch 136: val_loss did not improve from 30.96424
196/196 - 81s - loss: 30.8313 - MinusLogProbMetric: 30.8313 - val_loss: 30.9953 - val_MinusLogProbMetric: 30.9953 - lr: 1.2346e-05 - 81s/epoch - 415ms/step
Epoch 137/1000
2023-09-21 01:28:14.401 
Epoch 137/1000 
	 loss: 30.8975, MinusLogProbMetric: 30.8975, val_loss: 30.8249, val_MinusLogProbMetric: 30.8249

Epoch 137: val_loss improved from 30.96424 to 30.82491, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 30.8975 - MinusLogProbMetric: 30.8975 - val_loss: 30.8249 - val_MinusLogProbMetric: 30.8249 - lr: 1.2346e-05 - 83s/epoch - 425ms/step
Epoch 138/1000
2023-09-21 01:29:38.352 
Epoch 138/1000 
	 loss: 30.7194, MinusLogProbMetric: 30.7194, val_loss: 30.8435, val_MinusLogProbMetric: 30.8435

Epoch 138: val_loss did not improve from 30.82491
196/196 - 82s - loss: 30.7194 - MinusLogProbMetric: 30.7194 - val_loss: 30.8435 - val_MinusLogProbMetric: 30.8435 - lr: 1.2346e-05 - 82s/epoch - 420ms/step
Epoch 139/1000
2023-09-21 01:31:00.506 
Epoch 139/1000 
	 loss: 30.6926, MinusLogProbMetric: 30.6926, val_loss: 30.7400, val_MinusLogProbMetric: 30.7400

Epoch 139: val_loss improved from 30.82491 to 30.74002, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 30.6926 - MinusLogProbMetric: 30.6926 - val_loss: 30.7400 - val_MinusLogProbMetric: 30.7400 - lr: 1.2346e-05 - 84s/epoch - 428ms/step
Epoch 140/1000
2023-09-21 01:32:17.008 
Epoch 140/1000 
	 loss: 30.6427, MinusLogProbMetric: 30.6427, val_loss: 30.6420, val_MinusLogProbMetric: 30.6420

Epoch 140: val_loss improved from 30.74002 to 30.64199, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 76s - loss: 30.6427 - MinusLogProbMetric: 30.6427 - val_loss: 30.6420 - val_MinusLogProbMetric: 30.6420 - lr: 1.2346e-05 - 76s/epoch - 388ms/step
Epoch 141/1000
2023-09-21 01:33:34.582 
Epoch 141/1000 
	 loss: 30.5253, MinusLogProbMetric: 30.5253, val_loss: 30.6171, val_MinusLogProbMetric: 30.6171

Epoch 141: val_loss improved from 30.64199 to 30.61707, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 78s - loss: 30.5253 - MinusLogProbMetric: 30.5253 - val_loss: 30.6171 - val_MinusLogProbMetric: 30.6171 - lr: 1.2346e-05 - 78s/epoch - 397ms/step
Epoch 142/1000
2023-09-21 01:34:57.244 
Epoch 142/1000 
	 loss: 30.4873, MinusLogProbMetric: 30.4873, val_loss: 30.6259, val_MinusLogProbMetric: 30.6259

Epoch 142: val_loss did not improve from 30.61707
196/196 - 81s - loss: 30.4873 - MinusLogProbMetric: 30.4873 - val_loss: 30.6259 - val_MinusLogProbMetric: 30.6259 - lr: 1.2346e-05 - 81s/epoch - 413ms/step
Epoch 143/1000
2023-09-21 01:36:18.632 
Epoch 143/1000 
	 loss: 30.4632, MinusLogProbMetric: 30.4632, val_loss: 30.5128, val_MinusLogProbMetric: 30.5128

Epoch 143: val_loss improved from 30.61707 to 30.51282, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 83s - loss: 30.4632 - MinusLogProbMetric: 30.4632 - val_loss: 30.5128 - val_MinusLogProbMetric: 30.5128 - lr: 1.2346e-05 - 83s/epoch - 424ms/step
Epoch 144/1000
2023-09-21 01:37:40.008 
Epoch 144/1000 
	 loss: 30.3557, MinusLogProbMetric: 30.3557, val_loss: 30.3609, val_MinusLogProbMetric: 30.3609

Epoch 144: val_loss improved from 30.51282 to 30.36094, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 30.3557 - MinusLogProbMetric: 30.3557 - val_loss: 30.3609 - val_MinusLogProbMetric: 30.3609 - lr: 1.2346e-05 - 81s/epoch - 415ms/step
Epoch 145/1000
2023-09-21 01:39:00.594 
Epoch 145/1000 
	 loss: 30.4888, MinusLogProbMetric: 30.4888, val_loss: 30.4817, val_MinusLogProbMetric: 30.4817

Epoch 145: val_loss did not improve from 30.36094
196/196 - 79s - loss: 30.4888 - MinusLogProbMetric: 30.4888 - val_loss: 30.4817 - val_MinusLogProbMetric: 30.4817 - lr: 1.2346e-05 - 79s/epoch - 402ms/step
Epoch 146/1000
2023-09-21 01:40:19.736 
Epoch 146/1000 
	 loss: 30.2564, MinusLogProbMetric: 30.2564, val_loss: 30.3831, val_MinusLogProbMetric: 30.3831

Epoch 146: val_loss did not improve from 30.36094
196/196 - 79s - loss: 30.2564 - MinusLogProbMetric: 30.2564 - val_loss: 30.3831 - val_MinusLogProbMetric: 30.3831 - lr: 1.2346e-05 - 79s/epoch - 404ms/step
Epoch 147/1000
2023-09-21 01:41:38.417 
Epoch 147/1000 
	 loss: 80.1856, MinusLogProbMetric: 80.1856, val_loss: 113.4627, val_MinusLogProbMetric: 113.4627

Epoch 147: val_loss did not improve from 30.36094
196/196 - 79s - loss: 80.1856 - MinusLogProbMetric: 80.1856 - val_loss: 113.4627 - val_MinusLogProbMetric: 113.4627 - lr: 1.2346e-05 - 79s/epoch - 401ms/step
Epoch 148/1000
2023-09-21 01:42:57.453 
Epoch 148/1000 
	 loss: 94.0013, MinusLogProbMetric: 94.0013, val_loss: 71.1874, val_MinusLogProbMetric: 71.1874

Epoch 148: val_loss did not improve from 30.36094
196/196 - 79s - loss: 94.0013 - MinusLogProbMetric: 94.0013 - val_loss: 71.1874 - val_MinusLogProbMetric: 71.1874 - lr: 1.2346e-05 - 79s/epoch - 403ms/step
Epoch 149/1000
2023-09-21 01:44:17.100 
Epoch 149/1000 
	 loss: 74.9952, MinusLogProbMetric: 74.9952, val_loss: 65.7917, val_MinusLogProbMetric: 65.7917

Epoch 149: val_loss did not improve from 30.36094
196/196 - 80s - loss: 74.9952 - MinusLogProbMetric: 74.9952 - val_loss: 65.7917 - val_MinusLogProbMetric: 65.7917 - lr: 1.2346e-05 - 80s/epoch - 406ms/step
Epoch 150/1000
2023-09-21 01:45:33.771 
Epoch 150/1000 
	 loss: 62.1281, MinusLogProbMetric: 62.1281, val_loss: 58.7917, val_MinusLogProbMetric: 58.7917

Epoch 150: val_loss did not improve from 30.36094
196/196 - 77s - loss: 62.1281 - MinusLogProbMetric: 62.1281 - val_loss: 58.7917 - val_MinusLogProbMetric: 58.7917 - lr: 1.2346e-05 - 77s/epoch - 391ms/step
Epoch 151/1000
2023-09-21 01:46:52.292 
Epoch 151/1000 
	 loss: 56.8993, MinusLogProbMetric: 56.8993, val_loss: 54.5801, val_MinusLogProbMetric: 54.5801

Epoch 151: val_loss did not improve from 30.36094
196/196 - 79s - loss: 56.8993 - MinusLogProbMetric: 56.8993 - val_loss: 54.5801 - val_MinusLogProbMetric: 54.5801 - lr: 1.2346e-05 - 79s/epoch - 401ms/step
Epoch 152/1000
2023-09-21 01:48:11.198 
Epoch 152/1000 
	 loss: 53.4406, MinusLogProbMetric: 53.4406, val_loss: 51.8632, val_MinusLogProbMetric: 51.8632

Epoch 152: val_loss did not improve from 30.36094
196/196 - 79s - loss: 53.4406 - MinusLogProbMetric: 53.4406 - val_loss: 51.8632 - val_MinusLogProbMetric: 51.8632 - lr: 1.2346e-05 - 79s/epoch - 403ms/step
Epoch 153/1000
2023-09-21 01:49:28.763 
Epoch 153/1000 
	 loss: 50.2269, MinusLogProbMetric: 50.2269, val_loss: 48.4917, val_MinusLogProbMetric: 48.4917

Epoch 153: val_loss did not improve from 30.36094
196/196 - 78s - loss: 50.2269 - MinusLogProbMetric: 50.2269 - val_loss: 48.4917 - val_MinusLogProbMetric: 48.4917 - lr: 1.2346e-05 - 78s/epoch - 396ms/step
Epoch 154/1000
2023-09-21 01:50:46.708 
Epoch 154/1000 
	 loss: 47.7947, MinusLogProbMetric: 47.7947, val_loss: 47.2297, val_MinusLogProbMetric: 47.2297

Epoch 154: val_loss did not improve from 30.36094
196/196 - 78s - loss: 47.7947 - MinusLogProbMetric: 47.7947 - val_loss: 47.2297 - val_MinusLogProbMetric: 47.2297 - lr: 1.2346e-05 - 78s/epoch - 398ms/step
Epoch 155/1000
2023-09-21 01:52:04.444 
Epoch 155/1000 
	 loss: 46.5352, MinusLogProbMetric: 46.5352, val_loss: 45.4938, val_MinusLogProbMetric: 45.4938

Epoch 155: val_loss did not improve from 30.36094
196/196 - 78s - loss: 46.5352 - MinusLogProbMetric: 46.5352 - val_loss: 45.4938 - val_MinusLogProbMetric: 45.4938 - lr: 1.2346e-05 - 78s/epoch - 397ms/step
Epoch 156/1000
2023-09-21 01:53:21.635 
Epoch 156/1000 
	 loss: 44.9441, MinusLogProbMetric: 44.9441, val_loss: 44.2894, val_MinusLogProbMetric: 44.2894

Epoch 156: val_loss did not improve from 30.36094
196/196 - 77s - loss: 44.9441 - MinusLogProbMetric: 44.9441 - val_loss: 44.2894 - val_MinusLogProbMetric: 44.2894 - lr: 1.2346e-05 - 77s/epoch - 394ms/step
Epoch 157/1000
2023-09-21 01:54:39.718 
Epoch 157/1000 
	 loss: 44.0012, MinusLogProbMetric: 44.0012, val_loss: 43.2487, val_MinusLogProbMetric: 43.2487

Epoch 157: val_loss did not improve from 30.36094
196/196 - 78s - loss: 44.0012 - MinusLogProbMetric: 44.0012 - val_loss: 43.2487 - val_MinusLogProbMetric: 43.2487 - lr: 1.2346e-05 - 78s/epoch - 398ms/step
Epoch 158/1000
2023-09-21 01:55:57.465 
Epoch 158/1000 
	 loss: 42.9026, MinusLogProbMetric: 42.9026, val_loss: 42.4967, val_MinusLogProbMetric: 42.4967

Epoch 158: val_loss did not improve from 30.36094
196/196 - 78s - loss: 42.9026 - MinusLogProbMetric: 42.9026 - val_loss: 42.4967 - val_MinusLogProbMetric: 42.4967 - lr: 1.2346e-05 - 78s/epoch - 397ms/step
Epoch 159/1000
2023-09-21 01:57:14.758 
Epoch 159/1000 
	 loss: 42.0896, MinusLogProbMetric: 42.0896, val_loss: 41.5708, val_MinusLogProbMetric: 41.5708

Epoch 159: val_loss did not improve from 30.36094
196/196 - 77s - loss: 42.0896 - MinusLogProbMetric: 42.0896 - val_loss: 41.5708 - val_MinusLogProbMetric: 41.5708 - lr: 1.2346e-05 - 77s/epoch - 394ms/step
Epoch 160/1000
2023-09-21 01:58:31.681 
Epoch 160/1000 
	 loss: 41.2572, MinusLogProbMetric: 41.2572, val_loss: 41.0111, val_MinusLogProbMetric: 41.0111

Epoch 160: val_loss did not improve from 30.36094
196/196 - 77s - loss: 41.2572 - MinusLogProbMetric: 41.2572 - val_loss: 41.0111 - val_MinusLogProbMetric: 41.0111 - lr: 1.2346e-05 - 77s/epoch - 392ms/step
Epoch 161/1000
2023-09-21 01:59:48.711 
Epoch 161/1000 
	 loss: 40.5954, MinusLogProbMetric: 40.5954, val_loss: 40.2400, val_MinusLogProbMetric: 40.2400

Epoch 161: val_loss did not improve from 30.36094
196/196 - 77s - loss: 40.5954 - MinusLogProbMetric: 40.5954 - val_loss: 40.2400 - val_MinusLogProbMetric: 40.2400 - lr: 1.2346e-05 - 77s/epoch - 393ms/step
Epoch 162/1000
2023-09-21 02:01:07.332 
Epoch 162/1000 
	 loss: 39.9659, MinusLogProbMetric: 39.9659, val_loss: 39.6340, val_MinusLogProbMetric: 39.6340

Epoch 162: val_loss did not improve from 30.36094
196/196 - 79s - loss: 39.9659 - MinusLogProbMetric: 39.9659 - val_loss: 39.6340 - val_MinusLogProbMetric: 39.6340 - lr: 1.2346e-05 - 79s/epoch - 401ms/step
Epoch 163/1000
2023-09-21 02:02:23.202 
Epoch 163/1000 
	 loss: 39.3953, MinusLogProbMetric: 39.3953, val_loss: 39.1862, val_MinusLogProbMetric: 39.1862

Epoch 163: val_loss did not improve from 30.36094
196/196 - 76s - loss: 39.3953 - MinusLogProbMetric: 39.3953 - val_loss: 39.1862 - val_MinusLogProbMetric: 39.1862 - lr: 1.2346e-05 - 76s/epoch - 387ms/step
Epoch 164/1000
2023-09-21 02:03:39.431 
Epoch 164/1000 
	 loss: 38.8855, MinusLogProbMetric: 38.8855, val_loss: 38.6594, val_MinusLogProbMetric: 38.6594

Epoch 164: val_loss did not improve from 30.36094
196/196 - 76s - loss: 38.8855 - MinusLogProbMetric: 38.8855 - val_loss: 38.6594 - val_MinusLogProbMetric: 38.6594 - lr: 1.2346e-05 - 76s/epoch - 389ms/step
Epoch 165/1000
2023-09-21 02:04:56.643 
Epoch 165/1000 
	 loss: 38.4035, MinusLogProbMetric: 38.4035, val_loss: 38.2760, val_MinusLogProbMetric: 38.2760

Epoch 165: val_loss did not improve from 30.36094
196/196 - 77s - loss: 38.4035 - MinusLogProbMetric: 38.4035 - val_loss: 38.2760 - val_MinusLogProbMetric: 38.2760 - lr: 1.2346e-05 - 77s/epoch - 394ms/step
Epoch 166/1000
2023-09-21 02:06:13.354 
Epoch 166/1000 
	 loss: 38.0787, MinusLogProbMetric: 38.0787, val_loss: 38.0192, val_MinusLogProbMetric: 38.0192

Epoch 166: val_loss did not improve from 30.36094
196/196 - 77s - loss: 38.0787 - MinusLogProbMetric: 38.0787 - val_loss: 38.0192 - val_MinusLogProbMetric: 38.0192 - lr: 1.2346e-05 - 77s/epoch - 391ms/step
Epoch 167/1000
2023-09-21 02:07:28.830 
Epoch 167/1000 
	 loss: 37.6123, MinusLogProbMetric: 37.6123, val_loss: 37.4353, val_MinusLogProbMetric: 37.4353

Epoch 167: val_loss did not improve from 30.36094
196/196 - 75s - loss: 37.6123 - MinusLogProbMetric: 37.6123 - val_loss: 37.4353 - val_MinusLogProbMetric: 37.4353 - lr: 1.2346e-05 - 75s/epoch - 385ms/step
Epoch 168/1000
2023-09-21 02:08:45.719 
Epoch 168/1000 
	 loss: 37.2336, MinusLogProbMetric: 37.2336, val_loss: 37.0770, val_MinusLogProbMetric: 37.0770

Epoch 168: val_loss did not improve from 30.36094
196/196 - 77s - loss: 37.2336 - MinusLogProbMetric: 37.2336 - val_loss: 37.0770 - val_MinusLogProbMetric: 37.0770 - lr: 1.2346e-05 - 77s/epoch - 392ms/step
Epoch 169/1000
2023-09-21 02:10:02.211 
Epoch 169/1000 
	 loss: 36.8930, MinusLogProbMetric: 36.8930, val_loss: 36.7197, val_MinusLogProbMetric: 36.7197

Epoch 169: val_loss did not improve from 30.36094
196/196 - 76s - loss: 36.8930 - MinusLogProbMetric: 36.8930 - val_loss: 36.7197 - val_MinusLogProbMetric: 36.7197 - lr: 1.2346e-05 - 76s/epoch - 390ms/step
Epoch 170/1000
2023-09-21 02:11:19.203 
Epoch 170/1000 
	 loss: 36.6153, MinusLogProbMetric: 36.6153, val_loss: 36.4286, val_MinusLogProbMetric: 36.4286

Epoch 170: val_loss did not improve from 30.36094
196/196 - 77s - loss: 36.6153 - MinusLogProbMetric: 36.6153 - val_loss: 36.4286 - val_MinusLogProbMetric: 36.4286 - lr: 1.2346e-05 - 77s/epoch - 393ms/step
Epoch 171/1000
2023-09-21 02:12:36.425 
Epoch 171/1000 
	 loss: 36.3736, MinusLogProbMetric: 36.3736, val_loss: 36.2740, val_MinusLogProbMetric: 36.2740

Epoch 171: val_loss did not improve from 30.36094
196/196 - 77s - loss: 36.3736 - MinusLogProbMetric: 36.3736 - val_loss: 36.2740 - val_MinusLogProbMetric: 36.2740 - lr: 1.2346e-05 - 77s/epoch - 394ms/step
Epoch 172/1000
2023-09-21 02:13:52.872 
Epoch 172/1000 
	 loss: 57.0501, MinusLogProbMetric: 57.0501, val_loss: 59.1527, val_MinusLogProbMetric: 59.1527

Epoch 172: val_loss did not improve from 30.36094
196/196 - 76s - loss: 57.0501 - MinusLogProbMetric: 57.0501 - val_loss: 59.1527 - val_MinusLogProbMetric: 59.1527 - lr: 1.2346e-05 - 76s/epoch - 390ms/step
Epoch 173/1000
2023-09-21 02:15:09.921 
Epoch 173/1000 
	 loss: 52.8479, MinusLogProbMetric: 52.8479, val_loss: 47.3209, val_MinusLogProbMetric: 47.3209

Epoch 173: val_loss did not improve from 30.36094
196/196 - 77s - loss: 52.8479 - MinusLogProbMetric: 52.8479 - val_loss: 47.3209 - val_MinusLogProbMetric: 47.3209 - lr: 1.2346e-05 - 77s/epoch - 393ms/step
Epoch 174/1000
2023-09-21 02:16:26.734 
Epoch 174/1000 
	 loss: 47.7601, MinusLogProbMetric: 47.7601, val_loss: 48.6396, val_MinusLogProbMetric: 48.6396

Epoch 174: val_loss did not improve from 30.36094
196/196 - 77s - loss: 47.7601 - MinusLogProbMetric: 47.7601 - val_loss: 48.6396 - val_MinusLogProbMetric: 48.6396 - lr: 1.2346e-05 - 77s/epoch - 392ms/step
Epoch 175/1000
2023-09-21 02:17:44.198 
Epoch 175/1000 
	 loss: 43.4535, MinusLogProbMetric: 43.4535, val_loss: 42.6679, val_MinusLogProbMetric: 42.6679

Epoch 175: val_loss did not improve from 30.36094
196/196 - 77s - loss: 43.4535 - MinusLogProbMetric: 43.4535 - val_loss: 42.6679 - val_MinusLogProbMetric: 42.6679 - lr: 1.2346e-05 - 77s/epoch - 395ms/step
Epoch 176/1000
2023-09-21 02:19:02.027 
Epoch 176/1000 
	 loss: 50.1370, MinusLogProbMetric: 50.1370, val_loss: 45.7029, val_MinusLogProbMetric: 45.7029

Epoch 176: val_loss did not improve from 30.36094
196/196 - 78s - loss: 50.1370 - MinusLogProbMetric: 50.1370 - val_loss: 45.7029 - val_MinusLogProbMetric: 45.7029 - lr: 1.2346e-05 - 78s/epoch - 397ms/step
Epoch 177/1000
2023-09-21 02:20:19.435 
Epoch 177/1000 
	 loss: 43.7066, MinusLogProbMetric: 43.7066, val_loss: 43.6771, val_MinusLogProbMetric: 43.6771

Epoch 177: val_loss did not improve from 30.36094
196/196 - 77s - loss: 43.7066 - MinusLogProbMetric: 43.7066 - val_loss: 43.6771 - val_MinusLogProbMetric: 43.6771 - lr: 1.2346e-05 - 77s/epoch - 395ms/step
Epoch 178/1000
2023-09-21 02:21:35.616 
Epoch 178/1000 
	 loss: 42.0771, MinusLogProbMetric: 42.0771, val_loss: 44.3322, val_MinusLogProbMetric: 44.3322

Epoch 178: val_loss did not improve from 30.36094
196/196 - 76s - loss: 42.0771 - MinusLogProbMetric: 42.0771 - val_loss: 44.3322 - val_MinusLogProbMetric: 44.3322 - lr: 1.2346e-05 - 76s/epoch - 389ms/step
Epoch 179/1000
2023-09-21 02:22:52.754 
Epoch 179/1000 
	 loss: 39.4459, MinusLogProbMetric: 39.4459, val_loss: 38.3472, val_MinusLogProbMetric: 38.3472

Epoch 179: val_loss did not improve from 30.36094
196/196 - 77s - loss: 39.4459 - MinusLogProbMetric: 39.4459 - val_loss: 38.3472 - val_MinusLogProbMetric: 38.3472 - lr: 1.2346e-05 - 77s/epoch - 394ms/step
Epoch 180/1000
2023-09-21 02:24:09.934 
Epoch 180/1000 
	 loss: 38.0627, MinusLogProbMetric: 38.0627, val_loss: 37.5738, val_MinusLogProbMetric: 37.5738

Epoch 180: val_loss did not improve from 30.36094
196/196 - 77s - loss: 38.0627 - MinusLogProbMetric: 38.0627 - val_loss: 37.5738 - val_MinusLogProbMetric: 37.5738 - lr: 1.2346e-05 - 77s/epoch - 394ms/step
Epoch 181/1000
2023-09-21 02:25:26.735 
Epoch 181/1000 
	 loss: 37.5236, MinusLogProbMetric: 37.5236, val_loss: 37.0532, val_MinusLogProbMetric: 37.0532

Epoch 181: val_loss did not improve from 30.36094
196/196 - 77s - loss: 37.5236 - MinusLogProbMetric: 37.5236 - val_loss: 37.0532 - val_MinusLogProbMetric: 37.0532 - lr: 1.2346e-05 - 77s/epoch - 392ms/step
Epoch 182/1000
2023-09-21 02:26:43.485 
Epoch 182/1000 
	 loss: 37.2311, MinusLogProbMetric: 37.2311, val_loss: 36.8906, val_MinusLogProbMetric: 36.8906

Epoch 182: val_loss did not improve from 30.36094
196/196 - 77s - loss: 37.2311 - MinusLogProbMetric: 37.2311 - val_loss: 36.8906 - val_MinusLogProbMetric: 36.8906 - lr: 1.2346e-05 - 77s/epoch - 392ms/step
Epoch 183/1000
2023-09-21 02:28:00.180 
Epoch 183/1000 
	 loss: 38.0695, MinusLogProbMetric: 38.0695, val_loss: 36.8215, val_MinusLogProbMetric: 36.8215

Epoch 183: val_loss did not improve from 30.36094
196/196 - 77s - loss: 38.0695 - MinusLogProbMetric: 38.0695 - val_loss: 36.8215 - val_MinusLogProbMetric: 36.8215 - lr: 1.2346e-05 - 77s/epoch - 391ms/step
Epoch 184/1000
2023-09-21 02:29:16.211 
Epoch 184/1000 
	 loss: 36.4580, MinusLogProbMetric: 36.4580, val_loss: 36.2961, val_MinusLogProbMetric: 36.2961

Epoch 184: val_loss did not improve from 30.36094
196/196 - 76s - loss: 36.4580 - MinusLogProbMetric: 36.4580 - val_loss: 36.2961 - val_MinusLogProbMetric: 36.2961 - lr: 1.2346e-05 - 76s/epoch - 388ms/step
Epoch 185/1000
2023-09-21 02:30:33.139 
Epoch 185/1000 
	 loss: 36.2148, MinusLogProbMetric: 36.2148, val_loss: 35.8471, val_MinusLogProbMetric: 35.8471

Epoch 185: val_loss did not improve from 30.36094
196/196 - 77s - loss: 36.2148 - MinusLogProbMetric: 36.2148 - val_loss: 35.8471 - val_MinusLogProbMetric: 35.8471 - lr: 1.2346e-05 - 77s/epoch - 392ms/step
Epoch 186/1000
2023-09-21 02:31:49.385 
Epoch 186/1000 
	 loss: 35.8930, MinusLogProbMetric: 35.8930, val_loss: 35.8954, val_MinusLogProbMetric: 35.8954

Epoch 186: val_loss did not improve from 30.36094
196/196 - 76s - loss: 35.8930 - MinusLogProbMetric: 35.8930 - val_loss: 35.8954 - val_MinusLogProbMetric: 35.8954 - lr: 1.2346e-05 - 76s/epoch - 389ms/step
Epoch 187/1000
2023-09-21 02:33:06.535 
Epoch 187/1000 
	 loss: 35.6964, MinusLogProbMetric: 35.6964, val_loss: 35.3815, val_MinusLogProbMetric: 35.3815

Epoch 187: val_loss did not improve from 30.36094
196/196 - 77s - loss: 35.6964 - MinusLogProbMetric: 35.6964 - val_loss: 35.3815 - val_MinusLogProbMetric: 35.3815 - lr: 1.2346e-05 - 77s/epoch - 394ms/step
Epoch 188/1000
2023-09-21 02:34:23.020 
Epoch 188/1000 
	 loss: 35.2744, MinusLogProbMetric: 35.2744, val_loss: 35.2805, val_MinusLogProbMetric: 35.2805

Epoch 188: val_loss did not improve from 30.36094
196/196 - 76s - loss: 35.2744 - MinusLogProbMetric: 35.2744 - val_loss: 35.2805 - val_MinusLogProbMetric: 35.2805 - lr: 1.2346e-05 - 76s/epoch - 390ms/step
Epoch 189/1000
2023-09-21 02:35:39.524 
Epoch 189/1000 
	 loss: 35.3566, MinusLogProbMetric: 35.3566, val_loss: 34.9677, val_MinusLogProbMetric: 34.9677

Epoch 189: val_loss did not improve from 30.36094
196/196 - 77s - loss: 35.3566 - MinusLogProbMetric: 35.3566 - val_loss: 34.9677 - val_MinusLogProbMetric: 34.9677 - lr: 1.2346e-05 - 77s/epoch - 390ms/step
Epoch 190/1000
2023-09-21 02:36:56.192 
Epoch 190/1000 
	 loss: 34.8812, MinusLogProbMetric: 34.8812, val_loss: 34.6494, val_MinusLogProbMetric: 34.6494

Epoch 190: val_loss did not improve from 30.36094
196/196 - 77s - loss: 34.8812 - MinusLogProbMetric: 34.8812 - val_loss: 34.6494 - val_MinusLogProbMetric: 34.6494 - lr: 1.2346e-05 - 77s/epoch - 391ms/step
Epoch 191/1000
2023-09-21 02:38:13.460 
Epoch 191/1000 
	 loss: 34.8613, MinusLogProbMetric: 34.8613, val_loss: 34.3907, val_MinusLogProbMetric: 34.3907

Epoch 191: val_loss did not improve from 30.36094
196/196 - 77s - loss: 34.8613 - MinusLogProbMetric: 34.8613 - val_loss: 34.3907 - val_MinusLogProbMetric: 34.3907 - lr: 1.2346e-05 - 77s/epoch - 394ms/step
Epoch 192/1000
2023-09-21 02:39:30.053 
Epoch 192/1000 
	 loss: 34.3197, MinusLogProbMetric: 34.3197, val_loss: 34.1855, val_MinusLogProbMetric: 34.1855

Epoch 192: val_loss did not improve from 30.36094
196/196 - 77s - loss: 34.3197 - MinusLogProbMetric: 34.3197 - val_loss: 34.1855 - val_MinusLogProbMetric: 34.1855 - lr: 1.2346e-05 - 77s/epoch - 391ms/step
Epoch 193/1000
2023-09-21 02:40:47.005 
Epoch 193/1000 
	 loss: 34.9423, MinusLogProbMetric: 34.9423, val_loss: 34.4657, val_MinusLogProbMetric: 34.4657

Epoch 193: val_loss did not improve from 30.36094
196/196 - 77s - loss: 34.9423 - MinusLogProbMetric: 34.9423 - val_loss: 34.4657 - val_MinusLogProbMetric: 34.4657 - lr: 1.2346e-05 - 77s/epoch - 393ms/step
Epoch 194/1000
2023-09-21 02:42:03.351 
Epoch 194/1000 
	 loss: 34.0758, MinusLogProbMetric: 34.0758, val_loss: 33.9804, val_MinusLogProbMetric: 33.9804

Epoch 194: val_loss did not improve from 30.36094
196/196 - 76s - loss: 34.0758 - MinusLogProbMetric: 34.0758 - val_loss: 33.9804 - val_MinusLogProbMetric: 33.9804 - lr: 1.2346e-05 - 76s/epoch - 390ms/step
Epoch 195/1000
2023-09-21 02:43:19.691 
Epoch 195/1000 
	 loss: 33.7705, MinusLogProbMetric: 33.7705, val_loss: 33.7113, val_MinusLogProbMetric: 33.7113

Epoch 195: val_loss did not improve from 30.36094
196/196 - 76s - loss: 33.7705 - MinusLogProbMetric: 33.7705 - val_loss: 33.7113 - val_MinusLogProbMetric: 33.7113 - lr: 6.1728e-06 - 76s/epoch - 389ms/step
Epoch 196/1000
2023-09-21 02:44:35.704 
Epoch 196/1000 
	 loss: 33.6657, MinusLogProbMetric: 33.6657, val_loss: 33.5510, val_MinusLogProbMetric: 33.5510

Epoch 196: val_loss did not improve from 30.36094
196/196 - 76s - loss: 33.6657 - MinusLogProbMetric: 33.6657 - val_loss: 33.5510 - val_MinusLogProbMetric: 33.5510 - lr: 6.1728e-06 - 76s/epoch - 388ms/step
Epoch 197/1000
2023-09-21 02:45:52.496 
Epoch 197/1000 
	 loss: 33.5550, MinusLogProbMetric: 33.5550, val_loss: 33.4948, val_MinusLogProbMetric: 33.4948

Epoch 197: val_loss did not improve from 30.36094
196/196 - 77s - loss: 33.5550 - MinusLogProbMetric: 33.5550 - val_loss: 33.4948 - val_MinusLogProbMetric: 33.4948 - lr: 6.1728e-06 - 77s/epoch - 392ms/step
Epoch 198/1000
2023-09-21 02:47:09.719 
Epoch 198/1000 
	 loss: 33.4674, MinusLogProbMetric: 33.4674, val_loss: 33.3884, val_MinusLogProbMetric: 33.3884

Epoch 198: val_loss did not improve from 30.36094
196/196 - 77s - loss: 33.4674 - MinusLogProbMetric: 33.4674 - val_loss: 33.3884 - val_MinusLogProbMetric: 33.3884 - lr: 6.1728e-06 - 77s/epoch - 394ms/step
Epoch 199/1000
2023-09-21 02:48:26.435 
Epoch 199/1000 
	 loss: 33.3846, MinusLogProbMetric: 33.3846, val_loss: 33.3198, val_MinusLogProbMetric: 33.3198

Epoch 199: val_loss did not improve from 30.36094
196/196 - 77s - loss: 33.3846 - MinusLogProbMetric: 33.3846 - val_loss: 33.3198 - val_MinusLogProbMetric: 33.3198 - lr: 6.1728e-06 - 77s/epoch - 391ms/step
Epoch 200/1000
2023-09-21 02:49:44.255 
Epoch 200/1000 
	 loss: 33.3175, MinusLogProbMetric: 33.3175, val_loss: 33.2558, val_MinusLogProbMetric: 33.2558

Epoch 200: val_loss did not improve from 30.36094
196/196 - 78s - loss: 33.3175 - MinusLogProbMetric: 33.3175 - val_loss: 33.2558 - val_MinusLogProbMetric: 33.2558 - lr: 6.1728e-06 - 78s/epoch - 397ms/step
Epoch 201/1000
2023-09-21 02:51:01.106 
Epoch 201/1000 
	 loss: 33.2261, MinusLogProbMetric: 33.2261, val_loss: 33.1797, val_MinusLogProbMetric: 33.1797

Epoch 201: val_loss did not improve from 30.36094
196/196 - 77s - loss: 33.2261 - MinusLogProbMetric: 33.2261 - val_loss: 33.1797 - val_MinusLogProbMetric: 33.1797 - lr: 6.1728e-06 - 77s/epoch - 392ms/step
Epoch 202/1000
2023-09-21 02:52:18.204 
Epoch 202/1000 
	 loss: 33.1604, MinusLogProbMetric: 33.1604, val_loss: 33.1272, val_MinusLogProbMetric: 33.1272

Epoch 202: val_loss did not improve from 30.36094
196/196 - 77s - loss: 33.1604 - MinusLogProbMetric: 33.1604 - val_loss: 33.1272 - val_MinusLogProbMetric: 33.1272 - lr: 6.1728e-06 - 77s/epoch - 393ms/step
Epoch 203/1000
2023-09-21 02:53:35.377 
Epoch 203/1000 
	 loss: 33.0834, MinusLogProbMetric: 33.0834, val_loss: 33.0349, val_MinusLogProbMetric: 33.0349

Epoch 203: val_loss did not improve from 30.36094
196/196 - 77s - loss: 33.0834 - MinusLogProbMetric: 33.0834 - val_loss: 33.0349 - val_MinusLogProbMetric: 33.0349 - lr: 6.1728e-06 - 77s/epoch - 394ms/step
Epoch 204/1000
2023-09-21 02:54:51.432 
Epoch 204/1000 
	 loss: 33.0142, MinusLogProbMetric: 33.0142, val_loss: 32.9776, val_MinusLogProbMetric: 32.9776

Epoch 204: val_loss did not improve from 30.36094
196/196 - 76s - loss: 33.0142 - MinusLogProbMetric: 33.0142 - val_loss: 32.9776 - val_MinusLogProbMetric: 32.9776 - lr: 6.1728e-06 - 76s/epoch - 388ms/step
Epoch 205/1000
2023-09-21 02:56:08.233 
Epoch 205/1000 
	 loss: 32.9765, MinusLogProbMetric: 32.9765, val_loss: 32.9229, val_MinusLogProbMetric: 32.9229

Epoch 205: val_loss did not improve from 30.36094
196/196 - 77s - loss: 32.9765 - MinusLogProbMetric: 32.9765 - val_loss: 32.9229 - val_MinusLogProbMetric: 32.9229 - lr: 6.1728e-06 - 77s/epoch - 392ms/step
Epoch 206/1000
2023-09-21 02:57:24.983 
Epoch 206/1000 
	 loss: 32.8769, MinusLogProbMetric: 32.8769, val_loss: 32.9357, val_MinusLogProbMetric: 32.9357

Epoch 206: val_loss did not improve from 30.36094
196/196 - 77s - loss: 32.8769 - MinusLogProbMetric: 32.8769 - val_loss: 32.9357 - val_MinusLogProbMetric: 32.9357 - lr: 6.1728e-06 - 77s/epoch - 392ms/step
Epoch 207/1000
2023-09-21 02:58:42.629 
Epoch 207/1000 
	 loss: 32.8920, MinusLogProbMetric: 32.8920, val_loss: 32.8472, val_MinusLogProbMetric: 32.8472

Epoch 207: val_loss did not improve from 30.36094
196/196 - 78s - loss: 32.8920 - MinusLogProbMetric: 32.8920 - val_loss: 32.8472 - val_MinusLogProbMetric: 32.8472 - lr: 6.1728e-06 - 78s/epoch - 396ms/step
Epoch 208/1000
2023-09-21 02:59:58.961 
Epoch 208/1000 
	 loss: 32.7514, MinusLogProbMetric: 32.7514, val_loss: 32.7009, val_MinusLogProbMetric: 32.7009

Epoch 208: val_loss did not improve from 30.36094
196/196 - 76s - loss: 32.7514 - MinusLogProbMetric: 32.7514 - val_loss: 32.7009 - val_MinusLogProbMetric: 32.7009 - lr: 6.1728e-06 - 76s/epoch - 389ms/step
Epoch 209/1000
2023-09-21 03:01:15.694 
Epoch 209/1000 
	 loss: 32.6941, MinusLogProbMetric: 32.6941, val_loss: 32.7444, val_MinusLogProbMetric: 32.7444

Epoch 209: val_loss did not improve from 30.36094
196/196 - 77s - loss: 32.6941 - MinusLogProbMetric: 32.6941 - val_loss: 32.7444 - val_MinusLogProbMetric: 32.7444 - lr: 6.1728e-06 - 77s/epoch - 391ms/step
Epoch 210/1000
2023-09-21 03:02:32.922 
Epoch 210/1000 
	 loss: 32.6438, MinusLogProbMetric: 32.6438, val_loss: 32.5901, val_MinusLogProbMetric: 32.5901

Epoch 210: val_loss did not improve from 30.36094
196/196 - 77s - loss: 32.6438 - MinusLogProbMetric: 32.6438 - val_loss: 32.5901 - val_MinusLogProbMetric: 32.5901 - lr: 6.1728e-06 - 77s/epoch - 394ms/step
Epoch 211/1000
2023-09-21 03:03:48.991 
Epoch 211/1000 
	 loss: 71.1659, MinusLogProbMetric: 71.1659, val_loss: 64.1031, val_MinusLogProbMetric: 64.1031

Epoch 211: val_loss did not improve from 30.36094
196/196 - 76s - loss: 71.1659 - MinusLogProbMetric: 71.1659 - val_loss: 64.1031 - val_MinusLogProbMetric: 64.1031 - lr: 6.1728e-06 - 76s/epoch - 388ms/step
Epoch 212/1000
2023-09-21 03:05:05.904 
Epoch 212/1000 
	 loss: 56.8812, MinusLogProbMetric: 56.8812, val_loss: 50.6171, val_MinusLogProbMetric: 50.6171

Epoch 212: val_loss did not improve from 30.36094
196/196 - 77s - loss: 56.8812 - MinusLogProbMetric: 56.8812 - val_loss: 50.6171 - val_MinusLogProbMetric: 50.6171 - lr: 6.1728e-06 - 77s/epoch - 392ms/step
Epoch 213/1000
2023-09-21 03:06:22.449 
Epoch 213/1000 
	 loss: 48.0549, MinusLogProbMetric: 48.0549, val_loss: 45.6481, val_MinusLogProbMetric: 45.6481

Epoch 213: val_loss did not improve from 30.36094
196/196 - 77s - loss: 48.0549 - MinusLogProbMetric: 48.0549 - val_loss: 45.6481 - val_MinusLogProbMetric: 45.6481 - lr: 6.1728e-06 - 77s/epoch - 391ms/step
Epoch 214/1000
2023-09-21 03:07:38.815 
Epoch 214/1000 
	 loss: 44.5603, MinusLogProbMetric: 44.5603, val_loss: 43.2748, val_MinusLogProbMetric: 43.2748

Epoch 214: val_loss did not improve from 30.36094
196/196 - 76s - loss: 44.5603 - MinusLogProbMetric: 44.5603 - val_loss: 43.2748 - val_MinusLogProbMetric: 43.2748 - lr: 6.1728e-06 - 76s/epoch - 390ms/step
Epoch 215/1000
2023-09-21 03:08:55.183 
Epoch 215/1000 
	 loss: 42.8358, MinusLogProbMetric: 42.8358, val_loss: 41.8759, val_MinusLogProbMetric: 41.8759

Epoch 215: val_loss did not improve from 30.36094
196/196 - 76s - loss: 42.8358 - MinusLogProbMetric: 42.8358 - val_loss: 41.8759 - val_MinusLogProbMetric: 41.8759 - lr: 6.1728e-06 - 76s/epoch - 390ms/step
Epoch 216/1000
2023-09-21 03:10:11.411 
Epoch 216/1000 
	 loss: 41.6125, MinusLogProbMetric: 41.6125, val_loss: 41.4276, val_MinusLogProbMetric: 41.4276

Epoch 216: val_loss did not improve from 30.36094
196/196 - 76s - loss: 41.6125 - MinusLogProbMetric: 41.6125 - val_loss: 41.4276 - val_MinusLogProbMetric: 41.4276 - lr: 6.1728e-06 - 76s/epoch - 389ms/step
Epoch 217/1000
2023-09-21 03:11:26.843 
Epoch 217/1000 
	 loss: 40.0108, MinusLogProbMetric: 40.0108, val_loss: 39.0582, val_MinusLogProbMetric: 39.0582

Epoch 217: val_loss did not improve from 30.36094
196/196 - 75s - loss: 40.0108 - MinusLogProbMetric: 40.0108 - val_loss: 39.0582 - val_MinusLogProbMetric: 39.0582 - lr: 6.1728e-06 - 75s/epoch - 385ms/step
Epoch 218/1000
2023-09-21 03:12:43.288 
Epoch 218/1000 
	 loss: 39.2004, MinusLogProbMetric: 39.2004, val_loss: 38.6401, val_MinusLogProbMetric: 38.6401

Epoch 218: val_loss did not improve from 30.36094
196/196 - 76s - loss: 39.2004 - MinusLogProbMetric: 39.2004 - val_loss: 38.6401 - val_MinusLogProbMetric: 38.6401 - lr: 6.1728e-06 - 76s/epoch - 390ms/step
Epoch 219/1000
2023-09-21 03:13:59.001 
Epoch 219/1000 
	 loss: 38.5092, MinusLogProbMetric: 38.5092, val_loss: 37.5779, val_MinusLogProbMetric: 37.5779

Epoch 219: val_loss did not improve from 30.36094
196/196 - 76s - loss: 38.5092 - MinusLogProbMetric: 38.5092 - val_loss: 37.5779 - val_MinusLogProbMetric: 37.5779 - lr: 6.1728e-06 - 76s/epoch - 386ms/step
Epoch 220/1000
2023-09-21 03:15:14.902 
Epoch 220/1000 
	 loss: 39.7272, MinusLogProbMetric: 39.7272, val_loss: 39.9842, val_MinusLogProbMetric: 39.9842

Epoch 220: val_loss did not improve from 30.36094
196/196 - 76s - loss: 39.7272 - MinusLogProbMetric: 39.7272 - val_loss: 39.9842 - val_MinusLogProbMetric: 39.9842 - lr: 6.1728e-06 - 76s/epoch - 387ms/step
Epoch 221/1000
2023-09-21 03:16:29.739 
Epoch 221/1000 
	 loss: 38.9257, MinusLogProbMetric: 38.9257, val_loss: 37.3164, val_MinusLogProbMetric: 37.3164

Epoch 221: val_loss did not improve from 30.36094
196/196 - 75s - loss: 38.9257 - MinusLogProbMetric: 38.9257 - val_loss: 37.3164 - val_MinusLogProbMetric: 37.3164 - lr: 6.1728e-06 - 75s/epoch - 382ms/step
Epoch 222/1000
2023-09-21 03:17:46.363 
Epoch 222/1000 
	 loss: 50.6297, MinusLogProbMetric: 50.6297, val_loss: 41.5275, val_MinusLogProbMetric: 41.5275

Epoch 222: val_loss did not improve from 30.36094
196/196 - 77s - loss: 50.6297 - MinusLogProbMetric: 50.6297 - val_loss: 41.5275 - val_MinusLogProbMetric: 41.5275 - lr: 6.1728e-06 - 77s/epoch - 391ms/step
Epoch 223/1000
2023-09-21 03:19:03.556 
Epoch 223/1000 
	 loss: 39.2698, MinusLogProbMetric: 39.2698, val_loss: 37.6539, val_MinusLogProbMetric: 37.6539

Epoch 223: val_loss did not improve from 30.36094
196/196 - 77s - loss: 39.2698 - MinusLogProbMetric: 39.2698 - val_loss: 37.6539 - val_MinusLogProbMetric: 37.6539 - lr: 6.1728e-06 - 77s/epoch - 394ms/step
Epoch 224/1000
2023-09-21 03:20:20.471 
Epoch 224/1000 
	 loss: 37.6515, MinusLogProbMetric: 37.6515, val_loss: 36.6001, val_MinusLogProbMetric: 36.6001

Epoch 224: val_loss did not improve from 30.36094
196/196 - 77s - loss: 37.6515 - MinusLogProbMetric: 37.6515 - val_loss: 36.6001 - val_MinusLogProbMetric: 36.6001 - lr: 6.1728e-06 - 77s/epoch - 392ms/step
Epoch 225/1000
2023-09-21 03:21:37.804 
Epoch 225/1000 
	 loss: 36.5296, MinusLogProbMetric: 36.5296, val_loss: 37.0756, val_MinusLogProbMetric: 37.0756

Epoch 225: val_loss did not improve from 30.36094
196/196 - 77s - loss: 36.5296 - MinusLogProbMetric: 36.5296 - val_loss: 37.0756 - val_MinusLogProbMetric: 37.0756 - lr: 6.1728e-06 - 77s/epoch - 395ms/step
Epoch 226/1000
2023-09-21 03:22:54.695 
Epoch 226/1000 
	 loss: 41.5407, MinusLogProbMetric: 41.5407, val_loss: 39.7237, val_MinusLogProbMetric: 39.7237

Epoch 226: val_loss did not improve from 30.36094
196/196 - 77s - loss: 41.5407 - MinusLogProbMetric: 41.5407 - val_loss: 39.7237 - val_MinusLogProbMetric: 39.7237 - lr: 6.1728e-06 - 77s/epoch - 392ms/step
Epoch 227/1000
2023-09-21 03:24:11.422 
Epoch 227/1000 
	 loss: 36.5622, MinusLogProbMetric: 36.5622, val_loss: 35.6362, val_MinusLogProbMetric: 35.6362

Epoch 227: val_loss did not improve from 30.36094
196/196 - 77s - loss: 36.5622 - MinusLogProbMetric: 36.5622 - val_loss: 35.6362 - val_MinusLogProbMetric: 35.6362 - lr: 6.1728e-06 - 77s/epoch - 391ms/step
Epoch 228/1000
2023-09-21 03:25:27.606 
Epoch 228/1000 
	 loss: 58.5113, MinusLogProbMetric: 58.5113, val_loss: 98.0405, val_MinusLogProbMetric: 98.0405

Epoch 228: val_loss did not improve from 30.36094
196/196 - 76s - loss: 58.5113 - MinusLogProbMetric: 58.5113 - val_loss: 98.0405 - val_MinusLogProbMetric: 98.0405 - lr: 6.1728e-06 - 76s/epoch - 389ms/step
Epoch 229/1000
2023-09-21 03:26:43.559 
Epoch 229/1000 
	 loss: 66.8745, MinusLogProbMetric: 66.8745, val_loss: 53.3183, val_MinusLogProbMetric: 53.3183

Epoch 229: val_loss did not improve from 30.36094
196/196 - 76s - loss: 66.8745 - MinusLogProbMetric: 66.8745 - val_loss: 53.3183 - val_MinusLogProbMetric: 53.3183 - lr: 6.1728e-06 - 76s/epoch - 387ms/step
Epoch 230/1000
2023-09-21 03:28:00.328 
Epoch 230/1000 
	 loss: 50.1091, MinusLogProbMetric: 50.1091, val_loss: 47.4336, val_MinusLogProbMetric: 47.4336

Epoch 230: val_loss did not improve from 30.36094
196/196 - 77s - loss: 50.1091 - MinusLogProbMetric: 50.1091 - val_loss: 47.4336 - val_MinusLogProbMetric: 47.4336 - lr: 6.1728e-06 - 77s/epoch - 392ms/step
Epoch 231/1000
2023-09-21 03:29:16.624 
Epoch 231/1000 
	 loss: 45.5136, MinusLogProbMetric: 45.5136, val_loss: 43.6581, val_MinusLogProbMetric: 43.6581

Epoch 231: val_loss did not improve from 30.36094
196/196 - 76s - loss: 45.5136 - MinusLogProbMetric: 45.5136 - val_loss: 43.6581 - val_MinusLogProbMetric: 43.6581 - lr: 6.1728e-06 - 76s/epoch - 389ms/step
Epoch 232/1000
2023-09-21 03:30:31.919 
Epoch 232/1000 
	 loss: 42.0400, MinusLogProbMetric: 42.0400, val_loss: 40.4728, val_MinusLogProbMetric: 40.4728

Epoch 232: val_loss did not improve from 30.36094
196/196 - 75s - loss: 42.0400 - MinusLogProbMetric: 42.0400 - val_loss: 40.4728 - val_MinusLogProbMetric: 40.4728 - lr: 6.1728e-06 - 75s/epoch - 384ms/step
Epoch 233/1000
2023-09-21 03:31:47.735 
Epoch 233/1000 
	 loss: 39.0551, MinusLogProbMetric: 39.0551, val_loss: 38.2389, val_MinusLogProbMetric: 38.2389

Epoch 233: val_loss did not improve from 30.36094
196/196 - 76s - loss: 39.0551 - MinusLogProbMetric: 39.0551 - val_loss: 38.2389 - val_MinusLogProbMetric: 38.2389 - lr: 6.1728e-06 - 76s/epoch - 387ms/step
Epoch 234/1000
2023-09-21 03:33:04.470 
Epoch 234/1000 
	 loss: 37.8270, MinusLogProbMetric: 37.8270, val_loss: 36.7488, val_MinusLogProbMetric: 36.7488

Epoch 234: val_loss did not improve from 30.36094
196/196 - 77s - loss: 37.8270 - MinusLogProbMetric: 37.8270 - val_loss: 36.7488 - val_MinusLogProbMetric: 36.7488 - lr: 6.1728e-06 - 77s/epoch - 391ms/step
Epoch 235/1000
2023-09-21 03:34:21.519 
Epoch 235/1000 
	 loss: 36.7099, MinusLogProbMetric: 36.7099, val_loss: 35.8030, val_MinusLogProbMetric: 35.8030

Epoch 235: val_loss did not improve from 30.36094
196/196 - 77s - loss: 36.7099 - MinusLogProbMetric: 36.7099 - val_loss: 35.8030 - val_MinusLogProbMetric: 35.8030 - lr: 6.1728e-06 - 77s/epoch - 393ms/step
Epoch 236/1000
Warning: The fraction of NaNs in loss is below threshold. Removing them from average.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Batch 55: Invalid loss, terminating training
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
2023-09-21 03:34:47.154 
Epoch 236/1000 
	 loss: nan, MinusLogProbMetric: 60.8513, val_loss: nan, val_MinusLogProbMetric: nan

Epoch 236: val_loss did not improve from 30.36094
196/196 - 26s - loss: nan - MinusLogProbMetric: 60.8513 - val_loss: nan - val_MinusLogProbMetric: nan - lr: 6.1728e-06 - 26s/epoch - 131ms/step
The loss history contains NaN values.
Training failed: trying again with seed 326159 and lr 4.115226337448558e-06.
===========
Generating train data for run 263.
===========
Train data generated in 0.32 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_263/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 377}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 4.115226337448558e-06, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_263/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.1831715 ,  3.2834203 ,  8.308094  , ...,  7.3133397 ,
         2.7002556 ,  1.7567806 ],
       [ 6.1308765 ,  7.147402  ,  6.0903115 , ...,  4.022617  ,
         2.6618268 ,  7.627545  ],
       [ 2.7429156 ,  3.6509063 ,  7.295548  , ...,  7.086021  ,
         2.8938296 ,  1.8224454 ],
       ...,
       [ 2.1098776 ,  4.1337423 ,  8.041495  , ...,  7.2043395 ,
         2.3724499 ,  1.8449893 ],
       [ 4.759076  ,  5.6016526 , -0.17659053, ...,  1.2483898 ,
         6.6213574 ,  1.391019  ],
       [ 4.6478305 ,  5.6608987 ,  0.05425403, ...,  1.0307544 ,
         6.027231  ,  1.3217621 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_263/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_263
self.data_kwargs: {'seed': 377}
self.x_data: [[5.416377   7.151266   6.5657053  ... 3.613302   2.6304417  8.037386  ]
 [4.297167   5.832213   0.12875912 ... 1.4317983  6.415448   1.3533646 ]
 [6.2353234  7.1795187  6.219724   ... 4.5891814  2.66546    7.551563  ]
 ...
 [1.8237456  4.102903   7.5608215  ... 7.136859   2.564185   1.5539532 ]
 [2.2305896  4.6568003  8.321339   ... 7.0577617  2.6189713  1.518045  ]
 [5.653481   7.1263475  6.929123   ... 4.292566   2.643216   7.404443  ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_268"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_269 (InputLayer)      [(None, 32)]              0         
                                                                 
 log_prob_layer_28 (LogProbL  (None,)                  1074400   
 ayer)                                                           
                                                                 
=================================================================
Total params: 1,074,400
Trainable params: 1,074,400
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_28/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_28'")
self.model: <keras.engine.functional.Functional object at 0x7faaca0164d0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 4.115226337448558e-06, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7faeea89e5c0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 4.115226337448558e-06, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7faeea89e5c0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7faa746984c0>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7faa9c6f6f50>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7faa9c6f7b20>, <keras.callbacks.ModelCheckpoint object at 0x7faa9c6f7be0>, <keras.callbacks.EarlyStopping object at 0x7faa9c6f5b10>, <keras.callbacks.ReduceLROnPlateau object at 0x7faa9c6f6cb0>, <keras.callbacks.TerminateOnNaN object at 0x7faa9c6f7fa0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.1831715 ,  3.2834203 ,  8.308094  , ...,  7.3133397 ,
         2.7002556 ,  1.7567806 ],
       [ 6.1308765 ,  7.147402  ,  6.0903115 , ...,  4.022617  ,
         2.6618268 ,  7.627545  ],
       [ 2.7429156 ,  3.6509063 ,  7.295548  , ...,  7.086021  ,
         2.8938296 ,  1.8224454 ],
       ...,
       [ 2.1098776 ,  4.1337423 ,  8.041495  , ...,  7.2043395 ,
         2.3724499 ,  1.8449893 ],
       [ 4.759076  ,  5.6016526 , -0.17659053, ...,  1.2483898 ,
         6.6213574 ,  1.391019  ],
       [ 4.6478305 ,  5.6608987 ,  0.05425403, ...,  1.0307544 ,
         6.027231  ,  1.3217621 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
Found and loaded existing weights.
No history found. Generating new history.
===============
Running 263/720 with hyperparameters:
timestamp = 2023-09-21 03:35:03.037834
ndims = 32
seed_train = 377
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 1074400
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 4.115226337448558e-06...
Train first sample: [ 5.416377    7.151266    6.5657053   5.44807     3.870332    6.1800294
  2.9008856   8.441634    9.391678    4.1002183   7.382605    5.3625755
  5.5868373   9.949682    0.82923275  1.9832962  -0.10069095  8.219267
  8.539603    9.221239    9.5321455   8.239499    4.945965    8.152974
 -0.16393006  6.303131    0.6036788   9.50227     6.1976576   3.613302
  2.6304417   8.037386  ]
Epoch 1/1000
2023-09-21 03:39:19.162 
Epoch 1/1000 
	 loss: 30.5643, MinusLogProbMetric: 30.5643, val_loss: 30.4591, val_MinusLogProbMetric: 30.4591

Epoch 1: val_loss improved from inf to 30.45915, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 257s - loss: 30.5643 - MinusLogProbMetric: 30.5643 - val_loss: 30.4591 - val_MinusLogProbMetric: 30.4591 - lr: 4.1152e-06 - 257s/epoch - 1s/step
Epoch 2/1000
2023-09-21 03:40:40.974 
Epoch 2/1000 
	 loss: 30.2909, MinusLogProbMetric: 30.2909, val_loss: 30.2162, val_MinusLogProbMetric: 30.2162

Epoch 2: val_loss improved from 30.45915 to 30.21616, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 30.2909 - MinusLogProbMetric: 30.2909 - val_loss: 30.2162 - val_MinusLogProbMetric: 30.2162 - lr: 4.1152e-06 - 81s/epoch - 414ms/step
Epoch 3/1000
2023-09-21 03:42:01.333 
Epoch 3/1000 
	 loss: 30.3005, MinusLogProbMetric: 30.3005, val_loss: 30.4763, val_MinusLogProbMetric: 30.4763

Epoch 3: val_loss did not improve from 30.21616
196/196 - 79s - loss: 30.3005 - MinusLogProbMetric: 30.3005 - val_loss: 30.4763 - val_MinusLogProbMetric: 30.4763 - lr: 4.1152e-06 - 79s/epoch - 401ms/step
Epoch 4/1000
2023-09-21 03:43:21.353 
Epoch 4/1000 
	 loss: 29.7966, MinusLogProbMetric: 29.7966, val_loss: 29.8011, val_MinusLogProbMetric: 29.8011

Epoch 4: val_loss improved from 30.21616 to 29.80111, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 29.7966 - MinusLogProbMetric: 29.7966 - val_loss: 29.8011 - val_MinusLogProbMetric: 29.8011 - lr: 4.1152e-06 - 82s/epoch - 418ms/step
Epoch 5/1000
2023-09-21 03:44:43.383 
Epoch 5/1000 
	 loss: 44.3257, MinusLogProbMetric: 44.3257, val_loss: 54.5165, val_MinusLogProbMetric: 54.5165

Epoch 5: val_loss did not improve from 29.80111
196/196 - 80s - loss: 44.3257 - MinusLogProbMetric: 44.3257 - val_loss: 54.5165 - val_MinusLogProbMetric: 54.5165 - lr: 4.1152e-06 - 80s/epoch - 409ms/step
Epoch 6/1000
2023-09-21 03:46:03.355 
Epoch 6/1000 
	 loss: 45.1931, MinusLogProbMetric: 45.1931, val_loss: 38.7271, val_MinusLogProbMetric: 38.7271

Epoch 6: val_loss did not improve from 29.80111
196/196 - 80s - loss: 45.1931 - MinusLogProbMetric: 45.1931 - val_loss: 38.7271 - val_MinusLogProbMetric: 38.7271 - lr: 4.1152e-06 - 80s/epoch - 408ms/step
Epoch 7/1000
2023-09-21 03:47:23.567 
Epoch 7/1000 
	 loss: 35.2163, MinusLogProbMetric: 35.2163, val_loss: 33.1266, val_MinusLogProbMetric: 33.1266

Epoch 7: val_loss did not improve from 29.80111
196/196 - 80s - loss: 35.2163 - MinusLogProbMetric: 35.2163 - val_loss: 33.1266 - val_MinusLogProbMetric: 33.1266 - lr: 4.1152e-06 - 80s/epoch - 409ms/step
Epoch 8/1000
2023-09-21 03:48:42.084 
Epoch 8/1000 
	 loss: 33.3864, MinusLogProbMetric: 33.3864, val_loss: 31.6478, val_MinusLogProbMetric: 31.6478

Epoch 8: val_loss did not improve from 29.80111
196/196 - 79s - loss: 33.3864 - MinusLogProbMetric: 33.3864 - val_loss: 31.6478 - val_MinusLogProbMetric: 31.6478 - lr: 4.1152e-06 - 79s/epoch - 401ms/step
Epoch 9/1000
2023-09-21 03:50:01.319 
Epoch 9/1000 
	 loss: 31.5625, MinusLogProbMetric: 31.5625, val_loss: 31.7078, val_MinusLogProbMetric: 31.7078

Epoch 9: val_loss did not improve from 29.80111
196/196 - 79s - loss: 31.5625 - MinusLogProbMetric: 31.5625 - val_loss: 31.7078 - val_MinusLogProbMetric: 31.7078 - lr: 4.1152e-06 - 79s/epoch - 404ms/step
Epoch 10/1000
2023-09-21 03:51:20.210 
Epoch 10/1000 
	 loss: 31.1542, MinusLogProbMetric: 31.1542, val_loss: 31.9212, val_MinusLogProbMetric: 31.9212

Epoch 10: val_loss did not improve from 29.80111
196/196 - 79s - loss: 31.1542 - MinusLogProbMetric: 31.1542 - val_loss: 31.9212 - val_MinusLogProbMetric: 31.9212 - lr: 4.1152e-06 - 79s/epoch - 402ms/step
Epoch 11/1000
2023-09-21 03:52:39.628 
Epoch 11/1000 
	 loss: 30.5474, MinusLogProbMetric: 30.5474, val_loss: 30.3834, val_MinusLogProbMetric: 30.3834

Epoch 11: val_loss did not improve from 29.80111
196/196 - 79s - loss: 30.5474 - MinusLogProbMetric: 30.5474 - val_loss: 30.3834 - val_MinusLogProbMetric: 30.3834 - lr: 4.1152e-06 - 79s/epoch - 405ms/step
Epoch 12/1000
2023-09-21 03:53:59.945 
Epoch 12/1000 
	 loss: 38.7659, MinusLogProbMetric: 38.7659, val_loss: 31.4558, val_MinusLogProbMetric: 31.4558

Epoch 12: val_loss did not improve from 29.80111
196/196 - 80s - loss: 38.7659 - MinusLogProbMetric: 38.7659 - val_loss: 31.4558 - val_MinusLogProbMetric: 31.4558 - lr: 4.1152e-06 - 80s/epoch - 410ms/step
Epoch 13/1000
2023-09-21 03:55:20.406 
Epoch 13/1000 
	 loss: 30.6966, MinusLogProbMetric: 30.6966, val_loss: 30.4091, val_MinusLogProbMetric: 30.4091

Epoch 13: val_loss did not improve from 29.80111
196/196 - 80s - loss: 30.6966 - MinusLogProbMetric: 30.6966 - val_loss: 30.4091 - val_MinusLogProbMetric: 30.4091 - lr: 4.1152e-06 - 80s/epoch - 410ms/step
Epoch 14/1000
2023-09-21 03:56:40.033 
Epoch 14/1000 
	 loss: 30.1301, MinusLogProbMetric: 30.1301, val_loss: 30.0229, val_MinusLogProbMetric: 30.0229

Epoch 14: val_loss did not improve from 29.80111
196/196 - 80s - loss: 30.1301 - MinusLogProbMetric: 30.1301 - val_loss: 30.0229 - val_MinusLogProbMetric: 30.0229 - lr: 4.1152e-06 - 80s/epoch - 406ms/step
Epoch 15/1000
2023-09-21 03:57:59.938 
Epoch 15/1000 
	 loss: 30.6004, MinusLogProbMetric: 30.6004, val_loss: 29.9799, val_MinusLogProbMetric: 29.9799

Epoch 15: val_loss did not improve from 29.80111
196/196 - 80s - loss: 30.6004 - MinusLogProbMetric: 30.6004 - val_loss: 29.9799 - val_MinusLogProbMetric: 29.9799 - lr: 4.1152e-06 - 80s/epoch - 408ms/step
Epoch 16/1000
2023-09-21 03:59:18.805 
Epoch 16/1000 
	 loss: 29.7842, MinusLogProbMetric: 29.7842, val_loss: 29.7556, val_MinusLogProbMetric: 29.7556

Epoch 16: val_loss improved from 29.80111 to 29.75555, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 29.7842 - MinusLogProbMetric: 29.7842 - val_loss: 29.7556 - val_MinusLogProbMetric: 29.7556 - lr: 4.1152e-06 - 80s/epoch - 410ms/step
Epoch 17/1000
2023-09-21 04:00:40.202 
Epoch 17/1000 
	 loss: 29.6395, MinusLogProbMetric: 29.6395, val_loss: 29.6135, val_MinusLogProbMetric: 29.6135

Epoch 17: val_loss improved from 29.75555 to 29.61350, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 29.6395 - MinusLogProbMetric: 29.6395 - val_loss: 29.6135 - val_MinusLogProbMetric: 29.6135 - lr: 4.1152e-06 - 81s/epoch - 415ms/step
Epoch 18/1000
2023-09-21 04:02:01.290 
Epoch 18/1000 
	 loss: 29.5646, MinusLogProbMetric: 29.5646, val_loss: 29.6894, val_MinusLogProbMetric: 29.6894

Epoch 18: val_loss did not improve from 29.61350
196/196 - 80s - loss: 29.5646 - MinusLogProbMetric: 29.5646 - val_loss: 29.6894 - val_MinusLogProbMetric: 29.6894 - lr: 4.1152e-06 - 80s/epoch - 406ms/step
Epoch 19/1000
2023-09-21 04:03:19.544 
Epoch 19/1000 
	 loss: 29.6280, MinusLogProbMetric: 29.6280, val_loss: 29.6139, val_MinusLogProbMetric: 29.6139

Epoch 19: val_loss did not improve from 29.61350
196/196 - 78s - loss: 29.6280 - MinusLogProbMetric: 29.6280 - val_loss: 29.6139 - val_MinusLogProbMetric: 29.6139 - lr: 4.1152e-06 - 78s/epoch - 399ms/step
Epoch 20/1000
2023-09-21 04:04:39.304 
Epoch 20/1000 
	 loss: 29.3707, MinusLogProbMetric: 29.3707, val_loss: 29.4065, val_MinusLogProbMetric: 29.4065

Epoch 20: val_loss improved from 29.61350 to 29.40654, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 29.3707 - MinusLogProbMetric: 29.3707 - val_loss: 29.4065 - val_MinusLogProbMetric: 29.4065 - lr: 4.1152e-06 - 81s/epoch - 415ms/step
Epoch 21/1000
2023-09-21 04:06:00.387 
Epoch 21/1000 
	 loss: 29.3208, MinusLogProbMetric: 29.3208, val_loss: 29.3433, val_MinusLogProbMetric: 29.3433

Epoch 21: val_loss improved from 29.40654 to 29.34333, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 29.3208 - MinusLogProbMetric: 29.3208 - val_loss: 29.3433 - val_MinusLogProbMetric: 29.3433 - lr: 4.1152e-06 - 81s/epoch - 413ms/step
Epoch 22/1000
2023-09-21 04:07:22.042 
Epoch 22/1000 
	 loss: 29.2313, MinusLogProbMetric: 29.2313, val_loss: 29.2670, val_MinusLogProbMetric: 29.2670

Epoch 22: val_loss improved from 29.34333 to 29.26702, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 29.2313 - MinusLogProbMetric: 29.2313 - val_loss: 29.2670 - val_MinusLogProbMetric: 29.2670 - lr: 4.1152e-06 - 82s/epoch - 416ms/step
Epoch 23/1000
2023-09-21 04:08:42.588 
Epoch 23/1000 
	 loss: 29.3251, MinusLogProbMetric: 29.3251, val_loss: 29.2636, val_MinusLogProbMetric: 29.2636

Epoch 23: val_loss improved from 29.26702 to 29.26356, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 29.3251 - MinusLogProbMetric: 29.3251 - val_loss: 29.2636 - val_MinusLogProbMetric: 29.2636 - lr: 4.1152e-06 - 81s/epoch - 411ms/step
Epoch 24/1000
2023-09-21 04:10:03.323 
Epoch 24/1000 
	 loss: 29.1281, MinusLogProbMetric: 29.1281, val_loss: 29.2468, val_MinusLogProbMetric: 29.2468

Epoch 24: val_loss improved from 29.26356 to 29.24679, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 29.1281 - MinusLogProbMetric: 29.1281 - val_loss: 29.2468 - val_MinusLogProbMetric: 29.2468 - lr: 4.1152e-06 - 81s/epoch - 414ms/step
Epoch 25/1000
2023-09-21 04:11:24.959 
Epoch 25/1000 
	 loss: 29.4207, MinusLogProbMetric: 29.4207, val_loss: 29.2383, val_MinusLogProbMetric: 29.2383

Epoch 25: val_loss improved from 29.24679 to 29.23833, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 29.4207 - MinusLogProbMetric: 29.4207 - val_loss: 29.2383 - val_MinusLogProbMetric: 29.2383 - lr: 4.1152e-06 - 81s/epoch - 414ms/step
Epoch 26/1000
2023-09-21 04:12:45.648 
Epoch 26/1000 
	 loss: 29.0528, MinusLogProbMetric: 29.0528, val_loss: 29.1245, val_MinusLogProbMetric: 29.1245

Epoch 26: val_loss improved from 29.23833 to 29.12454, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 29.0528 - MinusLogProbMetric: 29.0528 - val_loss: 29.1245 - val_MinusLogProbMetric: 29.1245 - lr: 4.1152e-06 - 81s/epoch - 412ms/step
Epoch 27/1000
2023-09-21 04:14:05.821 
Epoch 27/1000 
	 loss: 29.0081, MinusLogProbMetric: 29.0081, val_loss: 29.1287, val_MinusLogProbMetric: 29.1287

Epoch 27: val_loss did not improve from 29.12454
196/196 - 79s - loss: 29.0081 - MinusLogProbMetric: 29.0081 - val_loss: 29.1287 - val_MinusLogProbMetric: 29.1287 - lr: 4.1152e-06 - 79s/epoch - 402ms/step
Epoch 28/1000
2023-09-21 04:15:25.803 
Epoch 28/1000 
	 loss: 28.9990, MinusLogProbMetric: 28.9990, val_loss: 29.1388, val_MinusLogProbMetric: 29.1388

Epoch 28: val_loss did not improve from 29.12454
196/196 - 80s - loss: 28.9990 - MinusLogProbMetric: 28.9990 - val_loss: 29.1388 - val_MinusLogProbMetric: 29.1388 - lr: 4.1152e-06 - 80s/epoch - 408ms/step
Epoch 29/1000
2023-09-21 04:16:45.606 
Epoch 29/1000 
	 loss: 28.9079, MinusLogProbMetric: 28.9079, val_loss: 28.9566, val_MinusLogProbMetric: 28.9566

Epoch 29: val_loss improved from 29.12454 to 28.95662, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 28.9079 - MinusLogProbMetric: 28.9079 - val_loss: 28.9566 - val_MinusLogProbMetric: 28.9566 - lr: 4.1152e-06 - 81s/epoch - 416ms/step
Epoch 30/1000
2023-09-21 04:18:07.032 
Epoch 30/1000 
	 loss: 28.9349, MinusLogProbMetric: 28.9349, val_loss: 28.9125, val_MinusLogProbMetric: 28.9125

Epoch 30: val_loss improved from 28.95662 to 28.91249, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 28.9349 - MinusLogProbMetric: 28.9349 - val_loss: 28.9125 - val_MinusLogProbMetric: 28.9125 - lr: 4.1152e-06 - 82s/epoch - 417ms/step
Epoch 31/1000
2023-09-21 04:19:28.771 
Epoch 31/1000 
	 loss: 28.8238, MinusLogProbMetric: 28.8238, val_loss: 28.8857, val_MinusLogProbMetric: 28.8857

Epoch 31: val_loss improved from 28.91249 to 28.88573, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 28.8238 - MinusLogProbMetric: 28.8238 - val_loss: 28.8857 - val_MinusLogProbMetric: 28.8857 - lr: 4.1152e-06 - 81s/epoch - 415ms/step
Epoch 32/1000
2023-09-21 04:20:49.977 
Epoch 32/1000 
	 loss: 28.8101, MinusLogProbMetric: 28.8101, val_loss: 29.1778, val_MinusLogProbMetric: 29.1778

Epoch 32: val_loss did not improve from 28.88573
196/196 - 79s - loss: 28.8101 - MinusLogProbMetric: 28.8101 - val_loss: 29.1778 - val_MinusLogProbMetric: 29.1778 - lr: 4.1152e-06 - 79s/epoch - 405ms/step
Epoch 33/1000
2023-09-21 04:22:09.996 
Epoch 33/1000 
	 loss: 28.7673, MinusLogProbMetric: 28.7673, val_loss: 28.8163, val_MinusLogProbMetric: 28.8163

Epoch 33: val_loss improved from 28.88573 to 28.81627, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 28.7673 - MinusLogProbMetric: 28.7673 - val_loss: 28.8163 - val_MinusLogProbMetric: 28.8163 - lr: 4.1152e-06 - 81s/epoch - 414ms/step
Epoch 34/1000
2023-09-21 04:23:29.778 
Epoch 34/1000 
	 loss: 29.7098, MinusLogProbMetric: 29.7098, val_loss: 31.1945, val_MinusLogProbMetric: 31.1945

Epoch 34: val_loss did not improve from 28.81627
196/196 - 79s - loss: 29.7098 - MinusLogProbMetric: 29.7098 - val_loss: 31.1945 - val_MinusLogProbMetric: 31.1945 - lr: 4.1152e-06 - 79s/epoch - 401ms/step
Epoch 35/1000
2023-09-21 04:24:49.516 
Epoch 35/1000 
	 loss: 31.5864, MinusLogProbMetric: 31.5864, val_loss: 37.1265, val_MinusLogProbMetric: 37.1265

Epoch 35: val_loss did not improve from 28.81627
196/196 - 80s - loss: 31.5864 - MinusLogProbMetric: 31.5864 - val_loss: 37.1265 - val_MinusLogProbMetric: 37.1265 - lr: 4.1152e-06 - 80s/epoch - 407ms/step
Epoch 36/1000
2023-09-21 04:26:09.501 
Epoch 36/1000 
	 loss: 31.6693, MinusLogProbMetric: 31.6693, val_loss: 29.3178, val_MinusLogProbMetric: 29.3178

Epoch 36: val_loss did not improve from 28.81627
196/196 - 80s - loss: 31.6693 - MinusLogProbMetric: 31.6693 - val_loss: 29.3178 - val_MinusLogProbMetric: 29.3178 - lr: 4.1152e-06 - 80s/epoch - 408ms/step
Epoch 37/1000
2023-09-21 04:27:29.477 
Epoch 37/1000 
	 loss: 28.9261, MinusLogProbMetric: 28.9261, val_loss: 28.8838, val_MinusLogProbMetric: 28.8838

Epoch 37: val_loss did not improve from 28.81627
196/196 - 80s - loss: 28.9261 - MinusLogProbMetric: 28.9261 - val_loss: 28.8838 - val_MinusLogProbMetric: 28.8838 - lr: 4.1152e-06 - 80s/epoch - 408ms/step
Epoch 38/1000
2023-09-21 04:28:48.416 
Epoch 38/1000 
	 loss: 28.7510, MinusLogProbMetric: 28.7510, val_loss: 28.7284, val_MinusLogProbMetric: 28.7284

Epoch 38: val_loss improved from 28.81627 to 28.72842, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 84s - loss: 28.7510 - MinusLogProbMetric: 28.7510 - val_loss: 28.7284 - val_MinusLogProbMetric: 28.7284 - lr: 4.1152e-06 - 84s/epoch - 428ms/step
Epoch 39/1000
2023-09-21 04:30:13.388 
Epoch 39/1000 
	 loss: 28.6056, MinusLogProbMetric: 28.6056, val_loss: 28.6860, val_MinusLogProbMetric: 28.6860

Epoch 39: val_loss improved from 28.72842 to 28.68604, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 28.6056 - MinusLogProbMetric: 28.6056 - val_loss: 28.6860 - val_MinusLogProbMetric: 28.6860 - lr: 4.1152e-06 - 82s/epoch - 418ms/step
Epoch 40/1000
2023-09-21 04:31:34.077 
Epoch 40/1000 
	 loss: 28.5529, MinusLogProbMetric: 28.5529, val_loss: 28.5943, val_MinusLogProbMetric: 28.5943

Epoch 40: val_loss improved from 28.68604 to 28.59431, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 28.5529 - MinusLogProbMetric: 28.5529 - val_loss: 28.5943 - val_MinusLogProbMetric: 28.5943 - lr: 4.1152e-06 - 81s/epoch - 412ms/step
Epoch 41/1000
2023-09-21 04:32:55.177 
Epoch 41/1000 
	 loss: 43.7918, MinusLogProbMetric: 43.7918, val_loss: 36.6982, val_MinusLogProbMetric: 36.6982

Epoch 41: val_loss did not improve from 28.59431
196/196 - 79s - loss: 43.7918 - MinusLogProbMetric: 43.7918 - val_loss: 36.6982 - val_MinusLogProbMetric: 36.6982 - lr: 4.1152e-06 - 79s/epoch - 405ms/step
Epoch 42/1000
2023-09-21 04:34:15.186 
Epoch 42/1000 
	 loss: 34.5893, MinusLogProbMetric: 34.5893, val_loss: 32.0188, val_MinusLogProbMetric: 32.0188

Epoch 42: val_loss did not improve from 28.59431
196/196 - 80s - loss: 34.5893 - MinusLogProbMetric: 34.5893 - val_loss: 32.0188 - val_MinusLogProbMetric: 32.0188 - lr: 4.1152e-06 - 80s/epoch - 408ms/step
Epoch 43/1000
2023-09-21 04:35:34.789 
Epoch 43/1000 
	 loss: 31.6028, MinusLogProbMetric: 31.6028, val_loss: 30.5631, val_MinusLogProbMetric: 30.5631

Epoch 43: val_loss did not improve from 28.59431
196/196 - 80s - loss: 31.6028 - MinusLogProbMetric: 31.6028 - val_loss: 30.5631 - val_MinusLogProbMetric: 30.5631 - lr: 4.1152e-06 - 80s/epoch - 406ms/step
Epoch 44/1000
2023-09-21 04:36:53.850 
Epoch 44/1000 
	 loss: 31.5722, MinusLogProbMetric: 31.5722, val_loss: 29.8010, val_MinusLogProbMetric: 29.8010

Epoch 44: val_loss did not improve from 28.59431
196/196 - 79s - loss: 31.5722 - MinusLogProbMetric: 31.5722 - val_loss: 29.8010 - val_MinusLogProbMetric: 29.8010 - lr: 4.1152e-06 - 79s/epoch - 403ms/step
Epoch 45/1000
2023-09-21 04:38:12.825 
Epoch 45/1000 
	 loss: 29.5927, MinusLogProbMetric: 29.5927, val_loss: 29.2483, val_MinusLogProbMetric: 29.2483

Epoch 45: val_loss did not improve from 28.59431
196/196 - 79s - loss: 29.5927 - MinusLogProbMetric: 29.5927 - val_loss: 29.2483 - val_MinusLogProbMetric: 29.2483 - lr: 4.1152e-06 - 79s/epoch - 403ms/step
Epoch 46/1000
2023-09-21 04:39:32.370 
Epoch 46/1000 
	 loss: 29.3840, MinusLogProbMetric: 29.3840, val_loss: 29.0288, val_MinusLogProbMetric: 29.0288

Epoch 46: val_loss did not improve from 28.59431
196/196 - 80s - loss: 29.3840 - MinusLogProbMetric: 29.3840 - val_loss: 29.0288 - val_MinusLogProbMetric: 29.0288 - lr: 4.1152e-06 - 80s/epoch - 406ms/step
Epoch 47/1000
2023-09-21 04:40:52.457 
Epoch 47/1000 
	 loss: 28.7353, MinusLogProbMetric: 28.7353, val_loss: 28.6858, val_MinusLogProbMetric: 28.6858

Epoch 47: val_loss did not improve from 28.59431
196/196 - 80s - loss: 28.7353 - MinusLogProbMetric: 28.7353 - val_loss: 28.6858 - val_MinusLogProbMetric: 28.6858 - lr: 4.1152e-06 - 80s/epoch - 409ms/step
Epoch 48/1000
2023-09-21 04:42:11.939 
Epoch 48/1000 
	 loss: 28.5556, MinusLogProbMetric: 28.5556, val_loss: 28.6154, val_MinusLogProbMetric: 28.6154

Epoch 48: val_loss did not improve from 28.59431
196/196 - 79s - loss: 28.5556 - MinusLogProbMetric: 28.5556 - val_loss: 28.6154 - val_MinusLogProbMetric: 28.6154 - lr: 4.1152e-06 - 79s/epoch - 406ms/step
Epoch 49/1000
2023-09-21 04:43:31.728 
Epoch 49/1000 
	 loss: 28.4905, MinusLogProbMetric: 28.4905, val_loss: 28.6081, val_MinusLogProbMetric: 28.6081

Epoch 49: val_loss did not improve from 28.59431
196/196 - 80s - loss: 28.4905 - MinusLogProbMetric: 28.4905 - val_loss: 28.6081 - val_MinusLogProbMetric: 28.6081 - lr: 4.1152e-06 - 80s/epoch - 407ms/step
Epoch 50/1000
2023-09-21 04:44:51.114 
Epoch 50/1000 
	 loss: 28.5580, MinusLogProbMetric: 28.5580, val_loss: 28.5602, val_MinusLogProbMetric: 28.5602

Epoch 50: val_loss improved from 28.59431 to 28.56017, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 28.5580 - MinusLogProbMetric: 28.5580 - val_loss: 28.5602 - val_MinusLogProbMetric: 28.5602 - lr: 4.1152e-06 - 81s/epoch - 414ms/step
Epoch 51/1000
2023-09-21 04:46:12.391 
Epoch 51/1000 
	 loss: 28.3954, MinusLogProbMetric: 28.3954, val_loss: 28.4395, val_MinusLogProbMetric: 28.4395

Epoch 51: val_loss improved from 28.56017 to 28.43954, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 28.3954 - MinusLogProbMetric: 28.3954 - val_loss: 28.4395 - val_MinusLogProbMetric: 28.4395 - lr: 4.1152e-06 - 81s/epoch - 413ms/step
Epoch 52/1000
2023-09-21 04:47:33.355 
Epoch 52/1000 
	 loss: 28.3898, MinusLogProbMetric: 28.3898, val_loss: 28.7030, val_MinusLogProbMetric: 28.7030

Epoch 52: val_loss did not improve from 28.43954
196/196 - 80s - loss: 28.3898 - MinusLogProbMetric: 28.3898 - val_loss: 28.7030 - val_MinusLogProbMetric: 28.7030 - lr: 4.1152e-06 - 80s/epoch - 406ms/step
Epoch 53/1000
2023-09-21 04:48:51.184 
Epoch 53/1000 
	 loss: 28.3217, MinusLogProbMetric: 28.3217, val_loss: 28.3727, val_MinusLogProbMetric: 28.3727

Epoch 53: val_loss improved from 28.43954 to 28.37270, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 28.3217 - MinusLogProbMetric: 28.3217 - val_loss: 28.3727 - val_MinusLogProbMetric: 28.3727 - lr: 4.1152e-06 - 80s/epoch - 408ms/step
Epoch 54/1000
2023-09-21 04:50:13.487 
Epoch 54/1000 
	 loss: 28.2699, MinusLogProbMetric: 28.2699, val_loss: 28.3672, val_MinusLogProbMetric: 28.3672

Epoch 54: val_loss improved from 28.37270 to 28.36722, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 28.2699 - MinusLogProbMetric: 28.2699 - val_loss: 28.3672 - val_MinusLogProbMetric: 28.3672 - lr: 4.1152e-06 - 82s/epoch - 417ms/step
Epoch 55/1000
2023-09-21 04:51:32.388 
Epoch 55/1000 
	 loss: 28.6861, MinusLogProbMetric: 28.6861, val_loss: 28.3518, val_MinusLogProbMetric: 28.3518

Epoch 55: val_loss improved from 28.36722 to 28.35181, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 79s - loss: 28.6861 - MinusLogProbMetric: 28.6861 - val_loss: 28.3518 - val_MinusLogProbMetric: 28.3518 - lr: 4.1152e-06 - 79s/epoch - 403ms/step
Epoch 56/1000
2023-09-21 04:52:53.506 
Epoch 56/1000 
	 loss: 28.2541, MinusLogProbMetric: 28.2541, val_loss: 28.7708, val_MinusLogProbMetric: 28.7708

Epoch 56: val_loss did not improve from 28.35181
196/196 - 79s - loss: 28.2541 - MinusLogProbMetric: 28.2541 - val_loss: 28.7708 - val_MinusLogProbMetric: 28.7708 - lr: 4.1152e-06 - 79s/epoch - 405ms/step
Epoch 57/1000
2023-09-21 04:54:13.522 
Epoch 57/1000 
	 loss: 28.2351, MinusLogProbMetric: 28.2351, val_loss: 28.2603, val_MinusLogProbMetric: 28.2603

Epoch 57: val_loss improved from 28.35181 to 28.26031, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 28.2351 - MinusLogProbMetric: 28.2351 - val_loss: 28.2603 - val_MinusLogProbMetric: 28.2603 - lr: 4.1152e-06 - 81s/epoch - 415ms/step
Epoch 58/1000
2023-09-21 04:55:33.902 
Epoch 58/1000 
	 loss: 28.6281, MinusLogProbMetric: 28.6281, val_loss: 28.2923, val_MinusLogProbMetric: 28.2923

Epoch 58: val_loss did not improve from 28.26031
196/196 - 79s - loss: 28.6281 - MinusLogProbMetric: 28.6281 - val_loss: 28.2923 - val_MinusLogProbMetric: 28.2923 - lr: 4.1152e-06 - 79s/epoch - 403ms/step
Epoch 59/1000
2023-09-21 04:56:53.543 
Epoch 59/1000 
	 loss: 28.1671, MinusLogProbMetric: 28.1671, val_loss: 28.2549, val_MinusLogProbMetric: 28.2549

Epoch 59: val_loss improved from 28.26031 to 28.25489, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 28.1671 - MinusLogProbMetric: 28.1671 - val_loss: 28.2549 - val_MinusLogProbMetric: 28.2549 - lr: 4.1152e-06 - 81s/epoch - 415ms/step
Epoch 60/1000
2023-09-21 04:58:13.327 
Epoch 60/1000 
	 loss: 28.1102, MinusLogProbMetric: 28.1102, val_loss: 28.2631, val_MinusLogProbMetric: 28.2631

Epoch 60: val_loss did not improve from 28.25489
196/196 - 78s - loss: 28.1102 - MinusLogProbMetric: 28.1102 - val_loss: 28.2631 - val_MinusLogProbMetric: 28.2631 - lr: 4.1152e-06 - 78s/epoch - 399ms/step
Epoch 61/1000
2023-09-21 04:59:31.989 
Epoch 61/1000 
	 loss: 44.1292, MinusLogProbMetric: 44.1292, val_loss: 60.3375, val_MinusLogProbMetric: 60.3375

Epoch 61: val_loss did not improve from 28.25489
196/196 - 79s - loss: 44.1292 - MinusLogProbMetric: 44.1292 - val_loss: 60.3375 - val_MinusLogProbMetric: 60.3375 - lr: 4.1152e-06 - 79s/epoch - 401ms/step
Epoch 62/1000
2023-09-21 05:00:51.185 
Epoch 62/1000 
	 loss: 56.1460, MinusLogProbMetric: 56.1460, val_loss: 107.0991, val_MinusLogProbMetric: 107.0991

Epoch 62: val_loss did not improve from 28.25489
196/196 - 79s - loss: 56.1460 - MinusLogProbMetric: 56.1460 - val_loss: 107.0991 - val_MinusLogProbMetric: 107.0991 - lr: 4.1152e-06 - 79s/epoch - 404ms/step
Epoch 63/1000
2023-09-21 05:02:10.281 
Epoch 63/1000 
	 loss: 72.0478, MinusLogProbMetric: 72.0478, val_loss: 60.9426, val_MinusLogProbMetric: 60.9426

Epoch 63: val_loss did not improve from 28.25489
196/196 - 79s - loss: 72.0478 - MinusLogProbMetric: 72.0478 - val_loss: 60.9426 - val_MinusLogProbMetric: 60.9426 - lr: 4.1152e-06 - 79s/epoch - 404ms/step
Epoch 64/1000
2023-09-21 05:03:29.688 
Epoch 64/1000 
	 loss: 56.6096, MinusLogProbMetric: 56.6096, val_loss: 54.0044, val_MinusLogProbMetric: 54.0044

Epoch 64: val_loss did not improve from 28.25489
196/196 - 79s - loss: 56.6096 - MinusLogProbMetric: 56.6096 - val_loss: 54.0044 - val_MinusLogProbMetric: 54.0044 - lr: 4.1152e-06 - 79s/epoch - 405ms/step
Epoch 65/1000
2023-09-21 05:04:49.475 
Epoch 65/1000 
	 loss: 54.9262, MinusLogProbMetric: 54.9262, val_loss: 53.2801, val_MinusLogProbMetric: 53.2801

Epoch 65: val_loss did not improve from 28.25489
196/196 - 80s - loss: 54.9262 - MinusLogProbMetric: 54.9262 - val_loss: 53.2801 - val_MinusLogProbMetric: 53.2801 - lr: 4.1152e-06 - 80s/epoch - 407ms/step
Epoch 66/1000
2023-09-21 05:06:08.817 
Epoch 66/1000 
	 loss: 48.3900, MinusLogProbMetric: 48.3900, val_loss: 46.4884, val_MinusLogProbMetric: 46.4884

Epoch 66: val_loss did not improve from 28.25489
196/196 - 79s - loss: 48.3900 - MinusLogProbMetric: 48.3900 - val_loss: 46.4884 - val_MinusLogProbMetric: 46.4884 - lr: 4.1152e-06 - 79s/epoch - 405ms/step
Epoch 67/1000
2023-09-21 05:07:27.971 
Epoch 67/1000 
	 loss: 45.2786, MinusLogProbMetric: 45.2786, val_loss: 44.2252, val_MinusLogProbMetric: 44.2252

Epoch 67: val_loss did not improve from 28.25489
196/196 - 79s - loss: 45.2786 - MinusLogProbMetric: 45.2786 - val_loss: 44.2252 - val_MinusLogProbMetric: 44.2252 - lr: 4.1152e-06 - 79s/epoch - 404ms/step
Epoch 68/1000
2023-09-21 05:08:47.248 
Epoch 68/1000 
	 loss: 43.4492, MinusLogProbMetric: 43.4492, val_loss: 42.2075, val_MinusLogProbMetric: 42.2075

Epoch 68: val_loss did not improve from 28.25489
196/196 - 79s - loss: 43.4492 - MinusLogProbMetric: 43.4492 - val_loss: 42.2075 - val_MinusLogProbMetric: 42.2075 - lr: 4.1152e-06 - 79s/epoch - 404ms/step
Epoch 69/1000
2023-09-21 05:10:04.686 
Epoch 69/1000 
	 loss: 41.1032, MinusLogProbMetric: 41.1032, val_loss: 39.5166, val_MinusLogProbMetric: 39.5166

Epoch 69: val_loss did not improve from 28.25489
196/196 - 77s - loss: 41.1032 - MinusLogProbMetric: 41.1032 - val_loss: 39.5166 - val_MinusLogProbMetric: 39.5166 - lr: 4.1152e-06 - 77s/epoch - 395ms/step
Epoch 70/1000
2023-09-21 05:11:23.182 
Epoch 70/1000 
	 loss: 38.2095, MinusLogProbMetric: 38.2095, val_loss: 37.7125, val_MinusLogProbMetric: 37.7125

Epoch 70: val_loss did not improve from 28.25489
196/196 - 78s - loss: 38.2095 - MinusLogProbMetric: 38.2095 - val_loss: 37.7125 - val_MinusLogProbMetric: 37.7125 - lr: 4.1152e-06 - 78s/epoch - 400ms/step
Epoch 71/1000
2023-09-21 05:12:41.523 
Epoch 71/1000 
	 loss: 37.6751, MinusLogProbMetric: 37.6751, val_loss: 36.8225, val_MinusLogProbMetric: 36.8225

Epoch 71: val_loss did not improve from 28.25489
196/196 - 78s - loss: 37.6751 - MinusLogProbMetric: 37.6751 - val_loss: 36.8225 - val_MinusLogProbMetric: 36.8225 - lr: 4.1152e-06 - 78s/epoch - 400ms/step
Epoch 72/1000
2023-09-21 05:14:00.054 
Epoch 72/1000 
	 loss: 36.1157, MinusLogProbMetric: 36.1157, val_loss: 36.0131, val_MinusLogProbMetric: 36.0131

Epoch 72: val_loss did not improve from 28.25489
196/196 - 79s - loss: 36.1157 - MinusLogProbMetric: 36.1157 - val_loss: 36.0131 - val_MinusLogProbMetric: 36.0131 - lr: 4.1152e-06 - 79s/epoch - 401ms/step
Epoch 73/1000
2023-09-21 05:15:18.126 
Epoch 73/1000 
	 loss: 35.2434, MinusLogProbMetric: 35.2434, val_loss: 34.8127, val_MinusLogProbMetric: 34.8127

Epoch 73: val_loss did not improve from 28.25489
196/196 - 78s - loss: 35.2434 - MinusLogProbMetric: 35.2434 - val_loss: 34.8127 - val_MinusLogProbMetric: 34.8127 - lr: 4.1152e-06 - 78s/epoch - 398ms/step
Epoch 74/1000
2023-09-21 05:16:36.934 
Epoch 74/1000 
	 loss: 34.1203, MinusLogProbMetric: 34.1203, val_loss: 33.5282, val_MinusLogProbMetric: 33.5282

Epoch 74: val_loss did not improve from 28.25489
196/196 - 79s - loss: 34.1203 - MinusLogProbMetric: 34.1203 - val_loss: 33.5282 - val_MinusLogProbMetric: 33.5282 - lr: 4.1152e-06 - 79s/epoch - 402ms/step
Epoch 75/1000
2023-09-21 05:17:56.288 
Epoch 75/1000 
	 loss: 32.8325, MinusLogProbMetric: 32.8325, val_loss: 32.4651, val_MinusLogProbMetric: 32.4651

Epoch 75: val_loss did not improve from 28.25489
196/196 - 79s - loss: 32.8325 - MinusLogProbMetric: 32.8325 - val_loss: 32.4651 - val_MinusLogProbMetric: 32.4651 - lr: 4.1152e-06 - 79s/epoch - 405ms/step
Epoch 76/1000
2023-09-21 05:19:15.439 
Epoch 76/1000 
	 loss: 32.0339, MinusLogProbMetric: 32.0339, val_loss: 31.9546, val_MinusLogProbMetric: 31.9546

Epoch 76: val_loss did not improve from 28.25489
196/196 - 79s - loss: 32.0339 - MinusLogProbMetric: 32.0339 - val_loss: 31.9546 - val_MinusLogProbMetric: 31.9546 - lr: 4.1152e-06 - 79s/epoch - 404ms/step
Epoch 77/1000
2023-09-21 05:20:34.406 
Epoch 77/1000 
	 loss: 32.0054, MinusLogProbMetric: 32.0054, val_loss: 31.6392, val_MinusLogProbMetric: 31.6392

Epoch 77: val_loss did not improve from 28.25489
196/196 - 79s - loss: 32.0054 - MinusLogProbMetric: 32.0054 - val_loss: 31.6392 - val_MinusLogProbMetric: 31.6392 - lr: 4.1152e-06 - 79s/epoch - 403ms/step
Epoch 78/1000
2023-09-21 05:21:53.495 
Epoch 78/1000 
	 loss: 31.3576, MinusLogProbMetric: 31.3576, val_loss: 31.2946, val_MinusLogProbMetric: 31.2946

Epoch 78: val_loss did not improve from 28.25489
196/196 - 79s - loss: 31.3576 - MinusLogProbMetric: 31.3576 - val_loss: 31.2946 - val_MinusLogProbMetric: 31.2946 - lr: 4.1152e-06 - 79s/epoch - 403ms/step
Epoch 79/1000
2023-09-21 05:23:12.200 
Epoch 79/1000 
	 loss: 31.0606, MinusLogProbMetric: 31.0606, val_loss: 31.0280, val_MinusLogProbMetric: 31.0280

Epoch 79: val_loss did not improve from 28.25489
196/196 - 79s - loss: 31.0606 - MinusLogProbMetric: 31.0606 - val_loss: 31.0280 - val_MinusLogProbMetric: 31.0280 - lr: 4.1152e-06 - 79s/epoch - 402ms/step
Epoch 80/1000
2023-09-21 05:24:31.817 
Epoch 80/1000 
	 loss: 30.8078, MinusLogProbMetric: 30.8078, val_loss: 30.8497, val_MinusLogProbMetric: 30.8497

Epoch 80: val_loss did not improve from 28.25489
196/196 - 80s - loss: 30.8078 - MinusLogProbMetric: 30.8078 - val_loss: 30.8497 - val_MinusLogProbMetric: 30.8497 - lr: 4.1152e-06 - 80s/epoch - 406ms/step
Epoch 81/1000
2023-09-21 05:25:51.300 
Epoch 81/1000 
	 loss: 30.6040, MinusLogProbMetric: 30.6040, val_loss: 30.6220, val_MinusLogProbMetric: 30.6220

Epoch 81: val_loss did not improve from 28.25489
196/196 - 79s - loss: 30.6040 - MinusLogProbMetric: 30.6040 - val_loss: 30.6220 - val_MinusLogProbMetric: 30.6220 - lr: 4.1152e-06 - 79s/epoch - 405ms/step
Epoch 82/1000
2023-09-21 05:27:10.116 
Epoch 82/1000 
	 loss: 30.6422, MinusLogProbMetric: 30.6422, val_loss: 30.4663, val_MinusLogProbMetric: 30.4663

Epoch 82: val_loss did not improve from 28.25489
196/196 - 79s - loss: 30.6422 - MinusLogProbMetric: 30.6422 - val_loss: 30.4663 - val_MinusLogProbMetric: 30.4663 - lr: 4.1152e-06 - 79s/epoch - 402ms/step
Epoch 83/1000
2023-09-21 05:28:29.066 
Epoch 83/1000 
	 loss: 30.2818, MinusLogProbMetric: 30.2818, val_loss: 30.3239, val_MinusLogProbMetric: 30.3239

Epoch 83: val_loss did not improve from 28.25489
196/196 - 79s - loss: 30.2818 - MinusLogProbMetric: 30.2818 - val_loss: 30.3239 - val_MinusLogProbMetric: 30.3239 - lr: 4.1152e-06 - 79s/epoch - 403ms/step
Epoch 84/1000
2023-09-21 05:29:48.368 
Epoch 84/1000 
	 loss: 30.0993, MinusLogProbMetric: 30.0993, val_loss: 30.1172, val_MinusLogProbMetric: 30.1172

Epoch 84: val_loss did not improve from 28.25489
196/196 - 79s - loss: 30.0993 - MinusLogProbMetric: 30.0993 - val_loss: 30.1172 - val_MinusLogProbMetric: 30.1172 - lr: 4.1152e-06 - 79s/epoch - 405ms/step
Epoch 85/1000
2023-09-21 05:31:07.288 
Epoch 85/1000 
	 loss: 29.8963, MinusLogProbMetric: 29.8963, val_loss: 29.8759, val_MinusLogProbMetric: 29.8759

Epoch 85: val_loss did not improve from 28.25489
196/196 - 79s - loss: 29.8963 - MinusLogProbMetric: 29.8963 - val_loss: 29.8759 - val_MinusLogProbMetric: 29.8759 - lr: 4.1152e-06 - 79s/epoch - 403ms/step
Epoch 86/1000
2023-09-21 05:32:25.637 
Epoch 86/1000 
	 loss: 29.6054, MinusLogProbMetric: 29.6054, val_loss: 29.5555, val_MinusLogProbMetric: 29.5555

Epoch 86: val_loss did not improve from 28.25489
196/196 - 78s - loss: 29.6054 - MinusLogProbMetric: 29.6054 - val_loss: 29.5555 - val_MinusLogProbMetric: 29.5555 - lr: 4.1152e-06 - 78s/epoch - 400ms/step
Epoch 87/1000
2023-09-21 05:33:44.479 
Epoch 87/1000 
	 loss: 29.3708, MinusLogProbMetric: 29.3708, val_loss: 29.3813, val_MinusLogProbMetric: 29.3813

Epoch 87: val_loss did not improve from 28.25489
196/196 - 79s - loss: 29.3708 - MinusLogProbMetric: 29.3708 - val_loss: 29.3813 - val_MinusLogProbMetric: 29.3813 - lr: 4.1152e-06 - 79s/epoch - 402ms/step
Epoch 88/1000
2023-09-21 05:35:03.953 
Epoch 88/1000 
	 loss: 29.2016, MinusLogProbMetric: 29.2016, val_loss: 29.3063, val_MinusLogProbMetric: 29.3063

Epoch 88: val_loss did not improve from 28.25489
196/196 - 79s - loss: 29.2016 - MinusLogProbMetric: 29.2016 - val_loss: 29.3063 - val_MinusLogProbMetric: 29.3063 - lr: 4.1152e-06 - 79s/epoch - 405ms/step
Epoch 89/1000
2023-09-21 05:36:23.679 
Epoch 89/1000 
	 loss: 29.0650, MinusLogProbMetric: 29.0650, val_loss: 29.1081, val_MinusLogProbMetric: 29.1081

Epoch 89: val_loss did not improve from 28.25489
196/196 - 80s - loss: 29.0650 - MinusLogProbMetric: 29.0650 - val_loss: 29.1081 - val_MinusLogProbMetric: 29.1081 - lr: 4.1152e-06 - 80s/epoch - 407ms/step
Epoch 90/1000
2023-09-21 05:37:42.908 
Epoch 90/1000 
	 loss: 28.9298, MinusLogProbMetric: 28.9298, val_loss: 29.0161, val_MinusLogProbMetric: 29.0161

Epoch 90: val_loss did not improve from 28.25489
196/196 - 79s - loss: 28.9298 - MinusLogProbMetric: 28.9298 - val_loss: 29.0161 - val_MinusLogProbMetric: 29.0161 - lr: 4.1152e-06 - 79s/epoch - 404ms/step
Epoch 91/1000
2023-09-21 05:39:01.016 
Epoch 91/1000 
	 loss: 28.8323, MinusLogProbMetric: 28.8323, val_loss: 28.8449, val_MinusLogProbMetric: 28.8449

Epoch 91: val_loss did not improve from 28.25489
196/196 - 78s - loss: 28.8323 - MinusLogProbMetric: 28.8323 - val_loss: 28.8449 - val_MinusLogProbMetric: 28.8449 - lr: 4.1152e-06 - 78s/epoch - 398ms/step
Epoch 92/1000
2023-09-21 05:40:20.090 
Epoch 92/1000 
	 loss: 28.7185, MinusLogProbMetric: 28.7185, val_loss: 28.7694, val_MinusLogProbMetric: 28.7694

Epoch 92: val_loss did not improve from 28.25489
196/196 - 79s - loss: 28.7185 - MinusLogProbMetric: 28.7185 - val_loss: 28.7694 - val_MinusLogProbMetric: 28.7694 - lr: 4.1152e-06 - 79s/epoch - 403ms/step
Epoch 93/1000
2023-09-21 05:41:38.851 
Epoch 93/1000 
	 loss: 28.6884, MinusLogProbMetric: 28.6884, val_loss: 28.7742, val_MinusLogProbMetric: 28.7742

Epoch 93: val_loss did not improve from 28.25489
196/196 - 79s - loss: 28.6884 - MinusLogProbMetric: 28.6884 - val_loss: 28.7742 - val_MinusLogProbMetric: 28.7742 - lr: 4.1152e-06 - 79s/epoch - 402ms/step
Epoch 94/1000
2023-09-21 05:42:58.024 
Epoch 94/1000 
	 loss: 32.4698, MinusLogProbMetric: 32.4698, val_loss: 30.3911, val_MinusLogProbMetric: 30.3911

Epoch 94: val_loss did not improve from 28.25489
196/196 - 79s - loss: 32.4698 - MinusLogProbMetric: 32.4698 - val_loss: 30.3911 - val_MinusLogProbMetric: 30.3911 - lr: 4.1152e-06 - 79s/epoch - 404ms/step
Epoch 95/1000
2023-09-21 05:44:17.244 
Epoch 95/1000 
	 loss: 28.8105, MinusLogProbMetric: 28.8105, val_loss: 28.6853, val_MinusLogProbMetric: 28.6853

Epoch 95: val_loss did not improve from 28.25489
196/196 - 79s - loss: 28.8105 - MinusLogProbMetric: 28.8105 - val_loss: 28.6853 - val_MinusLogProbMetric: 28.6853 - lr: 4.1152e-06 - 79s/epoch - 404ms/step
Epoch 96/1000
2023-09-21 05:45:34.722 
Epoch 96/1000 
	 loss: 28.6241, MinusLogProbMetric: 28.6241, val_loss: 28.6018, val_MinusLogProbMetric: 28.6018

Epoch 96: val_loss did not improve from 28.25489
196/196 - 77s - loss: 28.6241 - MinusLogProbMetric: 28.6241 - val_loss: 28.6018 - val_MinusLogProbMetric: 28.6018 - lr: 4.1152e-06 - 77s/epoch - 395ms/step
Epoch 97/1000
2023-09-21 05:46:53.810 
Epoch 97/1000 
	 loss: 28.4528, MinusLogProbMetric: 28.4528, val_loss: 28.5478, val_MinusLogProbMetric: 28.5478

Epoch 97: val_loss did not improve from 28.25489
196/196 - 79s - loss: 28.4528 - MinusLogProbMetric: 28.4528 - val_loss: 28.5478 - val_MinusLogProbMetric: 28.5478 - lr: 4.1152e-06 - 79s/epoch - 403ms/step
Epoch 98/1000
2023-09-21 05:48:11.650 
Epoch 98/1000 
	 loss: 28.4515, MinusLogProbMetric: 28.4515, val_loss: 28.4891, val_MinusLogProbMetric: 28.4891

Epoch 98: val_loss did not improve from 28.25489
196/196 - 78s - loss: 28.4515 - MinusLogProbMetric: 28.4515 - val_loss: 28.4891 - val_MinusLogProbMetric: 28.4891 - lr: 4.1152e-06 - 78s/epoch - 397ms/step
Epoch 99/1000
2023-09-21 05:49:30.331 
Epoch 99/1000 
	 loss: 28.4878, MinusLogProbMetric: 28.4878, val_loss: 28.4798, val_MinusLogProbMetric: 28.4798

Epoch 99: val_loss did not improve from 28.25489
196/196 - 79s - loss: 28.4878 - MinusLogProbMetric: 28.4878 - val_loss: 28.4798 - val_MinusLogProbMetric: 28.4798 - lr: 4.1152e-06 - 79s/epoch - 401ms/step
Epoch 100/1000
2023-09-21 05:50:48.577 
Epoch 100/1000 
	 loss: 28.3336, MinusLogProbMetric: 28.3336, val_loss: 28.4256, val_MinusLogProbMetric: 28.4256

Epoch 100: val_loss did not improve from 28.25489
196/196 - 78s - loss: 28.3336 - MinusLogProbMetric: 28.3336 - val_loss: 28.4256 - val_MinusLogProbMetric: 28.4256 - lr: 4.1152e-06 - 78s/epoch - 399ms/step
Epoch 101/1000
2023-09-21 05:52:07.390 
Epoch 101/1000 
	 loss: 28.3091, MinusLogProbMetric: 28.3091, val_loss: 28.3873, val_MinusLogProbMetric: 28.3873

Epoch 101: val_loss did not improve from 28.25489
196/196 - 79s - loss: 28.3091 - MinusLogProbMetric: 28.3091 - val_loss: 28.3873 - val_MinusLogProbMetric: 28.3873 - lr: 4.1152e-06 - 79s/epoch - 402ms/step
Epoch 102/1000
2023-09-21 05:53:26.544 
Epoch 102/1000 
	 loss: 28.2700, MinusLogProbMetric: 28.2700, val_loss: 28.3661, val_MinusLogProbMetric: 28.3661

Epoch 102: val_loss did not improve from 28.25489
196/196 - 79s - loss: 28.2700 - MinusLogProbMetric: 28.2700 - val_loss: 28.3661 - val_MinusLogProbMetric: 28.3661 - lr: 4.1152e-06 - 79s/epoch - 404ms/step
Epoch 103/1000
2023-09-21 05:54:45.214 
Epoch 103/1000 
	 loss: 28.2249, MinusLogProbMetric: 28.2249, val_loss: 28.3272, val_MinusLogProbMetric: 28.3272

Epoch 103: val_loss did not improve from 28.25489
196/196 - 79s - loss: 28.2249 - MinusLogProbMetric: 28.2249 - val_loss: 28.3272 - val_MinusLogProbMetric: 28.3272 - lr: 4.1152e-06 - 79s/epoch - 401ms/step
Epoch 104/1000
2023-09-21 05:56:05.009 
Epoch 104/1000 
	 loss: 33.8108, MinusLogProbMetric: 33.8108, val_loss: 30.3203, val_MinusLogProbMetric: 30.3203

Epoch 104: val_loss did not improve from 28.25489
196/196 - 80s - loss: 33.8108 - MinusLogProbMetric: 33.8108 - val_loss: 30.3203 - val_MinusLogProbMetric: 30.3203 - lr: 4.1152e-06 - 80s/epoch - 407ms/step
Epoch 105/1000
2023-09-21 05:57:22.703 
Epoch 105/1000 
	 loss: 28.4895, MinusLogProbMetric: 28.4895, val_loss: 28.3698, val_MinusLogProbMetric: 28.3698

Epoch 105: val_loss did not improve from 28.25489
196/196 - 78s - loss: 28.4895 - MinusLogProbMetric: 28.4895 - val_loss: 28.3698 - val_MinusLogProbMetric: 28.3698 - lr: 4.1152e-06 - 78s/epoch - 396ms/step
Epoch 106/1000
2023-09-21 05:58:41.286 
Epoch 106/1000 
	 loss: 28.2290, MinusLogProbMetric: 28.2290, val_loss: 28.2882, val_MinusLogProbMetric: 28.2882

Epoch 106: val_loss did not improve from 28.25489
196/196 - 79s - loss: 28.2290 - MinusLogProbMetric: 28.2290 - val_loss: 28.2882 - val_MinusLogProbMetric: 28.2882 - lr: 4.1152e-06 - 79s/epoch - 401ms/step
Epoch 107/1000
2023-09-21 05:59:59.611 
Epoch 107/1000 
	 loss: 29.7843, MinusLogProbMetric: 29.7843, val_loss: 39.4660, val_MinusLogProbMetric: 39.4660

Epoch 107: val_loss did not improve from 28.25489
196/196 - 78s - loss: 29.7843 - MinusLogProbMetric: 29.7843 - val_loss: 39.4660 - val_MinusLogProbMetric: 39.4660 - lr: 4.1152e-06 - 78s/epoch - 400ms/step
Epoch 108/1000
2023-09-21 06:01:18.772 
Epoch 108/1000 
	 loss: 29.2870, MinusLogProbMetric: 29.2870, val_loss: 28.3337, val_MinusLogProbMetric: 28.3337

Epoch 108: val_loss did not improve from 28.25489
196/196 - 79s - loss: 29.2870 - MinusLogProbMetric: 29.2870 - val_loss: 28.3337 - val_MinusLogProbMetric: 28.3337 - lr: 4.1152e-06 - 79s/epoch - 404ms/step
Epoch 109/1000
2023-09-21 06:02:37.610 
Epoch 109/1000 
	 loss: 28.2673, MinusLogProbMetric: 28.2673, val_loss: 28.5907, val_MinusLogProbMetric: 28.5907

Epoch 109: val_loss did not improve from 28.25489
196/196 - 79s - loss: 28.2673 - MinusLogProbMetric: 28.2673 - val_loss: 28.5907 - val_MinusLogProbMetric: 28.5907 - lr: 4.1152e-06 - 79s/epoch - 402ms/step
Epoch 110/1000
2023-09-21 06:03:56.132 
Epoch 110/1000 
	 loss: 28.1719, MinusLogProbMetric: 28.1719, val_loss: 28.2305, val_MinusLogProbMetric: 28.2305

Epoch 110: val_loss improved from 28.25489 to 28.23045, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 28.1719 - MinusLogProbMetric: 28.1719 - val_loss: 28.2305 - val_MinusLogProbMetric: 28.2305 - lr: 2.0576e-06 - 82s/epoch - 417ms/step
Epoch 111/1000
2023-09-21 06:05:17.561 
Epoch 111/1000 
	 loss: 28.0884, MinusLogProbMetric: 28.0884, val_loss: 28.1946, val_MinusLogProbMetric: 28.1946

Epoch 111: val_loss improved from 28.23045 to 28.19463, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 28.0884 - MinusLogProbMetric: 28.0884 - val_loss: 28.1946 - val_MinusLogProbMetric: 28.1946 - lr: 2.0576e-06 - 82s/epoch - 420ms/step
Epoch 112/1000
2023-09-21 06:06:39.637 
Epoch 112/1000 
	 loss: 28.0624, MinusLogProbMetric: 28.0624, val_loss: 28.1719, val_MinusLogProbMetric: 28.1719

Epoch 112: val_loss improved from 28.19463 to 28.17192, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 28.0624 - MinusLogProbMetric: 28.0624 - val_loss: 28.1719 - val_MinusLogProbMetric: 28.1719 - lr: 2.0576e-06 - 80s/epoch - 406ms/step
Epoch 113/1000
2023-09-21 06:07:59.930 
Epoch 113/1000 
	 loss: 28.0442, MinusLogProbMetric: 28.0442, val_loss: 28.1621, val_MinusLogProbMetric: 28.1621

Epoch 113: val_loss improved from 28.17192 to 28.16207, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 28.0442 - MinusLogProbMetric: 28.0442 - val_loss: 28.1621 - val_MinusLogProbMetric: 28.1621 - lr: 2.0576e-06 - 80s/epoch - 410ms/step
Epoch 114/1000
2023-09-21 06:09:20.260 
Epoch 114/1000 
	 loss: 28.0294, MinusLogProbMetric: 28.0294, val_loss: 28.1597, val_MinusLogProbMetric: 28.1597

Epoch 114: val_loss improved from 28.16207 to 28.15975, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 28.0294 - MinusLogProbMetric: 28.0294 - val_loss: 28.1597 - val_MinusLogProbMetric: 28.1597 - lr: 2.0576e-06 - 80s/epoch - 409ms/step
Epoch 115/1000
2023-09-21 06:10:39.473 
Epoch 115/1000 
	 loss: 28.0315, MinusLogProbMetric: 28.0315, val_loss: 28.1145, val_MinusLogProbMetric: 28.1145

Epoch 115: val_loss improved from 28.15975 to 28.11447, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 28.0315 - MinusLogProbMetric: 28.0315 - val_loss: 28.1145 - val_MinusLogProbMetric: 28.1145 - lr: 2.0576e-06 - 80s/epoch - 408ms/step
Epoch 116/1000
2023-09-21 06:11:59.350 
Epoch 116/1000 
	 loss: 27.9958, MinusLogProbMetric: 27.9958, val_loss: 28.1058, val_MinusLogProbMetric: 28.1058

Epoch 116: val_loss improved from 28.11447 to 28.10581, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 79s - loss: 27.9958 - MinusLogProbMetric: 27.9958 - val_loss: 28.1058 - val_MinusLogProbMetric: 28.1058 - lr: 2.0576e-06 - 79s/epoch - 405ms/step
Epoch 117/1000
2023-09-21 06:13:19.136 
Epoch 117/1000 
	 loss: 27.9785, MinusLogProbMetric: 27.9785, val_loss: 28.0971, val_MinusLogProbMetric: 28.0971

Epoch 117: val_loss improved from 28.10581 to 28.09707, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 79s - loss: 27.9785 - MinusLogProbMetric: 27.9785 - val_loss: 28.0971 - val_MinusLogProbMetric: 28.0971 - lr: 2.0576e-06 - 79s/epoch - 405ms/step
Epoch 118/1000
2023-09-21 06:14:39.600 
Epoch 118/1000 
	 loss: 27.9679, MinusLogProbMetric: 27.9679, val_loss: 28.0856, val_MinusLogProbMetric: 28.0856

Epoch 118: val_loss improved from 28.09707 to 28.08562, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 27.9679 - MinusLogProbMetric: 27.9679 - val_loss: 28.0856 - val_MinusLogProbMetric: 28.0856 - lr: 2.0576e-06 - 81s/epoch - 411ms/step
Epoch 119/1000
2023-09-21 06:15:59.633 
Epoch 119/1000 
	 loss: 27.9574, MinusLogProbMetric: 27.9574, val_loss: 28.0616, val_MinusLogProbMetric: 28.0616

Epoch 119: val_loss improved from 28.08562 to 28.06157, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.9574 - MinusLogProbMetric: 27.9574 - val_loss: 28.0616 - val_MinusLogProbMetric: 28.0616 - lr: 2.0576e-06 - 80s/epoch - 410ms/step
Epoch 120/1000
2023-09-21 06:17:20.076 
Epoch 120/1000 
	 loss: 27.9421, MinusLogProbMetric: 27.9421, val_loss: 28.1049, val_MinusLogProbMetric: 28.1049

Epoch 120: val_loss did not improve from 28.06157
196/196 - 79s - loss: 27.9421 - MinusLogProbMetric: 27.9421 - val_loss: 28.1049 - val_MinusLogProbMetric: 28.1049 - lr: 2.0576e-06 - 79s/epoch - 402ms/step
Epoch 121/1000
2023-09-21 06:18:38.982 
Epoch 121/1000 
	 loss: 27.9372, MinusLogProbMetric: 27.9372, val_loss: 28.0496, val_MinusLogProbMetric: 28.0496

Epoch 121: val_loss improved from 28.06157 to 28.04956, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 27.9372 - MinusLogProbMetric: 27.9372 - val_loss: 28.0496 - val_MinusLogProbMetric: 28.0496 - lr: 2.0576e-06 - 81s/epoch - 415ms/step
Epoch 122/1000
2023-09-21 06:20:00.514 
Epoch 122/1000 
	 loss: 27.9311, MinusLogProbMetric: 27.9311, val_loss: 28.0347, val_MinusLogProbMetric: 28.0347

Epoch 122: val_loss improved from 28.04956 to 28.03467, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.9311 - MinusLogProbMetric: 27.9311 - val_loss: 28.0347 - val_MinusLogProbMetric: 28.0347 - lr: 2.0576e-06 - 80s/epoch - 410ms/step
Epoch 123/1000
2023-09-21 06:21:20.555 
Epoch 123/1000 
	 loss: 27.9146, MinusLogProbMetric: 27.9146, val_loss: 28.0454, val_MinusLogProbMetric: 28.0454

Epoch 123: val_loss did not improve from 28.03467
196/196 - 79s - loss: 27.9146 - MinusLogProbMetric: 27.9146 - val_loss: 28.0454 - val_MinusLogProbMetric: 28.0454 - lr: 2.0576e-06 - 79s/epoch - 401ms/step
Epoch 124/1000
2023-09-21 06:22:38.790 
Epoch 124/1000 
	 loss: 28.2520, MinusLogProbMetric: 28.2520, val_loss: 28.2273, val_MinusLogProbMetric: 28.2273

Epoch 124: val_loss did not improve from 28.03467
196/196 - 78s - loss: 28.2520 - MinusLogProbMetric: 28.2520 - val_loss: 28.2273 - val_MinusLogProbMetric: 28.2273 - lr: 2.0576e-06 - 78s/epoch - 399ms/step
Epoch 125/1000
2023-09-21 06:23:57.750 
Epoch 125/1000 
	 loss: 27.9296, MinusLogProbMetric: 27.9296, val_loss: 28.0033, val_MinusLogProbMetric: 28.0033

Epoch 125: val_loss improved from 28.03467 to 28.00326, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.9296 - MinusLogProbMetric: 27.9296 - val_loss: 28.0033 - val_MinusLogProbMetric: 28.0033 - lr: 2.0576e-06 - 80s/epoch - 410ms/step
Epoch 126/1000
2023-09-21 06:25:17.982 
Epoch 126/1000 
	 loss: 27.9500, MinusLogProbMetric: 27.9500, val_loss: 28.0241, val_MinusLogProbMetric: 28.0241

Epoch 126: val_loss did not improve from 28.00326
196/196 - 79s - loss: 27.9500 - MinusLogProbMetric: 27.9500 - val_loss: 28.0241 - val_MinusLogProbMetric: 28.0241 - lr: 2.0576e-06 - 79s/epoch - 402ms/step
Epoch 127/1000
2023-09-21 06:26:36.488 
Epoch 127/1000 
	 loss: 27.8797, MinusLogProbMetric: 27.8797, val_loss: 27.9935, val_MinusLogProbMetric: 27.9935

Epoch 127: val_loss improved from 28.00326 to 27.99347, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.8797 - MinusLogProbMetric: 27.8797 - val_loss: 27.9935 - val_MinusLogProbMetric: 27.9935 - lr: 2.0576e-06 - 80s/epoch - 410ms/step
Epoch 128/1000
2023-09-21 06:27:57.019 
Epoch 128/1000 
	 loss: 27.8649, MinusLogProbMetric: 27.8649, val_loss: 27.9721, val_MinusLogProbMetric: 27.9721

Epoch 128: val_loss improved from 27.99347 to 27.97211, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.8649 - MinusLogProbMetric: 27.8649 - val_loss: 27.9721 - val_MinusLogProbMetric: 27.9721 - lr: 2.0576e-06 - 80s/epoch - 409ms/step
Epoch 129/1000
2023-09-21 06:29:18.039 
Epoch 129/1000 
	 loss: 27.8460, MinusLogProbMetric: 27.8460, val_loss: 27.9563, val_MinusLogProbMetric: 27.9563

Epoch 129: val_loss improved from 27.97211 to 27.95626, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 27.8460 - MinusLogProbMetric: 27.8460 - val_loss: 27.9563 - val_MinusLogProbMetric: 27.9563 - lr: 2.0576e-06 - 81s/epoch - 412ms/step
Epoch 130/1000
2023-09-21 06:30:29.255 
Epoch 130/1000 
	 loss: 27.8331, MinusLogProbMetric: 27.8331, val_loss: 27.9599, val_MinusLogProbMetric: 27.9599

Epoch 130: val_loss did not improve from 27.95626
196/196 - 70s - loss: 27.8331 - MinusLogProbMetric: 27.8331 - val_loss: 27.9599 - val_MinusLogProbMetric: 27.9599 - lr: 2.0576e-06 - 70s/epoch - 356ms/step
Epoch 131/1000
2023-09-21 06:31:45.442 
Epoch 131/1000 
	 loss: 30.7386, MinusLogProbMetric: 30.7386, val_loss: 28.2227, val_MinusLogProbMetric: 28.2227

Epoch 131: val_loss did not improve from 27.95626
196/196 - 76s - loss: 30.7386 - MinusLogProbMetric: 30.7386 - val_loss: 28.2227 - val_MinusLogProbMetric: 28.2227 - lr: 2.0576e-06 - 76s/epoch - 389ms/step
Epoch 132/1000
2023-09-21 06:33:03.182 
Epoch 132/1000 
	 loss: 27.9261, MinusLogProbMetric: 27.9261, val_loss: 28.0801, val_MinusLogProbMetric: 28.0801

Epoch 132: val_loss did not improve from 27.95626
196/196 - 78s - loss: 27.9261 - MinusLogProbMetric: 27.9261 - val_loss: 28.0801 - val_MinusLogProbMetric: 28.0801 - lr: 2.0576e-06 - 78s/epoch - 397ms/step
Epoch 133/1000
2023-09-21 06:34:21.174 
Epoch 133/1000 
	 loss: 27.8697, MinusLogProbMetric: 27.8697, val_loss: 27.9822, val_MinusLogProbMetric: 27.9822

Epoch 133: val_loss did not improve from 27.95626
196/196 - 78s - loss: 27.8697 - MinusLogProbMetric: 27.8697 - val_loss: 27.9822 - val_MinusLogProbMetric: 27.9822 - lr: 2.0576e-06 - 78s/epoch - 398ms/step
Epoch 134/1000
2023-09-21 06:35:39.378 
Epoch 134/1000 
	 loss: 27.8230, MinusLogProbMetric: 27.8230, val_loss: 27.9665, val_MinusLogProbMetric: 27.9665

Epoch 134: val_loss did not improve from 27.95626
196/196 - 78s - loss: 27.8230 - MinusLogProbMetric: 27.8230 - val_loss: 27.9665 - val_MinusLogProbMetric: 27.9665 - lr: 2.0576e-06 - 78s/epoch - 399ms/step
Epoch 135/1000
2023-09-21 06:36:56.396 
Epoch 135/1000 
	 loss: 27.8180, MinusLogProbMetric: 27.8180, val_loss: 27.9465, val_MinusLogProbMetric: 27.9465

Epoch 135: val_loss improved from 27.95626 to 27.94649, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.8180 - MinusLogProbMetric: 27.8180 - val_loss: 27.9465 - val_MinusLogProbMetric: 27.9465 - lr: 2.0576e-06 - 80s/epoch - 408ms/step
Epoch 136/1000
2023-09-21 06:38:17.342 
Epoch 136/1000 
	 loss: 27.8008, MinusLogProbMetric: 27.8008, val_loss: 27.9143, val_MinusLogProbMetric: 27.9143

Epoch 136: val_loss improved from 27.94649 to 27.91430, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 79s - loss: 27.8008 - MinusLogProbMetric: 27.8008 - val_loss: 27.9143 - val_MinusLogProbMetric: 27.9143 - lr: 2.0576e-06 - 79s/epoch - 405ms/step
Epoch 137/1000
2023-09-21 06:39:35.882 
Epoch 137/1000 
	 loss: 27.7888, MinusLogProbMetric: 27.7888, val_loss: 27.9009, val_MinusLogProbMetric: 27.9009

Epoch 137: val_loss improved from 27.91430 to 27.90093, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.7888 - MinusLogProbMetric: 27.7888 - val_loss: 27.9009 - val_MinusLogProbMetric: 27.9009 - lr: 2.0576e-06 - 80s/epoch - 410ms/step
Epoch 138/1000
2023-09-21 06:40:56.526 
Epoch 138/1000 
	 loss: 27.8114, MinusLogProbMetric: 27.8114, val_loss: 27.8925, val_MinusLogProbMetric: 27.8925

Epoch 138: val_loss improved from 27.90093 to 27.89248, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 79s - loss: 27.8114 - MinusLogProbMetric: 27.8114 - val_loss: 27.8925 - val_MinusLogProbMetric: 27.8925 - lr: 2.0576e-06 - 79s/epoch - 402ms/step
Epoch 139/1000
2023-09-21 06:42:14.624 
Epoch 139/1000 
	 loss: 27.7807, MinusLogProbMetric: 27.7807, val_loss: 27.8870, val_MinusLogProbMetric: 27.8870

Epoch 139: val_loss improved from 27.89248 to 27.88702, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 79s - loss: 27.7807 - MinusLogProbMetric: 27.7807 - val_loss: 27.8870 - val_MinusLogProbMetric: 27.8870 - lr: 2.0576e-06 - 79s/epoch - 403ms/step
Epoch 140/1000
2023-09-21 06:43:34.529 
Epoch 140/1000 
	 loss: 29.8611, MinusLogProbMetric: 29.8611, val_loss: 28.0205, val_MinusLogProbMetric: 28.0205

Epoch 140: val_loss did not improve from 27.88702
196/196 - 78s - loss: 29.8611 - MinusLogProbMetric: 29.8611 - val_loss: 28.0205 - val_MinusLogProbMetric: 28.0205 - lr: 2.0576e-06 - 78s/epoch - 396ms/step
Epoch 141/1000
2023-09-21 06:44:52.038 
Epoch 141/1000 
	 loss: 27.9150, MinusLogProbMetric: 27.9150, val_loss: 27.8990, val_MinusLogProbMetric: 27.8990

Epoch 141: val_loss did not improve from 27.88702
196/196 - 78s - loss: 27.9150 - MinusLogProbMetric: 27.9150 - val_loss: 27.8990 - val_MinusLogProbMetric: 27.8990 - lr: 2.0576e-06 - 78s/epoch - 395ms/step
Epoch 142/1000
2023-09-21 06:46:09.739 
Epoch 142/1000 
	 loss: 27.8338, MinusLogProbMetric: 27.8338, val_loss: 27.9247, val_MinusLogProbMetric: 27.9247

Epoch 142: val_loss did not improve from 27.88702
196/196 - 78s - loss: 27.8338 - MinusLogProbMetric: 27.8338 - val_loss: 27.9247 - val_MinusLogProbMetric: 27.9247 - lr: 2.0576e-06 - 78s/epoch - 396ms/step
Epoch 143/1000
2023-09-21 06:47:27.046 
Epoch 143/1000 
	 loss: 27.8131, MinusLogProbMetric: 27.8131, val_loss: 28.4307, val_MinusLogProbMetric: 28.4307

Epoch 143: val_loss did not improve from 27.88702
196/196 - 77s - loss: 27.8131 - MinusLogProbMetric: 27.8131 - val_loss: 28.4307 - val_MinusLogProbMetric: 28.4307 - lr: 2.0576e-06 - 77s/epoch - 394ms/step
Epoch 144/1000
2023-09-21 06:48:44.784 
Epoch 144/1000 
	 loss: 27.8249, MinusLogProbMetric: 27.8249, val_loss: 27.8636, val_MinusLogProbMetric: 27.8636

Epoch 144: val_loss improved from 27.88702 to 27.86358, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 86s - loss: 27.8249 - MinusLogProbMetric: 27.8249 - val_loss: 27.8636 - val_MinusLogProbMetric: 27.8636 - lr: 2.0576e-06 - 86s/epoch - 438ms/step
Epoch 145/1000
2023-09-21 06:50:10.726 
Epoch 145/1000 
	 loss: 27.7684, MinusLogProbMetric: 27.7684, val_loss: 27.8572, val_MinusLogProbMetric: 27.8572

Epoch 145: val_loss improved from 27.86358 to 27.85716, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.7684 - MinusLogProbMetric: 27.7684 - val_loss: 27.8572 - val_MinusLogProbMetric: 27.8572 - lr: 2.0576e-06 - 80s/epoch - 406ms/step
Epoch 146/1000
2023-09-21 06:51:30.622 
Epoch 146/1000 
	 loss: 27.7290, MinusLogProbMetric: 27.7290, val_loss: 27.8343, val_MinusLogProbMetric: 27.8343

Epoch 146: val_loss improved from 27.85716 to 27.83425, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.7290 - MinusLogProbMetric: 27.7290 - val_loss: 27.8343 - val_MinusLogProbMetric: 27.8343 - lr: 2.0576e-06 - 80s/epoch - 406ms/step
Epoch 147/1000
2023-09-21 06:52:49.494 
Epoch 147/1000 
	 loss: 28.4798, MinusLogProbMetric: 28.4798, val_loss: 28.0465, val_MinusLogProbMetric: 28.0465

Epoch 147: val_loss did not improve from 27.83425
196/196 - 77s - loss: 28.4798 - MinusLogProbMetric: 28.4798 - val_loss: 28.0465 - val_MinusLogProbMetric: 28.0465 - lr: 2.0576e-06 - 77s/epoch - 394ms/step
Epoch 148/1000
2023-09-21 06:54:07.334 
Epoch 148/1000 
	 loss: 27.7943, MinusLogProbMetric: 27.7943, val_loss: 27.8526, val_MinusLogProbMetric: 27.8526

Epoch 148: val_loss did not improve from 27.83425
196/196 - 78s - loss: 27.7943 - MinusLogProbMetric: 27.7943 - val_loss: 27.8526 - val_MinusLogProbMetric: 27.8526 - lr: 2.0576e-06 - 78s/epoch - 397ms/step
Epoch 149/1000
2023-09-21 06:55:25.866 
Epoch 149/1000 
	 loss: 27.7145, MinusLogProbMetric: 27.7145, val_loss: 27.8332, val_MinusLogProbMetric: 27.8332

Epoch 149: val_loss improved from 27.83425 to 27.83319, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.7145 - MinusLogProbMetric: 27.7145 - val_loss: 27.8332 - val_MinusLogProbMetric: 27.8332 - lr: 2.0576e-06 - 80s/epoch - 409ms/step
Epoch 150/1000
2023-09-21 06:56:45.374 
Epoch 150/1000 
	 loss: 27.7197, MinusLogProbMetric: 27.7197, val_loss: 27.8338, val_MinusLogProbMetric: 27.8338

Epoch 150: val_loss did not improve from 27.83319
196/196 - 78s - loss: 27.7197 - MinusLogProbMetric: 27.7197 - val_loss: 27.8338 - val_MinusLogProbMetric: 27.8338 - lr: 2.0576e-06 - 78s/epoch - 397ms/step
Epoch 151/1000
2023-09-21 06:58:03.015 
Epoch 151/1000 
	 loss: 28.8365, MinusLogProbMetric: 28.8365, val_loss: 27.9866, val_MinusLogProbMetric: 27.9866

Epoch 151: val_loss did not improve from 27.83319
196/196 - 78s - loss: 28.8365 - MinusLogProbMetric: 28.8365 - val_loss: 27.9866 - val_MinusLogProbMetric: 27.9866 - lr: 2.0576e-06 - 78s/epoch - 396ms/step
Epoch 152/1000
2023-09-21 06:59:20.962 
Epoch 152/1000 
	 loss: 27.7822, MinusLogProbMetric: 27.7822, val_loss: 27.8154, val_MinusLogProbMetric: 27.8154

Epoch 152: val_loss improved from 27.83319 to 27.81543, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.7822 - MinusLogProbMetric: 27.7822 - val_loss: 27.8154 - val_MinusLogProbMetric: 27.8154 - lr: 2.0576e-06 - 80s/epoch - 407ms/step
Epoch 153/1000
2023-09-21 07:00:40.424 
Epoch 153/1000 
	 loss: 27.8878, MinusLogProbMetric: 27.8878, val_loss: 27.7932, val_MinusLogProbMetric: 27.7932

Epoch 153: val_loss improved from 27.81543 to 27.79324, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 79s - loss: 27.8878 - MinusLogProbMetric: 27.8878 - val_loss: 27.7932 - val_MinusLogProbMetric: 27.7932 - lr: 2.0576e-06 - 79s/epoch - 405ms/step
Epoch 154/1000
2023-09-21 07:01:58.714 
Epoch 154/1000 
	 loss: 27.6733, MinusLogProbMetric: 27.6733, val_loss: 27.8018, val_MinusLogProbMetric: 27.8018

Epoch 154: val_loss did not improve from 27.79324
196/196 - 77s - loss: 27.6733 - MinusLogProbMetric: 27.6733 - val_loss: 27.8018 - val_MinusLogProbMetric: 27.8018 - lr: 2.0576e-06 - 77s/epoch - 391ms/step
Epoch 155/1000
2023-09-21 07:03:17.197 
Epoch 155/1000 
	 loss: 27.7043, MinusLogProbMetric: 27.7043, val_loss: 28.6625, val_MinusLogProbMetric: 28.6625

Epoch 155: val_loss did not improve from 27.79324
196/196 - 78s - loss: 27.7043 - MinusLogProbMetric: 27.7043 - val_loss: 28.6625 - val_MinusLogProbMetric: 28.6625 - lr: 2.0576e-06 - 78s/epoch - 400ms/step
Epoch 156/1000
2023-09-21 07:04:35.982 
Epoch 156/1000 
	 loss: 27.7382, MinusLogProbMetric: 27.7382, val_loss: 27.7658, val_MinusLogProbMetric: 27.7658

Epoch 156: val_loss improved from 27.79324 to 27.76583, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.7382 - MinusLogProbMetric: 27.7382 - val_loss: 27.7658 - val_MinusLogProbMetric: 27.7658 - lr: 2.0576e-06 - 80s/epoch - 410ms/step
Epoch 157/1000
2023-09-21 07:05:56.040 
Epoch 157/1000 
	 loss: 27.7219, MinusLogProbMetric: 27.7219, val_loss: 27.7657, val_MinusLogProbMetric: 27.7657

Epoch 157: val_loss improved from 27.76583 to 27.76571, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.7219 - MinusLogProbMetric: 27.7219 - val_loss: 27.7657 - val_MinusLogProbMetric: 27.7657 - lr: 2.0576e-06 - 80s/epoch - 410ms/step
Epoch 158/1000
2023-09-21 07:07:15.547 
Epoch 158/1000 
	 loss: 29.8480, MinusLogProbMetric: 29.8480, val_loss: 28.7070, val_MinusLogProbMetric: 28.7070

Epoch 158: val_loss did not improve from 27.76571
196/196 - 78s - loss: 29.8480 - MinusLogProbMetric: 29.8480 - val_loss: 28.7070 - val_MinusLogProbMetric: 28.7070 - lr: 2.0576e-06 - 78s/epoch - 396ms/step
Epoch 159/1000
2023-09-21 07:08:32.500 
Epoch 159/1000 
	 loss: 28.0143, MinusLogProbMetric: 28.0143, val_loss: 27.8629, val_MinusLogProbMetric: 27.8629

Epoch 159: val_loss did not improve from 27.76571
196/196 - 77s - loss: 28.0143 - MinusLogProbMetric: 28.0143 - val_loss: 27.8629 - val_MinusLogProbMetric: 27.8629 - lr: 2.0576e-06 - 77s/epoch - 393ms/step
Epoch 160/1000
2023-09-21 07:09:50.127 
Epoch 160/1000 
	 loss: 27.6928, MinusLogProbMetric: 27.6928, val_loss: 27.8527, val_MinusLogProbMetric: 27.8527

Epoch 160: val_loss did not improve from 27.76571
196/196 - 78s - loss: 27.6928 - MinusLogProbMetric: 27.6928 - val_loss: 27.8527 - val_MinusLogProbMetric: 27.8527 - lr: 2.0576e-06 - 78s/epoch - 396ms/step
Epoch 161/1000
2023-09-21 07:11:08.299 
Epoch 161/1000 
	 loss: 27.6810, MinusLogProbMetric: 27.6810, val_loss: 27.7596, val_MinusLogProbMetric: 27.7596

Epoch 161: val_loss improved from 27.76571 to 27.75955, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.6810 - MinusLogProbMetric: 27.6810 - val_loss: 27.7596 - val_MinusLogProbMetric: 27.7596 - lr: 2.0576e-06 - 80s/epoch - 407ms/step
Epoch 162/1000
2023-09-21 07:12:26.876 
Epoch 162/1000 
	 loss: 29.0687, MinusLogProbMetric: 29.0687, val_loss: 27.8118, val_MinusLogProbMetric: 27.8118

Epoch 162: val_loss did not improve from 27.75955
196/196 - 77s - loss: 29.0687 - MinusLogProbMetric: 29.0687 - val_loss: 27.8118 - val_MinusLogProbMetric: 27.8118 - lr: 2.0576e-06 - 77s/epoch - 393ms/step
Epoch 163/1000
2023-09-21 07:13:43.939 
Epoch 163/1000 
	 loss: 27.6649, MinusLogProbMetric: 27.6649, val_loss: 27.7873, val_MinusLogProbMetric: 27.7873

Epoch 163: val_loss did not improve from 27.75955
196/196 - 77s - loss: 27.6649 - MinusLogProbMetric: 27.6649 - val_loss: 27.7873 - val_MinusLogProbMetric: 27.7873 - lr: 2.0576e-06 - 77s/epoch - 393ms/step
Epoch 164/1000
2023-09-21 07:15:01.205 
Epoch 164/1000 
	 loss: 27.6340, MinusLogProbMetric: 27.6340, val_loss: 27.7289, val_MinusLogProbMetric: 27.7289

Epoch 164: val_loss improved from 27.75955 to 27.72886, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 79s - loss: 27.6340 - MinusLogProbMetric: 27.6340 - val_loss: 27.7289 - val_MinusLogProbMetric: 27.7289 - lr: 2.0576e-06 - 79s/epoch - 405ms/step
Epoch 165/1000
2023-09-21 07:16:21.224 
Epoch 165/1000 
	 loss: 27.6037, MinusLogProbMetric: 27.6037, val_loss: 27.7233, val_MinusLogProbMetric: 27.7233

Epoch 165: val_loss improved from 27.72886 to 27.72333, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.6037 - MinusLogProbMetric: 27.6037 - val_loss: 27.7233 - val_MinusLogProbMetric: 27.7233 - lr: 2.0576e-06 - 80s/epoch - 406ms/step
Epoch 166/1000
2023-09-21 07:17:41.565 
Epoch 166/1000 
	 loss: 27.6086, MinusLogProbMetric: 27.6086, val_loss: 27.7085, val_MinusLogProbMetric: 27.7085

Epoch 166: val_loss improved from 27.72333 to 27.70850, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.6086 - MinusLogProbMetric: 27.6086 - val_loss: 27.7085 - val_MinusLogProbMetric: 27.7085 - lr: 2.0576e-06 - 80s/epoch - 408ms/step
Epoch 167/1000
2023-09-21 07:19:00.381 
Epoch 167/1000 
	 loss: 27.7286, MinusLogProbMetric: 27.7286, val_loss: 27.7346, val_MinusLogProbMetric: 27.7346

Epoch 167: val_loss did not improve from 27.70850
196/196 - 77s - loss: 27.7286 - MinusLogProbMetric: 27.7286 - val_loss: 27.7346 - val_MinusLogProbMetric: 27.7346 - lr: 2.0576e-06 - 77s/epoch - 395ms/step
Epoch 168/1000
2023-09-21 07:20:17.898 
Epoch 168/1000 
	 loss: 27.6038, MinusLogProbMetric: 27.6038, val_loss: 27.7344, val_MinusLogProbMetric: 27.7344

Epoch 168: val_loss did not improve from 27.70850
196/196 - 78s - loss: 27.6038 - MinusLogProbMetric: 27.6038 - val_loss: 27.7344 - val_MinusLogProbMetric: 27.7344 - lr: 2.0576e-06 - 78s/epoch - 395ms/step
Epoch 169/1000
2023-09-21 07:21:35.018 
Epoch 169/1000 
	 loss: 27.5839, MinusLogProbMetric: 27.5839, val_loss: 27.6860, val_MinusLogProbMetric: 27.6860

Epoch 169: val_loss improved from 27.70850 to 27.68605, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 79s - loss: 27.5839 - MinusLogProbMetric: 27.5839 - val_loss: 27.6860 - val_MinusLogProbMetric: 27.6860 - lr: 2.0576e-06 - 79s/epoch - 402ms/step
Epoch 170/1000
2023-09-21 07:22:54.767 
Epoch 170/1000 
	 loss: 27.5641, MinusLogProbMetric: 27.5641, val_loss: 27.7338, val_MinusLogProbMetric: 27.7338

Epoch 170: val_loss did not improve from 27.68605
196/196 - 78s - loss: 27.5641 - MinusLogProbMetric: 27.5641 - val_loss: 27.7338 - val_MinusLogProbMetric: 27.7338 - lr: 2.0576e-06 - 78s/epoch - 399ms/step
Epoch 171/1000
2023-09-21 07:24:11.921 
Epoch 171/1000 
	 loss: 27.5554, MinusLogProbMetric: 27.5554, val_loss: 27.6856, val_MinusLogProbMetric: 27.6856

Epoch 171: val_loss improved from 27.68605 to 27.68558, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 79s - loss: 27.5554 - MinusLogProbMetric: 27.5554 - val_loss: 27.6856 - val_MinusLogProbMetric: 27.6856 - lr: 2.0576e-06 - 79s/epoch - 402ms/step
Epoch 172/1000
2023-09-21 07:25:32.394 
Epoch 172/1000 
	 loss: 27.5969, MinusLogProbMetric: 27.5969, val_loss: 27.6706, val_MinusLogProbMetric: 27.6706

Epoch 172: val_loss improved from 27.68558 to 27.67062, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 27.5969 - MinusLogProbMetric: 27.5969 - val_loss: 27.6706 - val_MinusLogProbMetric: 27.6706 - lr: 2.0576e-06 - 81s/epoch - 411ms/step
Epoch 173/1000
2023-09-21 07:26:52.599 
Epoch 173/1000 
	 loss: 27.5453, MinusLogProbMetric: 27.5453, val_loss: 27.6682, val_MinusLogProbMetric: 27.6682

Epoch 173: val_loss improved from 27.67062 to 27.66818, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.5453 - MinusLogProbMetric: 27.5453 - val_loss: 27.6682 - val_MinusLogProbMetric: 27.6682 - lr: 2.0576e-06 - 80s/epoch - 407ms/step
Epoch 174/1000
2023-09-21 07:28:11.145 
Epoch 174/1000 
	 loss: 27.6479, MinusLogProbMetric: 27.6479, val_loss: 27.6774, val_MinusLogProbMetric: 27.6774

Epoch 174: val_loss did not improve from 27.66818
196/196 - 77s - loss: 27.6479 - MinusLogProbMetric: 27.6479 - val_loss: 27.6774 - val_MinusLogProbMetric: 27.6774 - lr: 2.0576e-06 - 77s/epoch - 393ms/step
Epoch 175/1000
2023-09-21 07:29:28.775 
Epoch 175/1000 
	 loss: 27.5491, MinusLogProbMetric: 27.5491, val_loss: 27.6418, val_MinusLogProbMetric: 27.6418

Epoch 175: val_loss improved from 27.66818 to 27.64182, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 79s - loss: 27.5491 - MinusLogProbMetric: 27.5491 - val_loss: 27.6418 - val_MinusLogProbMetric: 27.6418 - lr: 2.0576e-06 - 79s/epoch - 403ms/step
Epoch 176/1000
2023-09-21 07:30:48.759 
Epoch 176/1000 
	 loss: 27.5285, MinusLogProbMetric: 27.5285, val_loss: 27.6414, val_MinusLogProbMetric: 27.6414

Epoch 176: val_loss improved from 27.64182 to 27.64143, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.5285 - MinusLogProbMetric: 27.5285 - val_loss: 27.6414 - val_MinusLogProbMetric: 27.6414 - lr: 2.0576e-06 - 80s/epoch - 408ms/step
Epoch 177/1000
2023-09-21 07:32:08.272 
Epoch 177/1000 
	 loss: 27.5380, MinusLogProbMetric: 27.5380, val_loss: 27.6404, val_MinusLogProbMetric: 27.6404

Epoch 177: val_loss improved from 27.64143 to 27.64044, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.5380 - MinusLogProbMetric: 27.5380 - val_loss: 27.6404 - val_MinusLogProbMetric: 27.6404 - lr: 2.0576e-06 - 80s/epoch - 406ms/step
Epoch 178/1000
2023-09-21 07:33:28.629 
Epoch 178/1000 
	 loss: 27.5707, MinusLogProbMetric: 27.5707, val_loss: 27.8615, val_MinusLogProbMetric: 27.8615

Epoch 178: val_loss did not improve from 27.64044
196/196 - 79s - loss: 27.5707 - MinusLogProbMetric: 27.5707 - val_loss: 27.8615 - val_MinusLogProbMetric: 27.8615 - lr: 2.0576e-06 - 79s/epoch - 403ms/step
Epoch 179/1000
2023-09-21 07:34:46.550 
Epoch 179/1000 
	 loss: 27.5973, MinusLogProbMetric: 27.5973, val_loss: 27.7164, val_MinusLogProbMetric: 27.7164

Epoch 179: val_loss did not improve from 27.64044
196/196 - 78s - loss: 27.5973 - MinusLogProbMetric: 27.5973 - val_loss: 27.7164 - val_MinusLogProbMetric: 27.7164 - lr: 2.0576e-06 - 78s/epoch - 398ms/step
Epoch 180/1000
2023-09-21 07:36:03.825 
Epoch 180/1000 
	 loss: 27.5142, MinusLogProbMetric: 27.5142, val_loss: 27.6232, val_MinusLogProbMetric: 27.6232

Epoch 180: val_loss improved from 27.64044 to 27.62318, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 79s - loss: 27.5142 - MinusLogProbMetric: 27.5142 - val_loss: 27.6232 - val_MinusLogProbMetric: 27.6232 - lr: 2.0576e-06 - 79s/epoch - 402ms/step
Epoch 181/1000
2023-09-21 07:37:22.974 
Epoch 181/1000 
	 loss: 27.5100, MinusLogProbMetric: 27.5100, val_loss: 27.6094, val_MinusLogProbMetric: 27.6094

Epoch 181: val_loss improved from 27.62318 to 27.60942, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 79s - loss: 27.5100 - MinusLogProbMetric: 27.5100 - val_loss: 27.6094 - val_MinusLogProbMetric: 27.6094 - lr: 2.0576e-06 - 79s/epoch - 405ms/step
Epoch 182/1000
2023-09-21 07:38:42.744 
Epoch 182/1000 
	 loss: 27.4942, MinusLogProbMetric: 27.4942, val_loss: 27.6141, val_MinusLogProbMetric: 27.6141

Epoch 182: val_loss did not improve from 27.60942
196/196 - 78s - loss: 27.4942 - MinusLogProbMetric: 27.4942 - val_loss: 27.6141 - val_MinusLogProbMetric: 27.6141 - lr: 2.0576e-06 - 78s/epoch - 398ms/step
Epoch 183/1000
2023-09-21 07:40:01.213 
Epoch 183/1000 
	 loss: 27.6896, MinusLogProbMetric: 27.6896, val_loss: 27.6661, val_MinusLogProbMetric: 27.6661

Epoch 183: val_loss did not improve from 27.60942
196/196 - 78s - loss: 27.6896 - MinusLogProbMetric: 27.6896 - val_loss: 27.6661 - val_MinusLogProbMetric: 27.6661 - lr: 2.0576e-06 - 78s/epoch - 400ms/step
Epoch 184/1000
2023-09-21 07:41:19.945 
Epoch 184/1000 
	 loss: 27.4902, MinusLogProbMetric: 27.4902, val_loss: 27.6291, val_MinusLogProbMetric: 27.6291

Epoch 184: val_loss did not improve from 27.60942
196/196 - 79s - loss: 27.4902 - MinusLogProbMetric: 27.4902 - val_loss: 27.6291 - val_MinusLogProbMetric: 27.6291 - lr: 2.0576e-06 - 79s/epoch - 402ms/step
Epoch 185/1000
2023-09-21 07:42:38.425 
Epoch 185/1000 
	 loss: 27.4785, MinusLogProbMetric: 27.4785, val_loss: 27.5894, val_MinusLogProbMetric: 27.5894

Epoch 185: val_loss improved from 27.60942 to 27.58935, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.4785 - MinusLogProbMetric: 27.4785 - val_loss: 27.5894 - val_MinusLogProbMetric: 27.5894 - lr: 2.0576e-06 - 80s/epoch - 409ms/step
Epoch 186/1000
2023-09-21 07:43:58.767 
Epoch 186/1000 
	 loss: 27.4710, MinusLogProbMetric: 27.4710, val_loss: 27.6049, val_MinusLogProbMetric: 27.6049

Epoch 186: val_loss did not improve from 27.58935
196/196 - 79s - loss: 27.4710 - MinusLogProbMetric: 27.4710 - val_loss: 27.6049 - val_MinusLogProbMetric: 27.6049 - lr: 2.0576e-06 - 79s/epoch - 401ms/step
Epoch 187/1000
2023-09-21 07:45:17.094 
Epoch 187/1000 
	 loss: 27.4624, MinusLogProbMetric: 27.4624, val_loss: 27.5865, val_MinusLogProbMetric: 27.5865

Epoch 187: val_loss improved from 27.58935 to 27.58651, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.4624 - MinusLogProbMetric: 27.4624 - val_loss: 27.5865 - val_MinusLogProbMetric: 27.5865 - lr: 2.0576e-06 - 80s/epoch - 407ms/step
Epoch 188/1000
2023-09-21 07:46:37.462 
Epoch 188/1000 
	 loss: 27.4755, MinusLogProbMetric: 27.4755, val_loss: 27.5899, val_MinusLogProbMetric: 27.5899

Epoch 188: val_loss did not improve from 27.58651
196/196 - 79s - loss: 27.4755 - MinusLogProbMetric: 27.4755 - val_loss: 27.5899 - val_MinusLogProbMetric: 27.5899 - lr: 2.0576e-06 - 79s/epoch - 402ms/step
Epoch 189/1000
2023-09-21 07:47:55.793 
Epoch 189/1000 
	 loss: 27.4508, MinusLogProbMetric: 27.4508, val_loss: 27.5724, val_MinusLogProbMetric: 27.5724

Epoch 189: val_loss improved from 27.58651 to 27.57242, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.4508 - MinusLogProbMetric: 27.4508 - val_loss: 27.5724 - val_MinusLogProbMetric: 27.5724 - lr: 2.0576e-06 - 80s/epoch - 408ms/step
Epoch 190/1000
2023-09-21 07:49:17.027 
Epoch 190/1000 
	 loss: 27.4724, MinusLogProbMetric: 27.4724, val_loss: 27.5624, val_MinusLogProbMetric: 27.5624

Epoch 190: val_loss improved from 27.57242 to 27.56244, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 27.4724 - MinusLogProbMetric: 27.4724 - val_loss: 27.5624 - val_MinusLogProbMetric: 27.5624 - lr: 2.0576e-06 - 81s/epoch - 415ms/step
Epoch 191/1000
2023-09-21 07:50:35.227 
Epoch 191/1000 
	 loss: 30.9921, MinusLogProbMetric: 30.9921, val_loss: 28.6734, val_MinusLogProbMetric: 28.6734

Epoch 191: val_loss did not improve from 27.56244
196/196 - 76s - loss: 30.9921 - MinusLogProbMetric: 30.9921 - val_loss: 28.6734 - val_MinusLogProbMetric: 28.6734 - lr: 2.0576e-06 - 76s/epoch - 390ms/step
Epoch 192/1000
2023-09-21 07:51:53.717 
Epoch 192/1000 
	 loss: 27.7085, MinusLogProbMetric: 27.7085, val_loss: 27.6242, val_MinusLogProbMetric: 27.6242

Epoch 192: val_loss did not improve from 27.56244
196/196 - 78s - loss: 27.7085 - MinusLogProbMetric: 27.7085 - val_loss: 27.6242 - val_MinusLogProbMetric: 27.6242 - lr: 2.0576e-06 - 78s/epoch - 400ms/step
Epoch 193/1000
2023-09-21 07:53:12.829 
Epoch 193/1000 
	 loss: 27.4882, MinusLogProbMetric: 27.4882, val_loss: 27.5847, val_MinusLogProbMetric: 27.5847

Epoch 193: val_loss did not improve from 27.56244
196/196 - 79s - loss: 27.4882 - MinusLogProbMetric: 27.4882 - val_loss: 27.5847 - val_MinusLogProbMetric: 27.5847 - lr: 2.0576e-06 - 79s/epoch - 404ms/step
Epoch 194/1000
2023-09-21 07:54:31.551 
Epoch 194/1000 
	 loss: 31.1305, MinusLogProbMetric: 31.1305, val_loss: 37.6383, val_MinusLogProbMetric: 37.6383

Epoch 194: val_loss did not improve from 27.56244
196/196 - 79s - loss: 31.1305 - MinusLogProbMetric: 31.1305 - val_loss: 37.6383 - val_MinusLogProbMetric: 37.6383 - lr: 2.0576e-06 - 79s/epoch - 402ms/step
Epoch 195/1000
2023-09-21 07:55:49.398 
Epoch 195/1000 
	 loss: 30.6164, MinusLogProbMetric: 30.6164, val_loss: 27.8943, val_MinusLogProbMetric: 27.8943

Epoch 195: val_loss did not improve from 27.56244
196/196 - 78s - loss: 30.6164 - MinusLogProbMetric: 30.6164 - val_loss: 27.8943 - val_MinusLogProbMetric: 27.8943 - lr: 2.0576e-06 - 78s/epoch - 397ms/step
Epoch 196/1000
2023-09-21 07:57:07.953 
Epoch 196/1000 
	 loss: 27.6095, MinusLogProbMetric: 27.6095, val_loss: 27.6705, val_MinusLogProbMetric: 27.6705

Epoch 196: val_loss did not improve from 27.56244
196/196 - 79s - loss: 27.6095 - MinusLogProbMetric: 27.6095 - val_loss: 27.6705 - val_MinusLogProbMetric: 27.6705 - lr: 2.0576e-06 - 79s/epoch - 401ms/step
Epoch 197/1000
2023-09-21 07:58:27.009 
Epoch 197/1000 
	 loss: 27.5054, MinusLogProbMetric: 27.5054, val_loss: 27.5975, val_MinusLogProbMetric: 27.5975

Epoch 197: val_loss did not improve from 27.56244
196/196 - 79s - loss: 27.5054 - MinusLogProbMetric: 27.5054 - val_loss: 27.5975 - val_MinusLogProbMetric: 27.5975 - lr: 2.0576e-06 - 79s/epoch - 403ms/step
Epoch 198/1000
2023-09-21 07:59:44.916 
Epoch 198/1000 
	 loss: 27.5370, MinusLogProbMetric: 27.5370, val_loss: 27.5726, val_MinusLogProbMetric: 27.5726

Epoch 198: val_loss did not improve from 27.56244
196/196 - 78s - loss: 27.5370 - MinusLogProbMetric: 27.5370 - val_loss: 27.5726 - val_MinusLogProbMetric: 27.5726 - lr: 2.0576e-06 - 78s/epoch - 397ms/step
Epoch 199/1000
2023-09-21 08:01:02.358 
Epoch 199/1000 
	 loss: 27.4531, MinusLogProbMetric: 27.4531, val_loss: 27.5772, val_MinusLogProbMetric: 27.5772

Epoch 199: val_loss did not improve from 27.56244
196/196 - 77s - loss: 27.4531 - MinusLogProbMetric: 27.4531 - val_loss: 27.5772 - val_MinusLogProbMetric: 27.5772 - lr: 2.0576e-06 - 77s/epoch - 395ms/step
Epoch 200/1000
2023-09-21 08:02:20.512 
Epoch 200/1000 
	 loss: 27.4825, MinusLogProbMetric: 27.4825, val_loss: 27.5555, val_MinusLogProbMetric: 27.5555

Epoch 200: val_loss improved from 27.56244 to 27.55551, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.4825 - MinusLogProbMetric: 27.4825 - val_loss: 27.5555 - val_MinusLogProbMetric: 27.5555 - lr: 2.0576e-06 - 80s/epoch - 409ms/step
Epoch 201/1000
2023-09-21 08:03:41.394 
Epoch 201/1000 
	 loss: 27.4293, MinusLogProbMetric: 27.4293, val_loss: 27.5457, val_MinusLogProbMetric: 27.5457

Epoch 201: val_loss improved from 27.55551 to 27.54565, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 82s - loss: 27.4293 - MinusLogProbMetric: 27.4293 - val_loss: 27.5457 - val_MinusLogProbMetric: 27.5457 - lr: 2.0576e-06 - 82s/epoch - 418ms/step
Epoch 202/1000
2023-09-21 08:05:03.494 
Epoch 202/1000 
	 loss: 33.7160, MinusLogProbMetric: 33.7160, val_loss: 32.6316, val_MinusLogProbMetric: 32.6316

Epoch 202: val_loss did not improve from 27.54565
196/196 - 79s - loss: 33.7160 - MinusLogProbMetric: 33.7160 - val_loss: 32.6316 - val_MinusLogProbMetric: 32.6316 - lr: 2.0576e-06 - 79s/epoch - 403ms/step
Epoch 203/1000
2023-09-21 08:06:21.586 
Epoch 203/1000 
	 loss: 29.7066, MinusLogProbMetric: 29.7066, val_loss: 28.2645, val_MinusLogProbMetric: 28.2645

Epoch 203: val_loss did not improve from 27.54565
196/196 - 78s - loss: 29.7066 - MinusLogProbMetric: 29.7066 - val_loss: 28.2645 - val_MinusLogProbMetric: 28.2645 - lr: 2.0576e-06 - 78s/epoch - 398ms/step
Epoch 204/1000
2023-09-21 08:07:41.238 
Epoch 204/1000 
	 loss: 27.8260, MinusLogProbMetric: 27.8260, val_loss: 27.7779, val_MinusLogProbMetric: 27.7779

Epoch 204: val_loss did not improve from 27.54565
196/196 - 80s - loss: 27.8260 - MinusLogProbMetric: 27.8260 - val_loss: 27.7779 - val_MinusLogProbMetric: 27.7779 - lr: 2.0576e-06 - 80s/epoch - 406ms/step
Epoch 205/1000
2023-09-21 08:09:01.555 
Epoch 205/1000 
	 loss: 27.6023, MinusLogProbMetric: 27.6023, val_loss: 27.6682, val_MinusLogProbMetric: 27.6682

Epoch 205: val_loss did not improve from 27.54565
196/196 - 80s - loss: 27.6023 - MinusLogProbMetric: 27.6023 - val_loss: 27.6682 - val_MinusLogProbMetric: 27.6682 - lr: 2.0576e-06 - 80s/epoch - 410ms/step
Epoch 206/1000
2023-09-21 08:10:21.071 
Epoch 206/1000 
	 loss: 27.6642, MinusLogProbMetric: 27.6642, val_loss: 27.6557, val_MinusLogProbMetric: 27.6557

Epoch 206: val_loss did not improve from 27.54565
196/196 - 80s - loss: 27.6642 - MinusLogProbMetric: 27.6642 - val_loss: 27.6557 - val_MinusLogProbMetric: 27.6557 - lr: 2.0576e-06 - 80s/epoch - 406ms/step
Epoch 207/1000
2023-09-21 08:11:40.914 
Epoch 207/1000 
	 loss: 27.6682, MinusLogProbMetric: 27.6682, val_loss: 27.6721, val_MinusLogProbMetric: 27.6721

Epoch 207: val_loss did not improve from 27.54565
196/196 - 80s - loss: 27.6682 - MinusLogProbMetric: 27.6682 - val_loss: 27.6721 - val_MinusLogProbMetric: 27.6721 - lr: 2.0576e-06 - 80s/epoch - 407ms/step
Epoch 208/1000
2023-09-21 08:13:00.148 
Epoch 208/1000 
	 loss: 27.4926, MinusLogProbMetric: 27.4926, val_loss: 27.5639, val_MinusLogProbMetric: 27.5639

Epoch 208: val_loss did not improve from 27.54565
196/196 - 79s - loss: 27.4926 - MinusLogProbMetric: 27.4926 - val_loss: 27.5639 - val_MinusLogProbMetric: 27.5639 - lr: 2.0576e-06 - 79s/epoch - 404ms/step
Epoch 209/1000
2023-09-21 08:14:19.105 
Epoch 209/1000 
	 loss: 27.5747, MinusLogProbMetric: 27.5747, val_loss: 27.5608, val_MinusLogProbMetric: 27.5608

Epoch 209: val_loss did not improve from 27.54565
196/196 - 79s - loss: 27.5747 - MinusLogProbMetric: 27.5747 - val_loss: 27.5608 - val_MinusLogProbMetric: 27.5608 - lr: 2.0576e-06 - 79s/epoch - 403ms/step
Epoch 210/1000
2023-09-21 08:15:37.155 
Epoch 210/1000 
	 loss: 27.4525, MinusLogProbMetric: 27.4525, val_loss: 27.5501, val_MinusLogProbMetric: 27.5501

Epoch 210: val_loss did not improve from 27.54565
196/196 - 78s - loss: 27.4525 - MinusLogProbMetric: 27.4525 - val_loss: 27.5501 - val_MinusLogProbMetric: 27.5501 - lr: 2.0576e-06 - 78s/epoch - 398ms/step
Epoch 211/1000
2023-09-21 08:16:54.539 
Epoch 211/1000 
	 loss: 27.4463, MinusLogProbMetric: 27.4463, val_loss: 27.5719, val_MinusLogProbMetric: 27.5719

Epoch 211: val_loss did not improve from 27.54565
196/196 - 77s - loss: 27.4463 - MinusLogProbMetric: 27.4463 - val_loss: 27.5719 - val_MinusLogProbMetric: 27.5719 - lr: 2.0576e-06 - 77s/epoch - 395ms/step
Epoch 212/1000
2023-09-21 08:18:12.845 
Epoch 212/1000 
	 loss: 27.4063, MinusLogProbMetric: 27.4063, val_loss: 27.5203, val_MinusLogProbMetric: 27.5203

Epoch 212: val_loss improved from 27.54565 to 27.52027, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.4063 - MinusLogProbMetric: 27.4063 - val_loss: 27.5203 - val_MinusLogProbMetric: 27.5203 - lr: 2.0576e-06 - 80s/epoch - 408ms/step
Epoch 213/1000
2023-09-21 08:19:32.384 
Epoch 213/1000 
	 loss: 27.4042, MinusLogProbMetric: 27.4042, val_loss: 27.5005, val_MinusLogProbMetric: 27.5005

Epoch 213: val_loss improved from 27.52027 to 27.50052, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 79s - loss: 27.4042 - MinusLogProbMetric: 27.4042 - val_loss: 27.5005 - val_MinusLogProbMetric: 27.5005 - lr: 2.0576e-06 - 79s/epoch - 405ms/step
Epoch 214/1000
2023-09-21 08:20:51.743 
Epoch 214/1000 
	 loss: 27.6116, MinusLogProbMetric: 27.6116, val_loss: 27.5211, val_MinusLogProbMetric: 27.5211

Epoch 214: val_loss did not improve from 27.50052
196/196 - 78s - loss: 27.6116 - MinusLogProbMetric: 27.6116 - val_loss: 27.5211 - val_MinusLogProbMetric: 27.5211 - lr: 2.0576e-06 - 78s/epoch - 398ms/step
Epoch 215/1000
2023-09-21 08:22:10.276 
Epoch 215/1000 
	 loss: 27.3853, MinusLogProbMetric: 27.3853, val_loss: 27.4822, val_MinusLogProbMetric: 27.4822

Epoch 215: val_loss improved from 27.50052 to 27.48219, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.3853 - MinusLogProbMetric: 27.3853 - val_loss: 27.4822 - val_MinusLogProbMetric: 27.4822 - lr: 2.0576e-06 - 80s/epoch - 408ms/step
Epoch 216/1000
2023-09-21 08:23:30.745 
Epoch 216/1000 
	 loss: 27.3671, MinusLogProbMetric: 27.3671, val_loss: 27.5032, val_MinusLogProbMetric: 27.5032

Epoch 216: val_loss did not improve from 27.48219
196/196 - 79s - loss: 27.3671 - MinusLogProbMetric: 27.3671 - val_loss: 27.5032 - val_MinusLogProbMetric: 27.5032 - lr: 2.0576e-06 - 79s/epoch - 403ms/step
Epoch 217/1000
2023-09-21 08:24:48.453 
Epoch 217/1000 
	 loss: 27.3686, MinusLogProbMetric: 27.3686, val_loss: 27.4875, val_MinusLogProbMetric: 27.4875

Epoch 217: val_loss did not improve from 27.48219
196/196 - 78s - loss: 27.3686 - MinusLogProbMetric: 27.3686 - val_loss: 27.4875 - val_MinusLogProbMetric: 27.4875 - lr: 2.0576e-06 - 78s/epoch - 396ms/step
Epoch 218/1000
2023-09-21 08:26:06.809 
Epoch 218/1000 
	 loss: 27.3567, MinusLogProbMetric: 27.3567, val_loss: 27.4587, val_MinusLogProbMetric: 27.4587

Epoch 218: val_loss improved from 27.48219 to 27.45867, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 80s - loss: 27.3567 - MinusLogProbMetric: 27.3567 - val_loss: 27.4587 - val_MinusLogProbMetric: 27.4587 - lr: 2.0576e-06 - 80s/epoch - 407ms/step
Epoch 219/1000
2023-09-21 08:27:26.428 
Epoch 219/1000 
	 loss: 27.3491, MinusLogProbMetric: 27.3491, val_loss: 27.4839, val_MinusLogProbMetric: 27.4839

Epoch 219: val_loss did not improve from 27.45867
196/196 - 78s - loss: 27.3491 - MinusLogProbMetric: 27.3491 - val_loss: 27.4839 - val_MinusLogProbMetric: 27.4839 - lr: 2.0576e-06 - 78s/epoch - 399ms/step
Epoch 220/1000
2023-09-21 08:28:42.678 
Epoch 220/1000 
	 loss: 27.3624, MinusLogProbMetric: 27.3624, val_loss: 27.4665, val_MinusLogProbMetric: 27.4665

Epoch 220: val_loss did not improve from 27.45867
196/196 - 76s - loss: 27.3624 - MinusLogProbMetric: 27.3624 - val_loss: 27.4665 - val_MinusLogProbMetric: 27.4665 - lr: 2.0576e-06 - 76s/epoch - 389ms/step
Epoch 221/1000
2023-09-21 08:29:52.669 
Epoch 221/1000 
	 loss: 27.3472, MinusLogProbMetric: 27.3472, val_loss: 27.4395, val_MinusLogProbMetric: 27.4395

Epoch 221: val_loss improved from 27.45867 to 27.43947, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 72s - loss: 27.3472 - MinusLogProbMetric: 27.3472 - val_loss: 27.4395 - val_MinusLogProbMetric: 27.4395 - lr: 2.0576e-06 - 72s/epoch - 368ms/step
Epoch 222/1000
2023-09-21 08:31:13.837 
Epoch 222/1000 
	 loss: 27.3223, MinusLogProbMetric: 27.3223, val_loss: 27.4229, val_MinusLogProbMetric: 27.4229

Epoch 222: val_loss improved from 27.43947 to 27.42286, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 81s - loss: 27.3223 - MinusLogProbMetric: 27.3223 - val_loss: 27.4229 - val_MinusLogProbMetric: 27.4229 - lr: 2.0576e-06 - 81s/epoch - 412ms/step
Epoch 223/1000
2023-09-21 08:32:31.790 
Epoch 223/1000 
	 loss: 27.3159, MinusLogProbMetric: 27.3159, val_loss: 27.4272, val_MinusLogProbMetric: 27.4272

Epoch 223: val_loss did not improve from 27.42286
196/196 - 76s - loss: 27.3159 - MinusLogProbMetric: 27.3159 - val_loss: 27.4272 - val_MinusLogProbMetric: 27.4272 - lr: 2.0576e-06 - 76s/epoch - 389ms/step
Epoch 224/1000
2023-09-21 08:33:48.212 
Epoch 224/1000 
	 loss: 27.3296, MinusLogProbMetric: 27.3296, val_loss: 27.4495, val_MinusLogProbMetric: 27.4495

Epoch 224: val_loss did not improve from 27.42286
196/196 - 76s - loss: 27.3296 - MinusLogProbMetric: 27.3296 - val_loss: 27.4495 - val_MinusLogProbMetric: 27.4495 - lr: 2.0576e-06 - 76s/epoch - 390ms/step
Epoch 225/1000
2023-09-21 08:35:04.837 
Epoch 225/1000 
	 loss: 27.3390, MinusLogProbMetric: 27.3390, val_loss: 27.4895, val_MinusLogProbMetric: 27.4895

Epoch 225: val_loss did not improve from 27.42286
196/196 - 77s - loss: 27.3390 - MinusLogProbMetric: 27.3390 - val_loss: 27.4895 - val_MinusLogProbMetric: 27.4895 - lr: 2.0576e-06 - 77s/epoch - 391ms/step
Epoch 226/1000
2023-09-21 08:36:17.826 
Epoch 226/1000 
	 loss: 27.3488, MinusLogProbMetric: 27.3488, val_loss: 27.4206, val_MinusLogProbMetric: 27.4206

Epoch 226: val_loss improved from 27.42286 to 27.42056, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 75s - loss: 27.3488 - MinusLogProbMetric: 27.3488 - val_loss: 27.4206 - val_MinusLogProbMetric: 27.4206 - lr: 2.0576e-06 - 75s/epoch - 383ms/step
Epoch 227/1000
2023-09-21 08:37:27.381 
Epoch 227/1000 
	 loss: 27.4830, MinusLogProbMetric: 27.4830, val_loss: 27.4285, val_MinusLogProbMetric: 27.4285

Epoch 227: val_loss did not improve from 27.42056
196/196 - 67s - loss: 27.4830 - MinusLogProbMetric: 27.4830 - val_loss: 27.4285 - val_MinusLogProbMetric: 27.4285 - lr: 2.0576e-06 - 67s/epoch - 344ms/step
Epoch 228/1000
2023-09-21 08:38:36.469 
Epoch 228/1000 
	 loss: 27.2919, MinusLogProbMetric: 27.2919, val_loss: 27.3944, val_MinusLogProbMetric: 27.3944

Epoch 228: val_loss improved from 27.42056 to 27.39440, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_263/weights/best_weights.h5
196/196 - 71s - loss: 27.2919 - MinusLogProbMetric: 27.2919 - val_loss: 27.3944 - val_MinusLogProbMetric: 27.3944 - lr: 2.0576e-06 - 71s/epoch - 363ms/step
Epoch 229/1000
2023-09-21 08:39:55.500 
Epoch 229/1000 
	 loss: 32.3651, MinusLogProbMetric: 32.3651, val_loss: 67.2480, val_MinusLogProbMetric: 67.2480

Epoch 229: val_loss did not improve from 27.39440
196/196 - 77s - loss: 32.3651 - MinusLogProbMetric: 32.3651 - val_loss: 67.2480 - val_MinusLogProbMetric: 67.2480 - lr: 2.0576e-06 - 77s/epoch - 392ms/step
Epoch 230/1000
2023-09-21 08:41:12.333 
Epoch 230/1000 
	 loss: 45.5674, MinusLogProbMetric: 45.5674, val_loss: 38.3895, val_MinusLogProbMetric: 38.3895

Epoch 230: val_loss did not improve from 27.39440
196/196 - 77s - loss: 45.5674 - MinusLogProbMetric: 45.5674 - val_loss: 38.3895 - val_MinusLogProbMetric: 38.3895 - lr: 2.0576e-06 - 77s/epoch - 392ms/step
Epoch 231/1000
2023-09-21 08:42:30.413 
Epoch 231/1000 
	 loss: 35.2791, MinusLogProbMetric: 35.2791, val_loss: 33.3932, val_MinusLogProbMetric: 33.3932

Epoch 231: val_loss did not improve from 27.39440
196/196 - 78s - loss: 35.2791 - MinusLogProbMetric: 35.2791 - val_loss: 33.3932 - val_MinusLogProbMetric: 33.3932 - lr: 2.0576e-06 - 78s/epoch - 398ms/step
Epoch 232/1000
2023-09-21 08:43:41.701 
Epoch 232/1000 
	 loss: 32.1567, MinusLogProbMetric: 32.1567, val_loss: 31.1838, val_MinusLogProbMetric: 31.1838

Epoch 232: val_loss did not improve from 27.39440
196/196 - 71s - loss: 32.1567 - MinusLogProbMetric: 32.1567 - val_loss: 31.1838 - val_MinusLogProbMetric: 31.1838 - lr: 2.0576e-06 - 71s/epoch - 364ms/step
Epoch 233/1000
2023-09-21 08:44:51.383 
Epoch 233/1000 
	 loss: 30.4002, MinusLogProbMetric: 30.4002, val_loss: 29.8685, val_MinusLogProbMetric: 29.8685

Epoch 233: val_loss did not improve from 27.39440
196/196 - 70s - loss: 30.4002 - MinusLogProbMetric: 30.4002 - val_loss: 29.8685 - val_MinusLogProbMetric: 29.8685 - lr: 2.0576e-06 - 70s/epoch - 356ms/step
Epoch 234/1000
2023-09-21 08:46:02.886 
Epoch 234/1000 
	 loss: 29.0751, MinusLogProbMetric: 29.0751, val_loss: 28.6575, val_MinusLogProbMetric: 28.6575

Epoch 234: val_loss did not improve from 27.39440
196/196 - 72s - loss: 29.0751 - MinusLogProbMetric: 29.0751 - val_loss: 28.6575 - val_MinusLogProbMetric: 28.6575 - lr: 2.0576e-06 - 72s/epoch - 365ms/step
Epoch 235/1000
2023-09-21 08:47:12.488 
Epoch 235/1000 
	 loss: 28.2289, MinusLogProbMetric: 28.2289, val_loss: 28.1246, val_MinusLogProbMetric: 28.1246

Epoch 235: val_loss did not improve from 27.39440
196/196 - 70s - loss: 28.2289 - MinusLogProbMetric: 28.2289 - val_loss: 28.1246 - val_MinusLogProbMetric: 28.1246 - lr: 2.0576e-06 - 70s/epoch - 355ms/step
Epoch 236/1000
2023-09-21 08:48:18.720 
Epoch 236/1000 
	 loss: 27.9063, MinusLogProbMetric: 27.9063, val_loss: 28.0681, val_MinusLogProbMetric: 28.0681

Epoch 236: val_loss did not improve from 27.39440
196/196 - 66s - loss: 27.9063 - MinusLogProbMetric: 27.9063 - val_loss: 28.0681 - val_MinusLogProbMetric: 28.0681 - lr: 2.0576e-06 - 66s/epoch - 338ms/step
Epoch 237/1000
2023-09-21 08:49:22.397 
Epoch 237/1000 
	 loss: 27.7240, MinusLogProbMetric: 27.7240, val_loss: 27.7663, val_MinusLogProbMetric: 27.7663

Epoch 237: val_loss did not improve from 27.39440
196/196 - 64s - loss: 27.7240 - MinusLogProbMetric: 27.7240 - val_loss: 27.7663 - val_MinusLogProbMetric: 27.7663 - lr: 2.0576e-06 - 64s/epoch - 325ms/step
Epoch 238/1000
2023-09-21 08:50:24.130 
Epoch 238/1000 
	 loss: 27.6158, MinusLogProbMetric: 27.6158, val_loss: 27.7092, val_MinusLogProbMetric: 27.7092

Epoch 238: val_loss did not improve from 27.39440
196/196 - 62s - loss: 27.6158 - MinusLogProbMetric: 27.6158 - val_loss: 27.7092 - val_MinusLogProbMetric: 27.7092 - lr: 2.0576e-06 - 62s/epoch - 315ms/step
Epoch 239/1000
2023-09-21 08:51:26.252 
Epoch 239/1000 
	 loss: 27.5361, MinusLogProbMetric: 27.5361, val_loss: 27.6334, val_MinusLogProbMetric: 27.6334

Epoch 239: val_loss did not improve from 27.39440
196/196 - 62s - loss: 27.5361 - MinusLogProbMetric: 27.5361 - val_loss: 27.6334 - val_MinusLogProbMetric: 27.6334 - lr: 2.0576e-06 - 62s/epoch - 317ms/step
Epoch 240/1000
2023-09-21 08:52:27.090 
Epoch 240/1000 
	 loss: 27.5098, MinusLogProbMetric: 27.5098, val_loss: 27.5722, val_MinusLogProbMetric: 27.5722

Epoch 240: val_loss did not improve from 27.39440
196/196 - 61s - loss: 27.5098 - MinusLogProbMetric: 27.5098 - val_loss: 27.5722 - val_MinusLogProbMetric: 27.5722 - lr: 2.0576e-06 - 61s/epoch - 310ms/step
Epoch 241/1000
2023-09-21 08:53:29.426 
Epoch 241/1000 
	 loss: 27.4457, MinusLogProbMetric: 27.4457, val_loss: 27.5323, val_MinusLogProbMetric: 27.5323

Epoch 241: val_loss did not improve from 27.39440
196/196 - 62s - loss: 27.4457 - MinusLogProbMetric: 27.4457 - val_loss: 27.5323 - val_MinusLogProbMetric: 27.5323 - lr: 2.0576e-06 - 62s/epoch - 318ms/step
Epoch 242/1000
2023-09-21 08:54:38.514 
Epoch 242/1000 
	 loss: 27.4165, MinusLogProbMetric: 27.4165, val_loss: 27.5116, val_MinusLogProbMetric: 27.5116

Epoch 242: val_loss did not improve from 27.39440
196/196 - 69s - loss: 27.4165 - MinusLogProbMetric: 27.4165 - val_loss: 27.5116 - val_MinusLogProbMetric: 27.5116 - lr: 2.0576e-06 - 69s/epoch - 352ms/step
Epoch 243/1000
2023-09-21 08:55:47.005 
Epoch 243/1000 
	 loss: 27.4026, MinusLogProbMetric: 27.4026, val_loss: 27.5435, val_MinusLogProbMetric: 27.5435

Epoch 243: val_loss did not improve from 27.39440
196/196 - 68s - loss: 27.4026 - MinusLogProbMetric: 27.4026 - val_loss: 27.5435 - val_MinusLogProbMetric: 27.5435 - lr: 2.0576e-06 - 68s/epoch - 349ms/step
Epoch 244/1000
2023-09-21 08:56:57.357 
Epoch 244/1000 
	 loss: 27.3544, MinusLogProbMetric: 27.3544, val_loss: 27.4703, val_MinusLogProbMetric: 27.4703

Epoch 244: val_loss did not improve from 27.39440
196/196 - 70s - loss: 27.3544 - MinusLogProbMetric: 27.3544 - val_loss: 27.4703 - val_MinusLogProbMetric: 27.4703 - lr: 2.0576e-06 - 70s/epoch - 359ms/step
Epoch 245/1000
2023-09-21 08:58:06.493 
Epoch 245/1000 
	 loss: 27.3367, MinusLogProbMetric: 27.3367, val_loss: 27.4483, val_MinusLogProbMetric: 27.4483

Epoch 245: val_loss did not improve from 27.39440
196/196 - 69s - loss: 27.3367 - MinusLogProbMetric: 27.3367 - val_loss: 27.4483 - val_MinusLogProbMetric: 27.4483 - lr: 2.0576e-06 - 69s/epoch - 353ms/step
Epoch 246/1000
2023-09-21 08:59:14.020 
Epoch 246/1000 
	 loss: 27.3192, MinusLogProbMetric: 27.3192, val_loss: 27.4290, val_MinusLogProbMetric: 27.4290

Epoch 246: val_loss did not improve from 27.39440
196/196 - 68s - loss: 27.3192 - MinusLogProbMetric: 27.3192 - val_loss: 27.4290 - val_MinusLogProbMetric: 27.4290 - lr: 2.0576e-06 - 68s/epoch - 345ms/step
Epoch 247/1000
2023-09-21 09:00:24.897 
Epoch 247/1000 
	 loss: 27.3258, MinusLogProbMetric: 27.3258, val_loss: 27.4212, val_MinusLogProbMetric: 27.4212

Epoch 247: val_loss did not improve from 27.39440
196/196 - 71s - loss: 27.3258 - MinusLogProbMetric: 27.3258 - val_loss: 27.4212 - val_MinusLogProbMetric: 27.4212 - lr: 2.0576e-06 - 71s/epoch - 362ms/step
Epoch 248/1000
