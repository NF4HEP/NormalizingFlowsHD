2023-09-23 15:07:59.601550: Importing os...
2023-09-23 15:07:59.601613: Importing sys...
2023-09-23 15:07:59.601626: Importing and initializing argparse...
Visible devices: [0]
2023-09-23 15:07:59.617438: Importing timer from timeit...
2023-09-23 15:07:59.618046: Setting env variables for tf import (only device [0] will be available)...
2023-09-23 15:07:59.618091: Importing numpy...
2023-09-23 15:07:59.812613: Importing pandas...
2023-09-23 15:08:00.020267: Importing shutil...
2023-09-23 15:08:00.020304: Importing subprocess...
2023-09-23 15:08:00.020311: Importing tensorflow...
Tensorflow version: 2.12.0
2023-09-23 15:08:02.342562: Importing tensorflow_probability...
Tensorflow probability version: 0.20.1
2023-09-23 15:08:02.813483: Importing textwrap...
2023-09-23 15:08:02.813524: Importing timeit...
2023-09-23 15:08:02.813540: Importing traceback...
2023-09-23 15:08:02.813551: Importing typing...
2023-09-23 15:08:02.813566: Setting tf configs...
2023-09-23 15:08:02.938741: Importing custom module...
Successfully loaded GPU model: NVIDIA A40
2023-09-23 15:08:04.102842: All modues imported successfully.
Directory ../../results/CsplineN_new/ already exists.
Directory ../../results/CsplineN_new/run_1/ already exists.
Skipping it.
===========
Run 1/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_2/ already exists.
Skipping it.
===========
Run 2/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_3/ already exists.
Skipping it.
===========
Run 3/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_4/ already exists.
Skipping it.
===========
Run 4/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_5/ already exists.
Skipping it.
===========
Run 5/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_6/ already exists.
Skipping it.
===========
Run 6/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_7/ already exists.
Skipping it.
===========
Run 7/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_8/ already exists.
Skipping it.
===========
Run 8/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_9/ already exists.
Skipping it.
===========
Run 9/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_10/ already exists.
Skipping it.
===========
Run 10/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_11/ already exists.
Skipping it.
===========
Run 11/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_12/ already exists.
Skipping it.
===========
Run 12/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_13/ already exists.
Skipping it.
===========
Run 13/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_14/ already exists.
Skipping it.
===========
Run 14/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_15/ already exists.
Skipping it.
===========
Run 15/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_16/ already exists.
Skipping it.
===========
Run 16/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_17/ already exists.
Skipping it.
===========
Run 17/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_18/ already exists.
Skipping it.
===========
Run 18/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_19/ already exists.
Skipping it.
===========
Run 19/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_20/ already exists.
Skipping it.
===========
Run 20/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_21/ already exists.
Skipping it.
===========
Run 21/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_22/ already exists.
Skipping it.
===========
Run 22/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_23/ already exists.
Skipping it.
===========
Run 23/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_24/ already exists.
Skipping it.
===========
Run 24/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_25/ already exists.
Skipping it.
===========
Run 25/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_26/ already exists.
Skipping it.
===========
Run 26/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_27/ already exists.
Skipping it.
===========
Run 27/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_28/ already exists.
Skipping it.
===========
Run 28/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_29/ already exists.
Skipping it.
===========
Run 29/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_30/ already exists.
Skipping it.
===========
Run 30/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_31/ already exists.
Skipping it.
===========
Run 31/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_32/ already exists.
Skipping it.
===========
Run 32/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_33/ already exists.
Skipping it.
===========
Run 33/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_34/ already exists.
Skipping it.
===========
Run 34/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_35/ already exists.
Skipping it.
===========
Run 35/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_36/ already exists.
Skipping it.
===========
Run 36/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_37/ already exists.
Skipping it.
===========
Run 37/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_38/ already exists.
Skipping it.
===========
Run 38/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_39/ already exists.
Skipping it.
===========
Run 39/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_40/ already exists.
Skipping it.
===========
Run 40/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_41/ already exists.
Skipping it.
===========
Run 41/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_42/ already exists.
Skipping it.
===========
Run 42/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_43/ already exists.
Skipping it.
===========
Run 43/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_44/ already exists.
Skipping it.
===========
Run 44/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_45/ already exists.
Skipping it.
===========
Run 45/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_46/ already exists.
Skipping it.
===========
Run 46/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_47/ already exists.
Skipping it.
===========
Run 47/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_48/ already exists.
Skipping it.
===========
Run 48/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_49/ already exists.
Skipping it.
===========
Run 49/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_50/ already exists.
Skipping it.
===========
Run 50/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_51/ already exists.
Skipping it.
===========
Run 51/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_52/ already exists.
Skipping it.
===========
Run 52/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_53/ already exists.
Skipping it.
===========
Run 53/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_54/ already exists.
Skipping it.
===========
Run 54/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_55/ already exists.
Skipping it.
===========
Run 55/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_56/ already exists.
Skipping it.
===========
Run 56/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_57/ already exists.
Skipping it.
===========
Run 57/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_58/ already exists.
Skipping it.
===========
Run 58/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_59/ already exists.
Skipping it.
===========
Run 59/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_60/ already exists.
Skipping it.
===========
Run 60/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_61/ already exists.
Skipping it.
===========
Run 61/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_62/ already exists.
Skipping it.
===========
Run 62/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_63/ already exists.
Skipping it.
===========
Run 63/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_64/ already exists.
Skipping it.
===========
Run 64/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_65/ already exists.
Skipping it.
===========
Run 65/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_66/ already exists.
Skipping it.
===========
Run 66/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_67/ already exists.
Skipping it.
===========
Run 67/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_68/ already exists.
Skipping it.
===========
Run 68/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_69/ already exists.
Skipping it.
===========
Run 69/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_70/ already exists.
Skipping it.
===========
Run 70/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_71/ already exists.
Skipping it.
===========
Run 71/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_72/ already exists.
Skipping it.
===========
Run 72/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_73/ already exists.
Skipping it.
===========
Run 73/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_74/ already exists.
Skipping it.
===========
Run 74/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_75/ already exists.
Skipping it.
===========
Run 75/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_76/ already exists.
Skipping it.
===========
Run 76/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_77/ already exists.
Skipping it.
===========
Run 77/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_78/ already exists.
Skipping it.
===========
Run 78/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_79/ already exists.
Skipping it.
===========
Run 79/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_80/ already exists.
Skipping it.
===========
Run 80/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_81/ already exists.
Skipping it.
===========
Run 81/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_82/ already exists.
Skipping it.
===========
Run 82/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_83/ already exists.
Skipping it.
===========
Run 83/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_84/ already exists.
Skipping it.
===========
Run 84/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_85/ already exists.
Skipping it.
===========
Run 85/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_86/ already exists.
Skipping it.
===========
Run 86/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_87/ already exists.
Skipping it.
===========
Run 87/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_88/ already exists.
Skipping it.
===========
Run 88/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_89/ already exists.
Skipping it.
===========
Run 89/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_90/ already exists.
Skipping it.
===========
Run 90/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_91/ already exists.
Skipping it.
===========
Run 91/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_92/ already exists.
Skipping it.
===========
Run 92/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_93/ already exists.
Skipping it.
===========
Run 93/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_94/ already exists.
Skipping it.
===========
Run 94/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_95/ already exists.
Skipping it.
===========
Run 95/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_96/ already exists.
Skipping it.
===========
Run 96/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_97/ already exists.
Skipping it.
===========
Run 97/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_98/ already exists.
Skipping it.
===========
Run 98/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_99/ already exists.
Skipping it.
===========
Run 99/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_100/ already exists.
Skipping it.
===========
Run 100/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_101/ already exists.
Skipping it.
===========
Run 101/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_102/ already exists.
Skipping it.
===========
Run 102/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_103/ already exists.
Skipping it.
===========
Run 103/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_104/ already exists.
Skipping it.
===========
Run 104/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_105/ already exists.
Skipping it.
===========
Run 105/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_106/ already exists.
Skipping it.
===========
Run 106/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_107/ already exists.
Skipping it.
===========
Run 107/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_108/ already exists.
Skipping it.
===========
Run 108/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_109/ already exists.
Skipping it.
===========
Run 109/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_110/ already exists.
Skipping it.
===========
Run 110/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_111/ already exists.
Skipping it.
===========
Run 111/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_112/ already exists.
Skipping it.
===========
Run 112/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_113/ already exists.
Skipping it.
===========
Run 113/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_114/ already exists.
Skipping it.
===========
Run 114/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_115/ already exists.
Skipping it.
===========
Run 115/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_116/ already exists.
Skipping it.
===========
Run 116/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_117/ already exists.
Skipping it.
===========
Run 117/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_118/ already exists.
Skipping it.
===========
Run 118/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_119/ already exists.
Skipping it.
===========
Run 119/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_120/ already exists.
Skipping it.
===========
Run 120/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_121/ already exists.
Skipping it.
===========
Run 121/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_122/ already exists.
Skipping it.
===========
Run 122/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_123/ already exists.
Skipping it.
===========
Run 123/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_124/ already exists.
Skipping it.
===========
Run 124/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_125/ already exists.
Skipping it.
===========
Run 125/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_126/ already exists.
Skipping it.
===========
Run 126/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_127/ already exists.
Skipping it.
===========
Run 127/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_128/ already exists.
Skipping it.
===========
Run 128/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_129/ already exists.
Skipping it.
===========
Run 129/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_130/ already exists.
Skipping it.
===========
Run 130/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_131/ already exists.
Skipping it.
===========
Run 131/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_132/ already exists.
Skipping it.
===========
Run 132/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_133/ already exists.
Skipping it.
===========
Run 133/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_134/ already exists.
Skipping it.
===========
Run 134/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_135/ already exists.
Skipping it.
===========
Run 135/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_136/ already exists.
Skipping it.
===========
Run 136/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_137/ already exists.
Skipping it.
===========
Run 137/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_138/ already exists.
Skipping it.
===========
Run 138/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_139/ already exists.
Skipping it.
===========
Run 139/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_140/ already exists.
Skipping it.
===========
Run 140/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_141/ already exists.
Skipping it.
===========
Run 141/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_142/ already exists.
Skipping it.
===========
Run 142/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_143/ already exists.
Skipping it.
===========
Run 143/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_144/ already exists.
Skipping it.
===========
Run 144/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_145/ already exists.
Skipping it.
===========
Run 145/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_146/ already exists.
Skipping it.
===========
Run 146/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_147/ already exists.
Skipping it.
===========
Run 147/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_148/ already exists.
Skipping it.
===========
Run 148/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_149/ already exists.
Skipping it.
===========
Run 149/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_150/ already exists.
Skipping it.
===========
Run 150/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_151/ already exists.
Skipping it.
===========
Run 151/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_152/ already exists.
Skipping it.
===========
Run 152/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_153/ already exists.
Skipping it.
===========
Run 153/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_154/ already exists.
Skipping it.
===========
Run 154/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_155/ already exists.
Skipping it.
===========
Run 155/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_156/ already exists.
Skipping it.
===========
Run 156/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_157/ already exists.
Skipping it.
===========
Run 157/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_158/ already exists.
Skipping it.
===========
Run 158/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_159/ already exists.
Skipping it.
===========
Run 159/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_160/ already exists.
Skipping it.
===========
Run 160/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_161/ already exists.
Skipping it.
===========
Run 161/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_162/ already exists.
Skipping it.
===========
Run 162/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_163/ already exists.
Skipping it.
===========
Run 163/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_164/ already exists.
Skipping it.
===========
Run 164/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_165/ already exists.
Skipping it.
===========
Run 165/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_166/ already exists.
Skipping it.
===========
Run 166/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_167/ already exists.
Skipping it.
===========
Run 167/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_168/ already exists.
Skipping it.
===========
Run 168/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_169/ already exists.
Skipping it.
===========
Run 169/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_170/ already exists.
Skipping it.
===========
Run 170/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_171/ already exists.
Skipping it.
===========
Run 171/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_172/ already exists.
Skipping it.
===========
Run 172/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_173/ already exists.
Skipping it.
===========
Run 173/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_174/ already exists.
Skipping it.
===========
Run 174/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_175/ already exists.
Skipping it.
===========
Run 175/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_176/ already exists.
Skipping it.
===========
Run 176/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_177/ already exists.
Skipping it.
===========
Run 177/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_178/ already exists.
Skipping it.
===========
Run 178/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_179/ already exists.
Skipping it.
===========
Run 179/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_180/ already exists.
Skipping it.
===========
Run 180/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_181/ already exists.
Skipping it.
===========
Run 181/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_182/ already exists.
Skipping it.
===========
Run 182/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_183/ already exists.
Skipping it.
===========
Run 183/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_184/ already exists.
Skipping it.
===========
Run 184/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_185/ already exists.
Skipping it.
===========
Run 185/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_186/ already exists.
Skipping it.
===========
Run 186/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_187/ already exists.
Skipping it.
===========
Run 187/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_188/ already exists.
Skipping it.
===========
Run 188/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_189/ already exists.
Skipping it.
===========
Run 189/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_190/ already exists.
Skipping it.
===========
Run 190/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_191/ already exists.
Skipping it.
===========
Run 191/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_192/ already exists.
Skipping it.
===========
Run 192/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_193/ already exists.
Skipping it.
===========
Run 193/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_194/ already exists.
Skipping it.
===========
Run 194/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_195/ already exists.
Skipping it.
===========
Run 195/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_196/ already exists.
Skipping it.
===========
Run 196/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_197/ already exists.
Skipping it.
===========
Run 197/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_198/ already exists.
Skipping it.
===========
Run 198/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_199/ already exists.
Skipping it.
===========
Run 199/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_200/ already exists.
Skipping it.
===========
Run 200/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_201/ already exists.
Skipping it.
===========
Run 201/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_202/ already exists.
Skipping it.
===========
Run 202/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_203/ already exists.
Skipping it.
===========
Run 203/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_204/ already exists.
Skipping it.
===========
Run 204/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_205/ already exists.
Skipping it.
===========
Run 205/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_206/ already exists.
Skipping it.
===========
Run 206/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_207/ already exists.
Skipping it.
===========
Run 207/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_208/ already exists.
Skipping it.
===========
Run 208/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_209/ already exists.
Skipping it.
===========
Run 209/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_210/ already exists.
Skipping it.
===========
Run 210/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_211/ already exists.
Skipping it.
===========
Run 211/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_212/ already exists.
Skipping it.
===========
Run 212/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_213/ already exists.
Skipping it.
===========
Run 213/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_214/ already exists.
Skipping it.
===========
Run 214/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_215/ already exists.
Skipping it.
===========
Run 215/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_216/ already exists.
Skipping it.
===========
Run 216/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_217/ already exists.
Skipping it.
===========
Run 217/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_218/ already exists.
Skipping it.
===========
Run 218/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_219/ already exists.
Skipping it.
===========
Run 219/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_220/ already exists.
Skipping it.
===========
Run 220/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_221/ already exists.
Skipping it.
===========
Run 221/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_222/ already exists.
Skipping it.
===========
Run 222/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_223/ already exists.
Skipping it.
===========
Run 223/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_224/ already exists.
Skipping it.
===========
Run 224/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_225/ already exists.
Skipping it.
===========
Run 225/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_226/ already exists.
Skipping it.
===========
Run 226/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_227/ already exists.
Skipping it.
===========
Run 227/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_228/ already exists.
Skipping it.
===========
Run 228/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_229/ already exists.
Skipping it.
===========
Run 229/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_230/ already exists.
Skipping it.
===========
Run 230/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_231/ already exists.
Skipping it.
===========
Run 231/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_232/ already exists.
Skipping it.
===========
Run 232/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_233/ already exists.
Skipping it.
===========
Run 233/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_234/ already exists.
Skipping it.
===========
Run 234/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_235/ already exists.
Skipping it.
===========
Run 235/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_236/ already exists.
Skipping it.
===========
Run 236/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_237/ already exists.
Skipping it.
===========
Run 237/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_238/ already exists.
Skipping it.
===========
Run 238/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_239/ already exists.
Skipping it.
===========
Run 239/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_240/ already exists.
Skipping it.
===========
Run 240/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_241/ already exists.
Skipping it.
===========
Run 241/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_242/ already exists.
Skipping it.
===========
Run 242/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_243/ already exists.
Skipping it.
===========
Run 243/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_244/ already exists.
Skipping it.
===========
Run 244/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_245/ already exists.
Skipping it.
===========
Run 245/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_246/ already exists.
Skipping it.
===========
Run 246/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_247/ already exists.
Skipping it.
===========
Run 247/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_248/ already exists.
Skipping it.
===========
Run 248/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_249/ already exists.
Skipping it.
===========
Run 249/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_250/ already exists.
Skipping it.
===========
Run 250/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_251/ already exists.
Skipping it.
===========
Run 251/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_252/ already exists.
Skipping it.
===========
Run 252/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_253/ already exists.
Skipping it.
===========
Run 253/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_254/ already exists.
Skipping it.
===========
Run 254/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_255/ already exists.
Skipping it.
===========
Run 255/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_256/ already exists.
Skipping it.
===========
Run 256/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_257/ already exists.
Skipping it.
===========
Run 257/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_258/ already exists.
Skipping it.
===========
Run 258/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_259/ already exists.
Skipping it.
===========
Run 259/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_260/ already exists.
Skipping it.
===========
Run 260/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_261/ already exists.
Skipping it.
===========
Run 261/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_262/ already exists.
Skipping it.
===========
Run 262/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_263/ already exists.
Skipping it.
===========
Run 263/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_264/ already exists.
Skipping it.
===========
Run 264/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_265/ already exists.
Skipping it.
===========
Run 265/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_266/ already exists.
Skipping it.
===========
Run 266/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_267/ already exists.
Skipping it.
===========
Run 267/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_268/ already exists.
Skipping it.
===========
Run 268/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_269/ already exists.
Skipping it.
===========
Run 269/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_270/ already exists.
Skipping it.
===========
Run 270/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_271/ already exists.
Skipping it.
===========
Run 271/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_272/ already exists.
Skipping it.
===========
Run 272/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_273/ already exists.
Skipping it.
===========
Run 273/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_274/ already exists.
Skipping it.
===========
Run 274/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_275/ already exists.
Skipping it.
===========
Run 275/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_276/ already exists.
Skipping it.
===========
Run 276/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_277/ already exists.
Skipping it.
===========
Run 277/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_278/ already exists.
Skipping it.
===========
Run 278/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_279/ already exists.
Skipping it.
===========
Run 279/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_280/ already exists.
Skipping it.
===========
Run 280/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_281/ already exists.
Skipping it.
===========
Run 281/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_282/ already exists.
Skipping it.
===========
Run 282/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_283/ already exists.
Skipping it.
===========
Run 283/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_284/ already exists.
Skipping it.
===========
Run 284/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_285/ already exists.
Skipping it.
===========
Run 285/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_286/ already exists.
Skipping it.
===========
Run 286/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_287/ already exists.
Skipping it.
===========
Run 287/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_288/ already exists.
Skipping it.
===========
Run 288/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_289/ already exists.
Skipping it.
===========
Run 289/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_290/ already exists.
Skipping it.
===========
Run 290/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_291/ already exists.
Skipping it.
===========
Run 291/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_292/ already exists.
Skipping it.
===========
Run 292/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_293/ already exists.
Skipping it.
===========
Run 293/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_294/ already exists.
Skipping it.
===========
Run 294/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_295/ already exists.
Skipping it.
===========
Run 295/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_296/ already exists.
Skipping it.
===========
Run 296/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_297/ already exists.
Skipping it.
===========
Run 297/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_298/ already exists.
Skipping it.
===========
Run 298/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_299/ already exists.
Skipping it.
===========
Run 299/720 already exists. Skipping it.
===========

===========
Generating train data for run 300.
===========
Train data generated in 0.24 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_300/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 869}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_300/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.7724807 ,  3.5952213 ,  8.442487  , ...,  7.3644695 ,
         3.6588435 ,  2.0248146 ],
       [ 6.6242166 ,  7.1665483 ,  6.4277024 , ...,  3.1194153 ,
         2.6248946 ,  8.037665  ],
       [ 4.5211086 ,  5.2663136 , -0.6501303 , ...,  0.17722613,
         6.462096  ,  1.3170475 ],
       ...,
       [ 5.2085795 ,  5.348097  , -0.4658583 , ..., -0.03725696,
         5.9864964 ,  1.2388526 ],
       [ 3.9188156 ,  5.4859467 , -0.29968688, ...,  0.4149692 ,
         6.0867124 ,  1.4174792 ],
       [ 2.283803  ,  2.9701724 ,  8.729265  , ...,  6.0229187 ,
         3.2842712 ,  2.1182036 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_300/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_300
self.data_kwargs: {'seed': 869}
self.x_data: [[ 1.7417877   3.5044646   9.194398   ...  7.377848    2.8874114
   1.7757134 ]
 [ 3.8693519   4.134066    8.323213   ...  7.5259514   3.079576
   1.8540689 ]
 [ 2.7888105   3.5250566   6.8470335  ...  7.0512147   2.9893377
   1.7142482 ]
 ...
 [ 3.8914979   5.948059   -0.25578696 ...  1.7629418   6.8860593
   1.464444  ]
 [ 3.0775785   3.9001913   8.887795   ...  7.2041593   3.5200696
   1.5176823 ]
 [ 1.0419946   3.6002321   7.1163735  ...  7.3799496   3.218665
   1.6207042 ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_6 (InputLayer)        [(None, 32)]              0         
                                                                 
 log_prob_layer (LogProbLaye  (None,)                  1399280   
 r)                                                              
                                                                 
=================================================================
Total params: 1,399,280
Trainable params: 1,399,280
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer'")
self.model: <keras.engine.functional.Functional object at 0x7f907c33f9a0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7f909c17cca0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7f909c17cca0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7f909c10e5c0>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7f909c10e5f0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7f909c10cb80>, <keras.callbacks.ModelCheckpoint object at 0x7f909c10de40>, <keras.callbacks.EarlyStopping object at 0x7f909c10e0b0>, <keras.callbacks.ReduceLROnPlateau object at 0x7f909c10e110>, <keras.callbacks.TerminateOnNaN object at 0x7f909c10c5e0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.7724807 ,  3.5952213 ,  8.442487  , ...,  7.3644695 ,
         3.6588435 ,  2.0248146 ],
       [ 6.6242166 ,  7.1665483 ,  6.4277024 , ...,  3.1194153 ,
         2.6248946 ,  8.037665  ],
       [ 4.5211086 ,  5.2663136 , -0.6501303 , ...,  0.17722613,
         6.462096  ,  1.3170475 ],
       ...,
       [ 5.2085795 ,  5.348097  , -0.4658583 , ..., -0.03725696,
         5.9864964 ,  1.2388526 ],
       [ 3.9188156 ,  5.4859467 , -0.29968688, ...,  0.4149692 ,
         6.0867124 ,  1.4174792 ],
       [ 2.283803  ,  2.9701724 ,  8.729265  , ...,  6.0229187 ,
         3.2842712 ,  2.1182036 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_300/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 300/720 with hyperparameters:
timestamp = 2023-09-23 15:08:11.423744
ndims = 32
seed_train = 869
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 5
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 1399280
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 1.7417877   3.5044646   9.194398    1.0621872   8.910313    1.2448134
  9.752992    4.795541   10.214517    5.8200784   7.3571367   0.42017213
  3.0764782   1.1773593   3.1572356   1.3086243   2.6951017   5.712275
  0.4469142   6.9349284   5.5393224   1.8138231   6.1143165   1.1455625
  7.183009    9.098161    3.4021838   5.9704523   0.79392874  7.377848
  2.8874114   1.7757134 ]
Epoch 1/1000
2023-09-23 15:08:25.163441: Importing os...
2023-09-23 15:08:25.163519: Importing sys...
2023-09-23 15:08:25.163536: Importing and initializing argparse...
Visible devices: [0]
2023-09-23 15:08:25.184508: Importing timer from timeit...
2023-09-23 15:08:25.185407: Setting env variables for tf import (only device [0] will be available)...
2023-09-23 15:08:25.185527: Importing numpy...
2023-09-23 15:08:25.384632: Importing pandas...
2023-09-23 15:08:25.617227: Importing shutil...
2023-09-23 15:08:25.617266: Importing subprocess...
2023-09-23 15:08:25.617276: Importing tensorflow...
Tensorflow version: 2.12.0
2023-09-23 15:08:28.345893: Importing tensorflow_probability...
Tensorflow probability version: 0.20.1
2023-09-23 15:08:28.828171: Importing textwrap...
2023-09-23 15:08:28.828202: Importing timeit...
2023-09-23 15:08:28.828212: Importing traceback...
2023-09-23 15:08:28.828219: Importing typing...
2023-09-23 15:08:28.828228: Setting tf configs...
2023-09-23 15:08:28.961960: Importing custom module...
Successfully loaded GPU model: NVIDIA A40
2023-09-23 15:08:30.325453: All modues imported successfully.
Directory ../../results/CsplineN_new/ already exists.
Directory ../../results/CsplineN_new/run_1/ already exists.
Skipping it.
===========
Run 1/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_2/ already exists.
Skipping it.
===========
Run 2/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_3/ already exists.
Skipping it.
===========
Run 3/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_4/ already exists.
Skipping it.
===========
Run 4/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_5/ already exists.
Skipping it.
===========
Run 5/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_6/ already exists.
Skipping it.
===========
Run 6/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_7/ already exists.
Skipping it.
===========
Run 7/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_8/ already exists.
Skipping it.
===========
Run 8/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_9/ already exists.
Skipping it.
===========
Run 9/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_10/ already exists.
Skipping it.
===========
Run 10/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_11/ already exists.
Skipping it.
===========
Run 11/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_12/ already exists.
Skipping it.
===========
Run 12/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_13/ already exists.
Skipping it.
===========
Run 13/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_14/ already exists.
Skipping it.
===========
Run 14/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_15/ already exists.
Skipping it.
===========
Run 15/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_16/ already exists.
Skipping it.
===========
Run 16/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_17/ already exists.
Skipping it.
===========
Run 17/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_18/ already exists.
Skipping it.
===========
Run 18/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_19/ already exists.
Skipping it.
===========
Run 19/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_20/ already exists.
Skipping it.
===========
Run 20/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_21/ already exists.
Skipping it.
===========
Run 21/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_22/ already exists.
Skipping it.
===========
Run 22/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_23/ already exists.
Skipping it.
===========
Run 23/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_24/ already exists.
Skipping it.
===========
Run 24/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_25/ already exists.
Skipping it.
===========
Run 25/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_26/ already exists.
Skipping it.
===========
Run 26/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_27/ already exists.
Skipping it.
===========
Run 27/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_28/ already exists.
Skipping it.
===========
Run 28/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_29/ already exists.
Skipping it.
===========
Run 29/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_30/ already exists.
Skipping it.
===========
Run 30/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_31/ already exists.
Skipping it.
===========
Run 31/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_32/ already exists.
Skipping it.
===========
Run 32/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_33/ already exists.
Skipping it.
===========
Run 33/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_34/ already exists.
Skipping it.
===========
Run 34/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_35/ already exists.
Skipping it.
===========
Run 35/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_36/ already exists.
Skipping it.
===========
Run 36/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_37/ already exists.
Skipping it.
===========
Run 37/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_38/ already exists.
Skipping it.
===========
Run 38/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_39/ already exists.
Skipping it.
===========
Run 39/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_40/ already exists.
Skipping it.
===========
Run 40/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_41/ already exists.
Skipping it.
===========
Run 41/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_42/ already exists.
Skipping it.
===========
Run 42/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_43/ already exists.
Skipping it.
===========
Run 43/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_44/ already exists.
Skipping it.
===========
Run 44/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_45/ already exists.
Skipping it.
===========
Run 45/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_46/ already exists.
Skipping it.
===========
Run 46/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_47/ already exists.
Skipping it.
===========
Run 47/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_48/ already exists.
Skipping it.
===========
Run 48/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_49/ already exists.
Skipping it.
===========
Run 49/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_50/ already exists.
Skipping it.
===========
Run 50/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_51/ already exists.
Skipping it.
===========
Run 51/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_52/ already exists.
Skipping it.
===========
Run 52/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_53/ already exists.
Skipping it.
===========
Run 53/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_54/ already exists.
Skipping it.
===========
Run 54/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_55/ already exists.
Skipping it.
===========
Run 55/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_56/ already exists.
Skipping it.
===========
Run 56/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_57/ already exists.
Skipping it.
===========
Run 57/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_58/ already exists.
Skipping it.
===========
Run 58/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_59/ already exists.
Skipping it.
===========
Run 59/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_60/ already exists.
Skipping it.
===========
Run 60/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_61/ already exists.
Skipping it.
===========
Run 61/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_62/ already exists.
Skipping it.
===========
Run 62/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_63/ already exists.
Skipping it.
===========
Run 63/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_64/ already exists.
Skipping it.
===========
Run 64/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_65/ already exists.
Skipping it.
===========
Run 65/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_66/ already exists.
Skipping it.
===========
Run 66/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_67/ already exists.
Skipping it.
===========
Run 67/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_68/ already exists.
Skipping it.
===========
Run 68/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_69/ already exists.
Skipping it.
===========
Run 69/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_70/ already exists.
Skipping it.
===========
Run 70/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_71/ already exists.
Skipping it.
===========
Run 71/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_72/ already exists.
Skipping it.
===========
Run 72/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_73/ already exists.
Skipping it.
===========
Run 73/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_74/ already exists.
Skipping it.
===========
Run 74/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_75/ already exists.
Skipping it.
===========
Run 75/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_76/ already exists.
Skipping it.
===========
Run 76/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_77/ already exists.
Skipping it.
===========
Run 77/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_78/ already exists.
Skipping it.
===========
Run 78/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_79/ already exists.
Skipping it.
===========
Run 79/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_80/ already exists.
Skipping it.
===========
Run 80/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_81/ already exists.
Skipping it.
===========
Run 81/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_82/ already exists.
Skipping it.
===========
Run 82/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_83/ already exists.
Skipping it.
===========
Run 83/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_84/ already exists.
Skipping it.
===========
Run 84/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_85/ already exists.
Skipping it.
===========
Run 85/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_86/ already exists.
Skipping it.
===========
Run 86/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_87/ already exists.
Skipping it.
===========
Run 87/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_88/ already exists.
Skipping it.
===========
Run 88/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_89/ already exists.
Skipping it.
===========
Run 89/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_90/ already exists.
Skipping it.
===========
Run 90/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_91/ already exists.
Skipping it.
===========
Run 91/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_92/ already exists.
Skipping it.
===========
Run 92/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_93/ already exists.
Skipping it.
===========
Run 93/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_94/ already exists.
Skipping it.
===========
Run 94/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_95/ already exists.
Skipping it.
===========
Run 95/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_96/ already exists.
Skipping it.
===========
Run 96/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_97/ already exists.
Skipping it.
===========
Run 97/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_98/ already exists.
Skipping it.
===========
Run 98/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_99/ already exists.
Skipping it.
===========
Run 99/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_100/ already exists.
Skipping it.
===========
Run 100/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_101/ already exists.
Skipping it.
===========
Run 101/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_102/ already exists.
Skipping it.
===========
Run 102/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_103/ already exists.
Skipping it.
===========
Run 103/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_104/ already exists.
Skipping it.
===========
Run 104/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_105/ already exists.
Skipping it.
===========
Run 105/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_106/ already exists.
Skipping it.
===========
Run 106/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_107/ already exists.
Skipping it.
===========
Run 107/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_108/ already exists.
Skipping it.
===========
Run 108/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_109/ already exists.
Skipping it.
===========
Run 109/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_110/ already exists.
Skipping it.
===========
Run 110/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_111/ already exists.
Skipping it.
===========
Run 111/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_112/ already exists.
Skipping it.
===========
Run 112/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_113/ already exists.
Skipping it.
===========
Run 113/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_114/ already exists.
Skipping it.
===========
Run 114/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_115/ already exists.
Skipping it.
===========
Run 115/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_116/ already exists.
Skipping it.
===========
Run 116/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_117/ already exists.
Skipping it.
===========
Run 117/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_118/ already exists.
Skipping it.
===========
Run 118/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_119/ already exists.
Skipping it.
===========
Run 119/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_120/ already exists.
Skipping it.
===========
Run 120/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_121/ already exists.
Skipping it.
===========
Run 121/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_122/ already exists.
Skipping it.
===========
Run 122/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_123/ already exists.
Skipping it.
===========
Run 123/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_124/ already exists.
Skipping it.
===========
Run 124/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_125/ already exists.
Skipping it.
===========
Run 125/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_126/ already exists.
Skipping it.
===========
Run 126/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_127/ already exists.
Skipping it.
===========
Run 127/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_128/ already exists.
Skipping it.
===========
Run 128/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_129/ already exists.
Skipping it.
===========
Run 129/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_130/ already exists.
Skipping it.
===========
Run 130/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_131/ already exists.
Skipping it.
===========
Run 131/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_132/ already exists.
Skipping it.
===========
Run 132/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_133/ already exists.
Skipping it.
===========
Run 133/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_134/ already exists.
Skipping it.
===========
Run 134/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_135/ already exists.
Skipping it.
===========
Run 135/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_136/ already exists.
Skipping it.
===========
Run 136/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_137/ already exists.
Skipping it.
===========
Run 137/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_138/ already exists.
Skipping it.
===========
Run 138/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_139/ already exists.
Skipping it.
===========
Run 139/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_140/ already exists.
Skipping it.
===========
Run 140/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_141/ already exists.
Skipping it.
===========
Run 141/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_142/ already exists.
Skipping it.
===========
Run 142/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_143/ already exists.
Skipping it.
===========
Run 143/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_144/ already exists.
Skipping it.
===========
Run 144/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_145/ already exists.
Skipping it.
===========
Run 145/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_146/ already exists.
Skipping it.
===========
Run 146/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_147/ already exists.
Skipping it.
===========
Run 147/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_148/ already exists.
Skipping it.
===========
Run 148/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_149/ already exists.
Skipping it.
===========
Run 149/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_150/ already exists.
Skipping it.
===========
Run 150/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_151/ already exists.
Skipping it.
===========
Run 151/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_152/ already exists.
Skipping it.
===========
Run 152/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_153/ already exists.
Skipping it.
===========
Run 153/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_154/ already exists.
Skipping it.
===========
Run 154/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_155/ already exists.
Skipping it.
===========
Run 155/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_156/ already exists.
Skipping it.
===========
Run 156/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_157/ already exists.
Skipping it.
===========
Run 157/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_158/ already exists.
Skipping it.
===========
Run 158/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_159/ already exists.
Skipping it.
===========
Run 159/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_160/ already exists.
Skipping it.
===========
Run 160/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_161/ already exists.
Skipping it.
===========
Run 161/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_162/ already exists.
Skipping it.
===========
Run 162/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_163/ already exists.
Skipping it.
===========
Run 163/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_164/ already exists.
Skipping it.
===========
Run 164/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_165/ already exists.
Skipping it.
===========
Run 165/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_166/ already exists.
Skipping it.
===========
Run 166/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_167/ already exists.
Skipping it.
===========
Run 167/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_168/ already exists.
Skipping it.
===========
Run 168/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_169/ already exists.
Skipping it.
===========
Run 169/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_170/ already exists.
Skipping it.
===========
Run 170/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_171/ already exists.
Skipping it.
===========
Run 171/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_172/ already exists.
Skipping it.
===========
Run 172/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_173/ already exists.
Skipping it.
===========
Run 173/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_174/ already exists.
Skipping it.
===========
Run 174/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_175/ already exists.
Skipping it.
===========
Run 175/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_176/ already exists.
Skipping it.
===========
Run 176/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_177/ already exists.
Skipping it.
===========
Run 177/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_178/ already exists.
Skipping it.
===========
Run 178/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_179/ already exists.
Skipping it.
===========
Run 179/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_180/ already exists.
Skipping it.
===========
Run 180/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_181/ already exists.
Skipping it.
===========
Run 181/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_182/ already exists.
Skipping it.
===========
Run 182/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_183/ already exists.
Skipping it.
===========
Run 183/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_184/ already exists.
Skipping it.
===========
Run 184/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_185/ already exists.
Skipping it.
===========
Run 185/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_186/ already exists.
Skipping it.
===========
Run 186/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_187/ already exists.
Skipping it.
===========
Run 187/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_188/ already exists.
Skipping it.
===========
Run 188/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_189/ already exists.
Skipping it.
===========
Run 189/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_190/ already exists.
Skipping it.
===========
Run 190/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_191/ already exists.
Skipping it.
===========
Run 191/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_192/ already exists.
Skipping it.
===========
Run 192/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_193/ already exists.
Skipping it.
===========
Run 193/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_194/ already exists.
Skipping it.
===========
Run 194/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_195/ already exists.
Skipping it.
===========
Run 195/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_196/ already exists.
Skipping it.
===========
Run 196/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_197/ already exists.
Skipping it.
===========
Run 197/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_198/ already exists.
Skipping it.
===========
Run 198/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_199/ already exists.
Skipping it.
===========
Run 199/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_200/ already exists.
Skipping it.
===========
Run 200/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_201/ already exists.
Skipping it.
===========
Run 201/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_202/ already exists.
Skipping it.
===========
Run 202/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_203/ already exists.
Skipping it.
===========
Run 203/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_204/ already exists.
Skipping it.
===========
Run 204/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_205/ already exists.
Skipping it.
===========
Run 205/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_206/ already exists.
Skipping it.
===========
Run 206/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_207/ already exists.
Skipping it.
===========
Run 207/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_208/ already exists.
Skipping it.
===========
Run 208/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_209/ already exists.
Skipping it.
===========
Run 209/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_210/ already exists.
Skipping it.
===========
Run 210/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_211/ already exists.
Skipping it.
===========
Run 211/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_212/ already exists.
Skipping it.
===========
Run 212/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_213/ already exists.
Skipping it.
===========
Run 213/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_214/ already exists.
Skipping it.
===========
Run 214/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_215/ already exists.
Skipping it.
===========
Run 215/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_216/ already exists.
Skipping it.
===========
Run 216/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_217/ already exists.
Skipping it.
===========
Run 217/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_218/ already exists.
Skipping it.
===========
Run 218/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_219/ already exists.
Skipping it.
===========
Run 219/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_220/ already exists.
Skipping it.
===========
Run 220/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_221/ already exists.
Skipping it.
===========
Run 221/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_222/ already exists.
Skipping it.
===========
Run 222/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_223/ already exists.
Skipping it.
===========
Run 223/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_224/ already exists.
Skipping it.
===========
Run 224/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_225/ already exists.
Skipping it.
===========
Run 225/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_226/ already exists.
Skipping it.
===========
Run 226/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_227/ already exists.
Skipping it.
===========
Run 227/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_228/ already exists.
Skipping it.
===========
Run 228/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_229/ already exists.
Skipping it.
===========
Run 229/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_230/ already exists.
Skipping it.
===========
Run 230/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_231/ already exists.
Skipping it.
===========
Run 231/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_232/ already exists.
Skipping it.
===========
Run 232/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_233/ already exists.
Skipping it.
===========
Run 233/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_234/ already exists.
Skipping it.
===========
Run 234/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_235/ already exists.
Skipping it.
===========
Run 235/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_236/ already exists.
Skipping it.
===========
Run 236/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_237/ already exists.
Skipping it.
===========
Run 237/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_238/ already exists.
Skipping it.
===========
Run 238/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_239/ already exists.
Skipping it.
===========
Run 239/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_240/ already exists.
Skipping it.
===========
Run 240/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_241/ already exists.
Skipping it.
===========
Run 241/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_242/ already exists.
Skipping it.
===========
Run 242/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_243/ already exists.
Skipping it.
===========
Run 243/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_244/ already exists.
Skipping it.
===========
Run 244/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_245/ already exists.
Skipping it.
===========
Run 245/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_246/ already exists.
Skipping it.
===========
Run 246/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_247/ already exists.
Skipping it.
===========
Run 247/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_248/ already exists.
Skipping it.
===========
Run 248/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_249/ already exists.
Skipping it.
===========
Run 249/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_250/ already exists.
Skipping it.
===========
Run 250/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_251/ already exists.
Skipping it.
===========
Run 251/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_252/ already exists.
Skipping it.
===========
Run 252/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_253/ already exists.
Skipping it.
===========
Run 253/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_254/ already exists.
Skipping it.
===========
Run 254/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_255/ already exists.
Skipping it.
===========
Run 255/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_256/ already exists.
Skipping it.
===========
Run 256/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_257/ already exists.
Skipping it.
===========
Run 257/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_258/ already exists.
Skipping it.
===========
Run 258/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_259/ already exists.
Skipping it.
===========
Run 259/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_260/ already exists.
Skipping it.
===========
Run 260/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_261/ already exists.
Skipping it.
===========
Run 261/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_262/ already exists.
Skipping it.
===========
Run 262/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_263/ already exists.
Skipping it.
===========
Run 263/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_264/ already exists.
Skipping it.
===========
Run 264/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_265/ already exists.
Skipping it.
===========
Run 265/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_266/ already exists.
Skipping it.
===========
Run 266/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_267/ already exists.
Skipping it.
===========
Run 267/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_268/ already exists.
Skipping it.
===========
Run 268/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_269/ already exists.
Skipping it.
===========
Run 269/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_270/ already exists.
Skipping it.
===========
Run 270/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_271/ already exists.
Skipping it.
===========
Run 271/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_272/ already exists.
Skipping it.
===========
Run 272/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_273/ already exists.
Skipping it.
===========
Run 273/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_274/ already exists.
Skipping it.
===========
Run 274/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_275/ already exists.
Skipping it.
===========
Run 275/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_276/ already exists.
Skipping it.
===========
Run 276/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_277/ already exists.
Skipping it.
===========
Run 277/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_278/ already exists.
Skipping it.
===========
Run 278/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_279/ already exists.
Skipping it.
===========
Run 279/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_280/ already exists.
Skipping it.
===========
Run 280/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_281/ already exists.
Skipping it.
===========
Run 281/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_282/ already exists.
Skipping it.
===========
Run 282/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_283/ already exists.
Skipping it.
===========
Run 283/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_284/ already exists.
Skipping it.
===========
Run 284/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_285/ already exists.
Skipping it.
===========
Run 285/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_286/ already exists.
Skipping it.
===========
Run 286/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_287/ already exists.
Skipping it.
===========
Run 287/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_288/ already exists.
Skipping it.
===========
Run 288/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_289/ already exists.
Skipping it.
===========
Run 289/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_290/ already exists.
Skipping it.
===========
Run 290/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_291/ already exists.
Skipping it.
===========
Run 291/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_292/ already exists.
Skipping it.
===========
Run 292/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_293/ already exists.
Skipping it.
===========
Run 293/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_294/ already exists.
Skipping it.
===========
Run 294/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_295/ already exists.
Skipping it.
===========
Run 295/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_296/ already exists.
Skipping it.
===========
Run 296/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_297/ already exists.
Skipping it.
===========
Run 297/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_298/ already exists.
Skipping it.
===========
Run 298/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_299/ already exists.
Skipping it.
===========
Run 299/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_300/ already exists.
Skipping it.
===========
Run 300/720 already exists. Skipping it.
===========

Directory ../../results/CsplineN_new/run_301/ already exists.
Skipping it.
===========
Run 301/720 already exists. Skipping it.
===========

===========
Generating train data for run 302.
===========
Train data generated in 0.23 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_302/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 869}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_302/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.7724807 ,  3.5952213 ,  8.442487  , ...,  7.3644695 ,
         3.6588435 ,  2.0248146 ],
       [ 6.6242166 ,  7.1665483 ,  6.4277024 , ...,  3.1194153 ,
         2.6248946 ,  8.037665  ],
       [ 4.5211086 ,  5.2663136 , -0.6501303 , ...,  0.17722613,
         6.462096  ,  1.3170475 ],
       ...,
       [ 5.2085795 ,  5.348097  , -0.4658583 , ..., -0.03725696,
         5.9864964 ,  1.2388526 ],
       [ 3.9188156 ,  5.4859467 , -0.29968688, ...,  0.4149692 ,
         6.0867124 ,  1.4174792 ],
       [ 2.283803  ,  2.9701724 ,  8.729265  , ...,  6.0229187 ,
         3.2842712 ,  2.1182036 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_302/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_302
self.data_kwargs: {'seed': 869}
self.x_data: [[ 1.7417877   3.5044646   9.194398   ...  7.377848    2.8874114
   1.7757134 ]
 [ 3.8693519   4.134066    8.323213   ...  7.5259514   3.079576
   1.8540689 ]
 [ 2.7888105   3.5250566   6.8470335  ...  7.0512147   2.9893377
   1.7142482 ]
 ...
 [ 3.8914979   5.948059   -0.25578696 ...  1.7629418   6.8860593
   1.464444  ]
 [ 3.0775785   3.9001913   8.887795   ...  7.2041593   3.5200696
   1.5176823 ]
 [ 1.0419946   3.6002321   7.1163735  ...  7.3799496   3.218665
   1.6207042 ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_10"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_11 (InputLayer)       [(None, 32)]              0         
                                                                 
 log_prob_layer (LogProbLaye  (None,)                  2305120   
 r)                                                              
                                                                 
=================================================================
Total params: 2,305,120
Trainable params: 2,305,120
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer'")
self.model: <keras.engine.functional.Functional object at 0x7f5f18596770>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7f5f185b47c0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7f5f185b47c0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7f5f18571900>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7f5eb8689e70>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7f5eb868a3e0>, <keras.callbacks.ModelCheckpoint object at 0x7f5eb868a530>, <keras.callbacks.EarlyStopping object at 0x7f5eb868a740>, <keras.callbacks.ReduceLROnPlateau object at 0x7f5eb868a770>, <keras.callbacks.TerminateOnNaN object at 0x7f5eb868a4a0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.7724807 ,  3.5952213 ,  8.442487  , ...,  7.3644695 ,
         3.6588435 ,  2.0248146 ],
       [ 6.6242166 ,  7.1665483 ,  6.4277024 , ...,  3.1194153 ,
         2.6248946 ,  8.037665  ],
       [ 4.5211086 ,  5.2663136 , -0.6501303 , ...,  0.17722613,
         6.462096  ,  1.3170475 ],
       ...,
       [ 5.2085795 ,  5.348097  , -0.4658583 , ..., -0.03725696,
         5.9864964 ,  1.2388526 ],
       [ 3.9188156 ,  5.4859467 , -0.29968688, ...,  0.4149692 ,
         6.0867124 ,  1.4174792 ],
       [ 2.283803  ,  2.9701724 ,  8.729265  , ...,  6.0229187 ,
         3.2842712 ,  2.1182036 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_302/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 302/720 with hyperparameters:
timestamp = 2023-09-23 15:08:39.364696
ndims = 32
seed_train = 869
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 8
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 2305120
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 1.7417877   3.5044646   9.194398    1.0621872   8.910313    1.2448134
  9.752992    4.795541   10.214517    5.8200784   7.3571367   0.42017213
  3.0764782   1.1773593   3.1572356   1.3086243   2.6951017   5.712275
  0.4469142   6.9349284   5.5393224   1.8138231   6.1143165   1.1455625
  7.183009    9.098161    3.4021838   5.9704523   0.79392874  7.377848
  2.8874114   1.7757134 ]
Epoch 1/1000
2023-09-23 15:10:08.246 
Epoch 1/1000 
	 loss: 58.4637, MinusLogProbMetric: 58.4637, val_loss: 25.0139, val_MinusLogProbMetric: 25.0139

Epoch 1: val_loss improved from inf to 25.01390, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 117s - loss: 58.4637 - MinusLogProbMetric: 58.4637 - val_loss: 25.0139 - val_MinusLogProbMetric: 25.0139 - lr: 0.0010 - 117s/epoch - 597ms/step
Epoch 2/1000
2023-09-23 15:10:40.550 
Epoch 2/1000 
	 loss: 24.1688, MinusLogProbMetric: 24.1688, val_loss: 22.2324, val_MinusLogProbMetric: 22.2324

Epoch 2: val_loss improved from 25.01390 to 22.23243, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 32s - loss: 24.1688 - MinusLogProbMetric: 24.1688 - val_loss: 22.2324 - val_MinusLogProbMetric: 22.2324 - lr: 0.0010 - 32s/epoch - 164ms/step
Epoch 3/1000
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Batch 50: Invalid loss, terminating training
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
2023-09-23 15:11:14.781 
Epoch 1/1000 
	 loss: nan, MinusLogProbMetric: 1342.9625, val_loss: nan, val_MinusLogProbMetric: nan

Epoch 1: val_loss did not improve from inf
196/196 - 155s - loss: nan - MinusLogProbMetric: 1342.9625 - val_loss: nan - val_MinusLogProbMetric: nan - lr: 0.0010 - 155s/epoch - 792ms/step
2023-09-23 15:11:16.004 
Epoch 3/1000 
	 loss: 22.0438, MinusLogProbMetric: 22.0438, val_loss: 22.6853, val_MinusLogProbMetric: 22.6853

Epoch 3: val_loss did not improve from 22.23243
196/196 - 35s - loss: 22.0438 - MinusLogProbMetric: 22.0438 - val_loss: 22.6853 - val_MinusLogProbMetric: 22.6853 - lr: 0.0010 - 35s/epoch - 178ms/step
Epoch 4/1000
The loss history contains NaN values.
Training failed: trying again with seed 235536 and lr 0.0003333333333333333.
===========
Generating train data for run 302.
===========
Train data generated in 0.24 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/CsplineN_new/run_302/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 869}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/CsplineN_new/run_302/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.7724807 ,  3.5952213 ,  8.442487  , ...,  7.3644695 ,
         3.6588435 ,  2.0248146 ],
       [ 6.6242166 ,  7.1665483 ,  6.4277024 , ...,  3.1194153 ,
         2.6248946 ,  8.037665  ],
       [ 4.5211086 ,  5.2663136 , -0.6501303 , ...,  0.17722613,
         6.462096  ,  1.3170475 ],
       ...,
       [ 5.2085795 ,  5.348097  , -0.4658583 , ..., -0.03725696,
         5.9864964 ,  1.2388526 ],
       [ 3.9188156 ,  5.4859467 , -0.29968688, ...,  0.4149692 ,
         6.0867124 ,  1.4174792 ],
       [ 2.283803  ,  2.9701724 ,  8.729265  , ...,  6.0229187 ,
         3.2842712 ,  2.1182036 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline", batch_shape=[], min_event_ndims=1, bijectors=[Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline, Permute, Cspline])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/CsplineN_new/run_302/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/CsplineN_new/run_302
self.data_kwargs: {'seed': 869}
self.x_data: [[ 1.7417877   3.5044646   9.194398   ...  7.377848    2.8874114
   1.7757134 ]
 [ 3.8693519   4.134066    8.323213   ...  7.5259514   3.079576
   1.8540689 ]
 [ 2.7888105   3.5250566   6.8470335  ...  7.0512147   2.9893377
   1.7142482 ]
 ...
 [ 3.8914979   5.948059   -0.25578696 ...  1.7629418   6.8860593
   1.464444  ]
 [ 3.0775785   3.9001913   8.887795   ...  7.2041593   3.5200696
   1.5176823 ]
 [ 1.0419946   3.6002321   7.1163735  ...  7.3799496   3.218665
   1.6207042 ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_21"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_22 (InputLayer)       [(None, 32)]              0         
                                                                 
 log_prob_layer_1 (LogProbLa  (None,)                  2305120   
 yer)                                                            
                                                                 
=================================================================
Total params: 2,305,120
Trainable params: 2,305,120
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_1/chain_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_cspline_of_permute_of_csplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_1'")
self.model: <keras.engine.functional.Functional object at 0x7f630fc8feb0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7f62ff62d2a0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7f62ff62d2a0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7f62ff5864d0>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7f62ff5b4c10>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7f62ff5b5180>, <keras.callbacks.ModelCheckpoint object at 0x7f62ff5b5240>, <keras.callbacks.EarlyStopping object at 0x7f62ff5b54b0>, <keras.callbacks.ReduceLROnPlateau object at 0x7f62ff5b54e0>, <keras.callbacks.TerminateOnNaN object at 0x7f62ff5b5120>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.7724807 ,  3.5952213 ,  8.442487  , ...,  7.3644695 ,
         3.6588435 ,  2.0248146 ],
       [ 6.6242166 ,  7.1665483 ,  6.4277024 , ...,  3.1194153 ,
         2.6248946 ,  8.037665  ],
       [ 4.5211086 ,  5.2663136 , -0.6501303 , ...,  0.17722613,
         6.462096  ,  1.3170475 ],
       ...,
       [ 5.2085795 ,  5.348097  , -0.4658583 , ..., -0.03725696,
         5.9864964 ,  1.2388526 ],
       [ 3.9188156 ,  5.4859467 , -0.29968688, ...,  0.4149692 ,
         6.0867124 ,  1.4174792 ],
       [ 2.283803  ,  2.9701724 ,  8.729265  , ...,  6.0229187 ,
         3.2842712 ,  2.1182036 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/CsplineN_new/run_302/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 302/720 with hyperparameters:
timestamp = 2023-09-23 15:11:22.368459
ndims = 32
seed_train = 869
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = CsplineN
nbijectors = 10
spline_knots = 8
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 2305120
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.0003333333333333333...
Train first sample: [ 1.7417877   3.5044646   9.194398    1.0621872   8.910313    1.2448134
  9.752992    4.795541   10.214517    5.8200784   7.3571367   0.42017213
  3.0764782   1.1773593   3.1572356   1.3086243   2.6951017   5.712275
  0.4469142   6.9349284   5.5393224   1.8138231   6.1143165   1.1455625
  7.183009    9.098161    3.4021838   5.9704523   0.79392874  7.377848
  2.8874114   1.7757134 ]
Epoch 1/1000
2023-09-23 15:11:51.072 
Epoch 4/1000 
	 loss: 21.1209, MinusLogProbMetric: 21.1209, val_loss: 21.2286, val_MinusLogProbMetric: 21.2286

Epoch 4: val_loss improved from 22.23243 to 21.22864, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 36s - loss: 21.1209 - MinusLogProbMetric: 21.1209 - val_loss: 21.2286 - val_MinusLogProbMetric: 21.2286 - lr: 0.0010 - 36s/epoch - 182ms/step
Epoch 5/1000
2023-09-23 15:12:25.792 
Epoch 5/1000 
	 loss: 20.7024, MinusLogProbMetric: 20.7024, val_loss: 22.5371, val_MinusLogProbMetric: 22.5371

Epoch 5: val_loss did not improve from 21.22864
196/196 - 34s - loss: 20.7024 - MinusLogProbMetric: 20.7024 - val_loss: 22.5371 - val_MinusLogProbMetric: 22.5371 - lr: 0.0010 - 34s/epoch - 174ms/step
Epoch 6/1000
2023-09-23 15:12:59.438 
Epoch 6/1000 
	 loss: 20.2386, MinusLogProbMetric: 20.2386, val_loss: 20.0524, val_MinusLogProbMetric: 20.0524

Epoch 6: val_loss improved from 21.22864 to 20.05236, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 34s - loss: 20.2386 - MinusLogProbMetric: 20.2386 - val_loss: 20.0524 - val_MinusLogProbMetric: 20.0524 - lr: 0.0010 - 34s/epoch - 176ms/step
Epoch 7/1000
2023-09-23 15:13:37.176 
Epoch 7/1000 
	 loss: 19.9676, MinusLogProbMetric: 19.9676, val_loss: 19.8477, val_MinusLogProbMetric: 19.8477

Epoch 7: val_loss improved from 20.05236 to 19.84765, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 38s - loss: 19.9676 - MinusLogProbMetric: 19.9676 - val_loss: 19.8477 - val_MinusLogProbMetric: 19.8477 - lr: 0.0010 - 38s/epoch - 192ms/step
Epoch 8/1000
2023-09-23 15:14:20.542 
Epoch 8/1000 
	 loss: 19.6134, MinusLogProbMetric: 19.6134, val_loss: 21.4649, val_MinusLogProbMetric: 21.4649

Epoch 8: val_loss did not improve from 19.84765
196/196 - 43s - loss: 19.6134 - MinusLogProbMetric: 19.6134 - val_loss: 21.4649 - val_MinusLogProbMetric: 21.4649 - lr: 0.0010 - 43s/epoch - 217ms/step
Epoch 9/1000
2023-09-23 15:14:32.654 
Epoch 1/1000 
	 loss: 216.5350, MinusLogProbMetric: 216.5350, val_loss: 70.8826, val_MinusLogProbMetric: 70.8826

Epoch 1: val_loss improved from inf to 70.88261, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 191s - loss: 216.5350 - MinusLogProbMetric: 216.5350 - val_loss: 70.8826 - val_MinusLogProbMetric: 70.8826 - lr: 3.3333e-04 - 191s/epoch - 976ms/step
Epoch 2/1000
2023-09-23 15:15:00.302 
Epoch 9/1000 
	 loss: 19.5536, MinusLogProbMetric: 19.5536, val_loss: 19.7071, val_MinusLogProbMetric: 19.7071

Epoch 9: val_loss improved from 19.84765 to 19.70712, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 40s - loss: 19.5536 - MinusLogProbMetric: 19.5536 - val_loss: 19.7071 - val_MinusLogProbMetric: 19.7071 - lr: 0.0010 - 40s/epoch - 206ms/step
Epoch 10/1000
2023-09-23 15:15:32.581 
Epoch 2/1000 
	 loss: 55.9964, MinusLogProbMetric: 55.9964, val_loss: 41.3520, val_MinusLogProbMetric: 41.3520

Epoch 2: val_loss improved from 70.88261 to 41.35202, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 59s - loss: 55.9964 - MinusLogProbMetric: 55.9964 - val_loss: 41.3520 - val_MinusLogProbMetric: 41.3520 - lr: 3.3333e-04 - 59s/epoch - 302ms/step
Epoch 3/1000
2023-09-23 15:15:37.331 
Epoch 10/1000 
	 loss: 19.2224, MinusLogProbMetric: 19.2224, val_loss: 18.7468, val_MinusLogProbMetric: 18.7468

Epoch 10: val_loss improved from 19.70712 to 18.74683, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 37s - loss: 19.2224 - MinusLogProbMetric: 19.2224 - val_loss: 18.7468 - val_MinusLogProbMetric: 18.7468 - lr: 0.0010 - 37s/epoch - 189ms/step
Epoch 11/1000
2023-09-23 15:16:15.392 
Epoch 11/1000 
	 loss: 19.0627, MinusLogProbMetric: 19.0627, val_loss: 18.6899, val_MinusLogProbMetric: 18.6899

Epoch 11: val_loss improved from 18.74683 to 18.68987, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 38s - loss: 19.0627 - MinusLogProbMetric: 19.0627 - val_loss: 18.6899 - val_MinusLogProbMetric: 18.6899 - lr: 0.0010 - 38s/epoch - 195ms/step
Epoch 12/1000
2023-09-23 15:16:30.945 
Epoch 3/1000 
	 loss: 36.5432, MinusLogProbMetric: 36.5432, val_loss: 33.1219, val_MinusLogProbMetric: 33.1219

Epoch 3: val_loss improved from 41.35202 to 33.12192, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 58s - loss: 36.5432 - MinusLogProbMetric: 36.5432 - val_loss: 33.1219 - val_MinusLogProbMetric: 33.1219 - lr: 3.3333e-04 - 58s/epoch - 298ms/step
Epoch 4/1000
2023-09-23 15:16:55.973 
Epoch 12/1000 
	 loss: 18.8916, MinusLogProbMetric: 18.8916, val_loss: 19.4934, val_MinusLogProbMetric: 19.4934

Epoch 12: val_loss did not improve from 18.68987
196/196 - 40s - loss: 18.8916 - MinusLogProbMetric: 18.8916 - val_loss: 19.4934 - val_MinusLogProbMetric: 19.4934 - lr: 0.0010 - 40s/epoch - 203ms/step
Epoch 13/1000
2023-09-23 15:17:30.266 
Epoch 4/1000 
	 loss: 31.4443, MinusLogProbMetric: 31.4443, val_loss: 31.1444, val_MinusLogProbMetric: 31.1444

Epoch 4: val_loss improved from 33.12192 to 31.14441, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 59s - loss: 31.4443 - MinusLogProbMetric: 31.4443 - val_loss: 31.1444 - val_MinusLogProbMetric: 31.1444 - lr: 3.3333e-04 - 59s/epoch - 303ms/step
Epoch 5/1000
2023-09-23 15:17:36.594 
Epoch 13/1000 
	 loss: 18.8026, MinusLogProbMetric: 18.8026, val_loss: 18.9799, val_MinusLogProbMetric: 18.9799

Epoch 13: val_loss did not improve from 18.68987
196/196 - 41s - loss: 18.8026 - MinusLogProbMetric: 18.8026 - val_loss: 18.9799 - val_MinusLogProbMetric: 18.9799 - lr: 0.0010 - 41s/epoch - 207ms/step
Epoch 14/1000
2023-09-23 15:18:18.792 
Epoch 14/1000 
	 loss: 18.7839, MinusLogProbMetric: 18.7839, val_loss: 18.5185, val_MinusLogProbMetric: 18.5185

Epoch 14: val_loss improved from 18.68987 to 18.51846, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 43s - loss: 18.7839 - MinusLogProbMetric: 18.7839 - val_loss: 18.5185 - val_MinusLogProbMetric: 18.5185 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 15/1000
2023-09-23 15:18:31.347 
Epoch 5/1000 
	 loss: 28.3638, MinusLogProbMetric: 28.3638, val_loss: 27.7067, val_MinusLogProbMetric: 27.7067

Epoch 5: val_loss improved from 31.14441 to 27.70667, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 61s - loss: 28.3638 - MinusLogProbMetric: 28.3638 - val_loss: 27.7067 - val_MinusLogProbMetric: 27.7067 - lr: 3.3333e-04 - 61s/epoch - 312ms/step
Epoch 6/1000
2023-09-23 15:18:59.718 
Epoch 15/1000 
	 loss: 18.5377, MinusLogProbMetric: 18.5377, val_loss: 18.5023, val_MinusLogProbMetric: 18.5023

Epoch 15: val_loss improved from 18.51846 to 18.50229, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 41s - loss: 18.5377 - MinusLogProbMetric: 18.5377 - val_loss: 18.5023 - val_MinusLogProbMetric: 18.5023 - lr: 0.0010 - 41s/epoch - 209ms/step
Epoch 16/1000
2023-09-23 15:19:33.546 
Epoch 6/1000 
	 loss: 26.7629, MinusLogProbMetric: 26.7629, val_loss: 33.6650, val_MinusLogProbMetric: 33.6650

Epoch 6: val_loss did not improve from 27.70667
196/196 - 61s - loss: 26.7629 - MinusLogProbMetric: 26.7629 - val_loss: 33.6650 - val_MinusLogProbMetric: 33.6650 - lr: 3.3333e-04 - 61s/epoch - 311ms/step
Epoch 7/1000
2023-09-23 15:19:41.236 
Epoch 16/1000 
	 loss: 18.8653, MinusLogProbMetric: 18.8653, val_loss: 18.5137, val_MinusLogProbMetric: 18.5137

Epoch 16: val_loss did not improve from 18.50229
196/196 - 41s - loss: 18.8653 - MinusLogProbMetric: 18.8653 - val_loss: 18.5137 - val_MinusLogProbMetric: 18.5137 - lr: 0.0010 - 41s/epoch - 208ms/step
Epoch 17/1000
2023-09-23 15:20:23.350 
Epoch 17/1000 
	 loss: 18.3637, MinusLogProbMetric: 18.3637, val_loss: 18.4800, val_MinusLogProbMetric: 18.4800

Epoch 17: val_loss improved from 18.50229 to 18.48000, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 43s - loss: 18.3637 - MinusLogProbMetric: 18.3637 - val_loss: 18.4800 - val_MinusLogProbMetric: 18.4800 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 18/1000
2023-09-23 15:20:35.854 
Epoch 7/1000 
	 loss: 25.6053, MinusLogProbMetric: 25.6053, val_loss: 24.2221, val_MinusLogProbMetric: 24.2221

Epoch 7: val_loss improved from 27.70667 to 24.22206, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 63s - loss: 25.6053 - MinusLogProbMetric: 25.6053 - val_loss: 24.2221 - val_MinusLogProbMetric: 24.2221 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 8/1000
2023-09-23 15:21:07.271 
Epoch 18/1000 
	 loss: 18.3152, MinusLogProbMetric: 18.3152, val_loss: 18.5418, val_MinusLogProbMetric: 18.5418

Epoch 18: val_loss did not improve from 18.48000
196/196 - 43s - loss: 18.3152 - MinusLogProbMetric: 18.3152 - val_loss: 18.5418 - val_MinusLogProbMetric: 18.5418 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 19/1000
2023-09-23 15:21:40.879 
Epoch 8/1000 
	 loss: 24.7334, MinusLogProbMetric: 24.7334, val_loss: 24.2106, val_MinusLogProbMetric: 24.2106

Epoch 8: val_loss improved from 24.22206 to 24.21059, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 65s - loss: 24.7334 - MinusLogProbMetric: 24.7334 - val_loss: 24.2106 - val_MinusLogProbMetric: 24.2106 - lr: 3.3333e-04 - 65s/epoch - 333ms/step
Epoch 9/1000
2023-09-23 15:21:50.165 
Epoch 19/1000 
	 loss: 18.5058, MinusLogProbMetric: 18.5058, val_loss: 19.1441, val_MinusLogProbMetric: 19.1441

Epoch 19: val_loss did not improve from 18.48000
196/196 - 43s - loss: 18.5058 - MinusLogProbMetric: 18.5058 - val_loss: 19.1441 - val_MinusLogProbMetric: 19.1441 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 20/1000
2023-09-23 15:22:31.915 
Epoch 20/1000 
	 loss: 18.1173, MinusLogProbMetric: 18.1173, val_loss: 18.0816, val_MinusLogProbMetric: 18.0816

Epoch 20: val_loss improved from 18.48000 to 18.08158, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 42s - loss: 18.1173 - MinusLogProbMetric: 18.1173 - val_loss: 18.0816 - val_MinusLogProbMetric: 18.0816 - lr: 0.0010 - 42s/epoch - 217ms/step
Epoch 21/1000
2023-09-23 15:22:44.279 
Epoch 9/1000 
	 loss: 24.0068, MinusLogProbMetric: 24.0068, val_loss: 26.1598, val_MinusLogProbMetric: 26.1598

Epoch 9: val_loss did not improve from 24.21059
196/196 - 62s - loss: 24.0068 - MinusLogProbMetric: 24.0068 - val_loss: 26.1598 - val_MinusLogProbMetric: 26.1598 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 10/1000
2023-09-23 15:23:14.253 
Epoch 21/1000 
	 loss: 18.1161, MinusLogProbMetric: 18.1161, val_loss: 18.1263, val_MinusLogProbMetric: 18.1263

Epoch 21: val_loss did not improve from 18.08158
196/196 - 42s - loss: 18.1161 - MinusLogProbMetric: 18.1161 - val_loss: 18.1263 - val_MinusLogProbMetric: 18.1263 - lr: 0.0010 - 42s/epoch - 212ms/step
Epoch 22/1000
2023-09-23 15:23:46.455 
Epoch 10/1000 
	 loss: 23.5853, MinusLogProbMetric: 23.5853, val_loss: 25.1278, val_MinusLogProbMetric: 25.1278

Epoch 10: val_loss did not improve from 24.21059
196/196 - 62s - loss: 23.5853 - MinusLogProbMetric: 23.5853 - val_loss: 25.1278 - val_MinusLogProbMetric: 25.1278 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 11/1000
2023-09-23 15:23:56.164 
Epoch 22/1000 
	 loss: 18.2788, MinusLogProbMetric: 18.2788, val_loss: 19.7037, val_MinusLogProbMetric: 19.7037

Epoch 22: val_loss did not improve from 18.08158
196/196 - 42s - loss: 18.2788 - MinusLogProbMetric: 18.2788 - val_loss: 19.7037 - val_MinusLogProbMetric: 19.7037 - lr: 0.0010 - 42s/epoch - 214ms/step
Epoch 23/1000
2023-09-23 15:24:39.636 
Epoch 23/1000 
	 loss: 18.1014, MinusLogProbMetric: 18.1014, val_loss: 18.1267, val_MinusLogProbMetric: 18.1267

Epoch 23: val_loss did not improve from 18.08158
196/196 - 43s - loss: 18.1014 - MinusLogProbMetric: 18.1014 - val_loss: 18.1267 - val_MinusLogProbMetric: 18.1267 - lr: 0.0010 - 43s/epoch - 222ms/step
Epoch 24/1000
2023-09-23 15:24:49.252 
Epoch 11/1000 
	 loss: 23.1464, MinusLogProbMetric: 23.1464, val_loss: 23.8696, val_MinusLogProbMetric: 23.8696

Epoch 11: val_loss improved from 24.21059 to 23.86959, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 64s - loss: 23.1464 - MinusLogProbMetric: 23.1464 - val_loss: 23.8696 - val_MinusLogProbMetric: 23.8696 - lr: 3.3333e-04 - 64s/epoch - 326ms/step
Epoch 12/1000
2023-09-23 15:25:23.167 
Epoch 24/1000 
	 loss: 18.0487, MinusLogProbMetric: 18.0487, val_loss: 17.9835, val_MinusLogProbMetric: 17.9835

Epoch 24: val_loss improved from 18.08158 to 17.98347, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 44s - loss: 18.0487 - MinusLogProbMetric: 18.0487 - val_loss: 17.9835 - val_MinusLogProbMetric: 17.9835 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 25/1000
2023-09-23 15:25:53.709 
Epoch 12/1000 
	 loss: 22.6341, MinusLogProbMetric: 22.6341, val_loss: 22.3377, val_MinusLogProbMetric: 22.3377

Epoch 12: val_loss improved from 23.86959 to 22.33771, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 64s - loss: 22.6341 - MinusLogProbMetric: 22.6341 - val_loss: 22.3377 - val_MinusLogProbMetric: 22.3377 - lr: 3.3333e-04 - 64s/epoch - 328ms/step
Epoch 13/1000
2023-09-23 15:26:06.925 
Epoch 25/1000 
	 loss: 17.9148, MinusLogProbMetric: 17.9148, val_loss: 18.1126, val_MinusLogProbMetric: 18.1126

Epoch 25: val_loss did not improve from 17.98347
196/196 - 43s - loss: 17.9148 - MinusLogProbMetric: 17.9148 - val_loss: 18.1126 - val_MinusLogProbMetric: 18.1126 - lr: 0.0010 - 43s/epoch - 219ms/step
Epoch 26/1000
2023-09-23 15:26:48.360 
Epoch 26/1000 
	 loss: 17.9069, MinusLogProbMetric: 17.9069, val_loss: 17.9195, val_MinusLogProbMetric: 17.9195

Epoch 26: val_loss improved from 17.98347 to 17.91947, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 42s - loss: 17.9069 - MinusLogProbMetric: 17.9069 - val_loss: 17.9195 - val_MinusLogProbMetric: 17.9195 - lr: 0.0010 - 42s/epoch - 215ms/step
Epoch 27/1000
2023-09-23 15:26:55.485 
Epoch 13/1000 
	 loss: 22.3910, MinusLogProbMetric: 22.3910, val_loss: 22.0740, val_MinusLogProbMetric: 22.0740

Epoch 13: val_loss improved from 22.33771 to 22.07405, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 62s - loss: 22.3910 - MinusLogProbMetric: 22.3910 - val_loss: 22.0740 - val_MinusLogProbMetric: 22.0740 - lr: 3.3333e-04 - 62s/epoch - 316ms/step
Epoch 14/1000
2023-09-23 15:27:31.547 
Epoch 27/1000 
	 loss: 17.9129, MinusLogProbMetric: 17.9129, val_loss: 18.1467, val_MinusLogProbMetric: 18.1467

Epoch 27: val_loss did not improve from 17.91947
196/196 - 42s - loss: 17.9129 - MinusLogProbMetric: 17.9129 - val_loss: 18.1467 - val_MinusLogProbMetric: 18.1467 - lr: 0.0010 - 42s/epoch - 217ms/step
Epoch 28/1000
2023-09-23 15:27:59.626 
Epoch 14/1000 
	 loss: 22.0856, MinusLogProbMetric: 22.0856, val_loss: 22.1198, val_MinusLogProbMetric: 22.1198

Epoch 14: val_loss did not improve from 22.07405
196/196 - 63s - loss: 22.0856 - MinusLogProbMetric: 22.0856 - val_loss: 22.1198 - val_MinusLogProbMetric: 22.1198 - lr: 3.3333e-04 - 63s/epoch - 322ms/step
Epoch 15/1000
2023-09-23 15:28:14.594 
Epoch 28/1000 
	 loss: 17.8236, MinusLogProbMetric: 17.8236, val_loss: 18.9619, val_MinusLogProbMetric: 18.9619

Epoch 28: val_loss did not improve from 17.91947
196/196 - 43s - loss: 17.8236 - MinusLogProbMetric: 17.8236 - val_loss: 18.9619 - val_MinusLogProbMetric: 18.9619 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 29/1000
2023-09-23 15:28:52.037 
Epoch 29/1000 
	 loss: 17.8668, MinusLogProbMetric: 17.8668, val_loss: 17.7420, val_MinusLogProbMetric: 17.7420

Epoch 29: val_loss improved from 17.91947 to 17.74203, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 38s - loss: 17.8668 - MinusLogProbMetric: 17.8668 - val_loss: 17.7420 - val_MinusLogProbMetric: 17.7420 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 30/1000
2023-09-23 15:28:58.168 
Epoch 15/1000 
	 loss: 22.3351, MinusLogProbMetric: 22.3351, val_loss: 22.2142, val_MinusLogProbMetric: 22.2142

Epoch 15: val_loss did not improve from 22.07405
196/196 - 59s - loss: 22.3351 - MinusLogProbMetric: 22.3351 - val_loss: 22.2142 - val_MinusLogProbMetric: 22.2142 - lr: 3.3333e-04 - 59s/epoch - 299ms/step
Epoch 16/1000
2023-09-23 15:29:29.768 
Epoch 30/1000 
	 loss: 17.8218, MinusLogProbMetric: 17.8218, val_loss: 18.1537, val_MinusLogProbMetric: 18.1537

Epoch 30: val_loss did not improve from 17.74203
196/196 - 37s - loss: 17.8218 - MinusLogProbMetric: 17.8218 - val_loss: 18.1537 - val_MinusLogProbMetric: 18.1537 - lr: 0.0010 - 37s/epoch - 189ms/step
Epoch 31/1000
2023-09-23 15:29:55.443 
Epoch 16/1000 
	 loss: 21.8025, MinusLogProbMetric: 21.8025, val_loss: 23.1521, val_MinusLogProbMetric: 23.1521

Epoch 16: val_loss did not improve from 22.07405
196/196 - 57s - loss: 21.8025 - MinusLogProbMetric: 21.8025 - val_loss: 23.1521 - val_MinusLogProbMetric: 23.1521 - lr: 3.3333e-04 - 57s/epoch - 292ms/step
Epoch 17/1000
2023-09-23 15:30:06.390 
Epoch 31/1000 
	 loss: 17.7771, MinusLogProbMetric: 17.7771, val_loss: 17.6615, val_MinusLogProbMetric: 17.6615

Epoch 31: val_loss improved from 17.74203 to 17.66153, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 37s - loss: 17.7771 - MinusLogProbMetric: 17.7771 - val_loss: 17.6615 - val_MinusLogProbMetric: 17.6615 - lr: 0.0010 - 37s/epoch - 191ms/step
Epoch 32/1000
2023-09-23 15:30:47.009 
Epoch 32/1000 
	 loss: 17.6857, MinusLogProbMetric: 17.6857, val_loss: 18.8533, val_MinusLogProbMetric: 18.8533

Epoch 32: val_loss did not improve from 17.66153
196/196 - 40s - loss: 17.6857 - MinusLogProbMetric: 17.6857 - val_loss: 18.8533 - val_MinusLogProbMetric: 18.8533 - lr: 0.0010 - 40s/epoch - 203ms/step
Epoch 33/1000
2023-09-23 15:30:53.928 
Epoch 17/1000 
	 loss: 21.7954, MinusLogProbMetric: 21.7954, val_loss: 21.4978, val_MinusLogProbMetric: 21.4978

Epoch 17: val_loss improved from 22.07405 to 21.49781, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 59s - loss: 21.7954 - MinusLogProbMetric: 21.7954 - val_loss: 21.4978 - val_MinusLogProbMetric: 21.4978 - lr: 3.3333e-04 - 59s/epoch - 304ms/step
Epoch 18/1000
2023-09-23 15:31:28.241 
Epoch 33/1000 
	 loss: 17.6983, MinusLogProbMetric: 17.6983, val_loss: 17.8342, val_MinusLogProbMetric: 17.8342

Epoch 33: val_loss did not improve from 17.66153
196/196 - 41s - loss: 17.6983 - MinusLogProbMetric: 17.6983 - val_loss: 17.8342 - val_MinusLogProbMetric: 17.8342 - lr: 0.0010 - 41s/epoch - 210ms/step
Epoch 34/1000
2023-09-23 15:31:58.541 
Epoch 18/1000 
	 loss: 21.6508, MinusLogProbMetric: 21.6508, val_loss: 22.5922, val_MinusLogProbMetric: 22.5922

Epoch 18: val_loss did not improve from 21.49781
196/196 - 64s - loss: 21.6508 - MinusLogProbMetric: 21.6508 - val_loss: 22.5922 - val_MinusLogProbMetric: 22.5922 - lr: 3.3333e-04 - 64s/epoch - 324ms/step
Epoch 19/1000
2023-09-23 15:32:11.361 
Epoch 34/1000 
	 loss: 17.6557, MinusLogProbMetric: 17.6557, val_loss: 17.8799, val_MinusLogProbMetric: 17.8799

Epoch 34: val_loss did not improve from 17.66153
196/196 - 43s - loss: 17.6557 - MinusLogProbMetric: 17.6557 - val_loss: 17.8799 - val_MinusLogProbMetric: 17.8799 - lr: 0.0010 - 43s/epoch - 220ms/step
Epoch 35/1000
2023-09-23 15:32:54.892 
Epoch 35/1000 
	 loss: 17.6174, MinusLogProbMetric: 17.6174, val_loss: 18.1020, val_MinusLogProbMetric: 18.1020

Epoch 35: val_loss did not improve from 17.66153
196/196 - 44s - loss: 17.6174 - MinusLogProbMetric: 17.6174 - val_loss: 18.1020 - val_MinusLogProbMetric: 18.1020 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 36/1000
2023-09-23 15:33:03.542 
Epoch 19/1000 
	 loss: 21.5836, MinusLogProbMetric: 21.5836, val_loss: 22.3734, val_MinusLogProbMetric: 22.3734

Epoch 19: val_loss did not improve from 21.49781
196/196 - 65s - loss: 21.5836 - MinusLogProbMetric: 21.5836 - val_loss: 22.3734 - val_MinusLogProbMetric: 22.3734 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 20/1000
2023-09-23 15:33:39.205 
Epoch 36/1000 
	 loss: 17.6453, MinusLogProbMetric: 17.6453, val_loss: 17.9237, val_MinusLogProbMetric: 17.9237

Epoch 36: val_loss did not improve from 17.66153
196/196 - 44s - loss: 17.6453 - MinusLogProbMetric: 17.6453 - val_loss: 17.9237 - val_MinusLogProbMetric: 17.9237 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 37/1000
2023-09-23 15:34:09.202 
Epoch 20/1000 
	 loss: 21.2535, MinusLogProbMetric: 21.2535, val_loss: 20.9089, val_MinusLogProbMetric: 20.9089

Epoch 20: val_loss improved from 21.49781 to 20.90892, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 67s - loss: 21.2535 - MinusLogProbMetric: 21.2535 - val_loss: 20.9089 - val_MinusLogProbMetric: 20.9089 - lr: 3.3333e-04 - 67s/epoch - 340ms/step
Epoch 21/1000
2023-09-23 15:34:24.260 
Epoch 37/1000 
	 loss: 17.6176, MinusLogProbMetric: 17.6176, val_loss: 17.9592, val_MinusLogProbMetric: 17.9592

Epoch 37: val_loss did not improve from 17.66153
196/196 - 45s - loss: 17.6176 - MinusLogProbMetric: 17.6176 - val_loss: 17.9592 - val_MinusLogProbMetric: 17.9592 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 38/1000
2023-09-23 15:35:09.445 
Epoch 38/1000 
	 loss: 17.5681, MinusLogProbMetric: 17.5681, val_loss: 17.9427, val_MinusLogProbMetric: 17.9427

Epoch 38: val_loss did not improve from 17.66153
196/196 - 45s - loss: 17.5681 - MinusLogProbMetric: 17.5681 - val_loss: 17.9427 - val_MinusLogProbMetric: 17.9427 - lr: 0.0010 - 45s/epoch - 231ms/step
Epoch 39/1000
2023-09-23 15:35:15.779 
Epoch 21/1000 
	 loss: 21.0976, MinusLogProbMetric: 21.0976, val_loss: 23.6870, val_MinusLogProbMetric: 23.6870

Epoch 21: val_loss did not improve from 20.90892
196/196 - 66s - loss: 21.0976 - MinusLogProbMetric: 21.0976 - val_loss: 23.6870 - val_MinusLogProbMetric: 23.6870 - lr: 3.3333e-04 - 66s/epoch - 335ms/step
Epoch 22/1000
2023-09-23 15:35:54.134 
Epoch 39/1000 
	 loss: 17.4878, MinusLogProbMetric: 17.4878, val_loss: 17.8211, val_MinusLogProbMetric: 17.8211

Epoch 39: val_loss did not improve from 17.66153
196/196 - 45s - loss: 17.4878 - MinusLogProbMetric: 17.4878 - val_loss: 17.8211 - val_MinusLogProbMetric: 17.8211 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 40/1000
2023-09-23 15:36:20.905 
Epoch 22/1000 
	 loss: 21.0264, MinusLogProbMetric: 21.0264, val_loss: 22.6149, val_MinusLogProbMetric: 22.6149

Epoch 22: val_loss did not improve from 20.90892
196/196 - 65s - loss: 21.0264 - MinusLogProbMetric: 21.0264 - val_loss: 22.6149 - val_MinusLogProbMetric: 22.6149 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 23/1000
2023-09-23 15:36:39.015 
Epoch 40/1000 
	 loss: 17.5601, MinusLogProbMetric: 17.5601, val_loss: 18.0036, val_MinusLogProbMetric: 18.0036

Epoch 40: val_loss did not improve from 17.66153
196/196 - 45s - loss: 17.5601 - MinusLogProbMetric: 17.5601 - val_loss: 18.0036 - val_MinusLogProbMetric: 18.0036 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 41/1000
2023-09-23 15:37:23.973 
Epoch 41/1000 
	 loss: 17.5840, MinusLogProbMetric: 17.5840, val_loss: 18.0075, val_MinusLogProbMetric: 18.0075

Epoch 41: val_loss did not improve from 17.66153
196/196 - 45s - loss: 17.5840 - MinusLogProbMetric: 17.5840 - val_loss: 18.0075 - val_MinusLogProbMetric: 18.0075 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 42/1000
2023-09-23 15:37:26.792 
Epoch 23/1000 
	 loss: 20.6289, MinusLogProbMetric: 20.6289, val_loss: 21.2073, val_MinusLogProbMetric: 21.2073

Epoch 23: val_loss did not improve from 20.90892
196/196 - 66s - loss: 20.6289 - MinusLogProbMetric: 20.6289 - val_loss: 21.2073 - val_MinusLogProbMetric: 21.2073 - lr: 3.3333e-04 - 66s/epoch - 336ms/step
Epoch 24/1000
2023-09-23 15:38:08.611 
Epoch 42/1000 
	 loss: 17.4681, MinusLogProbMetric: 17.4681, val_loss: 17.8624, val_MinusLogProbMetric: 17.8624

Epoch 42: val_loss did not improve from 17.66153
196/196 - 45s - loss: 17.4681 - MinusLogProbMetric: 17.4681 - val_loss: 17.8624 - val_MinusLogProbMetric: 17.8624 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 43/1000
2023-09-23 15:38:31.853 
Epoch 24/1000 
	 loss: 20.8207, MinusLogProbMetric: 20.8207, val_loss: 21.1744, val_MinusLogProbMetric: 21.1744

Epoch 24: val_loss did not improve from 20.90892
196/196 - 65s - loss: 20.8207 - MinusLogProbMetric: 20.8207 - val_loss: 21.1744 - val_MinusLogProbMetric: 21.1744 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 25/1000
2023-09-23 15:38:52.408 
Epoch 43/1000 
	 loss: 17.4500, MinusLogProbMetric: 17.4500, val_loss: 17.8577, val_MinusLogProbMetric: 17.8577

Epoch 43: val_loss did not improve from 17.66153
196/196 - 44s - loss: 17.4500 - MinusLogProbMetric: 17.4500 - val_loss: 17.8577 - val_MinusLogProbMetric: 17.8577 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 44/1000
2023-09-23 15:39:36.394 
Epoch 44/1000 
	 loss: 17.5021, MinusLogProbMetric: 17.5021, val_loss: 17.9278, val_MinusLogProbMetric: 17.9278

Epoch 44: val_loss did not improve from 17.66153
196/196 - 44s - loss: 17.5021 - MinusLogProbMetric: 17.5021 - val_loss: 17.9278 - val_MinusLogProbMetric: 17.9278 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 45/1000
2023-09-23 15:39:36.625 
Epoch 25/1000 
	 loss: 20.7494, MinusLogProbMetric: 20.7494, val_loss: 20.7705, val_MinusLogProbMetric: 20.7705

Epoch 25: val_loss improved from 20.90892 to 20.77048, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 66s - loss: 20.7494 - MinusLogProbMetric: 20.7494 - val_loss: 20.7705 - val_MinusLogProbMetric: 20.7705 - lr: 3.3333e-04 - 66s/epoch - 336ms/step
Epoch 26/1000
2023-09-23 15:40:20.285 
Epoch 45/1000 
	 loss: 17.4849, MinusLogProbMetric: 17.4849, val_loss: 18.2431, val_MinusLogProbMetric: 18.2431

Epoch 45: val_loss did not improve from 17.66153
196/196 - 44s - loss: 17.4849 - MinusLogProbMetric: 17.4849 - val_loss: 18.2431 - val_MinusLogProbMetric: 18.2431 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 46/1000
2023-09-23 15:40:43.867 
Epoch 26/1000 
	 loss: 20.6286, MinusLogProbMetric: 20.6286, val_loss: 20.2866, val_MinusLogProbMetric: 20.2866

Epoch 26: val_loss improved from 20.77048 to 20.28655, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 67s - loss: 20.6286 - MinusLogProbMetric: 20.6286 - val_loss: 20.2866 - val_MinusLogProbMetric: 20.2866 - lr: 3.3333e-04 - 67s/epoch - 343ms/step
Epoch 27/1000
2023-09-23 15:41:04.255 
Epoch 46/1000 
	 loss: 17.4112, MinusLogProbMetric: 17.4112, val_loss: 17.7136, val_MinusLogProbMetric: 17.7136

Epoch 46: val_loss did not improve from 17.66153
196/196 - 44s - loss: 17.4112 - MinusLogProbMetric: 17.4112 - val_loss: 17.7136 - val_MinusLogProbMetric: 17.7136 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 47/1000
2023-09-23 15:41:48.247 
Epoch 47/1000 
	 loss: 17.3844, MinusLogProbMetric: 17.3844, val_loss: 17.8145, val_MinusLogProbMetric: 17.8145

Epoch 47: val_loss did not improve from 17.66153
196/196 - 44s - loss: 17.3844 - MinusLogProbMetric: 17.3844 - val_loss: 17.8145 - val_MinusLogProbMetric: 17.8145 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 48/1000
2023-09-23 15:41:51.389 
Epoch 27/1000 
	 loss: 20.5797, MinusLogProbMetric: 20.5797, val_loss: 20.5218, val_MinusLogProbMetric: 20.5218

Epoch 27: val_loss did not improve from 20.28655
196/196 - 66s - loss: 20.5797 - MinusLogProbMetric: 20.5797 - val_loss: 20.5218 - val_MinusLogProbMetric: 20.5218 - lr: 3.3333e-04 - 66s/epoch - 339ms/step
Epoch 28/1000
2023-09-23 15:42:32.160 
Epoch 48/1000 
	 loss: 17.4261, MinusLogProbMetric: 17.4261, val_loss: 17.6491, val_MinusLogProbMetric: 17.6491

Epoch 48: val_loss improved from 17.66153 to 17.64911, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 45s - loss: 17.4261 - MinusLogProbMetric: 17.4261 - val_loss: 17.6491 - val_MinusLogProbMetric: 17.6491 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 49/1000
2023-09-23 15:42:58.090 
Epoch 28/1000 
	 loss: 20.5705, MinusLogProbMetric: 20.5705, val_loss: 21.6900, val_MinusLogProbMetric: 21.6900

Epoch 28: val_loss did not improve from 20.28655
196/196 - 67s - loss: 20.5705 - MinusLogProbMetric: 20.5705 - val_loss: 21.6900 - val_MinusLogProbMetric: 21.6900 - lr: 3.3333e-04 - 67s/epoch - 340ms/step
Epoch 29/1000
2023-09-23 15:43:16.612 
Epoch 49/1000 
	 loss: 17.3303, MinusLogProbMetric: 17.3303, val_loss: 18.7480, val_MinusLogProbMetric: 18.7480

Epoch 49: val_loss did not improve from 17.64911
196/196 - 44s - loss: 17.3303 - MinusLogProbMetric: 17.3303 - val_loss: 18.7480 - val_MinusLogProbMetric: 18.7480 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 50/1000
2023-09-23 15:44:01.173 
Epoch 50/1000 
	 loss: 17.3517, MinusLogProbMetric: 17.3517, val_loss: 17.7312, val_MinusLogProbMetric: 17.7312

Epoch 50: val_loss did not improve from 17.64911
196/196 - 45s - loss: 17.3517 - MinusLogProbMetric: 17.3517 - val_loss: 17.7312 - val_MinusLogProbMetric: 17.7312 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 51/1000
2023-09-23 15:44:04.619 
Epoch 29/1000 
	 loss: 20.4343, MinusLogProbMetric: 20.4343, val_loss: 20.4084, val_MinusLogProbMetric: 20.4084

Epoch 29: val_loss did not improve from 20.28655
196/196 - 67s - loss: 20.4343 - MinusLogProbMetric: 20.4343 - val_loss: 20.4084 - val_MinusLogProbMetric: 20.4084 - lr: 3.3333e-04 - 67s/epoch - 339ms/step
Epoch 30/1000
2023-09-23 15:44:45.267 
Epoch 51/1000 
	 loss: 17.3421, MinusLogProbMetric: 17.3421, val_loss: 17.6198, val_MinusLogProbMetric: 17.6198

Epoch 51: val_loss improved from 17.64911 to 17.61984, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 45s - loss: 17.3421 - MinusLogProbMetric: 17.3421 - val_loss: 17.6198 - val_MinusLogProbMetric: 17.6198 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 52/1000
2023-09-23 15:45:10.293 
Epoch 30/1000 
	 loss: 20.3938, MinusLogProbMetric: 20.3938, val_loss: 20.1568, val_MinusLogProbMetric: 20.1568

Epoch 30: val_loss improved from 20.28655 to 20.15682, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 67s - loss: 20.3938 - MinusLogProbMetric: 20.3938 - val_loss: 20.1568 - val_MinusLogProbMetric: 20.1568 - lr: 3.3333e-04 - 67s/epoch - 340ms/step
Epoch 31/1000
2023-09-23 15:45:30.782 
Epoch 52/1000 
	 loss: 17.3457, MinusLogProbMetric: 17.3457, val_loss: 18.1759, val_MinusLogProbMetric: 18.1759

Epoch 52: val_loss did not improve from 17.61984
196/196 - 45s - loss: 17.3457 - MinusLogProbMetric: 17.3457 - val_loss: 18.1759 - val_MinusLogProbMetric: 18.1759 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 53/1000
2023-09-23 15:46:15.426 
Epoch 53/1000 
	 loss: 17.2770, MinusLogProbMetric: 17.2770, val_loss: 17.7855, val_MinusLogProbMetric: 17.7855

Epoch 53: val_loss did not improve from 17.61984
196/196 - 45s - loss: 17.2770 - MinusLogProbMetric: 17.2770 - val_loss: 17.7855 - val_MinusLogProbMetric: 17.7855 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 54/1000
2023-09-23 15:46:17.371 
Epoch 31/1000 
	 loss: 20.3042, MinusLogProbMetric: 20.3042, val_loss: 21.0391, val_MinusLogProbMetric: 21.0391

Epoch 31: val_loss did not improve from 20.15682
196/196 - 66s - loss: 20.3042 - MinusLogProbMetric: 20.3042 - val_loss: 21.0391 - val_MinusLogProbMetric: 21.0391 - lr: 3.3333e-04 - 66s/epoch - 337ms/step
Epoch 32/1000
2023-09-23 15:47:00.185 
Epoch 54/1000 
	 loss: 17.2526, MinusLogProbMetric: 17.2526, val_loss: 17.7286, val_MinusLogProbMetric: 17.7286

Epoch 54: val_loss did not improve from 17.61984
196/196 - 45s - loss: 17.2526 - MinusLogProbMetric: 17.2526 - val_loss: 17.7286 - val_MinusLogProbMetric: 17.7286 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 55/1000
2023-09-23 15:47:23.082 
Epoch 32/1000 
	 loss: 20.2424, MinusLogProbMetric: 20.2424, val_loss: 20.9633, val_MinusLogProbMetric: 20.9633

Epoch 32: val_loss did not improve from 20.15682
196/196 - 66s - loss: 20.2424 - MinusLogProbMetric: 20.2424 - val_loss: 20.9633 - val_MinusLogProbMetric: 20.9633 - lr: 3.3333e-04 - 66s/epoch - 335ms/step
Epoch 33/1000
2023-09-23 15:47:44.492 
Epoch 55/1000 
	 loss: 17.3347, MinusLogProbMetric: 17.3347, val_loss: 17.8762, val_MinusLogProbMetric: 17.8762

Epoch 55: val_loss did not improve from 17.61984
196/196 - 44s - loss: 17.3347 - MinusLogProbMetric: 17.3347 - val_loss: 17.8762 - val_MinusLogProbMetric: 17.8762 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 56/1000
2023-09-23 15:48:28.189 
Epoch 33/1000 
	 loss: 20.1369, MinusLogProbMetric: 20.1369, val_loss: 20.8026, val_MinusLogProbMetric: 20.8026

Epoch 33: val_loss did not improve from 20.15682
196/196 - 65s - loss: 20.1369 - MinusLogProbMetric: 20.1369 - val_loss: 20.8026 - val_MinusLogProbMetric: 20.8026 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 34/1000
2023-09-23 15:48:29.234 
Epoch 56/1000 
	 loss: 17.2904, MinusLogProbMetric: 17.2904, val_loss: 18.1970, val_MinusLogProbMetric: 18.1970

Epoch 56: val_loss did not improve from 17.61984
196/196 - 45s - loss: 17.2904 - MinusLogProbMetric: 17.2904 - val_loss: 18.1970 - val_MinusLogProbMetric: 18.1970 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 57/1000
2023-09-23 15:49:13.736 
Epoch 57/1000 
	 loss: 17.2868, MinusLogProbMetric: 17.2868, val_loss: 17.5739, val_MinusLogProbMetric: 17.5739

Epoch 57: val_loss improved from 17.61984 to 17.57394, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 45s - loss: 17.2868 - MinusLogProbMetric: 17.2868 - val_loss: 17.5739 - val_MinusLogProbMetric: 17.5739 - lr: 0.0010 - 45s/epoch - 231ms/step
Epoch 58/1000
2023-09-23 15:49:33.430 
Epoch 34/1000 
	 loss: 20.2164, MinusLogProbMetric: 20.2164, val_loss: 20.0414, val_MinusLogProbMetric: 20.0414

Epoch 34: val_loss improved from 20.15682 to 20.04144, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 66s - loss: 20.2164 - MinusLogProbMetric: 20.2164 - val_loss: 20.0414 - val_MinusLogProbMetric: 20.0414 - lr: 3.3333e-04 - 66s/epoch - 338ms/step
Epoch 35/1000
2023-09-23 15:49:59.399 
Epoch 58/1000 
	 loss: 17.2130, MinusLogProbMetric: 17.2130, val_loss: 17.6354, val_MinusLogProbMetric: 17.6354

Epoch 58: val_loss did not improve from 17.57394
196/196 - 45s - loss: 17.2130 - MinusLogProbMetric: 17.2130 - val_loss: 17.6354 - val_MinusLogProbMetric: 17.6354 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 59/1000
2023-09-23 15:50:41.540 
Epoch 35/1000 
	 loss: 19.9331, MinusLogProbMetric: 19.9331, val_loss: 23.1090, val_MinusLogProbMetric: 23.1090

Epoch 35: val_loss did not improve from 20.04144
196/196 - 67s - loss: 19.9331 - MinusLogProbMetric: 19.9331 - val_loss: 23.1090 - val_MinusLogProbMetric: 23.1090 - lr: 3.3333e-04 - 67s/epoch - 342ms/step
Epoch 36/1000
2023-09-23 15:50:43.678 
Epoch 59/1000 
	 loss: 17.2241, MinusLogProbMetric: 17.2241, val_loss: 19.0262, val_MinusLogProbMetric: 19.0262

Epoch 59: val_loss did not improve from 17.57394
196/196 - 44s - loss: 17.2241 - MinusLogProbMetric: 17.2241 - val_loss: 19.0262 - val_MinusLogProbMetric: 19.0262 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 60/1000
2023-09-23 15:51:27.759 
Epoch 60/1000 
	 loss: 17.2655, MinusLogProbMetric: 17.2655, val_loss: 17.7074, val_MinusLogProbMetric: 17.7074

Epoch 60: val_loss did not improve from 17.57394
196/196 - 44s - loss: 17.2655 - MinusLogProbMetric: 17.2655 - val_loss: 17.7074 - val_MinusLogProbMetric: 17.7074 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 61/1000
2023-09-23 15:51:47.668 
Epoch 36/1000 
	 loss: 19.9888, MinusLogProbMetric: 19.9888, val_loss: 19.3614, val_MinusLogProbMetric: 19.3614

Epoch 36: val_loss improved from 20.04144 to 19.36136, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 67s - loss: 19.9888 - MinusLogProbMetric: 19.9888 - val_loss: 19.3614 - val_MinusLogProbMetric: 19.3614 - lr: 3.3333e-04 - 67s/epoch - 343ms/step
Epoch 37/1000
2023-09-23 15:52:11.943 
Epoch 61/1000 
	 loss: 17.0974, MinusLogProbMetric: 17.0974, val_loss: 17.4896, val_MinusLogProbMetric: 17.4896

Epoch 61: val_loss improved from 17.57394 to 17.48959, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 45s - loss: 17.0974 - MinusLogProbMetric: 17.0974 - val_loss: 17.4896 - val_MinusLogProbMetric: 17.4896 - lr: 0.0010 - 45s/epoch - 230ms/step
Epoch 62/1000
2023-09-23 15:52:53.809 
Epoch 37/1000 
	 loss: 20.0413, MinusLogProbMetric: 20.0413, val_loss: 19.6689, val_MinusLogProbMetric: 19.6689

Epoch 37: val_loss did not improve from 19.36136
196/196 - 65s - loss: 20.0413 - MinusLogProbMetric: 20.0413 - val_loss: 19.6689 - val_MinusLogProbMetric: 19.6689 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 38/1000
2023-09-23 15:52:57.747 
Epoch 62/1000 
	 loss: 17.3294, MinusLogProbMetric: 17.3294, val_loss: 17.8412, val_MinusLogProbMetric: 17.8412

Epoch 62: val_loss did not improve from 17.48959
196/196 - 45s - loss: 17.3294 - MinusLogProbMetric: 17.3294 - val_loss: 17.8412 - val_MinusLogProbMetric: 17.8412 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 63/1000
2023-09-23 15:53:42.621 
Epoch 63/1000 
	 loss: 17.1460, MinusLogProbMetric: 17.1460, val_loss: 17.7820, val_MinusLogProbMetric: 17.7820

Epoch 63: val_loss did not improve from 17.48959
196/196 - 45s - loss: 17.1460 - MinusLogProbMetric: 17.1460 - val_loss: 17.7820 - val_MinusLogProbMetric: 17.7820 - lr: 0.0010 - 45s/epoch - 229ms/step
Epoch 64/1000
2023-09-23 15:53:58.541 
Epoch 38/1000 
	 loss: 19.8099, MinusLogProbMetric: 19.8099, val_loss: 20.7772, val_MinusLogProbMetric: 20.7772

Epoch 38: val_loss did not improve from 19.36136
196/196 - 65s - loss: 19.8099 - MinusLogProbMetric: 19.8099 - val_loss: 20.7772 - val_MinusLogProbMetric: 20.7772 - lr: 3.3333e-04 - 65s/epoch - 330ms/step
Epoch 39/1000
2023-09-23 15:54:26.941 
Epoch 64/1000 
	 loss: 17.2121, MinusLogProbMetric: 17.2121, val_loss: 17.5782, val_MinusLogProbMetric: 17.5782

Epoch 64: val_loss did not improve from 17.48959
196/196 - 44s - loss: 17.2121 - MinusLogProbMetric: 17.2121 - val_loss: 17.5782 - val_MinusLogProbMetric: 17.5782 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 65/1000
2023-09-23 15:55:04.361 
Epoch 39/1000 
	 loss: 20.1421, MinusLogProbMetric: 20.1421, val_loss: 20.8951, val_MinusLogProbMetric: 20.8951

Epoch 39: val_loss did not improve from 19.36136
196/196 - 66s - loss: 20.1421 - MinusLogProbMetric: 20.1421 - val_loss: 20.8951 - val_MinusLogProbMetric: 20.8951 - lr: 3.3333e-04 - 66s/epoch - 336ms/step
Epoch 40/1000
2023-09-23 15:55:10.961 
Epoch 65/1000 
	 loss: 17.1382, MinusLogProbMetric: 17.1382, val_loss: 17.6340, val_MinusLogProbMetric: 17.6340

Epoch 65: val_loss did not improve from 17.48959
196/196 - 44s - loss: 17.1382 - MinusLogProbMetric: 17.1382 - val_loss: 17.6340 - val_MinusLogProbMetric: 17.6340 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 66/1000
2023-09-23 15:55:55.463 
Epoch 66/1000 
	 loss: 17.0931, MinusLogProbMetric: 17.0931, val_loss: 18.2637, val_MinusLogProbMetric: 18.2637

Epoch 66: val_loss did not improve from 17.48959
196/196 - 44s - loss: 17.0931 - MinusLogProbMetric: 17.0931 - val_loss: 18.2637 - val_MinusLogProbMetric: 18.2637 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 67/1000
2023-09-23 15:56:09.476 
Epoch 40/1000 
	 loss: 19.7011, MinusLogProbMetric: 19.7011, val_loss: 19.5218, val_MinusLogProbMetric: 19.5218

Epoch 40: val_loss did not improve from 19.36136
196/196 - 65s - loss: 19.7011 - MinusLogProbMetric: 19.7011 - val_loss: 19.5218 - val_MinusLogProbMetric: 19.5218 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 41/1000
2023-09-23 15:56:39.810 
Epoch 67/1000 
	 loss: 17.1129, MinusLogProbMetric: 17.1129, val_loss: 17.6421, val_MinusLogProbMetric: 17.6421

Epoch 67: val_loss did not improve from 17.48959
196/196 - 44s - loss: 17.1129 - MinusLogProbMetric: 17.1129 - val_loss: 17.6421 - val_MinusLogProbMetric: 17.6421 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 68/1000
2023-09-23 15:57:15.020 
Epoch 41/1000 
	 loss: 19.8960, MinusLogProbMetric: 19.8960, val_loss: 20.1928, val_MinusLogProbMetric: 20.1928

Epoch 41: val_loss did not improve from 19.36136
196/196 - 66s - loss: 19.8960 - MinusLogProbMetric: 19.8960 - val_loss: 20.1928 - val_MinusLogProbMetric: 20.1928 - lr: 3.3333e-04 - 66s/epoch - 334ms/step
Epoch 42/1000
2023-09-23 15:57:23.828 
Epoch 68/1000 
	 loss: 17.1180, MinusLogProbMetric: 17.1180, val_loss: 17.5237, val_MinusLogProbMetric: 17.5237

Epoch 68: val_loss did not improve from 17.48959
196/196 - 44s - loss: 17.1180 - MinusLogProbMetric: 17.1180 - val_loss: 17.5237 - val_MinusLogProbMetric: 17.5237 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 69/1000
2023-09-23 15:58:08.124 
Epoch 69/1000 
	 loss: 17.0653, MinusLogProbMetric: 17.0653, val_loss: 17.5691, val_MinusLogProbMetric: 17.5691

Epoch 69: val_loss did not improve from 17.48959
196/196 - 44s - loss: 17.0653 - MinusLogProbMetric: 17.0653 - val_loss: 17.5691 - val_MinusLogProbMetric: 17.5691 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 70/1000
2023-09-23 15:58:19.700 
Epoch 42/1000 
	 loss: 19.9451, MinusLogProbMetric: 19.9451, val_loss: 20.4618, val_MinusLogProbMetric: 20.4618

Epoch 42: val_loss did not improve from 19.36136
196/196 - 65s - loss: 19.9451 - MinusLogProbMetric: 19.9451 - val_loss: 20.4618 - val_MinusLogProbMetric: 20.4618 - lr: 3.3333e-04 - 65s/epoch - 330ms/step
Epoch 43/1000
2023-09-23 15:58:51.902 
Epoch 70/1000 
	 loss: 17.1181, MinusLogProbMetric: 17.1181, val_loss: 18.0764, val_MinusLogProbMetric: 18.0764

Epoch 70: val_loss did not improve from 17.48959
196/196 - 44s - loss: 17.1181 - MinusLogProbMetric: 17.1181 - val_loss: 18.0764 - val_MinusLogProbMetric: 18.0764 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 71/1000
2023-09-23 15:59:24.668 
Epoch 43/1000 
	 loss: 19.6350, MinusLogProbMetric: 19.6350, val_loss: 20.4856, val_MinusLogProbMetric: 20.4856

Epoch 43: val_loss did not improve from 19.36136
196/196 - 65s - loss: 19.6350 - MinusLogProbMetric: 19.6350 - val_loss: 20.4856 - val_MinusLogProbMetric: 20.4856 - lr: 3.3333e-04 - 65s/epoch - 331ms/step
Epoch 44/1000
2023-09-23 15:59:36.352 
Epoch 71/1000 
	 loss: 17.0999, MinusLogProbMetric: 17.0999, val_loss: 17.9466, val_MinusLogProbMetric: 17.9466

Epoch 71: val_loss did not improve from 17.48959
196/196 - 44s - loss: 17.0999 - MinusLogProbMetric: 17.0999 - val_loss: 17.9466 - val_MinusLogProbMetric: 17.9466 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 72/1000
2023-09-23 16:00:20.338 
Epoch 72/1000 
	 loss: 17.0877, MinusLogProbMetric: 17.0877, val_loss: 18.1021, val_MinusLogProbMetric: 18.1021

Epoch 72: val_loss did not improve from 17.48959
196/196 - 44s - loss: 17.0877 - MinusLogProbMetric: 17.0877 - val_loss: 18.1021 - val_MinusLogProbMetric: 18.1021 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 73/1000
2023-09-23 16:00:29.979 
Epoch 44/1000 
	 loss: 19.6119, MinusLogProbMetric: 19.6119, val_loss: 21.7331, val_MinusLogProbMetric: 21.7331

Epoch 44: val_loss did not improve from 19.36136
196/196 - 65s - loss: 19.6119 - MinusLogProbMetric: 19.6119 - val_loss: 21.7331 - val_MinusLogProbMetric: 21.7331 - lr: 3.3333e-04 - 65s/epoch - 333ms/step
Epoch 45/1000
2023-09-23 16:01:04.344 
Epoch 73/1000 
	 loss: 16.9992, MinusLogProbMetric: 16.9992, val_loss: 17.6423, val_MinusLogProbMetric: 17.6423

Epoch 73: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.9992 - MinusLogProbMetric: 16.9992 - val_loss: 17.6423 - val_MinusLogProbMetric: 17.6423 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 74/1000
2023-09-23 16:01:36.182 
Epoch 45/1000 
	 loss: 19.7817, MinusLogProbMetric: 19.7817, val_loss: 20.1311, val_MinusLogProbMetric: 20.1311

Epoch 45: val_loss did not improve from 19.36136
196/196 - 66s - loss: 19.7817 - MinusLogProbMetric: 19.7817 - val_loss: 20.1311 - val_MinusLogProbMetric: 20.1311 - lr: 3.3333e-04 - 66s/epoch - 338ms/step
Epoch 46/1000
2023-09-23 16:01:47.903 
Epoch 74/1000 
	 loss: 17.0343, MinusLogProbMetric: 17.0343, val_loss: 17.5901, val_MinusLogProbMetric: 17.5901

Epoch 74: val_loss did not improve from 17.48959
196/196 - 44s - loss: 17.0343 - MinusLogProbMetric: 17.0343 - val_loss: 17.5901 - val_MinusLogProbMetric: 17.5901 - lr: 0.0010 - 44s/epoch - 222ms/step
Epoch 75/1000
2023-09-23 16:02:32.482 
Epoch 75/1000 
	 loss: 16.9909, MinusLogProbMetric: 16.9909, val_loss: 18.5863, val_MinusLogProbMetric: 18.5863

Epoch 75: val_loss did not improve from 17.48959
196/196 - 45s - loss: 16.9909 - MinusLogProbMetric: 16.9909 - val_loss: 18.5863 - val_MinusLogProbMetric: 18.5863 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 76/1000
2023-09-23 16:02:42.851 
Epoch 46/1000 
	 loss: 19.6499, MinusLogProbMetric: 19.6499, val_loss: 19.0705, val_MinusLogProbMetric: 19.0705

Epoch 46: val_loss improved from 19.36136 to 19.07050, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 68s - loss: 19.6499 - MinusLogProbMetric: 19.6499 - val_loss: 19.0705 - val_MinusLogProbMetric: 19.0705 - lr: 3.3333e-04 - 68s/epoch - 345ms/step
Epoch 47/1000
2023-09-23 16:03:16.793 
Epoch 76/1000 
	 loss: 16.9971, MinusLogProbMetric: 16.9971, val_loss: 17.5148, val_MinusLogProbMetric: 17.5148

Epoch 76: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.9971 - MinusLogProbMetric: 16.9971 - val_loss: 17.5148 - val_MinusLogProbMetric: 17.5148 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 77/1000
2023-09-23 16:03:49.907 
Epoch 47/1000 
	 loss: 19.7519, MinusLogProbMetric: 19.7519, val_loss: 20.5699, val_MinusLogProbMetric: 20.5699

Epoch 47: val_loss did not improve from 19.07050
196/196 - 66s - loss: 19.7519 - MinusLogProbMetric: 19.7519 - val_loss: 20.5699 - val_MinusLogProbMetric: 20.5699 - lr: 3.3333e-04 - 66s/epoch - 338ms/step
Epoch 48/1000
2023-09-23 16:04:01.051 
Epoch 77/1000 
	 loss: 17.0261, MinusLogProbMetric: 17.0261, val_loss: 17.8732, val_MinusLogProbMetric: 17.8732

Epoch 77: val_loss did not improve from 17.48959
196/196 - 44s - loss: 17.0261 - MinusLogProbMetric: 17.0261 - val_loss: 17.8732 - val_MinusLogProbMetric: 17.8732 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 78/1000
2023-09-23 16:04:45.390 
Epoch 78/1000 
	 loss: 16.9807, MinusLogProbMetric: 16.9807, val_loss: 17.5002, val_MinusLogProbMetric: 17.5002

Epoch 78: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.9807 - MinusLogProbMetric: 16.9807 - val_loss: 17.5002 - val_MinusLogProbMetric: 17.5002 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 79/1000
2023-09-23 16:04:55.934 
Epoch 48/1000 
	 loss: 19.6191, MinusLogProbMetric: 19.6191, val_loss: 19.4825, val_MinusLogProbMetric: 19.4825

Epoch 48: val_loss did not improve from 19.07050
196/196 - 66s - loss: 19.6191 - MinusLogProbMetric: 19.6191 - val_loss: 19.4825 - val_MinusLogProbMetric: 19.4825 - lr: 3.3333e-04 - 66s/epoch - 337ms/step
Epoch 49/1000
2023-09-23 16:05:29.433 
Epoch 79/1000 
	 loss: 16.9799, MinusLogProbMetric: 16.9799, val_loss: 17.5041, val_MinusLogProbMetric: 17.5041

Epoch 79: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.9799 - MinusLogProbMetric: 16.9799 - val_loss: 17.5041 - val_MinusLogProbMetric: 17.5041 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 80/1000
2023-09-23 16:06:02.450 
Epoch 49/1000 
	 loss: 19.5613, MinusLogProbMetric: 19.5613, val_loss: 21.0292, val_MinusLogProbMetric: 21.0292

Epoch 49: val_loss did not improve from 19.07050
196/196 - 67s - loss: 19.5613 - MinusLogProbMetric: 19.5613 - val_loss: 21.0292 - val_MinusLogProbMetric: 21.0292 - lr: 3.3333e-04 - 67s/epoch - 339ms/step
Epoch 50/1000
2023-09-23 16:06:13.591 
Epoch 80/1000 
	 loss: 16.9463, MinusLogProbMetric: 16.9463, val_loss: 17.6557, val_MinusLogProbMetric: 17.6557

Epoch 80: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.9463 - MinusLogProbMetric: 16.9463 - val_loss: 17.6557 - val_MinusLogProbMetric: 17.6557 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 81/1000
2023-09-23 16:06:57.816 
Epoch 81/1000 
	 loss: 16.9942, MinusLogProbMetric: 16.9942, val_loss: 17.5929, val_MinusLogProbMetric: 17.5929

Epoch 81: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.9942 - MinusLogProbMetric: 16.9942 - val_loss: 17.5929 - val_MinusLogProbMetric: 17.5929 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 82/1000
2023-09-23 16:07:09.328 
Epoch 50/1000 
	 loss: 19.5065, MinusLogProbMetric: 19.5065, val_loss: 20.1025, val_MinusLogProbMetric: 20.1025

Epoch 50: val_loss did not improve from 19.07050
196/196 - 67s - loss: 19.5065 - MinusLogProbMetric: 19.5065 - val_loss: 20.1025 - val_MinusLogProbMetric: 20.1025 - lr: 3.3333e-04 - 67s/epoch - 341ms/step
Epoch 51/1000
2023-09-23 16:07:41.769 
Epoch 82/1000 
	 loss: 17.2317, MinusLogProbMetric: 17.2317, val_loss: 17.7023, val_MinusLogProbMetric: 17.7023

Epoch 82: val_loss did not improve from 17.48959
196/196 - 44s - loss: 17.2317 - MinusLogProbMetric: 17.2317 - val_loss: 17.7023 - val_MinusLogProbMetric: 17.7023 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 83/1000
2023-09-23 16:08:16.646 
Epoch 51/1000 
	 loss: 19.5026, MinusLogProbMetric: 19.5026, val_loss: 19.4924, val_MinusLogProbMetric: 19.4924

Epoch 51: val_loss did not improve from 19.07050
196/196 - 67s - loss: 19.5026 - MinusLogProbMetric: 19.5026 - val_loss: 19.4924 - val_MinusLogProbMetric: 19.4924 - lr: 3.3333e-04 - 67s/epoch - 343ms/step
Epoch 52/1000
2023-09-23 16:08:26.128 
Epoch 83/1000 
	 loss: 16.8890, MinusLogProbMetric: 16.8890, val_loss: 17.5694, val_MinusLogProbMetric: 17.5694

Epoch 83: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.8890 - MinusLogProbMetric: 16.8890 - val_loss: 17.5694 - val_MinusLogProbMetric: 17.5694 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 84/1000
2023-09-23 16:09:10.523 
Epoch 84/1000 
	 loss: 16.9252, MinusLogProbMetric: 16.9252, val_loss: 17.8675, val_MinusLogProbMetric: 17.8675

Epoch 84: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.9252 - MinusLogProbMetric: 16.9252 - val_loss: 17.8675 - val_MinusLogProbMetric: 17.8675 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 85/1000
2023-09-23 16:09:22.984 
Epoch 52/1000 
	 loss: 19.3516, MinusLogProbMetric: 19.3516, val_loss: 18.8093, val_MinusLogProbMetric: 18.8093

Epoch 52: val_loss improved from 19.07050 to 18.80929, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 68s - loss: 19.3516 - MinusLogProbMetric: 19.3516 - val_loss: 18.8093 - val_MinusLogProbMetric: 18.8093 - lr: 3.3333e-04 - 68s/epoch - 345ms/step
Epoch 53/1000
2023-09-23 16:09:54.404 
Epoch 85/1000 
	 loss: 16.9070, MinusLogProbMetric: 16.9070, val_loss: 17.7555, val_MinusLogProbMetric: 17.7555

Epoch 85: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.9070 - MinusLogProbMetric: 16.9070 - val_loss: 17.7555 - val_MinusLogProbMetric: 17.7555 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 86/1000
2023-09-23 16:10:30.322 
Epoch 53/1000 
	 loss: 19.6558, MinusLogProbMetric: 19.6558, val_loss: 19.6061, val_MinusLogProbMetric: 19.6061

Epoch 53: val_loss did not improve from 18.80929
196/196 - 66s - loss: 19.6558 - MinusLogProbMetric: 19.6558 - val_loss: 19.6061 - val_MinusLogProbMetric: 19.6061 - lr: 3.3333e-04 - 66s/epoch - 337ms/step
Epoch 54/1000
2023-09-23 16:10:38.578 
Epoch 86/1000 
	 loss: 16.9794, MinusLogProbMetric: 16.9794, val_loss: 17.5768, val_MinusLogProbMetric: 17.5768

Epoch 86: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.9794 - MinusLogProbMetric: 16.9794 - val_loss: 17.5768 - val_MinusLogProbMetric: 17.5768 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 87/1000
2023-09-23 16:11:22.837 
Epoch 87/1000 
	 loss: 16.8990, MinusLogProbMetric: 16.8990, val_loss: 17.5271, val_MinusLogProbMetric: 17.5271

Epoch 87: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.8990 - MinusLogProbMetric: 16.8990 - val_loss: 17.5271 - val_MinusLogProbMetric: 17.5271 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 88/1000
2023-09-23 16:11:37.276 
Epoch 54/1000 
	 loss: 19.2359, MinusLogProbMetric: 19.2359, val_loss: 19.9051, val_MinusLogProbMetric: 19.9051

Epoch 54: val_loss did not improve from 18.80929
196/196 - 67s - loss: 19.2359 - MinusLogProbMetric: 19.2359 - val_loss: 19.9051 - val_MinusLogProbMetric: 19.9051 - lr: 3.3333e-04 - 67s/epoch - 342ms/step
Epoch 55/1000
2023-09-23 16:12:06.548 
Epoch 88/1000 
	 loss: 17.0076, MinusLogProbMetric: 17.0076, val_loss: 17.6157, val_MinusLogProbMetric: 17.6157

Epoch 88: val_loss did not improve from 17.48959
196/196 - 44s - loss: 17.0076 - MinusLogProbMetric: 17.0076 - val_loss: 17.6157 - val_MinusLogProbMetric: 17.6157 - lr: 0.0010 - 44s/epoch - 223ms/step
Epoch 89/1000
2023-09-23 16:12:44.185 
Epoch 55/1000 
	 loss: 19.3186, MinusLogProbMetric: 19.3186, val_loss: 19.5423, val_MinusLogProbMetric: 19.5423

Epoch 55: val_loss did not improve from 18.80929
196/196 - 67s - loss: 19.3186 - MinusLogProbMetric: 19.3186 - val_loss: 19.5423 - val_MinusLogProbMetric: 19.5423 - lr: 3.3333e-04 - 67s/epoch - 341ms/step
Epoch 56/1000
2023-09-23 16:12:50.602 
Epoch 89/1000 
	 loss: 16.9165, MinusLogProbMetric: 16.9165, val_loss: 17.6995, val_MinusLogProbMetric: 17.6995

Epoch 89: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.9165 - MinusLogProbMetric: 16.9165 - val_loss: 17.6995 - val_MinusLogProbMetric: 17.6995 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 90/1000
2023-09-23 16:13:34.533 
Epoch 90/1000 
	 loss: 16.8191, MinusLogProbMetric: 16.8191, val_loss: 17.6271, val_MinusLogProbMetric: 17.6271

Epoch 90: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.8191 - MinusLogProbMetric: 16.8191 - val_loss: 17.6271 - val_MinusLogProbMetric: 17.6271 - lr: 0.0010 - 44s/epoch - 224ms/step
Epoch 91/1000
2023-09-23 16:13:50.271 
Epoch 56/1000 
	 loss: 19.4599, MinusLogProbMetric: 19.4599, val_loss: 18.9500, val_MinusLogProbMetric: 18.9500

Epoch 56: val_loss did not improve from 18.80929
196/196 - 66s - loss: 19.4599 - MinusLogProbMetric: 19.4599 - val_loss: 18.9500 - val_MinusLogProbMetric: 18.9500 - lr: 3.3333e-04 - 66s/epoch - 337ms/step
Epoch 57/1000
2023-09-23 16:14:18.730 
Epoch 91/1000 
	 loss: 16.8779, MinusLogProbMetric: 16.8779, val_loss: 17.7393, val_MinusLogProbMetric: 17.7393

Epoch 91: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.8779 - MinusLogProbMetric: 16.8779 - val_loss: 17.7393 - val_MinusLogProbMetric: 17.7393 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 92/1000
2023-09-23 16:14:55.365 
Epoch 57/1000 
	 loss: 19.2694, MinusLogProbMetric: 19.2694, val_loss: 21.7348, val_MinusLogProbMetric: 21.7348

Epoch 57: val_loss did not improve from 18.80929
196/196 - 65s - loss: 19.2694 - MinusLogProbMetric: 19.2694 - val_loss: 21.7348 - val_MinusLogProbMetric: 21.7348 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 58/1000
2023-09-23 16:15:03.966 
Epoch 92/1000 
	 loss: 16.7909, MinusLogProbMetric: 16.7909, val_loss: 17.7694, val_MinusLogProbMetric: 17.7694

Epoch 92: val_loss did not improve from 17.48959
196/196 - 45s - loss: 16.7909 - MinusLogProbMetric: 16.7909 - val_loss: 17.7694 - val_MinusLogProbMetric: 17.7694 - lr: 0.0010 - 45s/epoch - 231ms/step
Epoch 93/1000
2023-09-23 16:15:48.649 
Epoch 93/1000 
	 loss: 16.8378, MinusLogProbMetric: 16.8378, val_loss: 17.7510, val_MinusLogProbMetric: 17.7510

Epoch 93: val_loss did not improve from 17.48959
196/196 - 45s - loss: 16.8378 - MinusLogProbMetric: 16.8378 - val_loss: 17.7510 - val_MinusLogProbMetric: 17.7510 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 94/1000
2023-09-23 16:15:59.860 
Epoch 58/1000 
	 loss: 19.4372, MinusLogProbMetric: 19.4372, val_loss: 19.3589, val_MinusLogProbMetric: 19.3589

Epoch 58: val_loss did not improve from 18.80929
196/196 - 64s - loss: 19.4372 - MinusLogProbMetric: 19.4372 - val_loss: 19.3589 - val_MinusLogProbMetric: 19.3589 - lr: 3.3333e-04 - 64s/epoch - 329ms/step
Epoch 59/1000
2023-09-23 16:16:33.922 
Epoch 94/1000 
	 loss: 16.7757, MinusLogProbMetric: 16.7757, val_loss: 17.8028, val_MinusLogProbMetric: 17.8028

Epoch 94: val_loss did not improve from 17.48959
196/196 - 45s - loss: 16.7757 - MinusLogProbMetric: 16.7757 - val_loss: 17.8028 - val_MinusLogProbMetric: 17.8028 - lr: 0.0010 - 45s/epoch - 231ms/step
Epoch 95/1000
2023-09-23 16:17:05.043 
Epoch 59/1000 
	 loss: 19.4072, MinusLogProbMetric: 19.4072, val_loss: 19.3607, val_MinusLogProbMetric: 19.3607

Epoch 59: val_loss did not improve from 18.80929
196/196 - 65s - loss: 19.4072 - MinusLogProbMetric: 19.4072 - val_loss: 19.3607 - val_MinusLogProbMetric: 19.3607 - lr: 3.3333e-04 - 65s/epoch - 333ms/step
Epoch 60/1000
2023-09-23 16:17:17.943 
Epoch 95/1000 
	 loss: 16.7945, MinusLogProbMetric: 16.7945, val_loss: 17.9725, val_MinusLogProbMetric: 17.9725

Epoch 95: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.7945 - MinusLogProbMetric: 16.7945 - val_loss: 17.9725 - val_MinusLogProbMetric: 17.9725 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 96/1000
2023-09-23 16:18:02.296 
Epoch 96/1000 
	 loss: 16.7791, MinusLogProbMetric: 16.7791, val_loss: 17.5300, val_MinusLogProbMetric: 17.5300

Epoch 96: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.7791 - MinusLogProbMetric: 16.7791 - val_loss: 17.5300 - val_MinusLogProbMetric: 17.5300 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 97/1000
2023-09-23 16:18:11.644 
Epoch 60/1000 
	 loss: 19.1903, MinusLogProbMetric: 19.1903, val_loss: 19.0674, val_MinusLogProbMetric: 19.0674

Epoch 60: val_loss did not improve from 18.80929
196/196 - 67s - loss: 19.1903 - MinusLogProbMetric: 19.1903 - val_loss: 19.0674 - val_MinusLogProbMetric: 19.0674 - lr: 3.3333e-04 - 67s/epoch - 340ms/step
Epoch 61/1000
2023-09-23 16:18:46.813 
Epoch 97/1000 
	 loss: 16.7866, MinusLogProbMetric: 16.7866, val_loss: 17.6205, val_MinusLogProbMetric: 17.6205

Epoch 97: val_loss did not improve from 17.48959
196/196 - 45s - loss: 16.7866 - MinusLogProbMetric: 16.7866 - val_loss: 17.6205 - val_MinusLogProbMetric: 17.6205 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 98/1000
2023-09-23 16:19:17.426 
Epoch 61/1000 
	 loss: 19.2413, MinusLogProbMetric: 19.2413, val_loss: 18.7541, val_MinusLogProbMetric: 18.7541

Epoch 61: val_loss improved from 18.80929 to 18.75405, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 67s - loss: 19.2413 - MinusLogProbMetric: 19.2413 - val_loss: 18.7541 - val_MinusLogProbMetric: 18.7541 - lr: 3.3333e-04 - 67s/epoch - 341ms/step
Epoch 62/1000
2023-09-23 16:19:30.894 
Epoch 98/1000 
	 loss: 16.7512, MinusLogProbMetric: 16.7512, val_loss: 18.1576, val_MinusLogProbMetric: 18.1576

Epoch 98: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.7512 - MinusLogProbMetric: 16.7512 - val_loss: 18.1576 - val_MinusLogProbMetric: 18.1576 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 99/1000
2023-09-23 16:20:15.403 
Epoch 99/1000 
	 loss: 16.7505, MinusLogProbMetric: 16.7505, val_loss: 17.7312, val_MinusLogProbMetric: 17.7312

Epoch 99: val_loss did not improve from 17.48959
196/196 - 45s - loss: 16.7505 - MinusLogProbMetric: 16.7505 - val_loss: 17.7312 - val_MinusLogProbMetric: 17.7312 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 100/1000
2023-09-23 16:20:24.482 
Epoch 62/1000 
	 loss: 19.1603, MinusLogProbMetric: 19.1603, val_loss: 19.1141, val_MinusLogProbMetric: 19.1141

Epoch 62: val_loss did not improve from 18.75405
196/196 - 66s - loss: 19.1603 - MinusLogProbMetric: 19.1603 - val_loss: 19.1141 - val_MinusLogProbMetric: 19.1141 - lr: 3.3333e-04 - 66s/epoch - 337ms/step
Epoch 63/1000
2023-09-23 16:20:59.450 
Epoch 100/1000 
	 loss: 16.8248, MinusLogProbMetric: 16.8248, val_loss: 17.6375, val_MinusLogProbMetric: 17.6375

Epoch 100: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.8248 - MinusLogProbMetric: 16.8248 - val_loss: 17.6375 - val_MinusLogProbMetric: 17.6375 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 101/1000
2023-09-23 16:21:30.616 
Epoch 63/1000 
	 loss: 19.1718, MinusLogProbMetric: 19.1718, val_loss: 19.1715, val_MinusLogProbMetric: 19.1715

Epoch 63: val_loss did not improve from 18.75405
196/196 - 66s - loss: 19.1718 - MinusLogProbMetric: 19.1718 - val_loss: 19.1715 - val_MinusLogProbMetric: 19.1715 - lr: 3.3333e-04 - 66s/epoch - 337ms/step
Epoch 64/1000
2023-09-23 16:21:44.078 
Epoch 101/1000 
	 loss: 16.6957, MinusLogProbMetric: 16.6957, val_loss: 17.5030, val_MinusLogProbMetric: 17.5030

Epoch 101: val_loss did not improve from 17.48959
196/196 - 45s - loss: 16.6957 - MinusLogProbMetric: 16.6957 - val_loss: 17.5030 - val_MinusLogProbMetric: 17.5030 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 102/1000
2023-09-23 16:22:28.606 
Epoch 102/1000 
	 loss: 16.8327, MinusLogProbMetric: 16.8327, val_loss: 18.0850, val_MinusLogProbMetric: 18.0850

Epoch 102: val_loss did not improve from 17.48959
196/196 - 45s - loss: 16.8327 - MinusLogProbMetric: 16.8327 - val_loss: 18.0850 - val_MinusLogProbMetric: 18.0850 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 103/1000
2023-09-23 16:22:35.933 
Epoch 64/1000 
	 loss: 18.9220, MinusLogProbMetric: 18.9220, val_loss: 19.1936, val_MinusLogProbMetric: 19.1936

Epoch 64: val_loss did not improve from 18.75405
196/196 - 65s - loss: 18.9220 - MinusLogProbMetric: 18.9220 - val_loss: 19.1936 - val_MinusLogProbMetric: 19.1936 - lr: 3.3333e-04 - 65s/epoch - 333ms/step
Epoch 65/1000
2023-09-23 16:23:13.124 
Epoch 103/1000 
	 loss: 16.6778, MinusLogProbMetric: 16.6778, val_loss: 17.6673, val_MinusLogProbMetric: 17.6673

Epoch 103: val_loss did not improve from 17.48959
196/196 - 45s - loss: 16.6778 - MinusLogProbMetric: 16.6778 - val_loss: 17.6673 - val_MinusLogProbMetric: 17.6673 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 104/1000
2023-09-23 16:23:41.600 
Epoch 65/1000 
	 loss: 19.2297, MinusLogProbMetric: 19.2297, val_loss: 19.0259, val_MinusLogProbMetric: 19.0259

Epoch 65: val_loss did not improve from 18.75405
196/196 - 66s - loss: 19.2297 - MinusLogProbMetric: 19.2297 - val_loss: 19.0259 - val_MinusLogProbMetric: 19.0259 - lr: 3.3333e-04 - 66s/epoch - 335ms/step
Epoch 66/1000
2023-09-23 16:23:57.560 
Epoch 104/1000 
	 loss: 16.6802, MinusLogProbMetric: 16.6802, val_loss: 17.6562, val_MinusLogProbMetric: 17.6562

Epoch 104: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.6802 - MinusLogProbMetric: 16.6802 - val_loss: 17.6562 - val_MinusLogProbMetric: 17.6562 - lr: 0.0010 - 44s/epoch - 227ms/step
Epoch 105/1000
2023-09-23 16:24:41.662 
Epoch 105/1000 
	 loss: 16.7360, MinusLogProbMetric: 16.7360, val_loss: 17.7839, val_MinusLogProbMetric: 17.7839

Epoch 105: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.7360 - MinusLogProbMetric: 16.7360 - val_loss: 17.7839 - val_MinusLogProbMetric: 17.7839 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 106/1000
2023-09-23 16:24:46.855 
Epoch 66/1000 
	 loss: 18.9678, MinusLogProbMetric: 18.9678, val_loss: 20.5742, val_MinusLogProbMetric: 20.5742

Epoch 66: val_loss did not improve from 18.75405
196/196 - 65s - loss: 18.9678 - MinusLogProbMetric: 18.9678 - val_loss: 20.5742 - val_MinusLogProbMetric: 20.5742 - lr: 3.3333e-04 - 65s/epoch - 333ms/step
Epoch 67/1000
2023-09-23 16:25:25.756 
Epoch 106/1000 
	 loss: 16.6986, MinusLogProbMetric: 16.6986, val_loss: 17.8950, val_MinusLogProbMetric: 17.8950

Epoch 106: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.6986 - MinusLogProbMetric: 16.6986 - val_loss: 17.8950 - val_MinusLogProbMetric: 17.8950 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 107/1000
2023-09-23 16:25:52.355 
Epoch 67/1000 
	 loss: 19.1303, MinusLogProbMetric: 19.1303, val_loss: 19.0052, val_MinusLogProbMetric: 19.0052

Epoch 67: val_loss did not improve from 18.75405
196/196 - 65s - loss: 19.1303 - MinusLogProbMetric: 19.1303 - val_loss: 19.0052 - val_MinusLogProbMetric: 19.0052 - lr: 3.3333e-04 - 65s/epoch - 334ms/step
Epoch 68/1000
2023-09-23 16:26:10.285 
Epoch 107/1000 
	 loss: 16.6797, MinusLogProbMetric: 16.6797, val_loss: 17.6343, val_MinusLogProbMetric: 17.6343

Epoch 107: val_loss did not improve from 17.48959
196/196 - 45s - loss: 16.6797 - MinusLogProbMetric: 16.6797 - val_loss: 17.6343 - val_MinusLogProbMetric: 17.6343 - lr: 0.0010 - 45s/epoch - 227ms/step
Epoch 108/1000
2023-09-23 16:26:54.666 
Epoch 108/1000 
	 loss: 16.6736, MinusLogProbMetric: 16.6736, val_loss: 17.5818, val_MinusLogProbMetric: 17.5818

Epoch 108: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.6736 - MinusLogProbMetric: 16.6736 - val_loss: 17.5818 - val_MinusLogProbMetric: 17.5818 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 109/1000
2023-09-23 16:26:58.165 
Epoch 68/1000 
	 loss: 19.0602, MinusLogProbMetric: 19.0602, val_loss: 19.3946, val_MinusLogProbMetric: 19.3946

Epoch 68: val_loss did not improve from 18.75405
196/196 - 66s - loss: 19.0602 - MinusLogProbMetric: 19.0602 - val_loss: 19.3946 - val_MinusLogProbMetric: 19.3946 - lr: 3.3333e-04 - 66s/epoch - 336ms/step
Epoch 69/1000
2023-09-23 16:27:39.017 
Epoch 109/1000 
	 loss: 16.6243, MinusLogProbMetric: 16.6243, val_loss: 17.7945, val_MinusLogProbMetric: 17.7945

Epoch 109: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.6243 - MinusLogProbMetric: 16.6243 - val_loss: 17.7945 - val_MinusLogProbMetric: 17.7945 - lr: 0.0010 - 44s/epoch - 226ms/step
Epoch 110/1000
2023-09-23 16:28:04.088 
Epoch 69/1000 
	 loss: 19.1789, MinusLogProbMetric: 19.1789, val_loss: 18.8060, val_MinusLogProbMetric: 18.8060

Epoch 69: val_loss did not improve from 18.75405
196/196 - 66s - loss: 19.1789 - MinusLogProbMetric: 19.1789 - val_loss: 18.8060 - val_MinusLogProbMetric: 18.8060 - lr: 3.3333e-04 - 66s/epoch - 336ms/step
Epoch 70/1000
2023-09-23 16:28:23.103 
Epoch 110/1000 
	 loss: 16.6485, MinusLogProbMetric: 16.6485, val_loss: 18.0128, val_MinusLogProbMetric: 18.0128

Epoch 110: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.6485 - MinusLogProbMetric: 16.6485 - val_loss: 18.0128 - val_MinusLogProbMetric: 18.0128 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 111/1000
2023-09-23 16:29:07.225 
Epoch 111/1000 
	 loss: 16.6206, MinusLogProbMetric: 16.6206, val_loss: 17.7105, val_MinusLogProbMetric: 17.7105

Epoch 111: val_loss did not improve from 17.48959
196/196 - 44s - loss: 16.6206 - MinusLogProbMetric: 16.6206 - val_loss: 17.7105 - val_MinusLogProbMetric: 17.7105 - lr: 0.0010 - 44s/epoch - 225ms/step
Epoch 112/1000
2023-09-23 16:29:09.686 
Epoch 70/1000 
	 loss: 19.1312, MinusLogProbMetric: 19.1312, val_loss: 19.5731, val_MinusLogProbMetric: 19.5731

Epoch 70: val_loss did not improve from 18.75405
196/196 - 66s - loss: 19.1312 - MinusLogProbMetric: 19.1312 - val_loss: 19.5731 - val_MinusLogProbMetric: 19.5731 - lr: 3.3333e-04 - 66s/epoch - 335ms/step
Epoch 71/1000
2023-09-23 16:29:51.306 
Epoch 112/1000 
	 loss: 16.2650, MinusLogProbMetric: 16.2650, val_loss: 17.4682, val_MinusLogProbMetric: 17.4682

Epoch 112: val_loss improved from 17.48959 to 17.46818, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 45s - loss: 16.2650 - MinusLogProbMetric: 16.2650 - val_loss: 17.4682 - val_MinusLogProbMetric: 17.4682 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 113/1000
2023-09-23 16:30:14.991 
Epoch 71/1000 
	 loss: 19.0368, MinusLogProbMetric: 19.0368, val_loss: 20.1559, val_MinusLogProbMetric: 20.1559

Epoch 71: val_loss did not improve from 18.75405
196/196 - 65s - loss: 19.0368 - MinusLogProbMetric: 19.0368 - val_loss: 20.1559 - val_MinusLogProbMetric: 20.1559 - lr: 3.3333e-04 - 65s/epoch - 333ms/step
Epoch 72/1000
2023-09-23 16:30:35.923 
Epoch 113/1000 
	 loss: 16.2379, MinusLogProbMetric: 16.2379, val_loss: 17.5603, val_MinusLogProbMetric: 17.5603

Epoch 113: val_loss did not improve from 17.46818
196/196 - 44s - loss: 16.2379 - MinusLogProbMetric: 16.2379 - val_loss: 17.5603 - val_MinusLogProbMetric: 17.5603 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 114/1000
2023-09-23 16:31:19.863 
Epoch 72/1000 
	 loss: 18.9267, MinusLogProbMetric: 18.9267, val_loss: 19.0370, val_MinusLogProbMetric: 19.0370

Epoch 72: val_loss did not improve from 18.75405
196/196 - 65s - loss: 18.9267 - MinusLogProbMetric: 18.9267 - val_loss: 19.0370 - val_MinusLogProbMetric: 19.0370 - lr: 3.3333e-04 - 65s/epoch - 331ms/step
Epoch 73/1000
2023-09-23 16:31:20.165 
Epoch 114/1000 
	 loss: 16.2285, MinusLogProbMetric: 16.2285, val_loss: 17.4624, val_MinusLogProbMetric: 17.4624

Epoch 114: val_loss improved from 17.46818 to 17.46242, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 45s - loss: 16.2285 - MinusLogProbMetric: 16.2285 - val_loss: 17.4624 - val_MinusLogProbMetric: 17.4624 - lr: 5.0000e-04 - 45s/epoch - 229ms/step
Epoch 115/1000
2023-09-23 16:32:05.239 
Epoch 115/1000 
	 loss: 16.2615, MinusLogProbMetric: 16.2615, val_loss: 17.4791, val_MinusLogProbMetric: 17.4791

Epoch 115: val_loss did not improve from 17.46242
196/196 - 44s - loss: 16.2615 - MinusLogProbMetric: 16.2615 - val_loss: 17.4791 - val_MinusLogProbMetric: 17.4791 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 116/1000
2023-09-23 16:32:25.009 
Epoch 73/1000 
	 loss: 18.9637, MinusLogProbMetric: 18.9637, val_loss: 19.2592, val_MinusLogProbMetric: 19.2592

Epoch 73: val_loss did not improve from 18.75405
196/196 - 65s - loss: 18.9637 - MinusLogProbMetric: 18.9637 - val_loss: 19.2592 - val_MinusLogProbMetric: 19.2592 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 74/1000
2023-09-23 16:32:49.852 
Epoch 116/1000 
	 loss: 16.2874, MinusLogProbMetric: 16.2874, val_loss: 17.5900, val_MinusLogProbMetric: 17.5900

Epoch 116: val_loss did not improve from 17.46242
196/196 - 45s - loss: 16.2874 - MinusLogProbMetric: 16.2874 - val_loss: 17.5900 - val_MinusLogProbMetric: 17.5900 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 117/1000
2023-09-23 16:33:30.487 
Epoch 74/1000 
	 loss: 19.0593, MinusLogProbMetric: 19.0593, val_loss: 18.9072, val_MinusLogProbMetric: 18.9072

Epoch 74: val_loss did not improve from 18.75405
196/196 - 65s - loss: 19.0593 - MinusLogProbMetric: 19.0593 - val_loss: 18.9072 - val_MinusLogProbMetric: 18.9072 - lr: 3.3333e-04 - 65s/epoch - 334ms/step
Epoch 75/1000
2023-09-23 16:33:34.731 
Epoch 117/1000 
	 loss: 16.2422, MinusLogProbMetric: 16.2422, val_loss: 17.4693, val_MinusLogProbMetric: 17.4693

Epoch 117: val_loss did not improve from 17.46242
196/196 - 45s - loss: 16.2422 - MinusLogProbMetric: 16.2422 - val_loss: 17.4693 - val_MinusLogProbMetric: 17.4693 - lr: 5.0000e-04 - 45s/epoch - 229ms/step
Epoch 118/1000
2023-09-23 16:34:18.789 
Epoch 118/1000 
	 loss: 16.1990, MinusLogProbMetric: 16.1990, val_loss: 17.5349, val_MinusLogProbMetric: 17.5349

Epoch 118: val_loss did not improve from 17.46242
196/196 - 44s - loss: 16.1990 - MinusLogProbMetric: 16.1990 - val_loss: 17.5349 - val_MinusLogProbMetric: 17.5349 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 119/1000
2023-09-23 16:34:35.885 
Epoch 75/1000 
	 loss: 18.9979, MinusLogProbMetric: 18.9979, val_loss: 19.0144, val_MinusLogProbMetric: 19.0144

Epoch 75: val_loss did not improve from 18.75405
196/196 - 65s - loss: 18.9979 - MinusLogProbMetric: 18.9979 - val_loss: 19.0144 - val_MinusLogProbMetric: 19.0144 - lr: 3.3333e-04 - 65s/epoch - 334ms/step
Epoch 76/1000
2023-09-23 16:35:01.110 
Epoch 119/1000 
	 loss: 16.2031, MinusLogProbMetric: 16.2031, val_loss: 17.4405, val_MinusLogProbMetric: 17.4405

Epoch 119: val_loss improved from 17.46242 to 17.44049, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_300/weights/best_weights.h5
196/196 - 43s - loss: 16.2031 - MinusLogProbMetric: 16.2031 - val_loss: 17.4405 - val_MinusLogProbMetric: 17.4405 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 120/1000
2023-09-23 16:35:34.053 
Epoch 76/1000 
	 loss: 18.8364, MinusLogProbMetric: 18.8364, val_loss: 18.9814, val_MinusLogProbMetric: 18.9814

Epoch 76: val_loss did not improve from 18.75405
196/196 - 58s - loss: 18.8364 - MinusLogProbMetric: 18.8364 - val_loss: 18.9814 - val_MinusLogProbMetric: 18.9814 - lr: 3.3333e-04 - 58s/epoch - 297ms/step
Epoch 77/1000
2023-09-23 16:35:37.923 
Epoch 120/1000 
	 loss: 16.2041, MinusLogProbMetric: 16.2041, val_loss: 17.6424, val_MinusLogProbMetric: 17.6424

Epoch 120: val_loss did not improve from 17.44049
196/196 - 36s - loss: 16.2041 - MinusLogProbMetric: 16.2041 - val_loss: 17.6424 - val_MinusLogProbMetric: 17.6424 - lr: 5.0000e-04 - 36s/epoch - 185ms/step
Epoch 121/1000
2023-09-23 16:36:14.151 
Epoch 121/1000 
	 loss: 16.2516, MinusLogProbMetric: 16.2516, val_loss: 17.5021, val_MinusLogProbMetric: 17.5021

Epoch 121: val_loss did not improve from 17.44049
196/196 - 36s - loss: 16.2516 - MinusLogProbMetric: 16.2516 - val_loss: 17.5021 - val_MinusLogProbMetric: 17.5021 - lr: 5.0000e-04 - 36s/epoch - 185ms/step
Epoch 122/1000
2023-09-23 16:36:30.909 
Epoch 77/1000 
	 loss: 18.9319, MinusLogProbMetric: 18.9319, val_loss: 19.7967, val_MinusLogProbMetric: 19.7967

Epoch 77: val_loss did not improve from 18.75405
196/196 - 57s - loss: 18.9319 - MinusLogProbMetric: 18.9319 - val_loss: 19.7967 - val_MinusLogProbMetric: 19.7967 - lr: 3.3333e-04 - 57s/epoch - 290ms/step
Epoch 78/1000
2023-09-23 16:36:53.606 
Epoch 122/1000 
	 loss: 16.1931, MinusLogProbMetric: 16.1931, val_loss: 17.9653, val_MinusLogProbMetric: 17.9653

Epoch 122: val_loss did not improve from 17.44049
196/196 - 39s - loss: 16.1931 - MinusLogProbMetric: 16.1931 - val_loss: 17.9653 - val_MinusLogProbMetric: 17.9653 - lr: 5.0000e-04 - 39s/epoch - 201ms/step
Epoch 123/1000
2023-09-23 16:37:32.855 
Epoch 78/1000 
	 loss: 18.8350, MinusLogProbMetric: 18.8350, val_loss: 19.2918, val_MinusLogProbMetric: 19.2918

Epoch 78: val_loss did not improve from 18.75405
196/196 - 62s - loss: 18.8350 - MinusLogProbMetric: 18.8350 - val_loss: 19.2918 - val_MinusLogProbMetric: 19.2918 - lr: 3.3333e-04 - 62s/epoch - 316ms/step
Epoch 79/1000
2023-09-23 16:37:36.495 
Epoch 123/1000 
	 loss: 16.1860, MinusLogProbMetric: 16.1860, val_loss: 17.4638, val_MinusLogProbMetric: 17.4638

Epoch 123: val_loss did not improve from 17.44049
196/196 - 43s - loss: 16.1860 - MinusLogProbMetric: 16.1860 - val_loss: 17.4638 - val_MinusLogProbMetric: 17.4638 - lr: 5.0000e-04 - 43s/epoch - 219ms/step
Epoch 124/1000
2023-09-23 16:38:20.676 
Epoch 124/1000 
	 loss: 16.2649, MinusLogProbMetric: 16.2649, val_loss: 17.5067, val_MinusLogProbMetric: 17.5067

Epoch 124: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.2649 - MinusLogProbMetric: 16.2649 - val_loss: 17.5067 - val_MinusLogProbMetric: 17.5067 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 125/1000
2023-09-23 16:38:38.159 
Epoch 79/1000 
	 loss: 18.7281, MinusLogProbMetric: 18.7281, val_loss: 18.4762, val_MinusLogProbMetric: 18.4762

Epoch 79: val_loss improved from 18.75405 to 18.47624, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 66s - loss: 18.7281 - MinusLogProbMetric: 18.7281 - val_loss: 18.4762 - val_MinusLogProbMetric: 18.4762 - lr: 3.3333e-04 - 66s/epoch - 339ms/step
Epoch 80/1000
2023-09-23 16:39:03.045 
Epoch 125/1000 
	 loss: 16.1868, MinusLogProbMetric: 16.1868, val_loss: 18.8951, val_MinusLogProbMetric: 18.8951

Epoch 125: val_loss did not improve from 17.44049
196/196 - 42s - loss: 16.1868 - MinusLogProbMetric: 16.1868 - val_loss: 18.8951 - val_MinusLogProbMetric: 18.8951 - lr: 5.0000e-04 - 42s/epoch - 216ms/step
Epoch 126/1000
2023-09-23 16:39:43.469 
Epoch 80/1000 
	 loss: 18.9058, MinusLogProbMetric: 18.9058, val_loss: 20.0191, val_MinusLogProbMetric: 20.0191

Epoch 80: val_loss did not improve from 18.47624
196/196 - 64s - loss: 18.9058 - MinusLogProbMetric: 18.9058 - val_loss: 20.0191 - val_MinusLogProbMetric: 20.0191 - lr: 3.3333e-04 - 64s/epoch - 328ms/step
Epoch 81/1000
2023-09-23 16:39:47.046 
Epoch 126/1000 
	 loss: 16.1640, MinusLogProbMetric: 16.1640, val_loss: 17.6732, val_MinusLogProbMetric: 17.6732

Epoch 126: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.1640 - MinusLogProbMetric: 16.1640 - val_loss: 17.6732 - val_MinusLogProbMetric: 17.6732 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 127/1000
2023-09-23 16:40:30.803 
Epoch 127/1000 
	 loss: 16.1555, MinusLogProbMetric: 16.1555, val_loss: 17.6926, val_MinusLogProbMetric: 17.6926

Epoch 127: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.1555 - MinusLogProbMetric: 16.1555 - val_loss: 17.6926 - val_MinusLogProbMetric: 17.6926 - lr: 5.0000e-04 - 44s/epoch - 223ms/step
Epoch 128/1000
2023-09-23 16:40:48.151 
Epoch 81/1000 
	 loss: 18.8748, MinusLogProbMetric: 18.8748, val_loss: 18.2746, val_MinusLogProbMetric: 18.2746

Epoch 81: val_loss improved from 18.47624 to 18.27457, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 66s - loss: 18.8748 - MinusLogProbMetric: 18.8748 - val_loss: 18.2746 - val_MinusLogProbMetric: 18.2746 - lr: 3.3333e-04 - 66s/epoch - 335ms/step
Epoch 82/1000
2023-09-23 16:41:14.959 
Epoch 128/1000 
	 loss: 16.2005, MinusLogProbMetric: 16.2005, val_loss: 18.0603, val_MinusLogProbMetric: 18.0603

Epoch 128: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.2005 - MinusLogProbMetric: 16.2005 - val_loss: 18.0603 - val_MinusLogProbMetric: 18.0603 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 129/1000
2023-09-23 16:41:54.114 
Epoch 82/1000 
	 loss: 18.7134, MinusLogProbMetric: 18.7134, val_loss: 18.7110, val_MinusLogProbMetric: 18.7110

Epoch 82: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.7134 - MinusLogProbMetric: 18.7134 - val_loss: 18.7110 - val_MinusLogProbMetric: 18.7110 - lr: 3.3333e-04 - 65s/epoch - 331ms/step
Epoch 83/1000
2023-09-23 16:41:59.024 
Epoch 129/1000 
	 loss: 16.1392, MinusLogProbMetric: 16.1392, val_loss: 17.5558, val_MinusLogProbMetric: 17.5558

Epoch 129: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.1392 - MinusLogProbMetric: 16.1392 - val_loss: 17.5558 - val_MinusLogProbMetric: 17.5558 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 130/1000
2023-09-23 16:42:43.040 
Epoch 130/1000 
	 loss: 16.2121, MinusLogProbMetric: 16.2121, val_loss: 17.6341, val_MinusLogProbMetric: 17.6341

Epoch 130: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.2121 - MinusLogProbMetric: 16.2121 - val_loss: 17.6341 - val_MinusLogProbMetric: 17.6341 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 131/1000
2023-09-23 16:42:58.468 
Epoch 83/1000 
	 loss: 18.7634, MinusLogProbMetric: 18.7634, val_loss: 18.7769, val_MinusLogProbMetric: 18.7769

Epoch 83: val_loss did not improve from 18.27457
196/196 - 64s - loss: 18.7634 - MinusLogProbMetric: 18.7634 - val_loss: 18.7769 - val_MinusLogProbMetric: 18.7769 - lr: 3.3333e-04 - 64s/epoch - 328ms/step
Epoch 84/1000
2023-09-23 16:43:26.897 
Epoch 131/1000 
	 loss: 16.1768, MinusLogProbMetric: 16.1768, val_loss: 17.7744, val_MinusLogProbMetric: 17.7744

Epoch 131: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.1768 - MinusLogProbMetric: 16.1768 - val_loss: 17.7744 - val_MinusLogProbMetric: 17.7744 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 132/1000
2023-09-23 16:44:04.098 
Epoch 84/1000 
	 loss: 18.7248, MinusLogProbMetric: 18.7248, val_loss: 19.7949, val_MinusLogProbMetric: 19.7949

Epoch 84: val_loss did not improve from 18.27457
196/196 - 66s - loss: 18.7248 - MinusLogProbMetric: 18.7248 - val_loss: 19.7949 - val_MinusLogProbMetric: 19.7949 - lr: 3.3333e-04 - 66s/epoch - 335ms/step
Epoch 85/1000
2023-09-23 16:44:10.945 
Epoch 132/1000 
	 loss: 16.1405, MinusLogProbMetric: 16.1405, val_loss: 17.8651, val_MinusLogProbMetric: 17.8651

Epoch 132: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.1405 - MinusLogProbMetric: 16.1405 - val_loss: 17.8651 - val_MinusLogProbMetric: 17.8651 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 133/1000
2023-09-23 16:44:54.968 
Epoch 133/1000 
	 loss: 16.1642, MinusLogProbMetric: 16.1642, val_loss: 17.5578, val_MinusLogProbMetric: 17.5578

Epoch 133: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.1642 - MinusLogProbMetric: 16.1642 - val_loss: 17.5578 - val_MinusLogProbMetric: 17.5578 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 134/1000
2023-09-23 16:45:09.627 
Epoch 85/1000 
	 loss: 18.7844, MinusLogProbMetric: 18.7844, val_loss: 18.6262, val_MinusLogProbMetric: 18.6262

Epoch 85: val_loss did not improve from 18.27457
196/196 - 66s - loss: 18.7844 - MinusLogProbMetric: 18.7844 - val_loss: 18.6262 - val_MinusLogProbMetric: 18.6262 - lr: 3.3333e-04 - 66s/epoch - 334ms/step
Epoch 86/1000
2023-09-23 16:45:39.007 
Epoch 134/1000 
	 loss: 16.1836, MinusLogProbMetric: 16.1836, val_loss: 17.9601, val_MinusLogProbMetric: 17.9601

Epoch 134: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.1836 - MinusLogProbMetric: 16.1836 - val_loss: 17.9601 - val_MinusLogProbMetric: 17.9601 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 135/1000
2023-09-23 16:46:14.483 
Epoch 86/1000 
	 loss: 18.7097, MinusLogProbMetric: 18.7097, val_loss: 18.7041, val_MinusLogProbMetric: 18.7041

Epoch 86: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.7097 - MinusLogProbMetric: 18.7097 - val_loss: 18.7041 - val_MinusLogProbMetric: 18.7041 - lr: 3.3333e-04 - 65s/epoch - 331ms/step
Epoch 87/1000
2023-09-23 16:46:23.359 
Epoch 135/1000 
	 loss: 16.1680, MinusLogProbMetric: 16.1680, val_loss: 17.8319, val_MinusLogProbMetric: 17.8319

Epoch 135: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.1680 - MinusLogProbMetric: 16.1680 - val_loss: 17.8319 - val_MinusLogProbMetric: 17.8319 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 136/1000
2023-09-23 16:47:07.781 
Epoch 136/1000 
	 loss: 16.1457, MinusLogProbMetric: 16.1457, val_loss: 17.6870, val_MinusLogProbMetric: 17.6870

Epoch 136: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.1457 - MinusLogProbMetric: 16.1457 - val_loss: 17.6870 - val_MinusLogProbMetric: 17.6870 - lr: 5.0000e-04 - 44s/epoch - 227ms/step
Epoch 137/1000
2023-09-23 16:47:19.676 
Epoch 87/1000 
	 loss: 18.6348, MinusLogProbMetric: 18.6348, val_loss: 18.9210, val_MinusLogProbMetric: 18.9210

Epoch 87: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.6348 - MinusLogProbMetric: 18.6348 - val_loss: 18.9210 - val_MinusLogProbMetric: 18.9210 - lr: 3.3333e-04 - 65s/epoch - 333ms/step
Epoch 88/1000
2023-09-23 16:47:51.935 
Epoch 137/1000 
	 loss: 16.1080, MinusLogProbMetric: 16.1080, val_loss: 17.6276, val_MinusLogProbMetric: 17.6276

Epoch 137: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.1080 - MinusLogProbMetric: 16.1080 - val_loss: 17.6276 - val_MinusLogProbMetric: 17.6276 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 138/1000
2023-09-23 16:48:24.447 
Epoch 88/1000 
	 loss: 18.5382, MinusLogProbMetric: 18.5382, val_loss: 18.9912, val_MinusLogProbMetric: 18.9912

Epoch 88: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.5382 - MinusLogProbMetric: 18.5382 - val_loss: 18.9912 - val_MinusLogProbMetric: 18.9912 - lr: 3.3333e-04 - 65s/epoch - 330ms/step
Epoch 89/1000
2023-09-23 16:48:36.256 
Epoch 138/1000 
	 loss: 16.1616, MinusLogProbMetric: 16.1616, val_loss: 17.7630, val_MinusLogProbMetric: 17.7630

Epoch 138: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.1616 - MinusLogProbMetric: 16.1616 - val_loss: 17.7630 - val_MinusLogProbMetric: 17.7630 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 139/1000
2023-09-23 16:49:20.868 
Epoch 139/1000 
	 loss: 16.1551, MinusLogProbMetric: 16.1551, val_loss: 17.6511, val_MinusLogProbMetric: 17.6511

Epoch 139: val_loss did not improve from 17.44049
196/196 - 45s - loss: 16.1551 - MinusLogProbMetric: 16.1551 - val_loss: 17.6511 - val_MinusLogProbMetric: 17.6511 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 140/1000
2023-09-23 16:49:29.326 
Epoch 89/1000 
	 loss: 18.7896, MinusLogProbMetric: 18.7896, val_loss: 19.1983, val_MinusLogProbMetric: 19.1983

Epoch 89: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.7896 - MinusLogProbMetric: 18.7896 - val_loss: 19.1983 - val_MinusLogProbMetric: 19.1983 - lr: 3.3333e-04 - 65s/epoch - 331ms/step
Epoch 90/1000
2023-09-23 16:50:05.007 
Epoch 140/1000 
	 loss: 16.1383, MinusLogProbMetric: 16.1383, val_loss: 17.6818, val_MinusLogProbMetric: 17.6818

Epoch 140: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.1383 - MinusLogProbMetric: 16.1383 - val_loss: 17.6818 - val_MinusLogProbMetric: 17.6818 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 141/1000
2023-09-23 16:50:34.439 
Epoch 90/1000 
	 loss: 18.6526, MinusLogProbMetric: 18.6526, val_loss: 18.9205, val_MinusLogProbMetric: 18.9205

Epoch 90: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.6526 - MinusLogProbMetric: 18.6526 - val_loss: 18.9205 - val_MinusLogProbMetric: 18.9205 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 91/1000
2023-09-23 16:50:49.502 
Epoch 141/1000 
	 loss: 16.0939, MinusLogProbMetric: 16.0939, val_loss: 17.6456, val_MinusLogProbMetric: 17.6456

Epoch 141: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.0939 - MinusLogProbMetric: 16.0939 - val_loss: 17.6456 - val_MinusLogProbMetric: 17.6456 - lr: 5.0000e-04 - 44s/epoch - 227ms/step
Epoch 142/1000
2023-09-23 16:51:33.850 
Epoch 142/1000 
	 loss: 16.0804, MinusLogProbMetric: 16.0804, val_loss: 17.6442, val_MinusLogProbMetric: 17.6442

Epoch 142: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.0804 - MinusLogProbMetric: 16.0804 - val_loss: 17.6442 - val_MinusLogProbMetric: 17.6442 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 143/1000
2023-09-23 16:51:39.746 
Epoch 91/1000 
	 loss: 18.8395, MinusLogProbMetric: 18.8395, val_loss: 19.3543, val_MinusLogProbMetric: 19.3543

Epoch 91: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.8395 - MinusLogProbMetric: 18.8395 - val_loss: 19.3543 - val_MinusLogProbMetric: 19.3543 - lr: 3.3333e-04 - 65s/epoch - 333ms/step
Epoch 92/1000
2023-09-23 16:52:17.934 
Epoch 143/1000 
	 loss: 16.0776, MinusLogProbMetric: 16.0776, val_loss: 17.7086, val_MinusLogProbMetric: 17.7086

Epoch 143: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.0776 - MinusLogProbMetric: 16.0776 - val_loss: 17.7086 - val_MinusLogProbMetric: 17.7086 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 144/1000
2023-09-23 16:52:44.467 
Epoch 92/1000 
	 loss: 18.6948, MinusLogProbMetric: 18.6948, val_loss: 19.7831, val_MinusLogProbMetric: 19.7831

Epoch 92: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.6948 - MinusLogProbMetric: 18.6948 - val_loss: 19.7831 - val_MinusLogProbMetric: 19.7831 - lr: 3.3333e-04 - 65s/epoch - 330ms/step
Epoch 93/1000
2023-09-23 16:53:01.752 
Epoch 144/1000 
	 loss: 16.0635, MinusLogProbMetric: 16.0635, val_loss: 17.9180, val_MinusLogProbMetric: 17.9180

Epoch 144: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.0635 - MinusLogProbMetric: 16.0635 - val_loss: 17.9180 - val_MinusLogProbMetric: 17.9180 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 145/1000
2023-09-23 16:53:45.652 
Epoch 145/1000 
	 loss: 16.1076, MinusLogProbMetric: 16.1076, val_loss: 17.6671, val_MinusLogProbMetric: 17.6671

Epoch 145: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.1076 - MinusLogProbMetric: 16.1076 - val_loss: 17.6671 - val_MinusLogProbMetric: 17.6671 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 146/1000
2023-09-23 16:53:49.444 
Epoch 93/1000 
	 loss: 18.7129, MinusLogProbMetric: 18.7129, val_loss: 18.5745, val_MinusLogProbMetric: 18.5745

Epoch 93: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.7129 - MinusLogProbMetric: 18.7129 - val_loss: 18.5745 - val_MinusLogProbMetric: 18.5745 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 94/1000
2023-09-23 16:54:29.736 
Epoch 146/1000 
	 loss: 16.0332, MinusLogProbMetric: 16.0332, val_loss: 17.6356, val_MinusLogProbMetric: 17.6356

Epoch 146: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.0332 - MinusLogProbMetric: 16.0332 - val_loss: 17.6356 - val_MinusLogProbMetric: 17.6356 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 147/1000
2023-09-23 16:54:54.025 
Epoch 94/1000 
	 loss: 18.6047, MinusLogProbMetric: 18.6047, val_loss: 19.0045, val_MinusLogProbMetric: 19.0045

Epoch 94: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.6047 - MinusLogProbMetric: 18.6047 - val_loss: 19.0045 - val_MinusLogProbMetric: 19.0045 - lr: 3.3333e-04 - 65s/epoch - 329ms/step
Epoch 95/1000
2023-09-23 16:55:13.727 
Epoch 147/1000 
	 loss: 16.0801, MinusLogProbMetric: 16.0801, val_loss: 17.6483, val_MinusLogProbMetric: 17.6483

Epoch 147: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.0801 - MinusLogProbMetric: 16.0801 - val_loss: 17.6483 - val_MinusLogProbMetric: 17.6483 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 148/1000
2023-09-23 16:55:57.678 
Epoch 148/1000 
	 loss: 16.1130, MinusLogProbMetric: 16.1130, val_loss: 17.6574, val_MinusLogProbMetric: 17.6574

Epoch 148: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.1130 - MinusLogProbMetric: 16.1130 - val_loss: 17.6574 - val_MinusLogProbMetric: 17.6574 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 149/1000
2023-09-23 16:55:58.765 
Epoch 95/1000 
	 loss: 18.5973, MinusLogProbMetric: 18.5973, val_loss: 18.4640, val_MinusLogProbMetric: 18.4640

Epoch 95: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.5973 - MinusLogProbMetric: 18.5973 - val_loss: 18.4640 - val_MinusLogProbMetric: 18.4640 - lr: 3.3333e-04 - 65s/epoch - 330ms/step
Epoch 96/1000
2023-09-23 16:56:41.495 
Epoch 149/1000 
	 loss: 16.0670, MinusLogProbMetric: 16.0670, val_loss: 17.6780, val_MinusLogProbMetric: 17.6780

Epoch 149: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.0670 - MinusLogProbMetric: 16.0670 - val_loss: 17.6780 - val_MinusLogProbMetric: 17.6780 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 150/1000
2023-09-23 16:57:03.822 
Epoch 96/1000 
	 loss: 18.4272, MinusLogProbMetric: 18.4272, val_loss: 18.6727, val_MinusLogProbMetric: 18.6727

Epoch 96: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.4272 - MinusLogProbMetric: 18.4272 - val_loss: 18.6727 - val_MinusLogProbMetric: 18.6727 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 97/1000
2023-09-23 16:57:25.641 
Epoch 150/1000 
	 loss: 16.1021, MinusLogProbMetric: 16.1021, val_loss: 17.6973, val_MinusLogProbMetric: 17.6973

Epoch 150: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.1021 - MinusLogProbMetric: 16.1021 - val_loss: 17.6973 - val_MinusLogProbMetric: 17.6973 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 151/1000
2023-09-23 16:58:08.809 
Epoch 97/1000 
	 loss: 18.6806, MinusLogProbMetric: 18.6806, val_loss: 21.4426, val_MinusLogProbMetric: 21.4426

Epoch 97: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.6806 - MinusLogProbMetric: 18.6806 - val_loss: 21.4426 - val_MinusLogProbMetric: 21.4426 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 98/1000
2023-09-23 16:58:09.313 
Epoch 151/1000 
	 loss: 16.1143, MinusLogProbMetric: 16.1143, val_loss: 17.7914, val_MinusLogProbMetric: 17.7914

Epoch 151: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.1143 - MinusLogProbMetric: 16.1143 - val_loss: 17.7914 - val_MinusLogProbMetric: 17.7914 - lr: 5.0000e-04 - 44s/epoch - 223ms/step
Epoch 152/1000
2023-09-23 16:58:53.376 
Epoch 152/1000 
	 loss: 16.0627, MinusLogProbMetric: 16.0627, val_loss: 17.6561, val_MinusLogProbMetric: 17.6561

Epoch 152: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.0627 - MinusLogProbMetric: 16.0627 - val_loss: 17.6561 - val_MinusLogProbMetric: 17.6561 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 153/1000
2023-09-23 16:59:13.363 
Epoch 98/1000 
	 loss: 18.5497, MinusLogProbMetric: 18.5497, val_loss: 19.1004, val_MinusLogProbMetric: 19.1004

Epoch 98: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.5497 - MinusLogProbMetric: 18.5497 - val_loss: 19.1004 - val_MinusLogProbMetric: 19.1004 - lr: 3.3333e-04 - 65s/epoch - 329ms/step
Epoch 99/1000
2023-09-23 16:59:37.253 
Epoch 153/1000 
	 loss: 16.0559, MinusLogProbMetric: 16.0559, val_loss: 17.6764, val_MinusLogProbMetric: 17.6764

Epoch 153: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.0559 - MinusLogProbMetric: 16.0559 - val_loss: 17.6764 - val_MinusLogProbMetric: 17.6764 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 154/1000
2023-09-23 17:00:18.261 
Epoch 99/1000 
	 loss: 18.4132, MinusLogProbMetric: 18.4132, val_loss: 18.8442, val_MinusLogProbMetric: 18.8442

Epoch 99: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.4132 - MinusLogProbMetric: 18.4132 - val_loss: 18.8442 - val_MinusLogProbMetric: 18.8442 - lr: 3.3333e-04 - 65s/epoch - 331ms/step
Epoch 100/1000
2023-09-23 17:00:21.295 
Epoch 154/1000 
	 loss: 16.0145, MinusLogProbMetric: 16.0145, val_loss: 17.6943, val_MinusLogProbMetric: 17.6943

Epoch 154: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.0145 - MinusLogProbMetric: 16.0145 - val_loss: 17.6943 - val_MinusLogProbMetric: 17.6943 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 155/1000
2023-09-23 17:01:05.375 
Epoch 155/1000 
	 loss: 16.0148, MinusLogProbMetric: 16.0148, val_loss: 17.7507, val_MinusLogProbMetric: 17.7507

Epoch 155: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.0148 - MinusLogProbMetric: 16.0148 - val_loss: 17.7507 - val_MinusLogProbMetric: 17.7507 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 156/1000
2023-09-23 17:01:23.220 
Epoch 100/1000 
	 loss: 18.5120, MinusLogProbMetric: 18.5120, val_loss: 18.3251, val_MinusLogProbMetric: 18.3251

Epoch 100: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.5120 - MinusLogProbMetric: 18.5120 - val_loss: 18.3251 - val_MinusLogProbMetric: 18.3251 - lr: 3.3333e-04 - 65s/epoch - 331ms/step
Epoch 101/1000
2023-09-23 17:01:49.991 
Epoch 156/1000 
	 loss: 16.0117, MinusLogProbMetric: 16.0117, val_loss: 17.6787, val_MinusLogProbMetric: 17.6787

Epoch 156: val_loss did not improve from 17.44049
196/196 - 45s - loss: 16.0117 - MinusLogProbMetric: 16.0117 - val_loss: 17.6787 - val_MinusLogProbMetric: 17.6787 - lr: 5.0000e-04 - 45s/epoch - 228ms/step
Epoch 157/1000
2023-09-23 17:02:28.073 
Epoch 101/1000 
	 loss: 18.4913, MinusLogProbMetric: 18.4913, val_loss: 18.4402, val_MinusLogProbMetric: 18.4402

Epoch 101: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.4913 - MinusLogProbMetric: 18.4913 - val_loss: 18.4402 - val_MinusLogProbMetric: 18.4402 - lr: 3.3333e-04 - 65s/epoch - 331ms/step
Epoch 102/1000
2023-09-23 17:02:33.330 
Epoch 157/1000 
	 loss: 16.0534, MinusLogProbMetric: 16.0534, val_loss: 17.6331, val_MinusLogProbMetric: 17.6331

Epoch 157: val_loss did not improve from 17.44049
196/196 - 43s - loss: 16.0534 - MinusLogProbMetric: 16.0534 - val_loss: 17.6331 - val_MinusLogProbMetric: 17.6331 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 158/1000
2023-09-23 17:03:17.341 
Epoch 158/1000 
	 loss: 16.0529, MinusLogProbMetric: 16.0529, val_loss: 17.7309, val_MinusLogProbMetric: 17.7309

Epoch 158: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.0529 - MinusLogProbMetric: 16.0529 - val_loss: 17.7309 - val_MinusLogProbMetric: 17.7309 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 159/1000
2023-09-23 17:03:32.675 
Epoch 102/1000 
	 loss: 18.4198, MinusLogProbMetric: 18.4198, val_loss: 18.6694, val_MinusLogProbMetric: 18.6694

Epoch 102: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.4198 - MinusLogProbMetric: 18.4198 - val_loss: 18.6694 - val_MinusLogProbMetric: 18.6694 - lr: 3.3333e-04 - 65s/epoch - 330ms/step
Epoch 103/1000
2023-09-23 17:04:01.036 
Epoch 159/1000 
	 loss: 16.0179, MinusLogProbMetric: 16.0179, val_loss: 17.7048, val_MinusLogProbMetric: 17.7048

Epoch 159: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.0179 - MinusLogProbMetric: 16.0179 - val_loss: 17.7048 - val_MinusLogProbMetric: 17.7048 - lr: 5.0000e-04 - 44s/epoch - 223ms/step
Epoch 160/1000
2023-09-23 17:04:37.839 
Epoch 103/1000 
	 loss: 18.5324, MinusLogProbMetric: 18.5324, val_loss: 19.0640, val_MinusLogProbMetric: 19.0640

Epoch 103: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.5324 - MinusLogProbMetric: 18.5324 - val_loss: 19.0640 - val_MinusLogProbMetric: 19.0640 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 104/1000
2023-09-23 17:04:44.826 
Epoch 160/1000 
	 loss: 15.9892, MinusLogProbMetric: 15.9892, val_loss: 17.6697, val_MinusLogProbMetric: 17.6697

Epoch 160: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.9892 - MinusLogProbMetric: 15.9892 - val_loss: 17.6697 - val_MinusLogProbMetric: 17.6697 - lr: 5.0000e-04 - 44s/epoch - 223ms/step
Epoch 161/1000
2023-09-23 17:05:28.428 
Epoch 161/1000 
	 loss: 16.0487, MinusLogProbMetric: 16.0487, val_loss: 17.7544, val_MinusLogProbMetric: 17.7544

Epoch 161: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.0487 - MinusLogProbMetric: 16.0487 - val_loss: 17.7544 - val_MinusLogProbMetric: 17.7544 - lr: 5.0000e-04 - 44s/epoch - 222ms/step
Epoch 162/1000
2023-09-23 17:05:42.463 
Epoch 104/1000 
	 loss: 18.5156, MinusLogProbMetric: 18.5156, val_loss: 19.1068, val_MinusLogProbMetric: 19.1068

Epoch 104: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.5156 - MinusLogProbMetric: 18.5156 - val_loss: 19.1068 - val_MinusLogProbMetric: 19.1068 - lr: 3.3333e-04 - 65s/epoch - 330ms/step
Epoch 105/1000
2023-09-23 17:06:11.755 
Epoch 162/1000 
	 loss: 16.0154, MinusLogProbMetric: 16.0154, val_loss: 17.7613, val_MinusLogProbMetric: 17.7613

Epoch 162: val_loss did not improve from 17.44049
196/196 - 43s - loss: 16.0154 - MinusLogProbMetric: 16.0154 - val_loss: 17.7613 - val_MinusLogProbMetric: 17.7613 - lr: 5.0000e-04 - 43s/epoch - 221ms/step
Epoch 163/1000
2023-09-23 17:06:47.210 
Epoch 105/1000 
	 loss: 18.7572, MinusLogProbMetric: 18.7572, val_loss: 18.9037, val_MinusLogProbMetric: 18.9037

Epoch 105: val_loss did not improve from 18.27457
196/196 - 65s - loss: 18.7572 - MinusLogProbMetric: 18.7572 - val_loss: 18.9037 - val_MinusLogProbMetric: 18.9037 - lr: 3.3333e-04 - 65s/epoch - 330ms/step
Epoch 106/1000
2023-09-23 17:06:55.650 
Epoch 163/1000 
	 loss: 16.0134, MinusLogProbMetric: 16.0134, val_loss: 17.7944, val_MinusLogProbMetric: 17.7944

Epoch 163: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.0134 - MinusLogProbMetric: 16.0134 - val_loss: 17.7944 - val_MinusLogProbMetric: 17.7944 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 164/1000
2023-09-23 17:07:39.446 
Epoch 164/1000 
	 loss: 15.9659, MinusLogProbMetric: 15.9659, val_loss: 17.7032, val_MinusLogProbMetric: 17.7032

Epoch 164: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.9659 - MinusLogProbMetric: 15.9659 - val_loss: 17.7032 - val_MinusLogProbMetric: 17.7032 - lr: 5.0000e-04 - 44s/epoch - 223ms/step
Epoch 165/1000
2023-09-23 17:07:51.701 
Epoch 106/1000 
	 loss: 18.4661, MinusLogProbMetric: 18.4661, val_loss: 18.7204, val_MinusLogProbMetric: 18.7204

Epoch 106: val_loss did not improve from 18.27457
196/196 - 64s - loss: 18.4661 - MinusLogProbMetric: 18.4661 - val_loss: 18.7204 - val_MinusLogProbMetric: 18.7204 - lr: 3.3333e-04 - 64s/epoch - 329ms/step
Epoch 107/1000
2023-09-23 17:08:23.676 
Epoch 165/1000 
	 loss: 15.9668, MinusLogProbMetric: 15.9668, val_loss: 17.8360, val_MinusLogProbMetric: 17.8360

Epoch 165: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.9668 - MinusLogProbMetric: 15.9668 - val_loss: 17.8360 - val_MinusLogProbMetric: 17.8360 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 166/1000
2023-09-23 17:08:56.467 
Epoch 107/1000 
	 loss: 18.4221, MinusLogProbMetric: 18.4221, val_loss: 18.2470, val_MinusLogProbMetric: 18.2470

Epoch 107: val_loss improved from 18.27457 to 18.24699, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 66s - loss: 18.4221 - MinusLogProbMetric: 18.4221 - val_loss: 18.2470 - val_MinusLogProbMetric: 18.2470 - lr: 3.3333e-04 - 66s/epoch - 335ms/step
Epoch 108/1000
2023-09-23 17:09:07.767 
Epoch 166/1000 
	 loss: 15.9961, MinusLogProbMetric: 15.9961, val_loss: 17.7301, val_MinusLogProbMetric: 17.7301

Epoch 166: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.9961 - MinusLogProbMetric: 15.9961 - val_loss: 17.7301 - val_MinusLogProbMetric: 17.7301 - lr: 5.0000e-04 - 44s/epoch - 225ms/step
Epoch 167/1000
2023-09-23 17:09:52.151 
Epoch 167/1000 
	 loss: 15.9428, MinusLogProbMetric: 15.9428, val_loss: 17.7797, val_MinusLogProbMetric: 17.7797

Epoch 167: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.9428 - MinusLogProbMetric: 15.9428 - val_loss: 17.7797 - val_MinusLogProbMetric: 17.7797 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 168/1000
2023-09-23 17:10:02.926 
Epoch 108/1000 
	 loss: 18.4019, MinusLogProbMetric: 18.4019, val_loss: 18.8929, val_MinusLogProbMetric: 18.8929

Epoch 108: val_loss did not improve from 18.24699
196/196 - 65s - loss: 18.4019 - MinusLogProbMetric: 18.4019 - val_loss: 18.8929 - val_MinusLogProbMetric: 18.8929 - lr: 3.3333e-04 - 65s/epoch - 334ms/step
Epoch 109/1000
2023-09-23 17:10:36.079 
Epoch 168/1000 
	 loss: 16.0005, MinusLogProbMetric: 16.0005, val_loss: 19.1103, val_MinusLogProbMetric: 19.1103

Epoch 168: val_loss did not improve from 17.44049
196/196 - 44s - loss: 16.0005 - MinusLogProbMetric: 16.0005 - val_loss: 19.1103 - val_MinusLogProbMetric: 19.1103 - lr: 5.0000e-04 - 44s/epoch - 224ms/step
Epoch 169/1000
2023-09-23 17:11:08.059 
Epoch 109/1000 
	 loss: 18.3925, MinusLogProbMetric: 18.3925, val_loss: 19.3116, val_MinusLogProbMetric: 19.3116

Epoch 109: val_loss did not improve from 18.24699
196/196 - 65s - loss: 18.3925 - MinusLogProbMetric: 18.3925 - val_loss: 19.3116 - val_MinusLogProbMetric: 19.3116 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 110/1000
2023-09-23 17:11:20.463 
Epoch 169/1000 
	 loss: 15.9722, MinusLogProbMetric: 15.9722, val_loss: 17.8258, val_MinusLogProbMetric: 17.8258

Epoch 169: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.9722 - MinusLogProbMetric: 15.9722 - val_loss: 17.8258 - val_MinusLogProbMetric: 17.8258 - lr: 5.0000e-04 - 44s/epoch - 226ms/step
Epoch 170/1000
2023-09-23 17:12:03.889 
Epoch 170/1000 
	 loss: 15.7477, MinusLogProbMetric: 15.7477, val_loss: 17.7995, val_MinusLogProbMetric: 17.7995

Epoch 170: val_loss did not improve from 17.44049
196/196 - 43s - loss: 15.7477 - MinusLogProbMetric: 15.7477 - val_loss: 17.7995 - val_MinusLogProbMetric: 17.7995 - lr: 2.5000e-04 - 43s/epoch - 222ms/step
Epoch 171/1000
2023-09-23 17:12:12.630 
Epoch 110/1000 
	 loss: 18.3859, MinusLogProbMetric: 18.3859, val_loss: 18.6989, val_MinusLogProbMetric: 18.6989

Epoch 110: val_loss did not improve from 18.24699
196/196 - 65s - loss: 18.3859 - MinusLogProbMetric: 18.3859 - val_loss: 18.6989 - val_MinusLogProbMetric: 18.6989 - lr: 3.3333e-04 - 65s/epoch - 329ms/step
Epoch 111/1000
2023-09-23 17:12:47.776 
Epoch 171/1000 
	 loss: 15.7390, MinusLogProbMetric: 15.7390, val_loss: 17.7509, val_MinusLogProbMetric: 17.7509

Epoch 171: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.7390 - MinusLogProbMetric: 15.7390 - val_loss: 17.7509 - val_MinusLogProbMetric: 17.7509 - lr: 2.5000e-04 - 44s/epoch - 224ms/step
Epoch 172/1000
2023-09-23 17:13:17.494 
Epoch 111/1000 
	 loss: 18.5314, MinusLogProbMetric: 18.5314, val_loss: 18.4726, val_MinusLogProbMetric: 18.4726

Epoch 111: val_loss did not improve from 18.24699
196/196 - 65s - loss: 18.5314 - MinusLogProbMetric: 18.5314 - val_loss: 18.4726 - val_MinusLogProbMetric: 18.4726 - lr: 3.3333e-04 - 65s/epoch - 331ms/step
Epoch 112/1000
2023-09-23 17:13:32.175 
Epoch 172/1000 
	 loss: 15.7402, MinusLogProbMetric: 15.7402, val_loss: 17.7799, val_MinusLogProbMetric: 17.7799

Epoch 172: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.7402 - MinusLogProbMetric: 15.7402 - val_loss: 17.7799 - val_MinusLogProbMetric: 17.7799 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 173/1000
2023-09-23 17:14:16.058 
Epoch 173/1000 
	 loss: 15.7478, MinusLogProbMetric: 15.7478, val_loss: 17.7638, val_MinusLogProbMetric: 17.7638

Epoch 173: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.7478 - MinusLogProbMetric: 15.7478 - val_loss: 17.7638 - val_MinusLogProbMetric: 17.7638 - lr: 2.5000e-04 - 44s/epoch - 224ms/step
Epoch 174/1000
2023-09-23 17:14:22.237 
Epoch 112/1000 
	 loss: 18.3521, MinusLogProbMetric: 18.3521, val_loss: 18.7770, val_MinusLogProbMetric: 18.7770

Epoch 112: val_loss did not improve from 18.24699
196/196 - 65s - loss: 18.3521 - MinusLogProbMetric: 18.3521 - val_loss: 18.7770 - val_MinusLogProbMetric: 18.7770 - lr: 3.3333e-04 - 65s/epoch - 330ms/step
Epoch 113/1000
2023-09-23 17:15:00.512 
Epoch 174/1000 
	 loss: 15.7235, MinusLogProbMetric: 15.7235, val_loss: 17.8304, val_MinusLogProbMetric: 17.8304

Epoch 174: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.7235 - MinusLogProbMetric: 15.7235 - val_loss: 17.8304 - val_MinusLogProbMetric: 17.8304 - lr: 2.5000e-04 - 44s/epoch - 227ms/step
Epoch 175/1000
2023-09-23 17:15:26.783 
Epoch 113/1000 
	 loss: 18.2385, MinusLogProbMetric: 18.2385, val_loss: 18.3709, val_MinusLogProbMetric: 18.3709

Epoch 113: val_loss did not improve from 18.24699
196/196 - 65s - loss: 18.2385 - MinusLogProbMetric: 18.2385 - val_loss: 18.3709 - val_MinusLogProbMetric: 18.3709 - lr: 3.3333e-04 - 65s/epoch - 329ms/step
Epoch 114/1000
2023-09-23 17:15:44.538 
Epoch 175/1000 
	 loss: 15.7509, MinusLogProbMetric: 15.7509, val_loss: 17.8449, val_MinusLogProbMetric: 17.8449

Epoch 175: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.7509 - MinusLogProbMetric: 15.7509 - val_loss: 17.8449 - val_MinusLogProbMetric: 17.8449 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 176/1000
2023-09-23 17:16:28.813 
Epoch 176/1000 
	 loss: 15.7404, MinusLogProbMetric: 15.7404, val_loss: 17.8196, val_MinusLogProbMetric: 17.8196

Epoch 176: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.7404 - MinusLogProbMetric: 15.7404 - val_loss: 17.8196 - val_MinusLogProbMetric: 17.8196 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 177/1000
2023-09-23 17:16:31.605 
Epoch 114/1000 
	 loss: 18.2870, MinusLogProbMetric: 18.2870, val_loss: 20.4892, val_MinusLogProbMetric: 20.4892

Epoch 114: val_loss did not improve from 18.24699
196/196 - 65s - loss: 18.2870 - MinusLogProbMetric: 18.2870 - val_loss: 20.4892 - val_MinusLogProbMetric: 20.4892 - lr: 3.3333e-04 - 65s/epoch - 331ms/step
Epoch 115/1000
2023-09-23 17:17:12.478 
Epoch 177/1000 
	 loss: 15.7397, MinusLogProbMetric: 15.7397, val_loss: 17.7887, val_MinusLogProbMetric: 17.7887

Epoch 177: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.7397 - MinusLogProbMetric: 15.7397 - val_loss: 17.7887 - val_MinusLogProbMetric: 17.7887 - lr: 2.5000e-04 - 44s/epoch - 223ms/step
Epoch 178/1000
2023-09-23 17:17:36.616 
Epoch 115/1000 
	 loss: 18.4698, MinusLogProbMetric: 18.4698, val_loss: 18.4060, val_MinusLogProbMetric: 18.4060

Epoch 115: val_loss did not improve from 18.24699
196/196 - 65s - loss: 18.4698 - MinusLogProbMetric: 18.4698 - val_loss: 18.4060 - val_MinusLogProbMetric: 18.4060 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 116/1000
2023-09-23 17:17:56.808 
Epoch 178/1000 
	 loss: 15.7394, MinusLogProbMetric: 15.7394, val_loss: 17.8057, val_MinusLogProbMetric: 17.8057

Epoch 178: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.7394 - MinusLogProbMetric: 15.7394 - val_loss: 17.8057 - val_MinusLogProbMetric: 17.8057 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 179/1000
2023-09-23 17:18:41.086 
Epoch 179/1000 
	 loss: 15.7302, MinusLogProbMetric: 15.7302, val_loss: 17.9048, val_MinusLogProbMetric: 17.9048

Epoch 179: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.7302 - MinusLogProbMetric: 15.7302 - val_loss: 17.9048 - val_MinusLogProbMetric: 17.9048 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 180/1000
2023-09-23 17:18:41.916 
Epoch 116/1000 
	 loss: 18.3678, MinusLogProbMetric: 18.3678, val_loss: 19.3646, val_MinusLogProbMetric: 19.3646

Epoch 116: val_loss did not improve from 18.24699
196/196 - 65s - loss: 18.3678 - MinusLogProbMetric: 18.3678 - val_loss: 19.3646 - val_MinusLogProbMetric: 19.3646 - lr: 3.3333e-04 - 65s/epoch - 333ms/step
Epoch 117/1000
2023-09-23 17:19:25.277 
Epoch 180/1000 
	 loss: 15.7058, MinusLogProbMetric: 15.7058, val_loss: 17.8073, val_MinusLogProbMetric: 17.8073

Epoch 180: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.7058 - MinusLogProbMetric: 15.7058 - val_loss: 17.8073 - val_MinusLogProbMetric: 17.8073 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 181/1000
2023-09-23 17:19:47.249 
Epoch 117/1000 
	 loss: 18.3812, MinusLogProbMetric: 18.3812, val_loss: 18.2305, val_MinusLogProbMetric: 18.2305

Epoch 117: val_loss improved from 18.24699 to 18.23052, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 67s - loss: 18.3812 - MinusLogProbMetric: 18.3812 - val_loss: 18.2305 - val_MinusLogProbMetric: 18.2305 - lr: 3.3333e-04 - 67s/epoch - 340ms/step
Epoch 118/1000
2023-09-23 17:20:09.194 
Epoch 181/1000 
	 loss: 15.7214, MinusLogProbMetric: 15.7214, val_loss: 17.8186, val_MinusLogProbMetric: 17.8186

Epoch 181: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.7214 - MinusLogProbMetric: 15.7214 - val_loss: 17.8186 - val_MinusLogProbMetric: 17.8186 - lr: 2.5000e-04 - 44s/epoch - 224ms/step
Epoch 182/1000
2023-09-23 17:20:53.306 
Epoch 182/1000 
	 loss: 15.7432, MinusLogProbMetric: 15.7432, val_loss: 17.8250, val_MinusLogProbMetric: 17.8250

Epoch 182: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.7432 - MinusLogProbMetric: 15.7432 - val_loss: 17.8250 - val_MinusLogProbMetric: 17.8250 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 183/1000
2023-09-23 17:20:53.627 
Epoch 118/1000 
	 loss: 18.2481, MinusLogProbMetric: 18.2481, val_loss: 18.8635, val_MinusLogProbMetric: 18.8635

Epoch 118: val_loss did not improve from 18.23052
196/196 - 65s - loss: 18.2481 - MinusLogProbMetric: 18.2481 - val_loss: 18.8635 - val_MinusLogProbMetric: 18.8635 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 119/1000
2023-09-23 17:21:37.664 
Epoch 183/1000 
	 loss: 15.7002, MinusLogProbMetric: 15.7002, val_loss: 18.0140, val_MinusLogProbMetric: 18.0140

Epoch 183: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.7002 - MinusLogProbMetric: 15.7002 - val_loss: 18.0140 - val_MinusLogProbMetric: 18.0140 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 184/1000
2023-09-23 17:21:58.288 
Epoch 119/1000 
	 loss: 18.2583, MinusLogProbMetric: 18.2583, val_loss: 18.0332, val_MinusLogProbMetric: 18.0332

Epoch 119: val_loss improved from 18.23052 to 18.03318, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 66s - loss: 18.2583 - MinusLogProbMetric: 18.2583 - val_loss: 18.0332 - val_MinusLogProbMetric: 18.0332 - lr: 3.3333e-04 - 66s/epoch - 335ms/step
Epoch 120/1000
2023-09-23 17:22:21.706 
Epoch 184/1000 
	 loss: 15.6963, MinusLogProbMetric: 15.6963, val_loss: 17.8696, val_MinusLogProbMetric: 17.8696

Epoch 184: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.6963 - MinusLogProbMetric: 15.6963 - val_loss: 17.8696 - val_MinusLogProbMetric: 17.8696 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 185/1000
2023-09-23 17:23:04.471 
Epoch 120/1000 
	 loss: 18.1799, MinusLogProbMetric: 18.1799, val_loss: 18.2750, val_MinusLogProbMetric: 18.2750

Epoch 120: val_loss did not improve from 18.03318
196/196 - 65s - loss: 18.1799 - MinusLogProbMetric: 18.1799 - val_loss: 18.2750 - val_MinusLogProbMetric: 18.2750 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 121/1000
2023-09-23 17:23:06.165 
Epoch 185/1000 
	 loss: 15.6943, MinusLogProbMetric: 15.6943, val_loss: 17.8797, val_MinusLogProbMetric: 17.8797

Epoch 185: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.6943 - MinusLogProbMetric: 15.6943 - val_loss: 17.8797 - val_MinusLogProbMetric: 17.8797 - lr: 2.5000e-04 - 44s/epoch - 227ms/step
Epoch 186/1000
2023-09-23 17:23:50.343 
Epoch 186/1000 
	 loss: 15.7128, MinusLogProbMetric: 15.7128, val_loss: 17.9387, val_MinusLogProbMetric: 17.9387

Epoch 186: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.7128 - MinusLogProbMetric: 15.7128 - val_loss: 17.9387 - val_MinusLogProbMetric: 17.9387 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 187/1000
2023-09-23 17:24:09.530 
Epoch 121/1000 
	 loss: 18.3884, MinusLogProbMetric: 18.3884, val_loss: 17.9336, val_MinusLogProbMetric: 17.9336

Epoch 121: val_loss improved from 18.03318 to 17.93357, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 66s - loss: 18.3884 - MinusLogProbMetric: 18.3884 - val_loss: 17.9336 - val_MinusLogProbMetric: 17.9336 - lr: 3.3333e-04 - 66s/epoch - 337ms/step
Epoch 122/1000
2023-09-23 17:24:34.620 
Epoch 187/1000 
	 loss: 15.7048, MinusLogProbMetric: 15.7048, val_loss: 17.8416, val_MinusLogProbMetric: 17.8416

Epoch 187: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.7048 - MinusLogProbMetric: 15.7048 - val_loss: 17.8416 - val_MinusLogProbMetric: 17.8416 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 188/1000
2023-09-23 17:25:15.240 
Epoch 122/1000 
	 loss: 18.2568, MinusLogProbMetric: 18.2568, val_loss: 19.0488, val_MinusLogProbMetric: 19.0488

Epoch 122: val_loss did not improve from 17.93357
196/196 - 65s - loss: 18.2568 - MinusLogProbMetric: 18.2568 - val_loss: 19.0488 - val_MinusLogProbMetric: 19.0488 - lr: 3.3333e-04 - 65s/epoch - 330ms/step
Epoch 123/1000
2023-09-23 17:25:18.663 
Epoch 188/1000 
	 loss: 15.7456, MinusLogProbMetric: 15.7456, val_loss: 17.9656, val_MinusLogProbMetric: 17.9656

Epoch 188: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.7456 - MinusLogProbMetric: 15.7456 - val_loss: 17.9656 - val_MinusLogProbMetric: 17.9656 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 189/1000
2023-09-23 17:26:02.846 
Epoch 189/1000 
	 loss: 15.6955, MinusLogProbMetric: 15.6955, val_loss: 17.9431, val_MinusLogProbMetric: 17.9431

Epoch 189: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.6955 - MinusLogProbMetric: 15.6955 - val_loss: 17.9431 - val_MinusLogProbMetric: 17.9431 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 190/1000
2023-09-23 17:26:20.374 
Epoch 123/1000 
	 loss: 18.2968, MinusLogProbMetric: 18.2968, val_loss: 18.7077, val_MinusLogProbMetric: 18.7077

Epoch 123: val_loss did not improve from 17.93357
196/196 - 65s - loss: 18.2968 - MinusLogProbMetric: 18.2968 - val_loss: 18.7077 - val_MinusLogProbMetric: 18.7077 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 124/1000
2023-09-23 17:26:46.594 
Epoch 190/1000 
	 loss: 15.6768, MinusLogProbMetric: 15.6768, val_loss: 17.8646, val_MinusLogProbMetric: 17.8646

Epoch 190: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.6768 - MinusLogProbMetric: 15.6768 - val_loss: 17.8646 - val_MinusLogProbMetric: 17.8646 - lr: 2.5000e-04 - 44s/epoch - 223ms/step
Epoch 191/1000
2023-09-23 17:27:30.062 
Epoch 124/1000 
	 loss: 18.1492, MinusLogProbMetric: 18.1492, val_loss: 19.0843, val_MinusLogProbMetric: 19.0843

Epoch 124: val_loss did not improve from 17.93357
196/196 - 70s - loss: 18.1492 - MinusLogProbMetric: 18.1492 - val_loss: 19.0843 - val_MinusLogProbMetric: 19.0843 - lr: 3.3333e-04 - 70s/epoch - 356ms/step
Epoch 125/1000
2023-09-23 17:27:34.248 
Epoch 191/1000 
	 loss: 15.6716, MinusLogProbMetric: 15.6716, val_loss: 18.1503, val_MinusLogProbMetric: 18.1503

Epoch 191: val_loss did not improve from 17.44049
196/196 - 48s - loss: 15.6716 - MinusLogProbMetric: 15.6716 - val_loss: 18.1503 - val_MinusLogProbMetric: 18.1503 - lr: 2.5000e-04 - 48s/epoch - 243ms/step
Epoch 192/1000
2023-09-23 17:28:18.863 
Epoch 192/1000 
	 loss: 15.6915, MinusLogProbMetric: 15.6915, val_loss: 17.8644, val_MinusLogProbMetric: 17.8644

Epoch 192: val_loss did not improve from 17.44049
196/196 - 45s - loss: 15.6915 - MinusLogProbMetric: 15.6915 - val_loss: 17.8644 - val_MinusLogProbMetric: 17.8644 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 193/1000
2023-09-23 17:28:36.631 
Epoch 125/1000 
	 loss: 18.0985, MinusLogProbMetric: 18.0985, val_loss: 17.9652, val_MinusLogProbMetric: 17.9652

Epoch 125: val_loss did not improve from 17.93357
196/196 - 67s - loss: 18.0985 - MinusLogProbMetric: 18.0985 - val_loss: 17.9652 - val_MinusLogProbMetric: 17.9652 - lr: 3.3333e-04 - 67s/epoch - 340ms/step
Epoch 126/1000
2023-09-23 17:29:03.813 
Epoch 193/1000 
	 loss: 15.6736, MinusLogProbMetric: 15.6736, val_loss: 17.8962, val_MinusLogProbMetric: 17.8962

Epoch 193: val_loss did not improve from 17.44049
196/196 - 45s - loss: 15.6736 - MinusLogProbMetric: 15.6736 - val_loss: 17.8962 - val_MinusLogProbMetric: 17.8962 - lr: 2.5000e-04 - 45s/epoch - 229ms/step
Epoch 194/1000
2023-09-23 17:29:42.645 
Epoch 126/1000 
	 loss: 18.1524, MinusLogProbMetric: 18.1524, val_loss: 18.0916, val_MinusLogProbMetric: 18.0916

Epoch 126: val_loss did not improve from 17.93357
196/196 - 66s - loss: 18.1524 - MinusLogProbMetric: 18.1524 - val_loss: 18.0916 - val_MinusLogProbMetric: 18.0916 - lr: 3.3333e-04 - 66s/epoch - 337ms/step
Epoch 127/1000
2023-09-23 17:29:48.900 
Epoch 194/1000 
	 loss: 15.6731, MinusLogProbMetric: 15.6731, val_loss: 17.9669, val_MinusLogProbMetric: 17.9669

Epoch 194: val_loss did not improve from 17.44049
196/196 - 45s - loss: 15.6731 - MinusLogProbMetric: 15.6731 - val_loss: 17.9669 - val_MinusLogProbMetric: 17.9669 - lr: 2.5000e-04 - 45s/epoch - 230ms/step
Epoch 195/1000
2023-09-23 17:30:33.894 
Epoch 195/1000 
	 loss: 15.6796, MinusLogProbMetric: 15.6796, val_loss: 18.0973, val_MinusLogProbMetric: 18.0973

Epoch 195: val_loss did not improve from 17.44049
196/196 - 45s - loss: 15.6796 - MinusLogProbMetric: 15.6796 - val_loss: 18.0973 - val_MinusLogProbMetric: 18.0973 - lr: 2.5000e-04 - 45s/epoch - 230ms/step
Epoch 196/1000
2023-09-23 17:30:48.232 
Epoch 127/1000 
	 loss: 18.2514, MinusLogProbMetric: 18.2514, val_loss: 18.8450, val_MinusLogProbMetric: 18.8450

Epoch 127: val_loss did not improve from 17.93357
196/196 - 66s - loss: 18.2514 - MinusLogProbMetric: 18.2514 - val_loss: 18.8450 - val_MinusLogProbMetric: 18.8450 - lr: 3.3333e-04 - 66s/epoch - 335ms/step
Epoch 128/1000
2023-09-23 17:31:18.663 
Epoch 196/1000 
	 loss: 15.7139, MinusLogProbMetric: 15.7139, val_loss: 17.9211, val_MinusLogProbMetric: 17.9211

Epoch 196: val_loss did not improve from 17.44049
196/196 - 45s - loss: 15.7139 - MinusLogProbMetric: 15.7139 - val_loss: 17.9211 - val_MinusLogProbMetric: 17.9211 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 197/1000
2023-09-23 17:31:54.031 
Epoch 128/1000 
	 loss: 18.2670, MinusLogProbMetric: 18.2670, val_loss: 18.3172, val_MinusLogProbMetric: 18.3172

Epoch 128: val_loss did not improve from 17.93357
196/196 - 66s - loss: 18.2670 - MinusLogProbMetric: 18.2670 - val_loss: 18.3172 - val_MinusLogProbMetric: 18.3172 - lr: 3.3333e-04 - 66s/epoch - 336ms/step
Epoch 129/1000
2023-09-23 17:32:03.285 
Epoch 197/1000 
	 loss: 15.6670, MinusLogProbMetric: 15.6670, val_loss: 17.9164, val_MinusLogProbMetric: 17.9164

Epoch 197: val_loss did not improve from 17.44049
196/196 - 45s - loss: 15.6670 - MinusLogProbMetric: 15.6670 - val_loss: 17.9164 - val_MinusLogProbMetric: 17.9164 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 198/1000
2023-09-23 17:32:48.409 
Epoch 198/1000 
	 loss: 15.6895, MinusLogProbMetric: 15.6895, val_loss: 17.9133, val_MinusLogProbMetric: 17.9133

Epoch 198: val_loss did not improve from 17.44049
196/196 - 45s - loss: 15.6895 - MinusLogProbMetric: 15.6895 - val_loss: 17.9133 - val_MinusLogProbMetric: 17.9133 - lr: 2.5000e-04 - 45s/epoch - 230ms/step
Epoch 199/1000
2023-09-23 17:32:59.553 
Epoch 129/1000 
	 loss: 18.1561, MinusLogProbMetric: 18.1561, val_loss: 18.4207, val_MinusLogProbMetric: 18.4207

Epoch 129: val_loss did not improve from 17.93357
196/196 - 66s - loss: 18.1561 - MinusLogProbMetric: 18.1561 - val_loss: 18.4207 - val_MinusLogProbMetric: 18.4207 - lr: 3.3333e-04 - 66s/epoch - 334ms/step
Epoch 130/1000
2023-09-23 17:33:33.209 
Epoch 199/1000 
	 loss: 15.6509, MinusLogProbMetric: 15.6509, val_loss: 17.9741, val_MinusLogProbMetric: 17.9741

Epoch 199: val_loss did not improve from 17.44049
196/196 - 45s - loss: 15.6509 - MinusLogProbMetric: 15.6509 - val_loss: 17.9741 - val_MinusLogProbMetric: 17.9741 - lr: 2.5000e-04 - 45s/epoch - 229ms/step
Epoch 200/1000
2023-09-23 17:34:05.796 
Epoch 130/1000 
	 loss: 18.2277, MinusLogProbMetric: 18.2277, val_loss: 18.2688, val_MinusLogProbMetric: 18.2688

Epoch 130: val_loss did not improve from 17.93357
196/196 - 66s - loss: 18.2277 - MinusLogProbMetric: 18.2277 - val_loss: 18.2688 - val_MinusLogProbMetric: 18.2688 - lr: 3.3333e-04 - 66s/epoch - 338ms/step
Epoch 131/1000
2023-09-23 17:34:17.926 
Epoch 200/1000 
	 loss: 15.6660, MinusLogProbMetric: 15.6660, val_loss: 18.0509, val_MinusLogProbMetric: 18.0509

Epoch 200: val_loss did not improve from 17.44049
196/196 - 45s - loss: 15.6660 - MinusLogProbMetric: 15.6660 - val_loss: 18.0509 - val_MinusLogProbMetric: 18.0509 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 201/1000
2023-09-23 17:35:02.934 
Epoch 201/1000 
	 loss: 15.6565, MinusLogProbMetric: 15.6565, val_loss: 17.9643, val_MinusLogProbMetric: 17.9643

Epoch 201: val_loss did not improve from 17.44049
196/196 - 45s - loss: 15.6565 - MinusLogProbMetric: 15.6565 - val_loss: 17.9643 - val_MinusLogProbMetric: 17.9643 - lr: 2.5000e-04 - 45s/epoch - 230ms/step
Epoch 202/1000
2023-09-23 17:35:11.850 
Epoch 131/1000 
	 loss: 18.1907, MinusLogProbMetric: 18.1907, val_loss: 18.3409, val_MinusLogProbMetric: 18.3409

Epoch 131: val_loss did not improve from 17.93357
196/196 - 66s - loss: 18.1907 - MinusLogProbMetric: 18.1907 - val_loss: 18.3409 - val_MinusLogProbMetric: 18.3409 - lr: 3.3333e-04 - 66s/epoch - 337ms/step
Epoch 132/1000
2023-09-23 17:35:47.398 
Epoch 202/1000 
	 loss: 15.6571, MinusLogProbMetric: 15.6571, val_loss: 17.9927, val_MinusLogProbMetric: 17.9927

Epoch 202: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.6571 - MinusLogProbMetric: 15.6571 - val_loss: 17.9927 - val_MinusLogProbMetric: 17.9927 - lr: 2.5000e-04 - 44s/epoch - 227ms/step
Epoch 203/1000
2023-09-23 17:36:17.731 
Epoch 132/1000 
	 loss: 18.2339, MinusLogProbMetric: 18.2339, val_loss: 18.9619, val_MinusLogProbMetric: 18.9619

Epoch 132: val_loss did not improve from 17.93357
196/196 - 66s - loss: 18.2339 - MinusLogProbMetric: 18.2339 - val_loss: 18.9619 - val_MinusLogProbMetric: 18.9619 - lr: 3.3333e-04 - 66s/epoch - 336ms/step
Epoch 133/1000
2023-09-23 17:36:31.902 
Epoch 203/1000 
	 loss: 15.6438, MinusLogProbMetric: 15.6438, val_loss: 18.0754, val_MinusLogProbMetric: 18.0754

Epoch 203: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.6438 - MinusLogProbMetric: 15.6438 - val_loss: 18.0754 - val_MinusLogProbMetric: 18.0754 - lr: 2.5000e-04 - 44s/epoch - 227ms/step
Epoch 204/1000
2023-09-23 17:37:16.040 
Epoch 204/1000 
	 loss: 15.6518, MinusLogProbMetric: 15.6518, val_loss: 17.9445, val_MinusLogProbMetric: 17.9445

Epoch 204: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.6518 - MinusLogProbMetric: 15.6518 - val_loss: 17.9445 - val_MinusLogProbMetric: 17.9445 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 205/1000
2023-09-23 17:37:22.850 
Epoch 133/1000 
	 loss: 18.1400, MinusLogProbMetric: 18.1400, val_loss: 18.3187, val_MinusLogProbMetric: 18.3187

Epoch 133: val_loss did not improve from 17.93357
196/196 - 65s - loss: 18.1400 - MinusLogProbMetric: 18.1400 - val_loss: 18.3187 - val_MinusLogProbMetric: 18.3187 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 134/1000
2023-09-23 17:37:59.904 
Epoch 205/1000 
	 loss: 15.6807, MinusLogProbMetric: 15.6807, val_loss: 17.9613, val_MinusLogProbMetric: 17.9613

Epoch 205: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.6807 - MinusLogProbMetric: 15.6807 - val_loss: 17.9613 - val_MinusLogProbMetric: 17.9613 - lr: 2.5000e-04 - 44s/epoch - 224ms/step
Epoch 206/1000
2023-09-23 17:38:27.836 
Epoch 134/1000 
	 loss: 18.2750, MinusLogProbMetric: 18.2750, val_loss: 18.7125, val_MinusLogProbMetric: 18.7125

Epoch 134: val_loss did not improve from 17.93357
196/196 - 65s - loss: 18.2750 - MinusLogProbMetric: 18.2750 - val_loss: 18.7125 - val_MinusLogProbMetric: 18.7125 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 135/1000
2023-09-23 17:38:43.937 
Epoch 206/1000 
	 loss: 15.6152, MinusLogProbMetric: 15.6152, val_loss: 18.0026, val_MinusLogProbMetric: 18.0026

Epoch 206: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.6152 - MinusLogProbMetric: 15.6152 - val_loss: 18.0026 - val_MinusLogProbMetric: 18.0026 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 207/1000
2023-09-23 17:39:28.301 
Epoch 207/1000 
	 loss: 15.6672, MinusLogProbMetric: 15.6672, val_loss: 18.0156, val_MinusLogProbMetric: 18.0156

Epoch 207: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.6672 - MinusLogProbMetric: 15.6672 - val_loss: 18.0156 - val_MinusLogProbMetric: 18.0156 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 208/1000
2023-09-23 17:39:33.200 
Epoch 135/1000 
	 loss: 18.1007, MinusLogProbMetric: 18.1007, val_loss: 18.0379, val_MinusLogProbMetric: 18.0379

Epoch 135: val_loss did not improve from 17.93357
196/196 - 65s - loss: 18.1007 - MinusLogProbMetric: 18.1007 - val_loss: 18.0379 - val_MinusLogProbMetric: 18.0379 - lr: 3.3333e-04 - 65s/epoch - 333ms/step
Epoch 136/1000
2023-09-23 17:40:12.359 
Epoch 208/1000 
	 loss: 15.6860, MinusLogProbMetric: 15.6860, val_loss: 18.1265, val_MinusLogProbMetric: 18.1265

Epoch 208: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.6860 - MinusLogProbMetric: 15.6860 - val_loss: 18.1265 - val_MinusLogProbMetric: 18.1265 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 209/1000
2023-09-23 17:40:38.626 
Epoch 136/1000 
	 loss: 18.2510, MinusLogProbMetric: 18.2510, val_loss: 18.7664, val_MinusLogProbMetric: 18.7664

Epoch 136: val_loss did not improve from 17.93357
196/196 - 65s - loss: 18.2510 - MinusLogProbMetric: 18.2510 - val_loss: 18.7664 - val_MinusLogProbMetric: 18.7664 - lr: 3.3333e-04 - 65s/epoch - 334ms/step
Epoch 137/1000
2023-09-23 17:40:56.382 
Epoch 209/1000 
	 loss: 15.6286, MinusLogProbMetric: 15.6286, val_loss: 18.0805, val_MinusLogProbMetric: 18.0805

Epoch 209: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.6286 - MinusLogProbMetric: 15.6286 - val_loss: 18.0805 - val_MinusLogProbMetric: 18.0805 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 210/1000
2023-09-23 17:41:40.284 
Epoch 210/1000 
	 loss: 15.6352, MinusLogProbMetric: 15.6352, val_loss: 18.0672, val_MinusLogProbMetric: 18.0672

Epoch 210: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.6352 - MinusLogProbMetric: 15.6352 - val_loss: 18.0672 - val_MinusLogProbMetric: 18.0672 - lr: 2.5000e-04 - 44s/epoch - 224ms/step
Epoch 211/1000
2023-09-23 17:41:43.752 
Epoch 137/1000 
	 loss: 18.1791, MinusLogProbMetric: 18.1791, val_loss: 18.3568, val_MinusLogProbMetric: 18.3568

Epoch 137: val_loss did not improve from 17.93357
196/196 - 65s - loss: 18.1791 - MinusLogProbMetric: 18.1791 - val_loss: 18.3568 - val_MinusLogProbMetric: 18.3568 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 138/1000
2023-09-23 17:42:24.742 
Epoch 211/1000 
	 loss: 15.6389, MinusLogProbMetric: 15.6389, val_loss: 17.9787, val_MinusLogProbMetric: 17.9787

Epoch 211: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.6389 - MinusLogProbMetric: 15.6389 - val_loss: 17.9787 - val_MinusLogProbMetric: 17.9787 - lr: 2.5000e-04 - 44s/epoch - 227ms/step
Epoch 212/1000
2023-09-23 17:42:48.713 
Epoch 138/1000 
	 loss: 18.0361, MinusLogProbMetric: 18.0361, val_loss: 18.1404, val_MinusLogProbMetric: 18.1404

Epoch 138: val_loss did not improve from 17.93357
196/196 - 65s - loss: 18.0361 - MinusLogProbMetric: 18.0361 - val_loss: 18.1404 - val_MinusLogProbMetric: 18.1404 - lr: 3.3333e-04 - 65s/epoch - 331ms/step
Epoch 139/1000
2023-09-23 17:43:09.098 
Epoch 212/1000 
	 loss: 15.6415, MinusLogProbMetric: 15.6415, val_loss: 18.0550, val_MinusLogProbMetric: 18.0550

Epoch 212: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.6415 - MinusLogProbMetric: 15.6415 - val_loss: 18.0550 - val_MinusLogProbMetric: 18.0550 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 213/1000
2023-09-23 17:43:53.144 
Epoch 213/1000 
	 loss: 15.6128, MinusLogProbMetric: 15.6128, val_loss: 18.0751, val_MinusLogProbMetric: 18.0751

Epoch 213: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.6128 - MinusLogProbMetric: 15.6128 - val_loss: 18.0751 - val_MinusLogProbMetric: 18.0751 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 214/1000
2023-09-23 17:43:53.402 
Epoch 139/1000 
	 loss: 18.0545, MinusLogProbMetric: 18.0545, val_loss: 17.7580, val_MinusLogProbMetric: 17.7580

Epoch 139: val_loss improved from 17.93357 to 17.75797, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 66s - loss: 18.0545 - MinusLogProbMetric: 18.0545 - val_loss: 17.7580 - val_MinusLogProbMetric: 17.7580 - lr: 3.3333e-04 - 66s/epoch - 334ms/step
Epoch 140/1000
2023-09-23 17:44:37.531 
Epoch 214/1000 
	 loss: 15.6546, MinusLogProbMetric: 15.6546, val_loss: 17.9395, val_MinusLogProbMetric: 17.9395

Epoch 214: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.6546 - MinusLogProbMetric: 15.6546 - val_loss: 17.9395 - val_MinusLogProbMetric: 17.9395 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 215/1000
2023-09-23 17:44:59.364 
Epoch 140/1000 
	 loss: 18.1046, MinusLogProbMetric: 18.1046, val_loss: 20.2343, val_MinusLogProbMetric: 20.2343

Epoch 140: val_loss did not improve from 17.75797
196/196 - 65s - loss: 18.1046 - MinusLogProbMetric: 18.1046 - val_loss: 20.2343 - val_MinusLogProbMetric: 20.2343 - lr: 3.3333e-04 - 65s/epoch - 332ms/step
Epoch 141/1000
2023-09-23 17:45:21.368 
Epoch 215/1000 
	 loss: 15.6295, MinusLogProbMetric: 15.6295, val_loss: 18.3793, val_MinusLogProbMetric: 18.3793

Epoch 215: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.6295 - MinusLogProbMetric: 15.6295 - val_loss: 18.3793 - val_MinusLogProbMetric: 18.3793 - lr: 2.5000e-04 - 44s/epoch - 224ms/step
Epoch 216/1000
2023-09-23 17:46:04.612 
Epoch 141/1000 
	 loss: 18.1262, MinusLogProbMetric: 18.1262, val_loss: 18.1698, val_MinusLogProbMetric: 18.1698

Epoch 141: val_loss did not improve from 17.75797
196/196 - 65s - loss: 18.1262 - MinusLogProbMetric: 18.1262 - val_loss: 18.1698 - val_MinusLogProbMetric: 18.1698 - lr: 3.3333e-04 - 65s/epoch - 333ms/step
Epoch 142/1000
2023-09-23 17:46:05.597 
Epoch 216/1000 
	 loss: 15.6240, MinusLogProbMetric: 15.6240, val_loss: 18.0036, val_MinusLogProbMetric: 18.0036

Epoch 216: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.6240 - MinusLogProbMetric: 15.6240 - val_loss: 18.0036 - val_MinusLogProbMetric: 18.0036 - lr: 2.5000e-04 - 44s/epoch - 226ms/step
Epoch 217/1000
2023-09-23 17:46:49.682 
Epoch 217/1000 
	 loss: 15.6196, MinusLogProbMetric: 15.6196, val_loss: 18.0324, val_MinusLogProbMetric: 18.0324

Epoch 217: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.6196 - MinusLogProbMetric: 15.6196 - val_loss: 18.0324 - val_MinusLogProbMetric: 18.0324 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 218/1000
2023-09-23 17:47:09.095 
Epoch 142/1000 
	 loss: 18.0588, MinusLogProbMetric: 18.0588, val_loss: 18.0347, val_MinusLogProbMetric: 18.0347

Epoch 142: val_loss did not improve from 17.75797
196/196 - 64s - loss: 18.0588 - MinusLogProbMetric: 18.0588 - val_loss: 18.0347 - val_MinusLogProbMetric: 18.0347 - lr: 3.3333e-04 - 64s/epoch - 329ms/step
Epoch 143/1000
2023-09-23 17:47:33.710 
Epoch 218/1000 
	 loss: 15.5878, MinusLogProbMetric: 15.5878, val_loss: 18.2558, val_MinusLogProbMetric: 18.2558

Epoch 218: val_loss did not improve from 17.44049
196/196 - 44s - loss: 15.5878 - MinusLogProbMetric: 15.5878 - val_loss: 18.2558 - val_MinusLogProbMetric: 18.2558 - lr: 2.5000e-04 - 44s/epoch - 225ms/step
Epoch 219/1000
2023-09-23 17:48:13.645 
Epoch 143/1000 
	 loss: 18.0888, MinusLogProbMetric: 18.0888, val_loss: 18.4017, val_MinusLogProbMetric: 18.4017

Epoch 143: val_loss did not improve from 17.75797
196/196 - 65s - loss: 18.0888 - MinusLogProbMetric: 18.0888 - val_loss: 18.4017 - val_MinusLogProbMetric: 18.4017 - lr: 3.3333e-04 - 65s/epoch - 329ms/step
Epoch 144/1000
2023-09-23 17:48:17.769 
Epoch 219/1000 
	 loss: 15.6202, MinusLogProbMetric: 15.6202, val_loss: 18.1784, val_MinusLogProbMetric: 18.1784

Epoch 219: val_loss did not improve from 17.44049
Restoring model weights from the end of the best epoch: 119.
196/196 - 45s - loss: 15.6202 - MinusLogProbMetric: 15.6202 - val_loss: 18.1784 - val_MinusLogProbMetric: 18.1784 - lr: 2.5000e-04 - 45s/epoch - 228ms/step
Epoch 219: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
LR metric calculation completed in 19.82763054500174 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
2023-09-23 17:49:21.079 
Epoch 144/1000 
	 loss: 18.0989, MinusLogProbMetric: 18.0989, val_loss: 17.8440, val_MinusLogProbMetric: 17.8440

Epoch 144: val_loss did not improve from 17.75797
196/196 - 67s - loss: 18.0989 - MinusLogProbMetric: 18.0989 - val_loss: 17.8440 - val_MinusLogProbMetric: 17.8440 - lr: 3.3333e-04 - 67s/epoch - 344ms/step
Epoch 145/1000
LR metric calculation completed in 35.119919714998105 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
2023-09-23 17:50:21.622 
Epoch 145/1000 
	 loss: 18.1330, MinusLogProbMetric: 18.1330, val_loss: 18.0833, val_MinusLogProbMetric: 18.0833

Epoch 145: val_loss did not improve from 17.75797
196/196 - 61s - loss: 18.1330 - MinusLogProbMetric: 18.1330 - val_loss: 18.0833 - val_MinusLogProbMetric: 18.0833 - lr: 3.3333e-04 - 61s/epoch - 309ms/step
Epoch 146/1000
2023-09-23 17:51:23.361 
Epoch 146/1000 
	 loss: 18.0230, MinusLogProbMetric: 18.0230, val_loss: 18.2620, val_MinusLogProbMetric: 18.2620

Epoch 146: val_loss did not improve from 17.75797
196/196 - 62s - loss: 18.0230 - MinusLogProbMetric: 18.0230 - val_loss: 18.2620 - val_MinusLogProbMetric: 18.2620 - lr: 3.3333e-04 - 62s/epoch - 315ms/step
Epoch 147/1000
2023-09-23 17:52:26.121 
Epoch 147/1000 
	 loss: 18.1764, MinusLogProbMetric: 18.1764, val_loss: 18.7481, val_MinusLogProbMetric: 18.7481

Epoch 147: val_loss did not improve from 17.75797
196/196 - 63s - loss: 18.1764 - MinusLogProbMetric: 18.1764 - val_loss: 18.7481 - val_MinusLogProbMetric: 18.7481 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 148/1000
2023-09-23 17:53:28.772 
Epoch 148/1000 
	 loss: 17.8535, MinusLogProbMetric: 17.8535, val_loss: 18.7656, val_MinusLogProbMetric: 18.7656

Epoch 148: val_loss did not improve from 17.75797
196/196 - 63s - loss: 17.8535 - MinusLogProbMetric: 17.8535 - val_loss: 18.7656 - val_MinusLogProbMetric: 18.7656 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 149/1000
2023-09-23 17:54:32.195 
Epoch 149/1000 
	 loss: 18.0626, MinusLogProbMetric: 18.0626, val_loss: 18.5363, val_MinusLogProbMetric: 18.5363

Epoch 149: val_loss did not improve from 17.75797
196/196 - 63s - loss: 18.0626 - MinusLogProbMetric: 18.0626 - val_loss: 18.5363 - val_MinusLogProbMetric: 18.5363 - lr: 3.3333e-04 - 63s/epoch - 324ms/step
Epoch 150/1000
2023-09-23 17:55:35.054 
Epoch 150/1000 
	 loss: 17.9816, MinusLogProbMetric: 17.9816, val_loss: 19.3534, val_MinusLogProbMetric: 19.3534

Epoch 150: val_loss did not improve from 17.75797
196/196 - 63s - loss: 17.9816 - MinusLogProbMetric: 17.9816 - val_loss: 19.3534 - val_MinusLogProbMetric: 19.3534 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 151/1000
2023-09-23 17:56:38.686 
Epoch 151/1000 
	 loss: 18.1059, MinusLogProbMetric: 18.1059, val_loss: 18.2967, val_MinusLogProbMetric: 18.2967

Epoch 151: val_loss did not improve from 17.75797
196/196 - 64s - loss: 18.1059 - MinusLogProbMetric: 18.1059 - val_loss: 18.2967 - val_MinusLogProbMetric: 18.2967 - lr: 3.3333e-04 - 64s/epoch - 325ms/step
Epoch 152/1000
2023-09-23 17:57:41.055 
Epoch 152/1000 
	 loss: 17.9929, MinusLogProbMetric: 17.9929, val_loss: 17.8696, val_MinusLogProbMetric: 17.8696

Epoch 152: val_loss did not improve from 17.75797
196/196 - 62s - loss: 17.9929 - MinusLogProbMetric: 17.9929 - val_loss: 17.8696 - val_MinusLogProbMetric: 17.8696 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 153/1000
2023-09-23 17:58:43.837 
Epoch 153/1000 
	 loss: 17.9941, MinusLogProbMetric: 17.9941, val_loss: 18.9372, val_MinusLogProbMetric: 18.9372

Epoch 153: val_loss did not improve from 17.75797
196/196 - 63s - loss: 17.9941 - MinusLogProbMetric: 17.9941 - val_loss: 18.9372 - val_MinusLogProbMetric: 18.9372 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 154/1000
2023-09-23 17:59:46.602 
Epoch 154/1000 
	 loss: 17.9486, MinusLogProbMetric: 17.9486, val_loss: 17.9871, val_MinusLogProbMetric: 17.9871

Epoch 154: val_loss did not improve from 17.75797
196/196 - 63s - loss: 17.9486 - MinusLogProbMetric: 17.9486 - val_loss: 17.9871 - val_MinusLogProbMetric: 17.9871 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 155/1000
2023-09-23 18:00:48.863 
Epoch 155/1000 
	 loss: 17.9356, MinusLogProbMetric: 17.9356, val_loss: 19.2569, val_MinusLogProbMetric: 19.2569

Epoch 155: val_loss did not improve from 17.75797
196/196 - 62s - loss: 17.9356 - MinusLogProbMetric: 17.9356 - val_loss: 19.2569 - val_MinusLogProbMetric: 19.2569 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 156/1000
2023-09-23 18:01:51.383 
Epoch 156/1000 
	 loss: 17.9877, MinusLogProbMetric: 17.9877, val_loss: 18.2044, val_MinusLogProbMetric: 18.2044

Epoch 156: val_loss did not improve from 17.75797
196/196 - 63s - loss: 17.9877 - MinusLogProbMetric: 17.9877 - val_loss: 18.2044 - val_MinusLogProbMetric: 18.2044 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 157/1000
2023-09-23 18:02:54.099 
Epoch 157/1000 
	 loss: 17.9842, MinusLogProbMetric: 17.9842, val_loss: 18.9343, val_MinusLogProbMetric: 18.9343

Epoch 157: val_loss did not improve from 17.75797
196/196 - 63s - loss: 17.9842 - MinusLogProbMetric: 17.9842 - val_loss: 18.9343 - val_MinusLogProbMetric: 18.9343 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 158/1000
2023-09-23 18:03:57.238 
Epoch 158/1000 
	 loss: 17.9704, MinusLogProbMetric: 17.9704, val_loss: 18.5634, val_MinusLogProbMetric: 18.5634

Epoch 158: val_loss did not improve from 17.75797
196/196 - 63s - loss: 17.9704 - MinusLogProbMetric: 17.9704 - val_loss: 18.5634 - val_MinusLogProbMetric: 18.5634 - lr: 3.3333e-04 - 63s/epoch - 322ms/step
Epoch 159/1000
2023-09-23 18:04:59.624 
Epoch 159/1000 
	 loss: 17.9881, MinusLogProbMetric: 17.9881, val_loss: 18.6654, val_MinusLogProbMetric: 18.6654

Epoch 159: val_loss did not improve from 17.75797
196/196 - 62s - loss: 17.9881 - MinusLogProbMetric: 17.9881 - val_loss: 18.6654 - val_MinusLogProbMetric: 18.6654 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 160/1000
2023-09-23 18:06:02.388 
Epoch 160/1000 
	 loss: 18.0274, MinusLogProbMetric: 18.0274, val_loss: 18.2445, val_MinusLogProbMetric: 18.2445

Epoch 160: val_loss did not improve from 17.75797
196/196 - 63s - loss: 18.0274 - MinusLogProbMetric: 18.0274 - val_loss: 18.2445 - val_MinusLogProbMetric: 18.2445 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 161/1000
2023-09-23 18:07:05.169 
Epoch 161/1000 
	 loss: 18.0229, MinusLogProbMetric: 18.0229, val_loss: 18.7588, val_MinusLogProbMetric: 18.7588

Epoch 161: val_loss did not improve from 17.75797
196/196 - 63s - loss: 18.0229 - MinusLogProbMetric: 18.0229 - val_loss: 18.7588 - val_MinusLogProbMetric: 18.7588 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 162/1000
2023-09-23 18:08:08.102 
Epoch 162/1000 
	 loss: 17.8151, MinusLogProbMetric: 17.8151, val_loss: 18.3092, val_MinusLogProbMetric: 18.3092

Epoch 162: val_loss did not improve from 17.75797
196/196 - 63s - loss: 17.8151 - MinusLogProbMetric: 17.8151 - val_loss: 18.3092 - val_MinusLogProbMetric: 18.3092 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 163/1000
2023-09-23 18:09:10.333 
Epoch 163/1000 
	 loss: 18.0057, MinusLogProbMetric: 18.0057, val_loss: 18.3402, val_MinusLogProbMetric: 18.3402

Epoch 163: val_loss did not improve from 17.75797
196/196 - 62s - loss: 18.0057 - MinusLogProbMetric: 18.0057 - val_loss: 18.3402 - val_MinusLogProbMetric: 18.3402 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 164/1000
2023-09-23 18:10:12.372 
Epoch 164/1000 
	 loss: 18.0166, MinusLogProbMetric: 18.0166, val_loss: 18.9476, val_MinusLogProbMetric: 18.9476

Epoch 164: val_loss did not improve from 17.75797
196/196 - 62s - loss: 18.0166 - MinusLogProbMetric: 18.0166 - val_loss: 18.9476 - val_MinusLogProbMetric: 18.9476 - lr: 3.3333e-04 - 62s/epoch - 316ms/step
Epoch 165/1000
2023-09-23 18:11:15.115 
Epoch 165/1000 
	 loss: 17.8599, MinusLogProbMetric: 17.8599, val_loss: 18.6071, val_MinusLogProbMetric: 18.6071

Epoch 165: val_loss did not improve from 17.75797
196/196 - 63s - loss: 17.8599 - MinusLogProbMetric: 17.8599 - val_loss: 18.6071 - val_MinusLogProbMetric: 18.6071 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 166/1000
2023-09-23 18:12:17.797 
Epoch 166/1000 
	 loss: 17.8821, MinusLogProbMetric: 17.8821, val_loss: 18.7670, val_MinusLogProbMetric: 18.7670

Epoch 166: val_loss did not improve from 17.75797
196/196 - 63s - loss: 17.8821 - MinusLogProbMetric: 17.8821 - val_loss: 18.7670 - val_MinusLogProbMetric: 18.7670 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 167/1000
2023-09-23 18:13:21.107 
Epoch 167/1000 
	 loss: 17.8616, MinusLogProbMetric: 17.8616, val_loss: 18.3621, val_MinusLogProbMetric: 18.3621

Epoch 167: val_loss did not improve from 17.75797
196/196 - 63s - loss: 17.8616 - MinusLogProbMetric: 17.8616 - val_loss: 18.3621 - val_MinusLogProbMetric: 18.3621 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 168/1000
2023-09-23 18:14:23.819 
Epoch 168/1000 
	 loss: 18.0079, MinusLogProbMetric: 18.0079, val_loss: 18.3601, val_MinusLogProbMetric: 18.3601

Epoch 168: val_loss did not improve from 17.75797
196/196 - 63s - loss: 18.0079 - MinusLogProbMetric: 18.0079 - val_loss: 18.3601 - val_MinusLogProbMetric: 18.3601 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 169/1000
2023-09-23 18:15:26.077 
Epoch 169/1000 
	 loss: 17.8900, MinusLogProbMetric: 17.8900, val_loss: 18.5477, val_MinusLogProbMetric: 18.5477

Epoch 169: val_loss did not improve from 17.75797
196/196 - 62s - loss: 17.8900 - MinusLogProbMetric: 17.8900 - val_loss: 18.5477 - val_MinusLogProbMetric: 18.5477 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 170/1000
2023-09-23 18:16:29.093 
Epoch 170/1000 
	 loss: 17.8970, MinusLogProbMetric: 17.8970, val_loss: 17.9292, val_MinusLogProbMetric: 17.9292

Epoch 170: val_loss did not improve from 17.75797
196/196 - 63s - loss: 17.8970 - MinusLogProbMetric: 17.8970 - val_loss: 17.9292 - val_MinusLogProbMetric: 17.9292 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 171/1000
2023-09-23 18:17:31.716 
Epoch 171/1000 
	 loss: 17.8778, MinusLogProbMetric: 17.8778, val_loss: 17.9441, val_MinusLogProbMetric: 17.9441

Epoch 171: val_loss did not improve from 17.75797
196/196 - 63s - loss: 17.8778 - MinusLogProbMetric: 17.8778 - val_loss: 17.9441 - val_MinusLogProbMetric: 17.9441 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 172/1000
2023-09-23 18:18:34.925 
Epoch 172/1000 
	 loss: 17.8413, MinusLogProbMetric: 17.8413, val_loss: 18.4774, val_MinusLogProbMetric: 18.4774

Epoch 172: val_loss did not improve from 17.75797
196/196 - 63s - loss: 17.8413 - MinusLogProbMetric: 17.8413 - val_loss: 18.4774 - val_MinusLogProbMetric: 18.4774 - lr: 3.3333e-04 - 63s/epoch - 322ms/step
Epoch 173/1000
2023-09-23 18:19:37.596 
Epoch 173/1000 
	 loss: 17.8581, MinusLogProbMetric: 17.8581, val_loss: 18.6057, val_MinusLogProbMetric: 18.6057

Epoch 173: val_loss did not improve from 17.75797
196/196 - 63s - loss: 17.8581 - MinusLogProbMetric: 17.8581 - val_loss: 18.6057 - val_MinusLogProbMetric: 18.6057 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 174/1000
2023-09-23 18:20:40.533 
Epoch 174/1000 
	 loss: 17.8062, MinusLogProbMetric: 17.8062, val_loss: 18.5125, val_MinusLogProbMetric: 18.5125

Epoch 174: val_loss did not improve from 17.75797
196/196 - 63s - loss: 17.8062 - MinusLogProbMetric: 17.8062 - val_loss: 18.5125 - val_MinusLogProbMetric: 18.5125 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 175/1000
2023-09-23 18:21:43.613 
Epoch 175/1000 
	 loss: 17.8503, MinusLogProbMetric: 17.8503, val_loss: 18.2191, val_MinusLogProbMetric: 18.2191

Epoch 175: val_loss did not improve from 17.75797
196/196 - 63s - loss: 17.8503 - MinusLogProbMetric: 17.8503 - val_loss: 18.2191 - val_MinusLogProbMetric: 18.2191 - lr: 3.3333e-04 - 63s/epoch - 322ms/step
Epoch 176/1000
2023-09-23 18:22:46.475 
Epoch 176/1000 
	 loss: 17.8832, MinusLogProbMetric: 17.8832, val_loss: 18.1684, val_MinusLogProbMetric: 18.1684

Epoch 176: val_loss did not improve from 17.75797
196/196 - 63s - loss: 17.8832 - MinusLogProbMetric: 17.8832 - val_loss: 18.1684 - val_MinusLogProbMetric: 18.1684 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 177/1000
2023-09-23 18:23:49.416 
Epoch 177/1000 
	 loss: 17.8417, MinusLogProbMetric: 17.8417, val_loss: 18.4560, val_MinusLogProbMetric: 18.4560

Epoch 177: val_loss did not improve from 17.75797
196/196 - 63s - loss: 17.8417 - MinusLogProbMetric: 17.8417 - val_loss: 18.4560 - val_MinusLogProbMetric: 18.4560 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 178/1000
2023-09-23 18:24:51.473 
Epoch 178/1000 
	 loss: 17.9035, MinusLogProbMetric: 17.9035, val_loss: 17.8117, val_MinusLogProbMetric: 17.8117

Epoch 178: val_loss did not improve from 17.75797
196/196 - 62s - loss: 17.9035 - MinusLogProbMetric: 17.9035 - val_loss: 17.8117 - val_MinusLogProbMetric: 17.8117 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 179/1000
2023-09-23 18:25:54.485 
Epoch 179/1000 
	 loss: 17.7240, MinusLogProbMetric: 17.7240, val_loss: 17.7125, val_MinusLogProbMetric: 17.7125

Epoch 179: val_loss improved from 17.75797 to 17.71254, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 64s - loss: 17.7240 - MinusLogProbMetric: 17.7240 - val_loss: 17.7125 - val_MinusLogProbMetric: 17.7125 - lr: 3.3333e-04 - 64s/epoch - 327ms/step
Epoch 180/1000
2023-09-23 18:26:58.315 
Epoch 180/1000 
	 loss: 17.8217, MinusLogProbMetric: 17.8217, val_loss: 17.8815, val_MinusLogProbMetric: 17.8815

Epoch 180: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.8217 - MinusLogProbMetric: 17.8217 - val_loss: 17.8815 - val_MinusLogProbMetric: 17.8815 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 181/1000
2023-09-23 18:28:00.419 
Epoch 181/1000 
	 loss: 17.8243, MinusLogProbMetric: 17.8243, val_loss: 18.3851, val_MinusLogProbMetric: 18.3851

Epoch 181: val_loss did not improve from 17.71254
196/196 - 62s - loss: 17.8243 - MinusLogProbMetric: 17.8243 - val_loss: 18.3851 - val_MinusLogProbMetric: 18.3851 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 182/1000
2023-09-23 18:29:03.159 
Epoch 182/1000 
	 loss: 17.9240, MinusLogProbMetric: 17.9240, val_loss: 18.7259, val_MinusLogProbMetric: 18.7259

Epoch 182: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.9240 - MinusLogProbMetric: 17.9240 - val_loss: 18.7259 - val_MinusLogProbMetric: 18.7259 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 183/1000
2023-09-23 18:30:05.455 
Epoch 183/1000 
	 loss: 17.6800, MinusLogProbMetric: 17.6800, val_loss: 17.9110, val_MinusLogProbMetric: 17.9110

Epoch 183: val_loss did not improve from 17.71254
196/196 - 62s - loss: 17.6800 - MinusLogProbMetric: 17.6800 - val_loss: 17.9110 - val_MinusLogProbMetric: 17.9110 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 184/1000
2023-09-23 18:31:08.436 
Epoch 184/1000 
	 loss: 17.9104, MinusLogProbMetric: 17.9104, val_loss: 18.1974, val_MinusLogProbMetric: 18.1974

Epoch 184: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.9104 - MinusLogProbMetric: 17.9104 - val_loss: 18.1974 - val_MinusLogProbMetric: 18.1974 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 185/1000
2023-09-23 18:32:10.998 
Epoch 185/1000 
	 loss: 17.7470, MinusLogProbMetric: 17.7470, val_loss: 17.8835, val_MinusLogProbMetric: 17.8835

Epoch 185: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.7470 - MinusLogProbMetric: 17.7470 - val_loss: 17.8835 - val_MinusLogProbMetric: 17.8835 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 186/1000
2023-09-23 18:33:13.516 
Epoch 186/1000 
	 loss: 17.7471, MinusLogProbMetric: 17.7471, val_loss: 18.0334, val_MinusLogProbMetric: 18.0334

Epoch 186: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.7471 - MinusLogProbMetric: 17.7471 - val_loss: 18.0334 - val_MinusLogProbMetric: 18.0334 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 187/1000
2023-09-23 18:34:16.370 
Epoch 187/1000 
	 loss: 17.7628, MinusLogProbMetric: 17.7628, val_loss: 18.2044, val_MinusLogProbMetric: 18.2044

Epoch 187: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.7628 - MinusLogProbMetric: 17.7628 - val_loss: 18.2044 - val_MinusLogProbMetric: 18.2044 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 188/1000
2023-09-23 18:35:18.841 
Epoch 188/1000 
	 loss: 17.8031, MinusLogProbMetric: 17.8031, val_loss: 17.8580, val_MinusLogProbMetric: 17.8580

Epoch 188: val_loss did not improve from 17.71254
196/196 - 62s - loss: 17.8031 - MinusLogProbMetric: 17.8031 - val_loss: 17.8580 - val_MinusLogProbMetric: 17.8580 - lr: 3.3333e-04 - 62s/epoch - 319ms/step
Epoch 189/1000
2023-09-23 18:36:21.488 
Epoch 189/1000 
	 loss: 17.7563, MinusLogProbMetric: 17.7563, val_loss: 17.8324, val_MinusLogProbMetric: 17.8324

Epoch 189: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.7563 - MinusLogProbMetric: 17.7563 - val_loss: 17.8324 - val_MinusLogProbMetric: 17.8324 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 190/1000
2023-09-23 18:37:24.300 
Epoch 190/1000 
	 loss: 17.7940, MinusLogProbMetric: 17.7940, val_loss: 18.4486, val_MinusLogProbMetric: 18.4486

Epoch 190: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.7940 - MinusLogProbMetric: 17.7940 - val_loss: 18.4486 - val_MinusLogProbMetric: 18.4486 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 191/1000
2023-09-23 18:38:27.125 
Epoch 191/1000 
	 loss: 17.7133, MinusLogProbMetric: 17.7133, val_loss: 18.3236, val_MinusLogProbMetric: 18.3236

Epoch 191: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.7133 - MinusLogProbMetric: 17.7133 - val_loss: 18.3236 - val_MinusLogProbMetric: 18.3236 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 192/1000
2023-09-23 18:39:30.233 
Epoch 192/1000 
	 loss: 17.7295, MinusLogProbMetric: 17.7295, val_loss: 18.9702, val_MinusLogProbMetric: 18.9702

Epoch 192: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.7295 - MinusLogProbMetric: 17.7295 - val_loss: 18.9702 - val_MinusLogProbMetric: 18.9702 - lr: 3.3333e-04 - 63s/epoch - 322ms/step
Epoch 193/1000
2023-09-23 18:40:33.011 
Epoch 193/1000 
	 loss: 17.8104, MinusLogProbMetric: 17.8104, val_loss: 17.8435, val_MinusLogProbMetric: 17.8435

Epoch 193: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.8104 - MinusLogProbMetric: 17.8104 - val_loss: 17.8435 - val_MinusLogProbMetric: 17.8435 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 194/1000
2023-09-23 18:41:35.431 
Epoch 194/1000 
	 loss: 17.7120, MinusLogProbMetric: 17.7120, val_loss: 18.0283, val_MinusLogProbMetric: 18.0283

Epoch 194: val_loss did not improve from 17.71254
196/196 - 62s - loss: 17.7120 - MinusLogProbMetric: 17.7120 - val_loss: 18.0283 - val_MinusLogProbMetric: 18.0283 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 195/1000
2023-09-23 18:42:38.315 
Epoch 195/1000 
	 loss: 17.6336, MinusLogProbMetric: 17.6336, val_loss: 18.2192, val_MinusLogProbMetric: 18.2192

Epoch 195: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.6336 - MinusLogProbMetric: 17.6336 - val_loss: 18.2192 - val_MinusLogProbMetric: 18.2192 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 196/1000
2023-09-23 18:43:41.110 
Epoch 196/1000 
	 loss: 17.7840, MinusLogProbMetric: 17.7840, val_loss: 18.5314, val_MinusLogProbMetric: 18.5314

Epoch 196: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.7840 - MinusLogProbMetric: 17.7840 - val_loss: 18.5314 - val_MinusLogProbMetric: 18.5314 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 197/1000
2023-09-23 18:44:43.870 
Epoch 197/1000 
	 loss: 17.7260, MinusLogProbMetric: 17.7260, val_loss: 19.2294, val_MinusLogProbMetric: 19.2294

Epoch 197: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.7260 - MinusLogProbMetric: 17.7260 - val_loss: 19.2294 - val_MinusLogProbMetric: 19.2294 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 198/1000
2023-09-23 18:45:46.501 
Epoch 198/1000 
	 loss: 17.7092, MinusLogProbMetric: 17.7092, val_loss: 18.2462, val_MinusLogProbMetric: 18.2462

Epoch 198: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.7092 - MinusLogProbMetric: 17.7092 - val_loss: 18.2462 - val_MinusLogProbMetric: 18.2462 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 199/1000
2023-09-23 18:46:49.559 
Epoch 199/1000 
	 loss: 17.6533, MinusLogProbMetric: 17.6533, val_loss: 17.8430, val_MinusLogProbMetric: 17.8430

Epoch 199: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.6533 - MinusLogProbMetric: 17.6533 - val_loss: 17.8430 - val_MinusLogProbMetric: 17.8430 - lr: 3.3333e-04 - 63s/epoch - 322ms/step
Epoch 200/1000
2023-09-23 18:47:52.207 
Epoch 200/1000 
	 loss: 17.7150, MinusLogProbMetric: 17.7150, val_loss: 18.0336, val_MinusLogProbMetric: 18.0336

Epoch 200: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.7150 - MinusLogProbMetric: 17.7150 - val_loss: 18.0336 - val_MinusLogProbMetric: 18.0336 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 201/1000
2023-09-23 18:48:54.774 
Epoch 201/1000 
	 loss: 17.6965, MinusLogProbMetric: 17.6965, val_loss: 19.2064, val_MinusLogProbMetric: 19.2064

Epoch 201: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.6965 - MinusLogProbMetric: 17.6965 - val_loss: 19.2064 - val_MinusLogProbMetric: 19.2064 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 202/1000
2023-09-23 18:49:57.400 
Epoch 202/1000 
	 loss: 17.7188, MinusLogProbMetric: 17.7188, val_loss: 17.7803, val_MinusLogProbMetric: 17.7803

Epoch 202: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.7188 - MinusLogProbMetric: 17.7188 - val_loss: 17.7803 - val_MinusLogProbMetric: 17.7803 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 203/1000
2023-09-23 18:50:59.789 
Epoch 203/1000 
	 loss: 17.6610, MinusLogProbMetric: 17.6610, val_loss: 18.6171, val_MinusLogProbMetric: 18.6171

Epoch 203: val_loss did not improve from 17.71254
196/196 - 62s - loss: 17.6610 - MinusLogProbMetric: 17.6610 - val_loss: 18.6171 - val_MinusLogProbMetric: 18.6171 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 204/1000
2023-09-23 18:52:02.175 
Epoch 204/1000 
	 loss: 17.6431, MinusLogProbMetric: 17.6431, val_loss: 18.0187, val_MinusLogProbMetric: 18.0187

Epoch 204: val_loss did not improve from 17.71254
196/196 - 62s - loss: 17.6431 - MinusLogProbMetric: 17.6431 - val_loss: 18.0187 - val_MinusLogProbMetric: 18.0187 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 205/1000
2023-09-23 18:53:04.558 
Epoch 205/1000 
	 loss: 17.7253, MinusLogProbMetric: 17.7253, val_loss: 18.5077, val_MinusLogProbMetric: 18.5077

Epoch 205: val_loss did not improve from 17.71254
196/196 - 62s - loss: 17.7253 - MinusLogProbMetric: 17.7253 - val_loss: 18.5077 - val_MinusLogProbMetric: 18.5077 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 206/1000
2023-09-23 18:54:07.108 
Epoch 206/1000 
	 loss: 17.6190, MinusLogProbMetric: 17.6190, val_loss: 18.5027, val_MinusLogProbMetric: 18.5027

Epoch 206: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.6190 - MinusLogProbMetric: 17.6190 - val_loss: 18.5027 - val_MinusLogProbMetric: 18.5027 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 207/1000
2023-09-23 18:55:10.120 
Epoch 207/1000 
	 loss: 17.7093, MinusLogProbMetric: 17.7093, val_loss: 18.5907, val_MinusLogProbMetric: 18.5907

Epoch 207: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.7093 - MinusLogProbMetric: 17.7093 - val_loss: 18.5907 - val_MinusLogProbMetric: 18.5907 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 208/1000
2023-09-23 18:56:12.523 
Epoch 208/1000 
	 loss: 17.7081, MinusLogProbMetric: 17.7081, val_loss: 17.9678, val_MinusLogProbMetric: 17.9678

Epoch 208: val_loss did not improve from 17.71254
196/196 - 62s - loss: 17.7081 - MinusLogProbMetric: 17.7081 - val_loss: 17.9678 - val_MinusLogProbMetric: 17.9678 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 209/1000
2023-09-23 18:57:14.619 
Epoch 209/1000 
	 loss: 17.7707, MinusLogProbMetric: 17.7707, val_loss: 18.3345, val_MinusLogProbMetric: 18.3345

Epoch 209: val_loss did not improve from 17.71254
196/196 - 62s - loss: 17.7707 - MinusLogProbMetric: 17.7707 - val_loss: 18.3345 - val_MinusLogProbMetric: 18.3345 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 210/1000
2023-09-23 18:58:16.626 
Epoch 210/1000 
	 loss: 17.6943, MinusLogProbMetric: 17.6943, val_loss: 18.0633, val_MinusLogProbMetric: 18.0633

Epoch 210: val_loss did not improve from 17.71254
196/196 - 62s - loss: 17.6943 - MinusLogProbMetric: 17.6943 - val_loss: 18.0633 - val_MinusLogProbMetric: 18.0633 - lr: 3.3333e-04 - 62s/epoch - 316ms/step
Epoch 211/1000
2023-09-23 18:59:19.030 
Epoch 211/1000 
	 loss: 17.5679, MinusLogProbMetric: 17.5679, val_loss: 17.8336, val_MinusLogProbMetric: 17.8336

Epoch 211: val_loss did not improve from 17.71254
196/196 - 62s - loss: 17.5679 - MinusLogProbMetric: 17.5679 - val_loss: 17.8336 - val_MinusLogProbMetric: 17.8336 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 212/1000
2023-09-23 19:00:21.408 
Epoch 212/1000 
	 loss: 17.5624, MinusLogProbMetric: 17.5624, val_loss: 18.4359, val_MinusLogProbMetric: 18.4359

Epoch 212: val_loss did not improve from 17.71254
196/196 - 62s - loss: 17.5624 - MinusLogProbMetric: 17.5624 - val_loss: 18.4359 - val_MinusLogProbMetric: 18.4359 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 213/1000
2023-09-23 19:01:24.167 
Epoch 213/1000 
	 loss: 17.6522, MinusLogProbMetric: 17.6522, val_loss: 18.0953, val_MinusLogProbMetric: 18.0953

Epoch 213: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.6522 - MinusLogProbMetric: 17.6522 - val_loss: 18.0953 - val_MinusLogProbMetric: 18.0953 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 214/1000
2023-09-23 19:02:27.080 
Epoch 214/1000 
	 loss: 17.6509, MinusLogProbMetric: 17.6509, val_loss: 17.8002, val_MinusLogProbMetric: 17.8002

Epoch 214: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.6509 - MinusLogProbMetric: 17.6509 - val_loss: 17.8002 - val_MinusLogProbMetric: 17.8002 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 215/1000
2023-09-23 19:03:28.828 
Epoch 215/1000 
	 loss: 17.5859, MinusLogProbMetric: 17.5859, val_loss: 17.9343, val_MinusLogProbMetric: 17.9343

Epoch 215: val_loss did not improve from 17.71254
196/196 - 62s - loss: 17.5859 - MinusLogProbMetric: 17.5859 - val_loss: 17.9343 - val_MinusLogProbMetric: 17.9343 - lr: 3.3333e-04 - 62s/epoch - 315ms/step
Epoch 216/1000
2023-09-23 19:04:31.241 
Epoch 216/1000 
	 loss: 17.7675, MinusLogProbMetric: 17.7675, val_loss: 17.8505, val_MinusLogProbMetric: 17.8505

Epoch 216: val_loss did not improve from 17.71254
196/196 - 62s - loss: 17.7675 - MinusLogProbMetric: 17.7675 - val_loss: 17.8505 - val_MinusLogProbMetric: 17.8505 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 217/1000
2023-09-23 19:05:35.133 
Epoch 217/1000 
	 loss: 17.7172, MinusLogProbMetric: 17.7172, val_loss: 18.2066, val_MinusLogProbMetric: 18.2066

Epoch 217: val_loss did not improve from 17.71254
196/196 - 64s - loss: 17.7172 - MinusLogProbMetric: 17.7172 - val_loss: 18.2066 - val_MinusLogProbMetric: 18.2066 - lr: 3.3333e-04 - 64s/epoch - 326ms/step
Epoch 218/1000
2023-09-23 19:06:37.706 
Epoch 218/1000 
	 loss: 17.5045, MinusLogProbMetric: 17.5045, val_loss: 18.0869, val_MinusLogProbMetric: 18.0869

Epoch 218: val_loss did not improve from 17.71254
196/196 - 63s - loss: 17.5045 - MinusLogProbMetric: 17.5045 - val_loss: 18.0869 - val_MinusLogProbMetric: 18.0869 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 219/1000
2023-09-23 19:07:39.540 
Epoch 219/1000 
	 loss: 17.6015, MinusLogProbMetric: 17.6015, val_loss: 17.9706, val_MinusLogProbMetric: 17.9706

Epoch 219: val_loss did not improve from 17.71254
196/196 - 62s - loss: 17.6015 - MinusLogProbMetric: 17.6015 - val_loss: 17.9706 - val_MinusLogProbMetric: 17.9706 - lr: 3.3333e-04 - 62s/epoch - 315ms/step
Epoch 220/1000
2023-09-23 19:08:41.467 
Epoch 220/1000 
	 loss: 17.6756, MinusLogProbMetric: 17.6756, val_loss: 18.3376, val_MinusLogProbMetric: 18.3376

Epoch 220: val_loss did not improve from 17.71254
196/196 - 62s - loss: 17.6756 - MinusLogProbMetric: 17.6756 - val_loss: 18.3376 - val_MinusLogProbMetric: 18.3376 - lr: 3.3333e-04 - 62s/epoch - 316ms/step
Epoch 221/1000
2023-09-23 19:09:43.437 
Epoch 221/1000 
	 loss: 17.6450, MinusLogProbMetric: 17.6450, val_loss: 17.9156, val_MinusLogProbMetric: 17.9156

Epoch 221: val_loss did not improve from 17.71254
196/196 - 62s - loss: 17.6450 - MinusLogProbMetric: 17.6450 - val_loss: 17.9156 - val_MinusLogProbMetric: 17.9156 - lr: 3.3333e-04 - 62s/epoch - 316ms/step
Epoch 222/1000
2023-09-23 19:10:45.633 
Epoch 222/1000 
	 loss: 17.6145, MinusLogProbMetric: 17.6145, val_loss: 18.3161, val_MinusLogProbMetric: 18.3161

Epoch 222: val_loss did not improve from 17.71254
196/196 - 62s - loss: 17.6145 - MinusLogProbMetric: 17.6145 - val_loss: 18.3161 - val_MinusLogProbMetric: 18.3161 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 223/1000
2023-09-23 19:11:47.773 
Epoch 223/1000 
	 loss: 17.6028, MinusLogProbMetric: 17.6028, val_loss: 17.8038, val_MinusLogProbMetric: 17.8038

Epoch 223: val_loss did not improve from 17.71254
196/196 - 62s - loss: 17.6028 - MinusLogProbMetric: 17.6028 - val_loss: 17.8038 - val_MinusLogProbMetric: 17.8038 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 224/1000
2023-09-23 19:12:50.273 
Epoch 224/1000 
	 loss: 17.5254, MinusLogProbMetric: 17.5254, val_loss: 17.5624, val_MinusLogProbMetric: 17.5624

Epoch 224: val_loss improved from 17.71254 to 17.56238, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 64s - loss: 17.5254 - MinusLogProbMetric: 17.5254 - val_loss: 17.5624 - val_MinusLogProbMetric: 17.5624 - lr: 3.3333e-04 - 64s/epoch - 324ms/step
Epoch 225/1000
2023-09-23 19:13:54.207 
Epoch 225/1000 
	 loss: 17.5915, MinusLogProbMetric: 17.5915, val_loss: 17.8096, val_MinusLogProbMetric: 17.8096

Epoch 225: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.5915 - MinusLogProbMetric: 17.5915 - val_loss: 17.8096 - val_MinusLogProbMetric: 17.8096 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 226/1000
2023-09-23 19:14:56.198 
Epoch 226/1000 
	 loss: 17.5999, MinusLogProbMetric: 17.5999, val_loss: 17.9647, val_MinusLogProbMetric: 17.9647

Epoch 226: val_loss did not improve from 17.56238
196/196 - 62s - loss: 17.5999 - MinusLogProbMetric: 17.5999 - val_loss: 17.9647 - val_MinusLogProbMetric: 17.9647 - lr: 3.3333e-04 - 62s/epoch - 316ms/step
Epoch 227/1000
2023-09-23 19:15:58.235 
Epoch 227/1000 
	 loss: 17.5298, MinusLogProbMetric: 17.5298, val_loss: 17.8662, val_MinusLogProbMetric: 17.8662

Epoch 227: val_loss did not improve from 17.56238
196/196 - 62s - loss: 17.5298 - MinusLogProbMetric: 17.5298 - val_loss: 17.8662 - val_MinusLogProbMetric: 17.8662 - lr: 3.3333e-04 - 62s/epoch - 316ms/step
Epoch 228/1000
2023-09-23 19:17:00.409 
Epoch 228/1000 
	 loss: 17.6256, MinusLogProbMetric: 17.6256, val_loss: 18.0965, val_MinusLogProbMetric: 18.0965

Epoch 228: val_loss did not improve from 17.56238
196/196 - 62s - loss: 17.6256 - MinusLogProbMetric: 17.6256 - val_loss: 18.0965 - val_MinusLogProbMetric: 18.0965 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 229/1000
2023-09-23 19:18:02.674 
Epoch 229/1000 
	 loss: 17.5374, MinusLogProbMetric: 17.5374, val_loss: 18.0989, val_MinusLogProbMetric: 18.0989

Epoch 229: val_loss did not improve from 17.56238
196/196 - 62s - loss: 17.5374 - MinusLogProbMetric: 17.5374 - val_loss: 18.0989 - val_MinusLogProbMetric: 18.0989 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 230/1000
2023-09-23 19:19:05.331 
Epoch 230/1000 
	 loss: 17.5768, MinusLogProbMetric: 17.5768, val_loss: 17.9052, val_MinusLogProbMetric: 17.9052

Epoch 230: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.5768 - MinusLogProbMetric: 17.5768 - val_loss: 17.9052 - val_MinusLogProbMetric: 17.9052 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 231/1000
2023-09-23 19:20:07.745 
Epoch 231/1000 
	 loss: 17.6169, MinusLogProbMetric: 17.6169, val_loss: 18.1242, val_MinusLogProbMetric: 18.1242

Epoch 231: val_loss did not improve from 17.56238
196/196 - 62s - loss: 17.6169 - MinusLogProbMetric: 17.6169 - val_loss: 18.1242 - val_MinusLogProbMetric: 18.1242 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 232/1000
2023-09-23 19:21:10.363 
Epoch 232/1000 
	 loss: 17.5293, MinusLogProbMetric: 17.5293, val_loss: 17.7819, val_MinusLogProbMetric: 17.7819

Epoch 232: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.5293 - MinusLogProbMetric: 17.5293 - val_loss: 17.7819 - val_MinusLogProbMetric: 17.7819 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 233/1000
2023-09-23 19:22:12.409 
Epoch 233/1000 
	 loss: 17.4344, MinusLogProbMetric: 17.4344, val_loss: 17.8052, val_MinusLogProbMetric: 17.8052

Epoch 233: val_loss did not improve from 17.56238
196/196 - 62s - loss: 17.4344 - MinusLogProbMetric: 17.4344 - val_loss: 17.8052 - val_MinusLogProbMetric: 17.8052 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 234/1000
2023-09-23 19:23:14.479 
Epoch 234/1000 
	 loss: 17.5756, MinusLogProbMetric: 17.5756, val_loss: 17.8179, val_MinusLogProbMetric: 17.8179

Epoch 234: val_loss did not improve from 17.56238
196/196 - 62s - loss: 17.5756 - MinusLogProbMetric: 17.5756 - val_loss: 17.8179 - val_MinusLogProbMetric: 17.8179 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 235/1000
2023-09-23 19:24:17.035 
Epoch 235/1000 
	 loss: 17.6489, MinusLogProbMetric: 17.6489, val_loss: 17.7224, val_MinusLogProbMetric: 17.7224

Epoch 235: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.6489 - MinusLogProbMetric: 17.6489 - val_loss: 17.7224 - val_MinusLogProbMetric: 17.7224 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 236/1000
2023-09-23 19:25:19.806 
Epoch 236/1000 
	 loss: 17.5266, MinusLogProbMetric: 17.5266, val_loss: 17.6198, val_MinusLogProbMetric: 17.6198

Epoch 236: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.5266 - MinusLogProbMetric: 17.5266 - val_loss: 17.6198 - val_MinusLogProbMetric: 17.6198 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 237/1000
2023-09-23 19:26:22.604 
Epoch 237/1000 
	 loss: 17.5558, MinusLogProbMetric: 17.5558, val_loss: 17.6719, val_MinusLogProbMetric: 17.6719

Epoch 237: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.5558 - MinusLogProbMetric: 17.5558 - val_loss: 17.6719 - val_MinusLogProbMetric: 17.6719 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 238/1000
2023-09-23 19:27:26.193 
Epoch 238/1000 
	 loss: 17.5433, MinusLogProbMetric: 17.5433, val_loss: 18.1140, val_MinusLogProbMetric: 18.1140

Epoch 238: val_loss did not improve from 17.56238
196/196 - 64s - loss: 17.5433 - MinusLogProbMetric: 17.5433 - val_loss: 18.1140 - val_MinusLogProbMetric: 18.1140 - lr: 3.3333e-04 - 64s/epoch - 324ms/step
Epoch 239/1000
2023-09-23 19:28:29.611 
Epoch 239/1000 
	 loss: 17.5116, MinusLogProbMetric: 17.5116, val_loss: 17.8818, val_MinusLogProbMetric: 17.8818

Epoch 239: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.5116 - MinusLogProbMetric: 17.5116 - val_loss: 17.8818 - val_MinusLogProbMetric: 17.8818 - lr: 3.3333e-04 - 63s/epoch - 324ms/step
Epoch 240/1000
2023-09-23 19:29:32.240 
Epoch 240/1000 
	 loss: 17.5800, MinusLogProbMetric: 17.5800, val_loss: 17.7873, val_MinusLogProbMetric: 17.7873

Epoch 240: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.5800 - MinusLogProbMetric: 17.5800 - val_loss: 17.7873 - val_MinusLogProbMetric: 17.7873 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 241/1000
2023-09-23 19:30:34.832 
Epoch 241/1000 
	 loss: 17.5050, MinusLogProbMetric: 17.5050, val_loss: 17.6425, val_MinusLogProbMetric: 17.6425

Epoch 241: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.5050 - MinusLogProbMetric: 17.5050 - val_loss: 17.6425 - val_MinusLogProbMetric: 17.6425 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 242/1000
2023-09-23 19:31:37.564 
Epoch 242/1000 
	 loss: 17.5273, MinusLogProbMetric: 17.5273, val_loss: 17.8830, val_MinusLogProbMetric: 17.8830

Epoch 242: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.5273 - MinusLogProbMetric: 17.5273 - val_loss: 17.8830 - val_MinusLogProbMetric: 17.8830 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 243/1000
2023-09-23 19:32:41.210 
Epoch 243/1000 
	 loss: 17.4514, MinusLogProbMetric: 17.4514, val_loss: 17.8589, val_MinusLogProbMetric: 17.8589

Epoch 243: val_loss did not improve from 17.56238
196/196 - 64s - loss: 17.4514 - MinusLogProbMetric: 17.4514 - val_loss: 17.8589 - val_MinusLogProbMetric: 17.8589 - lr: 3.3333e-04 - 64s/epoch - 325ms/step
Epoch 244/1000
2023-09-23 19:33:43.809 
Epoch 244/1000 
	 loss: 17.4422, MinusLogProbMetric: 17.4422, val_loss: 18.1333, val_MinusLogProbMetric: 18.1333

Epoch 244: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.4422 - MinusLogProbMetric: 17.4422 - val_loss: 18.1333 - val_MinusLogProbMetric: 18.1333 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 245/1000
2023-09-23 19:34:46.267 
Epoch 245/1000 
	 loss: 17.5766, MinusLogProbMetric: 17.5766, val_loss: 18.0854, val_MinusLogProbMetric: 18.0854

Epoch 245: val_loss did not improve from 17.56238
196/196 - 62s - loss: 17.5766 - MinusLogProbMetric: 17.5766 - val_loss: 18.0854 - val_MinusLogProbMetric: 18.0854 - lr: 3.3333e-04 - 62s/epoch - 319ms/step
Epoch 246/1000
2023-09-23 19:35:49.332 
Epoch 246/1000 
	 loss: 17.4517, MinusLogProbMetric: 17.4517, val_loss: 18.2987, val_MinusLogProbMetric: 18.2987

Epoch 246: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.4517 - MinusLogProbMetric: 17.4517 - val_loss: 18.2987 - val_MinusLogProbMetric: 18.2987 - lr: 3.3333e-04 - 63s/epoch - 322ms/step
Epoch 247/1000
2023-09-23 19:36:51.453 
Epoch 247/1000 
	 loss: 17.5929, MinusLogProbMetric: 17.5929, val_loss: 17.8247, val_MinusLogProbMetric: 17.8247

Epoch 247: val_loss did not improve from 17.56238
196/196 - 62s - loss: 17.5929 - MinusLogProbMetric: 17.5929 - val_loss: 17.8247 - val_MinusLogProbMetric: 17.8247 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 248/1000
2023-09-23 19:37:54.061 
Epoch 248/1000 
	 loss: 17.4492, MinusLogProbMetric: 17.4492, val_loss: 17.7097, val_MinusLogProbMetric: 17.7097

Epoch 248: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.4492 - MinusLogProbMetric: 17.4492 - val_loss: 17.7097 - val_MinusLogProbMetric: 17.7097 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 249/1000
2023-09-23 19:38:56.530 
Epoch 249/1000 
	 loss: 17.4135, MinusLogProbMetric: 17.4135, val_loss: 18.1225, val_MinusLogProbMetric: 18.1225

Epoch 249: val_loss did not improve from 17.56238
196/196 - 62s - loss: 17.4135 - MinusLogProbMetric: 17.4135 - val_loss: 18.1225 - val_MinusLogProbMetric: 18.1225 - lr: 3.3333e-04 - 62s/epoch - 319ms/step
Epoch 250/1000
2023-09-23 19:39:58.973 
Epoch 250/1000 
	 loss: 17.4985, MinusLogProbMetric: 17.4985, val_loss: 18.1892, val_MinusLogProbMetric: 18.1892

Epoch 250: val_loss did not improve from 17.56238
196/196 - 62s - loss: 17.4985 - MinusLogProbMetric: 17.4985 - val_loss: 18.1892 - val_MinusLogProbMetric: 18.1892 - lr: 3.3333e-04 - 62s/epoch - 319ms/step
Epoch 251/1000
2023-09-23 19:41:01.556 
Epoch 251/1000 
	 loss: 17.5031, MinusLogProbMetric: 17.5031, val_loss: 17.7859, val_MinusLogProbMetric: 17.7859

Epoch 251: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.5031 - MinusLogProbMetric: 17.5031 - val_loss: 17.7859 - val_MinusLogProbMetric: 17.7859 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 252/1000
2023-09-23 19:42:04.237 
Epoch 252/1000 
	 loss: 17.4584, MinusLogProbMetric: 17.4584, val_loss: 17.6286, val_MinusLogProbMetric: 17.6286

Epoch 252: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.4584 - MinusLogProbMetric: 17.4584 - val_loss: 17.6286 - val_MinusLogProbMetric: 17.6286 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 253/1000
2023-09-23 19:43:07.156 
Epoch 253/1000 
	 loss: 17.5991, MinusLogProbMetric: 17.5991, val_loss: 17.8792, val_MinusLogProbMetric: 17.8792

Epoch 253: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.5991 - MinusLogProbMetric: 17.5991 - val_loss: 17.8792 - val_MinusLogProbMetric: 17.8792 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 254/1000
2023-09-23 19:44:10.094 
Epoch 254/1000 
	 loss: 17.4332, MinusLogProbMetric: 17.4332, val_loss: 17.6357, val_MinusLogProbMetric: 17.6357

Epoch 254: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.4332 - MinusLogProbMetric: 17.4332 - val_loss: 17.6357 - val_MinusLogProbMetric: 17.6357 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 255/1000
2023-09-23 19:45:12.494 
Epoch 255/1000 
	 loss: 17.4703, MinusLogProbMetric: 17.4703, val_loss: 17.9001, val_MinusLogProbMetric: 17.9001

Epoch 255: val_loss did not improve from 17.56238
196/196 - 62s - loss: 17.4703 - MinusLogProbMetric: 17.4703 - val_loss: 17.9001 - val_MinusLogProbMetric: 17.9001 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 256/1000
2023-09-23 19:46:15.040 
Epoch 256/1000 
	 loss: 17.4421, MinusLogProbMetric: 17.4421, val_loss: 18.3030, val_MinusLogProbMetric: 18.3030

Epoch 256: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.4421 - MinusLogProbMetric: 17.4421 - val_loss: 18.3030 - val_MinusLogProbMetric: 18.3030 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 257/1000
2023-09-23 19:47:18.351 
Epoch 257/1000 
	 loss: 17.4306, MinusLogProbMetric: 17.4306, val_loss: 18.6003, val_MinusLogProbMetric: 18.6003

Epoch 257: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.4306 - MinusLogProbMetric: 17.4306 - val_loss: 18.6003 - val_MinusLogProbMetric: 18.6003 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 258/1000
2023-09-23 19:48:22.056 
Epoch 258/1000 
	 loss: 17.5312, MinusLogProbMetric: 17.5312, val_loss: 19.1111, val_MinusLogProbMetric: 19.1111

Epoch 258: val_loss did not improve from 17.56238
196/196 - 64s - loss: 17.5312 - MinusLogProbMetric: 17.5312 - val_loss: 19.1111 - val_MinusLogProbMetric: 19.1111 - lr: 3.3333e-04 - 64s/epoch - 325ms/step
Epoch 259/1000
2023-09-23 19:49:25.341 
Epoch 259/1000 
	 loss: 17.4214, MinusLogProbMetric: 17.4214, val_loss: 17.7891, val_MinusLogProbMetric: 17.7891

Epoch 259: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.4214 - MinusLogProbMetric: 17.4214 - val_loss: 17.7891 - val_MinusLogProbMetric: 17.7891 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 260/1000
2023-09-23 19:50:28.963 
Epoch 260/1000 
	 loss: 17.5347, MinusLogProbMetric: 17.5347, val_loss: 17.8834, val_MinusLogProbMetric: 17.8834

Epoch 260: val_loss did not improve from 17.56238
196/196 - 64s - loss: 17.5347 - MinusLogProbMetric: 17.5347 - val_loss: 17.8834 - val_MinusLogProbMetric: 17.8834 - lr: 3.3333e-04 - 64s/epoch - 325ms/step
Epoch 261/1000
2023-09-23 19:51:32.049 
Epoch 261/1000 
	 loss: 17.4649, MinusLogProbMetric: 17.4649, val_loss: 17.7789, val_MinusLogProbMetric: 17.7789

Epoch 261: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.4649 - MinusLogProbMetric: 17.4649 - val_loss: 17.7789 - val_MinusLogProbMetric: 17.7789 - lr: 3.3333e-04 - 63s/epoch - 322ms/step
Epoch 262/1000
2023-09-23 19:52:35.004 
Epoch 262/1000 
	 loss: 17.3926, MinusLogProbMetric: 17.3926, val_loss: 17.5975, val_MinusLogProbMetric: 17.5975

Epoch 262: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.3926 - MinusLogProbMetric: 17.3926 - val_loss: 17.5975 - val_MinusLogProbMetric: 17.5975 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 263/1000
2023-09-23 19:53:38.058 
Epoch 263/1000 
	 loss: 17.4347, MinusLogProbMetric: 17.4347, val_loss: 17.9171, val_MinusLogProbMetric: 17.9171

Epoch 263: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.4347 - MinusLogProbMetric: 17.4347 - val_loss: 17.9171 - val_MinusLogProbMetric: 17.9171 - lr: 3.3333e-04 - 63s/epoch - 322ms/step
Epoch 264/1000
2023-09-23 19:54:41.048 
Epoch 264/1000 
	 loss: 17.4358, MinusLogProbMetric: 17.4358, val_loss: 17.8737, val_MinusLogProbMetric: 17.8737

Epoch 264: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.4358 - MinusLogProbMetric: 17.4358 - val_loss: 17.8737 - val_MinusLogProbMetric: 17.8737 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 265/1000
2023-09-23 19:55:44.424 
Epoch 265/1000 
	 loss: 17.4605, MinusLogProbMetric: 17.4605, val_loss: 18.3743, val_MinusLogProbMetric: 18.3743

Epoch 265: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.4605 - MinusLogProbMetric: 17.4605 - val_loss: 18.3743 - val_MinusLogProbMetric: 18.3743 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 266/1000
2023-09-23 19:56:47.868 
Epoch 266/1000 
	 loss: 17.4235, MinusLogProbMetric: 17.4235, val_loss: 18.3892, val_MinusLogProbMetric: 18.3892

Epoch 266: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.4235 - MinusLogProbMetric: 17.4235 - val_loss: 18.3892 - val_MinusLogProbMetric: 18.3892 - lr: 3.3333e-04 - 63s/epoch - 324ms/step
Epoch 267/1000
2023-09-23 19:57:51.204 
Epoch 267/1000 
	 loss: 17.4720, MinusLogProbMetric: 17.4720, val_loss: 19.0131, val_MinusLogProbMetric: 19.0131

Epoch 267: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.4720 - MinusLogProbMetric: 17.4720 - val_loss: 19.0131 - val_MinusLogProbMetric: 19.0131 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 268/1000
2023-09-23 19:58:54.666 
Epoch 268/1000 
	 loss: 17.3309, MinusLogProbMetric: 17.3309, val_loss: 17.9486, val_MinusLogProbMetric: 17.9486

Epoch 268: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.3309 - MinusLogProbMetric: 17.3309 - val_loss: 17.9486 - val_MinusLogProbMetric: 17.9486 - lr: 3.3333e-04 - 63s/epoch - 324ms/step
Epoch 269/1000
2023-09-23 19:59:57.125 
Epoch 269/1000 
	 loss: 17.4113, MinusLogProbMetric: 17.4113, val_loss: 17.9105, val_MinusLogProbMetric: 17.9105

Epoch 269: val_loss did not improve from 17.56238
196/196 - 62s - loss: 17.4113 - MinusLogProbMetric: 17.4113 - val_loss: 17.9105 - val_MinusLogProbMetric: 17.9105 - lr: 3.3333e-04 - 62s/epoch - 319ms/step
Epoch 270/1000
2023-09-23 20:00:59.331 
Epoch 270/1000 
	 loss: 17.4121, MinusLogProbMetric: 17.4121, val_loss: 18.9170, val_MinusLogProbMetric: 18.9170

Epoch 270: val_loss did not improve from 17.56238
196/196 - 62s - loss: 17.4121 - MinusLogProbMetric: 17.4121 - val_loss: 18.9170 - val_MinusLogProbMetric: 18.9170 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 271/1000
2023-09-23 20:02:01.988 
Epoch 271/1000 
	 loss: 17.4683, MinusLogProbMetric: 17.4683, val_loss: 19.5558, val_MinusLogProbMetric: 19.5558

Epoch 271: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.4683 - MinusLogProbMetric: 17.4683 - val_loss: 19.5558 - val_MinusLogProbMetric: 19.5558 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 272/1000
2023-09-23 20:03:04.630 
Epoch 272/1000 
	 loss: 17.4643, MinusLogProbMetric: 17.4643, val_loss: 17.9517, val_MinusLogProbMetric: 17.9517

Epoch 272: val_loss did not improve from 17.56238
196/196 - 63s - loss: 17.4643 - MinusLogProbMetric: 17.4643 - val_loss: 17.9517 - val_MinusLogProbMetric: 17.9517 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 273/1000
2023-09-23 20:04:07.667 
Epoch 273/1000 
	 loss: 17.3158, MinusLogProbMetric: 17.3158, val_loss: 17.5379, val_MinusLogProbMetric: 17.5379

Epoch 273: val_loss improved from 17.56238 to 17.53786, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 64s - loss: 17.3158 - MinusLogProbMetric: 17.3158 - val_loss: 17.5379 - val_MinusLogProbMetric: 17.5379 - lr: 3.3333e-04 - 64s/epoch - 327ms/step
Epoch 274/1000
2023-09-23 20:05:11.756 
Epoch 274/1000 
	 loss: 17.3725, MinusLogProbMetric: 17.3725, val_loss: 17.7215, val_MinusLogProbMetric: 17.7215

Epoch 274: val_loss did not improve from 17.53786
196/196 - 63s - loss: 17.3725 - MinusLogProbMetric: 17.3725 - val_loss: 17.7215 - val_MinusLogProbMetric: 17.7215 - lr: 3.3333e-04 - 63s/epoch - 322ms/step
Epoch 275/1000
2023-09-23 20:06:14.314 
Epoch 275/1000 
	 loss: 17.4172, MinusLogProbMetric: 17.4172, val_loss: 17.5221, val_MinusLogProbMetric: 17.5221

Epoch 275: val_loss improved from 17.53786 to 17.52215, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 63s - loss: 17.4172 - MinusLogProbMetric: 17.4172 - val_loss: 17.5221 - val_MinusLogProbMetric: 17.5221 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 276/1000
2023-09-23 20:07:17.504 
Epoch 276/1000 
	 loss: 17.2946, MinusLogProbMetric: 17.2946, val_loss: 17.4931, val_MinusLogProbMetric: 17.4931

Epoch 276: val_loss improved from 17.52215 to 17.49313, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 63s - loss: 17.2946 - MinusLogProbMetric: 17.2946 - val_loss: 17.4931 - val_MinusLogProbMetric: 17.4931 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 277/1000
2023-09-23 20:08:20.784 
Epoch 277/1000 
	 loss: 17.3611, MinusLogProbMetric: 17.3611, val_loss: 17.6162, val_MinusLogProbMetric: 17.6162

Epoch 277: val_loss did not improve from 17.49313
196/196 - 62s - loss: 17.3611 - MinusLogProbMetric: 17.3611 - val_loss: 17.6162 - val_MinusLogProbMetric: 17.6162 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 278/1000
2023-09-23 20:09:23.399 
Epoch 278/1000 
	 loss: 17.3463, MinusLogProbMetric: 17.3463, val_loss: 18.1735, val_MinusLogProbMetric: 18.1735

Epoch 278: val_loss did not improve from 17.49313
196/196 - 63s - loss: 17.3463 - MinusLogProbMetric: 17.3463 - val_loss: 18.1735 - val_MinusLogProbMetric: 18.1735 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 279/1000
2023-09-23 20:10:26.077 
Epoch 279/1000 
	 loss: 17.3967, MinusLogProbMetric: 17.3967, val_loss: 18.0764, val_MinusLogProbMetric: 18.0764

Epoch 279: val_loss did not improve from 17.49313
196/196 - 63s - loss: 17.3967 - MinusLogProbMetric: 17.3967 - val_loss: 18.0764 - val_MinusLogProbMetric: 18.0764 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 280/1000
2023-09-23 20:11:28.822 
Epoch 280/1000 
	 loss: 17.3118, MinusLogProbMetric: 17.3118, val_loss: 17.8662, val_MinusLogProbMetric: 17.8662

Epoch 280: val_loss did not improve from 17.49313
196/196 - 63s - loss: 17.3118 - MinusLogProbMetric: 17.3118 - val_loss: 17.8662 - val_MinusLogProbMetric: 17.8662 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 281/1000
2023-09-23 20:12:31.191 
Epoch 281/1000 
	 loss: 17.3675, MinusLogProbMetric: 17.3675, val_loss: 18.2437, val_MinusLogProbMetric: 18.2437

Epoch 281: val_loss did not improve from 17.49313
196/196 - 62s - loss: 17.3675 - MinusLogProbMetric: 17.3675 - val_loss: 18.2437 - val_MinusLogProbMetric: 18.2437 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 282/1000
2023-09-23 20:13:33.703 
Epoch 282/1000 
	 loss: 17.3985, MinusLogProbMetric: 17.3985, val_loss: 17.5109, val_MinusLogProbMetric: 17.5109

Epoch 282: val_loss did not improve from 17.49313
196/196 - 63s - loss: 17.3985 - MinusLogProbMetric: 17.3985 - val_loss: 17.5109 - val_MinusLogProbMetric: 17.5109 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 283/1000
2023-09-23 20:14:36.357 
Epoch 283/1000 
	 loss: 17.3207, MinusLogProbMetric: 17.3207, val_loss: 17.5978, val_MinusLogProbMetric: 17.5978

Epoch 283: val_loss did not improve from 17.49313
196/196 - 63s - loss: 17.3207 - MinusLogProbMetric: 17.3207 - val_loss: 17.5978 - val_MinusLogProbMetric: 17.5978 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 284/1000
2023-09-23 20:15:39.535 
Epoch 284/1000 
	 loss: 17.3785, MinusLogProbMetric: 17.3785, val_loss: 17.7929, val_MinusLogProbMetric: 17.7929

Epoch 284: val_loss did not improve from 17.49313
196/196 - 63s - loss: 17.3785 - MinusLogProbMetric: 17.3785 - val_loss: 17.7929 - val_MinusLogProbMetric: 17.7929 - lr: 3.3333e-04 - 63s/epoch - 322ms/step
Epoch 285/1000
2023-09-23 20:16:42.920 
Epoch 285/1000 
	 loss: 17.3371, MinusLogProbMetric: 17.3371, val_loss: 17.9709, val_MinusLogProbMetric: 17.9709

Epoch 285: val_loss did not improve from 17.49313
196/196 - 63s - loss: 17.3371 - MinusLogProbMetric: 17.3371 - val_loss: 17.9709 - val_MinusLogProbMetric: 17.9709 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 286/1000
2023-09-23 20:17:46.383 
Epoch 286/1000 
	 loss: 17.2978, MinusLogProbMetric: 17.2978, val_loss: 17.5600, val_MinusLogProbMetric: 17.5600

Epoch 286: val_loss did not improve from 17.49313
196/196 - 63s - loss: 17.2978 - MinusLogProbMetric: 17.2978 - val_loss: 17.5600 - val_MinusLogProbMetric: 17.5600 - lr: 3.3333e-04 - 63s/epoch - 324ms/step
Epoch 287/1000
2023-09-23 20:18:49.725 
Epoch 287/1000 
	 loss: 17.3782, MinusLogProbMetric: 17.3782, val_loss: 18.5413, val_MinusLogProbMetric: 18.5413

Epoch 287: val_loss did not improve from 17.49313
196/196 - 63s - loss: 17.3782 - MinusLogProbMetric: 17.3782 - val_loss: 18.5413 - val_MinusLogProbMetric: 18.5413 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 288/1000
2023-09-23 20:19:52.541 
Epoch 288/1000 
	 loss: 17.4061, MinusLogProbMetric: 17.4061, val_loss: 17.3991, val_MinusLogProbMetric: 17.3991

Epoch 288: val_loss improved from 17.49313 to 17.39905, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 64s - loss: 17.4061 - MinusLogProbMetric: 17.4061 - val_loss: 17.3991 - val_MinusLogProbMetric: 17.3991 - lr: 3.3333e-04 - 64s/epoch - 325ms/step
Epoch 289/1000
2023-09-23 20:20:56.118 
Epoch 289/1000 
	 loss: 17.3832, MinusLogProbMetric: 17.3832, val_loss: 17.7063, val_MinusLogProbMetric: 17.7063

Epoch 289: val_loss did not improve from 17.39905
196/196 - 63s - loss: 17.3832 - MinusLogProbMetric: 17.3832 - val_loss: 17.7063 - val_MinusLogProbMetric: 17.7063 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 290/1000
2023-09-23 20:21:58.859 
Epoch 290/1000 
	 loss: 17.2818, MinusLogProbMetric: 17.2818, val_loss: 18.9762, val_MinusLogProbMetric: 18.9762

Epoch 290: val_loss did not improve from 17.39905
196/196 - 63s - loss: 17.2818 - MinusLogProbMetric: 17.2818 - val_loss: 18.9762 - val_MinusLogProbMetric: 18.9762 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 291/1000
2023-09-23 20:23:01.689 
Epoch 291/1000 
	 loss: 17.3158, MinusLogProbMetric: 17.3158, val_loss: 17.9886, val_MinusLogProbMetric: 17.9886

Epoch 291: val_loss did not improve from 17.39905
196/196 - 63s - loss: 17.3158 - MinusLogProbMetric: 17.3158 - val_loss: 17.9886 - val_MinusLogProbMetric: 17.9886 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 292/1000
2023-09-23 20:24:04.808 
Epoch 292/1000 
	 loss: 17.4018, MinusLogProbMetric: 17.4018, val_loss: 17.5929, val_MinusLogProbMetric: 17.5929

Epoch 292: val_loss did not improve from 17.39905
196/196 - 63s - loss: 17.4018 - MinusLogProbMetric: 17.4018 - val_loss: 17.5929 - val_MinusLogProbMetric: 17.5929 - lr: 3.3333e-04 - 63s/epoch - 322ms/step
Epoch 293/1000
2023-09-23 20:25:08.097 
Epoch 293/1000 
	 loss: 17.3679, MinusLogProbMetric: 17.3679, val_loss: 17.5367, val_MinusLogProbMetric: 17.5367

Epoch 293: val_loss did not improve from 17.39905
196/196 - 63s - loss: 17.3679 - MinusLogProbMetric: 17.3679 - val_loss: 17.5367 - val_MinusLogProbMetric: 17.5367 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 294/1000
2023-09-23 20:26:11.313 
Epoch 294/1000 
	 loss: 17.3118, MinusLogProbMetric: 17.3118, val_loss: 17.8472, val_MinusLogProbMetric: 17.8472

Epoch 294: val_loss did not improve from 17.39905
196/196 - 63s - loss: 17.3118 - MinusLogProbMetric: 17.3118 - val_loss: 17.8472 - val_MinusLogProbMetric: 17.8472 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 295/1000
2023-09-23 20:27:14.276 
Epoch 295/1000 
	 loss: 17.4008, MinusLogProbMetric: 17.4008, val_loss: 17.6268, val_MinusLogProbMetric: 17.6268

Epoch 295: val_loss did not improve from 17.39905
196/196 - 63s - loss: 17.4008 - MinusLogProbMetric: 17.4008 - val_loss: 17.6268 - val_MinusLogProbMetric: 17.6268 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 296/1000
2023-09-23 20:28:17.208 
Epoch 296/1000 
	 loss: 17.3139, MinusLogProbMetric: 17.3139, val_loss: 17.5844, val_MinusLogProbMetric: 17.5844

Epoch 296: val_loss did not improve from 17.39905
196/196 - 63s - loss: 17.3139 - MinusLogProbMetric: 17.3139 - val_loss: 17.5844 - val_MinusLogProbMetric: 17.5844 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 297/1000
2023-09-23 20:29:20.012 
Epoch 297/1000 
	 loss: 17.3653, MinusLogProbMetric: 17.3653, val_loss: 18.0690, val_MinusLogProbMetric: 18.0690

Epoch 297: val_loss did not improve from 17.39905
196/196 - 63s - loss: 17.3653 - MinusLogProbMetric: 17.3653 - val_loss: 18.0690 - val_MinusLogProbMetric: 18.0690 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 298/1000
2023-09-23 20:30:23.410 
Epoch 298/1000 
	 loss: 17.3385, MinusLogProbMetric: 17.3385, val_loss: 17.6901, val_MinusLogProbMetric: 17.6901

Epoch 298: val_loss did not improve from 17.39905
196/196 - 63s - loss: 17.3385 - MinusLogProbMetric: 17.3385 - val_loss: 17.6901 - val_MinusLogProbMetric: 17.6901 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 299/1000
2023-09-23 20:31:26.764 
Epoch 299/1000 
	 loss: 17.3234, MinusLogProbMetric: 17.3234, val_loss: 17.4313, val_MinusLogProbMetric: 17.4313

Epoch 299: val_loss did not improve from 17.39905
196/196 - 63s - loss: 17.3234 - MinusLogProbMetric: 17.3234 - val_loss: 17.4313 - val_MinusLogProbMetric: 17.4313 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 300/1000
2023-09-23 20:32:30.391 
Epoch 300/1000 
	 loss: 17.2695, MinusLogProbMetric: 17.2695, val_loss: 17.5925, val_MinusLogProbMetric: 17.5925

Epoch 300: val_loss did not improve from 17.39905
196/196 - 64s - loss: 17.2695 - MinusLogProbMetric: 17.2695 - val_loss: 17.5925 - val_MinusLogProbMetric: 17.5925 - lr: 3.3333e-04 - 64s/epoch - 325ms/step
Epoch 301/1000
2023-09-23 20:33:33.605 
Epoch 301/1000 
	 loss: 17.4448, MinusLogProbMetric: 17.4448, val_loss: 17.9206, val_MinusLogProbMetric: 17.9206

Epoch 301: val_loss did not improve from 17.39905
196/196 - 63s - loss: 17.4448 - MinusLogProbMetric: 17.4448 - val_loss: 17.9206 - val_MinusLogProbMetric: 17.9206 - lr: 3.3333e-04 - 63s/epoch - 322ms/step
Epoch 302/1000
2023-09-23 20:34:36.523 
Epoch 302/1000 
	 loss: 17.2468, MinusLogProbMetric: 17.2468, val_loss: 17.9141, val_MinusLogProbMetric: 17.9141

Epoch 302: val_loss did not improve from 17.39905
196/196 - 63s - loss: 17.2468 - MinusLogProbMetric: 17.2468 - val_loss: 17.9141 - val_MinusLogProbMetric: 17.9141 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 303/1000
2023-09-23 20:35:39.405 
Epoch 303/1000 
	 loss: 17.3011, MinusLogProbMetric: 17.3011, val_loss: 17.6500, val_MinusLogProbMetric: 17.6500

Epoch 303: val_loss did not improve from 17.39905
196/196 - 63s - loss: 17.3011 - MinusLogProbMetric: 17.3011 - val_loss: 17.6500 - val_MinusLogProbMetric: 17.6500 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 304/1000
2023-09-23 20:36:43.171 
Epoch 304/1000 
	 loss: 17.2535, MinusLogProbMetric: 17.2535, val_loss: 17.6061, val_MinusLogProbMetric: 17.6061

Epoch 304: val_loss did not improve from 17.39905
196/196 - 64s - loss: 17.2535 - MinusLogProbMetric: 17.2535 - val_loss: 17.6061 - val_MinusLogProbMetric: 17.6061 - lr: 3.3333e-04 - 64s/epoch - 325ms/step
Epoch 305/1000
2023-09-23 20:37:47.331 
Epoch 305/1000 
	 loss: 17.3299, MinusLogProbMetric: 17.3299, val_loss: 18.4836, val_MinusLogProbMetric: 18.4836

Epoch 305: val_loss did not improve from 17.39905
196/196 - 64s - loss: 17.3299 - MinusLogProbMetric: 17.3299 - val_loss: 18.4836 - val_MinusLogProbMetric: 18.4836 - lr: 3.3333e-04 - 64s/epoch - 327ms/step
Epoch 306/1000
2023-09-23 20:38:50.689 
Epoch 306/1000 
	 loss: 17.4022, MinusLogProbMetric: 17.4022, val_loss: 17.8604, val_MinusLogProbMetric: 17.8604

Epoch 306: val_loss did not improve from 17.39905
196/196 - 63s - loss: 17.4022 - MinusLogProbMetric: 17.4022 - val_loss: 17.8604 - val_MinusLogProbMetric: 17.8604 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 307/1000
2023-09-23 20:39:54.024 
Epoch 307/1000 
	 loss: 17.2963, MinusLogProbMetric: 17.2963, val_loss: 17.6545, val_MinusLogProbMetric: 17.6545

Epoch 307: val_loss did not improve from 17.39905
196/196 - 63s - loss: 17.2963 - MinusLogProbMetric: 17.2963 - val_loss: 17.6545 - val_MinusLogProbMetric: 17.6545 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 308/1000
2023-09-23 20:40:57.144 
Epoch 308/1000 
	 loss: 17.3737, MinusLogProbMetric: 17.3737, val_loss: 17.4758, val_MinusLogProbMetric: 17.4758

Epoch 308: val_loss did not improve from 17.39905
196/196 - 63s - loss: 17.3737 - MinusLogProbMetric: 17.3737 - val_loss: 17.4758 - val_MinusLogProbMetric: 17.4758 - lr: 3.3333e-04 - 63s/epoch - 322ms/step
Epoch 309/1000
2023-09-23 20:42:00.157 
Epoch 309/1000 
	 loss: 17.2730, MinusLogProbMetric: 17.2730, val_loss: 17.8210, val_MinusLogProbMetric: 17.8210

Epoch 309: val_loss did not improve from 17.39905
196/196 - 63s - loss: 17.2730 - MinusLogProbMetric: 17.2730 - val_loss: 17.8210 - val_MinusLogProbMetric: 17.8210 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 310/1000
2023-09-23 20:43:02.863 
Epoch 310/1000 
	 loss: 17.2202, MinusLogProbMetric: 17.2202, val_loss: 17.3895, val_MinusLogProbMetric: 17.3895

Epoch 310: val_loss improved from 17.39905 to 17.38948, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 64s - loss: 17.2202 - MinusLogProbMetric: 17.2202 - val_loss: 17.3895 - val_MinusLogProbMetric: 17.3895 - lr: 3.3333e-04 - 64s/epoch - 325ms/step
Epoch 311/1000
2023-09-23 20:44:06.730 
Epoch 311/1000 
	 loss: 17.3117, MinusLogProbMetric: 17.3117, val_loss: 18.0586, val_MinusLogProbMetric: 18.0586

Epoch 311: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.3117 - MinusLogProbMetric: 17.3117 - val_loss: 18.0586 - val_MinusLogProbMetric: 18.0586 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 312/1000
2023-09-23 20:45:09.543 
Epoch 312/1000 
	 loss: 17.2791, MinusLogProbMetric: 17.2791, val_loss: 18.8403, val_MinusLogProbMetric: 18.8403

Epoch 312: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.2791 - MinusLogProbMetric: 17.2791 - val_loss: 18.8403 - val_MinusLogProbMetric: 18.8403 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 313/1000
2023-09-23 20:46:12.481 
Epoch 313/1000 
	 loss: 17.2381, MinusLogProbMetric: 17.2381, val_loss: 17.5505, val_MinusLogProbMetric: 17.5505

Epoch 313: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.2381 - MinusLogProbMetric: 17.2381 - val_loss: 17.5505 - val_MinusLogProbMetric: 17.5505 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 314/1000
2023-09-23 20:47:15.300 
Epoch 314/1000 
	 loss: 17.2644, MinusLogProbMetric: 17.2644, val_loss: 18.3945, val_MinusLogProbMetric: 18.3945

Epoch 314: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.2644 - MinusLogProbMetric: 17.2644 - val_loss: 18.3945 - val_MinusLogProbMetric: 18.3945 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 315/1000
2023-09-23 20:48:17.976 
Epoch 315/1000 
	 loss: 17.3023, MinusLogProbMetric: 17.3023, val_loss: 17.9932, val_MinusLogProbMetric: 17.9932

Epoch 315: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.3023 - MinusLogProbMetric: 17.3023 - val_loss: 17.9932 - val_MinusLogProbMetric: 17.9932 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 316/1000
2023-09-23 20:49:20.811 
Epoch 316/1000 
	 loss: 17.2218, MinusLogProbMetric: 17.2218, val_loss: 17.7318, val_MinusLogProbMetric: 17.7318

Epoch 316: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.2218 - MinusLogProbMetric: 17.2218 - val_loss: 17.7318 - val_MinusLogProbMetric: 17.7318 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 317/1000
2023-09-23 20:50:24.329 
Epoch 317/1000 
	 loss: 17.3200, MinusLogProbMetric: 17.3200, val_loss: 17.9506, val_MinusLogProbMetric: 17.9506

Epoch 317: val_loss did not improve from 17.38948
196/196 - 64s - loss: 17.3200 - MinusLogProbMetric: 17.3200 - val_loss: 17.9506 - val_MinusLogProbMetric: 17.9506 - lr: 3.3333e-04 - 64s/epoch - 324ms/step
Epoch 318/1000
2023-09-23 20:51:27.399 
Epoch 318/1000 
	 loss: 17.3765, MinusLogProbMetric: 17.3765, val_loss: 17.7283, val_MinusLogProbMetric: 17.7283

Epoch 318: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.3765 - MinusLogProbMetric: 17.3765 - val_loss: 17.7283 - val_MinusLogProbMetric: 17.7283 - lr: 3.3333e-04 - 63s/epoch - 322ms/step
Epoch 319/1000
2023-09-23 20:52:30.855 
Epoch 319/1000 
	 loss: 17.1714, MinusLogProbMetric: 17.1714, val_loss: 17.8862, val_MinusLogProbMetric: 17.8862

Epoch 319: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.1714 - MinusLogProbMetric: 17.1714 - val_loss: 17.8862 - val_MinusLogProbMetric: 17.8862 - lr: 3.3333e-04 - 63s/epoch - 324ms/step
Epoch 320/1000
2023-09-23 20:53:33.872 
Epoch 320/1000 
	 loss: 17.3319, MinusLogProbMetric: 17.3319, val_loss: 18.0852, val_MinusLogProbMetric: 18.0852

Epoch 320: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.3319 - MinusLogProbMetric: 17.3319 - val_loss: 18.0852 - val_MinusLogProbMetric: 18.0852 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 321/1000
2023-09-23 20:54:37.151 
Epoch 321/1000 
	 loss: 17.2960, MinusLogProbMetric: 17.2960, val_loss: 17.6449, val_MinusLogProbMetric: 17.6449

Epoch 321: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.2960 - MinusLogProbMetric: 17.2960 - val_loss: 17.6449 - val_MinusLogProbMetric: 17.6449 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 322/1000
2023-09-23 20:55:39.926 
Epoch 322/1000 
	 loss: 17.2064, MinusLogProbMetric: 17.2064, val_loss: 17.7317, val_MinusLogProbMetric: 17.7317

Epoch 322: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.2064 - MinusLogProbMetric: 17.2064 - val_loss: 17.7317 - val_MinusLogProbMetric: 17.7317 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 323/1000
2023-09-23 20:56:43.242 
Epoch 323/1000 
	 loss: 17.2574, MinusLogProbMetric: 17.2574, val_loss: 17.6466, val_MinusLogProbMetric: 17.6466

Epoch 323: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.2574 - MinusLogProbMetric: 17.2574 - val_loss: 17.6466 - val_MinusLogProbMetric: 17.6466 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 324/1000
2023-09-23 20:57:46.328 
Epoch 324/1000 
	 loss: 17.2386, MinusLogProbMetric: 17.2386, val_loss: 17.4817, val_MinusLogProbMetric: 17.4817

Epoch 324: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.2386 - MinusLogProbMetric: 17.2386 - val_loss: 17.4817 - val_MinusLogProbMetric: 17.4817 - lr: 3.3333e-04 - 63s/epoch - 322ms/step
Epoch 325/1000
2023-09-23 20:58:49.341 
Epoch 325/1000 
	 loss: 17.2711, MinusLogProbMetric: 17.2711, val_loss: 17.7162, val_MinusLogProbMetric: 17.7162

Epoch 325: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.2711 - MinusLogProbMetric: 17.2711 - val_loss: 17.7162 - val_MinusLogProbMetric: 17.7162 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 326/1000
2023-09-23 20:59:51.728 
Epoch 326/1000 
	 loss: 17.2328, MinusLogProbMetric: 17.2328, val_loss: 17.9320, val_MinusLogProbMetric: 17.9320

Epoch 326: val_loss did not improve from 17.38948
196/196 - 62s - loss: 17.2328 - MinusLogProbMetric: 17.2328 - val_loss: 17.9320 - val_MinusLogProbMetric: 17.9320 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 327/1000
2023-09-23 21:00:55.075 
Epoch 327/1000 
	 loss: 17.2087, MinusLogProbMetric: 17.2087, val_loss: 17.4961, val_MinusLogProbMetric: 17.4961

Epoch 327: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.2087 - MinusLogProbMetric: 17.2087 - val_loss: 17.4961 - val_MinusLogProbMetric: 17.4961 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 328/1000
2023-09-23 21:01:58.547 
Epoch 328/1000 
	 loss: 17.2300, MinusLogProbMetric: 17.2300, val_loss: 17.5174, val_MinusLogProbMetric: 17.5174

Epoch 328: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.2300 - MinusLogProbMetric: 17.2300 - val_loss: 17.5174 - val_MinusLogProbMetric: 17.5174 - lr: 3.3333e-04 - 63s/epoch - 324ms/step
Epoch 329/1000
2023-09-23 21:03:02.332 
Epoch 329/1000 
	 loss: 17.2379, MinusLogProbMetric: 17.2379, val_loss: 17.5003, val_MinusLogProbMetric: 17.5003

Epoch 329: val_loss did not improve from 17.38948
196/196 - 64s - loss: 17.2379 - MinusLogProbMetric: 17.2379 - val_loss: 17.5003 - val_MinusLogProbMetric: 17.5003 - lr: 3.3333e-04 - 64s/epoch - 325ms/step
Epoch 330/1000
2023-09-23 21:04:05.523 
Epoch 330/1000 
	 loss: 17.2856, MinusLogProbMetric: 17.2856, val_loss: 17.6140, val_MinusLogProbMetric: 17.6140

Epoch 330: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.2856 - MinusLogProbMetric: 17.2856 - val_loss: 17.6140 - val_MinusLogProbMetric: 17.6140 - lr: 3.3333e-04 - 63s/epoch - 322ms/step
Epoch 331/1000
2023-09-23 21:05:08.538 
Epoch 331/1000 
	 loss: 17.1737, MinusLogProbMetric: 17.1737, val_loss: 17.5406, val_MinusLogProbMetric: 17.5406

Epoch 331: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.1737 - MinusLogProbMetric: 17.1737 - val_loss: 17.5406 - val_MinusLogProbMetric: 17.5406 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 332/1000
2023-09-23 21:06:11.077 
Epoch 332/1000 
	 loss: 17.1746, MinusLogProbMetric: 17.1746, val_loss: 17.8479, val_MinusLogProbMetric: 17.8479

Epoch 332: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.1746 - MinusLogProbMetric: 17.1746 - val_loss: 17.8479 - val_MinusLogProbMetric: 17.8479 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 333/1000
2023-09-23 21:07:13.832 
Epoch 333/1000 
	 loss: 17.1708, MinusLogProbMetric: 17.1708, val_loss: 17.8671, val_MinusLogProbMetric: 17.8671

Epoch 333: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.1708 - MinusLogProbMetric: 17.1708 - val_loss: 17.8671 - val_MinusLogProbMetric: 17.8671 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 334/1000
2023-09-23 21:08:17.314 
Epoch 334/1000 
	 loss: 17.2162, MinusLogProbMetric: 17.2162, val_loss: 18.3731, val_MinusLogProbMetric: 18.3731

Epoch 334: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.2162 - MinusLogProbMetric: 17.2162 - val_loss: 18.3731 - val_MinusLogProbMetric: 18.3731 - lr: 3.3333e-04 - 63s/epoch - 324ms/step
Epoch 335/1000
2023-09-23 21:09:20.235 
Epoch 335/1000 
	 loss: 17.2321, MinusLogProbMetric: 17.2321, val_loss: 17.6201, val_MinusLogProbMetric: 17.6201

Epoch 335: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.2321 - MinusLogProbMetric: 17.2321 - val_loss: 17.6201 - val_MinusLogProbMetric: 17.6201 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 336/1000
2023-09-23 21:10:22.874 
Epoch 336/1000 
	 loss: 17.2238, MinusLogProbMetric: 17.2238, val_loss: 17.7068, val_MinusLogProbMetric: 17.7068

Epoch 336: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.2238 - MinusLogProbMetric: 17.2238 - val_loss: 17.7068 - val_MinusLogProbMetric: 17.7068 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 337/1000
2023-09-23 21:11:25.772 
Epoch 337/1000 
	 loss: 17.2587, MinusLogProbMetric: 17.2587, val_loss: 17.6682, val_MinusLogProbMetric: 17.6682

Epoch 337: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.2587 - MinusLogProbMetric: 17.2587 - val_loss: 17.6682 - val_MinusLogProbMetric: 17.6682 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 338/1000
2023-09-23 21:12:28.061 
Epoch 338/1000 
	 loss: 17.1541, MinusLogProbMetric: 17.1541, val_loss: 17.7191, val_MinusLogProbMetric: 17.7191

Epoch 338: val_loss did not improve from 17.38948
196/196 - 62s - loss: 17.1541 - MinusLogProbMetric: 17.1541 - val_loss: 17.7191 - val_MinusLogProbMetric: 17.7191 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 339/1000
2023-09-23 21:13:29.914 
Epoch 339/1000 
	 loss: 17.1675, MinusLogProbMetric: 17.1675, val_loss: 17.4932, val_MinusLogProbMetric: 17.4932

Epoch 339: val_loss did not improve from 17.38948
196/196 - 62s - loss: 17.1675 - MinusLogProbMetric: 17.1675 - val_loss: 17.4932 - val_MinusLogProbMetric: 17.4932 - lr: 3.3333e-04 - 62s/epoch - 316ms/step
Epoch 340/1000
2023-09-23 21:14:34.564 
Epoch 340/1000 
	 loss: 17.1252, MinusLogProbMetric: 17.1252, val_loss: 18.4823, val_MinusLogProbMetric: 18.4823

Epoch 340: val_loss did not improve from 17.38948
196/196 - 65s - loss: 17.1252 - MinusLogProbMetric: 17.1252 - val_loss: 18.4823 - val_MinusLogProbMetric: 18.4823 - lr: 3.3333e-04 - 65s/epoch - 330ms/step
Epoch 341/1000
2023-09-23 21:15:35.935 
Epoch 341/1000 
	 loss: 17.1963, MinusLogProbMetric: 17.1963, val_loss: 17.7545, val_MinusLogProbMetric: 17.7545

Epoch 341: val_loss did not improve from 17.38948
196/196 - 61s - loss: 17.1963 - MinusLogProbMetric: 17.1963 - val_loss: 17.7545 - val_MinusLogProbMetric: 17.7545 - lr: 3.3333e-04 - 61s/epoch - 313ms/step
Epoch 342/1000
2023-09-23 21:16:38.078 
Epoch 342/1000 
	 loss: 17.2388, MinusLogProbMetric: 17.2388, val_loss: 17.5564, val_MinusLogProbMetric: 17.5564

Epoch 342: val_loss did not improve from 17.38948
196/196 - 62s - loss: 17.2388 - MinusLogProbMetric: 17.2388 - val_loss: 17.5564 - val_MinusLogProbMetric: 17.5564 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 343/1000
2023-09-23 21:17:41.400 
Epoch 343/1000 
	 loss: 17.2031, MinusLogProbMetric: 17.2031, val_loss: 17.4973, val_MinusLogProbMetric: 17.4973

Epoch 343: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.2031 - MinusLogProbMetric: 17.2031 - val_loss: 17.4973 - val_MinusLogProbMetric: 17.4973 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 344/1000
2023-09-23 21:18:46.337 
Epoch 344/1000 
	 loss: 17.2951, MinusLogProbMetric: 17.2951, val_loss: 17.8989, val_MinusLogProbMetric: 17.8989

Epoch 344: val_loss did not improve from 17.38948
196/196 - 65s - loss: 17.2951 - MinusLogProbMetric: 17.2951 - val_loss: 17.8989 - val_MinusLogProbMetric: 17.8989 - lr: 3.3333e-04 - 65s/epoch - 331ms/step
Epoch 345/1000
2023-09-23 21:19:52.395 
Epoch 345/1000 
	 loss: 17.1748, MinusLogProbMetric: 17.1748, val_loss: 17.6730, val_MinusLogProbMetric: 17.6730

Epoch 345: val_loss did not improve from 17.38948
196/196 - 66s - loss: 17.1748 - MinusLogProbMetric: 17.1748 - val_loss: 17.6730 - val_MinusLogProbMetric: 17.6730 - lr: 3.3333e-04 - 66s/epoch - 337ms/step
Epoch 346/1000
2023-09-23 21:20:56.515 
Epoch 346/1000 
	 loss: 17.1277, MinusLogProbMetric: 17.1277, val_loss: 17.6515, val_MinusLogProbMetric: 17.6515

Epoch 346: val_loss did not improve from 17.38948
196/196 - 64s - loss: 17.1277 - MinusLogProbMetric: 17.1277 - val_loss: 17.6515 - val_MinusLogProbMetric: 17.6515 - lr: 3.3333e-04 - 64s/epoch - 327ms/step
Epoch 347/1000
2023-09-23 21:21:59.877 
Epoch 347/1000 
	 loss: 17.2393, MinusLogProbMetric: 17.2393, val_loss: 17.4358, val_MinusLogProbMetric: 17.4358

Epoch 347: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.2393 - MinusLogProbMetric: 17.2393 - val_loss: 17.4358 - val_MinusLogProbMetric: 17.4358 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 348/1000
2023-09-23 21:23:02.826 
Epoch 348/1000 
	 loss: 17.1282, MinusLogProbMetric: 17.1282, val_loss: 18.5251, val_MinusLogProbMetric: 18.5251

Epoch 348: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.1282 - MinusLogProbMetric: 17.1282 - val_loss: 18.5251 - val_MinusLogProbMetric: 18.5251 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 349/1000
2023-09-23 21:24:04.620 
Epoch 349/1000 
	 loss: 17.1571, MinusLogProbMetric: 17.1571, val_loss: 17.5904, val_MinusLogProbMetric: 17.5904

Epoch 349: val_loss did not improve from 17.38948
196/196 - 62s - loss: 17.1571 - MinusLogProbMetric: 17.1571 - val_loss: 17.5904 - val_MinusLogProbMetric: 17.5904 - lr: 3.3333e-04 - 62s/epoch - 315ms/step
Epoch 350/1000
2023-09-23 21:25:06.748 
Epoch 350/1000 
	 loss: 17.1063, MinusLogProbMetric: 17.1063, val_loss: 17.7309, val_MinusLogProbMetric: 17.7309

Epoch 350: val_loss did not improve from 17.38948
196/196 - 62s - loss: 17.1063 - MinusLogProbMetric: 17.1063 - val_loss: 17.7309 - val_MinusLogProbMetric: 17.7309 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 351/1000
2023-09-23 21:26:08.564 
Epoch 351/1000 
	 loss: 17.1517, MinusLogProbMetric: 17.1517, val_loss: 17.4832, val_MinusLogProbMetric: 17.4832

Epoch 351: val_loss did not improve from 17.38948
196/196 - 62s - loss: 17.1517 - MinusLogProbMetric: 17.1517 - val_loss: 17.4832 - val_MinusLogProbMetric: 17.4832 - lr: 3.3333e-04 - 62s/epoch - 315ms/step
Epoch 352/1000
2023-09-23 21:27:10.411 
Epoch 352/1000 
	 loss: 17.1728, MinusLogProbMetric: 17.1728, val_loss: 17.7622, val_MinusLogProbMetric: 17.7622

Epoch 352: val_loss did not improve from 17.38948
196/196 - 62s - loss: 17.1728 - MinusLogProbMetric: 17.1728 - val_loss: 17.7622 - val_MinusLogProbMetric: 17.7622 - lr: 3.3333e-04 - 62s/epoch - 316ms/step
Epoch 353/1000
2023-09-23 21:28:12.951 
Epoch 353/1000 
	 loss: 17.2275, MinusLogProbMetric: 17.2275, val_loss: 17.5050, val_MinusLogProbMetric: 17.5050

Epoch 353: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.2275 - MinusLogProbMetric: 17.2275 - val_loss: 17.5050 - val_MinusLogProbMetric: 17.5050 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 354/1000
2023-09-23 21:29:14.316 
Epoch 354/1000 
	 loss: 17.1568, MinusLogProbMetric: 17.1568, val_loss: 17.6588, val_MinusLogProbMetric: 17.6588

Epoch 354: val_loss did not improve from 17.38948
196/196 - 61s - loss: 17.1568 - MinusLogProbMetric: 17.1568 - val_loss: 17.6588 - val_MinusLogProbMetric: 17.6588 - lr: 3.3333e-04 - 61s/epoch - 313ms/step
Epoch 355/1000
2023-09-23 21:30:16.849 
Epoch 355/1000 
	 loss: 17.1769, MinusLogProbMetric: 17.1769, val_loss: 17.6898, val_MinusLogProbMetric: 17.6898

Epoch 355: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.1769 - MinusLogProbMetric: 17.1769 - val_loss: 17.6898 - val_MinusLogProbMetric: 17.6898 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 356/1000
2023-09-23 21:31:18.828 
Epoch 356/1000 
	 loss: 17.1477, MinusLogProbMetric: 17.1477, val_loss: 17.6072, val_MinusLogProbMetric: 17.6072

Epoch 356: val_loss did not improve from 17.38948
196/196 - 62s - loss: 17.1477 - MinusLogProbMetric: 17.1477 - val_loss: 17.6072 - val_MinusLogProbMetric: 17.6072 - lr: 3.3333e-04 - 62s/epoch - 316ms/step
Epoch 357/1000
2023-09-23 21:32:21.110 
Epoch 357/1000 
	 loss: 17.1177, MinusLogProbMetric: 17.1177, val_loss: 18.0772, val_MinusLogProbMetric: 18.0772

Epoch 357: val_loss did not improve from 17.38948
196/196 - 62s - loss: 17.1177 - MinusLogProbMetric: 17.1177 - val_loss: 18.0772 - val_MinusLogProbMetric: 18.0772 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 358/1000
2023-09-23 21:33:24.539 
Epoch 358/1000 
	 loss: 17.1720, MinusLogProbMetric: 17.1720, val_loss: 17.5768, val_MinusLogProbMetric: 17.5768

Epoch 358: val_loss did not improve from 17.38948
196/196 - 63s - loss: 17.1720 - MinusLogProbMetric: 17.1720 - val_loss: 17.5768 - val_MinusLogProbMetric: 17.5768 - lr: 3.3333e-04 - 63s/epoch - 324ms/step
Epoch 359/1000
2023-09-23 21:34:27.321 
Epoch 359/1000 
	 loss: 17.1516, MinusLogProbMetric: 17.1516, val_loss: 17.3619, val_MinusLogProbMetric: 17.3619

Epoch 359: val_loss improved from 17.38948 to 17.36194, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 64s - loss: 17.1516 - MinusLogProbMetric: 17.1516 - val_loss: 17.3619 - val_MinusLogProbMetric: 17.3619 - lr: 3.3333e-04 - 64s/epoch - 326ms/step
Epoch 360/1000
2023-09-23 21:35:30.509 
Epoch 360/1000 
	 loss: 17.1826, MinusLogProbMetric: 17.1826, val_loss: 17.5077, val_MinusLogProbMetric: 17.5077

Epoch 360: val_loss did not improve from 17.36194
196/196 - 62s - loss: 17.1826 - MinusLogProbMetric: 17.1826 - val_loss: 17.5077 - val_MinusLogProbMetric: 17.5077 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 361/1000
2023-09-23 21:36:32.810 
Epoch 361/1000 
	 loss: 17.0723, MinusLogProbMetric: 17.0723, val_loss: 18.0460, val_MinusLogProbMetric: 18.0460

Epoch 361: val_loss did not improve from 17.36194
196/196 - 62s - loss: 17.0723 - MinusLogProbMetric: 17.0723 - val_loss: 18.0460 - val_MinusLogProbMetric: 18.0460 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 362/1000
2023-09-23 21:37:35.020 
Epoch 362/1000 
	 loss: 17.1445, MinusLogProbMetric: 17.1445, val_loss: 17.5578, val_MinusLogProbMetric: 17.5578

Epoch 362: val_loss did not improve from 17.36194
196/196 - 62s - loss: 17.1445 - MinusLogProbMetric: 17.1445 - val_loss: 17.5578 - val_MinusLogProbMetric: 17.5578 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 363/1000
2023-09-23 21:38:37.046 
Epoch 363/1000 
	 loss: 17.1300, MinusLogProbMetric: 17.1300, val_loss: 18.1643, val_MinusLogProbMetric: 18.1643

Epoch 363: val_loss did not improve from 17.36194
196/196 - 62s - loss: 17.1300 - MinusLogProbMetric: 17.1300 - val_loss: 18.1643 - val_MinusLogProbMetric: 18.1643 - lr: 3.3333e-04 - 62s/epoch - 316ms/step
Epoch 364/1000
2023-09-23 21:39:39.916 
Epoch 364/1000 
	 loss: 17.1621, MinusLogProbMetric: 17.1621, val_loss: 17.4616, val_MinusLogProbMetric: 17.4616

Epoch 364: val_loss did not improve from 17.36194
196/196 - 63s - loss: 17.1621 - MinusLogProbMetric: 17.1621 - val_loss: 17.4616 - val_MinusLogProbMetric: 17.4616 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 365/1000
2023-09-23 21:40:43.053 
Epoch 365/1000 
	 loss: 17.1466, MinusLogProbMetric: 17.1466, val_loss: 17.8593, val_MinusLogProbMetric: 17.8593

Epoch 365: val_loss did not improve from 17.36194
196/196 - 63s - loss: 17.1466 - MinusLogProbMetric: 17.1466 - val_loss: 17.8593 - val_MinusLogProbMetric: 17.8593 - lr: 3.3333e-04 - 63s/epoch - 322ms/step
Epoch 366/1000
2023-09-23 21:41:44.787 
Epoch 366/1000 
	 loss: 17.0819, MinusLogProbMetric: 17.0819, val_loss: 17.7462, val_MinusLogProbMetric: 17.7462

Epoch 366: val_loss did not improve from 17.36194
196/196 - 62s - loss: 17.0819 - MinusLogProbMetric: 17.0819 - val_loss: 17.7462 - val_MinusLogProbMetric: 17.7462 - lr: 3.3333e-04 - 62s/epoch - 315ms/step
Epoch 367/1000
2023-09-23 21:42:47.551 
Epoch 367/1000 
	 loss: 17.1520, MinusLogProbMetric: 17.1520, val_loss: 17.7163, val_MinusLogProbMetric: 17.7163

Epoch 367: val_loss did not improve from 17.36194
196/196 - 63s - loss: 17.1520 - MinusLogProbMetric: 17.1520 - val_loss: 17.7163 - val_MinusLogProbMetric: 17.7163 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 368/1000
2023-09-23 21:43:50.037 
Epoch 368/1000 
	 loss: 17.0842, MinusLogProbMetric: 17.0842, val_loss: 17.5203, val_MinusLogProbMetric: 17.5203

Epoch 368: val_loss did not improve from 17.36194
196/196 - 62s - loss: 17.0842 - MinusLogProbMetric: 17.0842 - val_loss: 17.5203 - val_MinusLogProbMetric: 17.5203 - lr: 3.3333e-04 - 62s/epoch - 319ms/step
Epoch 369/1000
2023-09-23 21:44:52.443 
Epoch 369/1000 
	 loss: 17.0381, MinusLogProbMetric: 17.0381, val_loss: 18.4474, val_MinusLogProbMetric: 18.4474

Epoch 369: val_loss did not improve from 17.36194
196/196 - 62s - loss: 17.0381 - MinusLogProbMetric: 17.0381 - val_loss: 18.4474 - val_MinusLogProbMetric: 18.4474 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 370/1000
2023-09-23 21:45:54.951 
Epoch 370/1000 
	 loss: 17.2527, MinusLogProbMetric: 17.2527, val_loss: 18.3434, val_MinusLogProbMetric: 18.3434

Epoch 370: val_loss did not improve from 17.36194
196/196 - 63s - loss: 17.2527 - MinusLogProbMetric: 17.2527 - val_loss: 18.3434 - val_MinusLogProbMetric: 18.3434 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 371/1000
2023-09-23 21:46:57.179 
Epoch 371/1000 
	 loss: 17.1371, MinusLogProbMetric: 17.1371, val_loss: 17.5624, val_MinusLogProbMetric: 17.5624

Epoch 371: val_loss did not improve from 17.36194
196/196 - 62s - loss: 17.1371 - MinusLogProbMetric: 17.1371 - val_loss: 17.5624 - val_MinusLogProbMetric: 17.5624 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 372/1000
2023-09-23 21:48:00.129 
Epoch 372/1000 
	 loss: 17.1621, MinusLogProbMetric: 17.1621, val_loss: 17.7999, val_MinusLogProbMetric: 17.7999

Epoch 372: val_loss did not improve from 17.36194
196/196 - 63s - loss: 17.1621 - MinusLogProbMetric: 17.1621 - val_loss: 17.7999 - val_MinusLogProbMetric: 17.7999 - lr: 3.3333e-04 - 63s/epoch - 321ms/step
Epoch 373/1000
2023-09-23 21:49:02.941 
Epoch 373/1000 
	 loss: 17.0641, MinusLogProbMetric: 17.0641, val_loss: 17.7393, val_MinusLogProbMetric: 17.7393

Epoch 373: val_loss did not improve from 17.36194
196/196 - 63s - loss: 17.0641 - MinusLogProbMetric: 17.0641 - val_loss: 17.7393 - val_MinusLogProbMetric: 17.7393 - lr: 3.3333e-04 - 63s/epoch - 320ms/step
Epoch 374/1000
2023-09-23 21:50:06.666 
Epoch 374/1000 
	 loss: 17.1198, MinusLogProbMetric: 17.1198, val_loss: 17.5797, val_MinusLogProbMetric: 17.5797

Epoch 374: val_loss did not improve from 17.36194
196/196 - 64s - loss: 17.1198 - MinusLogProbMetric: 17.1198 - val_loss: 17.5797 - val_MinusLogProbMetric: 17.5797 - lr: 3.3333e-04 - 64s/epoch - 325ms/step
Epoch 375/1000
2023-09-23 21:51:08.936 
Epoch 375/1000 
	 loss: 17.1905, MinusLogProbMetric: 17.1905, val_loss: 17.9613, val_MinusLogProbMetric: 17.9613

Epoch 375: val_loss did not improve from 17.36194
196/196 - 62s - loss: 17.1905 - MinusLogProbMetric: 17.1905 - val_loss: 17.9613 - val_MinusLogProbMetric: 17.9613 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 376/1000
2023-09-23 21:52:11.258 
Epoch 376/1000 
	 loss: 17.1271, MinusLogProbMetric: 17.1271, val_loss: 17.7634, val_MinusLogProbMetric: 17.7634

Epoch 376: val_loss did not improve from 17.36194
196/196 - 62s - loss: 17.1271 - MinusLogProbMetric: 17.1271 - val_loss: 17.7634 - val_MinusLogProbMetric: 17.7634 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 377/1000
2023-09-23 21:53:13.702 
Epoch 377/1000 
	 loss: 17.1626, MinusLogProbMetric: 17.1626, val_loss: 17.4908, val_MinusLogProbMetric: 17.4908

Epoch 377: val_loss did not improve from 17.36194
196/196 - 62s - loss: 17.1626 - MinusLogProbMetric: 17.1626 - val_loss: 17.4908 - val_MinusLogProbMetric: 17.4908 - lr: 3.3333e-04 - 62s/epoch - 319ms/step
Epoch 378/1000
2023-09-23 21:54:16.295 
Epoch 378/1000 
	 loss: 17.0584, MinusLogProbMetric: 17.0584, val_loss: 17.5404, val_MinusLogProbMetric: 17.5404

Epoch 378: val_loss did not improve from 17.36194
196/196 - 63s - loss: 17.0584 - MinusLogProbMetric: 17.0584 - val_loss: 17.5404 - val_MinusLogProbMetric: 17.5404 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 379/1000
2023-09-23 21:55:18.334 
Epoch 379/1000 
	 loss: 17.0583, MinusLogProbMetric: 17.0583, val_loss: 17.6246, val_MinusLogProbMetric: 17.6246

Epoch 379: val_loss did not improve from 17.36194
196/196 - 62s - loss: 17.0583 - MinusLogProbMetric: 17.0583 - val_loss: 17.6246 - val_MinusLogProbMetric: 17.6246 - lr: 3.3333e-04 - 62s/epoch - 316ms/step
Epoch 380/1000
2023-09-23 21:56:20.668 
Epoch 380/1000 
	 loss: 17.1023, MinusLogProbMetric: 17.1023, val_loss: 18.7424, val_MinusLogProbMetric: 18.7424

Epoch 380: val_loss did not improve from 17.36194
196/196 - 62s - loss: 17.1023 - MinusLogProbMetric: 17.1023 - val_loss: 18.7424 - val_MinusLogProbMetric: 18.7424 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 381/1000
2023-09-23 21:57:24.974 
Epoch 381/1000 
	 loss: 17.0926, MinusLogProbMetric: 17.0926, val_loss: 17.7308, val_MinusLogProbMetric: 17.7308

Epoch 381: val_loss did not improve from 17.36194
196/196 - 64s - loss: 17.0926 - MinusLogProbMetric: 17.0926 - val_loss: 17.7308 - val_MinusLogProbMetric: 17.7308 - lr: 3.3333e-04 - 64s/epoch - 328ms/step
Epoch 382/1000
2023-09-23 21:58:28.755 
Epoch 382/1000 
	 loss: 17.0764, MinusLogProbMetric: 17.0764, val_loss: 17.3436, val_MinusLogProbMetric: 17.3436

Epoch 382: val_loss improved from 17.36194 to 17.34357, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 65s - loss: 17.0764 - MinusLogProbMetric: 17.0764 - val_loss: 17.3436 - val_MinusLogProbMetric: 17.3436 - lr: 3.3333e-04 - 65s/epoch - 331ms/step
Epoch 383/1000
2023-09-23 21:59:33.188 
Epoch 383/1000 
	 loss: 17.1227, MinusLogProbMetric: 17.1227, val_loss: 17.7168, val_MinusLogProbMetric: 17.7168

Epoch 383: val_loss did not improve from 17.34357
196/196 - 63s - loss: 17.1227 - MinusLogProbMetric: 17.1227 - val_loss: 17.7168 - val_MinusLogProbMetric: 17.7168 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 384/1000
2023-09-23 22:00:34.875 
Epoch 384/1000 
	 loss: 17.1640, MinusLogProbMetric: 17.1640, val_loss: 17.6358, val_MinusLogProbMetric: 17.6358

Epoch 384: val_loss did not improve from 17.34357
196/196 - 62s - loss: 17.1640 - MinusLogProbMetric: 17.1640 - val_loss: 17.6358 - val_MinusLogProbMetric: 17.6358 - lr: 3.3333e-04 - 62s/epoch - 315ms/step
Epoch 385/1000
2023-09-23 22:01:39.495 
Epoch 385/1000 
	 loss: 17.0720, MinusLogProbMetric: 17.0720, val_loss: 17.9675, val_MinusLogProbMetric: 17.9675

Epoch 385: val_loss did not improve from 17.34357
196/196 - 65s - loss: 17.0720 - MinusLogProbMetric: 17.0720 - val_loss: 17.9675 - val_MinusLogProbMetric: 17.9675 - lr: 3.3333e-04 - 65s/epoch - 330ms/step
Epoch 386/1000
2023-09-23 22:02:43.674 
Epoch 386/1000 
	 loss: 17.0070, MinusLogProbMetric: 17.0070, val_loss: 17.7780, val_MinusLogProbMetric: 17.7780

Epoch 386: val_loss did not improve from 17.34357
196/196 - 64s - loss: 17.0070 - MinusLogProbMetric: 17.0070 - val_loss: 17.7780 - val_MinusLogProbMetric: 17.7780 - lr: 3.3333e-04 - 64s/epoch - 327ms/step
Epoch 387/1000
2023-09-23 22:03:47.049 
Epoch 387/1000 
	 loss: 17.0965, MinusLogProbMetric: 17.0965, val_loss: 17.7340, val_MinusLogProbMetric: 17.7340

Epoch 387: val_loss did not improve from 17.34357
196/196 - 63s - loss: 17.0965 - MinusLogProbMetric: 17.0965 - val_loss: 17.7340 - val_MinusLogProbMetric: 17.7340 - lr: 3.3333e-04 - 63s/epoch - 323ms/step
Epoch 388/1000
2023-09-23 22:04:49.614 
Epoch 388/1000 
	 loss: 17.1045, MinusLogProbMetric: 17.1045, val_loss: 17.5715, val_MinusLogProbMetric: 17.5715

Epoch 388: val_loss did not improve from 17.34357
196/196 - 63s - loss: 17.1045 - MinusLogProbMetric: 17.1045 - val_loss: 17.5715 - val_MinusLogProbMetric: 17.5715 - lr: 3.3333e-04 - 63s/epoch - 319ms/step
Epoch 389/1000
2023-09-23 22:05:52.646 
Epoch 389/1000 
	 loss: 17.0317, MinusLogProbMetric: 17.0317, val_loss: 17.7321, val_MinusLogProbMetric: 17.7321

Epoch 389: val_loss did not improve from 17.34357
196/196 - 63s - loss: 17.0317 - MinusLogProbMetric: 17.0317 - val_loss: 17.7321 - val_MinusLogProbMetric: 17.7321 - lr: 3.3333e-04 - 63s/epoch - 322ms/step
Epoch 390/1000
2023-09-23 22:06:54.733 
Epoch 390/1000 
	 loss: 17.0940, MinusLogProbMetric: 17.0940, val_loss: 17.7101, val_MinusLogProbMetric: 17.7101

Epoch 390: val_loss did not improve from 17.34357
196/196 - 62s - loss: 17.0940 - MinusLogProbMetric: 17.0940 - val_loss: 17.7101 - val_MinusLogProbMetric: 17.7101 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 391/1000
2023-09-23 22:07:56.140 
Epoch 391/1000 
	 loss: 17.0933, MinusLogProbMetric: 17.0933, val_loss: 17.9053, val_MinusLogProbMetric: 17.9053

Epoch 391: val_loss did not improve from 17.34357
196/196 - 61s - loss: 17.0933 - MinusLogProbMetric: 17.0933 - val_loss: 17.9053 - val_MinusLogProbMetric: 17.9053 - lr: 3.3333e-04 - 61s/epoch - 313ms/step
Epoch 392/1000
2023-09-23 22:08:55.336 
Epoch 392/1000 
	 loss: 17.0990, MinusLogProbMetric: 17.0990, val_loss: 17.5854, val_MinusLogProbMetric: 17.5854

Epoch 392: val_loss did not improve from 17.34357
196/196 - 59s - loss: 17.0990 - MinusLogProbMetric: 17.0990 - val_loss: 17.5854 - val_MinusLogProbMetric: 17.5854 - lr: 3.3333e-04 - 59s/epoch - 302ms/step
Epoch 393/1000
2023-09-23 22:09:58.786 
Epoch 393/1000 
	 loss: 17.0326, MinusLogProbMetric: 17.0326, val_loss: 17.6097, val_MinusLogProbMetric: 17.6097

Epoch 393: val_loss did not improve from 17.34357
196/196 - 63s - loss: 17.0326 - MinusLogProbMetric: 17.0326 - val_loss: 17.6097 - val_MinusLogProbMetric: 17.6097 - lr: 3.3333e-04 - 63s/epoch - 324ms/step
Epoch 394/1000
2023-09-23 22:10:58.862 
Epoch 394/1000 
	 loss: 17.1391, MinusLogProbMetric: 17.1391, val_loss: 17.4951, val_MinusLogProbMetric: 17.4951

Epoch 394: val_loss did not improve from 17.34357
196/196 - 60s - loss: 17.1391 - MinusLogProbMetric: 17.1391 - val_loss: 17.4951 - val_MinusLogProbMetric: 17.4951 - lr: 3.3333e-04 - 60s/epoch - 306ms/step
Epoch 395/1000
2023-09-23 22:11:58.670 
Epoch 395/1000 
	 loss: 16.9725, MinusLogProbMetric: 16.9725, val_loss: 17.5819, val_MinusLogProbMetric: 17.5819

Epoch 395: val_loss did not improve from 17.34357
196/196 - 60s - loss: 16.9725 - MinusLogProbMetric: 16.9725 - val_loss: 17.5819 - val_MinusLogProbMetric: 17.5819 - lr: 3.3333e-04 - 60s/epoch - 305ms/step
Epoch 396/1000
2023-09-23 22:12:59.958 
Epoch 396/1000 
	 loss: 17.0480, MinusLogProbMetric: 17.0480, val_loss: 17.8097, val_MinusLogProbMetric: 17.8097

Epoch 396: val_loss did not improve from 17.34357
196/196 - 61s - loss: 17.0480 - MinusLogProbMetric: 17.0480 - val_loss: 17.8097 - val_MinusLogProbMetric: 17.8097 - lr: 3.3333e-04 - 61s/epoch - 313ms/step
Epoch 397/1000
2023-09-23 22:14:00.850 
Epoch 397/1000 
	 loss: 17.0942, MinusLogProbMetric: 17.0942, val_loss: 17.6464, val_MinusLogProbMetric: 17.6464

Epoch 397: val_loss did not improve from 17.34357
196/196 - 61s - loss: 17.0942 - MinusLogProbMetric: 17.0942 - val_loss: 17.6464 - val_MinusLogProbMetric: 17.6464 - lr: 3.3333e-04 - 61s/epoch - 311ms/step
Epoch 398/1000
2023-09-23 22:15:02.253 
Epoch 398/1000 
	 loss: 17.0410, MinusLogProbMetric: 17.0410, val_loss: 17.5211, val_MinusLogProbMetric: 17.5211

Epoch 398: val_loss did not improve from 17.34357
196/196 - 61s - loss: 17.0410 - MinusLogProbMetric: 17.0410 - val_loss: 17.5211 - val_MinusLogProbMetric: 17.5211 - lr: 3.3333e-04 - 61s/epoch - 313ms/step
Epoch 399/1000
2023-09-23 22:16:04.117 
Epoch 399/1000 
	 loss: 17.0696, MinusLogProbMetric: 17.0696, val_loss: 18.4514, val_MinusLogProbMetric: 18.4514

Epoch 399: val_loss did not improve from 17.34357
196/196 - 62s - loss: 17.0696 - MinusLogProbMetric: 17.0696 - val_loss: 18.4514 - val_MinusLogProbMetric: 18.4514 - lr: 3.3333e-04 - 62s/epoch - 316ms/step
Epoch 400/1000
2023-09-23 22:17:05.575 
Epoch 400/1000 
	 loss: 17.0558, MinusLogProbMetric: 17.0558, val_loss: 17.4250, val_MinusLogProbMetric: 17.4250

Epoch 400: val_loss did not improve from 17.34357
196/196 - 61s - loss: 17.0558 - MinusLogProbMetric: 17.0558 - val_loss: 17.4250 - val_MinusLogProbMetric: 17.4250 - lr: 3.3333e-04 - 61s/epoch - 314ms/step
Epoch 401/1000
2023-09-23 22:18:06.947 
Epoch 401/1000 
	 loss: 17.0632, MinusLogProbMetric: 17.0632, val_loss: 17.7680, val_MinusLogProbMetric: 17.7680

Epoch 401: val_loss did not improve from 17.34357
196/196 - 61s - loss: 17.0632 - MinusLogProbMetric: 17.0632 - val_loss: 17.7680 - val_MinusLogProbMetric: 17.7680 - lr: 3.3333e-04 - 61s/epoch - 313ms/step
Epoch 402/1000
2023-09-23 22:19:07.989 
Epoch 402/1000 
	 loss: 17.1446, MinusLogProbMetric: 17.1446, val_loss: 17.4087, val_MinusLogProbMetric: 17.4087

Epoch 402: val_loss did not improve from 17.34357
196/196 - 61s - loss: 17.1446 - MinusLogProbMetric: 17.1446 - val_loss: 17.4087 - val_MinusLogProbMetric: 17.4087 - lr: 3.3333e-04 - 61s/epoch - 311ms/step
Epoch 403/1000
2023-09-23 22:20:09.128 
Epoch 403/1000 
	 loss: 17.0386, MinusLogProbMetric: 17.0386, val_loss: 17.3915, val_MinusLogProbMetric: 17.3915

Epoch 403: val_loss did not improve from 17.34357
196/196 - 61s - loss: 17.0386 - MinusLogProbMetric: 17.0386 - val_loss: 17.3915 - val_MinusLogProbMetric: 17.3915 - lr: 3.3333e-04 - 61s/epoch - 312ms/step
Epoch 404/1000
2023-09-23 22:21:10.341 
Epoch 404/1000 
	 loss: 16.9623, MinusLogProbMetric: 16.9623, val_loss: 17.8027, val_MinusLogProbMetric: 17.8027

Epoch 404: val_loss did not improve from 17.34357
196/196 - 61s - loss: 16.9623 - MinusLogProbMetric: 16.9623 - val_loss: 17.8027 - val_MinusLogProbMetric: 17.8027 - lr: 3.3333e-04 - 61s/epoch - 312ms/step
Epoch 405/1000
2023-09-23 22:22:12.307 
Epoch 405/1000 
	 loss: 17.0174, MinusLogProbMetric: 17.0174, val_loss: 17.5724, val_MinusLogProbMetric: 17.5724

Epoch 405: val_loss did not improve from 17.34357
196/196 - 62s - loss: 17.0174 - MinusLogProbMetric: 17.0174 - val_loss: 17.5724 - val_MinusLogProbMetric: 17.5724 - lr: 3.3333e-04 - 62s/epoch - 316ms/step
Epoch 406/1000
2023-09-23 22:23:13.622 
Epoch 406/1000 
	 loss: 17.0524, MinusLogProbMetric: 17.0524, val_loss: 17.4652, val_MinusLogProbMetric: 17.4652

Epoch 406: val_loss did not improve from 17.34357
196/196 - 61s - loss: 17.0524 - MinusLogProbMetric: 17.0524 - val_loss: 17.4652 - val_MinusLogProbMetric: 17.4652 - lr: 3.3333e-04 - 61s/epoch - 313ms/step
Epoch 407/1000
2023-09-23 22:24:15.257 
Epoch 407/1000 
	 loss: 16.9783, MinusLogProbMetric: 16.9783, val_loss: 17.6979, val_MinusLogProbMetric: 17.6979

Epoch 407: val_loss did not improve from 17.34357
196/196 - 62s - loss: 16.9783 - MinusLogProbMetric: 16.9783 - val_loss: 17.6979 - val_MinusLogProbMetric: 17.6979 - lr: 3.3333e-04 - 62s/epoch - 314ms/step
Epoch 408/1000
2023-09-23 22:25:16.768 
Epoch 408/1000 
	 loss: 17.0110, MinusLogProbMetric: 17.0110, val_loss: 17.8509, val_MinusLogProbMetric: 17.8509

Epoch 408: val_loss did not improve from 17.34357
196/196 - 62s - loss: 17.0110 - MinusLogProbMetric: 17.0110 - val_loss: 17.8509 - val_MinusLogProbMetric: 17.8509 - lr: 3.3333e-04 - 62s/epoch - 314ms/step
Epoch 409/1000
2023-09-23 22:26:18.844 
Epoch 409/1000 
	 loss: 17.0060, MinusLogProbMetric: 17.0060, val_loss: 17.3558, val_MinusLogProbMetric: 17.3558

Epoch 409: val_loss did not improve from 17.34357
196/196 - 62s - loss: 17.0060 - MinusLogProbMetric: 17.0060 - val_loss: 17.3558 - val_MinusLogProbMetric: 17.3558 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 410/1000
2023-09-23 22:27:20.050 
Epoch 410/1000 
	 loss: 17.0749, MinusLogProbMetric: 17.0749, val_loss: 17.7687, val_MinusLogProbMetric: 17.7687

Epoch 410: val_loss did not improve from 17.34357
196/196 - 61s - loss: 17.0749 - MinusLogProbMetric: 17.0749 - val_loss: 17.7687 - val_MinusLogProbMetric: 17.7687 - lr: 3.3333e-04 - 61s/epoch - 312ms/step
Epoch 411/1000
2023-09-23 22:28:20.196 
Epoch 411/1000 
	 loss: 17.0059, MinusLogProbMetric: 17.0059, val_loss: 18.7119, val_MinusLogProbMetric: 18.7119

Epoch 411: val_loss did not improve from 17.34357
196/196 - 60s - loss: 17.0059 - MinusLogProbMetric: 17.0059 - val_loss: 18.7119 - val_MinusLogProbMetric: 18.7119 - lr: 3.3333e-04 - 60s/epoch - 307ms/step
Epoch 412/1000
2023-09-23 22:29:21.752 
Epoch 412/1000 
	 loss: 17.0398, MinusLogProbMetric: 17.0398, val_loss: 17.4481, val_MinusLogProbMetric: 17.4481

Epoch 412: val_loss did not improve from 17.34357
196/196 - 62s - loss: 17.0398 - MinusLogProbMetric: 17.0398 - val_loss: 17.4481 - val_MinusLogProbMetric: 17.4481 - lr: 3.3333e-04 - 62s/epoch - 314ms/step
Epoch 413/1000
2023-09-23 22:30:22.557 
Epoch 413/1000 
	 loss: 17.0129, MinusLogProbMetric: 17.0129, val_loss: 17.6393, val_MinusLogProbMetric: 17.6393

Epoch 413: val_loss did not improve from 17.34357
196/196 - 61s - loss: 17.0129 - MinusLogProbMetric: 17.0129 - val_loss: 17.6393 - val_MinusLogProbMetric: 17.6393 - lr: 3.3333e-04 - 61s/epoch - 310ms/step
Epoch 414/1000
2023-09-23 22:31:24.662 
Epoch 414/1000 
	 loss: 16.9453, MinusLogProbMetric: 16.9453, val_loss: 17.4112, val_MinusLogProbMetric: 17.4112

Epoch 414: val_loss did not improve from 17.34357
196/196 - 62s - loss: 16.9453 - MinusLogProbMetric: 16.9453 - val_loss: 17.4112 - val_MinusLogProbMetric: 17.4112 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 415/1000
2023-09-23 22:32:26.513 
Epoch 415/1000 
	 loss: 16.9951, MinusLogProbMetric: 16.9951, val_loss: 18.2480, val_MinusLogProbMetric: 18.2480

Epoch 415: val_loss did not improve from 17.34357
196/196 - 62s - loss: 16.9951 - MinusLogProbMetric: 16.9951 - val_loss: 18.2480 - val_MinusLogProbMetric: 18.2480 - lr: 3.3333e-04 - 62s/epoch - 316ms/step
Epoch 416/1000
2023-09-23 22:33:26.659 
Epoch 416/1000 
	 loss: 17.0671, MinusLogProbMetric: 17.0671, val_loss: 17.8420, val_MinusLogProbMetric: 17.8420

Epoch 416: val_loss did not improve from 17.34357
196/196 - 60s - loss: 17.0671 - MinusLogProbMetric: 17.0671 - val_loss: 17.8420 - val_MinusLogProbMetric: 17.8420 - lr: 3.3333e-04 - 60s/epoch - 307ms/step
Epoch 417/1000
2023-09-23 22:34:26.982 
Epoch 417/1000 
	 loss: 16.9515, MinusLogProbMetric: 16.9515, val_loss: 17.6583, val_MinusLogProbMetric: 17.6583

Epoch 417: val_loss did not improve from 17.34357
196/196 - 60s - loss: 16.9515 - MinusLogProbMetric: 16.9515 - val_loss: 17.6583 - val_MinusLogProbMetric: 17.6583 - lr: 3.3333e-04 - 60s/epoch - 308ms/step
Epoch 418/1000
2023-09-23 22:35:29.137 
Epoch 418/1000 
	 loss: 16.9593, MinusLogProbMetric: 16.9593, val_loss: 18.6523, val_MinusLogProbMetric: 18.6523

Epoch 418: val_loss did not improve from 17.34357
196/196 - 62s - loss: 16.9593 - MinusLogProbMetric: 16.9593 - val_loss: 18.6523 - val_MinusLogProbMetric: 18.6523 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 419/1000
2023-09-23 22:36:31.071 
Epoch 419/1000 
	 loss: 17.1360, MinusLogProbMetric: 17.1360, val_loss: 17.5147, val_MinusLogProbMetric: 17.5147

Epoch 419: val_loss did not improve from 17.34357
196/196 - 62s - loss: 17.1360 - MinusLogProbMetric: 17.1360 - val_loss: 17.5147 - val_MinusLogProbMetric: 17.5147 - lr: 3.3333e-04 - 62s/epoch - 316ms/step
Epoch 420/1000
2023-09-23 22:37:32.327 
Epoch 420/1000 
	 loss: 17.0161, MinusLogProbMetric: 17.0161, val_loss: 17.7038, val_MinusLogProbMetric: 17.7038

Epoch 420: val_loss did not improve from 17.34357
196/196 - 61s - loss: 17.0161 - MinusLogProbMetric: 17.0161 - val_loss: 17.7038 - val_MinusLogProbMetric: 17.7038 - lr: 3.3333e-04 - 61s/epoch - 313ms/step
Epoch 421/1000
2023-09-23 22:38:34.453 
Epoch 421/1000 
	 loss: 16.9757, MinusLogProbMetric: 16.9757, val_loss: 17.4447, val_MinusLogProbMetric: 17.4447

Epoch 421: val_loss did not improve from 17.34357
196/196 - 62s - loss: 16.9757 - MinusLogProbMetric: 16.9757 - val_loss: 17.4447 - val_MinusLogProbMetric: 17.4447 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 422/1000
2023-09-23 22:39:35.603 
Epoch 422/1000 
	 loss: 16.9808, MinusLogProbMetric: 16.9808, val_loss: 17.6890, val_MinusLogProbMetric: 17.6890

Epoch 422: val_loss did not improve from 17.34357
196/196 - 61s - loss: 16.9808 - MinusLogProbMetric: 16.9808 - val_loss: 17.6890 - val_MinusLogProbMetric: 17.6890 - lr: 3.3333e-04 - 61s/epoch - 312ms/step
Epoch 423/1000
2023-09-23 22:40:35.271 
Epoch 423/1000 
	 loss: 17.0683, MinusLogProbMetric: 17.0683, val_loss: 17.7688, val_MinusLogProbMetric: 17.7688

Epoch 423: val_loss did not improve from 17.34357
196/196 - 60s - loss: 17.0683 - MinusLogProbMetric: 17.0683 - val_loss: 17.7688 - val_MinusLogProbMetric: 17.7688 - lr: 3.3333e-04 - 60s/epoch - 304ms/step
Epoch 424/1000
2023-09-23 22:41:37.598 
Epoch 424/1000 
	 loss: 16.9887, MinusLogProbMetric: 16.9887, val_loss: 17.5542, val_MinusLogProbMetric: 17.5542

Epoch 424: val_loss did not improve from 17.34357
196/196 - 62s - loss: 16.9887 - MinusLogProbMetric: 16.9887 - val_loss: 17.5542 - val_MinusLogProbMetric: 17.5542 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 425/1000
2023-09-23 22:42:39.177 
Epoch 425/1000 
	 loss: 16.9412, MinusLogProbMetric: 16.9412, val_loss: 17.8088, val_MinusLogProbMetric: 17.8088

Epoch 425: val_loss did not improve from 17.34357
196/196 - 62s - loss: 16.9412 - MinusLogProbMetric: 16.9412 - val_loss: 17.8088 - val_MinusLogProbMetric: 17.8088 - lr: 3.3333e-04 - 62s/epoch - 314ms/step
Epoch 426/1000
2023-09-23 22:43:41.285 
Epoch 426/1000 
	 loss: 17.0424, MinusLogProbMetric: 17.0424, val_loss: 17.3888, val_MinusLogProbMetric: 17.3888

Epoch 426: val_loss did not improve from 17.34357
196/196 - 62s - loss: 17.0424 - MinusLogProbMetric: 17.0424 - val_loss: 17.3888 - val_MinusLogProbMetric: 17.3888 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 427/1000
2023-09-23 22:44:42.709 
Epoch 427/1000 
	 loss: 17.0326, MinusLogProbMetric: 17.0326, val_loss: 17.5986, val_MinusLogProbMetric: 17.5986

Epoch 427: val_loss did not improve from 17.34357
196/196 - 61s - loss: 17.0326 - MinusLogProbMetric: 17.0326 - val_loss: 17.5986 - val_MinusLogProbMetric: 17.5986 - lr: 3.3333e-04 - 61s/epoch - 313ms/step
Epoch 428/1000
2023-09-23 22:45:44.225 
Epoch 428/1000 
	 loss: 16.9740, MinusLogProbMetric: 16.9740, val_loss: 17.3619, val_MinusLogProbMetric: 17.3619

Epoch 428: val_loss did not improve from 17.34357
196/196 - 62s - loss: 16.9740 - MinusLogProbMetric: 16.9740 - val_loss: 17.3619 - val_MinusLogProbMetric: 17.3619 - lr: 3.3333e-04 - 62s/epoch - 314ms/step
Epoch 429/1000
2023-09-23 22:46:46.253 
Epoch 429/1000 
	 loss: 16.9739, MinusLogProbMetric: 16.9739, val_loss: 17.4452, val_MinusLogProbMetric: 17.4452

Epoch 429: val_loss did not improve from 17.34357
196/196 - 62s - loss: 16.9739 - MinusLogProbMetric: 16.9739 - val_loss: 17.4452 - val_MinusLogProbMetric: 17.4452 - lr: 3.3333e-04 - 62s/epoch - 316ms/step
Epoch 430/1000
2023-09-23 22:47:48.309 
Epoch 430/1000 
	 loss: 16.9365, MinusLogProbMetric: 16.9365, val_loss: 17.5928, val_MinusLogProbMetric: 17.5928

Epoch 430: val_loss did not improve from 17.34357
196/196 - 62s - loss: 16.9365 - MinusLogProbMetric: 16.9365 - val_loss: 17.5928 - val_MinusLogProbMetric: 17.5928 - lr: 3.3333e-04 - 62s/epoch - 317ms/step
Epoch 431/1000
2023-09-23 22:48:49.288 
Epoch 431/1000 
	 loss: 16.9939, MinusLogProbMetric: 16.9939, val_loss: 17.6314, val_MinusLogProbMetric: 17.6314

Epoch 431: val_loss did not improve from 17.34357
196/196 - 61s - loss: 16.9939 - MinusLogProbMetric: 16.9939 - val_loss: 17.6314 - val_MinusLogProbMetric: 17.6314 - lr: 3.3333e-04 - 61s/epoch - 311ms/step
Epoch 432/1000
2023-09-23 22:49:50.792 
Epoch 432/1000 
	 loss: 16.9557, MinusLogProbMetric: 16.9557, val_loss: 17.4379, val_MinusLogProbMetric: 17.4379

Epoch 432: val_loss did not improve from 17.34357
196/196 - 62s - loss: 16.9557 - MinusLogProbMetric: 16.9557 - val_loss: 17.4379 - val_MinusLogProbMetric: 17.4379 - lr: 3.3333e-04 - 62s/epoch - 314ms/step
Epoch 433/1000
2023-09-23 22:50:52.798 
Epoch 433/1000 
	 loss: 16.5221, MinusLogProbMetric: 16.5221, val_loss: 17.2878, val_MinusLogProbMetric: 17.2878

Epoch 433: val_loss improved from 17.34357 to 17.28782, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 63s - loss: 16.5221 - MinusLogProbMetric: 16.5221 - val_loss: 17.2878 - val_MinusLogProbMetric: 17.2878 - lr: 1.6667e-04 - 63s/epoch - 321ms/step
Epoch 434/1000
2023-09-23 22:51:54.346 
Epoch 434/1000 
	 loss: 16.5174, MinusLogProbMetric: 16.5174, val_loss: 17.1739, val_MinusLogProbMetric: 17.1739

Epoch 434: val_loss improved from 17.28782 to 17.17390, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 62s - loss: 16.5174 - MinusLogProbMetric: 16.5174 - val_loss: 17.1739 - val_MinusLogProbMetric: 17.1739 - lr: 1.6667e-04 - 62s/epoch - 315ms/step
Epoch 435/1000
2023-09-23 22:52:57.070 
Epoch 435/1000 
	 loss: 16.5869, MinusLogProbMetric: 16.5869, val_loss: 17.2611, val_MinusLogProbMetric: 17.2611

Epoch 435: val_loss did not improve from 17.17390
196/196 - 62s - loss: 16.5869 - MinusLogProbMetric: 16.5869 - val_loss: 17.2611 - val_MinusLogProbMetric: 17.2611 - lr: 1.6667e-04 - 62s/epoch - 315ms/step
Epoch 436/1000
2023-09-23 22:53:58.240 
Epoch 436/1000 
	 loss: 16.5620, MinusLogProbMetric: 16.5620, val_loss: 17.3917, val_MinusLogProbMetric: 17.3917

Epoch 436: val_loss did not improve from 17.17390
196/196 - 61s - loss: 16.5620 - MinusLogProbMetric: 16.5620 - val_loss: 17.3917 - val_MinusLogProbMetric: 17.3917 - lr: 1.6667e-04 - 61s/epoch - 312ms/step
Epoch 437/1000
2023-09-23 22:54:57.747 
Epoch 437/1000 
	 loss: 16.5720, MinusLogProbMetric: 16.5720, val_loss: 17.1511, val_MinusLogProbMetric: 17.1511

Epoch 437: val_loss improved from 17.17390 to 17.15111, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 61s - loss: 16.5720 - MinusLogProbMetric: 16.5720 - val_loss: 17.1511 - val_MinusLogProbMetric: 17.1511 - lr: 1.6667e-04 - 61s/epoch - 309ms/step
Epoch 438/1000
2023-09-23 22:55:59.630 
Epoch 438/1000 
	 loss: 16.5373, MinusLogProbMetric: 16.5373, val_loss: 17.3681, val_MinusLogProbMetric: 17.3681

Epoch 438: val_loss did not improve from 17.15111
196/196 - 61s - loss: 16.5373 - MinusLogProbMetric: 16.5373 - val_loss: 17.3681 - val_MinusLogProbMetric: 17.3681 - lr: 1.6667e-04 - 61s/epoch - 310ms/step
Epoch 439/1000
2023-09-23 22:57:01.281 
Epoch 439/1000 
	 loss: 16.5545, MinusLogProbMetric: 16.5545, val_loss: 17.2320, val_MinusLogProbMetric: 17.2320

Epoch 439: val_loss did not improve from 17.15111
196/196 - 62s - loss: 16.5545 - MinusLogProbMetric: 16.5545 - val_loss: 17.2320 - val_MinusLogProbMetric: 17.2320 - lr: 1.6667e-04 - 62s/epoch - 315ms/step
Epoch 440/1000
2023-09-23 22:58:02.034 
Epoch 440/1000 
	 loss: 16.5444, MinusLogProbMetric: 16.5444, val_loss: 17.4884, val_MinusLogProbMetric: 17.4884

Epoch 440: val_loss did not improve from 17.15111
196/196 - 61s - loss: 16.5444 - MinusLogProbMetric: 16.5444 - val_loss: 17.4884 - val_MinusLogProbMetric: 17.4884 - lr: 1.6667e-04 - 61s/epoch - 310ms/step
Epoch 441/1000
2023-09-23 22:59:02.938 
Epoch 441/1000 
	 loss: 16.5879, MinusLogProbMetric: 16.5879, val_loss: 17.2151, val_MinusLogProbMetric: 17.2151

Epoch 441: val_loss did not improve from 17.15111
196/196 - 61s - loss: 16.5879 - MinusLogProbMetric: 16.5879 - val_loss: 17.2151 - val_MinusLogProbMetric: 17.2151 - lr: 1.6667e-04 - 61s/epoch - 311ms/step
Epoch 442/1000
2023-09-23 23:00:04.578 
Epoch 442/1000 
	 loss: 16.5567, MinusLogProbMetric: 16.5567, val_loss: 17.2270, val_MinusLogProbMetric: 17.2270

Epoch 442: val_loss did not improve from 17.15111
196/196 - 62s - loss: 16.5567 - MinusLogProbMetric: 16.5567 - val_loss: 17.2270 - val_MinusLogProbMetric: 17.2270 - lr: 1.6667e-04 - 62s/epoch - 314ms/step
Epoch 443/1000
2023-09-23 23:01:05.781 
Epoch 443/1000 
	 loss: 16.5824, MinusLogProbMetric: 16.5824, val_loss: 17.3669, val_MinusLogProbMetric: 17.3669

Epoch 443: val_loss did not improve from 17.15111
196/196 - 61s - loss: 16.5824 - MinusLogProbMetric: 16.5824 - val_loss: 17.3669 - val_MinusLogProbMetric: 17.3669 - lr: 1.6667e-04 - 61s/epoch - 312ms/step
Epoch 444/1000
2023-09-23 23:02:07.305 
Epoch 444/1000 
	 loss: 16.5343, MinusLogProbMetric: 16.5343, val_loss: 17.1562, val_MinusLogProbMetric: 17.1562

Epoch 444: val_loss did not improve from 17.15111
196/196 - 62s - loss: 16.5343 - MinusLogProbMetric: 16.5343 - val_loss: 17.1562 - val_MinusLogProbMetric: 17.1562 - lr: 1.6667e-04 - 62s/epoch - 314ms/step
Epoch 445/1000
2023-09-23 23:03:09.177 
Epoch 445/1000 
	 loss: 16.5415, MinusLogProbMetric: 16.5415, val_loss: 17.5857, val_MinusLogProbMetric: 17.5857

Epoch 445: val_loss did not improve from 17.15111
196/196 - 62s - loss: 16.5415 - MinusLogProbMetric: 16.5415 - val_loss: 17.5857 - val_MinusLogProbMetric: 17.5857 - lr: 1.6667e-04 - 62s/epoch - 316ms/step
Epoch 446/1000
2023-09-23 23:04:10.297 
Epoch 446/1000 
	 loss: 16.5798, MinusLogProbMetric: 16.5798, val_loss: 17.1592, val_MinusLogProbMetric: 17.1592

Epoch 446: val_loss did not improve from 17.15111
196/196 - 61s - loss: 16.5798 - MinusLogProbMetric: 16.5798 - val_loss: 17.1592 - val_MinusLogProbMetric: 17.1592 - lr: 1.6667e-04 - 61s/epoch - 312ms/step
Epoch 447/1000
2023-09-23 23:05:12.068 
Epoch 447/1000 
	 loss: 16.5590, MinusLogProbMetric: 16.5590, val_loss: 17.2023, val_MinusLogProbMetric: 17.2023

Epoch 447: val_loss did not improve from 17.15111
196/196 - 62s - loss: 16.5590 - MinusLogProbMetric: 16.5590 - val_loss: 17.2023 - val_MinusLogProbMetric: 17.2023 - lr: 1.6667e-04 - 62s/epoch - 315ms/step
Epoch 448/1000
2023-09-23 23:06:13.492 
Epoch 448/1000 
	 loss: 16.5298, MinusLogProbMetric: 16.5298, val_loss: 17.2820, val_MinusLogProbMetric: 17.2820

Epoch 448: val_loss did not improve from 17.15111
196/196 - 61s - loss: 16.5298 - MinusLogProbMetric: 16.5298 - val_loss: 17.2820 - val_MinusLogProbMetric: 17.2820 - lr: 1.6667e-04 - 61s/epoch - 313ms/step
Epoch 449/1000
2023-09-23 23:07:15.344 
Epoch 449/1000 
	 loss: 16.5877, MinusLogProbMetric: 16.5877, val_loss: 17.4592, val_MinusLogProbMetric: 17.4592

Epoch 449: val_loss did not improve from 17.15111
196/196 - 62s - loss: 16.5877 - MinusLogProbMetric: 16.5877 - val_loss: 17.4592 - val_MinusLogProbMetric: 17.4592 - lr: 1.6667e-04 - 62s/epoch - 316ms/step
Epoch 450/1000
2023-09-23 23:08:16.763 
Epoch 450/1000 
	 loss: 16.5143, MinusLogProbMetric: 16.5143, val_loss: 17.2754, val_MinusLogProbMetric: 17.2754

Epoch 450: val_loss did not improve from 17.15111
196/196 - 61s - loss: 16.5143 - MinusLogProbMetric: 16.5143 - val_loss: 17.2754 - val_MinusLogProbMetric: 17.2754 - lr: 1.6667e-04 - 61s/epoch - 313ms/step
Epoch 451/1000
2023-09-23 23:09:18.147 
Epoch 451/1000 
	 loss: 16.5653, MinusLogProbMetric: 16.5653, val_loss: 17.3801, val_MinusLogProbMetric: 17.3801

Epoch 451: val_loss did not improve from 17.15111
196/196 - 61s - loss: 16.5653 - MinusLogProbMetric: 16.5653 - val_loss: 17.3801 - val_MinusLogProbMetric: 17.3801 - lr: 1.6667e-04 - 61s/epoch - 313ms/step
Epoch 452/1000
2023-09-23 23:10:19.426 
Epoch 452/1000 
	 loss: 16.5419, MinusLogProbMetric: 16.5419, val_loss: 17.1559, val_MinusLogProbMetric: 17.1559

Epoch 452: val_loss did not improve from 17.15111
196/196 - 61s - loss: 16.5419 - MinusLogProbMetric: 16.5419 - val_loss: 17.1559 - val_MinusLogProbMetric: 17.1559 - lr: 1.6667e-04 - 61s/epoch - 313ms/step
Epoch 453/1000
2023-09-23 23:11:20.995 
Epoch 453/1000 
	 loss: 16.5240, MinusLogProbMetric: 16.5240, val_loss: 17.1838, val_MinusLogProbMetric: 17.1838

Epoch 453: val_loss did not improve from 17.15111
196/196 - 62s - loss: 16.5240 - MinusLogProbMetric: 16.5240 - val_loss: 17.1838 - val_MinusLogProbMetric: 17.1838 - lr: 1.6667e-04 - 62s/epoch - 314ms/step
Epoch 454/1000
2023-09-23 23:12:22.935 
Epoch 454/1000 
	 loss: 16.5534, MinusLogProbMetric: 16.5534, val_loss: 17.2363, val_MinusLogProbMetric: 17.2363

Epoch 454: val_loss did not improve from 17.15111
196/196 - 62s - loss: 16.5534 - MinusLogProbMetric: 16.5534 - val_loss: 17.2363 - val_MinusLogProbMetric: 17.2363 - lr: 1.6667e-04 - 62s/epoch - 316ms/step
Epoch 455/1000
2023-09-23 23:13:23.060 
Epoch 455/1000 
	 loss: 16.4966, MinusLogProbMetric: 16.4966, val_loss: 17.5830, val_MinusLogProbMetric: 17.5830

Epoch 455: val_loss did not improve from 17.15111
196/196 - 60s - loss: 16.4966 - MinusLogProbMetric: 16.4966 - val_loss: 17.5830 - val_MinusLogProbMetric: 17.5830 - lr: 1.6667e-04 - 60s/epoch - 307ms/step
Epoch 456/1000
2023-09-23 23:14:21.675 
Epoch 456/1000 
	 loss: 16.5476, MinusLogProbMetric: 16.5476, val_loss: 17.3221, val_MinusLogProbMetric: 17.3221

Epoch 456: val_loss did not improve from 17.15111
196/196 - 59s - loss: 16.5476 - MinusLogProbMetric: 16.5476 - val_loss: 17.3221 - val_MinusLogProbMetric: 17.3221 - lr: 1.6667e-04 - 59s/epoch - 299ms/step
Epoch 457/1000
2023-09-23 23:15:23.385 
Epoch 457/1000 
	 loss: 16.5193, MinusLogProbMetric: 16.5193, val_loss: 17.4509, val_MinusLogProbMetric: 17.4509

Epoch 457: val_loss did not improve from 17.15111
196/196 - 62s - loss: 16.5193 - MinusLogProbMetric: 16.5193 - val_loss: 17.4509 - val_MinusLogProbMetric: 17.4509 - lr: 1.6667e-04 - 62s/epoch - 315ms/step
Epoch 458/1000
2023-09-23 23:16:24.478 
Epoch 458/1000 
	 loss: 16.5762, MinusLogProbMetric: 16.5762, val_loss: 17.3245, val_MinusLogProbMetric: 17.3245

Epoch 458: val_loss did not improve from 17.15111
196/196 - 61s - loss: 16.5762 - MinusLogProbMetric: 16.5762 - val_loss: 17.3245 - val_MinusLogProbMetric: 17.3245 - lr: 1.6667e-04 - 61s/epoch - 312ms/step
Epoch 459/1000
2023-09-23 23:17:25.962 
Epoch 459/1000 
	 loss: 16.5411, MinusLogProbMetric: 16.5411, val_loss: 17.2726, val_MinusLogProbMetric: 17.2726

Epoch 459: val_loss did not improve from 17.15111
196/196 - 61s - loss: 16.5411 - MinusLogProbMetric: 16.5411 - val_loss: 17.2726 - val_MinusLogProbMetric: 17.2726 - lr: 1.6667e-04 - 61s/epoch - 314ms/step
Epoch 460/1000
2023-09-23 23:18:26.616 
Epoch 460/1000 
	 loss: 16.5636, MinusLogProbMetric: 16.5636, val_loss: 17.4593, val_MinusLogProbMetric: 17.4593

Epoch 460: val_loss did not improve from 17.15111
196/196 - 61s - loss: 16.5636 - MinusLogProbMetric: 16.5636 - val_loss: 17.4593 - val_MinusLogProbMetric: 17.4593 - lr: 1.6667e-04 - 61s/epoch - 309ms/step
Epoch 461/1000
2023-09-23 23:19:25.270 
Epoch 461/1000 
	 loss: 16.5534, MinusLogProbMetric: 16.5534, val_loss: 17.1129, val_MinusLogProbMetric: 17.1129

Epoch 461: val_loss improved from 17.15111 to 17.11288, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 60s - loss: 16.5534 - MinusLogProbMetric: 16.5534 - val_loss: 17.1129 - val_MinusLogProbMetric: 17.1129 - lr: 1.6667e-04 - 60s/epoch - 304ms/step
Epoch 462/1000
2023-09-23 23:20:26.960 
Epoch 462/1000 
	 loss: 16.4926, MinusLogProbMetric: 16.4926, val_loss: 17.1696, val_MinusLogProbMetric: 17.1696

Epoch 462: val_loss did not improve from 17.11288
196/196 - 61s - loss: 16.4926 - MinusLogProbMetric: 16.4926 - val_loss: 17.1696 - val_MinusLogProbMetric: 17.1696 - lr: 1.6667e-04 - 61s/epoch - 310ms/step
Epoch 463/1000
2023-09-23 23:21:28.721 
Epoch 463/1000 
	 loss: 16.5574, MinusLogProbMetric: 16.5574, val_loss: 17.4640, val_MinusLogProbMetric: 17.4640

Epoch 463: val_loss did not improve from 17.11288
196/196 - 62s - loss: 16.5574 - MinusLogProbMetric: 16.5574 - val_loss: 17.4640 - val_MinusLogProbMetric: 17.4640 - lr: 1.6667e-04 - 62s/epoch - 315ms/step
Epoch 464/1000
2023-09-23 23:22:30.006 
Epoch 464/1000 
	 loss: 16.5332, MinusLogProbMetric: 16.5332, val_loss: 17.2520, val_MinusLogProbMetric: 17.2520

Epoch 464: val_loss did not improve from 17.11288
196/196 - 61s - loss: 16.5332 - MinusLogProbMetric: 16.5332 - val_loss: 17.2520 - val_MinusLogProbMetric: 17.2520 - lr: 1.6667e-04 - 61s/epoch - 313ms/step
Epoch 465/1000
2023-09-23 23:23:33.148 
Epoch 465/1000 
	 loss: 16.5265, MinusLogProbMetric: 16.5265, val_loss: 17.4844, val_MinusLogProbMetric: 17.4844

Epoch 465: val_loss did not improve from 17.11288
196/196 - 63s - loss: 16.5265 - MinusLogProbMetric: 16.5265 - val_loss: 17.4844 - val_MinusLogProbMetric: 17.4844 - lr: 1.6667e-04 - 63s/epoch - 322ms/step
Epoch 466/1000
2023-09-23 23:24:34.337 
Epoch 466/1000 
	 loss: 16.5100, MinusLogProbMetric: 16.5100, val_loss: 17.1527, val_MinusLogProbMetric: 17.1527

Epoch 466: val_loss did not improve from 17.11288
196/196 - 61s - loss: 16.5100 - MinusLogProbMetric: 16.5100 - val_loss: 17.1527 - val_MinusLogProbMetric: 17.1527 - lr: 1.6667e-04 - 61s/epoch - 312ms/step
Epoch 467/1000
2023-09-23 23:25:35.074 
Epoch 467/1000 
	 loss: 16.5508, MinusLogProbMetric: 16.5508, val_loss: 17.3684, val_MinusLogProbMetric: 17.3684

Epoch 467: val_loss did not improve from 17.11288
196/196 - 61s - loss: 16.5508 - MinusLogProbMetric: 16.5508 - val_loss: 17.3684 - val_MinusLogProbMetric: 17.3684 - lr: 1.6667e-04 - 61s/epoch - 310ms/step
Epoch 468/1000
2023-09-23 23:26:35.942 
Epoch 468/1000 
	 loss: 16.5422, MinusLogProbMetric: 16.5422, val_loss: 17.2062, val_MinusLogProbMetric: 17.2062

Epoch 468: val_loss did not improve from 17.11288
196/196 - 61s - loss: 16.5422 - MinusLogProbMetric: 16.5422 - val_loss: 17.2062 - val_MinusLogProbMetric: 17.2062 - lr: 1.6667e-04 - 61s/epoch - 311ms/step
Epoch 469/1000
2023-09-23 23:27:37.564 
Epoch 469/1000 
	 loss: 16.5451, MinusLogProbMetric: 16.5451, val_loss: 17.2327, val_MinusLogProbMetric: 17.2327

Epoch 469: val_loss did not improve from 17.11288
196/196 - 62s - loss: 16.5451 - MinusLogProbMetric: 16.5451 - val_loss: 17.2327 - val_MinusLogProbMetric: 17.2327 - lr: 1.6667e-04 - 62s/epoch - 314ms/step
Epoch 470/1000
2023-09-23 23:28:38.152 
Epoch 470/1000 
	 loss: 16.5149, MinusLogProbMetric: 16.5149, val_loss: 17.1454, val_MinusLogProbMetric: 17.1454

Epoch 470: val_loss did not improve from 17.11288
196/196 - 61s - loss: 16.5149 - MinusLogProbMetric: 16.5149 - val_loss: 17.1454 - val_MinusLogProbMetric: 17.1454 - lr: 1.6667e-04 - 61s/epoch - 309ms/step
Epoch 471/1000
2023-09-23 23:29:37.971 
Epoch 471/1000 
	 loss: 16.5099, MinusLogProbMetric: 16.5099, val_loss: 17.2182, val_MinusLogProbMetric: 17.2182

Epoch 471: val_loss did not improve from 17.11288
196/196 - 60s - loss: 16.5099 - MinusLogProbMetric: 16.5099 - val_loss: 17.2182 - val_MinusLogProbMetric: 17.2182 - lr: 1.6667e-04 - 60s/epoch - 305ms/step
Epoch 472/1000
2023-09-23 23:30:39.091 
Epoch 472/1000 
	 loss: 16.5529, MinusLogProbMetric: 16.5529, val_loss: 17.1789, val_MinusLogProbMetric: 17.1789

Epoch 472: val_loss did not improve from 17.11288
196/196 - 61s - loss: 16.5529 - MinusLogProbMetric: 16.5529 - val_loss: 17.1789 - val_MinusLogProbMetric: 17.1789 - lr: 1.6667e-04 - 61s/epoch - 312ms/step
Epoch 473/1000
2023-09-23 23:31:41.102 
Epoch 473/1000 
	 loss: 16.5634, MinusLogProbMetric: 16.5634, val_loss: 17.3464, val_MinusLogProbMetric: 17.3464

Epoch 473: val_loss did not improve from 17.11288
196/196 - 62s - loss: 16.5634 - MinusLogProbMetric: 16.5634 - val_loss: 17.3464 - val_MinusLogProbMetric: 17.3464 - lr: 1.6667e-04 - 62s/epoch - 316ms/step
Epoch 474/1000
2023-09-23 23:32:41.150 
Epoch 474/1000 
	 loss: 16.5234, MinusLogProbMetric: 16.5234, val_loss: 17.3712, val_MinusLogProbMetric: 17.3712

Epoch 474: val_loss did not improve from 17.11288
196/196 - 60s - loss: 16.5234 - MinusLogProbMetric: 16.5234 - val_loss: 17.3712 - val_MinusLogProbMetric: 17.3712 - lr: 1.6667e-04 - 60s/epoch - 306ms/step
Epoch 475/1000
2023-09-23 23:33:42.669 
Epoch 475/1000 
	 loss: 16.5241, MinusLogProbMetric: 16.5241, val_loss: 17.4750, val_MinusLogProbMetric: 17.4750

Epoch 475: val_loss did not improve from 17.11288
196/196 - 62s - loss: 16.5241 - MinusLogProbMetric: 16.5241 - val_loss: 17.4750 - val_MinusLogProbMetric: 17.4750 - lr: 1.6667e-04 - 62s/epoch - 314ms/step
Epoch 476/1000
2023-09-23 23:34:43.314 
Epoch 476/1000 
	 loss: 16.5397, MinusLogProbMetric: 16.5397, val_loss: 17.5489, val_MinusLogProbMetric: 17.5489

Epoch 476: val_loss did not improve from 17.11288
196/196 - 61s - loss: 16.5397 - MinusLogProbMetric: 16.5397 - val_loss: 17.5489 - val_MinusLogProbMetric: 17.5489 - lr: 1.6667e-04 - 61s/epoch - 309ms/step
Epoch 477/1000
2023-09-23 23:35:45.682 
Epoch 477/1000 
	 loss: 16.5386, MinusLogProbMetric: 16.5386, val_loss: 17.5245, val_MinusLogProbMetric: 17.5245

Epoch 477: val_loss did not improve from 17.11288
196/196 - 62s - loss: 16.5386 - MinusLogProbMetric: 16.5386 - val_loss: 17.5245 - val_MinusLogProbMetric: 17.5245 - lr: 1.6667e-04 - 62s/epoch - 318ms/step
Epoch 478/1000
2023-09-23 23:36:49.532 
Epoch 478/1000 
	 loss: 16.5032, MinusLogProbMetric: 16.5032, val_loss: 17.2021, val_MinusLogProbMetric: 17.2021

Epoch 478: val_loss did not improve from 17.11288
196/196 - 64s - loss: 16.5032 - MinusLogProbMetric: 16.5032 - val_loss: 17.2021 - val_MinusLogProbMetric: 17.2021 - lr: 1.6667e-04 - 64s/epoch - 326ms/step
Epoch 479/1000
2023-09-23 23:37:49.606 
Epoch 479/1000 
	 loss: 16.5222, MinusLogProbMetric: 16.5222, val_loss: 17.5116, val_MinusLogProbMetric: 17.5116

Epoch 479: val_loss did not improve from 17.11288
196/196 - 60s - loss: 16.5222 - MinusLogProbMetric: 16.5222 - val_loss: 17.5116 - val_MinusLogProbMetric: 17.5116 - lr: 1.6667e-04 - 60s/epoch - 306ms/step
Epoch 480/1000
2023-09-23 23:38:50.737 
Epoch 480/1000 
	 loss: 16.5342, MinusLogProbMetric: 16.5342, val_loss: 17.1649, val_MinusLogProbMetric: 17.1649

Epoch 480: val_loss did not improve from 17.11288
196/196 - 61s - loss: 16.5342 - MinusLogProbMetric: 16.5342 - val_loss: 17.1649 - val_MinusLogProbMetric: 17.1649 - lr: 1.6667e-04 - 61s/epoch - 312ms/step
Epoch 481/1000
2023-09-23 23:39:51.141 
Epoch 481/1000 
	 loss: 16.5101, MinusLogProbMetric: 16.5101, val_loss: 17.2021, val_MinusLogProbMetric: 17.2021

Epoch 481: val_loss did not improve from 17.11288
196/196 - 60s - loss: 16.5101 - MinusLogProbMetric: 16.5101 - val_loss: 17.2021 - val_MinusLogProbMetric: 17.2021 - lr: 1.6667e-04 - 60s/epoch - 308ms/step
Epoch 482/1000
2023-09-23 23:40:51.873 
Epoch 482/1000 
	 loss: 16.5035, MinusLogProbMetric: 16.5035, val_loss: 17.1987, val_MinusLogProbMetric: 17.1987

Epoch 482: val_loss did not improve from 17.11288
196/196 - 61s - loss: 16.5035 - MinusLogProbMetric: 16.5035 - val_loss: 17.1987 - val_MinusLogProbMetric: 17.1987 - lr: 1.6667e-04 - 61s/epoch - 310ms/step
Epoch 483/1000
2023-09-23 23:41:54.254 
Epoch 483/1000 
	 loss: 16.5123, MinusLogProbMetric: 16.5123, val_loss: 17.2741, val_MinusLogProbMetric: 17.2741

Epoch 483: val_loss did not improve from 17.11288
196/196 - 62s - loss: 16.5123 - MinusLogProbMetric: 16.5123 - val_loss: 17.2741 - val_MinusLogProbMetric: 17.2741 - lr: 1.6667e-04 - 62s/epoch - 318ms/step
Epoch 484/1000
2023-09-23 23:42:54.529 
Epoch 484/1000 
	 loss: 16.5306, MinusLogProbMetric: 16.5306, val_loss: 17.1613, val_MinusLogProbMetric: 17.1613

Epoch 484: val_loss did not improve from 17.11288
196/196 - 60s - loss: 16.5306 - MinusLogProbMetric: 16.5306 - val_loss: 17.1613 - val_MinusLogProbMetric: 17.1613 - lr: 1.6667e-04 - 60s/epoch - 308ms/step
Epoch 485/1000
2023-09-23 23:43:54.110 
Epoch 485/1000 
	 loss: 16.4816, MinusLogProbMetric: 16.4816, val_loss: 17.8094, val_MinusLogProbMetric: 17.8094

Epoch 485: val_loss did not improve from 17.11288
196/196 - 60s - loss: 16.4816 - MinusLogProbMetric: 16.4816 - val_loss: 17.8094 - val_MinusLogProbMetric: 17.8094 - lr: 1.6667e-04 - 60s/epoch - 304ms/step
Epoch 486/1000
2023-09-23 23:44:52.734 
Epoch 486/1000 
	 loss: 16.5814, MinusLogProbMetric: 16.5814, val_loss: 17.2059, val_MinusLogProbMetric: 17.2059

Epoch 486: val_loss did not improve from 17.11288
196/196 - 59s - loss: 16.5814 - MinusLogProbMetric: 16.5814 - val_loss: 17.2059 - val_MinusLogProbMetric: 17.2059 - lr: 1.6667e-04 - 59s/epoch - 299ms/step
Epoch 487/1000
2023-09-23 23:45:50.919 
Epoch 487/1000 
	 loss: 16.5391, MinusLogProbMetric: 16.5391, val_loss: 17.2417, val_MinusLogProbMetric: 17.2417

Epoch 487: val_loss did not improve from 17.11288
196/196 - 58s - loss: 16.5391 - MinusLogProbMetric: 16.5391 - val_loss: 17.2417 - val_MinusLogProbMetric: 17.2417 - lr: 1.6667e-04 - 58s/epoch - 297ms/step
Epoch 488/1000
2023-09-23 23:46:50.638 
Epoch 488/1000 
	 loss: 16.5441, MinusLogProbMetric: 16.5441, val_loss: 17.1489, val_MinusLogProbMetric: 17.1489

Epoch 488: val_loss did not improve from 17.11288
196/196 - 60s - loss: 16.5441 - MinusLogProbMetric: 16.5441 - val_loss: 17.1489 - val_MinusLogProbMetric: 17.1489 - lr: 1.6667e-04 - 60s/epoch - 305ms/step
Epoch 489/1000
2023-09-23 23:47:51.928 
Epoch 489/1000 
	 loss: 16.5367, MinusLogProbMetric: 16.5367, val_loss: 17.2636, val_MinusLogProbMetric: 17.2636

Epoch 489: val_loss did not improve from 17.11288
196/196 - 61s - loss: 16.5367 - MinusLogProbMetric: 16.5367 - val_loss: 17.2636 - val_MinusLogProbMetric: 17.2636 - lr: 1.6667e-04 - 61s/epoch - 313ms/step
Epoch 490/1000
2023-09-23 23:48:53.946 
Epoch 490/1000 
	 loss: 16.4992, MinusLogProbMetric: 16.4992, val_loss: 17.2369, val_MinusLogProbMetric: 17.2369

Epoch 490: val_loss did not improve from 17.11288
196/196 - 62s - loss: 16.4992 - MinusLogProbMetric: 16.4992 - val_loss: 17.2369 - val_MinusLogProbMetric: 17.2369 - lr: 1.6667e-04 - 62s/epoch - 316ms/step
Epoch 491/1000
2023-09-23 23:49:54.156 
Epoch 491/1000 
	 loss: 16.5209, MinusLogProbMetric: 16.5209, val_loss: 17.3942, val_MinusLogProbMetric: 17.3942

Epoch 491: val_loss did not improve from 17.11288
196/196 - 60s - loss: 16.5209 - MinusLogProbMetric: 16.5209 - val_loss: 17.3942 - val_MinusLogProbMetric: 17.3942 - lr: 1.6667e-04 - 60s/epoch - 307ms/step
Epoch 492/1000
2023-09-23 23:50:53.788 
Epoch 492/1000 
	 loss: 16.5269, MinusLogProbMetric: 16.5269, val_loss: 17.3873, val_MinusLogProbMetric: 17.3873

Epoch 492: val_loss did not improve from 17.11288
196/196 - 60s - loss: 16.5269 - MinusLogProbMetric: 16.5269 - val_loss: 17.3873 - val_MinusLogProbMetric: 17.3873 - lr: 1.6667e-04 - 60s/epoch - 304ms/step
Epoch 493/1000
2023-09-23 23:51:55.856 
Epoch 493/1000 
	 loss: 16.5370, MinusLogProbMetric: 16.5370, val_loss: 17.3071, val_MinusLogProbMetric: 17.3071

Epoch 493: val_loss did not improve from 17.11288
196/196 - 62s - loss: 16.5370 - MinusLogProbMetric: 16.5370 - val_loss: 17.3071 - val_MinusLogProbMetric: 17.3071 - lr: 1.6667e-04 - 62s/epoch - 317ms/step
Epoch 494/1000
2023-09-23 23:52:57.676 
Epoch 494/1000 
	 loss: 16.5180, MinusLogProbMetric: 16.5180, val_loss: 17.4473, val_MinusLogProbMetric: 17.4473

Epoch 494: val_loss did not improve from 17.11288
196/196 - 62s - loss: 16.5180 - MinusLogProbMetric: 16.5180 - val_loss: 17.4473 - val_MinusLogProbMetric: 17.4473 - lr: 1.6667e-04 - 62s/epoch - 315ms/step
Epoch 495/1000
2023-09-23 23:53:59.446 
Epoch 495/1000 
	 loss: 16.5101, MinusLogProbMetric: 16.5101, val_loss: 17.1695, val_MinusLogProbMetric: 17.1695

Epoch 495: val_loss did not improve from 17.11288
196/196 - 62s - loss: 16.5101 - MinusLogProbMetric: 16.5101 - val_loss: 17.1695 - val_MinusLogProbMetric: 17.1695 - lr: 1.6667e-04 - 62s/epoch - 315ms/step
Epoch 496/1000
2023-09-23 23:55:00.954 
Epoch 496/1000 
	 loss: 16.5260, MinusLogProbMetric: 16.5260, val_loss: 17.4616, val_MinusLogProbMetric: 17.4616

Epoch 496: val_loss did not improve from 17.11288
196/196 - 62s - loss: 16.5260 - MinusLogProbMetric: 16.5260 - val_loss: 17.4616 - val_MinusLogProbMetric: 17.4616 - lr: 1.6667e-04 - 62s/epoch - 314ms/step
Epoch 497/1000
2023-09-23 23:56:02.542 
Epoch 497/1000 
	 loss: 16.5076, MinusLogProbMetric: 16.5076, val_loss: 17.2371, val_MinusLogProbMetric: 17.2371

Epoch 497: val_loss did not improve from 17.11288
196/196 - 62s - loss: 16.5076 - MinusLogProbMetric: 16.5076 - val_loss: 17.2371 - val_MinusLogProbMetric: 17.2371 - lr: 1.6667e-04 - 62s/epoch - 314ms/step
Epoch 498/1000
2023-09-23 23:57:04.042 
Epoch 498/1000 
	 loss: 16.5166, MinusLogProbMetric: 16.5166, val_loss: 17.3607, val_MinusLogProbMetric: 17.3607

Epoch 498: val_loss did not improve from 17.11288
196/196 - 61s - loss: 16.5166 - MinusLogProbMetric: 16.5166 - val_loss: 17.3607 - val_MinusLogProbMetric: 17.3607 - lr: 1.6667e-04 - 61s/epoch - 314ms/step
Epoch 499/1000
2023-09-23 23:58:04.355 
Epoch 499/1000 
	 loss: 16.4930, MinusLogProbMetric: 16.4930, val_loss: 17.2336, val_MinusLogProbMetric: 17.2336

Epoch 499: val_loss did not improve from 17.11288
196/196 - 60s - loss: 16.4930 - MinusLogProbMetric: 16.4930 - val_loss: 17.2336 - val_MinusLogProbMetric: 17.2336 - lr: 1.6667e-04 - 60s/epoch - 308ms/step
Epoch 500/1000
2023-09-23 23:59:04.415 
Epoch 500/1000 
	 loss: 16.4869, MinusLogProbMetric: 16.4869, val_loss: 17.1663, val_MinusLogProbMetric: 17.1663

Epoch 500: val_loss did not improve from 17.11288
196/196 - 60s - loss: 16.4869 - MinusLogProbMetric: 16.4869 - val_loss: 17.1663 - val_MinusLogProbMetric: 17.1663 - lr: 1.6667e-04 - 60s/epoch - 306ms/step
Epoch 501/1000
2023-09-24 00:00:05.981 
Epoch 501/1000 
	 loss: 16.4792, MinusLogProbMetric: 16.4792, val_loss: 17.2578, val_MinusLogProbMetric: 17.2578

Epoch 501: val_loss did not improve from 17.11288
196/196 - 62s - loss: 16.4792 - MinusLogProbMetric: 16.4792 - val_loss: 17.2578 - val_MinusLogProbMetric: 17.2578 - lr: 1.6667e-04 - 62s/epoch - 314ms/step
Epoch 502/1000
2023-09-24 00:01:07.403 
Epoch 502/1000 
	 loss: 16.5223, MinusLogProbMetric: 16.5223, val_loss: 17.2636, val_MinusLogProbMetric: 17.2636

Epoch 502: val_loss did not improve from 17.11288
196/196 - 61s - loss: 16.5223 - MinusLogProbMetric: 16.5223 - val_loss: 17.2636 - val_MinusLogProbMetric: 17.2636 - lr: 1.6667e-04 - 61s/epoch - 313ms/step
Epoch 503/1000
2023-09-24 00:02:09.408 
Epoch 503/1000 
	 loss: 16.5114, MinusLogProbMetric: 16.5114, val_loss: 17.1834, val_MinusLogProbMetric: 17.1834

Epoch 503: val_loss did not improve from 17.11288
196/196 - 62s - loss: 16.5114 - MinusLogProbMetric: 16.5114 - val_loss: 17.1834 - val_MinusLogProbMetric: 17.1834 - lr: 1.6667e-04 - 62s/epoch - 316ms/step
Epoch 504/1000
2023-09-24 00:03:10.836 
Epoch 504/1000 
	 loss: 16.5045, MinusLogProbMetric: 16.5045, val_loss: 17.2015, val_MinusLogProbMetric: 17.2015

Epoch 504: val_loss did not improve from 17.11288
196/196 - 61s - loss: 16.5045 - MinusLogProbMetric: 16.5045 - val_loss: 17.2015 - val_MinusLogProbMetric: 17.2015 - lr: 1.6667e-04 - 61s/epoch - 313ms/step
Epoch 505/1000
2023-09-24 00:04:11.496 
Epoch 505/1000 
	 loss: 16.4749, MinusLogProbMetric: 16.4749, val_loss: 17.1684, val_MinusLogProbMetric: 17.1684

Epoch 505: val_loss did not improve from 17.11288
196/196 - 61s - loss: 16.4749 - MinusLogProbMetric: 16.4749 - val_loss: 17.1684 - val_MinusLogProbMetric: 17.1684 - lr: 1.6667e-04 - 61s/epoch - 309ms/step
Epoch 506/1000
2023-09-24 00:05:10.627 
Epoch 506/1000 
	 loss: 16.5563, MinusLogProbMetric: 16.5563, val_loss: 17.1973, val_MinusLogProbMetric: 17.1973

Epoch 506: val_loss did not improve from 17.11288
196/196 - 59s - loss: 16.5563 - MinusLogProbMetric: 16.5563 - val_loss: 17.1973 - val_MinusLogProbMetric: 17.1973 - lr: 1.6667e-04 - 59s/epoch - 302ms/step
Epoch 507/1000
2023-09-24 00:06:12.531 
Epoch 507/1000 
	 loss: 16.4613, MinusLogProbMetric: 16.4613, val_loss: 17.9513, val_MinusLogProbMetric: 17.9513

Epoch 507: val_loss did not improve from 17.11288
196/196 - 62s - loss: 16.4613 - MinusLogProbMetric: 16.4613 - val_loss: 17.9513 - val_MinusLogProbMetric: 17.9513 - lr: 1.6667e-04 - 62s/epoch - 316ms/step
Epoch 508/1000
2023-09-24 00:07:13.557 
Epoch 508/1000 
	 loss: 16.4942, MinusLogProbMetric: 16.4942, val_loss: 17.5303, val_MinusLogProbMetric: 17.5303

Epoch 508: val_loss did not improve from 17.11288
196/196 - 61s - loss: 16.4942 - MinusLogProbMetric: 16.4942 - val_loss: 17.5303 - val_MinusLogProbMetric: 17.5303 - lr: 1.6667e-04 - 61s/epoch - 311ms/step
Epoch 509/1000
2023-09-24 00:08:13.020 
Epoch 509/1000 
	 loss: 16.4833, MinusLogProbMetric: 16.4833, val_loss: 17.2757, val_MinusLogProbMetric: 17.2757

Epoch 509: val_loss did not improve from 17.11288
196/196 - 59s - loss: 16.4833 - MinusLogProbMetric: 16.4833 - val_loss: 17.2757 - val_MinusLogProbMetric: 17.2757 - lr: 1.6667e-04 - 59s/epoch - 303ms/step
Epoch 510/1000
2023-09-24 00:09:15.087 
Epoch 510/1000 
	 loss: 16.5462, MinusLogProbMetric: 16.5462, val_loss: 17.3133, val_MinusLogProbMetric: 17.3133

Epoch 510: val_loss did not improve from 17.11288
196/196 - 62s - loss: 16.5462 - MinusLogProbMetric: 16.5462 - val_loss: 17.3133 - val_MinusLogProbMetric: 17.3133 - lr: 1.6667e-04 - 62s/epoch - 317ms/step
Epoch 511/1000
2023-09-24 00:10:14.844 
Epoch 511/1000 
	 loss: 16.4829, MinusLogProbMetric: 16.4829, val_loss: 17.2295, val_MinusLogProbMetric: 17.2295

Epoch 511: val_loss did not improve from 17.11288
196/196 - 60s - loss: 16.4829 - MinusLogProbMetric: 16.4829 - val_loss: 17.2295 - val_MinusLogProbMetric: 17.2295 - lr: 1.6667e-04 - 60s/epoch - 305ms/step
Epoch 512/1000
2023-09-24 00:11:14.956 
Epoch 512/1000 
	 loss: 16.3211, MinusLogProbMetric: 16.3211, val_loss: 17.0711, val_MinusLogProbMetric: 17.0711

Epoch 512: val_loss improved from 17.11288 to 17.07111, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 61s - loss: 16.3211 - MinusLogProbMetric: 16.3211 - val_loss: 17.0711 - val_MinusLogProbMetric: 17.0711 - lr: 8.3333e-05 - 61s/epoch - 312ms/step
Epoch 513/1000
2023-09-24 00:12:13.884 
Epoch 513/1000 
	 loss: 16.3036, MinusLogProbMetric: 16.3036, val_loss: 17.1295, val_MinusLogProbMetric: 17.1295

Epoch 513: val_loss did not improve from 17.07111
196/196 - 58s - loss: 16.3036 - MinusLogProbMetric: 16.3036 - val_loss: 17.1295 - val_MinusLogProbMetric: 17.1295 - lr: 8.3333e-05 - 58s/epoch - 296ms/step
Epoch 514/1000
2023-09-24 00:13:16.401 
Epoch 514/1000 
	 loss: 16.3150, MinusLogProbMetric: 16.3150, val_loss: 17.0849, val_MinusLogProbMetric: 17.0849

Epoch 514: val_loss did not improve from 17.07111
196/196 - 63s - loss: 16.3150 - MinusLogProbMetric: 16.3150 - val_loss: 17.0849 - val_MinusLogProbMetric: 17.0849 - lr: 8.3333e-05 - 63s/epoch - 319ms/step
Epoch 515/1000
2023-09-24 00:14:17.360 
Epoch 515/1000 
	 loss: 16.3094, MinusLogProbMetric: 16.3094, val_loss: 17.1327, val_MinusLogProbMetric: 17.1327

Epoch 515: val_loss did not improve from 17.07111
196/196 - 61s - loss: 16.3094 - MinusLogProbMetric: 16.3094 - val_loss: 17.1327 - val_MinusLogProbMetric: 17.1327 - lr: 8.3333e-05 - 61s/epoch - 311ms/step
Epoch 516/1000
2023-09-24 00:15:18.176 
Epoch 516/1000 
	 loss: 16.3490, MinusLogProbMetric: 16.3490, val_loss: 17.1383, val_MinusLogProbMetric: 17.1383

Epoch 516: val_loss did not improve from 17.07111
196/196 - 61s - loss: 16.3490 - MinusLogProbMetric: 16.3490 - val_loss: 17.1383 - val_MinusLogProbMetric: 17.1383 - lr: 8.3333e-05 - 61s/epoch - 310ms/step
Epoch 517/1000
2023-09-24 00:16:19.144 
Epoch 517/1000 
	 loss: 16.3228, MinusLogProbMetric: 16.3228, val_loss: 17.1113, val_MinusLogProbMetric: 17.1113

Epoch 517: val_loss did not improve from 17.07111
196/196 - 61s - loss: 16.3228 - MinusLogProbMetric: 16.3228 - val_loss: 17.1113 - val_MinusLogProbMetric: 17.1113 - lr: 8.3333e-05 - 61s/epoch - 311ms/step
Epoch 518/1000
2023-09-24 00:17:20.966 
Epoch 518/1000 
	 loss: 16.3204, MinusLogProbMetric: 16.3204, val_loss: 17.0878, val_MinusLogProbMetric: 17.0878

Epoch 518: val_loss did not improve from 17.07111
196/196 - 62s - loss: 16.3204 - MinusLogProbMetric: 16.3204 - val_loss: 17.0878 - val_MinusLogProbMetric: 17.0878 - lr: 8.3333e-05 - 62s/epoch - 315ms/step
Epoch 519/1000
2023-09-24 00:18:21.975 
Epoch 519/1000 
	 loss: 16.3110, MinusLogProbMetric: 16.3110, val_loss: 17.0703, val_MinusLogProbMetric: 17.0703

Epoch 519: val_loss improved from 17.07111 to 17.07033, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 62s - loss: 16.3110 - MinusLogProbMetric: 16.3110 - val_loss: 17.0703 - val_MinusLogProbMetric: 17.0703 - lr: 8.3333e-05 - 62s/epoch - 316ms/step
Epoch 520/1000
2023-09-24 00:19:24.539 
Epoch 520/1000 
	 loss: 16.3184, MinusLogProbMetric: 16.3184, val_loss: 17.0910, val_MinusLogProbMetric: 17.0910

Epoch 520: val_loss did not improve from 17.07033
196/196 - 62s - loss: 16.3184 - MinusLogProbMetric: 16.3184 - val_loss: 17.0910 - val_MinusLogProbMetric: 17.0910 - lr: 8.3333e-05 - 62s/epoch - 315ms/step
Epoch 521/1000
2023-09-24 00:20:26.456 
Epoch 521/1000 
	 loss: 16.3179, MinusLogProbMetric: 16.3179, val_loss: 17.1087, val_MinusLogProbMetric: 17.1087

Epoch 521: val_loss did not improve from 17.07033
196/196 - 62s - loss: 16.3179 - MinusLogProbMetric: 16.3179 - val_loss: 17.1087 - val_MinusLogProbMetric: 17.1087 - lr: 8.3333e-05 - 62s/epoch - 316ms/step
Epoch 522/1000
2023-09-24 00:21:28.353 
Epoch 522/1000 
	 loss: 16.2996, MinusLogProbMetric: 16.2996, val_loss: 17.1222, val_MinusLogProbMetric: 17.1222

Epoch 522: val_loss did not improve from 17.07033
196/196 - 62s - loss: 16.2996 - MinusLogProbMetric: 16.2996 - val_loss: 17.1222 - val_MinusLogProbMetric: 17.1222 - lr: 8.3333e-05 - 62s/epoch - 316ms/step
Epoch 523/1000
2023-09-24 00:22:30.647 
Epoch 523/1000 
	 loss: 16.2989, MinusLogProbMetric: 16.2989, val_loss: 17.0560, val_MinusLogProbMetric: 17.0560

Epoch 523: val_loss improved from 17.07033 to 17.05602, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 63s - loss: 16.2989 - MinusLogProbMetric: 16.2989 - val_loss: 17.0560 - val_MinusLogProbMetric: 17.0560 - lr: 8.3333e-05 - 63s/epoch - 322ms/step
Epoch 524/1000
2023-09-24 00:23:32.143 
Epoch 524/1000 
	 loss: 16.3002, MinusLogProbMetric: 16.3002, val_loss: 17.0803, val_MinusLogProbMetric: 17.0803

Epoch 524: val_loss did not improve from 17.05602
196/196 - 61s - loss: 16.3002 - MinusLogProbMetric: 16.3002 - val_loss: 17.0803 - val_MinusLogProbMetric: 17.0803 - lr: 8.3333e-05 - 61s/epoch - 310ms/step
Epoch 525/1000
2023-09-24 00:24:32.445 
Epoch 525/1000 
	 loss: 16.3035, MinusLogProbMetric: 16.3035, val_loss: 17.0809, val_MinusLogProbMetric: 17.0809

Epoch 525: val_loss did not improve from 17.05602
196/196 - 60s - loss: 16.3035 - MinusLogProbMetric: 16.3035 - val_loss: 17.0809 - val_MinusLogProbMetric: 17.0809 - lr: 8.3333e-05 - 60s/epoch - 308ms/step
Epoch 526/1000
2023-09-24 00:25:32.019 
Epoch 526/1000 
	 loss: 16.3037, MinusLogProbMetric: 16.3037, val_loss: 17.2123, val_MinusLogProbMetric: 17.2123

Epoch 526: val_loss did not improve from 17.05602
196/196 - 60s - loss: 16.3037 - MinusLogProbMetric: 16.3037 - val_loss: 17.2123 - val_MinusLogProbMetric: 17.2123 - lr: 8.3333e-05 - 60s/epoch - 304ms/step
Epoch 527/1000
2023-09-24 00:26:32.451 
Epoch 527/1000 
	 loss: 16.3056, MinusLogProbMetric: 16.3056, val_loss: 17.0893, val_MinusLogProbMetric: 17.0893

Epoch 527: val_loss did not improve from 17.05602
196/196 - 60s - loss: 16.3056 - MinusLogProbMetric: 16.3056 - val_loss: 17.0893 - val_MinusLogProbMetric: 17.0893 - lr: 8.3333e-05 - 60s/epoch - 308ms/step
Epoch 528/1000
2023-09-24 00:27:34.216 
Epoch 528/1000 
	 loss: 16.3051, MinusLogProbMetric: 16.3051, val_loss: 17.1058, val_MinusLogProbMetric: 17.1058

Epoch 528: val_loss did not improve from 17.05602
196/196 - 62s - loss: 16.3051 - MinusLogProbMetric: 16.3051 - val_loss: 17.1058 - val_MinusLogProbMetric: 17.1058 - lr: 8.3333e-05 - 62s/epoch - 315ms/step
Epoch 529/1000
2023-09-24 00:28:35.311 
Epoch 529/1000 
	 loss: 16.3050, MinusLogProbMetric: 16.3050, val_loss: 17.2415, val_MinusLogProbMetric: 17.2415

Epoch 529: val_loss did not improve from 17.05602
196/196 - 61s - loss: 16.3050 - MinusLogProbMetric: 16.3050 - val_loss: 17.2415 - val_MinusLogProbMetric: 17.2415 - lr: 8.3333e-05 - 61s/epoch - 312ms/step
Epoch 530/1000
2023-09-24 00:29:36.330 
Epoch 530/1000 
	 loss: 16.2990, MinusLogProbMetric: 16.2990, val_loss: 17.1654, val_MinusLogProbMetric: 17.1654

Epoch 530: val_loss did not improve from 17.05602
196/196 - 61s - loss: 16.2990 - MinusLogProbMetric: 16.2990 - val_loss: 17.1654 - val_MinusLogProbMetric: 17.1654 - lr: 8.3333e-05 - 61s/epoch - 311ms/step
Epoch 531/1000
2023-09-24 00:30:38.288 
Epoch 531/1000 
	 loss: 16.3193, MinusLogProbMetric: 16.3193, val_loss: 17.1272, val_MinusLogProbMetric: 17.1272

Epoch 531: val_loss did not improve from 17.05602
196/196 - 62s - loss: 16.3193 - MinusLogProbMetric: 16.3193 - val_loss: 17.1272 - val_MinusLogProbMetric: 17.1272 - lr: 8.3333e-05 - 62s/epoch - 316ms/step
Epoch 532/1000
2023-09-24 00:31:39.892 
Epoch 532/1000 
	 loss: 16.3099, MinusLogProbMetric: 16.3099, val_loss: 17.1126, val_MinusLogProbMetric: 17.1126

Epoch 532: val_loss did not improve from 17.05602
196/196 - 62s - loss: 16.3099 - MinusLogProbMetric: 16.3099 - val_loss: 17.1126 - val_MinusLogProbMetric: 17.1126 - lr: 8.3333e-05 - 62s/epoch - 314ms/step
Epoch 533/1000
2023-09-24 00:32:41.782 
Epoch 533/1000 
	 loss: 16.3065, MinusLogProbMetric: 16.3065, val_loss: 17.2217, val_MinusLogProbMetric: 17.2217

Epoch 533: val_loss did not improve from 17.05602
196/196 - 62s - loss: 16.3065 - MinusLogProbMetric: 16.3065 - val_loss: 17.2217 - val_MinusLogProbMetric: 17.2217 - lr: 8.3333e-05 - 62s/epoch - 316ms/step
Epoch 534/1000
2023-09-24 00:33:42.033 
Epoch 534/1000 
	 loss: 16.3048, MinusLogProbMetric: 16.3048, val_loss: 17.1101, val_MinusLogProbMetric: 17.1101

Epoch 534: val_loss did not improve from 17.05602
196/196 - 60s - loss: 16.3048 - MinusLogProbMetric: 16.3048 - val_loss: 17.1101 - val_MinusLogProbMetric: 17.1101 - lr: 8.3333e-05 - 60s/epoch - 307ms/step
Epoch 535/1000
2023-09-24 00:34:45.134 
Epoch 535/1000 
	 loss: 16.3366, MinusLogProbMetric: 16.3366, val_loss: 17.1076, val_MinusLogProbMetric: 17.1076

Epoch 535: val_loss did not improve from 17.05602
196/196 - 63s - loss: 16.3366 - MinusLogProbMetric: 16.3366 - val_loss: 17.1076 - val_MinusLogProbMetric: 17.1076 - lr: 8.3333e-05 - 63s/epoch - 322ms/step
Epoch 536/1000
2023-09-24 00:35:48.573 
Epoch 536/1000 
	 loss: 16.3097, MinusLogProbMetric: 16.3097, val_loss: 17.1243, val_MinusLogProbMetric: 17.1243

Epoch 536: val_loss did not improve from 17.05602
196/196 - 63s - loss: 16.3097 - MinusLogProbMetric: 16.3097 - val_loss: 17.1243 - val_MinusLogProbMetric: 17.1243 - lr: 8.3333e-05 - 63s/epoch - 324ms/step
Epoch 537/1000
2023-09-24 00:36:51.327 
Epoch 537/1000 
	 loss: 16.3180, MinusLogProbMetric: 16.3180, val_loss: 17.0849, val_MinusLogProbMetric: 17.0849

Epoch 537: val_loss did not improve from 17.05602
196/196 - 63s - loss: 16.3180 - MinusLogProbMetric: 16.3180 - val_loss: 17.0849 - val_MinusLogProbMetric: 17.0849 - lr: 8.3333e-05 - 63s/epoch - 320ms/step
Epoch 538/1000
2023-09-24 00:37:54.122 
Epoch 538/1000 
	 loss: 16.2990, MinusLogProbMetric: 16.2990, val_loss: 17.1278, val_MinusLogProbMetric: 17.1278

Epoch 538: val_loss did not improve from 17.05602
196/196 - 63s - loss: 16.2990 - MinusLogProbMetric: 16.2990 - val_loss: 17.1278 - val_MinusLogProbMetric: 17.1278 - lr: 8.3333e-05 - 63s/epoch - 320ms/step
Epoch 539/1000
2023-09-24 00:38:55.621 
Epoch 539/1000 
	 loss: 16.3006, MinusLogProbMetric: 16.3006, val_loss: 17.0634, val_MinusLogProbMetric: 17.0634

Epoch 539: val_loss did not improve from 17.05602
196/196 - 61s - loss: 16.3006 - MinusLogProbMetric: 16.3006 - val_loss: 17.0634 - val_MinusLogProbMetric: 17.0634 - lr: 8.3333e-05 - 61s/epoch - 314ms/step
Epoch 540/1000
2023-09-24 00:39:56.642 
Epoch 540/1000 
	 loss: 16.3028, MinusLogProbMetric: 16.3028, val_loss: 17.1685, val_MinusLogProbMetric: 17.1685

Epoch 540: val_loss did not improve from 17.05602
196/196 - 61s - loss: 16.3028 - MinusLogProbMetric: 16.3028 - val_loss: 17.1685 - val_MinusLogProbMetric: 17.1685 - lr: 8.3333e-05 - 61s/epoch - 311ms/step
Epoch 541/1000
2023-09-24 00:40:59.117 
Epoch 541/1000 
	 loss: 16.3063, MinusLogProbMetric: 16.3063, val_loss: 17.0709, val_MinusLogProbMetric: 17.0709

Epoch 541: val_loss did not improve from 17.05602
196/196 - 62s - loss: 16.3063 - MinusLogProbMetric: 16.3063 - val_loss: 17.0709 - val_MinusLogProbMetric: 17.0709 - lr: 8.3333e-05 - 62s/epoch - 319ms/step
Epoch 542/1000
2023-09-24 00:42:00.509 
Epoch 542/1000 
	 loss: 16.3030, MinusLogProbMetric: 16.3030, val_loss: 17.0616, val_MinusLogProbMetric: 17.0616

Epoch 542: val_loss did not improve from 17.05602
196/196 - 61s - loss: 16.3030 - MinusLogProbMetric: 16.3030 - val_loss: 17.0616 - val_MinusLogProbMetric: 17.0616 - lr: 8.3333e-05 - 61s/epoch - 313ms/step
Epoch 543/1000
2023-09-24 00:43:01.456 
Epoch 543/1000 
	 loss: 16.2905, MinusLogProbMetric: 16.2905, val_loss: 17.1823, val_MinusLogProbMetric: 17.1823

Epoch 543: val_loss did not improve from 17.05602
196/196 - 61s - loss: 16.2905 - MinusLogProbMetric: 16.2905 - val_loss: 17.1823 - val_MinusLogProbMetric: 17.1823 - lr: 8.3333e-05 - 61s/epoch - 311ms/step
Epoch 544/1000
2023-09-24 00:44:02.793 
Epoch 544/1000 
	 loss: 16.2982, MinusLogProbMetric: 16.2982, val_loss: 17.0740, val_MinusLogProbMetric: 17.0740

Epoch 544: val_loss did not improve from 17.05602
196/196 - 61s - loss: 16.2982 - MinusLogProbMetric: 16.2982 - val_loss: 17.0740 - val_MinusLogProbMetric: 17.0740 - lr: 8.3333e-05 - 61s/epoch - 313ms/step
Epoch 545/1000
2023-09-24 00:45:02.528 
Epoch 545/1000 
	 loss: 16.3018, MinusLogProbMetric: 16.3018, val_loss: 17.0769, val_MinusLogProbMetric: 17.0769

Epoch 545: val_loss did not improve from 17.05602
196/196 - 60s - loss: 16.3018 - MinusLogProbMetric: 16.3018 - val_loss: 17.0769 - val_MinusLogProbMetric: 17.0769 - lr: 8.3333e-05 - 60s/epoch - 305ms/step
Epoch 546/1000
2023-09-24 00:46:00.994 
Epoch 546/1000 
	 loss: 16.3101, MinusLogProbMetric: 16.3101, val_loss: 17.0787, val_MinusLogProbMetric: 17.0787

Epoch 546: val_loss did not improve from 17.05602
196/196 - 58s - loss: 16.3101 - MinusLogProbMetric: 16.3101 - val_loss: 17.0787 - val_MinusLogProbMetric: 17.0787 - lr: 8.3333e-05 - 58s/epoch - 298ms/step
Epoch 547/1000
2023-09-24 00:47:01.055 
Epoch 547/1000 
	 loss: 16.3167, MinusLogProbMetric: 16.3167, val_loss: 17.1792, val_MinusLogProbMetric: 17.1792

Epoch 547: val_loss did not improve from 17.05602
196/196 - 60s - loss: 16.3167 - MinusLogProbMetric: 16.3167 - val_loss: 17.1792 - val_MinusLogProbMetric: 17.1792 - lr: 8.3333e-05 - 60s/epoch - 306ms/step
Epoch 548/1000
2023-09-24 00:48:00.907 
Epoch 548/1000 
	 loss: 16.3007, MinusLogProbMetric: 16.3007, val_loss: 17.0876, val_MinusLogProbMetric: 17.0876

Epoch 548: val_loss did not improve from 17.05602
196/196 - 60s - loss: 16.3007 - MinusLogProbMetric: 16.3007 - val_loss: 17.0876 - val_MinusLogProbMetric: 17.0876 - lr: 8.3333e-05 - 60s/epoch - 305ms/step
Epoch 549/1000
2023-09-24 00:49:02.650 
Epoch 549/1000 
	 loss: 16.2978, MinusLogProbMetric: 16.2978, val_loss: 17.1160, val_MinusLogProbMetric: 17.1160

Epoch 549: val_loss did not improve from 17.05602
196/196 - 62s - loss: 16.2978 - MinusLogProbMetric: 16.2978 - val_loss: 17.1160 - val_MinusLogProbMetric: 17.1160 - lr: 8.3333e-05 - 62s/epoch - 315ms/step
Epoch 550/1000
2023-09-24 00:50:03.320 
Epoch 550/1000 
	 loss: 16.3325, MinusLogProbMetric: 16.3325, val_loss: 17.1425, val_MinusLogProbMetric: 17.1425

Epoch 550: val_loss did not improve from 17.05602
196/196 - 61s - loss: 16.3325 - MinusLogProbMetric: 16.3325 - val_loss: 17.1425 - val_MinusLogProbMetric: 17.1425 - lr: 8.3333e-05 - 61s/epoch - 310ms/step
Epoch 551/1000
2023-09-24 00:51:02.063 
Epoch 551/1000 
	 loss: 16.3140, MinusLogProbMetric: 16.3140, val_loss: 17.1756, val_MinusLogProbMetric: 17.1756

Epoch 551: val_loss did not improve from 17.05602
196/196 - 59s - loss: 16.3140 - MinusLogProbMetric: 16.3140 - val_loss: 17.1756 - val_MinusLogProbMetric: 17.1756 - lr: 8.3333e-05 - 59s/epoch - 300ms/step
Epoch 552/1000
2023-09-24 00:52:02.957 
Epoch 552/1000 
	 loss: 16.3024, MinusLogProbMetric: 16.3024, val_loss: 17.0857, val_MinusLogProbMetric: 17.0857

Epoch 552: val_loss did not improve from 17.05602
196/196 - 61s - loss: 16.3024 - MinusLogProbMetric: 16.3024 - val_loss: 17.0857 - val_MinusLogProbMetric: 17.0857 - lr: 8.3333e-05 - 61s/epoch - 311ms/step
Epoch 553/1000
2023-09-24 00:53:04.687 
Epoch 553/1000 
	 loss: 16.2949, MinusLogProbMetric: 16.2949, val_loss: 17.0707, val_MinusLogProbMetric: 17.0707

Epoch 553: val_loss did not improve from 17.05602
196/196 - 62s - loss: 16.2949 - MinusLogProbMetric: 16.2949 - val_loss: 17.0707 - val_MinusLogProbMetric: 17.0707 - lr: 8.3333e-05 - 62s/epoch - 315ms/step
Epoch 554/1000
2023-09-24 00:54:04.871 
Epoch 554/1000 
	 loss: 16.2944, MinusLogProbMetric: 16.2944, val_loss: 17.0657, val_MinusLogProbMetric: 17.0657

Epoch 554: val_loss did not improve from 17.05602
196/196 - 60s - loss: 16.2944 - MinusLogProbMetric: 16.2944 - val_loss: 17.0657 - val_MinusLogProbMetric: 17.0657 - lr: 8.3333e-05 - 60s/epoch - 307ms/step
Epoch 555/1000
2023-09-24 00:55:05.966 
Epoch 555/1000 
	 loss: 16.2949, MinusLogProbMetric: 16.2949, val_loss: 17.2105, val_MinusLogProbMetric: 17.2105

Epoch 555: val_loss did not improve from 17.05602
196/196 - 61s - loss: 16.2949 - MinusLogProbMetric: 16.2949 - val_loss: 17.2105 - val_MinusLogProbMetric: 17.2105 - lr: 8.3333e-05 - 61s/epoch - 312ms/step
Epoch 556/1000
2023-09-24 00:56:06.089 
Epoch 556/1000 
	 loss: 16.2974, MinusLogProbMetric: 16.2974, val_loss: 17.2342, val_MinusLogProbMetric: 17.2342

Epoch 556: val_loss did not improve from 17.05602
196/196 - 60s - loss: 16.2974 - MinusLogProbMetric: 16.2974 - val_loss: 17.2342 - val_MinusLogProbMetric: 17.2342 - lr: 8.3333e-05 - 60s/epoch - 307ms/step
Epoch 557/1000
2023-09-24 00:57:04.314 
Epoch 557/1000 
	 loss: 16.3013, MinusLogProbMetric: 16.3013, val_loss: 17.0636, val_MinusLogProbMetric: 17.0636

Epoch 557: val_loss did not improve from 17.05602
196/196 - 58s - loss: 16.3013 - MinusLogProbMetric: 16.3013 - val_loss: 17.0636 - val_MinusLogProbMetric: 17.0636 - lr: 8.3333e-05 - 58s/epoch - 297ms/step
Epoch 558/1000
2023-09-24 00:58:04.179 
Epoch 558/1000 
	 loss: 16.2935, MinusLogProbMetric: 16.2935, val_loss: 17.0822, val_MinusLogProbMetric: 17.0822

Epoch 558: val_loss did not improve from 17.05602
196/196 - 60s - loss: 16.2935 - MinusLogProbMetric: 16.2935 - val_loss: 17.0822 - val_MinusLogProbMetric: 17.0822 - lr: 8.3333e-05 - 60s/epoch - 305ms/step
Epoch 559/1000
2023-09-24 00:59:06.250 
Epoch 559/1000 
	 loss: 16.3051, MinusLogProbMetric: 16.3051, val_loss: 17.2474, val_MinusLogProbMetric: 17.2474

Epoch 559: val_loss did not improve from 17.05602
196/196 - 62s - loss: 16.3051 - MinusLogProbMetric: 16.3051 - val_loss: 17.2474 - val_MinusLogProbMetric: 17.2474 - lr: 8.3333e-05 - 62s/epoch - 317ms/step
Epoch 560/1000
2023-09-24 01:00:07.393 
Epoch 560/1000 
	 loss: 16.3067, MinusLogProbMetric: 16.3067, val_loss: 17.0700, val_MinusLogProbMetric: 17.0700

Epoch 560: val_loss did not improve from 17.05602
196/196 - 61s - loss: 16.3067 - MinusLogProbMetric: 16.3067 - val_loss: 17.0700 - val_MinusLogProbMetric: 17.0700 - lr: 8.3333e-05 - 61s/epoch - 312ms/step
Epoch 561/1000
2023-09-24 01:01:09.791 
Epoch 561/1000 
	 loss: 16.2983, MinusLogProbMetric: 16.2983, val_loss: 17.2259, val_MinusLogProbMetric: 17.2259

Epoch 561: val_loss did not improve from 17.05602
196/196 - 62s - loss: 16.2983 - MinusLogProbMetric: 16.2983 - val_loss: 17.2259 - val_MinusLogProbMetric: 17.2259 - lr: 8.3333e-05 - 62s/epoch - 318ms/step
Epoch 562/1000
2023-09-24 01:02:10.342 
Epoch 562/1000 
	 loss: 16.3001, MinusLogProbMetric: 16.3001, val_loss: 17.0763, val_MinusLogProbMetric: 17.0763

Epoch 562: val_loss did not improve from 17.05602
196/196 - 61s - loss: 16.3001 - MinusLogProbMetric: 16.3001 - val_loss: 17.0763 - val_MinusLogProbMetric: 17.0763 - lr: 8.3333e-05 - 61s/epoch - 309ms/step
Epoch 563/1000
2023-09-24 01:03:11.126 
Epoch 563/1000 
	 loss: 16.3159, MinusLogProbMetric: 16.3159, val_loss: 17.0630, val_MinusLogProbMetric: 17.0630

Epoch 563: val_loss did not improve from 17.05602
196/196 - 61s - loss: 16.3159 - MinusLogProbMetric: 16.3159 - val_loss: 17.0630 - val_MinusLogProbMetric: 17.0630 - lr: 8.3333e-05 - 61s/epoch - 310ms/step
Epoch 564/1000
2023-09-24 01:04:11.616 
Epoch 564/1000 
	 loss: 16.2967, MinusLogProbMetric: 16.2967, val_loss: 17.1197, val_MinusLogProbMetric: 17.1197

Epoch 564: val_loss did not improve from 17.05602
196/196 - 60s - loss: 16.2967 - MinusLogProbMetric: 16.2967 - val_loss: 17.1197 - val_MinusLogProbMetric: 17.1197 - lr: 8.3333e-05 - 60s/epoch - 309ms/step
Epoch 565/1000
2023-09-24 01:05:14.179 
Epoch 565/1000 
	 loss: 16.2947, MinusLogProbMetric: 16.2947, val_loss: 17.2820, val_MinusLogProbMetric: 17.2820

Epoch 565: val_loss did not improve from 17.05602
196/196 - 63s - loss: 16.2947 - MinusLogProbMetric: 16.2947 - val_loss: 17.2820 - val_MinusLogProbMetric: 17.2820 - lr: 8.3333e-05 - 63s/epoch - 319ms/step
Epoch 566/1000
2023-09-24 01:06:14.591 
Epoch 566/1000 
	 loss: 16.3016, MinusLogProbMetric: 16.3016, val_loss: 17.0917, val_MinusLogProbMetric: 17.0917

Epoch 566: val_loss did not improve from 17.05602
196/196 - 60s - loss: 16.3016 - MinusLogProbMetric: 16.3016 - val_loss: 17.0917 - val_MinusLogProbMetric: 17.0917 - lr: 8.3333e-05 - 60s/epoch - 308ms/step
Epoch 567/1000
2023-09-24 01:07:16.791 
Epoch 567/1000 
	 loss: 16.3095, MinusLogProbMetric: 16.3095, val_loss: 17.0934, val_MinusLogProbMetric: 17.0934

Epoch 567: val_loss did not improve from 17.05602
196/196 - 62s - loss: 16.3095 - MinusLogProbMetric: 16.3095 - val_loss: 17.0934 - val_MinusLogProbMetric: 17.0934 - lr: 8.3333e-05 - 62s/epoch - 317ms/step
Epoch 568/1000
2023-09-24 01:08:18.936 
Epoch 568/1000 
	 loss: 16.3031, MinusLogProbMetric: 16.3031, val_loss: 17.0617, val_MinusLogProbMetric: 17.0617

Epoch 568: val_loss did not improve from 17.05602
196/196 - 62s - loss: 16.3031 - MinusLogProbMetric: 16.3031 - val_loss: 17.0617 - val_MinusLogProbMetric: 17.0617 - lr: 8.3333e-05 - 62s/epoch - 317ms/step
Epoch 569/1000
2023-09-24 01:09:20.299 
Epoch 569/1000 
	 loss: 16.2899, MinusLogProbMetric: 16.2899, val_loss: 17.0693, val_MinusLogProbMetric: 17.0693

Epoch 569: val_loss did not improve from 17.05602
196/196 - 61s - loss: 16.2899 - MinusLogProbMetric: 16.2899 - val_loss: 17.0693 - val_MinusLogProbMetric: 17.0693 - lr: 8.3333e-05 - 61s/epoch - 313ms/step
Epoch 570/1000
2023-09-24 01:10:22.258 
Epoch 570/1000 
	 loss: 16.2823, MinusLogProbMetric: 16.2823, val_loss: 17.1171, val_MinusLogProbMetric: 17.1171

Epoch 570: val_loss did not improve from 17.05602
196/196 - 62s - loss: 16.2823 - MinusLogProbMetric: 16.2823 - val_loss: 17.1171 - val_MinusLogProbMetric: 17.1171 - lr: 8.3333e-05 - 62s/epoch - 316ms/step
Epoch 571/1000
2023-09-24 01:11:23.839 
Epoch 571/1000 
	 loss: 16.2881, MinusLogProbMetric: 16.2881, val_loss: 17.1239, val_MinusLogProbMetric: 17.1239

Epoch 571: val_loss did not improve from 17.05602
196/196 - 62s - loss: 16.2881 - MinusLogProbMetric: 16.2881 - val_loss: 17.1239 - val_MinusLogProbMetric: 17.1239 - lr: 8.3333e-05 - 62s/epoch - 314ms/step
Epoch 572/1000
2023-09-24 01:12:25.725 
Epoch 572/1000 
	 loss: 16.2917, MinusLogProbMetric: 16.2917, val_loss: 17.1240, val_MinusLogProbMetric: 17.1240

Epoch 572: val_loss did not improve from 17.05602
196/196 - 62s - loss: 16.2917 - MinusLogProbMetric: 16.2917 - val_loss: 17.1240 - val_MinusLogProbMetric: 17.1240 - lr: 8.3333e-05 - 62s/epoch - 316ms/step
Epoch 573/1000
2023-09-24 01:13:26.582 
Epoch 573/1000 
	 loss: 16.3133, MinusLogProbMetric: 16.3133, val_loss: 17.0931, val_MinusLogProbMetric: 17.0931

Epoch 573: val_loss did not improve from 17.05602
196/196 - 61s - loss: 16.3133 - MinusLogProbMetric: 16.3133 - val_loss: 17.0931 - val_MinusLogProbMetric: 17.0931 - lr: 8.3333e-05 - 61s/epoch - 310ms/step
Epoch 574/1000
2023-09-24 01:14:30.792 
Epoch 574/1000 
	 loss: 16.2253, MinusLogProbMetric: 16.2253, val_loss: 17.0540, val_MinusLogProbMetric: 17.0540

Epoch 574: val_loss improved from 17.05602 to 17.05401, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 65s - loss: 16.2253 - MinusLogProbMetric: 16.2253 - val_loss: 17.0540 - val_MinusLogProbMetric: 17.0540 - lr: 4.1667e-05 - 65s/epoch - 332ms/step
Epoch 575/1000
2023-09-24 01:15:33.504 
Epoch 575/1000 
	 loss: 16.2249, MinusLogProbMetric: 16.2249, val_loss: 17.0686, val_MinusLogProbMetric: 17.0686

Epoch 575: val_loss did not improve from 17.05401
196/196 - 62s - loss: 16.2249 - MinusLogProbMetric: 16.2249 - val_loss: 17.0686 - val_MinusLogProbMetric: 17.0686 - lr: 4.1667e-05 - 62s/epoch - 315ms/step
Epoch 576/1000
2023-09-24 01:16:36.017 
Epoch 576/1000 
	 loss: 16.2329, MinusLogProbMetric: 16.2329, val_loss: 17.1153, val_MinusLogProbMetric: 17.1153

Epoch 576: val_loss did not improve from 17.05401
196/196 - 63s - loss: 16.2329 - MinusLogProbMetric: 16.2329 - val_loss: 17.1153 - val_MinusLogProbMetric: 17.1153 - lr: 4.1667e-05 - 63s/epoch - 319ms/step
Epoch 577/1000
2023-09-24 01:17:36.059 
Epoch 577/1000 
	 loss: 16.2262, MinusLogProbMetric: 16.2262, val_loss: 17.0540, val_MinusLogProbMetric: 17.0540

Epoch 577: val_loss did not improve from 17.05401
196/196 - 60s - loss: 16.2262 - MinusLogProbMetric: 16.2262 - val_loss: 17.0540 - val_MinusLogProbMetric: 17.0540 - lr: 4.1667e-05 - 60s/epoch - 306ms/step
Epoch 578/1000
2023-09-24 01:18:39.971 
Epoch 578/1000 
	 loss: 16.2249, MinusLogProbMetric: 16.2249, val_loss: 17.0714, val_MinusLogProbMetric: 17.0714

Epoch 578: val_loss did not improve from 17.05401
196/196 - 64s - loss: 16.2249 - MinusLogProbMetric: 16.2249 - val_loss: 17.0714 - val_MinusLogProbMetric: 17.0714 - lr: 4.1667e-05 - 64s/epoch - 326ms/step
Epoch 579/1000
2023-09-24 01:19:38.160 
Epoch 579/1000 
	 loss: 16.2293, MinusLogProbMetric: 16.2293, val_loss: 17.0564, val_MinusLogProbMetric: 17.0564

Epoch 579: val_loss did not improve from 17.05401
196/196 - 58s - loss: 16.2293 - MinusLogProbMetric: 16.2293 - val_loss: 17.0564 - val_MinusLogProbMetric: 17.0564 - lr: 4.1667e-05 - 58s/epoch - 297ms/step
Epoch 580/1000
2023-09-24 01:20:39.068 
Epoch 580/1000 
	 loss: 16.2179, MinusLogProbMetric: 16.2179, val_loss: 17.0649, val_MinusLogProbMetric: 17.0649

Epoch 580: val_loss did not improve from 17.05401
196/196 - 61s - loss: 16.2179 - MinusLogProbMetric: 16.2179 - val_loss: 17.0649 - val_MinusLogProbMetric: 17.0649 - lr: 4.1667e-05 - 61s/epoch - 311ms/step
Epoch 581/1000
2023-09-24 01:21:40.446 
Epoch 581/1000 
	 loss: 16.2273, MinusLogProbMetric: 16.2273, val_loss: 17.0608, val_MinusLogProbMetric: 17.0608

Epoch 581: val_loss did not improve from 17.05401
196/196 - 61s - loss: 16.2273 - MinusLogProbMetric: 16.2273 - val_loss: 17.0608 - val_MinusLogProbMetric: 17.0608 - lr: 4.1667e-05 - 61s/epoch - 313ms/step
Epoch 582/1000
2023-09-24 01:22:42.963 
Epoch 582/1000 
	 loss: 16.2266, MinusLogProbMetric: 16.2266, val_loss: 17.0415, val_MinusLogProbMetric: 17.0415

Epoch 582: val_loss improved from 17.05401 to 17.04150, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 63s - loss: 16.2266 - MinusLogProbMetric: 16.2266 - val_loss: 17.0415 - val_MinusLogProbMetric: 17.0415 - lr: 4.1667e-05 - 63s/epoch - 323ms/step
Epoch 583/1000
2023-09-24 01:23:46.075 
Epoch 583/1000 
	 loss: 16.2224, MinusLogProbMetric: 16.2224, val_loss: 17.0559, val_MinusLogProbMetric: 17.0559

Epoch 583: val_loss did not improve from 17.04150
196/196 - 62s - loss: 16.2224 - MinusLogProbMetric: 16.2224 - val_loss: 17.0559 - val_MinusLogProbMetric: 17.0559 - lr: 4.1667e-05 - 62s/epoch - 318ms/step
Epoch 584/1000
2023-09-24 01:24:47.218 
Epoch 584/1000 
	 loss: 16.2299, MinusLogProbMetric: 16.2299, val_loss: 17.0447, val_MinusLogProbMetric: 17.0447

Epoch 584: val_loss did not improve from 17.04150
196/196 - 61s - loss: 16.2299 - MinusLogProbMetric: 16.2299 - val_loss: 17.0447 - val_MinusLogProbMetric: 17.0447 - lr: 4.1667e-05 - 61s/epoch - 312ms/step
Epoch 585/1000
2023-09-24 01:25:49.478 
Epoch 585/1000 
	 loss: 16.2242, MinusLogProbMetric: 16.2242, val_loss: 17.0572, val_MinusLogProbMetric: 17.0572

Epoch 585: val_loss did not improve from 17.04150
196/196 - 62s - loss: 16.2242 - MinusLogProbMetric: 16.2242 - val_loss: 17.0572 - val_MinusLogProbMetric: 17.0572 - lr: 4.1667e-05 - 62s/epoch - 318ms/step
Epoch 586/1000
2023-09-24 01:26:50.259 
Epoch 586/1000 
	 loss: 16.2324, MinusLogProbMetric: 16.2324, val_loss: 17.0468, val_MinusLogProbMetric: 17.0468

Epoch 586: val_loss did not improve from 17.04150
196/196 - 61s - loss: 16.2324 - MinusLogProbMetric: 16.2324 - val_loss: 17.0468 - val_MinusLogProbMetric: 17.0468 - lr: 4.1667e-05 - 61s/epoch - 310ms/step
Epoch 587/1000
2023-09-24 01:27:49.441 
Epoch 587/1000 
	 loss: 16.2243, MinusLogProbMetric: 16.2243, val_loss: 17.0631, val_MinusLogProbMetric: 17.0631

Epoch 587: val_loss did not improve from 17.04150
196/196 - 59s - loss: 16.2243 - MinusLogProbMetric: 16.2243 - val_loss: 17.0631 - val_MinusLogProbMetric: 17.0631 - lr: 4.1667e-05 - 59s/epoch - 302ms/step
Epoch 588/1000
2023-09-24 01:28:50.057 
Epoch 588/1000 
	 loss: 16.2276, MinusLogProbMetric: 16.2276, val_loss: 17.0852, val_MinusLogProbMetric: 17.0852

Epoch 588: val_loss did not improve from 17.04150
196/196 - 61s - loss: 16.2276 - MinusLogProbMetric: 16.2276 - val_loss: 17.0852 - val_MinusLogProbMetric: 17.0852 - lr: 4.1667e-05 - 61s/epoch - 309ms/step
Epoch 589/1000
2023-09-24 01:29:51.092 
Epoch 589/1000 
	 loss: 16.2165, MinusLogProbMetric: 16.2165, val_loss: 17.0593, val_MinusLogProbMetric: 17.0593

Epoch 589: val_loss did not improve from 17.04150
196/196 - 61s - loss: 16.2165 - MinusLogProbMetric: 16.2165 - val_loss: 17.0593 - val_MinusLogProbMetric: 17.0593 - lr: 4.1667e-05 - 61s/epoch - 311ms/step
Epoch 590/1000
2023-09-24 01:30:51.129 
Epoch 590/1000 
	 loss: 16.2180, MinusLogProbMetric: 16.2180, val_loss: 17.0472, val_MinusLogProbMetric: 17.0472

Epoch 590: val_loss did not improve from 17.04150
196/196 - 60s - loss: 16.2180 - MinusLogProbMetric: 16.2180 - val_loss: 17.0472 - val_MinusLogProbMetric: 17.0472 - lr: 4.1667e-05 - 60s/epoch - 306ms/step
Epoch 591/1000
2023-09-24 01:31:52.616 
Epoch 591/1000 
	 loss: 16.2169, MinusLogProbMetric: 16.2169, val_loss: 17.0404, val_MinusLogProbMetric: 17.0404

Epoch 591: val_loss improved from 17.04150 to 17.04040, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 62s - loss: 16.2169 - MinusLogProbMetric: 16.2169 - val_loss: 17.0404 - val_MinusLogProbMetric: 17.0404 - lr: 4.1667e-05 - 62s/epoch - 318ms/step
Epoch 592/1000
2023-09-24 01:32:54.806 
Epoch 592/1000 
	 loss: 16.2248, MinusLogProbMetric: 16.2248, val_loss: 17.0757, val_MinusLogProbMetric: 17.0757

Epoch 592: val_loss did not improve from 17.04040
196/196 - 61s - loss: 16.2248 - MinusLogProbMetric: 16.2248 - val_loss: 17.0757 - val_MinusLogProbMetric: 17.0757 - lr: 4.1667e-05 - 61s/epoch - 313ms/step
Epoch 593/1000
2023-09-24 01:33:54.760 
Epoch 593/1000 
	 loss: 16.2248, MinusLogProbMetric: 16.2248, val_loss: 17.0631, val_MinusLogProbMetric: 17.0631

Epoch 593: val_loss did not improve from 17.04040
196/196 - 60s - loss: 16.2248 - MinusLogProbMetric: 16.2248 - val_loss: 17.0631 - val_MinusLogProbMetric: 17.0631 - lr: 4.1667e-05 - 60s/epoch - 306ms/step
Epoch 594/1000
2023-09-24 01:34:55.516 
Epoch 594/1000 
	 loss: 16.2170, MinusLogProbMetric: 16.2170, val_loss: 17.0980, val_MinusLogProbMetric: 17.0980

Epoch 594: val_loss did not improve from 17.04040
196/196 - 61s - loss: 16.2170 - MinusLogProbMetric: 16.2170 - val_loss: 17.0980 - val_MinusLogProbMetric: 17.0980 - lr: 4.1667e-05 - 61s/epoch - 310ms/step
Epoch 595/1000
2023-09-24 01:35:55.937 
Epoch 595/1000 
	 loss: 16.2211, MinusLogProbMetric: 16.2211, val_loss: 17.0529, val_MinusLogProbMetric: 17.0529

Epoch 595: val_loss did not improve from 17.04040
196/196 - 60s - loss: 16.2211 - MinusLogProbMetric: 16.2211 - val_loss: 17.0529 - val_MinusLogProbMetric: 17.0529 - lr: 4.1667e-05 - 60s/epoch - 308ms/step
Epoch 596/1000
2023-09-24 01:36:58.391 
Epoch 596/1000 
	 loss: 16.2219, MinusLogProbMetric: 16.2219, val_loss: 17.0603, val_MinusLogProbMetric: 17.0603

Epoch 596: val_loss did not improve from 17.04040
196/196 - 62s - loss: 16.2219 - MinusLogProbMetric: 16.2219 - val_loss: 17.0603 - val_MinusLogProbMetric: 17.0603 - lr: 4.1667e-05 - 62s/epoch - 319ms/step
Epoch 597/1000
2023-09-24 01:38:00.724 
Epoch 597/1000 
	 loss: 16.2213, MinusLogProbMetric: 16.2213, val_loss: 17.0355, val_MinusLogProbMetric: 17.0355

Epoch 597: val_loss improved from 17.04040 to 17.03555, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 63s - loss: 16.2213 - MinusLogProbMetric: 16.2213 - val_loss: 17.0355 - val_MinusLogProbMetric: 17.0355 - lr: 4.1667e-05 - 63s/epoch - 322ms/step
Epoch 598/1000
2023-09-24 01:39:04.018 
Epoch 598/1000 
	 loss: 16.2123, MinusLogProbMetric: 16.2123, val_loss: 17.0557, val_MinusLogProbMetric: 17.0557

Epoch 598: val_loss did not improve from 17.03555
196/196 - 62s - loss: 16.2123 - MinusLogProbMetric: 16.2123 - val_loss: 17.0557 - val_MinusLogProbMetric: 17.0557 - lr: 4.1667e-05 - 62s/epoch - 319ms/step
Epoch 599/1000
2023-09-24 01:40:07.557 
Epoch 599/1000 
	 loss: 16.2220, MinusLogProbMetric: 16.2220, val_loss: 17.0962, val_MinusLogProbMetric: 17.0962

Epoch 599: val_loss did not improve from 17.03555
196/196 - 64s - loss: 16.2220 - MinusLogProbMetric: 16.2220 - val_loss: 17.0962 - val_MinusLogProbMetric: 17.0962 - lr: 4.1667e-05 - 64s/epoch - 324ms/step
Epoch 600/1000
2023-09-24 01:41:10.993 
Epoch 600/1000 
	 loss: 16.2219, MinusLogProbMetric: 16.2219, val_loss: 17.0558, val_MinusLogProbMetric: 17.0558

Epoch 600: val_loss did not improve from 17.03555
196/196 - 63s - loss: 16.2219 - MinusLogProbMetric: 16.2219 - val_loss: 17.0558 - val_MinusLogProbMetric: 17.0558 - lr: 4.1667e-05 - 63s/epoch - 324ms/step
Epoch 601/1000
2023-09-24 01:42:13.563 
Epoch 601/1000 
	 loss: 16.2236, MinusLogProbMetric: 16.2236, val_loss: 17.0962, val_MinusLogProbMetric: 17.0962

Epoch 601: val_loss did not improve from 17.03555
196/196 - 63s - loss: 16.2236 - MinusLogProbMetric: 16.2236 - val_loss: 17.0962 - val_MinusLogProbMetric: 17.0962 - lr: 4.1667e-05 - 63s/epoch - 319ms/step
Epoch 602/1000
2023-09-24 01:43:14.494 
Epoch 602/1000 
	 loss: 16.2199, MinusLogProbMetric: 16.2199, val_loss: 17.0392, val_MinusLogProbMetric: 17.0392

Epoch 602: val_loss did not improve from 17.03555
196/196 - 61s - loss: 16.2199 - MinusLogProbMetric: 16.2199 - val_loss: 17.0392 - val_MinusLogProbMetric: 17.0392 - lr: 4.1667e-05 - 61s/epoch - 311ms/step
Epoch 603/1000
2023-09-24 01:44:16.167 
Epoch 603/1000 
	 loss: 16.2156, MinusLogProbMetric: 16.2156, val_loss: 17.0643, val_MinusLogProbMetric: 17.0643

Epoch 603: val_loss did not improve from 17.03555
196/196 - 62s - loss: 16.2156 - MinusLogProbMetric: 16.2156 - val_loss: 17.0643 - val_MinusLogProbMetric: 17.0643 - lr: 4.1667e-05 - 62s/epoch - 315ms/step
Epoch 604/1000
2023-09-24 01:45:18.763 
Epoch 604/1000 
	 loss: 16.2239, MinusLogProbMetric: 16.2239, val_loss: 17.0606, val_MinusLogProbMetric: 17.0606

Epoch 604: val_loss did not improve from 17.03555
196/196 - 63s - loss: 16.2239 - MinusLogProbMetric: 16.2239 - val_loss: 17.0606 - val_MinusLogProbMetric: 17.0606 - lr: 4.1667e-05 - 63s/epoch - 319ms/step
Epoch 605/1000
2023-09-24 01:46:19.800 
Epoch 605/1000 
	 loss: 16.2163, MinusLogProbMetric: 16.2163, val_loss: 17.0338, val_MinusLogProbMetric: 17.0338

Epoch 605: val_loss improved from 17.03555 to 17.03383, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 62s - loss: 16.2163 - MinusLogProbMetric: 16.2163 - val_loss: 17.0338 - val_MinusLogProbMetric: 17.0338 - lr: 4.1667e-05 - 62s/epoch - 316ms/step
Epoch 606/1000
2023-09-24 01:47:22.934 
Epoch 606/1000 
	 loss: 16.2176, MinusLogProbMetric: 16.2176, val_loss: 17.1113, val_MinusLogProbMetric: 17.1113

Epoch 606: val_loss did not improve from 17.03383
196/196 - 62s - loss: 16.2176 - MinusLogProbMetric: 16.2176 - val_loss: 17.1113 - val_MinusLogProbMetric: 17.1113 - lr: 4.1667e-05 - 62s/epoch - 317ms/step
Epoch 607/1000
2023-09-24 01:48:26.227 
Epoch 607/1000 
	 loss: 16.2239, MinusLogProbMetric: 16.2239, val_loss: 17.0469, val_MinusLogProbMetric: 17.0469

Epoch 607: val_loss did not improve from 17.03383
196/196 - 63s - loss: 16.2239 - MinusLogProbMetric: 16.2239 - val_loss: 17.0469 - val_MinusLogProbMetric: 17.0469 - lr: 4.1667e-05 - 63s/epoch - 323ms/step
Epoch 608/1000
2023-09-24 01:49:27.016 
Epoch 608/1000 
	 loss: 16.2191, MinusLogProbMetric: 16.2191, val_loss: 17.0670, val_MinusLogProbMetric: 17.0670

Epoch 608: val_loss did not improve from 17.03383
196/196 - 61s - loss: 16.2191 - MinusLogProbMetric: 16.2191 - val_loss: 17.0670 - val_MinusLogProbMetric: 17.0670 - lr: 4.1667e-05 - 61s/epoch - 310ms/step
Epoch 609/1000
2023-09-24 01:50:29.289 
Epoch 609/1000 
	 loss: 16.2126, MinusLogProbMetric: 16.2126, val_loss: 17.0557, val_MinusLogProbMetric: 17.0557

Epoch 609: val_loss did not improve from 17.03383
196/196 - 62s - loss: 16.2126 - MinusLogProbMetric: 16.2126 - val_loss: 17.0557 - val_MinusLogProbMetric: 17.0557 - lr: 4.1667e-05 - 62s/epoch - 318ms/step
Epoch 610/1000
2023-09-24 01:51:31.226 
Epoch 610/1000 
	 loss: 16.2142, MinusLogProbMetric: 16.2142, val_loss: 17.0565, val_MinusLogProbMetric: 17.0565

Epoch 610: val_loss did not improve from 17.03383
196/196 - 62s - loss: 16.2142 - MinusLogProbMetric: 16.2142 - val_loss: 17.0565 - val_MinusLogProbMetric: 17.0565 - lr: 4.1667e-05 - 62s/epoch - 316ms/step
Epoch 611/1000
2023-09-24 01:52:32.360 
Epoch 611/1000 
	 loss: 16.2235, MinusLogProbMetric: 16.2235, val_loss: 17.0419, val_MinusLogProbMetric: 17.0419

Epoch 611: val_loss did not improve from 17.03383
196/196 - 61s - loss: 16.2235 - MinusLogProbMetric: 16.2235 - val_loss: 17.0419 - val_MinusLogProbMetric: 17.0419 - lr: 4.1667e-05 - 61s/epoch - 312ms/step
Epoch 612/1000
2023-09-24 01:53:33.784 
Epoch 612/1000 
	 loss: 16.2138, MinusLogProbMetric: 16.2138, val_loss: 17.0795, val_MinusLogProbMetric: 17.0795

Epoch 612: val_loss did not improve from 17.03383
196/196 - 61s - loss: 16.2138 - MinusLogProbMetric: 16.2138 - val_loss: 17.0795 - val_MinusLogProbMetric: 17.0795 - lr: 4.1667e-05 - 61s/epoch - 313ms/step
Epoch 613/1000
2023-09-24 01:54:34.799 
Epoch 613/1000 
	 loss: 16.2158, MinusLogProbMetric: 16.2158, val_loss: 17.0755, val_MinusLogProbMetric: 17.0755

Epoch 613: val_loss did not improve from 17.03383
196/196 - 61s - loss: 16.2158 - MinusLogProbMetric: 16.2158 - val_loss: 17.0755 - val_MinusLogProbMetric: 17.0755 - lr: 4.1667e-05 - 61s/epoch - 311ms/step
Epoch 614/1000
2023-09-24 01:55:37.272 
Epoch 614/1000 
	 loss: 16.2164, MinusLogProbMetric: 16.2164, val_loss: 17.0491, val_MinusLogProbMetric: 17.0491

Epoch 614: val_loss did not improve from 17.03383
196/196 - 62s - loss: 16.2164 - MinusLogProbMetric: 16.2164 - val_loss: 17.0491 - val_MinusLogProbMetric: 17.0491 - lr: 4.1667e-05 - 62s/epoch - 319ms/step
Epoch 615/1000
2023-09-24 01:56:41.022 
Epoch 615/1000 
	 loss: 16.2209, MinusLogProbMetric: 16.2209, val_loss: 17.0485, val_MinusLogProbMetric: 17.0485

Epoch 615: val_loss did not improve from 17.03383
196/196 - 64s - loss: 16.2209 - MinusLogProbMetric: 16.2209 - val_loss: 17.0485 - val_MinusLogProbMetric: 17.0485 - lr: 4.1667e-05 - 64s/epoch - 325ms/step
Epoch 616/1000
2023-09-24 01:57:43.866 
Epoch 616/1000 
	 loss: 16.2203, MinusLogProbMetric: 16.2203, val_loss: 17.0506, val_MinusLogProbMetric: 17.0506

Epoch 616: val_loss did not improve from 17.03383
196/196 - 63s - loss: 16.2203 - MinusLogProbMetric: 16.2203 - val_loss: 17.0506 - val_MinusLogProbMetric: 17.0506 - lr: 4.1667e-05 - 63s/epoch - 321ms/step
Epoch 617/1000
2023-09-24 01:58:46.312 
Epoch 617/1000 
	 loss: 16.2216, MinusLogProbMetric: 16.2216, val_loss: 17.0691, val_MinusLogProbMetric: 17.0691

Epoch 617: val_loss did not improve from 17.03383
196/196 - 62s - loss: 16.2216 - MinusLogProbMetric: 16.2216 - val_loss: 17.0691 - val_MinusLogProbMetric: 17.0691 - lr: 4.1667e-05 - 62s/epoch - 319ms/step
Epoch 618/1000
2023-09-24 01:59:46.516 
Epoch 618/1000 
	 loss: 16.2132, MinusLogProbMetric: 16.2132, val_loss: 17.0625, val_MinusLogProbMetric: 17.0625

Epoch 618: val_loss did not improve from 17.03383
196/196 - 60s - loss: 16.2132 - MinusLogProbMetric: 16.2132 - val_loss: 17.0625 - val_MinusLogProbMetric: 17.0625 - lr: 4.1667e-05 - 60s/epoch - 307ms/step
Epoch 619/1000
2023-09-24 02:00:47.444 
Epoch 619/1000 
	 loss: 16.2149, MinusLogProbMetric: 16.2149, val_loss: 17.0640, val_MinusLogProbMetric: 17.0640

Epoch 619: val_loss did not improve from 17.03383
196/196 - 61s - loss: 16.2149 - MinusLogProbMetric: 16.2149 - val_loss: 17.0640 - val_MinusLogProbMetric: 17.0640 - lr: 4.1667e-05 - 61s/epoch - 311ms/step
Epoch 620/1000
2023-09-24 02:01:48.891 
Epoch 620/1000 
	 loss: 16.2145, MinusLogProbMetric: 16.2145, val_loss: 17.0463, val_MinusLogProbMetric: 17.0463

Epoch 620: val_loss did not improve from 17.03383
196/196 - 61s - loss: 16.2145 - MinusLogProbMetric: 16.2145 - val_loss: 17.0463 - val_MinusLogProbMetric: 17.0463 - lr: 4.1667e-05 - 61s/epoch - 313ms/step
Epoch 621/1000
2023-09-24 02:02:50.653 
Epoch 621/1000 
	 loss: 16.2166, MinusLogProbMetric: 16.2166, val_loss: 17.0433, val_MinusLogProbMetric: 17.0433

Epoch 621: val_loss did not improve from 17.03383
196/196 - 62s - loss: 16.2166 - MinusLogProbMetric: 16.2166 - val_loss: 17.0433 - val_MinusLogProbMetric: 17.0433 - lr: 4.1667e-05 - 62s/epoch - 315ms/step
Epoch 622/1000
2023-09-24 02:03:52.466 
Epoch 622/1000 
	 loss: 16.2195, MinusLogProbMetric: 16.2195, val_loss: 17.0709, val_MinusLogProbMetric: 17.0709

Epoch 622: val_loss did not improve from 17.03383
196/196 - 62s - loss: 16.2195 - MinusLogProbMetric: 16.2195 - val_loss: 17.0709 - val_MinusLogProbMetric: 17.0709 - lr: 4.1667e-05 - 62s/epoch - 315ms/step
Epoch 623/1000
2023-09-24 02:04:54.399 
Epoch 623/1000 
	 loss: 16.2116, MinusLogProbMetric: 16.2116, val_loss: 17.0539, val_MinusLogProbMetric: 17.0539

Epoch 623: val_loss did not improve from 17.03383
196/196 - 62s - loss: 16.2116 - MinusLogProbMetric: 16.2116 - val_loss: 17.0539 - val_MinusLogProbMetric: 17.0539 - lr: 4.1667e-05 - 62s/epoch - 316ms/step
Epoch 624/1000
2023-09-24 02:05:55.803 
Epoch 624/1000 
	 loss: 16.2174, MinusLogProbMetric: 16.2174, val_loss: 17.1019, val_MinusLogProbMetric: 17.1019

Epoch 624: val_loss did not improve from 17.03383
196/196 - 61s - loss: 16.2174 - MinusLogProbMetric: 16.2174 - val_loss: 17.1019 - val_MinusLogProbMetric: 17.1019 - lr: 4.1667e-05 - 61s/epoch - 313ms/step
Epoch 625/1000
2023-09-24 02:06:56.720 
Epoch 625/1000 
	 loss: 16.2162, MinusLogProbMetric: 16.2162, val_loss: 17.0597, val_MinusLogProbMetric: 17.0597

Epoch 625: val_loss did not improve from 17.03383
196/196 - 61s - loss: 16.2162 - MinusLogProbMetric: 16.2162 - val_loss: 17.0597 - val_MinusLogProbMetric: 17.0597 - lr: 4.1667e-05 - 61s/epoch - 311ms/step
Epoch 626/1000
2023-09-24 02:07:58.754 
Epoch 626/1000 
	 loss: 16.2122, MinusLogProbMetric: 16.2122, val_loss: 17.0478, val_MinusLogProbMetric: 17.0478

Epoch 626: val_loss did not improve from 17.03383
196/196 - 62s - loss: 16.2122 - MinusLogProbMetric: 16.2122 - val_loss: 17.0478 - val_MinusLogProbMetric: 17.0478 - lr: 4.1667e-05 - 62s/epoch - 316ms/step
Epoch 627/1000
2023-09-24 02:09:00.061 
Epoch 627/1000 
	 loss: 16.2187, MinusLogProbMetric: 16.2187, val_loss: 17.0435, val_MinusLogProbMetric: 17.0435

Epoch 627: val_loss did not improve from 17.03383
196/196 - 61s - loss: 16.2187 - MinusLogProbMetric: 16.2187 - val_loss: 17.0435 - val_MinusLogProbMetric: 17.0435 - lr: 4.1667e-05 - 61s/epoch - 313ms/step
Epoch 628/1000
2023-09-24 02:10:02.756 
Epoch 628/1000 
	 loss: 16.2188, MinusLogProbMetric: 16.2188, val_loss: 17.1097, val_MinusLogProbMetric: 17.1097

Epoch 628: val_loss did not improve from 17.03383
196/196 - 63s - loss: 16.2188 - MinusLogProbMetric: 16.2188 - val_loss: 17.1097 - val_MinusLogProbMetric: 17.1097 - lr: 4.1667e-05 - 63s/epoch - 320ms/step
Epoch 629/1000
2023-09-24 02:11:04.344 
Epoch 629/1000 
	 loss: 16.2159, MinusLogProbMetric: 16.2159, val_loss: 17.0512, val_MinusLogProbMetric: 17.0512

Epoch 629: val_loss did not improve from 17.03383
196/196 - 62s - loss: 16.2159 - MinusLogProbMetric: 16.2159 - val_loss: 17.0512 - val_MinusLogProbMetric: 17.0512 - lr: 4.1667e-05 - 62s/epoch - 314ms/step
Epoch 630/1000
2023-09-24 02:12:06.527 
Epoch 630/1000 
	 loss: 16.2094, MinusLogProbMetric: 16.2094, val_loss: 17.0770, val_MinusLogProbMetric: 17.0770

Epoch 630: val_loss did not improve from 17.03383
196/196 - 62s - loss: 16.2094 - MinusLogProbMetric: 16.2094 - val_loss: 17.0770 - val_MinusLogProbMetric: 17.0770 - lr: 4.1667e-05 - 62s/epoch - 317ms/step
Epoch 631/1000
2023-09-24 02:13:08.396 
Epoch 631/1000 
	 loss: 16.2165, MinusLogProbMetric: 16.2165, val_loss: 17.0597, val_MinusLogProbMetric: 17.0597

Epoch 631: val_loss did not improve from 17.03383
196/196 - 62s - loss: 16.2165 - MinusLogProbMetric: 16.2165 - val_loss: 17.0597 - val_MinusLogProbMetric: 17.0597 - lr: 4.1667e-05 - 62s/epoch - 316ms/step
Epoch 632/1000
2023-09-24 02:14:10.645 
Epoch 632/1000 
	 loss: 16.2165, MinusLogProbMetric: 16.2165, val_loss: 17.0464, val_MinusLogProbMetric: 17.0464

Epoch 632: val_loss did not improve from 17.03383
196/196 - 62s - loss: 16.2165 - MinusLogProbMetric: 16.2165 - val_loss: 17.0464 - val_MinusLogProbMetric: 17.0464 - lr: 4.1667e-05 - 62s/epoch - 318ms/step
Epoch 633/1000
2023-09-24 02:15:13.435 
Epoch 633/1000 
	 loss: 16.2136, MinusLogProbMetric: 16.2136, val_loss: 17.0335, val_MinusLogProbMetric: 17.0335

Epoch 633: val_loss improved from 17.03383 to 17.03354, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 64s - loss: 16.2136 - MinusLogProbMetric: 16.2136 - val_loss: 17.0335 - val_MinusLogProbMetric: 17.0335 - lr: 4.1667e-05 - 64s/epoch - 325ms/step
Epoch 634/1000
2023-09-24 02:16:14.473 
Epoch 634/1000 
	 loss: 16.2135, MinusLogProbMetric: 16.2135, val_loss: 17.0692, val_MinusLogProbMetric: 17.0692

Epoch 634: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.2135 - MinusLogProbMetric: 16.2135 - val_loss: 17.0692 - val_MinusLogProbMetric: 17.0692 - lr: 4.1667e-05 - 60s/epoch - 306ms/step
Epoch 635/1000
2023-09-24 02:17:14.860 
Epoch 635/1000 
	 loss: 16.2142, MinusLogProbMetric: 16.2142, val_loss: 17.0738, val_MinusLogProbMetric: 17.0738

Epoch 635: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.2142 - MinusLogProbMetric: 16.2142 - val_loss: 17.0738 - val_MinusLogProbMetric: 17.0738 - lr: 4.1667e-05 - 60s/epoch - 308ms/step
Epoch 636/1000
2023-09-24 02:18:14.131 
Epoch 636/1000 
	 loss: 16.2065, MinusLogProbMetric: 16.2065, val_loss: 17.0573, val_MinusLogProbMetric: 17.0573

Epoch 636: val_loss did not improve from 17.03354
196/196 - 59s - loss: 16.2065 - MinusLogProbMetric: 16.2065 - val_loss: 17.0573 - val_MinusLogProbMetric: 17.0573 - lr: 4.1667e-05 - 59s/epoch - 302ms/step
Epoch 637/1000
2023-09-24 02:19:14.420 
Epoch 637/1000 
	 loss: 16.2125, MinusLogProbMetric: 16.2125, val_loss: 17.0906, val_MinusLogProbMetric: 17.0906

Epoch 637: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.2125 - MinusLogProbMetric: 16.2125 - val_loss: 17.0906 - val_MinusLogProbMetric: 17.0906 - lr: 4.1667e-05 - 60s/epoch - 308ms/step
Epoch 638/1000
2023-09-24 02:20:15.687 
Epoch 638/1000 
	 loss: 16.2141, MinusLogProbMetric: 16.2141, val_loss: 17.0645, val_MinusLogProbMetric: 17.0645

Epoch 638: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.2141 - MinusLogProbMetric: 16.2141 - val_loss: 17.0645 - val_MinusLogProbMetric: 17.0645 - lr: 4.1667e-05 - 61s/epoch - 313ms/step
Epoch 639/1000
2023-09-24 02:21:16.471 
Epoch 639/1000 
	 loss: 16.2111, MinusLogProbMetric: 16.2111, val_loss: 17.0512, val_MinusLogProbMetric: 17.0512

Epoch 639: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.2111 - MinusLogProbMetric: 16.2111 - val_loss: 17.0512 - val_MinusLogProbMetric: 17.0512 - lr: 4.1667e-05 - 61s/epoch - 310ms/step
Epoch 640/1000
2023-09-24 02:22:17.173 
Epoch 640/1000 
	 loss: 16.2146, MinusLogProbMetric: 16.2146, val_loss: 17.0515, val_MinusLogProbMetric: 17.0515

Epoch 640: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.2146 - MinusLogProbMetric: 16.2146 - val_loss: 17.0515 - val_MinusLogProbMetric: 17.0515 - lr: 4.1667e-05 - 61s/epoch - 310ms/step
Epoch 641/1000
2023-09-24 02:23:18.974 
Epoch 641/1000 
	 loss: 16.2166, MinusLogProbMetric: 16.2166, val_loss: 17.0476, val_MinusLogProbMetric: 17.0476

Epoch 641: val_loss did not improve from 17.03354
196/196 - 62s - loss: 16.2166 - MinusLogProbMetric: 16.2166 - val_loss: 17.0476 - val_MinusLogProbMetric: 17.0476 - lr: 4.1667e-05 - 62s/epoch - 315ms/step
Epoch 642/1000
2023-09-24 02:24:21.135 
Epoch 642/1000 
	 loss: 16.2073, MinusLogProbMetric: 16.2073, val_loss: 17.0630, val_MinusLogProbMetric: 17.0630

Epoch 642: val_loss did not improve from 17.03354
196/196 - 62s - loss: 16.2073 - MinusLogProbMetric: 16.2073 - val_loss: 17.0630 - val_MinusLogProbMetric: 17.0630 - lr: 4.1667e-05 - 62s/epoch - 317ms/step
Epoch 643/1000
2023-09-24 02:25:26.014 
Epoch 643/1000 
	 loss: 16.2135, MinusLogProbMetric: 16.2135, val_loss: 17.0474, val_MinusLogProbMetric: 17.0474

Epoch 643: val_loss did not improve from 17.03354
196/196 - 65s - loss: 16.2135 - MinusLogProbMetric: 16.2135 - val_loss: 17.0474 - val_MinusLogProbMetric: 17.0474 - lr: 4.1667e-05 - 65s/epoch - 331ms/step
Epoch 644/1000
2023-09-24 02:26:27.486 
Epoch 644/1000 
	 loss: 16.2186, MinusLogProbMetric: 16.2186, val_loss: 17.0548, val_MinusLogProbMetric: 17.0548

Epoch 644: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.2186 - MinusLogProbMetric: 16.2186 - val_loss: 17.0548 - val_MinusLogProbMetric: 17.0548 - lr: 4.1667e-05 - 61s/epoch - 314ms/step
Epoch 645/1000
2023-09-24 02:27:28.801 
Epoch 645/1000 
	 loss: 16.2129, MinusLogProbMetric: 16.2129, val_loss: 17.0421, val_MinusLogProbMetric: 17.0421

Epoch 645: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.2129 - MinusLogProbMetric: 16.2129 - val_loss: 17.0421 - val_MinusLogProbMetric: 17.0421 - lr: 4.1667e-05 - 61s/epoch - 313ms/step
Epoch 646/1000
2023-09-24 02:28:30.384 
Epoch 646/1000 
	 loss: 16.2088, MinusLogProbMetric: 16.2088, val_loss: 17.0549, val_MinusLogProbMetric: 17.0549

Epoch 646: val_loss did not improve from 17.03354
196/196 - 62s - loss: 16.2088 - MinusLogProbMetric: 16.2088 - val_loss: 17.0549 - val_MinusLogProbMetric: 17.0549 - lr: 4.1667e-05 - 62s/epoch - 314ms/step
Epoch 647/1000
2023-09-24 02:29:32.103 
Epoch 647/1000 
	 loss: 16.2112, MinusLogProbMetric: 16.2112, val_loss: 17.0608, val_MinusLogProbMetric: 17.0608

Epoch 647: val_loss did not improve from 17.03354
196/196 - 62s - loss: 16.2112 - MinusLogProbMetric: 16.2112 - val_loss: 17.0608 - val_MinusLogProbMetric: 17.0608 - lr: 4.1667e-05 - 62s/epoch - 315ms/step
Epoch 648/1000
2023-09-24 02:30:34.150 
Epoch 648/1000 
	 loss: 16.2146, MinusLogProbMetric: 16.2146, val_loss: 17.0447, val_MinusLogProbMetric: 17.0447

Epoch 648: val_loss did not improve from 17.03354
196/196 - 62s - loss: 16.2146 - MinusLogProbMetric: 16.2146 - val_loss: 17.0447 - val_MinusLogProbMetric: 17.0447 - lr: 4.1667e-05 - 62s/epoch - 317ms/step
Epoch 649/1000
2023-09-24 02:31:35.317 
Epoch 649/1000 
	 loss: 16.2163, MinusLogProbMetric: 16.2163, val_loss: 17.0607, val_MinusLogProbMetric: 17.0607

Epoch 649: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.2163 - MinusLogProbMetric: 16.2163 - val_loss: 17.0607 - val_MinusLogProbMetric: 17.0607 - lr: 4.1667e-05 - 61s/epoch - 312ms/step
Epoch 650/1000
2023-09-24 02:32:34.860 
Epoch 650/1000 
	 loss: 16.2047, MinusLogProbMetric: 16.2047, val_loss: 17.0971, val_MinusLogProbMetric: 17.0971

Epoch 650: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.2047 - MinusLogProbMetric: 16.2047 - val_loss: 17.0971 - val_MinusLogProbMetric: 17.0971 - lr: 4.1667e-05 - 60s/epoch - 304ms/step
Epoch 651/1000
2023-09-24 02:33:36.797 
Epoch 651/1000 
	 loss: 16.2063, MinusLogProbMetric: 16.2063, val_loss: 17.1048, val_MinusLogProbMetric: 17.1048

Epoch 651: val_loss did not improve from 17.03354
196/196 - 62s - loss: 16.2063 - MinusLogProbMetric: 16.2063 - val_loss: 17.1048 - val_MinusLogProbMetric: 17.1048 - lr: 4.1667e-05 - 62s/epoch - 316ms/step
Epoch 652/1000
2023-09-24 02:34:38.618 
Epoch 652/1000 
	 loss: 16.2096, MinusLogProbMetric: 16.2096, val_loss: 17.0573, val_MinusLogProbMetric: 17.0573

Epoch 652: val_loss did not improve from 17.03354
196/196 - 62s - loss: 16.2096 - MinusLogProbMetric: 16.2096 - val_loss: 17.0573 - val_MinusLogProbMetric: 17.0573 - lr: 4.1667e-05 - 62s/epoch - 315ms/step
Epoch 653/1000
2023-09-24 02:35:41.900 
Epoch 653/1000 
	 loss: 16.2089, MinusLogProbMetric: 16.2089, val_loss: 17.0790, val_MinusLogProbMetric: 17.0790

Epoch 653: val_loss did not improve from 17.03354
196/196 - 63s - loss: 16.2089 - MinusLogProbMetric: 16.2089 - val_loss: 17.0790 - val_MinusLogProbMetric: 17.0790 - lr: 4.1667e-05 - 63s/epoch - 323ms/step
Epoch 654/1000
2023-09-24 02:36:45.200 
Epoch 654/1000 
	 loss: 16.2081, MinusLogProbMetric: 16.2081, val_loss: 17.0537, val_MinusLogProbMetric: 17.0537

Epoch 654: val_loss did not improve from 17.03354
196/196 - 63s - loss: 16.2081 - MinusLogProbMetric: 16.2081 - val_loss: 17.0537 - val_MinusLogProbMetric: 17.0537 - lr: 4.1667e-05 - 63s/epoch - 323ms/step
Epoch 655/1000
2023-09-24 02:37:46.595 
Epoch 655/1000 
	 loss: 16.2069, MinusLogProbMetric: 16.2069, val_loss: 17.0635, val_MinusLogProbMetric: 17.0635

Epoch 655: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.2069 - MinusLogProbMetric: 16.2069 - val_loss: 17.0635 - val_MinusLogProbMetric: 17.0635 - lr: 4.1667e-05 - 61s/epoch - 313ms/step
Epoch 656/1000
2023-09-24 02:38:47.174 
Epoch 656/1000 
	 loss: 16.2126, MinusLogProbMetric: 16.2126, val_loss: 17.0873, val_MinusLogProbMetric: 17.0873

Epoch 656: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.2126 - MinusLogProbMetric: 16.2126 - val_loss: 17.0873 - val_MinusLogProbMetric: 17.0873 - lr: 4.1667e-05 - 61s/epoch - 309ms/step
Epoch 657/1000
2023-09-24 02:39:48.308 
Epoch 657/1000 
	 loss: 16.2146, MinusLogProbMetric: 16.2146, val_loss: 17.0706, val_MinusLogProbMetric: 17.0706

Epoch 657: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.2146 - MinusLogProbMetric: 16.2146 - val_loss: 17.0706 - val_MinusLogProbMetric: 17.0706 - lr: 4.1667e-05 - 61s/epoch - 312ms/step
Epoch 658/1000
2023-09-24 02:40:48.817 
Epoch 658/1000 
	 loss: 16.2137, MinusLogProbMetric: 16.2137, val_loss: 17.0620, val_MinusLogProbMetric: 17.0620

Epoch 658: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.2137 - MinusLogProbMetric: 16.2137 - val_loss: 17.0620 - val_MinusLogProbMetric: 17.0620 - lr: 4.1667e-05 - 61s/epoch - 309ms/step
Epoch 659/1000
2023-09-24 02:41:50.931 
Epoch 659/1000 
	 loss: 16.2079, MinusLogProbMetric: 16.2079, val_loss: 17.1050, val_MinusLogProbMetric: 17.1050

Epoch 659: val_loss did not improve from 17.03354
196/196 - 62s - loss: 16.2079 - MinusLogProbMetric: 16.2079 - val_loss: 17.1050 - val_MinusLogProbMetric: 17.1050 - lr: 4.1667e-05 - 62s/epoch - 317ms/step
Epoch 660/1000
2023-09-24 02:42:54.956 
Epoch 660/1000 
	 loss: 16.2057, MinusLogProbMetric: 16.2057, val_loss: 17.0552, val_MinusLogProbMetric: 17.0552

Epoch 660: val_loss did not improve from 17.03354
196/196 - 64s - loss: 16.2057 - MinusLogProbMetric: 16.2057 - val_loss: 17.0552 - val_MinusLogProbMetric: 17.0552 - lr: 4.1667e-05 - 64s/epoch - 327ms/step
Epoch 661/1000
2023-09-24 02:43:54.932 
Epoch 661/1000 
	 loss: 16.2041, MinusLogProbMetric: 16.2041, val_loss: 17.0409, val_MinusLogProbMetric: 17.0409

Epoch 661: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.2041 - MinusLogProbMetric: 16.2041 - val_loss: 17.0409 - val_MinusLogProbMetric: 17.0409 - lr: 4.1667e-05 - 60s/epoch - 306ms/step
Epoch 662/1000
2023-09-24 02:44:59.213 
Epoch 662/1000 
	 loss: 16.2013, MinusLogProbMetric: 16.2013, val_loss: 17.0750, val_MinusLogProbMetric: 17.0750

Epoch 662: val_loss did not improve from 17.03354
196/196 - 64s - loss: 16.2013 - MinusLogProbMetric: 16.2013 - val_loss: 17.0750 - val_MinusLogProbMetric: 17.0750 - lr: 4.1667e-05 - 64s/epoch - 328ms/step
Epoch 663/1000
2023-09-24 02:45:59.954 
Epoch 663/1000 
	 loss: 16.2085, MinusLogProbMetric: 16.2085, val_loss: 17.0871, val_MinusLogProbMetric: 17.0871

Epoch 663: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.2085 - MinusLogProbMetric: 16.2085 - val_loss: 17.0871 - val_MinusLogProbMetric: 17.0871 - lr: 4.1667e-05 - 61s/epoch - 310ms/step
Epoch 664/1000
2023-09-24 02:47:02.258 
Epoch 664/1000 
	 loss: 16.2095, MinusLogProbMetric: 16.2095, val_loss: 17.0485, val_MinusLogProbMetric: 17.0485

Epoch 664: val_loss did not improve from 17.03354
196/196 - 62s - loss: 16.2095 - MinusLogProbMetric: 16.2095 - val_loss: 17.0485 - val_MinusLogProbMetric: 17.0485 - lr: 4.1667e-05 - 62s/epoch - 318ms/step
Epoch 665/1000
2023-09-24 02:48:05.395 
Epoch 665/1000 
	 loss: 16.2045, MinusLogProbMetric: 16.2045, val_loss: 17.0767, val_MinusLogProbMetric: 17.0767

Epoch 665: val_loss did not improve from 17.03354
196/196 - 63s - loss: 16.2045 - MinusLogProbMetric: 16.2045 - val_loss: 17.0767 - val_MinusLogProbMetric: 17.0767 - lr: 4.1667e-05 - 63s/epoch - 322ms/step
Epoch 666/1000
2023-09-24 02:49:05.435 
Epoch 666/1000 
	 loss: 16.2100, MinusLogProbMetric: 16.2100, val_loss: 17.1054, val_MinusLogProbMetric: 17.1054

Epoch 666: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.2100 - MinusLogProbMetric: 16.2100 - val_loss: 17.1054 - val_MinusLogProbMetric: 17.1054 - lr: 4.1667e-05 - 60s/epoch - 306ms/step
Epoch 667/1000
2023-09-24 02:50:07.995 
Epoch 667/1000 
	 loss: 16.2062, MinusLogProbMetric: 16.2062, val_loss: 17.0390, val_MinusLogProbMetric: 17.0390

Epoch 667: val_loss did not improve from 17.03354
196/196 - 63s - loss: 16.2062 - MinusLogProbMetric: 16.2062 - val_loss: 17.0390 - val_MinusLogProbMetric: 17.0390 - lr: 4.1667e-05 - 63s/epoch - 319ms/step
Epoch 668/1000
2023-09-24 02:51:11.500 
Epoch 668/1000 
	 loss: 16.2098, MinusLogProbMetric: 16.2098, val_loss: 17.0787, val_MinusLogProbMetric: 17.0787

Epoch 668: val_loss did not improve from 17.03354
196/196 - 63s - loss: 16.2098 - MinusLogProbMetric: 16.2098 - val_loss: 17.0787 - val_MinusLogProbMetric: 17.0787 - lr: 4.1667e-05 - 63s/epoch - 324ms/step
Epoch 669/1000
2023-09-24 02:52:13.718 
Epoch 669/1000 
	 loss: 16.2115, MinusLogProbMetric: 16.2115, val_loss: 17.0504, val_MinusLogProbMetric: 17.0504

Epoch 669: val_loss did not improve from 17.03354
196/196 - 62s - loss: 16.2115 - MinusLogProbMetric: 16.2115 - val_loss: 17.0504 - val_MinusLogProbMetric: 17.0504 - lr: 4.1667e-05 - 62s/epoch - 317ms/step
Epoch 670/1000
2023-09-24 02:53:13.422 
Epoch 670/1000 
	 loss: 16.2004, MinusLogProbMetric: 16.2004, val_loss: 17.0679, val_MinusLogProbMetric: 17.0679

Epoch 670: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.2004 - MinusLogProbMetric: 16.2004 - val_loss: 17.0679 - val_MinusLogProbMetric: 17.0679 - lr: 4.1667e-05 - 60s/epoch - 305ms/step
Epoch 671/1000
2023-09-24 02:54:13.341 
Epoch 671/1000 
	 loss: 16.2071, MinusLogProbMetric: 16.2071, val_loss: 17.0643, val_MinusLogProbMetric: 17.0643

Epoch 671: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.2071 - MinusLogProbMetric: 16.2071 - val_loss: 17.0643 - val_MinusLogProbMetric: 17.0643 - lr: 4.1667e-05 - 60s/epoch - 306ms/step
Epoch 672/1000
2023-09-24 02:55:12.781 
Epoch 672/1000 
	 loss: 16.1997, MinusLogProbMetric: 16.1997, val_loss: 17.0525, val_MinusLogProbMetric: 17.0525

Epoch 672: val_loss did not improve from 17.03354
196/196 - 59s - loss: 16.1997 - MinusLogProbMetric: 16.1997 - val_loss: 17.0525 - val_MinusLogProbMetric: 17.0525 - lr: 4.1667e-05 - 59s/epoch - 303ms/step
Epoch 673/1000
2023-09-24 02:56:14.100 
Epoch 673/1000 
	 loss: 16.2072, MinusLogProbMetric: 16.2072, val_loss: 17.0586, val_MinusLogProbMetric: 17.0586

Epoch 673: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.2072 - MinusLogProbMetric: 16.2072 - val_loss: 17.0586 - val_MinusLogProbMetric: 17.0586 - lr: 4.1667e-05 - 61s/epoch - 313ms/step
Epoch 674/1000
2023-09-24 02:57:14.728 
Epoch 674/1000 
	 loss: 16.2110, MinusLogProbMetric: 16.2110, val_loss: 17.1109, val_MinusLogProbMetric: 17.1109

Epoch 674: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.2110 - MinusLogProbMetric: 16.2110 - val_loss: 17.1109 - val_MinusLogProbMetric: 17.1109 - lr: 4.1667e-05 - 61s/epoch - 309ms/step
Epoch 675/1000
2023-09-24 02:58:14.431 
Epoch 675/1000 
	 loss: 16.2087, MinusLogProbMetric: 16.2087, val_loss: 17.0477, val_MinusLogProbMetric: 17.0477

Epoch 675: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.2087 - MinusLogProbMetric: 16.2087 - val_loss: 17.0477 - val_MinusLogProbMetric: 17.0477 - lr: 4.1667e-05 - 60s/epoch - 305ms/step
Epoch 676/1000
2023-09-24 02:59:15.365 
Epoch 676/1000 
	 loss: 16.1982, MinusLogProbMetric: 16.1982, val_loss: 17.0919, val_MinusLogProbMetric: 17.0919

Epoch 676: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.1982 - MinusLogProbMetric: 16.1982 - val_loss: 17.0919 - val_MinusLogProbMetric: 17.0919 - lr: 4.1667e-05 - 61s/epoch - 311ms/step
Epoch 677/1000
2023-09-24 03:00:16.236 
Epoch 677/1000 
	 loss: 16.2062, MinusLogProbMetric: 16.2062, val_loss: 17.0420, val_MinusLogProbMetric: 17.0420

Epoch 677: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.2062 - MinusLogProbMetric: 16.2062 - val_loss: 17.0420 - val_MinusLogProbMetric: 17.0420 - lr: 4.1667e-05 - 61s/epoch - 311ms/step
Epoch 678/1000
2023-09-24 03:01:17.595 
Epoch 678/1000 
	 loss: 16.2077, MinusLogProbMetric: 16.2077, val_loss: 17.0492, val_MinusLogProbMetric: 17.0492

Epoch 678: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.2077 - MinusLogProbMetric: 16.2077 - val_loss: 17.0492 - val_MinusLogProbMetric: 17.0492 - lr: 4.1667e-05 - 61s/epoch - 313ms/step
Epoch 679/1000
2023-09-24 03:02:18.076 
Epoch 679/1000 
	 loss: 16.1984, MinusLogProbMetric: 16.1984, val_loss: 17.0531, val_MinusLogProbMetric: 17.0531

Epoch 679: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.1984 - MinusLogProbMetric: 16.1984 - val_loss: 17.0531 - val_MinusLogProbMetric: 17.0531 - lr: 4.1667e-05 - 60s/epoch - 309ms/step
Epoch 680/1000
2023-09-24 03:03:19.010 
Epoch 680/1000 
	 loss: 16.2088, MinusLogProbMetric: 16.2088, val_loss: 17.0546, val_MinusLogProbMetric: 17.0546

Epoch 680: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.2088 - MinusLogProbMetric: 16.2088 - val_loss: 17.0546 - val_MinusLogProbMetric: 17.0546 - lr: 4.1667e-05 - 61s/epoch - 311ms/step
Epoch 681/1000
2023-09-24 03:04:19.574 
Epoch 681/1000 
	 loss: 16.2022, MinusLogProbMetric: 16.2022, val_loss: 17.0476, val_MinusLogProbMetric: 17.0476

Epoch 681: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.2022 - MinusLogProbMetric: 16.2022 - val_loss: 17.0476 - val_MinusLogProbMetric: 17.0476 - lr: 4.1667e-05 - 61s/epoch - 309ms/step
Epoch 682/1000
2023-09-24 03:05:20.333 
Epoch 682/1000 
	 loss: 16.2079, MinusLogProbMetric: 16.2079, val_loss: 17.0761, val_MinusLogProbMetric: 17.0761

Epoch 682: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.2079 - MinusLogProbMetric: 16.2079 - val_loss: 17.0761 - val_MinusLogProbMetric: 17.0761 - lr: 4.1667e-05 - 61s/epoch - 310ms/step
Epoch 683/1000
2023-09-24 03:06:21.166 
Epoch 683/1000 
	 loss: 16.2047, MinusLogProbMetric: 16.2047, val_loss: 17.0971, val_MinusLogProbMetric: 17.0971

Epoch 683: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.2047 - MinusLogProbMetric: 16.2047 - val_loss: 17.0971 - val_MinusLogProbMetric: 17.0971 - lr: 4.1667e-05 - 61s/epoch - 310ms/step
Epoch 684/1000
2023-09-24 03:07:22.182 
Epoch 684/1000 
	 loss: 16.1761, MinusLogProbMetric: 16.1761, val_loss: 17.0476, val_MinusLogProbMetric: 17.0476

Epoch 684: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.1761 - MinusLogProbMetric: 16.1761 - val_loss: 17.0476 - val_MinusLogProbMetric: 17.0476 - lr: 2.0833e-05 - 61s/epoch - 311ms/step
Epoch 685/1000
2023-09-24 03:08:23.383 
Epoch 685/1000 
	 loss: 16.1730, MinusLogProbMetric: 16.1730, val_loss: 17.0480, val_MinusLogProbMetric: 17.0480

Epoch 685: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.1730 - MinusLogProbMetric: 16.1730 - val_loss: 17.0480 - val_MinusLogProbMetric: 17.0480 - lr: 2.0833e-05 - 61s/epoch - 312ms/step
Epoch 686/1000
2023-09-24 03:09:25.853 
Epoch 686/1000 
	 loss: 16.1735, MinusLogProbMetric: 16.1735, val_loss: 17.0421, val_MinusLogProbMetric: 17.0421

Epoch 686: val_loss did not improve from 17.03354
196/196 - 62s - loss: 16.1735 - MinusLogProbMetric: 16.1735 - val_loss: 17.0421 - val_MinusLogProbMetric: 17.0421 - lr: 2.0833e-05 - 62s/epoch - 319ms/step
Epoch 687/1000
2023-09-24 03:10:26.364 
Epoch 687/1000 
	 loss: 16.1738, MinusLogProbMetric: 16.1738, val_loss: 17.0443, val_MinusLogProbMetric: 17.0443

Epoch 687: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.1738 - MinusLogProbMetric: 16.1738 - val_loss: 17.0443 - val_MinusLogProbMetric: 17.0443 - lr: 2.0833e-05 - 61s/epoch - 309ms/step
Epoch 688/1000
2023-09-24 03:11:26.410 
Epoch 688/1000 
	 loss: 16.1773, MinusLogProbMetric: 16.1773, val_loss: 17.0437, val_MinusLogProbMetric: 17.0437

Epoch 688: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.1773 - MinusLogProbMetric: 16.1773 - val_loss: 17.0437 - val_MinusLogProbMetric: 17.0437 - lr: 2.0833e-05 - 60s/epoch - 306ms/step
Epoch 689/1000
2023-09-24 03:12:27.280 
Epoch 689/1000 
	 loss: 16.1729, MinusLogProbMetric: 16.1729, val_loss: 17.0444, val_MinusLogProbMetric: 17.0444

Epoch 689: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.1729 - MinusLogProbMetric: 16.1729 - val_loss: 17.0444 - val_MinusLogProbMetric: 17.0444 - lr: 2.0833e-05 - 61s/epoch - 311ms/step
Epoch 690/1000
2023-09-24 03:13:25.888 
Epoch 690/1000 
	 loss: 16.1736, MinusLogProbMetric: 16.1736, val_loss: 17.0391, val_MinusLogProbMetric: 17.0391

Epoch 690: val_loss did not improve from 17.03354
196/196 - 59s - loss: 16.1736 - MinusLogProbMetric: 16.1736 - val_loss: 17.0391 - val_MinusLogProbMetric: 17.0391 - lr: 2.0833e-05 - 59s/epoch - 299ms/step
Epoch 691/1000
2023-09-24 03:14:26.939 
Epoch 691/1000 
	 loss: 16.1724, MinusLogProbMetric: 16.1724, val_loss: 17.0444, val_MinusLogProbMetric: 17.0444

Epoch 691: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.1724 - MinusLogProbMetric: 16.1724 - val_loss: 17.0444 - val_MinusLogProbMetric: 17.0444 - lr: 2.0833e-05 - 61s/epoch - 311ms/step
Epoch 692/1000
2023-09-24 03:15:25.697 
Epoch 692/1000 
	 loss: 16.1749, MinusLogProbMetric: 16.1749, val_loss: 17.0441, val_MinusLogProbMetric: 17.0441

Epoch 692: val_loss did not improve from 17.03354
196/196 - 59s - loss: 16.1749 - MinusLogProbMetric: 16.1749 - val_loss: 17.0441 - val_MinusLogProbMetric: 17.0441 - lr: 2.0833e-05 - 59s/epoch - 300ms/step
Epoch 693/1000
2023-09-24 03:16:25.391 
Epoch 693/1000 
	 loss: 16.1769, MinusLogProbMetric: 16.1769, val_loss: 17.0527, val_MinusLogProbMetric: 17.0527

Epoch 693: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.1769 - MinusLogProbMetric: 16.1769 - val_loss: 17.0527 - val_MinusLogProbMetric: 17.0527 - lr: 2.0833e-05 - 60s/epoch - 305ms/step
Epoch 694/1000
2023-09-24 03:17:24.691 
Epoch 694/1000 
	 loss: 16.1751, MinusLogProbMetric: 16.1751, val_loss: 17.0438, val_MinusLogProbMetric: 17.0438

Epoch 694: val_loss did not improve from 17.03354
196/196 - 59s - loss: 16.1751 - MinusLogProbMetric: 16.1751 - val_loss: 17.0438 - val_MinusLogProbMetric: 17.0438 - lr: 2.0833e-05 - 59s/epoch - 303ms/step
Epoch 695/1000
2023-09-24 03:18:22.915 
Epoch 695/1000 
	 loss: 16.1710, MinusLogProbMetric: 16.1710, val_loss: 17.0453, val_MinusLogProbMetric: 17.0453

Epoch 695: val_loss did not improve from 17.03354
196/196 - 58s - loss: 16.1710 - MinusLogProbMetric: 16.1710 - val_loss: 17.0453 - val_MinusLogProbMetric: 17.0453 - lr: 2.0833e-05 - 58s/epoch - 297ms/step
Epoch 696/1000
2023-09-24 03:19:24.337 
Epoch 696/1000 
	 loss: 16.1726, MinusLogProbMetric: 16.1726, val_loss: 17.0448, val_MinusLogProbMetric: 17.0448

Epoch 696: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.1726 - MinusLogProbMetric: 16.1726 - val_loss: 17.0448 - val_MinusLogProbMetric: 17.0448 - lr: 2.0833e-05 - 61s/epoch - 313ms/step
Epoch 697/1000
2023-09-24 03:20:27.391 
Epoch 697/1000 
	 loss: 16.1746, MinusLogProbMetric: 16.1746, val_loss: 17.0627, val_MinusLogProbMetric: 17.0627

Epoch 697: val_loss did not improve from 17.03354
196/196 - 63s - loss: 16.1746 - MinusLogProbMetric: 16.1746 - val_loss: 17.0627 - val_MinusLogProbMetric: 17.0627 - lr: 2.0833e-05 - 63s/epoch - 322ms/step
Epoch 698/1000
2023-09-24 03:21:26.923 
Epoch 698/1000 
	 loss: 16.1741, MinusLogProbMetric: 16.1741, val_loss: 17.0514, val_MinusLogProbMetric: 17.0514

Epoch 698: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.1741 - MinusLogProbMetric: 16.1741 - val_loss: 17.0514 - val_MinusLogProbMetric: 17.0514 - lr: 2.0833e-05 - 60s/epoch - 304ms/step
Epoch 699/1000
2023-09-24 03:22:26.689 
Epoch 699/1000 
	 loss: 16.1737, MinusLogProbMetric: 16.1737, val_loss: 17.0343, val_MinusLogProbMetric: 17.0343

Epoch 699: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.1737 - MinusLogProbMetric: 16.1737 - val_loss: 17.0343 - val_MinusLogProbMetric: 17.0343 - lr: 2.0833e-05 - 60s/epoch - 305ms/step
Epoch 700/1000
2023-09-24 03:23:27.098 
Epoch 700/1000 
	 loss: 16.1698, MinusLogProbMetric: 16.1698, val_loss: 17.0414, val_MinusLogProbMetric: 17.0414

Epoch 700: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.1698 - MinusLogProbMetric: 16.1698 - val_loss: 17.0414 - val_MinusLogProbMetric: 17.0414 - lr: 2.0833e-05 - 60s/epoch - 308ms/step
Epoch 701/1000
2023-09-24 03:24:30.078 
Epoch 701/1000 
	 loss: 16.1680, MinusLogProbMetric: 16.1680, val_loss: 17.0476, val_MinusLogProbMetric: 17.0476

Epoch 701: val_loss did not improve from 17.03354
196/196 - 63s - loss: 16.1680 - MinusLogProbMetric: 16.1680 - val_loss: 17.0476 - val_MinusLogProbMetric: 17.0476 - lr: 2.0833e-05 - 63s/epoch - 321ms/step
Epoch 702/1000
2023-09-24 03:25:33.801 
Epoch 702/1000 
	 loss: 16.1786, MinusLogProbMetric: 16.1786, val_loss: 17.0378, val_MinusLogProbMetric: 17.0378

Epoch 702: val_loss did not improve from 17.03354
196/196 - 64s - loss: 16.1786 - MinusLogProbMetric: 16.1786 - val_loss: 17.0378 - val_MinusLogProbMetric: 17.0378 - lr: 2.0833e-05 - 64s/epoch - 325ms/step
Epoch 703/1000
2023-09-24 03:26:32.822 
Epoch 703/1000 
	 loss: 16.1707, MinusLogProbMetric: 16.1707, val_loss: 17.0549, val_MinusLogProbMetric: 17.0549

Epoch 703: val_loss did not improve from 17.03354
196/196 - 59s - loss: 16.1707 - MinusLogProbMetric: 16.1707 - val_loss: 17.0549 - val_MinusLogProbMetric: 17.0549 - lr: 2.0833e-05 - 59s/epoch - 301ms/step
Epoch 704/1000
2023-09-24 03:27:32.798 
Epoch 704/1000 
	 loss: 16.1737, MinusLogProbMetric: 16.1737, val_loss: 17.0738, val_MinusLogProbMetric: 17.0738

Epoch 704: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.1737 - MinusLogProbMetric: 16.1737 - val_loss: 17.0738 - val_MinusLogProbMetric: 17.0738 - lr: 2.0833e-05 - 60s/epoch - 306ms/step
Epoch 705/1000
2023-09-24 03:28:35.598 
Epoch 705/1000 
	 loss: 16.1701, MinusLogProbMetric: 16.1701, val_loss: 17.0450, val_MinusLogProbMetric: 17.0450

Epoch 705: val_loss did not improve from 17.03354
196/196 - 63s - loss: 16.1701 - MinusLogProbMetric: 16.1701 - val_loss: 17.0450 - val_MinusLogProbMetric: 17.0450 - lr: 2.0833e-05 - 63s/epoch - 320ms/step
Epoch 706/1000
2023-09-24 03:29:35.473 
Epoch 706/1000 
	 loss: 16.1695, MinusLogProbMetric: 16.1695, val_loss: 17.0543, val_MinusLogProbMetric: 17.0543

Epoch 706: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.1695 - MinusLogProbMetric: 16.1695 - val_loss: 17.0543 - val_MinusLogProbMetric: 17.0543 - lr: 2.0833e-05 - 60s/epoch - 305ms/step
Epoch 707/1000
2023-09-24 03:30:37.009 
Epoch 707/1000 
	 loss: 16.1739, MinusLogProbMetric: 16.1739, val_loss: 17.0583, val_MinusLogProbMetric: 17.0583

Epoch 707: val_loss did not improve from 17.03354
196/196 - 62s - loss: 16.1739 - MinusLogProbMetric: 16.1739 - val_loss: 17.0583 - val_MinusLogProbMetric: 17.0583 - lr: 2.0833e-05 - 62s/epoch - 314ms/step
Epoch 708/1000
2023-09-24 03:31:39.731 
Epoch 708/1000 
	 loss: 16.1725, MinusLogProbMetric: 16.1725, val_loss: 17.0426, val_MinusLogProbMetric: 17.0426

Epoch 708: val_loss did not improve from 17.03354
196/196 - 63s - loss: 16.1725 - MinusLogProbMetric: 16.1725 - val_loss: 17.0426 - val_MinusLogProbMetric: 17.0426 - lr: 2.0833e-05 - 63s/epoch - 320ms/step
Epoch 709/1000
2023-09-24 03:32:42.799 
Epoch 709/1000 
	 loss: 16.1753, MinusLogProbMetric: 16.1753, val_loss: 17.0832, val_MinusLogProbMetric: 17.0832

Epoch 709: val_loss did not improve from 17.03354
196/196 - 63s - loss: 16.1753 - MinusLogProbMetric: 16.1753 - val_loss: 17.0832 - val_MinusLogProbMetric: 17.0832 - lr: 2.0833e-05 - 63s/epoch - 322ms/step
Epoch 710/1000
2023-09-24 03:33:45.000 
Epoch 710/1000 
	 loss: 16.1721, MinusLogProbMetric: 16.1721, val_loss: 17.0376, val_MinusLogProbMetric: 17.0376

Epoch 710: val_loss did not improve from 17.03354
196/196 - 62s - loss: 16.1721 - MinusLogProbMetric: 16.1721 - val_loss: 17.0376 - val_MinusLogProbMetric: 17.0376 - lr: 2.0833e-05 - 62s/epoch - 317ms/step
Epoch 711/1000
2023-09-24 03:34:46.870 
Epoch 711/1000 
	 loss: 16.1735, MinusLogProbMetric: 16.1735, val_loss: 17.0532, val_MinusLogProbMetric: 17.0532

Epoch 711: val_loss did not improve from 17.03354
196/196 - 62s - loss: 16.1735 - MinusLogProbMetric: 16.1735 - val_loss: 17.0532 - val_MinusLogProbMetric: 17.0532 - lr: 2.0833e-05 - 62s/epoch - 316ms/step
Epoch 712/1000
2023-09-24 03:35:49.182 
Epoch 712/1000 
	 loss: 16.1727, MinusLogProbMetric: 16.1727, val_loss: 17.0465, val_MinusLogProbMetric: 17.0465

Epoch 712: val_loss did not improve from 17.03354
196/196 - 62s - loss: 16.1727 - MinusLogProbMetric: 16.1727 - val_loss: 17.0465 - val_MinusLogProbMetric: 17.0465 - lr: 2.0833e-05 - 62s/epoch - 318ms/step
Epoch 713/1000
2023-09-24 03:36:48.613 
Epoch 713/1000 
	 loss: 16.1700, MinusLogProbMetric: 16.1700, val_loss: 17.0408, val_MinusLogProbMetric: 17.0408

Epoch 713: val_loss did not improve from 17.03354
196/196 - 59s - loss: 16.1700 - MinusLogProbMetric: 16.1700 - val_loss: 17.0408 - val_MinusLogProbMetric: 17.0408 - lr: 2.0833e-05 - 59s/epoch - 303ms/step
Epoch 714/1000
2023-09-24 03:37:49.614 
Epoch 714/1000 
	 loss: 16.1713, MinusLogProbMetric: 16.1713, val_loss: 17.0450, val_MinusLogProbMetric: 17.0450

Epoch 714: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.1713 - MinusLogProbMetric: 16.1713 - val_loss: 17.0450 - val_MinusLogProbMetric: 17.0450 - lr: 2.0833e-05 - 61s/epoch - 311ms/step
Epoch 715/1000
2023-09-24 03:38:50.598 
Epoch 715/1000 
	 loss: 16.1724, MinusLogProbMetric: 16.1724, val_loss: 17.0547, val_MinusLogProbMetric: 17.0547

Epoch 715: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.1724 - MinusLogProbMetric: 16.1724 - val_loss: 17.0547 - val_MinusLogProbMetric: 17.0547 - lr: 2.0833e-05 - 61s/epoch - 311ms/step
Epoch 716/1000
2023-09-24 03:39:51.922 
Epoch 716/1000 
	 loss: 16.1720, MinusLogProbMetric: 16.1720, val_loss: 17.0512, val_MinusLogProbMetric: 17.0512

Epoch 716: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.1720 - MinusLogProbMetric: 16.1720 - val_loss: 17.0512 - val_MinusLogProbMetric: 17.0512 - lr: 2.0833e-05 - 61s/epoch - 313ms/step
Epoch 717/1000
2023-09-24 03:40:51.281 
Epoch 717/1000 
	 loss: 16.1705, MinusLogProbMetric: 16.1705, val_loss: 17.0459, val_MinusLogProbMetric: 17.0459

Epoch 717: val_loss did not improve from 17.03354
196/196 - 59s - loss: 16.1705 - MinusLogProbMetric: 16.1705 - val_loss: 17.0459 - val_MinusLogProbMetric: 17.0459 - lr: 2.0833e-05 - 59s/epoch - 303ms/step
Epoch 718/1000
2023-09-24 03:41:51.980 
Epoch 718/1000 
	 loss: 16.1734, MinusLogProbMetric: 16.1734, val_loss: 17.0474, val_MinusLogProbMetric: 17.0474

Epoch 718: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.1734 - MinusLogProbMetric: 16.1734 - val_loss: 17.0474 - val_MinusLogProbMetric: 17.0474 - lr: 2.0833e-05 - 61s/epoch - 310ms/step
Epoch 719/1000
2023-09-24 03:42:52.060 
Epoch 719/1000 
	 loss: 16.1698, MinusLogProbMetric: 16.1698, val_loss: 17.0540, val_MinusLogProbMetric: 17.0540

Epoch 719: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.1698 - MinusLogProbMetric: 16.1698 - val_loss: 17.0540 - val_MinusLogProbMetric: 17.0540 - lr: 2.0833e-05 - 60s/epoch - 307ms/step
Epoch 720/1000
2023-09-24 03:43:52.522 
Epoch 720/1000 
	 loss: 16.1724, MinusLogProbMetric: 16.1724, val_loss: 17.0419, val_MinusLogProbMetric: 17.0419

Epoch 720: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.1724 - MinusLogProbMetric: 16.1724 - val_loss: 17.0419 - val_MinusLogProbMetric: 17.0419 - lr: 2.0833e-05 - 60s/epoch - 308ms/step
Epoch 721/1000
2023-09-24 03:44:52.499 
Epoch 721/1000 
	 loss: 16.1716, MinusLogProbMetric: 16.1716, val_loss: 17.0386, val_MinusLogProbMetric: 17.0386

Epoch 721: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.1716 - MinusLogProbMetric: 16.1716 - val_loss: 17.0386 - val_MinusLogProbMetric: 17.0386 - lr: 2.0833e-05 - 60s/epoch - 306ms/step
Epoch 722/1000
2023-09-24 03:45:52.799 
Epoch 722/1000 
	 loss: 16.1699, MinusLogProbMetric: 16.1699, val_loss: 17.0595, val_MinusLogProbMetric: 17.0595

Epoch 722: val_loss did not improve from 17.03354
196/196 - 60s - loss: 16.1699 - MinusLogProbMetric: 16.1699 - val_loss: 17.0595 - val_MinusLogProbMetric: 17.0595 - lr: 2.0833e-05 - 60s/epoch - 308ms/step
Epoch 723/1000
2023-09-24 03:46:55.317 
Epoch 723/1000 
	 loss: 16.1750, MinusLogProbMetric: 16.1750, val_loss: 17.0640, val_MinusLogProbMetric: 17.0640

Epoch 723: val_loss did not improve from 17.03354
196/196 - 63s - loss: 16.1750 - MinusLogProbMetric: 16.1750 - val_loss: 17.0640 - val_MinusLogProbMetric: 17.0640 - lr: 2.0833e-05 - 63s/epoch - 319ms/step
Epoch 724/1000
2023-09-24 03:47:57.779 
Epoch 724/1000 
	 loss: 16.1732, MinusLogProbMetric: 16.1732, val_loss: 17.0405, val_MinusLogProbMetric: 17.0405

Epoch 724: val_loss did not improve from 17.03354
196/196 - 62s - loss: 16.1732 - MinusLogProbMetric: 16.1732 - val_loss: 17.0405 - val_MinusLogProbMetric: 17.0405 - lr: 2.0833e-05 - 62s/epoch - 319ms/step
Epoch 725/1000
2023-09-24 03:48:56.803 
Epoch 725/1000 
	 loss: 16.1726, MinusLogProbMetric: 16.1726, val_loss: 17.0406, val_MinusLogProbMetric: 17.0406

Epoch 725: val_loss did not improve from 17.03354
196/196 - 59s - loss: 16.1726 - MinusLogProbMetric: 16.1726 - val_loss: 17.0406 - val_MinusLogProbMetric: 17.0406 - lr: 2.0833e-05 - 59s/epoch - 301ms/step
Epoch 726/1000
2023-09-24 03:49:58.305 
Epoch 726/1000 
	 loss: 16.1662, MinusLogProbMetric: 16.1662, val_loss: 17.0575, val_MinusLogProbMetric: 17.0575

Epoch 726: val_loss did not improve from 17.03354
196/196 - 61s - loss: 16.1662 - MinusLogProbMetric: 16.1662 - val_loss: 17.0575 - val_MinusLogProbMetric: 17.0575 - lr: 2.0833e-05 - 61s/epoch - 314ms/step
Epoch 727/1000
2023-09-24 03:51:00.519 
Epoch 727/1000 
	 loss: 16.1717, MinusLogProbMetric: 16.1717, val_loss: 17.0310, val_MinusLogProbMetric: 17.0310

Epoch 727: val_loss improved from 17.03354 to 17.03097, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/CsplineN_new/run_302/weights/best_weights.h5
196/196 - 63s - loss: 16.1717 - MinusLogProbMetric: 16.1717 - val_loss: 17.0310 - val_MinusLogProbMetric: 17.0310 - lr: 2.0833e-05 - 63s/epoch - 322ms/step
Epoch 728/1000
2023-09-24 03:52:01.121 
Epoch 728/1000 
	 loss: 16.1704, MinusLogProbMetric: 16.1704, val_loss: 17.0447, val_MinusLogProbMetric: 17.0447

Epoch 728: val_loss did not improve from 17.03097
196/196 - 60s - loss: 16.1704 - MinusLogProbMetric: 16.1704 - val_loss: 17.0447 - val_MinusLogProbMetric: 17.0447 - lr: 2.0833e-05 - 60s/epoch - 304ms/step
Epoch 729/1000
2023-09-24 03:53:01.904 
Epoch 729/1000 
	 loss: 16.1680, MinusLogProbMetric: 16.1680, val_loss: 17.0454, val_MinusLogProbMetric: 17.0454

Epoch 729: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1680 - MinusLogProbMetric: 16.1680 - val_loss: 17.0454 - val_MinusLogProbMetric: 17.0454 - lr: 2.0833e-05 - 61s/epoch - 310ms/step
Epoch 730/1000
2023-09-24 03:54:03.728 
Epoch 730/1000 
	 loss: 16.1696, MinusLogProbMetric: 16.1696, val_loss: 17.0442, val_MinusLogProbMetric: 17.0442

Epoch 730: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1696 - MinusLogProbMetric: 16.1696 - val_loss: 17.0442 - val_MinusLogProbMetric: 17.0442 - lr: 2.0833e-05 - 62s/epoch - 315ms/step
Epoch 731/1000
2023-09-24 03:55:05.813 
Epoch 731/1000 
	 loss: 16.1726, MinusLogProbMetric: 16.1726, val_loss: 17.0441, val_MinusLogProbMetric: 17.0441

Epoch 731: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1726 - MinusLogProbMetric: 16.1726 - val_loss: 17.0441 - val_MinusLogProbMetric: 17.0441 - lr: 2.0833e-05 - 62s/epoch - 317ms/step
Epoch 732/1000
2023-09-24 03:56:08.081 
Epoch 732/1000 
	 loss: 16.1693, MinusLogProbMetric: 16.1693, val_loss: 17.0424, val_MinusLogProbMetric: 17.0424

Epoch 732: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1693 - MinusLogProbMetric: 16.1693 - val_loss: 17.0424 - val_MinusLogProbMetric: 17.0424 - lr: 2.0833e-05 - 62s/epoch - 318ms/step
Epoch 733/1000
2023-09-24 03:57:09.686 
Epoch 733/1000 
	 loss: 16.1681, MinusLogProbMetric: 16.1681, val_loss: 17.0400, val_MinusLogProbMetric: 17.0400

Epoch 733: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1681 - MinusLogProbMetric: 16.1681 - val_loss: 17.0400 - val_MinusLogProbMetric: 17.0400 - lr: 2.0833e-05 - 62s/epoch - 314ms/step
Epoch 734/1000
2023-09-24 03:58:09.781 
Epoch 734/1000 
	 loss: 16.1700, MinusLogProbMetric: 16.1700, val_loss: 17.0427, val_MinusLogProbMetric: 17.0427

Epoch 734: val_loss did not improve from 17.03097
196/196 - 60s - loss: 16.1700 - MinusLogProbMetric: 16.1700 - val_loss: 17.0427 - val_MinusLogProbMetric: 17.0427 - lr: 2.0833e-05 - 60s/epoch - 307ms/step
Epoch 735/1000
2023-09-24 03:59:09.178 
Epoch 735/1000 
	 loss: 16.1685, MinusLogProbMetric: 16.1685, val_loss: 17.0495, val_MinusLogProbMetric: 17.0495

Epoch 735: val_loss did not improve from 17.03097
196/196 - 59s - loss: 16.1685 - MinusLogProbMetric: 16.1685 - val_loss: 17.0495 - val_MinusLogProbMetric: 17.0495 - lr: 2.0833e-05 - 59s/epoch - 303ms/step
Epoch 736/1000
2023-09-24 04:00:10.333 
Epoch 736/1000 
	 loss: 16.1688, MinusLogProbMetric: 16.1688, val_loss: 17.0390, val_MinusLogProbMetric: 17.0390

Epoch 736: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1688 - MinusLogProbMetric: 16.1688 - val_loss: 17.0390 - val_MinusLogProbMetric: 17.0390 - lr: 2.0833e-05 - 61s/epoch - 312ms/step
Epoch 737/1000
2023-09-24 04:01:11.871 
Epoch 737/1000 
	 loss: 16.1703, MinusLogProbMetric: 16.1703, val_loss: 17.0601, val_MinusLogProbMetric: 17.0601

Epoch 737: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1703 - MinusLogProbMetric: 16.1703 - val_loss: 17.0601 - val_MinusLogProbMetric: 17.0601 - lr: 2.0833e-05 - 62s/epoch - 314ms/step
Epoch 738/1000
2023-09-24 04:02:11.580 
Epoch 738/1000 
	 loss: 16.1699, MinusLogProbMetric: 16.1699, val_loss: 17.0424, val_MinusLogProbMetric: 17.0424

Epoch 738: val_loss did not improve from 17.03097
196/196 - 60s - loss: 16.1699 - MinusLogProbMetric: 16.1699 - val_loss: 17.0424 - val_MinusLogProbMetric: 17.0424 - lr: 2.0833e-05 - 60s/epoch - 305ms/step
Epoch 739/1000
2023-09-24 04:03:15.603 
Epoch 739/1000 
	 loss: 16.1683, MinusLogProbMetric: 16.1683, val_loss: 17.0443, val_MinusLogProbMetric: 17.0443

Epoch 739: val_loss did not improve from 17.03097
196/196 - 64s - loss: 16.1683 - MinusLogProbMetric: 16.1683 - val_loss: 17.0443 - val_MinusLogProbMetric: 17.0443 - lr: 2.0833e-05 - 64s/epoch - 327ms/step
Epoch 740/1000
2023-09-24 04:04:18.175 
Epoch 740/1000 
	 loss: 16.1690, MinusLogProbMetric: 16.1690, val_loss: 17.0415, val_MinusLogProbMetric: 17.0415

Epoch 740: val_loss did not improve from 17.03097
196/196 - 63s - loss: 16.1690 - MinusLogProbMetric: 16.1690 - val_loss: 17.0415 - val_MinusLogProbMetric: 17.0415 - lr: 2.0833e-05 - 63s/epoch - 319ms/step
Epoch 741/1000
2023-09-24 04:05:18.865 
Epoch 741/1000 
	 loss: 16.1672, MinusLogProbMetric: 16.1672, val_loss: 17.0452, val_MinusLogProbMetric: 17.0452

Epoch 741: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1672 - MinusLogProbMetric: 16.1672 - val_loss: 17.0452 - val_MinusLogProbMetric: 17.0452 - lr: 2.0833e-05 - 61s/epoch - 310ms/step
Epoch 742/1000
2023-09-24 04:06:21.011 
Epoch 742/1000 
	 loss: 16.1685, MinusLogProbMetric: 16.1685, val_loss: 17.0588, val_MinusLogProbMetric: 17.0588

Epoch 742: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1685 - MinusLogProbMetric: 16.1685 - val_loss: 17.0588 - val_MinusLogProbMetric: 17.0588 - lr: 2.0833e-05 - 62s/epoch - 317ms/step
Epoch 743/1000
2023-09-24 04:07:22.360 
Epoch 743/1000 
	 loss: 16.1703, MinusLogProbMetric: 16.1703, val_loss: 17.0480, val_MinusLogProbMetric: 17.0480

Epoch 743: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1703 - MinusLogProbMetric: 16.1703 - val_loss: 17.0480 - val_MinusLogProbMetric: 17.0480 - lr: 2.0833e-05 - 61s/epoch - 313ms/step
Epoch 744/1000
2023-09-24 04:08:23.334 
Epoch 744/1000 
	 loss: 16.1731, MinusLogProbMetric: 16.1731, val_loss: 17.0657, val_MinusLogProbMetric: 17.0657

Epoch 744: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1731 - MinusLogProbMetric: 16.1731 - val_loss: 17.0657 - val_MinusLogProbMetric: 17.0657 - lr: 2.0833e-05 - 61s/epoch - 311ms/step
Epoch 745/1000
2023-09-24 04:09:24.035 
Epoch 745/1000 
	 loss: 16.1694, MinusLogProbMetric: 16.1694, val_loss: 17.0437, val_MinusLogProbMetric: 17.0437

Epoch 745: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1694 - MinusLogProbMetric: 16.1694 - val_loss: 17.0437 - val_MinusLogProbMetric: 17.0437 - lr: 2.0833e-05 - 61s/epoch - 310ms/step
Epoch 746/1000
2023-09-24 04:10:27.291 
Epoch 746/1000 
	 loss: 16.1685, MinusLogProbMetric: 16.1685, val_loss: 17.0443, val_MinusLogProbMetric: 17.0443

Epoch 746: val_loss did not improve from 17.03097
196/196 - 63s - loss: 16.1685 - MinusLogProbMetric: 16.1685 - val_loss: 17.0443 - val_MinusLogProbMetric: 17.0443 - lr: 2.0833e-05 - 63s/epoch - 323ms/step
Epoch 747/1000
2023-09-24 04:11:29.364 
Epoch 747/1000 
	 loss: 16.1675, MinusLogProbMetric: 16.1675, val_loss: 17.0524, val_MinusLogProbMetric: 17.0524

Epoch 747: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1675 - MinusLogProbMetric: 16.1675 - val_loss: 17.0524 - val_MinusLogProbMetric: 17.0524 - lr: 2.0833e-05 - 62s/epoch - 317ms/step
Epoch 748/1000
2023-09-24 04:12:32.118 
Epoch 748/1000 
	 loss: 16.1701, MinusLogProbMetric: 16.1701, val_loss: 17.0870, val_MinusLogProbMetric: 17.0870

Epoch 748: val_loss did not improve from 17.03097
196/196 - 63s - loss: 16.1701 - MinusLogProbMetric: 16.1701 - val_loss: 17.0870 - val_MinusLogProbMetric: 17.0870 - lr: 2.0833e-05 - 63s/epoch - 320ms/step
Epoch 749/1000
2023-09-24 04:13:33.416 
Epoch 749/1000 
	 loss: 16.1690, MinusLogProbMetric: 16.1690, val_loss: 17.0374, val_MinusLogProbMetric: 17.0374

Epoch 749: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1690 - MinusLogProbMetric: 16.1690 - val_loss: 17.0374 - val_MinusLogProbMetric: 17.0374 - lr: 2.0833e-05 - 61s/epoch - 313ms/step
Epoch 750/1000
2023-09-24 04:14:34.293 
Epoch 750/1000 
	 loss: 16.1690, MinusLogProbMetric: 16.1690, val_loss: 17.0492, val_MinusLogProbMetric: 17.0492

Epoch 750: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1690 - MinusLogProbMetric: 16.1690 - val_loss: 17.0492 - val_MinusLogProbMetric: 17.0492 - lr: 2.0833e-05 - 61s/epoch - 311ms/step
Epoch 751/1000
2023-09-24 04:15:36.512 
Epoch 751/1000 
	 loss: 16.1691, MinusLogProbMetric: 16.1691, val_loss: 17.0505, val_MinusLogProbMetric: 17.0505

Epoch 751: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1691 - MinusLogProbMetric: 16.1691 - val_loss: 17.0505 - val_MinusLogProbMetric: 17.0505 - lr: 2.0833e-05 - 62s/epoch - 317ms/step
Epoch 752/1000
2023-09-24 04:16:36.843 
Epoch 752/1000 
	 loss: 16.1675, MinusLogProbMetric: 16.1675, val_loss: 17.0692, val_MinusLogProbMetric: 17.0692

Epoch 752: val_loss did not improve from 17.03097
196/196 - 60s - loss: 16.1675 - MinusLogProbMetric: 16.1675 - val_loss: 17.0692 - val_MinusLogProbMetric: 17.0692 - lr: 2.0833e-05 - 60s/epoch - 308ms/step
Epoch 753/1000
2023-09-24 04:17:38.839 
Epoch 753/1000 
	 loss: 16.1681, MinusLogProbMetric: 16.1681, val_loss: 17.0425, val_MinusLogProbMetric: 17.0425

Epoch 753: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1681 - MinusLogProbMetric: 16.1681 - val_loss: 17.0425 - val_MinusLogProbMetric: 17.0425 - lr: 2.0833e-05 - 62s/epoch - 316ms/step
Epoch 754/1000
2023-09-24 04:18:41.389 
Epoch 754/1000 
	 loss: 16.1666, MinusLogProbMetric: 16.1666, val_loss: 17.0439, val_MinusLogProbMetric: 17.0439

Epoch 754: val_loss did not improve from 17.03097
196/196 - 63s - loss: 16.1666 - MinusLogProbMetric: 16.1666 - val_loss: 17.0439 - val_MinusLogProbMetric: 17.0439 - lr: 2.0833e-05 - 63s/epoch - 319ms/step
Epoch 755/1000
2023-09-24 04:19:41.988 
Epoch 755/1000 
	 loss: 16.1730, MinusLogProbMetric: 16.1730, val_loss: 17.0865, val_MinusLogProbMetric: 17.0865

Epoch 755: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1730 - MinusLogProbMetric: 16.1730 - val_loss: 17.0865 - val_MinusLogProbMetric: 17.0865 - lr: 2.0833e-05 - 61s/epoch - 309ms/step
Epoch 756/1000
2023-09-24 04:20:43.558 
Epoch 756/1000 
	 loss: 16.1738, MinusLogProbMetric: 16.1738, val_loss: 17.0747, val_MinusLogProbMetric: 17.0747

Epoch 756: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1738 - MinusLogProbMetric: 16.1738 - val_loss: 17.0747 - val_MinusLogProbMetric: 17.0747 - lr: 2.0833e-05 - 62s/epoch - 314ms/step
Epoch 757/1000
2023-09-24 04:21:43.108 
Epoch 757/1000 
	 loss: 16.1687, MinusLogProbMetric: 16.1687, val_loss: 17.0416, val_MinusLogProbMetric: 17.0416

Epoch 757: val_loss did not improve from 17.03097
196/196 - 60s - loss: 16.1687 - MinusLogProbMetric: 16.1687 - val_loss: 17.0416 - val_MinusLogProbMetric: 17.0416 - lr: 2.0833e-05 - 60s/epoch - 304ms/step
Epoch 758/1000
2023-09-24 04:22:44.226 
Epoch 758/1000 
	 loss: 16.1651, MinusLogProbMetric: 16.1651, val_loss: 17.0618, val_MinusLogProbMetric: 17.0618

Epoch 758: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1651 - MinusLogProbMetric: 16.1651 - val_loss: 17.0618 - val_MinusLogProbMetric: 17.0618 - lr: 2.0833e-05 - 61s/epoch - 312ms/step
Epoch 759/1000
2023-09-24 04:23:46.057 
Epoch 759/1000 
	 loss: 16.1680, MinusLogProbMetric: 16.1680, val_loss: 17.0518, val_MinusLogProbMetric: 17.0518

Epoch 759: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1680 - MinusLogProbMetric: 16.1680 - val_loss: 17.0518 - val_MinusLogProbMetric: 17.0518 - lr: 2.0833e-05 - 62s/epoch - 315ms/step
Epoch 760/1000
2023-09-24 04:24:48.416 
Epoch 760/1000 
	 loss: 16.1688, MinusLogProbMetric: 16.1688, val_loss: 17.0450, val_MinusLogProbMetric: 17.0450

Epoch 760: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1688 - MinusLogProbMetric: 16.1688 - val_loss: 17.0450 - val_MinusLogProbMetric: 17.0450 - lr: 2.0833e-05 - 62s/epoch - 318ms/step
Epoch 761/1000
2023-09-24 04:25:48.778 
Epoch 761/1000 
	 loss: 16.1671, MinusLogProbMetric: 16.1671, val_loss: 17.0509, val_MinusLogProbMetric: 17.0509

Epoch 761: val_loss did not improve from 17.03097
196/196 - 60s - loss: 16.1671 - MinusLogProbMetric: 16.1671 - val_loss: 17.0509 - val_MinusLogProbMetric: 17.0509 - lr: 2.0833e-05 - 60s/epoch - 308ms/step
Epoch 762/1000
2023-09-24 04:26:49.594 
Epoch 762/1000 
	 loss: 16.1666, MinusLogProbMetric: 16.1666, val_loss: 17.0681, val_MinusLogProbMetric: 17.0681

Epoch 762: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1666 - MinusLogProbMetric: 16.1666 - val_loss: 17.0681 - val_MinusLogProbMetric: 17.0681 - lr: 2.0833e-05 - 61s/epoch - 310ms/step
Epoch 763/1000
2023-09-24 04:27:51.691 
Epoch 763/1000 
	 loss: 16.1663, MinusLogProbMetric: 16.1663, val_loss: 17.0435, val_MinusLogProbMetric: 17.0435

Epoch 763: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1663 - MinusLogProbMetric: 16.1663 - val_loss: 17.0435 - val_MinusLogProbMetric: 17.0435 - lr: 2.0833e-05 - 62s/epoch - 317ms/step
Epoch 764/1000
2023-09-24 04:28:50.134 
Epoch 764/1000 
	 loss: 16.1679, MinusLogProbMetric: 16.1679, val_loss: 17.0552, val_MinusLogProbMetric: 17.0552

Epoch 764: val_loss did not improve from 17.03097
196/196 - 58s - loss: 16.1679 - MinusLogProbMetric: 16.1679 - val_loss: 17.0552 - val_MinusLogProbMetric: 17.0552 - lr: 2.0833e-05 - 58s/epoch - 298ms/step
Epoch 765/1000
2023-09-24 04:29:50.676 
Epoch 765/1000 
	 loss: 16.1703, MinusLogProbMetric: 16.1703, val_loss: 17.0463, val_MinusLogProbMetric: 17.0463

Epoch 765: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1703 - MinusLogProbMetric: 16.1703 - val_loss: 17.0463 - val_MinusLogProbMetric: 17.0463 - lr: 2.0833e-05 - 61s/epoch - 309ms/step
Epoch 766/1000
2023-09-24 04:30:52.153 
Epoch 766/1000 
	 loss: 16.1682, MinusLogProbMetric: 16.1682, val_loss: 17.0394, val_MinusLogProbMetric: 17.0394

Epoch 766: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1682 - MinusLogProbMetric: 16.1682 - val_loss: 17.0394 - val_MinusLogProbMetric: 17.0394 - lr: 2.0833e-05 - 61s/epoch - 314ms/step
Epoch 767/1000
2023-09-24 04:31:53.994 
Epoch 767/1000 
	 loss: 16.1642, MinusLogProbMetric: 16.1642, val_loss: 17.0440, val_MinusLogProbMetric: 17.0440

Epoch 767: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1642 - MinusLogProbMetric: 16.1642 - val_loss: 17.0440 - val_MinusLogProbMetric: 17.0440 - lr: 2.0833e-05 - 62s/epoch - 316ms/step
Epoch 768/1000
2023-09-24 04:32:54.698 
Epoch 768/1000 
	 loss: 16.1687, MinusLogProbMetric: 16.1687, val_loss: 17.0503, val_MinusLogProbMetric: 17.0503

Epoch 768: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1687 - MinusLogProbMetric: 16.1687 - val_loss: 17.0503 - val_MinusLogProbMetric: 17.0503 - lr: 2.0833e-05 - 61s/epoch - 310ms/step
Epoch 769/1000
2023-09-24 04:33:57.350 
Epoch 769/1000 
	 loss: 16.1652, MinusLogProbMetric: 16.1652, val_loss: 17.0488, val_MinusLogProbMetric: 17.0488

Epoch 769: val_loss did not improve from 17.03097
196/196 - 63s - loss: 16.1652 - MinusLogProbMetric: 16.1652 - val_loss: 17.0488 - val_MinusLogProbMetric: 17.0488 - lr: 2.0833e-05 - 63s/epoch - 320ms/step
Epoch 770/1000
2023-09-24 04:34:59.037 
Epoch 770/1000 
	 loss: 16.1645, MinusLogProbMetric: 16.1645, val_loss: 17.0524, val_MinusLogProbMetric: 17.0524

Epoch 770: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1645 - MinusLogProbMetric: 16.1645 - val_loss: 17.0524 - val_MinusLogProbMetric: 17.0524 - lr: 2.0833e-05 - 62s/epoch - 315ms/step
Epoch 771/1000
2023-09-24 04:36:00.473 
Epoch 771/1000 
	 loss: 16.1654, MinusLogProbMetric: 16.1654, val_loss: 17.0436, val_MinusLogProbMetric: 17.0436

Epoch 771: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1654 - MinusLogProbMetric: 16.1654 - val_loss: 17.0436 - val_MinusLogProbMetric: 17.0436 - lr: 2.0833e-05 - 61s/epoch - 313ms/step
Epoch 772/1000
2023-09-24 04:37:01.861 
Epoch 772/1000 
	 loss: 16.1647, MinusLogProbMetric: 16.1647, val_loss: 17.0581, val_MinusLogProbMetric: 17.0581

Epoch 772: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1647 - MinusLogProbMetric: 16.1647 - val_loss: 17.0581 - val_MinusLogProbMetric: 17.0581 - lr: 2.0833e-05 - 61s/epoch - 313ms/step
Epoch 773/1000
2023-09-24 04:38:02.120 
Epoch 773/1000 
	 loss: 16.1678, MinusLogProbMetric: 16.1678, val_loss: 17.0505, val_MinusLogProbMetric: 17.0505

Epoch 773: val_loss did not improve from 17.03097
196/196 - 60s - loss: 16.1678 - MinusLogProbMetric: 16.1678 - val_loss: 17.0505 - val_MinusLogProbMetric: 17.0505 - lr: 2.0833e-05 - 60s/epoch - 307ms/step
Epoch 774/1000
2023-09-24 04:39:03.156 
Epoch 774/1000 
	 loss: 16.1667, MinusLogProbMetric: 16.1667, val_loss: 17.0622, val_MinusLogProbMetric: 17.0622

Epoch 774: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1667 - MinusLogProbMetric: 16.1667 - val_loss: 17.0622 - val_MinusLogProbMetric: 17.0622 - lr: 2.0833e-05 - 61s/epoch - 311ms/step
Epoch 775/1000
2023-09-24 04:40:03.347 
Epoch 775/1000 
	 loss: 16.1664, MinusLogProbMetric: 16.1664, val_loss: 17.0494, val_MinusLogProbMetric: 17.0494

Epoch 775: val_loss did not improve from 17.03097
196/196 - 60s - loss: 16.1664 - MinusLogProbMetric: 16.1664 - val_loss: 17.0494 - val_MinusLogProbMetric: 17.0494 - lr: 2.0833e-05 - 60s/epoch - 307ms/step
Epoch 776/1000
2023-09-24 04:41:04.720 
Epoch 776/1000 
	 loss: 16.1671, MinusLogProbMetric: 16.1671, val_loss: 17.0486, val_MinusLogProbMetric: 17.0486

Epoch 776: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1671 - MinusLogProbMetric: 16.1671 - val_loss: 17.0486 - val_MinusLogProbMetric: 17.0486 - lr: 2.0833e-05 - 61s/epoch - 313ms/step
Epoch 777/1000
2023-09-24 04:42:06.949 
Epoch 777/1000 
	 loss: 16.1661, MinusLogProbMetric: 16.1661, val_loss: 17.0484, val_MinusLogProbMetric: 17.0484

Epoch 777: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1661 - MinusLogProbMetric: 16.1661 - val_loss: 17.0484 - val_MinusLogProbMetric: 17.0484 - lr: 2.0833e-05 - 62s/epoch - 317ms/step
Epoch 778/1000
2023-09-24 04:43:08.696 
Epoch 778/1000 
	 loss: 16.1515, MinusLogProbMetric: 16.1515, val_loss: 17.0420, val_MinusLogProbMetric: 17.0420

Epoch 778: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1515 - MinusLogProbMetric: 16.1515 - val_loss: 17.0420 - val_MinusLogProbMetric: 17.0420 - lr: 1.0417e-05 - 62s/epoch - 315ms/step
Epoch 779/1000
2023-09-24 04:44:09.293 
Epoch 779/1000 
	 loss: 16.1508, MinusLogProbMetric: 16.1508, val_loss: 17.0401, val_MinusLogProbMetric: 17.0401

Epoch 779: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1508 - MinusLogProbMetric: 16.1508 - val_loss: 17.0401 - val_MinusLogProbMetric: 17.0401 - lr: 1.0417e-05 - 61s/epoch - 309ms/step
Epoch 780/1000
2023-09-24 04:45:09.754 
Epoch 780/1000 
	 loss: 16.1514, MinusLogProbMetric: 16.1514, val_loss: 17.0510, val_MinusLogProbMetric: 17.0510

Epoch 780: val_loss did not improve from 17.03097
196/196 - 60s - loss: 16.1514 - MinusLogProbMetric: 16.1514 - val_loss: 17.0510 - val_MinusLogProbMetric: 17.0510 - lr: 1.0417e-05 - 60s/epoch - 308ms/step
Epoch 781/1000
2023-09-24 04:46:10.801 
Epoch 781/1000 
	 loss: 16.1501, MinusLogProbMetric: 16.1501, val_loss: 17.0419, val_MinusLogProbMetric: 17.0419

Epoch 781: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1501 - MinusLogProbMetric: 16.1501 - val_loss: 17.0419 - val_MinusLogProbMetric: 17.0419 - lr: 1.0417e-05 - 61s/epoch - 311ms/step
Epoch 782/1000
2023-09-24 04:47:12.493 
Epoch 782/1000 
	 loss: 16.1499, MinusLogProbMetric: 16.1499, val_loss: 17.0379, val_MinusLogProbMetric: 17.0379

Epoch 782: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1499 - MinusLogProbMetric: 16.1499 - val_loss: 17.0379 - val_MinusLogProbMetric: 17.0379 - lr: 1.0417e-05 - 62s/epoch - 315ms/step
Epoch 783/1000
2023-09-24 04:48:13.348 
Epoch 783/1000 
	 loss: 16.1511, MinusLogProbMetric: 16.1511, val_loss: 17.0397, val_MinusLogProbMetric: 17.0397

Epoch 783: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1511 - MinusLogProbMetric: 16.1511 - val_loss: 17.0397 - val_MinusLogProbMetric: 17.0397 - lr: 1.0417e-05 - 61s/epoch - 310ms/step
Epoch 784/1000
2023-09-24 04:49:14.675 
Epoch 784/1000 
	 loss: 16.1491, MinusLogProbMetric: 16.1491, val_loss: 17.0491, val_MinusLogProbMetric: 17.0491

Epoch 784: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1491 - MinusLogProbMetric: 16.1491 - val_loss: 17.0491 - val_MinusLogProbMetric: 17.0491 - lr: 1.0417e-05 - 61s/epoch - 313ms/step
Epoch 785/1000
2023-09-24 04:50:17.459 
Epoch 785/1000 
	 loss: 16.1514, MinusLogProbMetric: 16.1514, val_loss: 17.0476, val_MinusLogProbMetric: 17.0476

Epoch 785: val_loss did not improve from 17.03097
196/196 - 63s - loss: 16.1514 - MinusLogProbMetric: 16.1514 - val_loss: 17.0476 - val_MinusLogProbMetric: 17.0476 - lr: 1.0417e-05 - 63s/epoch - 320ms/step
Epoch 786/1000
2023-09-24 04:51:18.703 
Epoch 786/1000 
	 loss: 16.1500, MinusLogProbMetric: 16.1500, val_loss: 17.0501, val_MinusLogProbMetric: 17.0501

Epoch 786: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1500 - MinusLogProbMetric: 16.1500 - val_loss: 17.0501 - val_MinusLogProbMetric: 17.0501 - lr: 1.0417e-05 - 61s/epoch - 312ms/step
Epoch 787/1000
2023-09-24 04:52:20.869 
Epoch 787/1000 
	 loss: 16.1500, MinusLogProbMetric: 16.1500, val_loss: 17.0396, val_MinusLogProbMetric: 17.0396

Epoch 787: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1500 - MinusLogProbMetric: 16.1500 - val_loss: 17.0396 - val_MinusLogProbMetric: 17.0396 - lr: 1.0417e-05 - 62s/epoch - 317ms/step
Epoch 788/1000
2023-09-24 04:53:23.387 
Epoch 788/1000 
	 loss: 16.1498, MinusLogProbMetric: 16.1498, val_loss: 17.0378, val_MinusLogProbMetric: 17.0378

Epoch 788: val_loss did not improve from 17.03097
196/196 - 63s - loss: 16.1498 - MinusLogProbMetric: 16.1498 - val_loss: 17.0378 - val_MinusLogProbMetric: 17.0378 - lr: 1.0417e-05 - 63s/epoch - 319ms/step
Epoch 789/1000
2023-09-24 04:54:26.205 
Epoch 789/1000 
	 loss: 16.1503, MinusLogProbMetric: 16.1503, val_loss: 17.0366, val_MinusLogProbMetric: 17.0366

Epoch 789: val_loss did not improve from 17.03097
196/196 - 63s - loss: 16.1503 - MinusLogProbMetric: 16.1503 - val_loss: 17.0366 - val_MinusLogProbMetric: 17.0366 - lr: 1.0417e-05 - 63s/epoch - 320ms/step
Epoch 790/1000
2023-09-24 04:55:28.236 
Epoch 790/1000 
	 loss: 16.1517, MinusLogProbMetric: 16.1517, val_loss: 17.0325, val_MinusLogProbMetric: 17.0325

Epoch 790: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1517 - MinusLogProbMetric: 16.1517 - val_loss: 17.0325 - val_MinusLogProbMetric: 17.0325 - lr: 1.0417e-05 - 62s/epoch - 316ms/step
Epoch 791/1000
2023-09-24 04:56:28.307 
Epoch 791/1000 
	 loss: 16.1507, MinusLogProbMetric: 16.1507, val_loss: 17.0448, val_MinusLogProbMetric: 17.0448

Epoch 791: val_loss did not improve from 17.03097
196/196 - 60s - loss: 16.1507 - MinusLogProbMetric: 16.1507 - val_loss: 17.0448 - val_MinusLogProbMetric: 17.0448 - lr: 1.0417e-05 - 60s/epoch - 306ms/step
Epoch 792/1000
2023-09-24 04:57:27.292 
Epoch 792/1000 
	 loss: 16.1511, MinusLogProbMetric: 16.1511, val_loss: 17.0388, val_MinusLogProbMetric: 17.0388

Epoch 792: val_loss did not improve from 17.03097
196/196 - 59s - loss: 16.1511 - MinusLogProbMetric: 16.1511 - val_loss: 17.0388 - val_MinusLogProbMetric: 17.0388 - lr: 1.0417e-05 - 59s/epoch - 301ms/step
Epoch 793/1000
2023-09-24 04:58:28.762 
Epoch 793/1000 
	 loss: 16.1485, MinusLogProbMetric: 16.1485, val_loss: 17.0378, val_MinusLogProbMetric: 17.0378

Epoch 793: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1485 - MinusLogProbMetric: 16.1485 - val_loss: 17.0378 - val_MinusLogProbMetric: 17.0378 - lr: 1.0417e-05 - 61s/epoch - 314ms/step
Epoch 794/1000
2023-09-24 04:59:28.302 
Epoch 794/1000 
	 loss: 16.1520, MinusLogProbMetric: 16.1520, val_loss: 17.0360, val_MinusLogProbMetric: 17.0360

Epoch 794: val_loss did not improve from 17.03097
196/196 - 60s - loss: 16.1520 - MinusLogProbMetric: 16.1520 - val_loss: 17.0360 - val_MinusLogProbMetric: 17.0360 - lr: 1.0417e-05 - 60s/epoch - 304ms/step
Epoch 795/1000
2023-09-24 05:00:29.027 
Epoch 795/1000 
	 loss: 16.1494, MinusLogProbMetric: 16.1494, val_loss: 17.0352, val_MinusLogProbMetric: 17.0352

Epoch 795: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1494 - MinusLogProbMetric: 16.1494 - val_loss: 17.0352 - val_MinusLogProbMetric: 17.0352 - lr: 1.0417e-05 - 61s/epoch - 310ms/step
Epoch 796/1000
2023-09-24 05:01:30.735 
Epoch 796/1000 
	 loss: 16.1494, MinusLogProbMetric: 16.1494, val_loss: 17.0398, val_MinusLogProbMetric: 17.0398

Epoch 796: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1494 - MinusLogProbMetric: 16.1494 - val_loss: 17.0398 - val_MinusLogProbMetric: 17.0398 - lr: 1.0417e-05 - 62s/epoch - 315ms/step
Epoch 797/1000
2023-09-24 05:02:35.599 
Epoch 797/1000 
	 loss: 16.1492, MinusLogProbMetric: 16.1492, val_loss: 17.0431, val_MinusLogProbMetric: 17.0431

Epoch 797: val_loss did not improve from 17.03097
196/196 - 65s - loss: 16.1492 - MinusLogProbMetric: 16.1492 - val_loss: 17.0431 - val_MinusLogProbMetric: 17.0431 - lr: 1.0417e-05 - 65s/epoch - 331ms/step
Epoch 798/1000
2023-09-24 05:03:36.852 
Epoch 798/1000 
	 loss: 16.1505, MinusLogProbMetric: 16.1505, val_loss: 17.0402, val_MinusLogProbMetric: 17.0402

Epoch 798: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1505 - MinusLogProbMetric: 16.1505 - val_loss: 17.0402 - val_MinusLogProbMetric: 17.0402 - lr: 1.0417e-05 - 61s/epoch - 312ms/step
Epoch 799/1000
2023-09-24 05:04:39.502 
Epoch 799/1000 
	 loss: 16.1511, MinusLogProbMetric: 16.1511, val_loss: 17.0485, val_MinusLogProbMetric: 17.0485

Epoch 799: val_loss did not improve from 17.03097
196/196 - 63s - loss: 16.1511 - MinusLogProbMetric: 16.1511 - val_loss: 17.0485 - val_MinusLogProbMetric: 17.0485 - lr: 1.0417e-05 - 63s/epoch - 320ms/step
Epoch 800/1000
2023-09-24 05:05:41.190 
Epoch 800/1000 
	 loss: 16.1502, MinusLogProbMetric: 16.1502, val_loss: 17.0456, val_MinusLogProbMetric: 17.0456

Epoch 800: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1502 - MinusLogProbMetric: 16.1502 - val_loss: 17.0456 - val_MinusLogProbMetric: 17.0456 - lr: 1.0417e-05 - 62s/epoch - 315ms/step
Epoch 801/1000
2023-09-24 05:06:45.472 
Epoch 801/1000 
	 loss: 16.1499, MinusLogProbMetric: 16.1499, val_loss: 17.0418, val_MinusLogProbMetric: 17.0418

Epoch 801: val_loss did not improve from 17.03097
196/196 - 64s - loss: 16.1499 - MinusLogProbMetric: 16.1499 - val_loss: 17.0418 - val_MinusLogProbMetric: 17.0418 - lr: 1.0417e-05 - 64s/epoch - 328ms/step
Epoch 802/1000
2023-09-24 05:07:47.879 
Epoch 802/1000 
	 loss: 16.1497, MinusLogProbMetric: 16.1497, val_loss: 17.0346, val_MinusLogProbMetric: 17.0346

Epoch 802: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1497 - MinusLogProbMetric: 16.1497 - val_loss: 17.0346 - val_MinusLogProbMetric: 17.0346 - lr: 1.0417e-05 - 62s/epoch - 318ms/step
Epoch 803/1000
2023-09-24 05:08:48.673 
Epoch 803/1000 
	 loss: 16.1483, MinusLogProbMetric: 16.1483, val_loss: 17.0369, val_MinusLogProbMetric: 17.0369

Epoch 803: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1483 - MinusLogProbMetric: 16.1483 - val_loss: 17.0369 - val_MinusLogProbMetric: 17.0369 - lr: 1.0417e-05 - 61s/epoch - 310ms/step
Epoch 804/1000
2023-09-24 05:09:49.033 
Epoch 804/1000 
	 loss: 16.1480, MinusLogProbMetric: 16.1480, val_loss: 17.0417, val_MinusLogProbMetric: 17.0417

Epoch 804: val_loss did not improve from 17.03097
196/196 - 60s - loss: 16.1480 - MinusLogProbMetric: 16.1480 - val_loss: 17.0417 - val_MinusLogProbMetric: 17.0417 - lr: 1.0417e-05 - 60s/epoch - 308ms/step
Epoch 805/1000
2023-09-24 05:10:50.670 
Epoch 805/1000 
	 loss: 16.1503, MinusLogProbMetric: 16.1503, val_loss: 17.0471, val_MinusLogProbMetric: 17.0471

Epoch 805: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1503 - MinusLogProbMetric: 16.1503 - val_loss: 17.0471 - val_MinusLogProbMetric: 17.0471 - lr: 1.0417e-05 - 62s/epoch - 314ms/step
Epoch 806/1000
2023-09-24 05:11:51.970 
Epoch 806/1000 
	 loss: 16.1498, MinusLogProbMetric: 16.1498, val_loss: 17.0388, val_MinusLogProbMetric: 17.0388

Epoch 806: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1498 - MinusLogProbMetric: 16.1498 - val_loss: 17.0388 - val_MinusLogProbMetric: 17.0388 - lr: 1.0417e-05 - 61s/epoch - 313ms/step
Epoch 807/1000
2023-09-24 05:12:52.623 
Epoch 807/1000 
	 loss: 16.1489, MinusLogProbMetric: 16.1489, val_loss: 17.0404, val_MinusLogProbMetric: 17.0404

Epoch 807: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1489 - MinusLogProbMetric: 16.1489 - val_loss: 17.0404 - val_MinusLogProbMetric: 17.0404 - lr: 1.0417e-05 - 61s/epoch - 309ms/step
Epoch 808/1000
2023-09-24 05:13:53.103 
Epoch 808/1000 
	 loss: 16.1502, MinusLogProbMetric: 16.1502, val_loss: 17.0382, val_MinusLogProbMetric: 17.0382

Epoch 808: val_loss did not improve from 17.03097
196/196 - 60s - loss: 16.1502 - MinusLogProbMetric: 16.1502 - val_loss: 17.0382 - val_MinusLogProbMetric: 17.0382 - lr: 1.0417e-05 - 60s/epoch - 309ms/step
Epoch 809/1000
2023-09-24 05:14:53.254 
Epoch 809/1000 
	 loss: 16.1481, MinusLogProbMetric: 16.1481, val_loss: 17.0560, val_MinusLogProbMetric: 17.0560

Epoch 809: val_loss did not improve from 17.03097
196/196 - 60s - loss: 16.1481 - MinusLogProbMetric: 16.1481 - val_loss: 17.0560 - val_MinusLogProbMetric: 17.0560 - lr: 1.0417e-05 - 60s/epoch - 307ms/step
Epoch 810/1000
2023-09-24 05:15:51.608 
Epoch 810/1000 
	 loss: 16.1500, MinusLogProbMetric: 16.1500, val_loss: 17.0397, val_MinusLogProbMetric: 17.0397

Epoch 810: val_loss did not improve from 17.03097
196/196 - 58s - loss: 16.1500 - MinusLogProbMetric: 16.1500 - val_loss: 17.0397 - val_MinusLogProbMetric: 17.0397 - lr: 1.0417e-05 - 58s/epoch - 298ms/step
Epoch 811/1000
2023-09-24 05:16:53.732 
Epoch 811/1000 
	 loss: 16.1502, MinusLogProbMetric: 16.1502, val_loss: 17.0517, val_MinusLogProbMetric: 17.0517

Epoch 811: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1502 - MinusLogProbMetric: 16.1502 - val_loss: 17.0517 - val_MinusLogProbMetric: 17.0517 - lr: 1.0417e-05 - 62s/epoch - 317ms/step
Epoch 812/1000
2023-09-24 05:17:56.113 
Epoch 812/1000 
	 loss: 16.1497, MinusLogProbMetric: 16.1497, val_loss: 17.0406, val_MinusLogProbMetric: 17.0406

Epoch 812: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1497 - MinusLogProbMetric: 16.1497 - val_loss: 17.0406 - val_MinusLogProbMetric: 17.0406 - lr: 1.0417e-05 - 62s/epoch - 318ms/step
Epoch 813/1000
2023-09-24 05:18:58.273 
Epoch 813/1000 
	 loss: 16.1470, MinusLogProbMetric: 16.1470, val_loss: 17.0453, val_MinusLogProbMetric: 17.0453

Epoch 813: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1470 - MinusLogProbMetric: 16.1470 - val_loss: 17.0453 - val_MinusLogProbMetric: 17.0453 - lr: 1.0417e-05 - 62s/epoch - 317ms/step
Epoch 814/1000
2023-09-24 05:19:59.184 
Epoch 814/1000 
	 loss: 16.1490, MinusLogProbMetric: 16.1490, val_loss: 17.0422, val_MinusLogProbMetric: 17.0422

Epoch 814: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1490 - MinusLogProbMetric: 16.1490 - val_loss: 17.0422 - val_MinusLogProbMetric: 17.0422 - lr: 1.0417e-05 - 61s/epoch - 311ms/step
Epoch 815/1000
2023-09-24 05:21:01.400 
Epoch 815/1000 
	 loss: 16.1479, MinusLogProbMetric: 16.1479, val_loss: 17.0423, val_MinusLogProbMetric: 17.0423

Epoch 815: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1479 - MinusLogProbMetric: 16.1479 - val_loss: 17.0423 - val_MinusLogProbMetric: 17.0423 - lr: 1.0417e-05 - 62s/epoch - 317ms/step
Epoch 816/1000
2023-09-24 05:22:01.325 
Epoch 816/1000 
	 loss: 16.1486, MinusLogProbMetric: 16.1486, val_loss: 17.0409, val_MinusLogProbMetric: 17.0409

Epoch 816: val_loss did not improve from 17.03097
196/196 - 60s - loss: 16.1486 - MinusLogProbMetric: 16.1486 - val_loss: 17.0409 - val_MinusLogProbMetric: 17.0409 - lr: 1.0417e-05 - 60s/epoch - 306ms/step
Epoch 817/1000
2023-09-24 05:23:00.968 
Epoch 817/1000 
	 loss: 16.1473, MinusLogProbMetric: 16.1473, val_loss: 17.0394, val_MinusLogProbMetric: 17.0394

Epoch 817: val_loss did not improve from 17.03097
196/196 - 60s - loss: 16.1473 - MinusLogProbMetric: 16.1473 - val_loss: 17.0394 - val_MinusLogProbMetric: 17.0394 - lr: 1.0417e-05 - 60s/epoch - 304ms/step
Epoch 818/1000
2023-09-24 05:24:00.547 
Epoch 818/1000 
	 loss: 16.1479, MinusLogProbMetric: 16.1479, val_loss: 17.0448, val_MinusLogProbMetric: 17.0448

Epoch 818: val_loss did not improve from 17.03097
196/196 - 60s - loss: 16.1479 - MinusLogProbMetric: 16.1479 - val_loss: 17.0448 - val_MinusLogProbMetric: 17.0448 - lr: 1.0417e-05 - 60s/epoch - 304ms/step
Epoch 819/1000
2023-09-24 05:25:01.605 
Epoch 819/1000 
	 loss: 16.1486, MinusLogProbMetric: 16.1486, val_loss: 17.0396, val_MinusLogProbMetric: 17.0396

Epoch 819: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1486 - MinusLogProbMetric: 16.1486 - val_loss: 17.0396 - val_MinusLogProbMetric: 17.0396 - lr: 1.0417e-05 - 61s/epoch - 312ms/step
Epoch 820/1000
2023-09-24 05:26:04.756 
Epoch 820/1000 
	 loss: 16.1487, MinusLogProbMetric: 16.1487, val_loss: 17.0400, val_MinusLogProbMetric: 17.0400

Epoch 820: val_loss did not improve from 17.03097
196/196 - 63s - loss: 16.1487 - MinusLogProbMetric: 16.1487 - val_loss: 17.0400 - val_MinusLogProbMetric: 17.0400 - lr: 1.0417e-05 - 63s/epoch - 322ms/step
Epoch 821/1000
2023-09-24 05:27:05.295 
Epoch 821/1000 
	 loss: 16.1484, MinusLogProbMetric: 16.1484, val_loss: 17.0482, val_MinusLogProbMetric: 17.0482

Epoch 821: val_loss did not improve from 17.03097
196/196 - 61s - loss: 16.1484 - MinusLogProbMetric: 16.1484 - val_loss: 17.0482 - val_MinusLogProbMetric: 17.0482 - lr: 1.0417e-05 - 61s/epoch - 309ms/step
Epoch 822/1000
2023-09-24 05:28:07.784 
Epoch 822/1000 
	 loss: 16.1488, MinusLogProbMetric: 16.1488, val_loss: 17.0468, val_MinusLogProbMetric: 17.0468

Epoch 822: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1488 - MinusLogProbMetric: 16.1488 - val_loss: 17.0468 - val_MinusLogProbMetric: 17.0468 - lr: 1.0417e-05 - 62s/epoch - 319ms/step
Epoch 823/1000
2023-09-24 05:29:09.682 
Epoch 823/1000 
	 loss: 16.1476, MinusLogProbMetric: 16.1476, val_loss: 17.0416, val_MinusLogProbMetric: 17.0416

Epoch 823: val_loss did not improve from 17.03097
196/196 - 62s - loss: 16.1476 - MinusLogProbMetric: 16.1476 - val_loss: 17.0416 - val_MinusLogProbMetric: 17.0416 - lr: 1.0417e-05 - 62s/epoch - 316ms/step
Epoch 824/1000
2023-09-24 05:30:08.587 
Epoch 824/1000 
	 loss: 16.1470, MinusLogProbMetric: 16.1470, val_loss: 17.0430, val_MinusLogProbMetric: 17.0430

Epoch 824: val_loss did not improve from 17.03097
196/196 - 59s - loss: 16.1470 - MinusLogProbMetric: 16.1470 - val_loss: 17.0430 - val_MinusLogProbMetric: 17.0430 - lr: 1.0417e-05 - 59s/epoch - 301ms/step
Epoch 825/1000
2023-09-24 05:31:08.596 
Epoch 825/1000 
	 loss: 16.1498, MinusLogProbMetric: 16.1498, val_loss: 17.0384, val_MinusLogProbMetric: 17.0384

Epoch 825: val_loss did not improve from 17.03097
196/196 - 60s - loss: 16.1498 - MinusLogProbMetric: 16.1498 - val_loss: 17.0384 - val_MinusLogProbMetric: 17.0384 - lr: 1.0417e-05 - 60s/epoch - 306ms/step
Epoch 826/1000
2023-09-24 05:32:11.589 
Epoch 826/1000 
	 loss: 16.1482, MinusLogProbMetric: 16.1482, val_loss: 17.0369, val_MinusLogProbMetric: 17.0369

Epoch 826: val_loss did not improve from 17.03097
196/196 - 63s - loss: 16.1482 - MinusLogProbMetric: 16.1482 - val_loss: 17.0369 - val_MinusLogProbMetric: 17.0369 - lr: 1.0417e-05 - 63s/epoch - 321ms/step
Epoch 827/1000
2023-09-24 05:33:10.986 
Epoch 827/1000 
	 loss: 16.1485, MinusLogProbMetric: 16.1485, val_loss: 17.0428, val_MinusLogProbMetric: 17.0428

Epoch 827: val_loss did not improve from 17.03097
Restoring model weights from the end of the best epoch: 727.
196/196 - 60s - loss: 16.1485 - MinusLogProbMetric: 16.1485 - val_loss: 17.0428 - val_MinusLogProbMetric: 17.0428 - lr: 1.0417e-05 - 60s/epoch - 305ms/step
Epoch 827: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
LR metric calculation completed in 25.71396824999829 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
LR metric calculation completed in 53.180751555002644 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
