2023-10-01 08:48:40.834012: Importing os...
2023-10-01 08:48:40.834195: Importing sys...
2023-10-01 08:48:40.834223: Importing and initializing argparse...
Visible devices: [2]
2023-10-01 08:48:40.849988: Importing timer from timeit...
2023-10-01 08:48:40.850376: Setting env variables for tf import (only device [2] will be available)...
2023-10-01 08:48:40.850408: Importing numpy...
2023-10-01 08:48:41.037781: Importing pandas...
2023-10-01 08:48:41.489610: Importing shutil...
2023-10-01 08:48:41.489653: Importing subprocess...
2023-10-01 08:48:41.489665: Importing tensorflow...
Tensorflow version: 2.12.0
2023-10-01 08:48:47.852053: Importing tensorflow_probability...
Tensorflow probability version: 0.20.1
2023-10-01 08:48:50.113925: Importing textwrap...
2023-10-01 08:48:50.113972: Importing timeit...
2023-10-01 08:48:50.113985: Importing traceback...
2023-10-01 08:48:50.113994: Importing typing...
2023-10-01 08:48:50.114011: Setting tf configs...
2023-10-01 08:48:50.579691: Importing custom module...
Successfully loaded GPU model: NVIDIA A40
2023-10-01 08:48:54.506107: All modues imported successfully.
Directory ../../results/MsplineN_new/ already exists.
Directory ../../results/MsplineN_new/run_1/ already exists.
Skipping it.
===========
Run 1/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_2/ already exists.
Skipping it.
===========
Run 2/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_3/ already exists.
Skipping it.
===========
Run 3/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_4/ already exists.
Skipping it.
===========
Run 4/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_5/ already exists.
Skipping it.
===========
Run 5/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_6/ already exists.
Skipping it.
===========
Run 6/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_7/ already exists.
Skipping it.
===========
Run 7/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_8/ already exists.
Skipping it.
===========
Run 8/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_9/ already exists.
Skipping it.
===========
Run 9/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_10/ already exists.
Skipping it.
===========
Run 10/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_11/ already exists.
Skipping it.
===========
Run 11/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_12/ already exists.
Skipping it.
===========
Run 12/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_13/ already exists.
Skipping it.
===========
Run 13/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_14/ already exists.
Skipping it.
===========
Run 14/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_15/ already exists.
Skipping it.
===========
Run 15/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_16/ already exists.
Skipping it.
===========
Run 16/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_17/ already exists.
Skipping it.
===========
Run 17/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_18/ already exists.
Skipping it.
===========
Run 18/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_19/ already exists.
Skipping it.
===========
Run 19/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_20/ already exists.
Skipping it.
===========
Run 20/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_21/ already exists.
Skipping it.
===========
Run 21/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_22/ already exists.
Skipping it.
===========
Run 22/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_23/ already exists.
Skipping it.
===========
Run 23/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_24/ already exists.
Skipping it.
===========
Run 24/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_25/ already exists.
Skipping it.
===========
Run 25/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_26/ already exists.
Skipping it.
===========
Run 26/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_27/ already exists.
Skipping it.
===========
Run 27/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_28/ already exists.
Skipping it.
===========
Run 28/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_29/ already exists.
Skipping it.
===========
Run 29/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_30/ already exists.
Skipping it.
===========
Run 30/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_31/ already exists.
Skipping it.
===========
Run 31/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_32/ already exists.
Skipping it.
===========
Run 32/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_33/ already exists.
Skipping it.
===========
Run 33/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_34/ already exists.
Skipping it.
===========
Run 34/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_35/ already exists.
Skipping it.
===========
Run 35/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_36/ already exists.
Skipping it.
===========
Run 36/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_37/ already exists.
Skipping it.
===========
Run 37/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_38/ already exists.
Skipping it.
===========
Run 38/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_39/ already exists.
Skipping it.
===========
Run 39/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_40/ already exists.
Skipping it.
===========
Run 40/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_41/ already exists.
Skipping it.
===========
Run 41/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_42/ already exists.
Skipping it.
===========
Run 42/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_43/ already exists.
Skipping it.
===========
Run 43/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_44/ already exists.
Skipping it.
===========
Run 44/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_45/ already exists.
Skipping it.
===========
Run 45/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_46/ already exists.
Skipping it.
===========
Run 46/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_47/ already exists.
Skipping it.
===========
Run 47/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_48/ already exists.
Skipping it.
===========
Run 48/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_49/ already exists.
Skipping it.
===========
Run 49/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_50/ already exists.
Skipping it.
===========
Run 50/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_51/ already exists.
Skipping it.
===========
Run 51/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_52/ already exists.
Skipping it.
===========
Run 52/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_53/ already exists.
Skipping it.
===========
Run 53/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_54/ already exists.
Skipping it.
===========
Run 54/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_55/ already exists.
Skipping it.
===========
Run 55/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_56/ already exists.
Skipping it.
===========
Run 56/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_57/ already exists.
Skipping it.
===========
Run 57/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_58/ already exists.
Skipping it.
===========
Run 58/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_59/ already exists.
Skipping it.
===========
Run 59/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_60/ already exists.
Skipping it.
===========
Run 60/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_61/ already exists.
Skipping it.
===========
Run 61/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_62/ already exists.
Skipping it.
===========
Run 62/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_63/ already exists.
Skipping it.
===========
Run 63/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_64/ already exists.
Skipping it.
===========
Run 64/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_65/ already exists.
Skipping it.
===========
Run 65/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_66/ already exists.
Skipping it.
===========
Run 66/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_67/ already exists.
Skipping it.
===========
Run 67/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_68/ already exists.
Skipping it.
===========
Run 68/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_69/ already exists.
Skipping it.
===========
Run 69/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_70/ already exists.
Skipping it.
===========
Run 70/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_71/ already exists.
Skipping it.
===========
Run 71/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_72/ already exists.
Skipping it.
===========
Run 72/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_73/ already exists.
Skipping it.
===========
Run 73/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_74/ already exists.
Skipping it.
===========
Run 74/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_75/ already exists.
Skipping it.
===========
Run 75/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_76/ already exists.
Skipping it.
===========
Run 76/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_77/ already exists.
Skipping it.
===========
Run 77/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_78/ already exists.
Skipping it.
===========
Run 78/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_79/ already exists.
Skipping it.
===========
Run 79/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_80/ already exists.
Skipping it.
===========
Run 80/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_81/ already exists.
Skipping it.
===========
Run 81/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_82/ already exists.
Skipping it.
===========
Run 82/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_83/ already exists.
Skipping it.
===========
Run 83/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_84/ already exists.
Skipping it.
===========
Run 84/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_85/ already exists.
Skipping it.
===========
Run 85/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_86/ already exists.
Skipping it.
===========
Run 86/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_87/ already exists.
Skipping it.
===========
Run 87/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_88/ already exists.
Skipping it.
===========
Run 88/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_89/ already exists.
Skipping it.
===========
Run 89/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_90/ already exists.
Skipping it.
===========
Run 90/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_91/ already exists.
Skipping it.
===========
Run 91/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_92/ already exists.
Skipping it.
===========
Run 92/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_93/ already exists.
Skipping it.
===========
Run 93/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_94/ already exists.
Skipping it.
===========
Run 94/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_95/ already exists.
Skipping it.
===========
Run 95/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_96/ already exists.
Skipping it.
===========
Run 96/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_97/ already exists.
Skipping it.
===========
Run 97/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_98/ already exists.
Skipping it.
===========
Run 98/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_99/ already exists.
Skipping it.
===========
Run 99/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_100/ already exists.
Skipping it.
===========
Run 100/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_101/ already exists.
Skipping it.
===========
Run 101/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_102/ already exists.
Skipping it.
===========
Run 102/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_103/ already exists.
Skipping it.
===========
Run 103/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_104/ already exists.
Skipping it.
===========
Run 104/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_105/ already exists.
Skipping it.
===========
Run 105/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_106/ already exists.
Skipping it.
===========
Run 106/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_107/ already exists.
Skipping it.
===========
Run 107/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_108/ already exists.
Skipping it.
===========
Run 108/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_109/ already exists.
Skipping it.
===========
Run 109/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_110/ already exists.
Skipping it.
===========
Run 110/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_111/ already exists.
Skipping it.
===========
Run 111/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_112/ already exists.
Skipping it.
===========
Run 112/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_113/ already exists.
Skipping it.
===========
Run 113/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_114/ already exists.
Skipping it.
===========
Run 114/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_115/ already exists.
Skipping it.
===========
Run 115/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_116/ already exists.
Skipping it.
===========
Run 116/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_117/ already exists.
Skipping it.
===========
Run 117/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_118/ already exists.
Skipping it.
===========
Run 118/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_119/ already exists.
Skipping it.
===========
Run 119/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_120/ already exists.
Skipping it.
===========
Run 120/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_121/ already exists.
Skipping it.
===========
Run 121/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_122/ already exists.
Skipping it.
===========
Run 122/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_123/ already exists.
Skipping it.
===========
Run 123/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_124/ already exists.
Skipping it.
===========
Run 124/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_125/ already exists.
Skipping it.
===========
Run 125/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_126/ already exists.
Skipping it.
===========
Run 126/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_127/ already exists.
Skipping it.
===========
Run 127/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_128/ already exists.
Skipping it.
===========
Run 128/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_129/ already exists.
Skipping it.
===========
Run 129/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_130/ already exists.
Skipping it.
===========
Run 130/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_131/ already exists.
Skipping it.
===========
Run 131/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_132/ already exists.
Skipping it.
===========
Run 132/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_133/ already exists.
Skipping it.
===========
Run 133/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_134/ already exists.
Skipping it.
===========
Run 134/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_135/ already exists.
Skipping it.
===========
Run 135/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_136/ already exists.
Skipping it.
===========
Run 136/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_137/ already exists.
Skipping it.
===========
Run 137/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_138/ already exists.
Skipping it.
===========
Run 138/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_139/ already exists.
Skipping it.
===========
Run 139/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_140/ already exists.
Skipping it.
===========
Run 140/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_141/ already exists.
Skipping it.
===========
Run 141/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_142/ already exists.
Skipping it.
===========
Run 142/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_143/ already exists.
Skipping it.
===========
Run 143/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_144/ already exists.
Skipping it.
===========
Run 144/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_145/ already exists.
Skipping it.
===========
Run 145/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_146/ already exists.
Skipping it.
===========
Run 146/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_147/ already exists.
Skipping it.
===========
Run 147/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_148/ already exists.
Skipping it.
===========
Run 148/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_149/ already exists.
Skipping it.
===========
Run 149/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_150/ already exists.
Skipping it.
===========
Run 150/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_151/ already exists.
Skipping it.
===========
Run 151/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_152/ already exists.
Skipping it.
===========
Run 152/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_153/ already exists.
Skipping it.
===========
Run 153/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_154/ already exists.
Skipping it.
===========
Run 154/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_155/ already exists.
Skipping it.
===========
Run 155/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_156/ already exists.
Skipping it.
===========
Run 156/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_157/ already exists.
Skipping it.
===========
Run 157/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_158/ already exists.
Skipping it.
===========
Run 158/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_159/ already exists.
Skipping it.
===========
Run 159/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_160/ already exists.
Skipping it.
===========
Run 160/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_161/ already exists.
Skipping it.
===========
Run 161/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_162/ already exists.
Skipping it.
===========
Run 162/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_163/ already exists.
Skipping it.
===========
Run 163/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_164/ already exists.
Skipping it.
===========
Run 164/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_165/ already exists.
Skipping it.
===========
Run 165/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_166/ already exists.
Skipping it.
===========
Run 166/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_167/ already exists.
Skipping it.
===========
Run 167/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_168/ already exists.
Skipping it.
===========
Run 168/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_169/ already exists.
Skipping it.
===========
Run 169/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_170/ already exists.
Skipping it.
===========
Run 170/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_171/ already exists.
Skipping it.
===========
Run 171/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_172/ already exists.
Skipping it.
===========
Run 172/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_173/ already exists.
Skipping it.
===========
Run 173/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_174/ already exists.
Skipping it.
===========
Run 174/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_175/ already exists.
Skipping it.
===========
Run 175/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_176/ already exists.
Skipping it.
===========
Run 176/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_177/ already exists.
Skipping it.
===========
Run 177/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_178/ already exists.
Skipping it.
===========
Run 178/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_179/ already exists.
Skipping it.
===========
Run 179/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_180/ already exists.
Skipping it.
===========
Run 180/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_181/ already exists.
Skipping it.
===========
Run 181/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_182/ already exists.
Skipping it.
===========
Run 182/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_183/ already exists.
Skipping it.
===========
Run 183/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_184/ already exists.
Skipping it.
===========
Run 184/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_185/ already exists.
Skipping it.
===========
Run 185/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_186/ already exists.
Skipping it.
===========
Run 186/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_187/ already exists.
Skipping it.
===========
Run 187/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_188/ already exists.
Skipping it.
===========
Run 188/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_189/ already exists.
Skipping it.
===========
Run 189/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_190/ already exists.
Skipping it.
===========
Run 190/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_191/ already exists.
Skipping it.
===========
Run 191/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_192/ already exists.
Skipping it.
===========
Run 192/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_193/ already exists.
Skipping it.
===========
Run 193/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_194/ already exists.
Skipping it.
===========
Run 194/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_195/ already exists.
Skipping it.
===========
Run 195/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_196/ already exists.
Skipping it.
===========
Run 196/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_197/ already exists.
Skipping it.
===========
Run 197/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_198/ already exists.
Skipping it.
===========
Run 198/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_199/ already exists.
Skipping it.
===========
Run 199/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_200/ already exists.
Skipping it.
===========
Run 200/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_201/ already exists.
Skipping it.
===========
Run 201/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_202/ already exists.
Skipping it.
===========
Run 202/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_203/ already exists.
Skipping it.
===========
Run 203/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_204/ already exists.
Skipping it.
===========
Run 204/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_205/ already exists.
Skipping it.
===========
Run 205/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_206/ already exists.
Skipping it.
===========
Run 206/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_207/ already exists.
Skipping it.
===========
Run 207/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_208/ already exists.
Skipping it.
===========
Run 208/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_209/ already exists.
Skipping it.
===========
Run 209/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_210/ already exists.
Skipping it.
===========
Run 210/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_211/ already exists.
Skipping it.
===========
Run 211/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_212/ already exists.
Skipping it.
===========
Run 212/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_213/ already exists.
Skipping it.
===========
Run 213/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_214/ already exists.
Skipping it.
===========
Run 214/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_215/ already exists.
Skipping it.
===========
Run 215/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_216/ already exists.
Skipping it.
===========
Run 216/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_217/ already exists.
Skipping it.
===========
Run 217/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_218/ already exists.
Skipping it.
===========
Run 218/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_219/ already exists.
Skipping it.
===========
Run 219/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_220/ already exists.
Skipping it.
===========
Run 220/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_221/ already exists.
Skipping it.
===========
Run 221/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_222/ already exists.
Skipping it.
===========
Run 222/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_223/ already exists.
Skipping it.
===========
Run 223/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_224/ already exists.
Skipping it.
===========
Run 224/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_225/ already exists.
Skipping it.
===========
Run 225/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_226/ already exists.
Skipping it.
===========
Run 226/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_227/ already exists.
Skipping it.
===========
Run 227/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_228/ already exists.
Skipping it.
===========
Run 228/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_229/ already exists.
Skipping it.
===========
Run 229/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_230/ already exists.
Skipping it.
===========
Run 230/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_231/ already exists.
Skipping it.
===========
Run 231/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_232/ already exists.
Skipping it.
===========
Run 232/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_233/ already exists.
Skipping it.
===========
Run 233/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_234/ already exists.
Skipping it.
===========
Run 234/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_235/ already exists.
Skipping it.
===========
Run 235/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_236/ already exists.
Skipping it.
===========
Run 236/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_237/ already exists.
Skipping it.
===========
Run 237/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_238/ already exists.
Skipping it.
===========
Run 238/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_239/ already exists.
Skipping it.
===========
Run 239/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_240/ already exists.
Skipping it.
===========
Run 240/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_241/ already exists.
Skipping it.
===========
Run 241/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_242/ already exists.
Skipping it.
===========
Run 242/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_243/ already exists.
Skipping it.
===========
Run 243/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_244/ already exists.
Skipping it.
===========
Run 244/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_245/ already exists.
Skipping it.
===========
Run 245/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_246/ already exists.
Skipping it.
===========
Run 246/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_247/ already exists.
Skipping it.
===========
Run 247/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_248/ already exists.
Skipping it.
===========
Run 248/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_249/ already exists.
Skipping it.
===========
Run 249/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_250/ already exists.
Skipping it.
===========
Run 250/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_251/ already exists.
Skipping it.
===========
Run 251/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_252/ already exists.
Skipping it.
===========
Run 252/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_253/ already exists.
Skipping it.
===========
Run 253/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_254/ already exists.
Skipping it.
===========
Run 254/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_255/ already exists.
Skipping it.
===========
Run 255/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_256/ already exists.
Skipping it.
===========
Run 256/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_257/ already exists.
Skipping it.
===========
Run 257/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_258/ already exists.
Skipping it.
===========
Run 258/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_259/ already exists.
Skipping it.
===========
Run 259/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_260/ already exists.
Skipping it.
===========
Run 260/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_261/ already exists.
Skipping it.
===========
Run 261/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_262/ already exists.
Skipping it.
===========
Run 262/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_263/ already exists.
Skipping it.
===========
Run 263/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_264/ already exists.
Skipping it.
===========
Run 264/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_265/ already exists.
Skipping it.
===========
Run 265/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_266/ already exists.
Skipping it.
===========
Run 266/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_267/ already exists.
Skipping it.
===========
Run 267/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_268/ already exists.
Skipping it.
===========
Run 268/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_269/ already exists.
Skipping it.
===========
Run 269/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_270/ already exists.
Skipping it.
===========
Run 270/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_271/ already exists.
Skipping it.
===========
Run 271/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_272/ already exists.
Skipping it.
===========
Run 272/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_273/ already exists.
Skipping it.
===========
Run 273/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_274/ already exists.
Skipping it.
===========
Run 274/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_275/ already exists.
Skipping it.
===========
Run 275/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_276/ already exists.
Skipping it.
===========
Run 276/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_277/ already exists.
Skipping it.
===========
Run 277/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_278/ already exists.
Skipping it.
===========
Run 278/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_279/ already exists.
Skipping it.
===========
Run 279/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_280/ already exists.
Skipping it.
===========
Run 280/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_281/ already exists.
Skipping it.
===========
Run 281/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_282/ already exists.
Skipping it.
===========
Run 282/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_283/ already exists.
Skipping it.
===========
Run 283/360 already exists. Skipping it.
===========

===========
Generating train data for run 284.
===========
Train data generated in 2.35 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[400], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 400)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_284/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 0}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_284/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.076268  ,  6.88616   ,  5.3478165 , ...,  3.8629014 ,
         1.1995566 ,  1.9267883 ],
       [ 4.8225775 ,  8.95118   ,  0.7528707 , ...,  1.8203573 ,
         3.4836862 ,  3.4921005 ],
       [ 2.742781  ,  9.857591  ,  0.9890757 , ...,  2.6715052 ,
         3.6458585 ,  4.5970035 ],
       ...,
       [ 5.4338427 ,  6.269119  ,  5.358934  , ...,  2.6914477 ,
        -2.7269814 ,  1.9649754 ],
       [ 5.3152013 ,  6.395792  ,  4.6159983 , ...,  3.7290556 ,
         0.62769914,  1.8891894 ],
       [ 5.8299494 ,  6.2016344 ,  6.5653257 , ...,  3.37879   ,
         2.086897  ,  2.0929666 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[400], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[400], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_284/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_284
self.data_kwargs: {'seed': 0}
self.x_data: [[ 5.6986647   7.6514974   5.9171104  ...  3.1435006   1.5815616
   1.7001917 ]
 [ 5.3164554   9.30571     1.5868908  ...  1.8673227   2.4644895
   4.6784062 ]
 [ 5.472836    8.201929    5.8684087  ...  3.6847925  -1.5378693
   1.7608978 ]
 ...
 [ 2.7201624   9.963066    0.8373301  ...  2.670981    3.0996678
   5.0951123 ]
 [ 5.1644115   9.55198     0.5943103  ...  1.9947044   2.484257
   5.261216  ]
 [ 5.661538    7.9890366   6.225719   ...  4.3883452  -0.20478143
   1.9053537 ]]
self.y_data: []
self.ndims: 400
Model defined.
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 400)]             0         
                                                                 
 log_prob_layer (LogProbLaye  (None,)                  7664480   
 r)                                                              
                                                                 
=================================================================
Total params: 7,664,480
Trainable params: 7,664,480
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer'")
self.model: <keras.engine.functional.Functional object at 0x7f65f0059f00>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7f65c84eba30>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7f65c84eba30>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7f65c825c640>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7f65c825d000>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7f65c825d570>, <keras.callbacks.ModelCheckpoint object at 0x7f65c825d6c0>, <keras.callbacks.EarlyStopping object at 0x7f65c825d8d0>, <keras.callbacks.ReduceLROnPlateau object at 0x7f65c825d900>, <keras.callbacks.TerminateOnNaN object at 0x7f65c825d630>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.076268  ,  6.88616   ,  5.3478165 , ...,  3.8629014 ,
         1.1995566 ,  1.9267883 ],
       [ 4.8225775 ,  8.95118   ,  0.7528707 , ...,  1.8203573 ,
         3.4836862 ,  3.4921005 ],
       [ 2.742781  ,  9.857591  ,  0.9890757 , ...,  2.6715052 ,
         3.6458585 ,  4.5970035 ],
       ...,
       [ 5.4338427 ,  6.269119  ,  5.358934  , ...,  2.6914477 ,
        -2.7269814 ,  1.9649754 ],
       [ 5.3152013 ,  6.395792  ,  4.6159983 , ...,  3.7290556 ,
         0.62769914,  1.8891894 ],
       [ 5.8299494 ,  6.2016344 ,  6.5653257 , ...,  3.37879   ,
         2.086897  ,  2.0929666 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_284/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 284/360 with hyperparameters:
timestamp = 2023-10-01 08:49:04.702508
ndims = 400
seed_train = 0
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 7664480
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 5.6986647   7.6514974   5.9171104   6.3874607   3.7683864   6.315198
  4.0855026   8.229398    9.511869    3.2328355   7.9900284   5.228388
  6.0711856   9.19881    -0.53193074  0.6028388   0.08086238  8.274891
  7.6968718   8.590947    9.087498    7.0211024   3.3921885   8.039434
  0.60600084  6.3953805   1.7101501   9.396954    5.439033    5.0416694
  2.6972475   7.573504    4.420139    4.8672085   0.18404531  7.1216006
  5.424125    5.4142923   9.499141    6.801403    3.5617      4.6616745
  7.6904817   0.68938696  8.02792     7.2567043   2.430327    0.47877562
  2.5878737   4.1901207   4.142128    4.484779    9.642824    2.431578
  1.9777191   1.7798417   6.77623     2.1065412   4.603537    2.7922816
  1.5140517   1.4961886   7.6337137   1.8176042   2.7499375   5.540959
  9.062795    1.0919399   8.526628    0.9855308   9.996653    4.7181334
 10.673272    5.53888     6.768131   -0.11722896  2.0328965   2.027494
  3.7579627   0.6429475   3.173918    5.053435    0.64978456  6.9842157
  5.377479    2.8529625   5.191739    1.0143875   5.6961336   9.327963
  3.7327814   8.966709    0.44215888  6.9540224   2.9075873   0.7294414
  6.6453743   0.41962385 10.126916    0.16560169  5.887296    2.5854962
  7.7728786  10.696261    2.0910528   7.5604696   4.4947186   5.6077495
  2.1176286   8.501421    5.056799    8.4281845   7.6826935   3.000727
  8.159652    3.450142    8.628886    7.515711    8.991402    7.5273967
  8.607548    4.98791     9.567427    7.191281    4.132717    7.6777983
 -0.87460804  3.0146704   6.6280794   3.5004234   5.7523274   3.393818
 -0.08495498  2.4759398   6.289991    5.82453     6.914207    6.066643
  6.418559    4.3311663   8.712504    4.173428    4.6862025   9.480156
  7.9101753   7.9537754   1.1981745   9.402272    7.474897    9.538285
  1.755903    9.249703    2.1388073   6.85404     2.3388042   8.44887
  8.140929    6.254293    3.8785343  -0.57600987  6.5560427   3.7062604
  7.3387465   8.582174   10.304363    8.409807   -0.3102733   3.6643646
  6.8256      0.9068533   4.850386    0.45045167  1.8944049   0.27928168
  7.8176565   2.0320911   3.3524973   9.757498    7.467601    0.87533504
  1.8758272   6.2271996   5.6681485   2.4275374   8.508893    6.7606125
  5.2955656   6.373493    7.1711936   3.36423     4.037153    2.699342
  1.9231356  10.359797    6.879227    5.1303353   3.0493474   2.5620956
  1.8800769   4.0123587   2.7936947   7.42107     3.7820895   1.8949326
  0.09360699 -0.4583012   6.8220634   4.5539517   4.6279488   9.441487
 10.026452    2.8485103   6.999056    2.531457    0.32464084  7.565683
  3.2945087   3.8199189   6.028941    9.405453    6.3799043   8.5198
  2.6267679   8.359268    1.8683264   9.688679    6.9771137   3.0506783
  9.310956    6.280671    2.3518283   2.173439    5.056288    1.200287
  1.838595    5.680684    3.3294065   6.6520257   2.8509219   5.003288
  7.740259    1.1952301   5.0048275   0.18754601  6.9930954   3.8974705
  5.546231    3.164465    1.0633062   4.1084657   3.9901583   8.413511
  8.756381    7.2518163   9.182116    1.2080611   6.124805    5.890928
  9.981709    2.6445248   2.4708004   1.6516155   0.38599092  8.390312
  8.48535     8.63641     2.519439    5.5393343   0.7096226   5.2080193
  9.780407    9.82083     4.150905    8.762878    2.4894845   9.2281885
  9.195977    8.037719    5.654861    8.146059    3.0055616   8.065545
  6.1640725   0.7547456   3.304792    2.9217584   9.819063    4.010496
  4.7889414   6.1152916   2.61193     0.7662176   7.676996    2.4714673
  2.4742422   2.261958    0.82979137  8.694324    9.718234    9.885107
  9.413482    7.257649    3.440421    0.73255527  1.7351725   3.840838
  2.3125005   0.38587588  6.591376    0.05615995  7.6522884   1.4482789
  0.9847053   1.1432056   6.1383877   2.4958684   4.82392     4.3693404
  8.897161    9.817988    2.1162376   0.62157476  1.205469    2.8096547
  2.1008475   5.3051467   6.9504256   7.6150713   2.8341916   3.8360279
  1.7632424   6.0884132   0.6784027   7.012564    7.2794385   6.7903004
  3.459392    2.7969608   5.1842337   2.7385743   4.0812817   2.155891
  4.4230895   0.55661917  8.154131    0.8012624   5.2568727   3.4612136
  5.2981954   9.518413    5.9109726   0.07157508  3.8748505   5.076651
  5.365879    6.797507    2.8396149   1.1554915   4.8941483   9.061147
  2.3738723   8.746267    5.3657002   3.9611053   8.72354     4.927108
  7.275825    3.9251623   9.644724    7.551099    7.2622724   2.0224228
  7.8441443   6.197558    2.4150403   1.6151003   8.196012   10.26697
  5.35332     6.4662495   9.066096    5.311637    9.721733    5.3543406
  9.785578    8.9016075   8.228127    1.5874082   6.6150055   3.9042728
  0.7777583   4.2105155   2.6493232   9.150846    0.452482    8.061001
  4.128545    3.1435006   1.5815616   1.7001917 ]
Epoch 1/1000
2023-10-01 08:50:54.006 
Epoch 1/1000 
	 loss: 455.7071, MinusLogProbMetric: 455.7071, val_loss: 216.3192, val_MinusLogProbMetric: 216.3192

Epoch 1: val_loss improved from inf to 216.31921, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 110s - loss: 455.7071 - MinusLogProbMetric: 455.7071 - val_loss: 216.3192 - val_MinusLogProbMetric: 216.3192 - lr: 0.0010 - 110s/epoch - 561ms/step
Epoch 2/1000
2023-10-01 08:51:21.983 
Epoch 2/1000 
	 loss: 207.4843, MinusLogProbMetric: 207.4843, val_loss: 203.0565, val_MinusLogProbMetric: 203.0565

Epoch 2: val_loss improved from 216.31921 to 203.05647, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 27s - loss: 207.4843 - MinusLogProbMetric: 207.4843 - val_loss: 203.0565 - val_MinusLogProbMetric: 203.0565 - lr: 0.0010 - 27s/epoch - 138ms/step
Epoch 3/1000
2023-10-01 08:51:48.589 
Epoch 3/1000 
	 loss: 198.4746, MinusLogProbMetric: 198.4746, val_loss: 197.6822, val_MinusLogProbMetric: 197.6822

Epoch 3: val_loss improved from 203.05647 to 197.68221, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 27s - loss: 198.4746 - MinusLogProbMetric: 198.4746 - val_loss: 197.6822 - val_MinusLogProbMetric: 197.6822 - lr: 0.0010 - 27s/epoch - 136ms/step
Epoch 4/1000
2023-10-01 08:52:16.214 
Epoch 4/1000 
	 loss: 194.1187, MinusLogProbMetric: 194.1187, val_loss: 193.6420, val_MinusLogProbMetric: 193.6420

Epoch 4: val_loss improved from 197.68221 to 193.64201, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 28s - loss: 194.1187 - MinusLogProbMetric: 194.1187 - val_loss: 193.6420 - val_MinusLogProbMetric: 193.6420 - lr: 0.0010 - 28s/epoch - 144ms/step
Epoch 5/1000
2023-10-01 08:52:42.271 
Epoch 5/1000 
	 loss: 191.9310, MinusLogProbMetric: 191.9310, val_loss: 190.3408, val_MinusLogProbMetric: 190.3408

Epoch 5: val_loss improved from 193.64201 to 190.34084, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 26s - loss: 191.9310 - MinusLogProbMetric: 191.9310 - val_loss: 190.3408 - val_MinusLogProbMetric: 190.3408 - lr: 0.0010 - 26s/epoch - 132ms/step
Epoch 6/1000
2023-10-01 08:53:06.965 
Epoch 6/1000 
	 loss: 190.6982, MinusLogProbMetric: 190.6982, val_loss: 191.0600, val_MinusLogProbMetric: 191.0600

Epoch 6: val_loss did not improve from 190.34084
196/196 - 24s - loss: 190.6982 - MinusLogProbMetric: 190.6982 - val_loss: 191.0600 - val_MinusLogProbMetric: 191.0600 - lr: 0.0010 - 24s/epoch - 122ms/step
Epoch 7/1000
2023-10-01 08:53:33.708 
Epoch 7/1000 
	 loss: 189.5146, MinusLogProbMetric: 189.5146, val_loss: 188.0826, val_MinusLogProbMetric: 188.0826

Epoch 7: val_loss improved from 190.34084 to 188.08263, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 27s - loss: 189.5146 - MinusLogProbMetric: 189.5146 - val_loss: 188.0826 - val_MinusLogProbMetric: 188.0826 - lr: 0.0010 - 27s/epoch - 137ms/step
Epoch 8/1000
2023-10-01 08:53:59.777 
Epoch 8/1000 
	 loss: 188.6572, MinusLogProbMetric: 188.6572, val_loss: 187.9235, val_MinusLogProbMetric: 187.9235

Epoch 8: val_loss improved from 188.08263 to 187.92346, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 27s - loss: 188.6572 - MinusLogProbMetric: 188.6572 - val_loss: 187.9235 - val_MinusLogProbMetric: 187.9235 - lr: 0.0010 - 27s/epoch - 138ms/step
Epoch 9/1000
2023-10-01 08:54:26.095 
Epoch 9/1000 
	 loss: 187.6667, MinusLogProbMetric: 187.6667, val_loss: 191.6349, val_MinusLogProbMetric: 191.6349

Epoch 9: val_loss did not improve from 187.92346
196/196 - 25s - loss: 187.6667 - MinusLogProbMetric: 187.6667 - val_loss: 191.6349 - val_MinusLogProbMetric: 191.6349 - lr: 0.0010 - 25s/epoch - 128ms/step
Epoch 10/1000
2023-10-01 08:54:52.104 
Epoch 10/1000 
	 loss: 187.6171, MinusLogProbMetric: 187.6171, val_loss: 189.4084, val_MinusLogProbMetric: 189.4084

Epoch 10: val_loss did not improve from 187.92346
196/196 - 26s - loss: 187.6171 - MinusLogProbMetric: 187.6171 - val_loss: 189.4084 - val_MinusLogProbMetric: 189.4084 - lr: 0.0010 - 26s/epoch - 133ms/step
Epoch 11/1000
2023-10-01 08:55:15.733 
Epoch 11/1000 
	 loss: 187.3457, MinusLogProbMetric: 187.3457, val_loss: 189.0948, val_MinusLogProbMetric: 189.0948

Epoch 11: val_loss did not improve from 187.92346
196/196 - 24s - loss: 187.3457 - MinusLogProbMetric: 187.3457 - val_loss: 189.0948 - val_MinusLogProbMetric: 189.0948 - lr: 0.0010 - 24s/epoch - 121ms/step
Epoch 12/1000
2023-10-01 08:55:38.917 
Epoch 12/1000 
	 loss: 186.3622, MinusLogProbMetric: 186.3622, val_loss: 188.2277, val_MinusLogProbMetric: 188.2277

Epoch 12: val_loss did not improve from 187.92346
196/196 - 23s - loss: 186.3622 - MinusLogProbMetric: 186.3622 - val_loss: 188.2277 - val_MinusLogProbMetric: 188.2277 - lr: 0.0010 - 23s/epoch - 118ms/step
Epoch 13/1000
2023-10-01 08:56:03.552 
Epoch 13/1000 
	 loss: 186.5289, MinusLogProbMetric: 186.5289, val_loss: 185.9465, val_MinusLogProbMetric: 185.9465

Epoch 13: val_loss improved from 187.92346 to 185.94655, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 25s - loss: 186.5289 - MinusLogProbMetric: 186.5289 - val_loss: 185.9465 - val_MinusLogProbMetric: 185.9465 - lr: 0.0010 - 25s/epoch - 129ms/step
Epoch 14/1000
2023-10-01 08:56:27.167 
Epoch 14/1000 
	 loss: 186.3309, MinusLogProbMetric: 186.3309, val_loss: 185.6270, val_MinusLogProbMetric: 185.6270

Epoch 14: val_loss improved from 185.94655 to 185.62704, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 24s - loss: 186.3309 - MinusLogProbMetric: 186.3309 - val_loss: 185.6270 - val_MinusLogProbMetric: 185.6270 - lr: 0.0010 - 24s/epoch - 120ms/step
Epoch 15/1000
2023-10-01 08:56:53.598 
Epoch 15/1000 
	 loss: 185.5524, MinusLogProbMetric: 185.5524, val_loss: 187.7253, val_MinusLogProbMetric: 187.7253

Epoch 15: val_loss did not improve from 185.62704
196/196 - 26s - loss: 185.5524 - MinusLogProbMetric: 185.5524 - val_loss: 187.7253 - val_MinusLogProbMetric: 187.7253 - lr: 0.0010 - 26s/epoch - 132ms/step
Epoch 16/1000
2023-10-01 08:57:16.997 
Epoch 16/1000 
	 loss: 185.2440, MinusLogProbMetric: 185.2440, val_loss: 185.8819, val_MinusLogProbMetric: 185.8819

Epoch 16: val_loss did not improve from 185.62704
196/196 - 23s - loss: 185.2440 - MinusLogProbMetric: 185.2440 - val_loss: 185.8819 - val_MinusLogProbMetric: 185.8819 - lr: 0.0010 - 23s/epoch - 119ms/step
Epoch 17/1000
2023-10-01 08:57:39.507 
Epoch 17/1000 
	 loss: 184.9557, MinusLogProbMetric: 184.9557, val_loss: 184.9407, val_MinusLogProbMetric: 184.9407

Epoch 17: val_loss improved from 185.62704 to 184.94073, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 23s - loss: 184.9557 - MinusLogProbMetric: 184.9557 - val_loss: 184.9407 - val_MinusLogProbMetric: 184.9407 - lr: 0.0010 - 23s/epoch - 117ms/step
Epoch 18/1000
2023-10-01 08:58:04.740 
Epoch 18/1000 
	 loss: 184.9654, MinusLogProbMetric: 184.9654, val_loss: 186.1255, val_MinusLogProbMetric: 186.1255

Epoch 18: val_loss did not improve from 184.94073
196/196 - 25s - loss: 184.9654 - MinusLogProbMetric: 184.9654 - val_loss: 186.1255 - val_MinusLogProbMetric: 186.1255 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 19/1000
2023-10-01 08:58:27.945 
Epoch 19/1000 
	 loss: 184.6375, MinusLogProbMetric: 184.6375, val_loss: 184.3954, val_MinusLogProbMetric: 184.3954

Epoch 19: val_loss improved from 184.94073 to 184.39542, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 24s - loss: 184.6375 - MinusLogProbMetric: 184.6375 - val_loss: 184.3954 - val_MinusLogProbMetric: 184.3954 - lr: 0.0010 - 24s/epoch - 125ms/step
Epoch 20/1000
2023-10-01 08:58:54.192 
Epoch 20/1000 
	 loss: 184.6954, MinusLogProbMetric: 184.6954, val_loss: 184.8926, val_MinusLogProbMetric: 184.8926

Epoch 20: val_loss did not improve from 184.39542
196/196 - 25s - loss: 184.6954 - MinusLogProbMetric: 184.6954 - val_loss: 184.8926 - val_MinusLogProbMetric: 184.8926 - lr: 0.0010 - 25s/epoch - 128ms/step
Epoch 21/1000
2023-10-01 08:59:19.634 
Epoch 21/1000 
	 loss: 184.3670, MinusLogProbMetric: 184.3670, val_loss: 187.0594, val_MinusLogProbMetric: 187.0594

Epoch 21: val_loss did not improve from 184.39542
196/196 - 25s - loss: 184.3670 - MinusLogProbMetric: 184.3670 - val_loss: 187.0594 - val_MinusLogProbMetric: 187.0594 - lr: 0.0010 - 25s/epoch - 130ms/step
Epoch 22/1000
2023-10-01 08:59:45.335 
Epoch 22/1000 
	 loss: 184.0287, MinusLogProbMetric: 184.0287, val_loss: 183.6791, val_MinusLogProbMetric: 183.6791

Epoch 22: val_loss improved from 184.39542 to 183.67906, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 26s - loss: 184.0287 - MinusLogProbMetric: 184.0287 - val_loss: 183.6791 - val_MinusLogProbMetric: 183.6791 - lr: 0.0010 - 26s/epoch - 131ms/step
Epoch 23/1000
2023-10-01 09:00:11.340 
Epoch 23/1000 
	 loss: 183.8982, MinusLogProbMetric: 183.8982, val_loss: 185.0417, val_MinusLogProbMetric: 185.0417

Epoch 23: val_loss did not improve from 183.67906
196/196 - 26s - loss: 183.8982 - MinusLogProbMetric: 183.8982 - val_loss: 185.0417 - val_MinusLogProbMetric: 185.0417 - lr: 0.0010 - 26s/epoch - 132ms/step
Epoch 24/1000
2023-10-01 09:00:34.512 
Epoch 24/1000 
	 loss: 183.8584, MinusLogProbMetric: 183.8584, val_loss: 186.2408, val_MinusLogProbMetric: 186.2408

Epoch 24: val_loss did not improve from 183.67906
196/196 - 23s - loss: 183.8584 - MinusLogProbMetric: 183.8584 - val_loss: 186.2408 - val_MinusLogProbMetric: 186.2408 - lr: 0.0010 - 23s/epoch - 118ms/step
Epoch 25/1000
2023-10-01 09:00:58.933 
Epoch 25/1000 
	 loss: 183.5020, MinusLogProbMetric: 183.5020, val_loss: 183.7351, val_MinusLogProbMetric: 183.7351

Epoch 25: val_loss did not improve from 183.67906
196/196 - 24s - loss: 183.5020 - MinusLogProbMetric: 183.5020 - val_loss: 183.7351 - val_MinusLogProbMetric: 183.7351 - lr: 0.0010 - 24s/epoch - 125ms/step
Epoch 26/1000
2023-10-01 09:01:23.639 
Epoch 26/1000 
	 loss: 183.7509, MinusLogProbMetric: 183.7509, val_loss: 183.2887, val_MinusLogProbMetric: 183.2887

Epoch 26: val_loss improved from 183.67906 to 183.28873, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 25s - loss: 183.7509 - MinusLogProbMetric: 183.7509 - val_loss: 183.2887 - val_MinusLogProbMetric: 183.2887 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 27/1000
2023-10-01 09:01:49.136 
Epoch 27/1000 
	 loss: 183.4644, MinusLogProbMetric: 183.4644, val_loss: 189.6375, val_MinusLogProbMetric: 189.6375

Epoch 27: val_loss did not improve from 183.28873
196/196 - 25s - loss: 183.4644 - MinusLogProbMetric: 183.4644 - val_loss: 189.6375 - val_MinusLogProbMetric: 189.6375 - lr: 0.0010 - 25s/epoch - 130ms/step
Epoch 28/1000
2023-10-01 09:02:11.872 
Epoch 28/1000 
	 loss: 183.3466, MinusLogProbMetric: 183.3466, val_loss: 183.2016, val_MinusLogProbMetric: 183.2016

Epoch 28: val_loss improved from 183.28873 to 183.20160, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 24s - loss: 183.3466 - MinusLogProbMetric: 183.3466 - val_loss: 183.2016 - val_MinusLogProbMetric: 183.2016 - lr: 0.0010 - 24s/epoch - 120ms/step
Epoch 29/1000
2023-10-01 09:02:38.225 
Epoch 29/1000 
	 loss: 183.3454, MinusLogProbMetric: 183.3454, val_loss: 183.6505, val_MinusLogProbMetric: 183.6505

Epoch 29: val_loss did not improve from 183.20160
196/196 - 26s - loss: 183.3454 - MinusLogProbMetric: 183.3454 - val_loss: 183.6505 - val_MinusLogProbMetric: 183.6505 - lr: 0.0010 - 26s/epoch - 130ms/step
Epoch 30/1000
2023-10-01 09:03:02.848 
Epoch 30/1000 
	 loss: 183.1614, MinusLogProbMetric: 183.1614, val_loss: 183.7943, val_MinusLogProbMetric: 183.7943

Epoch 30: val_loss did not improve from 183.20160
196/196 - 25s - loss: 183.1614 - MinusLogProbMetric: 183.1614 - val_loss: 183.7943 - val_MinusLogProbMetric: 183.7943 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 31/1000
2023-10-01 09:03:27.884 
Epoch 31/1000 
	 loss: 183.0721, MinusLogProbMetric: 183.0721, val_loss: 183.3970, val_MinusLogProbMetric: 183.3970

Epoch 31: val_loss did not improve from 183.20160
196/196 - 25s - loss: 183.0721 - MinusLogProbMetric: 183.0721 - val_loss: 183.3970 - val_MinusLogProbMetric: 183.3970 - lr: 0.0010 - 25s/epoch - 128ms/step
Epoch 32/1000
2023-10-01 09:03:53.620 
Epoch 32/1000 
	 loss: 183.0234, MinusLogProbMetric: 183.0234, val_loss: 183.2254, val_MinusLogProbMetric: 183.2254

Epoch 32: val_loss did not improve from 183.20160
196/196 - 26s - loss: 183.0234 - MinusLogProbMetric: 183.0234 - val_loss: 183.2254 - val_MinusLogProbMetric: 183.2254 - lr: 0.0010 - 26s/epoch - 131ms/step
Epoch 33/1000
2023-10-01 09:04:18.445 
Epoch 33/1000 
	 loss: 182.7883, MinusLogProbMetric: 182.7883, val_loss: 184.9370, val_MinusLogProbMetric: 184.9370

Epoch 33: val_loss did not improve from 183.20160
196/196 - 25s - loss: 182.7883 - MinusLogProbMetric: 182.7883 - val_loss: 184.9370 - val_MinusLogProbMetric: 184.9370 - lr: 0.0010 - 25s/epoch - 127ms/step
Epoch 34/1000
2023-10-01 09:04:44.678 
Epoch 34/1000 
	 loss: 182.9239, MinusLogProbMetric: 182.9239, val_loss: 183.1924, val_MinusLogProbMetric: 183.1924

Epoch 34: val_loss improved from 183.20160 to 183.19240, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 26s - loss: 182.9239 - MinusLogProbMetric: 182.9239 - val_loss: 183.1924 - val_MinusLogProbMetric: 183.1924 - lr: 0.0010 - 26s/epoch - 134ms/step
Epoch 35/1000
2023-10-01 09:05:09.871 
Epoch 35/1000 
	 loss: 182.6546, MinusLogProbMetric: 182.6546, val_loss: 182.6351, val_MinusLogProbMetric: 182.6351

Epoch 35: val_loss improved from 183.19240 to 182.63515, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 26s - loss: 182.6546 - MinusLogProbMetric: 182.6546 - val_loss: 182.6351 - val_MinusLogProbMetric: 182.6351 - lr: 0.0010 - 26s/epoch - 130ms/step
Epoch 36/1000
2023-10-01 09:05:35.279 
Epoch 36/1000 
	 loss: 182.7250, MinusLogProbMetric: 182.7250, val_loss: 183.7938, val_MinusLogProbMetric: 183.7938

Epoch 36: val_loss did not improve from 182.63515
196/196 - 25s - loss: 182.7250 - MinusLogProbMetric: 182.7250 - val_loss: 183.7938 - val_MinusLogProbMetric: 183.7938 - lr: 0.0010 - 25s/epoch - 127ms/step
Epoch 37/1000
2023-10-01 09:06:00.590 
Epoch 37/1000 
	 loss: 182.4827, MinusLogProbMetric: 182.4827, val_loss: 183.8019, val_MinusLogProbMetric: 183.8019

Epoch 37: val_loss did not improve from 182.63515
196/196 - 25s - loss: 182.4827 - MinusLogProbMetric: 182.4827 - val_loss: 183.8019 - val_MinusLogProbMetric: 183.8019 - lr: 0.0010 - 25s/epoch - 129ms/step
Epoch 38/1000
2023-10-01 09:06:24.045 
Epoch 38/1000 
	 loss: 182.6162, MinusLogProbMetric: 182.6162, val_loss: 182.5035, val_MinusLogProbMetric: 182.5035

Epoch 38: val_loss improved from 182.63515 to 182.50354, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 24s - loss: 182.6162 - MinusLogProbMetric: 182.6162 - val_loss: 182.5035 - val_MinusLogProbMetric: 182.5035 - lr: 0.0010 - 24s/epoch - 124ms/step
Epoch 39/1000
2023-10-01 09:06:51.978 
Epoch 39/1000 
	 loss: 182.3851, MinusLogProbMetric: 182.3851, val_loss: 183.8774, val_MinusLogProbMetric: 183.8774

Epoch 39: val_loss did not improve from 182.50354
196/196 - 27s - loss: 182.3851 - MinusLogProbMetric: 182.3851 - val_loss: 183.8774 - val_MinusLogProbMetric: 183.8774 - lr: 0.0010 - 27s/epoch - 138ms/step
Epoch 40/1000
2023-10-01 09:07:17.609 
Epoch 40/1000 
	 loss: 182.4510, MinusLogProbMetric: 182.4510, val_loss: 182.3000, val_MinusLogProbMetric: 182.3000

Epoch 40: val_loss improved from 182.50354 to 182.29996, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 26s - loss: 182.4510 - MinusLogProbMetric: 182.4510 - val_loss: 182.3000 - val_MinusLogProbMetric: 182.3000 - lr: 0.0010 - 26s/epoch - 135ms/step
Epoch 41/1000
2023-10-01 09:07:43.460 
Epoch 41/1000 
	 loss: 182.4414, MinusLogProbMetric: 182.4414, val_loss: 182.5076, val_MinusLogProbMetric: 182.5076

Epoch 41: val_loss did not improve from 182.29996
196/196 - 25s - loss: 182.4414 - MinusLogProbMetric: 182.4414 - val_loss: 182.5076 - val_MinusLogProbMetric: 182.5076 - lr: 0.0010 - 25s/epoch - 128ms/step
Epoch 42/1000
2023-10-01 09:08:08.543 
Epoch 42/1000 
	 loss: 182.3273, MinusLogProbMetric: 182.3273, val_loss: 183.0975, val_MinusLogProbMetric: 183.0975

Epoch 42: val_loss did not improve from 182.29996
196/196 - 25s - loss: 182.3273 - MinusLogProbMetric: 182.3273 - val_loss: 183.0975 - val_MinusLogProbMetric: 183.0975 - lr: 0.0010 - 25s/epoch - 128ms/step
Epoch 43/1000
2023-10-01 09:08:32.634 
Epoch 43/1000 
	 loss: 182.3345, MinusLogProbMetric: 182.3345, val_loss: 182.6348, val_MinusLogProbMetric: 182.6348

Epoch 43: val_loss did not improve from 182.29996
196/196 - 24s - loss: 182.3345 - MinusLogProbMetric: 182.3345 - val_loss: 182.6348 - val_MinusLogProbMetric: 182.6348 - lr: 0.0010 - 24s/epoch - 123ms/step
Epoch 44/1000
2023-10-01 09:08:58.323 
Epoch 44/1000 
	 loss: 182.2074, MinusLogProbMetric: 182.2074, val_loss: 183.2032, val_MinusLogProbMetric: 183.2032

Epoch 44: val_loss did not improve from 182.29996
196/196 - 26s - loss: 182.2074 - MinusLogProbMetric: 182.2074 - val_loss: 183.2032 - val_MinusLogProbMetric: 183.2032 - lr: 0.0010 - 26s/epoch - 131ms/step
Epoch 45/1000
2023-10-01 09:09:22.333 
Epoch 45/1000 
	 loss: 182.0943, MinusLogProbMetric: 182.0943, val_loss: 182.2134, val_MinusLogProbMetric: 182.2134

Epoch 45: val_loss improved from 182.29996 to 182.21338, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 24s - loss: 182.0943 - MinusLogProbMetric: 182.0943 - val_loss: 182.2134 - val_MinusLogProbMetric: 182.2134 - lr: 0.0010 - 24s/epoch - 124ms/step
Epoch 46/1000
2023-10-01 09:09:45.065 
Epoch 46/1000 
	 loss: 182.1242, MinusLogProbMetric: 182.1242, val_loss: 183.9793, val_MinusLogProbMetric: 183.9793

Epoch 46: val_loss did not improve from 182.21338
196/196 - 22s - loss: 182.1242 - MinusLogProbMetric: 182.1242 - val_loss: 183.9793 - val_MinusLogProbMetric: 183.9793 - lr: 0.0010 - 22s/epoch - 114ms/step
Epoch 47/1000
2023-10-01 09:10:10.090 
Epoch 47/1000 
	 loss: 182.1249, MinusLogProbMetric: 182.1249, val_loss: 182.9377, val_MinusLogProbMetric: 182.9377

Epoch 47: val_loss did not improve from 182.21338
196/196 - 25s - loss: 182.1249 - MinusLogProbMetric: 182.1249 - val_loss: 182.9377 - val_MinusLogProbMetric: 182.9377 - lr: 0.0010 - 25s/epoch - 128ms/step
Epoch 48/1000
2023-10-01 09:10:35.962 
Epoch 48/1000 
	 loss: 181.8786, MinusLogProbMetric: 181.8786, val_loss: 183.9259, val_MinusLogProbMetric: 183.9259

Epoch 48: val_loss did not improve from 182.21338
196/196 - 26s - loss: 181.8786 - MinusLogProbMetric: 181.8786 - val_loss: 183.9259 - val_MinusLogProbMetric: 183.9259 - lr: 0.0010 - 26s/epoch - 132ms/step
Epoch 49/1000
2023-10-01 09:10:59.733 
Epoch 49/1000 
	 loss: 181.9089, MinusLogProbMetric: 181.9089, val_loss: 183.2397, val_MinusLogProbMetric: 183.2397

Epoch 49: val_loss did not improve from 182.21338
196/196 - 24s - loss: 181.9089 - MinusLogProbMetric: 181.9089 - val_loss: 183.2397 - val_MinusLogProbMetric: 183.2397 - lr: 0.0010 - 24s/epoch - 121ms/step
Epoch 50/1000
2023-10-01 09:11:24.290 
Epoch 50/1000 
	 loss: 181.9735, MinusLogProbMetric: 181.9735, val_loss: 182.9692, val_MinusLogProbMetric: 182.9692

Epoch 50: val_loss did not improve from 182.21338
196/196 - 25s - loss: 181.9735 - MinusLogProbMetric: 181.9735 - val_loss: 182.9692 - val_MinusLogProbMetric: 182.9692 - lr: 0.0010 - 25s/epoch - 125ms/step
Epoch 51/1000
2023-10-01 09:11:49.313 
Epoch 51/1000 
	 loss: 182.0534, MinusLogProbMetric: 182.0534, val_loss: 182.4313, val_MinusLogProbMetric: 182.4313

Epoch 51: val_loss did not improve from 182.21338
196/196 - 25s - loss: 182.0534 - MinusLogProbMetric: 182.0534 - val_loss: 182.4313 - val_MinusLogProbMetric: 182.4313 - lr: 0.0010 - 25s/epoch - 128ms/step
Epoch 52/1000
2023-10-01 09:12:14.459 
Epoch 52/1000 
	 loss: 181.9229, MinusLogProbMetric: 181.9229, val_loss: 181.6606, val_MinusLogProbMetric: 181.6606

Epoch 52: val_loss improved from 182.21338 to 181.66064, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 25s - loss: 181.9229 - MinusLogProbMetric: 181.9229 - val_loss: 181.6606 - val_MinusLogProbMetric: 181.6606 - lr: 0.0010 - 25s/epoch - 129ms/step
Epoch 53/1000
2023-10-01 09:12:40.167 
Epoch 53/1000 
	 loss: 181.8290, MinusLogProbMetric: 181.8290, val_loss: 182.2586, val_MinusLogProbMetric: 182.2586

Epoch 53: val_loss did not improve from 181.66064
196/196 - 26s - loss: 181.8290 - MinusLogProbMetric: 181.8290 - val_loss: 182.2586 - val_MinusLogProbMetric: 182.2586 - lr: 0.0010 - 26s/epoch - 131ms/step
Epoch 54/1000
2023-10-01 09:13:04.875 
Epoch 54/1000 
	 loss: 181.6966, MinusLogProbMetric: 181.6966, val_loss: 181.7537, val_MinusLogProbMetric: 181.7537

Epoch 54: val_loss did not improve from 181.66064
196/196 - 25s - loss: 181.6966 - MinusLogProbMetric: 181.6966 - val_loss: 181.7537 - val_MinusLogProbMetric: 181.7537 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 55/1000
2023-10-01 09:13:30.211 
Epoch 55/1000 
	 loss: 181.6721, MinusLogProbMetric: 181.6721, val_loss: 182.2121, val_MinusLogProbMetric: 182.2121

Epoch 55: val_loss did not improve from 181.66064
196/196 - 25s - loss: 181.6721 - MinusLogProbMetric: 181.6721 - val_loss: 182.2121 - val_MinusLogProbMetric: 182.2121 - lr: 0.0010 - 25s/epoch - 129ms/step
Epoch 56/1000
2023-10-01 09:13:56.093 
Epoch 56/1000 
	 loss: 181.6757, MinusLogProbMetric: 181.6757, val_loss: 183.7684, val_MinusLogProbMetric: 183.7684

Epoch 56: val_loss did not improve from 181.66064
196/196 - 26s - loss: 181.6757 - MinusLogProbMetric: 181.6757 - val_loss: 183.7684 - val_MinusLogProbMetric: 183.7684 - lr: 0.0010 - 26s/epoch - 132ms/step
Epoch 57/1000
2023-10-01 09:14:20.099 
Epoch 57/1000 
	 loss: 181.7236, MinusLogProbMetric: 181.7236, val_loss: 181.9402, val_MinusLogProbMetric: 181.9402

Epoch 57: val_loss did not improve from 181.66064
196/196 - 24s - loss: 181.7236 - MinusLogProbMetric: 181.7236 - val_loss: 181.9402 - val_MinusLogProbMetric: 181.9402 - lr: 0.0010 - 24s/epoch - 123ms/step
Epoch 58/1000
2023-10-01 09:14:45.442 
Epoch 58/1000 
	 loss: 181.7488, MinusLogProbMetric: 181.7488, val_loss: 181.8573, val_MinusLogProbMetric: 181.8573

Epoch 58: val_loss did not improve from 181.66064
196/196 - 25s - loss: 181.7488 - MinusLogProbMetric: 181.7488 - val_loss: 181.8573 - val_MinusLogProbMetric: 181.8573 - lr: 0.0010 - 25s/epoch - 129ms/step
Epoch 59/1000
2023-10-01 09:15:11.732 
Epoch 59/1000 
	 loss: 181.7693, MinusLogProbMetric: 181.7693, val_loss: 181.5963, val_MinusLogProbMetric: 181.5963

Epoch 59: val_loss improved from 181.66064 to 181.59634, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 28s - loss: 181.7693 - MinusLogProbMetric: 181.7693 - val_loss: 181.5963 - val_MinusLogProbMetric: 181.5963 - lr: 0.0010 - 28s/epoch - 141ms/step
Epoch 60/1000
2023-10-01 09:15:38.472 
Epoch 60/1000 
	 loss: 181.5127, MinusLogProbMetric: 181.5127, val_loss: 182.2172, val_MinusLogProbMetric: 182.2172

Epoch 60: val_loss did not improve from 181.59634
196/196 - 25s - loss: 181.5127 - MinusLogProbMetric: 181.5127 - val_loss: 182.2172 - val_MinusLogProbMetric: 182.2172 - lr: 0.0010 - 25s/epoch - 129ms/step
Epoch 61/1000
2023-10-01 09:16:02.761 
Epoch 61/1000 
	 loss: 181.5453, MinusLogProbMetric: 181.5453, val_loss: 182.1465, val_MinusLogProbMetric: 182.1465

Epoch 61: val_loss did not improve from 181.59634
196/196 - 24s - loss: 181.5453 - MinusLogProbMetric: 181.5453 - val_loss: 182.1465 - val_MinusLogProbMetric: 182.1465 - lr: 0.0010 - 24s/epoch - 124ms/step
Epoch 62/1000
2023-10-01 09:16:28.558 
Epoch 62/1000 
	 loss: 181.5120, MinusLogProbMetric: 181.5120, val_loss: 181.6453, val_MinusLogProbMetric: 181.6453

Epoch 62: val_loss did not improve from 181.59634
196/196 - 26s - loss: 181.5120 - MinusLogProbMetric: 181.5120 - val_loss: 181.6453 - val_MinusLogProbMetric: 181.6453 - lr: 0.0010 - 26s/epoch - 132ms/step
Epoch 63/1000
2023-10-01 09:16:54.629 
Epoch 63/1000 
	 loss: 181.4764, MinusLogProbMetric: 181.4764, val_loss: 182.7991, val_MinusLogProbMetric: 182.7991

Epoch 63: val_loss did not improve from 181.59634
196/196 - 26s - loss: 181.4764 - MinusLogProbMetric: 181.4764 - val_loss: 182.7991 - val_MinusLogProbMetric: 182.7991 - lr: 0.0010 - 26s/epoch - 133ms/step
Epoch 64/1000
2023-10-01 09:17:20.385 
Epoch 64/1000 
	 loss: 181.4274, MinusLogProbMetric: 181.4274, val_loss: 181.5221, val_MinusLogProbMetric: 181.5221

Epoch 64: val_loss improved from 181.59634 to 181.52209, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 26s - loss: 181.4274 - MinusLogProbMetric: 181.4274 - val_loss: 181.5221 - val_MinusLogProbMetric: 181.5221 - lr: 0.0010 - 26s/epoch - 132ms/step
Epoch 65/1000
2023-10-01 09:17:46.666 
Epoch 65/1000 
	 loss: 181.3902, MinusLogProbMetric: 181.3902, val_loss: 182.5935, val_MinusLogProbMetric: 182.5935

Epoch 65: val_loss did not improve from 181.52209
196/196 - 26s - loss: 181.3902 - MinusLogProbMetric: 181.3902 - val_loss: 182.5935 - val_MinusLogProbMetric: 182.5935 - lr: 0.0010 - 26s/epoch - 134ms/step
Epoch 66/1000
2023-10-01 09:18:12.567 
Epoch 66/1000 
	 loss: 181.5129, MinusLogProbMetric: 181.5129, val_loss: 181.6546, val_MinusLogProbMetric: 181.6546

Epoch 66: val_loss did not improve from 181.52209
196/196 - 26s - loss: 181.5129 - MinusLogProbMetric: 181.5129 - val_loss: 181.6546 - val_MinusLogProbMetric: 181.6546 - lr: 0.0010 - 26s/epoch - 132ms/step
Epoch 67/1000
2023-10-01 09:18:38.956 
Epoch 67/1000 
	 loss: 181.4328, MinusLogProbMetric: 181.4328, val_loss: 182.1715, val_MinusLogProbMetric: 182.1715

Epoch 67: val_loss did not improve from 181.52209
196/196 - 26s - loss: 181.4328 - MinusLogProbMetric: 181.4328 - val_loss: 182.1715 - val_MinusLogProbMetric: 182.1715 - lr: 0.0010 - 26s/epoch - 134ms/step
Epoch 68/1000
2023-10-01 09:19:04.172 
Epoch 68/1000 
	 loss: 181.2702, MinusLogProbMetric: 181.2702, val_loss: 181.8314, val_MinusLogProbMetric: 181.8314

Epoch 68: val_loss did not improve from 181.52209
196/196 - 25s - loss: 181.2702 - MinusLogProbMetric: 181.2702 - val_loss: 181.8314 - val_MinusLogProbMetric: 181.8314 - lr: 0.0010 - 25s/epoch - 129ms/step
Epoch 69/1000
2023-10-01 09:19:28.507 
Epoch 69/1000 
	 loss: 181.4096, MinusLogProbMetric: 181.4096, val_loss: 181.6617, val_MinusLogProbMetric: 181.6617

Epoch 69: val_loss did not improve from 181.52209
196/196 - 24s - loss: 181.4096 - MinusLogProbMetric: 181.4096 - val_loss: 181.6617 - val_MinusLogProbMetric: 181.6617 - lr: 0.0010 - 24s/epoch - 124ms/step
Epoch 70/1000
2023-10-01 09:19:53.099 
Epoch 70/1000 
	 loss: 181.2118, MinusLogProbMetric: 181.2118, val_loss: 181.6434, val_MinusLogProbMetric: 181.6434

Epoch 70: val_loss did not improve from 181.52209
196/196 - 25s - loss: 181.2118 - MinusLogProbMetric: 181.2118 - val_loss: 181.6434 - val_MinusLogProbMetric: 181.6434 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 71/1000
2023-10-01 09:20:16.892 
Epoch 71/1000 
	 loss: 181.3648, MinusLogProbMetric: 181.3648, val_loss: 181.4317, val_MinusLogProbMetric: 181.4317

Epoch 71: val_loss improved from 181.52209 to 181.43167, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 24s - loss: 181.3648 - MinusLogProbMetric: 181.3648 - val_loss: 181.4317 - val_MinusLogProbMetric: 181.4317 - lr: 0.0010 - 24s/epoch - 122ms/step
Epoch 72/1000
2023-10-01 09:20:43.677 
Epoch 72/1000 
	 loss: 181.2554, MinusLogProbMetric: 181.2554, val_loss: 181.6124, val_MinusLogProbMetric: 181.6124

Epoch 72: val_loss did not improve from 181.43167
196/196 - 27s - loss: 181.2554 - MinusLogProbMetric: 181.2554 - val_loss: 181.6124 - val_MinusLogProbMetric: 181.6124 - lr: 0.0010 - 27s/epoch - 136ms/step
Epoch 73/1000
2023-10-01 09:21:07.912 
Epoch 73/1000 
	 loss: 181.4235, MinusLogProbMetric: 181.4235, val_loss: 181.7935, val_MinusLogProbMetric: 181.7935

Epoch 73: val_loss did not improve from 181.43167
196/196 - 24s - loss: 181.4235 - MinusLogProbMetric: 181.4235 - val_loss: 181.7935 - val_MinusLogProbMetric: 181.7935 - lr: 0.0010 - 24s/epoch - 124ms/step
Epoch 74/1000
2023-10-01 09:21:31.878 
Epoch 74/1000 
	 loss: 181.1728, MinusLogProbMetric: 181.1728, val_loss: 181.8196, val_MinusLogProbMetric: 181.8196

Epoch 74: val_loss did not improve from 181.43167
196/196 - 24s - loss: 181.1728 - MinusLogProbMetric: 181.1728 - val_loss: 181.8196 - val_MinusLogProbMetric: 181.8196 - lr: 0.0010 - 24s/epoch - 122ms/step
Epoch 75/1000
2023-10-01 09:21:54.042 
Epoch 75/1000 
	 loss: 181.2007, MinusLogProbMetric: 181.2007, val_loss: 181.5663, val_MinusLogProbMetric: 181.5663

Epoch 75: val_loss did not improve from 181.43167
196/196 - 22s - loss: 181.2007 - MinusLogProbMetric: 181.2007 - val_loss: 181.5663 - val_MinusLogProbMetric: 181.5663 - lr: 0.0010 - 22s/epoch - 113ms/step
Epoch 76/1000
2023-10-01 09:22:20.064 
Epoch 76/1000 
	 loss: 181.2254, MinusLogProbMetric: 181.2254, val_loss: 181.8495, val_MinusLogProbMetric: 181.8495

Epoch 76: val_loss did not improve from 181.43167
196/196 - 26s - loss: 181.2254 - MinusLogProbMetric: 181.2254 - val_loss: 181.8495 - val_MinusLogProbMetric: 181.8495 - lr: 0.0010 - 26s/epoch - 133ms/step
Epoch 77/1000
2023-10-01 09:22:44.317 
Epoch 77/1000 
	 loss: 181.1899, MinusLogProbMetric: 181.1899, val_loss: 181.6056, val_MinusLogProbMetric: 181.6056

Epoch 77: val_loss did not improve from 181.43167
196/196 - 24s - loss: 181.1899 - MinusLogProbMetric: 181.1899 - val_loss: 181.6056 - val_MinusLogProbMetric: 181.6056 - lr: 0.0010 - 24s/epoch - 124ms/step
Epoch 78/1000
2023-10-01 09:23:07.891 
Epoch 78/1000 
	 loss: 181.1871, MinusLogProbMetric: 181.1871, val_loss: 181.8528, val_MinusLogProbMetric: 181.8528

Epoch 78: val_loss did not improve from 181.43167
196/196 - 24s - loss: 181.1871 - MinusLogProbMetric: 181.1871 - val_loss: 181.8528 - val_MinusLogProbMetric: 181.8528 - lr: 0.0010 - 24s/epoch - 120ms/step
Epoch 79/1000
2023-10-01 09:23:29.935 
Epoch 79/1000 
	 loss: 181.1345, MinusLogProbMetric: 181.1345, val_loss: 181.4018, val_MinusLogProbMetric: 181.4018

Epoch 79: val_loss improved from 181.43167 to 181.40176, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 22s - loss: 181.1345 - MinusLogProbMetric: 181.1345 - val_loss: 181.4018 - val_MinusLogProbMetric: 181.4018 - lr: 0.0010 - 22s/epoch - 114ms/step
Epoch 80/1000
2023-10-01 09:23:55.367 
Epoch 80/1000 
	 loss: 181.0424, MinusLogProbMetric: 181.0424, val_loss: 181.5049, val_MinusLogProbMetric: 181.5049

Epoch 80: val_loss did not improve from 181.40176
196/196 - 25s - loss: 181.0424 - MinusLogProbMetric: 181.0424 - val_loss: 181.5049 - val_MinusLogProbMetric: 181.5049 - lr: 0.0010 - 25s/epoch - 129ms/step
Epoch 81/1000
2023-10-01 09:24:20.142 
Epoch 81/1000 
	 loss: 181.0689, MinusLogProbMetric: 181.0689, val_loss: 181.7765, val_MinusLogProbMetric: 181.7765

Epoch 81: val_loss did not improve from 181.40176
196/196 - 25s - loss: 181.0689 - MinusLogProbMetric: 181.0689 - val_loss: 181.7765 - val_MinusLogProbMetric: 181.7765 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 82/1000
2023-10-01 09:24:42.899 
Epoch 82/1000 
	 loss: 181.1717, MinusLogProbMetric: 181.1717, val_loss: 183.2838, val_MinusLogProbMetric: 183.2838

Epoch 82: val_loss did not improve from 181.40176
196/196 - 23s - loss: 181.1717 - MinusLogProbMetric: 181.1717 - val_loss: 183.2838 - val_MinusLogProbMetric: 183.2838 - lr: 0.0010 - 23s/epoch - 116ms/step
Epoch 83/1000
2023-10-01 09:25:07.619 
Epoch 83/1000 
	 loss: 180.9857, MinusLogProbMetric: 180.9857, val_loss: 182.3614, val_MinusLogProbMetric: 182.3614

Epoch 83: val_loss did not improve from 181.40176
196/196 - 25s - loss: 180.9857 - MinusLogProbMetric: 180.9857 - val_loss: 182.3614 - val_MinusLogProbMetric: 182.3614 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 84/1000
2023-10-01 09:25:33.948 
Epoch 84/1000 
	 loss: 180.9940, MinusLogProbMetric: 180.9940, val_loss: 183.1095, val_MinusLogProbMetric: 183.1095

Epoch 84: val_loss did not improve from 181.40176
196/196 - 26s - loss: 180.9940 - MinusLogProbMetric: 180.9940 - val_loss: 183.1095 - val_MinusLogProbMetric: 183.1095 - lr: 0.0010 - 26s/epoch - 134ms/step
Epoch 85/1000
2023-10-01 09:25:58.005 
Epoch 85/1000 
	 loss: 181.0305, MinusLogProbMetric: 181.0305, val_loss: 182.2344, val_MinusLogProbMetric: 182.2344

Epoch 85: val_loss did not improve from 181.40176
196/196 - 24s - loss: 181.0305 - MinusLogProbMetric: 181.0305 - val_loss: 182.2344 - val_MinusLogProbMetric: 182.2344 - lr: 0.0010 - 24s/epoch - 123ms/step
Epoch 86/1000
2023-10-01 09:26:22.173 
Epoch 86/1000 
	 loss: 181.2677, MinusLogProbMetric: 181.2677, val_loss: 182.6005, val_MinusLogProbMetric: 182.6005

Epoch 86: val_loss did not improve from 181.40176
196/196 - 24s - loss: 181.2677 - MinusLogProbMetric: 181.2677 - val_loss: 182.6005 - val_MinusLogProbMetric: 182.6005 - lr: 0.0010 - 24s/epoch - 123ms/step
Epoch 87/1000
2023-10-01 09:26:46.552 
Epoch 87/1000 
	 loss: 180.8939, MinusLogProbMetric: 180.8939, val_loss: 182.2428, val_MinusLogProbMetric: 182.2428

Epoch 87: val_loss did not improve from 181.40176
196/196 - 24s - loss: 180.8939 - MinusLogProbMetric: 180.8939 - val_loss: 182.2428 - val_MinusLogProbMetric: 182.2428 - lr: 0.0010 - 24s/epoch - 124ms/step
Epoch 88/1000
2023-10-01 09:27:11.333 
Epoch 88/1000 
	 loss: 181.1675, MinusLogProbMetric: 181.1675, val_loss: 181.5652, val_MinusLogProbMetric: 181.5652

Epoch 88: val_loss did not improve from 181.40176
196/196 - 25s - loss: 181.1675 - MinusLogProbMetric: 181.1675 - val_loss: 181.5652 - val_MinusLogProbMetric: 181.5652 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 89/1000
2023-10-01 09:27:37.965 
Epoch 89/1000 
	 loss: 180.8421, MinusLogProbMetric: 180.8421, val_loss: 181.8015, val_MinusLogProbMetric: 181.8015

Epoch 89: val_loss did not improve from 181.40176
196/196 - 27s - loss: 180.8421 - MinusLogProbMetric: 180.8421 - val_loss: 181.8015 - val_MinusLogProbMetric: 181.8015 - lr: 0.0010 - 27s/epoch - 136ms/step
Epoch 90/1000
2023-10-01 09:28:03.783 
Epoch 90/1000 
	 loss: 181.0298, MinusLogProbMetric: 181.0298, val_loss: 181.2149, val_MinusLogProbMetric: 181.2149

Epoch 90: val_loss improved from 181.40176 to 181.21492, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 26s - loss: 181.0298 - MinusLogProbMetric: 181.0298 - val_loss: 181.2149 - val_MinusLogProbMetric: 181.2149 - lr: 0.0010 - 26s/epoch - 133ms/step
Epoch 91/1000
2023-10-01 09:28:27.993 
Epoch 91/1000 
	 loss: 180.8419, MinusLogProbMetric: 180.8419, val_loss: 181.8421, val_MinusLogProbMetric: 181.8421

Epoch 91: val_loss did not improve from 181.21492
196/196 - 24s - loss: 180.8419 - MinusLogProbMetric: 180.8419 - val_loss: 181.8421 - val_MinusLogProbMetric: 181.8421 - lr: 0.0010 - 24s/epoch - 123ms/step
Epoch 92/1000
2023-10-01 09:28:53.709 
Epoch 92/1000 
	 loss: 180.8300, MinusLogProbMetric: 180.8300, val_loss: 181.5705, val_MinusLogProbMetric: 181.5705

Epoch 92: val_loss did not improve from 181.21492
196/196 - 26s - loss: 180.8300 - MinusLogProbMetric: 180.8300 - val_loss: 181.5705 - val_MinusLogProbMetric: 181.5705 - lr: 0.0010 - 26s/epoch - 131ms/step
Epoch 93/1000
2023-10-01 09:29:18.255 
Epoch 93/1000 
	 loss: 180.8618, MinusLogProbMetric: 180.8618, val_loss: 181.6001, val_MinusLogProbMetric: 181.6001

Epoch 93: val_loss did not improve from 181.21492
196/196 - 25s - loss: 180.8618 - MinusLogProbMetric: 180.8618 - val_loss: 181.6001 - val_MinusLogProbMetric: 181.6001 - lr: 0.0010 - 25s/epoch - 125ms/step
Epoch 94/1000
2023-10-01 09:29:45.268 
Epoch 94/1000 
	 loss: 180.8418, MinusLogProbMetric: 180.8418, val_loss: 182.2595, val_MinusLogProbMetric: 182.2595

Epoch 94: val_loss did not improve from 181.21492
196/196 - 27s - loss: 180.8418 - MinusLogProbMetric: 180.8418 - val_loss: 182.2595 - val_MinusLogProbMetric: 182.2595 - lr: 0.0010 - 27s/epoch - 138ms/step
Epoch 95/1000
2023-10-01 09:30:11.090 
Epoch 95/1000 
	 loss: 180.7979, MinusLogProbMetric: 180.7979, val_loss: 183.8163, val_MinusLogProbMetric: 183.8163

Epoch 95: val_loss did not improve from 181.21492
196/196 - 26s - loss: 180.7979 - MinusLogProbMetric: 180.7979 - val_loss: 183.8163 - val_MinusLogProbMetric: 183.8163 - lr: 0.0010 - 26s/epoch - 132ms/step
Epoch 96/1000
2023-10-01 09:30:35.948 
Epoch 96/1000 
	 loss: 180.7755, MinusLogProbMetric: 180.7755, val_loss: 181.4106, val_MinusLogProbMetric: 181.4106

Epoch 96: val_loss did not improve from 181.21492
196/196 - 25s - loss: 180.7755 - MinusLogProbMetric: 180.7755 - val_loss: 181.4106 - val_MinusLogProbMetric: 181.4106 - lr: 0.0010 - 25s/epoch - 127ms/step
Epoch 97/1000
2023-10-01 09:31:01.614 
Epoch 97/1000 
	 loss: 180.8533, MinusLogProbMetric: 180.8533, val_loss: 182.1871, val_MinusLogProbMetric: 182.1871

Epoch 97: val_loss did not improve from 181.21492
196/196 - 26s - loss: 180.8533 - MinusLogProbMetric: 180.8533 - val_loss: 182.1871 - val_MinusLogProbMetric: 182.1871 - lr: 0.0010 - 26s/epoch - 131ms/step
Epoch 98/1000
2023-10-01 09:31:26.870 
Epoch 98/1000 
	 loss: 180.9901, MinusLogProbMetric: 180.9901, val_loss: 181.2644, val_MinusLogProbMetric: 181.2644

Epoch 98: val_loss did not improve from 181.21492
196/196 - 25s - loss: 180.9901 - MinusLogProbMetric: 180.9901 - val_loss: 181.2644 - val_MinusLogProbMetric: 181.2644 - lr: 0.0010 - 25s/epoch - 129ms/step
Epoch 99/1000
2023-10-01 09:31:50.252 
Epoch 99/1000 
	 loss: 180.7083, MinusLogProbMetric: 180.7083, val_loss: 182.1297, val_MinusLogProbMetric: 182.1297

Epoch 99: val_loss did not improve from 181.21492
196/196 - 23s - loss: 180.7083 - MinusLogProbMetric: 180.7083 - val_loss: 182.1297 - val_MinusLogProbMetric: 182.1297 - lr: 0.0010 - 23s/epoch - 119ms/step
Epoch 100/1000
2023-10-01 09:32:12.350 
Epoch 100/1000 
	 loss: 180.7539, MinusLogProbMetric: 180.7539, val_loss: 181.3791, val_MinusLogProbMetric: 181.3791

Epoch 100: val_loss did not improve from 181.21492
196/196 - 22s - loss: 180.7539 - MinusLogProbMetric: 180.7539 - val_loss: 181.3791 - val_MinusLogProbMetric: 181.3791 - lr: 0.0010 - 22s/epoch - 113ms/step
Epoch 101/1000
2023-10-01 09:32:37.989 
Epoch 101/1000 
	 loss: 180.7118, MinusLogProbMetric: 180.7118, val_loss: 182.6427, val_MinusLogProbMetric: 182.6427

Epoch 101: val_loss did not improve from 181.21492
196/196 - 26s - loss: 180.7118 - MinusLogProbMetric: 180.7118 - val_loss: 182.6427 - val_MinusLogProbMetric: 182.6427 - lr: 0.0010 - 26s/epoch - 131ms/step
Epoch 102/1000
2023-10-01 09:33:02.082 
Epoch 102/1000 
	 loss: 180.7150, MinusLogProbMetric: 180.7150, val_loss: 181.7404, val_MinusLogProbMetric: 181.7404

Epoch 102: val_loss did not improve from 181.21492
196/196 - 24s - loss: 180.7150 - MinusLogProbMetric: 180.7150 - val_loss: 181.7404 - val_MinusLogProbMetric: 181.7404 - lr: 0.0010 - 24s/epoch - 123ms/step
Epoch 103/1000
2023-10-01 09:33:28.424 
Epoch 103/1000 
	 loss: 180.7536, MinusLogProbMetric: 180.7536, val_loss: 181.5094, val_MinusLogProbMetric: 181.5094

Epoch 103: val_loss did not improve from 181.21492
196/196 - 26s - loss: 180.7536 - MinusLogProbMetric: 180.7536 - val_loss: 181.5094 - val_MinusLogProbMetric: 181.5094 - lr: 0.0010 - 26s/epoch - 134ms/step
Epoch 104/1000
2023-10-01 09:33:52.096 
Epoch 104/1000 
	 loss: 180.8671, MinusLogProbMetric: 180.8671, val_loss: 181.6047, val_MinusLogProbMetric: 181.6047

Epoch 104: val_loss did not improve from 181.21492
196/196 - 24s - loss: 180.8671 - MinusLogProbMetric: 180.8671 - val_loss: 181.6047 - val_MinusLogProbMetric: 181.6047 - lr: 0.0010 - 24s/epoch - 121ms/step
Epoch 105/1000
2023-10-01 09:34:17.505 
Epoch 105/1000 
	 loss: 180.5585, MinusLogProbMetric: 180.5585, val_loss: 181.4418, val_MinusLogProbMetric: 181.4418

Epoch 105: val_loss did not improve from 181.21492
196/196 - 25s - loss: 180.5585 - MinusLogProbMetric: 180.5585 - val_loss: 181.4418 - val_MinusLogProbMetric: 181.4418 - lr: 0.0010 - 25s/epoch - 130ms/step
Epoch 106/1000
2023-10-01 09:34:43.632 
Epoch 106/1000 
	 loss: 180.6153, MinusLogProbMetric: 180.6153, val_loss: 181.6151, val_MinusLogProbMetric: 181.6151

Epoch 106: val_loss did not improve from 181.21492
196/196 - 26s - loss: 180.6153 - MinusLogProbMetric: 180.6153 - val_loss: 181.6151 - val_MinusLogProbMetric: 181.6151 - lr: 0.0010 - 26s/epoch - 133ms/step
Epoch 107/1000
2023-10-01 09:35:11.439 
Epoch 107/1000 
	 loss: 180.7736, MinusLogProbMetric: 180.7736, val_loss: 184.1702, val_MinusLogProbMetric: 184.1702

Epoch 107: val_loss did not improve from 181.21492
196/196 - 28s - loss: 180.7736 - MinusLogProbMetric: 180.7736 - val_loss: 184.1702 - val_MinusLogProbMetric: 184.1702 - lr: 0.0010 - 28s/epoch - 142ms/step
Epoch 108/1000
2023-10-01 09:35:35.907 
Epoch 108/1000 
	 loss: 180.5999, MinusLogProbMetric: 180.5999, val_loss: 181.2691, val_MinusLogProbMetric: 181.2691

Epoch 108: val_loss did not improve from 181.21492
196/196 - 24s - loss: 180.5999 - MinusLogProbMetric: 180.5999 - val_loss: 181.2691 - val_MinusLogProbMetric: 181.2691 - lr: 0.0010 - 24s/epoch - 125ms/step
Epoch 109/1000
2023-10-01 09:36:03.454 
Epoch 109/1000 
	 loss: 180.6239, MinusLogProbMetric: 180.6239, val_loss: 181.7251, val_MinusLogProbMetric: 181.7251

Epoch 109: val_loss did not improve from 181.21492
196/196 - 28s - loss: 180.6239 - MinusLogProbMetric: 180.6239 - val_loss: 181.7251 - val_MinusLogProbMetric: 181.7251 - lr: 0.0010 - 28s/epoch - 141ms/step
Epoch 110/1000
2023-10-01 09:36:29.186 
Epoch 110/1000 
	 loss: 180.5914, MinusLogProbMetric: 180.5914, val_loss: 182.1414, val_MinusLogProbMetric: 182.1414

Epoch 110: val_loss did not improve from 181.21492
196/196 - 26s - loss: 180.5914 - MinusLogProbMetric: 180.5914 - val_loss: 182.1414 - val_MinusLogProbMetric: 182.1414 - lr: 0.0010 - 26s/epoch - 131ms/step
Epoch 111/1000
2023-10-01 09:36:54.247 
Epoch 111/1000 
	 loss: 180.6702, MinusLogProbMetric: 180.6702, val_loss: 181.6136, val_MinusLogProbMetric: 181.6136

Epoch 111: val_loss did not improve from 181.21492
196/196 - 25s - loss: 180.6702 - MinusLogProbMetric: 180.6702 - val_loss: 181.6136 - val_MinusLogProbMetric: 181.6136 - lr: 0.0010 - 25s/epoch - 128ms/step
Epoch 112/1000
2023-10-01 09:37:19.150 
Epoch 112/1000 
	 loss: 180.7105, MinusLogProbMetric: 180.7105, val_loss: 181.4476, val_MinusLogProbMetric: 181.4476

Epoch 112: val_loss did not improve from 181.21492
196/196 - 25s - loss: 180.7105 - MinusLogProbMetric: 180.7105 - val_loss: 181.4476 - val_MinusLogProbMetric: 181.4476 - lr: 0.0010 - 25s/epoch - 127ms/step
Epoch 113/1000
2023-10-01 09:37:45.205 
Epoch 113/1000 
	 loss: 180.4518, MinusLogProbMetric: 180.4518, val_loss: 181.3657, val_MinusLogProbMetric: 181.3657

Epoch 113: val_loss did not improve from 181.21492
196/196 - 26s - loss: 180.4518 - MinusLogProbMetric: 180.4518 - val_loss: 181.3657 - val_MinusLogProbMetric: 181.3657 - lr: 0.0010 - 26s/epoch - 133ms/step
Epoch 114/1000
2023-10-01 09:38:10.444 
Epoch 114/1000 
	 loss: 180.5350, MinusLogProbMetric: 180.5350, val_loss: 181.8187, val_MinusLogProbMetric: 181.8187

Epoch 114: val_loss did not improve from 181.21492
196/196 - 25s - loss: 180.5350 - MinusLogProbMetric: 180.5350 - val_loss: 181.8187 - val_MinusLogProbMetric: 181.8187 - lr: 0.0010 - 25s/epoch - 129ms/step
Epoch 115/1000
2023-10-01 09:38:35.002 
Epoch 115/1000 
	 loss: 180.5403, MinusLogProbMetric: 180.5403, val_loss: 182.2863, val_MinusLogProbMetric: 182.2863

Epoch 115: val_loss did not improve from 181.21492
196/196 - 25s - loss: 180.5403 - MinusLogProbMetric: 180.5403 - val_loss: 182.2863 - val_MinusLogProbMetric: 182.2863 - lr: 0.0010 - 25s/epoch - 125ms/step
Epoch 116/1000
2023-10-01 09:39:02.007 
Epoch 116/1000 
	 loss: 180.5142, MinusLogProbMetric: 180.5142, val_loss: 181.2913, val_MinusLogProbMetric: 181.2913

Epoch 116: val_loss did not improve from 181.21492
196/196 - 27s - loss: 180.5142 - MinusLogProbMetric: 180.5142 - val_loss: 181.2913 - val_MinusLogProbMetric: 181.2913 - lr: 0.0010 - 27s/epoch - 138ms/step
Epoch 117/1000
2023-10-01 09:39:27.697 
Epoch 117/1000 
	 loss: 180.4959, MinusLogProbMetric: 180.4959, val_loss: 181.1738, val_MinusLogProbMetric: 181.1738

Epoch 117: val_loss improved from 181.21492 to 181.17380, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 27s - loss: 180.4959 - MinusLogProbMetric: 180.4959 - val_loss: 181.1738 - val_MinusLogProbMetric: 181.1738 - lr: 0.0010 - 27s/epoch - 136ms/step
Epoch 118/1000
2023-10-01 09:39:55.044 
Epoch 118/1000 
	 loss: 180.4947, MinusLogProbMetric: 180.4947, val_loss: 182.0006, val_MinusLogProbMetric: 182.0006

Epoch 118: val_loss did not improve from 181.17380
196/196 - 26s - loss: 180.4947 - MinusLogProbMetric: 180.4947 - val_loss: 182.0006 - val_MinusLogProbMetric: 182.0006 - lr: 0.0010 - 26s/epoch - 135ms/step
Epoch 119/1000
2023-10-01 09:40:21.183 
Epoch 119/1000 
	 loss: 180.5013, MinusLogProbMetric: 180.5013, val_loss: 181.1575, val_MinusLogProbMetric: 181.1575

Epoch 119: val_loss improved from 181.17380 to 181.15753, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 26s - loss: 180.5013 - MinusLogProbMetric: 180.5013 - val_loss: 181.1575 - val_MinusLogProbMetric: 181.1575 - lr: 0.0010 - 26s/epoch - 134ms/step
Epoch 120/1000
2023-10-01 09:40:47.703 
Epoch 120/1000 
	 loss: 180.5517, MinusLogProbMetric: 180.5517, val_loss: 181.7505, val_MinusLogProbMetric: 181.7505

Epoch 120: val_loss did not improve from 181.15753
196/196 - 26s - loss: 180.5517 - MinusLogProbMetric: 180.5517 - val_loss: 181.7505 - val_MinusLogProbMetric: 181.7505 - lr: 0.0010 - 26s/epoch - 134ms/step
Epoch 121/1000
2023-10-01 09:41:13.892 
Epoch 121/1000 
	 loss: 180.5031, MinusLogProbMetric: 180.5031, val_loss: 181.6656, val_MinusLogProbMetric: 181.6656

Epoch 121: val_loss did not improve from 181.15753
196/196 - 26s - loss: 180.5031 - MinusLogProbMetric: 180.5031 - val_loss: 181.6656 - val_MinusLogProbMetric: 181.6656 - lr: 0.0010 - 26s/epoch - 134ms/step
Epoch 122/1000
2023-10-01 09:41:39.292 
Epoch 122/1000 
	 loss: 180.4247, MinusLogProbMetric: 180.4247, val_loss: 181.9108, val_MinusLogProbMetric: 181.9108

Epoch 122: val_loss did not improve from 181.15753
196/196 - 25s - loss: 180.4247 - MinusLogProbMetric: 180.4247 - val_loss: 181.9108 - val_MinusLogProbMetric: 181.9108 - lr: 0.0010 - 25s/epoch - 130ms/step
Epoch 123/1000
2023-10-01 09:42:06.373 
Epoch 123/1000 
	 loss: 180.4322, MinusLogProbMetric: 180.4322, val_loss: 181.3328, val_MinusLogProbMetric: 181.3328

Epoch 123: val_loss did not improve from 181.15753
196/196 - 27s - loss: 180.4322 - MinusLogProbMetric: 180.4322 - val_loss: 181.3328 - val_MinusLogProbMetric: 181.3328 - lr: 0.0010 - 27s/epoch - 138ms/step
Epoch 124/1000
2023-10-01 09:42:32.792 
Epoch 124/1000 
	 loss: 180.4135, MinusLogProbMetric: 180.4135, val_loss: 181.0854, val_MinusLogProbMetric: 181.0854

Epoch 124: val_loss improved from 181.15753 to 181.08539, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 28s - loss: 180.4135 - MinusLogProbMetric: 180.4135 - val_loss: 181.0854 - val_MinusLogProbMetric: 181.0854 - lr: 0.0010 - 28s/epoch - 141ms/step
Epoch 125/1000
2023-10-01 09:42:58.666 
Epoch 125/1000 
	 loss: 180.3906, MinusLogProbMetric: 180.3906, val_loss: 181.6188, val_MinusLogProbMetric: 181.6188

Epoch 125: val_loss did not improve from 181.08539
196/196 - 25s - loss: 180.3906 - MinusLogProbMetric: 180.3906 - val_loss: 181.6188 - val_MinusLogProbMetric: 181.6188 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 126/1000
2023-10-01 09:43:26.348 
Epoch 126/1000 
	 loss: 180.5573, MinusLogProbMetric: 180.5573, val_loss: 181.1384, val_MinusLogProbMetric: 181.1384

Epoch 126: val_loss did not improve from 181.08539
196/196 - 28s - loss: 180.5573 - MinusLogProbMetric: 180.5573 - val_loss: 181.1384 - val_MinusLogProbMetric: 181.1384 - lr: 0.0010 - 28s/epoch - 141ms/step
Epoch 127/1000
2023-10-01 09:43:51.993 
Epoch 127/1000 
	 loss: 180.3909, MinusLogProbMetric: 180.3909, val_loss: 181.3837, val_MinusLogProbMetric: 181.3837

Epoch 127: val_loss did not improve from 181.08539
196/196 - 26s - loss: 180.3909 - MinusLogProbMetric: 180.3909 - val_loss: 181.3837 - val_MinusLogProbMetric: 181.3837 - lr: 0.0010 - 26s/epoch - 131ms/step
Epoch 128/1000
2023-10-01 09:44:17.254 
Epoch 128/1000 
	 loss: 180.3554, MinusLogProbMetric: 180.3554, val_loss: 181.1785, val_MinusLogProbMetric: 181.1785

Epoch 128: val_loss did not improve from 181.08539
196/196 - 25s - loss: 180.3554 - MinusLogProbMetric: 180.3554 - val_loss: 181.1785 - val_MinusLogProbMetric: 181.1785 - lr: 0.0010 - 25s/epoch - 129ms/step
Epoch 129/1000
2023-10-01 09:44:44.266 
Epoch 129/1000 
	 loss: 180.4076, MinusLogProbMetric: 180.4076, val_loss: 181.3671, val_MinusLogProbMetric: 181.3671

Epoch 129: val_loss did not improve from 181.08539
196/196 - 27s - loss: 180.4076 - MinusLogProbMetric: 180.4076 - val_loss: 181.3671 - val_MinusLogProbMetric: 181.3671 - lr: 0.0010 - 27s/epoch - 138ms/step
Epoch 130/1000
2023-10-01 09:45:09.383 
Epoch 130/1000 
	 loss: 180.3804, MinusLogProbMetric: 180.3804, val_loss: 182.4298, val_MinusLogProbMetric: 182.4298

Epoch 130: val_loss did not improve from 181.08539
196/196 - 25s - loss: 180.3804 - MinusLogProbMetric: 180.3804 - val_loss: 182.4298 - val_MinusLogProbMetric: 182.4298 - lr: 0.0010 - 25s/epoch - 128ms/step
Epoch 131/1000
2023-10-01 09:45:34.045 
Epoch 131/1000 
	 loss: 180.4607, MinusLogProbMetric: 180.4607, val_loss: 181.1194, val_MinusLogProbMetric: 181.1194

Epoch 131: val_loss did not improve from 181.08539
196/196 - 25s - loss: 180.4607 - MinusLogProbMetric: 180.4607 - val_loss: 181.1194 - val_MinusLogProbMetric: 181.1194 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 132/1000
2023-10-01 09:46:00.047 
Epoch 132/1000 
	 loss: 180.5658, MinusLogProbMetric: 180.5658, val_loss: 181.5617, val_MinusLogProbMetric: 181.5617

Epoch 132: val_loss did not improve from 181.08539
196/196 - 26s - loss: 180.5658 - MinusLogProbMetric: 180.5658 - val_loss: 181.5617 - val_MinusLogProbMetric: 181.5617 - lr: 0.0010 - 26s/epoch - 133ms/step
Epoch 133/1000
2023-10-01 09:46:25.220 
Epoch 133/1000 
	 loss: 180.2392, MinusLogProbMetric: 180.2392, val_loss: 181.3798, val_MinusLogProbMetric: 181.3798

Epoch 133: val_loss did not improve from 181.08539
196/196 - 25s - loss: 180.2392 - MinusLogProbMetric: 180.2392 - val_loss: 181.3798 - val_MinusLogProbMetric: 181.3798 - lr: 0.0010 - 25s/epoch - 128ms/step
Epoch 134/1000
2023-10-01 09:46:49.234 
Epoch 134/1000 
	 loss: 180.2695, MinusLogProbMetric: 180.2695, val_loss: 181.7990, val_MinusLogProbMetric: 181.7990

Epoch 134: val_loss did not improve from 181.08539
196/196 - 24s - loss: 180.2695 - MinusLogProbMetric: 180.2695 - val_loss: 181.7990 - val_MinusLogProbMetric: 181.7990 - lr: 0.0010 - 24s/epoch - 122ms/step
Epoch 135/1000
2023-10-01 09:47:14.673 
Epoch 135/1000 
	 loss: 180.2765, MinusLogProbMetric: 180.2765, val_loss: 181.2103, val_MinusLogProbMetric: 181.2103

Epoch 135: val_loss did not improve from 181.08539
196/196 - 25s - loss: 180.2765 - MinusLogProbMetric: 180.2765 - val_loss: 181.2103 - val_MinusLogProbMetric: 181.2103 - lr: 0.0010 - 25s/epoch - 130ms/step
Epoch 136/1000
2023-10-01 09:47:40.046 
Epoch 136/1000 
	 loss: 180.2560, MinusLogProbMetric: 180.2560, val_loss: 181.1210, val_MinusLogProbMetric: 181.1210

Epoch 136: val_loss did not improve from 181.08539
196/196 - 25s - loss: 180.2560 - MinusLogProbMetric: 180.2560 - val_loss: 181.1210 - val_MinusLogProbMetric: 181.1210 - lr: 0.0010 - 25s/epoch - 129ms/step
Epoch 137/1000
2023-10-01 09:48:05.232 
Epoch 137/1000 
	 loss: 180.2576, MinusLogProbMetric: 180.2576, val_loss: 182.1322, val_MinusLogProbMetric: 182.1322

Epoch 137: val_loss did not improve from 181.08539
196/196 - 25s - loss: 180.2576 - MinusLogProbMetric: 180.2576 - val_loss: 182.1322 - val_MinusLogProbMetric: 182.1322 - lr: 0.0010 - 25s/epoch - 129ms/step
Epoch 138/1000
2023-10-01 09:48:30.609 
Epoch 138/1000 
	 loss: 180.2587, MinusLogProbMetric: 180.2587, val_loss: 181.2285, val_MinusLogProbMetric: 181.2285

Epoch 138: val_loss did not improve from 181.08539
196/196 - 25s - loss: 180.2587 - MinusLogProbMetric: 180.2587 - val_loss: 181.2285 - val_MinusLogProbMetric: 181.2285 - lr: 0.0010 - 25s/epoch - 129ms/step
Epoch 139/1000
2023-10-01 09:48:55.143 
Epoch 139/1000 
	 loss: 180.2926, MinusLogProbMetric: 180.2926, val_loss: 181.6243, val_MinusLogProbMetric: 181.6243

Epoch 139: val_loss did not improve from 181.08539
196/196 - 25s - loss: 180.2926 - MinusLogProbMetric: 180.2926 - val_loss: 181.6243 - val_MinusLogProbMetric: 181.6243 - lr: 0.0010 - 25s/epoch - 125ms/step
Epoch 140/1000
2023-10-01 09:49:21.765 
Epoch 140/1000 
	 loss: 180.2551, MinusLogProbMetric: 180.2551, val_loss: 181.8573, val_MinusLogProbMetric: 181.8573

Epoch 140: val_loss did not improve from 181.08539
196/196 - 27s - loss: 180.2551 - MinusLogProbMetric: 180.2551 - val_loss: 181.8573 - val_MinusLogProbMetric: 181.8573 - lr: 0.0010 - 27s/epoch - 136ms/step
Epoch 141/1000
2023-10-01 09:49:48.581 
Epoch 141/1000 
	 loss: 180.2825, MinusLogProbMetric: 180.2825, val_loss: 181.7007, val_MinusLogProbMetric: 181.7007

Epoch 141: val_loss did not improve from 181.08539
196/196 - 27s - loss: 180.2825 - MinusLogProbMetric: 180.2825 - val_loss: 181.7007 - val_MinusLogProbMetric: 181.7007 - lr: 0.0010 - 27s/epoch - 137ms/step
Epoch 142/1000
2023-10-01 09:50:13.868 
Epoch 142/1000 
	 loss: 180.1842, MinusLogProbMetric: 180.1842, val_loss: 181.4335, val_MinusLogProbMetric: 181.4335

Epoch 142: val_loss did not improve from 181.08539
196/196 - 25s - loss: 180.1842 - MinusLogProbMetric: 180.1842 - val_loss: 181.4335 - val_MinusLogProbMetric: 181.4335 - lr: 0.0010 - 25s/epoch - 129ms/step
Epoch 143/1000
2023-10-01 09:50:39.669 
Epoch 143/1000 
	 loss: 180.2589, MinusLogProbMetric: 180.2589, val_loss: 183.4464, val_MinusLogProbMetric: 183.4464

Epoch 143: val_loss did not improve from 181.08539
196/196 - 26s - loss: 180.2589 - MinusLogProbMetric: 180.2589 - val_loss: 183.4464 - val_MinusLogProbMetric: 183.4464 - lr: 0.0010 - 26s/epoch - 132ms/step
Epoch 144/1000
2023-10-01 09:51:05.088 
Epoch 144/1000 
	 loss: 180.5634, MinusLogProbMetric: 180.5634, val_loss: 181.3664, val_MinusLogProbMetric: 181.3664

Epoch 144: val_loss did not improve from 181.08539
196/196 - 25s - loss: 180.5634 - MinusLogProbMetric: 180.5634 - val_loss: 181.3664 - val_MinusLogProbMetric: 181.3664 - lr: 0.0010 - 25s/epoch - 130ms/step
Epoch 145/1000
2023-10-01 09:51:30.865 
Epoch 145/1000 
	 loss: 180.1497, MinusLogProbMetric: 180.1497, val_loss: 181.4259, val_MinusLogProbMetric: 181.4259

Epoch 145: val_loss did not improve from 181.08539
196/196 - 26s - loss: 180.1497 - MinusLogProbMetric: 180.1497 - val_loss: 181.4259 - val_MinusLogProbMetric: 181.4259 - lr: 0.0010 - 26s/epoch - 131ms/step
Epoch 146/1000
2023-10-01 09:51:57.022 
Epoch 146/1000 
	 loss: 180.1664, MinusLogProbMetric: 180.1664, val_loss: 182.8468, val_MinusLogProbMetric: 182.8468

Epoch 146: val_loss did not improve from 181.08539
196/196 - 26s - loss: 180.1664 - MinusLogProbMetric: 180.1664 - val_loss: 182.8468 - val_MinusLogProbMetric: 182.8468 - lr: 0.0010 - 26s/epoch - 133ms/step
Epoch 147/1000
2023-10-01 09:52:23.084 
Epoch 147/1000 
	 loss: 180.3949, MinusLogProbMetric: 180.3949, val_loss: 184.2786, val_MinusLogProbMetric: 184.2786

Epoch 147: val_loss did not improve from 181.08539
196/196 - 26s - loss: 180.3949 - MinusLogProbMetric: 180.3949 - val_loss: 184.2786 - val_MinusLogProbMetric: 184.2786 - lr: 0.0010 - 26s/epoch - 133ms/step
Epoch 148/1000
2023-10-01 09:52:48.121 
Epoch 148/1000 
	 loss: 180.1973, MinusLogProbMetric: 180.1973, val_loss: 181.3704, val_MinusLogProbMetric: 181.3704

Epoch 148: val_loss did not improve from 181.08539
196/196 - 25s - loss: 180.1973 - MinusLogProbMetric: 180.1973 - val_loss: 181.3704 - val_MinusLogProbMetric: 181.3704 - lr: 0.0010 - 25s/epoch - 128ms/step
Epoch 149/1000
2023-10-01 09:53:15.194 
Epoch 149/1000 
	 loss: 180.1728, MinusLogProbMetric: 180.1728, val_loss: 181.5665, val_MinusLogProbMetric: 181.5665

Epoch 149: val_loss did not improve from 181.08539
196/196 - 27s - loss: 180.1728 - MinusLogProbMetric: 180.1728 - val_loss: 181.5665 - val_MinusLogProbMetric: 181.5665 - lr: 0.0010 - 27s/epoch - 138ms/step
Epoch 150/1000
2023-10-01 09:53:41.444 
Epoch 150/1000 
	 loss: 180.1187, MinusLogProbMetric: 180.1187, val_loss: 181.1527, val_MinusLogProbMetric: 181.1527

Epoch 150: val_loss did not improve from 181.08539
196/196 - 26s - loss: 180.1187 - MinusLogProbMetric: 180.1187 - val_loss: 181.1527 - val_MinusLogProbMetric: 181.1527 - lr: 0.0010 - 26s/epoch - 134ms/step
Epoch 151/1000
2023-10-01 09:54:07.496 
Epoch 151/1000 
	 loss: 180.1707, MinusLogProbMetric: 180.1707, val_loss: 181.4903, val_MinusLogProbMetric: 181.4903

Epoch 151: val_loss did not improve from 181.08539
196/196 - 26s - loss: 180.1707 - MinusLogProbMetric: 180.1707 - val_loss: 181.4903 - val_MinusLogProbMetric: 181.4903 - lr: 0.0010 - 26s/epoch - 133ms/step
Epoch 152/1000
2023-10-01 09:54:33.202 
Epoch 152/1000 
	 loss: 180.1494, MinusLogProbMetric: 180.1494, val_loss: 182.1146, val_MinusLogProbMetric: 182.1146

Epoch 152: val_loss did not improve from 181.08539
196/196 - 26s - loss: 180.1494 - MinusLogProbMetric: 180.1494 - val_loss: 182.1146 - val_MinusLogProbMetric: 182.1146 - lr: 0.0010 - 26s/epoch - 131ms/step
Epoch 153/1000
2023-10-01 09:54:58.168 
Epoch 153/1000 
	 loss: 180.0800, MinusLogProbMetric: 180.0800, val_loss: 181.2971, val_MinusLogProbMetric: 181.2971

Epoch 153: val_loss did not improve from 181.08539
196/196 - 25s - loss: 180.0800 - MinusLogProbMetric: 180.0800 - val_loss: 181.2971 - val_MinusLogProbMetric: 181.2971 - lr: 0.0010 - 25s/epoch - 127ms/step
Epoch 154/1000
2023-10-01 09:55:23.179 
Epoch 154/1000 
	 loss: 180.1170, MinusLogProbMetric: 180.1170, val_loss: 181.2520, val_MinusLogProbMetric: 181.2520

Epoch 154: val_loss did not improve from 181.08539
196/196 - 25s - loss: 180.1170 - MinusLogProbMetric: 180.1170 - val_loss: 181.2520 - val_MinusLogProbMetric: 181.2520 - lr: 0.0010 - 25s/epoch - 128ms/step
Epoch 155/1000
2023-10-01 09:55:47.010 
Epoch 155/1000 
	 loss: 180.0590, MinusLogProbMetric: 180.0590, val_loss: 181.4931, val_MinusLogProbMetric: 181.4931

Epoch 155: val_loss did not improve from 181.08539
196/196 - 24s - loss: 180.0590 - MinusLogProbMetric: 180.0590 - val_loss: 181.4931 - val_MinusLogProbMetric: 181.4931 - lr: 0.0010 - 24s/epoch - 122ms/step
Epoch 156/1000
2023-10-01 09:56:12.659 
Epoch 156/1000 
	 loss: 180.0937, MinusLogProbMetric: 180.0937, val_loss: 182.0227, val_MinusLogProbMetric: 182.0227

Epoch 156: val_loss did not improve from 181.08539
196/196 - 26s - loss: 180.0937 - MinusLogProbMetric: 180.0937 - val_loss: 182.0227 - val_MinusLogProbMetric: 182.0227 - lr: 0.0010 - 26s/epoch - 131ms/step
Epoch 157/1000
2023-10-01 09:56:39.014 
Epoch 157/1000 
	 loss: 180.1003, MinusLogProbMetric: 180.1003, val_loss: 181.0772, val_MinusLogProbMetric: 181.0772

Epoch 157: val_loss improved from 181.08539 to 181.07716, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 28s - loss: 180.1003 - MinusLogProbMetric: 180.1003 - val_loss: 181.0772 - val_MinusLogProbMetric: 181.0772 - lr: 0.0010 - 28s/epoch - 142ms/step
Epoch 158/1000
2023-10-01 09:57:04.633 
Epoch 158/1000 
	 loss: 180.1083, MinusLogProbMetric: 180.1083, val_loss: 181.1998, val_MinusLogProbMetric: 181.1998

Epoch 158: val_loss did not improve from 181.07716
196/196 - 24s - loss: 180.1083 - MinusLogProbMetric: 180.1083 - val_loss: 181.1998 - val_MinusLogProbMetric: 181.1998 - lr: 0.0010 - 24s/epoch - 123ms/step
Epoch 159/1000
2023-10-01 09:57:29.359 
Epoch 159/1000 
	 loss: 180.1011, MinusLogProbMetric: 180.1011, val_loss: 181.2883, val_MinusLogProbMetric: 181.2883

Epoch 159: val_loss did not improve from 181.07716
196/196 - 25s - loss: 180.1011 - MinusLogProbMetric: 180.1011 - val_loss: 181.2883 - val_MinusLogProbMetric: 181.2883 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 160/1000
2023-10-01 09:57:53.974 
Epoch 160/1000 
	 loss: 180.1423, MinusLogProbMetric: 180.1423, val_loss: 183.9909, val_MinusLogProbMetric: 183.9909

Epoch 160: val_loss did not improve from 181.07716
196/196 - 25s - loss: 180.1423 - MinusLogProbMetric: 180.1423 - val_loss: 183.9909 - val_MinusLogProbMetric: 183.9909 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 161/1000
2023-10-01 09:58:18.167 
Epoch 161/1000 
	 loss: 180.0613, MinusLogProbMetric: 180.0613, val_loss: 181.1225, val_MinusLogProbMetric: 181.1225

Epoch 161: val_loss did not improve from 181.07716
196/196 - 24s - loss: 180.0613 - MinusLogProbMetric: 180.0613 - val_loss: 181.1225 - val_MinusLogProbMetric: 181.1225 - lr: 0.0010 - 24s/epoch - 123ms/step
Epoch 162/1000
2023-10-01 09:58:42.827 
Epoch 162/1000 
	 loss: 179.9667, MinusLogProbMetric: 179.9667, val_loss: 181.5175, val_MinusLogProbMetric: 181.5175

Epoch 162: val_loss did not improve from 181.07716
196/196 - 25s - loss: 179.9667 - MinusLogProbMetric: 179.9667 - val_loss: 181.5175 - val_MinusLogProbMetric: 181.5175 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 163/1000
2023-10-01 09:59:08.732 
Epoch 163/1000 
	 loss: 180.0467, MinusLogProbMetric: 180.0467, val_loss: 181.3125, val_MinusLogProbMetric: 181.3125

Epoch 163: val_loss did not improve from 181.07716
196/196 - 26s - loss: 180.0467 - MinusLogProbMetric: 180.0467 - val_loss: 181.3125 - val_MinusLogProbMetric: 181.3125 - lr: 0.0010 - 26s/epoch - 132ms/step
Epoch 164/1000
2023-10-01 09:59:34.850 
Epoch 164/1000 
	 loss: 180.0121, MinusLogProbMetric: 180.0121, val_loss: 181.1844, val_MinusLogProbMetric: 181.1844

Epoch 164: val_loss did not improve from 181.07716
196/196 - 26s - loss: 180.0121 - MinusLogProbMetric: 180.0121 - val_loss: 181.1844 - val_MinusLogProbMetric: 181.1844 - lr: 0.0010 - 26s/epoch - 133ms/step
Epoch 165/1000
2023-10-01 10:00:00.651 
Epoch 165/1000 
	 loss: 180.0236, MinusLogProbMetric: 180.0236, val_loss: 181.7178, val_MinusLogProbMetric: 181.7178

Epoch 165: val_loss did not improve from 181.07716
196/196 - 26s - loss: 180.0236 - MinusLogProbMetric: 180.0236 - val_loss: 181.7178 - val_MinusLogProbMetric: 181.7178 - lr: 0.0010 - 26s/epoch - 132ms/step
Epoch 166/1000
2023-10-01 10:00:25.221 
Epoch 166/1000 
	 loss: 180.1317, MinusLogProbMetric: 180.1317, val_loss: 181.6177, val_MinusLogProbMetric: 181.6177

Epoch 166: val_loss did not improve from 181.07716
196/196 - 25s - loss: 180.1317 - MinusLogProbMetric: 180.1317 - val_loss: 181.6177 - val_MinusLogProbMetric: 181.6177 - lr: 0.0010 - 25s/epoch - 125ms/step
Epoch 167/1000
2023-10-01 10:00:51.267 
Epoch 167/1000 
	 loss: 179.9126, MinusLogProbMetric: 179.9126, val_loss: 181.3640, val_MinusLogProbMetric: 181.3640

Epoch 167: val_loss did not improve from 181.07716
196/196 - 26s - loss: 179.9126 - MinusLogProbMetric: 179.9126 - val_loss: 181.3640 - val_MinusLogProbMetric: 181.3640 - lr: 0.0010 - 26s/epoch - 133ms/step
Epoch 168/1000
2023-10-01 10:01:16.166 
Epoch 168/1000 
	 loss: 179.9780, MinusLogProbMetric: 179.9780, val_loss: 181.2556, val_MinusLogProbMetric: 181.2556

Epoch 168: val_loss did not improve from 181.07716
196/196 - 25s - loss: 179.9780 - MinusLogProbMetric: 179.9780 - val_loss: 181.2556 - val_MinusLogProbMetric: 181.2556 - lr: 0.0010 - 25s/epoch - 127ms/step
Epoch 169/1000
2023-10-01 10:01:41.973 
Epoch 169/1000 
	 loss: 179.9010, MinusLogProbMetric: 179.9010, val_loss: 181.3068, val_MinusLogProbMetric: 181.3068

Epoch 169: val_loss did not improve from 181.07716
196/196 - 26s - loss: 179.9010 - MinusLogProbMetric: 179.9010 - val_loss: 181.3068 - val_MinusLogProbMetric: 181.3068 - lr: 0.0010 - 26s/epoch - 132ms/step
Epoch 170/1000
2023-10-01 10:02:06.792 
Epoch 170/1000 
	 loss: 179.9521, MinusLogProbMetric: 179.9521, val_loss: 181.1630, val_MinusLogProbMetric: 181.1630

Epoch 170: val_loss did not improve from 181.07716
196/196 - 25s - loss: 179.9521 - MinusLogProbMetric: 179.9521 - val_loss: 181.1630 - val_MinusLogProbMetric: 181.1630 - lr: 0.0010 - 25s/epoch - 127ms/step
Epoch 171/1000
2023-10-01 10:02:31.202 
Epoch 171/1000 
	 loss: 179.9218, MinusLogProbMetric: 179.9218, val_loss: 181.3170, val_MinusLogProbMetric: 181.3170

Epoch 171: val_loss did not improve from 181.07716
196/196 - 24s - loss: 179.9218 - MinusLogProbMetric: 179.9218 - val_loss: 181.3170 - val_MinusLogProbMetric: 181.3170 - lr: 0.0010 - 24s/epoch - 125ms/step
Epoch 172/1000
2023-10-01 10:02:54.076 
Epoch 172/1000 
	 loss: 179.8893, MinusLogProbMetric: 179.8893, val_loss: 182.2740, val_MinusLogProbMetric: 182.2740

Epoch 172: val_loss did not improve from 181.07716
196/196 - 23s - loss: 179.8893 - MinusLogProbMetric: 179.8893 - val_loss: 182.2740 - val_MinusLogProbMetric: 182.2740 - lr: 0.0010 - 23s/epoch - 117ms/step
Epoch 173/1000
2023-10-01 10:03:19.853 
Epoch 173/1000 
	 loss: 179.9712, MinusLogProbMetric: 179.9712, val_loss: 181.3096, val_MinusLogProbMetric: 181.3096

Epoch 173: val_loss did not improve from 181.07716
196/196 - 26s - loss: 179.9712 - MinusLogProbMetric: 179.9712 - val_loss: 181.3096 - val_MinusLogProbMetric: 181.3096 - lr: 0.0010 - 26s/epoch - 132ms/step
Epoch 174/1000
2023-10-01 10:03:44.550 
Epoch 174/1000 
	 loss: 180.0431, MinusLogProbMetric: 180.0431, val_loss: 181.1907, val_MinusLogProbMetric: 181.1907

Epoch 174: val_loss did not improve from 181.07716
196/196 - 25s - loss: 180.0431 - MinusLogProbMetric: 180.0431 - val_loss: 181.1907 - val_MinusLogProbMetric: 181.1907 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 175/1000
2023-10-01 10:04:09.558 
Epoch 175/1000 
	 loss: 179.8494, MinusLogProbMetric: 179.8494, val_loss: 181.2171, val_MinusLogProbMetric: 181.2171

Epoch 175: val_loss did not improve from 181.07716
196/196 - 25s - loss: 179.8494 - MinusLogProbMetric: 179.8494 - val_loss: 181.2171 - val_MinusLogProbMetric: 181.2171 - lr: 0.0010 - 25s/epoch - 127ms/step
Epoch 176/1000
2023-10-01 10:04:33.798 
Epoch 176/1000 
	 loss: 179.8839, MinusLogProbMetric: 179.8839, val_loss: 181.4041, val_MinusLogProbMetric: 181.4041

Epoch 176: val_loss did not improve from 181.07716
196/196 - 24s - loss: 179.8839 - MinusLogProbMetric: 179.8839 - val_loss: 181.4041 - val_MinusLogProbMetric: 181.4041 - lr: 0.0010 - 24s/epoch - 124ms/step
Epoch 177/1000
2023-10-01 10:05:00.614 
Epoch 177/1000 
	 loss: 179.8802, MinusLogProbMetric: 179.8802, val_loss: 181.8301, val_MinusLogProbMetric: 181.8301

Epoch 177: val_loss did not improve from 181.07716
196/196 - 27s - loss: 179.8802 - MinusLogProbMetric: 179.8802 - val_loss: 181.8301 - val_MinusLogProbMetric: 181.8301 - lr: 0.0010 - 27s/epoch - 137ms/step
Epoch 178/1000
2023-10-01 10:05:24.410 
Epoch 178/1000 
	 loss: 179.8845, MinusLogProbMetric: 179.8845, val_loss: 181.5894, val_MinusLogProbMetric: 181.5894

Epoch 178: val_loss did not improve from 181.07716
196/196 - 24s - loss: 179.8845 - MinusLogProbMetric: 179.8845 - val_loss: 181.5894 - val_MinusLogProbMetric: 181.5894 - lr: 0.0010 - 24s/epoch - 121ms/step
Epoch 179/1000
2023-10-01 10:05:49.919 
Epoch 179/1000 
	 loss: 179.8854, MinusLogProbMetric: 179.8854, val_loss: 181.2382, val_MinusLogProbMetric: 181.2382

Epoch 179: val_loss did not improve from 181.07716
196/196 - 25s - loss: 179.8854 - MinusLogProbMetric: 179.8854 - val_loss: 181.2382 - val_MinusLogProbMetric: 181.2382 - lr: 0.0010 - 25s/epoch - 130ms/step
Epoch 180/1000
2023-10-01 10:06:16.285 
Epoch 180/1000 
	 loss: 179.7891, MinusLogProbMetric: 179.7891, val_loss: 181.1974, val_MinusLogProbMetric: 181.1974

Epoch 180: val_loss did not improve from 181.07716
196/196 - 26s - loss: 179.7891 - MinusLogProbMetric: 179.7891 - val_loss: 181.1974 - val_MinusLogProbMetric: 181.1974 - lr: 0.0010 - 26s/epoch - 134ms/step
Epoch 181/1000
2023-10-01 10:06:42.368 
Epoch 181/1000 
	 loss: 179.8679, MinusLogProbMetric: 179.8679, val_loss: 181.1010, val_MinusLogProbMetric: 181.1010

Epoch 181: val_loss did not improve from 181.07716
196/196 - 26s - loss: 179.8679 - MinusLogProbMetric: 179.8679 - val_loss: 181.1010 - val_MinusLogProbMetric: 181.1010 - lr: 0.0010 - 26s/epoch - 133ms/step
Epoch 182/1000
2023-10-01 10:07:06.531 
Epoch 182/1000 
	 loss: 179.9036, MinusLogProbMetric: 179.9036, val_loss: 181.1046, val_MinusLogProbMetric: 181.1046

Epoch 182: val_loss did not improve from 181.07716
196/196 - 24s - loss: 179.9036 - MinusLogProbMetric: 179.9036 - val_loss: 181.1046 - val_MinusLogProbMetric: 181.1046 - lr: 0.0010 - 24s/epoch - 123ms/step
Epoch 183/1000
2023-10-01 10:07:30.558 
Epoch 183/1000 
	 loss: 179.8051, MinusLogProbMetric: 179.8051, val_loss: 181.3202, val_MinusLogProbMetric: 181.3202

Epoch 183: val_loss did not improve from 181.07716
196/196 - 24s - loss: 179.8051 - MinusLogProbMetric: 179.8051 - val_loss: 181.3202 - val_MinusLogProbMetric: 181.3202 - lr: 0.0010 - 24s/epoch - 123ms/step
Epoch 184/1000
2023-10-01 10:07:55.624 
Epoch 184/1000 
	 loss: 179.8375, MinusLogProbMetric: 179.8375, val_loss: 181.8294, val_MinusLogProbMetric: 181.8294

Epoch 184: val_loss did not improve from 181.07716
196/196 - 25s - loss: 179.8375 - MinusLogProbMetric: 179.8375 - val_loss: 181.8294 - val_MinusLogProbMetric: 181.8294 - lr: 0.0010 - 25s/epoch - 128ms/step
Epoch 185/1000
2023-10-01 10:08:18.029 
Epoch 185/1000 
	 loss: 180.0480, MinusLogProbMetric: 180.0480, val_loss: 181.4042, val_MinusLogProbMetric: 181.4042

Epoch 185: val_loss did not improve from 181.07716
196/196 - 22s - loss: 180.0480 - MinusLogProbMetric: 180.0480 - val_loss: 181.4042 - val_MinusLogProbMetric: 181.4042 - lr: 0.0010 - 22s/epoch - 114ms/step
Epoch 186/1000
2023-10-01 10:08:41.985 
Epoch 186/1000 
	 loss: 179.6797, MinusLogProbMetric: 179.6797, val_loss: 181.7673, val_MinusLogProbMetric: 181.7673

Epoch 186: val_loss did not improve from 181.07716
196/196 - 24s - loss: 179.6797 - MinusLogProbMetric: 179.6797 - val_loss: 181.7673 - val_MinusLogProbMetric: 181.7673 - lr: 0.0010 - 24s/epoch - 122ms/step
Epoch 187/1000
2023-10-01 10:09:06.672 
Epoch 187/1000 
	 loss: 179.7489, MinusLogProbMetric: 179.7489, val_loss: 181.6037, val_MinusLogProbMetric: 181.6037

Epoch 187: val_loss did not improve from 181.07716
196/196 - 25s - loss: 179.7489 - MinusLogProbMetric: 179.7489 - val_loss: 181.6037 - val_MinusLogProbMetric: 181.6037 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 188/1000
2023-10-01 10:09:30.893 
Epoch 188/1000 
	 loss: 179.7613, MinusLogProbMetric: 179.7613, val_loss: 181.8419, val_MinusLogProbMetric: 181.8419

Epoch 188: val_loss did not improve from 181.07716
196/196 - 24s - loss: 179.7613 - MinusLogProbMetric: 179.7613 - val_loss: 181.8419 - val_MinusLogProbMetric: 181.8419 - lr: 0.0010 - 24s/epoch - 124ms/step
Epoch 189/1000
2023-10-01 10:09:53.693 
Epoch 189/1000 
	 loss: 179.7755, MinusLogProbMetric: 179.7755, val_loss: 181.4546, val_MinusLogProbMetric: 181.4546

Epoch 189: val_loss did not improve from 181.07716
196/196 - 23s - loss: 179.7755 - MinusLogProbMetric: 179.7755 - val_loss: 181.4546 - val_MinusLogProbMetric: 181.4546 - lr: 0.0010 - 23s/epoch - 116ms/step
Epoch 190/1000
2023-10-01 10:10:18.474 
Epoch 190/1000 
	 loss: 179.8501, MinusLogProbMetric: 179.8501, val_loss: 181.5399, val_MinusLogProbMetric: 181.5399

Epoch 190: val_loss did not improve from 181.07716
196/196 - 25s - loss: 179.8501 - MinusLogProbMetric: 179.8501 - val_loss: 181.5399 - val_MinusLogProbMetric: 181.5399 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 191/1000
2023-10-01 10:10:42.136 
Epoch 191/1000 
	 loss: 179.7723, MinusLogProbMetric: 179.7723, val_loss: 181.1367, val_MinusLogProbMetric: 181.1367

Epoch 191: val_loss did not improve from 181.07716
196/196 - 24s - loss: 179.7723 - MinusLogProbMetric: 179.7723 - val_loss: 181.1367 - val_MinusLogProbMetric: 181.1367 - lr: 0.0010 - 24s/epoch - 121ms/step
Epoch 192/1000
2023-10-01 10:11:05.271 
Epoch 192/1000 
	 loss: 179.8540, MinusLogProbMetric: 179.8540, val_loss: 181.1520, val_MinusLogProbMetric: 181.1520

Epoch 192: val_loss did not improve from 181.07716
196/196 - 23s - loss: 179.8540 - MinusLogProbMetric: 179.8540 - val_loss: 181.1520 - val_MinusLogProbMetric: 181.1520 - lr: 0.0010 - 23s/epoch - 118ms/step
Epoch 193/1000
2023-10-01 10:11:29.953 
Epoch 193/1000 
	 loss: 179.6574, MinusLogProbMetric: 179.6574, val_loss: 181.0354, val_MinusLogProbMetric: 181.0354

Epoch 193: val_loss improved from 181.07716 to 181.03540, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 25s - loss: 179.6574 - MinusLogProbMetric: 179.6574 - val_loss: 181.0354 - val_MinusLogProbMetric: 181.0354 - lr: 0.0010 - 25s/epoch - 130ms/step
Epoch 194/1000
2023-10-01 10:11:56.859 
Epoch 194/1000 
	 loss: 179.8790, MinusLogProbMetric: 179.8790, val_loss: 181.6520, val_MinusLogProbMetric: 181.6520

Epoch 194: val_loss did not improve from 181.03540
196/196 - 26s - loss: 179.8790 - MinusLogProbMetric: 179.8790 - val_loss: 181.6520 - val_MinusLogProbMetric: 181.6520 - lr: 0.0010 - 26s/epoch - 133ms/step
Epoch 195/1000
2023-10-01 10:12:21.624 
Epoch 195/1000 
	 loss: 179.7077, MinusLogProbMetric: 179.7077, val_loss: 182.0842, val_MinusLogProbMetric: 182.0842

Epoch 195: val_loss did not improve from 181.03540
196/196 - 25s - loss: 179.7077 - MinusLogProbMetric: 179.7077 - val_loss: 182.0842 - val_MinusLogProbMetric: 182.0842 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 196/1000
2023-10-01 10:12:45.952 
Epoch 196/1000 
	 loss: 179.6897, MinusLogProbMetric: 179.6897, val_loss: 181.2343, val_MinusLogProbMetric: 181.2343

Epoch 196: val_loss did not improve from 181.03540
196/196 - 24s - loss: 179.6897 - MinusLogProbMetric: 179.6897 - val_loss: 181.2343 - val_MinusLogProbMetric: 181.2343 - lr: 0.0010 - 24s/epoch - 124ms/step
Epoch 197/1000
2023-10-01 10:13:09.621 
Epoch 197/1000 
	 loss: 179.7292, MinusLogProbMetric: 179.7292, val_loss: 181.5538, val_MinusLogProbMetric: 181.5538

Epoch 197: val_loss did not improve from 181.03540
196/196 - 24s - loss: 179.7292 - MinusLogProbMetric: 179.7292 - val_loss: 181.5538 - val_MinusLogProbMetric: 181.5538 - lr: 0.0010 - 24s/epoch - 121ms/step
Epoch 198/1000
2023-10-01 10:13:33.162 
Epoch 198/1000 
	 loss: 179.7986, MinusLogProbMetric: 179.7986, val_loss: 181.3363, val_MinusLogProbMetric: 181.3363

Epoch 198: val_loss did not improve from 181.03540
196/196 - 24s - loss: 179.7986 - MinusLogProbMetric: 179.7986 - val_loss: 181.3363 - val_MinusLogProbMetric: 181.3363 - lr: 0.0010 - 24s/epoch - 120ms/step
Epoch 199/1000
2023-10-01 10:13:59.313 
Epoch 199/1000 
	 loss: 179.8540, MinusLogProbMetric: 179.8540, val_loss: 181.4775, val_MinusLogProbMetric: 181.4775

Epoch 199: val_loss did not improve from 181.03540
196/196 - 26s - loss: 179.8540 - MinusLogProbMetric: 179.8540 - val_loss: 181.4775 - val_MinusLogProbMetric: 181.4775 - lr: 0.0010 - 26s/epoch - 133ms/step
Epoch 200/1000
2023-10-01 10:14:23.641 
Epoch 200/1000 
	 loss: 179.6191, MinusLogProbMetric: 179.6191, val_loss: 181.3019, val_MinusLogProbMetric: 181.3019

Epoch 200: val_loss did not improve from 181.03540
196/196 - 24s - loss: 179.6191 - MinusLogProbMetric: 179.6191 - val_loss: 181.3019 - val_MinusLogProbMetric: 181.3019 - lr: 0.0010 - 24s/epoch - 124ms/step
Epoch 201/1000
2023-10-01 10:14:50.111 
Epoch 201/1000 
	 loss: 179.6625, MinusLogProbMetric: 179.6625, val_loss: 181.4544, val_MinusLogProbMetric: 181.4544

Epoch 201: val_loss did not improve from 181.03540
196/196 - 26s - loss: 179.6625 - MinusLogProbMetric: 179.6625 - val_loss: 181.4544 - val_MinusLogProbMetric: 181.4544 - lr: 0.0010 - 26s/epoch - 135ms/step
Epoch 202/1000
2023-10-01 10:15:15.571 
Epoch 202/1000 
	 loss: 179.6723, MinusLogProbMetric: 179.6723, val_loss: 181.1248, val_MinusLogProbMetric: 181.1248

Epoch 202: val_loss did not improve from 181.03540
196/196 - 25s - loss: 179.6723 - MinusLogProbMetric: 179.6723 - val_loss: 181.1248 - val_MinusLogProbMetric: 181.1248 - lr: 0.0010 - 25s/epoch - 130ms/step
Epoch 203/1000
2023-10-01 10:15:40.506 
Epoch 203/1000 
	 loss: 179.7863, MinusLogProbMetric: 179.7863, val_loss: 181.4222, val_MinusLogProbMetric: 181.4222

Epoch 203: val_loss did not improve from 181.03540
196/196 - 25s - loss: 179.7863 - MinusLogProbMetric: 179.7863 - val_loss: 181.4222 - val_MinusLogProbMetric: 181.4222 - lr: 0.0010 - 25s/epoch - 127ms/step
Epoch 204/1000
2023-10-01 10:16:06.481 
Epoch 204/1000 
	 loss: 179.6297, MinusLogProbMetric: 179.6297, val_loss: 181.6519, val_MinusLogProbMetric: 181.6519

Epoch 204: val_loss did not improve from 181.03540
196/196 - 26s - loss: 179.6297 - MinusLogProbMetric: 179.6297 - val_loss: 181.6519 - val_MinusLogProbMetric: 181.6519 - lr: 0.0010 - 26s/epoch - 132ms/step
Epoch 205/1000
2023-10-01 10:16:30.532 
Epoch 205/1000 
	 loss: 179.6764, MinusLogProbMetric: 179.6764, val_loss: 181.4508, val_MinusLogProbMetric: 181.4508

Epoch 205: val_loss did not improve from 181.03540
196/196 - 24s - loss: 179.6764 - MinusLogProbMetric: 179.6764 - val_loss: 181.4508 - val_MinusLogProbMetric: 181.4508 - lr: 0.0010 - 24s/epoch - 123ms/step
Epoch 206/1000
2023-10-01 10:16:56.573 
Epoch 206/1000 
	 loss: 179.6584, MinusLogProbMetric: 179.6584, val_loss: 182.6270, val_MinusLogProbMetric: 182.6270

Epoch 206: val_loss did not improve from 181.03540
196/196 - 26s - loss: 179.6584 - MinusLogProbMetric: 179.6584 - val_loss: 182.6270 - val_MinusLogProbMetric: 182.6270 - lr: 0.0010 - 26s/epoch - 133ms/step
Epoch 207/1000
2023-10-01 10:17:21.198 
Epoch 207/1000 
	 loss: 179.6747, MinusLogProbMetric: 179.6747, val_loss: 181.0717, val_MinusLogProbMetric: 181.0717

Epoch 207: val_loss did not improve from 181.03540
196/196 - 25s - loss: 179.6747 - MinusLogProbMetric: 179.6747 - val_loss: 181.0717 - val_MinusLogProbMetric: 181.0717 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 208/1000
2023-10-01 10:17:46.637 
Epoch 208/1000 
	 loss: 179.6470, MinusLogProbMetric: 179.6470, val_loss: 181.3219, val_MinusLogProbMetric: 181.3219

Epoch 208: val_loss did not improve from 181.03540
196/196 - 25s - loss: 179.6470 - MinusLogProbMetric: 179.6470 - val_loss: 181.3219 - val_MinusLogProbMetric: 181.3219 - lr: 0.0010 - 25s/epoch - 130ms/step
Epoch 209/1000
2023-10-01 10:18:13.514 
Epoch 209/1000 
	 loss: 179.5995, MinusLogProbMetric: 179.5995, val_loss: 182.3116, val_MinusLogProbMetric: 182.3116

Epoch 209: val_loss did not improve from 181.03540
196/196 - 27s - loss: 179.5995 - MinusLogProbMetric: 179.5995 - val_loss: 182.3116 - val_MinusLogProbMetric: 182.3116 - lr: 0.0010 - 27s/epoch - 137ms/step
Epoch 210/1000
2023-10-01 10:18:39.514 
Epoch 210/1000 
	 loss: 179.6181, MinusLogProbMetric: 179.6181, val_loss: 181.5714, val_MinusLogProbMetric: 181.5714

Epoch 210: val_loss did not improve from 181.03540
196/196 - 26s - loss: 179.6181 - MinusLogProbMetric: 179.6181 - val_loss: 181.5714 - val_MinusLogProbMetric: 181.5714 - lr: 0.0010 - 26s/epoch - 133ms/step
Epoch 211/1000
2023-10-01 10:19:04.124 
Epoch 211/1000 
	 loss: 179.5921, MinusLogProbMetric: 179.5921, val_loss: 181.2343, val_MinusLogProbMetric: 181.2343

Epoch 211: val_loss did not improve from 181.03540
196/196 - 25s - loss: 179.5921 - MinusLogProbMetric: 179.5921 - val_loss: 181.2343 - val_MinusLogProbMetric: 181.2343 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 212/1000
2023-10-01 10:19:28.152 
Epoch 212/1000 
	 loss: 179.6678, MinusLogProbMetric: 179.6678, val_loss: 181.2965, val_MinusLogProbMetric: 181.2965

Epoch 212: val_loss did not improve from 181.03540
196/196 - 24s - loss: 179.6678 - MinusLogProbMetric: 179.6678 - val_loss: 181.2965 - val_MinusLogProbMetric: 181.2965 - lr: 0.0010 - 24s/epoch - 123ms/step
Epoch 213/1000
2023-10-01 10:19:52.782 
Epoch 213/1000 
	 loss: 179.5946, MinusLogProbMetric: 179.5946, val_loss: 183.5921, val_MinusLogProbMetric: 183.5921

Epoch 213: val_loss did not improve from 181.03540
196/196 - 25s - loss: 179.5946 - MinusLogProbMetric: 179.5946 - val_loss: 183.5921 - val_MinusLogProbMetric: 183.5921 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 214/1000
2023-10-01 10:20:17.823 
Epoch 214/1000 
	 loss: 179.5805, MinusLogProbMetric: 179.5805, val_loss: 181.4527, val_MinusLogProbMetric: 181.4527

Epoch 214: val_loss did not improve from 181.03540
196/196 - 25s - loss: 179.5805 - MinusLogProbMetric: 179.5805 - val_loss: 181.4527 - val_MinusLogProbMetric: 181.4527 - lr: 0.0010 - 25s/epoch - 128ms/step
Epoch 215/1000
2023-10-01 10:20:42.732 
Epoch 215/1000 
	 loss: 179.5425, MinusLogProbMetric: 179.5425, val_loss: 181.3629, val_MinusLogProbMetric: 181.3629

Epoch 215: val_loss did not improve from 181.03540
196/196 - 25s - loss: 179.5425 - MinusLogProbMetric: 179.5425 - val_loss: 181.3629 - val_MinusLogProbMetric: 181.3629 - lr: 0.0010 - 25s/epoch - 127ms/step
Epoch 216/1000
2023-10-01 10:21:07.636 
Epoch 216/1000 
	 loss: 179.5642, MinusLogProbMetric: 179.5642, val_loss: 181.2489, val_MinusLogProbMetric: 181.2489

Epoch 216: val_loss did not improve from 181.03540
196/196 - 25s - loss: 179.5642 - MinusLogProbMetric: 179.5642 - val_loss: 181.2489 - val_MinusLogProbMetric: 181.2489 - lr: 0.0010 - 25s/epoch - 127ms/step
Epoch 217/1000
2023-10-01 10:21:32.061 
Epoch 217/1000 
	 loss: 179.5740, MinusLogProbMetric: 179.5740, val_loss: 181.4199, val_MinusLogProbMetric: 181.4199

Epoch 217: val_loss did not improve from 181.03540
196/196 - 24s - loss: 179.5740 - MinusLogProbMetric: 179.5740 - val_loss: 181.4199 - val_MinusLogProbMetric: 181.4199 - lr: 0.0010 - 24s/epoch - 125ms/step
Epoch 218/1000
2023-10-01 10:21:55.036 
Epoch 218/1000 
	 loss: 179.5933, MinusLogProbMetric: 179.5933, val_loss: 181.1458, val_MinusLogProbMetric: 181.1458

Epoch 218: val_loss did not improve from 181.03540
196/196 - 23s - loss: 179.5933 - MinusLogProbMetric: 179.5933 - val_loss: 181.1458 - val_MinusLogProbMetric: 181.1458 - lr: 0.0010 - 23s/epoch - 117ms/step
Epoch 219/1000
2023-10-01 10:22:20.935 
Epoch 219/1000 
	 loss: 179.5049, MinusLogProbMetric: 179.5049, val_loss: 181.5558, val_MinusLogProbMetric: 181.5558

Epoch 219: val_loss did not improve from 181.03540
196/196 - 26s - loss: 179.5049 - MinusLogProbMetric: 179.5049 - val_loss: 181.5558 - val_MinusLogProbMetric: 181.5558 - lr: 0.0010 - 26s/epoch - 132ms/step
Epoch 220/1000
2023-10-01 10:22:48.142 
Epoch 220/1000 
	 loss: 179.7169, MinusLogProbMetric: 179.7169, val_loss: 186.5243, val_MinusLogProbMetric: 186.5243

Epoch 220: val_loss did not improve from 181.03540
196/196 - 27s - loss: 179.7169 - MinusLogProbMetric: 179.7169 - val_loss: 186.5243 - val_MinusLogProbMetric: 186.5243 - lr: 0.0010 - 27s/epoch - 139ms/step
Epoch 221/1000
2023-10-01 10:23:12.507 
Epoch 221/1000 
	 loss: 179.6775, MinusLogProbMetric: 179.6775, val_loss: 181.3065, val_MinusLogProbMetric: 181.3065

Epoch 221: val_loss did not improve from 181.03540
196/196 - 24s - loss: 179.6775 - MinusLogProbMetric: 179.6775 - val_loss: 181.3065 - val_MinusLogProbMetric: 181.3065 - lr: 0.0010 - 24s/epoch - 124ms/step
Epoch 222/1000
2023-10-01 10:23:38.158 
Epoch 222/1000 
	 loss: 179.4869, MinusLogProbMetric: 179.4869, val_loss: 181.2759, val_MinusLogProbMetric: 181.2759

Epoch 222: val_loss did not improve from 181.03540
196/196 - 26s - loss: 179.4869 - MinusLogProbMetric: 179.4869 - val_loss: 181.2759 - val_MinusLogProbMetric: 181.2759 - lr: 0.0010 - 26s/epoch - 131ms/step
Epoch 223/1000
2023-10-01 10:24:03.513 
Epoch 223/1000 
	 loss: 179.4840, MinusLogProbMetric: 179.4840, val_loss: 181.2643, val_MinusLogProbMetric: 181.2643

Epoch 223: val_loss did not improve from 181.03540
196/196 - 25s - loss: 179.4840 - MinusLogProbMetric: 179.4840 - val_loss: 181.2643 - val_MinusLogProbMetric: 181.2643 - lr: 0.0010 - 25s/epoch - 129ms/step
Epoch 224/1000
2023-10-01 10:24:29.401 
Epoch 224/1000 
	 loss: 179.7001, MinusLogProbMetric: 179.7001, val_loss: 183.0584, val_MinusLogProbMetric: 183.0584

Epoch 224: val_loss did not improve from 181.03540
196/196 - 26s - loss: 179.7001 - MinusLogProbMetric: 179.7001 - val_loss: 183.0584 - val_MinusLogProbMetric: 183.0584 - lr: 0.0010 - 26s/epoch - 132ms/step
Epoch 225/1000
2023-10-01 10:24:55.166 
Epoch 225/1000 
	 loss: 179.4347, MinusLogProbMetric: 179.4347, val_loss: 181.2040, val_MinusLogProbMetric: 181.2040

Epoch 225: val_loss did not improve from 181.03540
196/196 - 26s - loss: 179.4347 - MinusLogProbMetric: 179.4347 - val_loss: 181.2040 - val_MinusLogProbMetric: 181.2040 - lr: 0.0010 - 26s/epoch - 131ms/step
Epoch 226/1000
2023-10-01 10:25:21.193 
Epoch 226/1000 
	 loss: 179.4839, MinusLogProbMetric: 179.4839, val_loss: 181.1877, val_MinusLogProbMetric: 181.1877

Epoch 226: val_loss did not improve from 181.03540
196/196 - 26s - loss: 179.4839 - MinusLogProbMetric: 179.4839 - val_loss: 181.1877 - val_MinusLogProbMetric: 181.1877 - lr: 0.0010 - 26s/epoch - 133ms/step
Epoch 227/1000
2023-10-01 10:25:45.953 
Epoch 227/1000 
	 loss: 179.5764, MinusLogProbMetric: 179.5764, val_loss: 181.5871, val_MinusLogProbMetric: 181.5871

Epoch 227: val_loss did not improve from 181.03540
196/196 - 25s - loss: 179.5764 - MinusLogProbMetric: 179.5764 - val_loss: 181.5871 - val_MinusLogProbMetric: 181.5871 - lr: 0.0010 - 25s/epoch - 126ms/step
Epoch 228/1000
2023-10-01 10:26:10.229 
Epoch 228/1000 
	 loss: 179.4286, MinusLogProbMetric: 179.4286, val_loss: 181.4828, val_MinusLogProbMetric: 181.4828

Epoch 228: val_loss did not improve from 181.03540
196/196 - 24s - loss: 179.4286 - MinusLogProbMetric: 179.4286 - val_loss: 181.4828 - val_MinusLogProbMetric: 181.4828 - lr: 0.0010 - 24s/epoch - 124ms/step
Epoch 229/1000
2023-10-01 10:26:35.353 
Epoch 229/1000 
	 loss: 179.8399, MinusLogProbMetric: 179.8399, val_loss: 181.4539, val_MinusLogProbMetric: 181.4539

Epoch 229: val_loss did not improve from 181.03540
196/196 - 25s - loss: 179.8399 - MinusLogProbMetric: 179.8399 - val_loss: 181.4539 - val_MinusLogProbMetric: 181.4539 - lr: 0.0010 - 25s/epoch - 128ms/step
Epoch 230/1000
2023-10-01 10:27:01.008 
Epoch 230/1000 
	 loss: 179.3609, MinusLogProbMetric: 179.3609, val_loss: 181.1467, val_MinusLogProbMetric: 181.1467

Epoch 230: val_loss did not improve from 181.03540
196/196 - 26s - loss: 179.3609 - MinusLogProbMetric: 179.3609 - val_loss: 181.1467 - val_MinusLogProbMetric: 181.1467 - lr: 0.0010 - 26s/epoch - 131ms/step
Epoch 231/1000
2023-10-01 10:27:26.928 
Epoch 231/1000 
	 loss: 179.4139, MinusLogProbMetric: 179.4139, val_loss: 181.6872, val_MinusLogProbMetric: 181.6872

Epoch 231: val_loss did not improve from 181.03540
196/196 - 26s - loss: 179.4139 - MinusLogProbMetric: 179.4139 - val_loss: 181.6872 - val_MinusLogProbMetric: 181.6872 - lr: 0.0010 - 26s/epoch - 132ms/step
Epoch 232/1000
2023-10-01 10:27:50.698 
Epoch 232/1000 
	 loss: 179.8696, MinusLogProbMetric: 179.8696, val_loss: 181.4785, val_MinusLogProbMetric: 181.4785

Epoch 232: val_loss did not improve from 181.03540
196/196 - 24s - loss: 179.8696 - MinusLogProbMetric: 179.8696 - val_loss: 181.4785 - val_MinusLogProbMetric: 181.4785 - lr: 0.0010 - 24s/epoch - 121ms/step
Epoch 233/1000
2023-10-01 10:28:13.483 
Epoch 233/1000 
	 loss: 179.3571, MinusLogProbMetric: 179.3571, val_loss: 181.5503, val_MinusLogProbMetric: 181.5503

Epoch 233: val_loss did not improve from 181.03540
196/196 - 23s - loss: 179.3571 - MinusLogProbMetric: 179.3571 - val_loss: 181.5503 - val_MinusLogProbMetric: 181.5503 - lr: 0.0010 - 23s/epoch - 116ms/step
Epoch 234/1000
2023-10-01 10:28:37.560 
Epoch 234/1000 
	 loss: 179.3949, MinusLogProbMetric: 179.3949, val_loss: 182.5638, val_MinusLogProbMetric: 182.5638

Epoch 234: val_loss did not improve from 181.03540
196/196 - 24s - loss: 179.3949 - MinusLogProbMetric: 179.3949 - val_loss: 182.5638 - val_MinusLogProbMetric: 182.5638 - lr: 0.0010 - 24s/epoch - 123ms/step
Epoch 235/1000
2023-10-01 10:29:03.669 
Epoch 235/1000 
	 loss: 179.4438, MinusLogProbMetric: 179.4438, val_loss: 181.4828, val_MinusLogProbMetric: 181.4828

Epoch 235: val_loss did not improve from 181.03540
196/196 - 26s - loss: 179.4438 - MinusLogProbMetric: 179.4438 - val_loss: 181.4828 - val_MinusLogProbMetric: 181.4828 - lr: 0.0010 - 26s/epoch - 133ms/step
Epoch 236/1000
2023-10-01 10:29:29.243 
Epoch 236/1000 
	 loss: 179.4452, MinusLogProbMetric: 179.4452, val_loss: 181.3157, val_MinusLogProbMetric: 181.3157

Epoch 236: val_loss did not improve from 181.03540
196/196 - 26s - loss: 179.4452 - MinusLogProbMetric: 179.4452 - val_loss: 181.3157 - val_MinusLogProbMetric: 181.3157 - lr: 0.0010 - 26s/epoch - 130ms/step
Epoch 237/1000
2023-10-01 10:29:53.592 
Epoch 237/1000 
	 loss: 179.4458, MinusLogProbMetric: 179.4458, val_loss: 181.2552, val_MinusLogProbMetric: 181.2552

Epoch 237: val_loss did not improve from 181.03540
196/196 - 24s - loss: 179.4458 - MinusLogProbMetric: 179.4458 - val_loss: 181.2552 - val_MinusLogProbMetric: 181.2552 - lr: 0.0010 - 24s/epoch - 124ms/step
Epoch 238/1000
2023-10-01 10:30:15.250 
Epoch 238/1000 
	 loss: 179.3890, MinusLogProbMetric: 179.3890, val_loss: 181.4859, val_MinusLogProbMetric: 181.4859

Epoch 238: val_loss did not improve from 181.03540
196/196 - 22s - loss: 179.3890 - MinusLogProbMetric: 179.3890 - val_loss: 181.4859 - val_MinusLogProbMetric: 181.4859 - lr: 0.0010 - 22s/epoch - 110ms/step
Epoch 239/1000
2023-10-01 10:30:39.249 
Epoch 239/1000 
	 loss: 179.3769, MinusLogProbMetric: 179.3769, val_loss: 182.1136, val_MinusLogProbMetric: 182.1136

Epoch 239: val_loss did not improve from 181.03540
196/196 - 24s - loss: 179.3769 - MinusLogProbMetric: 179.3769 - val_loss: 182.1136 - val_MinusLogProbMetric: 182.1136 - lr: 0.0010 - 24s/epoch - 122ms/step
Epoch 240/1000
2023-10-01 10:31:03.215 
Epoch 240/1000 
	 loss: 179.3925, MinusLogProbMetric: 179.3925, val_loss: 181.4577, val_MinusLogProbMetric: 181.4577

Epoch 240: val_loss did not improve from 181.03540
196/196 - 24s - loss: 179.3925 - MinusLogProbMetric: 179.3925 - val_loss: 181.4577 - val_MinusLogProbMetric: 181.4577 - lr: 0.0010 - 24s/epoch - 122ms/step
Epoch 241/1000
2023-10-01 10:31:26.275 
Epoch 241/1000 
	 loss: 179.6154, MinusLogProbMetric: 179.6154, val_loss: 181.3667, val_MinusLogProbMetric: 181.3667

Epoch 241: val_loss did not improve from 181.03540
196/196 - 23s - loss: 179.6154 - MinusLogProbMetric: 179.6154 - val_loss: 181.3667 - val_MinusLogProbMetric: 181.3667 - lr: 0.0010 - 23s/epoch - 118ms/step
Epoch 242/1000
2023-10-01 10:31:52.221 
Epoch 242/1000 
	 loss: 179.3880, MinusLogProbMetric: 179.3880, val_loss: 181.3118, val_MinusLogProbMetric: 181.3118

Epoch 242: val_loss did not improve from 181.03540
196/196 - 26s - loss: 179.3880 - MinusLogProbMetric: 179.3880 - val_loss: 181.3118 - val_MinusLogProbMetric: 181.3118 - lr: 0.0010 - 26s/epoch - 132ms/step
Epoch 243/1000
2023-10-01 10:32:17.231 
Epoch 243/1000 
	 loss: 179.3958, MinusLogProbMetric: 179.3958, val_loss: 181.2431, val_MinusLogProbMetric: 181.2431

Epoch 243: val_loss did not improve from 181.03540
196/196 - 25s - loss: 179.3958 - MinusLogProbMetric: 179.3958 - val_loss: 181.2431 - val_MinusLogProbMetric: 181.2431 - lr: 0.0010 - 25s/epoch - 128ms/step
Epoch 244/1000
2023-10-01 10:32:43.044 
Epoch 244/1000 
	 loss: 178.6022, MinusLogProbMetric: 178.6022, val_loss: 180.8168, val_MinusLogProbMetric: 180.8168

Epoch 244: val_loss improved from 181.03540 to 180.81676, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 26s - loss: 178.6022 - MinusLogProbMetric: 178.6022 - val_loss: 180.8168 - val_MinusLogProbMetric: 180.8168 - lr: 5.0000e-04 - 26s/epoch - 132ms/step
Epoch 245/1000
2023-10-01 10:33:09.062 
Epoch 245/1000 
	 loss: 178.5658, MinusLogProbMetric: 178.5658, val_loss: 180.8421, val_MinusLogProbMetric: 180.8421

Epoch 245: val_loss did not improve from 180.81676
196/196 - 26s - loss: 178.5658 - MinusLogProbMetric: 178.5658 - val_loss: 180.8421 - val_MinusLogProbMetric: 180.8421 - lr: 5.0000e-04 - 26s/epoch - 132ms/step
Epoch 246/1000
2023-10-01 10:33:34.766 
Epoch 246/1000 
	 loss: 178.6281, MinusLogProbMetric: 178.6281, val_loss: 180.8536, val_MinusLogProbMetric: 180.8536

Epoch 246: val_loss did not improve from 180.81676
196/196 - 26s - loss: 178.6281 - MinusLogProbMetric: 178.6281 - val_loss: 180.8536 - val_MinusLogProbMetric: 180.8536 - lr: 5.0000e-04 - 26s/epoch - 131ms/step
Epoch 247/1000
2023-10-01 10:34:00.995 
Epoch 247/1000 
	 loss: 178.6513, MinusLogProbMetric: 178.6513, val_loss: 180.8904, val_MinusLogProbMetric: 180.8904

Epoch 247: val_loss did not improve from 180.81676
196/196 - 26s - loss: 178.6513 - MinusLogProbMetric: 178.6513 - val_loss: 180.8904 - val_MinusLogProbMetric: 180.8904 - lr: 5.0000e-04 - 26s/epoch - 134ms/step
Epoch 248/1000
2023-10-01 10:34:26.989 
Epoch 248/1000 
	 loss: 178.6023, MinusLogProbMetric: 178.6023, val_loss: 181.1695, val_MinusLogProbMetric: 181.1695

Epoch 248: val_loss did not improve from 180.81676
196/196 - 26s - loss: 178.6023 - MinusLogProbMetric: 178.6023 - val_loss: 181.1695 - val_MinusLogProbMetric: 181.1695 - lr: 5.0000e-04 - 26s/epoch - 133ms/step
Epoch 249/1000
2023-10-01 10:34:51.338 
Epoch 249/1000 
	 loss: 178.6558, MinusLogProbMetric: 178.6558, val_loss: 180.8680, val_MinusLogProbMetric: 180.8680

Epoch 249: val_loss did not improve from 180.81676
196/196 - 24s - loss: 178.6558 - MinusLogProbMetric: 178.6558 - val_loss: 180.8680 - val_MinusLogProbMetric: 180.8680 - lr: 5.0000e-04 - 24s/epoch - 124ms/step
Epoch 250/1000
2023-10-01 10:35:16.547 
Epoch 250/1000 
	 loss: 178.9764, MinusLogProbMetric: 178.9764, val_loss: 180.8118, val_MinusLogProbMetric: 180.8118

Epoch 250: val_loss improved from 180.81676 to 180.81180, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 26s - loss: 178.9764 - MinusLogProbMetric: 178.9764 - val_loss: 180.8118 - val_MinusLogProbMetric: 180.8118 - lr: 5.0000e-04 - 26s/epoch - 131ms/step
Epoch 251/1000
2023-10-01 10:35:42.545 
Epoch 251/1000 
	 loss: 178.5149, MinusLogProbMetric: 178.5149, val_loss: 180.7634, val_MinusLogProbMetric: 180.7634

Epoch 251: val_loss improved from 180.81180 to 180.76343, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 26s - loss: 178.5149 - MinusLogProbMetric: 178.5149 - val_loss: 180.7634 - val_MinusLogProbMetric: 180.7634 - lr: 5.0000e-04 - 26s/epoch - 135ms/step
Epoch 252/1000
2023-10-01 10:36:08.573 
Epoch 252/1000 
	 loss: 178.5391, MinusLogProbMetric: 178.5391, val_loss: 180.8265, val_MinusLogProbMetric: 180.8265

Epoch 252: val_loss did not improve from 180.76343
196/196 - 25s - loss: 178.5391 - MinusLogProbMetric: 178.5391 - val_loss: 180.8265 - val_MinusLogProbMetric: 180.8265 - lr: 5.0000e-04 - 25s/epoch - 128ms/step
Epoch 253/1000
2023-10-01 10:36:32.036 
Epoch 253/1000 
	 loss: 178.6160, MinusLogProbMetric: 178.6160, val_loss: 181.0137, val_MinusLogProbMetric: 181.0137

Epoch 253: val_loss did not improve from 180.76343
196/196 - 23s - loss: 178.6160 - MinusLogProbMetric: 178.6160 - val_loss: 181.0137 - val_MinusLogProbMetric: 181.0137 - lr: 5.0000e-04 - 23s/epoch - 120ms/step
Epoch 254/1000
2023-10-01 10:36:55.362 
Epoch 254/1000 
	 loss: 178.5967, MinusLogProbMetric: 178.5967, val_loss: 180.7826, val_MinusLogProbMetric: 180.7826

Epoch 254: val_loss did not improve from 180.76343
196/196 - 23s - loss: 178.5967 - MinusLogProbMetric: 178.5967 - val_loss: 180.7826 - val_MinusLogProbMetric: 180.7826 - lr: 5.0000e-04 - 23s/epoch - 119ms/step
Epoch 255/1000
2023-10-01 10:37:20.169 
Epoch 255/1000 
	 loss: 178.5981, MinusLogProbMetric: 178.5981, val_loss: 181.0230, val_MinusLogProbMetric: 181.0230

Epoch 255: val_loss did not improve from 180.76343
196/196 - 25s - loss: 178.5981 - MinusLogProbMetric: 178.5981 - val_loss: 181.0230 - val_MinusLogProbMetric: 181.0230 - lr: 5.0000e-04 - 25s/epoch - 127ms/step
Epoch 256/1000
2023-10-01 10:37:43.332 
Epoch 256/1000 
	 loss: 178.5959, MinusLogProbMetric: 178.5959, val_loss: 180.8520, val_MinusLogProbMetric: 180.8520

Epoch 256: val_loss did not improve from 180.76343
196/196 - 23s - loss: 178.5959 - MinusLogProbMetric: 178.5959 - val_loss: 180.8520 - val_MinusLogProbMetric: 180.8520 - lr: 5.0000e-04 - 23s/epoch - 118ms/step
Epoch 257/1000
2023-10-01 10:38:08.635 
Epoch 257/1000 
	 loss: 178.6123, MinusLogProbMetric: 178.6123, val_loss: 182.5801, val_MinusLogProbMetric: 182.5801

Epoch 257: val_loss did not improve from 180.76343
196/196 - 25s - loss: 178.6123 - MinusLogProbMetric: 178.6123 - val_loss: 182.5801 - val_MinusLogProbMetric: 182.5801 - lr: 5.0000e-04 - 25s/epoch - 129ms/step
Epoch 258/1000
2023-10-01 10:38:34.092 
Epoch 258/1000 
	 loss: 178.6406, MinusLogProbMetric: 178.6406, val_loss: 181.3213, val_MinusLogProbMetric: 181.3213

Epoch 258: val_loss did not improve from 180.76343
196/196 - 25s - loss: 178.6406 - MinusLogProbMetric: 178.6406 - val_loss: 181.3213 - val_MinusLogProbMetric: 181.3213 - lr: 5.0000e-04 - 25s/epoch - 130ms/step
Epoch 259/1000
2023-10-01 10:38:58.223 
Epoch 259/1000 
	 loss: 178.5548, MinusLogProbMetric: 178.5548, val_loss: 181.0573, val_MinusLogProbMetric: 181.0573

Epoch 259: val_loss did not improve from 180.76343
196/196 - 24s - loss: 178.5548 - MinusLogProbMetric: 178.5548 - val_loss: 181.0573 - val_MinusLogProbMetric: 181.0573 - lr: 5.0000e-04 - 24s/epoch - 123ms/step
Epoch 260/1000
2023-10-01 10:39:22.192 
Epoch 260/1000 
	 loss: 178.5494, MinusLogProbMetric: 178.5494, val_loss: 180.8652, val_MinusLogProbMetric: 180.8652

Epoch 260: val_loss did not improve from 180.76343
196/196 - 24s - loss: 178.5494 - MinusLogProbMetric: 178.5494 - val_loss: 180.8652 - val_MinusLogProbMetric: 180.8652 - lr: 5.0000e-04 - 24s/epoch - 122ms/step
Epoch 261/1000
2023-10-01 10:39:46.019 
Epoch 261/1000 
	 loss: 178.5652, MinusLogProbMetric: 178.5652, val_loss: 180.7111, val_MinusLogProbMetric: 180.7111

Epoch 261: val_loss improved from 180.76343 to 180.71111, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 24s - loss: 178.5652 - MinusLogProbMetric: 178.5652 - val_loss: 180.7111 - val_MinusLogProbMetric: 180.7111 - lr: 5.0000e-04 - 24s/epoch - 124ms/step
Epoch 262/1000
2023-10-01 10:40:11.841 
Epoch 262/1000 
	 loss: 178.5672, MinusLogProbMetric: 178.5672, val_loss: 180.8430, val_MinusLogProbMetric: 180.8430

Epoch 262: val_loss did not improve from 180.71111
196/196 - 25s - loss: 178.5672 - MinusLogProbMetric: 178.5672 - val_loss: 180.8430 - val_MinusLogProbMetric: 180.8430 - lr: 5.0000e-04 - 25s/epoch - 129ms/step
Epoch 263/1000
2023-10-01 10:40:37.996 
Epoch 263/1000 
	 loss: 178.5760, MinusLogProbMetric: 178.5760, val_loss: 180.8804, val_MinusLogProbMetric: 180.8804

Epoch 263: val_loss did not improve from 180.71111
196/196 - 26s - loss: 178.5760 - MinusLogProbMetric: 178.5760 - val_loss: 180.8804 - val_MinusLogProbMetric: 180.8804 - lr: 5.0000e-04 - 26s/epoch - 133ms/step
Epoch 264/1000
2023-10-01 10:41:01.521 
Epoch 264/1000 
	 loss: 178.5329, MinusLogProbMetric: 178.5329, val_loss: 180.8538, val_MinusLogProbMetric: 180.8538

Epoch 264: val_loss did not improve from 180.71111
196/196 - 24s - loss: 178.5329 - MinusLogProbMetric: 178.5329 - val_loss: 180.8538 - val_MinusLogProbMetric: 180.8538 - lr: 5.0000e-04 - 24s/epoch - 120ms/step
Epoch 265/1000
2023-10-01 10:41:27.759 
Epoch 265/1000 
	 loss: 178.5527, MinusLogProbMetric: 178.5527, val_loss: 180.9053, val_MinusLogProbMetric: 180.9053

Epoch 265: val_loss did not improve from 180.71111
196/196 - 26s - loss: 178.5527 - MinusLogProbMetric: 178.5527 - val_loss: 180.9053 - val_MinusLogProbMetric: 180.9053 - lr: 5.0000e-04 - 26s/epoch - 134ms/step
Epoch 266/1000
2023-10-01 10:41:51.311 
Epoch 266/1000 
	 loss: 178.5489, MinusLogProbMetric: 178.5489, val_loss: 181.1100, val_MinusLogProbMetric: 181.1100

Epoch 266: val_loss did not improve from 180.71111
196/196 - 24s - loss: 178.5489 - MinusLogProbMetric: 178.5489 - val_loss: 181.1100 - val_MinusLogProbMetric: 181.1100 - lr: 5.0000e-04 - 24s/epoch - 120ms/step
Epoch 267/1000
2023-10-01 10:42:15.657 
Epoch 267/1000 
	 loss: 178.5152, MinusLogProbMetric: 178.5152, val_loss: 180.7628, val_MinusLogProbMetric: 180.7628

Epoch 267: val_loss did not improve from 180.71111
196/196 - 24s - loss: 178.5152 - MinusLogProbMetric: 178.5152 - val_loss: 180.7628 - val_MinusLogProbMetric: 180.7628 - lr: 5.0000e-04 - 24s/epoch - 124ms/step
Epoch 268/1000
2023-10-01 10:42:38.709 
Epoch 268/1000 
	 loss: 178.5449, MinusLogProbMetric: 178.5449, val_loss: 180.8586, val_MinusLogProbMetric: 180.8586

Epoch 268: val_loss did not improve from 180.71111
196/196 - 23s - loss: 178.5449 - MinusLogProbMetric: 178.5449 - val_loss: 180.8586 - val_MinusLogProbMetric: 180.8586 - lr: 5.0000e-04 - 23s/epoch - 118ms/step
Epoch 269/1000
2023-10-01 10:43:00.403 
Epoch 269/1000 
	 loss: 178.5199, MinusLogProbMetric: 178.5199, val_loss: 180.8394, val_MinusLogProbMetric: 180.8394

Epoch 269: val_loss did not improve from 180.71111
196/196 - 22s - loss: 178.5199 - MinusLogProbMetric: 178.5199 - val_loss: 180.8394 - val_MinusLogProbMetric: 180.8394 - lr: 5.0000e-04 - 22s/epoch - 110ms/step
Epoch 270/1000
2023-10-01 10:43:24.844 
Epoch 270/1000 
	 loss: 178.5585, MinusLogProbMetric: 178.5585, val_loss: 180.8029, val_MinusLogProbMetric: 180.8029

Epoch 270: val_loss did not improve from 180.71111
196/196 - 24s - loss: 178.5585 - MinusLogProbMetric: 178.5585 - val_loss: 180.8029 - val_MinusLogProbMetric: 180.8029 - lr: 5.0000e-04 - 24s/epoch - 124ms/step
Epoch 271/1000
2023-10-01 10:43:48.413 
Epoch 271/1000 
	 loss: 178.5159, MinusLogProbMetric: 178.5159, val_loss: 180.9747, val_MinusLogProbMetric: 180.9747

Epoch 271: val_loss did not improve from 180.71111
196/196 - 24s - loss: 178.5159 - MinusLogProbMetric: 178.5159 - val_loss: 180.9747 - val_MinusLogProbMetric: 180.9747 - lr: 5.0000e-04 - 24s/epoch - 120ms/step
Epoch 272/1000
2023-10-01 10:44:12.240 
Epoch 272/1000 
	 loss: 178.5366, MinusLogProbMetric: 178.5366, val_loss: 180.9741, val_MinusLogProbMetric: 180.9741

Epoch 272: val_loss did not improve from 180.71111
196/196 - 24s - loss: 178.5366 - MinusLogProbMetric: 178.5366 - val_loss: 180.9741 - val_MinusLogProbMetric: 180.9741 - lr: 5.0000e-04 - 24s/epoch - 121ms/step
Epoch 273/1000
2023-10-01 10:44:37.786 
Epoch 273/1000 
	 loss: 178.5248, MinusLogProbMetric: 178.5248, val_loss: 180.8338, val_MinusLogProbMetric: 180.8338

Epoch 273: val_loss did not improve from 180.71111
196/196 - 26s - loss: 178.5248 - MinusLogProbMetric: 178.5248 - val_loss: 180.8338 - val_MinusLogProbMetric: 180.8338 - lr: 5.0000e-04 - 26s/epoch - 130ms/step
Epoch 274/1000
2023-10-01 10:45:04.458 
Epoch 274/1000 
	 loss: 178.5073, MinusLogProbMetric: 178.5073, val_loss: 180.7940, val_MinusLogProbMetric: 180.7940

Epoch 274: val_loss did not improve from 180.71111
196/196 - 27s - loss: 178.5073 - MinusLogProbMetric: 178.5073 - val_loss: 180.7940 - val_MinusLogProbMetric: 180.7940 - lr: 5.0000e-04 - 27s/epoch - 136ms/step
Epoch 275/1000
2023-10-01 10:45:29.293 
Epoch 275/1000 
	 loss: 178.5246, MinusLogProbMetric: 178.5246, val_loss: 181.0018, val_MinusLogProbMetric: 181.0018

Epoch 275: val_loss did not improve from 180.71111
196/196 - 25s - loss: 178.5246 - MinusLogProbMetric: 178.5246 - val_loss: 181.0018 - val_MinusLogProbMetric: 181.0018 - lr: 5.0000e-04 - 25s/epoch - 127ms/step
Epoch 276/1000
2023-10-01 10:45:53.093 
Epoch 276/1000 
	 loss: 178.5322, MinusLogProbMetric: 178.5322, val_loss: 180.9850, val_MinusLogProbMetric: 180.9850

Epoch 276: val_loss did not improve from 180.71111
196/196 - 24s - loss: 178.5322 - MinusLogProbMetric: 178.5322 - val_loss: 180.9850 - val_MinusLogProbMetric: 180.9850 - lr: 5.0000e-04 - 24s/epoch - 121ms/step
Epoch 277/1000
2023-10-01 10:46:16.391 
Epoch 277/1000 
	 loss: 178.4563, MinusLogProbMetric: 178.4563, val_loss: 180.9525, val_MinusLogProbMetric: 180.9525

Epoch 277: val_loss did not improve from 180.71111
196/196 - 23s - loss: 178.4563 - MinusLogProbMetric: 178.4563 - val_loss: 180.9525 - val_MinusLogProbMetric: 180.9525 - lr: 5.0000e-04 - 23s/epoch - 119ms/step
Epoch 278/1000
2023-10-01 10:46:40.975 
Epoch 278/1000 
	 loss: 178.5382, MinusLogProbMetric: 178.5382, val_loss: 180.9367, val_MinusLogProbMetric: 180.9367

Epoch 278: val_loss did not improve from 180.71111
196/196 - 25s - loss: 178.5382 - MinusLogProbMetric: 178.5382 - val_loss: 180.9367 - val_MinusLogProbMetric: 180.9367 - lr: 5.0000e-04 - 25s/epoch - 125ms/step
Epoch 279/1000
2023-10-01 10:47:04.566 
Epoch 279/1000 
	 loss: 178.4615, MinusLogProbMetric: 178.4615, val_loss: 181.4930, val_MinusLogProbMetric: 181.4930

Epoch 279: val_loss did not improve from 180.71111
196/196 - 24s - loss: 178.4615 - MinusLogProbMetric: 178.4615 - val_loss: 181.4930 - val_MinusLogProbMetric: 181.4930 - lr: 5.0000e-04 - 24s/epoch - 120ms/step
Epoch 280/1000
2023-10-01 10:47:27.325 
Epoch 280/1000 
	 loss: 178.4823, MinusLogProbMetric: 178.4823, val_loss: 180.9231, val_MinusLogProbMetric: 180.9231

Epoch 280: val_loss did not improve from 180.71111
196/196 - 23s - loss: 178.4823 - MinusLogProbMetric: 178.4823 - val_loss: 180.9231 - val_MinusLogProbMetric: 180.9231 - lr: 5.0000e-04 - 23s/epoch - 116ms/step
Epoch 281/1000
2023-10-01 10:47:53.188 
Epoch 281/1000 
	 loss: 178.4931, MinusLogProbMetric: 178.4931, val_loss: 180.9000, val_MinusLogProbMetric: 180.9000

Epoch 281: val_loss did not improve from 180.71111
196/196 - 26s - loss: 178.4931 - MinusLogProbMetric: 178.4931 - val_loss: 180.9000 - val_MinusLogProbMetric: 180.9000 - lr: 5.0000e-04 - 26s/epoch - 132ms/step
Epoch 282/1000
2023-10-01 10:48:18.857 
Epoch 282/1000 
	 loss: 178.4789, MinusLogProbMetric: 178.4789, val_loss: 180.8528, val_MinusLogProbMetric: 180.8528

Epoch 282: val_loss did not improve from 180.71111
196/196 - 26s - loss: 178.4789 - MinusLogProbMetric: 178.4789 - val_loss: 180.8528 - val_MinusLogProbMetric: 180.8528 - lr: 5.0000e-04 - 26s/epoch - 131ms/step
Epoch 283/1000
2023-10-01 10:48:42.313 
Epoch 283/1000 
	 loss: 178.4974, MinusLogProbMetric: 178.4974, val_loss: 180.9571, val_MinusLogProbMetric: 180.9571

Epoch 283: val_loss did not improve from 180.71111
196/196 - 23s - loss: 178.4974 - MinusLogProbMetric: 178.4974 - val_loss: 180.9571 - val_MinusLogProbMetric: 180.9571 - lr: 5.0000e-04 - 23s/epoch - 120ms/step
Epoch 284/1000
2023-10-01 10:49:08.095 
Epoch 284/1000 
	 loss: 178.4840, MinusLogProbMetric: 178.4840, val_loss: 181.2030, val_MinusLogProbMetric: 181.2030

Epoch 284: val_loss did not improve from 180.71111
196/196 - 26s - loss: 178.4840 - MinusLogProbMetric: 178.4840 - val_loss: 181.2030 - val_MinusLogProbMetric: 181.2030 - lr: 5.0000e-04 - 26s/epoch - 132ms/step
Epoch 285/1000
2023-10-01 10:49:33.786 
Epoch 285/1000 
	 loss: 178.4434, MinusLogProbMetric: 178.4434, val_loss: 180.8165, val_MinusLogProbMetric: 180.8165

Epoch 285: val_loss did not improve from 180.71111
196/196 - 26s - loss: 178.4434 - MinusLogProbMetric: 178.4434 - val_loss: 180.8165 - val_MinusLogProbMetric: 180.8165 - lr: 5.0000e-04 - 26s/epoch - 131ms/step
Epoch 286/1000
2023-10-01 10:49:59.580 
Epoch 286/1000 
	 loss: 178.5200, MinusLogProbMetric: 178.5200, val_loss: 180.9576, val_MinusLogProbMetric: 180.9576

Epoch 286: val_loss did not improve from 180.71111
196/196 - 26s - loss: 178.5200 - MinusLogProbMetric: 178.5200 - val_loss: 180.9576 - val_MinusLogProbMetric: 180.9576 - lr: 5.0000e-04 - 26s/epoch - 132ms/step
Epoch 287/1000
2023-10-01 10:50:24.306 
Epoch 287/1000 
	 loss: 178.4225, MinusLogProbMetric: 178.4225, val_loss: 180.8712, val_MinusLogProbMetric: 180.8712

Epoch 287: val_loss did not improve from 180.71111
196/196 - 25s - loss: 178.4225 - MinusLogProbMetric: 178.4225 - val_loss: 180.8712 - val_MinusLogProbMetric: 180.8712 - lr: 5.0000e-04 - 25s/epoch - 126ms/step
Epoch 288/1000
2023-10-01 10:50:50.120 
Epoch 288/1000 
	 loss: 178.4778, MinusLogProbMetric: 178.4778, val_loss: 181.1433, val_MinusLogProbMetric: 181.1433

Epoch 288: val_loss did not improve from 180.71111
196/196 - 26s - loss: 178.4778 - MinusLogProbMetric: 178.4778 - val_loss: 181.1433 - val_MinusLogProbMetric: 181.1433 - lr: 5.0000e-04 - 26s/epoch - 132ms/step
Epoch 289/1000
2023-10-01 10:51:15.392 
Epoch 289/1000 
	 loss: 178.4853, MinusLogProbMetric: 178.4853, val_loss: 181.6385, val_MinusLogProbMetric: 181.6385

Epoch 289: val_loss did not improve from 180.71111
196/196 - 25s - loss: 178.4853 - MinusLogProbMetric: 178.4853 - val_loss: 181.6385 - val_MinusLogProbMetric: 181.6385 - lr: 5.0000e-04 - 25s/epoch - 129ms/step
Epoch 290/1000
2023-10-01 10:51:38.237 
Epoch 290/1000 
	 loss: 178.4569, MinusLogProbMetric: 178.4569, val_loss: 180.8512, val_MinusLogProbMetric: 180.8512

Epoch 290: val_loss did not improve from 180.71111
196/196 - 23s - loss: 178.4569 - MinusLogProbMetric: 178.4569 - val_loss: 180.8512 - val_MinusLogProbMetric: 180.8512 - lr: 5.0000e-04 - 23s/epoch - 117ms/step
Epoch 291/1000
2023-10-01 10:52:01.832 
Epoch 291/1000 
	 loss: 178.4705, MinusLogProbMetric: 178.4705, val_loss: 181.0067, val_MinusLogProbMetric: 181.0067

Epoch 291: val_loss did not improve from 180.71111
196/196 - 24s - loss: 178.4705 - MinusLogProbMetric: 178.4705 - val_loss: 181.0067 - val_MinusLogProbMetric: 181.0067 - lr: 5.0000e-04 - 24s/epoch - 120ms/step
Epoch 292/1000
2023-10-01 10:52:28.041 
Epoch 292/1000 
	 loss: 178.5415, MinusLogProbMetric: 178.5415, val_loss: 180.9227, val_MinusLogProbMetric: 180.9227

Epoch 292: val_loss did not improve from 180.71111
196/196 - 26s - loss: 178.5415 - MinusLogProbMetric: 178.5415 - val_loss: 180.9227 - val_MinusLogProbMetric: 180.9227 - lr: 5.0000e-04 - 26s/epoch - 134ms/step
Epoch 293/1000
2023-10-01 10:52:52.643 
Epoch 293/1000 
	 loss: 178.3965, MinusLogProbMetric: 178.3965, val_loss: 180.8197, val_MinusLogProbMetric: 180.8197

Epoch 293: val_loss did not improve from 180.71111
196/196 - 25s - loss: 178.3965 - MinusLogProbMetric: 178.3965 - val_loss: 180.8197 - val_MinusLogProbMetric: 180.8197 - lr: 5.0000e-04 - 25s/epoch - 126ms/step
Epoch 294/1000
2023-10-01 10:53:15.253 
Epoch 294/1000 
	 loss: 178.4484, MinusLogProbMetric: 178.4484, val_loss: 180.9216, val_MinusLogProbMetric: 180.9216

Epoch 294: val_loss did not improve from 180.71111
196/196 - 23s - loss: 178.4484 - MinusLogProbMetric: 178.4484 - val_loss: 180.9216 - val_MinusLogProbMetric: 180.9216 - lr: 5.0000e-04 - 23s/epoch - 115ms/step
Epoch 295/1000
2023-10-01 10:53:41.732 
Epoch 295/1000 
	 loss: 178.3873, MinusLogProbMetric: 178.3873, val_loss: 181.1597, val_MinusLogProbMetric: 181.1597

Epoch 295: val_loss did not improve from 180.71111
196/196 - 26s - loss: 178.3873 - MinusLogProbMetric: 178.3873 - val_loss: 181.1597 - val_MinusLogProbMetric: 181.1597 - lr: 5.0000e-04 - 26s/epoch - 135ms/step
Epoch 296/1000
2023-10-01 10:54:07.773 
Epoch 296/1000 
	 loss: 178.4265, MinusLogProbMetric: 178.4265, val_loss: 180.9222, val_MinusLogProbMetric: 180.9222

Epoch 296: val_loss did not improve from 180.71111
196/196 - 26s - loss: 178.4265 - MinusLogProbMetric: 178.4265 - val_loss: 180.9222 - val_MinusLogProbMetric: 180.9222 - lr: 5.0000e-04 - 26s/epoch - 133ms/step
Epoch 297/1000
2023-10-01 10:54:31.191 
Epoch 297/1000 
	 loss: 178.4307, MinusLogProbMetric: 178.4307, val_loss: 181.1231, val_MinusLogProbMetric: 181.1231

Epoch 297: val_loss did not improve from 180.71111
196/196 - 23s - loss: 178.4307 - MinusLogProbMetric: 178.4307 - val_loss: 181.1231 - val_MinusLogProbMetric: 181.1231 - lr: 5.0000e-04 - 23s/epoch - 119ms/step
Epoch 298/1000
2023-10-01 10:54:54.509 
Epoch 298/1000 
	 loss: 178.4147, MinusLogProbMetric: 178.4147, val_loss: 180.9507, val_MinusLogProbMetric: 180.9507

Epoch 298: val_loss did not improve from 180.71111
196/196 - 23s - loss: 178.4147 - MinusLogProbMetric: 178.4147 - val_loss: 180.9507 - val_MinusLogProbMetric: 180.9507 - lr: 5.0000e-04 - 23s/epoch - 119ms/step
Epoch 299/1000
2023-10-01 10:55:18.373 
Epoch 299/1000 
	 loss: 178.3940, MinusLogProbMetric: 178.3940, val_loss: 180.8921, val_MinusLogProbMetric: 180.8921

Epoch 299: val_loss did not improve from 180.71111
196/196 - 24s - loss: 178.3940 - MinusLogProbMetric: 178.3940 - val_loss: 180.8921 - val_MinusLogProbMetric: 180.8921 - lr: 5.0000e-04 - 24s/epoch - 121ms/step
Epoch 300/1000
2023-10-01 10:55:43.832 
Epoch 300/1000 
	 loss: 178.4632, MinusLogProbMetric: 178.4632, val_loss: 187.3769, val_MinusLogProbMetric: 187.3769

Epoch 300: val_loss did not improve from 180.71111
196/196 - 25s - loss: 178.4632 - MinusLogProbMetric: 178.4632 - val_loss: 187.3769 - val_MinusLogProbMetric: 187.3769 - lr: 5.0000e-04 - 25s/epoch - 130ms/step
Epoch 301/1000
2023-10-01 10:56:09.339 
Epoch 301/1000 
	 loss: 179.0658, MinusLogProbMetric: 179.0658, val_loss: 180.9758, val_MinusLogProbMetric: 180.9758

Epoch 301: val_loss did not improve from 180.71111
196/196 - 25s - loss: 179.0658 - MinusLogProbMetric: 179.0658 - val_loss: 180.9758 - val_MinusLogProbMetric: 180.9758 - lr: 5.0000e-04 - 25s/epoch - 130ms/step
Epoch 302/1000
2023-10-01 10:56:34.941 
Epoch 302/1000 
	 loss: 178.3093, MinusLogProbMetric: 178.3093, val_loss: 180.9390, val_MinusLogProbMetric: 180.9390

Epoch 302: val_loss did not improve from 180.71111
196/196 - 26s - loss: 178.3093 - MinusLogProbMetric: 178.3093 - val_loss: 180.9390 - val_MinusLogProbMetric: 180.9390 - lr: 5.0000e-04 - 26s/epoch - 131ms/step
Epoch 303/1000
2023-10-01 10:56:59.744 
Epoch 303/1000 
	 loss: 178.3138, MinusLogProbMetric: 178.3138, val_loss: 180.9420, val_MinusLogProbMetric: 180.9420

Epoch 303: val_loss did not improve from 180.71111
196/196 - 25s - loss: 178.3138 - MinusLogProbMetric: 178.3138 - val_loss: 180.9420 - val_MinusLogProbMetric: 180.9420 - lr: 5.0000e-04 - 25s/epoch - 127ms/step
Epoch 304/1000
2023-10-01 10:57:24.970 
Epoch 304/1000 
	 loss: 178.3913, MinusLogProbMetric: 178.3913, val_loss: 181.2952, val_MinusLogProbMetric: 181.2952

Epoch 304: val_loss did not improve from 180.71111
196/196 - 25s - loss: 178.3913 - MinusLogProbMetric: 178.3913 - val_loss: 181.2952 - val_MinusLogProbMetric: 181.2952 - lr: 5.0000e-04 - 25s/epoch - 128ms/step
Epoch 305/1000
2023-10-01 10:57:50.030 
Epoch 305/1000 
	 loss: 178.3616, MinusLogProbMetric: 178.3616, val_loss: 180.8812, val_MinusLogProbMetric: 180.8812

Epoch 305: val_loss did not improve from 180.71111
196/196 - 25s - loss: 178.3616 - MinusLogProbMetric: 178.3616 - val_loss: 180.8812 - val_MinusLogProbMetric: 180.8812 - lr: 5.0000e-04 - 25s/epoch - 128ms/step
Epoch 306/1000
2023-10-01 10:58:15.403 
Epoch 306/1000 
	 loss: 178.4637, MinusLogProbMetric: 178.4637, val_loss: 181.6550, val_MinusLogProbMetric: 181.6550

Epoch 306: val_loss did not improve from 180.71111
196/196 - 25s - loss: 178.4637 - MinusLogProbMetric: 178.4637 - val_loss: 181.6550 - val_MinusLogProbMetric: 181.6550 - lr: 5.0000e-04 - 25s/epoch - 129ms/step
Epoch 307/1000
2023-10-01 10:58:39.076 
Epoch 307/1000 
	 loss: 178.4895, MinusLogProbMetric: 178.4895, val_loss: 181.0118, val_MinusLogProbMetric: 181.0118

Epoch 307: val_loss did not improve from 180.71111
196/196 - 24s - loss: 178.4895 - MinusLogProbMetric: 178.4895 - val_loss: 181.0118 - val_MinusLogProbMetric: 181.0118 - lr: 5.0000e-04 - 24s/epoch - 121ms/step
Epoch 308/1000
2023-10-01 10:59:04.726 
Epoch 308/1000 
	 loss: 178.3420, MinusLogProbMetric: 178.3420, val_loss: 180.9974, val_MinusLogProbMetric: 180.9974

Epoch 308: val_loss did not improve from 180.71111
196/196 - 26s - loss: 178.3420 - MinusLogProbMetric: 178.3420 - val_loss: 180.9974 - val_MinusLogProbMetric: 180.9974 - lr: 5.0000e-04 - 26s/epoch - 131ms/step
Epoch 309/1000
2023-10-01 10:59:29.299 
Epoch 309/1000 
	 loss: 178.4228, MinusLogProbMetric: 178.4228, val_loss: 180.9635, val_MinusLogProbMetric: 180.9635

Epoch 309: val_loss did not improve from 180.71111
196/196 - 25s - loss: 178.4228 - MinusLogProbMetric: 178.4228 - val_loss: 180.9635 - val_MinusLogProbMetric: 180.9635 - lr: 5.0000e-04 - 25s/epoch - 125ms/step
Epoch 310/1000
2023-10-01 10:59:54.602 
Epoch 310/1000 
	 loss: 178.4920, MinusLogProbMetric: 178.4920, val_loss: 181.1050, val_MinusLogProbMetric: 181.1050

Epoch 310: val_loss did not improve from 180.71111
196/196 - 25s - loss: 178.4920 - MinusLogProbMetric: 178.4920 - val_loss: 181.1050 - val_MinusLogProbMetric: 181.1050 - lr: 5.0000e-04 - 25s/epoch - 129ms/step
Epoch 311/1000
2023-10-01 11:00:17.626 
Epoch 311/1000 
	 loss: 178.3592, MinusLogProbMetric: 178.3592, val_loss: 181.1353, val_MinusLogProbMetric: 181.1353

Epoch 311: val_loss did not improve from 180.71111
196/196 - 23s - loss: 178.3592 - MinusLogProbMetric: 178.3592 - val_loss: 181.1353 - val_MinusLogProbMetric: 181.1353 - lr: 5.0000e-04 - 23s/epoch - 118ms/step
Epoch 312/1000
2023-10-01 11:00:42.774 
Epoch 312/1000 
	 loss: 177.9609, MinusLogProbMetric: 177.9609, val_loss: 180.7366, val_MinusLogProbMetric: 180.7366

Epoch 312: val_loss did not improve from 180.71111
196/196 - 25s - loss: 177.9609 - MinusLogProbMetric: 177.9609 - val_loss: 180.7366 - val_MinusLogProbMetric: 180.7366 - lr: 2.5000e-04 - 25s/epoch - 128ms/step
Epoch 313/1000
2023-10-01 11:01:07.352 
Epoch 313/1000 
	 loss: 177.9274, MinusLogProbMetric: 177.9274, val_loss: 180.7042, val_MinusLogProbMetric: 180.7042

Epoch 313: val_loss improved from 180.71111 to 180.70419, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 25s - loss: 177.9274 - MinusLogProbMetric: 177.9274 - val_loss: 180.7042 - val_MinusLogProbMetric: 180.7042 - lr: 2.5000e-04 - 25s/epoch - 126ms/step
Epoch 314/1000
2023-10-01 11:01:31.753 
Epoch 314/1000 
	 loss: 177.9229, MinusLogProbMetric: 177.9229, val_loss: 180.7229, val_MinusLogProbMetric: 180.7229

Epoch 314: val_loss did not improve from 180.70419
196/196 - 24s - loss: 177.9229 - MinusLogProbMetric: 177.9229 - val_loss: 180.7229 - val_MinusLogProbMetric: 180.7229 - lr: 2.5000e-04 - 24s/epoch - 124ms/step
Epoch 315/1000
2023-10-01 11:01:54.627 
Epoch 315/1000 
	 loss: 177.9439, MinusLogProbMetric: 177.9439, val_loss: 180.6841, val_MinusLogProbMetric: 180.6841

Epoch 315: val_loss improved from 180.70419 to 180.68410, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 23s - loss: 177.9439 - MinusLogProbMetric: 177.9439 - val_loss: 180.6841 - val_MinusLogProbMetric: 180.6841 - lr: 2.5000e-04 - 23s/epoch - 118ms/step
Epoch 316/1000
2023-10-01 11:02:20.361 
Epoch 316/1000 
	 loss: 177.9208, MinusLogProbMetric: 177.9208, val_loss: 180.6886, val_MinusLogProbMetric: 180.6886

Epoch 316: val_loss did not improve from 180.68410
196/196 - 26s - loss: 177.9208 - MinusLogProbMetric: 177.9208 - val_loss: 180.6886 - val_MinusLogProbMetric: 180.6886 - lr: 2.5000e-04 - 26s/epoch - 130ms/step
Epoch 317/1000
2023-10-01 11:02:46.272 
Epoch 317/1000 
	 loss: 177.8968, MinusLogProbMetric: 177.8968, val_loss: 181.1050, val_MinusLogProbMetric: 181.1050

Epoch 317: val_loss did not improve from 180.68410
196/196 - 26s - loss: 177.8968 - MinusLogProbMetric: 177.8968 - val_loss: 181.1050 - val_MinusLogProbMetric: 181.1050 - lr: 2.5000e-04 - 26s/epoch - 132ms/step
Epoch 318/1000
2023-10-01 11:03:12.341 
Epoch 318/1000 
	 loss: 177.9678, MinusLogProbMetric: 177.9678, val_loss: 180.7913, val_MinusLogProbMetric: 180.7913

Epoch 318: val_loss did not improve from 180.68410
196/196 - 26s - loss: 177.9678 - MinusLogProbMetric: 177.9678 - val_loss: 180.7913 - val_MinusLogProbMetric: 180.7913 - lr: 2.5000e-04 - 26s/epoch - 133ms/step
Epoch 319/1000
2023-10-01 11:03:37.420 
Epoch 319/1000 
	 loss: 177.9562, MinusLogProbMetric: 177.9562, val_loss: 180.6992, val_MinusLogProbMetric: 180.6992

Epoch 319: val_loss did not improve from 180.68410
196/196 - 25s - loss: 177.9562 - MinusLogProbMetric: 177.9562 - val_loss: 180.6992 - val_MinusLogProbMetric: 180.6992 - lr: 2.5000e-04 - 25s/epoch - 128ms/step
Epoch 320/1000
2023-10-01 11:04:03.550 
Epoch 320/1000 
	 loss: 177.9100, MinusLogProbMetric: 177.9100, val_loss: 180.8736, val_MinusLogProbMetric: 180.8736

Epoch 320: val_loss did not improve from 180.68410
196/196 - 26s - loss: 177.9100 - MinusLogProbMetric: 177.9100 - val_loss: 180.8736 - val_MinusLogProbMetric: 180.8736 - lr: 2.5000e-04 - 26s/epoch - 133ms/step
Epoch 321/1000
2023-10-01 11:04:28.152 
Epoch 321/1000 
	 loss: 177.9431, MinusLogProbMetric: 177.9431, val_loss: 180.8156, val_MinusLogProbMetric: 180.8156

Epoch 321: val_loss did not improve from 180.68410
196/196 - 25s - loss: 177.9431 - MinusLogProbMetric: 177.9431 - val_loss: 180.8156 - val_MinusLogProbMetric: 180.8156 - lr: 2.5000e-04 - 25s/epoch - 125ms/step
Epoch 322/1000
2023-10-01 11:04:51.353 
Epoch 322/1000 
	 loss: 178.1741, MinusLogProbMetric: 178.1741, val_loss: 180.8203, val_MinusLogProbMetric: 180.8203

Epoch 322: val_loss did not improve from 180.68410
196/196 - 23s - loss: 178.1741 - MinusLogProbMetric: 178.1741 - val_loss: 180.8203 - val_MinusLogProbMetric: 180.8203 - lr: 2.5000e-04 - 23s/epoch - 118ms/step
Epoch 323/1000
2023-10-01 11:05:16.990 
Epoch 323/1000 
	 loss: 177.9293, MinusLogProbMetric: 177.9293, val_loss: 180.7216, val_MinusLogProbMetric: 180.7216

Epoch 323: val_loss did not improve from 180.68410
196/196 - 26s - loss: 177.9293 - MinusLogProbMetric: 177.9293 - val_loss: 180.7216 - val_MinusLogProbMetric: 180.7216 - lr: 2.5000e-04 - 26s/epoch - 131ms/step
Epoch 324/1000
2023-10-01 11:05:42.535 
Epoch 324/1000 
	 loss: 177.8882, MinusLogProbMetric: 177.8882, val_loss: 180.7947, val_MinusLogProbMetric: 180.7947

Epoch 324: val_loss did not improve from 180.68410
196/196 - 26s - loss: 177.8882 - MinusLogProbMetric: 177.8882 - val_loss: 180.7947 - val_MinusLogProbMetric: 180.7947 - lr: 2.5000e-04 - 26s/epoch - 130ms/step
Epoch 325/1000
2023-10-01 11:06:06.830 
Epoch 325/1000 
	 loss: 177.9481, MinusLogProbMetric: 177.9481, val_loss: 180.7235, val_MinusLogProbMetric: 180.7235

Epoch 325: val_loss did not improve from 180.68410
196/196 - 24s - loss: 177.9481 - MinusLogProbMetric: 177.9481 - val_loss: 180.7235 - val_MinusLogProbMetric: 180.7235 - lr: 2.5000e-04 - 24s/epoch - 124ms/step
Epoch 326/1000
2023-10-01 11:06:30.081 
Epoch 326/1000 
	 loss: 177.9371, MinusLogProbMetric: 177.9371, val_loss: 180.8300, val_MinusLogProbMetric: 180.8300

Epoch 326: val_loss did not improve from 180.68410
196/196 - 23s - loss: 177.9371 - MinusLogProbMetric: 177.9371 - val_loss: 180.8300 - val_MinusLogProbMetric: 180.8300 - lr: 2.5000e-04 - 23s/epoch - 119ms/step
Epoch 327/1000
2023-10-01 11:06:52.691 
Epoch 327/1000 
	 loss: 178.0590, MinusLogProbMetric: 178.0590, val_loss: 180.8629, val_MinusLogProbMetric: 180.8629

Epoch 327: val_loss did not improve from 180.68410
196/196 - 23s - loss: 178.0590 - MinusLogProbMetric: 178.0590 - val_loss: 180.8629 - val_MinusLogProbMetric: 180.8629 - lr: 2.5000e-04 - 23s/epoch - 115ms/step
Epoch 328/1000
2023-10-01 11:07:17.963 
Epoch 328/1000 
	 loss: 177.8756, MinusLogProbMetric: 177.8756, val_loss: 180.7140, val_MinusLogProbMetric: 180.7140

Epoch 328: val_loss did not improve from 180.68410
196/196 - 25s - loss: 177.8756 - MinusLogProbMetric: 177.8756 - val_loss: 180.7140 - val_MinusLogProbMetric: 180.7140 - lr: 2.5000e-04 - 25s/epoch - 129ms/step
Epoch 329/1000
2023-10-01 11:07:42.253 
Epoch 329/1000 
	 loss: 177.8952, MinusLogProbMetric: 177.8952, val_loss: 181.1739, val_MinusLogProbMetric: 181.1739

Epoch 329: val_loss did not improve from 180.68410
196/196 - 24s - loss: 177.8952 - MinusLogProbMetric: 177.8952 - val_loss: 181.1739 - val_MinusLogProbMetric: 181.1739 - lr: 2.5000e-04 - 24s/epoch - 124ms/step
Epoch 330/1000
2023-10-01 11:08:07.953 
Epoch 330/1000 
	 loss: 177.9312, MinusLogProbMetric: 177.9312, val_loss: 180.7533, val_MinusLogProbMetric: 180.7533

Epoch 330: val_loss did not improve from 180.68410
196/196 - 26s - loss: 177.9312 - MinusLogProbMetric: 177.9312 - val_loss: 180.7533 - val_MinusLogProbMetric: 180.7533 - lr: 2.5000e-04 - 26s/epoch - 131ms/step
Epoch 331/1000
2023-10-01 11:08:30.129 
Epoch 331/1000 
	 loss: 177.9307, MinusLogProbMetric: 177.9307, val_loss: 180.6784, val_MinusLogProbMetric: 180.6784

Epoch 331: val_loss improved from 180.68410 to 180.67844, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_284/weights/best_weights.h5
196/196 - 23s - loss: 177.9307 - MinusLogProbMetric: 177.9307 - val_loss: 180.6784 - val_MinusLogProbMetric: 180.6784 - lr: 2.5000e-04 - 23s/epoch - 116ms/step
Epoch 332/1000
2023-10-01 11:08:55.484 
Epoch 332/1000 
	 loss: 177.8980, MinusLogProbMetric: 177.8980, val_loss: 181.0318, val_MinusLogProbMetric: 181.0318

Epoch 332: val_loss did not improve from 180.67844
196/196 - 25s - loss: 177.8980 - MinusLogProbMetric: 177.8980 - val_loss: 181.0318 - val_MinusLogProbMetric: 181.0318 - lr: 2.5000e-04 - 25s/epoch - 126ms/step
Epoch 333/1000
2023-10-01 11:09:20.272 
Epoch 333/1000 
	 loss: 177.9077, MinusLogProbMetric: 177.9077, val_loss: 180.9841, val_MinusLogProbMetric: 180.9841

Epoch 333: val_loss did not improve from 180.67844
196/196 - 25s - loss: 177.9077 - MinusLogProbMetric: 177.9077 - val_loss: 180.9841 - val_MinusLogProbMetric: 180.9841 - lr: 2.5000e-04 - 25s/epoch - 126ms/step
Epoch 334/1000
2023-10-01 11:09:43.940 
Epoch 334/1000 
	 loss: 177.9671, MinusLogProbMetric: 177.9671, val_loss: 180.8918, val_MinusLogProbMetric: 180.8918

Epoch 334: val_loss did not improve from 180.67844
196/196 - 24s - loss: 177.9671 - MinusLogProbMetric: 177.9671 - val_loss: 180.8918 - val_MinusLogProbMetric: 180.8918 - lr: 2.5000e-04 - 24s/epoch - 121ms/step
Epoch 335/1000
2023-10-01 11:10:08.612 
Epoch 335/1000 
	 loss: 177.9315, MinusLogProbMetric: 177.9315, val_loss: 180.7519, val_MinusLogProbMetric: 180.7519

Epoch 335: val_loss did not improve from 180.67844
196/196 - 25s - loss: 177.9315 - MinusLogProbMetric: 177.9315 - val_loss: 180.7519 - val_MinusLogProbMetric: 180.7519 - lr: 2.5000e-04 - 25s/epoch - 126ms/step
Epoch 336/1000
2023-10-01 11:10:33.644 
Epoch 336/1000 
	 loss: 177.8899, MinusLogProbMetric: 177.8899, val_loss: 180.7507, val_MinusLogProbMetric: 180.7507

Epoch 336: val_loss did not improve from 180.67844
196/196 - 25s - loss: 177.8899 - MinusLogProbMetric: 177.8899 - val_loss: 180.7507 - val_MinusLogProbMetric: 180.7507 - lr: 2.5000e-04 - 25s/epoch - 128ms/step
Epoch 337/1000
2023-10-01 11:10:59.197 
Epoch 337/1000 
	 loss: 177.8859, MinusLogProbMetric: 177.8859, val_loss: 180.7717, val_MinusLogProbMetric: 180.7717

Epoch 337: val_loss did not improve from 180.67844
196/196 - 26s - loss: 177.8859 - MinusLogProbMetric: 177.8859 - val_loss: 180.7717 - val_MinusLogProbMetric: 180.7717 - lr: 2.5000e-04 - 26s/epoch - 130ms/step
Epoch 338/1000
2023-10-01 11:11:22.156 
Epoch 338/1000 
	 loss: 177.9028, MinusLogProbMetric: 177.9028, val_loss: 180.7196, val_MinusLogProbMetric: 180.7196

Epoch 338: val_loss did not improve from 180.67844
196/196 - 23s - loss: 177.9028 - MinusLogProbMetric: 177.9028 - val_loss: 180.7196 - val_MinusLogProbMetric: 180.7196 - lr: 2.5000e-04 - 23s/epoch - 117ms/step
Epoch 339/1000
2023-10-01 11:11:46.618 
Epoch 339/1000 
	 loss: 177.8985, MinusLogProbMetric: 177.8985, val_loss: 180.7470, val_MinusLogProbMetric: 180.7470

Epoch 339: val_loss did not improve from 180.67844
196/196 - 24s - loss: 177.8985 - MinusLogProbMetric: 177.8985 - val_loss: 180.7470 - val_MinusLogProbMetric: 180.7470 - lr: 2.5000e-04 - 24s/epoch - 125ms/step
Epoch 340/1000
2023-10-01 11:12:10.673 
Epoch 340/1000 
	 loss: 177.9044, MinusLogProbMetric: 177.9044, val_loss: 180.8385, val_MinusLogProbMetric: 180.8385

Epoch 340: val_loss did not improve from 180.67844
196/196 - 24s - loss: 177.9044 - MinusLogProbMetric: 177.9044 - val_loss: 180.8385 - val_MinusLogProbMetric: 180.8385 - lr: 2.5000e-04 - 24s/epoch - 123ms/step
Epoch 341/1000
2023-10-01 11:12:36.172 
Epoch 341/1000 
	 loss: 177.9288, MinusLogProbMetric: 177.9288, val_loss: 180.8542, val_MinusLogProbMetric: 180.8542

Epoch 341: val_loss did not improve from 180.67844
196/196 - 25s - loss: 177.9288 - MinusLogProbMetric: 177.9288 - val_loss: 180.8542 - val_MinusLogProbMetric: 180.8542 - lr: 2.5000e-04 - 25s/epoch - 130ms/step
Epoch 342/1000
2023-10-01 11:13:00.988 
Epoch 342/1000 
	 loss: 177.8922, MinusLogProbMetric: 177.8922, val_loss: 181.0542, val_MinusLogProbMetric: 181.0542

Epoch 342: val_loss did not improve from 180.67844
196/196 - 25s - loss: 177.8922 - MinusLogProbMetric: 177.8922 - val_loss: 181.0542 - val_MinusLogProbMetric: 181.0542 - lr: 2.5000e-04 - 25s/epoch - 127ms/step
Epoch 343/1000
2023-10-01 11:13:26.132 
Epoch 343/1000 
	 loss: 177.8827, MinusLogProbMetric: 177.8827, val_loss: 181.0237, val_MinusLogProbMetric: 181.0237

Epoch 343: val_loss did not improve from 180.67844
196/196 - 25s - loss: 177.8827 - MinusLogProbMetric: 177.8827 - val_loss: 181.0237 - val_MinusLogProbMetric: 181.0237 - lr: 2.5000e-04 - 25s/epoch - 128ms/step
Epoch 344/1000
2023-10-01 11:13:50.281 
Epoch 344/1000 
	 loss: 177.8786, MinusLogProbMetric: 177.8786, val_loss: 180.7918, val_MinusLogProbMetric: 180.7918

Epoch 344: val_loss did not improve from 180.67844
196/196 - 24s - loss: 177.8786 - MinusLogProbMetric: 177.8786 - val_loss: 180.7918 - val_MinusLogProbMetric: 180.7918 - lr: 2.5000e-04 - 24s/epoch - 123ms/step
Epoch 345/1000
2023-10-01 11:14:13.692 
Epoch 345/1000 
	 loss: 177.8978, MinusLogProbMetric: 177.8978, val_loss: 181.0545, val_MinusLogProbMetric: 181.0545

Epoch 345: val_loss did not improve from 180.67844
196/196 - 23s - loss: 177.8978 - MinusLogProbMetric: 177.8978 - val_loss: 181.0545 - val_MinusLogProbMetric: 181.0545 - lr: 2.5000e-04 - 23s/epoch - 119ms/step
Epoch 346/1000
2023-10-01 11:14:36.642 
Epoch 346/1000 
	 loss: 177.9341, MinusLogProbMetric: 177.9341, val_loss: 180.8129, val_MinusLogProbMetric: 180.8129

Epoch 346: val_loss did not improve from 180.67844
196/196 - 23s - loss: 177.9341 - MinusLogProbMetric: 177.9341 - val_loss: 180.8129 - val_MinusLogProbMetric: 180.8129 - lr: 2.5000e-04 - 23s/epoch - 117ms/step
Epoch 347/1000
2023-10-01 11:14:58.410 
Epoch 347/1000 
	 loss: 177.9262, MinusLogProbMetric: 177.9262, val_loss: 180.7503, val_MinusLogProbMetric: 180.7503

Epoch 347: val_loss did not improve from 180.67844
196/196 - 22s - loss: 177.9262 - MinusLogProbMetric: 177.9262 - val_loss: 180.7503 - val_MinusLogProbMetric: 180.7503 - lr: 2.5000e-04 - 22s/epoch - 111ms/step
Epoch 348/1000
2023-10-01 11:15:22.274 
Epoch 348/1000 
	 loss: 177.8925, MinusLogProbMetric: 177.8925, val_loss: 181.5032, val_MinusLogProbMetric: 181.5032

Epoch 348: val_loss did not improve from 180.67844
196/196 - 24s - loss: 177.8925 - MinusLogProbMetric: 177.8925 - val_loss: 181.5032 - val_MinusLogProbMetric: 181.5032 - lr: 2.5000e-04 - 24s/epoch - 122ms/step
Epoch 349/1000
2023-10-01 11:15:46.141 
Epoch 349/1000 
	 loss: 177.8869, MinusLogProbMetric: 177.8869, val_loss: 180.8468, val_MinusLogProbMetric: 180.8468

Epoch 349: val_loss did not improve from 180.67844
196/196 - 24s - loss: 177.8869 - MinusLogProbMetric: 177.8869 - val_loss: 180.8468 - val_MinusLogProbMetric: 180.8468 - lr: 2.5000e-04 - 24s/epoch - 122ms/step
Epoch 350/1000
2023-10-01 11:16:10.196 
Epoch 350/1000 
	 loss: 177.8949, MinusLogProbMetric: 177.8949, val_loss: 180.7540, val_MinusLogProbMetric: 180.7540

Epoch 350: val_loss did not improve from 180.67844
196/196 - 24s - loss: 177.8949 - MinusLogProbMetric: 177.8949 - val_loss: 180.7540 - val_MinusLogProbMetric: 180.7540 - lr: 2.5000e-04 - 24s/epoch - 123ms/step
Epoch 351/1000
2023-10-01 11:16:35.672 
Epoch 351/1000 
	 loss: 177.9819, MinusLogProbMetric: 177.9819, val_loss: 180.9403, val_MinusLogProbMetric: 180.9403

Epoch 351: val_loss did not improve from 180.67844
196/196 - 25s - loss: 177.9819 - MinusLogProbMetric: 177.9819 - val_loss: 180.9403 - val_MinusLogProbMetric: 180.9403 - lr: 2.5000e-04 - 25s/epoch - 130ms/step
Epoch 352/1000
2023-10-01 11:16:58.821 
Epoch 352/1000 
	 loss: 177.9141, MinusLogProbMetric: 177.9141, val_loss: 180.7772, val_MinusLogProbMetric: 180.7772

Epoch 352: val_loss did not improve from 180.67844
196/196 - 23s - loss: 177.9141 - MinusLogProbMetric: 177.9141 - val_loss: 180.7772 - val_MinusLogProbMetric: 180.7772 - lr: 2.5000e-04 - 23s/epoch - 118ms/step
Epoch 353/1000
2023-10-01 11:17:22.213 
Epoch 353/1000 
	 loss: 177.8551, MinusLogProbMetric: 177.8551, val_loss: 180.7457, val_MinusLogProbMetric: 180.7457

Epoch 353: val_loss did not improve from 180.67844
196/196 - 23s - loss: 177.8551 - MinusLogProbMetric: 177.8551 - val_loss: 180.7457 - val_MinusLogProbMetric: 180.7457 - lr: 2.5000e-04 - 23s/epoch - 119ms/step
Epoch 354/1000
2023-10-01 11:17:47.270 
Epoch 354/1000 
	 loss: 177.8542, MinusLogProbMetric: 177.8542, val_loss: 180.8659, val_MinusLogProbMetric: 180.8659

Epoch 354: val_loss did not improve from 180.67844
196/196 - 25s - loss: 177.8542 - MinusLogProbMetric: 177.8542 - val_loss: 180.8659 - val_MinusLogProbMetric: 180.8659 - lr: 2.5000e-04 - 25s/epoch - 128ms/step
Epoch 355/1000
2023-10-01 11:18:12.040 
Epoch 355/1000 
	 loss: 177.8744, MinusLogProbMetric: 177.8744, val_loss: 180.9982, val_MinusLogProbMetric: 180.9982

Epoch 355: val_loss did not improve from 180.67844
196/196 - 25s - loss: 177.8744 - MinusLogProbMetric: 177.8744 - val_loss: 180.9982 - val_MinusLogProbMetric: 180.9982 - lr: 2.5000e-04 - 25s/epoch - 126ms/step
Epoch 356/1000
2023-10-01 11:18:36.524 
Epoch 356/1000 
	 loss: 177.8836, MinusLogProbMetric: 177.8836, val_loss: 180.9033, val_MinusLogProbMetric: 180.9033

Epoch 356: val_loss did not improve from 180.67844
196/196 - 24s - loss: 177.8836 - MinusLogProbMetric: 177.8836 - val_loss: 180.9033 - val_MinusLogProbMetric: 180.9033 - lr: 2.5000e-04 - 24s/epoch - 125ms/step
Epoch 357/1000
2023-10-01 11:18:59.484 
Epoch 357/1000 
	 loss: 177.9008, MinusLogProbMetric: 177.9008, val_loss: 180.8842, val_MinusLogProbMetric: 180.8842

Epoch 357: val_loss did not improve from 180.67844
196/196 - 23s - loss: 177.9008 - MinusLogProbMetric: 177.9008 - val_loss: 180.8842 - val_MinusLogProbMetric: 180.8842 - lr: 2.5000e-04 - 23s/epoch - 117ms/step
Epoch 358/1000
2023-10-01 11:19:24.664 
Epoch 358/1000 
	 loss: 179.0795, MinusLogProbMetric: 179.0795, val_loss: 181.7800, val_MinusLogProbMetric: 181.7800

Epoch 358: val_loss did not improve from 180.67844
196/196 - 25s - loss: 179.0795 - MinusLogProbMetric: 179.0795 - val_loss: 181.7800 - val_MinusLogProbMetric: 181.7800 - lr: 2.5000e-04 - 25s/epoch - 128ms/step
Epoch 359/1000
2023-10-01 11:19:50.585 
Epoch 359/1000 
	 loss: 178.3964, MinusLogProbMetric: 178.3964, val_loss: 181.0072, val_MinusLogProbMetric: 181.0072

Epoch 359: val_loss did not improve from 180.67844
196/196 - 26s - loss: 178.3964 - MinusLogProbMetric: 178.3964 - val_loss: 181.0072 - val_MinusLogProbMetric: 181.0072 - lr: 2.5000e-04 - 26s/epoch - 132ms/step
Epoch 360/1000
2023-10-01 11:20:14.821 
Epoch 360/1000 
	 loss: 178.0330, MinusLogProbMetric: 178.0330, val_loss: 181.1703, val_MinusLogProbMetric: 181.1703

Epoch 360: val_loss did not improve from 180.67844
196/196 - 24s - loss: 178.0330 - MinusLogProbMetric: 178.0330 - val_loss: 181.1703 - val_MinusLogProbMetric: 181.1703 - lr: 2.5000e-04 - 24s/epoch - 124ms/step
Epoch 361/1000
2023-10-01 11:20:35.789 
Epoch 361/1000 
	 loss: 178.0432, MinusLogProbMetric: 178.0432, val_loss: 180.8144, val_MinusLogProbMetric: 180.8144

Epoch 361: val_loss did not improve from 180.67844
196/196 - 21s - loss: 178.0432 - MinusLogProbMetric: 178.0432 - val_loss: 180.8144 - val_MinusLogProbMetric: 180.8144 - lr: 2.5000e-04 - 21s/epoch - 107ms/step
Epoch 362/1000
2023-10-01 11:20:55.615 
Epoch 362/1000 
	 loss: 177.9704, MinusLogProbMetric: 177.9704, val_loss: 181.2892, val_MinusLogProbMetric: 181.2892

Epoch 362: val_loss did not improve from 180.67844
196/196 - 20s - loss: 177.9704 - MinusLogProbMetric: 177.9704 - val_loss: 181.2892 - val_MinusLogProbMetric: 181.2892 - lr: 2.5000e-04 - 20s/epoch - 101ms/step
Epoch 363/1000
2023-10-01 11:21:14.948 
Epoch 363/1000 
	 loss: 177.9902, MinusLogProbMetric: 177.9902, val_loss: 180.7567, val_MinusLogProbMetric: 180.7567

Epoch 363: val_loss did not improve from 180.67844
196/196 - 19s - loss: 177.9902 - MinusLogProbMetric: 177.9902 - val_loss: 180.7567 - val_MinusLogProbMetric: 180.7567 - lr: 2.5000e-04 - 19s/epoch - 99ms/step
Epoch 364/1000
2023-10-01 11:21:35.247 
Epoch 364/1000 
	 loss: 177.9006, MinusLogProbMetric: 177.9006, val_loss: 180.8051, val_MinusLogProbMetric: 180.8051

Epoch 364: val_loss did not improve from 180.67844
196/196 - 20s - loss: 177.9006 - MinusLogProbMetric: 177.9006 - val_loss: 180.8051 - val_MinusLogProbMetric: 180.8051 - lr: 2.5000e-04 - 20s/epoch - 104ms/step
Epoch 365/1000
2023-10-01 11:22:02.614 
Epoch 365/1000 
	 loss: 177.8939, MinusLogProbMetric: 177.8939, val_loss: 180.7312, val_MinusLogProbMetric: 180.7312

Epoch 365: val_loss did not improve from 180.67844
196/196 - 27s - loss: 177.8939 - MinusLogProbMetric: 177.8939 - val_loss: 180.7312 - val_MinusLogProbMetric: 180.7312 - lr: 2.5000e-04 - 27s/epoch - 140ms/step
Epoch 366/1000
2023-10-01 11:22:29.612 
Epoch 366/1000 
	 loss: 177.9050, MinusLogProbMetric: 177.9050, val_loss: 180.8080, val_MinusLogProbMetric: 180.8080

Epoch 366: val_loss did not improve from 180.67844
196/196 - 27s - loss: 177.9050 - MinusLogProbMetric: 177.9050 - val_loss: 180.8080 - val_MinusLogProbMetric: 180.8080 - lr: 2.5000e-04 - 27s/epoch - 138ms/step
Epoch 367/1000
2023-10-01 11:22:56.833 
Epoch 367/1000 
	 loss: 177.9096, MinusLogProbMetric: 177.9096, val_loss: 180.8310, val_MinusLogProbMetric: 180.8310

Epoch 367: val_loss did not improve from 180.67844
196/196 - 27s - loss: 177.9096 - MinusLogProbMetric: 177.9096 - val_loss: 180.8310 - val_MinusLogProbMetric: 180.8310 - lr: 2.5000e-04 - 27s/epoch - 139ms/step
Epoch 368/1000
2023-10-01 11:23:23.693 
Epoch 368/1000 
	 loss: 177.9068, MinusLogProbMetric: 177.9068, val_loss: 180.8285, val_MinusLogProbMetric: 180.8285

Epoch 368: val_loss did not improve from 180.67844
196/196 - 27s - loss: 177.9068 - MinusLogProbMetric: 177.9068 - val_loss: 180.8285 - val_MinusLogProbMetric: 180.8285 - lr: 2.5000e-04 - 27s/epoch - 137ms/step
Epoch 369/1000
2023-10-01 11:23:51.739 
Epoch 369/1000 
	 loss: 177.8605, MinusLogProbMetric: 177.8605, val_loss: 180.8949, val_MinusLogProbMetric: 180.8949

Epoch 369: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.8605 - MinusLogProbMetric: 177.8605 - val_loss: 180.8949 - val_MinusLogProbMetric: 180.8949 - lr: 2.5000e-04 - 28s/epoch - 143ms/step
Epoch 370/1000
2023-10-01 11:24:19.476 
Epoch 370/1000 
	 loss: 177.8804, MinusLogProbMetric: 177.8804, val_loss: 180.8224, val_MinusLogProbMetric: 180.8224

Epoch 370: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.8804 - MinusLogProbMetric: 177.8804 - val_loss: 180.8224 - val_MinusLogProbMetric: 180.8224 - lr: 2.5000e-04 - 28s/epoch - 142ms/step
Epoch 371/1000
2023-10-01 11:24:46.190 
Epoch 371/1000 
	 loss: 177.9334, MinusLogProbMetric: 177.9334, val_loss: 180.7275, val_MinusLogProbMetric: 180.7275

Epoch 371: val_loss did not improve from 180.67844
196/196 - 27s - loss: 177.9334 - MinusLogProbMetric: 177.9334 - val_loss: 180.7275 - val_MinusLogProbMetric: 180.7275 - lr: 2.5000e-04 - 27s/epoch - 136ms/step
Epoch 372/1000
2023-10-01 11:25:14.571 
Epoch 372/1000 
	 loss: 177.8517, MinusLogProbMetric: 177.8517, val_loss: 180.8181, val_MinusLogProbMetric: 180.8181

Epoch 372: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.8517 - MinusLogProbMetric: 177.8517 - val_loss: 180.8181 - val_MinusLogProbMetric: 180.8181 - lr: 2.5000e-04 - 28s/epoch - 145ms/step
Epoch 373/1000
2023-10-01 11:25:44.296 
Epoch 373/1000 
	 loss: 177.8290, MinusLogProbMetric: 177.8290, val_loss: 180.7327, val_MinusLogProbMetric: 180.7327

Epoch 373: val_loss did not improve from 180.67844
196/196 - 30s - loss: 177.8290 - MinusLogProbMetric: 177.8290 - val_loss: 180.7327 - val_MinusLogProbMetric: 180.7327 - lr: 2.5000e-04 - 30s/epoch - 152ms/step
Epoch 374/1000
2023-10-01 11:26:13.793 
Epoch 374/1000 
	 loss: 177.9277, MinusLogProbMetric: 177.9277, val_loss: 180.9342, val_MinusLogProbMetric: 180.9342

Epoch 374: val_loss did not improve from 180.67844
196/196 - 29s - loss: 177.9277 - MinusLogProbMetric: 177.9277 - val_loss: 180.9342 - val_MinusLogProbMetric: 180.9342 - lr: 2.5000e-04 - 29s/epoch - 150ms/step
Epoch 375/1000
2023-10-01 11:26:42.258 
Epoch 375/1000 
	 loss: 177.9944, MinusLogProbMetric: 177.9944, val_loss: 180.8817, val_MinusLogProbMetric: 180.8817

Epoch 375: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.9944 - MinusLogProbMetric: 177.9944 - val_loss: 180.8817 - val_MinusLogProbMetric: 180.8817 - lr: 2.5000e-04 - 28s/epoch - 145ms/step
Epoch 376/1000
2023-10-01 11:27:12.560 
Epoch 376/1000 
	 loss: 177.8145, MinusLogProbMetric: 177.8145, val_loss: 180.7981, val_MinusLogProbMetric: 180.7981

Epoch 376: val_loss did not improve from 180.67844
196/196 - 30s - loss: 177.8145 - MinusLogProbMetric: 177.8145 - val_loss: 180.7981 - val_MinusLogProbMetric: 180.7981 - lr: 2.5000e-04 - 30s/epoch - 154ms/step
Epoch 377/1000
2023-10-01 11:27:40.327 
Epoch 377/1000 
	 loss: 177.9760, MinusLogProbMetric: 177.9760, val_loss: 181.0659, val_MinusLogProbMetric: 181.0659

Epoch 377: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.9760 - MinusLogProbMetric: 177.9760 - val_loss: 181.0659 - val_MinusLogProbMetric: 181.0659 - lr: 2.5000e-04 - 28s/epoch - 142ms/step
Epoch 378/1000
2023-10-01 11:28:08.719 
Epoch 378/1000 
	 loss: 177.9488, MinusLogProbMetric: 177.9488, val_loss: 180.7946, val_MinusLogProbMetric: 180.7946

Epoch 378: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.9488 - MinusLogProbMetric: 177.9488 - val_loss: 180.7946 - val_MinusLogProbMetric: 180.7946 - lr: 2.5000e-04 - 28s/epoch - 145ms/step
Epoch 379/1000
2023-10-01 11:28:39.051 
Epoch 379/1000 
	 loss: 177.8653, MinusLogProbMetric: 177.8653, val_loss: 180.8263, val_MinusLogProbMetric: 180.8263

Epoch 379: val_loss did not improve from 180.67844
196/196 - 30s - loss: 177.8653 - MinusLogProbMetric: 177.8653 - val_loss: 180.8263 - val_MinusLogProbMetric: 180.8263 - lr: 2.5000e-04 - 30s/epoch - 155ms/step
Epoch 380/1000
2023-10-01 11:29:08.791 
Epoch 380/1000 
	 loss: 177.8809, MinusLogProbMetric: 177.8809, val_loss: 180.9899, val_MinusLogProbMetric: 180.9899

Epoch 380: val_loss did not improve from 180.67844
196/196 - 30s - loss: 177.8809 - MinusLogProbMetric: 177.8809 - val_loss: 180.9899 - val_MinusLogProbMetric: 180.9899 - lr: 2.5000e-04 - 30s/epoch - 152ms/step
Epoch 381/1000
2023-10-01 11:29:36.869 
Epoch 381/1000 
	 loss: 177.8728, MinusLogProbMetric: 177.8728, val_loss: 180.8319, val_MinusLogProbMetric: 180.8319

Epoch 381: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.8728 - MinusLogProbMetric: 177.8728 - val_loss: 180.8319 - val_MinusLogProbMetric: 180.8319 - lr: 2.5000e-04 - 28s/epoch - 143ms/step
Epoch 382/1000
2023-10-01 11:30:05.095 
Epoch 382/1000 
	 loss: 177.6337, MinusLogProbMetric: 177.6337, val_loss: 180.7092, val_MinusLogProbMetric: 180.7092

Epoch 382: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.6337 - MinusLogProbMetric: 177.6337 - val_loss: 180.7092 - val_MinusLogProbMetric: 180.7092 - lr: 1.2500e-04 - 28s/epoch - 144ms/step
Epoch 383/1000
2023-10-01 11:30:34.190 
Epoch 383/1000 
	 loss: 177.6098, MinusLogProbMetric: 177.6098, val_loss: 180.7602, val_MinusLogProbMetric: 180.7602

Epoch 383: val_loss did not improve from 180.67844
196/196 - 29s - loss: 177.6098 - MinusLogProbMetric: 177.6098 - val_loss: 180.7602 - val_MinusLogProbMetric: 180.7602 - lr: 1.2500e-04 - 29s/epoch - 148ms/step
Epoch 384/1000
2023-10-01 11:31:03.938 
Epoch 384/1000 
	 loss: 177.6031, MinusLogProbMetric: 177.6031, val_loss: 180.7546, val_MinusLogProbMetric: 180.7546

Epoch 384: val_loss did not improve from 180.67844
196/196 - 30s - loss: 177.6031 - MinusLogProbMetric: 177.6031 - val_loss: 180.7546 - val_MinusLogProbMetric: 180.7546 - lr: 1.2500e-04 - 30s/epoch - 152ms/step
Epoch 385/1000
2023-10-01 11:31:30.778 
Epoch 385/1000 
	 loss: 177.6098, MinusLogProbMetric: 177.6098, val_loss: 180.7735, val_MinusLogProbMetric: 180.7735

Epoch 385: val_loss did not improve from 180.67844
196/196 - 27s - loss: 177.6098 - MinusLogProbMetric: 177.6098 - val_loss: 180.7735 - val_MinusLogProbMetric: 180.7735 - lr: 1.2500e-04 - 27s/epoch - 137ms/step
Epoch 386/1000
2023-10-01 11:31:57.532 
Epoch 386/1000 
	 loss: 177.6023, MinusLogProbMetric: 177.6023, val_loss: 180.7294, val_MinusLogProbMetric: 180.7294

Epoch 386: val_loss did not improve from 180.67844
196/196 - 27s - loss: 177.6023 - MinusLogProbMetric: 177.6023 - val_loss: 180.7294 - val_MinusLogProbMetric: 180.7294 - lr: 1.2500e-04 - 27s/epoch - 137ms/step
Epoch 387/1000
2023-10-01 11:32:22.532 
Epoch 387/1000 
	 loss: 177.6190, MinusLogProbMetric: 177.6190, val_loss: 180.7044, val_MinusLogProbMetric: 180.7044

Epoch 387: val_loss did not improve from 180.67844
196/196 - 25s - loss: 177.6190 - MinusLogProbMetric: 177.6190 - val_loss: 180.7044 - val_MinusLogProbMetric: 180.7044 - lr: 1.2500e-04 - 25s/epoch - 127ms/step
Epoch 388/1000
2023-10-01 11:32:50.499 
Epoch 388/1000 
	 loss: 177.6045, MinusLogProbMetric: 177.6045, val_loss: 180.7211, val_MinusLogProbMetric: 180.7211

Epoch 388: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.6045 - MinusLogProbMetric: 177.6045 - val_loss: 180.7211 - val_MinusLogProbMetric: 180.7211 - lr: 1.2500e-04 - 28s/epoch - 143ms/step
Epoch 389/1000
2023-10-01 11:33:18.801 
Epoch 389/1000 
	 loss: 177.5925, MinusLogProbMetric: 177.5925, val_loss: 180.7042, val_MinusLogProbMetric: 180.7042

Epoch 389: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.5925 - MinusLogProbMetric: 177.5925 - val_loss: 180.7042 - val_MinusLogProbMetric: 180.7042 - lr: 1.2500e-04 - 28s/epoch - 144ms/step
Epoch 390/1000
2023-10-01 11:33:45.548 
Epoch 390/1000 
	 loss: 177.5948, MinusLogProbMetric: 177.5948, val_loss: 180.7660, val_MinusLogProbMetric: 180.7660

Epoch 390: val_loss did not improve from 180.67844
196/196 - 27s - loss: 177.5948 - MinusLogProbMetric: 177.5948 - val_loss: 180.7660 - val_MinusLogProbMetric: 180.7660 - lr: 1.2500e-04 - 27s/epoch - 137ms/step
Epoch 391/1000
2023-10-01 11:34:12.644 
Epoch 391/1000 
	 loss: 177.5915, MinusLogProbMetric: 177.5915, val_loss: 180.7170, val_MinusLogProbMetric: 180.7170

Epoch 391: val_loss did not improve from 180.67844
196/196 - 27s - loss: 177.5915 - MinusLogProbMetric: 177.5915 - val_loss: 180.7170 - val_MinusLogProbMetric: 180.7170 - lr: 1.2500e-04 - 27s/epoch - 138ms/step
Epoch 392/1000
2023-10-01 11:34:39.692 
Epoch 392/1000 
	 loss: 177.5902, MinusLogProbMetric: 177.5902, val_loss: 180.7081, val_MinusLogProbMetric: 180.7081

Epoch 392: val_loss did not improve from 180.67844
196/196 - 27s - loss: 177.5902 - MinusLogProbMetric: 177.5902 - val_loss: 180.7081 - val_MinusLogProbMetric: 180.7081 - lr: 1.2500e-04 - 27s/epoch - 138ms/step
Epoch 393/1000
2023-10-01 11:35:09.748 
Epoch 393/1000 
	 loss: 177.5913, MinusLogProbMetric: 177.5913, val_loss: 180.7096, val_MinusLogProbMetric: 180.7096

Epoch 393: val_loss did not improve from 180.67844
196/196 - 30s - loss: 177.5913 - MinusLogProbMetric: 177.5913 - val_loss: 180.7096 - val_MinusLogProbMetric: 180.7096 - lr: 1.2500e-04 - 30s/epoch - 153ms/step
Epoch 394/1000
2023-10-01 11:35:40.421 
Epoch 394/1000 
	 loss: 177.6096, MinusLogProbMetric: 177.6096, val_loss: 180.7527, val_MinusLogProbMetric: 180.7527

Epoch 394: val_loss did not improve from 180.67844
196/196 - 31s - loss: 177.6096 - MinusLogProbMetric: 177.6096 - val_loss: 180.7527 - val_MinusLogProbMetric: 180.7527 - lr: 1.2500e-04 - 31s/epoch - 156ms/step
Epoch 395/1000
2023-10-01 11:36:08.364 
Epoch 395/1000 
	 loss: 177.5945, MinusLogProbMetric: 177.5945, val_loss: 180.7497, val_MinusLogProbMetric: 180.7497

Epoch 395: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.5945 - MinusLogProbMetric: 177.5945 - val_loss: 180.7497 - val_MinusLogProbMetric: 180.7497 - lr: 1.2500e-04 - 28s/epoch - 143ms/step
Epoch 396/1000
2023-10-01 11:36:36.548 
Epoch 396/1000 
	 loss: 177.5905, MinusLogProbMetric: 177.5905, val_loss: 180.7699, val_MinusLogProbMetric: 180.7699

Epoch 396: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.5905 - MinusLogProbMetric: 177.5905 - val_loss: 180.7699 - val_MinusLogProbMetric: 180.7699 - lr: 1.2500e-04 - 28s/epoch - 144ms/step
Epoch 397/1000
2023-10-01 11:37:05.332 
Epoch 397/1000 
	 loss: 177.5992, MinusLogProbMetric: 177.5992, val_loss: 180.7436, val_MinusLogProbMetric: 180.7436

Epoch 397: val_loss did not improve from 180.67844
196/196 - 29s - loss: 177.5992 - MinusLogProbMetric: 177.5992 - val_loss: 180.7436 - val_MinusLogProbMetric: 180.7436 - lr: 1.2500e-04 - 29s/epoch - 147ms/step
Epoch 398/1000
2023-10-01 11:37:34.387 
Epoch 398/1000 
	 loss: 177.5791, MinusLogProbMetric: 177.5791, val_loss: 180.7399, val_MinusLogProbMetric: 180.7399

Epoch 398: val_loss did not improve from 180.67844
196/196 - 29s - loss: 177.5791 - MinusLogProbMetric: 177.5791 - val_loss: 180.7399 - val_MinusLogProbMetric: 180.7399 - lr: 1.2500e-04 - 29s/epoch - 148ms/step
Epoch 399/1000
2023-10-01 11:38:02.694 
Epoch 399/1000 
	 loss: 177.5918, MinusLogProbMetric: 177.5918, val_loss: 180.8726, val_MinusLogProbMetric: 180.8726

Epoch 399: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.5918 - MinusLogProbMetric: 177.5918 - val_loss: 180.8726 - val_MinusLogProbMetric: 180.8726 - lr: 1.2500e-04 - 28s/epoch - 145ms/step
Epoch 400/1000
2023-10-01 11:38:31.033 
Epoch 400/1000 
	 loss: 177.5965, MinusLogProbMetric: 177.5965, val_loss: 180.7164, val_MinusLogProbMetric: 180.7164

Epoch 400: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.5965 - MinusLogProbMetric: 177.5965 - val_loss: 180.7164 - val_MinusLogProbMetric: 180.7164 - lr: 1.2500e-04 - 28s/epoch - 144ms/step
Epoch 401/1000
2023-10-01 11:38:59.853 
Epoch 401/1000 
	 loss: 177.6370, MinusLogProbMetric: 177.6370, val_loss: 180.7887, val_MinusLogProbMetric: 180.7887

Epoch 401: val_loss did not improve from 180.67844
196/196 - 29s - loss: 177.6370 - MinusLogProbMetric: 177.6370 - val_loss: 180.7887 - val_MinusLogProbMetric: 180.7887 - lr: 1.2500e-04 - 29s/epoch - 147ms/step
Epoch 402/1000
2023-10-01 11:39:28.664 
Epoch 402/1000 
	 loss: 177.6139, MinusLogProbMetric: 177.6139, val_loss: 180.7767, val_MinusLogProbMetric: 180.7767

Epoch 402: val_loss did not improve from 180.67844
196/196 - 29s - loss: 177.6139 - MinusLogProbMetric: 177.6139 - val_loss: 180.7767 - val_MinusLogProbMetric: 180.7767 - lr: 1.2500e-04 - 29s/epoch - 147ms/step
Epoch 403/1000
2023-10-01 11:39:56.845 
Epoch 403/1000 
	 loss: 177.5782, MinusLogProbMetric: 177.5782, val_loss: 180.7359, val_MinusLogProbMetric: 180.7359

Epoch 403: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.5782 - MinusLogProbMetric: 177.5782 - val_loss: 180.7359 - val_MinusLogProbMetric: 180.7359 - lr: 1.2500e-04 - 28s/epoch - 144ms/step
Epoch 404/1000
2023-10-01 11:40:25.483 
Epoch 404/1000 
	 loss: 177.5752, MinusLogProbMetric: 177.5752, val_loss: 180.7409, val_MinusLogProbMetric: 180.7409

Epoch 404: val_loss did not improve from 180.67844
196/196 - 29s - loss: 177.5752 - MinusLogProbMetric: 177.5752 - val_loss: 180.7409 - val_MinusLogProbMetric: 180.7409 - lr: 1.2500e-04 - 29s/epoch - 146ms/step
Epoch 405/1000
2023-10-01 11:40:53.905 
Epoch 405/1000 
	 loss: 177.6009, MinusLogProbMetric: 177.6009, val_loss: 180.7755, val_MinusLogProbMetric: 180.7755

Epoch 405: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.6009 - MinusLogProbMetric: 177.6009 - val_loss: 180.7755 - val_MinusLogProbMetric: 180.7755 - lr: 1.2500e-04 - 28s/epoch - 145ms/step
Epoch 406/1000
2023-10-01 11:41:23.645 
Epoch 406/1000 
	 loss: 177.5832, MinusLogProbMetric: 177.5832, val_loss: 180.7601, val_MinusLogProbMetric: 180.7601

Epoch 406: val_loss did not improve from 180.67844
196/196 - 30s - loss: 177.5832 - MinusLogProbMetric: 177.5832 - val_loss: 180.7601 - val_MinusLogProbMetric: 180.7601 - lr: 1.2500e-04 - 30s/epoch - 151ms/step
Epoch 407/1000
2023-10-01 11:41:51.312 
Epoch 407/1000 
	 loss: 177.5677, MinusLogProbMetric: 177.5677, val_loss: 180.7759, val_MinusLogProbMetric: 180.7759

Epoch 407: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.5677 - MinusLogProbMetric: 177.5677 - val_loss: 180.7759 - val_MinusLogProbMetric: 180.7759 - lr: 1.2500e-04 - 28s/epoch - 141ms/step
Epoch 408/1000
2023-10-01 11:42:22.283 
Epoch 408/1000 
	 loss: 177.5714, MinusLogProbMetric: 177.5714, val_loss: 180.7681, val_MinusLogProbMetric: 180.7681

Epoch 408: val_loss did not improve from 180.67844
196/196 - 31s - loss: 177.5714 - MinusLogProbMetric: 177.5714 - val_loss: 180.7681 - val_MinusLogProbMetric: 180.7681 - lr: 1.2500e-04 - 31s/epoch - 158ms/step
Epoch 409/1000
2023-10-01 11:42:49.504 
Epoch 409/1000 
	 loss: 177.5711, MinusLogProbMetric: 177.5711, val_loss: 180.7351, val_MinusLogProbMetric: 180.7351

Epoch 409: val_loss did not improve from 180.67844
196/196 - 27s - loss: 177.5711 - MinusLogProbMetric: 177.5711 - val_loss: 180.7351 - val_MinusLogProbMetric: 180.7351 - lr: 1.2500e-04 - 27s/epoch - 139ms/step
Epoch 410/1000
2023-10-01 11:43:15.913 
Epoch 410/1000 
	 loss: 177.5763, MinusLogProbMetric: 177.5763, val_loss: 180.8194, val_MinusLogProbMetric: 180.8194

Epoch 410: val_loss did not improve from 180.67844
196/196 - 26s - loss: 177.5763 - MinusLogProbMetric: 177.5763 - val_loss: 180.8194 - val_MinusLogProbMetric: 180.8194 - lr: 1.2500e-04 - 26s/epoch - 135ms/step
Epoch 411/1000
2023-10-01 11:43:42.492 
Epoch 411/1000 
	 loss: 177.5676, MinusLogProbMetric: 177.5676, val_loss: 180.7342, val_MinusLogProbMetric: 180.7342

Epoch 411: val_loss did not improve from 180.67844
196/196 - 27s - loss: 177.5676 - MinusLogProbMetric: 177.5676 - val_loss: 180.7342 - val_MinusLogProbMetric: 180.7342 - lr: 1.2500e-04 - 27s/epoch - 136ms/step
Epoch 412/1000
2023-10-01 11:44:11.067 
Epoch 412/1000 
	 loss: 177.5899, MinusLogProbMetric: 177.5899, val_loss: 180.7361, val_MinusLogProbMetric: 180.7361

Epoch 412: val_loss did not improve from 180.67844
196/196 - 29s - loss: 177.5899 - MinusLogProbMetric: 177.5899 - val_loss: 180.7361 - val_MinusLogProbMetric: 180.7361 - lr: 1.2500e-04 - 29s/epoch - 146ms/step
Epoch 413/1000
2023-10-01 11:44:37.870 
Epoch 413/1000 
	 loss: 177.5687, MinusLogProbMetric: 177.5687, val_loss: 180.7937, val_MinusLogProbMetric: 180.7937

Epoch 413: val_loss did not improve from 180.67844
196/196 - 27s - loss: 177.5687 - MinusLogProbMetric: 177.5687 - val_loss: 180.7937 - val_MinusLogProbMetric: 180.7937 - lr: 1.2500e-04 - 27s/epoch - 137ms/step
Epoch 414/1000
2023-10-01 11:45:05.758 
Epoch 414/1000 
	 loss: 177.5566, MinusLogProbMetric: 177.5566, val_loss: 180.7754, val_MinusLogProbMetric: 180.7754

Epoch 414: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.5566 - MinusLogProbMetric: 177.5566 - val_loss: 180.7754 - val_MinusLogProbMetric: 180.7754 - lr: 1.2500e-04 - 28s/epoch - 142ms/step
Epoch 415/1000
2023-10-01 11:45:33.267 
Epoch 415/1000 
	 loss: 177.5965, MinusLogProbMetric: 177.5965, val_loss: 180.7485, val_MinusLogProbMetric: 180.7485

Epoch 415: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.5965 - MinusLogProbMetric: 177.5965 - val_loss: 180.7485 - val_MinusLogProbMetric: 180.7485 - lr: 1.2500e-04 - 28s/epoch - 141ms/step
Epoch 416/1000
2023-10-01 11:46:01.838 
Epoch 416/1000 
	 loss: 177.5755, MinusLogProbMetric: 177.5755, val_loss: 180.8455, val_MinusLogProbMetric: 180.8455

Epoch 416: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.5755 - MinusLogProbMetric: 177.5755 - val_loss: 180.8455 - val_MinusLogProbMetric: 180.8455 - lr: 1.2500e-04 - 28s/epoch - 145ms/step
Epoch 417/1000
2023-10-01 11:46:30.586 
Epoch 417/1000 
	 loss: 177.5962, MinusLogProbMetric: 177.5962, val_loss: 180.8897, val_MinusLogProbMetric: 180.8897

Epoch 417: val_loss did not improve from 180.67844
196/196 - 29s - loss: 177.5962 - MinusLogProbMetric: 177.5962 - val_loss: 180.8897 - val_MinusLogProbMetric: 180.8897 - lr: 1.2500e-04 - 29s/epoch - 147ms/step
Epoch 418/1000
2023-10-01 11:46:58.898 
Epoch 418/1000 
	 loss: 177.5791, MinusLogProbMetric: 177.5791, val_loss: 180.7806, val_MinusLogProbMetric: 180.7806

Epoch 418: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.5791 - MinusLogProbMetric: 177.5791 - val_loss: 180.7806 - val_MinusLogProbMetric: 180.7806 - lr: 1.2500e-04 - 28s/epoch - 144ms/step
Epoch 419/1000
2023-10-01 11:47:27.439 
Epoch 419/1000 
	 loss: 177.5538, MinusLogProbMetric: 177.5538, val_loss: 180.7649, val_MinusLogProbMetric: 180.7649

Epoch 419: val_loss did not improve from 180.67844
196/196 - 29s - loss: 177.5538 - MinusLogProbMetric: 177.5538 - val_loss: 180.7649 - val_MinusLogProbMetric: 180.7649 - lr: 1.2500e-04 - 29s/epoch - 145ms/step
Epoch 420/1000
2023-10-01 11:47:55.628 
Epoch 420/1000 
	 loss: 177.5555, MinusLogProbMetric: 177.5555, val_loss: 180.7762, val_MinusLogProbMetric: 180.7762

Epoch 420: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.5555 - MinusLogProbMetric: 177.5555 - val_loss: 180.7762 - val_MinusLogProbMetric: 180.7762 - lr: 1.2500e-04 - 28s/epoch - 144ms/step
Epoch 421/1000
2023-10-01 11:48:24.030 
Epoch 421/1000 
	 loss: 177.6184, MinusLogProbMetric: 177.6184, val_loss: 180.7701, val_MinusLogProbMetric: 180.7701

Epoch 421: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.6184 - MinusLogProbMetric: 177.6184 - val_loss: 180.7701 - val_MinusLogProbMetric: 180.7701 - lr: 1.2500e-04 - 28s/epoch - 145ms/step
Epoch 422/1000
2023-10-01 11:48:53.428 
Epoch 422/1000 
	 loss: 177.5885, MinusLogProbMetric: 177.5885, val_loss: 180.7851, val_MinusLogProbMetric: 180.7851

Epoch 422: val_loss did not improve from 180.67844
196/196 - 29s - loss: 177.5885 - MinusLogProbMetric: 177.5885 - val_loss: 180.7851 - val_MinusLogProbMetric: 180.7851 - lr: 1.2500e-04 - 29s/epoch - 150ms/step
Epoch 423/1000
2023-10-01 11:49:22.792 
Epoch 423/1000 
	 loss: 177.5768, MinusLogProbMetric: 177.5768, val_loss: 180.8367, val_MinusLogProbMetric: 180.8367

Epoch 423: val_loss did not improve from 180.67844
196/196 - 29s - loss: 177.5768 - MinusLogProbMetric: 177.5768 - val_loss: 180.8367 - val_MinusLogProbMetric: 180.8367 - lr: 1.2500e-04 - 29s/epoch - 150ms/step
Epoch 424/1000
2023-10-01 11:49:52.398 
Epoch 424/1000 
	 loss: 177.5769, MinusLogProbMetric: 177.5769, val_loss: 180.7664, val_MinusLogProbMetric: 180.7664

Epoch 424: val_loss did not improve from 180.67844
196/196 - 30s - loss: 177.5769 - MinusLogProbMetric: 177.5769 - val_loss: 180.7664 - val_MinusLogProbMetric: 180.7664 - lr: 1.2500e-04 - 30s/epoch - 151ms/step
Epoch 425/1000
2023-10-01 11:50:21.925 
Epoch 425/1000 
	 loss: 177.5760, MinusLogProbMetric: 177.5760, val_loss: 180.7764, val_MinusLogProbMetric: 180.7764

Epoch 425: val_loss did not improve from 180.67844
196/196 - 30s - loss: 177.5760 - MinusLogProbMetric: 177.5760 - val_loss: 180.7764 - val_MinusLogProbMetric: 180.7764 - lr: 1.2500e-04 - 30s/epoch - 151ms/step
Epoch 426/1000
2023-10-01 11:50:50.843 
Epoch 426/1000 
	 loss: 177.5480, MinusLogProbMetric: 177.5480, val_loss: 180.7914, val_MinusLogProbMetric: 180.7914

Epoch 426: val_loss did not improve from 180.67844
196/196 - 29s - loss: 177.5480 - MinusLogProbMetric: 177.5480 - val_loss: 180.7914 - val_MinusLogProbMetric: 180.7914 - lr: 1.2500e-04 - 29s/epoch - 148ms/step
Epoch 427/1000
2023-10-01 11:51:22.909 
Epoch 427/1000 
	 loss: 177.5795, MinusLogProbMetric: 177.5795, val_loss: 180.8004, val_MinusLogProbMetric: 180.8004

Epoch 427: val_loss did not improve from 180.67844
196/196 - 32s - loss: 177.5795 - MinusLogProbMetric: 177.5795 - val_loss: 180.8004 - val_MinusLogProbMetric: 180.8004 - lr: 1.2500e-04 - 32s/epoch - 164ms/step
Epoch 428/1000
2023-10-01 11:51:51.862 
Epoch 428/1000 
	 loss: 177.5788, MinusLogProbMetric: 177.5788, val_loss: 180.7888, val_MinusLogProbMetric: 180.7888

Epoch 428: val_loss did not improve from 180.67844
196/196 - 29s - loss: 177.5788 - MinusLogProbMetric: 177.5788 - val_loss: 180.7888 - val_MinusLogProbMetric: 180.7888 - lr: 1.2500e-04 - 29s/epoch - 148ms/step
Epoch 429/1000
2023-10-01 11:52:19.933 
Epoch 429/1000 
	 loss: 177.5462, MinusLogProbMetric: 177.5462, val_loss: 180.7648, val_MinusLogProbMetric: 180.7648

Epoch 429: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.5462 - MinusLogProbMetric: 177.5462 - val_loss: 180.7648 - val_MinusLogProbMetric: 180.7648 - lr: 1.2500e-04 - 28s/epoch - 143ms/step
Epoch 430/1000
2023-10-01 11:52:48.042 
Epoch 430/1000 
	 loss: 177.5418, MinusLogProbMetric: 177.5418, val_loss: 180.8135, val_MinusLogProbMetric: 180.8135

Epoch 430: val_loss did not improve from 180.67844
196/196 - 28s - loss: 177.5418 - MinusLogProbMetric: 177.5418 - val_loss: 180.8135 - val_MinusLogProbMetric: 180.8135 - lr: 1.2500e-04 - 28s/epoch - 143ms/step
Epoch 431/1000
2023-10-01 11:53:15.874 
Epoch 431/1000 
	 loss: 177.5771, MinusLogProbMetric: 177.5771, val_loss: 180.7955, val_MinusLogProbMetric: 180.7955

Epoch 431: val_loss did not improve from 180.67844
Restoring model weights from the end of the best epoch: 331.
196/196 - 28s - loss: 177.5771 - MinusLogProbMetric: 177.5771 - val_loss: 180.7955 - val_MinusLogProbMetric: 180.7955 - lr: 1.2500e-04 - 28s/epoch - 143ms/step
Epoch 431: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
LR metric calculation completed in 60092.835767096956 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
Iterating from 0 to 1 out of 10 .
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
nchunks = 10
Iterating from 1 to 2 out of 10 .
Iterating from 2 to 3 out of 10 .
Iterating from 3 to 4 out of 10 .
Iterating from 4 to 5 out of 10 .
Iterating from 5 to 6 out of 10 .
Iterating from 6 to 7 out of 10 .
