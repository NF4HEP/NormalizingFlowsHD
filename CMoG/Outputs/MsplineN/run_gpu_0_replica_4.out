2023-09-14 10:09:53.776845: Importing os...
2023-09-14 10:09:53.776897: Importing sys...
2023-09-14 10:09:53.776905: Importing and initializing argparse...
Visible devices: [0]
2023-09-14 10:09:53.787855: Importing timer from timeit...
2023-09-14 10:09:53.788327: Setting env variables for tf import (only device [0] will be available)...
2023-09-14 10:09:53.788363: Importing numpy...
2023-09-14 10:09:53.918012: Importing pandas...
2023-09-14 10:09:54.113944: Importing shutil...
2023-09-14 10:09:54.113969: Importing subprocess...
2023-09-14 10:09:54.113977: Importing tensorflow...
Tensorflow version: 2.12.0
2023-09-14 10:09:56.840371: Importing tensorflow_probability...
Tensorflow probability version: 0.20.1
2023-09-14 10:09:57.305315: Importing textwrap...
2023-09-14 10:09:57.305356: Importing timeit...
2023-09-14 10:09:57.305367: Importing traceback...
2023-09-14 10:09:57.305375: Importing typing...
2023-09-14 10:09:57.305386: Setting tf configs...
2023-09-14 10:09:57.463862: Importing custom module...
Successfully loaded GPU model: NVIDIA A40
2023-09-14 10:09:58.791867: All modues imported successfully.
Directory ../../results/MsplineN_new/ already exists.
Directory ../../results/MsplineN_new/run_1/ already exists.
Skipping it.
===========
Run 1/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_2/ already exists.
Skipping it.
===========
Run 2/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_3/ already exists.
Skipping it.
===========
Run 3/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_4/ already exists.
Skipping it.
===========
Run 4/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_5/ already exists.
Skipping it.
===========
Run 5/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_6/ already exists.
Skipping it.
===========
Run 6/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_7/ already exists.
Skipping it.
===========
Run 7/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_8/ already exists.
Skipping it.
===========
Run 8/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_9/ already exists.
Skipping it.
===========
Run 9/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_10/ already exists.
Skipping it.
===========
Run 10/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_11/ already exists.
Skipping it.
===========
Run 11/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_12/ already exists.
Skipping it.
===========
Run 12/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_13/ already exists.
Skipping it.
===========
Run 13/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_14/ already exists.
Skipping it.
===========
Run 14/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_15/ already exists.
Skipping it.
===========
Run 15/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_16/ already exists.
Skipping it.
===========
Run 16/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_17/ already exists.
Skipping it.
===========
Run 17/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_18/ already exists.
Skipping it.
===========
Run 18/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_19/ already exists.
Skipping it.
===========
Run 19/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_20/ already exists.
Skipping it.
===========
Run 20/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_21/ already exists.
Skipping it.
===========
Run 21/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_22/ already exists.
Skipping it.
===========
Run 22/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_23/ already exists.
Skipping it.
===========
Run 23/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_24/ already exists.
Skipping it.
===========
Run 24/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_25/ already exists.
Skipping it.
===========
Run 25/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_26/ already exists.
Skipping it.
===========
Run 26/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_27/ already exists.
Skipping it.
===========
Run 27/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_28/ already exists.
Skipping it.
===========
Run 28/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_29/ already exists.
Skipping it.
===========
Run 29/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_30/ already exists.
Skipping it.
===========
Run 30/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_31/ already exists.
Skipping it.
===========
Run 31/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_32/ already exists.
Skipping it.
===========
Run 32/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_33/ already exists.
Skipping it.
===========
Run 33/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_34/ already exists.
Skipping it.
===========
Run 34/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_35/ already exists.
Skipping it.
===========
Run 35/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_36/ already exists.
Skipping it.
===========
Run 36/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_37/ already exists.
Skipping it.
===========
Run 37/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_38/ already exists.
Skipping it.
===========
Run 38/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_39/ already exists.
Skipping it.
===========
Run 39/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_40/ already exists.
Skipping it.
===========
Run 40/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_41/ already exists.
Skipping it.
===========
Run 41/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_42/ already exists.
Skipping it.
===========
Run 42/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_43/ already exists.
Skipping it.
===========
Run 43/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_44/ already exists.
Skipping it.
===========
Run 44/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_45/ already exists.
Skipping it.
===========
Run 45/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_46/ already exists.
Skipping it.
===========
Run 46/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_47/ already exists.
Skipping it.
===========
Run 47/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_48/ already exists.
Skipping it.
===========
Run 48/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_49/ already exists.
Skipping it.
===========
Run 49/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_50/ already exists.
Skipping it.
===========
Run 50/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_51/ already exists.
Skipping it.
===========
Run 51/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_52/ already exists.
Skipping it.
===========
Run 52/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_53/ already exists.
Skipping it.
===========
Run 53/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_54/ already exists.
Skipping it.
===========
Run 54/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_55/ already exists.
Skipping it.
===========
Run 55/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_56/ already exists.
Skipping it.
===========
Run 56/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_57/ already exists.
Skipping it.
===========
Run 57/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_58/ already exists.
Skipping it.
===========
Run 58/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_59/ already exists.
Skipping it.
===========
Run 59/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_60/ already exists.
Skipping it.
===========
Run 60/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_61/ already exists.
Skipping it.
===========
Run 61/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_62/ already exists.
Skipping it.
===========
Run 62/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_63/ already exists.
Skipping it.
===========
Run 63/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_64/ already exists.
Skipping it.
===========
Run 64/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_65/ already exists.
Skipping it.
===========
Run 65/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_66/ already exists.
Skipping it.
===========
Run 66/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_67/ already exists.
Skipping it.
===========
Run 67/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_68/ already exists.
Skipping it.
===========
Run 68/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_69/ already exists.
Skipping it.
===========
Run 69/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_70/ already exists.
Skipping it.
===========
Run 70/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_71/ already exists.
Skipping it.
===========
Run 71/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_72/ already exists.
Skipping it.
===========
Run 72/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_73/ already exists.
Skipping it.
===========
Run 73/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_74/ already exists.
Skipping it.
===========
Run 74/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_75/ already exists.
Skipping it.
===========
Run 75/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_76/ already exists.
Skipping it.
===========
Run 76/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_77/ already exists.
Skipping it.
===========
Run 77/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_78/ already exists.
Skipping it.
===========
Run 78/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_79/ already exists.
Skipping it.
===========
Run 79/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_80/ already exists.
Skipping it.
===========
Run 80/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_81/ already exists.
Skipping it.
===========
Run 81/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_82/ already exists.
Skipping it.
===========
Run 82/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_83/ already exists.
Skipping it.
===========
Run 83/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_84/ already exists.
Skipping it.
===========
Run 84/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_85/ already exists.
Skipping it.
===========
Run 85/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_86/ already exists.
Skipping it.
===========
Run 86/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_87/ already exists.
Skipping it.
===========
Run 87/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_88/ already exists.
Skipping it.
===========
Run 88/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_89/ already exists.
Skipping it.
===========
Run 89/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_90/ already exists.
Skipping it.
===========
Run 90/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_91/ already exists.
Skipping it.
===========
Run 91/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_92/ already exists.
Skipping it.
===========
Run 92/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_93/ already exists.
Skipping it.
===========
Run 93/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_94/ already exists.
Skipping it.
===========
Run 94/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_95/ already exists.
Skipping it.
===========
Run 95/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_96/ already exists.
Skipping it.
===========
Run 96/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_97/ already exists.
Skipping it.
===========
Run 97/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_98/ already exists.
Skipping it.
===========
Run 98/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_99/ already exists.
Skipping it.
===========
Run 99/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_100/ already exists.
Skipping it.
===========
Run 100/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_101/ already exists.
Skipping it.
===========
Run 101/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_102/ already exists.
Skipping it.
===========
Run 102/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_103/ already exists.
Skipping it.
===========
Run 103/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_104/ already exists.
Skipping it.
===========
Run 104/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_105/ already exists.
Skipping it.
===========
Run 105/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_106/ already exists.
Skipping it.
===========
Run 106/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_107/ already exists.
Skipping it.
===========
Run 107/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_108/ already exists.
Skipping it.
===========
Run 108/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_109/ already exists.
Skipping it.
===========
Run 109/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_110/ already exists.
Skipping it.
===========
Run 110/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_111/ already exists.
Skipping it.
===========
Run 111/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_112/ already exists.
Skipping it.
===========
Run 112/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_113/ already exists.
Skipping it.
===========
Run 113/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_114/ already exists.
Skipping it.
===========
Run 114/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_115/ already exists.
Skipping it.
===========
Run 115/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_116/ already exists.
Skipping it.
===========
Run 116/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_117/ already exists.
Skipping it.
===========
Run 117/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_118/ already exists.
Skipping it.
===========
Run 118/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_119/ already exists.
Skipping it.
===========
Run 119/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_120/ already exists.
Skipping it.
===========
Run 120/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_121/ already exists.
Skipping it.
===========
Run 121/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_122/ already exists.
Skipping it.
===========
Run 122/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_123/ already exists.
Skipping it.
===========
Run 123/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_124/ already exists.
Skipping it.
===========
Run 124/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_125/ already exists.
Skipping it.
===========
Run 125/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_126/ already exists.
Skipping it.
===========
Run 126/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_127/ already exists.
Skipping it.
===========
Run 127/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_128/ already exists.
Skipping it.
===========
Run 128/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_129/ already exists.
Skipping it.
===========
Run 129/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_130/ already exists.
Skipping it.
===========
Run 130/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_131/ already exists.
Skipping it.
===========
Run 131/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_132/ already exists.
Skipping it.
===========
Run 132/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_133/ already exists.
Skipping it.
===========
Run 133/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_134/ already exists.
Skipping it.
===========
Run 134/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_135/ already exists.
Skipping it.
===========
Run 135/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_136/ already exists.
Skipping it.
===========
Run 136/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_137/ already exists.
Skipping it.
===========
Run 137/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_138/ already exists.
Skipping it.
===========
Run 138/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_139/ already exists.
Skipping it.
===========
Run 139/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_140/ already exists.
Skipping it.
===========
Run 140/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_141/ already exists.
Skipping it.
===========
Run 141/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_142/ already exists.
Skipping it.
===========
Run 142/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_143/ already exists.
Skipping it.
===========
Run 143/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_144/ already exists.
Skipping it.
===========
Run 144/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_145/ already exists.
Skipping it.
===========
Run 145/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_146/ already exists.
Skipping it.
===========
Run 146/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_147/ already exists.
Skipping it.
===========
Run 147/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_148/ already exists.
Skipping it.
===========
Run 148/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_149/ already exists.
Skipping it.
===========
Run 149/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_150/ already exists.
Skipping it.
===========
Run 150/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_151/ already exists.
Skipping it.
===========
Run 151/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_152/ already exists.
Skipping it.
===========
Run 152/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_153/ already exists.
Skipping it.
===========
Run 153/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_154/ already exists.
Skipping it.
===========
Run 154/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_155/ already exists.
Skipping it.
===========
Run 155/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_156/ already exists.
Skipping it.
===========
Run 156/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_157/ already exists.
Skipping it.
===========
Run 157/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_158/ already exists.
Skipping it.
===========
Run 158/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_159/ already exists.
Skipping it.
===========
Run 159/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_160/ already exists.
Skipping it.
===========
Run 160/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_161/ already exists.
Skipping it.
===========
Run 161/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_162/ already exists.
Skipping it.
===========
Run 162/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_163/ already exists.
Skipping it.
===========
Run 163/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_164/ already exists.
Skipping it.
===========
Run 164/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_165/ already exists.
Skipping it.
===========
Run 165/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_166/ already exists.
Skipping it.
===========
Run 166/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_167/ already exists.
Skipping it.
===========
Run 167/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_168/ already exists.
Skipping it.
===========
Run 168/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_169/ already exists.
Skipping it.
===========
Run 169/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_170/ already exists.
Skipping it.
===========
Run 170/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_171/ already exists.
Skipping it.
===========
Run 171/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_172/ already exists.
Skipping it.
===========
Run 172/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_173/ already exists.
Skipping it.
===========
Run 173/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_174/ already exists.
Skipping it.
===========
Run 174/360 already exists. Skipping it.
===========

===========
Generating train data for run 175.
===========
Train data generated in 0.29 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 64)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_175/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 440}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_175/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[5.7541595 , 5.721841  , 7.5400248 , ..., 0.17855006, 7.5787845 ,
        1.3515668 ],
       [5.442636  , 8.331263  , 5.8727856 , ..., 1.0242728 , 8.106918  ,
        1.274803  ],
       [1.849359  , 3.4476702 , 6.8133354 , ..., 6.851224  , 0.8453402 ,
        3.4794679 ],
       ...,
       [2.3177798 , 4.2122316 , 7.105509  , ..., 7.2533946 , 0.7699296 ,
        1.7943734 ],
       [6.3632    , 2.8481505 , 6.2368546 , ..., 3.6055064 , 5.1009455 ,
        2.9910412 ],
       [7.1731195 , 2.729657  , 6.1427665 , ..., 3.274747  , 1.7997704 ,
        2.8153737 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_175/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_175
self.data_kwargs: {'seed': 440}
self.x_data: [[ 2.0547452   3.776408    6.9601746  ...  5.8637457  -0.4179731
   2.747595  ]
 [ 6.405085    2.999549    6.1033454  ...  2.8107233   3.0569289
   2.003619  ]
 [ 2.0047038   4.064143    6.2048492  ...  5.6568336   0.71395487
   2.6926432 ]
 ...
 [ 5.645455    7.0971727   6.202566   ...  0.61970913  6.238492
   1.3539525 ]
 [ 6.475603    3.1151166   6.2248073  ...  2.8990176   3.6724448
   2.289971  ]
 [ 2.2290072   4.101192    7.1413527  ...  6.717821   -2.0046902
   2.3999293 ]]
self.y_data: []
self.ndims: 64
Model defined.
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 64)]              0         
                                                                 
 log_prob_layer (LogProbLaye  (None,)                  660608    
 r)                                                              
                                                                 
=================================================================
Total params: 660,608
Trainable params: 660,608
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer'")
self.model: <keras.engine.functional.Functional object at 0x7fc5303f34c0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc5243aa560>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc5243aa560>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc5243aae30>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc5243abaf0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc5243abfd0>, <keras.callbacks.ModelCheckpoint object at 0x7fc5241081f0>, <keras.callbacks.EarlyStopping object at 0x7fc524108400>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc524108430>, <keras.callbacks.TerminateOnNaN object at 0x7fc524108160>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[5.7541595 , 5.721841  , 7.5400248 , ..., 0.17855006, 7.5787845 ,
        1.3515668 ],
       [5.442636  , 8.331263  , 5.8727856 , ..., 1.0242728 , 8.106918  ,
        1.274803  ],
       [1.849359  , 3.4476702 , 6.8133354 , ..., 6.851224  , 0.8453402 ,
        3.4794679 ],
       ...,
       [2.3177798 , 4.2122316 , 7.105509  , ..., 7.2533946 , 0.7699296 ,
        1.7943734 ],
       [6.3632    , 2.8481505 , 6.2368546 , ..., 3.6055064 , 5.1009455 ,
        2.9910412 ],
       [7.1731195 , 2.729657  , 6.1427665 , ..., 3.274747  , 1.7997704 ,
        2.8153737 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_175/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 175/360 with hyperparameters:
timestamp = 2023-09-14 10:10:02.077787
ndims = 64
seed_train = 440
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 660608
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 2.0547452   3.776408    6.9601746   1.2163222   8.644804    1.0450234
  9.756204    5.9333344   9.3759165   6.2056174   7.6663713   0.8787037
  2.7781603   1.7675867   3.9287794   0.8286338   3.6572614   4.846633
  0.68292063  6.317236    6.48625     3.843101    5.88724     2.0270782
  5.1297107   7.7579265   2.6054757   6.6726594   1.0543873   7.123391
  3.5526195   2.046467    5.620422   -0.869851    8.648443    0.02500496
  7.4141846   2.6777635   7.6790566   9.76465     2.481489    6.2672224
  5.7068043   4.504637    1.1161722   9.691578    4.0927534   8.503739
  6.9964066   3.1729455   8.086372    4.0078015   8.096493    5.813139
  8.181514    6.97417     7.246071    5.0315676  10.666024    6.2678714
  3.6855178   5.8637457  -0.4179731   2.747595  ]
Epoch 1/1000
2023-09-14 10:10:35.855 
Epoch 1/1000 
	 loss: 101.4342, MinusLogProbMetric: 101.4342, val_loss: 37.7639, val_MinusLogProbMetric: 37.7639

Epoch 1: val_loss improved from inf to 37.76386, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 34s - loss: 101.4342 - MinusLogProbMetric: 101.4342 - val_loss: 37.7639 - val_MinusLogProbMetric: 37.7639 - lr: 0.0010 - 34s/epoch - 172ms/step
Epoch 2/1000
2023-09-14 10:10:48.026 
Epoch 2/1000 
	 loss: 33.4896, MinusLogProbMetric: 33.4896, val_loss: 31.6416, val_MinusLogProbMetric: 31.6416

Epoch 2: val_loss improved from 37.76386 to 31.64156, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 12s - loss: 33.4896 - MinusLogProbMetric: 33.4896 - val_loss: 31.6416 - val_MinusLogProbMetric: 31.6416 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 3/1000
2023-09-14 10:11:00.195 
Epoch 3/1000 
	 loss: 30.6840, MinusLogProbMetric: 30.6840, val_loss: 29.8826, val_MinusLogProbMetric: 29.8826

Epoch 3: val_loss improved from 31.64156 to 29.88256, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 12s - loss: 30.6840 - MinusLogProbMetric: 30.6840 - val_loss: 29.8826 - val_MinusLogProbMetric: 29.8826 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 4/1000
2023-09-14 10:11:12.272 
Epoch 4/1000 
	 loss: 29.8380, MinusLogProbMetric: 29.8380, val_loss: 29.4235, val_MinusLogProbMetric: 29.4235

Epoch 4: val_loss improved from 29.88256 to 29.42354, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 12s - loss: 29.8380 - MinusLogProbMetric: 29.8380 - val_loss: 29.4235 - val_MinusLogProbMetric: 29.4235 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 5/1000
2023-09-14 10:11:24.538 
Epoch 5/1000 
	 loss: 29.4051, MinusLogProbMetric: 29.4051, val_loss: 29.2644, val_MinusLogProbMetric: 29.2644

Epoch 5: val_loss improved from 29.42354 to 29.26435, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 12s - loss: 29.4051 - MinusLogProbMetric: 29.4051 - val_loss: 29.2644 - val_MinusLogProbMetric: 29.2644 - lr: 0.0010 - 12s/epoch - 63ms/step
Epoch 6/1000
2023-09-14 10:11:36.382 
Epoch 6/1000 
	 loss: 29.0206, MinusLogProbMetric: 29.0206, val_loss: 29.4477, val_MinusLogProbMetric: 29.4477

Epoch 6: val_loss did not improve from 29.26435
196/196 - 12s - loss: 29.0206 - MinusLogProbMetric: 29.0206 - val_loss: 29.4477 - val_MinusLogProbMetric: 29.4477 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 7/1000
2023-09-14 10:11:47.718 
Epoch 7/1000 
	 loss: 28.8449, MinusLogProbMetric: 28.8449, val_loss: 29.5473, val_MinusLogProbMetric: 29.5473

Epoch 7: val_loss did not improve from 29.26435
196/196 - 11s - loss: 28.8449 - MinusLogProbMetric: 28.8449 - val_loss: 29.5473 - val_MinusLogProbMetric: 29.5473 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 8/1000
2023-09-14 10:11:59.074 
Epoch 8/1000 
	 loss: 28.7339, MinusLogProbMetric: 28.7339, val_loss: 28.9693, val_MinusLogProbMetric: 28.9693

Epoch 8: val_loss improved from 29.26435 to 28.96930, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 11s - loss: 28.7339 - MinusLogProbMetric: 28.7339 - val_loss: 28.9693 - val_MinusLogProbMetric: 28.9693 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 9/1000
2023-09-14 10:12:09.296 
Epoch 9/1000 
	 loss: 28.5331, MinusLogProbMetric: 28.5331, val_loss: 28.4902, val_MinusLogProbMetric: 28.4902

Epoch 9: val_loss improved from 28.96930 to 28.49015, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 10s - loss: 28.5331 - MinusLogProbMetric: 28.5331 - val_loss: 28.4902 - val_MinusLogProbMetric: 28.4902 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 10/1000
2023-09-14 10:12:21.386 
Epoch 10/1000 
	 loss: 28.4612, MinusLogProbMetric: 28.4612, val_loss: 28.5129, val_MinusLogProbMetric: 28.5129

Epoch 10: val_loss did not improve from 28.49015
196/196 - 12s - loss: 28.4612 - MinusLogProbMetric: 28.4612 - val_loss: 28.5129 - val_MinusLogProbMetric: 28.5129 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 11/1000
2023-09-14 10:12:33.030 
Epoch 11/1000 
	 loss: 28.4116, MinusLogProbMetric: 28.4116, val_loss: 28.5213, val_MinusLogProbMetric: 28.5213

Epoch 11: val_loss did not improve from 28.49015
196/196 - 12s - loss: 28.4116 - MinusLogProbMetric: 28.4116 - val_loss: 28.5213 - val_MinusLogProbMetric: 28.5213 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 12/1000
2023-09-14 10:12:45.031 
Epoch 12/1000 
	 loss: 28.3122, MinusLogProbMetric: 28.3122, val_loss: 28.3288, val_MinusLogProbMetric: 28.3288

Epoch 12: val_loss improved from 28.49015 to 28.32875, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 12s - loss: 28.3122 - MinusLogProbMetric: 28.3122 - val_loss: 28.3288 - val_MinusLogProbMetric: 28.3288 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 13/1000
2023-09-14 10:12:57.018 
Epoch 13/1000 
	 loss: 28.2446, MinusLogProbMetric: 28.2446, val_loss: 28.1674, val_MinusLogProbMetric: 28.1674

Epoch 13: val_loss improved from 28.32875 to 28.16743, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 12s - loss: 28.2446 - MinusLogProbMetric: 28.2446 - val_loss: 28.1674 - val_MinusLogProbMetric: 28.1674 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 14/1000
2023-09-14 10:13:08.857 
Epoch 14/1000 
	 loss: 28.2735, MinusLogProbMetric: 28.2735, val_loss: 28.2719, val_MinusLogProbMetric: 28.2719

Epoch 14: val_loss did not improve from 28.16743
196/196 - 12s - loss: 28.2735 - MinusLogProbMetric: 28.2735 - val_loss: 28.2719 - val_MinusLogProbMetric: 28.2719 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 15/1000
2023-09-14 10:13:20.559 
Epoch 15/1000 
	 loss: 28.1827, MinusLogProbMetric: 28.1827, val_loss: 28.2919, val_MinusLogProbMetric: 28.2919

Epoch 15: val_loss did not improve from 28.16743
196/196 - 12s - loss: 28.1827 - MinusLogProbMetric: 28.1827 - val_loss: 28.2919 - val_MinusLogProbMetric: 28.2919 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 16/1000
2023-09-14 10:13:31.889 
Epoch 16/1000 
	 loss: 28.1443, MinusLogProbMetric: 28.1443, val_loss: 28.0632, val_MinusLogProbMetric: 28.0632

Epoch 16: val_loss improved from 28.16743 to 28.06318, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 11s - loss: 28.1443 - MinusLogProbMetric: 28.1443 - val_loss: 28.0632 - val_MinusLogProbMetric: 28.0632 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 17/1000
2023-09-14 10:13:43.169 
Epoch 17/1000 
	 loss: 28.1119, MinusLogProbMetric: 28.1119, val_loss: 28.2640, val_MinusLogProbMetric: 28.2640

Epoch 17: val_loss did not improve from 28.06318
196/196 - 11s - loss: 28.1119 - MinusLogProbMetric: 28.1119 - val_loss: 28.2640 - val_MinusLogProbMetric: 28.2640 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 18/1000
2023-09-14 10:13:54.046 
Epoch 18/1000 
	 loss: 28.0677, MinusLogProbMetric: 28.0677, val_loss: 28.0223, val_MinusLogProbMetric: 28.0223

Epoch 18: val_loss improved from 28.06318 to 28.02230, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 11s - loss: 28.0677 - MinusLogProbMetric: 28.0677 - val_loss: 28.0223 - val_MinusLogProbMetric: 28.0223 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 19/1000
2023-09-14 10:14:04.449 
Epoch 19/1000 
	 loss: 28.0442, MinusLogProbMetric: 28.0442, val_loss: 28.1413, val_MinusLogProbMetric: 28.1413

Epoch 19: val_loss did not improve from 28.02230
196/196 - 10s - loss: 28.0442 - MinusLogProbMetric: 28.0442 - val_loss: 28.1413 - val_MinusLogProbMetric: 28.1413 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 20/1000
2023-09-14 10:14:15.500 
Epoch 20/1000 
	 loss: 28.0245, MinusLogProbMetric: 28.0245, val_loss: 28.1547, val_MinusLogProbMetric: 28.1547

Epoch 20: val_loss did not improve from 28.02230
196/196 - 11s - loss: 28.0245 - MinusLogProbMetric: 28.0245 - val_loss: 28.1547 - val_MinusLogProbMetric: 28.1547 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 21/1000
2023-09-14 10:14:26.844 
Epoch 21/1000 
	 loss: 27.9880, MinusLogProbMetric: 27.9880, val_loss: 28.1765, val_MinusLogProbMetric: 28.1765

Epoch 21: val_loss did not improve from 28.02230
196/196 - 11s - loss: 27.9880 - MinusLogProbMetric: 27.9880 - val_loss: 28.1765 - val_MinusLogProbMetric: 28.1765 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 22/1000
2023-09-14 10:14:37.989 
Epoch 22/1000 
	 loss: 27.9648, MinusLogProbMetric: 27.9648, val_loss: 27.9483, val_MinusLogProbMetric: 27.9483

Epoch 22: val_loss improved from 28.02230 to 27.94832, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 11s - loss: 27.9648 - MinusLogProbMetric: 27.9648 - val_loss: 27.9483 - val_MinusLogProbMetric: 27.9483 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 23/1000
2023-09-14 10:14:49.305 
Epoch 23/1000 
	 loss: 27.9469, MinusLogProbMetric: 27.9469, val_loss: 28.0246, val_MinusLogProbMetric: 28.0246

Epoch 23: val_loss did not improve from 27.94832
196/196 - 11s - loss: 27.9469 - MinusLogProbMetric: 27.9469 - val_loss: 28.0246 - val_MinusLogProbMetric: 28.0246 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 24/1000
2023-09-14 10:14:59.941 
Epoch 24/1000 
	 loss: 27.9477, MinusLogProbMetric: 27.9477, val_loss: 28.0353, val_MinusLogProbMetric: 28.0353

Epoch 24: val_loss did not improve from 27.94832
196/196 - 11s - loss: 27.9477 - MinusLogProbMetric: 27.9477 - val_loss: 28.0353 - val_MinusLogProbMetric: 28.0353 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 25/1000
2023-09-14 10:15:11.083 
Epoch 25/1000 
	 loss: 27.9581, MinusLogProbMetric: 27.9581, val_loss: 27.8992, val_MinusLogProbMetric: 27.8992

Epoch 25: val_loss improved from 27.94832 to 27.89919, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 11s - loss: 27.9581 - MinusLogProbMetric: 27.9581 - val_loss: 27.8992 - val_MinusLogProbMetric: 27.8992 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 26/1000
2023-09-14 10:15:22.250 
Epoch 26/1000 
	 loss: 27.8734, MinusLogProbMetric: 27.8734, val_loss: 27.9743, val_MinusLogProbMetric: 27.9743

Epoch 26: val_loss did not improve from 27.89919
196/196 - 11s - loss: 27.8734 - MinusLogProbMetric: 27.8734 - val_loss: 27.9743 - val_MinusLogProbMetric: 27.9743 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 27/1000
2023-09-14 10:15:33.229 
Epoch 27/1000 
	 loss: 27.8896, MinusLogProbMetric: 27.8896, val_loss: 27.9619, val_MinusLogProbMetric: 27.9619

Epoch 27: val_loss did not improve from 27.89919
196/196 - 11s - loss: 27.8896 - MinusLogProbMetric: 27.8896 - val_loss: 27.9619 - val_MinusLogProbMetric: 27.9619 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 28/1000
2023-09-14 10:15:44.107 
Epoch 28/1000 
	 loss: 27.8804, MinusLogProbMetric: 27.8804, val_loss: 28.0399, val_MinusLogProbMetric: 28.0399

Epoch 28: val_loss did not improve from 27.89919
196/196 - 11s - loss: 27.8804 - MinusLogProbMetric: 27.8804 - val_loss: 28.0399 - val_MinusLogProbMetric: 28.0399 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 29/1000
2023-09-14 10:15:55.243 
Epoch 29/1000 
	 loss: 27.8833, MinusLogProbMetric: 27.8833, val_loss: 27.9182, val_MinusLogProbMetric: 27.9182

Epoch 29: val_loss did not improve from 27.89919
196/196 - 11s - loss: 27.8833 - MinusLogProbMetric: 27.8833 - val_loss: 27.9182 - val_MinusLogProbMetric: 27.9182 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 30/1000
2023-09-14 10:16:06.274 
Epoch 30/1000 
	 loss: 27.8219, MinusLogProbMetric: 27.8219, val_loss: 27.8430, val_MinusLogProbMetric: 27.8430

Epoch 30: val_loss improved from 27.89919 to 27.84304, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 11s - loss: 27.8219 - MinusLogProbMetric: 27.8219 - val_loss: 27.8430 - val_MinusLogProbMetric: 27.8430 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 31/1000
2023-09-14 10:16:17.471 
Epoch 31/1000 
	 loss: 27.8545, MinusLogProbMetric: 27.8545, val_loss: 27.9506, val_MinusLogProbMetric: 27.9506

Epoch 31: val_loss did not improve from 27.84304
196/196 - 11s - loss: 27.8545 - MinusLogProbMetric: 27.8545 - val_loss: 27.9506 - val_MinusLogProbMetric: 27.9506 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 32/1000
2023-09-14 10:16:28.385 
Epoch 32/1000 
	 loss: 27.8509, MinusLogProbMetric: 27.8509, val_loss: 27.8617, val_MinusLogProbMetric: 27.8617

Epoch 32: val_loss did not improve from 27.84304
196/196 - 11s - loss: 27.8509 - MinusLogProbMetric: 27.8509 - val_loss: 27.8617 - val_MinusLogProbMetric: 27.8617 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 33/1000
2023-09-14 10:16:39.574 
Epoch 33/1000 
	 loss: 27.8009, MinusLogProbMetric: 27.8009, val_loss: 27.8880, val_MinusLogProbMetric: 27.8880

Epoch 33: val_loss did not improve from 27.84304
196/196 - 11s - loss: 27.8009 - MinusLogProbMetric: 27.8009 - val_loss: 27.8880 - val_MinusLogProbMetric: 27.8880 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 34/1000
2023-09-14 10:16:50.614 
Epoch 34/1000 
	 loss: 27.8173, MinusLogProbMetric: 27.8173, val_loss: 27.8586, val_MinusLogProbMetric: 27.8586

Epoch 34: val_loss did not improve from 27.84304
196/196 - 11s - loss: 27.8173 - MinusLogProbMetric: 27.8173 - val_loss: 27.8586 - val_MinusLogProbMetric: 27.8586 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 35/1000
2023-09-14 10:17:01.775 
Epoch 35/1000 
	 loss: 27.7713, MinusLogProbMetric: 27.7713, val_loss: 27.8520, val_MinusLogProbMetric: 27.8520

Epoch 35: val_loss did not improve from 27.84304
196/196 - 11s - loss: 27.7713 - MinusLogProbMetric: 27.7713 - val_loss: 27.8520 - val_MinusLogProbMetric: 27.8520 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 36/1000
2023-09-14 10:17:12.510 
Epoch 36/1000 
	 loss: 27.8038, MinusLogProbMetric: 27.8038, val_loss: 27.8248, val_MinusLogProbMetric: 27.8248

Epoch 36: val_loss improved from 27.84304 to 27.82476, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 11s - loss: 27.8038 - MinusLogProbMetric: 27.8038 - val_loss: 27.8248 - val_MinusLogProbMetric: 27.8248 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 37/1000
2023-09-14 10:17:23.662 
Epoch 37/1000 
	 loss: 27.7840, MinusLogProbMetric: 27.7840, val_loss: 27.9517, val_MinusLogProbMetric: 27.9517

Epoch 37: val_loss did not improve from 27.82476
196/196 - 11s - loss: 27.7840 - MinusLogProbMetric: 27.7840 - val_loss: 27.9517 - val_MinusLogProbMetric: 27.9517 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 38/1000
2023-09-14 10:17:34.592 
Epoch 38/1000 
	 loss: 27.7816, MinusLogProbMetric: 27.7816, val_loss: 27.7611, val_MinusLogProbMetric: 27.7611

Epoch 38: val_loss improved from 27.82476 to 27.76113, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 11s - loss: 27.7816 - MinusLogProbMetric: 27.7816 - val_loss: 27.7611 - val_MinusLogProbMetric: 27.7611 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 39/1000
2023-09-14 10:17:45.685 
Epoch 39/1000 
	 loss: 27.7767, MinusLogProbMetric: 27.7767, val_loss: 27.9545, val_MinusLogProbMetric: 27.9545

Epoch 39: val_loss did not improve from 27.76113
196/196 - 11s - loss: 27.7767 - MinusLogProbMetric: 27.7767 - val_loss: 27.9545 - val_MinusLogProbMetric: 27.9545 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 40/1000
2023-09-14 10:17:56.009 
Epoch 40/1000 
	 loss: 27.7649, MinusLogProbMetric: 27.7649, val_loss: 27.8402, val_MinusLogProbMetric: 27.8402

Epoch 40: val_loss did not improve from 27.76113
196/196 - 10s - loss: 27.7649 - MinusLogProbMetric: 27.7649 - val_loss: 27.8402 - val_MinusLogProbMetric: 27.8402 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 41/1000
2023-09-14 10:18:06.969 
Epoch 41/1000 
	 loss: 27.7288, MinusLogProbMetric: 27.7288, val_loss: 27.8230, val_MinusLogProbMetric: 27.8230

Epoch 41: val_loss did not improve from 27.76113
196/196 - 11s - loss: 27.7288 - MinusLogProbMetric: 27.7288 - val_loss: 27.8230 - val_MinusLogProbMetric: 27.8230 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 42/1000
2023-09-14 10:18:17.283 
Epoch 42/1000 
	 loss: 27.7455, MinusLogProbMetric: 27.7455, val_loss: 27.7376, val_MinusLogProbMetric: 27.7376

Epoch 42: val_loss improved from 27.76113 to 27.73755, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 10s - loss: 27.7455 - MinusLogProbMetric: 27.7455 - val_loss: 27.7376 - val_MinusLogProbMetric: 27.7376 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 43/1000
2023-09-14 10:18:28.201 
Epoch 43/1000 
	 loss: 27.7480, MinusLogProbMetric: 27.7480, val_loss: 27.8620, val_MinusLogProbMetric: 27.8620

Epoch 43: val_loss did not improve from 27.73755
196/196 - 11s - loss: 27.7480 - MinusLogProbMetric: 27.7480 - val_loss: 27.8620 - val_MinusLogProbMetric: 27.8620 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 44/1000
2023-09-14 10:18:39.040 
Epoch 44/1000 
	 loss: 27.7404, MinusLogProbMetric: 27.7404, val_loss: 27.7505, val_MinusLogProbMetric: 27.7505

Epoch 44: val_loss did not improve from 27.73755
196/196 - 11s - loss: 27.7404 - MinusLogProbMetric: 27.7404 - val_loss: 27.7505 - val_MinusLogProbMetric: 27.7505 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 45/1000
2023-09-14 10:18:49.843 
Epoch 45/1000 
	 loss: 27.7375, MinusLogProbMetric: 27.7375, val_loss: 28.3163, val_MinusLogProbMetric: 28.3163

Epoch 45: val_loss did not improve from 27.73755
196/196 - 11s - loss: 27.7375 - MinusLogProbMetric: 27.7375 - val_loss: 28.3163 - val_MinusLogProbMetric: 28.3163 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 46/1000
2023-09-14 10:19:00.426 
Epoch 46/1000 
	 loss: 27.7261, MinusLogProbMetric: 27.7261, val_loss: 27.7925, val_MinusLogProbMetric: 27.7925

Epoch 46: val_loss did not improve from 27.73755
196/196 - 11s - loss: 27.7261 - MinusLogProbMetric: 27.7261 - val_loss: 27.7925 - val_MinusLogProbMetric: 27.7925 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 47/1000
2023-09-14 10:19:11.329 
Epoch 47/1000 
	 loss: 27.7131, MinusLogProbMetric: 27.7131, val_loss: 27.8420, val_MinusLogProbMetric: 27.8420

Epoch 47: val_loss did not improve from 27.73755
196/196 - 11s - loss: 27.7131 - MinusLogProbMetric: 27.7131 - val_loss: 27.8420 - val_MinusLogProbMetric: 27.8420 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 48/1000
2023-09-14 10:19:22.154 
Epoch 48/1000 
	 loss: 27.7036, MinusLogProbMetric: 27.7036, val_loss: 27.7733, val_MinusLogProbMetric: 27.7733

Epoch 48: val_loss did not improve from 27.73755
196/196 - 11s - loss: 27.7036 - MinusLogProbMetric: 27.7036 - val_loss: 27.7733 - val_MinusLogProbMetric: 27.7733 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 49/1000
2023-09-14 10:19:33.045 
Epoch 49/1000 
	 loss: 27.6927, MinusLogProbMetric: 27.6927, val_loss: 27.9406, val_MinusLogProbMetric: 27.9406

Epoch 49: val_loss did not improve from 27.73755
196/196 - 11s - loss: 27.6927 - MinusLogProbMetric: 27.6927 - val_loss: 27.9406 - val_MinusLogProbMetric: 27.9406 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 50/1000
2023-09-14 10:19:43.912 
Epoch 50/1000 
	 loss: 27.7158, MinusLogProbMetric: 27.7158, val_loss: 27.8309, val_MinusLogProbMetric: 27.8309

Epoch 50: val_loss did not improve from 27.73755
196/196 - 11s - loss: 27.7158 - MinusLogProbMetric: 27.7158 - val_loss: 27.8309 - val_MinusLogProbMetric: 27.8309 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 51/1000
2023-09-14 10:19:54.998 
Epoch 51/1000 
	 loss: 27.6976, MinusLogProbMetric: 27.6976, val_loss: 27.8145, val_MinusLogProbMetric: 27.8145

Epoch 51: val_loss did not improve from 27.73755
196/196 - 11s - loss: 27.6976 - MinusLogProbMetric: 27.6976 - val_loss: 27.8145 - val_MinusLogProbMetric: 27.8145 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 52/1000
2023-09-14 10:20:05.769 
Epoch 52/1000 
	 loss: 27.7104, MinusLogProbMetric: 27.7104, val_loss: 27.8348, val_MinusLogProbMetric: 27.8348

Epoch 52: val_loss did not improve from 27.73755
196/196 - 11s - loss: 27.7104 - MinusLogProbMetric: 27.7104 - val_loss: 27.8348 - val_MinusLogProbMetric: 27.8348 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 53/1000
2023-09-14 10:20:16.807 
Epoch 53/1000 
	 loss: 27.6731, MinusLogProbMetric: 27.6731, val_loss: 27.9118, val_MinusLogProbMetric: 27.9118

Epoch 53: val_loss did not improve from 27.73755
196/196 - 11s - loss: 27.6731 - MinusLogProbMetric: 27.6731 - val_loss: 27.9118 - val_MinusLogProbMetric: 27.9118 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 54/1000
2023-09-14 10:20:27.935 
Epoch 54/1000 
	 loss: 27.7085, MinusLogProbMetric: 27.7085, val_loss: 27.8079, val_MinusLogProbMetric: 27.8079

Epoch 54: val_loss did not improve from 27.73755
196/196 - 11s - loss: 27.7085 - MinusLogProbMetric: 27.7085 - val_loss: 27.8079 - val_MinusLogProbMetric: 27.8079 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 55/1000
2023-09-14 10:20:38.946 
Epoch 55/1000 
	 loss: 27.7052, MinusLogProbMetric: 27.7052, val_loss: 27.9545, val_MinusLogProbMetric: 27.9545

Epoch 55: val_loss did not improve from 27.73755
196/196 - 11s - loss: 27.7052 - MinusLogProbMetric: 27.7052 - val_loss: 27.9545 - val_MinusLogProbMetric: 27.9545 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 56/1000
2023-09-14 10:20:48.820 
Epoch 56/1000 
	 loss: 27.6839, MinusLogProbMetric: 27.6839, val_loss: 27.8038, val_MinusLogProbMetric: 27.8038

Epoch 56: val_loss did not improve from 27.73755
196/196 - 10s - loss: 27.6839 - MinusLogProbMetric: 27.6839 - val_loss: 27.8038 - val_MinusLogProbMetric: 27.8038 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 57/1000
2023-09-14 10:20:59.829 
Epoch 57/1000 
	 loss: 27.6705, MinusLogProbMetric: 27.6705, val_loss: 27.7282, val_MinusLogProbMetric: 27.7282

Epoch 57: val_loss improved from 27.73755 to 27.72818, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 11s - loss: 27.6705 - MinusLogProbMetric: 27.6705 - val_loss: 27.7282 - val_MinusLogProbMetric: 27.7282 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 58/1000
2023-09-14 10:21:11.027 
Epoch 58/1000 
	 loss: 27.6725, MinusLogProbMetric: 27.6725, val_loss: 27.8007, val_MinusLogProbMetric: 27.8007

Epoch 58: val_loss did not improve from 27.72818
196/196 - 11s - loss: 27.6725 - MinusLogProbMetric: 27.6725 - val_loss: 27.8007 - val_MinusLogProbMetric: 27.8007 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 59/1000
2023-09-14 10:21:22.020 
Epoch 59/1000 
	 loss: 27.6741, MinusLogProbMetric: 27.6741, val_loss: 27.7578, val_MinusLogProbMetric: 27.7578

Epoch 59: val_loss did not improve from 27.72818
196/196 - 11s - loss: 27.6741 - MinusLogProbMetric: 27.6741 - val_loss: 27.7578 - val_MinusLogProbMetric: 27.7578 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 60/1000
2023-09-14 10:21:33.134 
Epoch 60/1000 
	 loss: 27.6674, MinusLogProbMetric: 27.6674, val_loss: 27.7755, val_MinusLogProbMetric: 27.7755

Epoch 60: val_loss did not improve from 27.72818
196/196 - 11s - loss: 27.6674 - MinusLogProbMetric: 27.6674 - val_loss: 27.7755 - val_MinusLogProbMetric: 27.7755 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 61/1000
2023-09-14 10:21:44.260 
Epoch 61/1000 
	 loss: 27.6615, MinusLogProbMetric: 27.6615, val_loss: 27.8071, val_MinusLogProbMetric: 27.8071

Epoch 61: val_loss did not improve from 27.72818
196/196 - 11s - loss: 27.6615 - MinusLogProbMetric: 27.6615 - val_loss: 27.8071 - val_MinusLogProbMetric: 27.8071 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 62/1000
2023-09-14 10:21:55.397 
Epoch 62/1000 
	 loss: 27.6435, MinusLogProbMetric: 27.6435, val_loss: 27.7772, val_MinusLogProbMetric: 27.7772

Epoch 62: val_loss did not improve from 27.72818
196/196 - 11s - loss: 27.6435 - MinusLogProbMetric: 27.6435 - val_loss: 27.7772 - val_MinusLogProbMetric: 27.7772 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 63/1000
2023-09-14 10:22:06.580 
Epoch 63/1000 
	 loss: 27.6503, MinusLogProbMetric: 27.6503, val_loss: 27.7126, val_MinusLogProbMetric: 27.7126

Epoch 63: val_loss improved from 27.72818 to 27.71265, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 11s - loss: 27.6503 - MinusLogProbMetric: 27.6503 - val_loss: 27.7126 - val_MinusLogProbMetric: 27.7126 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 64/1000
2023-09-14 10:22:17.848 
Epoch 64/1000 
	 loss: 27.6489, MinusLogProbMetric: 27.6489, val_loss: 27.8924, val_MinusLogProbMetric: 27.8924

Epoch 64: val_loss did not improve from 27.71265
196/196 - 11s - loss: 27.6489 - MinusLogProbMetric: 27.6489 - val_loss: 27.8924 - val_MinusLogProbMetric: 27.8924 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 65/1000
2023-09-14 10:22:28.895 
Epoch 65/1000 
	 loss: 27.6337, MinusLogProbMetric: 27.6337, val_loss: 27.8613, val_MinusLogProbMetric: 27.8613

Epoch 65: val_loss did not improve from 27.71265
196/196 - 11s - loss: 27.6337 - MinusLogProbMetric: 27.6337 - val_loss: 27.8613 - val_MinusLogProbMetric: 27.8613 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 66/1000
2023-09-14 10:22:39.990 
Epoch 66/1000 
	 loss: 27.6418, MinusLogProbMetric: 27.6418, val_loss: 27.7235, val_MinusLogProbMetric: 27.7235

Epoch 66: val_loss did not improve from 27.71265
196/196 - 11s - loss: 27.6418 - MinusLogProbMetric: 27.6418 - val_loss: 27.7235 - val_MinusLogProbMetric: 27.7235 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 67/1000
2023-09-14 10:22:50.767 
Epoch 67/1000 
	 loss: 27.6243, MinusLogProbMetric: 27.6243, val_loss: 27.7272, val_MinusLogProbMetric: 27.7272

Epoch 67: val_loss did not improve from 27.71265
196/196 - 11s - loss: 27.6243 - MinusLogProbMetric: 27.6243 - val_loss: 27.7272 - val_MinusLogProbMetric: 27.7272 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 68/1000
2023-09-14 10:23:02.088 
Epoch 68/1000 
	 loss: 27.6247, MinusLogProbMetric: 27.6247, val_loss: 27.6685, val_MinusLogProbMetric: 27.6685

Epoch 68: val_loss improved from 27.71265 to 27.66849, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 11s - loss: 27.6247 - MinusLogProbMetric: 27.6247 - val_loss: 27.6685 - val_MinusLogProbMetric: 27.6685 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 69/1000
2023-09-14 10:23:13.357 
Epoch 69/1000 
	 loss: 27.6549, MinusLogProbMetric: 27.6549, val_loss: 27.7654, val_MinusLogProbMetric: 27.7654

Epoch 69: val_loss did not improve from 27.66849
196/196 - 11s - loss: 27.6549 - MinusLogProbMetric: 27.6549 - val_loss: 27.7654 - val_MinusLogProbMetric: 27.7654 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 70/1000
2023-09-14 10:23:24.567 
Epoch 70/1000 
	 loss: 27.6271, MinusLogProbMetric: 27.6271, val_loss: 27.7468, val_MinusLogProbMetric: 27.7468

Epoch 70: val_loss did not improve from 27.66849
196/196 - 11s - loss: 27.6271 - MinusLogProbMetric: 27.6271 - val_loss: 27.7468 - val_MinusLogProbMetric: 27.7468 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 71/1000
2023-09-14 10:23:35.640 
Epoch 71/1000 
	 loss: 27.6317, MinusLogProbMetric: 27.6317, val_loss: 27.7387, val_MinusLogProbMetric: 27.7387

Epoch 71: val_loss did not improve from 27.66849
196/196 - 11s - loss: 27.6317 - MinusLogProbMetric: 27.6317 - val_loss: 27.7387 - val_MinusLogProbMetric: 27.7387 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 72/1000
2023-09-14 10:23:46.838 
Epoch 72/1000 
	 loss: 27.6336, MinusLogProbMetric: 27.6336, val_loss: 27.7018, val_MinusLogProbMetric: 27.7018

Epoch 72: val_loss did not improve from 27.66849
196/196 - 11s - loss: 27.6336 - MinusLogProbMetric: 27.6336 - val_loss: 27.7018 - val_MinusLogProbMetric: 27.7018 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 73/1000
2023-09-14 10:23:58.097 
Epoch 73/1000 
	 loss: 27.6391, MinusLogProbMetric: 27.6391, val_loss: 27.8722, val_MinusLogProbMetric: 27.8722

Epoch 73: val_loss did not improve from 27.66849
196/196 - 11s - loss: 27.6391 - MinusLogProbMetric: 27.6391 - val_loss: 27.8722 - val_MinusLogProbMetric: 27.8722 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 74/1000
2023-09-14 10:24:09.387 
Epoch 74/1000 
	 loss: 27.6075, MinusLogProbMetric: 27.6075, val_loss: 27.7176, val_MinusLogProbMetric: 27.7176

Epoch 74: val_loss did not improve from 27.66849
196/196 - 11s - loss: 27.6075 - MinusLogProbMetric: 27.6075 - val_loss: 27.7176 - val_MinusLogProbMetric: 27.7176 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 75/1000
2023-09-14 10:24:20.350 
Epoch 75/1000 
	 loss: 27.5974, MinusLogProbMetric: 27.5974, val_loss: 27.7638, val_MinusLogProbMetric: 27.7638

Epoch 75: val_loss did not improve from 27.66849
196/196 - 11s - loss: 27.5974 - MinusLogProbMetric: 27.5974 - val_loss: 27.7638 - val_MinusLogProbMetric: 27.7638 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 76/1000
2023-09-14 10:24:31.581 
Epoch 76/1000 
	 loss: 27.6150, MinusLogProbMetric: 27.6150, val_loss: 27.7720, val_MinusLogProbMetric: 27.7720

Epoch 76: val_loss did not improve from 27.66849
196/196 - 11s - loss: 27.6150 - MinusLogProbMetric: 27.6150 - val_loss: 27.7720 - val_MinusLogProbMetric: 27.7720 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 77/1000
2023-09-14 10:24:42.793 
Epoch 77/1000 
	 loss: 27.5967, MinusLogProbMetric: 27.5967, val_loss: 27.6563, val_MinusLogProbMetric: 27.6563

Epoch 77: val_loss improved from 27.66849 to 27.65630, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 11s - loss: 27.5967 - MinusLogProbMetric: 27.5967 - val_loss: 27.6563 - val_MinusLogProbMetric: 27.6563 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 78/1000
2023-09-14 10:24:54.029 
Epoch 78/1000 
	 loss: 27.6009, MinusLogProbMetric: 27.6009, val_loss: 27.6849, val_MinusLogProbMetric: 27.6849

Epoch 78: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.6009 - MinusLogProbMetric: 27.6009 - val_loss: 27.6849 - val_MinusLogProbMetric: 27.6849 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 79/1000
2023-09-14 10:25:04.716 
Epoch 79/1000 
	 loss: 27.6057, MinusLogProbMetric: 27.6057, val_loss: 27.7459, val_MinusLogProbMetric: 27.7459

Epoch 79: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.6057 - MinusLogProbMetric: 27.6057 - val_loss: 27.7459 - val_MinusLogProbMetric: 27.7459 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 80/1000
2023-09-14 10:25:15.899 
Epoch 80/1000 
	 loss: 27.5872, MinusLogProbMetric: 27.5872, val_loss: 27.8550, val_MinusLogProbMetric: 27.8550

Epoch 80: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.5872 - MinusLogProbMetric: 27.5872 - val_loss: 27.8550 - val_MinusLogProbMetric: 27.8550 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 81/1000
2023-09-14 10:25:27.002 
Epoch 81/1000 
	 loss: 27.6135, MinusLogProbMetric: 27.6135, val_loss: 27.7355, val_MinusLogProbMetric: 27.7355

Epoch 81: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.6135 - MinusLogProbMetric: 27.6135 - val_loss: 27.7355 - val_MinusLogProbMetric: 27.7355 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 82/1000
2023-09-14 10:25:38.253 
Epoch 82/1000 
	 loss: 27.6053, MinusLogProbMetric: 27.6053, val_loss: 27.7439, val_MinusLogProbMetric: 27.7439

Epoch 82: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.6053 - MinusLogProbMetric: 27.6053 - val_loss: 27.7439 - val_MinusLogProbMetric: 27.7439 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 83/1000
2023-09-14 10:25:49.468 
Epoch 83/1000 
	 loss: 27.6058, MinusLogProbMetric: 27.6058, val_loss: 27.7183, val_MinusLogProbMetric: 27.7183

Epoch 83: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.6058 - MinusLogProbMetric: 27.6058 - val_loss: 27.7183 - val_MinusLogProbMetric: 27.7183 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 84/1000
2023-09-14 10:26:00.747 
Epoch 84/1000 
	 loss: 27.5956, MinusLogProbMetric: 27.5956, val_loss: 27.7425, val_MinusLogProbMetric: 27.7425

Epoch 84: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.5956 - MinusLogProbMetric: 27.5956 - val_loss: 27.7425 - val_MinusLogProbMetric: 27.7425 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 85/1000
2023-09-14 10:26:11.787 
Epoch 85/1000 
	 loss: 27.6022, MinusLogProbMetric: 27.6022, val_loss: 27.7050, val_MinusLogProbMetric: 27.7050

Epoch 85: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.6022 - MinusLogProbMetric: 27.6022 - val_loss: 27.7050 - val_MinusLogProbMetric: 27.7050 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 86/1000
2023-09-14 10:26:23.110 
Epoch 86/1000 
	 loss: 27.5925, MinusLogProbMetric: 27.5925, val_loss: 27.7635, val_MinusLogProbMetric: 27.7635

Epoch 86: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.5925 - MinusLogProbMetric: 27.5925 - val_loss: 27.7635 - val_MinusLogProbMetric: 27.7635 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 87/1000
2023-09-14 10:26:34.397 
Epoch 87/1000 
	 loss: 27.5888, MinusLogProbMetric: 27.5888, val_loss: 27.7737, val_MinusLogProbMetric: 27.7737

Epoch 87: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.5888 - MinusLogProbMetric: 27.5888 - val_loss: 27.7737 - val_MinusLogProbMetric: 27.7737 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 88/1000
2023-09-14 10:26:45.592 
Epoch 88/1000 
	 loss: 27.5889, MinusLogProbMetric: 27.5889, val_loss: 27.7161, val_MinusLogProbMetric: 27.7161

Epoch 88: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.5889 - MinusLogProbMetric: 27.5889 - val_loss: 27.7161 - val_MinusLogProbMetric: 27.7161 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 89/1000
2023-09-14 10:26:56.739 
Epoch 89/1000 
	 loss: 27.5958, MinusLogProbMetric: 27.5958, val_loss: 27.7780, val_MinusLogProbMetric: 27.7780

Epoch 89: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.5958 - MinusLogProbMetric: 27.5958 - val_loss: 27.7780 - val_MinusLogProbMetric: 27.7780 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 90/1000
2023-09-14 10:27:08.066 
Epoch 90/1000 
	 loss: 27.5997, MinusLogProbMetric: 27.5997, val_loss: 27.8325, val_MinusLogProbMetric: 27.8325

Epoch 90: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.5997 - MinusLogProbMetric: 27.5997 - val_loss: 27.8325 - val_MinusLogProbMetric: 27.8325 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 91/1000
2023-09-14 10:27:19.311 
Epoch 91/1000 
	 loss: 27.5805, MinusLogProbMetric: 27.5805, val_loss: 27.6863, val_MinusLogProbMetric: 27.6863

Epoch 91: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.5805 - MinusLogProbMetric: 27.5805 - val_loss: 27.6863 - val_MinusLogProbMetric: 27.6863 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 92/1000
2023-09-14 10:27:30.642 
Epoch 92/1000 
	 loss: 27.5782, MinusLogProbMetric: 27.5782, val_loss: 27.7274, val_MinusLogProbMetric: 27.7274

Epoch 92: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.5782 - MinusLogProbMetric: 27.5782 - val_loss: 27.7274 - val_MinusLogProbMetric: 27.7274 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 93/1000
2023-09-14 10:27:41.589 
Epoch 93/1000 
	 loss: 27.5757, MinusLogProbMetric: 27.5757, val_loss: 27.8331, val_MinusLogProbMetric: 27.8331

Epoch 93: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.5757 - MinusLogProbMetric: 27.5757 - val_loss: 27.8331 - val_MinusLogProbMetric: 27.8331 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 94/1000
2023-09-14 10:27:52.641 
Epoch 94/1000 
	 loss: 27.5978, MinusLogProbMetric: 27.5978, val_loss: 27.7515, val_MinusLogProbMetric: 27.7515

Epoch 94: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.5978 - MinusLogProbMetric: 27.5978 - val_loss: 27.7515 - val_MinusLogProbMetric: 27.7515 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 95/1000
2023-09-14 10:28:04.010 
Epoch 95/1000 
	 loss: 27.5668, MinusLogProbMetric: 27.5668, val_loss: 27.7216, val_MinusLogProbMetric: 27.7216

Epoch 95: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.5668 - MinusLogProbMetric: 27.5668 - val_loss: 27.7216 - val_MinusLogProbMetric: 27.7216 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 96/1000
2023-09-14 10:28:15.082 
Epoch 96/1000 
	 loss: 27.5735, MinusLogProbMetric: 27.5735, val_loss: 27.7494, val_MinusLogProbMetric: 27.7494

Epoch 96: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.5735 - MinusLogProbMetric: 27.5735 - val_loss: 27.7494 - val_MinusLogProbMetric: 27.7494 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 97/1000
2023-09-14 10:28:26.298 
Epoch 97/1000 
	 loss: 27.5831, MinusLogProbMetric: 27.5831, val_loss: 27.7211, val_MinusLogProbMetric: 27.7211

Epoch 97: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.5831 - MinusLogProbMetric: 27.5831 - val_loss: 27.7211 - val_MinusLogProbMetric: 27.7211 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 98/1000
2023-09-14 10:28:37.533 
Epoch 98/1000 
	 loss: 27.5712, MinusLogProbMetric: 27.5712, val_loss: 27.7193, val_MinusLogProbMetric: 27.7193

Epoch 98: val_loss did not improve from 27.65630
196/196 - 11s - loss: 27.5712 - MinusLogProbMetric: 27.5712 - val_loss: 27.7193 - val_MinusLogProbMetric: 27.7193 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 99/1000
2023-09-14 10:28:48.901 
Epoch 99/1000 
	 loss: 27.5687, MinusLogProbMetric: 27.5687, val_loss: 27.6499, val_MinusLogProbMetric: 27.6499

Epoch 99: val_loss improved from 27.65630 to 27.64989, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 11s - loss: 27.5687 - MinusLogProbMetric: 27.5687 - val_loss: 27.6499 - val_MinusLogProbMetric: 27.6499 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 100/1000
2023-09-14 10:28:59.742 
Epoch 100/1000 
	 loss: 27.5547, MinusLogProbMetric: 27.5547, val_loss: 27.7557, val_MinusLogProbMetric: 27.7557

Epoch 100: val_loss did not improve from 27.64989
196/196 - 11s - loss: 27.5547 - MinusLogProbMetric: 27.5547 - val_loss: 27.7557 - val_MinusLogProbMetric: 27.7557 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 101/1000
2023-09-14 10:29:10.763 
Epoch 101/1000 
	 loss: 27.5680, MinusLogProbMetric: 27.5680, val_loss: 27.7189, val_MinusLogProbMetric: 27.7189

Epoch 101: val_loss did not improve from 27.64989
196/196 - 11s - loss: 27.5680 - MinusLogProbMetric: 27.5680 - val_loss: 27.7189 - val_MinusLogProbMetric: 27.7189 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 102/1000
2023-09-14 10:29:22.076 
Epoch 102/1000 
	 loss: 27.5644, MinusLogProbMetric: 27.5644, val_loss: 27.6705, val_MinusLogProbMetric: 27.6705

Epoch 102: val_loss did not improve from 27.64989
196/196 - 11s - loss: 27.5644 - MinusLogProbMetric: 27.5644 - val_loss: 27.6705 - val_MinusLogProbMetric: 27.6705 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 103/1000
2023-09-14 10:29:33.375 
Epoch 103/1000 
	 loss: 27.5611, MinusLogProbMetric: 27.5611, val_loss: 27.6910, val_MinusLogProbMetric: 27.6910

Epoch 103: val_loss did not improve from 27.64989
196/196 - 11s - loss: 27.5611 - MinusLogProbMetric: 27.5611 - val_loss: 27.6910 - val_MinusLogProbMetric: 27.6910 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 104/1000
2023-09-14 10:29:44.587 
Epoch 104/1000 
	 loss: 27.5493, MinusLogProbMetric: 27.5493, val_loss: 27.7099, val_MinusLogProbMetric: 27.7099

Epoch 104: val_loss did not improve from 27.64989
196/196 - 11s - loss: 27.5493 - MinusLogProbMetric: 27.5493 - val_loss: 27.7099 - val_MinusLogProbMetric: 27.7099 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 105/1000
2023-09-14 10:29:55.720 
Epoch 105/1000 
	 loss: 27.5692, MinusLogProbMetric: 27.5692, val_loss: 27.7294, val_MinusLogProbMetric: 27.7294

Epoch 105: val_loss did not improve from 27.64989
196/196 - 11s - loss: 27.5692 - MinusLogProbMetric: 27.5692 - val_loss: 27.7294 - val_MinusLogProbMetric: 27.7294 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 106/1000
2023-09-14 10:30:06.118 
Epoch 106/1000 
	 loss: 27.5671, MinusLogProbMetric: 27.5671, val_loss: 27.6798, val_MinusLogProbMetric: 27.6798

Epoch 106: val_loss did not improve from 27.64989
196/196 - 10s - loss: 27.5671 - MinusLogProbMetric: 27.5671 - val_loss: 27.6798 - val_MinusLogProbMetric: 27.6798 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 107/1000
2023-09-14 10:30:16.730 
Epoch 107/1000 
	 loss: 27.5510, MinusLogProbMetric: 27.5510, val_loss: 27.7387, val_MinusLogProbMetric: 27.7387

Epoch 107: val_loss did not improve from 27.64989
196/196 - 11s - loss: 27.5510 - MinusLogProbMetric: 27.5510 - val_loss: 27.7387 - val_MinusLogProbMetric: 27.7387 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 108/1000
2023-09-14 10:30:27.985 
Epoch 108/1000 
	 loss: 27.5555, MinusLogProbMetric: 27.5555, val_loss: 27.7299, val_MinusLogProbMetric: 27.7299

Epoch 108: val_loss did not improve from 27.64989
196/196 - 11s - loss: 27.5555 - MinusLogProbMetric: 27.5555 - val_loss: 27.7299 - val_MinusLogProbMetric: 27.7299 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 109/1000
2023-09-14 10:30:39.255 
Epoch 109/1000 
	 loss: 27.5547, MinusLogProbMetric: 27.5547, val_loss: 27.7102, val_MinusLogProbMetric: 27.7102

Epoch 109: val_loss did not improve from 27.64989
196/196 - 11s - loss: 27.5547 - MinusLogProbMetric: 27.5547 - val_loss: 27.7102 - val_MinusLogProbMetric: 27.7102 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 110/1000
2023-09-14 10:30:50.569 
Epoch 110/1000 
	 loss: 27.5499, MinusLogProbMetric: 27.5499, val_loss: 27.6872, val_MinusLogProbMetric: 27.6872

Epoch 110: val_loss did not improve from 27.64989
196/196 - 11s - loss: 27.5499 - MinusLogProbMetric: 27.5499 - val_loss: 27.6872 - val_MinusLogProbMetric: 27.6872 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 111/1000
2023-09-14 10:31:02.007 
Epoch 111/1000 
	 loss: 27.5352, MinusLogProbMetric: 27.5352, val_loss: 27.7517, val_MinusLogProbMetric: 27.7517

Epoch 111: val_loss did not improve from 27.64989
196/196 - 11s - loss: 27.5352 - MinusLogProbMetric: 27.5352 - val_loss: 27.7517 - val_MinusLogProbMetric: 27.7517 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 112/1000
2023-09-14 10:31:13.304 
Epoch 112/1000 
	 loss: 27.5374, MinusLogProbMetric: 27.5374, val_loss: 27.6881, val_MinusLogProbMetric: 27.6881

Epoch 112: val_loss did not improve from 27.64989
196/196 - 11s - loss: 27.5374 - MinusLogProbMetric: 27.5374 - val_loss: 27.6881 - val_MinusLogProbMetric: 27.6881 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 113/1000
2023-09-14 10:31:24.685 
Epoch 113/1000 
	 loss: 27.5397, MinusLogProbMetric: 27.5397, val_loss: 27.7359, val_MinusLogProbMetric: 27.7359

Epoch 113: val_loss did not improve from 27.64989
196/196 - 11s - loss: 27.5397 - MinusLogProbMetric: 27.5397 - val_loss: 27.7359 - val_MinusLogProbMetric: 27.7359 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 114/1000
2023-09-14 10:31:35.890 
Epoch 114/1000 
	 loss: 27.5463, MinusLogProbMetric: 27.5463, val_loss: 27.6473, val_MinusLogProbMetric: 27.6473

Epoch 114: val_loss improved from 27.64989 to 27.64730, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 11s - loss: 27.5463 - MinusLogProbMetric: 27.5463 - val_loss: 27.6473 - val_MinusLogProbMetric: 27.6473 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 115/1000
2023-09-14 10:31:47.174 
Epoch 115/1000 
	 loss: 27.5389, MinusLogProbMetric: 27.5389, val_loss: 27.7620, val_MinusLogProbMetric: 27.7620

Epoch 115: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5389 - MinusLogProbMetric: 27.5389 - val_loss: 27.7620 - val_MinusLogProbMetric: 27.7620 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 116/1000
2023-09-14 10:31:57.704 
Epoch 116/1000 
	 loss: 27.5367, MinusLogProbMetric: 27.5367, val_loss: 27.7470, val_MinusLogProbMetric: 27.7470

Epoch 116: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5367 - MinusLogProbMetric: 27.5367 - val_loss: 27.7470 - val_MinusLogProbMetric: 27.7470 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 117/1000
2023-09-14 10:32:08.788 
Epoch 117/1000 
	 loss: 27.5446, MinusLogProbMetric: 27.5446, val_loss: 27.6481, val_MinusLogProbMetric: 27.6481

Epoch 117: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5446 - MinusLogProbMetric: 27.5446 - val_loss: 27.6481 - val_MinusLogProbMetric: 27.6481 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 118/1000
2023-09-14 10:32:20.102 
Epoch 118/1000 
	 loss: 27.5448, MinusLogProbMetric: 27.5448, val_loss: 27.6696, val_MinusLogProbMetric: 27.6696

Epoch 118: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5448 - MinusLogProbMetric: 27.5448 - val_loss: 27.6696 - val_MinusLogProbMetric: 27.6696 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 119/1000
2023-09-14 10:32:30.582 
Epoch 119/1000 
	 loss: 27.5314, MinusLogProbMetric: 27.5314, val_loss: 27.6845, val_MinusLogProbMetric: 27.6845

Epoch 119: val_loss did not improve from 27.64730
196/196 - 10s - loss: 27.5314 - MinusLogProbMetric: 27.5314 - val_loss: 27.6845 - val_MinusLogProbMetric: 27.6845 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 120/1000
2023-09-14 10:32:41.758 
Epoch 120/1000 
	 loss: 27.5193, MinusLogProbMetric: 27.5193, val_loss: 27.7156, val_MinusLogProbMetric: 27.7156

Epoch 120: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5193 - MinusLogProbMetric: 27.5193 - val_loss: 27.7156 - val_MinusLogProbMetric: 27.7156 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 121/1000
2023-09-14 10:32:52.378 
Epoch 121/1000 
	 loss: 27.5378, MinusLogProbMetric: 27.5378, val_loss: 27.6716, val_MinusLogProbMetric: 27.6716

Epoch 121: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5378 - MinusLogProbMetric: 27.5378 - val_loss: 27.6716 - val_MinusLogProbMetric: 27.6716 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 122/1000
2023-09-14 10:33:03.700 
Epoch 122/1000 
	 loss: 27.5292, MinusLogProbMetric: 27.5292, val_loss: 27.7194, val_MinusLogProbMetric: 27.7194

Epoch 122: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5292 - MinusLogProbMetric: 27.5292 - val_loss: 27.7194 - val_MinusLogProbMetric: 27.7194 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 123/1000
2023-09-14 10:33:15.186 
Epoch 123/1000 
	 loss: 27.5296, MinusLogProbMetric: 27.5296, val_loss: 27.7151, val_MinusLogProbMetric: 27.7151

Epoch 123: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5296 - MinusLogProbMetric: 27.5296 - val_loss: 27.7151 - val_MinusLogProbMetric: 27.7151 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 124/1000
2023-09-14 10:33:25.971 
Epoch 124/1000 
	 loss: 27.5416, MinusLogProbMetric: 27.5416, val_loss: 27.6839, val_MinusLogProbMetric: 27.6839

Epoch 124: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5416 - MinusLogProbMetric: 27.5416 - val_loss: 27.6839 - val_MinusLogProbMetric: 27.6839 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 125/1000
2023-09-14 10:33:37.338 
Epoch 125/1000 
	 loss: 27.5156, MinusLogProbMetric: 27.5156, val_loss: 27.7587, val_MinusLogProbMetric: 27.7587

Epoch 125: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5156 - MinusLogProbMetric: 27.5156 - val_loss: 27.7587 - val_MinusLogProbMetric: 27.7587 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 126/1000
2023-09-14 10:33:48.472 
Epoch 126/1000 
	 loss: 27.5290, MinusLogProbMetric: 27.5290, val_loss: 27.6672, val_MinusLogProbMetric: 27.6672

Epoch 126: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5290 - MinusLogProbMetric: 27.5290 - val_loss: 27.6672 - val_MinusLogProbMetric: 27.6672 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 127/1000
2023-09-14 10:33:58.244 
Epoch 127/1000 
	 loss: 27.5254, MinusLogProbMetric: 27.5254, val_loss: 27.6530, val_MinusLogProbMetric: 27.6530

Epoch 127: val_loss did not improve from 27.64730
196/196 - 10s - loss: 27.5254 - MinusLogProbMetric: 27.5254 - val_loss: 27.6530 - val_MinusLogProbMetric: 27.6530 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 128/1000
2023-09-14 10:34:09.430 
Epoch 128/1000 
	 loss: 27.5261, MinusLogProbMetric: 27.5261, val_loss: 27.6846, val_MinusLogProbMetric: 27.6846

Epoch 128: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5261 - MinusLogProbMetric: 27.5261 - val_loss: 27.6846 - val_MinusLogProbMetric: 27.6846 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 129/1000
2023-09-14 10:34:19.688 
Epoch 129/1000 
	 loss: 27.5358, MinusLogProbMetric: 27.5358, val_loss: 27.7628, val_MinusLogProbMetric: 27.7628

Epoch 129: val_loss did not improve from 27.64730
196/196 - 10s - loss: 27.5358 - MinusLogProbMetric: 27.5358 - val_loss: 27.7628 - val_MinusLogProbMetric: 27.7628 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 130/1000
2023-09-14 10:34:30.475 
Epoch 130/1000 
	 loss: 27.5185, MinusLogProbMetric: 27.5185, val_loss: 27.6668, val_MinusLogProbMetric: 27.6668

Epoch 130: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5185 - MinusLogProbMetric: 27.5185 - val_loss: 27.6668 - val_MinusLogProbMetric: 27.6668 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 131/1000
2023-09-14 10:34:41.780 
Epoch 131/1000 
	 loss: 27.5100, MinusLogProbMetric: 27.5100, val_loss: 27.6959, val_MinusLogProbMetric: 27.6959

Epoch 131: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5100 - MinusLogProbMetric: 27.5100 - val_loss: 27.6959 - val_MinusLogProbMetric: 27.6959 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 132/1000
2023-09-14 10:34:52.575 
Epoch 132/1000 
	 loss: 27.5268, MinusLogProbMetric: 27.5268, val_loss: 27.6698, val_MinusLogProbMetric: 27.6698

Epoch 132: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5268 - MinusLogProbMetric: 27.5268 - val_loss: 27.6698 - val_MinusLogProbMetric: 27.6698 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 133/1000
2023-09-14 10:35:03.685 
Epoch 133/1000 
	 loss: 27.5155, MinusLogProbMetric: 27.5155, val_loss: 27.6547, val_MinusLogProbMetric: 27.6547

Epoch 133: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5155 - MinusLogProbMetric: 27.5155 - val_loss: 27.6547 - val_MinusLogProbMetric: 27.6547 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 134/1000
2023-09-14 10:35:14.888 
Epoch 134/1000 
	 loss: 27.5090, MinusLogProbMetric: 27.5090, val_loss: 27.7155, val_MinusLogProbMetric: 27.7155

Epoch 134: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5090 - MinusLogProbMetric: 27.5090 - val_loss: 27.7155 - val_MinusLogProbMetric: 27.7155 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 135/1000
2023-09-14 10:35:25.622 
Epoch 135/1000 
	 loss: 27.5258, MinusLogProbMetric: 27.5258, val_loss: 27.7587, val_MinusLogProbMetric: 27.7587

Epoch 135: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5258 - MinusLogProbMetric: 27.5258 - val_loss: 27.7587 - val_MinusLogProbMetric: 27.7587 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 136/1000
2023-09-14 10:35:36.510 
Epoch 136/1000 
	 loss: 27.5060, MinusLogProbMetric: 27.5060, val_loss: 27.7045, val_MinusLogProbMetric: 27.7045

Epoch 136: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5060 - MinusLogProbMetric: 27.5060 - val_loss: 27.7045 - val_MinusLogProbMetric: 27.7045 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 137/1000
2023-09-14 10:35:47.578 
Epoch 137/1000 
	 loss: 27.5106, MinusLogProbMetric: 27.5106, val_loss: 27.6648, val_MinusLogProbMetric: 27.6648

Epoch 137: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5106 - MinusLogProbMetric: 27.5106 - val_loss: 27.6648 - val_MinusLogProbMetric: 27.6648 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 138/1000
2023-09-14 10:35:58.726 
Epoch 138/1000 
	 loss: 27.5014, MinusLogProbMetric: 27.5014, val_loss: 27.6974, val_MinusLogProbMetric: 27.6974

Epoch 138: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5014 - MinusLogProbMetric: 27.5014 - val_loss: 27.6974 - val_MinusLogProbMetric: 27.6974 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 139/1000
2023-09-14 10:36:09.819 
Epoch 139/1000 
	 loss: 27.5038, MinusLogProbMetric: 27.5038, val_loss: 27.7108, val_MinusLogProbMetric: 27.7108

Epoch 139: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5038 - MinusLogProbMetric: 27.5038 - val_loss: 27.7108 - val_MinusLogProbMetric: 27.7108 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 140/1000
2023-09-14 10:36:20.975 
Epoch 140/1000 
	 loss: 27.5158, MinusLogProbMetric: 27.5158, val_loss: 27.6868, val_MinusLogProbMetric: 27.6868

Epoch 140: val_loss did not improve from 27.64730
196/196 - 11s - loss: 27.5158 - MinusLogProbMetric: 27.5158 - val_loss: 27.6868 - val_MinusLogProbMetric: 27.6868 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 141/1000
2023-09-14 10:36:32.245 
Epoch 141/1000 
	 loss: 27.5057, MinusLogProbMetric: 27.5057, val_loss: 27.6444, val_MinusLogProbMetric: 27.6444

Epoch 141: val_loss improved from 27.64730 to 27.64439, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 11s - loss: 27.5057 - MinusLogProbMetric: 27.5057 - val_loss: 27.6444 - val_MinusLogProbMetric: 27.6444 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 142/1000
2023-09-14 10:36:43.545 
Epoch 142/1000 
	 loss: 27.4973, MinusLogProbMetric: 27.4973, val_loss: 27.6819, val_MinusLogProbMetric: 27.6819

Epoch 142: val_loss did not improve from 27.64439
196/196 - 11s - loss: 27.4973 - MinusLogProbMetric: 27.4973 - val_loss: 27.6819 - val_MinusLogProbMetric: 27.6819 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 143/1000
2023-09-14 10:36:54.974 
Epoch 143/1000 
	 loss: 27.5051, MinusLogProbMetric: 27.5051, val_loss: 27.6523, val_MinusLogProbMetric: 27.6523

Epoch 143: val_loss did not improve from 27.64439
196/196 - 11s - loss: 27.5051 - MinusLogProbMetric: 27.5051 - val_loss: 27.6523 - val_MinusLogProbMetric: 27.6523 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 144/1000
2023-09-14 10:37:06.051 
Epoch 144/1000 
	 loss: 27.5029, MinusLogProbMetric: 27.5029, val_loss: 27.6479, val_MinusLogProbMetric: 27.6479

Epoch 144: val_loss did not improve from 27.64439
196/196 - 11s - loss: 27.5029 - MinusLogProbMetric: 27.5029 - val_loss: 27.6479 - val_MinusLogProbMetric: 27.6479 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 145/1000
2023-09-14 10:37:17.163 
Epoch 145/1000 
	 loss: 27.5013, MinusLogProbMetric: 27.5013, val_loss: 27.6871, val_MinusLogProbMetric: 27.6871

Epoch 145: val_loss did not improve from 27.64439
196/196 - 11s - loss: 27.5013 - MinusLogProbMetric: 27.5013 - val_loss: 27.6871 - val_MinusLogProbMetric: 27.6871 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 146/1000
2023-09-14 10:37:28.466 
Epoch 146/1000 
	 loss: 27.4929, MinusLogProbMetric: 27.4929, val_loss: 27.6365, val_MinusLogProbMetric: 27.6365

Epoch 146: val_loss improved from 27.64439 to 27.63650, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 11s - loss: 27.4929 - MinusLogProbMetric: 27.4929 - val_loss: 27.6365 - val_MinusLogProbMetric: 27.6365 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 147/1000
2023-09-14 10:37:39.437 
Epoch 147/1000 
	 loss: 27.5002, MinusLogProbMetric: 27.5002, val_loss: 27.7211, val_MinusLogProbMetric: 27.7211

Epoch 147: val_loss did not improve from 27.63650
196/196 - 11s - loss: 27.5002 - MinusLogProbMetric: 27.5002 - val_loss: 27.7211 - val_MinusLogProbMetric: 27.7211 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 148/1000
2023-09-14 10:37:50.463 
Epoch 148/1000 
	 loss: 27.4962, MinusLogProbMetric: 27.4962, val_loss: 27.6898, val_MinusLogProbMetric: 27.6898

Epoch 148: val_loss did not improve from 27.63650
196/196 - 11s - loss: 27.4962 - MinusLogProbMetric: 27.4962 - val_loss: 27.6898 - val_MinusLogProbMetric: 27.6898 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 149/1000
2023-09-14 10:38:01.828 
Epoch 149/1000 
	 loss: 27.5145, MinusLogProbMetric: 27.5145, val_loss: 27.6614, val_MinusLogProbMetric: 27.6614

Epoch 149: val_loss did not improve from 27.63650
196/196 - 11s - loss: 27.5145 - MinusLogProbMetric: 27.5145 - val_loss: 27.6614 - val_MinusLogProbMetric: 27.6614 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 150/1000
2023-09-14 10:38:13.180 
Epoch 150/1000 
	 loss: 27.4959, MinusLogProbMetric: 27.4959, val_loss: 27.6794, val_MinusLogProbMetric: 27.6794

Epoch 150: val_loss did not improve from 27.63650
196/196 - 11s - loss: 27.4959 - MinusLogProbMetric: 27.4959 - val_loss: 27.6794 - val_MinusLogProbMetric: 27.6794 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 151/1000
2023-09-14 10:38:24.596 
Epoch 151/1000 
	 loss: 27.4906, MinusLogProbMetric: 27.4906, val_loss: 27.7242, val_MinusLogProbMetric: 27.7242

Epoch 151: val_loss did not improve from 27.63650
196/196 - 11s - loss: 27.4906 - MinusLogProbMetric: 27.4906 - val_loss: 27.7242 - val_MinusLogProbMetric: 27.7242 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 152/1000
2023-09-14 10:38:35.877 
Epoch 152/1000 
	 loss: 27.4983, MinusLogProbMetric: 27.4983, val_loss: 27.7479, val_MinusLogProbMetric: 27.7479

Epoch 152: val_loss did not improve from 27.63650
196/196 - 11s - loss: 27.4983 - MinusLogProbMetric: 27.4983 - val_loss: 27.7479 - val_MinusLogProbMetric: 27.7479 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 153/1000
2023-09-14 10:38:47.005 
Epoch 153/1000 
	 loss: 27.4917, MinusLogProbMetric: 27.4917, val_loss: 27.6464, val_MinusLogProbMetric: 27.6464

Epoch 153: val_loss did not improve from 27.63650
196/196 - 11s - loss: 27.4917 - MinusLogProbMetric: 27.4917 - val_loss: 27.6464 - val_MinusLogProbMetric: 27.6464 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 154/1000
2023-09-14 10:38:57.859 
Epoch 154/1000 
	 loss: 27.4928, MinusLogProbMetric: 27.4928, val_loss: 27.7717, val_MinusLogProbMetric: 27.7717

Epoch 154: val_loss did not improve from 27.63650
196/196 - 11s - loss: 27.4928 - MinusLogProbMetric: 27.4928 - val_loss: 27.7717 - val_MinusLogProbMetric: 27.7717 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 155/1000
2023-09-14 10:39:08.900 
Epoch 155/1000 
	 loss: 27.4912, MinusLogProbMetric: 27.4912, val_loss: 27.6782, val_MinusLogProbMetric: 27.6782

Epoch 155: val_loss did not improve from 27.63650
196/196 - 11s - loss: 27.4912 - MinusLogProbMetric: 27.4912 - val_loss: 27.6782 - val_MinusLogProbMetric: 27.6782 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 156/1000
2023-09-14 10:39:19.713 
Epoch 156/1000 
	 loss: 27.4955, MinusLogProbMetric: 27.4955, val_loss: 27.6721, val_MinusLogProbMetric: 27.6721

Epoch 156: val_loss did not improve from 27.63650
196/196 - 11s - loss: 27.4955 - MinusLogProbMetric: 27.4955 - val_loss: 27.6721 - val_MinusLogProbMetric: 27.6721 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 157/1000
2023-09-14 10:39:30.954 
Epoch 157/1000 
	 loss: 27.4870, MinusLogProbMetric: 27.4870, val_loss: 27.6441, val_MinusLogProbMetric: 27.6441

Epoch 157: val_loss did not improve from 27.63650
196/196 - 11s - loss: 27.4870 - MinusLogProbMetric: 27.4870 - val_loss: 27.6441 - val_MinusLogProbMetric: 27.6441 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 158/1000
2023-09-14 10:39:42.150 
Epoch 158/1000 
	 loss: 27.4969, MinusLogProbMetric: 27.4969, val_loss: 27.6918, val_MinusLogProbMetric: 27.6918

Epoch 158: val_loss did not improve from 27.63650
196/196 - 11s - loss: 27.4969 - MinusLogProbMetric: 27.4969 - val_loss: 27.6918 - val_MinusLogProbMetric: 27.6918 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 159/1000
2023-09-14 10:39:53.355 
Epoch 159/1000 
	 loss: 27.5032, MinusLogProbMetric: 27.5032, val_loss: 27.7256, val_MinusLogProbMetric: 27.7256

Epoch 159: val_loss did not improve from 27.63650
196/196 - 11s - loss: 27.5032 - MinusLogProbMetric: 27.5032 - val_loss: 27.7256 - val_MinusLogProbMetric: 27.7256 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 160/1000
2023-09-14 10:40:03.303 
Epoch 160/1000 
	 loss: 27.4968, MinusLogProbMetric: 27.4968, val_loss: 27.7741, val_MinusLogProbMetric: 27.7741

Epoch 160: val_loss did not improve from 27.63650
196/196 - 10s - loss: 27.4968 - MinusLogProbMetric: 27.4968 - val_loss: 27.7741 - val_MinusLogProbMetric: 27.7741 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 161/1000
2023-09-14 10:40:14.245 
Epoch 161/1000 
	 loss: 27.4876, MinusLogProbMetric: 27.4876, val_loss: 27.8023, val_MinusLogProbMetric: 27.8023

Epoch 161: val_loss did not improve from 27.63650
196/196 - 11s - loss: 27.4876 - MinusLogProbMetric: 27.4876 - val_loss: 27.8023 - val_MinusLogProbMetric: 27.8023 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 162/1000
2023-09-14 10:40:25.827 
Epoch 162/1000 
	 loss: 27.5070, MinusLogProbMetric: 27.5070, val_loss: 27.6893, val_MinusLogProbMetric: 27.6893

Epoch 162: val_loss did not improve from 27.63650
196/196 - 12s - loss: 27.5070 - MinusLogProbMetric: 27.5070 - val_loss: 27.6893 - val_MinusLogProbMetric: 27.6893 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 163/1000
2023-09-14 10:40:37.393 
Epoch 163/1000 
	 loss: 27.4787, MinusLogProbMetric: 27.4787, val_loss: 27.6838, val_MinusLogProbMetric: 27.6838

Epoch 163: val_loss did not improve from 27.63650
196/196 - 12s - loss: 27.4787 - MinusLogProbMetric: 27.4787 - val_loss: 27.6838 - val_MinusLogProbMetric: 27.6838 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 164/1000
2023-09-14 10:40:48.926 
Epoch 164/1000 
	 loss: 27.4757, MinusLogProbMetric: 27.4757, val_loss: 27.7508, val_MinusLogProbMetric: 27.7508

Epoch 164: val_loss did not improve from 27.63650
196/196 - 12s - loss: 27.4757 - MinusLogProbMetric: 27.4757 - val_loss: 27.7508 - val_MinusLogProbMetric: 27.7508 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 165/1000
2023-09-14 10:41:00.156 
Epoch 165/1000 
	 loss: 27.4865, MinusLogProbMetric: 27.4865, val_loss: 27.7004, val_MinusLogProbMetric: 27.7004

Epoch 165: val_loss did not improve from 27.63650
196/196 - 11s - loss: 27.4865 - MinusLogProbMetric: 27.4865 - val_loss: 27.7004 - val_MinusLogProbMetric: 27.7004 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 166/1000
2023-09-14 10:41:11.452 
Epoch 166/1000 
	 loss: 27.4792, MinusLogProbMetric: 27.4792, val_loss: 27.6751, val_MinusLogProbMetric: 27.6751

Epoch 166: val_loss did not improve from 27.63650
196/196 - 11s - loss: 27.4792 - MinusLogProbMetric: 27.4792 - val_loss: 27.6751 - val_MinusLogProbMetric: 27.6751 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 167/1000
2023-09-14 10:41:22.471 
Epoch 167/1000 
	 loss: 27.4910, MinusLogProbMetric: 27.4910, val_loss: 27.6788, val_MinusLogProbMetric: 27.6788

Epoch 167: val_loss did not improve from 27.63650
196/196 - 11s - loss: 27.4910 - MinusLogProbMetric: 27.4910 - val_loss: 27.6788 - val_MinusLogProbMetric: 27.6788 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 168/1000
2023-09-14 10:41:33.621 
Epoch 168/1000 
	 loss: 27.4712, MinusLogProbMetric: 27.4712, val_loss: 27.6308, val_MinusLogProbMetric: 27.6308

Epoch 168: val_loss improved from 27.63650 to 27.63083, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 11s - loss: 27.4712 - MinusLogProbMetric: 27.4712 - val_loss: 27.6308 - val_MinusLogProbMetric: 27.6308 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 169/1000
2023-09-14 10:41:44.858 
Epoch 169/1000 
	 loss: 27.4808, MinusLogProbMetric: 27.4808, val_loss: 27.7856, val_MinusLogProbMetric: 27.7856

Epoch 169: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4808 - MinusLogProbMetric: 27.4808 - val_loss: 27.7856 - val_MinusLogProbMetric: 27.7856 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 170/1000
2023-09-14 10:41:55.773 
Epoch 170/1000 
	 loss: 27.4892, MinusLogProbMetric: 27.4892, val_loss: 27.6718, val_MinusLogProbMetric: 27.6718

Epoch 170: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4892 - MinusLogProbMetric: 27.4892 - val_loss: 27.6718 - val_MinusLogProbMetric: 27.6718 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 171/1000
2023-09-14 10:42:07.168 
Epoch 171/1000 
	 loss: 27.4744, MinusLogProbMetric: 27.4744, val_loss: 27.6934, val_MinusLogProbMetric: 27.6934

Epoch 171: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4744 - MinusLogProbMetric: 27.4744 - val_loss: 27.6934 - val_MinusLogProbMetric: 27.6934 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 172/1000
2023-09-14 10:42:18.396 
Epoch 172/1000 
	 loss: 27.4695, MinusLogProbMetric: 27.4695, val_loss: 27.7031, val_MinusLogProbMetric: 27.7031

Epoch 172: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4695 - MinusLogProbMetric: 27.4695 - val_loss: 27.7031 - val_MinusLogProbMetric: 27.7031 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 173/1000
2023-09-14 10:42:29.323 
Epoch 173/1000 
	 loss: 27.4747, MinusLogProbMetric: 27.4747, val_loss: 27.7046, val_MinusLogProbMetric: 27.7046

Epoch 173: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4747 - MinusLogProbMetric: 27.4747 - val_loss: 27.7046 - val_MinusLogProbMetric: 27.7046 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 174/1000
2023-09-14 10:42:40.493 
Epoch 174/1000 
	 loss: 27.4836, MinusLogProbMetric: 27.4836, val_loss: 27.6573, val_MinusLogProbMetric: 27.6573

Epoch 174: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4836 - MinusLogProbMetric: 27.4836 - val_loss: 27.6573 - val_MinusLogProbMetric: 27.6573 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 175/1000
2023-09-14 10:42:51.717 
Epoch 175/1000 
	 loss: 27.4878, MinusLogProbMetric: 27.4878, val_loss: 27.6906, val_MinusLogProbMetric: 27.6906

Epoch 175: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4878 - MinusLogProbMetric: 27.4878 - val_loss: 27.6906 - val_MinusLogProbMetric: 27.6906 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 176/1000
2023-09-14 10:43:03.004 
Epoch 176/1000 
	 loss: 27.4644, MinusLogProbMetric: 27.4644, val_loss: 27.7113, val_MinusLogProbMetric: 27.7113

Epoch 176: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4644 - MinusLogProbMetric: 27.4644 - val_loss: 27.7113 - val_MinusLogProbMetric: 27.7113 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 177/1000
2023-09-14 10:43:14.296 
Epoch 177/1000 
	 loss: 27.4704, MinusLogProbMetric: 27.4704, val_loss: 27.6936, val_MinusLogProbMetric: 27.6936

Epoch 177: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4704 - MinusLogProbMetric: 27.4704 - val_loss: 27.6936 - val_MinusLogProbMetric: 27.6936 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 178/1000
2023-09-14 10:43:25.651 
Epoch 178/1000 
	 loss: 27.4651, MinusLogProbMetric: 27.4651, val_loss: 27.7357, val_MinusLogProbMetric: 27.7357

Epoch 178: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4651 - MinusLogProbMetric: 27.4651 - val_loss: 27.7357 - val_MinusLogProbMetric: 27.7357 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 179/1000
2023-09-14 10:43:36.810 
Epoch 179/1000 
	 loss: 27.4628, MinusLogProbMetric: 27.4628, val_loss: 27.6728, val_MinusLogProbMetric: 27.6728

Epoch 179: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4628 - MinusLogProbMetric: 27.4628 - val_loss: 27.6728 - val_MinusLogProbMetric: 27.6728 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 180/1000
2023-09-14 10:43:48.027 
Epoch 180/1000 
	 loss: 27.4691, MinusLogProbMetric: 27.4691, val_loss: 27.6610, val_MinusLogProbMetric: 27.6610

Epoch 180: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4691 - MinusLogProbMetric: 27.4691 - val_loss: 27.6610 - val_MinusLogProbMetric: 27.6610 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 181/1000
2023-09-14 10:43:59.233 
Epoch 181/1000 
	 loss: 27.4589, MinusLogProbMetric: 27.4589, val_loss: 27.6677, val_MinusLogProbMetric: 27.6677

Epoch 181: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4589 - MinusLogProbMetric: 27.4589 - val_loss: 27.6677 - val_MinusLogProbMetric: 27.6677 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 182/1000
2023-09-14 10:44:10.386 
Epoch 182/1000 
	 loss: 27.4597, MinusLogProbMetric: 27.4597, val_loss: 27.6761, val_MinusLogProbMetric: 27.6761

Epoch 182: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4597 - MinusLogProbMetric: 27.4597 - val_loss: 27.6761 - val_MinusLogProbMetric: 27.6761 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 183/1000
2023-09-14 10:44:21.765 
Epoch 183/1000 
	 loss: 27.4647, MinusLogProbMetric: 27.4647, val_loss: 27.6761, val_MinusLogProbMetric: 27.6761

Epoch 183: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4647 - MinusLogProbMetric: 27.4647 - val_loss: 27.6761 - val_MinusLogProbMetric: 27.6761 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 184/1000
2023-09-14 10:44:33.042 
Epoch 184/1000 
	 loss: 27.4596, MinusLogProbMetric: 27.4596, val_loss: 27.6495, val_MinusLogProbMetric: 27.6495

Epoch 184: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4596 - MinusLogProbMetric: 27.4596 - val_loss: 27.6495 - val_MinusLogProbMetric: 27.6495 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 185/1000
2023-09-14 10:44:44.314 
Epoch 185/1000 
	 loss: 27.4533, MinusLogProbMetric: 27.4533, val_loss: 27.7048, val_MinusLogProbMetric: 27.7048

Epoch 185: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4533 - MinusLogProbMetric: 27.4533 - val_loss: 27.7048 - val_MinusLogProbMetric: 27.7048 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 186/1000
2023-09-14 10:44:55.542 
Epoch 186/1000 
	 loss: 27.4529, MinusLogProbMetric: 27.4529, val_loss: 27.6721, val_MinusLogProbMetric: 27.6721

Epoch 186: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4529 - MinusLogProbMetric: 27.4529 - val_loss: 27.6721 - val_MinusLogProbMetric: 27.6721 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 187/1000
2023-09-14 10:45:06.841 
Epoch 187/1000 
	 loss: 27.4651, MinusLogProbMetric: 27.4651, val_loss: 27.6485, val_MinusLogProbMetric: 27.6485

Epoch 187: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4651 - MinusLogProbMetric: 27.4651 - val_loss: 27.6485 - val_MinusLogProbMetric: 27.6485 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 188/1000
2023-09-14 10:45:17.995 
Epoch 188/1000 
	 loss: 27.4489, MinusLogProbMetric: 27.4489, val_loss: 27.6751, val_MinusLogProbMetric: 27.6751

Epoch 188: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4489 - MinusLogProbMetric: 27.4489 - val_loss: 27.6751 - val_MinusLogProbMetric: 27.6751 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 189/1000
2023-09-14 10:45:29.430 
Epoch 189/1000 
	 loss: 27.4577, MinusLogProbMetric: 27.4577, val_loss: 27.6611, val_MinusLogProbMetric: 27.6611

Epoch 189: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4577 - MinusLogProbMetric: 27.4577 - val_loss: 27.6611 - val_MinusLogProbMetric: 27.6611 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 190/1000
2023-09-14 10:45:40.852 
Epoch 190/1000 
	 loss: 27.4656, MinusLogProbMetric: 27.4656, val_loss: 27.6704, val_MinusLogProbMetric: 27.6704

Epoch 190: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4656 - MinusLogProbMetric: 27.4656 - val_loss: 27.6704 - val_MinusLogProbMetric: 27.6704 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 191/1000
2023-09-14 10:45:52.093 
Epoch 191/1000 
	 loss: 27.4600, MinusLogProbMetric: 27.4600, val_loss: 27.6670, val_MinusLogProbMetric: 27.6670

Epoch 191: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4600 - MinusLogProbMetric: 27.4600 - val_loss: 27.6670 - val_MinusLogProbMetric: 27.6670 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 192/1000
2023-09-14 10:46:03.510 
Epoch 192/1000 
	 loss: 27.4608, MinusLogProbMetric: 27.4608, val_loss: 27.6918, val_MinusLogProbMetric: 27.6918

Epoch 192: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4608 - MinusLogProbMetric: 27.4608 - val_loss: 27.6918 - val_MinusLogProbMetric: 27.6918 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 193/1000
2023-09-14 10:46:14.804 
Epoch 193/1000 
	 loss: 27.4537, MinusLogProbMetric: 27.4537, val_loss: 27.7091, val_MinusLogProbMetric: 27.7091

Epoch 193: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4537 - MinusLogProbMetric: 27.4537 - val_loss: 27.7091 - val_MinusLogProbMetric: 27.7091 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 194/1000
2023-09-14 10:46:26.204 
Epoch 194/1000 
	 loss: 27.4503, MinusLogProbMetric: 27.4503, val_loss: 27.6684, val_MinusLogProbMetric: 27.6684

Epoch 194: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4503 - MinusLogProbMetric: 27.4503 - val_loss: 27.6684 - val_MinusLogProbMetric: 27.6684 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 195/1000
2023-09-14 10:46:37.330 
Epoch 195/1000 
	 loss: 27.4487, MinusLogProbMetric: 27.4487, val_loss: 27.6973, val_MinusLogProbMetric: 27.6973

Epoch 195: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4487 - MinusLogProbMetric: 27.4487 - val_loss: 27.6973 - val_MinusLogProbMetric: 27.6973 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 196/1000
2023-09-14 10:46:48.793 
Epoch 196/1000 
	 loss: 27.4423, MinusLogProbMetric: 27.4423, val_loss: 27.7279, val_MinusLogProbMetric: 27.7279

Epoch 196: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4423 - MinusLogProbMetric: 27.4423 - val_loss: 27.7279 - val_MinusLogProbMetric: 27.7279 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 197/1000
2023-09-14 10:47:00.063 
Epoch 197/1000 
	 loss: 27.4570, MinusLogProbMetric: 27.4570, val_loss: 27.7106, val_MinusLogProbMetric: 27.7106

Epoch 197: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4570 - MinusLogProbMetric: 27.4570 - val_loss: 27.7106 - val_MinusLogProbMetric: 27.7106 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 198/1000
2023-09-14 10:47:11.194 
Epoch 198/1000 
	 loss: 27.4472, MinusLogProbMetric: 27.4472, val_loss: 27.6949, val_MinusLogProbMetric: 27.6949

Epoch 198: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4472 - MinusLogProbMetric: 27.4472 - val_loss: 27.6949 - val_MinusLogProbMetric: 27.6949 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 199/1000
2023-09-14 10:47:22.448 
Epoch 199/1000 
	 loss: 27.4518, MinusLogProbMetric: 27.4518, val_loss: 27.6552, val_MinusLogProbMetric: 27.6552

Epoch 199: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4518 - MinusLogProbMetric: 27.4518 - val_loss: 27.6552 - val_MinusLogProbMetric: 27.6552 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 200/1000
2023-09-14 10:47:33.547 
Epoch 200/1000 
	 loss: 27.4427, MinusLogProbMetric: 27.4427, val_loss: 27.6595, val_MinusLogProbMetric: 27.6595

Epoch 200: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4427 - MinusLogProbMetric: 27.4427 - val_loss: 27.6595 - val_MinusLogProbMetric: 27.6595 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 201/1000
2023-09-14 10:47:44.857 
Epoch 201/1000 
	 loss: 27.4482, MinusLogProbMetric: 27.4482, val_loss: 27.6782, val_MinusLogProbMetric: 27.6782

Epoch 201: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4482 - MinusLogProbMetric: 27.4482 - val_loss: 27.6782 - val_MinusLogProbMetric: 27.6782 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 202/1000
2023-09-14 10:47:55.950 
Epoch 202/1000 
	 loss: 27.4467, MinusLogProbMetric: 27.4467, val_loss: 27.7697, val_MinusLogProbMetric: 27.7697

Epoch 202: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4467 - MinusLogProbMetric: 27.4467 - val_loss: 27.7697 - val_MinusLogProbMetric: 27.7697 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 203/1000
2023-09-14 10:48:06.588 
Epoch 203/1000 
	 loss: 27.4516, MinusLogProbMetric: 27.4516, val_loss: 27.6389, val_MinusLogProbMetric: 27.6389

Epoch 203: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4516 - MinusLogProbMetric: 27.4516 - val_loss: 27.6389 - val_MinusLogProbMetric: 27.6389 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 204/1000
2023-09-14 10:48:17.873 
Epoch 204/1000 
	 loss: 27.4533, MinusLogProbMetric: 27.4533, val_loss: 27.6948, val_MinusLogProbMetric: 27.6948

Epoch 204: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4533 - MinusLogProbMetric: 27.4533 - val_loss: 27.6948 - val_MinusLogProbMetric: 27.6948 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 205/1000
2023-09-14 10:48:29.072 
Epoch 205/1000 
	 loss: 27.4466, MinusLogProbMetric: 27.4466, val_loss: 27.6845, val_MinusLogProbMetric: 27.6845

Epoch 205: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4466 - MinusLogProbMetric: 27.4466 - val_loss: 27.6845 - val_MinusLogProbMetric: 27.6845 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 206/1000
2023-09-14 10:48:40.026 
Epoch 206/1000 
	 loss: 27.4465, MinusLogProbMetric: 27.4465, val_loss: 27.6715, val_MinusLogProbMetric: 27.6715

Epoch 206: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4465 - MinusLogProbMetric: 27.4465 - val_loss: 27.6715 - val_MinusLogProbMetric: 27.6715 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 207/1000
2023-09-14 10:48:51.149 
Epoch 207/1000 
	 loss: 27.4442, MinusLogProbMetric: 27.4442, val_loss: 27.7277, val_MinusLogProbMetric: 27.7277

Epoch 207: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4442 - MinusLogProbMetric: 27.4442 - val_loss: 27.7277 - val_MinusLogProbMetric: 27.7277 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 208/1000
2023-09-14 10:49:02.405 
Epoch 208/1000 
	 loss: 27.4420, MinusLogProbMetric: 27.4420, val_loss: 27.7005, val_MinusLogProbMetric: 27.7005

Epoch 208: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4420 - MinusLogProbMetric: 27.4420 - val_loss: 27.7005 - val_MinusLogProbMetric: 27.7005 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 209/1000
2023-09-14 10:49:13.654 
Epoch 209/1000 
	 loss: 27.4482, MinusLogProbMetric: 27.4482, val_loss: 27.6843, val_MinusLogProbMetric: 27.6843

Epoch 209: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4482 - MinusLogProbMetric: 27.4482 - val_loss: 27.6843 - val_MinusLogProbMetric: 27.6843 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 210/1000
2023-09-14 10:49:24.853 
Epoch 210/1000 
	 loss: 27.4381, MinusLogProbMetric: 27.4381, val_loss: 27.6668, val_MinusLogProbMetric: 27.6668

Epoch 210: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4381 - MinusLogProbMetric: 27.4381 - val_loss: 27.6668 - val_MinusLogProbMetric: 27.6668 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 211/1000
2023-09-14 10:49:35.923 
Epoch 211/1000 
	 loss: 27.4383, MinusLogProbMetric: 27.4383, val_loss: 27.7921, val_MinusLogProbMetric: 27.7921

Epoch 211: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4383 - MinusLogProbMetric: 27.4383 - val_loss: 27.7921 - val_MinusLogProbMetric: 27.7921 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 212/1000
2023-09-14 10:49:46.697 
Epoch 212/1000 
	 loss: 27.4433, MinusLogProbMetric: 27.4433, val_loss: 27.6788, val_MinusLogProbMetric: 27.6788

Epoch 212: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4433 - MinusLogProbMetric: 27.4433 - val_loss: 27.6788 - val_MinusLogProbMetric: 27.6788 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 213/1000
2023-09-14 10:49:57.979 
Epoch 213/1000 
	 loss: 27.4399, MinusLogProbMetric: 27.4399, val_loss: 27.7915, val_MinusLogProbMetric: 27.7915

Epoch 213: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4399 - MinusLogProbMetric: 27.4399 - val_loss: 27.7915 - val_MinusLogProbMetric: 27.7915 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 214/1000
2023-09-14 10:50:09.246 
Epoch 214/1000 
	 loss: 27.4409, MinusLogProbMetric: 27.4409, val_loss: 27.6971, val_MinusLogProbMetric: 27.6971

Epoch 214: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4409 - MinusLogProbMetric: 27.4409 - val_loss: 27.6971 - val_MinusLogProbMetric: 27.6971 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 215/1000
2023-09-14 10:50:20.411 
Epoch 215/1000 
	 loss: 27.4323, MinusLogProbMetric: 27.4323, val_loss: 27.6591, val_MinusLogProbMetric: 27.6591

Epoch 215: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4323 - MinusLogProbMetric: 27.4323 - val_loss: 27.6591 - val_MinusLogProbMetric: 27.6591 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 216/1000
2023-09-14 10:50:31.414 
Epoch 216/1000 
	 loss: 27.4247, MinusLogProbMetric: 27.4247, val_loss: 27.7503, val_MinusLogProbMetric: 27.7503

Epoch 216: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4247 - MinusLogProbMetric: 27.4247 - val_loss: 27.7503 - val_MinusLogProbMetric: 27.7503 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 217/1000
2023-09-14 10:50:42.286 
Epoch 217/1000 
	 loss: 27.4398, MinusLogProbMetric: 27.4398, val_loss: 27.7602, val_MinusLogProbMetric: 27.7602

Epoch 217: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4398 - MinusLogProbMetric: 27.4398 - val_loss: 27.7602 - val_MinusLogProbMetric: 27.7602 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 218/1000
2023-09-14 10:50:53.742 
Epoch 218/1000 
	 loss: 27.4383, MinusLogProbMetric: 27.4383, val_loss: 27.7430, val_MinusLogProbMetric: 27.7430

Epoch 218: val_loss did not improve from 27.63083
196/196 - 11s - loss: 27.4383 - MinusLogProbMetric: 27.4383 - val_loss: 27.7430 - val_MinusLogProbMetric: 27.7430 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 219/1000
2023-09-14 10:51:04.892 
Epoch 219/1000 
	 loss: 27.3560, MinusLogProbMetric: 27.3560, val_loss: 27.6047, val_MinusLogProbMetric: 27.6047

Epoch 219: val_loss improved from 27.63083 to 27.60475, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 11s - loss: 27.3560 - MinusLogProbMetric: 27.3560 - val_loss: 27.6047 - val_MinusLogProbMetric: 27.6047 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 220/1000
2023-09-14 10:51:15.408 
Epoch 220/1000 
	 loss: 27.3492, MinusLogProbMetric: 27.3492, val_loss: 27.5999, val_MinusLogProbMetric: 27.5999

Epoch 220: val_loss improved from 27.60475 to 27.59992, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 10s - loss: 27.3492 - MinusLogProbMetric: 27.3492 - val_loss: 27.5999 - val_MinusLogProbMetric: 27.5999 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 221/1000
2023-09-14 10:51:26.514 
Epoch 221/1000 
	 loss: 27.3493, MinusLogProbMetric: 27.3493, val_loss: 27.5980, val_MinusLogProbMetric: 27.5980

Epoch 221: val_loss improved from 27.59992 to 27.59803, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 11s - loss: 27.3493 - MinusLogProbMetric: 27.3493 - val_loss: 27.5980 - val_MinusLogProbMetric: 27.5980 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 222/1000
2023-09-14 10:51:37.340 
Epoch 222/1000 
	 loss: 27.3505, MinusLogProbMetric: 27.3505, val_loss: 27.6239, val_MinusLogProbMetric: 27.6239

Epoch 222: val_loss did not improve from 27.59803
196/196 - 11s - loss: 27.3505 - MinusLogProbMetric: 27.3505 - val_loss: 27.6239 - val_MinusLogProbMetric: 27.6239 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 223/1000
2023-09-14 10:51:48.689 
Epoch 223/1000 
	 loss: 27.3476, MinusLogProbMetric: 27.3476, val_loss: 27.6241, val_MinusLogProbMetric: 27.6241

Epoch 223: val_loss did not improve from 27.59803
196/196 - 11s - loss: 27.3476 - MinusLogProbMetric: 27.3476 - val_loss: 27.6241 - val_MinusLogProbMetric: 27.6241 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 224/1000
2023-09-14 10:52:00.265 
Epoch 224/1000 
	 loss: 27.3495, MinusLogProbMetric: 27.3495, val_loss: 27.6070, val_MinusLogProbMetric: 27.6070

Epoch 224: val_loss did not improve from 27.59803
196/196 - 12s - loss: 27.3495 - MinusLogProbMetric: 27.3495 - val_loss: 27.6070 - val_MinusLogProbMetric: 27.6070 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 225/1000
2023-09-14 10:52:11.770 
Epoch 225/1000 
	 loss: 27.3555, MinusLogProbMetric: 27.3555, val_loss: 27.5861, val_MinusLogProbMetric: 27.5861

Epoch 225: val_loss improved from 27.59803 to 27.58611, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_175/weights/best_weights.h5
196/196 - 12s - loss: 27.3555 - MinusLogProbMetric: 27.3555 - val_loss: 27.5861 - val_MinusLogProbMetric: 27.5861 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 226/1000
2023-09-14 10:52:23.054 
Epoch 226/1000 
	 loss: 27.3463, MinusLogProbMetric: 27.3463, val_loss: 27.6355, val_MinusLogProbMetric: 27.6355

Epoch 226: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3463 - MinusLogProbMetric: 27.3463 - val_loss: 27.6355 - val_MinusLogProbMetric: 27.6355 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 227/1000
2023-09-14 10:52:34.566 
Epoch 227/1000 
	 loss: 27.3439, MinusLogProbMetric: 27.3439, val_loss: 27.5976, val_MinusLogProbMetric: 27.5976

Epoch 227: val_loss did not improve from 27.58611
196/196 - 12s - loss: 27.3439 - MinusLogProbMetric: 27.3439 - val_loss: 27.5976 - val_MinusLogProbMetric: 27.5976 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 228/1000
2023-09-14 10:52:45.879 
Epoch 228/1000 
	 loss: 27.3450, MinusLogProbMetric: 27.3450, val_loss: 27.6181, val_MinusLogProbMetric: 27.6181

Epoch 228: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3450 - MinusLogProbMetric: 27.3450 - val_loss: 27.6181 - val_MinusLogProbMetric: 27.6181 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 229/1000
2023-09-14 10:52:57.254 
Epoch 229/1000 
	 loss: 27.3419, MinusLogProbMetric: 27.3419, val_loss: 27.6210, val_MinusLogProbMetric: 27.6210

Epoch 229: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3419 - MinusLogProbMetric: 27.3419 - val_loss: 27.6210 - val_MinusLogProbMetric: 27.6210 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 230/1000
2023-09-14 10:53:07.941 
Epoch 230/1000 
	 loss: 27.3459, MinusLogProbMetric: 27.3459, val_loss: 27.6088, val_MinusLogProbMetric: 27.6088

Epoch 230: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3459 - MinusLogProbMetric: 27.3459 - val_loss: 27.6088 - val_MinusLogProbMetric: 27.6088 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 231/1000
2023-09-14 10:53:19.315 
Epoch 231/1000 
	 loss: 27.3509, MinusLogProbMetric: 27.3509, val_loss: 27.6124, val_MinusLogProbMetric: 27.6124

Epoch 231: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3509 - MinusLogProbMetric: 27.3509 - val_loss: 27.6124 - val_MinusLogProbMetric: 27.6124 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 232/1000
2023-09-14 10:53:30.522 
Epoch 232/1000 
	 loss: 27.3392, MinusLogProbMetric: 27.3392, val_loss: 27.6116, val_MinusLogProbMetric: 27.6116

Epoch 232: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3392 - MinusLogProbMetric: 27.3392 - val_loss: 27.6116 - val_MinusLogProbMetric: 27.6116 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 233/1000
2023-09-14 10:53:41.635 
Epoch 233/1000 
	 loss: 27.3439, MinusLogProbMetric: 27.3439, val_loss: 27.6133, val_MinusLogProbMetric: 27.6133

Epoch 233: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3439 - MinusLogProbMetric: 27.3439 - val_loss: 27.6133 - val_MinusLogProbMetric: 27.6133 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 234/1000
2023-09-14 10:53:51.295 
Epoch 234/1000 
	 loss: 27.3394, MinusLogProbMetric: 27.3394, val_loss: 27.6142, val_MinusLogProbMetric: 27.6142

Epoch 234: val_loss did not improve from 27.58611
196/196 - 10s - loss: 27.3394 - MinusLogProbMetric: 27.3394 - val_loss: 27.6142 - val_MinusLogProbMetric: 27.6142 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 235/1000
2023-09-14 10:54:01.701 
Epoch 235/1000 
	 loss: 27.3445, MinusLogProbMetric: 27.3445, val_loss: 27.6155, val_MinusLogProbMetric: 27.6155

Epoch 235: val_loss did not improve from 27.58611
196/196 - 10s - loss: 27.3445 - MinusLogProbMetric: 27.3445 - val_loss: 27.6155 - val_MinusLogProbMetric: 27.6155 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 236/1000
2023-09-14 10:54:12.117 
Epoch 236/1000 
	 loss: 27.3410, MinusLogProbMetric: 27.3410, val_loss: 27.6349, val_MinusLogProbMetric: 27.6349

Epoch 236: val_loss did not improve from 27.58611
196/196 - 10s - loss: 27.3410 - MinusLogProbMetric: 27.3410 - val_loss: 27.6349 - val_MinusLogProbMetric: 27.6349 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 237/1000
2023-09-14 10:54:22.262 
Epoch 237/1000 
	 loss: 27.3426, MinusLogProbMetric: 27.3426, val_loss: 27.6239, val_MinusLogProbMetric: 27.6239

Epoch 237: val_loss did not improve from 27.58611
196/196 - 10s - loss: 27.3426 - MinusLogProbMetric: 27.3426 - val_loss: 27.6239 - val_MinusLogProbMetric: 27.6239 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 238/1000
2023-09-14 10:54:31.902 
Epoch 238/1000 
	 loss: 27.3421, MinusLogProbMetric: 27.3421, val_loss: 27.6195, val_MinusLogProbMetric: 27.6195

Epoch 238: val_loss did not improve from 27.58611
196/196 - 10s - loss: 27.3421 - MinusLogProbMetric: 27.3421 - val_loss: 27.6195 - val_MinusLogProbMetric: 27.6195 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 239/1000
2023-09-14 10:54:43.150 
Epoch 239/1000 
	 loss: 27.3436, MinusLogProbMetric: 27.3436, val_loss: 27.6340, val_MinusLogProbMetric: 27.6340

Epoch 239: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3436 - MinusLogProbMetric: 27.3436 - val_loss: 27.6340 - val_MinusLogProbMetric: 27.6340 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 240/1000
2023-09-14 10:54:54.271 
Epoch 240/1000 
	 loss: 27.3405, MinusLogProbMetric: 27.3405, val_loss: 27.6316, val_MinusLogProbMetric: 27.6316

Epoch 240: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3405 - MinusLogProbMetric: 27.3405 - val_loss: 27.6316 - val_MinusLogProbMetric: 27.6316 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 241/1000
2023-09-14 10:55:05.407 
Epoch 241/1000 
	 loss: 27.3439, MinusLogProbMetric: 27.3439, val_loss: 27.6229, val_MinusLogProbMetric: 27.6229

Epoch 241: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3439 - MinusLogProbMetric: 27.3439 - val_loss: 27.6229 - val_MinusLogProbMetric: 27.6229 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 242/1000
2023-09-14 10:55:16.833 
Epoch 242/1000 
	 loss: 27.3383, MinusLogProbMetric: 27.3383, val_loss: 27.6078, val_MinusLogProbMetric: 27.6078

Epoch 242: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3383 - MinusLogProbMetric: 27.3383 - val_loss: 27.6078 - val_MinusLogProbMetric: 27.6078 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 243/1000
2023-09-14 10:55:27.965 
Epoch 243/1000 
	 loss: 27.3397, MinusLogProbMetric: 27.3397, val_loss: 27.6149, val_MinusLogProbMetric: 27.6149

Epoch 243: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3397 - MinusLogProbMetric: 27.3397 - val_loss: 27.6149 - val_MinusLogProbMetric: 27.6149 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 244/1000
2023-09-14 10:55:39.078 
Epoch 244/1000 
	 loss: 27.3404, MinusLogProbMetric: 27.3404, val_loss: 27.6210, val_MinusLogProbMetric: 27.6210

Epoch 244: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3404 - MinusLogProbMetric: 27.3404 - val_loss: 27.6210 - val_MinusLogProbMetric: 27.6210 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 245/1000
2023-09-14 10:55:50.230 
Epoch 245/1000 
	 loss: 27.3395, MinusLogProbMetric: 27.3395, val_loss: 27.6367, val_MinusLogProbMetric: 27.6367

Epoch 245: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3395 - MinusLogProbMetric: 27.3395 - val_loss: 27.6367 - val_MinusLogProbMetric: 27.6367 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 246/1000
2023-09-14 10:56:01.336 
Epoch 246/1000 
	 loss: 27.3408, MinusLogProbMetric: 27.3408, val_loss: 27.6361, val_MinusLogProbMetric: 27.6361

Epoch 246: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3408 - MinusLogProbMetric: 27.3408 - val_loss: 27.6361 - val_MinusLogProbMetric: 27.6361 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 247/1000
2023-09-14 10:56:12.629 
Epoch 247/1000 
	 loss: 27.3423, MinusLogProbMetric: 27.3423, val_loss: 27.6095, val_MinusLogProbMetric: 27.6095

Epoch 247: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3423 - MinusLogProbMetric: 27.3423 - val_loss: 27.6095 - val_MinusLogProbMetric: 27.6095 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 248/1000
2023-09-14 10:56:23.790 
Epoch 248/1000 
	 loss: 27.3407, MinusLogProbMetric: 27.3407, val_loss: 27.6605, val_MinusLogProbMetric: 27.6605

Epoch 248: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3407 - MinusLogProbMetric: 27.3407 - val_loss: 27.6605 - val_MinusLogProbMetric: 27.6605 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 249/1000
2023-09-14 10:56:34.973 
Epoch 249/1000 
	 loss: 27.3404, MinusLogProbMetric: 27.3404, val_loss: 27.6198, val_MinusLogProbMetric: 27.6198

Epoch 249: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3404 - MinusLogProbMetric: 27.3404 - val_loss: 27.6198 - val_MinusLogProbMetric: 27.6198 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 250/1000
2023-09-14 10:56:46.121 
Epoch 250/1000 
	 loss: 27.3409, MinusLogProbMetric: 27.3409, val_loss: 27.6369, val_MinusLogProbMetric: 27.6369

Epoch 250: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3409 - MinusLogProbMetric: 27.3409 - val_loss: 27.6369 - val_MinusLogProbMetric: 27.6369 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 251/1000
2023-09-14 10:56:57.510 
Epoch 251/1000 
	 loss: 27.3379, MinusLogProbMetric: 27.3379, val_loss: 27.6253, val_MinusLogProbMetric: 27.6253

Epoch 251: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3379 - MinusLogProbMetric: 27.3379 - val_loss: 27.6253 - val_MinusLogProbMetric: 27.6253 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 252/1000
2023-09-14 10:57:08.758 
Epoch 252/1000 
	 loss: 27.3372, MinusLogProbMetric: 27.3372, val_loss: 27.6363, val_MinusLogProbMetric: 27.6363

Epoch 252: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3372 - MinusLogProbMetric: 27.3372 - val_loss: 27.6363 - val_MinusLogProbMetric: 27.6363 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 253/1000
2023-09-14 10:57:19.982 
Epoch 253/1000 
	 loss: 27.3393, MinusLogProbMetric: 27.3393, val_loss: 27.6317, val_MinusLogProbMetric: 27.6317

Epoch 253: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3393 - MinusLogProbMetric: 27.3393 - val_loss: 27.6317 - val_MinusLogProbMetric: 27.6317 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 254/1000
2023-09-14 10:57:31.104 
Epoch 254/1000 
	 loss: 27.3344, MinusLogProbMetric: 27.3344, val_loss: 27.6076, val_MinusLogProbMetric: 27.6076

Epoch 254: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3344 - MinusLogProbMetric: 27.3344 - val_loss: 27.6076 - val_MinusLogProbMetric: 27.6076 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 255/1000
2023-09-14 10:57:42.398 
Epoch 255/1000 
	 loss: 27.3354, MinusLogProbMetric: 27.3354, val_loss: 27.6372, val_MinusLogProbMetric: 27.6372

Epoch 255: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3354 - MinusLogProbMetric: 27.3354 - val_loss: 27.6372 - val_MinusLogProbMetric: 27.6372 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 256/1000
2023-09-14 10:57:53.620 
Epoch 256/1000 
	 loss: 27.3347, MinusLogProbMetric: 27.3347, val_loss: 27.6441, val_MinusLogProbMetric: 27.6441

Epoch 256: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3347 - MinusLogProbMetric: 27.3347 - val_loss: 27.6441 - val_MinusLogProbMetric: 27.6441 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 257/1000
2023-09-14 10:58:04.783 
Epoch 257/1000 
	 loss: 27.3352, MinusLogProbMetric: 27.3352, val_loss: 27.6418, val_MinusLogProbMetric: 27.6418

Epoch 257: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3352 - MinusLogProbMetric: 27.3352 - val_loss: 27.6418 - val_MinusLogProbMetric: 27.6418 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 258/1000
2023-09-14 10:58:15.824 
Epoch 258/1000 
	 loss: 27.3346, MinusLogProbMetric: 27.3346, val_loss: 27.6376, val_MinusLogProbMetric: 27.6376

Epoch 258: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3346 - MinusLogProbMetric: 27.3346 - val_loss: 27.6376 - val_MinusLogProbMetric: 27.6376 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 259/1000
2023-09-14 10:58:26.962 
Epoch 259/1000 
	 loss: 27.3342, MinusLogProbMetric: 27.3342, val_loss: 27.6299, val_MinusLogProbMetric: 27.6299

Epoch 259: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3342 - MinusLogProbMetric: 27.3342 - val_loss: 27.6299 - val_MinusLogProbMetric: 27.6299 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 260/1000
2023-09-14 10:58:38.255 
Epoch 260/1000 
	 loss: 27.3366, MinusLogProbMetric: 27.3366, val_loss: 27.6230, val_MinusLogProbMetric: 27.6230

Epoch 260: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3366 - MinusLogProbMetric: 27.3366 - val_loss: 27.6230 - val_MinusLogProbMetric: 27.6230 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 261/1000
2023-09-14 10:58:49.379 
Epoch 261/1000 
	 loss: 27.3334, MinusLogProbMetric: 27.3334, val_loss: 27.6342, val_MinusLogProbMetric: 27.6342

Epoch 261: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3334 - MinusLogProbMetric: 27.3334 - val_loss: 27.6342 - val_MinusLogProbMetric: 27.6342 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 262/1000
2023-09-14 10:58:59.704 
Epoch 262/1000 
	 loss: 27.3311, MinusLogProbMetric: 27.3311, val_loss: 27.6385, val_MinusLogProbMetric: 27.6385

Epoch 262: val_loss did not improve from 27.58611
196/196 - 10s - loss: 27.3311 - MinusLogProbMetric: 27.3311 - val_loss: 27.6385 - val_MinusLogProbMetric: 27.6385 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 263/1000
2023-09-14 10:59:10.939 
Epoch 263/1000 
	 loss: 27.3351, MinusLogProbMetric: 27.3351, val_loss: 27.6322, val_MinusLogProbMetric: 27.6322

Epoch 263: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3351 - MinusLogProbMetric: 27.3351 - val_loss: 27.6322 - val_MinusLogProbMetric: 27.6322 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 264/1000
2023-09-14 10:59:22.320 
Epoch 264/1000 
	 loss: 27.3308, MinusLogProbMetric: 27.3308, val_loss: 27.6548, val_MinusLogProbMetric: 27.6548

Epoch 264: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3308 - MinusLogProbMetric: 27.3308 - val_loss: 27.6548 - val_MinusLogProbMetric: 27.6548 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 265/1000
2023-09-14 10:59:33.436 
Epoch 265/1000 
	 loss: 27.3325, MinusLogProbMetric: 27.3325, val_loss: 27.6234, val_MinusLogProbMetric: 27.6234

Epoch 265: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3325 - MinusLogProbMetric: 27.3325 - val_loss: 27.6234 - val_MinusLogProbMetric: 27.6234 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 266/1000
2023-09-14 10:59:44.251 
Epoch 266/1000 
	 loss: 27.3304, MinusLogProbMetric: 27.3304, val_loss: 27.6265, val_MinusLogProbMetric: 27.6265

Epoch 266: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3304 - MinusLogProbMetric: 27.3304 - val_loss: 27.6265 - val_MinusLogProbMetric: 27.6265 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 267/1000
2023-09-14 10:59:55.259 
Epoch 267/1000 
	 loss: 27.3289, MinusLogProbMetric: 27.3289, val_loss: 27.6473, val_MinusLogProbMetric: 27.6473

Epoch 267: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3289 - MinusLogProbMetric: 27.3289 - val_loss: 27.6473 - val_MinusLogProbMetric: 27.6473 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 268/1000
2023-09-14 11:00:06.658 
Epoch 268/1000 
	 loss: 27.3286, MinusLogProbMetric: 27.3286, val_loss: 27.6164, val_MinusLogProbMetric: 27.6164

Epoch 268: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3286 - MinusLogProbMetric: 27.3286 - val_loss: 27.6164 - val_MinusLogProbMetric: 27.6164 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 269/1000
2023-09-14 11:00:17.829 
Epoch 269/1000 
	 loss: 27.3309, MinusLogProbMetric: 27.3309, val_loss: 27.6478, val_MinusLogProbMetric: 27.6478

Epoch 269: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3309 - MinusLogProbMetric: 27.3309 - val_loss: 27.6478 - val_MinusLogProbMetric: 27.6478 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 270/1000
2023-09-14 11:00:29.059 
Epoch 270/1000 
	 loss: 27.3339, MinusLogProbMetric: 27.3339, val_loss: 27.6223, val_MinusLogProbMetric: 27.6223

Epoch 270: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3339 - MinusLogProbMetric: 27.3339 - val_loss: 27.6223 - val_MinusLogProbMetric: 27.6223 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 271/1000
2023-09-14 11:00:40.187 
Epoch 271/1000 
	 loss: 27.3315, MinusLogProbMetric: 27.3315, val_loss: 27.6221, val_MinusLogProbMetric: 27.6221

Epoch 271: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3315 - MinusLogProbMetric: 27.3315 - val_loss: 27.6221 - val_MinusLogProbMetric: 27.6221 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 272/1000
2023-09-14 11:00:51.400 
Epoch 272/1000 
	 loss: 27.3259, MinusLogProbMetric: 27.3259, val_loss: 27.6613, val_MinusLogProbMetric: 27.6613

Epoch 272: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3259 - MinusLogProbMetric: 27.3259 - val_loss: 27.6613 - val_MinusLogProbMetric: 27.6613 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 273/1000
2023-09-14 11:01:02.573 
Epoch 273/1000 
	 loss: 27.3308, MinusLogProbMetric: 27.3308, val_loss: 27.6435, val_MinusLogProbMetric: 27.6435

Epoch 273: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3308 - MinusLogProbMetric: 27.3308 - val_loss: 27.6435 - val_MinusLogProbMetric: 27.6435 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 274/1000
2023-09-14 11:01:13.345 
Epoch 274/1000 
	 loss: 27.3304, MinusLogProbMetric: 27.3304, val_loss: 27.6276, val_MinusLogProbMetric: 27.6276

Epoch 274: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.3304 - MinusLogProbMetric: 27.3304 - val_loss: 27.6276 - val_MinusLogProbMetric: 27.6276 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 275/1000
2023-09-14 11:01:23.837 
Epoch 275/1000 
	 loss: 27.3282, MinusLogProbMetric: 27.3282, val_loss: 27.6554, val_MinusLogProbMetric: 27.6554

Epoch 275: val_loss did not improve from 27.58611
196/196 - 10s - loss: 27.3282 - MinusLogProbMetric: 27.3282 - val_loss: 27.6554 - val_MinusLogProbMetric: 27.6554 - lr: 5.0000e-04 - 10s/epoch - 54ms/step
Epoch 276/1000
2023-09-14 11:01:35.104 
Epoch 276/1000 
	 loss: 27.2927, MinusLogProbMetric: 27.2927, val_loss: 27.6040, val_MinusLogProbMetric: 27.6040

Epoch 276: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2927 - MinusLogProbMetric: 27.2927 - val_loss: 27.6040 - val_MinusLogProbMetric: 27.6040 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 277/1000
2023-09-14 11:01:46.327 
Epoch 277/1000 
	 loss: 27.2896, MinusLogProbMetric: 27.2896, val_loss: 27.6037, val_MinusLogProbMetric: 27.6037

Epoch 277: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2896 - MinusLogProbMetric: 27.2896 - val_loss: 27.6037 - val_MinusLogProbMetric: 27.6037 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 278/1000
2023-09-14 11:01:56.778 
Epoch 278/1000 
	 loss: 27.2872, MinusLogProbMetric: 27.2872, val_loss: 27.6068, val_MinusLogProbMetric: 27.6068

Epoch 278: val_loss did not improve from 27.58611
196/196 - 10s - loss: 27.2872 - MinusLogProbMetric: 27.2872 - val_loss: 27.6068 - val_MinusLogProbMetric: 27.6068 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 279/1000
2023-09-14 11:02:07.850 
Epoch 279/1000 
	 loss: 27.2870, MinusLogProbMetric: 27.2870, val_loss: 27.6146, val_MinusLogProbMetric: 27.6146

Epoch 279: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2870 - MinusLogProbMetric: 27.2870 - val_loss: 27.6146 - val_MinusLogProbMetric: 27.6146 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 280/1000
2023-09-14 11:02:19.130 
Epoch 280/1000 
	 loss: 27.2885, MinusLogProbMetric: 27.2885, val_loss: 27.6014, val_MinusLogProbMetric: 27.6014

Epoch 280: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2885 - MinusLogProbMetric: 27.2885 - val_loss: 27.6014 - val_MinusLogProbMetric: 27.6014 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 281/1000
2023-09-14 11:02:30.363 
Epoch 281/1000 
	 loss: 27.2877, MinusLogProbMetric: 27.2877, val_loss: 27.6201, val_MinusLogProbMetric: 27.6201

Epoch 281: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2877 - MinusLogProbMetric: 27.2877 - val_loss: 27.6201 - val_MinusLogProbMetric: 27.6201 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 282/1000
2023-09-14 11:02:41.549 
Epoch 282/1000 
	 loss: 27.2859, MinusLogProbMetric: 27.2859, val_loss: 27.6071, val_MinusLogProbMetric: 27.6071

Epoch 282: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2859 - MinusLogProbMetric: 27.2859 - val_loss: 27.6071 - val_MinusLogProbMetric: 27.6071 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 283/1000
2023-09-14 11:02:52.545 
Epoch 283/1000 
	 loss: 27.2862, MinusLogProbMetric: 27.2862, val_loss: 27.6061, val_MinusLogProbMetric: 27.6061

Epoch 283: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2862 - MinusLogProbMetric: 27.2862 - val_loss: 27.6061 - val_MinusLogProbMetric: 27.6061 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 284/1000
2023-09-14 11:03:03.872 
Epoch 284/1000 
	 loss: 27.2867, MinusLogProbMetric: 27.2867, val_loss: 27.6076, val_MinusLogProbMetric: 27.6076

Epoch 284: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2867 - MinusLogProbMetric: 27.2867 - val_loss: 27.6076 - val_MinusLogProbMetric: 27.6076 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 285/1000
2023-09-14 11:03:14.966 
Epoch 285/1000 
	 loss: 27.2852, MinusLogProbMetric: 27.2852, val_loss: 27.6075, val_MinusLogProbMetric: 27.6075

Epoch 285: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2852 - MinusLogProbMetric: 27.2852 - val_loss: 27.6075 - val_MinusLogProbMetric: 27.6075 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 286/1000
2023-09-14 11:03:26.297 
Epoch 286/1000 
	 loss: 27.2863, MinusLogProbMetric: 27.2863, val_loss: 27.6172, val_MinusLogProbMetric: 27.6172

Epoch 286: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2863 - MinusLogProbMetric: 27.2863 - val_loss: 27.6172 - val_MinusLogProbMetric: 27.6172 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 287/1000
2023-09-14 11:03:37.451 
Epoch 287/1000 
	 loss: 27.2864, MinusLogProbMetric: 27.2864, val_loss: 27.6158, val_MinusLogProbMetric: 27.6158

Epoch 287: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2864 - MinusLogProbMetric: 27.2864 - val_loss: 27.6158 - val_MinusLogProbMetric: 27.6158 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 288/1000
2023-09-14 11:03:48.533 
Epoch 288/1000 
	 loss: 27.2869, MinusLogProbMetric: 27.2869, val_loss: 27.6185, val_MinusLogProbMetric: 27.6185

Epoch 288: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2869 - MinusLogProbMetric: 27.2869 - val_loss: 27.6185 - val_MinusLogProbMetric: 27.6185 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 289/1000
2023-09-14 11:03:59.324 
Epoch 289/1000 
	 loss: 27.2855, MinusLogProbMetric: 27.2855, val_loss: 27.6151, val_MinusLogProbMetric: 27.6151

Epoch 289: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2855 - MinusLogProbMetric: 27.2855 - val_loss: 27.6151 - val_MinusLogProbMetric: 27.6151 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 290/1000
2023-09-14 11:04:10.502 
Epoch 290/1000 
	 loss: 27.2856, MinusLogProbMetric: 27.2856, val_loss: 27.6008, val_MinusLogProbMetric: 27.6008

Epoch 290: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2856 - MinusLogProbMetric: 27.2856 - val_loss: 27.6008 - val_MinusLogProbMetric: 27.6008 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 291/1000
2023-09-14 11:04:21.823 
Epoch 291/1000 
	 loss: 27.2859, MinusLogProbMetric: 27.2859, val_loss: 27.6073, val_MinusLogProbMetric: 27.6073

Epoch 291: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2859 - MinusLogProbMetric: 27.2859 - val_loss: 27.6073 - val_MinusLogProbMetric: 27.6073 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 292/1000
2023-09-14 11:04:32.978 
Epoch 292/1000 
	 loss: 27.2852, MinusLogProbMetric: 27.2852, val_loss: 27.6144, val_MinusLogProbMetric: 27.6144

Epoch 292: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2852 - MinusLogProbMetric: 27.2852 - val_loss: 27.6144 - val_MinusLogProbMetric: 27.6144 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 293/1000
2023-09-14 11:04:44.165 
Epoch 293/1000 
	 loss: 27.2850, MinusLogProbMetric: 27.2850, val_loss: 27.6055, val_MinusLogProbMetric: 27.6055

Epoch 293: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2850 - MinusLogProbMetric: 27.2850 - val_loss: 27.6055 - val_MinusLogProbMetric: 27.6055 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 294/1000
2023-09-14 11:04:55.377 
Epoch 294/1000 
	 loss: 27.2865, MinusLogProbMetric: 27.2865, val_loss: 27.6058, val_MinusLogProbMetric: 27.6058

Epoch 294: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2865 - MinusLogProbMetric: 27.2865 - val_loss: 27.6058 - val_MinusLogProbMetric: 27.6058 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 295/1000
2023-09-14 11:05:06.576 
Epoch 295/1000 
	 loss: 27.2870, MinusLogProbMetric: 27.2870, val_loss: 27.6153, val_MinusLogProbMetric: 27.6153

Epoch 295: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2870 - MinusLogProbMetric: 27.2870 - val_loss: 27.6153 - val_MinusLogProbMetric: 27.6153 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 296/1000
2023-09-14 11:05:17.762 
Epoch 296/1000 
	 loss: 27.2836, MinusLogProbMetric: 27.2836, val_loss: 27.6037, val_MinusLogProbMetric: 27.6037

Epoch 296: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2836 - MinusLogProbMetric: 27.2836 - val_loss: 27.6037 - val_MinusLogProbMetric: 27.6037 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 297/1000
2023-09-14 11:05:28.884 
Epoch 297/1000 
	 loss: 27.2814, MinusLogProbMetric: 27.2814, val_loss: 27.6125, val_MinusLogProbMetric: 27.6125

Epoch 297: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2814 - MinusLogProbMetric: 27.2814 - val_loss: 27.6125 - val_MinusLogProbMetric: 27.6125 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 298/1000
2023-09-14 11:05:40.020 
Epoch 298/1000 
	 loss: 27.2845, MinusLogProbMetric: 27.2845, val_loss: 27.6141, val_MinusLogProbMetric: 27.6141

Epoch 298: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2845 - MinusLogProbMetric: 27.2845 - val_loss: 27.6141 - val_MinusLogProbMetric: 27.6141 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 299/1000
2023-09-14 11:05:51.011 
Epoch 299/1000 
	 loss: 27.2846, MinusLogProbMetric: 27.2846, val_loss: 27.6184, val_MinusLogProbMetric: 27.6184

Epoch 299: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2846 - MinusLogProbMetric: 27.2846 - val_loss: 27.6184 - val_MinusLogProbMetric: 27.6184 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 300/1000
2023-09-14 11:06:02.260 
Epoch 300/1000 
	 loss: 27.2830, MinusLogProbMetric: 27.2830, val_loss: 27.6164, val_MinusLogProbMetric: 27.6164

Epoch 300: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2830 - MinusLogProbMetric: 27.2830 - val_loss: 27.6164 - val_MinusLogProbMetric: 27.6164 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 301/1000
2023-09-14 11:06:13.553 
Epoch 301/1000 
	 loss: 27.2829, MinusLogProbMetric: 27.2829, val_loss: 27.6119, val_MinusLogProbMetric: 27.6119

Epoch 301: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2829 - MinusLogProbMetric: 27.2829 - val_loss: 27.6119 - val_MinusLogProbMetric: 27.6119 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 302/1000
2023-09-14 11:06:24.515 
Epoch 302/1000 
	 loss: 27.2837, MinusLogProbMetric: 27.2837, val_loss: 27.6203, val_MinusLogProbMetric: 27.6203

Epoch 302: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2837 - MinusLogProbMetric: 27.2837 - val_loss: 27.6203 - val_MinusLogProbMetric: 27.6203 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 303/1000
2023-09-14 11:06:35.642 
Epoch 303/1000 
	 loss: 27.2849, MinusLogProbMetric: 27.2849, val_loss: 27.6038, val_MinusLogProbMetric: 27.6038

Epoch 303: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2849 - MinusLogProbMetric: 27.2849 - val_loss: 27.6038 - val_MinusLogProbMetric: 27.6038 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 304/1000
2023-09-14 11:06:46.833 
Epoch 304/1000 
	 loss: 27.2831, MinusLogProbMetric: 27.2831, val_loss: 27.6089, val_MinusLogProbMetric: 27.6089

Epoch 304: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2831 - MinusLogProbMetric: 27.2831 - val_loss: 27.6089 - val_MinusLogProbMetric: 27.6089 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 305/1000
2023-09-14 11:06:58.037 
Epoch 305/1000 
	 loss: 27.2814, MinusLogProbMetric: 27.2814, val_loss: 27.6152, val_MinusLogProbMetric: 27.6152

Epoch 305: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2814 - MinusLogProbMetric: 27.2814 - val_loss: 27.6152 - val_MinusLogProbMetric: 27.6152 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 306/1000
2023-09-14 11:07:09.304 
Epoch 306/1000 
	 loss: 27.2864, MinusLogProbMetric: 27.2864, val_loss: 27.6047, val_MinusLogProbMetric: 27.6047

Epoch 306: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2864 - MinusLogProbMetric: 27.2864 - val_loss: 27.6047 - val_MinusLogProbMetric: 27.6047 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 307/1000
2023-09-14 11:07:20.479 
Epoch 307/1000 
	 loss: 27.2805, MinusLogProbMetric: 27.2805, val_loss: 27.6116, val_MinusLogProbMetric: 27.6116

Epoch 307: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2805 - MinusLogProbMetric: 27.2805 - val_loss: 27.6116 - val_MinusLogProbMetric: 27.6116 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 308/1000
2023-09-14 11:07:31.687 
Epoch 308/1000 
	 loss: 27.2826, MinusLogProbMetric: 27.2826, val_loss: 27.6173, val_MinusLogProbMetric: 27.6173

Epoch 308: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2826 - MinusLogProbMetric: 27.2826 - val_loss: 27.6173 - val_MinusLogProbMetric: 27.6173 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 309/1000
2023-09-14 11:07:42.892 
Epoch 309/1000 
	 loss: 27.2834, MinusLogProbMetric: 27.2834, val_loss: 27.6118, val_MinusLogProbMetric: 27.6118

Epoch 309: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2834 - MinusLogProbMetric: 27.2834 - val_loss: 27.6118 - val_MinusLogProbMetric: 27.6118 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 310/1000
2023-09-14 11:07:54.064 
Epoch 310/1000 
	 loss: 27.2819, MinusLogProbMetric: 27.2819, val_loss: 27.6113, val_MinusLogProbMetric: 27.6113

Epoch 310: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2819 - MinusLogProbMetric: 27.2819 - val_loss: 27.6113 - val_MinusLogProbMetric: 27.6113 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 311/1000
2023-09-14 11:08:05.322 
Epoch 311/1000 
	 loss: 27.2825, MinusLogProbMetric: 27.2825, val_loss: 27.6162, val_MinusLogProbMetric: 27.6162

Epoch 311: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2825 - MinusLogProbMetric: 27.2825 - val_loss: 27.6162 - val_MinusLogProbMetric: 27.6162 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 312/1000
2023-09-14 11:08:16.552 
Epoch 312/1000 
	 loss: 27.2830, MinusLogProbMetric: 27.2830, val_loss: 27.6120, val_MinusLogProbMetric: 27.6120

Epoch 312: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2830 - MinusLogProbMetric: 27.2830 - val_loss: 27.6120 - val_MinusLogProbMetric: 27.6120 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 313/1000
2023-09-14 11:08:27.696 
Epoch 313/1000 
	 loss: 27.2824, MinusLogProbMetric: 27.2824, val_loss: 27.6193, val_MinusLogProbMetric: 27.6193

Epoch 313: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2824 - MinusLogProbMetric: 27.2824 - val_loss: 27.6193 - val_MinusLogProbMetric: 27.6193 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 314/1000
2023-09-14 11:08:38.895 
Epoch 314/1000 
	 loss: 27.2832, MinusLogProbMetric: 27.2832, val_loss: 27.6176, val_MinusLogProbMetric: 27.6176

Epoch 314: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2832 - MinusLogProbMetric: 27.2832 - val_loss: 27.6176 - val_MinusLogProbMetric: 27.6176 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 315/1000
2023-09-14 11:08:50.009 
Epoch 315/1000 
	 loss: 27.2815, MinusLogProbMetric: 27.2815, val_loss: 27.6188, val_MinusLogProbMetric: 27.6188

Epoch 315: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2815 - MinusLogProbMetric: 27.2815 - val_loss: 27.6188 - val_MinusLogProbMetric: 27.6188 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 316/1000
2023-09-14 11:09:01.116 
Epoch 316/1000 
	 loss: 27.2803, MinusLogProbMetric: 27.2803, val_loss: 27.6170, val_MinusLogProbMetric: 27.6170

Epoch 316: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2803 - MinusLogProbMetric: 27.2803 - val_loss: 27.6170 - val_MinusLogProbMetric: 27.6170 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 317/1000
2023-09-14 11:09:12.247 
Epoch 317/1000 
	 loss: 27.2839, MinusLogProbMetric: 27.2839, val_loss: 27.6282, val_MinusLogProbMetric: 27.6282

Epoch 317: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2839 - MinusLogProbMetric: 27.2839 - val_loss: 27.6282 - val_MinusLogProbMetric: 27.6282 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 318/1000
2023-09-14 11:09:23.569 
Epoch 318/1000 
	 loss: 27.2817, MinusLogProbMetric: 27.2817, val_loss: 27.6174, val_MinusLogProbMetric: 27.6174

Epoch 318: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2817 - MinusLogProbMetric: 27.2817 - val_loss: 27.6174 - val_MinusLogProbMetric: 27.6174 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 319/1000
2023-09-14 11:09:34.926 
Epoch 319/1000 
	 loss: 27.2794, MinusLogProbMetric: 27.2794, val_loss: 27.6199, val_MinusLogProbMetric: 27.6199

Epoch 319: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2794 - MinusLogProbMetric: 27.2794 - val_loss: 27.6199 - val_MinusLogProbMetric: 27.6199 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 320/1000
2023-09-14 11:09:46.138 
Epoch 320/1000 
	 loss: 27.2802, MinusLogProbMetric: 27.2802, val_loss: 27.6141, val_MinusLogProbMetric: 27.6141

Epoch 320: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2802 - MinusLogProbMetric: 27.2802 - val_loss: 27.6141 - val_MinusLogProbMetric: 27.6141 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 321/1000
2023-09-14 11:09:57.240 
Epoch 321/1000 
	 loss: 27.2801, MinusLogProbMetric: 27.2801, val_loss: 27.6101, val_MinusLogProbMetric: 27.6101

Epoch 321: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2801 - MinusLogProbMetric: 27.2801 - val_loss: 27.6101 - val_MinusLogProbMetric: 27.6101 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 322/1000
2023-09-14 11:10:08.421 
Epoch 322/1000 
	 loss: 27.2817, MinusLogProbMetric: 27.2817, val_loss: 27.6171, val_MinusLogProbMetric: 27.6171

Epoch 322: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2817 - MinusLogProbMetric: 27.2817 - val_loss: 27.6171 - val_MinusLogProbMetric: 27.6171 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 323/1000
2023-09-14 11:10:19.480 
Epoch 323/1000 
	 loss: 27.2806, MinusLogProbMetric: 27.2806, val_loss: 27.6152, val_MinusLogProbMetric: 27.6152

Epoch 323: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2806 - MinusLogProbMetric: 27.2806 - val_loss: 27.6152 - val_MinusLogProbMetric: 27.6152 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 324/1000
2023-09-14 11:10:30.717 
Epoch 324/1000 
	 loss: 27.2794, MinusLogProbMetric: 27.2794, val_loss: 27.6236, val_MinusLogProbMetric: 27.6236

Epoch 324: val_loss did not improve from 27.58611
196/196 - 11s - loss: 27.2794 - MinusLogProbMetric: 27.2794 - val_loss: 27.6236 - val_MinusLogProbMetric: 27.6236 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 325/1000
2023-09-14 11:10:41.768 
Epoch 325/1000 
	 loss: 27.2785, MinusLogProbMetric: 27.2785, val_loss: 27.6170, val_MinusLogProbMetric: 27.6170

Epoch 325: val_loss did not improve from 27.58611
Restoring model weights from the end of the best epoch: 225.
196/196 - 11s - loss: 27.2785 - MinusLogProbMetric: 27.2785 - val_loss: 27.6170 - val_MinusLogProbMetric: 27.6170 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 325: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 272.6962980120443 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
2023-09-14 11:15:25.721673: F ./tensorflow/core/util/gpu_launch_config.h:160] Check failed: work_element_count > 0 (0 vs. -2054967296)
