2023-10-01 08:49:59.866799: Importing os...
2023-10-01 08:49:59.866988: Importing sys...
2023-10-01 08:49:59.867012: Importing and initializing argparse...
Visible devices: [0]
2023-10-01 08:49:59.926734: Importing timer from timeit...
2023-10-01 08:49:59.927954: Setting env variables for tf import (only device [0] will be available)...
2023-10-01 08:49:59.928052: Importing numpy...
2023-10-01 08:50:00.202347: Importing pandas...
2023-10-01 08:50:00.790120: Importing shutil...
2023-10-01 08:50:00.790249: Importing subprocess...
2023-10-01 08:50:00.790260: Importing tensorflow...
Tensorflow version: 2.12.0
2023-10-01 08:50:05.985168: Importing tensorflow_probability...
Tensorflow probability version: 0.20.1
2023-10-01 08:50:06.832235: Importing textwrap...
2023-10-01 08:50:06.832309: Importing timeit...
2023-10-01 08:50:06.832318: Importing traceback...
2023-10-01 08:50:06.832324: Importing typing...
2023-10-01 08:50:06.832335: Setting tf configs...
2023-10-01 08:50:07.191241: Importing custom module...
Successfully loaded GPU model: NVIDIA A40
2023-10-01 08:50:10.022695: All modues imported successfully.
Directory ../../results/MsplineN_new/ already exists.
Directory ../../results/MsplineN_new/run_1/ already exists.
Skipping it.
===========
Run 1/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_2/ already exists.
Skipping it.
===========
Run 2/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_3/ already exists.
Skipping it.
===========
Run 3/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_4/ already exists.
Skipping it.
===========
Run 4/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_5/ already exists.
Skipping it.
===========
Run 5/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_6/ already exists.
Skipping it.
===========
Run 6/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_7/ already exists.
Skipping it.
===========
Run 7/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_8/ already exists.
Skipping it.
===========
Run 8/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_9/ already exists.
Skipping it.
===========
Run 9/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_10/ already exists.
Skipping it.
===========
Run 10/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_11/ already exists.
Skipping it.
===========
Run 11/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_12/ already exists.
Skipping it.
===========
Run 12/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_13/ already exists.
Skipping it.
===========
Run 13/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_14/ already exists.
Skipping it.
===========
Run 14/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_15/ already exists.
Skipping it.
===========
Run 15/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_16/ already exists.
Skipping it.
===========
Run 16/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_17/ already exists.
Skipping it.
===========
Run 17/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_18/ already exists.
Skipping it.
===========
Run 18/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_19/ already exists.
Skipping it.
===========
Run 19/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_20/ already exists.
Skipping it.
===========
Run 20/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_21/ already exists.
Skipping it.
===========
Run 21/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_22/ already exists.
Skipping it.
===========
Run 22/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_23/ already exists.
Skipping it.
===========
Run 23/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_24/ already exists.
Skipping it.
===========
Run 24/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_25/ already exists.
Skipping it.
===========
Run 25/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_26/ already exists.
Skipping it.
===========
Run 26/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_27/ already exists.
Skipping it.
===========
Run 27/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_28/ already exists.
Skipping it.
===========
Run 28/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_29/ already exists.
Skipping it.
===========
Run 29/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_30/ already exists.
Skipping it.
===========
Run 30/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_31/ already exists.
Skipping it.
===========
Run 31/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_32/ already exists.
Skipping it.
===========
Run 32/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_33/ already exists.
Skipping it.
===========
Run 33/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_34/ already exists.
Skipping it.
===========
Run 34/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_35/ already exists.
Skipping it.
===========
Run 35/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_36/ already exists.
Skipping it.
===========
Run 36/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_37/ already exists.
Skipping it.
===========
Run 37/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_38/ already exists.
Skipping it.
===========
Run 38/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_39/ already exists.
Skipping it.
===========
Run 39/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_40/ already exists.
Skipping it.
===========
Run 40/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_41/ already exists.
Skipping it.
===========
Run 41/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_42/ already exists.
Skipping it.
===========
Run 42/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_43/ already exists.
Skipping it.
===========
Run 43/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_44/ already exists.
Skipping it.
===========
Run 44/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_45/ already exists.
Skipping it.
===========
Run 45/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_46/ already exists.
Skipping it.
===========
Run 46/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_47/ already exists.
Skipping it.
===========
Run 47/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_48/ already exists.
Skipping it.
===========
Run 48/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_49/ already exists.
Skipping it.
===========
Run 49/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_50/ already exists.
Skipping it.
===========
Run 50/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_51/ already exists.
Skipping it.
===========
Run 51/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_52/ already exists.
Skipping it.
===========
Run 52/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_53/ already exists.
Skipping it.
===========
Run 53/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_54/ already exists.
Skipping it.
===========
Run 54/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_55/ already exists.
Skipping it.
===========
Run 55/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_56/ already exists.
Skipping it.
===========
Run 56/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_57/ already exists.
Skipping it.
===========
Run 57/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_58/ already exists.
Skipping it.
===========
Run 58/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_59/ already exists.
Skipping it.
===========
Run 59/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_60/ already exists.
Skipping it.
===========
Run 60/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_61/ already exists.
Skipping it.
===========
Run 61/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_62/ already exists.
Skipping it.
===========
Run 62/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_63/ already exists.
Skipping it.
===========
Run 63/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_64/ already exists.
Skipping it.
===========
Run 64/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_65/ already exists.
Skipping it.
===========
Run 65/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_66/ already exists.
Skipping it.
===========
Run 66/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_67/ already exists.
Skipping it.
===========
Run 67/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_68/ already exists.
Skipping it.
===========
Run 68/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_69/ already exists.
Skipping it.
===========
Run 69/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_70/ already exists.
Skipping it.
===========
Run 70/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_71/ already exists.
Skipping it.
===========
Run 71/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_72/ already exists.
Skipping it.
===========
Run 72/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_73/ already exists.
Skipping it.
===========
Run 73/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_74/ already exists.
Skipping it.
===========
Run 74/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_75/ already exists.
Skipping it.
===========
Run 75/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_76/ already exists.
Skipping it.
===========
Run 76/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_77/ already exists.
Skipping it.
===========
Run 77/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_78/ already exists.
Skipping it.
===========
Run 78/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_79/ already exists.
Skipping it.
===========
Run 79/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_80/ already exists.
Skipping it.
===========
Run 80/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_81/ already exists.
Skipping it.
===========
Run 81/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_82/ already exists.
Skipping it.
===========
Run 82/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_83/ already exists.
Skipping it.
===========
Run 83/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_84/ already exists.
Skipping it.
===========
Run 84/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_85/ already exists.
Skipping it.
===========
Run 85/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_86/ already exists.
Skipping it.
===========
Run 86/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_87/ already exists.
Skipping it.
===========
Run 87/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_88/ already exists.
Skipping it.
===========
Run 88/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_89/ already exists.
Skipping it.
===========
Run 89/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_90/ already exists.
Skipping it.
===========
Run 90/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_91/ already exists.
Skipping it.
===========
Run 91/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_92/ already exists.
Skipping it.
===========
Run 92/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_93/ already exists.
Skipping it.
===========
Run 93/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_94/ already exists.
Skipping it.
===========
Run 94/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_95/ already exists.
Skipping it.
===========
Run 95/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_96/ already exists.
Skipping it.
===========
Run 96/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_97/ already exists.
Skipping it.
===========
Run 97/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_98/ already exists.
Skipping it.
===========
Run 98/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_99/ already exists.
Skipping it.
===========
Run 99/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_100/ already exists.
Skipping it.
===========
Run 100/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_101/ already exists.
Skipping it.
===========
Run 101/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_102/ already exists.
Skipping it.
===========
Run 102/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_103/ already exists.
Skipping it.
===========
Run 103/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_104/ already exists.
Skipping it.
===========
Run 104/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_105/ already exists.
Skipping it.
===========
Run 105/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_106/ already exists.
Skipping it.
===========
Run 106/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_107/ already exists.
Skipping it.
===========
Run 107/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_108/ already exists.
Skipping it.
===========
Run 108/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_109/ already exists.
Skipping it.
===========
Run 109/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_110/ already exists.
Skipping it.
===========
Run 110/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_111/ already exists.
Skipping it.
===========
Run 111/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_112/ already exists.
Skipping it.
===========
Run 112/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_113/ already exists.
Skipping it.
===========
Run 113/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_114/ already exists.
Skipping it.
===========
Run 114/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_115/ already exists.
Skipping it.
===========
Run 115/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_116/ already exists.
Skipping it.
===========
Run 116/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_117/ already exists.
Skipping it.
===========
Run 117/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_118/ already exists.
Skipping it.
===========
Run 118/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_119/ already exists.
Skipping it.
===========
Run 119/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_120/ already exists.
Skipping it.
===========
Run 120/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_121/ already exists.
Skipping it.
===========
Run 121/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_122/ already exists.
Skipping it.
===========
Run 122/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_123/ already exists.
Skipping it.
===========
Run 123/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_124/ already exists.
Skipping it.
===========
Run 124/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_125/ already exists.
Skipping it.
===========
Run 125/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_126/ already exists.
Skipping it.
===========
Run 126/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_127/ already exists.
Skipping it.
===========
Run 127/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_128/ already exists.
Skipping it.
===========
Run 128/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_129/ already exists.
Skipping it.
===========
Run 129/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_130/ already exists.
Skipping it.
===========
Run 130/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_131/ already exists.
Skipping it.
===========
Run 131/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_132/ already exists.
Skipping it.
===========
Run 132/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_133/ already exists.
Skipping it.
===========
Run 133/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_134/ already exists.
Skipping it.
===========
Run 134/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_135/ already exists.
Skipping it.
===========
Run 135/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_136/ already exists.
Skipping it.
===========
Run 136/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_137/ already exists.
Skipping it.
===========
Run 137/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_138/ already exists.
Skipping it.
===========
Run 138/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_139/ already exists.
Skipping it.
===========
Run 139/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_140/ already exists.
Skipping it.
===========
Run 140/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_141/ already exists.
Skipping it.
===========
Run 141/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_142/ already exists.
Skipping it.
===========
Run 142/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_143/ already exists.
Skipping it.
===========
Run 143/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_144/ already exists.
Skipping it.
===========
Run 144/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_145/ already exists.
Skipping it.
===========
Run 145/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_146/ already exists.
Skipping it.
===========
Run 146/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_147/ already exists.
Skipping it.
===========
Run 147/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_148/ already exists.
Skipping it.
===========
Run 148/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_149/ already exists.
Skipping it.
===========
Run 149/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_150/ already exists.
Skipping it.
===========
Run 150/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_151/ already exists.
Skipping it.
===========
Run 151/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_152/ already exists.
Skipping it.
===========
Run 152/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_153/ already exists.
Skipping it.
===========
Run 153/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_154/ already exists.
Skipping it.
===========
Run 154/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_155/ already exists.
Skipping it.
===========
Run 155/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_156/ already exists.
Skipping it.
===========
Run 156/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_157/ already exists.
Skipping it.
===========
Run 157/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_158/ already exists.
Skipping it.
===========
Run 158/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_159/ already exists.
Skipping it.
===========
Run 159/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_160/ already exists.
Skipping it.
===========
Run 160/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_161/ already exists.
Skipping it.
===========
Run 161/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_162/ already exists.
Skipping it.
===========
Run 162/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_163/ already exists.
Skipping it.
===========
Run 163/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_164/ already exists.
Skipping it.
===========
Run 164/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_165/ already exists.
Skipping it.
===========
Run 165/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_166/ already exists.
Skipping it.
===========
Run 166/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_167/ already exists.
Skipping it.
===========
Run 167/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_168/ already exists.
Skipping it.
===========
Run 168/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_169/ already exists.
Skipping it.
===========
Run 169/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_170/ already exists.
Skipping it.
===========
Run 170/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_171/ already exists.
Skipping it.
===========
Run 171/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_172/ already exists.
Skipping it.
===========
Run 172/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_173/ already exists.
Skipping it.
===========
Run 173/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_174/ already exists.
Skipping it.
===========
Run 174/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_175/ already exists.
Skipping it.
===========
Run 175/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_176/ already exists.
Skipping it.
===========
Run 176/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_177/ already exists.
Skipping it.
===========
Run 177/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_178/ already exists.
Skipping it.
===========
Run 178/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_179/ already exists.
Skipping it.
===========
Run 179/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_180/ already exists.
Skipping it.
===========
Run 180/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_181/ already exists.
Skipping it.
===========
Run 181/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_182/ already exists.
Skipping it.
===========
Run 182/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_183/ already exists.
Skipping it.
===========
Run 183/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_184/ already exists.
Skipping it.
===========
Run 184/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_185/ already exists.
Skipping it.
===========
Run 185/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_186/ already exists.
Skipping it.
===========
Run 186/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_187/ already exists.
Skipping it.
===========
Run 187/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_188/ already exists.
Skipping it.
===========
Run 188/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_189/ already exists.
Skipping it.
===========
Run 189/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_190/ already exists.
Skipping it.
===========
Run 190/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_191/ already exists.
Skipping it.
===========
Run 191/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_192/ already exists.
Skipping it.
===========
Run 192/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_193/ already exists.
Skipping it.
===========
Run 193/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_194/ already exists.
Skipping it.
===========
Run 194/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_195/ already exists.
Skipping it.
===========
Run 195/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_196/ already exists.
Skipping it.
===========
Run 196/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_197/ already exists.
Skipping it.
===========
Run 197/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_198/ already exists.
Skipping it.
===========
Run 198/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_199/ already exists.
Skipping it.
===========
Run 199/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_200/ already exists.
Skipping it.
===========
Run 200/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_201/ already exists.
Skipping it.
===========
Run 201/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_202/ already exists.
Skipping it.
===========
Run 202/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_203/ already exists.
Skipping it.
===========
Run 203/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_204/ already exists.
Skipping it.
===========
Run 204/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_205/ already exists.
Skipping it.
===========
Run 205/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_206/ already exists.
Skipping it.
===========
Run 206/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_207/ already exists.
Skipping it.
===========
Run 207/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_208/ already exists.
Skipping it.
===========
Run 208/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_209/ already exists.
Skipping it.
===========
Run 209/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_210/ already exists.
Skipping it.
===========
Run 210/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_211/ already exists.
Skipping it.
===========
Run 211/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_212/ already exists.
Skipping it.
===========
Run 212/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_213/ already exists.
Skipping it.
===========
Run 213/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_214/ already exists.
Skipping it.
===========
Run 214/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_215/ already exists.
Skipping it.
===========
Run 215/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_216/ already exists.
Skipping it.
===========
Run 216/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_217/ already exists.
Skipping it.
===========
Run 217/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_218/ already exists.
Skipping it.
===========
Run 218/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_219/ already exists.
Skipping it.
===========
Run 219/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_220/ already exists.
Skipping it.
===========
Run 220/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_221/ already exists.
Skipping it.
===========
Run 221/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_222/ already exists.
Skipping it.
===========
Run 222/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_223/ already exists.
Skipping it.
===========
Run 223/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_224/ already exists.
Skipping it.
===========
Run 224/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_225/ already exists.
Skipping it.
===========
Run 225/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_226/ already exists.
Skipping it.
===========
Run 226/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_227/ already exists.
Skipping it.
===========
Run 227/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_228/ already exists.
Skipping it.
===========
Run 228/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_229/ already exists.
Skipping it.
===========
Run 229/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_230/ already exists.
Skipping it.
===========
Run 230/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_231/ already exists.
Skipping it.
===========
Run 231/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_232/ already exists.
Skipping it.
===========
Run 232/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_233/ already exists.
Skipping it.
===========
Run 233/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_234/ already exists.
Skipping it.
===========
Run 234/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_235/ already exists.
Skipping it.
===========
Run 235/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_236/ already exists.
Skipping it.
===========
Run 236/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_237/ already exists.
Skipping it.
===========
Run 237/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_238/ already exists.
Skipping it.
===========
Run 238/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_239/ already exists.
Skipping it.
===========
Run 239/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_240/ already exists.
Skipping it.
===========
Run 240/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_241/ already exists.
Skipping it.
===========
Run 241/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_242/ already exists.
Skipping it.
===========
Run 242/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_243/ already exists.
Skipping it.
===========
Run 243/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_244/ already exists.
Skipping it.
===========
Run 244/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_245/ already exists.
Skipping it.
===========
Run 245/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_246/ already exists.
Skipping it.
===========
Run 246/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_247/ already exists.
Skipping it.
===========
Run 247/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_248/ already exists.
Skipping it.
===========
Run 248/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_249/ already exists.
Skipping it.
===========
Run 249/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_250/ already exists.
Skipping it.
===========
Run 250/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_251/ already exists.
Skipping it.
===========
Run 251/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_252/ already exists.
Skipping it.
===========
Run 252/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_253/ already exists.
Skipping it.
===========
Run 253/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_254/ already exists.
Skipping it.
===========
Run 254/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_255/ already exists.
Skipping it.
===========
Run 255/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_256/ already exists.
Skipping it.
===========
Run 256/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_257/ already exists.
Skipping it.
===========
Run 257/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_258/ already exists.
Skipping it.
===========
Run 258/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_259/ already exists.
Skipping it.
===========
Run 259/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_260/ already exists.
Skipping it.
===========
Run 260/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_261/ already exists.
Skipping it.
===========
Run 261/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_262/ already exists.
Skipping it.
===========
Run 262/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_263/ already exists.
Skipping it.
===========
Run 263/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_264/ already exists.
Skipping it.
===========
Run 264/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_265/ already exists.
Skipping it.
===========
Run 265/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_266/ already exists.
Skipping it.
===========
Run 266/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_267/ already exists.
Skipping it.
===========
Run 267/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_268/ already exists.
Skipping it.
===========
Run 268/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_269/ already exists.
Skipping it.
===========
Run 269/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_270/ already exists.
Skipping it.
===========
Run 270/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_271/ already exists.
Skipping it.
===========
Run 271/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_272/ already exists.
Skipping it.
===========
Run 272/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_273/ already exists.
Skipping it.
===========
Run 273/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_274/ already exists.
Skipping it.
===========
Run 274/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_275/ already exists.
Skipping it.
===========
Run 275/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_276/ already exists.
Skipping it.
===========
Run 276/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_277/ already exists.
Skipping it.
===========
Run 277/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_278/ already exists.
Skipping it.
===========
Run 278/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_279/ already exists.
Skipping it.
===========
Run 279/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_280/ already exists.
Skipping it.
===========
Run 280/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_281/ already exists.
Skipping it.
===========
Run 281/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_282/ already exists.
Skipping it.
===========
Run 282/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_283/ already exists.
Skipping it.
===========
Run 283/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_284/ already exists.
Skipping it.
===========
Run 284/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_285/ already exists.
Skipping it.
===========
Run 285/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_286/ already exists.
Skipping it.
===========
Run 286/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_287/ already exists.
Skipping it.
===========
Run 287/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_288/ already exists.
Skipping it.
===========
Run 288/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_289/ already exists.
Skipping it.
===========
Run 289/360 already exists. Skipping it.
===========

===========
Generating train data for run 290.
===========
Train data generated in 4.08 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[400], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 400)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_290/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 377}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_290/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 3.7238696 ,  9.43685   ,  1.1190627 , ...,  2.142107  ,
         2.3926744 ,  4.8186955 ],
       [ 6.241181  ,  7.717636  ,  5.651493  , ...,  3.425949  ,
        -0.49265265,  1.9154986 ],
       [ 3.3726914 ,  9.29804   ,  1.3570417 , ...,  2.4970124 ,
         2.6094882 ,  4.711849  ],
       ...,
       [ 3.94811   ,  9.164151  ,  0.50363195, ...,  2.3412814 ,
         2.652659  ,  4.991491  ],
       [ 5.233636  ,  7.4719415 ,  6.5299125 , ...,  3.209942  ,
        -0.06977074,  1.8583359 ],
       [ 5.8670726 ,  8.517102  ,  6.5077605 , ...,  2.7807686 ,
        -0.09155883,  1.80868   ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[400], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[400], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_290/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_290
self.data_kwargs: {'seed': 377}
self.x_data: [[ 5.4503875   7.122494    6.6042137  ...  4.0400963  -0.13201235
   1.9971261 ]
 [ 4.036721    9.156662    0.41902506 ...  2.9766989   2.529345
   4.880709  ]
 [ 5.4924355   5.4514885   5.156783   ...  3.4015932   0.04154692
   1.7029461 ]
 ...
 [ 5.200512    7.6560297   5.578568   ...  4.698631   -0.40574354
   1.779597  ]
 [ 3.6791496   9.481186    1.055154   ...  2.77986     2.2883475
   5.4494743 ]
 [ 5.7552614   5.6031685   5.1716557  ...  2.688277    0.6328201
   1.813958  ]]
self.y_data: []
self.ndims: 400
Model defined.
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 400)]             0         
                                                                 
 log_prob_layer (LogProbLaye  (None,)                  5197280   
 r)                                                              
                                                                 
=================================================================
Total params: 5,197,280
Trainable params: 5,197,280
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer'")
self.model: <keras.engine.functional.Functional object at 0x7f73ccb61e10>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7f73c01139a0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7f73c01139a0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7f73a03145b0>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7f73a0314f70>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7f73a03154e0>, <keras.callbacks.ModelCheckpoint object at 0x7f73a0315630>, <keras.callbacks.EarlyStopping object at 0x7f73a0315840>, <keras.callbacks.ReduceLROnPlateau object at 0x7f73a0315870>, <keras.callbacks.TerminateOnNaN object at 0x7f73a03155a0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 3.7238696 ,  9.43685   ,  1.1190627 , ...,  2.142107  ,
         2.3926744 ,  4.8186955 ],
       [ 6.241181  ,  7.717636  ,  5.651493  , ...,  3.425949  ,
        -0.49265265,  1.9154986 ],
       [ 3.3726914 ,  9.29804   ,  1.3570417 , ...,  2.4970124 ,
         2.6094882 ,  4.711849  ],
       ...,
       [ 3.94811   ,  9.164151  ,  0.50363195, ...,  2.3412814 ,
         2.652659  ,  4.991491  ],
       [ 5.233636  ,  7.4719415 ,  6.5299125 , ...,  3.209942  ,
        -0.06977074,  1.8583359 ],
       [ 5.8670726 ,  8.517102  ,  6.5077605 , ...,  2.7807686 ,
        -0.09155883,  1.80868   ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_290/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 290/360 with hyperparameters:
timestamp = 2023-10-01 08:50:23.469153
ndims = 400
seed_train = 377
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 8
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 5197280
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 5.4503875   7.122494    6.6042137   5.309246    3.8837402   6.1032987
  3.2747407   8.514353    9.539525    4.2039814   7.8800626   5.3939905
  5.34158     9.293106    0.8770968   1.5314108   0.12865204  8.272855
  8.501842    9.446226    9.502767    8.410516    4.9876294   7.864842
 -0.55943847  6.3523383   1.0358174   9.512058    5.688881    3.6485534
  2.499226    7.8448067   4.597729    5.5665426   0.18910412  5.667873
  6.1968737   6.712283    9.476086    6.7765236   3.408581    4.6058736
  7.6050043   0.61984926  7.3563876   6.6170125   2.510723    1.2874926
  3.5798266   4.2793493   6.275016    5.0620513   9.66742    -1.1743706
  3.0800657   1.4056138   6.7072477   1.9207056   3.8525152   4.3401546
  1.6627069   1.2231957   6.987124    1.8149761   3.182506    5.0326567
  8.409589    1.4434397   8.23025     0.39415985  9.307192    4.6735597
 10.650202    5.3744183   6.418746    0.9898615   2.788737    1.1858863
  1.5611295   0.5064502   3.2564132   4.914442    0.6098506   7.010224
  5.8092403  -0.169492    5.161507    1.3462601   5.788928    9.193622
  2.9173136   7.232309    1.6720103   7.4426236   2.9197469   1.3062096
  6.1982694   0.29196495 10.953671   -0.08677885  6.939062    2.4709713
  7.2325597  10.329311    1.4309065   4.638652    6.3280687   5.644319
  2.196842   10.387783    4.901941    8.565788    6.5343223   2.9470005
  8.325199    3.7861805   9.136329    5.550188    7.813981    5.9644313
  8.237377    5.0038056   9.581938    6.99911     6.1039143   6.056915
  1.4445473   3.103255    6.632713    4.342426    6.0340533   4.7459965
  1.7692869   2.8366094   6.415392    5.6114826   5.1275196   6.3984747
  6.735465    4.4016485   8.709706    3.1417663   4.2276716   9.660656
  8.2883005   6.626367    0.8080669   9.418564    6.830899   10.237706
  1.456694    8.203584    1.5723522   6.484804    0.86127687  8.478307
  8.103653    5.547103    3.8008394   0.7299273   6.362139    2.8127298
  7.636023    8.78479     9.290354    9.385742   -1.1753615   3.9683168
  6.8877616   2.2416272   5.5708094  -0.50811183  3.8391137   0.16558449
  8.009146    2.571927    3.5177958   8.998734    7.11121     0.09595776
  1.2741346   6.253047    5.895323    2.0915527   9.29054     5.743179
  6.255039    5.7778873   7.3571024   2.2485785   4.0739074   1.6081592
  1.7199721   8.725073    7.77918     5.1006904   2.0623055   3.1545155
  0.75499594  5.0893865   2.8197107   6.962087    3.5659146   1.0267289
 -0.6260812   1.5355247   6.8308463   4.5483804   5.9158072   9.006858
  9.77616     2.2165966   7.460669    2.5373344   0.4081487   7.6157484
  3.3750906   3.8960402   5.71214     7.490446    6.4016957   8.613486
  2.819387    7.9303412   1.7314224   9.538648    7.736958    2.4179955
  9.527001    7.059995    2.5198023   2.2539816   5.3620934   0.23087181
  1.9677207   4.671521    3.6718035   3.2287874   2.1796823   5.821259
  9.039222    1.179612    5.078053    0.9973426   6.7585154   3.899846
  6.6729937   1.6273023   2.4085488   4.114567    3.7328508   9.127069
  7.4458785   7.0147486   9.325275    1.4195807   5.9998426   5.2286615
 10.043154    2.888986    4.7117496   0.20093238  0.27483445 10.93615
  6.9039683   7.4092994   2.8905458   6.046226    0.6812333   3.4357529
  9.768889    8.091893    3.1047525   9.926891    2.1120188   9.629967
  9.930694    8.028074    7.014969    9.691176    2.9244244   7.99433
  6.159864   -0.79785514  4.143048    0.21752763  9.482869    5.7499695
  5.2542515   6.244202    4.2482862   1.6801087   8.515542    0.3167255
  5.2831907   2.2083943   0.5855354   8.535191    9.725981    9.691748
  9.653526    7.3058367   3.5405674   0.73322135  5.719691    2.8237493
  0.32978755  0.90659106  7.4820457   0.9795703   7.6823697   1.7277029
  0.6435243   1.8246074   7.6032724   2.4023383   4.2732863   6.1268206
  8.705712    6.832186    2.7310984   2.5975013   0.0902206   3.399262
  1.5055735   3.8568573   6.621214    7.6750536   2.6225915   4.1453314
  1.7073083   8.89813    -0.1718573   6.9725533   7.7773223   7.9170265
  2.6101732   2.9853687   7.1697206   3.2915673   3.891646    3.5294948
  4.866458    0.55452836  7.8279204   0.6481973   3.7568944   4.0404058
  5.8455215   9.152357    5.336799    2.168101    3.8556015   5.4018097
  5.2359657   6.204859    2.8202639   1.5846847   3.3806565   9.7963
  2.567823    9.835822    5.4188037   4.832603    9.032858    4.1352024
  7.3247995   3.8723443   9.145787    6.9910374   6.391391    3.4071174
  7.336579    6.554969    2.3683283   1.6141974   8.361311    9.761565
  5.8582726   6.3765154   8.276069    4.728798    7.642629    4.2543736
 10.530394   10.085689    8.994264    1.6067865   5.8006144   4.0085006
 -0.28021276  4.5861626   2.0959966   8.551464    0.39145368  9.690211
  3.7690969   4.0400963  -0.13201235  1.9971261 ]
Epoch 1/1000
2023-10-01 08:53:21.198 
Epoch 1/1000 
	 loss: 467.7394, MinusLogProbMetric: 467.7394, val_loss: 219.3662, val_MinusLogProbMetric: 219.3662

Epoch 1: val_loss improved from inf to 219.36620, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 178s - loss: 467.7394 - MinusLogProbMetric: 467.7394 - val_loss: 219.3662 - val_MinusLogProbMetric: 219.3662 - lr: 0.0010 - 178s/epoch - 908ms/step
Epoch 2/1000
2023-10-01 08:54:45.093 
Epoch 2/1000 
	 loss: 206.1817, MinusLogProbMetric: 206.1817, val_loss: 204.8297, val_MinusLogProbMetric: 204.8297

Epoch 2: val_loss improved from 219.36620 to 204.82965, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 85s - loss: 206.1817 - MinusLogProbMetric: 206.1817 - val_loss: 204.8297 - val_MinusLogProbMetric: 204.8297 - lr: 0.0010 - 85s/epoch - 431ms/step
Epoch 3/1000
2023-10-01 08:56:07.714 
Epoch 3/1000 
	 loss: 196.7490, MinusLogProbMetric: 196.7490, val_loss: 194.2706, val_MinusLogProbMetric: 194.2706

Epoch 3: val_loss improved from 204.82965 to 194.27058, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 82s - loss: 196.7490 - MinusLogProbMetric: 196.7490 - val_loss: 194.2706 - val_MinusLogProbMetric: 194.2706 - lr: 0.0010 - 82s/epoch - 417ms/step
Epoch 4/1000
2023-10-01 08:57:18.313 
Epoch 4/1000 
	 loss: 193.3615, MinusLogProbMetric: 193.3615, val_loss: 192.0063, val_MinusLogProbMetric: 192.0063

Epoch 4: val_loss improved from 194.27058 to 192.00633, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 71s - loss: 193.3615 - MinusLogProbMetric: 193.3615 - val_loss: 192.0063 - val_MinusLogProbMetric: 192.0063 - lr: 0.0010 - 71s/epoch - 360ms/step
Epoch 5/1000
2023-10-01 08:58:15.923 
Epoch 5/1000 
	 loss: 191.1823, MinusLogProbMetric: 191.1823, val_loss: 191.2883, val_MinusLogProbMetric: 191.2883

Epoch 5: val_loss improved from 192.00633 to 191.28825, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 58s - loss: 191.1823 - MinusLogProbMetric: 191.1823 - val_loss: 191.2883 - val_MinusLogProbMetric: 191.2883 - lr: 0.0010 - 58s/epoch - 296ms/step
Epoch 6/1000
2023-10-01 08:59:14.926 
Epoch 6/1000 
	 loss: 190.5546, MinusLogProbMetric: 190.5546, val_loss: 190.6707, val_MinusLogProbMetric: 190.6707

Epoch 6: val_loss improved from 191.28825 to 190.67065, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 59s - loss: 190.5546 - MinusLogProbMetric: 190.5546 - val_loss: 190.6707 - val_MinusLogProbMetric: 190.6707 - lr: 0.0010 - 59s/epoch - 301ms/step
Epoch 7/1000
2023-10-01 09:00:11.661 
Epoch 7/1000 
	 loss: 188.9291, MinusLogProbMetric: 188.9291, val_loss: 196.5669, val_MinusLogProbMetric: 196.5669

Epoch 7: val_loss did not improve from 190.67065
196/196 - 56s - loss: 188.9291 - MinusLogProbMetric: 188.9291 - val_loss: 196.5669 - val_MinusLogProbMetric: 196.5669 - lr: 0.0010 - 56s/epoch - 285ms/step
Epoch 8/1000
2023-10-01 09:01:06.568 
Epoch 8/1000 
	 loss: 188.5105, MinusLogProbMetric: 188.5105, val_loss: 189.0041, val_MinusLogProbMetric: 189.0041

Epoch 8: val_loss improved from 190.67065 to 189.00414, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 56s - loss: 188.5105 - MinusLogProbMetric: 188.5105 - val_loss: 189.0041 - val_MinusLogProbMetric: 189.0041 - lr: 0.0010 - 56s/epoch - 285ms/step
Epoch 9/1000
2023-10-01 09:02:01.805 
Epoch 9/1000 
	 loss: 188.0041, MinusLogProbMetric: 188.0041, val_loss: 186.5798, val_MinusLogProbMetric: 186.5798

Epoch 9: val_loss improved from 189.00414 to 186.57982, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 55s - loss: 188.0041 - MinusLogProbMetric: 188.0041 - val_loss: 186.5798 - val_MinusLogProbMetric: 186.5798 - lr: 0.0010 - 55s/epoch - 280ms/step
Epoch 10/1000
2023-10-01 09:02:56.633 
Epoch 10/1000 
	 loss: 187.2012, MinusLogProbMetric: 187.2012, val_loss: 202.6688, val_MinusLogProbMetric: 202.6688

Epoch 10: val_loss did not improve from 186.57982
196/196 - 54s - loss: 187.2012 - MinusLogProbMetric: 187.2012 - val_loss: 202.6688 - val_MinusLogProbMetric: 202.6688 - lr: 0.0010 - 54s/epoch - 277ms/step
Epoch 11/1000
2023-10-01 09:03:51.199 
Epoch 11/1000 
	 loss: 187.2203, MinusLogProbMetric: 187.2203, val_loss: 186.5547, val_MinusLogProbMetric: 186.5547

Epoch 11: val_loss improved from 186.57982 to 186.55470, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 55s - loss: 187.2203 - MinusLogProbMetric: 187.2203 - val_loss: 186.5547 - val_MinusLogProbMetric: 186.5547 - lr: 0.0010 - 55s/epoch - 282ms/step
Epoch 12/1000
2023-10-01 09:04:50.734 
Epoch 12/1000 
	 loss: 185.8859, MinusLogProbMetric: 185.8859, val_loss: 186.5027, val_MinusLogProbMetric: 186.5027

Epoch 12: val_loss improved from 186.55470 to 186.50270, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 59s - loss: 185.8859 - MinusLogProbMetric: 185.8859 - val_loss: 186.5027 - val_MinusLogProbMetric: 186.5027 - lr: 0.0010 - 59s/epoch - 302ms/step
Epoch 13/1000
2023-10-01 09:05:44.735 
Epoch 13/1000 
	 loss: 185.8228, MinusLogProbMetric: 185.8228, val_loss: 185.3367, val_MinusLogProbMetric: 185.3367

Epoch 13: val_loss improved from 186.50270 to 185.33670, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 55s - loss: 185.8228 - MinusLogProbMetric: 185.8228 - val_loss: 185.3367 - val_MinusLogProbMetric: 185.3367 - lr: 0.0010 - 55s/epoch - 281ms/step
Epoch 14/1000
2023-10-01 09:06:40.791 
Epoch 14/1000 
	 loss: 185.5642, MinusLogProbMetric: 185.5642, val_loss: 186.0632, val_MinusLogProbMetric: 186.0632

Epoch 14: val_loss did not improve from 185.33670
196/196 - 55s - loss: 185.5642 - MinusLogProbMetric: 185.5642 - val_loss: 186.0632 - val_MinusLogProbMetric: 186.0632 - lr: 0.0010 - 55s/epoch - 278ms/step
Epoch 15/1000
2023-10-01 09:07:36.372 
Epoch 15/1000 
	 loss: 185.2452, MinusLogProbMetric: 185.2452, val_loss: 185.1223, val_MinusLogProbMetric: 185.1223

Epoch 15: val_loss improved from 185.33670 to 185.12225, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 56s - loss: 185.2452 - MinusLogProbMetric: 185.2452 - val_loss: 185.1223 - val_MinusLogProbMetric: 185.1223 - lr: 0.0010 - 56s/epoch - 287ms/step
Epoch 16/1000
2023-10-01 09:08:31.329 
Epoch 16/1000 
	 loss: 185.3618, MinusLogProbMetric: 185.3618, val_loss: 185.1155, val_MinusLogProbMetric: 185.1155

Epoch 16: val_loss improved from 185.12225 to 185.11546, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 55s - loss: 185.3618 - MinusLogProbMetric: 185.3618 - val_loss: 185.1155 - val_MinusLogProbMetric: 185.1155 - lr: 0.0010 - 55s/epoch - 281ms/step
Epoch 17/1000
2023-10-01 09:09:26.882 
Epoch 17/1000 
	 loss: 184.6021, MinusLogProbMetric: 184.6021, val_loss: 184.9423, val_MinusLogProbMetric: 184.9423

Epoch 17: val_loss improved from 185.11546 to 184.94232, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 56s - loss: 184.6021 - MinusLogProbMetric: 184.6021 - val_loss: 184.9423 - val_MinusLogProbMetric: 184.9423 - lr: 0.0010 - 56s/epoch - 285ms/step
Epoch 18/1000
2023-10-01 09:10:23.457 
Epoch 18/1000 
	 loss: 184.3673, MinusLogProbMetric: 184.3673, val_loss: 183.9506, val_MinusLogProbMetric: 183.9506

Epoch 18: val_loss improved from 184.94232 to 183.95061, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 56s - loss: 184.3673 - MinusLogProbMetric: 184.3673 - val_loss: 183.9506 - val_MinusLogProbMetric: 183.9506 - lr: 0.0010 - 56s/epoch - 284ms/step
Epoch 19/1000
2023-10-01 09:11:19.239 
Epoch 19/1000 
	 loss: 184.1051, MinusLogProbMetric: 184.1051, val_loss: 184.5695, val_MinusLogProbMetric: 184.5695

Epoch 19: val_loss did not improve from 183.95061
196/196 - 56s - loss: 184.1051 - MinusLogProbMetric: 184.1051 - val_loss: 184.5695 - val_MinusLogProbMetric: 184.5695 - lr: 0.0010 - 56s/epoch - 284ms/step
Epoch 20/1000
2023-10-01 09:12:11.432 
Epoch 20/1000 
	 loss: 183.9366, MinusLogProbMetric: 183.9366, val_loss: 183.9504, val_MinusLogProbMetric: 183.9504

Epoch 20: val_loss improved from 183.95061 to 183.95044, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 53s - loss: 183.9366 - MinusLogProbMetric: 183.9366 - val_loss: 183.9504 - val_MinusLogProbMetric: 183.9504 - lr: 0.0010 - 53s/epoch - 270ms/step
Epoch 21/1000
2023-10-01 09:13:05.289 
Epoch 21/1000 
	 loss: 183.8417, MinusLogProbMetric: 183.8417, val_loss: 184.1509, val_MinusLogProbMetric: 184.1509

Epoch 21: val_loss did not improve from 183.95044
196/196 - 53s - loss: 183.8417 - MinusLogProbMetric: 183.8417 - val_loss: 184.1509 - val_MinusLogProbMetric: 184.1509 - lr: 0.0010 - 53s/epoch - 271ms/step
Epoch 22/1000
2023-10-01 09:13:59.187 
Epoch 22/1000 
	 loss: 183.5814, MinusLogProbMetric: 183.5814, val_loss: 184.0647, val_MinusLogProbMetric: 184.0647

Epoch 22: val_loss did not improve from 183.95044
196/196 - 54s - loss: 183.5814 - MinusLogProbMetric: 183.5814 - val_loss: 184.0647 - val_MinusLogProbMetric: 184.0647 - lr: 0.0010 - 54s/epoch - 275ms/step
Epoch 23/1000
2023-10-01 09:14:58.479 
Epoch 23/1000 
	 loss: 183.7029, MinusLogProbMetric: 183.7029, val_loss: 185.0026, val_MinusLogProbMetric: 185.0026

Epoch 23: val_loss did not improve from 183.95044
196/196 - 59s - loss: 183.7029 - MinusLogProbMetric: 183.7029 - val_loss: 185.0026 - val_MinusLogProbMetric: 185.0026 - lr: 0.0010 - 59s/epoch - 302ms/step
Epoch 24/1000
2023-10-01 09:15:52.738 
Epoch 24/1000 
	 loss: 183.5827, MinusLogProbMetric: 183.5827, val_loss: 183.4725, val_MinusLogProbMetric: 183.4725

Epoch 24: val_loss improved from 183.95044 to 183.47249, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 55s - loss: 183.5827 - MinusLogProbMetric: 183.5827 - val_loss: 183.4725 - val_MinusLogProbMetric: 183.4725 - lr: 0.0010 - 55s/epoch - 279ms/step
Epoch 25/1000
2023-10-01 09:16:46.053 
Epoch 25/1000 
	 loss: 183.1380, MinusLogProbMetric: 183.1380, val_loss: 182.9066, val_MinusLogProbMetric: 182.9066

Epoch 25: val_loss improved from 183.47249 to 182.90662, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 54s - loss: 183.1380 - MinusLogProbMetric: 183.1380 - val_loss: 182.9066 - val_MinusLogProbMetric: 182.9066 - lr: 0.0010 - 54s/epoch - 273ms/step
Epoch 26/1000
2023-10-01 09:17:40.319 
Epoch 26/1000 
	 loss: 183.0807, MinusLogProbMetric: 183.0807, val_loss: 182.8318, val_MinusLogProbMetric: 182.8318

Epoch 26: val_loss improved from 182.90662 to 182.83176, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 54s - loss: 183.0807 - MinusLogProbMetric: 183.0807 - val_loss: 182.8318 - val_MinusLogProbMetric: 182.8318 - lr: 0.0010 - 54s/epoch - 275ms/step
Epoch 27/1000
2023-10-01 09:18:34.802 
Epoch 27/1000 
	 loss: 183.0585, MinusLogProbMetric: 183.0585, val_loss: 183.4150, val_MinusLogProbMetric: 183.4150

Epoch 27: val_loss did not improve from 182.83176
196/196 - 54s - loss: 183.0585 - MinusLogProbMetric: 183.0585 - val_loss: 183.4150 - val_MinusLogProbMetric: 183.4150 - lr: 0.0010 - 54s/epoch - 277ms/step
Epoch 28/1000
2023-10-01 09:19:28.652 
Epoch 28/1000 
	 loss: 182.9564, MinusLogProbMetric: 182.9564, val_loss: 183.1770, val_MinusLogProbMetric: 183.1770

Epoch 28: val_loss did not improve from 182.83176
196/196 - 54s - loss: 182.9564 - MinusLogProbMetric: 182.9564 - val_loss: 183.1770 - val_MinusLogProbMetric: 183.1770 - lr: 0.0010 - 54s/epoch - 275ms/step
Epoch 29/1000
2023-10-01 09:20:22.425 
Epoch 29/1000 
	 loss: 182.9707, MinusLogProbMetric: 182.9707, val_loss: 184.3116, val_MinusLogProbMetric: 184.3116

Epoch 29: val_loss did not improve from 182.83176
196/196 - 54s - loss: 182.9707 - MinusLogProbMetric: 182.9707 - val_loss: 184.3116 - val_MinusLogProbMetric: 184.3116 - lr: 0.0010 - 54s/epoch - 274ms/step
Epoch 30/1000
2023-10-01 09:21:21.461 
Epoch 30/1000 
	 loss: 182.7684, MinusLogProbMetric: 182.7684, val_loss: 183.7029, val_MinusLogProbMetric: 183.7029

Epoch 30: val_loss did not improve from 182.83176
196/196 - 59s - loss: 182.7684 - MinusLogProbMetric: 182.7684 - val_loss: 183.7029 - val_MinusLogProbMetric: 183.7029 - lr: 0.0010 - 59s/epoch - 301ms/step
Epoch 31/1000
2023-10-01 09:22:19.688 
Epoch 31/1000 
	 loss: 182.7562, MinusLogProbMetric: 182.7562, val_loss: 182.5023, val_MinusLogProbMetric: 182.5023

Epoch 31: val_loss improved from 182.83176 to 182.50230, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 59s - loss: 182.7562 - MinusLogProbMetric: 182.7562 - val_loss: 182.5023 - val_MinusLogProbMetric: 182.5023 - lr: 0.0010 - 59s/epoch - 303ms/step
Epoch 32/1000
2023-10-01 09:23:15.624 
Epoch 32/1000 
	 loss: 182.8672, MinusLogProbMetric: 182.8672, val_loss: 183.2676, val_MinusLogProbMetric: 183.2676

Epoch 32: val_loss did not improve from 182.50230
196/196 - 55s - loss: 182.8672 - MinusLogProbMetric: 182.8672 - val_loss: 183.2676 - val_MinusLogProbMetric: 183.2676 - lr: 0.0010 - 55s/epoch - 280ms/step
Epoch 33/1000
2023-10-01 09:24:08.086 
Epoch 33/1000 
	 loss: 182.3966, MinusLogProbMetric: 182.3966, val_loss: 182.6333, val_MinusLogProbMetric: 182.6333

Epoch 33: val_loss did not improve from 182.50230
196/196 - 52s - loss: 182.3966 - MinusLogProbMetric: 182.3966 - val_loss: 182.6333 - val_MinusLogProbMetric: 182.6333 - lr: 0.0010 - 52s/epoch - 268ms/step
Epoch 34/1000
2023-10-01 09:25:07.882 
Epoch 34/1000 
	 loss: 183.0642, MinusLogProbMetric: 183.0642, val_loss: 182.4283, val_MinusLogProbMetric: 182.4283

Epoch 34: val_loss improved from 182.50230 to 182.42830, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 61s - loss: 183.0642 - MinusLogProbMetric: 183.0642 - val_loss: 182.4283 - val_MinusLogProbMetric: 182.4283 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 35/1000
2023-10-01 09:26:04.481 
Epoch 35/1000 
	 loss: 182.5589, MinusLogProbMetric: 182.5589, val_loss: 183.4823, val_MinusLogProbMetric: 183.4823

Epoch 35: val_loss did not improve from 182.42830
196/196 - 56s - loss: 182.5589 - MinusLogProbMetric: 182.5589 - val_loss: 183.4823 - val_MinusLogProbMetric: 183.4823 - lr: 0.0010 - 56s/epoch - 284ms/step
Epoch 36/1000
2023-10-01 09:26:58.926 
Epoch 36/1000 
	 loss: 182.4305, MinusLogProbMetric: 182.4305, val_loss: 182.5960, val_MinusLogProbMetric: 182.5960

Epoch 36: val_loss did not improve from 182.42830
196/196 - 54s - loss: 182.4305 - MinusLogProbMetric: 182.4305 - val_loss: 182.5960 - val_MinusLogProbMetric: 182.5960 - lr: 0.0010 - 54s/epoch - 278ms/step
Epoch 37/1000
2023-10-01 09:27:53.310 
Epoch 37/1000 
	 loss: 182.0479, MinusLogProbMetric: 182.0479, val_loss: 183.2005, val_MinusLogProbMetric: 183.2005

Epoch 37: val_loss did not improve from 182.42830
196/196 - 54s - loss: 182.0479 - MinusLogProbMetric: 182.0479 - val_loss: 183.2005 - val_MinusLogProbMetric: 183.2005 - lr: 0.0010 - 54s/epoch - 277ms/step
Epoch 38/1000
2023-10-01 09:28:46.892 
Epoch 38/1000 
	 loss: 182.1466, MinusLogProbMetric: 182.1466, val_loss: 183.4107, val_MinusLogProbMetric: 183.4107

Epoch 38: val_loss did not improve from 182.42830
196/196 - 54s - loss: 182.1466 - MinusLogProbMetric: 182.1466 - val_loss: 183.4107 - val_MinusLogProbMetric: 183.4107 - lr: 0.0010 - 54s/epoch - 273ms/step
Epoch 39/1000
2023-10-01 09:29:39.950 
Epoch 39/1000 
	 loss: 182.4567, MinusLogProbMetric: 182.4567, val_loss: 182.5836, val_MinusLogProbMetric: 182.5836

Epoch 39: val_loss did not improve from 182.42830
196/196 - 53s - loss: 182.4567 - MinusLogProbMetric: 182.4567 - val_loss: 182.5836 - val_MinusLogProbMetric: 182.5836 - lr: 0.0010 - 53s/epoch - 271ms/step
Epoch 40/1000
2023-10-01 09:30:33.474 
Epoch 40/1000 
	 loss: 181.9116, MinusLogProbMetric: 181.9116, val_loss: 182.4749, val_MinusLogProbMetric: 182.4749

Epoch 40: val_loss did not improve from 182.42830
196/196 - 53s - loss: 181.9116 - MinusLogProbMetric: 181.9116 - val_loss: 182.4749 - val_MinusLogProbMetric: 182.4749 - lr: 0.0010 - 53s/epoch - 273ms/step
Epoch 41/1000
2023-10-01 09:31:27.590 
Epoch 41/1000 
	 loss: 182.0026, MinusLogProbMetric: 182.0026, val_loss: 183.6194, val_MinusLogProbMetric: 183.6194

Epoch 41: val_loss did not improve from 182.42830
196/196 - 54s - loss: 182.0026 - MinusLogProbMetric: 182.0026 - val_loss: 183.6194 - val_MinusLogProbMetric: 183.6194 - lr: 0.0010 - 54s/epoch - 276ms/step
Epoch 42/1000
2023-10-01 09:32:26.156 
Epoch 42/1000 
	 loss: 182.0215, MinusLogProbMetric: 182.0215, val_loss: 182.4794, val_MinusLogProbMetric: 182.4794

Epoch 42: val_loss did not improve from 182.42830
196/196 - 59s - loss: 182.0215 - MinusLogProbMetric: 182.0215 - val_loss: 182.4794 - val_MinusLogProbMetric: 182.4794 - lr: 0.0010 - 59s/epoch - 299ms/step
Epoch 43/1000
2023-10-01 09:33:21.312 
Epoch 43/1000 
	 loss: 181.8079, MinusLogProbMetric: 181.8079, val_loss: 183.1110, val_MinusLogProbMetric: 183.1110

Epoch 43: val_loss did not improve from 182.42830
196/196 - 55s - loss: 181.8079 - MinusLogProbMetric: 181.8079 - val_loss: 183.1110 - val_MinusLogProbMetric: 183.1110 - lr: 0.0010 - 55s/epoch - 281ms/step
Epoch 44/1000
2023-10-01 09:34:20.589 
Epoch 44/1000 
	 loss: 181.8855, MinusLogProbMetric: 181.8855, val_loss: 182.0537, val_MinusLogProbMetric: 182.0537

Epoch 44: val_loss improved from 182.42830 to 182.05370, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 60s - loss: 181.8855 - MinusLogProbMetric: 181.8855 - val_loss: 182.0537 - val_MinusLogProbMetric: 182.0537 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 45/1000
2023-10-01 09:35:15.748 
Epoch 45/1000 
	 loss: 181.8668, MinusLogProbMetric: 181.8668, val_loss: 181.8732, val_MinusLogProbMetric: 181.8732

Epoch 45: val_loss improved from 182.05370 to 181.87323, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 55s - loss: 181.8668 - MinusLogProbMetric: 181.8668 - val_loss: 181.8732 - val_MinusLogProbMetric: 181.8732 - lr: 0.0010 - 55s/epoch - 282ms/step
Epoch 46/1000
2023-10-01 09:36:10.926 
Epoch 46/1000 
	 loss: 182.2922, MinusLogProbMetric: 182.2922, val_loss: 182.6462, val_MinusLogProbMetric: 182.6462

Epoch 46: val_loss did not improve from 181.87323
196/196 - 54s - loss: 182.2922 - MinusLogProbMetric: 182.2922 - val_loss: 182.6462 - val_MinusLogProbMetric: 182.6462 - lr: 0.0010 - 54s/epoch - 278ms/step
Epoch 47/1000
2023-10-01 09:37:04.773 
Epoch 47/1000 
	 loss: 181.8696, MinusLogProbMetric: 181.8696, val_loss: 181.9733, val_MinusLogProbMetric: 181.9733

Epoch 47: val_loss did not improve from 181.87323
196/196 - 54s - loss: 181.8696 - MinusLogProbMetric: 181.8696 - val_loss: 181.9733 - val_MinusLogProbMetric: 181.9733 - lr: 0.0010 - 54s/epoch - 275ms/step
Epoch 48/1000
2023-10-01 09:38:03.020 
Epoch 48/1000 
	 loss: 181.7213, MinusLogProbMetric: 181.7213, val_loss: 183.1419, val_MinusLogProbMetric: 183.1419

Epoch 48: val_loss did not improve from 181.87323
196/196 - 58s - loss: 181.7213 - MinusLogProbMetric: 181.7213 - val_loss: 183.1419 - val_MinusLogProbMetric: 183.1419 - lr: 0.0010 - 58s/epoch - 297ms/step
Epoch 49/1000
2023-10-01 09:38:57.962 
Epoch 49/1000 
	 loss: 181.4310, MinusLogProbMetric: 181.4310, val_loss: 183.0672, val_MinusLogProbMetric: 183.0672

Epoch 49: val_loss did not improve from 181.87323
196/196 - 55s - loss: 181.4310 - MinusLogProbMetric: 181.4310 - val_loss: 183.0672 - val_MinusLogProbMetric: 183.0672 - lr: 0.0010 - 55s/epoch - 280ms/step
Epoch 50/1000
2023-10-01 09:39:56.784 
Epoch 50/1000 
	 loss: 181.6342, MinusLogProbMetric: 181.6342, val_loss: 181.8512, val_MinusLogProbMetric: 181.8512

Epoch 50: val_loss improved from 181.87323 to 181.85117, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 60s - loss: 181.6342 - MinusLogProbMetric: 181.6342 - val_loss: 181.8512 - val_MinusLogProbMetric: 181.8512 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 51/1000
2023-10-01 09:40:52.950 
Epoch 51/1000 
	 loss: 181.7542, MinusLogProbMetric: 181.7542, val_loss: 181.7346, val_MinusLogProbMetric: 181.7346

Epoch 51: val_loss improved from 181.85117 to 181.73462, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 56s - loss: 181.7542 - MinusLogProbMetric: 181.7542 - val_loss: 181.7346 - val_MinusLogProbMetric: 181.7346 - lr: 0.0010 - 56s/epoch - 283ms/step
Epoch 52/1000
2023-10-01 09:41:48.137 
Epoch 52/1000 
	 loss: 181.3694, MinusLogProbMetric: 181.3694, val_loss: 181.8921, val_MinusLogProbMetric: 181.8921

Epoch 52: val_loss did not improve from 181.73462
196/196 - 55s - loss: 181.3694 - MinusLogProbMetric: 181.3694 - val_loss: 181.8921 - val_MinusLogProbMetric: 181.8921 - lr: 0.0010 - 55s/epoch - 281ms/step
Epoch 53/1000
2023-10-01 09:42:43.189 
Epoch 53/1000 
	 loss: 181.7028, MinusLogProbMetric: 181.7028, val_loss: 182.2228, val_MinusLogProbMetric: 182.2228

Epoch 53: val_loss did not improve from 181.73462
196/196 - 55s - loss: 181.7028 - MinusLogProbMetric: 181.7028 - val_loss: 182.2228 - val_MinusLogProbMetric: 182.2228 - lr: 0.0010 - 55s/epoch - 281ms/step
Epoch 54/1000
2023-10-01 09:43:37.833 
Epoch 54/1000 
	 loss: 181.3850, MinusLogProbMetric: 181.3850, val_loss: 181.7876, val_MinusLogProbMetric: 181.7876

Epoch 54: val_loss did not improve from 181.73462
196/196 - 55s - loss: 181.3850 - MinusLogProbMetric: 181.3850 - val_loss: 181.7876 - val_MinusLogProbMetric: 181.7876 - lr: 0.0010 - 55s/epoch - 279ms/step
Epoch 55/1000
2023-10-01 09:44:31.852 
Epoch 55/1000 
	 loss: 181.6284, MinusLogProbMetric: 181.6284, val_loss: 182.0530, val_MinusLogProbMetric: 182.0530

Epoch 55: val_loss did not improve from 181.73462
196/196 - 54s - loss: 181.6284 - MinusLogProbMetric: 181.6284 - val_loss: 182.0530 - val_MinusLogProbMetric: 182.0530 - lr: 0.0010 - 54s/epoch - 275ms/step
Epoch 56/1000
2023-10-01 09:45:30.959 
Epoch 56/1000 
	 loss: 181.2358, MinusLogProbMetric: 181.2358, val_loss: 183.3977, val_MinusLogProbMetric: 183.3977

Epoch 56: val_loss did not improve from 181.73462
196/196 - 59s - loss: 181.2358 - MinusLogProbMetric: 181.2358 - val_loss: 183.3977 - val_MinusLogProbMetric: 183.3977 - lr: 0.0010 - 59s/epoch - 301ms/step
Epoch 57/1000
2023-10-01 09:46:25.498 
Epoch 57/1000 
	 loss: 181.8668, MinusLogProbMetric: 181.8668, val_loss: 182.3163, val_MinusLogProbMetric: 182.3163

Epoch 57: val_loss did not improve from 181.73462
196/196 - 55s - loss: 181.8668 - MinusLogProbMetric: 181.8668 - val_loss: 182.3163 - val_MinusLogProbMetric: 182.3163 - lr: 0.0010 - 55s/epoch - 278ms/step
Epoch 58/1000
2023-10-01 09:47:20.932 
Epoch 58/1000 
	 loss: 181.4652, MinusLogProbMetric: 181.4652, val_loss: 181.8354, val_MinusLogProbMetric: 181.8354

Epoch 58: val_loss did not improve from 181.73462
196/196 - 55s - loss: 181.4652 - MinusLogProbMetric: 181.4652 - val_loss: 181.8354 - val_MinusLogProbMetric: 181.8354 - lr: 0.0010 - 55s/epoch - 283ms/step
Epoch 59/1000
2023-10-01 09:48:15.997 
Epoch 59/1000 
	 loss: 181.1015, MinusLogProbMetric: 181.1015, val_loss: 181.8477, val_MinusLogProbMetric: 181.8477

Epoch 59: val_loss did not improve from 181.73462
196/196 - 55s - loss: 181.1015 - MinusLogProbMetric: 181.1015 - val_loss: 181.8477 - val_MinusLogProbMetric: 181.8477 - lr: 0.0010 - 55s/epoch - 281ms/step
Epoch 60/1000
2023-10-01 09:49:16.632 
Epoch 60/1000 
	 loss: 181.1111, MinusLogProbMetric: 181.1111, val_loss: 182.5840, val_MinusLogProbMetric: 182.5840

Epoch 60: val_loss did not improve from 181.73462
196/196 - 61s - loss: 181.1111 - MinusLogProbMetric: 181.1111 - val_loss: 182.5840 - val_MinusLogProbMetric: 182.5840 - lr: 0.0010 - 61s/epoch - 309ms/step
Epoch 61/1000
2023-10-01 09:50:10.881 
Epoch 61/1000 
	 loss: 181.2056, MinusLogProbMetric: 181.2056, val_loss: 183.0108, val_MinusLogProbMetric: 183.0108

Epoch 61: val_loss did not improve from 181.73462
196/196 - 54s - loss: 181.2056 - MinusLogProbMetric: 181.2056 - val_loss: 183.0108 - val_MinusLogProbMetric: 183.0108 - lr: 0.0010 - 54s/epoch - 277ms/step
Epoch 62/1000
2023-10-01 09:51:05.028 
Epoch 62/1000 
	 loss: 181.4992, MinusLogProbMetric: 181.4992, val_loss: 182.9639, val_MinusLogProbMetric: 182.9639

Epoch 62: val_loss did not improve from 181.73462
196/196 - 54s - loss: 181.4992 - MinusLogProbMetric: 181.4992 - val_loss: 182.9639 - val_MinusLogProbMetric: 182.9639 - lr: 0.0010 - 54s/epoch - 276ms/step
Epoch 63/1000
2023-10-01 09:51:59.045 
Epoch 63/1000 
	 loss: 181.0560, MinusLogProbMetric: 181.0560, val_loss: 181.8563, val_MinusLogProbMetric: 181.8563

Epoch 63: val_loss did not improve from 181.73462
196/196 - 54s - loss: 181.0560 - MinusLogProbMetric: 181.0560 - val_loss: 181.8563 - val_MinusLogProbMetric: 181.8563 - lr: 0.0010 - 54s/epoch - 276ms/step
Epoch 64/1000
2023-10-01 09:52:53.144 
Epoch 64/1000 
	 loss: 181.1032, MinusLogProbMetric: 181.1032, val_loss: 181.3382, val_MinusLogProbMetric: 181.3382

Epoch 64: val_loss improved from 181.73462 to 181.33821, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 55s - loss: 181.1032 - MinusLogProbMetric: 181.1032 - val_loss: 181.3382 - val_MinusLogProbMetric: 181.3382 - lr: 0.0010 - 55s/epoch - 278ms/step
Epoch 65/1000
2023-10-01 09:53:52.327 
Epoch 65/1000 
	 loss: 181.1082, MinusLogProbMetric: 181.1082, val_loss: 181.7124, val_MinusLogProbMetric: 181.7124

Epoch 65: val_loss did not improve from 181.33821
196/196 - 59s - loss: 181.1082 - MinusLogProbMetric: 181.1082 - val_loss: 181.7124 - val_MinusLogProbMetric: 181.7124 - lr: 0.0010 - 59s/epoch - 300ms/step
Epoch 66/1000
2023-10-01 09:54:46.561 
Epoch 66/1000 
	 loss: 181.1771, MinusLogProbMetric: 181.1771, val_loss: 181.3450, val_MinusLogProbMetric: 181.3450

Epoch 66: val_loss did not improve from 181.33821
196/196 - 54s - loss: 181.1771 - MinusLogProbMetric: 181.1771 - val_loss: 181.3450 - val_MinusLogProbMetric: 181.3450 - lr: 0.0010 - 54s/epoch - 277ms/step
Epoch 67/1000
2023-10-01 09:55:40.646 
Epoch 67/1000 
	 loss: 180.9343, MinusLogProbMetric: 180.9343, val_loss: 181.5760, val_MinusLogProbMetric: 181.5760

Epoch 67: val_loss did not improve from 181.33821
196/196 - 54s - loss: 180.9343 - MinusLogProbMetric: 180.9343 - val_loss: 181.5760 - val_MinusLogProbMetric: 181.5760 - lr: 0.0010 - 54s/epoch - 276ms/step
Epoch 68/1000
2023-10-01 09:56:33.694 
Epoch 68/1000 
	 loss: 181.0747, MinusLogProbMetric: 181.0747, val_loss: 181.9650, val_MinusLogProbMetric: 181.9650

Epoch 68: val_loss did not improve from 181.33821
196/196 - 53s - loss: 181.0747 - MinusLogProbMetric: 181.0747 - val_loss: 181.9650 - val_MinusLogProbMetric: 181.9650 - lr: 0.0010 - 53s/epoch - 271ms/step
Epoch 69/1000
2023-10-01 09:57:31.678 
Epoch 69/1000 
	 loss: 180.9685, MinusLogProbMetric: 180.9685, val_loss: 182.0779, val_MinusLogProbMetric: 182.0779

Epoch 69: val_loss did not improve from 181.33821
196/196 - 58s - loss: 180.9685 - MinusLogProbMetric: 180.9685 - val_loss: 182.0779 - val_MinusLogProbMetric: 182.0779 - lr: 0.0010 - 58s/epoch - 296ms/step
Epoch 70/1000
2023-10-01 09:58:24.283 
Epoch 70/1000 
	 loss: 181.0487, MinusLogProbMetric: 181.0487, val_loss: 182.7596, val_MinusLogProbMetric: 182.7596

Epoch 70: val_loss did not improve from 181.33821
196/196 - 53s - loss: 181.0487 - MinusLogProbMetric: 181.0487 - val_loss: 182.7596 - val_MinusLogProbMetric: 182.7596 - lr: 0.0010 - 53s/epoch - 268ms/step
Epoch 71/1000
2023-10-01 09:59:17.864 
Epoch 71/1000 
	 loss: 180.9300, MinusLogProbMetric: 180.9300, val_loss: 181.7933, val_MinusLogProbMetric: 181.7933

Epoch 71: val_loss did not improve from 181.33821
196/196 - 54s - loss: 180.9300 - MinusLogProbMetric: 180.9300 - val_loss: 181.7933 - val_MinusLogProbMetric: 181.7933 - lr: 0.0010 - 54s/epoch - 273ms/step
Epoch 72/1000
2023-10-01 10:00:13.294 
Epoch 72/1000 
	 loss: 181.0246, MinusLogProbMetric: 181.0246, val_loss: 181.4355, val_MinusLogProbMetric: 181.4355

Epoch 72: val_loss did not improve from 181.33821
196/196 - 55s - loss: 181.0246 - MinusLogProbMetric: 181.0246 - val_loss: 181.4355 - val_MinusLogProbMetric: 181.4355 - lr: 0.0010 - 55s/epoch - 283ms/step
Epoch 73/1000
2023-10-01 10:01:07.082 
Epoch 73/1000 
	 loss: 180.9163, MinusLogProbMetric: 180.9163, val_loss: 184.4362, val_MinusLogProbMetric: 184.4362

Epoch 73: val_loss did not improve from 181.33821
196/196 - 54s - loss: 180.9163 - MinusLogProbMetric: 180.9163 - val_loss: 184.4362 - val_MinusLogProbMetric: 184.4362 - lr: 0.0010 - 54s/epoch - 274ms/step
Epoch 74/1000
2023-10-01 10:02:02.502 
Epoch 74/1000 
	 loss: 180.9623, MinusLogProbMetric: 180.9623, val_loss: 181.7988, val_MinusLogProbMetric: 181.7988

Epoch 74: val_loss did not improve from 181.33821
196/196 - 55s - loss: 180.9623 - MinusLogProbMetric: 180.9623 - val_loss: 181.7988 - val_MinusLogProbMetric: 181.7988 - lr: 0.0010 - 55s/epoch - 283ms/step
Epoch 75/1000
2023-10-01 10:02:57.150 
Epoch 75/1000 
	 loss: 181.0117, MinusLogProbMetric: 181.0117, val_loss: 181.4817, val_MinusLogProbMetric: 181.4817

Epoch 75: val_loss did not improve from 181.33821
196/196 - 55s - loss: 181.0117 - MinusLogProbMetric: 181.0117 - val_loss: 181.4817 - val_MinusLogProbMetric: 181.4817 - lr: 0.0010 - 55s/epoch - 279ms/step
Epoch 76/1000
2023-10-01 10:03:50.454 
Epoch 76/1000 
	 loss: 180.8433, MinusLogProbMetric: 180.8433, val_loss: 181.4969, val_MinusLogProbMetric: 181.4969

Epoch 76: val_loss did not improve from 181.33821
196/196 - 53s - loss: 180.8433 - MinusLogProbMetric: 180.8433 - val_loss: 181.4969 - val_MinusLogProbMetric: 181.4969 - lr: 0.0010 - 53s/epoch - 272ms/step
Epoch 77/1000
2023-10-01 10:04:44.295 
Epoch 77/1000 
	 loss: 180.7830, MinusLogProbMetric: 180.7830, val_loss: 182.7193, val_MinusLogProbMetric: 182.7193

Epoch 77: val_loss did not improve from 181.33821
196/196 - 54s - loss: 180.7830 - MinusLogProbMetric: 180.7830 - val_loss: 182.7193 - val_MinusLogProbMetric: 182.7193 - lr: 0.0010 - 54s/epoch - 275ms/step
Epoch 78/1000
2023-10-01 10:05:38.677 
Epoch 78/1000 
	 loss: 180.9805, MinusLogProbMetric: 180.9805, val_loss: 181.6583, val_MinusLogProbMetric: 181.6583

Epoch 78: val_loss did not improve from 181.33821
196/196 - 54s - loss: 180.9805 - MinusLogProbMetric: 180.9805 - val_loss: 181.6583 - val_MinusLogProbMetric: 181.6583 - lr: 0.0010 - 54s/epoch - 277ms/step
Epoch 79/1000
2023-10-01 10:06:33.783 
Epoch 79/1000 
	 loss: 180.6654, MinusLogProbMetric: 180.6654, val_loss: 182.6473, val_MinusLogProbMetric: 182.6473

Epoch 79: val_loss did not improve from 181.33821
196/196 - 55s - loss: 180.6654 - MinusLogProbMetric: 180.6654 - val_loss: 182.6473 - val_MinusLogProbMetric: 182.6473 - lr: 0.0010 - 55s/epoch - 281ms/step
Epoch 80/1000
2023-10-01 10:07:29.038 
Epoch 80/1000 
	 loss: 181.2170, MinusLogProbMetric: 181.2170, val_loss: 181.7992, val_MinusLogProbMetric: 181.7992

Epoch 80: val_loss did not improve from 181.33821
196/196 - 55s - loss: 181.2170 - MinusLogProbMetric: 181.2170 - val_loss: 181.7992 - val_MinusLogProbMetric: 181.7992 - lr: 0.0010 - 55s/epoch - 282ms/step
Epoch 81/1000
2023-10-01 10:08:24.399 
Epoch 81/1000 
	 loss: 180.8055, MinusLogProbMetric: 180.8055, val_loss: 181.2070, val_MinusLogProbMetric: 181.2070

Epoch 81: val_loss improved from 181.33821 to 181.20695, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 56s - loss: 180.8055 - MinusLogProbMetric: 180.8055 - val_loss: 181.2070 - val_MinusLogProbMetric: 181.2070 - lr: 0.0010 - 56s/epoch - 285ms/step
Epoch 82/1000
2023-10-01 10:09:18.674 
Epoch 82/1000 
	 loss: 181.1702, MinusLogProbMetric: 181.1702, val_loss: 181.6679, val_MinusLogProbMetric: 181.6679

Epoch 82: val_loss did not improve from 181.20695
196/196 - 54s - loss: 181.1702 - MinusLogProbMetric: 181.1702 - val_loss: 181.6679 - val_MinusLogProbMetric: 181.6679 - lr: 0.0010 - 54s/epoch - 275ms/step
Epoch 83/1000
2023-10-01 10:10:13.633 
Epoch 83/1000 
	 loss: 180.8064, MinusLogProbMetric: 180.8064, val_loss: 181.3731, val_MinusLogProbMetric: 181.3731

Epoch 83: val_loss did not improve from 181.20695
196/196 - 55s - loss: 180.8064 - MinusLogProbMetric: 180.8064 - val_loss: 181.3731 - val_MinusLogProbMetric: 181.3731 - lr: 0.0010 - 55s/epoch - 280ms/step
Epoch 84/1000
2023-10-01 10:11:08.062 
Epoch 84/1000 
	 loss: 180.6349, MinusLogProbMetric: 180.6349, val_loss: 181.2102, val_MinusLogProbMetric: 181.2102

Epoch 84: val_loss did not improve from 181.20695
196/196 - 54s - loss: 180.6349 - MinusLogProbMetric: 180.6349 - val_loss: 181.2102 - val_MinusLogProbMetric: 181.2102 - lr: 0.0010 - 54s/epoch - 277ms/step
Epoch 85/1000
2023-10-01 10:12:03.623 
Epoch 85/1000 
	 loss: 180.7106, MinusLogProbMetric: 180.7106, val_loss: 181.4510, val_MinusLogProbMetric: 181.4510

Epoch 85: val_loss did not improve from 181.20695
196/196 - 56s - loss: 180.7106 - MinusLogProbMetric: 180.7106 - val_loss: 181.4510 - val_MinusLogProbMetric: 181.4510 - lr: 0.0010 - 56s/epoch - 284ms/step
Epoch 86/1000
2023-10-01 10:12:59.560 
Epoch 86/1000 
	 loss: 180.6843, MinusLogProbMetric: 180.6843, val_loss: 181.7508, val_MinusLogProbMetric: 181.7508

Epoch 86: val_loss did not improve from 181.20695
196/196 - 56s - loss: 180.6843 - MinusLogProbMetric: 180.6843 - val_loss: 181.7508 - val_MinusLogProbMetric: 181.7508 - lr: 0.0010 - 56s/epoch - 285ms/step
Epoch 87/1000
2023-10-01 10:13:55.821 
Epoch 87/1000 
	 loss: 180.6048, MinusLogProbMetric: 180.6048, val_loss: 181.3370, val_MinusLogProbMetric: 181.3370

Epoch 87: val_loss did not improve from 181.20695
196/196 - 56s - loss: 180.6048 - MinusLogProbMetric: 180.6048 - val_loss: 181.3370 - val_MinusLogProbMetric: 181.3370 - lr: 0.0010 - 56s/epoch - 287ms/step
Epoch 88/1000
2023-10-01 10:14:50.584 
Epoch 88/1000 
	 loss: 180.6843, MinusLogProbMetric: 180.6843, val_loss: 181.4426, val_MinusLogProbMetric: 181.4426

Epoch 88: val_loss did not improve from 181.20695
196/196 - 55s - loss: 180.6843 - MinusLogProbMetric: 180.6843 - val_loss: 181.4426 - val_MinusLogProbMetric: 181.4426 - lr: 0.0010 - 55s/epoch - 279ms/step
Epoch 89/1000
2023-10-01 10:15:45.183 
Epoch 89/1000 
	 loss: 180.8323, MinusLogProbMetric: 180.8323, val_loss: 181.4995, val_MinusLogProbMetric: 181.4995

Epoch 89: val_loss did not improve from 181.20695
196/196 - 55s - loss: 180.8323 - MinusLogProbMetric: 180.8323 - val_loss: 181.4995 - val_MinusLogProbMetric: 181.4995 - lr: 0.0010 - 55s/epoch - 279ms/step
Epoch 90/1000
2023-10-01 10:16:38.954 
Epoch 90/1000 
	 loss: 180.5267, MinusLogProbMetric: 180.5267, val_loss: 181.2608, val_MinusLogProbMetric: 181.2608

Epoch 90: val_loss did not improve from 181.20695
196/196 - 54s - loss: 180.5267 - MinusLogProbMetric: 180.5267 - val_loss: 181.2608 - val_MinusLogProbMetric: 181.2608 - lr: 0.0010 - 54s/epoch - 275ms/step
Epoch 91/1000
2023-10-01 10:17:32.874 
Epoch 91/1000 
	 loss: 180.6533, MinusLogProbMetric: 180.6533, val_loss: 181.4062, val_MinusLogProbMetric: 181.4062

Epoch 91: val_loss did not improve from 181.20695
196/196 - 54s - loss: 180.6533 - MinusLogProbMetric: 180.6533 - val_loss: 181.4062 - val_MinusLogProbMetric: 181.4062 - lr: 0.0010 - 54s/epoch - 275ms/step
Epoch 92/1000
2023-10-01 10:18:27.710 
Epoch 92/1000 
	 loss: 180.7101, MinusLogProbMetric: 180.7101, val_loss: 181.7048, val_MinusLogProbMetric: 181.7048

Epoch 92: val_loss did not improve from 181.20695
196/196 - 55s - loss: 180.7101 - MinusLogProbMetric: 180.7101 - val_loss: 181.7048 - val_MinusLogProbMetric: 181.7048 - lr: 0.0010 - 55s/epoch - 280ms/step
Epoch 93/1000
2023-10-01 10:19:23.014 
Epoch 93/1000 
	 loss: 180.6159, MinusLogProbMetric: 180.6159, val_loss: 181.8521, val_MinusLogProbMetric: 181.8521

Epoch 93: val_loss did not improve from 181.20695
196/196 - 55s - loss: 180.6159 - MinusLogProbMetric: 180.6159 - val_loss: 181.8521 - val_MinusLogProbMetric: 181.8521 - lr: 0.0010 - 55s/epoch - 282ms/step
Epoch 94/1000
2023-10-01 10:20:23.113 
Epoch 94/1000 
	 loss: 180.5482, MinusLogProbMetric: 180.5482, val_loss: 181.6737, val_MinusLogProbMetric: 181.6737

Epoch 94: val_loss did not improve from 181.20695
196/196 - 60s - loss: 180.5482 - MinusLogProbMetric: 180.5482 - val_loss: 181.6737 - val_MinusLogProbMetric: 181.6737 - lr: 0.0010 - 60s/epoch - 307ms/step
Epoch 95/1000
2023-10-01 10:21:17.893 
Epoch 95/1000 
	 loss: 180.4963, MinusLogProbMetric: 180.4963, val_loss: 181.2852, val_MinusLogProbMetric: 181.2852

Epoch 95: val_loss did not improve from 181.20695
196/196 - 55s - loss: 180.4963 - MinusLogProbMetric: 180.4963 - val_loss: 181.2852 - val_MinusLogProbMetric: 181.2852 - lr: 0.0010 - 55s/epoch - 279ms/step
Epoch 96/1000
2023-10-01 10:22:16.245 
Epoch 96/1000 
	 loss: 180.5422, MinusLogProbMetric: 180.5422, val_loss: 181.6479, val_MinusLogProbMetric: 181.6479

Epoch 96: val_loss did not improve from 181.20695
196/196 - 58s - loss: 180.5422 - MinusLogProbMetric: 180.5422 - val_loss: 181.6479 - val_MinusLogProbMetric: 181.6479 - lr: 0.0010 - 58s/epoch - 298ms/step
Epoch 97/1000
2023-10-01 10:23:12.338 
Epoch 97/1000 
	 loss: 180.6283, MinusLogProbMetric: 180.6283, val_loss: 181.2170, val_MinusLogProbMetric: 181.2170

Epoch 97: val_loss did not improve from 181.20695
196/196 - 56s - loss: 180.6283 - MinusLogProbMetric: 180.6283 - val_loss: 181.2170 - val_MinusLogProbMetric: 181.2170 - lr: 0.0010 - 56s/epoch - 286ms/step
Epoch 98/1000
2023-10-01 10:24:08.222 
Epoch 98/1000 
	 loss: 180.4139, MinusLogProbMetric: 180.4139, val_loss: 181.1100, val_MinusLogProbMetric: 181.1100

Epoch 98: val_loss improved from 181.20695 to 181.11005, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 56s - loss: 180.4139 - MinusLogProbMetric: 180.4139 - val_loss: 181.1100 - val_MinusLogProbMetric: 181.1100 - lr: 0.0010 - 56s/epoch - 287ms/step
Epoch 99/1000
2023-10-01 10:25:04.857 
Epoch 99/1000 
	 loss: 180.4923, MinusLogProbMetric: 180.4923, val_loss: 181.1416, val_MinusLogProbMetric: 181.1416

Epoch 99: val_loss did not improve from 181.11005
196/196 - 56s - loss: 180.4923 - MinusLogProbMetric: 180.4923 - val_loss: 181.1416 - val_MinusLogProbMetric: 181.1416 - lr: 0.0010 - 56s/epoch - 286ms/step
Epoch 100/1000
2023-10-01 10:25:59.783 
Epoch 100/1000 
	 loss: 180.5064, MinusLogProbMetric: 180.5064, val_loss: 181.0679, val_MinusLogProbMetric: 181.0679

Epoch 100: val_loss improved from 181.11005 to 181.06793, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 55s - loss: 180.5064 - MinusLogProbMetric: 180.5064 - val_loss: 181.0679 - val_MinusLogProbMetric: 181.0679 - lr: 0.0010 - 55s/epoch - 283ms/step
Epoch 101/1000
2023-10-01 10:26:55.121 
Epoch 101/1000 
	 loss: 180.5176, MinusLogProbMetric: 180.5176, val_loss: 182.0451, val_MinusLogProbMetric: 182.0451

Epoch 101: val_loss did not improve from 181.06793
196/196 - 55s - loss: 180.5176 - MinusLogProbMetric: 180.5176 - val_loss: 182.0451 - val_MinusLogProbMetric: 182.0451 - lr: 0.0010 - 55s/epoch - 279ms/step
Epoch 102/1000
2023-10-01 10:27:49.450 
Epoch 102/1000 
	 loss: 180.5969, MinusLogProbMetric: 180.5969, val_loss: 181.0298, val_MinusLogProbMetric: 181.0298

Epoch 102: val_loss improved from 181.06793 to 181.02979, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 55s - loss: 180.5969 - MinusLogProbMetric: 180.5969 - val_loss: 181.0298 - val_MinusLogProbMetric: 181.0298 - lr: 0.0010 - 55s/epoch - 280ms/step
Epoch 103/1000
2023-10-01 10:28:44.090 
Epoch 103/1000 
	 loss: 180.3841, MinusLogProbMetric: 180.3841, val_loss: 181.6723, val_MinusLogProbMetric: 181.6723

Epoch 103: val_loss did not improve from 181.02979
196/196 - 54s - loss: 180.3841 - MinusLogProbMetric: 180.3841 - val_loss: 181.6723 - val_MinusLogProbMetric: 181.6723 - lr: 0.0010 - 54s/epoch - 275ms/step
Epoch 104/1000
2023-10-01 10:29:42.082 
Epoch 104/1000 
	 loss: 180.3686, MinusLogProbMetric: 180.3686, val_loss: 182.2735, val_MinusLogProbMetric: 182.2735

Epoch 104: val_loss did not improve from 181.02979
196/196 - 58s - loss: 180.3686 - MinusLogProbMetric: 180.3686 - val_loss: 182.2735 - val_MinusLogProbMetric: 182.2735 - lr: 0.0010 - 58s/epoch - 296ms/step
Epoch 105/1000
2023-10-01 10:30:36.185 
Epoch 105/1000 
	 loss: 180.4147, MinusLogProbMetric: 180.4147, val_loss: 181.8685, val_MinusLogProbMetric: 181.8685

Epoch 105: val_loss did not improve from 181.02979
196/196 - 54s - loss: 180.4147 - MinusLogProbMetric: 180.4147 - val_loss: 181.8685 - val_MinusLogProbMetric: 181.8685 - lr: 0.0010 - 54s/epoch - 276ms/step
Epoch 106/1000
2023-10-01 10:31:30.412 
Epoch 106/1000 
	 loss: 180.9183, MinusLogProbMetric: 180.9183, val_loss: 181.2265, val_MinusLogProbMetric: 181.2265

Epoch 106: val_loss did not improve from 181.02979
196/196 - 54s - loss: 180.9183 - MinusLogProbMetric: 180.9183 - val_loss: 181.2265 - val_MinusLogProbMetric: 181.2265 - lr: 0.0010 - 54s/epoch - 277ms/step
Epoch 107/1000
2023-10-01 10:32:24.619 
Epoch 107/1000 
	 loss: 180.2900, MinusLogProbMetric: 180.2900, val_loss: 181.1434, val_MinusLogProbMetric: 181.1434

Epoch 107: val_loss did not improve from 181.02979
196/196 - 54s - loss: 180.2900 - MinusLogProbMetric: 180.2900 - val_loss: 181.1434 - val_MinusLogProbMetric: 181.1434 - lr: 0.0010 - 54s/epoch - 276ms/step
Epoch 108/1000
2023-10-01 10:33:17.618 
Epoch 108/1000 
	 loss: 180.3051, MinusLogProbMetric: 180.3051, val_loss: 181.3396, val_MinusLogProbMetric: 181.3396

Epoch 108: val_loss did not improve from 181.02979
196/196 - 53s - loss: 180.3051 - MinusLogProbMetric: 180.3051 - val_loss: 181.3396 - val_MinusLogProbMetric: 181.3396 - lr: 0.0010 - 53s/epoch - 270ms/step
Epoch 109/1000
2023-10-01 10:34:11.850 
Epoch 109/1000 
	 loss: 180.5433, MinusLogProbMetric: 180.5433, val_loss: 181.3270, val_MinusLogProbMetric: 181.3270

Epoch 109: val_loss did not improve from 181.02979
196/196 - 54s - loss: 180.5433 - MinusLogProbMetric: 180.5433 - val_loss: 181.3270 - val_MinusLogProbMetric: 181.3270 - lr: 0.0010 - 54s/epoch - 277ms/step
Epoch 110/1000
2023-10-01 10:35:05.293 
Epoch 110/1000 
	 loss: 180.2300, MinusLogProbMetric: 180.2300, val_loss: 181.7552, val_MinusLogProbMetric: 181.7552

Epoch 110: val_loss did not improve from 181.02979
196/196 - 53s - loss: 180.2300 - MinusLogProbMetric: 180.2300 - val_loss: 181.7552 - val_MinusLogProbMetric: 181.7552 - lr: 0.0010 - 53s/epoch - 273ms/step
Epoch 111/1000
2023-10-01 10:35:59.201 
Epoch 111/1000 
	 loss: 180.3528, MinusLogProbMetric: 180.3528, val_loss: 182.0457, val_MinusLogProbMetric: 182.0457

Epoch 111: val_loss did not improve from 181.02979
196/196 - 54s - loss: 180.3528 - MinusLogProbMetric: 180.3528 - val_loss: 182.0457 - val_MinusLogProbMetric: 182.0457 - lr: 0.0010 - 54s/epoch - 275ms/step
Epoch 112/1000
2023-10-01 10:36:52.536 
Epoch 112/1000 
	 loss: 180.3869, MinusLogProbMetric: 180.3869, val_loss: 181.3998, val_MinusLogProbMetric: 181.3998

Epoch 112: val_loss did not improve from 181.02979
196/196 - 53s - loss: 180.3869 - MinusLogProbMetric: 180.3869 - val_loss: 181.3998 - val_MinusLogProbMetric: 181.3998 - lr: 0.0010 - 53s/epoch - 272ms/step
Epoch 113/1000
2023-10-01 10:37:46.944 
Epoch 113/1000 
	 loss: 180.3095, MinusLogProbMetric: 180.3095, val_loss: 181.4561, val_MinusLogProbMetric: 181.4561

Epoch 113: val_loss did not improve from 181.02979
196/196 - 54s - loss: 180.3095 - MinusLogProbMetric: 180.3095 - val_loss: 181.4561 - val_MinusLogProbMetric: 181.4561 - lr: 0.0010 - 54s/epoch - 277ms/step
Epoch 114/1000
2023-10-01 10:38:41.118 
Epoch 114/1000 
	 loss: 180.2540, MinusLogProbMetric: 180.2540, val_loss: 180.9006, val_MinusLogProbMetric: 180.9006

Epoch 114: val_loss improved from 181.02979 to 180.90059, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 55s - loss: 180.2540 - MinusLogProbMetric: 180.2540 - val_loss: 180.9006 - val_MinusLogProbMetric: 180.9006 - lr: 0.0010 - 55s/epoch - 280ms/step
Epoch 115/1000
2023-10-01 10:39:37.728 
Epoch 115/1000 
	 loss: 180.5612, MinusLogProbMetric: 180.5612, val_loss: 181.2760, val_MinusLogProbMetric: 181.2760

Epoch 115: val_loss did not improve from 180.90059
196/196 - 56s - loss: 180.5612 - MinusLogProbMetric: 180.5612 - val_loss: 181.2760 - val_MinusLogProbMetric: 181.2760 - lr: 0.0010 - 56s/epoch - 285ms/step
Epoch 116/1000
2023-10-01 10:40:31.933 
Epoch 116/1000 
	 loss: 180.1924, MinusLogProbMetric: 180.1924, val_loss: 181.0531, val_MinusLogProbMetric: 181.0531

Epoch 116: val_loss did not improve from 180.90059
196/196 - 54s - loss: 180.1924 - MinusLogProbMetric: 180.1924 - val_loss: 181.0531 - val_MinusLogProbMetric: 181.0531 - lr: 0.0010 - 54s/epoch - 276ms/step
Epoch 117/1000
2023-10-01 10:41:26.905 
Epoch 117/1000 
	 loss: 180.4159, MinusLogProbMetric: 180.4159, val_loss: 181.3639, val_MinusLogProbMetric: 181.3639

Epoch 117: val_loss did not improve from 180.90059
196/196 - 55s - loss: 180.4159 - MinusLogProbMetric: 180.4159 - val_loss: 181.3639 - val_MinusLogProbMetric: 181.3639 - lr: 0.0010 - 55s/epoch - 280ms/step
Epoch 118/1000
2023-10-01 10:42:21.272 
Epoch 118/1000 
	 loss: 180.2073, MinusLogProbMetric: 180.2073, val_loss: 185.2801, val_MinusLogProbMetric: 185.2801

Epoch 118: val_loss did not improve from 180.90059
196/196 - 54s - loss: 180.2073 - MinusLogProbMetric: 180.2073 - val_loss: 185.2801 - val_MinusLogProbMetric: 185.2801 - lr: 0.0010 - 54s/epoch - 277ms/step
Epoch 119/1000
2023-10-01 10:43:16.013 
Epoch 119/1000 
	 loss: 180.2568, MinusLogProbMetric: 180.2568, val_loss: 181.0316, val_MinusLogProbMetric: 181.0316

Epoch 119: val_loss did not improve from 180.90059
196/196 - 55s - loss: 180.2568 - MinusLogProbMetric: 180.2568 - val_loss: 181.0316 - val_MinusLogProbMetric: 181.0316 - lr: 0.0010 - 55s/epoch - 279ms/step
Epoch 120/1000
2023-10-01 10:44:09.091 
Epoch 120/1000 
	 loss: 180.2287, MinusLogProbMetric: 180.2287, val_loss: 181.5266, val_MinusLogProbMetric: 181.5266

Epoch 120: val_loss did not improve from 180.90059
196/196 - 53s - loss: 180.2287 - MinusLogProbMetric: 180.2287 - val_loss: 181.5266 - val_MinusLogProbMetric: 181.5266 - lr: 0.0010 - 53s/epoch - 271ms/step
Epoch 121/1000
2023-10-01 10:45:01.193 
Epoch 121/1000 
	 loss: 180.4040, MinusLogProbMetric: 180.4040, val_loss: 181.3793, val_MinusLogProbMetric: 181.3793

Epoch 121: val_loss did not improve from 180.90059
196/196 - 52s - loss: 180.4040 - MinusLogProbMetric: 180.4040 - val_loss: 181.3793 - val_MinusLogProbMetric: 181.3793 - lr: 0.0010 - 52s/epoch - 266ms/step
Epoch 122/1000
2023-10-01 10:45:54.789 
Epoch 122/1000 
	 loss: 180.2099, MinusLogProbMetric: 180.2099, val_loss: 180.9535, val_MinusLogProbMetric: 180.9535

Epoch 122: val_loss did not improve from 180.90059
196/196 - 54s - loss: 180.2099 - MinusLogProbMetric: 180.2099 - val_loss: 180.9535 - val_MinusLogProbMetric: 180.9535 - lr: 0.0010 - 54s/epoch - 273ms/step
Epoch 123/1000
2023-10-01 10:46:45.945 
Epoch 123/1000 
	 loss: 180.6007, MinusLogProbMetric: 180.6007, val_loss: 181.0866, val_MinusLogProbMetric: 181.0866

Epoch 123: val_loss did not improve from 180.90059
196/196 - 51s - loss: 180.6007 - MinusLogProbMetric: 180.6007 - val_loss: 181.0866 - val_MinusLogProbMetric: 181.0866 - lr: 0.0010 - 51s/epoch - 261ms/step
Epoch 124/1000
2023-10-01 10:47:44.129 
Epoch 124/1000 
	 loss: 180.0760, MinusLogProbMetric: 180.0760, val_loss: 180.9045, val_MinusLogProbMetric: 180.9045

Epoch 124: val_loss did not improve from 180.90059
196/196 - 58s - loss: 180.0760 - MinusLogProbMetric: 180.0760 - val_loss: 180.9045 - val_MinusLogProbMetric: 180.9045 - lr: 0.0010 - 58s/epoch - 297ms/step
Epoch 125/1000
2023-10-01 10:48:32.298 
Epoch 125/1000 
	 loss: 180.1636, MinusLogProbMetric: 180.1636, val_loss: 181.1567, val_MinusLogProbMetric: 181.1567

Epoch 125: val_loss did not improve from 180.90059
196/196 - 48s - loss: 180.1636 - MinusLogProbMetric: 180.1636 - val_loss: 181.1567 - val_MinusLogProbMetric: 181.1567 - lr: 0.0010 - 48s/epoch - 246ms/step
Epoch 126/1000
2023-10-01 10:49:30.744 
Epoch 126/1000 
	 loss: 181.0989, MinusLogProbMetric: 181.0989, val_loss: 181.5293, val_MinusLogProbMetric: 181.5293

Epoch 126: val_loss did not improve from 180.90059
196/196 - 58s - loss: 181.0989 - MinusLogProbMetric: 181.0989 - val_loss: 181.5293 - val_MinusLogProbMetric: 181.5293 - lr: 0.0010 - 58s/epoch - 298ms/step
Epoch 127/1000
2023-10-01 10:50:21.513 
Epoch 127/1000 
	 loss: 180.1711, MinusLogProbMetric: 180.1711, val_loss: 181.1145, val_MinusLogProbMetric: 181.1145

Epoch 127: val_loss did not improve from 180.90059
196/196 - 51s - loss: 180.1711 - MinusLogProbMetric: 180.1711 - val_loss: 181.1145 - val_MinusLogProbMetric: 181.1145 - lr: 0.0010 - 51s/epoch - 259ms/step
Epoch 128/1000
2023-10-01 10:51:16.574 
Epoch 128/1000 
	 loss: 180.0216, MinusLogProbMetric: 180.0216, val_loss: 181.2027, val_MinusLogProbMetric: 181.2027

Epoch 128: val_loss did not improve from 180.90059
196/196 - 55s - loss: 180.0216 - MinusLogProbMetric: 180.0216 - val_loss: 181.2027 - val_MinusLogProbMetric: 181.2027 - lr: 0.0010 - 55s/epoch - 281ms/step
Epoch 129/1000
2023-10-01 10:52:12.905 
Epoch 129/1000 
	 loss: 180.1777, MinusLogProbMetric: 180.1777, val_loss: 181.4089, val_MinusLogProbMetric: 181.4089

Epoch 129: val_loss did not improve from 180.90059
196/196 - 56s - loss: 180.1777 - MinusLogProbMetric: 180.1777 - val_loss: 181.4089 - val_MinusLogProbMetric: 181.4089 - lr: 0.0010 - 56s/epoch - 287ms/step
Epoch 130/1000
2023-10-01 10:53:03.970 
Epoch 130/1000 
	 loss: 180.4242, MinusLogProbMetric: 180.4242, val_loss: 182.0468, val_MinusLogProbMetric: 182.0468

Epoch 130: val_loss did not improve from 180.90059
196/196 - 51s - loss: 180.4242 - MinusLogProbMetric: 180.4242 - val_loss: 182.0468 - val_MinusLogProbMetric: 182.0468 - lr: 0.0010 - 51s/epoch - 261ms/step
Epoch 131/1000
2023-10-01 10:54:01.233 
Epoch 131/1000 
	 loss: 180.1452, MinusLogProbMetric: 180.1452, val_loss: 181.2279, val_MinusLogProbMetric: 181.2279

Epoch 131: val_loss did not improve from 180.90059
196/196 - 57s - loss: 180.1452 - MinusLogProbMetric: 180.1452 - val_loss: 181.2279 - val_MinusLogProbMetric: 181.2279 - lr: 0.0010 - 57s/epoch - 292ms/step
Epoch 132/1000
2023-10-01 10:54:54.973 
Epoch 132/1000 
	 loss: 180.0379, MinusLogProbMetric: 180.0379, val_loss: 181.5856, val_MinusLogProbMetric: 181.5856

Epoch 132: val_loss did not improve from 180.90059
196/196 - 54s - loss: 180.0379 - MinusLogProbMetric: 180.0379 - val_loss: 181.5856 - val_MinusLogProbMetric: 181.5856 - lr: 0.0010 - 54s/epoch - 274ms/step
Epoch 133/1000
2023-10-01 10:55:48.508 
Epoch 133/1000 
	 loss: 180.2459, MinusLogProbMetric: 180.2459, val_loss: 181.3622, val_MinusLogProbMetric: 181.3622

Epoch 133: val_loss did not improve from 180.90059
196/196 - 54s - loss: 180.2459 - MinusLogProbMetric: 180.2459 - val_loss: 181.3622 - val_MinusLogProbMetric: 181.3622 - lr: 0.0010 - 54s/epoch - 273ms/step
Epoch 134/1000
2023-10-01 10:56:41.772 
Epoch 134/1000 
	 loss: 180.0956, MinusLogProbMetric: 180.0956, val_loss: 180.9225, val_MinusLogProbMetric: 180.9225

Epoch 134: val_loss did not improve from 180.90059
196/196 - 53s - loss: 180.0956 - MinusLogProbMetric: 180.0956 - val_loss: 180.9225 - val_MinusLogProbMetric: 180.9225 - lr: 0.0010 - 53s/epoch - 272ms/step
Epoch 135/1000
2023-10-01 10:57:36.093 
Epoch 135/1000 
	 loss: 180.3947, MinusLogProbMetric: 180.3947, val_loss: 180.9856, val_MinusLogProbMetric: 180.9856

Epoch 135: val_loss did not improve from 180.90059
196/196 - 54s - loss: 180.3947 - MinusLogProbMetric: 180.3947 - val_loss: 180.9856 - val_MinusLogProbMetric: 180.9856 - lr: 0.0010 - 54s/epoch - 277ms/step
Epoch 136/1000
2023-10-01 10:58:29.981 
Epoch 136/1000 
	 loss: 180.0238, MinusLogProbMetric: 180.0238, val_loss: 181.1154, val_MinusLogProbMetric: 181.1154

Epoch 136: val_loss did not improve from 180.90059
196/196 - 54s - loss: 180.0238 - MinusLogProbMetric: 180.0238 - val_loss: 181.1154 - val_MinusLogProbMetric: 181.1154 - lr: 0.0010 - 54s/epoch - 275ms/step
Epoch 137/1000
2023-10-01 10:59:21.976 
Epoch 137/1000 
	 loss: 180.0508, MinusLogProbMetric: 180.0508, val_loss: 181.0635, val_MinusLogProbMetric: 181.0635

Epoch 137: val_loss did not improve from 180.90059
196/196 - 52s - loss: 180.0508 - MinusLogProbMetric: 180.0508 - val_loss: 181.0635 - val_MinusLogProbMetric: 181.0635 - lr: 0.0010 - 52s/epoch - 265ms/step
Epoch 138/1000
2023-10-01 11:00:15.467 
Epoch 138/1000 
	 loss: 180.5594, MinusLogProbMetric: 180.5594, val_loss: 181.4842, val_MinusLogProbMetric: 181.4842

Epoch 138: val_loss did not improve from 180.90059
196/196 - 53s - loss: 180.5594 - MinusLogProbMetric: 180.5594 - val_loss: 181.4842 - val_MinusLogProbMetric: 181.4842 - lr: 0.0010 - 53s/epoch - 273ms/step
Epoch 139/1000
2023-10-01 11:01:13.839 
Epoch 139/1000 
	 loss: 180.1129, MinusLogProbMetric: 180.1129, val_loss: 181.0823, val_MinusLogProbMetric: 181.0823

Epoch 139: val_loss did not improve from 180.90059
196/196 - 58s - loss: 180.1129 - MinusLogProbMetric: 180.1129 - val_loss: 181.0823 - val_MinusLogProbMetric: 181.0823 - lr: 0.0010 - 58s/epoch - 298ms/step
Epoch 140/1000
2023-10-01 11:02:06.789 
Epoch 140/1000 
	 loss: 179.9137, MinusLogProbMetric: 179.9137, val_loss: 180.9760, val_MinusLogProbMetric: 180.9760

Epoch 140: val_loss did not improve from 180.90059
196/196 - 53s - loss: 179.9137 - MinusLogProbMetric: 179.9137 - val_loss: 180.9760 - val_MinusLogProbMetric: 180.9760 - lr: 0.0010 - 53s/epoch - 270ms/step
Epoch 141/1000
2023-10-01 11:03:00.833 
Epoch 141/1000 
	 loss: 179.9549, MinusLogProbMetric: 179.9549, val_loss: 182.9437, val_MinusLogProbMetric: 182.9437

Epoch 141: val_loss did not improve from 180.90059
196/196 - 54s - loss: 179.9549 - MinusLogProbMetric: 179.9549 - val_loss: 182.9437 - val_MinusLogProbMetric: 182.9437 - lr: 0.0010 - 54s/epoch - 276ms/step
Epoch 142/1000
2023-10-01 11:03:54.262 
Epoch 142/1000 
	 loss: 180.0993, MinusLogProbMetric: 180.0993, val_loss: 181.0062, val_MinusLogProbMetric: 181.0062

Epoch 142: val_loss did not improve from 180.90059
196/196 - 53s - loss: 180.0993 - MinusLogProbMetric: 180.0993 - val_loss: 181.0062 - val_MinusLogProbMetric: 181.0062 - lr: 0.0010 - 53s/epoch - 272ms/step
Epoch 143/1000
2023-10-01 11:04:48.467 
Epoch 143/1000 
	 loss: 179.9828, MinusLogProbMetric: 179.9828, val_loss: 181.0736, val_MinusLogProbMetric: 181.0736

Epoch 143: val_loss did not improve from 180.90059
196/196 - 54s - loss: 179.9828 - MinusLogProbMetric: 179.9828 - val_loss: 181.0736 - val_MinusLogProbMetric: 181.0736 - lr: 0.0010 - 54s/epoch - 276ms/step
Epoch 144/1000
2023-10-01 11:05:41.941 
Epoch 144/1000 
	 loss: 180.0681, MinusLogProbMetric: 180.0681, val_loss: 181.5340, val_MinusLogProbMetric: 181.5340

Epoch 144: val_loss did not improve from 180.90059
196/196 - 53s - loss: 180.0681 - MinusLogProbMetric: 180.0681 - val_loss: 181.5340 - val_MinusLogProbMetric: 181.5340 - lr: 0.0010 - 53s/epoch - 273ms/step
Epoch 145/1000
2023-10-01 11:06:35.756 
Epoch 145/1000 
	 loss: 180.0061, MinusLogProbMetric: 180.0061, val_loss: 181.4384, val_MinusLogProbMetric: 181.4384

Epoch 145: val_loss did not improve from 180.90059
196/196 - 54s - loss: 180.0061 - MinusLogProbMetric: 180.0061 - val_loss: 181.4384 - val_MinusLogProbMetric: 181.4384 - lr: 0.0010 - 54s/epoch - 274ms/step
Epoch 146/1000
2023-10-01 11:07:28.446 
Epoch 146/1000 
	 loss: 179.9885, MinusLogProbMetric: 179.9885, val_loss: 181.1174, val_MinusLogProbMetric: 181.1174

Epoch 146: val_loss did not improve from 180.90059
196/196 - 53s - loss: 179.9885 - MinusLogProbMetric: 179.9885 - val_loss: 181.1174 - val_MinusLogProbMetric: 181.1174 - lr: 0.0010 - 53s/epoch - 269ms/step
Epoch 147/1000
2023-10-01 11:08:22.249 
Epoch 147/1000 
	 loss: 179.9988, MinusLogProbMetric: 179.9988, val_loss: 180.8595, val_MinusLogProbMetric: 180.8595

Epoch 147: val_loss improved from 180.90059 to 180.85948, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 55s - loss: 179.9988 - MinusLogProbMetric: 179.9988 - val_loss: 180.8595 - val_MinusLogProbMetric: 180.8595 - lr: 0.0010 - 55s/epoch - 279ms/step
Epoch 148/1000
2023-10-01 11:09:16.092 
Epoch 148/1000 
	 loss: 179.9397, MinusLogProbMetric: 179.9397, val_loss: 180.9226, val_MinusLogProbMetric: 180.9226

Epoch 148: val_loss did not improve from 180.85948
196/196 - 53s - loss: 179.9397 - MinusLogProbMetric: 179.9397 - val_loss: 180.9226 - val_MinusLogProbMetric: 180.9226 - lr: 0.0010 - 53s/epoch - 270ms/step
Epoch 149/1000
2023-10-01 11:10:09.932 
Epoch 149/1000 
	 loss: 179.9530, MinusLogProbMetric: 179.9530, val_loss: 180.9982, val_MinusLogProbMetric: 180.9982

Epoch 149: val_loss did not improve from 180.85948
196/196 - 54s - loss: 179.9530 - MinusLogProbMetric: 179.9530 - val_loss: 180.9982 - val_MinusLogProbMetric: 180.9982 - lr: 0.0010 - 54s/epoch - 275ms/step
Epoch 150/1000
2023-10-01 11:11:04.185 
Epoch 150/1000 
	 loss: 179.9357, MinusLogProbMetric: 179.9357, val_loss: 181.0060, val_MinusLogProbMetric: 181.0060

Epoch 150: val_loss did not improve from 180.85948
196/196 - 54s - loss: 179.9357 - MinusLogProbMetric: 179.9357 - val_loss: 181.0060 - val_MinusLogProbMetric: 181.0060 - lr: 0.0010 - 54s/epoch - 277ms/step
Epoch 151/1000
2023-10-01 11:11:58.633 
Epoch 151/1000 
	 loss: 180.2576, MinusLogProbMetric: 180.2576, val_loss: 181.3746, val_MinusLogProbMetric: 181.3746

Epoch 151: val_loss did not improve from 180.85948
196/196 - 54s - loss: 180.2576 - MinusLogProbMetric: 180.2576 - val_loss: 181.3746 - val_MinusLogProbMetric: 181.3746 - lr: 0.0010 - 54s/epoch - 278ms/step
Epoch 152/1000
2023-10-01 11:12:53.510 
Epoch 152/1000 
	 loss: 179.8978, MinusLogProbMetric: 179.8978, val_loss: 181.7141, val_MinusLogProbMetric: 181.7141

Epoch 152: val_loss did not improve from 180.85948
196/196 - 55s - loss: 179.8978 - MinusLogProbMetric: 179.8978 - val_loss: 181.7141 - val_MinusLogProbMetric: 181.7141 - lr: 0.0010 - 55s/epoch - 280ms/step
Epoch 153/1000
2023-10-01 11:13:47.339 
Epoch 153/1000 
	 loss: 180.1983, MinusLogProbMetric: 180.1983, val_loss: 181.3744, val_MinusLogProbMetric: 181.3744

Epoch 153: val_loss did not improve from 180.85948
196/196 - 54s - loss: 180.1983 - MinusLogProbMetric: 180.1983 - val_loss: 181.3744 - val_MinusLogProbMetric: 181.3744 - lr: 0.0010 - 54s/epoch - 275ms/step
Epoch 154/1000
2023-10-01 11:14:40.150 
Epoch 154/1000 
	 loss: 179.9268, MinusLogProbMetric: 179.9268, val_loss: 180.9075, val_MinusLogProbMetric: 180.9075

Epoch 154: val_loss did not improve from 180.85948
196/196 - 53s - loss: 179.9268 - MinusLogProbMetric: 179.9268 - val_loss: 180.9075 - val_MinusLogProbMetric: 180.9075 - lr: 0.0010 - 53s/epoch - 270ms/step
Epoch 155/1000
2023-10-01 11:15:39.081 
Epoch 155/1000 
	 loss: 179.8652, MinusLogProbMetric: 179.8652, val_loss: 180.8554, val_MinusLogProbMetric: 180.8554

Epoch 155: val_loss improved from 180.85948 to 180.85542, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 60s - loss: 179.8652 - MinusLogProbMetric: 179.8652 - val_loss: 180.8554 - val_MinusLogProbMetric: 180.8554 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 156/1000
2023-10-01 11:16:33.319 
Epoch 156/1000 
	 loss: 179.8991, MinusLogProbMetric: 179.8991, val_loss: 182.2592, val_MinusLogProbMetric: 182.2592

Epoch 156: val_loss did not improve from 180.85542
196/196 - 53s - loss: 179.8991 - MinusLogProbMetric: 179.8991 - val_loss: 182.2592 - val_MinusLogProbMetric: 182.2592 - lr: 0.0010 - 53s/epoch - 272ms/step
Epoch 157/1000
2023-10-01 11:17:27.213 
Epoch 157/1000 
	 loss: 179.9800, MinusLogProbMetric: 179.9800, val_loss: 181.2468, val_MinusLogProbMetric: 181.2468

Epoch 157: val_loss did not improve from 180.85542
196/196 - 54s - loss: 179.9800 - MinusLogProbMetric: 179.9800 - val_loss: 181.2468 - val_MinusLogProbMetric: 181.2468 - lr: 0.0010 - 54s/epoch - 275ms/step
Epoch 158/1000
2023-10-01 11:18:21.688 
Epoch 158/1000 
	 loss: 179.8847, MinusLogProbMetric: 179.8847, val_loss: 180.8500, val_MinusLogProbMetric: 180.8500

Epoch 158: val_loss improved from 180.85542 to 180.84996, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 55s - loss: 179.8847 - MinusLogProbMetric: 179.8847 - val_loss: 180.8500 - val_MinusLogProbMetric: 180.8500 - lr: 0.0010 - 55s/epoch - 282ms/step
Epoch 159/1000
2023-10-01 11:19:16.589 
Epoch 159/1000 
	 loss: 180.1227, MinusLogProbMetric: 180.1227, val_loss: 182.3161, val_MinusLogProbMetric: 182.3161

Epoch 159: val_loss did not improve from 180.84996
196/196 - 54s - loss: 180.1227 - MinusLogProbMetric: 180.1227 - val_loss: 182.3161 - val_MinusLogProbMetric: 182.3161 - lr: 0.0010 - 54s/epoch - 276ms/step
Epoch 160/1000
2023-10-01 11:20:09.292 
Epoch 160/1000 
	 loss: 179.8112, MinusLogProbMetric: 179.8112, val_loss: 181.4670, val_MinusLogProbMetric: 181.4670

Epoch 160: val_loss did not improve from 180.84996
196/196 - 53s - loss: 179.8112 - MinusLogProbMetric: 179.8112 - val_loss: 181.4670 - val_MinusLogProbMetric: 181.4670 - lr: 0.0010 - 53s/epoch - 269ms/step
Epoch 161/1000
2023-10-01 11:21:02.793 
Epoch 161/1000 
	 loss: 179.8509, MinusLogProbMetric: 179.8509, val_loss: 180.9734, val_MinusLogProbMetric: 180.9734

Epoch 161: val_loss did not improve from 180.84996
196/196 - 53s - loss: 179.8509 - MinusLogProbMetric: 179.8509 - val_loss: 180.9734 - val_MinusLogProbMetric: 180.9734 - lr: 0.0010 - 53s/epoch - 273ms/step
Epoch 162/1000
2023-10-01 11:21:55.699 
Epoch 162/1000 
	 loss: 179.8705, MinusLogProbMetric: 179.8705, val_loss: 181.0943, val_MinusLogProbMetric: 181.0943

Epoch 162: val_loss did not improve from 180.84996
196/196 - 53s - loss: 179.8705 - MinusLogProbMetric: 179.8705 - val_loss: 181.0943 - val_MinusLogProbMetric: 181.0943 - lr: 0.0010 - 53s/epoch - 270ms/step
Epoch 163/1000
2023-10-01 11:22:50.208 
Epoch 163/1000 
	 loss: 179.8627, MinusLogProbMetric: 179.8627, val_loss: 181.2092, val_MinusLogProbMetric: 181.2092

Epoch 163: val_loss did not improve from 180.84996
196/196 - 54s - loss: 179.8627 - MinusLogProbMetric: 179.8627 - val_loss: 181.2092 - val_MinusLogProbMetric: 181.2092 - lr: 0.0010 - 54s/epoch - 278ms/step
Epoch 164/1000
2023-10-01 11:23:44.159 
Epoch 164/1000 
	 loss: 179.8695, MinusLogProbMetric: 179.8695, val_loss: 181.2707, val_MinusLogProbMetric: 181.2707

Epoch 164: val_loss did not improve from 180.84996
196/196 - 54s - loss: 179.8695 - MinusLogProbMetric: 179.8695 - val_loss: 181.2707 - val_MinusLogProbMetric: 181.2707 - lr: 0.0010 - 54s/epoch - 275ms/step
Epoch 165/1000
2023-10-01 11:24:37.703 
Epoch 165/1000 
	 loss: 179.7902, MinusLogProbMetric: 179.7902, val_loss: 181.2198, val_MinusLogProbMetric: 181.2198

Epoch 165: val_loss did not improve from 180.84996
196/196 - 54s - loss: 179.7902 - MinusLogProbMetric: 179.7902 - val_loss: 181.2198 - val_MinusLogProbMetric: 181.2198 - lr: 0.0010 - 54s/epoch - 273ms/step
Epoch 166/1000
2023-10-01 11:25:37.424 
Epoch 166/1000 
	 loss: 180.0257, MinusLogProbMetric: 180.0257, val_loss: 181.3016, val_MinusLogProbMetric: 181.3016

Epoch 166: val_loss did not improve from 180.84996
196/196 - 60s - loss: 180.0257 - MinusLogProbMetric: 180.0257 - val_loss: 181.3016 - val_MinusLogProbMetric: 181.3016 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 167/1000
2023-10-01 11:26:32.532 
Epoch 167/1000 
	 loss: 179.9414, MinusLogProbMetric: 179.9414, val_loss: 181.4236, val_MinusLogProbMetric: 181.4236

Epoch 167: val_loss did not improve from 180.84996
196/196 - 55s - loss: 179.9414 - MinusLogProbMetric: 179.9414 - val_loss: 181.4236 - val_MinusLogProbMetric: 181.4236 - lr: 0.0010 - 55s/epoch - 281ms/step
Epoch 168/1000
2023-10-01 11:27:25.983 
Epoch 168/1000 
	 loss: 179.7392, MinusLogProbMetric: 179.7392, val_loss: 180.9665, val_MinusLogProbMetric: 180.9665

Epoch 168: val_loss did not improve from 180.84996
196/196 - 53s - loss: 179.7392 - MinusLogProbMetric: 179.7392 - val_loss: 180.9665 - val_MinusLogProbMetric: 180.9665 - lr: 0.0010 - 53s/epoch - 273ms/step
Epoch 169/1000
2023-10-01 11:28:19.152 
Epoch 169/1000 
	 loss: 179.7807, MinusLogProbMetric: 179.7807, val_loss: 181.4842, val_MinusLogProbMetric: 181.4842

Epoch 169: val_loss did not improve from 180.84996
196/196 - 53s - loss: 179.7807 - MinusLogProbMetric: 179.7807 - val_loss: 181.4842 - val_MinusLogProbMetric: 181.4842 - lr: 0.0010 - 53s/epoch - 271ms/step
Epoch 170/1000
2023-10-01 11:29:19.050 
Epoch 170/1000 
	 loss: 179.8228, MinusLogProbMetric: 179.8228, val_loss: 181.0887, val_MinusLogProbMetric: 181.0887

Epoch 170: val_loss did not improve from 180.84996
196/196 - 60s - loss: 179.8228 - MinusLogProbMetric: 179.8228 - val_loss: 181.0887 - val_MinusLogProbMetric: 181.0887 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 171/1000
2023-10-01 11:30:14.359 
Epoch 171/1000 
	 loss: 179.7777, MinusLogProbMetric: 179.7777, val_loss: 181.0701, val_MinusLogProbMetric: 181.0701

Epoch 171: val_loss did not improve from 180.84996
196/196 - 55s - loss: 179.7777 - MinusLogProbMetric: 179.7777 - val_loss: 181.0701 - val_MinusLogProbMetric: 181.0701 - lr: 0.0010 - 55s/epoch - 282ms/step
Epoch 172/1000
2023-10-01 11:31:08.510 
Epoch 172/1000 
	 loss: 179.7767, MinusLogProbMetric: 179.7767, val_loss: 181.2708, val_MinusLogProbMetric: 181.2708

Epoch 172: val_loss did not improve from 180.84996
196/196 - 54s - loss: 179.7767 - MinusLogProbMetric: 179.7767 - val_loss: 181.2708 - val_MinusLogProbMetric: 181.2708 - lr: 0.0010 - 54s/epoch - 276ms/step
Epoch 173/1000
2023-10-01 11:32:01.681 
Epoch 173/1000 
	 loss: 179.7500, MinusLogProbMetric: 179.7500, val_loss: 181.0036, val_MinusLogProbMetric: 181.0036

Epoch 173: val_loss did not improve from 180.84996
196/196 - 53s - loss: 179.7500 - MinusLogProbMetric: 179.7500 - val_loss: 181.0036 - val_MinusLogProbMetric: 181.0036 - lr: 0.0010 - 53s/epoch - 271ms/step
Epoch 174/1000
2023-10-01 11:32:55.452 
Epoch 174/1000 
	 loss: 180.1110, MinusLogProbMetric: 180.1110, val_loss: 181.1538, val_MinusLogProbMetric: 181.1538

Epoch 174: val_loss did not improve from 180.84996
196/196 - 54s - loss: 180.1110 - MinusLogProbMetric: 180.1110 - val_loss: 181.1538 - val_MinusLogProbMetric: 181.1538 - lr: 0.0010 - 54s/epoch - 274ms/step
Epoch 175/1000
2023-10-01 11:33:55.266 
Epoch 175/1000 
	 loss: 179.6994, MinusLogProbMetric: 179.6994, val_loss: 181.3553, val_MinusLogProbMetric: 181.3553

Epoch 175: val_loss did not improve from 180.84996
196/196 - 60s - loss: 179.6994 - MinusLogProbMetric: 179.6994 - val_loss: 181.3553 - val_MinusLogProbMetric: 181.3553 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 176/1000
2023-10-01 11:34:55.229 
Epoch 176/1000 
	 loss: 179.6651, MinusLogProbMetric: 179.6651, val_loss: 181.0558, val_MinusLogProbMetric: 181.0558

Epoch 176: val_loss did not improve from 180.84996
196/196 - 60s - loss: 179.6651 - MinusLogProbMetric: 179.6651 - val_loss: 181.0558 - val_MinusLogProbMetric: 181.0558 - lr: 0.0010 - 60s/epoch - 306ms/step
Epoch 177/1000
2023-10-01 11:35:49.534 
Epoch 177/1000 
	 loss: 179.7484, MinusLogProbMetric: 179.7484, val_loss: 181.1131, val_MinusLogProbMetric: 181.1131

Epoch 177: val_loss did not improve from 180.84996
196/196 - 54s - loss: 179.7484 - MinusLogProbMetric: 179.7484 - val_loss: 181.1131 - val_MinusLogProbMetric: 181.1131 - lr: 0.0010 - 54s/epoch - 277ms/step
Epoch 178/1000
2023-10-01 11:36:43.107 
Epoch 178/1000 
	 loss: 179.7625, MinusLogProbMetric: 179.7625, val_loss: 182.0059, val_MinusLogProbMetric: 182.0059

Epoch 178: val_loss did not improve from 180.84996
196/196 - 54s - loss: 179.7625 - MinusLogProbMetric: 179.7625 - val_loss: 182.0059 - val_MinusLogProbMetric: 182.0059 - lr: 0.0010 - 54s/epoch - 273ms/step
Epoch 179/1000
2023-10-01 11:37:37.852 
Epoch 179/1000 
	 loss: 180.0856, MinusLogProbMetric: 180.0856, val_loss: 185.9386, val_MinusLogProbMetric: 185.9386

Epoch 179: val_loss did not improve from 180.84996
196/196 - 55s - loss: 180.0856 - MinusLogProbMetric: 180.0856 - val_loss: 185.9386 - val_MinusLogProbMetric: 185.9386 - lr: 0.0010 - 55s/epoch - 279ms/step
Epoch 180/1000
2023-10-01 11:38:08.240 
Epoch 180/1000 
	 loss: 179.9972, MinusLogProbMetric: 179.9972, val_loss: 181.0230, val_MinusLogProbMetric: 181.0230

Epoch 180: val_loss did not improve from 180.84996
196/196 - 30s - loss: 179.9972 - MinusLogProbMetric: 179.9972 - val_loss: 181.0230 - val_MinusLogProbMetric: 181.0230 - lr: 0.0010 - 30s/epoch - 155ms/step
Epoch 181/1000
2023-10-01 11:39:03.261 
Epoch 181/1000 
	 loss: 179.6202, MinusLogProbMetric: 179.6202, val_loss: 180.9274, val_MinusLogProbMetric: 180.9274

Epoch 181: val_loss did not improve from 180.84996
196/196 - 55s - loss: 179.6202 - MinusLogProbMetric: 179.6202 - val_loss: 180.9274 - val_MinusLogProbMetric: 180.9274 - lr: 0.0010 - 55s/epoch - 281ms/step
Epoch 182/1000
2023-10-01 11:39:54.130 
Epoch 182/1000 
	 loss: 179.6686, MinusLogProbMetric: 179.6686, val_loss: 181.5395, val_MinusLogProbMetric: 181.5395

Epoch 182: val_loss did not improve from 180.84996
196/196 - 51s - loss: 179.6686 - MinusLogProbMetric: 179.6686 - val_loss: 181.5395 - val_MinusLogProbMetric: 181.5395 - lr: 0.0010 - 51s/epoch - 259ms/step
Epoch 183/1000
2023-10-01 11:40:51.139 
Epoch 183/1000 
	 loss: 179.9680, MinusLogProbMetric: 179.9680, val_loss: 181.3107, val_MinusLogProbMetric: 181.3107

Epoch 183: val_loss did not improve from 180.84996
196/196 - 57s - loss: 179.9680 - MinusLogProbMetric: 179.9680 - val_loss: 181.3107 - val_MinusLogProbMetric: 181.3107 - lr: 0.0010 - 57s/epoch - 291ms/step
Epoch 184/1000
2023-10-01 11:41:42.023 
Epoch 184/1000 
	 loss: 179.6086, MinusLogProbMetric: 179.6086, val_loss: 181.0532, val_MinusLogProbMetric: 181.0532

Epoch 184: val_loss did not improve from 180.84996
196/196 - 51s - loss: 179.6086 - MinusLogProbMetric: 179.6086 - val_loss: 181.0532 - val_MinusLogProbMetric: 181.0532 - lr: 0.0010 - 51s/epoch - 259ms/step
Epoch 185/1000
2023-10-01 11:42:42.456 
Epoch 185/1000 
	 loss: 179.7292, MinusLogProbMetric: 179.7292, val_loss: 181.1008, val_MinusLogProbMetric: 181.1008

Epoch 185: val_loss did not improve from 180.84996
196/196 - 60s - loss: 179.7292 - MinusLogProbMetric: 179.7292 - val_loss: 181.1008 - val_MinusLogProbMetric: 181.1008 - lr: 0.0010 - 60s/epoch - 308ms/step
Epoch 186/1000
2023-10-01 11:43:35.965 
Epoch 186/1000 
	 loss: 179.6604, MinusLogProbMetric: 179.6604, val_loss: 181.7351, val_MinusLogProbMetric: 181.7351

Epoch 186: val_loss did not improve from 180.84996
196/196 - 53s - loss: 179.6604 - MinusLogProbMetric: 179.6604 - val_loss: 181.7351 - val_MinusLogProbMetric: 181.7351 - lr: 0.0010 - 53s/epoch - 273ms/step
Epoch 187/1000
2023-10-01 11:44:29.413 
Epoch 187/1000 
	 loss: 179.7518, MinusLogProbMetric: 179.7518, val_loss: 181.0693, val_MinusLogProbMetric: 181.0693

Epoch 187: val_loss did not improve from 180.84996
196/196 - 53s - loss: 179.7518 - MinusLogProbMetric: 179.7518 - val_loss: 181.0693 - val_MinusLogProbMetric: 181.0693 - lr: 0.0010 - 53s/epoch - 273ms/step
Epoch 188/1000
2023-10-01 11:45:25.085 
Epoch 188/1000 
	 loss: 180.1637, MinusLogProbMetric: 180.1637, val_loss: 181.4207, val_MinusLogProbMetric: 181.4207

Epoch 188: val_loss did not improve from 180.84996
196/196 - 56s - loss: 180.1637 - MinusLogProbMetric: 180.1637 - val_loss: 181.4207 - val_MinusLogProbMetric: 181.4207 - lr: 0.0010 - 56s/epoch - 284ms/step
Epoch 189/1000
2023-10-01 11:46:15.995 
Epoch 189/1000 
	 loss: 179.5718, MinusLogProbMetric: 179.5718, val_loss: 181.0699, val_MinusLogProbMetric: 181.0699

Epoch 189: val_loss did not improve from 180.84996
196/196 - 51s - loss: 179.5718 - MinusLogProbMetric: 179.5718 - val_loss: 181.0699 - val_MinusLogProbMetric: 181.0699 - lr: 0.0010 - 51s/epoch - 259ms/step
Epoch 190/1000
2023-10-01 11:47:09.417 
Epoch 190/1000 
	 loss: 179.6728, MinusLogProbMetric: 179.6728, val_loss: 181.0882, val_MinusLogProbMetric: 181.0882

Epoch 190: val_loss did not improve from 180.84996
196/196 - 53s - loss: 179.6728 - MinusLogProbMetric: 179.6728 - val_loss: 181.0882 - val_MinusLogProbMetric: 181.0882 - lr: 0.0010 - 53s/epoch - 273ms/step
Epoch 191/1000
2023-10-01 11:48:03.649 
Epoch 191/1000 
	 loss: 179.6474, MinusLogProbMetric: 179.6474, val_loss: 180.9637, val_MinusLogProbMetric: 180.9637

Epoch 191: val_loss did not improve from 180.84996
196/196 - 54s - loss: 179.6474 - MinusLogProbMetric: 179.6474 - val_loss: 180.9637 - val_MinusLogProbMetric: 180.9637 - lr: 0.0010 - 54s/epoch - 277ms/step
Epoch 192/1000
2023-10-01 11:48:57.565 
Epoch 192/1000 
	 loss: 179.7205, MinusLogProbMetric: 179.7205, val_loss: 181.1931, val_MinusLogProbMetric: 181.1931

Epoch 192: val_loss did not improve from 180.84996
196/196 - 54s - loss: 179.7205 - MinusLogProbMetric: 179.7205 - val_loss: 181.1931 - val_MinusLogProbMetric: 181.1931 - lr: 0.0010 - 54s/epoch - 275ms/step
Epoch 193/1000
2023-10-01 11:49:51.341 
Epoch 193/1000 
	 loss: 179.6543, MinusLogProbMetric: 179.6543, val_loss: 182.0329, val_MinusLogProbMetric: 182.0329

Epoch 193: val_loss did not improve from 180.84996
196/196 - 54s - loss: 179.6543 - MinusLogProbMetric: 179.6543 - val_loss: 182.0329 - val_MinusLogProbMetric: 182.0329 - lr: 0.0010 - 54s/epoch - 274ms/step
Epoch 194/1000
2023-10-01 11:50:45.682 
Epoch 194/1000 
	 loss: 179.6025, MinusLogProbMetric: 179.6025, val_loss: 181.3184, val_MinusLogProbMetric: 181.3184

Epoch 194: val_loss did not improve from 180.84996
196/196 - 54s - loss: 179.6025 - MinusLogProbMetric: 179.6025 - val_loss: 181.3184 - val_MinusLogProbMetric: 181.3184 - lr: 0.0010 - 54s/epoch - 277ms/step
Epoch 195/1000
2023-10-01 11:51:40.161 
Epoch 195/1000 
	 loss: 179.6429, MinusLogProbMetric: 179.6429, val_loss: 181.9044, val_MinusLogProbMetric: 181.9044

Epoch 195: val_loss did not improve from 180.84996
196/196 - 54s - loss: 179.6429 - MinusLogProbMetric: 179.6429 - val_loss: 181.9044 - val_MinusLogProbMetric: 181.9044 - lr: 0.0010 - 54s/epoch - 278ms/step
Epoch 196/1000
2023-10-01 11:52:34.332 
Epoch 196/1000 
	 loss: 179.6309, MinusLogProbMetric: 179.6309, val_loss: 181.1210, val_MinusLogProbMetric: 181.1210

Epoch 196: val_loss did not improve from 180.84996
196/196 - 54s - loss: 179.6309 - MinusLogProbMetric: 179.6309 - val_loss: 181.1210 - val_MinusLogProbMetric: 181.1210 - lr: 0.0010 - 54s/epoch - 276ms/step
Epoch 197/1000
2023-10-01 11:53:28.818 
Epoch 197/1000 
	 loss: 179.5983, MinusLogProbMetric: 179.5983, val_loss: 181.0110, val_MinusLogProbMetric: 181.0110

Epoch 197: val_loss did not improve from 180.84996
196/196 - 54s - loss: 179.5983 - MinusLogProbMetric: 179.5983 - val_loss: 181.0110 - val_MinusLogProbMetric: 181.0110 - lr: 0.0010 - 54s/epoch - 278ms/step
Epoch 198/1000
2023-10-01 11:54:22.478 
Epoch 198/1000 
	 loss: 179.6194, MinusLogProbMetric: 179.6194, val_loss: 181.2402, val_MinusLogProbMetric: 181.2402

Epoch 198: val_loss did not improve from 180.84996
196/196 - 54s - loss: 179.6194 - MinusLogProbMetric: 179.6194 - val_loss: 181.2402 - val_MinusLogProbMetric: 181.2402 - lr: 0.0010 - 54s/epoch - 274ms/step
Epoch 199/1000
2023-10-01 11:55:17.948 
Epoch 199/1000 
	 loss: 180.1487, MinusLogProbMetric: 180.1487, val_loss: 181.1474, val_MinusLogProbMetric: 181.1474

Epoch 199: val_loss did not improve from 180.84996
196/196 - 55s - loss: 180.1487 - MinusLogProbMetric: 180.1487 - val_loss: 181.1474 - val_MinusLogProbMetric: 181.1474 - lr: 0.0010 - 55s/epoch - 283ms/step
Epoch 200/1000
2023-10-01 11:56:19.391 
Epoch 200/1000 
	 loss: 179.4993, MinusLogProbMetric: 179.4993, val_loss: 181.1071, val_MinusLogProbMetric: 181.1071

Epoch 200: val_loss did not improve from 180.84996
196/196 - 61s - loss: 179.4993 - MinusLogProbMetric: 179.4993 - val_loss: 181.1071 - val_MinusLogProbMetric: 181.1071 - lr: 0.0010 - 61s/epoch - 314ms/step
Epoch 201/1000
2023-10-01 11:57:17.440 
Epoch 201/1000 
	 loss: 179.5455, MinusLogProbMetric: 179.5455, val_loss: 181.2954, val_MinusLogProbMetric: 181.2954

Epoch 201: val_loss did not improve from 180.84996
196/196 - 58s - loss: 179.5455 - MinusLogProbMetric: 179.5455 - val_loss: 181.2954 - val_MinusLogProbMetric: 181.2954 - lr: 0.0010 - 58s/epoch - 296ms/step
Epoch 202/1000
2023-10-01 11:58:12.707 
Epoch 202/1000 
	 loss: 179.5509, MinusLogProbMetric: 179.5509, val_loss: 181.1531, val_MinusLogProbMetric: 181.1531

Epoch 202: val_loss did not improve from 180.84996
196/196 - 55s - loss: 179.5509 - MinusLogProbMetric: 179.5509 - val_loss: 181.1531 - val_MinusLogProbMetric: 181.1531 - lr: 0.0010 - 55s/epoch - 282ms/step
Epoch 203/1000
2023-10-01 11:59:10.502 
Epoch 203/1000 
	 loss: 179.5883, MinusLogProbMetric: 179.5883, val_loss: 181.1699, val_MinusLogProbMetric: 181.1699

Epoch 203: val_loss did not improve from 180.84996
196/196 - 58s - loss: 179.5883 - MinusLogProbMetric: 179.5883 - val_loss: 181.1699 - val_MinusLogProbMetric: 181.1699 - lr: 0.0010 - 58s/epoch - 295ms/step
Epoch 204/1000
2023-10-01 12:00:10.122 
Epoch 204/1000 
	 loss: 179.5707, MinusLogProbMetric: 179.5707, val_loss: 181.6845, val_MinusLogProbMetric: 181.6845

Epoch 204: val_loss did not improve from 180.84996
196/196 - 60s - loss: 179.5707 - MinusLogProbMetric: 179.5707 - val_loss: 181.6845 - val_MinusLogProbMetric: 181.6845 - lr: 0.0010 - 60s/epoch - 304ms/step
Epoch 205/1000
2023-10-01 12:01:07.825 
Epoch 205/1000 
	 loss: 179.6817, MinusLogProbMetric: 179.6817, val_loss: 181.5267, val_MinusLogProbMetric: 181.5267

Epoch 205: val_loss did not improve from 180.84996
196/196 - 58s - loss: 179.6817 - MinusLogProbMetric: 179.6817 - val_loss: 181.5267 - val_MinusLogProbMetric: 181.5267 - lr: 0.0010 - 58s/epoch - 294ms/step
Epoch 206/1000
2023-10-01 12:02:05.248 
Epoch 206/1000 
	 loss: 179.8420, MinusLogProbMetric: 179.8420, val_loss: 181.3051, val_MinusLogProbMetric: 181.3051

Epoch 206: val_loss did not improve from 180.84996
196/196 - 57s - loss: 179.8420 - MinusLogProbMetric: 179.8420 - val_loss: 181.3051 - val_MinusLogProbMetric: 181.3051 - lr: 0.0010 - 57s/epoch - 293ms/step
Epoch 207/1000
2023-10-01 12:03:03.979 
Epoch 207/1000 
	 loss: 179.5131, MinusLogProbMetric: 179.5131, val_loss: 180.8611, val_MinusLogProbMetric: 180.8611

Epoch 207: val_loss did not improve from 180.84996
196/196 - 59s - loss: 179.5131 - MinusLogProbMetric: 179.5131 - val_loss: 180.8611 - val_MinusLogProbMetric: 180.8611 - lr: 0.0010 - 59s/epoch - 300ms/step
Epoch 208/1000
2023-10-01 12:04:04.797 
Epoch 208/1000 
	 loss: 179.6006, MinusLogProbMetric: 179.6006, val_loss: 180.9222, val_MinusLogProbMetric: 180.9222

Epoch 208: val_loss did not improve from 180.84996
196/196 - 61s - loss: 179.6006 - MinusLogProbMetric: 179.6006 - val_loss: 180.9222 - val_MinusLogProbMetric: 180.9222 - lr: 0.0010 - 61s/epoch - 310ms/step
Epoch 209/1000
2023-10-01 12:05:05.425 
Epoch 209/1000 
	 loss: 178.7879, MinusLogProbMetric: 178.7879, val_loss: 180.4625, val_MinusLogProbMetric: 180.4625

Epoch 209: val_loss improved from 180.84996 to 180.46248, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 61s - loss: 178.7879 - MinusLogProbMetric: 178.7879 - val_loss: 180.4625 - val_MinusLogProbMetric: 180.4625 - lr: 5.0000e-04 - 61s/epoch - 313ms/step
Epoch 210/1000
2023-10-01 12:06:07.804 
Epoch 210/1000 
	 loss: 178.8101, MinusLogProbMetric: 178.8101, val_loss: 180.4503, val_MinusLogProbMetric: 180.4503

Epoch 210: val_loss improved from 180.46248 to 180.45032, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 62s - loss: 178.8101 - MinusLogProbMetric: 178.8101 - val_loss: 180.4503 - val_MinusLogProbMetric: 180.4503 - lr: 5.0000e-04 - 62s/epoch - 318ms/step
Epoch 211/1000
2023-10-01 12:07:08.769 
Epoch 211/1000 
	 loss: 178.9863, MinusLogProbMetric: 178.9863, val_loss: 180.4797, val_MinusLogProbMetric: 180.4797

Epoch 211: val_loss did not improve from 180.45032
196/196 - 60s - loss: 178.9863 - MinusLogProbMetric: 178.9863 - val_loss: 180.4797 - val_MinusLogProbMetric: 180.4797 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 212/1000
2023-10-01 12:08:10.439 
Epoch 212/1000 
	 loss: 178.7490, MinusLogProbMetric: 178.7490, val_loss: 180.4288, val_MinusLogProbMetric: 180.4288

Epoch 212: val_loss improved from 180.45032 to 180.42880, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 62s - loss: 178.7490 - MinusLogProbMetric: 178.7490 - val_loss: 180.4288 - val_MinusLogProbMetric: 180.4288 - lr: 5.0000e-04 - 62s/epoch - 318ms/step
Epoch 213/1000
2023-10-01 12:09:12.865 
Epoch 213/1000 
	 loss: 178.7819, MinusLogProbMetric: 178.7819, val_loss: 180.5725, val_MinusLogProbMetric: 180.5725

Epoch 213: val_loss did not improve from 180.42880
196/196 - 62s - loss: 178.7819 - MinusLogProbMetric: 178.7819 - val_loss: 180.5725 - val_MinusLogProbMetric: 180.5725 - lr: 5.0000e-04 - 62s/epoch - 315ms/step
Epoch 214/1000
2023-10-01 12:10:14.293 
Epoch 214/1000 
	 loss: 178.7903, MinusLogProbMetric: 178.7903, val_loss: 180.9429, val_MinusLogProbMetric: 180.9429

Epoch 214: val_loss did not improve from 180.42880
196/196 - 61s - loss: 178.7903 - MinusLogProbMetric: 178.7903 - val_loss: 180.9429 - val_MinusLogProbMetric: 180.9429 - lr: 5.0000e-04 - 61s/epoch - 313ms/step
Epoch 215/1000
2023-10-01 12:11:14.870 
Epoch 215/1000 
	 loss: 178.8359, MinusLogProbMetric: 178.8359, val_loss: 180.4580, val_MinusLogProbMetric: 180.4580

Epoch 215: val_loss did not improve from 180.42880
196/196 - 61s - loss: 178.8359 - MinusLogProbMetric: 178.8359 - val_loss: 180.4580 - val_MinusLogProbMetric: 180.4580 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 216/1000
2023-10-01 12:12:19.882 
Epoch 216/1000 
	 loss: 178.9916, MinusLogProbMetric: 178.9916, val_loss: 180.6091, val_MinusLogProbMetric: 180.6091

Epoch 216: val_loss did not improve from 180.42880
196/196 - 65s - loss: 178.9916 - MinusLogProbMetric: 178.9916 - val_loss: 180.6091 - val_MinusLogProbMetric: 180.6091 - lr: 5.0000e-04 - 65s/epoch - 331ms/step
Epoch 217/1000
2023-10-01 12:13:19.889 
Epoch 217/1000 
	 loss: 178.8267, MinusLogProbMetric: 178.8267, val_loss: 181.3825, val_MinusLogProbMetric: 181.3825

Epoch 217: val_loss did not improve from 180.42880
196/196 - 60s - loss: 178.8267 - MinusLogProbMetric: 178.8267 - val_loss: 181.3825 - val_MinusLogProbMetric: 181.3825 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 218/1000
2023-10-01 12:14:20.266 
Epoch 218/1000 
	 loss: 178.9668, MinusLogProbMetric: 178.9668, val_loss: 180.6460, val_MinusLogProbMetric: 180.6460

Epoch 218: val_loss did not improve from 180.42880
196/196 - 60s - loss: 178.9668 - MinusLogProbMetric: 178.9668 - val_loss: 180.6460 - val_MinusLogProbMetric: 180.6460 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 219/1000
2023-10-01 12:15:20.246 
Epoch 219/1000 
	 loss: 178.7002, MinusLogProbMetric: 178.7002, val_loss: 180.9733, val_MinusLogProbMetric: 180.9733

Epoch 219: val_loss did not improve from 180.42880
196/196 - 60s - loss: 178.7002 - MinusLogProbMetric: 178.7002 - val_loss: 180.9733 - val_MinusLogProbMetric: 180.9733 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 220/1000
2023-10-01 12:16:24.547 
Epoch 220/1000 
	 loss: 178.7223, MinusLogProbMetric: 178.7223, val_loss: 180.4203, val_MinusLogProbMetric: 180.4203

Epoch 220: val_loss improved from 180.42880 to 180.42027, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 65s - loss: 178.7223 - MinusLogProbMetric: 178.7223 - val_loss: 180.4203 - val_MinusLogProbMetric: 180.4203 - lr: 5.0000e-04 - 65s/epoch - 331ms/step
Epoch 221/1000
2023-10-01 12:17:26.985 
Epoch 221/1000 
	 loss: 178.7925, MinusLogProbMetric: 178.7925, val_loss: 180.8188, val_MinusLogProbMetric: 180.8188

Epoch 221: val_loss did not improve from 180.42027
196/196 - 62s - loss: 178.7925 - MinusLogProbMetric: 178.7925 - val_loss: 180.8188 - val_MinusLogProbMetric: 180.8188 - lr: 5.0000e-04 - 62s/epoch - 315ms/step
Epoch 222/1000
2023-10-01 12:18:26.731 
Epoch 222/1000 
	 loss: 178.7482, MinusLogProbMetric: 178.7482, val_loss: 180.9981, val_MinusLogProbMetric: 180.9981

Epoch 222: val_loss did not improve from 180.42027
196/196 - 60s - loss: 178.7482 - MinusLogProbMetric: 178.7482 - val_loss: 180.9981 - val_MinusLogProbMetric: 180.9981 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 223/1000
2023-10-01 12:19:26.673 
Epoch 223/1000 
	 loss: 178.7627, MinusLogProbMetric: 178.7627, val_loss: 180.4192, val_MinusLogProbMetric: 180.4192

Epoch 223: val_loss improved from 180.42027 to 180.41920, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 61s - loss: 178.7627 - MinusLogProbMetric: 178.7627 - val_loss: 180.4192 - val_MinusLogProbMetric: 180.4192 - lr: 5.0000e-04 - 61s/epoch - 314ms/step
Epoch 224/1000
2023-10-01 12:20:28.731 
Epoch 224/1000 
	 loss: 178.7770, MinusLogProbMetric: 178.7770, val_loss: 181.3426, val_MinusLogProbMetric: 181.3426

Epoch 224: val_loss did not improve from 180.41920
196/196 - 61s - loss: 178.7770 - MinusLogProbMetric: 178.7770 - val_loss: 181.3426 - val_MinusLogProbMetric: 181.3426 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 225/1000
2023-10-01 12:21:34.434 
Epoch 225/1000 
	 loss: 178.9090, MinusLogProbMetric: 178.9090, val_loss: 180.5487, val_MinusLogProbMetric: 180.5487

Epoch 225: val_loss did not improve from 180.41920
196/196 - 66s - loss: 178.9090 - MinusLogProbMetric: 178.9090 - val_loss: 180.5487 - val_MinusLogProbMetric: 180.5487 - lr: 5.0000e-04 - 66s/epoch - 335ms/step
Epoch 226/1000
2023-10-01 12:22:40.619 
Epoch 226/1000 
	 loss: 178.8238, MinusLogProbMetric: 178.8238, val_loss: 180.6035, val_MinusLogProbMetric: 180.6035

Epoch 226: val_loss did not improve from 180.41920
196/196 - 66s - loss: 178.8238 - MinusLogProbMetric: 178.8238 - val_loss: 180.6035 - val_MinusLogProbMetric: 180.6035 - lr: 5.0000e-04 - 66s/epoch - 338ms/step
Epoch 227/1000
2023-10-01 12:23:40.493 
Epoch 227/1000 
	 loss: 178.8247, MinusLogProbMetric: 178.8247, val_loss: 180.7948, val_MinusLogProbMetric: 180.7948

Epoch 227: val_loss did not improve from 180.41920
196/196 - 60s - loss: 178.8247 - MinusLogProbMetric: 178.8247 - val_loss: 180.7948 - val_MinusLogProbMetric: 180.7948 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 228/1000
2023-10-01 12:24:45.392 
Epoch 228/1000 
	 loss: 178.8273, MinusLogProbMetric: 178.8273, val_loss: 180.5850, val_MinusLogProbMetric: 180.5850

Epoch 228: val_loss did not improve from 180.41920
196/196 - 65s - loss: 178.8273 - MinusLogProbMetric: 178.8273 - val_loss: 180.5850 - val_MinusLogProbMetric: 180.5850 - lr: 5.0000e-04 - 65s/epoch - 331ms/step
Epoch 229/1000
2023-10-01 12:25:51.027 
Epoch 229/1000 
	 loss: 178.6619, MinusLogProbMetric: 178.6619, val_loss: 181.0666, val_MinusLogProbMetric: 181.0666

Epoch 229: val_loss did not improve from 180.41920
196/196 - 66s - loss: 178.6619 - MinusLogProbMetric: 178.6619 - val_loss: 181.0666 - val_MinusLogProbMetric: 181.0666 - lr: 5.0000e-04 - 66s/epoch - 335ms/step
Epoch 230/1000
2023-10-01 12:26:52.142 
Epoch 230/1000 
	 loss: 178.8550, MinusLogProbMetric: 178.8550, val_loss: 180.8969, val_MinusLogProbMetric: 180.8969

Epoch 230: val_loss did not improve from 180.41920
196/196 - 61s - loss: 178.8550 - MinusLogProbMetric: 178.8550 - val_loss: 180.8969 - val_MinusLogProbMetric: 180.8969 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 231/1000
2023-10-01 12:27:52.853 
Epoch 231/1000 
	 loss: 178.7031, MinusLogProbMetric: 178.7031, val_loss: 180.5269, val_MinusLogProbMetric: 180.5269

Epoch 231: val_loss did not improve from 180.41920
196/196 - 61s - loss: 178.7031 - MinusLogProbMetric: 178.7031 - val_loss: 180.5269 - val_MinusLogProbMetric: 180.5269 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 232/1000
2023-10-01 12:28:52.712 
Epoch 232/1000 
	 loss: 178.8227, MinusLogProbMetric: 178.8227, val_loss: 180.4664, val_MinusLogProbMetric: 180.4664

Epoch 232: val_loss did not improve from 180.41920
196/196 - 60s - loss: 178.8227 - MinusLogProbMetric: 178.8227 - val_loss: 180.4664 - val_MinusLogProbMetric: 180.4664 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 233/1000
2023-10-01 12:29:53.312 
Epoch 233/1000 
	 loss: 178.6750, MinusLogProbMetric: 178.6750, val_loss: 180.5226, val_MinusLogProbMetric: 180.5226

Epoch 233: val_loss did not improve from 180.41920
196/196 - 61s - loss: 178.6750 - MinusLogProbMetric: 178.6750 - val_loss: 180.5226 - val_MinusLogProbMetric: 180.5226 - lr: 5.0000e-04 - 61s/epoch - 309ms/step
Epoch 234/1000
2023-10-01 12:30:53.102 
Epoch 234/1000 
	 loss: 178.6967, MinusLogProbMetric: 178.6967, val_loss: 180.4663, val_MinusLogProbMetric: 180.4663

Epoch 234: val_loss did not improve from 180.41920
196/196 - 60s - loss: 178.6967 - MinusLogProbMetric: 178.6967 - val_loss: 180.4663 - val_MinusLogProbMetric: 180.4663 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 235/1000
2023-10-01 12:31:51.202 
Epoch 235/1000 
	 loss: 178.7084, MinusLogProbMetric: 178.7084, val_loss: 180.9527, val_MinusLogProbMetric: 180.9527

Epoch 235: val_loss did not improve from 180.41920
196/196 - 58s - loss: 178.7084 - MinusLogProbMetric: 178.7084 - val_loss: 180.9527 - val_MinusLogProbMetric: 180.9527 - lr: 5.0000e-04 - 58s/epoch - 296ms/step
Epoch 236/1000
2023-10-01 12:32:49.973 
Epoch 236/1000 
	 loss: 178.8426, MinusLogProbMetric: 178.8426, val_loss: 180.4847, val_MinusLogProbMetric: 180.4847

Epoch 236: val_loss did not improve from 180.41920
196/196 - 59s - loss: 178.8426 - MinusLogProbMetric: 178.8426 - val_loss: 180.4847 - val_MinusLogProbMetric: 180.4847 - lr: 5.0000e-04 - 59s/epoch - 300ms/step
Epoch 237/1000
2023-10-01 12:33:54.646 
Epoch 237/1000 
	 loss: 178.7775, MinusLogProbMetric: 178.7775, val_loss: 180.5491, val_MinusLogProbMetric: 180.5491

Epoch 237: val_loss did not improve from 180.41920
196/196 - 65s - loss: 178.7775 - MinusLogProbMetric: 178.7775 - val_loss: 180.5491 - val_MinusLogProbMetric: 180.5491 - lr: 5.0000e-04 - 65s/epoch - 330ms/step
Epoch 238/1000
2023-10-01 12:34:54.277 
Epoch 238/1000 
	 loss: 178.6654, MinusLogProbMetric: 178.6654, val_loss: 180.4805, val_MinusLogProbMetric: 180.4805

Epoch 238: val_loss did not improve from 180.41920
196/196 - 60s - loss: 178.6654 - MinusLogProbMetric: 178.6654 - val_loss: 180.4805 - val_MinusLogProbMetric: 180.4805 - lr: 5.0000e-04 - 60s/epoch - 304ms/step
Epoch 239/1000
2023-10-01 12:35:55.492 
Epoch 239/1000 
	 loss: 178.8281, MinusLogProbMetric: 178.8281, val_loss: 180.5374, val_MinusLogProbMetric: 180.5374

Epoch 239: val_loss did not improve from 180.41920
196/196 - 61s - loss: 178.8281 - MinusLogProbMetric: 178.8281 - val_loss: 180.5374 - val_MinusLogProbMetric: 180.5374 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 240/1000
2023-10-01 12:36:55.786 
Epoch 240/1000 
	 loss: 178.6659, MinusLogProbMetric: 178.6659, val_loss: 180.6058, val_MinusLogProbMetric: 180.6058

Epoch 240: val_loss did not improve from 180.41920
196/196 - 60s - loss: 178.6659 - MinusLogProbMetric: 178.6659 - val_loss: 180.6058 - val_MinusLogProbMetric: 180.6058 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 241/1000
2023-10-01 12:37:55.701 
Epoch 241/1000 
	 loss: 179.0133, MinusLogProbMetric: 179.0133, val_loss: 180.6224, val_MinusLogProbMetric: 180.6224

Epoch 241: val_loss did not improve from 180.41920
196/196 - 60s - loss: 179.0133 - MinusLogProbMetric: 179.0133 - val_loss: 180.6224 - val_MinusLogProbMetric: 180.6224 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 242/1000
2023-10-01 12:38:55.519 
Epoch 242/1000 
	 loss: 178.6789, MinusLogProbMetric: 178.6789, val_loss: 180.4620, val_MinusLogProbMetric: 180.4620

Epoch 242: val_loss did not improve from 180.41920
196/196 - 60s - loss: 178.6789 - MinusLogProbMetric: 178.6789 - val_loss: 180.4620 - val_MinusLogProbMetric: 180.4620 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 243/1000
2023-10-01 12:39:56.914 
Epoch 243/1000 
	 loss: 178.7683, MinusLogProbMetric: 178.7683, val_loss: 181.0649, val_MinusLogProbMetric: 181.0649

Epoch 243: val_loss did not improve from 180.41920
196/196 - 61s - loss: 178.7683 - MinusLogProbMetric: 178.7683 - val_loss: 181.0649 - val_MinusLogProbMetric: 181.0649 - lr: 5.0000e-04 - 61s/epoch - 313ms/step
Epoch 244/1000
2023-10-01 12:40:56.855 
Epoch 244/1000 
	 loss: 178.6977, MinusLogProbMetric: 178.6977, val_loss: 180.4935, val_MinusLogProbMetric: 180.4935

Epoch 244: val_loss did not improve from 180.41920
196/196 - 60s - loss: 178.6977 - MinusLogProbMetric: 178.6977 - val_loss: 180.4935 - val_MinusLogProbMetric: 180.4935 - lr: 5.0000e-04 - 60s/epoch - 306ms/step
Epoch 245/1000
2023-10-01 12:41:56.930 
Epoch 245/1000 
	 loss: 178.6251, MinusLogProbMetric: 178.6251, val_loss: 180.9912, val_MinusLogProbMetric: 180.9912

Epoch 245: val_loss did not improve from 180.41920
196/196 - 60s - loss: 178.6251 - MinusLogProbMetric: 178.6251 - val_loss: 180.9912 - val_MinusLogProbMetric: 180.9912 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 246/1000
2023-10-01 12:42:56.592 
Epoch 246/1000 
	 loss: 178.9020, MinusLogProbMetric: 178.9020, val_loss: 180.6897, val_MinusLogProbMetric: 180.6897

Epoch 246: val_loss did not improve from 180.41920
196/196 - 60s - loss: 178.9020 - MinusLogProbMetric: 178.9020 - val_loss: 180.6897 - val_MinusLogProbMetric: 180.6897 - lr: 5.0000e-04 - 60s/epoch - 304ms/step
Epoch 247/1000
2023-10-01 12:43:57.593 
Epoch 247/1000 
	 loss: 178.6450, MinusLogProbMetric: 178.6450, val_loss: 180.5652, val_MinusLogProbMetric: 180.5652

Epoch 247: val_loss did not improve from 180.41920
196/196 - 61s - loss: 178.6450 - MinusLogProbMetric: 178.6450 - val_loss: 180.5652 - val_MinusLogProbMetric: 180.5652 - lr: 5.0000e-04 - 61s/epoch - 311ms/step
Epoch 248/1000
2023-10-01 12:44:59.416 
Epoch 248/1000 
	 loss: 178.7773, MinusLogProbMetric: 178.7773, val_loss: 180.5409, val_MinusLogProbMetric: 180.5409

Epoch 248: val_loss did not improve from 180.41920
196/196 - 62s - loss: 178.7773 - MinusLogProbMetric: 178.7773 - val_loss: 180.5409 - val_MinusLogProbMetric: 180.5409 - lr: 5.0000e-04 - 62s/epoch - 315ms/step
Epoch 249/1000
2023-10-01 12:46:00.546 
Epoch 249/1000 
	 loss: 178.6141, MinusLogProbMetric: 178.6141, val_loss: 181.5026, val_MinusLogProbMetric: 181.5026

Epoch 249: val_loss did not improve from 180.41920
196/196 - 61s - loss: 178.6141 - MinusLogProbMetric: 178.6141 - val_loss: 181.5026 - val_MinusLogProbMetric: 181.5026 - lr: 5.0000e-04 - 61s/epoch - 312ms/step
Epoch 250/1000
2023-10-01 12:47:00.313 
Epoch 250/1000 
	 loss: 178.7818, MinusLogProbMetric: 178.7818, val_loss: 180.6003, val_MinusLogProbMetric: 180.6003

Epoch 250: val_loss did not improve from 180.41920
196/196 - 60s - loss: 178.7818 - MinusLogProbMetric: 178.7818 - val_loss: 180.6003 - val_MinusLogProbMetric: 180.6003 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 251/1000
2023-10-01 12:48:00.487 
Epoch 251/1000 
	 loss: 178.6191, MinusLogProbMetric: 178.6191, val_loss: 180.4651, val_MinusLogProbMetric: 180.4651

Epoch 251: val_loss did not improve from 180.41920
196/196 - 60s - loss: 178.6191 - MinusLogProbMetric: 178.6191 - val_loss: 180.4651 - val_MinusLogProbMetric: 180.4651 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 252/1000
2023-10-01 12:49:01.254 
Epoch 252/1000 
	 loss: 178.6449, MinusLogProbMetric: 178.6449, val_loss: 180.5772, val_MinusLogProbMetric: 180.5772

Epoch 252: val_loss did not improve from 180.41920
196/196 - 61s - loss: 178.6449 - MinusLogProbMetric: 178.6449 - val_loss: 180.5772 - val_MinusLogProbMetric: 180.5772 - lr: 5.0000e-04 - 61s/epoch - 310ms/step
Epoch 253/1000
2023-10-01 12:50:00.174 
Epoch 253/1000 
	 loss: 178.6706, MinusLogProbMetric: 178.6706, val_loss: 180.9454, val_MinusLogProbMetric: 180.9454

Epoch 253: val_loss did not improve from 180.41920
196/196 - 59s - loss: 178.6706 - MinusLogProbMetric: 178.6706 - val_loss: 180.9454 - val_MinusLogProbMetric: 180.9454 - lr: 5.0000e-04 - 59s/epoch - 301ms/step
Epoch 254/1000
2023-10-01 12:50:56.849 
Epoch 254/1000 
	 loss: 178.7388, MinusLogProbMetric: 178.7388, val_loss: 180.6141, val_MinusLogProbMetric: 180.6141

Epoch 254: val_loss did not improve from 180.41920
196/196 - 57s - loss: 178.7388 - MinusLogProbMetric: 178.7388 - val_loss: 180.6141 - val_MinusLogProbMetric: 180.6141 - lr: 5.0000e-04 - 57s/epoch - 289ms/step
Epoch 255/1000
2023-10-01 12:51:52.795 
Epoch 255/1000 
	 loss: 178.6262, MinusLogProbMetric: 178.6262, val_loss: 180.5334, val_MinusLogProbMetric: 180.5334

Epoch 255: val_loss did not improve from 180.41920
196/196 - 56s - loss: 178.6262 - MinusLogProbMetric: 178.6262 - val_loss: 180.5334 - val_MinusLogProbMetric: 180.5334 - lr: 5.0000e-04 - 56s/epoch - 285ms/step
Epoch 256/1000
2023-10-01 12:52:49.082 
Epoch 256/1000 
	 loss: 178.6458, MinusLogProbMetric: 178.6458, val_loss: 180.5577, val_MinusLogProbMetric: 180.5577

Epoch 256: val_loss did not improve from 180.41920
196/196 - 56s - loss: 178.6458 - MinusLogProbMetric: 178.6458 - val_loss: 180.5577 - val_MinusLogProbMetric: 180.5577 - lr: 5.0000e-04 - 56s/epoch - 287ms/step
Epoch 257/1000
2023-10-01 12:53:46.624 
Epoch 257/1000 
	 loss: 178.6212, MinusLogProbMetric: 178.6212, val_loss: 181.5263, val_MinusLogProbMetric: 181.5263

Epoch 257: val_loss did not improve from 180.41920
196/196 - 58s - loss: 178.6212 - MinusLogProbMetric: 178.6212 - val_loss: 181.5263 - val_MinusLogProbMetric: 181.5263 - lr: 5.0000e-04 - 58s/epoch - 293ms/step
Epoch 258/1000
2023-10-01 12:54:46.499 
Epoch 258/1000 
	 loss: 178.6642, MinusLogProbMetric: 178.6642, val_loss: 180.6082, val_MinusLogProbMetric: 180.6082

Epoch 258: val_loss did not improve from 180.41920
196/196 - 60s - loss: 178.6642 - MinusLogProbMetric: 178.6642 - val_loss: 180.6082 - val_MinusLogProbMetric: 180.6082 - lr: 5.0000e-04 - 60s/epoch - 305ms/step
Epoch 259/1000
2023-10-01 12:55:44.229 
Epoch 259/1000 
	 loss: 178.8674, MinusLogProbMetric: 178.8674, val_loss: 180.8450, val_MinusLogProbMetric: 180.8450

Epoch 259: val_loss did not improve from 180.41920
196/196 - 58s - loss: 178.8674 - MinusLogProbMetric: 178.8674 - val_loss: 180.8450 - val_MinusLogProbMetric: 180.8450 - lr: 5.0000e-04 - 58s/epoch - 294ms/step
Epoch 260/1000
2023-10-01 12:56:40.776 
Epoch 260/1000 
	 loss: 178.5619, MinusLogProbMetric: 178.5619, val_loss: 180.6942, val_MinusLogProbMetric: 180.6942

Epoch 260: val_loss did not improve from 180.41920
196/196 - 57s - loss: 178.5619 - MinusLogProbMetric: 178.5619 - val_loss: 180.6942 - val_MinusLogProbMetric: 180.6942 - lr: 5.0000e-04 - 57s/epoch - 288ms/step
Epoch 261/1000
2023-10-01 12:57:40.879 
Epoch 261/1000 
	 loss: 178.7417, MinusLogProbMetric: 178.7417, val_loss: 180.7445, val_MinusLogProbMetric: 180.7445

Epoch 261: val_loss did not improve from 180.41920
196/196 - 60s - loss: 178.7417 - MinusLogProbMetric: 178.7417 - val_loss: 180.7445 - val_MinusLogProbMetric: 180.7445 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 262/1000
2023-10-01 12:58:36.488 
Epoch 262/1000 
	 loss: 178.5933, MinusLogProbMetric: 178.5933, val_loss: 180.5702, val_MinusLogProbMetric: 180.5702

Epoch 262: val_loss did not improve from 180.41920
196/196 - 56s - loss: 178.5933 - MinusLogProbMetric: 178.5933 - val_loss: 180.5702 - val_MinusLogProbMetric: 180.5702 - lr: 5.0000e-04 - 56s/epoch - 284ms/step
Epoch 263/1000
2023-10-01 12:59:32.106 
Epoch 263/1000 
	 loss: 178.7304, MinusLogProbMetric: 178.7304, val_loss: 180.5588, val_MinusLogProbMetric: 180.5588

Epoch 263: val_loss did not improve from 180.41920
196/196 - 56s - loss: 178.7304 - MinusLogProbMetric: 178.7304 - val_loss: 180.5588 - val_MinusLogProbMetric: 180.5588 - lr: 5.0000e-04 - 56s/epoch - 284ms/step
Epoch 264/1000
2023-10-01 13:00:29.641 
Epoch 264/1000 
	 loss: 178.5977, MinusLogProbMetric: 178.5977, val_loss: 181.7359, val_MinusLogProbMetric: 181.7359

Epoch 264: val_loss did not improve from 180.41920
196/196 - 58s - loss: 178.5977 - MinusLogProbMetric: 178.5977 - val_loss: 181.7359 - val_MinusLogProbMetric: 181.7359 - lr: 5.0000e-04 - 58s/epoch - 294ms/step
Epoch 265/1000
2023-10-01 13:01:31.806 
Epoch 265/1000 
	 loss: 178.6278, MinusLogProbMetric: 178.6278, val_loss: 180.5596, val_MinusLogProbMetric: 180.5596

Epoch 265: val_loss did not improve from 180.41920
196/196 - 62s - loss: 178.6278 - MinusLogProbMetric: 178.6278 - val_loss: 180.5596 - val_MinusLogProbMetric: 180.5596 - lr: 5.0000e-04 - 62s/epoch - 317ms/step
Epoch 266/1000
2023-10-01 13:02:32.108 
Epoch 266/1000 
	 loss: 178.7857, MinusLogProbMetric: 178.7857, val_loss: 180.6166, val_MinusLogProbMetric: 180.6166

Epoch 266: val_loss did not improve from 180.41920
196/196 - 60s - loss: 178.7857 - MinusLogProbMetric: 178.7857 - val_loss: 180.6166 - val_MinusLogProbMetric: 180.6166 - lr: 5.0000e-04 - 60s/epoch - 308ms/step
Epoch 267/1000
2023-10-01 13:03:37.173 
Epoch 267/1000 
	 loss: 178.6191, MinusLogProbMetric: 178.6191, val_loss: 180.5652, val_MinusLogProbMetric: 180.5652

Epoch 267: val_loss did not improve from 180.41920
196/196 - 65s - loss: 178.6191 - MinusLogProbMetric: 178.6191 - val_loss: 180.5652 - val_MinusLogProbMetric: 180.5652 - lr: 5.0000e-04 - 65s/epoch - 332ms/step
Epoch 268/1000
2023-10-01 13:04:43.587 
Epoch 268/1000 
	 loss: 178.5675, MinusLogProbMetric: 178.5675, val_loss: 180.6975, val_MinusLogProbMetric: 180.6975

Epoch 268: val_loss did not improve from 180.41920
196/196 - 66s - loss: 178.5675 - MinusLogProbMetric: 178.5675 - val_loss: 180.6975 - val_MinusLogProbMetric: 180.6975 - lr: 5.0000e-04 - 66s/epoch - 339ms/step
Epoch 269/1000
2023-10-01 13:05:43.859 
Epoch 269/1000 
	 loss: 178.6630, MinusLogProbMetric: 178.6630, val_loss: 182.2787, val_MinusLogProbMetric: 182.2787

Epoch 269: val_loss did not improve from 180.41920
196/196 - 60s - loss: 178.6630 - MinusLogProbMetric: 178.6630 - val_loss: 182.2787 - val_MinusLogProbMetric: 182.2787 - lr: 5.0000e-04 - 60s/epoch - 307ms/step
Epoch 270/1000
2023-10-01 13:06:40.278 
Epoch 270/1000 
	 loss: 178.8505, MinusLogProbMetric: 178.8505, val_loss: 180.6252, val_MinusLogProbMetric: 180.6252

Epoch 270: val_loss did not improve from 180.41920
196/196 - 56s - loss: 178.8505 - MinusLogProbMetric: 178.8505 - val_loss: 180.6252 - val_MinusLogProbMetric: 180.6252 - lr: 5.0000e-04 - 56s/epoch - 288ms/step
Epoch 271/1000
2023-10-01 13:07:36.945 
Epoch 271/1000 
	 loss: 178.5662, MinusLogProbMetric: 178.5662, val_loss: 180.5679, val_MinusLogProbMetric: 180.5679

Epoch 271: val_loss did not improve from 180.41920
196/196 - 57s - loss: 178.5662 - MinusLogProbMetric: 178.5662 - val_loss: 180.5679 - val_MinusLogProbMetric: 180.5679 - lr: 5.0000e-04 - 57s/epoch - 289ms/step
Epoch 272/1000
2023-10-01 13:08:44.525 
Epoch 272/1000 
	 loss: 178.5996, MinusLogProbMetric: 178.5996, val_loss: 180.6818, val_MinusLogProbMetric: 180.6818

Epoch 272: val_loss did not improve from 180.41920
196/196 - 68s - loss: 178.5996 - MinusLogProbMetric: 178.5996 - val_loss: 180.6818 - val_MinusLogProbMetric: 180.6818 - lr: 5.0000e-04 - 68s/epoch - 345ms/step
Epoch 273/1000
2023-10-01 13:09:47.048 
Epoch 273/1000 
	 loss: 178.5630, MinusLogProbMetric: 178.5630, val_loss: 180.6499, val_MinusLogProbMetric: 180.6499

Epoch 273: val_loss did not improve from 180.41920
196/196 - 62s - loss: 178.5630 - MinusLogProbMetric: 178.5630 - val_loss: 180.6499 - val_MinusLogProbMetric: 180.6499 - lr: 5.0000e-04 - 62s/epoch - 319ms/step
Epoch 274/1000
2023-10-01 13:10:46.406 
Epoch 274/1000 
	 loss: 178.2348, MinusLogProbMetric: 178.2348, val_loss: 180.3763, val_MinusLogProbMetric: 180.3763

Epoch 274: val_loss improved from 180.41920 to 180.37630, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 60s - loss: 178.2348 - MinusLogProbMetric: 178.2348 - val_loss: 180.3763 - val_MinusLogProbMetric: 180.3763 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 275/1000
2023-10-01 13:11:53.961 
Epoch 275/1000 
	 loss: 178.2043, MinusLogProbMetric: 178.2043, val_loss: 180.3560, val_MinusLogProbMetric: 180.3560

Epoch 275: val_loss improved from 180.37630 to 180.35596, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 68s - loss: 178.2043 - MinusLogProbMetric: 178.2043 - val_loss: 180.3560 - val_MinusLogProbMetric: 180.3560 - lr: 2.5000e-04 - 68s/epoch - 348ms/step
Epoch 276/1000
2023-10-01 13:12:56.207 
Epoch 276/1000 
	 loss: 178.2056, MinusLogProbMetric: 178.2056, val_loss: 180.3749, val_MinusLogProbMetric: 180.3749

Epoch 276: val_loss did not improve from 180.35596
196/196 - 61s - loss: 178.2056 - MinusLogProbMetric: 178.2056 - val_loss: 180.3749 - val_MinusLogProbMetric: 180.3749 - lr: 2.5000e-04 - 61s/epoch - 312ms/step
Epoch 277/1000
2023-10-01 13:14:03.087 
Epoch 277/1000 
	 loss: 178.2080, MinusLogProbMetric: 178.2080, val_loss: 180.3810, val_MinusLogProbMetric: 180.3810

Epoch 277: val_loss did not improve from 180.35596
196/196 - 67s - loss: 178.2080 - MinusLogProbMetric: 178.2080 - val_loss: 180.3810 - val_MinusLogProbMetric: 180.3810 - lr: 2.5000e-04 - 67s/epoch - 341ms/step
Epoch 278/1000
2023-10-01 13:15:03.912 
Epoch 278/1000 
	 loss: 178.2117, MinusLogProbMetric: 178.2117, val_loss: 180.3220, val_MinusLogProbMetric: 180.3220

Epoch 278: val_loss improved from 180.35596 to 180.32204, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_290/weights/best_weights.h5
196/196 - 61s - loss: 178.2117 - MinusLogProbMetric: 178.2117 - val_loss: 180.3220 - val_MinusLogProbMetric: 180.3220 - lr: 2.5000e-04 - 61s/epoch - 313ms/step
Epoch 279/1000
2023-10-01 13:16:05.392 
Epoch 279/1000 
	 loss: 178.2341, MinusLogProbMetric: 178.2341, val_loss: 180.9163, val_MinusLogProbMetric: 180.9163

Epoch 279: val_loss did not improve from 180.32204
196/196 - 61s - loss: 178.2341 - MinusLogProbMetric: 178.2341 - val_loss: 180.9163 - val_MinusLogProbMetric: 180.9163 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 280/1000
2023-10-01 13:17:05.110 
Epoch 280/1000 
	 loss: 178.2407, MinusLogProbMetric: 178.2407, val_loss: 180.4256, val_MinusLogProbMetric: 180.4256

Epoch 280: val_loss did not improve from 180.32204
196/196 - 60s - loss: 178.2407 - MinusLogProbMetric: 178.2407 - val_loss: 180.4256 - val_MinusLogProbMetric: 180.4256 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 281/1000
2023-10-01 13:18:06.589 
Epoch 281/1000 
	 loss: 178.1859, MinusLogProbMetric: 178.1859, val_loss: 180.3405, val_MinusLogProbMetric: 180.3405

Epoch 281: val_loss did not improve from 180.32204
196/196 - 61s - loss: 178.1859 - MinusLogProbMetric: 178.1859 - val_loss: 180.3405 - val_MinusLogProbMetric: 180.3405 - lr: 2.5000e-04 - 61s/epoch - 314ms/step
Epoch 282/1000
2023-10-01 13:19:06.870 
Epoch 282/1000 
	 loss: 178.2768, MinusLogProbMetric: 178.2768, val_loss: 180.3434, val_MinusLogProbMetric: 180.3434

Epoch 282: val_loss did not improve from 180.32204
196/196 - 60s - loss: 178.2768 - MinusLogProbMetric: 178.2768 - val_loss: 180.3434 - val_MinusLogProbMetric: 180.3434 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 283/1000
2023-10-01 13:20:06.229 
Epoch 283/1000 
	 loss: 178.2510, MinusLogProbMetric: 178.2510, val_loss: 180.3388, val_MinusLogProbMetric: 180.3388

Epoch 283: val_loss did not improve from 180.32204
196/196 - 59s - loss: 178.2510 - MinusLogProbMetric: 178.2510 - val_loss: 180.3388 - val_MinusLogProbMetric: 180.3388 - lr: 2.5000e-04 - 59s/epoch - 303ms/step
Epoch 284/1000
2023-10-01 13:21:06.110 
Epoch 284/1000 
	 loss: 178.1990, MinusLogProbMetric: 178.1990, val_loss: 180.3443, val_MinusLogProbMetric: 180.3443

Epoch 284: val_loss did not improve from 180.32204
196/196 - 60s - loss: 178.1990 - MinusLogProbMetric: 178.1990 - val_loss: 180.3443 - val_MinusLogProbMetric: 180.3443 - lr: 2.5000e-04 - 60s/epoch - 305ms/step
Epoch 285/1000
2023-10-01 13:22:07.393 
Epoch 285/1000 
	 loss: 178.2203, MinusLogProbMetric: 178.2203, val_loss: 180.3756, val_MinusLogProbMetric: 180.3756

Epoch 285: val_loss did not improve from 180.32204
196/196 - 61s - loss: 178.2203 - MinusLogProbMetric: 178.2203 - val_loss: 180.3756 - val_MinusLogProbMetric: 180.3756 - lr: 2.5000e-04 - 61s/epoch - 313ms/step
Epoch 286/1000
2023-10-01 13:23:08.673 
Epoch 286/1000 
	 loss: 178.2331, MinusLogProbMetric: 178.2331, val_loss: 180.7437, val_MinusLogProbMetric: 180.7437

Epoch 286: val_loss did not improve from 180.32204
196/196 - 61s - loss: 178.2331 - MinusLogProbMetric: 178.2331 - val_loss: 180.7437 - val_MinusLogProbMetric: 180.7437 - lr: 2.5000e-04 - 61s/epoch - 312ms/step
Epoch 287/1000
2023-10-01 13:24:11.790 
Epoch 287/1000 
	 loss: 178.2205, MinusLogProbMetric: 178.2205, val_loss: 180.3842, val_MinusLogProbMetric: 180.3842

Epoch 287: val_loss did not improve from 180.32204
196/196 - 63s - loss: 178.2205 - MinusLogProbMetric: 178.2205 - val_loss: 180.3842 - val_MinusLogProbMetric: 180.3842 - lr: 2.5000e-04 - 63s/epoch - 322ms/step
Epoch 288/1000
2023-10-01 13:25:11.146 
Epoch 288/1000 
	 loss: 178.2489, MinusLogProbMetric: 178.2489, val_loss: 180.3405, val_MinusLogProbMetric: 180.3405

Epoch 288: val_loss did not improve from 180.32204
196/196 - 59s - loss: 178.2489 - MinusLogProbMetric: 178.2489 - val_loss: 180.3405 - val_MinusLogProbMetric: 180.3405 - lr: 2.5000e-04 - 59s/epoch - 303ms/step
Epoch 289/1000
2023-10-01 13:26:13.352 
Epoch 289/1000 
	 loss: 178.2087, MinusLogProbMetric: 178.2087, val_loss: 180.4782, val_MinusLogProbMetric: 180.4782

Epoch 289: val_loss did not improve from 180.32204
196/196 - 62s - loss: 178.2087 - MinusLogProbMetric: 178.2087 - val_loss: 180.4782 - val_MinusLogProbMetric: 180.4782 - lr: 2.5000e-04 - 62s/epoch - 317ms/step
Epoch 290/1000
2023-10-01 13:27:12.848 
Epoch 290/1000 
	 loss: 178.1968, MinusLogProbMetric: 178.1968, val_loss: 180.5581, val_MinusLogProbMetric: 180.5581

Epoch 290: val_loss did not improve from 180.32204
196/196 - 59s - loss: 178.1968 - MinusLogProbMetric: 178.1968 - val_loss: 180.5581 - val_MinusLogProbMetric: 180.5581 - lr: 2.5000e-04 - 59s/epoch - 304ms/step
Epoch 291/1000
2023-10-01 13:28:17.359 
Epoch 291/1000 
	 loss: 178.2686, MinusLogProbMetric: 178.2686, val_loss: 180.4249, val_MinusLogProbMetric: 180.4249

Epoch 291: val_loss did not improve from 180.32204
196/196 - 64s - loss: 178.2686 - MinusLogProbMetric: 178.2686 - val_loss: 180.4249 - val_MinusLogProbMetric: 180.4249 - lr: 2.5000e-04 - 64s/epoch - 329ms/step
Epoch 292/1000
2023-10-01 13:29:13.348 
Epoch 292/1000 
	 loss: 178.1907, MinusLogProbMetric: 178.1907, val_loss: 180.3704, val_MinusLogProbMetric: 180.3704

Epoch 292: val_loss did not improve from 180.32204
196/196 - 56s - loss: 178.1907 - MinusLogProbMetric: 178.1907 - val_loss: 180.3704 - val_MinusLogProbMetric: 180.3704 - lr: 2.5000e-04 - 56s/epoch - 286ms/step
Epoch 293/1000
2023-10-01 13:30:13.841 
Epoch 293/1000 
	 loss: 178.2176, MinusLogProbMetric: 178.2176, val_loss: 180.5221, val_MinusLogProbMetric: 180.5221

Epoch 293: val_loss did not improve from 180.32204
196/196 - 60s - loss: 178.2176 - MinusLogProbMetric: 178.2176 - val_loss: 180.5221 - val_MinusLogProbMetric: 180.5221 - lr: 2.5000e-04 - 60s/epoch - 309ms/step
Epoch 294/1000
2023-10-01 13:31:14.997 
Epoch 294/1000 
	 loss: 178.2252, MinusLogProbMetric: 178.2252, val_loss: 180.3914, val_MinusLogProbMetric: 180.3914

Epoch 294: val_loss did not improve from 180.32204
196/196 - 61s - loss: 178.2252 - MinusLogProbMetric: 178.2252 - val_loss: 180.3914 - val_MinusLogProbMetric: 180.3914 - lr: 2.5000e-04 - 61s/epoch - 312ms/step
Epoch 295/1000
2023-10-01 13:32:17.115 
Epoch 295/1000 
	 loss: 178.2555, MinusLogProbMetric: 178.2555, val_loss: 180.6151, val_MinusLogProbMetric: 180.6151

Epoch 295: val_loss did not improve from 180.32204
196/196 - 62s - loss: 178.2555 - MinusLogProbMetric: 178.2555 - val_loss: 180.6151 - val_MinusLogProbMetric: 180.6151 - lr: 2.5000e-04 - 62s/epoch - 317ms/step
Epoch 296/1000
2023-10-01 13:33:18.179 
Epoch 296/1000 
	 loss: 178.1957, MinusLogProbMetric: 178.1957, val_loss: 180.3792, val_MinusLogProbMetric: 180.3792

Epoch 296: val_loss did not improve from 180.32204
196/196 - 61s - loss: 178.1957 - MinusLogProbMetric: 178.1957 - val_loss: 180.3792 - val_MinusLogProbMetric: 180.3792 - lr: 2.5000e-04 - 61s/epoch - 311ms/step
Epoch 297/1000
2023-10-01 13:34:19.451 
Epoch 297/1000 
	 loss: 178.2557, MinusLogProbMetric: 178.2557, val_loss: 180.3507, val_MinusLogProbMetric: 180.3507

Epoch 297: val_loss did not improve from 180.32204
196/196 - 61s - loss: 178.2557 - MinusLogProbMetric: 178.2557 - val_loss: 180.3507 - val_MinusLogProbMetric: 180.3507 - lr: 2.5000e-04 - 61s/epoch - 312ms/step
Epoch 298/1000
2023-10-01 13:35:21.324 
Epoch 298/1000 
	 loss: 178.2257, MinusLogProbMetric: 178.2257, val_loss: 180.5515, val_MinusLogProbMetric: 180.5515

Epoch 298: val_loss did not improve from 180.32204
196/196 - 62s - loss: 178.2257 - MinusLogProbMetric: 178.2257 - val_loss: 180.5515 - val_MinusLogProbMetric: 180.5515 - lr: 2.5000e-04 - 62s/epoch - 316ms/step
Epoch 299/1000
2023-10-01 13:36:28.645 
Epoch 299/1000 
	 loss: 178.1986, MinusLogProbMetric: 178.1986, val_loss: 180.4910, val_MinusLogProbMetric: 180.4910

Epoch 299: val_loss did not improve from 180.32204
196/196 - 67s - loss: 178.1986 - MinusLogProbMetric: 178.1986 - val_loss: 180.4910 - val_MinusLogProbMetric: 180.4910 - lr: 2.5000e-04 - 67s/epoch - 343ms/step
Epoch 300/1000
2023-10-01 13:37:31.029 
Epoch 300/1000 
	 loss: 178.2193, MinusLogProbMetric: 178.2193, val_loss: 180.4266, val_MinusLogProbMetric: 180.4266

Epoch 300: val_loss did not improve from 180.32204
196/196 - 62s - loss: 178.2193 - MinusLogProbMetric: 178.2193 - val_loss: 180.4266 - val_MinusLogProbMetric: 180.4266 - lr: 2.5000e-04 - 62s/epoch - 318ms/step
Epoch 301/1000
2023-10-01 13:38:28.319 
Epoch 301/1000 
	 loss: 178.2858, MinusLogProbMetric: 178.2858, val_loss: 180.4753, val_MinusLogProbMetric: 180.4753

Epoch 301: val_loss did not improve from 180.32204
196/196 - 57s - loss: 178.2858 - MinusLogProbMetric: 178.2858 - val_loss: 180.4753 - val_MinusLogProbMetric: 180.4753 - lr: 2.5000e-04 - 57s/epoch - 292ms/step
Epoch 302/1000
2023-10-01 13:39:27.332 
Epoch 302/1000 
	 loss: 178.1891, MinusLogProbMetric: 178.1891, val_loss: 180.4720, val_MinusLogProbMetric: 180.4720

Epoch 302: val_loss did not improve from 180.32204
196/196 - 59s - loss: 178.1891 - MinusLogProbMetric: 178.1891 - val_loss: 180.4720 - val_MinusLogProbMetric: 180.4720 - lr: 2.5000e-04 - 59s/epoch - 301ms/step
Epoch 303/1000
2023-10-01 13:40:26.818 
Epoch 303/1000 
	 loss: 178.1922, MinusLogProbMetric: 178.1922, val_loss: 180.4169, val_MinusLogProbMetric: 180.4169

Epoch 303: val_loss did not improve from 180.32204
196/196 - 59s - loss: 178.1922 - MinusLogProbMetric: 178.1922 - val_loss: 180.4169 - val_MinusLogProbMetric: 180.4169 - lr: 2.5000e-04 - 59s/epoch - 303ms/step
Epoch 304/1000
2023-10-01 13:41:26.709 
Epoch 304/1000 
	 loss: 178.1976, MinusLogProbMetric: 178.1976, val_loss: 180.4258, val_MinusLogProbMetric: 180.4258

Epoch 304: val_loss did not improve from 180.32204
196/196 - 60s - loss: 178.1976 - MinusLogProbMetric: 178.1976 - val_loss: 180.4258 - val_MinusLogProbMetric: 180.4258 - lr: 2.5000e-04 - 60s/epoch - 306ms/step
Epoch 305/1000
2023-10-01 13:42:25.610 
Epoch 305/1000 
	 loss: 178.1855, MinusLogProbMetric: 178.1855, val_loss: 180.4228, val_MinusLogProbMetric: 180.4228

Epoch 305: val_loss did not improve from 180.32204
196/196 - 59s - loss: 178.1855 - MinusLogProbMetric: 178.1855 - val_loss: 180.4228 - val_MinusLogProbMetric: 180.4228 - lr: 2.5000e-04 - 59s/epoch - 300ms/step
Epoch 306/1000
2023-10-01 13:43:27.939 
Epoch 306/1000 
	 loss: 178.2549, MinusLogProbMetric: 178.2549, val_loss: 180.4250, val_MinusLogProbMetric: 180.4250

Epoch 306: val_loss did not improve from 180.32204
196/196 - 62s - loss: 178.2549 - MinusLogProbMetric: 178.2549 - val_loss: 180.4250 - val_MinusLogProbMetric: 180.4250 - lr: 2.5000e-04 - 62s/epoch - 318ms/step
Epoch 307/1000
2023-10-01 13:44:29.406 
Epoch 307/1000 
	 loss: 178.2351, MinusLogProbMetric: 178.2351, val_loss: 180.4457, val_MinusLogProbMetric: 180.4457

Epoch 307: val_loss did not improve from 180.32204
196/196 - 61s - loss: 178.2351 - MinusLogProbMetric: 178.2351 - val_loss: 180.4457 - val_MinusLogProbMetric: 180.4457 - lr: 2.5000e-04 - 61s/epoch - 314ms/step
Epoch 308/1000
2023-10-01 13:45:36.928 
Epoch 308/1000 
	 loss: 178.1503, MinusLogProbMetric: 178.1503, val_loss: 180.8920, val_MinusLogProbMetric: 180.8920

Epoch 308: val_loss did not improve from 180.32204
196/196 - 67s - loss: 178.1503 - MinusLogProbMetric: 178.1503 - val_loss: 180.8920 - val_MinusLogProbMetric: 180.8920 - lr: 2.5000e-04 - 67s/epoch - 344ms/step
Epoch 309/1000
2023-10-01 13:46:37.554 
Epoch 309/1000 
	 loss: 178.2131, MinusLogProbMetric: 178.2131, val_loss: 180.4055, val_MinusLogProbMetric: 180.4055

Epoch 309: val_loss did not improve from 180.32204
196/196 - 61s - loss: 178.2131 - MinusLogProbMetric: 178.2131 - val_loss: 180.4055 - val_MinusLogProbMetric: 180.4055 - lr: 2.5000e-04 - 61s/epoch - 309ms/step
Epoch 310/1000
2023-10-01 13:47:38.042 
Epoch 310/1000 
	 loss: 178.1425, MinusLogProbMetric: 178.1425, val_loss: 180.3664, val_MinusLogProbMetric: 180.3664

Epoch 310: val_loss did not improve from 180.32204
196/196 - 60s - loss: 178.1425 - MinusLogProbMetric: 178.1425 - val_loss: 180.3664 - val_MinusLogProbMetric: 180.3664 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 311/1000
2023-10-01 13:48:39.903 
Epoch 311/1000 
	 loss: 178.1601, MinusLogProbMetric: 178.1601, val_loss: 180.4478, val_MinusLogProbMetric: 180.4478

Epoch 311: val_loss did not improve from 180.32204
196/196 - 62s - loss: 178.1601 - MinusLogProbMetric: 178.1601 - val_loss: 180.4478 - val_MinusLogProbMetric: 180.4478 - lr: 2.5000e-04 - 62s/epoch - 316ms/step
Epoch 312/1000
2023-10-01 13:49:41.153 
Epoch 312/1000 
	 loss: 178.1759, MinusLogProbMetric: 178.1759, val_loss: 180.4214, val_MinusLogProbMetric: 180.4214

Epoch 312: val_loss did not improve from 180.32204
196/196 - 61s - loss: 178.1759 - MinusLogProbMetric: 178.1759 - val_loss: 180.4214 - val_MinusLogProbMetric: 180.4214 - lr: 2.5000e-04 - 61s/epoch - 312ms/step
Epoch 313/1000
2023-10-01 13:50:43.213 
Epoch 313/1000 
	 loss: 178.2857, MinusLogProbMetric: 178.2857, val_loss: 180.4815, val_MinusLogProbMetric: 180.4815

Epoch 313: val_loss did not improve from 180.32204
196/196 - 62s - loss: 178.2857 - MinusLogProbMetric: 178.2857 - val_loss: 180.4815 - val_MinusLogProbMetric: 180.4815 - lr: 2.5000e-04 - 62s/epoch - 317ms/step
Epoch 314/1000
2023-10-01 13:51:43.630 
Epoch 314/1000 
	 loss: 178.1504, MinusLogProbMetric: 178.1504, val_loss: 180.4209, val_MinusLogProbMetric: 180.4209

Epoch 314: val_loss did not improve from 180.32204
196/196 - 60s - loss: 178.1504 - MinusLogProbMetric: 178.1504 - val_loss: 180.4209 - val_MinusLogProbMetric: 180.4209 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 315/1000
2023-10-01 13:52:46.033 
Epoch 315/1000 
	 loss: 178.2153, MinusLogProbMetric: 178.2153, val_loss: 180.5153, val_MinusLogProbMetric: 180.5153

Epoch 315: val_loss did not improve from 180.32204
196/196 - 62s - loss: 178.2153 - MinusLogProbMetric: 178.2153 - val_loss: 180.5153 - val_MinusLogProbMetric: 180.5153 - lr: 2.5000e-04 - 62s/epoch - 318ms/step
Epoch 316/1000
2023-10-01 13:53:47.476 
Epoch 316/1000 
	 loss: 178.2141, MinusLogProbMetric: 178.2141, val_loss: 180.4572, val_MinusLogProbMetric: 180.4572

Epoch 316: val_loss did not improve from 180.32204
196/196 - 61s - loss: 178.2141 - MinusLogProbMetric: 178.2141 - val_loss: 180.4572 - val_MinusLogProbMetric: 180.4572 - lr: 2.5000e-04 - 61s/epoch - 313ms/step
Epoch 317/1000
2023-10-01 13:54:47.766 
Epoch 317/1000 
	 loss: 178.1365, MinusLogProbMetric: 178.1365, val_loss: 180.4303, val_MinusLogProbMetric: 180.4303

Epoch 317: val_loss did not improve from 180.32204
196/196 - 60s - loss: 178.1365 - MinusLogProbMetric: 178.1365 - val_loss: 180.4303 - val_MinusLogProbMetric: 180.4303 - lr: 2.5000e-04 - 60s/epoch - 308ms/step
Epoch 318/1000
2023-10-01 13:55:52.855 
Epoch 318/1000 
	 loss: 178.2564, MinusLogProbMetric: 178.2564, val_loss: 180.4608, val_MinusLogProbMetric: 180.4608

Epoch 318: val_loss did not improve from 180.32204
196/196 - 65s - loss: 178.2564 - MinusLogProbMetric: 178.2564 - val_loss: 180.4608 - val_MinusLogProbMetric: 180.4608 - lr: 2.5000e-04 - 65s/epoch - 332ms/step
Epoch 319/1000
2023-10-01 13:56:48.488 
Epoch 319/1000 
	 loss: 178.1832, MinusLogProbMetric: 178.1832, val_loss: 180.5456, val_MinusLogProbMetric: 180.5456

Epoch 319: val_loss did not improve from 180.32204
196/196 - 56s - loss: 178.1832 - MinusLogProbMetric: 178.1832 - val_loss: 180.5456 - val_MinusLogProbMetric: 180.5456 - lr: 2.5000e-04 - 56s/epoch - 284ms/step
Epoch 320/1000
2023-10-01 13:57:46.124 
Epoch 320/1000 
	 loss: 178.2187, MinusLogProbMetric: 178.2187, val_loss: 180.7057, val_MinusLogProbMetric: 180.7057

Epoch 320: val_loss did not improve from 180.32204
196/196 - 58s - loss: 178.2187 - MinusLogProbMetric: 178.2187 - val_loss: 180.7057 - val_MinusLogProbMetric: 180.7057 - lr: 2.5000e-04 - 58s/epoch - 294ms/step
Epoch 321/1000
2023-10-01 13:58:43.158 
Epoch 321/1000 
	 loss: 178.2165, MinusLogProbMetric: 178.2165, val_loss: 180.4767, val_MinusLogProbMetric: 180.4767

Epoch 321: val_loss did not improve from 180.32204
196/196 - 57s - loss: 178.2165 - MinusLogProbMetric: 178.2165 - val_loss: 180.4767 - val_MinusLogProbMetric: 180.4767 - lr: 2.5000e-04 - 57s/epoch - 291ms/step
Epoch 322/1000
2023-10-01 13:59:38.674 
Epoch 322/1000 
	 loss: 178.1182, MinusLogProbMetric: 178.1182, val_loss: 180.4577, val_MinusLogProbMetric: 180.4577

Epoch 322: val_loss did not improve from 180.32204
196/196 - 56s - loss: 178.1182 - MinusLogProbMetric: 178.1182 - val_loss: 180.4577 - val_MinusLogProbMetric: 180.4577 - lr: 2.5000e-04 - 56s/epoch - 283ms/step
Epoch 323/1000
2023-10-01 14:00:37.043 
Epoch 323/1000 
	 loss: 178.1414, MinusLogProbMetric: 178.1414, val_loss: 180.7133, val_MinusLogProbMetric: 180.7133

Epoch 323: val_loss did not improve from 180.32204
196/196 - 58s - loss: 178.1414 - MinusLogProbMetric: 178.1414 - val_loss: 180.7133 - val_MinusLogProbMetric: 180.7133 - lr: 2.5000e-04 - 58s/epoch - 298ms/step
Epoch 324/1000
2023-10-01 14:01:34.745 
Epoch 324/1000 
	 loss: 178.1474, MinusLogProbMetric: 178.1474, val_loss: 180.5932, val_MinusLogProbMetric: 180.5932

Epoch 324: val_loss did not improve from 180.32204
196/196 - 58s - loss: 178.1474 - MinusLogProbMetric: 178.1474 - val_loss: 180.5932 - val_MinusLogProbMetric: 180.5932 - lr: 2.5000e-04 - 58s/epoch - 294ms/step
Epoch 325/1000
2023-10-01 14:02:27.923 
Epoch 325/1000 
	 loss: 178.1535, MinusLogProbMetric: 178.1535, val_loss: 180.4480, val_MinusLogProbMetric: 180.4480

Epoch 325: val_loss did not improve from 180.32204
196/196 - 53s - loss: 178.1535 - MinusLogProbMetric: 178.1535 - val_loss: 180.4480 - val_MinusLogProbMetric: 180.4480 - lr: 2.5000e-04 - 53s/epoch - 271ms/step
Epoch 326/1000
2023-10-01 14:03:24.716 
Epoch 326/1000 
	 loss: 178.2848, MinusLogProbMetric: 178.2848, val_loss: 180.4528, val_MinusLogProbMetric: 180.4528

Epoch 326: val_loss did not improve from 180.32204
196/196 - 57s - loss: 178.2848 - MinusLogProbMetric: 178.2848 - val_loss: 180.4528 - val_MinusLogProbMetric: 180.4528 - lr: 2.5000e-04 - 57s/epoch - 290ms/step
Epoch 327/1000
2023-10-01 14:04:21.405 
Epoch 327/1000 
	 loss: 178.1374, MinusLogProbMetric: 178.1374, val_loss: 180.6281, val_MinusLogProbMetric: 180.6281

Epoch 327: val_loss did not improve from 180.32204
196/196 - 57s - loss: 178.1374 - MinusLogProbMetric: 178.1374 - val_loss: 180.6281 - val_MinusLogProbMetric: 180.6281 - lr: 2.5000e-04 - 57s/epoch - 289ms/step
Epoch 328/1000
2023-10-01 14:05:18.331 
Epoch 328/1000 
	 loss: 178.3024, MinusLogProbMetric: 178.3024, val_loss: 180.7628, val_MinusLogProbMetric: 180.7628

Epoch 328: val_loss did not improve from 180.32204
196/196 - 57s - loss: 178.3024 - MinusLogProbMetric: 178.3024 - val_loss: 180.7628 - val_MinusLogProbMetric: 180.7628 - lr: 2.5000e-04 - 57s/epoch - 290ms/step
Epoch 329/1000
2023-10-01 14:06:17.825 
Epoch 329/1000 
	 loss: 177.9922, MinusLogProbMetric: 177.9922, val_loss: 180.3659, val_MinusLogProbMetric: 180.3659

Epoch 329: val_loss did not improve from 180.32204
196/196 - 59s - loss: 177.9922 - MinusLogProbMetric: 177.9922 - val_loss: 180.3659 - val_MinusLogProbMetric: 180.3659 - lr: 1.2500e-04 - 59s/epoch - 303ms/step
Epoch 330/1000
2023-10-01 14:07:10.317 
Epoch 330/1000 
	 loss: 177.9685, MinusLogProbMetric: 177.9685, val_loss: 180.3246, val_MinusLogProbMetric: 180.3246

Epoch 330: val_loss did not improve from 180.32204
196/196 - 53s - loss: 177.9685 - MinusLogProbMetric: 177.9685 - val_loss: 180.3246 - val_MinusLogProbMetric: 180.3246 - lr: 1.2500e-04 - 53s/epoch - 268ms/step
Epoch 331/1000
2023-10-01 14:08:05.897 
Epoch 331/1000 
	 loss: 177.9685, MinusLogProbMetric: 177.9685, val_loss: 180.3511, val_MinusLogProbMetric: 180.3511

Epoch 331: val_loss did not improve from 180.32204
196/196 - 56s - loss: 177.9685 - MinusLogProbMetric: 177.9685 - val_loss: 180.3511 - val_MinusLogProbMetric: 180.3511 - lr: 1.2500e-04 - 56s/epoch - 283ms/step
Epoch 332/1000
2023-10-01 14:09:01.647 
Epoch 332/1000 
	 loss: 177.9604, MinusLogProbMetric: 177.9604, val_loss: 180.3519, val_MinusLogProbMetric: 180.3519

Epoch 332: val_loss did not improve from 180.32204
196/196 - 56s - loss: 177.9604 - MinusLogProbMetric: 177.9604 - val_loss: 180.3519 - val_MinusLogProbMetric: 180.3519 - lr: 1.2500e-04 - 56s/epoch - 284ms/step
Epoch 333/1000
2023-10-01 14:09:59.804 
Epoch 333/1000 
	 loss: 177.9626, MinusLogProbMetric: 177.9626, val_loss: 180.3525, val_MinusLogProbMetric: 180.3525

Epoch 333: val_loss did not improve from 180.32204
196/196 - 58s - loss: 177.9626 - MinusLogProbMetric: 177.9626 - val_loss: 180.3525 - val_MinusLogProbMetric: 180.3525 - lr: 1.2500e-04 - 58s/epoch - 297ms/step
Epoch 334/1000
2023-10-01 14:10:58.371 
Epoch 334/1000 
	 loss: 177.9626, MinusLogProbMetric: 177.9626, val_loss: 180.3506, val_MinusLogProbMetric: 180.3506

Epoch 334: val_loss did not improve from 180.32204
196/196 - 59s - loss: 177.9626 - MinusLogProbMetric: 177.9626 - val_loss: 180.3506 - val_MinusLogProbMetric: 180.3506 - lr: 1.2500e-04 - 59s/epoch - 299ms/step
Epoch 335/1000
2023-10-01 14:12:00.309 
Epoch 335/1000 
	 loss: 177.9575, MinusLogProbMetric: 177.9575, val_loss: 180.3672, val_MinusLogProbMetric: 180.3672

Epoch 335: val_loss did not improve from 180.32204
196/196 - 62s - loss: 177.9575 - MinusLogProbMetric: 177.9575 - val_loss: 180.3672 - val_MinusLogProbMetric: 180.3672 - lr: 1.2500e-04 - 62s/epoch - 316ms/step
Epoch 336/1000
2023-10-01 14:13:00.706 
Epoch 336/1000 
	 loss: 177.9519, MinusLogProbMetric: 177.9519, val_loss: 180.3940, val_MinusLogProbMetric: 180.3940

Epoch 336: val_loss did not improve from 180.32204
196/196 - 60s - loss: 177.9519 - MinusLogProbMetric: 177.9519 - val_loss: 180.3940 - val_MinusLogProbMetric: 180.3940 - lr: 1.2500e-04 - 60s/epoch - 308ms/step
Epoch 337/1000
2023-10-01 14:14:01.893 
Epoch 337/1000 
	 loss: 177.9593, MinusLogProbMetric: 177.9593, val_loss: 180.3915, val_MinusLogProbMetric: 180.3915

Epoch 337: val_loss did not improve from 180.32204
196/196 - 61s - loss: 177.9593 - MinusLogProbMetric: 177.9593 - val_loss: 180.3915 - val_MinusLogProbMetric: 180.3915 - lr: 1.2500e-04 - 61s/epoch - 312ms/step
Epoch 338/1000
2023-10-01 14:14:59.258 
Epoch 338/1000 
	 loss: 177.9588, MinusLogProbMetric: 177.9588, val_loss: 180.5136, val_MinusLogProbMetric: 180.5136

Epoch 338: val_loss did not improve from 180.32204
196/196 - 57s - loss: 177.9588 - MinusLogProbMetric: 177.9588 - val_loss: 180.5136 - val_MinusLogProbMetric: 180.5136 - lr: 1.2500e-04 - 57s/epoch - 293ms/step
Epoch 339/1000
2023-10-01 14:15:56.295 
Epoch 339/1000 
	 loss: 177.9745, MinusLogProbMetric: 177.9745, val_loss: 180.3618, val_MinusLogProbMetric: 180.3618

Epoch 339: val_loss did not improve from 180.32204
196/196 - 57s - loss: 177.9745 - MinusLogProbMetric: 177.9745 - val_loss: 180.3618 - val_MinusLogProbMetric: 180.3618 - lr: 1.2500e-04 - 57s/epoch - 291ms/step
Epoch 340/1000
2023-10-01 14:16:58.652 
Epoch 340/1000 
	 loss: 177.9511, MinusLogProbMetric: 177.9511, val_loss: 180.3705, val_MinusLogProbMetric: 180.3705

Epoch 340: val_loss did not improve from 180.32204
196/196 - 62s - loss: 177.9511 - MinusLogProbMetric: 177.9511 - val_loss: 180.3705 - val_MinusLogProbMetric: 180.3705 - lr: 1.2500e-04 - 62s/epoch - 318ms/step
Epoch 341/1000
2023-10-01 14:17:55.085 
Epoch 341/1000 
	 loss: 177.9513, MinusLogProbMetric: 177.9513, val_loss: 180.3790, val_MinusLogProbMetric: 180.3790

Epoch 341: val_loss did not improve from 180.32204
196/196 - 56s - loss: 177.9513 - MinusLogProbMetric: 177.9513 - val_loss: 180.3790 - val_MinusLogProbMetric: 180.3790 - lr: 1.2500e-04 - 56s/epoch - 288ms/step
Epoch 342/1000
2023-10-01 14:18:52.102 
Epoch 342/1000 
	 loss: 177.9455, MinusLogProbMetric: 177.9455, val_loss: 180.3695, val_MinusLogProbMetric: 180.3695

Epoch 342: val_loss did not improve from 180.32204
196/196 - 57s - loss: 177.9455 - MinusLogProbMetric: 177.9455 - val_loss: 180.3695 - val_MinusLogProbMetric: 180.3695 - lr: 1.2500e-04 - 57s/epoch - 291ms/step
Epoch 343/1000
2023-10-01 14:19:47.299 
Epoch 343/1000 
	 loss: 177.9675, MinusLogProbMetric: 177.9675, val_loss: 180.3919, val_MinusLogProbMetric: 180.3919

Epoch 343: val_loss did not improve from 180.32204
196/196 - 55s - loss: 177.9675 - MinusLogProbMetric: 177.9675 - val_loss: 180.3919 - val_MinusLogProbMetric: 180.3919 - lr: 1.2500e-04 - 55s/epoch - 282ms/step
Epoch 344/1000
2023-10-01 14:20:43.591 
Epoch 344/1000 
	 loss: 177.9538, MinusLogProbMetric: 177.9538, val_loss: 180.3441, val_MinusLogProbMetric: 180.3441

Epoch 344: val_loss did not improve from 180.32204
196/196 - 56s - loss: 177.9538 - MinusLogProbMetric: 177.9538 - val_loss: 180.3441 - val_MinusLogProbMetric: 180.3441 - lr: 1.2500e-04 - 56s/epoch - 287ms/step
Epoch 345/1000
2023-10-01 14:21:38.141 
Epoch 345/1000 
	 loss: 177.9581, MinusLogProbMetric: 177.9581, val_loss: 180.3780, val_MinusLogProbMetric: 180.3780

Epoch 345: val_loss did not improve from 180.32204
196/196 - 55s - loss: 177.9581 - MinusLogProbMetric: 177.9581 - val_loss: 180.3780 - val_MinusLogProbMetric: 180.3780 - lr: 1.2500e-04 - 55s/epoch - 278ms/step
Epoch 346/1000
2023-10-01 14:22:37.171 
Epoch 346/1000 
	 loss: 177.9401, MinusLogProbMetric: 177.9401, val_loss: 180.3672, val_MinusLogProbMetric: 180.3672

Epoch 346: val_loss did not improve from 180.32204
196/196 - 59s - loss: 177.9401 - MinusLogProbMetric: 177.9401 - val_loss: 180.3672 - val_MinusLogProbMetric: 180.3672 - lr: 1.2500e-04 - 59s/epoch - 301ms/step
Epoch 347/1000
2023-10-01 14:23:36.968 
Epoch 347/1000 
	 loss: 177.9451, MinusLogProbMetric: 177.9451, val_loss: 180.3500, val_MinusLogProbMetric: 180.3500

Epoch 347: val_loss did not improve from 180.32204
196/196 - 60s - loss: 177.9451 - MinusLogProbMetric: 177.9451 - val_loss: 180.3500 - val_MinusLogProbMetric: 180.3500 - lr: 1.2500e-04 - 60s/epoch - 305ms/step
Epoch 348/1000
2023-10-01 14:24:33.348 
Epoch 348/1000 
	 loss: 177.9549, MinusLogProbMetric: 177.9549, val_loss: 180.3753, val_MinusLogProbMetric: 180.3753

Epoch 348: val_loss did not improve from 180.32204
196/196 - 56s - loss: 177.9549 - MinusLogProbMetric: 177.9549 - val_loss: 180.3753 - val_MinusLogProbMetric: 180.3753 - lr: 1.2500e-04 - 56s/epoch - 288ms/step
Epoch 349/1000
2023-10-01 14:25:29.255 
Epoch 349/1000 
	 loss: 177.9424, MinusLogProbMetric: 177.9424, val_loss: 180.3686, val_MinusLogProbMetric: 180.3686

Epoch 349: val_loss did not improve from 180.32204
196/196 - 56s - loss: 177.9424 - MinusLogProbMetric: 177.9424 - val_loss: 180.3686 - val_MinusLogProbMetric: 180.3686 - lr: 1.2500e-04 - 56s/epoch - 285ms/step
Epoch 350/1000
2023-10-01 14:26:27.432 
Epoch 350/1000 
	 loss: 177.9550, MinusLogProbMetric: 177.9550, val_loss: 180.4038, val_MinusLogProbMetric: 180.4038

Epoch 350: val_loss did not improve from 180.32204
196/196 - 58s - loss: 177.9550 - MinusLogProbMetric: 177.9550 - val_loss: 180.4038 - val_MinusLogProbMetric: 180.4038 - lr: 1.2500e-04 - 58s/epoch - 297ms/step
Epoch 351/1000
2023-10-01 14:27:25.042 
Epoch 351/1000 
	 loss: 177.9670, MinusLogProbMetric: 177.9670, val_loss: 180.3716, val_MinusLogProbMetric: 180.3716

Epoch 351: val_loss did not improve from 180.32204
196/196 - 58s - loss: 177.9670 - MinusLogProbMetric: 177.9670 - val_loss: 180.3716 - val_MinusLogProbMetric: 180.3716 - lr: 1.2500e-04 - 58s/epoch - 294ms/step
Epoch 352/1000
2023-10-01 14:28:22.761 
Epoch 352/1000 
	 loss: 177.9539, MinusLogProbMetric: 177.9539, val_loss: 180.4675, val_MinusLogProbMetric: 180.4675

Epoch 352: val_loss did not improve from 180.32204
196/196 - 58s - loss: 177.9539 - MinusLogProbMetric: 177.9539 - val_loss: 180.4675 - val_MinusLogProbMetric: 180.4675 - lr: 1.2500e-04 - 58s/epoch - 294ms/step
Epoch 353/1000
2023-10-01 14:29:19.188 
Epoch 353/1000 
	 loss: 177.9433, MinusLogProbMetric: 177.9433, val_loss: 180.3646, val_MinusLogProbMetric: 180.3646

Epoch 353: val_loss did not improve from 180.32204
196/196 - 56s - loss: 177.9433 - MinusLogProbMetric: 177.9433 - val_loss: 180.3646 - val_MinusLogProbMetric: 180.3646 - lr: 1.2500e-04 - 56s/epoch - 288ms/step
Epoch 354/1000
2023-10-01 14:30:16.244 
Epoch 354/1000 
	 loss: 177.9465, MinusLogProbMetric: 177.9465, val_loss: 180.3860, val_MinusLogProbMetric: 180.3860

Epoch 354: val_loss did not improve from 180.32204
196/196 - 57s - loss: 177.9465 - MinusLogProbMetric: 177.9465 - val_loss: 180.3860 - val_MinusLogProbMetric: 180.3860 - lr: 1.2500e-04 - 57s/epoch - 291ms/step
Epoch 355/1000
2023-10-01 14:31:15.888 
Epoch 355/1000 
	 loss: 177.9386, MinusLogProbMetric: 177.9386, val_loss: 180.4297, val_MinusLogProbMetric: 180.4297

Epoch 355: val_loss did not improve from 180.32204
196/196 - 60s - loss: 177.9386 - MinusLogProbMetric: 177.9386 - val_loss: 180.4297 - val_MinusLogProbMetric: 180.4297 - lr: 1.2500e-04 - 60s/epoch - 304ms/step
Epoch 356/1000
2023-10-01 14:32:11.592 
Epoch 356/1000 
	 loss: 177.9357, MinusLogProbMetric: 177.9357, val_loss: 180.4624, val_MinusLogProbMetric: 180.4624

Epoch 356: val_loss did not improve from 180.32204
196/196 - 56s - loss: 177.9357 - MinusLogProbMetric: 177.9357 - val_loss: 180.4624 - val_MinusLogProbMetric: 180.4624 - lr: 1.2500e-04 - 56s/epoch - 284ms/step
Epoch 357/1000
2023-10-01 14:32:44.923 
Epoch 357/1000 
	 loss: 177.9392, MinusLogProbMetric: 177.9392, val_loss: 180.4687, val_MinusLogProbMetric: 180.4687

Epoch 357: val_loss did not improve from 180.32204
196/196 - 33s - loss: 177.9392 - MinusLogProbMetric: 177.9392 - val_loss: 180.4687 - val_MinusLogProbMetric: 180.4687 - lr: 1.2500e-04 - 33s/epoch - 170ms/step
Epoch 358/1000
2023-10-01 14:33:44.029 
Epoch 358/1000 
	 loss: 177.9465, MinusLogProbMetric: 177.9465, val_loss: 180.3874, val_MinusLogProbMetric: 180.3874

Epoch 358: val_loss did not improve from 180.32204
196/196 - 59s - loss: 177.9465 - MinusLogProbMetric: 177.9465 - val_loss: 180.3874 - val_MinusLogProbMetric: 180.3874 - lr: 1.2500e-04 - 59s/epoch - 302ms/step
Epoch 359/1000
2023-10-01 14:34:38.600 
Epoch 359/1000 
	 loss: 177.9356, MinusLogProbMetric: 177.9356, val_loss: 180.4393, val_MinusLogProbMetric: 180.4393

Epoch 359: val_loss did not improve from 180.32204
196/196 - 54s - loss: 177.9356 - MinusLogProbMetric: 177.9356 - val_loss: 180.4393 - val_MinusLogProbMetric: 180.4393 - lr: 1.2500e-04 - 54s/epoch - 278ms/step
Epoch 360/1000
2023-10-01 14:35:39.295 
Epoch 360/1000 
	 loss: 177.9379, MinusLogProbMetric: 177.9379, val_loss: 180.4119, val_MinusLogProbMetric: 180.4119

Epoch 360: val_loss did not improve from 180.32204
196/196 - 61s - loss: 177.9379 - MinusLogProbMetric: 177.9379 - val_loss: 180.4119 - val_MinusLogProbMetric: 180.4119 - lr: 1.2500e-04 - 61s/epoch - 310ms/step
Epoch 361/1000
2023-10-01 14:36:36.928 
Epoch 361/1000 
	 loss: 177.9332, MinusLogProbMetric: 177.9332, val_loss: 180.4030, val_MinusLogProbMetric: 180.4030

Epoch 361: val_loss did not improve from 180.32204
196/196 - 58s - loss: 177.9332 - MinusLogProbMetric: 177.9332 - val_loss: 180.4030 - val_MinusLogProbMetric: 180.4030 - lr: 1.2500e-04 - 58s/epoch - 294ms/step
Epoch 362/1000
2023-10-01 14:37:33.920 
Epoch 362/1000 
	 loss: 177.9415, MinusLogProbMetric: 177.9415, val_loss: 180.4976, val_MinusLogProbMetric: 180.4976

Epoch 362: val_loss did not improve from 180.32204
196/196 - 57s - loss: 177.9415 - MinusLogProbMetric: 177.9415 - val_loss: 180.4976 - val_MinusLogProbMetric: 180.4976 - lr: 1.2500e-04 - 57s/epoch - 291ms/step
Epoch 363/1000
2023-10-01 14:38:30.425 
Epoch 363/1000 
	 loss: 177.9417, MinusLogProbMetric: 177.9417, val_loss: 180.4635, val_MinusLogProbMetric: 180.4635

Epoch 363: val_loss did not improve from 180.32204
196/196 - 57s - loss: 177.9417 - MinusLogProbMetric: 177.9417 - val_loss: 180.4635 - val_MinusLogProbMetric: 180.4635 - lr: 1.2500e-04 - 57s/epoch - 288ms/step
Epoch 364/1000
2023-10-01 14:39:26.373 
Epoch 364/1000 
	 loss: 177.9389, MinusLogProbMetric: 177.9389, val_loss: 180.4678, val_MinusLogProbMetric: 180.4678

Epoch 364: val_loss did not improve from 180.32204
196/196 - 56s - loss: 177.9389 - MinusLogProbMetric: 177.9389 - val_loss: 180.4678 - val_MinusLogProbMetric: 180.4678 - lr: 1.2500e-04 - 56s/epoch - 285ms/step
Epoch 365/1000
2023-10-01 14:40:20.781 
Epoch 365/1000 
	 loss: 177.9353, MinusLogProbMetric: 177.9353, val_loss: 180.3658, val_MinusLogProbMetric: 180.3658

Epoch 365: val_loss did not improve from 180.32204
196/196 - 54s - loss: 177.9353 - MinusLogProbMetric: 177.9353 - val_loss: 180.3658 - val_MinusLogProbMetric: 180.3658 - lr: 1.2500e-04 - 54s/epoch - 277ms/step
Epoch 366/1000
2023-10-01 14:41:18.901 
Epoch 366/1000 
	 loss: 177.9432, MinusLogProbMetric: 177.9432, val_loss: 180.3977, val_MinusLogProbMetric: 180.3977

Epoch 366: val_loss did not improve from 180.32204
196/196 - 58s - loss: 177.9432 - MinusLogProbMetric: 177.9432 - val_loss: 180.3977 - val_MinusLogProbMetric: 180.3977 - lr: 1.2500e-04 - 58s/epoch - 296ms/step
Epoch 367/1000
2023-10-01 14:42:13.190 
Epoch 367/1000 
	 loss: 177.9397, MinusLogProbMetric: 177.9397, val_loss: 180.4614, val_MinusLogProbMetric: 180.4614

Epoch 367: val_loss did not improve from 180.32204
196/196 - 54s - loss: 177.9397 - MinusLogProbMetric: 177.9397 - val_loss: 180.4614 - val_MinusLogProbMetric: 180.4614 - lr: 1.2500e-04 - 54s/epoch - 277ms/step
Epoch 368/1000
2023-10-01 14:43:08.569 
Epoch 368/1000 
	 loss: 177.9323, MinusLogProbMetric: 177.9323, val_loss: 180.5295, val_MinusLogProbMetric: 180.5295

Epoch 368: val_loss did not improve from 180.32204
196/196 - 55s - loss: 177.9323 - MinusLogProbMetric: 177.9323 - val_loss: 180.5295 - val_MinusLogProbMetric: 180.5295 - lr: 1.2500e-04 - 55s/epoch - 282ms/step
Epoch 369/1000
2023-10-01 14:44:03.693 
Epoch 369/1000 
	 loss: 177.9332, MinusLogProbMetric: 177.9332, val_loss: 180.4814, val_MinusLogProbMetric: 180.4814

Epoch 369: val_loss did not improve from 180.32204
196/196 - 55s - loss: 177.9332 - MinusLogProbMetric: 177.9332 - val_loss: 180.4814 - val_MinusLogProbMetric: 180.4814 - lr: 1.2500e-04 - 55s/epoch - 281ms/step
Epoch 370/1000
2023-10-01 14:44:59.433 
Epoch 370/1000 
	 loss: 177.9595, MinusLogProbMetric: 177.9595, val_loss: 180.4086, val_MinusLogProbMetric: 180.4086

Epoch 370: val_loss did not improve from 180.32204
196/196 - 56s - loss: 177.9595 - MinusLogProbMetric: 177.9595 - val_loss: 180.4086 - val_MinusLogProbMetric: 180.4086 - lr: 1.2500e-04 - 56s/epoch - 284ms/step
Epoch 371/1000
2023-10-01 14:45:55.489 
Epoch 371/1000 
	 loss: 177.9378, MinusLogProbMetric: 177.9378, val_loss: 180.4512, val_MinusLogProbMetric: 180.4512

Epoch 371: val_loss did not improve from 180.32204
196/196 - 56s - loss: 177.9378 - MinusLogProbMetric: 177.9378 - val_loss: 180.4512 - val_MinusLogProbMetric: 180.4512 - lr: 1.2500e-04 - 56s/epoch - 286ms/step
Epoch 372/1000
2023-10-01 14:46:50.130 
Epoch 372/1000 
	 loss: 177.9480, MinusLogProbMetric: 177.9480, val_loss: 180.3667, val_MinusLogProbMetric: 180.3667

Epoch 372: val_loss did not improve from 180.32204
196/196 - 55s - loss: 177.9480 - MinusLogProbMetric: 177.9480 - val_loss: 180.3667 - val_MinusLogProbMetric: 180.3667 - lr: 1.2500e-04 - 55s/epoch - 279ms/step
Epoch 373/1000
2023-10-01 14:47:46.573 
Epoch 373/1000 
	 loss: 177.9201, MinusLogProbMetric: 177.9201, val_loss: 180.4098, val_MinusLogProbMetric: 180.4098

Epoch 373: val_loss did not improve from 180.32204
196/196 - 56s - loss: 177.9201 - MinusLogProbMetric: 177.9201 - val_loss: 180.4098 - val_MinusLogProbMetric: 180.4098 - lr: 1.2500e-04 - 56s/epoch - 288ms/step
Epoch 374/1000
2023-10-01 14:48:44.915 
Epoch 374/1000 
	 loss: 177.9351, MinusLogProbMetric: 177.9351, val_loss: 180.4001, val_MinusLogProbMetric: 180.4001

Epoch 374: val_loss did not improve from 180.32204
196/196 - 58s - loss: 177.9351 - MinusLogProbMetric: 177.9351 - val_loss: 180.4001 - val_MinusLogProbMetric: 180.4001 - lr: 1.2500e-04 - 58s/epoch - 298ms/step
Epoch 375/1000
2023-10-01 14:49:41.511 
Epoch 375/1000 
	 loss: 177.9205, MinusLogProbMetric: 177.9205, val_loss: 180.4007, val_MinusLogProbMetric: 180.4007

Epoch 375: val_loss did not improve from 180.32204
196/196 - 57s - loss: 177.9205 - MinusLogProbMetric: 177.9205 - val_loss: 180.4007 - val_MinusLogProbMetric: 180.4007 - lr: 1.2500e-04 - 57s/epoch - 289ms/step
Epoch 376/1000
2023-10-01 14:50:40.112 
Epoch 376/1000 
	 loss: 177.9260, MinusLogProbMetric: 177.9260, val_loss: 180.4865, val_MinusLogProbMetric: 180.4865

Epoch 376: val_loss did not improve from 180.32204
196/196 - 59s - loss: 177.9260 - MinusLogProbMetric: 177.9260 - val_loss: 180.4865 - val_MinusLogProbMetric: 180.4865 - lr: 1.2500e-04 - 59s/epoch - 299ms/step
Epoch 377/1000
2023-10-01 14:51:40.236 
Epoch 377/1000 
	 loss: 177.9442, MinusLogProbMetric: 177.9442, val_loss: 180.4222, val_MinusLogProbMetric: 180.4222

Epoch 377: val_loss did not improve from 180.32204
196/196 - 60s - loss: 177.9442 - MinusLogProbMetric: 177.9442 - val_loss: 180.4222 - val_MinusLogProbMetric: 180.4222 - lr: 1.2500e-04 - 60s/epoch - 307ms/step
Epoch 378/1000
2023-10-01 14:52:38.496 
Epoch 378/1000 
	 loss: 177.9452, MinusLogProbMetric: 177.9452, val_loss: 180.4562, val_MinusLogProbMetric: 180.4562

Epoch 378: val_loss did not improve from 180.32204
Restoring model weights from the end of the best epoch: 278.
196/196 - 59s - loss: 177.9452 - MinusLogProbMetric: 177.9452 - val_loss: 180.4562 - val_MinusLogProbMetric: 180.4562 - lr: 1.2500e-04 - 59s/epoch - 301ms/step
Epoch 378: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
