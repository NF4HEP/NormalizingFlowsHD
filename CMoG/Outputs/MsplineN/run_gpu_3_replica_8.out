2023-10-05 09:16:07.015557: Importing os...
2023-10-05 09:16:07.015632: Importing sys...
2023-10-05 09:16:07.015645: Importing and initializing argparse...
Visible devices: [3]
2023-10-05 09:16:07.031752: Importing timer from timeit...
2023-10-05 09:16:07.032374: Setting env variables for tf import (only device [3] will be available)...
2023-10-05 09:16:07.032422: Importing numpy...
2023-10-05 09:16:07.188506: Importing pandas...
2023-10-05 09:16:07.399148: Importing shutil...
2023-10-05 09:16:07.399184: Importing subprocess...
2023-10-05 09:16:07.399193: Importing tensorflow...
Tensorflow version: 2.12.0
2023-10-05 09:16:10.154786: Importing tensorflow_probability...
Tensorflow probability version: 0.20.1
2023-10-05 09:16:10.671040: Importing textwrap...
2023-10-05 09:16:10.671090: Importing timeit...
2023-10-05 09:16:10.671105: Importing traceback...
2023-10-05 09:16:10.671116: Importing typing...
2023-10-05 09:16:10.671144: Setting tf configs...
2023-10-05 09:16:10.889224: Importing custom module...
Successfully loaded GPU model: NVIDIA A40
2023-10-05 09:16:12.864266: All modues imported successfully.
Directory ../../results/MsplineN_new/ already exists.
Directory ../../results/MsplineN_new/run_1/ already exists.
Skipping it.
===========
Run 1/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_2/ already exists.
Skipping it.
===========
Run 2/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_3/ already exists.
Skipping it.
===========
Run 3/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_4/ already exists.
Skipping it.
===========
Run 4/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_5/ already exists.
Skipping it.
===========
Run 5/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_6/ already exists.
Skipping it.
===========
Run 6/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_7/ already exists.
Skipping it.
===========
Run 7/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_8/ already exists.
Skipping it.
===========
Run 8/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_9/ already exists.
Skipping it.
===========
Run 9/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_10/ already exists.
Skipping it.
===========
Run 10/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_11/ already exists.
Skipping it.
===========
Run 11/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_12/ already exists.
Skipping it.
===========
Run 12/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_13/ already exists.
Skipping it.
===========
Run 13/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_14/ already exists.
Skipping it.
===========
Run 14/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_15/ already exists.
Skipping it.
===========
Run 15/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_16/ already exists.
Skipping it.
===========
Run 16/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_17/ already exists.
Skipping it.
===========
Run 17/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_18/ already exists.
Skipping it.
===========
Run 18/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_19/ already exists.
Skipping it.
===========
Run 19/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_20/ already exists.
Skipping it.
===========
Run 20/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_21/ already exists.
Skipping it.
===========
Run 21/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_22/ already exists.
Skipping it.
===========
Run 22/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_23/ already exists.
Skipping it.
===========
Run 23/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_24/ already exists.
Skipping it.
===========
Run 24/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_25/ already exists.
Skipping it.
===========
Run 25/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_26/ already exists.
Skipping it.
===========
Run 26/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_27/ already exists.
Skipping it.
===========
Run 27/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_28/ already exists.
Skipping it.
===========
Run 28/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_29/ already exists.
Skipping it.
===========
Run 29/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_30/ already exists.
Skipping it.
===========
Run 30/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_31/ already exists.
Skipping it.
===========
Run 31/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_32/ already exists.
Skipping it.
===========
Run 32/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_33/ already exists.
Skipping it.
===========
Run 33/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_34/ already exists.
Skipping it.
===========
Run 34/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_35/ already exists.
Skipping it.
===========
Run 35/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_36/ already exists.
Skipping it.
===========
Run 36/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_37/ already exists.
Skipping it.
===========
Run 37/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_38/ already exists.
Skipping it.
===========
Run 38/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_39/ already exists.
Skipping it.
===========
Run 39/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_40/ already exists.
Skipping it.
===========
Run 40/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_41/ already exists.
Skipping it.
===========
Run 41/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_42/ already exists.
Skipping it.
===========
Run 42/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_43/ already exists.
Skipping it.
===========
Run 43/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_44/ already exists.
Skipping it.
===========
Run 44/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_45/ already exists.
Skipping it.
===========
Run 45/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_46/ already exists.
Skipping it.
===========
Run 46/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_47/ already exists.
Skipping it.
===========
Run 47/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_48/ already exists.
Skipping it.
===========
Run 48/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_49/ already exists.
Skipping it.
===========
Run 49/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_50/ already exists.
Skipping it.
===========
Run 50/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_51/ already exists.
Skipping it.
===========
Run 51/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_52/ already exists.
Skipping it.
===========
Run 52/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_53/ already exists.
Skipping it.
===========
Run 53/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_54/ already exists.
Skipping it.
===========
Run 54/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_55/ already exists.
Skipping it.
===========
Run 55/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_56/ already exists.
Skipping it.
===========
Run 56/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_57/ already exists.
Skipping it.
===========
Run 57/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_58/ already exists.
Skipping it.
===========
Run 58/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_59/ already exists.
Skipping it.
===========
Run 59/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_60/ already exists.
Skipping it.
===========
Run 60/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_61/ already exists.
Skipping it.
===========
Run 61/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_62/ already exists.
Skipping it.
===========
Run 62/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_63/ already exists.
Skipping it.
===========
Run 63/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_64/ already exists.
Skipping it.
===========
Run 64/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_65/ already exists.
Skipping it.
===========
Run 65/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_66/ already exists.
Skipping it.
===========
Run 66/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_67/ already exists.
Skipping it.
===========
Run 67/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_68/ already exists.
Skipping it.
===========
Run 68/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_69/ already exists.
Skipping it.
===========
Run 69/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_70/ already exists.
Skipping it.
===========
Run 70/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_71/ already exists.
Skipping it.
===========
Run 71/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_72/ already exists.
Skipping it.
===========
Run 72/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_73/ already exists.
Skipping it.
===========
Run 73/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_74/ already exists.
Skipping it.
===========
Run 74/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_75/ already exists.
Skipping it.
===========
Run 75/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_76/ already exists.
Skipping it.
===========
Run 76/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_77/ already exists.
Skipping it.
===========
Run 77/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_78/ already exists.
Skipping it.
===========
Run 78/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_79/ already exists.
Skipping it.
===========
Run 79/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_80/ already exists.
Skipping it.
===========
Run 80/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_81/ already exists.
Skipping it.
===========
Run 81/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_82/ already exists.
Skipping it.
===========
Run 82/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_83/ already exists.
Skipping it.
===========
Run 83/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_84/ already exists.
Skipping it.
===========
Run 84/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_85/ already exists.
Skipping it.
===========
Run 85/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_86/ already exists.
Skipping it.
===========
Run 86/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_87/ already exists.
Skipping it.
===========
Run 87/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_88/ already exists.
Skipping it.
===========
Run 88/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_89/ already exists.
Skipping it.
===========
Run 89/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_90/ already exists.
Skipping it.
===========
Run 90/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_91/ already exists.
Skipping it.
===========
Run 91/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_92/ already exists.
Skipping it.
===========
Run 92/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_93/ already exists.
Skipping it.
===========
Run 93/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_94/ already exists.
Skipping it.
===========
Run 94/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_95/ already exists.
Skipping it.
===========
Run 95/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_96/ already exists.
Skipping it.
===========
Run 96/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_97/ already exists.
Skipping it.
===========
Run 97/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_98/ already exists.
Skipping it.
===========
Run 98/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_99/ already exists.
Skipping it.
===========
Run 99/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_100/ already exists.
Skipping it.
===========
Run 100/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_101/ already exists.
Skipping it.
===========
Run 101/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_102/ already exists.
Skipping it.
===========
Run 102/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_103/ already exists.
Skipping it.
===========
Run 103/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_104/ already exists.
Skipping it.
===========
Run 104/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_105/ already exists.
Skipping it.
===========
Run 105/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_106/ already exists.
Skipping it.
===========
Run 106/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_107/ already exists.
Skipping it.
===========
Run 107/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_108/ already exists.
Skipping it.
===========
Run 108/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_109/ already exists.
Skipping it.
===========
Run 109/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_110/ already exists.
Skipping it.
===========
Run 110/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_111/ already exists.
Skipping it.
===========
Run 111/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_112/ already exists.
Skipping it.
===========
Run 112/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_113/ already exists.
Skipping it.
===========
Run 113/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_114/ already exists.
Skipping it.
===========
Run 114/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_115/ already exists.
Skipping it.
===========
Run 115/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_116/ already exists.
Skipping it.
===========
Run 116/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_117/ already exists.
Skipping it.
===========
Run 117/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_118/ already exists.
Skipping it.
===========
Run 118/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_119/ already exists.
Skipping it.
===========
Run 119/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_120/ already exists.
Skipping it.
===========
Run 120/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_121/ already exists.
Skipping it.
===========
Run 121/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_122/ already exists.
Skipping it.
===========
Run 122/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_123/ already exists.
Skipping it.
===========
Run 123/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_124/ already exists.
Skipping it.
===========
Run 124/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_125/ already exists.
Skipping it.
===========
Run 125/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_126/ already exists.
Skipping it.
===========
Run 126/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_127/ already exists.
Skipping it.
===========
Run 127/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_128/ already exists.
Skipping it.
===========
Run 128/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_129/ already exists.
Skipping it.
===========
Run 129/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_130/ already exists.
Skipping it.
===========
Run 130/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_131/ already exists.
Skipping it.
===========
Run 131/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_132/ already exists.
Skipping it.
===========
Run 132/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_133/ already exists.
Skipping it.
===========
Run 133/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_134/ already exists.
Skipping it.
===========
Run 134/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_135/ already exists.
Skipping it.
===========
Run 135/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_136/ already exists.
Skipping it.
===========
Run 136/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_137/ already exists.
Skipping it.
===========
Run 137/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_138/ already exists.
Skipping it.
===========
Run 138/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_139/ already exists.
Skipping it.
===========
Run 139/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_140/ already exists.
Skipping it.
===========
Run 140/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_141/ already exists.
Skipping it.
===========
Run 141/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_142/ already exists.
Skipping it.
===========
Run 142/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_143/ already exists.
Skipping it.
===========
Run 143/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_144/ already exists.
Skipping it.
===========
Run 144/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_145/ already exists.
Skipping it.
===========
Run 145/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_146/ already exists.
Skipping it.
===========
Run 146/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_147/ already exists.
Skipping it.
===========
Run 147/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_148/ already exists.
Skipping it.
===========
Run 148/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_149/ already exists.
Skipping it.
===========
Run 149/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_150/ already exists.
Skipping it.
===========
Run 150/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_151/ already exists.
Skipping it.
===========
Run 151/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_152/ already exists.
Skipping it.
===========
Run 152/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_153/ already exists.
Skipping it.
===========
Run 153/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_154/ already exists.
Skipping it.
===========
Run 154/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_155/ already exists.
Skipping it.
===========
Run 155/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_156/ already exists.
Skipping it.
===========
Run 156/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_157/ already exists.
Skipping it.
===========
Run 157/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_158/ already exists.
Skipping it.
===========
Run 158/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_159/ already exists.
Skipping it.
===========
Run 159/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_160/ already exists.
Skipping it.
===========
Run 160/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_161/ already exists.
Skipping it.
===========
Run 161/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_162/ already exists.
Skipping it.
===========
Run 162/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_163/ already exists.
Skipping it.
===========
Run 163/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_164/ already exists.
Skipping it.
===========
Run 164/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_165/ already exists.
Skipping it.
===========
Run 165/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_166/ already exists.
Skipping it.
===========
Run 166/360 already exists. Skipping it.
===========

===========
Generating train data for run 167.
===========
Train data generated in 0.38 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 64)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_167/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 187}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_167/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 1.5031981 ,  2.9551353 ,  9.211626  , ...,  5.7474284 ,
         0.7829296 ,  3.3359163 ],
       [ 1.3903152 ,  3.1254141 ,  7.28215   , ...,  5.92416   ,
        -2.8417296 ,  2.9486704 ],
       [ 5.2294745 ,  8.137994  ,  5.014993  , ...,  0.691412  ,
         7.469742  ,  1.3593842 ],
       ...,
       [ 1.2930627 ,  4.346054  ,  8.208784  , ...,  5.237335  ,
         0.53958243,  2.6734426 ],
       [ 6.993642  ,  2.9345863 ,  6.120318  , ...,  2.501727  ,
         3.405333  ,  1.9821649 ],
       [ 5.214714  ,  6.173666  ,  5.530484  , ...,  0.3141932 ,
         6.645546  ,  1.3872935 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_167/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_167
self.data_kwargs: {'seed': 187}
self.x_data: [[ 6.8153725   2.8430347   6.1778684  ...  2.16058     2.2525268
   1.7267085 ]
 [ 2.1836705   1.800204    9.035551   ...  6.5503054   1.5567943
   2.9656742 ]
 [ 0.87054014  3.1855702   7.8237348  ...  6.3044343  -0.7088827
   2.3190107 ]
 ...
 [ 0.35442734  3.573855   10.922302   ...  5.8448343   0.8037275
   2.171598  ]
 [ 1.4908957   3.8775673   8.757837   ...  5.7039022  -0.88000226
   2.3087878 ]
 [ 1.7291393   3.7802503   9.770119   ...  5.5898924   0.22995539
   4.1106014 ]]
self.y_data: []
self.ndims: 64
Model defined.
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 64)]              0         
                                                                 
 log_prob_layer (LogProbLaye  (None,)                  660608    
 r)                                                              
                                                                 
=================================================================
Total params: 660,608
Trainable params: 660,608
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer'")
self.model: <keras.engine.functional.Functional object at 0x7f3409cca230>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7f33f8320970>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7f33f8320970>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7f33f8321240>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7f33f8321f00>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7f33f8322470>, <keras.callbacks.ModelCheckpoint object at 0x7f33f83225c0>, <keras.callbacks.EarlyStopping object at 0x7f33f83227d0>, <keras.callbacks.ReduceLROnPlateau object at 0x7f33f8322800>, <keras.callbacks.TerminateOnNaN object at 0x7f33f8322530>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 1.5031981 ,  2.9551353 ,  9.211626  , ...,  5.7474284 ,
         0.7829296 ,  3.3359163 ],
       [ 1.3903152 ,  3.1254141 ,  7.28215   , ...,  5.92416   ,
        -2.8417296 ,  2.9486704 ],
       [ 5.2294745 ,  8.137994  ,  5.014993  , ...,  0.691412  ,
         7.469742  ,  1.3593842 ],
       ...,
       [ 1.2930627 ,  4.346054  ,  8.208784  , ...,  5.237335  ,
         0.53958243,  2.6734426 ],
       [ 6.993642  ,  2.9345863 ,  6.120318  , ...,  2.501727  ,
         3.405333  ,  1.9821649 ],
       [ 5.214714  ,  6.173666  ,  5.530484  , ...,  0.3141932 ,
         6.645546  ,  1.3872935 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_167/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 167/360 with hyperparameters:
timestamp = 2023-10-05 09:16:17.542736
ndims = 64
seed_train = 187
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 660608
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 6.8153725e+00  2.8430347e+00  6.1778684e+00  4.2452879e+00
  1.6284513e+00  3.3207846e+00  7.0928354e+00  6.4340367e+00
  6.0301833e+00  6.4328456e+00  6.5495849e+00  4.9321003e+00
  8.9532204e+00  3.4481030e+00  4.8284545e+00  8.0901794e+00
  8.1549883e+00  7.3900299e+00  1.3510420e+00  9.5149851e+00
  7.5267930e+00  1.0017762e+01  1.1636026e+00  8.6080103e+00
  2.2276068e+00  6.2524571e+00  1.5594521e+00  8.2755499e+00
  8.5135918e+00  6.3978677e+00  3.8566861e+00  6.8423492e-01
  7.5210962e+00  5.4144373e+00  6.8548636e+00  8.7448330e+00
  9.6529083e+00  8.6500130e+00  9.1009712e-01  4.1672401e+00
  7.6439004e+00  9.0885794e-01  5.2691178e+00  8.8166595e-03
  7.4780917e-01 -4.8575500e-01  7.9515800e+00  2.7509699e+00
  4.8898096e+00  1.0073138e+01  7.4751706e+00  6.5633142e-01
  1.5831217e+00  6.0002384e+00  5.6322212e+00  2.2999794e+00
  9.1524439e+00  5.5740438e+00  5.8525505e+00  6.6422234e+00
  6.9292612e+00  2.1605799e+00  2.2525268e+00  1.7267085e+00]
Epoch 1/1000
2023-10-05 09:16:58.333 
Epoch 1/1000 
	 loss: 108.3060, MinusLogProbMetric: 108.3060, val_loss: 36.8847, val_MinusLogProbMetric: 36.8847

Epoch 1: val_loss improved from inf to 36.88473, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 41s - loss: 108.3060 - MinusLogProbMetric: 108.3060 - val_loss: 36.8847 - val_MinusLogProbMetric: 36.8847 - lr: 0.0010 - 41s/epoch - 208ms/step
Epoch 2/1000
2023-10-05 09:17:12.612 
Epoch 2/1000 
	 loss: 32.9615, MinusLogProbMetric: 32.9615, val_loss: 31.6426, val_MinusLogProbMetric: 31.6426

Epoch 2: val_loss improved from 36.88473 to 31.64257, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 32.9615 - MinusLogProbMetric: 32.9615 - val_loss: 31.6426 - val_MinusLogProbMetric: 31.6426 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 3/1000
2023-10-05 09:17:27.080 
Epoch 3/1000 
	 loss: 30.4468, MinusLogProbMetric: 30.4468, val_loss: 29.9602, val_MinusLogProbMetric: 29.9602

Epoch 3: val_loss improved from 31.64257 to 29.96025, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 30.4468 - MinusLogProbMetric: 30.4468 - val_loss: 29.9602 - val_MinusLogProbMetric: 29.9602 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 4/1000
2023-10-05 09:17:41.520 
Epoch 4/1000 
	 loss: 29.4444, MinusLogProbMetric: 29.4444, val_loss: 29.2665, val_MinusLogProbMetric: 29.2665

Epoch 4: val_loss improved from 29.96025 to 29.26651, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 29.4444 - MinusLogProbMetric: 29.4444 - val_loss: 29.2665 - val_MinusLogProbMetric: 29.2665 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 5/1000
2023-10-05 09:17:56.490 
Epoch 5/1000 
	 loss: 29.0888, MinusLogProbMetric: 29.0888, val_loss: 29.5781, val_MinusLogProbMetric: 29.5781

Epoch 5: val_loss did not improve from 29.26651
196/196 - 15s - loss: 29.0888 - MinusLogProbMetric: 29.0888 - val_loss: 29.5781 - val_MinusLogProbMetric: 29.5781 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 6/1000
2023-10-05 09:18:10.486 
Epoch 6/1000 
	 loss: 28.8382, MinusLogProbMetric: 28.8382, val_loss: 28.9312, val_MinusLogProbMetric: 28.9312

Epoch 6: val_loss improved from 29.26651 to 28.93118, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 28.8382 - MinusLogProbMetric: 28.8382 - val_loss: 28.9312 - val_MinusLogProbMetric: 28.9312 - lr: 0.0010 - 14s/epoch - 72ms/step
Epoch 7/1000
2023-10-05 09:18:24.041 
Epoch 7/1000 
	 loss: 28.7247, MinusLogProbMetric: 28.7247, val_loss: 28.9274, val_MinusLogProbMetric: 28.9274

Epoch 7: val_loss improved from 28.93118 to 28.92741, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 28.7247 - MinusLogProbMetric: 28.7247 - val_loss: 28.9274 - val_MinusLogProbMetric: 28.9274 - lr: 0.0010 - 14s/epoch - 69ms/step
Epoch 8/1000
2023-10-05 09:18:37.825 
Epoch 8/1000 
	 loss: 28.5131, MinusLogProbMetric: 28.5131, val_loss: 28.4408, val_MinusLogProbMetric: 28.4408

Epoch 8: val_loss improved from 28.92741 to 28.44080, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 28.5131 - MinusLogProbMetric: 28.5131 - val_loss: 28.4408 - val_MinusLogProbMetric: 28.4408 - lr: 0.0010 - 14s/epoch - 72ms/step
Epoch 9/1000
2023-10-05 09:18:52.005 
Epoch 9/1000 
	 loss: 28.3846, MinusLogProbMetric: 28.3846, val_loss: 28.2673, val_MinusLogProbMetric: 28.2673

Epoch 9: val_loss improved from 28.44080 to 28.26732, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 28.3846 - MinusLogProbMetric: 28.3846 - val_loss: 28.2673 - val_MinusLogProbMetric: 28.2673 - lr: 0.0010 - 14s/epoch - 72ms/step
Epoch 10/1000
2023-10-05 09:19:06.010 
Epoch 10/1000 
	 loss: 28.3526, MinusLogProbMetric: 28.3526, val_loss: 28.2312, val_MinusLogProbMetric: 28.2312

Epoch 10: val_loss improved from 28.26732 to 28.23116, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 28.3526 - MinusLogProbMetric: 28.3526 - val_loss: 28.2312 - val_MinusLogProbMetric: 28.2312 - lr: 0.0010 - 14s/epoch - 70ms/step
Epoch 11/1000
2023-10-05 09:19:19.676 
Epoch 11/1000 
	 loss: 28.2929, MinusLogProbMetric: 28.2929, val_loss: 28.4933, val_MinusLogProbMetric: 28.4933

Epoch 11: val_loss did not improve from 28.23116
196/196 - 14s - loss: 28.2929 - MinusLogProbMetric: 28.2929 - val_loss: 28.4933 - val_MinusLogProbMetric: 28.4933 - lr: 0.0010 - 14s/epoch - 69ms/step
Epoch 12/1000
2023-10-05 09:19:33.256 
Epoch 12/1000 
	 loss: 28.2306, MinusLogProbMetric: 28.2306, val_loss: 28.4451, val_MinusLogProbMetric: 28.4451

Epoch 12: val_loss did not improve from 28.23116
196/196 - 14s - loss: 28.2306 - MinusLogProbMetric: 28.2306 - val_loss: 28.4451 - val_MinusLogProbMetric: 28.4451 - lr: 0.0010 - 14s/epoch - 69ms/step
Epoch 13/1000
2023-10-05 09:19:46.658 
Epoch 13/1000 
	 loss: 28.1706, MinusLogProbMetric: 28.1706, val_loss: 28.1281, val_MinusLogProbMetric: 28.1281

Epoch 13: val_loss improved from 28.23116 to 28.12808, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 28.1706 - MinusLogProbMetric: 28.1706 - val_loss: 28.1281 - val_MinusLogProbMetric: 28.1281 - lr: 0.0010 - 14s/epoch - 70ms/step
Epoch 14/1000
2023-10-05 09:20:00.163 
Epoch 14/1000 
	 loss: 28.1534, MinusLogProbMetric: 28.1534, val_loss: 28.0851, val_MinusLogProbMetric: 28.0851

Epoch 14: val_loss improved from 28.12808 to 28.08512, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 13s - loss: 28.1534 - MinusLogProbMetric: 28.1534 - val_loss: 28.0851 - val_MinusLogProbMetric: 28.0851 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 15/1000
2023-10-05 09:20:13.563 
Epoch 15/1000 
	 loss: 28.1039, MinusLogProbMetric: 28.1039, val_loss: 28.1184, val_MinusLogProbMetric: 28.1184

Epoch 15: val_loss did not improve from 28.08512
196/196 - 13s - loss: 28.1039 - MinusLogProbMetric: 28.1039 - val_loss: 28.1184 - val_MinusLogProbMetric: 28.1184 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 16/1000
2023-10-05 09:20:26.908 
Epoch 16/1000 
	 loss: 28.1168, MinusLogProbMetric: 28.1168, val_loss: 28.3481, val_MinusLogProbMetric: 28.3481

Epoch 16: val_loss did not improve from 28.08512
196/196 - 13s - loss: 28.1168 - MinusLogProbMetric: 28.1168 - val_loss: 28.3481 - val_MinusLogProbMetric: 28.3481 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 17/1000
2023-10-05 09:20:40.736 
Epoch 17/1000 
	 loss: 28.0653, MinusLogProbMetric: 28.0653, val_loss: 28.0569, val_MinusLogProbMetric: 28.0569

Epoch 17: val_loss improved from 28.08512 to 28.05688, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 28.0653 - MinusLogProbMetric: 28.0653 - val_loss: 28.0569 - val_MinusLogProbMetric: 28.0569 - lr: 0.0010 - 14s/epoch - 71ms/step
Epoch 18/1000
2023-10-05 09:20:54.390 
Epoch 18/1000 
	 loss: 28.0378, MinusLogProbMetric: 28.0378, val_loss: 28.1380, val_MinusLogProbMetric: 28.1380

Epoch 18: val_loss did not improve from 28.05688
196/196 - 14s - loss: 28.0378 - MinusLogProbMetric: 28.0378 - val_loss: 28.1380 - val_MinusLogProbMetric: 28.1380 - lr: 0.0010 - 14s/epoch - 69ms/step
Epoch 19/1000
2023-10-05 09:21:07.863 
Epoch 19/1000 
	 loss: 27.9852, MinusLogProbMetric: 27.9852, val_loss: 27.9078, val_MinusLogProbMetric: 27.9078

Epoch 19: val_loss improved from 28.05688 to 27.90776, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 27.9852 - MinusLogProbMetric: 27.9852 - val_loss: 27.9078 - val_MinusLogProbMetric: 27.9078 - lr: 0.0010 - 14s/epoch - 70ms/step
Epoch 20/1000
2023-10-05 09:21:21.498 
Epoch 20/1000 
	 loss: 27.9788, MinusLogProbMetric: 27.9788, val_loss: 27.9751, val_MinusLogProbMetric: 27.9751

Epoch 20: val_loss did not improve from 27.90776
196/196 - 13s - loss: 27.9788 - MinusLogProbMetric: 27.9788 - val_loss: 27.9751 - val_MinusLogProbMetric: 27.9751 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 21/1000
2023-10-05 09:21:34.534 
Epoch 21/1000 
	 loss: 27.9662, MinusLogProbMetric: 27.9662, val_loss: 27.9167, val_MinusLogProbMetric: 27.9167

Epoch 21: val_loss did not improve from 27.90776
196/196 - 13s - loss: 27.9662 - MinusLogProbMetric: 27.9662 - val_loss: 27.9167 - val_MinusLogProbMetric: 27.9167 - lr: 0.0010 - 13s/epoch - 66ms/step
Epoch 22/1000
2023-10-05 09:21:47.579 
Epoch 22/1000 
	 loss: 27.9407, MinusLogProbMetric: 27.9407, val_loss: 27.9770, val_MinusLogProbMetric: 27.9770

Epoch 22: val_loss did not improve from 27.90776
196/196 - 13s - loss: 27.9407 - MinusLogProbMetric: 27.9407 - val_loss: 27.9770 - val_MinusLogProbMetric: 27.9770 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 23/1000
2023-10-05 09:22:00.800 
Epoch 23/1000 
	 loss: 27.9034, MinusLogProbMetric: 27.9034, val_loss: 28.1362, val_MinusLogProbMetric: 28.1362

Epoch 23: val_loss did not improve from 27.90776
196/196 - 13s - loss: 27.9034 - MinusLogProbMetric: 27.9034 - val_loss: 28.1362 - val_MinusLogProbMetric: 28.1362 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 24/1000
2023-10-05 09:22:14.019 
Epoch 24/1000 
	 loss: 27.8788, MinusLogProbMetric: 27.8788, val_loss: 27.9750, val_MinusLogProbMetric: 27.9750

Epoch 24: val_loss did not improve from 27.90776
196/196 - 13s - loss: 27.8788 - MinusLogProbMetric: 27.8788 - val_loss: 27.9750 - val_MinusLogProbMetric: 27.9750 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 25/1000
2023-10-05 09:22:27.366 
Epoch 25/1000 
	 loss: 27.8913, MinusLogProbMetric: 27.8913, val_loss: 28.0748, val_MinusLogProbMetric: 28.0748

Epoch 25: val_loss did not improve from 27.90776
196/196 - 13s - loss: 27.8913 - MinusLogProbMetric: 27.8913 - val_loss: 28.0748 - val_MinusLogProbMetric: 28.0748 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 26/1000
2023-10-05 09:22:40.965 
Epoch 26/1000 
	 loss: 27.8608, MinusLogProbMetric: 27.8608, val_loss: 27.8250, val_MinusLogProbMetric: 27.8250

Epoch 26: val_loss improved from 27.90776 to 27.82496, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 27.8608 - MinusLogProbMetric: 27.8608 - val_loss: 27.8250 - val_MinusLogProbMetric: 27.8250 - lr: 0.0010 - 14s/epoch - 70ms/step
Epoch 27/1000
2023-10-05 09:22:54.500 
Epoch 27/1000 
	 loss: 27.8446, MinusLogProbMetric: 27.8446, val_loss: 27.8375, val_MinusLogProbMetric: 27.8375

Epoch 27: val_loss did not improve from 27.82496
196/196 - 13s - loss: 27.8446 - MinusLogProbMetric: 27.8446 - val_loss: 27.8375 - val_MinusLogProbMetric: 27.8375 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 28/1000
2023-10-05 09:23:07.836 
Epoch 28/1000 
	 loss: 27.8372, MinusLogProbMetric: 27.8372, val_loss: 27.8809, val_MinusLogProbMetric: 27.8809

Epoch 28: val_loss did not improve from 27.82496
196/196 - 13s - loss: 27.8372 - MinusLogProbMetric: 27.8372 - val_loss: 27.8809 - val_MinusLogProbMetric: 27.8809 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 29/1000
2023-10-05 09:23:21.187 
Epoch 29/1000 
	 loss: 27.8465, MinusLogProbMetric: 27.8465, val_loss: 27.8046, val_MinusLogProbMetric: 27.8046

Epoch 29: val_loss improved from 27.82496 to 27.80459, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 13s - loss: 27.8465 - MinusLogProbMetric: 27.8465 - val_loss: 27.8046 - val_MinusLogProbMetric: 27.8046 - lr: 0.0010 - 13s/epoch - 69ms/step
Epoch 30/1000
2023-10-05 09:23:34.830 
Epoch 30/1000 
	 loss: 27.8431, MinusLogProbMetric: 27.8431, val_loss: 27.9519, val_MinusLogProbMetric: 27.9519

Epoch 30: val_loss did not improve from 27.80459
196/196 - 14s - loss: 27.8431 - MinusLogProbMetric: 27.8431 - val_loss: 27.9519 - val_MinusLogProbMetric: 27.9519 - lr: 0.0010 - 14s/epoch - 69ms/step
Epoch 31/1000
2023-10-05 09:23:48.299 
Epoch 31/1000 
	 loss: 27.8370, MinusLogProbMetric: 27.8370, val_loss: 27.7998, val_MinusLogProbMetric: 27.7998

Epoch 31: val_loss improved from 27.80459 to 27.79982, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 27.8370 - MinusLogProbMetric: 27.8370 - val_loss: 27.7998 - val_MinusLogProbMetric: 27.7998 - lr: 0.0010 - 14s/epoch - 71ms/step
Epoch 32/1000
2023-10-05 09:24:01.884 
Epoch 32/1000 
	 loss: 27.8274, MinusLogProbMetric: 27.8274, val_loss: 27.8967, val_MinusLogProbMetric: 27.8967

Epoch 32: val_loss did not improve from 27.79982
196/196 - 13s - loss: 27.8274 - MinusLogProbMetric: 27.8274 - val_loss: 27.8967 - val_MinusLogProbMetric: 27.8967 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 33/1000
2023-10-05 09:24:15.180 
Epoch 33/1000 
	 loss: 27.8216, MinusLogProbMetric: 27.8216, val_loss: 27.8503, val_MinusLogProbMetric: 27.8503

Epoch 33: val_loss did not improve from 27.79982
196/196 - 13s - loss: 27.8216 - MinusLogProbMetric: 27.8216 - val_loss: 27.8503 - val_MinusLogProbMetric: 27.8503 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 34/1000
2023-10-05 09:24:28.943 
Epoch 34/1000 
	 loss: 27.7750, MinusLogProbMetric: 27.7750, val_loss: 27.7984, val_MinusLogProbMetric: 27.7984

Epoch 34: val_loss improved from 27.79982 to 27.79843, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 27.7750 - MinusLogProbMetric: 27.7750 - val_loss: 27.7984 - val_MinusLogProbMetric: 27.7984 - lr: 0.0010 - 14s/epoch - 71ms/step
Epoch 35/1000
2023-10-05 09:24:42.421 
Epoch 35/1000 
	 loss: 27.7994, MinusLogProbMetric: 27.7994, val_loss: 27.8189, val_MinusLogProbMetric: 27.8189

Epoch 35: val_loss did not improve from 27.79843
196/196 - 13s - loss: 27.7994 - MinusLogProbMetric: 27.7994 - val_loss: 27.8189 - val_MinusLogProbMetric: 27.8189 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 36/1000
2023-10-05 09:24:55.594 
Epoch 36/1000 
	 loss: 27.7819, MinusLogProbMetric: 27.7819, val_loss: 27.8004, val_MinusLogProbMetric: 27.8004

Epoch 36: val_loss did not improve from 27.79843
196/196 - 13s - loss: 27.7819 - MinusLogProbMetric: 27.7819 - val_loss: 27.8004 - val_MinusLogProbMetric: 27.8004 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 37/1000
2023-10-05 09:25:07.609 
Epoch 37/1000 
	 loss: 27.7754, MinusLogProbMetric: 27.7754, val_loss: 27.8986, val_MinusLogProbMetric: 27.8986

Epoch 37: val_loss did not improve from 27.79843
196/196 - 12s - loss: 27.7754 - MinusLogProbMetric: 27.7754 - val_loss: 27.8986 - val_MinusLogProbMetric: 27.8986 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 38/1000
2023-10-05 09:25:19.852 
Epoch 38/1000 
	 loss: 27.7655, MinusLogProbMetric: 27.7655, val_loss: 27.7558, val_MinusLogProbMetric: 27.7558

Epoch 38: val_loss improved from 27.79843 to 27.75575, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 12s - loss: 27.7655 - MinusLogProbMetric: 27.7655 - val_loss: 27.7558 - val_MinusLogProbMetric: 27.7558 - lr: 0.0010 - 12s/epoch - 63ms/step
Epoch 39/1000
2023-10-05 09:25:33.272 
Epoch 39/1000 
	 loss: 27.7686, MinusLogProbMetric: 27.7686, val_loss: 27.7420, val_MinusLogProbMetric: 27.7420

Epoch 39: val_loss improved from 27.75575 to 27.74205, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 13s - loss: 27.7686 - MinusLogProbMetric: 27.7686 - val_loss: 27.7420 - val_MinusLogProbMetric: 27.7420 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 40/1000
2023-10-05 09:25:46.771 
Epoch 40/1000 
	 loss: 27.7443, MinusLogProbMetric: 27.7443, val_loss: 27.8070, val_MinusLogProbMetric: 27.8070

Epoch 40: val_loss did not improve from 27.74205
196/196 - 13s - loss: 27.7443 - MinusLogProbMetric: 27.7443 - val_loss: 27.8070 - val_MinusLogProbMetric: 27.8070 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 41/1000
2023-10-05 09:26:00.160 
Epoch 41/1000 
	 loss: 27.7535, MinusLogProbMetric: 27.7535, val_loss: 27.8606, val_MinusLogProbMetric: 27.8606

Epoch 41: val_loss did not improve from 27.74205
196/196 - 13s - loss: 27.7535 - MinusLogProbMetric: 27.7535 - val_loss: 27.8606 - val_MinusLogProbMetric: 27.8606 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 42/1000
2023-10-05 09:26:13.571 
Epoch 42/1000 
	 loss: 27.7477, MinusLogProbMetric: 27.7477, val_loss: 27.8846, val_MinusLogProbMetric: 27.8846

Epoch 42: val_loss did not improve from 27.74205
196/196 - 13s - loss: 27.7477 - MinusLogProbMetric: 27.7477 - val_loss: 27.8846 - val_MinusLogProbMetric: 27.8846 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 43/1000
2023-10-05 09:26:26.652 
Epoch 43/1000 
	 loss: 27.7317, MinusLogProbMetric: 27.7317, val_loss: 27.7833, val_MinusLogProbMetric: 27.7833

Epoch 43: val_loss did not improve from 27.74205
196/196 - 13s - loss: 27.7317 - MinusLogProbMetric: 27.7317 - val_loss: 27.7833 - val_MinusLogProbMetric: 27.7833 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 44/1000
2023-10-05 09:26:40.213 
Epoch 44/1000 
	 loss: 27.7347, MinusLogProbMetric: 27.7347, val_loss: 27.7537, val_MinusLogProbMetric: 27.7537

Epoch 44: val_loss did not improve from 27.74205
196/196 - 14s - loss: 27.7347 - MinusLogProbMetric: 27.7347 - val_loss: 27.7537 - val_MinusLogProbMetric: 27.7537 - lr: 0.0010 - 14s/epoch - 69ms/step
Epoch 45/1000
2023-10-05 09:26:53.543 
Epoch 45/1000 
	 loss: 27.7313, MinusLogProbMetric: 27.7313, val_loss: 27.7984, val_MinusLogProbMetric: 27.7984

Epoch 45: val_loss did not improve from 27.74205
196/196 - 13s - loss: 27.7313 - MinusLogProbMetric: 27.7313 - val_loss: 27.7984 - val_MinusLogProbMetric: 27.7984 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 46/1000
2023-10-05 09:27:07.288 
Epoch 46/1000 
	 loss: 27.7208, MinusLogProbMetric: 27.7208, val_loss: 27.7332, val_MinusLogProbMetric: 27.7332

Epoch 46: val_loss improved from 27.74205 to 27.73320, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 27.7208 - MinusLogProbMetric: 27.7208 - val_loss: 27.7332 - val_MinusLogProbMetric: 27.7332 - lr: 0.0010 - 14s/epoch - 71ms/step
Epoch 47/1000
2023-10-05 09:27:21.022 
Epoch 47/1000 
	 loss: 27.7488, MinusLogProbMetric: 27.7488, val_loss: 27.8187, val_MinusLogProbMetric: 27.8187

Epoch 47: val_loss did not improve from 27.73320
196/196 - 14s - loss: 27.7488 - MinusLogProbMetric: 27.7488 - val_loss: 27.8187 - val_MinusLogProbMetric: 27.8187 - lr: 0.0010 - 14s/epoch - 69ms/step
Epoch 48/1000
2023-10-05 09:27:34.371 
Epoch 48/1000 
	 loss: 27.7262, MinusLogProbMetric: 27.7262, val_loss: 27.7549, val_MinusLogProbMetric: 27.7549

Epoch 48: val_loss did not improve from 27.73320
196/196 - 13s - loss: 27.7262 - MinusLogProbMetric: 27.7262 - val_loss: 27.7549 - val_MinusLogProbMetric: 27.7549 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 49/1000
2023-10-05 09:27:47.289 
Epoch 49/1000 
	 loss: 27.7022, MinusLogProbMetric: 27.7022, val_loss: 27.8385, val_MinusLogProbMetric: 27.8385

Epoch 49: val_loss did not improve from 27.73320
196/196 - 13s - loss: 27.7022 - MinusLogProbMetric: 27.7022 - val_loss: 27.8385 - val_MinusLogProbMetric: 27.8385 - lr: 0.0010 - 13s/epoch - 66ms/step
Epoch 50/1000
2023-10-05 09:28:00.484 
Epoch 50/1000 
	 loss: 27.7151, MinusLogProbMetric: 27.7151, val_loss: 27.7496, val_MinusLogProbMetric: 27.7496

Epoch 50: val_loss did not improve from 27.73320
196/196 - 13s - loss: 27.7151 - MinusLogProbMetric: 27.7151 - val_loss: 27.7496 - val_MinusLogProbMetric: 27.7496 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 51/1000
2023-10-05 09:28:13.671 
Epoch 51/1000 
	 loss: 27.7152, MinusLogProbMetric: 27.7152, val_loss: 27.8622, val_MinusLogProbMetric: 27.8622

Epoch 51: val_loss did not improve from 27.73320
196/196 - 13s - loss: 27.7152 - MinusLogProbMetric: 27.7152 - val_loss: 27.8622 - val_MinusLogProbMetric: 27.8622 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 52/1000
2023-10-05 09:28:26.911 
Epoch 52/1000 
	 loss: 27.6866, MinusLogProbMetric: 27.6866, val_loss: 27.8048, val_MinusLogProbMetric: 27.8048

Epoch 52: val_loss did not improve from 27.73320
196/196 - 13s - loss: 27.6866 - MinusLogProbMetric: 27.6866 - val_loss: 27.8048 - val_MinusLogProbMetric: 27.8048 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 53/1000
2023-10-05 09:28:40.223 
Epoch 53/1000 
	 loss: 27.7038, MinusLogProbMetric: 27.7038, val_loss: 27.6981, val_MinusLogProbMetric: 27.6981

Epoch 53: val_loss improved from 27.73320 to 27.69813, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 27.7038 - MinusLogProbMetric: 27.7038 - val_loss: 27.6981 - val_MinusLogProbMetric: 27.6981 - lr: 0.0010 - 14s/epoch - 70ms/step
Epoch 54/1000
2023-10-05 09:28:53.741 
Epoch 54/1000 
	 loss: 27.6803, MinusLogProbMetric: 27.6803, val_loss: 27.7229, val_MinusLogProbMetric: 27.7229

Epoch 54: val_loss did not improve from 27.69813
196/196 - 13s - loss: 27.6803 - MinusLogProbMetric: 27.6803 - val_loss: 27.7229 - val_MinusLogProbMetric: 27.7229 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 55/1000
2023-10-05 09:29:06.868 
Epoch 55/1000 
	 loss: 27.6861, MinusLogProbMetric: 27.6861, val_loss: 27.9999, val_MinusLogProbMetric: 27.9999

Epoch 55: val_loss did not improve from 27.69813
196/196 - 13s - loss: 27.6861 - MinusLogProbMetric: 27.6861 - val_loss: 27.9999 - val_MinusLogProbMetric: 27.9999 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 56/1000
2023-10-05 09:29:19.797 
Epoch 56/1000 
	 loss: 27.6632, MinusLogProbMetric: 27.6632, val_loss: 27.7727, val_MinusLogProbMetric: 27.7727

Epoch 56: val_loss did not improve from 27.69813
196/196 - 13s - loss: 27.6632 - MinusLogProbMetric: 27.6632 - val_loss: 27.7727 - val_MinusLogProbMetric: 27.7727 - lr: 0.0010 - 13s/epoch - 66ms/step
Epoch 57/1000
2023-10-05 09:29:33.176 
Epoch 57/1000 
	 loss: 27.6857, MinusLogProbMetric: 27.6857, val_loss: 27.6977, val_MinusLogProbMetric: 27.6977

Epoch 57: val_loss improved from 27.69813 to 27.69774, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 27.6857 - MinusLogProbMetric: 27.6857 - val_loss: 27.6977 - val_MinusLogProbMetric: 27.6977 - lr: 0.0010 - 14s/epoch - 69ms/step
Epoch 58/1000
2023-10-05 09:29:46.527 
Epoch 58/1000 
	 loss: 27.6776, MinusLogProbMetric: 27.6776, val_loss: 27.7963, val_MinusLogProbMetric: 27.7963

Epoch 58: val_loss did not improve from 27.69774
196/196 - 13s - loss: 27.6776 - MinusLogProbMetric: 27.6776 - val_loss: 27.7963 - val_MinusLogProbMetric: 27.7963 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 59/1000
2023-10-05 09:29:59.887 
Epoch 59/1000 
	 loss: 27.6645, MinusLogProbMetric: 27.6645, val_loss: 27.6826, val_MinusLogProbMetric: 27.6826

Epoch 59: val_loss improved from 27.69774 to 27.68258, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 27.6645 - MinusLogProbMetric: 27.6645 - val_loss: 27.6826 - val_MinusLogProbMetric: 27.6826 - lr: 0.0010 - 14s/epoch - 69ms/step
Epoch 60/1000
2023-10-05 09:30:13.502 
Epoch 60/1000 
	 loss: 27.6648, MinusLogProbMetric: 27.6648, val_loss: 27.7657, val_MinusLogProbMetric: 27.7657

Epoch 60: val_loss did not improve from 27.68258
196/196 - 13s - loss: 27.6648 - MinusLogProbMetric: 27.6648 - val_loss: 27.7657 - val_MinusLogProbMetric: 27.7657 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 61/1000
2023-10-05 09:30:26.848 
Epoch 61/1000 
	 loss: 27.6740, MinusLogProbMetric: 27.6740, val_loss: 27.7158, val_MinusLogProbMetric: 27.7158

Epoch 61: val_loss did not improve from 27.68258
196/196 - 13s - loss: 27.6740 - MinusLogProbMetric: 27.6740 - val_loss: 27.7158 - val_MinusLogProbMetric: 27.7158 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 62/1000
2023-10-05 09:30:39.971 
Epoch 62/1000 
	 loss: 27.6935, MinusLogProbMetric: 27.6935, val_loss: 27.7018, val_MinusLogProbMetric: 27.7018

Epoch 62: val_loss did not improve from 27.68258
196/196 - 13s - loss: 27.6935 - MinusLogProbMetric: 27.6935 - val_loss: 27.7018 - val_MinusLogProbMetric: 27.7018 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 63/1000
2023-10-05 09:30:53.625 
Epoch 63/1000 
	 loss: 27.6514, MinusLogProbMetric: 27.6514, val_loss: 27.7484, val_MinusLogProbMetric: 27.7484

Epoch 63: val_loss did not improve from 27.68258
196/196 - 14s - loss: 27.6514 - MinusLogProbMetric: 27.6514 - val_loss: 27.7484 - val_MinusLogProbMetric: 27.7484 - lr: 0.0010 - 14s/epoch - 70ms/step
Epoch 64/1000
2023-10-05 09:31:07.060 
Epoch 64/1000 
	 loss: 27.6651, MinusLogProbMetric: 27.6651, val_loss: 27.7219, val_MinusLogProbMetric: 27.7219

Epoch 64: val_loss did not improve from 27.68258
196/196 - 13s - loss: 27.6651 - MinusLogProbMetric: 27.6651 - val_loss: 27.7219 - val_MinusLogProbMetric: 27.7219 - lr: 0.0010 - 13s/epoch - 69ms/step
Epoch 65/1000
2023-10-05 09:31:20.294 
Epoch 65/1000 
	 loss: 27.6589, MinusLogProbMetric: 27.6589, val_loss: 27.6632, val_MinusLogProbMetric: 27.6632

Epoch 65: val_loss improved from 27.68258 to 27.66318, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 13s - loss: 27.6589 - MinusLogProbMetric: 27.6589 - val_loss: 27.6632 - val_MinusLogProbMetric: 27.6632 - lr: 0.0010 - 13s/epoch - 69ms/step
Epoch 66/1000
2023-10-05 09:31:33.005 
Epoch 66/1000 
	 loss: 27.6557, MinusLogProbMetric: 27.6557, val_loss: 27.8362, val_MinusLogProbMetric: 27.8362

Epoch 66: val_loss did not improve from 27.66318
196/196 - 12s - loss: 27.6557 - MinusLogProbMetric: 27.6557 - val_loss: 27.8362 - val_MinusLogProbMetric: 27.8362 - lr: 0.0010 - 12s/epoch - 64ms/step
Epoch 67/1000
2023-10-05 09:31:45.857 
Epoch 67/1000 
	 loss: 27.6526, MinusLogProbMetric: 27.6526, val_loss: 27.6777, val_MinusLogProbMetric: 27.6777

Epoch 67: val_loss did not improve from 27.66318
196/196 - 13s - loss: 27.6526 - MinusLogProbMetric: 27.6526 - val_loss: 27.6777 - val_MinusLogProbMetric: 27.6777 - lr: 0.0010 - 13s/epoch - 66ms/step
Epoch 68/1000
2023-10-05 09:31:59.303 
Epoch 68/1000 
	 loss: 27.6387, MinusLogProbMetric: 27.6387, val_loss: 27.8900, val_MinusLogProbMetric: 27.8900

Epoch 68: val_loss did not improve from 27.66318
196/196 - 13s - loss: 27.6387 - MinusLogProbMetric: 27.6387 - val_loss: 27.8900 - val_MinusLogProbMetric: 27.8900 - lr: 0.0010 - 13s/epoch - 69ms/step
Epoch 69/1000
2023-10-05 09:32:12.869 
Epoch 69/1000 
	 loss: 27.6431, MinusLogProbMetric: 27.6431, val_loss: 27.7398, val_MinusLogProbMetric: 27.7398

Epoch 69: val_loss did not improve from 27.66318
196/196 - 14s - loss: 27.6431 - MinusLogProbMetric: 27.6431 - val_loss: 27.7398 - val_MinusLogProbMetric: 27.7398 - lr: 0.0010 - 14s/epoch - 69ms/step
Epoch 70/1000
2023-10-05 09:32:26.183 
Epoch 70/1000 
	 loss: 27.6379, MinusLogProbMetric: 27.6379, val_loss: 27.7047, val_MinusLogProbMetric: 27.7047

Epoch 70: val_loss did not improve from 27.66318
196/196 - 13s - loss: 27.6379 - MinusLogProbMetric: 27.6379 - val_loss: 27.7047 - val_MinusLogProbMetric: 27.7047 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 71/1000
2023-10-05 09:32:39.434 
Epoch 71/1000 
	 loss: 27.6340, MinusLogProbMetric: 27.6340, val_loss: 27.6546, val_MinusLogProbMetric: 27.6546

Epoch 71: val_loss improved from 27.66318 to 27.65458, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 27.6340 - MinusLogProbMetric: 27.6340 - val_loss: 27.6546 - val_MinusLogProbMetric: 27.6546 - lr: 0.0010 - 14s/epoch - 70ms/step
Epoch 72/1000
2023-10-05 09:32:53.186 
Epoch 72/1000 
	 loss: 27.6374, MinusLogProbMetric: 27.6374, val_loss: 27.7204, val_MinusLogProbMetric: 27.7204

Epoch 72: val_loss did not improve from 27.65458
196/196 - 13s - loss: 27.6374 - MinusLogProbMetric: 27.6374 - val_loss: 27.7204 - val_MinusLogProbMetric: 27.7204 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 73/1000
2023-10-05 09:33:06.508 
Epoch 73/1000 
	 loss: 27.6397, MinusLogProbMetric: 27.6397, val_loss: 27.6573, val_MinusLogProbMetric: 27.6573

Epoch 73: val_loss did not improve from 27.65458
196/196 - 13s - loss: 27.6397 - MinusLogProbMetric: 27.6397 - val_loss: 27.6573 - val_MinusLogProbMetric: 27.6573 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 74/1000
2023-10-05 09:33:19.613 
Epoch 74/1000 
	 loss: 27.6438, MinusLogProbMetric: 27.6438, val_loss: 27.6389, val_MinusLogProbMetric: 27.6389

Epoch 74: val_loss improved from 27.65458 to 27.63888, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 27.6438 - MinusLogProbMetric: 27.6438 - val_loss: 27.6389 - val_MinusLogProbMetric: 27.6389 - lr: 0.0010 - 14s/epoch - 69ms/step
Epoch 75/1000
2023-10-05 09:33:33.429 
Epoch 75/1000 
	 loss: 27.6482, MinusLogProbMetric: 27.6482, val_loss: 27.6927, val_MinusLogProbMetric: 27.6927

Epoch 75: val_loss did not improve from 27.63888
196/196 - 13s - loss: 27.6482 - MinusLogProbMetric: 27.6482 - val_loss: 27.6927 - val_MinusLogProbMetric: 27.6927 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 76/1000
2023-10-05 09:33:46.552 
Epoch 76/1000 
	 loss: 27.6194, MinusLogProbMetric: 27.6194, val_loss: 27.6734, val_MinusLogProbMetric: 27.6734

Epoch 76: val_loss did not improve from 27.63888
196/196 - 13s - loss: 27.6194 - MinusLogProbMetric: 27.6194 - val_loss: 27.6734 - val_MinusLogProbMetric: 27.6734 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 77/1000
2023-10-05 09:33:59.736 
Epoch 77/1000 
	 loss: 27.6201, MinusLogProbMetric: 27.6201, val_loss: 27.6134, val_MinusLogProbMetric: 27.6134

Epoch 77: val_loss improved from 27.63888 to 27.61336, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 13s - loss: 27.6201 - MinusLogProbMetric: 27.6201 - val_loss: 27.6134 - val_MinusLogProbMetric: 27.6134 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 78/1000
2023-10-05 09:34:13.183 
Epoch 78/1000 
	 loss: 27.6126, MinusLogProbMetric: 27.6126, val_loss: 27.6461, val_MinusLogProbMetric: 27.6461

Epoch 78: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.6126 - MinusLogProbMetric: 27.6126 - val_loss: 27.6461 - val_MinusLogProbMetric: 27.6461 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 79/1000
2023-10-05 09:34:26.559 
Epoch 79/1000 
	 loss: 27.5994, MinusLogProbMetric: 27.5994, val_loss: 27.6708, val_MinusLogProbMetric: 27.6708

Epoch 79: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.5994 - MinusLogProbMetric: 27.5994 - val_loss: 27.6708 - val_MinusLogProbMetric: 27.6708 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 80/1000
2023-10-05 09:34:39.794 
Epoch 80/1000 
	 loss: 27.6354, MinusLogProbMetric: 27.6354, val_loss: 27.7797, val_MinusLogProbMetric: 27.7797

Epoch 80: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.6354 - MinusLogProbMetric: 27.6354 - val_loss: 27.7797 - val_MinusLogProbMetric: 27.7797 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 81/1000
2023-10-05 09:34:53.544 
Epoch 81/1000 
	 loss: 27.6230, MinusLogProbMetric: 27.6230, val_loss: 27.6216, val_MinusLogProbMetric: 27.6216

Epoch 81: val_loss did not improve from 27.61336
196/196 - 14s - loss: 27.6230 - MinusLogProbMetric: 27.6230 - val_loss: 27.6216 - val_MinusLogProbMetric: 27.6216 - lr: 0.0010 - 14s/epoch - 70ms/step
Epoch 82/1000
2023-10-05 09:35:07.116 
Epoch 82/1000 
	 loss: 27.6123, MinusLogProbMetric: 27.6123, val_loss: 27.6674, val_MinusLogProbMetric: 27.6674

Epoch 82: val_loss did not improve from 27.61336
196/196 - 14s - loss: 27.6123 - MinusLogProbMetric: 27.6123 - val_loss: 27.6674 - val_MinusLogProbMetric: 27.6674 - lr: 0.0010 - 14s/epoch - 69ms/step
Epoch 83/1000
2023-10-05 09:35:20.511 
Epoch 83/1000 
	 loss: 27.6126, MinusLogProbMetric: 27.6126, val_loss: 27.6873, val_MinusLogProbMetric: 27.6873

Epoch 83: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.6126 - MinusLogProbMetric: 27.6126 - val_loss: 27.6873 - val_MinusLogProbMetric: 27.6873 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 84/1000
2023-10-05 09:35:34.005 
Epoch 84/1000 
	 loss: 27.6148, MinusLogProbMetric: 27.6148, val_loss: 27.6990, val_MinusLogProbMetric: 27.6990

Epoch 84: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.6148 - MinusLogProbMetric: 27.6148 - val_loss: 27.6990 - val_MinusLogProbMetric: 27.6990 - lr: 0.0010 - 13s/epoch - 69ms/step
Epoch 85/1000
2023-10-05 09:35:47.641 
Epoch 85/1000 
	 loss: 27.5983, MinusLogProbMetric: 27.5983, val_loss: 27.7156, val_MinusLogProbMetric: 27.7156

Epoch 85: val_loss did not improve from 27.61336
196/196 - 14s - loss: 27.5983 - MinusLogProbMetric: 27.5983 - val_loss: 27.7156 - val_MinusLogProbMetric: 27.7156 - lr: 0.0010 - 14s/epoch - 70ms/step
Epoch 86/1000
2023-10-05 09:36:00.842 
Epoch 86/1000 
	 loss: 27.6103, MinusLogProbMetric: 27.6103, val_loss: 27.6773, val_MinusLogProbMetric: 27.6773

Epoch 86: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.6103 - MinusLogProbMetric: 27.6103 - val_loss: 27.6773 - val_MinusLogProbMetric: 27.6773 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 87/1000
2023-10-05 09:36:14.373 
Epoch 87/1000 
	 loss: 27.6053, MinusLogProbMetric: 27.6053, val_loss: 27.6846, val_MinusLogProbMetric: 27.6846

Epoch 87: val_loss did not improve from 27.61336
196/196 - 14s - loss: 27.6053 - MinusLogProbMetric: 27.6053 - val_loss: 27.6846 - val_MinusLogProbMetric: 27.6846 - lr: 0.0010 - 14s/epoch - 69ms/step
Epoch 88/1000
2023-10-05 09:36:27.305 
Epoch 88/1000 
	 loss: 27.6014, MinusLogProbMetric: 27.6014, val_loss: 27.7563, val_MinusLogProbMetric: 27.7563

Epoch 88: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.6014 - MinusLogProbMetric: 27.6014 - val_loss: 27.7563 - val_MinusLogProbMetric: 27.7563 - lr: 0.0010 - 13s/epoch - 66ms/step
Epoch 89/1000
2023-10-05 09:36:40.449 
Epoch 89/1000 
	 loss: 27.6028, MinusLogProbMetric: 27.6028, val_loss: 27.6199, val_MinusLogProbMetric: 27.6199

Epoch 89: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.6028 - MinusLogProbMetric: 27.6028 - val_loss: 27.6199 - val_MinusLogProbMetric: 27.6199 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 90/1000
2023-10-05 09:36:53.912 
Epoch 90/1000 
	 loss: 27.5864, MinusLogProbMetric: 27.5864, val_loss: 27.6446, val_MinusLogProbMetric: 27.6446

Epoch 90: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.5864 - MinusLogProbMetric: 27.5864 - val_loss: 27.6446 - val_MinusLogProbMetric: 27.6446 - lr: 0.0010 - 13s/epoch - 69ms/step
Epoch 91/1000
2023-10-05 09:37:07.038 
Epoch 91/1000 
	 loss: 27.6061, MinusLogProbMetric: 27.6061, val_loss: 27.6298, val_MinusLogProbMetric: 27.6298

Epoch 91: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.6061 - MinusLogProbMetric: 27.6061 - val_loss: 27.6298 - val_MinusLogProbMetric: 27.6298 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 92/1000
2023-10-05 09:37:20.364 
Epoch 92/1000 
	 loss: 27.6006, MinusLogProbMetric: 27.6006, val_loss: 27.6881, val_MinusLogProbMetric: 27.6881

Epoch 92: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.6006 - MinusLogProbMetric: 27.6006 - val_loss: 27.6881 - val_MinusLogProbMetric: 27.6881 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 93/1000
2023-10-05 09:37:33.649 
Epoch 93/1000 
	 loss: 27.5925, MinusLogProbMetric: 27.5925, val_loss: 27.6636, val_MinusLogProbMetric: 27.6636

Epoch 93: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.5925 - MinusLogProbMetric: 27.5925 - val_loss: 27.6636 - val_MinusLogProbMetric: 27.6636 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 94/1000
2023-10-05 09:37:46.982 
Epoch 94/1000 
	 loss: 27.5816, MinusLogProbMetric: 27.5816, val_loss: 27.7740, val_MinusLogProbMetric: 27.7740

Epoch 94: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.5816 - MinusLogProbMetric: 27.5816 - val_loss: 27.7740 - val_MinusLogProbMetric: 27.7740 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 95/1000
2023-10-05 09:38:00.370 
Epoch 95/1000 
	 loss: 27.5874, MinusLogProbMetric: 27.5874, val_loss: 27.6484, val_MinusLogProbMetric: 27.6484

Epoch 95: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.5874 - MinusLogProbMetric: 27.5874 - val_loss: 27.6484 - val_MinusLogProbMetric: 27.6484 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 96/1000
2023-10-05 09:38:13.652 
Epoch 96/1000 
	 loss: 27.5988, MinusLogProbMetric: 27.5988, val_loss: 27.8549, val_MinusLogProbMetric: 27.8549

Epoch 96: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.5988 - MinusLogProbMetric: 27.5988 - val_loss: 27.8549 - val_MinusLogProbMetric: 27.8549 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 97/1000
2023-10-05 09:38:26.849 
Epoch 97/1000 
	 loss: 27.6009, MinusLogProbMetric: 27.6009, val_loss: 27.6531, val_MinusLogProbMetric: 27.6531

Epoch 97: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.6009 - MinusLogProbMetric: 27.6009 - val_loss: 27.6531 - val_MinusLogProbMetric: 27.6531 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 98/1000
2023-10-05 09:38:40.602 
Epoch 98/1000 
	 loss: 27.5733, MinusLogProbMetric: 27.5733, val_loss: 27.6688, val_MinusLogProbMetric: 27.6688

Epoch 98: val_loss did not improve from 27.61336
196/196 - 14s - loss: 27.5733 - MinusLogProbMetric: 27.5733 - val_loss: 27.6688 - val_MinusLogProbMetric: 27.6688 - lr: 0.0010 - 14s/epoch - 70ms/step
Epoch 99/1000
2023-10-05 09:38:54.076 
Epoch 99/1000 
	 loss: 27.5853, MinusLogProbMetric: 27.5853, val_loss: 27.8624, val_MinusLogProbMetric: 27.8624

Epoch 99: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.5853 - MinusLogProbMetric: 27.5853 - val_loss: 27.8624 - val_MinusLogProbMetric: 27.8624 - lr: 0.0010 - 13s/epoch - 69ms/step
Epoch 100/1000
2023-10-05 09:39:07.360 
Epoch 100/1000 
	 loss: 27.5867, MinusLogProbMetric: 27.5867, val_loss: 27.6922, val_MinusLogProbMetric: 27.6922

Epoch 100: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.5867 - MinusLogProbMetric: 27.5867 - val_loss: 27.6922 - val_MinusLogProbMetric: 27.6922 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 101/1000
2023-10-05 09:39:20.843 
Epoch 101/1000 
	 loss: 27.5921, MinusLogProbMetric: 27.5921, val_loss: 27.6191, val_MinusLogProbMetric: 27.6191

Epoch 101: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.5921 - MinusLogProbMetric: 27.5921 - val_loss: 27.6191 - val_MinusLogProbMetric: 27.6191 - lr: 0.0010 - 13s/epoch - 69ms/step
Epoch 102/1000
2023-10-05 09:39:34.176 
Epoch 102/1000 
	 loss: 27.5820, MinusLogProbMetric: 27.5820, val_loss: 27.6539, val_MinusLogProbMetric: 27.6539

Epoch 102: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.5820 - MinusLogProbMetric: 27.5820 - val_loss: 27.6539 - val_MinusLogProbMetric: 27.6539 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 103/1000
2023-10-05 09:39:47.203 
Epoch 103/1000 
	 loss: 27.5871, MinusLogProbMetric: 27.5871, val_loss: 27.7171, val_MinusLogProbMetric: 27.7171

Epoch 103: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.5871 - MinusLogProbMetric: 27.5871 - val_loss: 27.7171 - val_MinusLogProbMetric: 27.7171 - lr: 0.0010 - 13s/epoch - 66ms/step
Epoch 104/1000
2023-10-05 09:40:00.526 
Epoch 104/1000 
	 loss: 27.5701, MinusLogProbMetric: 27.5701, val_loss: 27.7114, val_MinusLogProbMetric: 27.7114

Epoch 104: val_loss did not improve from 27.61336
196/196 - 13s - loss: 27.5701 - MinusLogProbMetric: 27.5701 - val_loss: 27.7114 - val_MinusLogProbMetric: 27.7114 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 105/1000
2023-10-05 09:40:13.914 
Epoch 105/1000 
	 loss: 27.5740, MinusLogProbMetric: 27.5740, val_loss: 27.6092, val_MinusLogProbMetric: 27.6092

Epoch 105: val_loss improved from 27.61336 to 27.60922, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 27.5740 - MinusLogProbMetric: 27.5740 - val_loss: 27.6092 - val_MinusLogProbMetric: 27.6092 - lr: 0.0010 - 14s/epoch - 69ms/step
Epoch 106/1000
2023-10-05 09:40:27.412 
Epoch 106/1000 
	 loss: 27.5767, MinusLogProbMetric: 27.5767, val_loss: 27.6340, val_MinusLogProbMetric: 27.6340

Epoch 106: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5767 - MinusLogProbMetric: 27.5767 - val_loss: 27.6340 - val_MinusLogProbMetric: 27.6340 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 107/1000
2023-10-05 09:40:40.774 
Epoch 107/1000 
	 loss: 27.5675, MinusLogProbMetric: 27.5675, val_loss: 27.6538, val_MinusLogProbMetric: 27.6538

Epoch 107: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5675 - MinusLogProbMetric: 27.5675 - val_loss: 27.6538 - val_MinusLogProbMetric: 27.6538 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 108/1000
2023-10-05 09:40:54.089 
Epoch 108/1000 
	 loss: 27.5821, MinusLogProbMetric: 27.5821, val_loss: 27.6569, val_MinusLogProbMetric: 27.6569

Epoch 108: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5821 - MinusLogProbMetric: 27.5821 - val_loss: 27.6569 - val_MinusLogProbMetric: 27.6569 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 109/1000
2023-10-05 09:41:07.353 
Epoch 109/1000 
	 loss: 27.5732, MinusLogProbMetric: 27.5732, val_loss: 27.6940, val_MinusLogProbMetric: 27.6940

Epoch 109: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5732 - MinusLogProbMetric: 27.5732 - val_loss: 27.6940 - val_MinusLogProbMetric: 27.6940 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 110/1000
2023-10-05 09:41:19.917 
Epoch 110/1000 
	 loss: 27.5872, MinusLogProbMetric: 27.5872, val_loss: 27.6534, val_MinusLogProbMetric: 27.6534

Epoch 110: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5872 - MinusLogProbMetric: 27.5872 - val_loss: 27.6534 - val_MinusLogProbMetric: 27.6534 - lr: 0.0010 - 13s/epoch - 64ms/step
Epoch 111/1000
2023-10-05 09:41:32.595 
Epoch 111/1000 
	 loss: 27.5633, MinusLogProbMetric: 27.5633, val_loss: 27.6774, val_MinusLogProbMetric: 27.6774

Epoch 111: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5633 - MinusLogProbMetric: 27.5633 - val_loss: 27.6774 - val_MinusLogProbMetric: 27.6774 - lr: 0.0010 - 13s/epoch - 65ms/step
Epoch 112/1000
2023-10-05 09:41:45.810 
Epoch 112/1000 
	 loss: 27.5802, MinusLogProbMetric: 27.5802, val_loss: 27.6837, val_MinusLogProbMetric: 27.6837

Epoch 112: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5802 - MinusLogProbMetric: 27.5802 - val_loss: 27.6837 - val_MinusLogProbMetric: 27.6837 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 113/1000
2023-10-05 09:41:58.705 
Epoch 113/1000 
	 loss: 27.5630, MinusLogProbMetric: 27.5630, val_loss: 27.6752, val_MinusLogProbMetric: 27.6752

Epoch 113: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5630 - MinusLogProbMetric: 27.5630 - val_loss: 27.6752 - val_MinusLogProbMetric: 27.6752 - lr: 0.0010 - 13s/epoch - 66ms/step
Epoch 114/1000
2023-10-05 09:42:11.244 
Epoch 114/1000 
	 loss: 27.5609, MinusLogProbMetric: 27.5609, val_loss: 27.6316, val_MinusLogProbMetric: 27.6316

Epoch 114: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5609 - MinusLogProbMetric: 27.5609 - val_loss: 27.6316 - val_MinusLogProbMetric: 27.6316 - lr: 0.0010 - 13s/epoch - 64ms/step
Epoch 115/1000
2023-10-05 09:42:24.645 
Epoch 115/1000 
	 loss: 27.5569, MinusLogProbMetric: 27.5569, val_loss: 27.6658, val_MinusLogProbMetric: 27.6658

Epoch 115: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5569 - MinusLogProbMetric: 27.5569 - val_loss: 27.6658 - val_MinusLogProbMetric: 27.6658 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 116/1000
2023-10-05 09:42:37.949 
Epoch 116/1000 
	 loss: 27.5641, MinusLogProbMetric: 27.5641, val_loss: 27.6280, val_MinusLogProbMetric: 27.6280

Epoch 116: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5641 - MinusLogProbMetric: 27.5641 - val_loss: 27.6280 - val_MinusLogProbMetric: 27.6280 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 117/1000
2023-10-05 09:42:51.281 
Epoch 117/1000 
	 loss: 27.5597, MinusLogProbMetric: 27.5597, val_loss: 27.7668, val_MinusLogProbMetric: 27.7668

Epoch 117: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5597 - MinusLogProbMetric: 27.5597 - val_loss: 27.7668 - val_MinusLogProbMetric: 27.7668 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 118/1000
2023-10-05 09:43:04.624 
Epoch 118/1000 
	 loss: 27.5658, MinusLogProbMetric: 27.5658, val_loss: 27.6173, val_MinusLogProbMetric: 27.6173

Epoch 118: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5658 - MinusLogProbMetric: 27.5658 - val_loss: 27.6173 - val_MinusLogProbMetric: 27.6173 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 119/1000
2023-10-05 09:43:17.926 
Epoch 119/1000 
	 loss: 27.5480, MinusLogProbMetric: 27.5480, val_loss: 27.6666, val_MinusLogProbMetric: 27.6666

Epoch 119: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5480 - MinusLogProbMetric: 27.5480 - val_loss: 27.6666 - val_MinusLogProbMetric: 27.6666 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 120/1000
2023-10-05 09:43:31.201 
Epoch 120/1000 
	 loss: 27.5514, MinusLogProbMetric: 27.5514, val_loss: 27.6989, val_MinusLogProbMetric: 27.6989

Epoch 120: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5514 - MinusLogProbMetric: 27.5514 - val_loss: 27.6989 - val_MinusLogProbMetric: 27.6989 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 121/1000
2023-10-05 09:43:44.399 
Epoch 121/1000 
	 loss: 27.5578, MinusLogProbMetric: 27.5578, val_loss: 27.6373, val_MinusLogProbMetric: 27.6373

Epoch 121: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5578 - MinusLogProbMetric: 27.5578 - val_loss: 27.6373 - val_MinusLogProbMetric: 27.6373 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 122/1000
2023-10-05 09:43:57.683 
Epoch 122/1000 
	 loss: 27.5530, MinusLogProbMetric: 27.5530, val_loss: 27.6969, val_MinusLogProbMetric: 27.6969

Epoch 122: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5530 - MinusLogProbMetric: 27.5530 - val_loss: 27.6969 - val_MinusLogProbMetric: 27.6969 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 123/1000
2023-10-05 09:44:10.963 
Epoch 123/1000 
	 loss: 27.5659, MinusLogProbMetric: 27.5659, val_loss: 27.7590, val_MinusLogProbMetric: 27.7590

Epoch 123: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5659 - MinusLogProbMetric: 27.5659 - val_loss: 27.7590 - val_MinusLogProbMetric: 27.7590 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 124/1000
2023-10-05 09:44:24.195 
Epoch 124/1000 
	 loss: 27.5515, MinusLogProbMetric: 27.5515, val_loss: 27.6427, val_MinusLogProbMetric: 27.6427

Epoch 124: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5515 - MinusLogProbMetric: 27.5515 - val_loss: 27.6427 - val_MinusLogProbMetric: 27.6427 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 125/1000
2023-10-05 09:44:37.456 
Epoch 125/1000 
	 loss: 27.5522, MinusLogProbMetric: 27.5522, val_loss: 27.6125, val_MinusLogProbMetric: 27.6125

Epoch 125: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5522 - MinusLogProbMetric: 27.5522 - val_loss: 27.6125 - val_MinusLogProbMetric: 27.6125 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 126/1000
2023-10-05 09:44:50.746 
Epoch 126/1000 
	 loss: 27.5368, MinusLogProbMetric: 27.5368, val_loss: 27.6234, val_MinusLogProbMetric: 27.6234

Epoch 126: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5368 - MinusLogProbMetric: 27.5368 - val_loss: 27.6234 - val_MinusLogProbMetric: 27.6234 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 127/1000
2023-10-05 09:45:04.249 
Epoch 127/1000 
	 loss: 27.5381, MinusLogProbMetric: 27.5381, val_loss: 27.6412, val_MinusLogProbMetric: 27.6412

Epoch 127: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5381 - MinusLogProbMetric: 27.5381 - val_loss: 27.6412 - val_MinusLogProbMetric: 27.6412 - lr: 0.0010 - 13s/epoch - 69ms/step
Epoch 128/1000
2023-10-05 09:45:17.506 
Epoch 128/1000 
	 loss: 27.5414, MinusLogProbMetric: 27.5414, val_loss: 27.6766, val_MinusLogProbMetric: 27.6766

Epoch 128: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5414 - MinusLogProbMetric: 27.5414 - val_loss: 27.6766 - val_MinusLogProbMetric: 27.6766 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 129/1000
2023-10-05 09:45:30.703 
Epoch 129/1000 
	 loss: 27.5393, MinusLogProbMetric: 27.5393, val_loss: 27.6250, val_MinusLogProbMetric: 27.6250

Epoch 129: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5393 - MinusLogProbMetric: 27.5393 - val_loss: 27.6250 - val_MinusLogProbMetric: 27.6250 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 130/1000
2023-10-05 09:45:43.347 
Epoch 130/1000 
	 loss: 27.5317, MinusLogProbMetric: 27.5317, val_loss: 27.6909, val_MinusLogProbMetric: 27.6909

Epoch 130: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5317 - MinusLogProbMetric: 27.5317 - val_loss: 27.6909 - val_MinusLogProbMetric: 27.6909 - lr: 0.0010 - 13s/epoch - 64ms/step
Epoch 131/1000
2023-10-05 09:45:56.580 
Epoch 131/1000 
	 loss: 27.5506, MinusLogProbMetric: 27.5506, val_loss: 27.6453, val_MinusLogProbMetric: 27.6453

Epoch 131: val_loss did not improve from 27.60922
196/196 - 13s - loss: 27.5506 - MinusLogProbMetric: 27.5506 - val_loss: 27.6453 - val_MinusLogProbMetric: 27.6453 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 132/1000
2023-10-05 09:46:09.932 
Epoch 132/1000 
	 loss: 27.5318, MinusLogProbMetric: 27.5318, val_loss: 27.5906, val_MinusLogProbMetric: 27.5906

Epoch 132: val_loss improved from 27.60922 to 27.59061, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 27.5318 - MinusLogProbMetric: 27.5318 - val_loss: 27.5906 - val_MinusLogProbMetric: 27.5906 - lr: 0.0010 - 14s/epoch - 69ms/step
Epoch 133/1000
2023-10-05 09:46:23.345 
Epoch 133/1000 
	 loss: 27.5523, MinusLogProbMetric: 27.5523, val_loss: 27.6727, val_MinusLogProbMetric: 27.6727

Epoch 133: val_loss did not improve from 27.59061
196/196 - 13s - loss: 27.5523 - MinusLogProbMetric: 27.5523 - val_loss: 27.6727 - val_MinusLogProbMetric: 27.6727 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 134/1000
2023-10-05 09:46:36.612 
Epoch 134/1000 
	 loss: 27.5418, MinusLogProbMetric: 27.5418, val_loss: 27.5932, val_MinusLogProbMetric: 27.5932

Epoch 134: val_loss did not improve from 27.59061
196/196 - 13s - loss: 27.5418 - MinusLogProbMetric: 27.5418 - val_loss: 27.5932 - val_MinusLogProbMetric: 27.5932 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 135/1000
2023-10-05 09:46:49.904 
Epoch 135/1000 
	 loss: 27.5443, MinusLogProbMetric: 27.5443, val_loss: 27.6202, val_MinusLogProbMetric: 27.6202

Epoch 135: val_loss did not improve from 27.59061
196/196 - 13s - loss: 27.5443 - MinusLogProbMetric: 27.5443 - val_loss: 27.6202 - val_MinusLogProbMetric: 27.6202 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 136/1000
2023-10-05 09:47:03.191 
Epoch 136/1000 
	 loss: 27.5266, MinusLogProbMetric: 27.5266, val_loss: 27.6436, val_MinusLogProbMetric: 27.6436

Epoch 136: val_loss did not improve from 27.59061
196/196 - 13s - loss: 27.5266 - MinusLogProbMetric: 27.5266 - val_loss: 27.6436 - val_MinusLogProbMetric: 27.6436 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 137/1000
2023-10-05 09:47:16.435 
Epoch 137/1000 
	 loss: 27.5334, MinusLogProbMetric: 27.5334, val_loss: 27.6461, val_MinusLogProbMetric: 27.6461

Epoch 137: val_loss did not improve from 27.59061
196/196 - 13s - loss: 27.5334 - MinusLogProbMetric: 27.5334 - val_loss: 27.6461 - val_MinusLogProbMetric: 27.6461 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 138/1000
2023-10-05 09:47:29.782 
Epoch 138/1000 
	 loss: 27.5323, MinusLogProbMetric: 27.5323, val_loss: 27.6298, val_MinusLogProbMetric: 27.6298

Epoch 138: val_loss did not improve from 27.59061
196/196 - 13s - loss: 27.5323 - MinusLogProbMetric: 27.5323 - val_loss: 27.6298 - val_MinusLogProbMetric: 27.6298 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 139/1000
2023-10-05 09:47:43.069 
Epoch 139/1000 
	 loss: 27.5395, MinusLogProbMetric: 27.5395, val_loss: 27.6176, val_MinusLogProbMetric: 27.6176

Epoch 139: val_loss did not improve from 27.59061
196/196 - 13s - loss: 27.5395 - MinusLogProbMetric: 27.5395 - val_loss: 27.6176 - val_MinusLogProbMetric: 27.6176 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 140/1000
2023-10-05 09:47:56.071 
Epoch 140/1000 
	 loss: 27.5410, MinusLogProbMetric: 27.5410, val_loss: 27.6032, val_MinusLogProbMetric: 27.6032

Epoch 140: val_loss did not improve from 27.59061
196/196 - 13s - loss: 27.5410 - MinusLogProbMetric: 27.5410 - val_loss: 27.6032 - val_MinusLogProbMetric: 27.6032 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 141/1000
2023-10-05 09:48:09.340 
Epoch 141/1000 
	 loss: 27.5242, MinusLogProbMetric: 27.5242, val_loss: 27.6203, val_MinusLogProbMetric: 27.6203

Epoch 141: val_loss did not improve from 27.59061
196/196 - 13s - loss: 27.5242 - MinusLogProbMetric: 27.5242 - val_loss: 27.6203 - val_MinusLogProbMetric: 27.6203 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 142/1000
2023-10-05 09:48:22.528 
Epoch 142/1000 
	 loss: 27.5234, MinusLogProbMetric: 27.5234, val_loss: 27.5883, val_MinusLogProbMetric: 27.5883

Epoch 142: val_loss improved from 27.59061 to 27.58833, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 13s - loss: 27.5234 - MinusLogProbMetric: 27.5234 - val_loss: 27.5883 - val_MinusLogProbMetric: 27.5883 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 143/1000
2023-10-05 09:48:35.813 
Epoch 143/1000 
	 loss: 27.5182, MinusLogProbMetric: 27.5182, val_loss: 27.6378, val_MinusLogProbMetric: 27.6378

Epoch 143: val_loss did not improve from 27.58833
196/196 - 13s - loss: 27.5182 - MinusLogProbMetric: 27.5182 - val_loss: 27.6378 - val_MinusLogProbMetric: 27.6378 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 144/1000
2023-10-05 09:48:49.055 
Epoch 144/1000 
	 loss: 27.5476, MinusLogProbMetric: 27.5476, val_loss: 27.6610, val_MinusLogProbMetric: 27.6610

Epoch 144: val_loss did not improve from 27.58833
196/196 - 13s - loss: 27.5476 - MinusLogProbMetric: 27.5476 - val_loss: 27.6610 - val_MinusLogProbMetric: 27.6610 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 145/1000
2023-10-05 09:49:02.393 
Epoch 145/1000 
	 loss: 27.5233, MinusLogProbMetric: 27.5233, val_loss: 27.6910, val_MinusLogProbMetric: 27.6910

Epoch 145: val_loss did not improve from 27.58833
196/196 - 13s - loss: 27.5233 - MinusLogProbMetric: 27.5233 - val_loss: 27.6910 - val_MinusLogProbMetric: 27.6910 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 146/1000
2023-10-05 09:49:15.661 
Epoch 146/1000 
	 loss: 27.5166, MinusLogProbMetric: 27.5166, val_loss: 27.6011, val_MinusLogProbMetric: 27.6011

Epoch 146: val_loss did not improve from 27.58833
196/196 - 13s - loss: 27.5166 - MinusLogProbMetric: 27.5166 - val_loss: 27.6011 - val_MinusLogProbMetric: 27.6011 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 147/1000
2023-10-05 09:49:28.884 
Epoch 147/1000 
	 loss: 27.5249, MinusLogProbMetric: 27.5249, val_loss: 27.5982, val_MinusLogProbMetric: 27.5982

Epoch 147: val_loss did not improve from 27.58833
196/196 - 13s - loss: 27.5249 - MinusLogProbMetric: 27.5249 - val_loss: 27.5982 - val_MinusLogProbMetric: 27.5982 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 148/1000
2023-10-05 09:49:42.138 
Epoch 148/1000 
	 loss: 27.5226, MinusLogProbMetric: 27.5226, val_loss: 27.6177, val_MinusLogProbMetric: 27.6177

Epoch 148: val_loss did not improve from 27.58833
196/196 - 13s - loss: 27.5226 - MinusLogProbMetric: 27.5226 - val_loss: 27.6177 - val_MinusLogProbMetric: 27.6177 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 149/1000
2023-10-05 09:49:55.459 
Epoch 149/1000 
	 loss: 27.5332, MinusLogProbMetric: 27.5332, val_loss: 27.5750, val_MinusLogProbMetric: 27.5750

Epoch 149: val_loss improved from 27.58833 to 27.57498, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 13s - loss: 27.5332 - MinusLogProbMetric: 27.5332 - val_loss: 27.5750 - val_MinusLogProbMetric: 27.5750 - lr: 0.0010 - 13s/epoch - 69ms/step
Epoch 150/1000
2023-10-05 09:50:08.842 
Epoch 150/1000 
	 loss: 27.5228, MinusLogProbMetric: 27.5228, val_loss: 27.5777, val_MinusLogProbMetric: 27.5777

Epoch 150: val_loss did not improve from 27.57498
196/196 - 13s - loss: 27.5228 - MinusLogProbMetric: 27.5228 - val_loss: 27.5777 - val_MinusLogProbMetric: 27.5777 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 151/1000
2023-10-05 09:50:22.087 
Epoch 151/1000 
	 loss: 27.5221, MinusLogProbMetric: 27.5221, val_loss: 27.6195, val_MinusLogProbMetric: 27.6195

Epoch 151: val_loss did not improve from 27.57498
196/196 - 13s - loss: 27.5221 - MinusLogProbMetric: 27.5221 - val_loss: 27.6195 - val_MinusLogProbMetric: 27.6195 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 152/1000
2023-10-05 09:50:35.147 
Epoch 152/1000 
	 loss: 27.5229, MinusLogProbMetric: 27.5229, val_loss: 27.6554, val_MinusLogProbMetric: 27.6554

Epoch 152: val_loss did not improve from 27.57498
196/196 - 13s - loss: 27.5229 - MinusLogProbMetric: 27.5229 - val_loss: 27.6554 - val_MinusLogProbMetric: 27.6554 - lr: 0.0010 - 13s/epoch - 66ms/step
Epoch 153/1000
2023-10-05 09:50:48.015 
Epoch 153/1000 
	 loss: 27.5257, MinusLogProbMetric: 27.5257, val_loss: 27.6359, val_MinusLogProbMetric: 27.6359

Epoch 153: val_loss did not improve from 27.57498
196/196 - 13s - loss: 27.5257 - MinusLogProbMetric: 27.5257 - val_loss: 27.6359 - val_MinusLogProbMetric: 27.6359 - lr: 0.0010 - 13s/epoch - 65ms/step
Epoch 154/1000
2023-10-05 09:51:01.292 
Epoch 154/1000 
	 loss: 27.5133, MinusLogProbMetric: 27.5133, val_loss: 27.6065, val_MinusLogProbMetric: 27.6065

Epoch 154: val_loss did not improve from 27.57498
196/196 - 13s - loss: 27.5133 - MinusLogProbMetric: 27.5133 - val_loss: 27.6065 - val_MinusLogProbMetric: 27.6065 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 155/1000
2023-10-05 09:51:14.727 
Epoch 155/1000 
	 loss: 27.5198, MinusLogProbMetric: 27.5198, val_loss: 27.5895, val_MinusLogProbMetric: 27.5895

Epoch 155: val_loss did not improve from 27.57498
196/196 - 13s - loss: 27.5198 - MinusLogProbMetric: 27.5198 - val_loss: 27.5895 - val_MinusLogProbMetric: 27.5895 - lr: 0.0010 - 13s/epoch - 69ms/step
Epoch 156/1000
2023-10-05 09:51:27.915 
Epoch 156/1000 
	 loss: 27.5027, MinusLogProbMetric: 27.5027, val_loss: 27.5961, val_MinusLogProbMetric: 27.5961

Epoch 156: val_loss did not improve from 27.57498
196/196 - 13s - loss: 27.5027 - MinusLogProbMetric: 27.5027 - val_loss: 27.5961 - val_MinusLogProbMetric: 27.5961 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 157/1000
2023-10-05 09:51:40.666 
Epoch 157/1000 
	 loss: 27.5179, MinusLogProbMetric: 27.5179, val_loss: 27.6042, val_MinusLogProbMetric: 27.6042

Epoch 157: val_loss did not improve from 27.57498
196/196 - 13s - loss: 27.5179 - MinusLogProbMetric: 27.5179 - val_loss: 27.6042 - val_MinusLogProbMetric: 27.6042 - lr: 0.0010 - 13s/epoch - 66ms/step
Epoch 158/1000
2023-10-05 09:51:51.945 
Epoch 158/1000 
	 loss: 27.5153, MinusLogProbMetric: 27.5153, val_loss: 27.5845, val_MinusLogProbMetric: 27.5845

Epoch 158: val_loss did not improve from 27.57498
196/196 - 11s - loss: 27.5153 - MinusLogProbMetric: 27.5153 - val_loss: 27.5845 - val_MinusLogProbMetric: 27.5845 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 159/1000
2023-10-05 09:52:04.469 
Epoch 159/1000 
	 loss: 27.5102, MinusLogProbMetric: 27.5102, val_loss: 27.5573, val_MinusLogProbMetric: 27.5573

Epoch 159: val_loss improved from 27.57498 to 27.55729, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 13s - loss: 27.5102 - MinusLogProbMetric: 27.5102 - val_loss: 27.5573 - val_MinusLogProbMetric: 27.5573 - lr: 0.0010 - 13s/epoch - 66ms/step
Epoch 160/1000
2023-10-05 09:52:18.174 
Epoch 160/1000 
	 loss: 27.5057, MinusLogProbMetric: 27.5057, val_loss: 27.7034, val_MinusLogProbMetric: 27.7034

Epoch 160: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.5057 - MinusLogProbMetric: 27.5057 - val_loss: 27.7034 - val_MinusLogProbMetric: 27.7034 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 161/1000
2023-10-05 09:52:31.514 
Epoch 161/1000 
	 loss: 27.5175, MinusLogProbMetric: 27.5175, val_loss: 27.6389, val_MinusLogProbMetric: 27.6389

Epoch 161: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.5175 - MinusLogProbMetric: 27.5175 - val_loss: 27.6389 - val_MinusLogProbMetric: 27.6389 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 162/1000
2023-10-05 09:52:44.684 
Epoch 162/1000 
	 loss: 27.5106, MinusLogProbMetric: 27.5106, val_loss: 27.5948, val_MinusLogProbMetric: 27.5948

Epoch 162: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.5106 - MinusLogProbMetric: 27.5106 - val_loss: 27.5948 - val_MinusLogProbMetric: 27.5948 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 163/1000
2023-10-05 09:52:57.860 
Epoch 163/1000 
	 loss: 27.5130, MinusLogProbMetric: 27.5130, val_loss: 27.6473, val_MinusLogProbMetric: 27.6473

Epoch 163: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.5130 - MinusLogProbMetric: 27.5130 - val_loss: 27.6473 - val_MinusLogProbMetric: 27.6473 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 164/1000
2023-10-05 09:53:11.158 
Epoch 164/1000 
	 loss: 27.5217, MinusLogProbMetric: 27.5217, val_loss: 27.6300, val_MinusLogProbMetric: 27.6300

Epoch 164: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.5217 - MinusLogProbMetric: 27.5217 - val_loss: 27.6300 - val_MinusLogProbMetric: 27.6300 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 165/1000
2023-10-05 09:53:24.398 
Epoch 165/1000 
	 loss: 27.5197, MinusLogProbMetric: 27.5197, val_loss: 27.5909, val_MinusLogProbMetric: 27.5909

Epoch 165: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.5197 - MinusLogProbMetric: 27.5197 - val_loss: 27.5909 - val_MinusLogProbMetric: 27.5909 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 166/1000
2023-10-05 09:53:37.649 
Epoch 166/1000 
	 loss: 27.5131, MinusLogProbMetric: 27.5131, val_loss: 27.6262, val_MinusLogProbMetric: 27.6262

Epoch 166: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.5131 - MinusLogProbMetric: 27.5131 - val_loss: 27.6262 - val_MinusLogProbMetric: 27.6262 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 167/1000
2023-10-05 09:53:50.877 
Epoch 167/1000 
	 loss: 27.5048, MinusLogProbMetric: 27.5048, val_loss: 27.5968, val_MinusLogProbMetric: 27.5968

Epoch 167: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.5048 - MinusLogProbMetric: 27.5048 - val_loss: 27.5968 - val_MinusLogProbMetric: 27.5968 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 168/1000
2023-10-05 09:54:04.095 
Epoch 168/1000 
	 loss: 27.5043, MinusLogProbMetric: 27.5043, val_loss: 27.6295, val_MinusLogProbMetric: 27.6295

Epoch 168: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.5043 - MinusLogProbMetric: 27.5043 - val_loss: 27.6295 - val_MinusLogProbMetric: 27.6295 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 169/1000
2023-10-05 09:54:17.410 
Epoch 169/1000 
	 loss: 27.5113, MinusLogProbMetric: 27.5113, val_loss: 27.6134, val_MinusLogProbMetric: 27.6134

Epoch 169: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.5113 - MinusLogProbMetric: 27.5113 - val_loss: 27.6134 - val_MinusLogProbMetric: 27.6134 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 170/1000
2023-10-05 09:54:30.759 
Epoch 170/1000 
	 loss: 27.4985, MinusLogProbMetric: 27.4985, val_loss: 27.5736, val_MinusLogProbMetric: 27.5736

Epoch 170: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.4985 - MinusLogProbMetric: 27.4985 - val_loss: 27.5736 - val_MinusLogProbMetric: 27.5736 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 171/1000
2023-10-05 09:54:43.928 
Epoch 171/1000 
	 loss: 27.5073, MinusLogProbMetric: 27.5073, val_loss: 27.5976, val_MinusLogProbMetric: 27.5976

Epoch 171: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.5073 - MinusLogProbMetric: 27.5073 - val_loss: 27.5976 - val_MinusLogProbMetric: 27.5976 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 172/1000
2023-10-05 09:54:57.295 
Epoch 172/1000 
	 loss: 27.4895, MinusLogProbMetric: 27.4895, val_loss: 27.6374, val_MinusLogProbMetric: 27.6374

Epoch 172: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.4895 - MinusLogProbMetric: 27.4895 - val_loss: 27.6374 - val_MinusLogProbMetric: 27.6374 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 173/1000
2023-10-05 09:55:10.551 
Epoch 173/1000 
	 loss: 27.5077, MinusLogProbMetric: 27.5077, val_loss: 27.6855, val_MinusLogProbMetric: 27.6855

Epoch 173: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.5077 - MinusLogProbMetric: 27.5077 - val_loss: 27.6855 - val_MinusLogProbMetric: 27.6855 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 174/1000
2023-10-05 09:55:24.015 
Epoch 174/1000 
	 loss: 27.5061, MinusLogProbMetric: 27.5061, val_loss: 27.6140, val_MinusLogProbMetric: 27.6140

Epoch 174: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.5061 - MinusLogProbMetric: 27.5061 - val_loss: 27.6140 - val_MinusLogProbMetric: 27.6140 - lr: 0.0010 - 13s/epoch - 69ms/step
Epoch 175/1000
2023-10-05 09:55:37.277 
Epoch 175/1000 
	 loss: 27.4990, MinusLogProbMetric: 27.4990, val_loss: 27.5658, val_MinusLogProbMetric: 27.5658

Epoch 175: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.4990 - MinusLogProbMetric: 27.4990 - val_loss: 27.5658 - val_MinusLogProbMetric: 27.5658 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 176/1000
2023-10-05 09:55:50.068 
Epoch 176/1000 
	 loss: 27.4976, MinusLogProbMetric: 27.4976, val_loss: 27.6609, val_MinusLogProbMetric: 27.6609

Epoch 176: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.4976 - MinusLogProbMetric: 27.4976 - val_loss: 27.6609 - val_MinusLogProbMetric: 27.6609 - lr: 0.0010 - 13s/epoch - 65ms/step
Epoch 177/1000
2023-10-05 09:56:03.280 
Epoch 177/1000 
	 loss: 27.5065, MinusLogProbMetric: 27.5065, val_loss: 27.6529, val_MinusLogProbMetric: 27.6529

Epoch 177: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.5065 - MinusLogProbMetric: 27.5065 - val_loss: 27.6529 - val_MinusLogProbMetric: 27.6529 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 178/1000
2023-10-05 09:56:16.792 
Epoch 178/1000 
	 loss: 27.5038, MinusLogProbMetric: 27.5038, val_loss: 27.5844, val_MinusLogProbMetric: 27.5844

Epoch 178: val_loss did not improve from 27.55729
196/196 - 14s - loss: 27.5038 - MinusLogProbMetric: 27.5038 - val_loss: 27.5844 - val_MinusLogProbMetric: 27.5844 - lr: 0.0010 - 14s/epoch - 69ms/step
Epoch 179/1000
2023-10-05 09:56:29.972 
Epoch 179/1000 
	 loss: 27.4983, MinusLogProbMetric: 27.4983, val_loss: 27.6794, val_MinusLogProbMetric: 27.6794

Epoch 179: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.4983 - MinusLogProbMetric: 27.4983 - val_loss: 27.6794 - val_MinusLogProbMetric: 27.6794 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 180/1000
2023-10-05 09:56:43.021 
Epoch 180/1000 
	 loss: 27.5078, MinusLogProbMetric: 27.5078, val_loss: 27.6533, val_MinusLogProbMetric: 27.6533

Epoch 180: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.5078 - MinusLogProbMetric: 27.5078 - val_loss: 27.6533 - val_MinusLogProbMetric: 27.6533 - lr: 0.0010 - 13s/epoch - 66ms/step
Epoch 181/1000
2023-10-05 09:56:56.100 
Epoch 181/1000 
	 loss: 27.5008, MinusLogProbMetric: 27.5008, val_loss: 27.6141, val_MinusLogProbMetric: 27.6141

Epoch 181: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.5008 - MinusLogProbMetric: 27.5008 - val_loss: 27.6141 - val_MinusLogProbMetric: 27.6141 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 182/1000
2023-10-05 09:57:07.724 
Epoch 182/1000 
	 loss: 27.4930, MinusLogProbMetric: 27.4930, val_loss: 27.6570, val_MinusLogProbMetric: 27.6570

Epoch 182: val_loss did not improve from 27.55729
196/196 - 12s - loss: 27.4930 - MinusLogProbMetric: 27.4930 - val_loss: 27.6570 - val_MinusLogProbMetric: 27.6570 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 183/1000
2023-10-05 09:57:21.337 
Epoch 183/1000 
	 loss: 27.4956, MinusLogProbMetric: 27.4956, val_loss: 27.6150, val_MinusLogProbMetric: 27.6150

Epoch 183: val_loss did not improve from 27.55729
196/196 - 14s - loss: 27.4956 - MinusLogProbMetric: 27.4956 - val_loss: 27.6150 - val_MinusLogProbMetric: 27.6150 - lr: 0.0010 - 14s/epoch - 69ms/step
Epoch 184/1000
2023-10-05 09:57:34.634 
Epoch 184/1000 
	 loss: 27.4924, MinusLogProbMetric: 27.4924, val_loss: 27.6009, val_MinusLogProbMetric: 27.6009

Epoch 184: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.4924 - MinusLogProbMetric: 27.4924 - val_loss: 27.6009 - val_MinusLogProbMetric: 27.6009 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 185/1000
2023-10-05 09:57:47.860 
Epoch 185/1000 
	 loss: 27.4926, MinusLogProbMetric: 27.4926, val_loss: 27.6023, val_MinusLogProbMetric: 27.6023

Epoch 185: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.4926 - MinusLogProbMetric: 27.4926 - val_loss: 27.6023 - val_MinusLogProbMetric: 27.6023 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 186/1000
2023-10-05 09:58:00.285 
Epoch 186/1000 
	 loss: 27.5019, MinusLogProbMetric: 27.5019, val_loss: 27.7768, val_MinusLogProbMetric: 27.7768

Epoch 186: val_loss did not improve from 27.55729
196/196 - 12s - loss: 27.5019 - MinusLogProbMetric: 27.5019 - val_loss: 27.7768 - val_MinusLogProbMetric: 27.7768 - lr: 0.0010 - 12s/epoch - 63ms/step
Epoch 187/1000
2023-10-05 09:58:12.977 
Epoch 187/1000 
	 loss: 27.4922, MinusLogProbMetric: 27.4922, val_loss: 27.6028, val_MinusLogProbMetric: 27.6028

Epoch 187: val_loss did not improve from 27.55729
196/196 - 13s - loss: 27.4922 - MinusLogProbMetric: 27.4922 - val_loss: 27.6028 - val_MinusLogProbMetric: 27.6028 - lr: 0.0010 - 13s/epoch - 65ms/step
Epoch 188/1000
2023-10-05 09:58:23.435 
Epoch 188/1000 
	 loss: 27.4837, MinusLogProbMetric: 27.4837, val_loss: 27.6331, val_MinusLogProbMetric: 27.6331

Epoch 188: val_loss did not improve from 27.55729
196/196 - 10s - loss: 27.4837 - MinusLogProbMetric: 27.4837 - val_loss: 27.6331 - val_MinusLogProbMetric: 27.6331 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 189/1000
2023-10-05 09:58:33.995 
Epoch 189/1000 
	 loss: 27.4917, MinusLogProbMetric: 27.4917, val_loss: 27.6897, val_MinusLogProbMetric: 27.6897

Epoch 189: val_loss did not improve from 27.55729
196/196 - 11s - loss: 27.4917 - MinusLogProbMetric: 27.4917 - val_loss: 27.6897 - val_MinusLogProbMetric: 27.6897 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 190/1000
2023-10-05 09:58:45.371 
Epoch 190/1000 
	 loss: 27.4910, MinusLogProbMetric: 27.4910, val_loss: 27.6960, val_MinusLogProbMetric: 27.6960

Epoch 190: val_loss did not improve from 27.55729
196/196 - 11s - loss: 27.4910 - MinusLogProbMetric: 27.4910 - val_loss: 27.6960 - val_MinusLogProbMetric: 27.6960 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 191/1000
2023-10-05 09:58:56.631 
Epoch 191/1000 
	 loss: 27.4966, MinusLogProbMetric: 27.4966, val_loss: 27.6374, val_MinusLogProbMetric: 27.6374

Epoch 191: val_loss did not improve from 27.55729
196/196 - 11s - loss: 27.4966 - MinusLogProbMetric: 27.4966 - val_loss: 27.6374 - val_MinusLogProbMetric: 27.6374 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 192/1000
2023-10-05 09:59:07.029 
Epoch 192/1000 
	 loss: 27.4851, MinusLogProbMetric: 27.4851, val_loss: 27.6441, val_MinusLogProbMetric: 27.6441

Epoch 192: val_loss did not improve from 27.55729
196/196 - 10s - loss: 27.4851 - MinusLogProbMetric: 27.4851 - val_loss: 27.6441 - val_MinusLogProbMetric: 27.6441 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 193/1000
2023-10-05 09:59:17.487 
Epoch 193/1000 
	 loss: 27.4938, MinusLogProbMetric: 27.4938, val_loss: 27.6776, val_MinusLogProbMetric: 27.6776

Epoch 193: val_loss did not improve from 27.55729
196/196 - 10s - loss: 27.4938 - MinusLogProbMetric: 27.4938 - val_loss: 27.6776 - val_MinusLogProbMetric: 27.6776 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 194/1000
2023-10-05 09:59:27.714 
Epoch 194/1000 
	 loss: 27.4913, MinusLogProbMetric: 27.4913, val_loss: 27.5954, val_MinusLogProbMetric: 27.5954

Epoch 194: val_loss did not improve from 27.55729
196/196 - 10s - loss: 27.4913 - MinusLogProbMetric: 27.4913 - val_loss: 27.5954 - val_MinusLogProbMetric: 27.5954 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 195/1000
2023-10-05 09:59:37.846 
Epoch 195/1000 
	 loss: 27.4949, MinusLogProbMetric: 27.4949, val_loss: 27.6761, val_MinusLogProbMetric: 27.6761

Epoch 195: val_loss did not improve from 27.55729
196/196 - 10s - loss: 27.4949 - MinusLogProbMetric: 27.4949 - val_loss: 27.6761 - val_MinusLogProbMetric: 27.6761 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 196/1000
2023-10-05 09:59:49.431 
Epoch 196/1000 
	 loss: 27.4963, MinusLogProbMetric: 27.4963, val_loss: 27.6386, val_MinusLogProbMetric: 27.6386

Epoch 196: val_loss did not improve from 27.55729
196/196 - 12s - loss: 27.4963 - MinusLogProbMetric: 27.4963 - val_loss: 27.6386 - val_MinusLogProbMetric: 27.6386 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 197/1000
2023-10-05 09:59:59.736 
Epoch 197/1000 
	 loss: 27.4807, MinusLogProbMetric: 27.4807, val_loss: 27.6207, val_MinusLogProbMetric: 27.6207

Epoch 197: val_loss did not improve from 27.55729
196/196 - 10s - loss: 27.4807 - MinusLogProbMetric: 27.4807 - val_loss: 27.6207 - val_MinusLogProbMetric: 27.6207 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 198/1000
2023-10-05 10:00:10.279 
Epoch 198/1000 
	 loss: 27.4817, MinusLogProbMetric: 27.4817, val_loss: 27.6123, val_MinusLogProbMetric: 27.6123

Epoch 198: val_loss did not improve from 27.55729
196/196 - 11s - loss: 27.4817 - MinusLogProbMetric: 27.4817 - val_loss: 27.6123 - val_MinusLogProbMetric: 27.6123 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 199/1000
2023-10-05 10:00:21.060 
Epoch 199/1000 
	 loss: 27.4887, MinusLogProbMetric: 27.4887, val_loss: 27.5932, val_MinusLogProbMetric: 27.5932

Epoch 199: val_loss did not improve from 27.55729
196/196 - 11s - loss: 27.4887 - MinusLogProbMetric: 27.4887 - val_loss: 27.5932 - val_MinusLogProbMetric: 27.5932 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 200/1000
2023-10-05 10:00:31.778 
Epoch 200/1000 
	 loss: 27.4842, MinusLogProbMetric: 27.4842, val_loss: 27.6232, val_MinusLogProbMetric: 27.6232

Epoch 200: val_loss did not improve from 27.55729
196/196 - 11s - loss: 27.4842 - MinusLogProbMetric: 27.4842 - val_loss: 27.6232 - val_MinusLogProbMetric: 27.6232 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 201/1000
2023-10-05 10:00:43.457 
Epoch 201/1000 
	 loss: 27.4817, MinusLogProbMetric: 27.4817, val_loss: 27.5932, val_MinusLogProbMetric: 27.5932

Epoch 201: val_loss did not improve from 27.55729
196/196 - 12s - loss: 27.4817 - MinusLogProbMetric: 27.4817 - val_loss: 27.5932 - val_MinusLogProbMetric: 27.5932 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 202/1000
2023-10-05 10:00:54.107 
Epoch 202/1000 
	 loss: 27.4859, MinusLogProbMetric: 27.4859, val_loss: 27.6100, val_MinusLogProbMetric: 27.6100

Epoch 202: val_loss did not improve from 27.55729
196/196 - 11s - loss: 27.4859 - MinusLogProbMetric: 27.4859 - val_loss: 27.6100 - val_MinusLogProbMetric: 27.6100 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 203/1000
2023-10-05 10:01:04.848 
Epoch 203/1000 
	 loss: 27.4807, MinusLogProbMetric: 27.4807, val_loss: 27.6173, val_MinusLogProbMetric: 27.6173

Epoch 203: val_loss did not improve from 27.55729
196/196 - 11s - loss: 27.4807 - MinusLogProbMetric: 27.4807 - val_loss: 27.6173 - val_MinusLogProbMetric: 27.6173 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 204/1000
2023-10-05 10:01:15.788 
Epoch 204/1000 
	 loss: 27.4791, MinusLogProbMetric: 27.4791, val_loss: 27.5903, val_MinusLogProbMetric: 27.5903

Epoch 204: val_loss did not improve from 27.55729
196/196 - 11s - loss: 27.4791 - MinusLogProbMetric: 27.4791 - val_loss: 27.5903 - val_MinusLogProbMetric: 27.5903 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 205/1000
2023-10-05 10:01:26.702 
Epoch 205/1000 
	 loss: 27.4806, MinusLogProbMetric: 27.4806, val_loss: 27.6467, val_MinusLogProbMetric: 27.6467

Epoch 205: val_loss did not improve from 27.55729
196/196 - 11s - loss: 27.4806 - MinusLogProbMetric: 27.4806 - val_loss: 27.6467 - val_MinusLogProbMetric: 27.6467 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 206/1000
2023-10-05 10:01:37.455 
Epoch 206/1000 
	 loss: 27.4788, MinusLogProbMetric: 27.4788, val_loss: 27.5821, val_MinusLogProbMetric: 27.5821

Epoch 206: val_loss did not improve from 27.55729
196/196 - 11s - loss: 27.4788 - MinusLogProbMetric: 27.4788 - val_loss: 27.5821 - val_MinusLogProbMetric: 27.5821 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 207/1000
2023-10-05 10:01:48.795 
Epoch 207/1000 
	 loss: 27.4823, MinusLogProbMetric: 27.4823, val_loss: 27.6431, val_MinusLogProbMetric: 27.6431

Epoch 207: val_loss did not improve from 27.55729
196/196 - 11s - loss: 27.4823 - MinusLogProbMetric: 27.4823 - val_loss: 27.6431 - val_MinusLogProbMetric: 27.6431 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 208/1000
2023-10-05 10:01:59.856 
Epoch 208/1000 
	 loss: 27.4781, MinusLogProbMetric: 27.4781, val_loss: 27.6539, val_MinusLogProbMetric: 27.6539

Epoch 208: val_loss did not improve from 27.55729
196/196 - 11s - loss: 27.4781 - MinusLogProbMetric: 27.4781 - val_loss: 27.6539 - val_MinusLogProbMetric: 27.6539 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 209/1000
2023-10-05 10:02:10.764 
Epoch 209/1000 
	 loss: 27.4786, MinusLogProbMetric: 27.4786, val_loss: 27.5939, val_MinusLogProbMetric: 27.5939

Epoch 209: val_loss did not improve from 27.55729
196/196 - 11s - loss: 27.4786 - MinusLogProbMetric: 27.4786 - val_loss: 27.5939 - val_MinusLogProbMetric: 27.5939 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 210/1000
2023-10-05 10:02:21.909 
Epoch 210/1000 
	 loss: 27.3957, MinusLogProbMetric: 27.3957, val_loss: 27.5223, val_MinusLogProbMetric: 27.5223

Epoch 210: val_loss improved from 27.55729 to 27.52230, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 12s - loss: 27.3957 - MinusLogProbMetric: 27.3957 - val_loss: 27.5223 - val_MinusLogProbMetric: 27.5223 - lr: 5.0000e-04 - 12s/epoch - 63ms/step
Epoch 211/1000
2023-10-05 10:02:34.039 
Epoch 211/1000 
	 loss: 27.3960, MinusLogProbMetric: 27.3960, val_loss: 27.5277, val_MinusLogProbMetric: 27.5277

Epoch 211: val_loss did not improve from 27.52230
196/196 - 11s - loss: 27.3960 - MinusLogProbMetric: 27.3960 - val_loss: 27.5277 - val_MinusLogProbMetric: 27.5277 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 212/1000
2023-10-05 10:02:45.112 
Epoch 212/1000 
	 loss: 27.3907, MinusLogProbMetric: 27.3907, val_loss: 27.5480, val_MinusLogProbMetric: 27.5480

Epoch 212: val_loss did not improve from 27.52230
196/196 - 11s - loss: 27.3907 - MinusLogProbMetric: 27.3907 - val_loss: 27.5480 - val_MinusLogProbMetric: 27.5480 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 213/1000
2023-10-05 10:02:56.164 
Epoch 213/1000 
	 loss: 27.3943, MinusLogProbMetric: 27.3943, val_loss: 27.5302, val_MinusLogProbMetric: 27.5302

Epoch 213: val_loss did not improve from 27.52230
196/196 - 11s - loss: 27.3943 - MinusLogProbMetric: 27.3943 - val_loss: 27.5302 - val_MinusLogProbMetric: 27.5302 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 214/1000
2023-10-05 10:03:07.192 
Epoch 214/1000 
	 loss: 27.3904, MinusLogProbMetric: 27.3904, val_loss: 27.5277, val_MinusLogProbMetric: 27.5277

Epoch 214: val_loss did not improve from 27.52230
196/196 - 11s - loss: 27.3904 - MinusLogProbMetric: 27.3904 - val_loss: 27.5277 - val_MinusLogProbMetric: 27.5277 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 215/1000
2023-10-05 10:03:17.926 
Epoch 215/1000 
	 loss: 27.3920, MinusLogProbMetric: 27.3920, val_loss: 27.5406, val_MinusLogProbMetric: 27.5406

Epoch 215: val_loss did not improve from 27.52230
196/196 - 11s - loss: 27.3920 - MinusLogProbMetric: 27.3920 - val_loss: 27.5406 - val_MinusLogProbMetric: 27.5406 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 216/1000
2023-10-05 10:03:29.030 
Epoch 216/1000 
	 loss: 27.3921, MinusLogProbMetric: 27.3921, val_loss: 27.5562, val_MinusLogProbMetric: 27.5562

Epoch 216: val_loss did not improve from 27.52230
196/196 - 11s - loss: 27.3921 - MinusLogProbMetric: 27.3921 - val_loss: 27.5562 - val_MinusLogProbMetric: 27.5562 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 217/1000
2023-10-05 10:03:39.865 
Epoch 217/1000 
	 loss: 27.3921, MinusLogProbMetric: 27.3921, val_loss: 27.5413, val_MinusLogProbMetric: 27.5413

Epoch 217: val_loss did not improve from 27.52230
196/196 - 11s - loss: 27.3921 - MinusLogProbMetric: 27.3921 - val_loss: 27.5413 - val_MinusLogProbMetric: 27.5413 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 218/1000
2023-10-05 10:03:50.643 
Epoch 218/1000 
	 loss: 27.3885, MinusLogProbMetric: 27.3885, val_loss: 27.5535, val_MinusLogProbMetric: 27.5535

Epoch 218: val_loss did not improve from 27.52230
196/196 - 11s - loss: 27.3885 - MinusLogProbMetric: 27.3885 - val_loss: 27.5535 - val_MinusLogProbMetric: 27.5535 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 219/1000
2023-10-05 10:04:01.314 
Epoch 219/1000 
	 loss: 27.3889, MinusLogProbMetric: 27.3889, val_loss: 27.5421, val_MinusLogProbMetric: 27.5421

Epoch 219: val_loss did not improve from 27.52230
196/196 - 11s - loss: 27.3889 - MinusLogProbMetric: 27.3889 - val_loss: 27.5421 - val_MinusLogProbMetric: 27.5421 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 220/1000
2023-10-05 10:04:11.563 
Epoch 220/1000 
	 loss: 27.3928, MinusLogProbMetric: 27.3928, val_loss: 27.5243, val_MinusLogProbMetric: 27.5243

Epoch 220: val_loss did not improve from 27.52230
196/196 - 10s - loss: 27.3928 - MinusLogProbMetric: 27.3928 - val_loss: 27.5243 - val_MinusLogProbMetric: 27.5243 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 221/1000
2023-10-05 10:04:22.010 
Epoch 221/1000 
	 loss: 27.3858, MinusLogProbMetric: 27.3858, val_loss: 27.5329, val_MinusLogProbMetric: 27.5329

Epoch 221: val_loss did not improve from 27.52230
196/196 - 10s - loss: 27.3858 - MinusLogProbMetric: 27.3858 - val_loss: 27.5329 - val_MinusLogProbMetric: 27.5329 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 222/1000
2023-10-05 10:04:32.489 
Epoch 222/1000 
	 loss: 27.3919, MinusLogProbMetric: 27.3919, val_loss: 27.5269, val_MinusLogProbMetric: 27.5269

Epoch 222: val_loss did not improve from 27.52230
196/196 - 10s - loss: 27.3919 - MinusLogProbMetric: 27.3919 - val_loss: 27.5269 - val_MinusLogProbMetric: 27.5269 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 223/1000
2023-10-05 10:04:43.033 
Epoch 223/1000 
	 loss: 27.3902, MinusLogProbMetric: 27.3902, val_loss: 27.5371, val_MinusLogProbMetric: 27.5371

Epoch 223: val_loss did not improve from 27.52230
196/196 - 11s - loss: 27.3902 - MinusLogProbMetric: 27.3902 - val_loss: 27.5371 - val_MinusLogProbMetric: 27.5371 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 224/1000
2023-10-05 10:04:53.496 
Epoch 224/1000 
	 loss: 27.3840, MinusLogProbMetric: 27.3840, val_loss: 27.5267, val_MinusLogProbMetric: 27.5267

Epoch 224: val_loss did not improve from 27.52230
196/196 - 10s - loss: 27.3840 - MinusLogProbMetric: 27.3840 - val_loss: 27.5267 - val_MinusLogProbMetric: 27.5267 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 225/1000
2023-10-05 10:05:03.816 
Epoch 225/1000 
	 loss: 27.3931, MinusLogProbMetric: 27.3931, val_loss: 27.5220, val_MinusLogProbMetric: 27.5220

Epoch 225: val_loss improved from 27.52230 to 27.52204, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 10s - loss: 27.3931 - MinusLogProbMetric: 27.3931 - val_loss: 27.5220 - val_MinusLogProbMetric: 27.5220 - lr: 5.0000e-04 - 10s/epoch - 54ms/step
Epoch 226/1000
2023-10-05 10:05:14.490 
Epoch 226/1000 
	 loss: 27.3881, MinusLogProbMetric: 27.3881, val_loss: 27.5412, val_MinusLogProbMetric: 27.5412

Epoch 226: val_loss did not improve from 27.52204
196/196 - 10s - loss: 27.3881 - MinusLogProbMetric: 27.3881 - val_loss: 27.5412 - val_MinusLogProbMetric: 27.5412 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 227/1000
2023-10-05 10:05:24.919 
Epoch 227/1000 
	 loss: 27.3888, MinusLogProbMetric: 27.3888, val_loss: 27.5317, val_MinusLogProbMetric: 27.5317

Epoch 227: val_loss did not improve from 27.52204
196/196 - 10s - loss: 27.3888 - MinusLogProbMetric: 27.3888 - val_loss: 27.5317 - val_MinusLogProbMetric: 27.5317 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 228/1000
2023-10-05 10:05:36.646 
Epoch 228/1000 
	 loss: 27.3889, MinusLogProbMetric: 27.3889, val_loss: 27.5268, val_MinusLogProbMetric: 27.5268

Epoch 228: val_loss did not improve from 27.52204
196/196 - 12s - loss: 27.3889 - MinusLogProbMetric: 27.3889 - val_loss: 27.5268 - val_MinusLogProbMetric: 27.5268 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 229/1000
2023-10-05 10:05:47.181 
Epoch 229/1000 
	 loss: 27.3898, MinusLogProbMetric: 27.3898, val_loss: 27.5389, val_MinusLogProbMetric: 27.5389

Epoch 229: val_loss did not improve from 27.52204
196/196 - 11s - loss: 27.3898 - MinusLogProbMetric: 27.3898 - val_loss: 27.5389 - val_MinusLogProbMetric: 27.5389 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 230/1000
2023-10-05 10:05:57.657 
Epoch 230/1000 
	 loss: 27.3895, MinusLogProbMetric: 27.3895, val_loss: 27.5275, val_MinusLogProbMetric: 27.5275

Epoch 230: val_loss did not improve from 27.52204
196/196 - 10s - loss: 27.3895 - MinusLogProbMetric: 27.3895 - val_loss: 27.5275 - val_MinusLogProbMetric: 27.5275 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 231/1000
2023-10-05 10:06:07.974 
Epoch 231/1000 
	 loss: 27.3882, MinusLogProbMetric: 27.3882, val_loss: 27.5369, val_MinusLogProbMetric: 27.5369

Epoch 231: val_loss did not improve from 27.52204
196/196 - 10s - loss: 27.3882 - MinusLogProbMetric: 27.3882 - val_loss: 27.5369 - val_MinusLogProbMetric: 27.5369 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 232/1000
2023-10-05 10:06:18.737 
Epoch 232/1000 
	 loss: 27.3907, MinusLogProbMetric: 27.3907, val_loss: 27.5463, val_MinusLogProbMetric: 27.5463

Epoch 232: val_loss did not improve from 27.52204
196/196 - 11s - loss: 27.3907 - MinusLogProbMetric: 27.3907 - val_loss: 27.5463 - val_MinusLogProbMetric: 27.5463 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 233/1000
2023-10-05 10:06:29.355 
Epoch 233/1000 
	 loss: 27.3890, MinusLogProbMetric: 27.3890, val_loss: 27.5591, val_MinusLogProbMetric: 27.5591

Epoch 233: val_loss did not improve from 27.52204
196/196 - 11s - loss: 27.3890 - MinusLogProbMetric: 27.3890 - val_loss: 27.5591 - val_MinusLogProbMetric: 27.5591 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 234/1000
2023-10-05 10:06:39.568 
Epoch 234/1000 
	 loss: 27.3920, MinusLogProbMetric: 27.3920, val_loss: 27.5410, val_MinusLogProbMetric: 27.5410

Epoch 234: val_loss did not improve from 27.52204
196/196 - 10s - loss: 27.3920 - MinusLogProbMetric: 27.3920 - val_loss: 27.5410 - val_MinusLogProbMetric: 27.5410 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 235/1000
2023-10-05 10:06:49.734 
Epoch 235/1000 
	 loss: 27.3832, MinusLogProbMetric: 27.3832, val_loss: 27.5471, val_MinusLogProbMetric: 27.5471

Epoch 235: val_loss did not improve from 27.52204
196/196 - 10s - loss: 27.3832 - MinusLogProbMetric: 27.3832 - val_loss: 27.5471 - val_MinusLogProbMetric: 27.5471 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 236/1000
2023-10-05 10:07:00.008 
Epoch 236/1000 
	 loss: 27.3856, MinusLogProbMetric: 27.3856, val_loss: 27.5367, val_MinusLogProbMetric: 27.5367

Epoch 236: val_loss did not improve from 27.52204
196/196 - 10s - loss: 27.3856 - MinusLogProbMetric: 27.3856 - val_loss: 27.5367 - val_MinusLogProbMetric: 27.5367 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 237/1000
2023-10-05 10:07:10.310 
Epoch 237/1000 
	 loss: 27.3869, MinusLogProbMetric: 27.3869, val_loss: 27.5310, val_MinusLogProbMetric: 27.5310

Epoch 237: val_loss did not improve from 27.52204
196/196 - 10s - loss: 27.3869 - MinusLogProbMetric: 27.3869 - val_loss: 27.5310 - val_MinusLogProbMetric: 27.5310 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 238/1000
2023-10-05 10:07:20.489 
Epoch 238/1000 
	 loss: 27.3868, MinusLogProbMetric: 27.3868, val_loss: 27.5323, val_MinusLogProbMetric: 27.5323

Epoch 238: val_loss did not improve from 27.52204
196/196 - 10s - loss: 27.3868 - MinusLogProbMetric: 27.3868 - val_loss: 27.5323 - val_MinusLogProbMetric: 27.5323 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 239/1000
2023-10-05 10:07:30.643 
Epoch 239/1000 
	 loss: 27.3838, MinusLogProbMetric: 27.3838, val_loss: 27.5478, val_MinusLogProbMetric: 27.5478

Epoch 239: val_loss did not improve from 27.52204
196/196 - 10s - loss: 27.3838 - MinusLogProbMetric: 27.3838 - val_loss: 27.5478 - val_MinusLogProbMetric: 27.5478 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 240/1000
2023-10-05 10:07:40.752 
Epoch 240/1000 
	 loss: 27.3856, MinusLogProbMetric: 27.3856, val_loss: 27.5228, val_MinusLogProbMetric: 27.5228

Epoch 240: val_loss did not improve from 27.52204
196/196 - 10s - loss: 27.3856 - MinusLogProbMetric: 27.3856 - val_loss: 27.5228 - val_MinusLogProbMetric: 27.5228 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 241/1000
2023-10-05 10:07:51.020 
Epoch 241/1000 
	 loss: 27.3857, MinusLogProbMetric: 27.3857, val_loss: 27.5375, val_MinusLogProbMetric: 27.5375

Epoch 241: val_loss did not improve from 27.52204
196/196 - 10s - loss: 27.3857 - MinusLogProbMetric: 27.3857 - val_loss: 27.5375 - val_MinusLogProbMetric: 27.5375 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 242/1000
2023-10-05 10:08:03.773 
Epoch 242/1000 
	 loss: 27.3816, MinusLogProbMetric: 27.3816, val_loss: 27.5483, val_MinusLogProbMetric: 27.5483

Epoch 242: val_loss did not improve from 27.52204
196/196 - 13s - loss: 27.3816 - MinusLogProbMetric: 27.3816 - val_loss: 27.5483 - val_MinusLogProbMetric: 27.5483 - lr: 5.0000e-04 - 13s/epoch - 65ms/step
Epoch 243/1000
2023-10-05 10:08:14.719 
Epoch 243/1000 
	 loss: 27.3818, MinusLogProbMetric: 27.3818, val_loss: 27.5358, val_MinusLogProbMetric: 27.5358

Epoch 243: val_loss did not improve from 27.52204
196/196 - 11s - loss: 27.3818 - MinusLogProbMetric: 27.3818 - val_loss: 27.5358 - val_MinusLogProbMetric: 27.5358 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 244/1000
2023-10-05 10:08:24.960 
Epoch 244/1000 
	 loss: 27.3827, MinusLogProbMetric: 27.3827, val_loss: 27.5424, val_MinusLogProbMetric: 27.5424

Epoch 244: val_loss did not improve from 27.52204
196/196 - 10s - loss: 27.3827 - MinusLogProbMetric: 27.3827 - val_loss: 27.5424 - val_MinusLogProbMetric: 27.5424 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 245/1000
2023-10-05 10:08:35.757 
Epoch 245/1000 
	 loss: 27.3866, MinusLogProbMetric: 27.3866, val_loss: 27.5298, val_MinusLogProbMetric: 27.5298

Epoch 245: val_loss did not improve from 27.52204
196/196 - 11s - loss: 27.3866 - MinusLogProbMetric: 27.3866 - val_loss: 27.5298 - val_MinusLogProbMetric: 27.5298 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 246/1000
2023-10-05 10:08:46.319 
Epoch 246/1000 
	 loss: 27.3820, MinusLogProbMetric: 27.3820, val_loss: 27.5218, val_MinusLogProbMetric: 27.5218

Epoch 246: val_loss improved from 27.52204 to 27.52184, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 11s - loss: 27.3820 - MinusLogProbMetric: 27.3820 - val_loss: 27.5218 - val_MinusLogProbMetric: 27.5218 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 247/1000
2023-10-05 10:08:56.862 
Epoch 247/1000 
	 loss: 27.3837, MinusLogProbMetric: 27.3837, val_loss: 27.5422, val_MinusLogProbMetric: 27.5422

Epoch 247: val_loss did not improve from 27.52184
196/196 - 10s - loss: 27.3837 - MinusLogProbMetric: 27.3837 - val_loss: 27.5422 - val_MinusLogProbMetric: 27.5422 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 248/1000
2023-10-05 10:09:07.324 
Epoch 248/1000 
	 loss: 27.3833, MinusLogProbMetric: 27.3833, val_loss: 27.5349, val_MinusLogProbMetric: 27.5349

Epoch 248: val_loss did not improve from 27.52184
196/196 - 10s - loss: 27.3833 - MinusLogProbMetric: 27.3833 - val_loss: 27.5349 - val_MinusLogProbMetric: 27.5349 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 249/1000
2023-10-05 10:09:17.937 
Epoch 249/1000 
	 loss: 27.3827, MinusLogProbMetric: 27.3827, val_loss: 27.5406, val_MinusLogProbMetric: 27.5406

Epoch 249: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3827 - MinusLogProbMetric: 27.3827 - val_loss: 27.5406 - val_MinusLogProbMetric: 27.5406 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 250/1000
2023-10-05 10:09:28.604 
Epoch 250/1000 
	 loss: 27.3871, MinusLogProbMetric: 27.3871, val_loss: 27.5658, val_MinusLogProbMetric: 27.5658

Epoch 250: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3871 - MinusLogProbMetric: 27.3871 - val_loss: 27.5658 - val_MinusLogProbMetric: 27.5658 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 251/1000
2023-10-05 10:09:39.160 
Epoch 251/1000 
	 loss: 27.3791, MinusLogProbMetric: 27.3791, val_loss: 27.5426, val_MinusLogProbMetric: 27.5426

Epoch 251: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3791 - MinusLogProbMetric: 27.3791 - val_loss: 27.5426 - val_MinusLogProbMetric: 27.5426 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 252/1000
2023-10-05 10:09:49.976 
Epoch 252/1000 
	 loss: 27.3806, MinusLogProbMetric: 27.3806, val_loss: 27.5375, val_MinusLogProbMetric: 27.5375

Epoch 252: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3806 - MinusLogProbMetric: 27.3806 - val_loss: 27.5375 - val_MinusLogProbMetric: 27.5375 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 253/1000
2023-10-05 10:10:00.882 
Epoch 253/1000 
	 loss: 27.3821, MinusLogProbMetric: 27.3821, val_loss: 27.5359, val_MinusLogProbMetric: 27.5359

Epoch 253: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3821 - MinusLogProbMetric: 27.3821 - val_loss: 27.5359 - val_MinusLogProbMetric: 27.5359 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 254/1000
2023-10-05 10:10:11.597 
Epoch 254/1000 
	 loss: 27.3823, MinusLogProbMetric: 27.3823, val_loss: 27.5482, val_MinusLogProbMetric: 27.5482

Epoch 254: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3823 - MinusLogProbMetric: 27.3823 - val_loss: 27.5482 - val_MinusLogProbMetric: 27.5482 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 255/1000
2023-10-05 10:10:22.507 
Epoch 255/1000 
	 loss: 27.3793, MinusLogProbMetric: 27.3793, val_loss: 27.5495, val_MinusLogProbMetric: 27.5495

Epoch 255: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3793 - MinusLogProbMetric: 27.3793 - val_loss: 27.5495 - val_MinusLogProbMetric: 27.5495 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 256/1000
2023-10-05 10:10:32.987 
Epoch 256/1000 
	 loss: 27.3814, MinusLogProbMetric: 27.3814, val_loss: 27.5373, val_MinusLogProbMetric: 27.5373

Epoch 256: val_loss did not improve from 27.52184
196/196 - 10s - loss: 27.3814 - MinusLogProbMetric: 27.3814 - val_loss: 27.5373 - val_MinusLogProbMetric: 27.5373 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 257/1000
2023-10-05 10:10:43.578 
Epoch 257/1000 
	 loss: 27.3819, MinusLogProbMetric: 27.3819, val_loss: 27.5266, val_MinusLogProbMetric: 27.5266

Epoch 257: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3819 - MinusLogProbMetric: 27.3819 - val_loss: 27.5266 - val_MinusLogProbMetric: 27.5266 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 258/1000
2023-10-05 10:10:54.428 
Epoch 258/1000 
	 loss: 27.3799, MinusLogProbMetric: 27.3799, val_loss: 27.5254, val_MinusLogProbMetric: 27.5254

Epoch 258: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3799 - MinusLogProbMetric: 27.3799 - val_loss: 27.5254 - val_MinusLogProbMetric: 27.5254 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 259/1000
2023-10-05 10:11:05.357 
Epoch 259/1000 
	 loss: 27.3771, MinusLogProbMetric: 27.3771, val_loss: 27.5252, val_MinusLogProbMetric: 27.5252

Epoch 259: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3771 - MinusLogProbMetric: 27.3771 - val_loss: 27.5252 - val_MinusLogProbMetric: 27.5252 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 260/1000
2023-10-05 10:11:16.211 
Epoch 260/1000 
	 loss: 27.3787, MinusLogProbMetric: 27.3787, val_loss: 27.5438, val_MinusLogProbMetric: 27.5438

Epoch 260: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3787 - MinusLogProbMetric: 27.3787 - val_loss: 27.5438 - val_MinusLogProbMetric: 27.5438 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 261/1000
2023-10-05 10:11:27.046 
Epoch 261/1000 
	 loss: 27.3805, MinusLogProbMetric: 27.3805, val_loss: 27.5309, val_MinusLogProbMetric: 27.5309

Epoch 261: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3805 - MinusLogProbMetric: 27.3805 - val_loss: 27.5309 - val_MinusLogProbMetric: 27.5309 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 262/1000
2023-10-05 10:11:38.032 
Epoch 262/1000 
	 loss: 27.3816, MinusLogProbMetric: 27.3816, val_loss: 27.5508, val_MinusLogProbMetric: 27.5508

Epoch 262: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3816 - MinusLogProbMetric: 27.3816 - val_loss: 27.5508 - val_MinusLogProbMetric: 27.5508 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 263/1000
2023-10-05 10:11:49.021 
Epoch 263/1000 
	 loss: 27.3795, MinusLogProbMetric: 27.3795, val_loss: 27.5389, val_MinusLogProbMetric: 27.5389

Epoch 263: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3795 - MinusLogProbMetric: 27.3795 - val_loss: 27.5389 - val_MinusLogProbMetric: 27.5389 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 264/1000
2023-10-05 10:11:59.903 
Epoch 264/1000 
	 loss: 27.3777, MinusLogProbMetric: 27.3777, val_loss: 27.5486, val_MinusLogProbMetric: 27.5486

Epoch 264: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3777 - MinusLogProbMetric: 27.3777 - val_loss: 27.5486 - val_MinusLogProbMetric: 27.5486 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 265/1000
2023-10-05 10:12:10.677 
Epoch 265/1000 
	 loss: 27.3755, MinusLogProbMetric: 27.3755, val_loss: 27.5622, val_MinusLogProbMetric: 27.5622

Epoch 265: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3755 - MinusLogProbMetric: 27.3755 - val_loss: 27.5622 - val_MinusLogProbMetric: 27.5622 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 266/1000
2023-10-05 10:12:21.634 
Epoch 266/1000 
	 loss: 27.3776, MinusLogProbMetric: 27.3776, val_loss: 27.5330, val_MinusLogProbMetric: 27.5330

Epoch 266: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3776 - MinusLogProbMetric: 27.3776 - val_loss: 27.5330 - val_MinusLogProbMetric: 27.5330 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 267/1000
2023-10-05 10:12:32.530 
Epoch 267/1000 
	 loss: 27.3774, MinusLogProbMetric: 27.3774, val_loss: 27.5545, val_MinusLogProbMetric: 27.5545

Epoch 267: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3774 - MinusLogProbMetric: 27.3774 - val_loss: 27.5545 - val_MinusLogProbMetric: 27.5545 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 268/1000
2023-10-05 10:12:43.441 
Epoch 268/1000 
	 loss: 27.3728, MinusLogProbMetric: 27.3728, val_loss: 27.5350, val_MinusLogProbMetric: 27.5350

Epoch 268: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3728 - MinusLogProbMetric: 27.3728 - val_loss: 27.5350 - val_MinusLogProbMetric: 27.5350 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 269/1000
2023-10-05 10:12:54.147 
Epoch 269/1000 
	 loss: 27.3792, MinusLogProbMetric: 27.3792, val_loss: 27.5350, val_MinusLogProbMetric: 27.5350

Epoch 269: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3792 - MinusLogProbMetric: 27.3792 - val_loss: 27.5350 - val_MinusLogProbMetric: 27.5350 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 270/1000
2023-10-05 10:13:05.050 
Epoch 270/1000 
	 loss: 27.3750, MinusLogProbMetric: 27.3750, val_loss: 27.5319, val_MinusLogProbMetric: 27.5319

Epoch 270: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3750 - MinusLogProbMetric: 27.3750 - val_loss: 27.5319 - val_MinusLogProbMetric: 27.5319 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 271/1000
2023-10-05 10:13:16.079 
Epoch 271/1000 
	 loss: 27.3760, MinusLogProbMetric: 27.3760, val_loss: 27.5366, val_MinusLogProbMetric: 27.5366

Epoch 271: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3760 - MinusLogProbMetric: 27.3760 - val_loss: 27.5366 - val_MinusLogProbMetric: 27.5366 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 272/1000
2023-10-05 10:13:27.127 
Epoch 272/1000 
	 loss: 27.3766, MinusLogProbMetric: 27.3766, val_loss: 27.5512, val_MinusLogProbMetric: 27.5512

Epoch 272: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3766 - MinusLogProbMetric: 27.3766 - val_loss: 27.5512 - val_MinusLogProbMetric: 27.5512 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 273/1000
2023-10-05 10:13:38.211 
Epoch 273/1000 
	 loss: 27.3760, MinusLogProbMetric: 27.3760, val_loss: 27.5391, val_MinusLogProbMetric: 27.5391

Epoch 273: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3760 - MinusLogProbMetric: 27.3760 - val_loss: 27.5391 - val_MinusLogProbMetric: 27.5391 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 274/1000
2023-10-05 10:13:49.114 
Epoch 274/1000 
	 loss: 27.3752, MinusLogProbMetric: 27.3752, val_loss: 27.5442, val_MinusLogProbMetric: 27.5442

Epoch 274: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3752 - MinusLogProbMetric: 27.3752 - val_loss: 27.5442 - val_MinusLogProbMetric: 27.5442 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 275/1000
2023-10-05 10:14:00.111 
Epoch 275/1000 
	 loss: 27.3771, MinusLogProbMetric: 27.3771, val_loss: 27.5527, val_MinusLogProbMetric: 27.5527

Epoch 275: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3771 - MinusLogProbMetric: 27.3771 - val_loss: 27.5527 - val_MinusLogProbMetric: 27.5527 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 276/1000
2023-10-05 10:14:10.440 
Epoch 276/1000 
	 loss: 27.3712, MinusLogProbMetric: 27.3712, val_loss: 27.5390, val_MinusLogProbMetric: 27.5390

Epoch 276: val_loss did not improve from 27.52184
196/196 - 10s - loss: 27.3712 - MinusLogProbMetric: 27.3712 - val_loss: 27.5390 - val_MinusLogProbMetric: 27.5390 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 277/1000
2023-10-05 10:14:20.961 
Epoch 277/1000 
	 loss: 27.3736, MinusLogProbMetric: 27.3736, val_loss: 27.5552, val_MinusLogProbMetric: 27.5552

Epoch 277: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3736 - MinusLogProbMetric: 27.3736 - val_loss: 27.5552 - val_MinusLogProbMetric: 27.5552 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 278/1000
2023-10-05 10:14:31.333 
Epoch 278/1000 
	 loss: 27.3789, MinusLogProbMetric: 27.3789, val_loss: 27.5485, val_MinusLogProbMetric: 27.5485

Epoch 278: val_loss did not improve from 27.52184
196/196 - 10s - loss: 27.3789 - MinusLogProbMetric: 27.3789 - val_loss: 27.5485 - val_MinusLogProbMetric: 27.5485 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 279/1000
2023-10-05 10:14:41.611 
Epoch 279/1000 
	 loss: 27.3763, MinusLogProbMetric: 27.3763, val_loss: 27.5281, val_MinusLogProbMetric: 27.5281

Epoch 279: val_loss did not improve from 27.52184
196/196 - 10s - loss: 27.3763 - MinusLogProbMetric: 27.3763 - val_loss: 27.5281 - val_MinusLogProbMetric: 27.5281 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 280/1000
2023-10-05 10:14:51.803 
Epoch 280/1000 
	 loss: 27.3769, MinusLogProbMetric: 27.3769, val_loss: 27.5368, val_MinusLogProbMetric: 27.5368

Epoch 280: val_loss did not improve from 27.52184
196/196 - 10s - loss: 27.3769 - MinusLogProbMetric: 27.3769 - val_loss: 27.5368 - val_MinusLogProbMetric: 27.5368 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 281/1000
2023-10-05 10:15:02.346 
Epoch 281/1000 
	 loss: 27.3694, MinusLogProbMetric: 27.3694, val_loss: 27.6080, val_MinusLogProbMetric: 27.6080

Epoch 281: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3694 - MinusLogProbMetric: 27.3694 - val_loss: 27.6080 - val_MinusLogProbMetric: 27.6080 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 282/1000
2023-10-05 10:15:12.940 
Epoch 282/1000 
	 loss: 27.3723, MinusLogProbMetric: 27.3723, val_loss: 27.5406, val_MinusLogProbMetric: 27.5406

Epoch 282: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3723 - MinusLogProbMetric: 27.3723 - val_loss: 27.5406 - val_MinusLogProbMetric: 27.5406 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 283/1000
2023-10-05 10:15:23.730 
Epoch 283/1000 
	 loss: 27.3713, MinusLogProbMetric: 27.3713, val_loss: 27.5523, val_MinusLogProbMetric: 27.5523

Epoch 283: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3713 - MinusLogProbMetric: 27.3713 - val_loss: 27.5523 - val_MinusLogProbMetric: 27.5523 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 284/1000
2023-10-05 10:15:34.444 
Epoch 284/1000 
	 loss: 27.3755, MinusLogProbMetric: 27.3755, val_loss: 27.5687, val_MinusLogProbMetric: 27.5687

Epoch 284: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3755 - MinusLogProbMetric: 27.3755 - val_loss: 27.5687 - val_MinusLogProbMetric: 27.5687 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 285/1000
2023-10-05 10:15:45.221 
Epoch 285/1000 
	 loss: 27.3751, MinusLogProbMetric: 27.3751, val_loss: 27.5286, val_MinusLogProbMetric: 27.5286

Epoch 285: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3751 - MinusLogProbMetric: 27.3751 - val_loss: 27.5286 - val_MinusLogProbMetric: 27.5286 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 286/1000
2023-10-05 10:15:55.914 
Epoch 286/1000 
	 loss: 27.3711, MinusLogProbMetric: 27.3711, val_loss: 27.5488, val_MinusLogProbMetric: 27.5488

Epoch 286: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3711 - MinusLogProbMetric: 27.3711 - val_loss: 27.5488 - val_MinusLogProbMetric: 27.5488 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 287/1000
2023-10-05 10:16:06.270 
Epoch 287/1000 
	 loss: 27.3757, MinusLogProbMetric: 27.3757, val_loss: 27.5829, val_MinusLogProbMetric: 27.5829

Epoch 287: val_loss did not improve from 27.52184
196/196 - 10s - loss: 27.3757 - MinusLogProbMetric: 27.3757 - val_loss: 27.5829 - val_MinusLogProbMetric: 27.5829 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 288/1000
2023-10-05 10:16:16.548 
Epoch 288/1000 
	 loss: 27.3784, MinusLogProbMetric: 27.3784, val_loss: 27.5460, val_MinusLogProbMetric: 27.5460

Epoch 288: val_loss did not improve from 27.52184
196/196 - 10s - loss: 27.3784 - MinusLogProbMetric: 27.3784 - val_loss: 27.5460 - val_MinusLogProbMetric: 27.5460 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 289/1000
2023-10-05 10:16:29.755 
Epoch 289/1000 
	 loss: 27.3697, MinusLogProbMetric: 27.3697, val_loss: 27.5496, val_MinusLogProbMetric: 27.5496

Epoch 289: val_loss did not improve from 27.52184
196/196 - 13s - loss: 27.3697 - MinusLogProbMetric: 27.3697 - val_loss: 27.5496 - val_MinusLogProbMetric: 27.5496 - lr: 5.0000e-04 - 13s/epoch - 67ms/step
Epoch 290/1000
2023-10-05 10:16:43.067 
Epoch 290/1000 
	 loss: 27.3761, MinusLogProbMetric: 27.3761, val_loss: 27.5527, val_MinusLogProbMetric: 27.5527

Epoch 290: val_loss did not improve from 27.52184
196/196 - 13s - loss: 27.3761 - MinusLogProbMetric: 27.3761 - val_loss: 27.5527 - val_MinusLogProbMetric: 27.5527 - lr: 5.0000e-04 - 13s/epoch - 68ms/step
Epoch 291/1000
2023-10-05 10:16:54.526 
Epoch 291/1000 
	 loss: 27.3758, MinusLogProbMetric: 27.3758, val_loss: 27.5438, val_MinusLogProbMetric: 27.5438

Epoch 291: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3758 - MinusLogProbMetric: 27.3758 - val_loss: 27.5438 - val_MinusLogProbMetric: 27.5438 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 292/1000
2023-10-05 10:17:04.922 
Epoch 292/1000 
	 loss: 27.3746, MinusLogProbMetric: 27.3746, val_loss: 27.5595, val_MinusLogProbMetric: 27.5595

Epoch 292: val_loss did not improve from 27.52184
196/196 - 10s - loss: 27.3746 - MinusLogProbMetric: 27.3746 - val_loss: 27.5595 - val_MinusLogProbMetric: 27.5595 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 293/1000
2023-10-05 10:17:17.899 
Epoch 293/1000 
	 loss: 27.3695, MinusLogProbMetric: 27.3695, val_loss: 27.5534, val_MinusLogProbMetric: 27.5534

Epoch 293: val_loss did not improve from 27.52184
196/196 - 13s - loss: 27.3695 - MinusLogProbMetric: 27.3695 - val_loss: 27.5534 - val_MinusLogProbMetric: 27.5534 - lr: 5.0000e-04 - 13s/epoch - 66ms/step
Epoch 294/1000
2023-10-05 10:17:31.736 
Epoch 294/1000 
	 loss: 27.3735, MinusLogProbMetric: 27.3735, val_loss: 27.5490, val_MinusLogProbMetric: 27.5490

Epoch 294: val_loss did not improve from 27.52184
196/196 - 14s - loss: 27.3735 - MinusLogProbMetric: 27.3735 - val_loss: 27.5490 - val_MinusLogProbMetric: 27.5490 - lr: 5.0000e-04 - 14s/epoch - 71ms/step
Epoch 295/1000
2023-10-05 10:17:42.799 
Epoch 295/1000 
	 loss: 27.3693, MinusLogProbMetric: 27.3693, val_loss: 27.5464, val_MinusLogProbMetric: 27.5464

Epoch 295: val_loss did not improve from 27.52184
196/196 - 11s - loss: 27.3693 - MinusLogProbMetric: 27.3693 - val_loss: 27.5464 - val_MinusLogProbMetric: 27.5464 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 296/1000
2023-10-05 10:17:52.835 
Epoch 296/1000 
	 loss: 27.3742, MinusLogProbMetric: 27.3742, val_loss: 27.5543, val_MinusLogProbMetric: 27.5543

Epoch 296: val_loss did not improve from 27.52184
196/196 - 10s - loss: 27.3742 - MinusLogProbMetric: 27.3742 - val_loss: 27.5543 - val_MinusLogProbMetric: 27.5543 - lr: 5.0000e-04 - 10s/epoch - 51ms/step
Epoch 297/1000
2023-10-05 10:18:03.865 
Epoch 297/1000 
	 loss: 27.3337, MinusLogProbMetric: 27.3337, val_loss: 27.5117, val_MinusLogProbMetric: 27.5117

Epoch 297: val_loss improved from 27.52184 to 27.51174, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 11s - loss: 27.3337 - MinusLogProbMetric: 27.3337 - val_loss: 27.5117 - val_MinusLogProbMetric: 27.5117 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 298/1000
2023-10-05 10:18:15.574 
Epoch 298/1000 
	 loss: 27.3299, MinusLogProbMetric: 27.3299, val_loss: 27.5213, val_MinusLogProbMetric: 27.5213

Epoch 298: val_loss did not improve from 27.51174
196/196 - 11s - loss: 27.3299 - MinusLogProbMetric: 27.3299 - val_loss: 27.5213 - val_MinusLogProbMetric: 27.5213 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 299/1000
2023-10-05 10:18:26.150 
Epoch 299/1000 
	 loss: 27.3320, MinusLogProbMetric: 27.3320, val_loss: 27.5187, val_MinusLogProbMetric: 27.5187

Epoch 299: val_loss did not improve from 27.51174
196/196 - 11s - loss: 27.3320 - MinusLogProbMetric: 27.3320 - val_loss: 27.5187 - val_MinusLogProbMetric: 27.5187 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 300/1000
2023-10-05 10:18:36.744 
Epoch 300/1000 
	 loss: 27.3298, MinusLogProbMetric: 27.3298, val_loss: 27.5166, val_MinusLogProbMetric: 27.5166

Epoch 300: val_loss did not improve from 27.51174
196/196 - 11s - loss: 27.3298 - MinusLogProbMetric: 27.3298 - val_loss: 27.5166 - val_MinusLogProbMetric: 27.5166 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 301/1000
2023-10-05 10:18:47.585 
Epoch 301/1000 
	 loss: 27.3323, MinusLogProbMetric: 27.3323, val_loss: 27.5131, val_MinusLogProbMetric: 27.5131

Epoch 301: val_loss did not improve from 27.51174
196/196 - 11s - loss: 27.3323 - MinusLogProbMetric: 27.3323 - val_loss: 27.5131 - val_MinusLogProbMetric: 27.5131 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 302/1000
2023-10-05 10:18:58.432 
Epoch 302/1000 
	 loss: 27.3296, MinusLogProbMetric: 27.3296, val_loss: 27.5162, val_MinusLogProbMetric: 27.5162

Epoch 302: val_loss did not improve from 27.51174
196/196 - 11s - loss: 27.3296 - MinusLogProbMetric: 27.3296 - val_loss: 27.5162 - val_MinusLogProbMetric: 27.5162 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 303/1000
2023-10-05 10:19:09.022 
Epoch 303/1000 
	 loss: 27.3301, MinusLogProbMetric: 27.3301, val_loss: 27.5257, val_MinusLogProbMetric: 27.5257

Epoch 303: val_loss did not improve from 27.51174
196/196 - 11s - loss: 27.3301 - MinusLogProbMetric: 27.3301 - val_loss: 27.5257 - val_MinusLogProbMetric: 27.5257 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 304/1000
2023-10-05 10:19:19.635 
Epoch 304/1000 
	 loss: 27.3325, MinusLogProbMetric: 27.3325, val_loss: 27.5208, val_MinusLogProbMetric: 27.5208

Epoch 304: val_loss did not improve from 27.51174
196/196 - 11s - loss: 27.3325 - MinusLogProbMetric: 27.3325 - val_loss: 27.5208 - val_MinusLogProbMetric: 27.5208 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 305/1000
2023-10-05 10:19:30.218 
Epoch 305/1000 
	 loss: 27.3281, MinusLogProbMetric: 27.3281, val_loss: 27.5166, val_MinusLogProbMetric: 27.5166

Epoch 305: val_loss did not improve from 27.51174
196/196 - 11s - loss: 27.3281 - MinusLogProbMetric: 27.3281 - val_loss: 27.5166 - val_MinusLogProbMetric: 27.5166 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 306/1000
2023-10-05 10:19:40.697 
Epoch 306/1000 
	 loss: 27.3302, MinusLogProbMetric: 27.3302, val_loss: 27.5229, val_MinusLogProbMetric: 27.5229

Epoch 306: val_loss did not improve from 27.51174
196/196 - 10s - loss: 27.3302 - MinusLogProbMetric: 27.3302 - val_loss: 27.5229 - val_MinusLogProbMetric: 27.5229 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 307/1000
2023-10-05 10:19:51.005 
Epoch 307/1000 
	 loss: 27.3310, MinusLogProbMetric: 27.3310, val_loss: 27.5170, val_MinusLogProbMetric: 27.5170

Epoch 307: val_loss did not improve from 27.51174
196/196 - 10s - loss: 27.3310 - MinusLogProbMetric: 27.3310 - val_loss: 27.5170 - val_MinusLogProbMetric: 27.5170 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 308/1000
2023-10-05 10:20:02.157 
Epoch 308/1000 
	 loss: 27.3316, MinusLogProbMetric: 27.3316, val_loss: 27.5267, val_MinusLogProbMetric: 27.5267

Epoch 308: val_loss did not improve from 27.51174
196/196 - 11s - loss: 27.3316 - MinusLogProbMetric: 27.3316 - val_loss: 27.5267 - val_MinusLogProbMetric: 27.5267 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 309/1000
2023-10-05 10:20:12.608 
Epoch 309/1000 
	 loss: 27.3317, MinusLogProbMetric: 27.3317, val_loss: 27.5223, val_MinusLogProbMetric: 27.5223

Epoch 309: val_loss did not improve from 27.51174
196/196 - 10s - loss: 27.3317 - MinusLogProbMetric: 27.3317 - val_loss: 27.5223 - val_MinusLogProbMetric: 27.5223 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 310/1000
2023-10-05 10:20:23.320 
Epoch 310/1000 
	 loss: 27.3308, MinusLogProbMetric: 27.3308, val_loss: 27.5222, val_MinusLogProbMetric: 27.5222

Epoch 310: val_loss did not improve from 27.51174
196/196 - 11s - loss: 27.3308 - MinusLogProbMetric: 27.3308 - val_loss: 27.5222 - val_MinusLogProbMetric: 27.5222 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 311/1000
2023-10-05 10:20:34.229 
Epoch 311/1000 
	 loss: 27.3293, MinusLogProbMetric: 27.3293, val_loss: 27.5124, val_MinusLogProbMetric: 27.5124

Epoch 311: val_loss did not improve from 27.51174
196/196 - 11s - loss: 27.3293 - MinusLogProbMetric: 27.3293 - val_loss: 27.5124 - val_MinusLogProbMetric: 27.5124 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 312/1000
2023-10-05 10:20:44.812 
Epoch 312/1000 
	 loss: 27.3295, MinusLogProbMetric: 27.3295, val_loss: 27.5229, val_MinusLogProbMetric: 27.5229

Epoch 312: val_loss did not improve from 27.51174
196/196 - 11s - loss: 27.3295 - MinusLogProbMetric: 27.3295 - val_loss: 27.5229 - val_MinusLogProbMetric: 27.5229 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 313/1000
2023-10-05 10:20:55.574 
Epoch 313/1000 
	 loss: 27.3292, MinusLogProbMetric: 27.3292, val_loss: 27.5117, val_MinusLogProbMetric: 27.5117

Epoch 313: val_loss improved from 27.51174 to 27.51165, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 11s - loss: 27.3292 - MinusLogProbMetric: 27.3292 - val_loss: 27.5117 - val_MinusLogProbMetric: 27.5117 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 314/1000
2023-10-05 10:21:06.915 
Epoch 314/1000 
	 loss: 27.3275, MinusLogProbMetric: 27.3275, val_loss: 27.5155, val_MinusLogProbMetric: 27.5155

Epoch 314: val_loss did not improve from 27.51165
196/196 - 11s - loss: 27.3275 - MinusLogProbMetric: 27.3275 - val_loss: 27.5155 - val_MinusLogProbMetric: 27.5155 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 315/1000
2023-10-05 10:21:17.901 
Epoch 315/1000 
	 loss: 27.3301, MinusLogProbMetric: 27.3301, val_loss: 27.5131, val_MinusLogProbMetric: 27.5131

Epoch 315: val_loss did not improve from 27.51165
196/196 - 11s - loss: 27.3301 - MinusLogProbMetric: 27.3301 - val_loss: 27.5131 - val_MinusLogProbMetric: 27.5131 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 316/1000
2023-10-05 10:21:28.742 
Epoch 316/1000 
	 loss: 27.3299, MinusLogProbMetric: 27.3299, val_loss: 27.5238, val_MinusLogProbMetric: 27.5238

Epoch 316: val_loss did not improve from 27.51165
196/196 - 11s - loss: 27.3299 - MinusLogProbMetric: 27.3299 - val_loss: 27.5238 - val_MinusLogProbMetric: 27.5238 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 317/1000
2023-10-05 10:21:39.803 
Epoch 317/1000 
	 loss: 27.3274, MinusLogProbMetric: 27.3274, val_loss: 27.5105, val_MinusLogProbMetric: 27.5105

Epoch 317: val_loss improved from 27.51165 to 27.51049, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 11s - loss: 27.3274 - MinusLogProbMetric: 27.3274 - val_loss: 27.5105 - val_MinusLogProbMetric: 27.5105 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 318/1000
2023-10-05 10:21:50.276 
Epoch 318/1000 
	 loss: 27.3269, MinusLogProbMetric: 27.3269, val_loss: 27.5210, val_MinusLogProbMetric: 27.5210

Epoch 318: val_loss did not improve from 27.51049
196/196 - 10s - loss: 27.3269 - MinusLogProbMetric: 27.3269 - val_loss: 27.5210 - val_MinusLogProbMetric: 27.5210 - lr: 2.5000e-04 - 10s/epoch - 52ms/step
Epoch 319/1000
2023-10-05 10:22:01.206 
Epoch 319/1000 
	 loss: 27.3281, MinusLogProbMetric: 27.3281, val_loss: 27.5128, val_MinusLogProbMetric: 27.5128

Epoch 319: val_loss did not improve from 27.51049
196/196 - 11s - loss: 27.3281 - MinusLogProbMetric: 27.3281 - val_loss: 27.5128 - val_MinusLogProbMetric: 27.5128 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 320/1000
2023-10-05 10:22:12.057 
Epoch 320/1000 
	 loss: 27.3285, MinusLogProbMetric: 27.3285, val_loss: 27.5133, val_MinusLogProbMetric: 27.5133

Epoch 320: val_loss did not improve from 27.51049
196/196 - 11s - loss: 27.3285 - MinusLogProbMetric: 27.3285 - val_loss: 27.5133 - val_MinusLogProbMetric: 27.5133 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 321/1000
2023-10-05 10:22:24.042 
Epoch 321/1000 
	 loss: 27.3280, MinusLogProbMetric: 27.3280, val_loss: 27.5141, val_MinusLogProbMetric: 27.5141

Epoch 321: val_loss did not improve from 27.51049
196/196 - 12s - loss: 27.3280 - MinusLogProbMetric: 27.3280 - val_loss: 27.5141 - val_MinusLogProbMetric: 27.5141 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 322/1000
2023-10-05 10:22:34.938 
Epoch 322/1000 
	 loss: 27.3257, MinusLogProbMetric: 27.3257, val_loss: 27.5190, val_MinusLogProbMetric: 27.5190

Epoch 322: val_loss did not improve from 27.51049
196/196 - 11s - loss: 27.3257 - MinusLogProbMetric: 27.3257 - val_loss: 27.5190 - val_MinusLogProbMetric: 27.5190 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 323/1000
2023-10-05 10:22:46.011 
Epoch 323/1000 
	 loss: 27.3284, MinusLogProbMetric: 27.3284, val_loss: 27.5293, val_MinusLogProbMetric: 27.5293

Epoch 323: val_loss did not improve from 27.51049
196/196 - 11s - loss: 27.3284 - MinusLogProbMetric: 27.3284 - val_loss: 27.5293 - val_MinusLogProbMetric: 27.5293 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 324/1000
2023-10-05 10:22:57.056 
Epoch 324/1000 
	 loss: 27.3262, MinusLogProbMetric: 27.3262, val_loss: 27.5121, val_MinusLogProbMetric: 27.5121

Epoch 324: val_loss did not improve from 27.51049
196/196 - 11s - loss: 27.3262 - MinusLogProbMetric: 27.3262 - val_loss: 27.5121 - val_MinusLogProbMetric: 27.5121 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 325/1000
2023-10-05 10:23:08.040 
Epoch 325/1000 
	 loss: 27.3262, MinusLogProbMetric: 27.3262, val_loss: 27.5230, val_MinusLogProbMetric: 27.5230

Epoch 325: val_loss did not improve from 27.51049
196/196 - 11s - loss: 27.3262 - MinusLogProbMetric: 27.3262 - val_loss: 27.5230 - val_MinusLogProbMetric: 27.5230 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 326/1000
2023-10-05 10:23:18.781 
Epoch 326/1000 
	 loss: 27.3293, MinusLogProbMetric: 27.3293, val_loss: 27.5195, val_MinusLogProbMetric: 27.5195

Epoch 326: val_loss did not improve from 27.51049
196/196 - 11s - loss: 27.3293 - MinusLogProbMetric: 27.3293 - val_loss: 27.5195 - val_MinusLogProbMetric: 27.5195 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 327/1000
2023-10-05 10:23:29.123 
Epoch 327/1000 
	 loss: 27.3297, MinusLogProbMetric: 27.3297, val_loss: 27.5135, val_MinusLogProbMetric: 27.5135

Epoch 327: val_loss did not improve from 27.51049
196/196 - 10s - loss: 27.3297 - MinusLogProbMetric: 27.3297 - val_loss: 27.5135 - val_MinusLogProbMetric: 27.5135 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 328/1000
2023-10-05 10:23:39.359 
Epoch 328/1000 
	 loss: 27.3248, MinusLogProbMetric: 27.3248, val_loss: 27.5313, val_MinusLogProbMetric: 27.5313

Epoch 328: val_loss did not improve from 27.51049
196/196 - 10s - loss: 27.3248 - MinusLogProbMetric: 27.3248 - val_loss: 27.5313 - val_MinusLogProbMetric: 27.5313 - lr: 2.5000e-04 - 10s/epoch - 52ms/step
Epoch 329/1000
2023-10-05 10:23:50.090 
Epoch 329/1000 
	 loss: 27.3275, MinusLogProbMetric: 27.3275, val_loss: 27.5095, val_MinusLogProbMetric: 27.5095

Epoch 329: val_loss improved from 27.51049 to 27.50953, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 11s - loss: 27.3275 - MinusLogProbMetric: 27.3275 - val_loss: 27.5095 - val_MinusLogProbMetric: 27.5095 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 330/1000
2023-10-05 10:24:01.184 
Epoch 330/1000 
	 loss: 27.3271, MinusLogProbMetric: 27.3271, val_loss: 27.5260, val_MinusLogProbMetric: 27.5260

Epoch 330: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3271 - MinusLogProbMetric: 27.3271 - val_loss: 27.5260 - val_MinusLogProbMetric: 27.5260 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 331/1000
2023-10-05 10:24:11.999 
Epoch 331/1000 
	 loss: 27.3270, MinusLogProbMetric: 27.3270, val_loss: 27.5252, val_MinusLogProbMetric: 27.5252

Epoch 331: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3270 - MinusLogProbMetric: 27.3270 - val_loss: 27.5252 - val_MinusLogProbMetric: 27.5252 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 332/1000
2023-10-05 10:24:22.748 
Epoch 332/1000 
	 loss: 27.3261, MinusLogProbMetric: 27.3261, val_loss: 27.5175, val_MinusLogProbMetric: 27.5175

Epoch 332: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3261 - MinusLogProbMetric: 27.3261 - val_loss: 27.5175 - val_MinusLogProbMetric: 27.5175 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 333/1000
2023-10-05 10:24:33.307 
Epoch 333/1000 
	 loss: 27.3295, MinusLogProbMetric: 27.3295, val_loss: 27.5256, val_MinusLogProbMetric: 27.5256

Epoch 333: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3295 - MinusLogProbMetric: 27.3295 - val_loss: 27.5256 - val_MinusLogProbMetric: 27.5256 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 334/1000
2023-10-05 10:24:43.749 
Epoch 334/1000 
	 loss: 27.3269, MinusLogProbMetric: 27.3269, val_loss: 27.5211, val_MinusLogProbMetric: 27.5211

Epoch 334: val_loss did not improve from 27.50953
196/196 - 10s - loss: 27.3269 - MinusLogProbMetric: 27.3269 - val_loss: 27.5211 - val_MinusLogProbMetric: 27.5211 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 335/1000
2023-10-05 10:24:54.243 
Epoch 335/1000 
	 loss: 27.3266, MinusLogProbMetric: 27.3266, val_loss: 27.5205, val_MinusLogProbMetric: 27.5205

Epoch 335: val_loss did not improve from 27.50953
196/196 - 10s - loss: 27.3266 - MinusLogProbMetric: 27.3266 - val_loss: 27.5205 - val_MinusLogProbMetric: 27.5205 - lr: 2.5000e-04 - 10s/epoch - 54ms/step
Epoch 336/1000
2023-10-05 10:25:05.228 
Epoch 336/1000 
	 loss: 27.3256, MinusLogProbMetric: 27.3256, val_loss: 27.5230, val_MinusLogProbMetric: 27.5230

Epoch 336: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3256 - MinusLogProbMetric: 27.3256 - val_loss: 27.5230 - val_MinusLogProbMetric: 27.5230 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 337/1000
2023-10-05 10:25:16.885 
Epoch 337/1000 
	 loss: 27.3290, MinusLogProbMetric: 27.3290, val_loss: 27.5237, val_MinusLogProbMetric: 27.5237

Epoch 337: val_loss did not improve from 27.50953
196/196 - 12s - loss: 27.3290 - MinusLogProbMetric: 27.3290 - val_loss: 27.5237 - val_MinusLogProbMetric: 27.5237 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 338/1000
2023-10-05 10:25:28.648 
Epoch 338/1000 
	 loss: 27.3257, MinusLogProbMetric: 27.3257, val_loss: 27.5188, val_MinusLogProbMetric: 27.5188

Epoch 338: val_loss did not improve from 27.50953
196/196 - 12s - loss: 27.3257 - MinusLogProbMetric: 27.3257 - val_loss: 27.5188 - val_MinusLogProbMetric: 27.5188 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 339/1000
2023-10-05 10:25:40.610 
Epoch 339/1000 
	 loss: 27.3263, MinusLogProbMetric: 27.3263, val_loss: 27.5155, val_MinusLogProbMetric: 27.5155

Epoch 339: val_loss did not improve from 27.50953
196/196 - 12s - loss: 27.3263 - MinusLogProbMetric: 27.3263 - val_loss: 27.5155 - val_MinusLogProbMetric: 27.5155 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 340/1000
2023-10-05 10:25:51.472 
Epoch 340/1000 
	 loss: 27.3263, MinusLogProbMetric: 27.3263, val_loss: 27.5255, val_MinusLogProbMetric: 27.5255

Epoch 340: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3263 - MinusLogProbMetric: 27.3263 - val_loss: 27.5255 - val_MinusLogProbMetric: 27.5255 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 341/1000
2023-10-05 10:26:02.505 
Epoch 341/1000 
	 loss: 27.3248, MinusLogProbMetric: 27.3248, val_loss: 27.5380, val_MinusLogProbMetric: 27.5380

Epoch 341: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3248 - MinusLogProbMetric: 27.3248 - val_loss: 27.5380 - val_MinusLogProbMetric: 27.5380 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 342/1000
2023-10-05 10:26:13.639 
Epoch 342/1000 
	 loss: 27.3264, MinusLogProbMetric: 27.3264, val_loss: 27.5172, val_MinusLogProbMetric: 27.5172

Epoch 342: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3264 - MinusLogProbMetric: 27.3264 - val_loss: 27.5172 - val_MinusLogProbMetric: 27.5172 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 343/1000
2023-10-05 10:26:24.607 
Epoch 343/1000 
	 loss: 27.3250, MinusLogProbMetric: 27.3250, val_loss: 27.5282, val_MinusLogProbMetric: 27.5282

Epoch 343: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3250 - MinusLogProbMetric: 27.3250 - val_loss: 27.5282 - val_MinusLogProbMetric: 27.5282 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 344/1000
2023-10-05 10:26:35.648 
Epoch 344/1000 
	 loss: 27.3247, MinusLogProbMetric: 27.3247, val_loss: 27.5216, val_MinusLogProbMetric: 27.5216

Epoch 344: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3247 - MinusLogProbMetric: 27.3247 - val_loss: 27.5216 - val_MinusLogProbMetric: 27.5216 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 345/1000
2023-10-05 10:26:46.859 
Epoch 345/1000 
	 loss: 27.3260, MinusLogProbMetric: 27.3260, val_loss: 27.5305, val_MinusLogProbMetric: 27.5305

Epoch 345: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3260 - MinusLogProbMetric: 27.3260 - val_loss: 27.5305 - val_MinusLogProbMetric: 27.5305 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 346/1000
2023-10-05 10:26:57.496 
Epoch 346/1000 
	 loss: 27.3234, MinusLogProbMetric: 27.3234, val_loss: 27.5209, val_MinusLogProbMetric: 27.5209

Epoch 346: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3234 - MinusLogProbMetric: 27.3234 - val_loss: 27.5209 - val_MinusLogProbMetric: 27.5209 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 347/1000
2023-10-05 10:27:08.264 
Epoch 347/1000 
	 loss: 27.3236, MinusLogProbMetric: 27.3236, val_loss: 27.5140, val_MinusLogProbMetric: 27.5140

Epoch 347: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3236 - MinusLogProbMetric: 27.3236 - val_loss: 27.5140 - val_MinusLogProbMetric: 27.5140 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 348/1000
2023-10-05 10:27:18.777 
Epoch 348/1000 
	 loss: 27.3234, MinusLogProbMetric: 27.3234, val_loss: 27.5206, val_MinusLogProbMetric: 27.5206

Epoch 348: val_loss did not improve from 27.50953
196/196 - 10s - loss: 27.3234 - MinusLogProbMetric: 27.3234 - val_loss: 27.5206 - val_MinusLogProbMetric: 27.5206 - lr: 2.5000e-04 - 10s/epoch - 54ms/step
Epoch 349/1000
2023-10-05 10:27:29.369 
Epoch 349/1000 
	 loss: 27.3222, MinusLogProbMetric: 27.3222, val_loss: 27.5263, val_MinusLogProbMetric: 27.5263

Epoch 349: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3222 - MinusLogProbMetric: 27.3222 - val_loss: 27.5263 - val_MinusLogProbMetric: 27.5263 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 350/1000
2023-10-05 10:27:40.018 
Epoch 350/1000 
	 loss: 27.3227, MinusLogProbMetric: 27.3227, val_loss: 27.5303, val_MinusLogProbMetric: 27.5303

Epoch 350: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3227 - MinusLogProbMetric: 27.3227 - val_loss: 27.5303 - val_MinusLogProbMetric: 27.5303 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 351/1000
2023-10-05 10:27:50.535 
Epoch 351/1000 
	 loss: 27.3237, MinusLogProbMetric: 27.3237, val_loss: 27.5338, val_MinusLogProbMetric: 27.5338

Epoch 351: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3237 - MinusLogProbMetric: 27.3237 - val_loss: 27.5338 - val_MinusLogProbMetric: 27.5338 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 352/1000
2023-10-05 10:28:00.957 
Epoch 352/1000 
	 loss: 27.3247, MinusLogProbMetric: 27.3247, val_loss: 27.5326, val_MinusLogProbMetric: 27.5326

Epoch 352: val_loss did not improve from 27.50953
196/196 - 10s - loss: 27.3247 - MinusLogProbMetric: 27.3247 - val_loss: 27.5326 - val_MinusLogProbMetric: 27.5326 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 353/1000
2023-10-05 10:28:11.548 
Epoch 353/1000 
	 loss: 27.3254, MinusLogProbMetric: 27.3254, val_loss: 27.5199, val_MinusLogProbMetric: 27.5199

Epoch 353: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3254 - MinusLogProbMetric: 27.3254 - val_loss: 27.5199 - val_MinusLogProbMetric: 27.5199 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 354/1000
2023-10-05 10:28:21.861 
Epoch 354/1000 
	 loss: 27.3215, MinusLogProbMetric: 27.3215, val_loss: 27.5304, val_MinusLogProbMetric: 27.5304

Epoch 354: val_loss did not improve from 27.50953
196/196 - 10s - loss: 27.3215 - MinusLogProbMetric: 27.3215 - val_loss: 27.5304 - val_MinusLogProbMetric: 27.5304 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 355/1000
2023-10-05 10:28:32.322 
Epoch 355/1000 
	 loss: 27.3233, MinusLogProbMetric: 27.3233, val_loss: 27.5247, val_MinusLogProbMetric: 27.5247

Epoch 355: val_loss did not improve from 27.50953
196/196 - 10s - loss: 27.3233 - MinusLogProbMetric: 27.3233 - val_loss: 27.5247 - val_MinusLogProbMetric: 27.5247 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 356/1000
2023-10-05 10:28:42.629 
Epoch 356/1000 
	 loss: 27.3233, MinusLogProbMetric: 27.3233, val_loss: 27.5231, val_MinusLogProbMetric: 27.5231

Epoch 356: val_loss did not improve from 27.50953
196/196 - 10s - loss: 27.3233 - MinusLogProbMetric: 27.3233 - val_loss: 27.5231 - val_MinusLogProbMetric: 27.5231 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 357/1000
2023-10-05 10:28:52.963 
Epoch 357/1000 
	 loss: 27.3238, MinusLogProbMetric: 27.3238, val_loss: 27.5329, val_MinusLogProbMetric: 27.5329

Epoch 357: val_loss did not improve from 27.50953
196/196 - 10s - loss: 27.3238 - MinusLogProbMetric: 27.3238 - val_loss: 27.5329 - val_MinusLogProbMetric: 27.5329 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 358/1000
2023-10-05 10:29:03.331 
Epoch 358/1000 
	 loss: 27.3224, MinusLogProbMetric: 27.3224, val_loss: 27.5212, val_MinusLogProbMetric: 27.5212

Epoch 358: val_loss did not improve from 27.50953
196/196 - 10s - loss: 27.3224 - MinusLogProbMetric: 27.3224 - val_loss: 27.5212 - val_MinusLogProbMetric: 27.5212 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 359/1000
2023-10-05 10:29:13.648 
Epoch 359/1000 
	 loss: 27.3246, MinusLogProbMetric: 27.3246, val_loss: 27.5188, val_MinusLogProbMetric: 27.5188

Epoch 359: val_loss did not improve from 27.50953
196/196 - 10s - loss: 27.3246 - MinusLogProbMetric: 27.3246 - val_loss: 27.5188 - val_MinusLogProbMetric: 27.5188 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 360/1000
2023-10-05 10:29:23.891 
Epoch 360/1000 
	 loss: 27.3232, MinusLogProbMetric: 27.3232, val_loss: 27.5198, val_MinusLogProbMetric: 27.5198

Epoch 360: val_loss did not improve from 27.50953
196/196 - 10s - loss: 27.3232 - MinusLogProbMetric: 27.3232 - val_loss: 27.5198 - val_MinusLogProbMetric: 27.5198 - lr: 2.5000e-04 - 10s/epoch - 52ms/step
Epoch 361/1000
2023-10-05 10:29:34.274 
Epoch 361/1000 
	 loss: 27.3208, MinusLogProbMetric: 27.3208, val_loss: 27.5224, val_MinusLogProbMetric: 27.5224

Epoch 361: val_loss did not improve from 27.50953
196/196 - 10s - loss: 27.3208 - MinusLogProbMetric: 27.3208 - val_loss: 27.5224 - val_MinusLogProbMetric: 27.5224 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 362/1000
2023-10-05 10:29:44.644 
Epoch 362/1000 
	 loss: 27.3237, MinusLogProbMetric: 27.3237, val_loss: 27.5259, val_MinusLogProbMetric: 27.5259

Epoch 362: val_loss did not improve from 27.50953
196/196 - 10s - loss: 27.3237 - MinusLogProbMetric: 27.3237 - val_loss: 27.5259 - val_MinusLogProbMetric: 27.5259 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 363/1000
2023-10-05 10:29:55.335 
Epoch 363/1000 
	 loss: 27.3239, MinusLogProbMetric: 27.3239, val_loss: 27.5314, val_MinusLogProbMetric: 27.5314

Epoch 363: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3239 - MinusLogProbMetric: 27.3239 - val_loss: 27.5314 - val_MinusLogProbMetric: 27.5314 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 364/1000
2023-10-05 10:30:06.121 
Epoch 364/1000 
	 loss: 27.3220, MinusLogProbMetric: 27.3220, val_loss: 27.5241, val_MinusLogProbMetric: 27.5241

Epoch 364: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3220 - MinusLogProbMetric: 27.3220 - val_loss: 27.5241 - val_MinusLogProbMetric: 27.5241 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 365/1000
2023-10-05 10:30:17.144 
Epoch 365/1000 
	 loss: 27.3206, MinusLogProbMetric: 27.3206, val_loss: 27.5186, val_MinusLogProbMetric: 27.5186

Epoch 365: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3206 - MinusLogProbMetric: 27.3206 - val_loss: 27.5186 - val_MinusLogProbMetric: 27.5186 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 366/1000
2023-10-05 10:30:27.770 
Epoch 366/1000 
	 loss: 27.3224, MinusLogProbMetric: 27.3224, val_loss: 27.5192, val_MinusLogProbMetric: 27.5192

Epoch 366: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3224 - MinusLogProbMetric: 27.3224 - val_loss: 27.5192 - val_MinusLogProbMetric: 27.5192 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 367/1000
2023-10-05 10:30:38.020 
Epoch 367/1000 
	 loss: 27.3222, MinusLogProbMetric: 27.3222, val_loss: 27.5196, val_MinusLogProbMetric: 27.5196

Epoch 367: val_loss did not improve from 27.50953
196/196 - 10s - loss: 27.3222 - MinusLogProbMetric: 27.3222 - val_loss: 27.5196 - val_MinusLogProbMetric: 27.5196 - lr: 2.5000e-04 - 10s/epoch - 52ms/step
Epoch 368/1000
2023-10-05 10:30:48.654 
Epoch 368/1000 
	 loss: 27.3221, MinusLogProbMetric: 27.3221, val_loss: 27.5240, val_MinusLogProbMetric: 27.5240

Epoch 368: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3221 - MinusLogProbMetric: 27.3221 - val_loss: 27.5240 - val_MinusLogProbMetric: 27.5240 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 369/1000
2023-10-05 10:30:59.646 
Epoch 369/1000 
	 loss: 27.3237, MinusLogProbMetric: 27.3237, val_loss: 27.5216, val_MinusLogProbMetric: 27.5216

Epoch 369: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3237 - MinusLogProbMetric: 27.3237 - val_loss: 27.5216 - val_MinusLogProbMetric: 27.5216 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 370/1000
2023-10-05 10:31:10.666 
Epoch 370/1000 
	 loss: 27.3220, MinusLogProbMetric: 27.3220, val_loss: 27.5231, val_MinusLogProbMetric: 27.5231

Epoch 370: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3220 - MinusLogProbMetric: 27.3220 - val_loss: 27.5231 - val_MinusLogProbMetric: 27.5231 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 371/1000
2023-10-05 10:31:21.787 
Epoch 371/1000 
	 loss: 27.3226, MinusLogProbMetric: 27.3226, val_loss: 27.5251, val_MinusLogProbMetric: 27.5251

Epoch 371: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3226 - MinusLogProbMetric: 27.3226 - val_loss: 27.5251 - val_MinusLogProbMetric: 27.5251 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 372/1000
2023-10-05 10:31:32.743 
Epoch 372/1000 
	 loss: 27.3230, MinusLogProbMetric: 27.3230, val_loss: 27.5173, val_MinusLogProbMetric: 27.5173

Epoch 372: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3230 - MinusLogProbMetric: 27.3230 - val_loss: 27.5173 - val_MinusLogProbMetric: 27.5173 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 373/1000
2023-10-05 10:31:43.644 
Epoch 373/1000 
	 loss: 27.3182, MinusLogProbMetric: 27.3182, val_loss: 27.5204, val_MinusLogProbMetric: 27.5204

Epoch 373: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3182 - MinusLogProbMetric: 27.3182 - val_loss: 27.5204 - val_MinusLogProbMetric: 27.5204 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 374/1000
2023-10-05 10:31:54.804 
Epoch 374/1000 
	 loss: 27.3221, MinusLogProbMetric: 27.3221, val_loss: 27.5199, val_MinusLogProbMetric: 27.5199

Epoch 374: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3221 - MinusLogProbMetric: 27.3221 - val_loss: 27.5199 - val_MinusLogProbMetric: 27.5199 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 375/1000
2023-10-05 10:32:05.864 
Epoch 375/1000 
	 loss: 27.3221, MinusLogProbMetric: 27.3221, val_loss: 27.5286, val_MinusLogProbMetric: 27.5286

Epoch 375: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3221 - MinusLogProbMetric: 27.3221 - val_loss: 27.5286 - val_MinusLogProbMetric: 27.5286 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 376/1000
2023-10-05 10:32:16.417 
Epoch 376/1000 
	 loss: 27.3197, MinusLogProbMetric: 27.3197, val_loss: 27.5230, val_MinusLogProbMetric: 27.5230

Epoch 376: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3197 - MinusLogProbMetric: 27.3197 - val_loss: 27.5230 - val_MinusLogProbMetric: 27.5230 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 377/1000
2023-10-05 10:32:26.782 
Epoch 377/1000 
	 loss: 27.3192, MinusLogProbMetric: 27.3192, val_loss: 27.5297, val_MinusLogProbMetric: 27.5297

Epoch 377: val_loss did not improve from 27.50953
196/196 - 10s - loss: 27.3192 - MinusLogProbMetric: 27.3192 - val_loss: 27.5297 - val_MinusLogProbMetric: 27.5297 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 378/1000
2023-10-05 10:32:37.579 
Epoch 378/1000 
	 loss: 27.3206, MinusLogProbMetric: 27.3206, val_loss: 27.5391, val_MinusLogProbMetric: 27.5391

Epoch 378: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3206 - MinusLogProbMetric: 27.3206 - val_loss: 27.5391 - val_MinusLogProbMetric: 27.5391 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 379/1000
2023-10-05 10:32:48.647 
Epoch 379/1000 
	 loss: 27.3218, MinusLogProbMetric: 27.3218, val_loss: 27.5254, val_MinusLogProbMetric: 27.5254

Epoch 379: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3218 - MinusLogProbMetric: 27.3218 - val_loss: 27.5254 - val_MinusLogProbMetric: 27.5254 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 380/1000
2023-10-05 10:32:59.520 
Epoch 380/1000 
	 loss: 27.3023, MinusLogProbMetric: 27.3023, val_loss: 27.5117, val_MinusLogProbMetric: 27.5117

Epoch 380: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3023 - MinusLogProbMetric: 27.3023 - val_loss: 27.5117 - val_MinusLogProbMetric: 27.5117 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 381/1000
2023-10-05 10:33:10.520 
Epoch 381/1000 
	 loss: 27.3015, MinusLogProbMetric: 27.3015, val_loss: 27.5104, val_MinusLogProbMetric: 27.5104

Epoch 381: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3015 - MinusLogProbMetric: 27.3015 - val_loss: 27.5104 - val_MinusLogProbMetric: 27.5104 - lr: 1.2500e-04 - 11s/epoch - 56ms/step
Epoch 382/1000
2023-10-05 10:33:21.249 
Epoch 382/1000 
	 loss: 27.3012, MinusLogProbMetric: 27.3012, val_loss: 27.5121, val_MinusLogProbMetric: 27.5121

Epoch 382: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3012 - MinusLogProbMetric: 27.3012 - val_loss: 27.5121 - val_MinusLogProbMetric: 27.5121 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 383/1000
2023-10-05 10:33:31.922 
Epoch 383/1000 
	 loss: 27.3005, MinusLogProbMetric: 27.3005, val_loss: 27.5131, val_MinusLogProbMetric: 27.5131

Epoch 383: val_loss did not improve from 27.50953
196/196 - 11s - loss: 27.3005 - MinusLogProbMetric: 27.3005 - val_loss: 27.5131 - val_MinusLogProbMetric: 27.5131 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 384/1000
2023-10-05 10:33:42.887 
Epoch 384/1000 
	 loss: 27.3008, MinusLogProbMetric: 27.3008, val_loss: 27.5094, val_MinusLogProbMetric: 27.5094

Epoch 384: val_loss improved from 27.50953 to 27.50938, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 11s - loss: 27.3008 - MinusLogProbMetric: 27.3008 - val_loss: 27.5094 - val_MinusLogProbMetric: 27.5094 - lr: 1.2500e-04 - 11s/epoch - 57ms/step
Epoch 385/1000
2023-10-05 10:33:53.755 
Epoch 385/1000 
	 loss: 27.3007, MinusLogProbMetric: 27.3007, val_loss: 27.5117, val_MinusLogProbMetric: 27.5117

Epoch 385: val_loss did not improve from 27.50938
196/196 - 11s - loss: 27.3007 - MinusLogProbMetric: 27.3007 - val_loss: 27.5117 - val_MinusLogProbMetric: 27.5117 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 386/1000
2023-10-05 10:34:03.951 
Epoch 386/1000 
	 loss: 27.2999, MinusLogProbMetric: 27.2999, val_loss: 27.5137, val_MinusLogProbMetric: 27.5137

Epoch 386: val_loss did not improve from 27.50938
196/196 - 10s - loss: 27.2999 - MinusLogProbMetric: 27.2999 - val_loss: 27.5137 - val_MinusLogProbMetric: 27.5137 - lr: 1.2500e-04 - 10s/epoch - 52ms/step
Epoch 387/1000
2023-10-05 10:34:14.340 
Epoch 387/1000 
	 loss: 27.3007, MinusLogProbMetric: 27.3007, val_loss: 27.5088, val_MinusLogProbMetric: 27.5088

Epoch 387: val_loss improved from 27.50938 to 27.50884, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 11s - loss: 27.3007 - MinusLogProbMetric: 27.3007 - val_loss: 27.5088 - val_MinusLogProbMetric: 27.5088 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 388/1000
2023-10-05 10:34:24.662 
Epoch 388/1000 
	 loss: 27.3009, MinusLogProbMetric: 27.3009, val_loss: 27.5123, val_MinusLogProbMetric: 27.5123

Epoch 388: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.3009 - MinusLogProbMetric: 27.3009 - val_loss: 27.5123 - val_MinusLogProbMetric: 27.5123 - lr: 1.2500e-04 - 10s/epoch - 52ms/step
Epoch 389/1000
2023-10-05 10:34:34.883 
Epoch 389/1000 
	 loss: 27.3000, MinusLogProbMetric: 27.3000, val_loss: 27.5108, val_MinusLogProbMetric: 27.5108

Epoch 389: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.3000 - MinusLogProbMetric: 27.3000 - val_loss: 27.5108 - val_MinusLogProbMetric: 27.5108 - lr: 1.2500e-04 - 10s/epoch - 52ms/step
Epoch 390/1000
2023-10-05 10:34:45.359 
Epoch 390/1000 
	 loss: 27.3012, MinusLogProbMetric: 27.3012, val_loss: 27.5110, val_MinusLogProbMetric: 27.5110

Epoch 390: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.3012 - MinusLogProbMetric: 27.3012 - val_loss: 27.5110 - val_MinusLogProbMetric: 27.5110 - lr: 1.2500e-04 - 10s/epoch - 53ms/step
Epoch 391/1000
2023-10-05 10:34:55.910 
Epoch 391/1000 
	 loss: 27.3006, MinusLogProbMetric: 27.3006, val_loss: 27.5121, val_MinusLogProbMetric: 27.5121

Epoch 391: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.3006 - MinusLogProbMetric: 27.3006 - val_loss: 27.5121 - val_MinusLogProbMetric: 27.5121 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 392/1000
2023-10-05 10:35:06.544 
Epoch 392/1000 
	 loss: 27.3011, MinusLogProbMetric: 27.3011, val_loss: 27.5118, val_MinusLogProbMetric: 27.5118

Epoch 392: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.3011 - MinusLogProbMetric: 27.3011 - val_loss: 27.5118 - val_MinusLogProbMetric: 27.5118 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 393/1000
2023-10-05 10:35:16.906 
Epoch 393/1000 
	 loss: 27.2995, MinusLogProbMetric: 27.2995, val_loss: 27.5113, val_MinusLogProbMetric: 27.5113

Epoch 393: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.2995 - MinusLogProbMetric: 27.2995 - val_loss: 27.5113 - val_MinusLogProbMetric: 27.5113 - lr: 1.2500e-04 - 10s/epoch - 53ms/step
Epoch 394/1000
2023-10-05 10:35:27.374 
Epoch 394/1000 
	 loss: 27.3005, MinusLogProbMetric: 27.3005, val_loss: 27.5133, val_MinusLogProbMetric: 27.5133

Epoch 394: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.3005 - MinusLogProbMetric: 27.3005 - val_loss: 27.5133 - val_MinusLogProbMetric: 27.5133 - lr: 1.2500e-04 - 10s/epoch - 53ms/step
Epoch 395/1000
2023-10-05 10:35:37.859 
Epoch 395/1000 
	 loss: 27.3003, MinusLogProbMetric: 27.3003, val_loss: 27.5112, val_MinusLogProbMetric: 27.5112

Epoch 395: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.3003 - MinusLogProbMetric: 27.3003 - val_loss: 27.5112 - val_MinusLogProbMetric: 27.5112 - lr: 1.2500e-04 - 10s/epoch - 53ms/step
Epoch 396/1000
2023-10-05 10:35:48.197 
Epoch 396/1000 
	 loss: 27.3007, MinusLogProbMetric: 27.3007, val_loss: 27.5176, val_MinusLogProbMetric: 27.5176

Epoch 396: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.3007 - MinusLogProbMetric: 27.3007 - val_loss: 27.5176 - val_MinusLogProbMetric: 27.5176 - lr: 1.2500e-04 - 10s/epoch - 53ms/step
Epoch 397/1000
2023-10-05 10:35:58.413 
Epoch 397/1000 
	 loss: 27.2996, MinusLogProbMetric: 27.2996, val_loss: 27.5119, val_MinusLogProbMetric: 27.5119

Epoch 397: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.2996 - MinusLogProbMetric: 27.2996 - val_loss: 27.5119 - val_MinusLogProbMetric: 27.5119 - lr: 1.2500e-04 - 10s/epoch - 52ms/step
Epoch 398/1000
2023-10-05 10:36:08.669 
Epoch 398/1000 
	 loss: 27.2991, MinusLogProbMetric: 27.2991, val_loss: 27.5136, val_MinusLogProbMetric: 27.5136

Epoch 398: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.2991 - MinusLogProbMetric: 27.2991 - val_loss: 27.5136 - val_MinusLogProbMetric: 27.5136 - lr: 1.2500e-04 - 10s/epoch - 52ms/step
Epoch 399/1000
2023-10-05 10:36:19.025 
Epoch 399/1000 
	 loss: 27.3004, MinusLogProbMetric: 27.3004, val_loss: 27.5144, val_MinusLogProbMetric: 27.5144

Epoch 399: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.3004 - MinusLogProbMetric: 27.3004 - val_loss: 27.5144 - val_MinusLogProbMetric: 27.5144 - lr: 1.2500e-04 - 10s/epoch - 53ms/step
Epoch 400/1000
2023-10-05 10:36:29.323 
Epoch 400/1000 
	 loss: 27.3000, MinusLogProbMetric: 27.3000, val_loss: 27.5131, val_MinusLogProbMetric: 27.5131

Epoch 400: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.3000 - MinusLogProbMetric: 27.3000 - val_loss: 27.5131 - val_MinusLogProbMetric: 27.5131 - lr: 1.2500e-04 - 10s/epoch - 52ms/step
Epoch 401/1000
2023-10-05 10:36:39.837 
Epoch 401/1000 
	 loss: 27.2994, MinusLogProbMetric: 27.2994, val_loss: 27.5130, val_MinusLogProbMetric: 27.5130

Epoch 401: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.2994 - MinusLogProbMetric: 27.2994 - val_loss: 27.5130 - val_MinusLogProbMetric: 27.5130 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 402/1000
2023-10-05 10:36:51.486 
Epoch 402/1000 
	 loss: 27.2990, MinusLogProbMetric: 27.2990, val_loss: 27.5111, val_MinusLogProbMetric: 27.5111

Epoch 402: val_loss did not improve from 27.50884
196/196 - 12s - loss: 27.2990 - MinusLogProbMetric: 27.2990 - val_loss: 27.5111 - val_MinusLogProbMetric: 27.5111 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 403/1000
2023-10-05 10:37:01.972 
Epoch 403/1000 
	 loss: 27.2993, MinusLogProbMetric: 27.2993, val_loss: 27.5167, val_MinusLogProbMetric: 27.5167

Epoch 403: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.2993 - MinusLogProbMetric: 27.2993 - val_loss: 27.5167 - val_MinusLogProbMetric: 27.5167 - lr: 1.2500e-04 - 10s/epoch - 53ms/step
Epoch 404/1000
2023-10-05 10:37:12.350 
Epoch 404/1000 
	 loss: 27.3005, MinusLogProbMetric: 27.3005, val_loss: 27.5174, val_MinusLogProbMetric: 27.5174

Epoch 404: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.3005 - MinusLogProbMetric: 27.3005 - val_loss: 27.5174 - val_MinusLogProbMetric: 27.5174 - lr: 1.2500e-04 - 10s/epoch - 53ms/step
Epoch 405/1000
2023-10-05 10:37:23.875 
Epoch 405/1000 
	 loss: 27.2995, MinusLogProbMetric: 27.2995, val_loss: 27.5125, val_MinusLogProbMetric: 27.5125

Epoch 405: val_loss did not improve from 27.50884
196/196 - 12s - loss: 27.2995 - MinusLogProbMetric: 27.2995 - val_loss: 27.5125 - val_MinusLogProbMetric: 27.5125 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 406/1000
2023-10-05 10:37:34.257 
Epoch 406/1000 
	 loss: 27.2990, MinusLogProbMetric: 27.2990, val_loss: 27.5125, val_MinusLogProbMetric: 27.5125

Epoch 406: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.2990 - MinusLogProbMetric: 27.2990 - val_loss: 27.5125 - val_MinusLogProbMetric: 27.5125 - lr: 1.2500e-04 - 10s/epoch - 53ms/step
Epoch 407/1000
2023-10-05 10:37:44.554 
Epoch 407/1000 
	 loss: 27.2990, MinusLogProbMetric: 27.2990, val_loss: 27.5236, val_MinusLogProbMetric: 27.5236

Epoch 407: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.2990 - MinusLogProbMetric: 27.2990 - val_loss: 27.5236 - val_MinusLogProbMetric: 27.5236 - lr: 1.2500e-04 - 10s/epoch - 53ms/step
Epoch 408/1000
2023-10-05 10:37:55.010 
Epoch 408/1000 
	 loss: 27.2994, MinusLogProbMetric: 27.2994, val_loss: 27.5234, val_MinusLogProbMetric: 27.5234

Epoch 408: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.2994 - MinusLogProbMetric: 27.2994 - val_loss: 27.5234 - val_MinusLogProbMetric: 27.5234 - lr: 1.2500e-04 - 10s/epoch - 53ms/step
Epoch 409/1000
2023-10-05 10:38:05.591 
Epoch 409/1000 
	 loss: 27.2994, MinusLogProbMetric: 27.2994, val_loss: 27.5126, val_MinusLogProbMetric: 27.5126

Epoch 409: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.2994 - MinusLogProbMetric: 27.2994 - val_loss: 27.5126 - val_MinusLogProbMetric: 27.5126 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 410/1000
2023-10-05 10:38:16.215 
Epoch 410/1000 
	 loss: 27.2995, MinusLogProbMetric: 27.2995, val_loss: 27.5113, val_MinusLogProbMetric: 27.5113

Epoch 410: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.2995 - MinusLogProbMetric: 27.2995 - val_loss: 27.5113 - val_MinusLogProbMetric: 27.5113 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 411/1000
2023-10-05 10:38:27.056 
Epoch 411/1000 
	 loss: 27.3003, MinusLogProbMetric: 27.3003, val_loss: 27.5144, val_MinusLogProbMetric: 27.5144

Epoch 411: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.3003 - MinusLogProbMetric: 27.3003 - val_loss: 27.5144 - val_MinusLogProbMetric: 27.5144 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 412/1000
2023-10-05 10:38:37.907 
Epoch 412/1000 
	 loss: 27.2989, MinusLogProbMetric: 27.2989, val_loss: 27.5154, val_MinusLogProbMetric: 27.5154

Epoch 412: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.2989 - MinusLogProbMetric: 27.2989 - val_loss: 27.5154 - val_MinusLogProbMetric: 27.5154 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 413/1000
2023-10-05 10:38:48.740 
Epoch 413/1000 
	 loss: 27.2991, MinusLogProbMetric: 27.2991, val_loss: 27.5110, val_MinusLogProbMetric: 27.5110

Epoch 413: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.2991 - MinusLogProbMetric: 27.2991 - val_loss: 27.5110 - val_MinusLogProbMetric: 27.5110 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 414/1000
2023-10-05 10:38:59.571 
Epoch 414/1000 
	 loss: 27.2975, MinusLogProbMetric: 27.2975, val_loss: 27.5175, val_MinusLogProbMetric: 27.5175

Epoch 414: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.2975 - MinusLogProbMetric: 27.2975 - val_loss: 27.5175 - val_MinusLogProbMetric: 27.5175 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 415/1000
2023-10-05 10:39:10.468 
Epoch 415/1000 
	 loss: 27.2993, MinusLogProbMetric: 27.2993, val_loss: 27.5189, val_MinusLogProbMetric: 27.5189

Epoch 415: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.2993 - MinusLogProbMetric: 27.2993 - val_loss: 27.5189 - val_MinusLogProbMetric: 27.5189 - lr: 1.2500e-04 - 11s/epoch - 56ms/step
Epoch 416/1000
2023-10-05 10:39:21.582 
Epoch 416/1000 
	 loss: 27.2988, MinusLogProbMetric: 27.2988, val_loss: 27.5202, val_MinusLogProbMetric: 27.5202

Epoch 416: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.2988 - MinusLogProbMetric: 27.2988 - val_loss: 27.5202 - val_MinusLogProbMetric: 27.5202 - lr: 1.2500e-04 - 11s/epoch - 57ms/step
Epoch 417/1000
2023-10-05 10:39:32.372 
Epoch 417/1000 
	 loss: 27.2992, MinusLogProbMetric: 27.2992, val_loss: 27.5091, val_MinusLogProbMetric: 27.5091

Epoch 417: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.2992 - MinusLogProbMetric: 27.2992 - val_loss: 27.5091 - val_MinusLogProbMetric: 27.5091 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 418/1000
2023-10-05 10:39:42.618 
Epoch 418/1000 
	 loss: 27.2976, MinusLogProbMetric: 27.2976, val_loss: 27.5091, val_MinusLogProbMetric: 27.5091

Epoch 418: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.2976 - MinusLogProbMetric: 27.2976 - val_loss: 27.5091 - val_MinusLogProbMetric: 27.5091 - lr: 1.2500e-04 - 10s/epoch - 52ms/step
Epoch 419/1000
2023-10-05 10:39:53.113 
Epoch 419/1000 
	 loss: 27.2974, MinusLogProbMetric: 27.2974, val_loss: 27.5148, val_MinusLogProbMetric: 27.5148

Epoch 419: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.2974 - MinusLogProbMetric: 27.2974 - val_loss: 27.5148 - val_MinusLogProbMetric: 27.5148 - lr: 1.2500e-04 - 10s/epoch - 54ms/step
Epoch 420/1000
2023-10-05 10:40:03.920 
Epoch 420/1000 
	 loss: 27.2993, MinusLogProbMetric: 27.2993, val_loss: 27.5144, val_MinusLogProbMetric: 27.5144

Epoch 420: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.2993 - MinusLogProbMetric: 27.2993 - val_loss: 27.5144 - val_MinusLogProbMetric: 27.5144 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 421/1000
2023-10-05 10:40:14.236 
Epoch 421/1000 
	 loss: 27.2976, MinusLogProbMetric: 27.2976, val_loss: 27.5171, val_MinusLogProbMetric: 27.5171

Epoch 421: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.2976 - MinusLogProbMetric: 27.2976 - val_loss: 27.5171 - val_MinusLogProbMetric: 27.5171 - lr: 1.2500e-04 - 10s/epoch - 53ms/step
Epoch 422/1000
2023-10-05 10:40:24.513 
Epoch 422/1000 
	 loss: 27.2982, MinusLogProbMetric: 27.2982, val_loss: 27.5152, val_MinusLogProbMetric: 27.5152

Epoch 422: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.2982 - MinusLogProbMetric: 27.2982 - val_loss: 27.5152 - val_MinusLogProbMetric: 27.5152 - lr: 1.2500e-04 - 10s/epoch - 52ms/step
Epoch 423/1000
2023-10-05 10:40:35.705 
Epoch 423/1000 
	 loss: 27.2979, MinusLogProbMetric: 27.2979, val_loss: 27.5117, val_MinusLogProbMetric: 27.5117

Epoch 423: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.2979 - MinusLogProbMetric: 27.2979 - val_loss: 27.5117 - val_MinusLogProbMetric: 27.5117 - lr: 1.2500e-04 - 11s/epoch - 57ms/step
Epoch 424/1000
2023-10-05 10:40:46.056 
Epoch 424/1000 
	 loss: 27.2979, MinusLogProbMetric: 27.2979, val_loss: 27.5136, val_MinusLogProbMetric: 27.5136

Epoch 424: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.2979 - MinusLogProbMetric: 27.2979 - val_loss: 27.5136 - val_MinusLogProbMetric: 27.5136 - lr: 1.2500e-04 - 10s/epoch - 53ms/step
Epoch 425/1000
2023-10-05 10:40:56.330 
Epoch 425/1000 
	 loss: 27.2988, MinusLogProbMetric: 27.2988, val_loss: 27.5126, val_MinusLogProbMetric: 27.5126

Epoch 425: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.2988 - MinusLogProbMetric: 27.2988 - val_loss: 27.5126 - val_MinusLogProbMetric: 27.5126 - lr: 1.2500e-04 - 10s/epoch - 52ms/step
Epoch 426/1000
2023-10-05 10:41:07.627 
Epoch 426/1000 
	 loss: 27.2980, MinusLogProbMetric: 27.2980, val_loss: 27.5134, val_MinusLogProbMetric: 27.5134

Epoch 426: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.2980 - MinusLogProbMetric: 27.2980 - val_loss: 27.5134 - val_MinusLogProbMetric: 27.5134 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 427/1000
2023-10-05 10:41:18.306 
Epoch 427/1000 
	 loss: 27.2992, MinusLogProbMetric: 27.2992, val_loss: 27.5185, val_MinusLogProbMetric: 27.5185

Epoch 427: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.2992 - MinusLogProbMetric: 27.2992 - val_loss: 27.5185 - val_MinusLogProbMetric: 27.5185 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 428/1000
2023-10-05 10:41:28.891 
Epoch 428/1000 
	 loss: 27.2971, MinusLogProbMetric: 27.2971, val_loss: 27.5146, val_MinusLogProbMetric: 27.5146

Epoch 428: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.2971 - MinusLogProbMetric: 27.2971 - val_loss: 27.5146 - val_MinusLogProbMetric: 27.5146 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 429/1000
2023-10-05 10:41:39.829 
Epoch 429/1000 
	 loss: 27.2972, MinusLogProbMetric: 27.2972, val_loss: 27.5159, val_MinusLogProbMetric: 27.5159

Epoch 429: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.2972 - MinusLogProbMetric: 27.2972 - val_loss: 27.5159 - val_MinusLogProbMetric: 27.5159 - lr: 1.2500e-04 - 11s/epoch - 56ms/step
Epoch 430/1000
2023-10-05 10:41:52.529 
Epoch 430/1000 
	 loss: 27.2966, MinusLogProbMetric: 27.2966, val_loss: 27.5142, val_MinusLogProbMetric: 27.5142

Epoch 430: val_loss did not improve from 27.50884
196/196 - 13s - loss: 27.2966 - MinusLogProbMetric: 27.2966 - val_loss: 27.5142 - val_MinusLogProbMetric: 27.5142 - lr: 1.2500e-04 - 13s/epoch - 65ms/step
Epoch 431/1000
2023-10-05 10:42:02.795 
Epoch 431/1000 
	 loss: 27.2970, MinusLogProbMetric: 27.2970, val_loss: 27.5131, val_MinusLogProbMetric: 27.5131

Epoch 431: val_loss did not improve from 27.50884
196/196 - 10s - loss: 27.2970 - MinusLogProbMetric: 27.2970 - val_loss: 27.5131 - val_MinusLogProbMetric: 27.5131 - lr: 1.2500e-04 - 10s/epoch - 52ms/step
Epoch 432/1000
2023-10-05 10:42:13.410 
Epoch 432/1000 
	 loss: 27.2983, MinusLogProbMetric: 27.2983, val_loss: 27.5164, val_MinusLogProbMetric: 27.5164

Epoch 432: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.2983 - MinusLogProbMetric: 27.2983 - val_loss: 27.5164 - val_MinusLogProbMetric: 27.5164 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 433/1000
2023-10-05 10:42:23.928 
Epoch 433/1000 
	 loss: 27.2974, MinusLogProbMetric: 27.2974, val_loss: 27.5137, val_MinusLogProbMetric: 27.5137

Epoch 433: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.2974 - MinusLogProbMetric: 27.2974 - val_loss: 27.5137 - val_MinusLogProbMetric: 27.5137 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 434/1000
2023-10-05 10:42:35.868 
Epoch 434/1000 
	 loss: 27.2968, MinusLogProbMetric: 27.2968, val_loss: 27.5132, val_MinusLogProbMetric: 27.5132

Epoch 434: val_loss did not improve from 27.50884
196/196 - 12s - loss: 27.2968 - MinusLogProbMetric: 27.2968 - val_loss: 27.5132 - val_MinusLogProbMetric: 27.5132 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 435/1000
2023-10-05 10:42:46.634 
Epoch 435/1000 
	 loss: 27.2972, MinusLogProbMetric: 27.2972, val_loss: 27.5198, val_MinusLogProbMetric: 27.5198

Epoch 435: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.2972 - MinusLogProbMetric: 27.2972 - val_loss: 27.5198 - val_MinusLogProbMetric: 27.5198 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 436/1000
2023-10-05 10:42:57.546 
Epoch 436/1000 
	 loss: 27.2974, MinusLogProbMetric: 27.2974, val_loss: 27.5153, val_MinusLogProbMetric: 27.5153

Epoch 436: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.2974 - MinusLogProbMetric: 27.2974 - val_loss: 27.5153 - val_MinusLogProbMetric: 27.5153 - lr: 1.2500e-04 - 11s/epoch - 56ms/step
Epoch 437/1000
2023-10-05 10:43:08.353 
Epoch 437/1000 
	 loss: 27.2974, MinusLogProbMetric: 27.2974, val_loss: 27.5094, val_MinusLogProbMetric: 27.5094

Epoch 437: val_loss did not improve from 27.50884
196/196 - 11s - loss: 27.2974 - MinusLogProbMetric: 27.2974 - val_loss: 27.5094 - val_MinusLogProbMetric: 27.5094 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 438/1000
2023-10-05 10:43:19.201 
Epoch 438/1000 
	 loss: 27.2876, MinusLogProbMetric: 27.2876, val_loss: 27.5086, val_MinusLogProbMetric: 27.5086

Epoch 438: val_loss improved from 27.50884 to 27.50858, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 11s - loss: 27.2876 - MinusLogProbMetric: 27.2876 - val_loss: 27.5086 - val_MinusLogProbMetric: 27.5086 - lr: 6.2500e-05 - 11s/epoch - 56ms/step
Epoch 439/1000
2023-10-05 10:43:31.309 
Epoch 439/1000 
	 loss: 27.2877, MinusLogProbMetric: 27.2877, val_loss: 27.5130, val_MinusLogProbMetric: 27.5130

Epoch 439: val_loss did not improve from 27.50858
196/196 - 12s - loss: 27.2877 - MinusLogProbMetric: 27.2877 - val_loss: 27.5130 - val_MinusLogProbMetric: 27.5130 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 440/1000
2023-10-05 10:43:41.540 
Epoch 440/1000 
	 loss: 27.2868, MinusLogProbMetric: 27.2868, val_loss: 27.5103, val_MinusLogProbMetric: 27.5103

Epoch 440: val_loss did not improve from 27.50858
196/196 - 10s - loss: 27.2868 - MinusLogProbMetric: 27.2868 - val_loss: 27.5103 - val_MinusLogProbMetric: 27.5103 - lr: 6.2500e-05 - 10s/epoch - 52ms/step
Epoch 441/1000
2023-10-05 10:43:52.693 
Epoch 441/1000 
	 loss: 27.2870, MinusLogProbMetric: 27.2870, val_loss: 27.5099, val_MinusLogProbMetric: 27.5099

Epoch 441: val_loss did not improve from 27.50858
196/196 - 11s - loss: 27.2870 - MinusLogProbMetric: 27.2870 - val_loss: 27.5099 - val_MinusLogProbMetric: 27.5099 - lr: 6.2500e-05 - 11s/epoch - 57ms/step
Epoch 442/1000
2023-10-05 10:44:05.011 
Epoch 442/1000 
	 loss: 27.2873, MinusLogProbMetric: 27.2873, val_loss: 27.5104, val_MinusLogProbMetric: 27.5104

Epoch 442: val_loss did not improve from 27.50858
196/196 - 12s - loss: 27.2873 - MinusLogProbMetric: 27.2873 - val_loss: 27.5104 - val_MinusLogProbMetric: 27.5104 - lr: 6.2500e-05 - 12s/epoch - 63ms/step
Epoch 443/1000
2023-10-05 10:44:15.396 
Epoch 443/1000 
	 loss: 27.2872, MinusLogProbMetric: 27.2872, val_loss: 27.5082, val_MinusLogProbMetric: 27.5082

Epoch 443: val_loss improved from 27.50858 to 27.50823, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 11s - loss: 27.2872 - MinusLogProbMetric: 27.2872 - val_loss: 27.5082 - val_MinusLogProbMetric: 27.5082 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 444/1000
2023-10-05 10:44:25.753 
Epoch 444/1000 
	 loss: 27.2869, MinusLogProbMetric: 27.2869, val_loss: 27.5097, val_MinusLogProbMetric: 27.5097

Epoch 444: val_loss did not improve from 27.50823
196/196 - 10s - loss: 27.2869 - MinusLogProbMetric: 27.2869 - val_loss: 27.5097 - val_MinusLogProbMetric: 27.5097 - lr: 6.2500e-05 - 10s/epoch - 52ms/step
Epoch 445/1000
2023-10-05 10:44:36.180 
Epoch 445/1000 
	 loss: 27.2869, MinusLogProbMetric: 27.2869, val_loss: 27.5080, val_MinusLogProbMetric: 27.5080

Epoch 445: val_loss improved from 27.50823 to 27.50795, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 11s - loss: 27.2869 - MinusLogProbMetric: 27.2869 - val_loss: 27.5080 - val_MinusLogProbMetric: 27.5080 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 446/1000
2023-10-05 10:44:46.679 
Epoch 446/1000 
	 loss: 27.2873, MinusLogProbMetric: 27.2873, val_loss: 27.5093, val_MinusLogProbMetric: 27.5093

Epoch 446: val_loss did not improve from 27.50795
196/196 - 10s - loss: 27.2873 - MinusLogProbMetric: 27.2873 - val_loss: 27.5093 - val_MinusLogProbMetric: 27.5093 - lr: 6.2500e-05 - 10s/epoch - 53ms/step
Epoch 447/1000
2023-10-05 10:44:56.978 
Epoch 447/1000 
	 loss: 27.2878, MinusLogProbMetric: 27.2878, val_loss: 27.5077, val_MinusLogProbMetric: 27.5077

Epoch 447: val_loss improved from 27.50795 to 27.50769, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 11s - loss: 27.2878 - MinusLogProbMetric: 27.2878 - val_loss: 27.5077 - val_MinusLogProbMetric: 27.5077 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 448/1000
2023-10-05 10:45:07.908 
Epoch 448/1000 
	 loss: 27.2867, MinusLogProbMetric: 27.2867, val_loss: 27.5114, val_MinusLogProbMetric: 27.5114

Epoch 448: val_loss did not improve from 27.50769
196/196 - 11s - loss: 27.2867 - MinusLogProbMetric: 27.2867 - val_loss: 27.5114 - val_MinusLogProbMetric: 27.5114 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 449/1000
2023-10-05 10:45:18.323 
Epoch 449/1000 
	 loss: 27.2866, MinusLogProbMetric: 27.2866, val_loss: 27.5088, val_MinusLogProbMetric: 27.5088

Epoch 449: val_loss did not improve from 27.50769
196/196 - 10s - loss: 27.2866 - MinusLogProbMetric: 27.2866 - val_loss: 27.5088 - val_MinusLogProbMetric: 27.5088 - lr: 6.2500e-05 - 10s/epoch - 53ms/step
Epoch 450/1000
2023-10-05 10:45:28.995 
Epoch 450/1000 
	 loss: 27.2864, MinusLogProbMetric: 27.2864, val_loss: 27.5117, val_MinusLogProbMetric: 27.5117

Epoch 450: val_loss did not improve from 27.50769
196/196 - 11s - loss: 27.2864 - MinusLogProbMetric: 27.2864 - val_loss: 27.5117 - val_MinusLogProbMetric: 27.5117 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 451/1000
2023-10-05 10:45:40.162 
Epoch 451/1000 
	 loss: 27.2868, MinusLogProbMetric: 27.2868, val_loss: 27.5099, val_MinusLogProbMetric: 27.5099

Epoch 451: val_loss did not improve from 27.50769
196/196 - 11s - loss: 27.2868 - MinusLogProbMetric: 27.2868 - val_loss: 27.5099 - val_MinusLogProbMetric: 27.5099 - lr: 6.2500e-05 - 11s/epoch - 57ms/step
Epoch 452/1000
2023-10-05 10:45:51.008 
Epoch 452/1000 
	 loss: 27.2872, MinusLogProbMetric: 27.2872, val_loss: 27.5081, val_MinusLogProbMetric: 27.5081

Epoch 452: val_loss did not improve from 27.50769
196/196 - 11s - loss: 27.2872 - MinusLogProbMetric: 27.2872 - val_loss: 27.5081 - val_MinusLogProbMetric: 27.5081 - lr: 6.2500e-05 - 11s/epoch - 55ms/step
Epoch 453/1000
2023-10-05 10:46:01.662 
Epoch 453/1000 
	 loss: 27.2871, MinusLogProbMetric: 27.2871, val_loss: 27.5075, val_MinusLogProbMetric: 27.5075

Epoch 453: val_loss improved from 27.50769 to 27.50747, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 13s - loss: 27.2871 - MinusLogProbMetric: 27.2871 - val_loss: 27.5075 - val_MinusLogProbMetric: 27.5075 - lr: 6.2500e-05 - 13s/epoch - 64ms/step
Epoch 454/1000
2023-10-05 10:46:14.154 
Epoch 454/1000 
	 loss: 27.2865, MinusLogProbMetric: 27.2865, val_loss: 27.5083, val_MinusLogProbMetric: 27.5083

Epoch 454: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2865 - MinusLogProbMetric: 27.2865 - val_loss: 27.5083 - val_MinusLogProbMetric: 27.5083 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 455/1000
2023-10-05 10:46:24.690 
Epoch 455/1000 
	 loss: 27.2869, MinusLogProbMetric: 27.2869, val_loss: 27.5130, val_MinusLogProbMetric: 27.5130

Epoch 455: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2869 - MinusLogProbMetric: 27.2869 - val_loss: 27.5130 - val_MinusLogProbMetric: 27.5130 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 456/1000
2023-10-05 10:46:35.277 
Epoch 456/1000 
	 loss: 27.2869, MinusLogProbMetric: 27.2869, val_loss: 27.5145, val_MinusLogProbMetric: 27.5145

Epoch 456: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2869 - MinusLogProbMetric: 27.2869 - val_loss: 27.5145 - val_MinusLogProbMetric: 27.5145 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 457/1000
2023-10-05 10:46:45.791 
Epoch 457/1000 
	 loss: 27.2864, MinusLogProbMetric: 27.2864, val_loss: 27.5106, val_MinusLogProbMetric: 27.5106

Epoch 457: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2864 - MinusLogProbMetric: 27.2864 - val_loss: 27.5106 - val_MinusLogProbMetric: 27.5106 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 458/1000
2023-10-05 10:46:56.660 
Epoch 458/1000 
	 loss: 27.2864, MinusLogProbMetric: 27.2864, val_loss: 27.5084, val_MinusLogProbMetric: 27.5084

Epoch 458: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2864 - MinusLogProbMetric: 27.2864 - val_loss: 27.5084 - val_MinusLogProbMetric: 27.5084 - lr: 6.2500e-05 - 11s/epoch - 55ms/step
Epoch 459/1000
2023-10-05 10:47:07.198 
Epoch 459/1000 
	 loss: 27.2862, MinusLogProbMetric: 27.2862, val_loss: 27.5118, val_MinusLogProbMetric: 27.5118

Epoch 459: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2862 - MinusLogProbMetric: 27.2862 - val_loss: 27.5118 - val_MinusLogProbMetric: 27.5118 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 460/1000
2023-10-05 10:47:17.829 
Epoch 460/1000 
	 loss: 27.2873, MinusLogProbMetric: 27.2873, val_loss: 27.5157, val_MinusLogProbMetric: 27.5157

Epoch 460: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2873 - MinusLogProbMetric: 27.2873 - val_loss: 27.5157 - val_MinusLogProbMetric: 27.5157 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 461/1000
2023-10-05 10:47:28.168 
Epoch 461/1000 
	 loss: 27.2866, MinusLogProbMetric: 27.2866, val_loss: 27.5088, val_MinusLogProbMetric: 27.5088

Epoch 461: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2866 - MinusLogProbMetric: 27.2866 - val_loss: 27.5088 - val_MinusLogProbMetric: 27.5088 - lr: 6.2500e-05 - 10s/epoch - 53ms/step
Epoch 462/1000
2023-10-05 10:47:38.322 
Epoch 462/1000 
	 loss: 27.2866, MinusLogProbMetric: 27.2866, val_loss: 27.5084, val_MinusLogProbMetric: 27.5084

Epoch 462: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2866 - MinusLogProbMetric: 27.2866 - val_loss: 27.5084 - val_MinusLogProbMetric: 27.5084 - lr: 6.2500e-05 - 10s/epoch - 52ms/step
Epoch 463/1000
2023-10-05 10:47:48.511 
Epoch 463/1000 
	 loss: 27.2863, MinusLogProbMetric: 27.2863, val_loss: 27.5078, val_MinusLogProbMetric: 27.5078

Epoch 463: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2863 - MinusLogProbMetric: 27.2863 - val_loss: 27.5078 - val_MinusLogProbMetric: 27.5078 - lr: 6.2500e-05 - 10s/epoch - 52ms/step
Epoch 464/1000
2023-10-05 10:47:58.669 
Epoch 464/1000 
	 loss: 27.2869, MinusLogProbMetric: 27.2869, val_loss: 27.5111, val_MinusLogProbMetric: 27.5111

Epoch 464: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2869 - MinusLogProbMetric: 27.2869 - val_loss: 27.5111 - val_MinusLogProbMetric: 27.5111 - lr: 6.2500e-05 - 10s/epoch - 52ms/step
Epoch 465/1000
2023-10-05 10:48:08.429 
Epoch 465/1000 
	 loss: 27.2861, MinusLogProbMetric: 27.2861, val_loss: 27.5114, val_MinusLogProbMetric: 27.5114

Epoch 465: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2861 - MinusLogProbMetric: 27.2861 - val_loss: 27.5114 - val_MinusLogProbMetric: 27.5114 - lr: 6.2500e-05 - 10s/epoch - 50ms/step
Epoch 466/1000
2023-10-05 10:48:16.829 
Epoch 466/1000 
	 loss: 27.2863, MinusLogProbMetric: 27.2863, val_loss: 27.5141, val_MinusLogProbMetric: 27.5141

Epoch 466: val_loss did not improve from 27.50747
196/196 - 8s - loss: 27.2863 - MinusLogProbMetric: 27.2863 - val_loss: 27.5141 - val_MinusLogProbMetric: 27.5141 - lr: 6.2500e-05 - 8s/epoch - 43ms/step
Epoch 467/1000
2023-10-05 10:48:25.283 
Epoch 467/1000 
	 loss: 27.2859, MinusLogProbMetric: 27.2859, val_loss: 27.5109, val_MinusLogProbMetric: 27.5109

Epoch 467: val_loss did not improve from 27.50747
196/196 - 8s - loss: 27.2859 - MinusLogProbMetric: 27.2859 - val_loss: 27.5109 - val_MinusLogProbMetric: 27.5109 - lr: 6.2500e-05 - 8s/epoch - 43ms/step
Epoch 468/1000
2023-10-05 10:48:34.982 
Epoch 468/1000 
	 loss: 27.2865, MinusLogProbMetric: 27.2865, val_loss: 27.5130, val_MinusLogProbMetric: 27.5130

Epoch 468: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2865 - MinusLogProbMetric: 27.2865 - val_loss: 27.5130 - val_MinusLogProbMetric: 27.5130 - lr: 6.2500e-05 - 10s/epoch - 49ms/step
Epoch 469/1000
2023-10-05 10:48:45.310 
Epoch 469/1000 
	 loss: 27.2864, MinusLogProbMetric: 27.2864, val_loss: 27.5101, val_MinusLogProbMetric: 27.5101

Epoch 469: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2864 - MinusLogProbMetric: 27.2864 - val_loss: 27.5101 - val_MinusLogProbMetric: 27.5101 - lr: 6.2500e-05 - 10s/epoch - 53ms/step
Epoch 470/1000
2023-10-05 10:48:55.644 
Epoch 470/1000 
	 loss: 27.2861, MinusLogProbMetric: 27.2861, val_loss: 27.5084, val_MinusLogProbMetric: 27.5084

Epoch 470: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2861 - MinusLogProbMetric: 27.2861 - val_loss: 27.5084 - val_MinusLogProbMetric: 27.5084 - lr: 6.2500e-05 - 10s/epoch - 53ms/step
Epoch 471/1000
2023-10-05 10:49:06.481 
Epoch 471/1000 
	 loss: 27.2855, MinusLogProbMetric: 27.2855, val_loss: 27.5080, val_MinusLogProbMetric: 27.5080

Epoch 471: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2855 - MinusLogProbMetric: 27.2855 - val_loss: 27.5080 - val_MinusLogProbMetric: 27.5080 - lr: 6.2500e-05 - 11s/epoch - 55ms/step
Epoch 472/1000
2023-10-05 10:49:17.369 
Epoch 472/1000 
	 loss: 27.2861, MinusLogProbMetric: 27.2861, val_loss: 27.5099, val_MinusLogProbMetric: 27.5099

Epoch 472: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2861 - MinusLogProbMetric: 27.2861 - val_loss: 27.5099 - val_MinusLogProbMetric: 27.5099 - lr: 6.2500e-05 - 11s/epoch - 56ms/step
Epoch 473/1000
2023-10-05 10:49:28.012 
Epoch 473/1000 
	 loss: 27.2865, MinusLogProbMetric: 27.2865, val_loss: 27.5121, val_MinusLogProbMetric: 27.5121

Epoch 473: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2865 - MinusLogProbMetric: 27.2865 - val_loss: 27.5121 - val_MinusLogProbMetric: 27.5121 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 474/1000
2023-10-05 10:49:38.705 
Epoch 474/1000 
	 loss: 27.2861, MinusLogProbMetric: 27.2861, val_loss: 27.5085, val_MinusLogProbMetric: 27.5085

Epoch 474: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2861 - MinusLogProbMetric: 27.2861 - val_loss: 27.5085 - val_MinusLogProbMetric: 27.5085 - lr: 6.2500e-05 - 11s/epoch - 55ms/step
Epoch 475/1000
2023-10-05 10:49:49.448 
Epoch 475/1000 
	 loss: 27.2852, MinusLogProbMetric: 27.2852, val_loss: 27.5116, val_MinusLogProbMetric: 27.5116

Epoch 475: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2852 - MinusLogProbMetric: 27.2852 - val_loss: 27.5116 - val_MinusLogProbMetric: 27.5116 - lr: 6.2500e-05 - 11s/epoch - 55ms/step
Epoch 476/1000
2023-10-05 10:50:00.093 
Epoch 476/1000 
	 loss: 27.2862, MinusLogProbMetric: 27.2862, val_loss: 27.5113, val_MinusLogProbMetric: 27.5113

Epoch 476: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2862 - MinusLogProbMetric: 27.2862 - val_loss: 27.5113 - val_MinusLogProbMetric: 27.5113 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 477/1000
2023-10-05 10:50:10.629 
Epoch 477/1000 
	 loss: 27.2855, MinusLogProbMetric: 27.2855, val_loss: 27.5112, val_MinusLogProbMetric: 27.5112

Epoch 477: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2855 - MinusLogProbMetric: 27.2855 - val_loss: 27.5112 - val_MinusLogProbMetric: 27.5112 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 478/1000
2023-10-05 10:50:21.223 
Epoch 478/1000 
	 loss: 27.2863, MinusLogProbMetric: 27.2863, val_loss: 27.5131, val_MinusLogProbMetric: 27.5131

Epoch 478: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2863 - MinusLogProbMetric: 27.2863 - val_loss: 27.5131 - val_MinusLogProbMetric: 27.5131 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 479/1000
2023-10-05 10:50:31.285 
Epoch 479/1000 
	 loss: 27.2859, MinusLogProbMetric: 27.2859, val_loss: 27.5106, val_MinusLogProbMetric: 27.5106

Epoch 479: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2859 - MinusLogProbMetric: 27.2859 - val_loss: 27.5106 - val_MinusLogProbMetric: 27.5106 - lr: 6.2500e-05 - 10s/epoch - 51ms/step
Epoch 480/1000
2023-10-05 10:50:41.821 
Epoch 480/1000 
	 loss: 27.2852, MinusLogProbMetric: 27.2852, val_loss: 27.5102, val_MinusLogProbMetric: 27.5102

Epoch 480: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2852 - MinusLogProbMetric: 27.2852 - val_loss: 27.5102 - val_MinusLogProbMetric: 27.5102 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 481/1000
2023-10-05 10:50:52.270 
Epoch 481/1000 
	 loss: 27.2858, MinusLogProbMetric: 27.2858, val_loss: 27.5115, val_MinusLogProbMetric: 27.5115

Epoch 481: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2858 - MinusLogProbMetric: 27.2858 - val_loss: 27.5115 - val_MinusLogProbMetric: 27.5115 - lr: 6.2500e-05 - 10s/epoch - 53ms/step
Epoch 482/1000
2023-10-05 10:51:02.362 
Epoch 482/1000 
	 loss: 27.2855, MinusLogProbMetric: 27.2855, val_loss: 27.5112, val_MinusLogProbMetric: 27.5112

Epoch 482: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2855 - MinusLogProbMetric: 27.2855 - val_loss: 27.5112 - val_MinusLogProbMetric: 27.5112 - lr: 6.2500e-05 - 10s/epoch - 51ms/step
Epoch 483/1000
2023-10-05 10:51:12.913 
Epoch 483/1000 
	 loss: 27.2856, MinusLogProbMetric: 27.2856, val_loss: 27.5108, val_MinusLogProbMetric: 27.5108

Epoch 483: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2856 - MinusLogProbMetric: 27.2856 - val_loss: 27.5108 - val_MinusLogProbMetric: 27.5108 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 484/1000
2023-10-05 10:51:24.098 
Epoch 484/1000 
	 loss: 27.2860, MinusLogProbMetric: 27.2860, val_loss: 27.5112, val_MinusLogProbMetric: 27.5112

Epoch 484: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2860 - MinusLogProbMetric: 27.2860 - val_loss: 27.5112 - val_MinusLogProbMetric: 27.5112 - lr: 6.2500e-05 - 11s/epoch - 57ms/step
Epoch 485/1000
2023-10-05 10:51:36.028 
Epoch 485/1000 
	 loss: 27.2854, MinusLogProbMetric: 27.2854, val_loss: 27.5129, val_MinusLogProbMetric: 27.5129

Epoch 485: val_loss did not improve from 27.50747
196/196 - 12s - loss: 27.2854 - MinusLogProbMetric: 27.2854 - val_loss: 27.5129 - val_MinusLogProbMetric: 27.5129 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 486/1000
2023-10-05 10:51:46.483 
Epoch 486/1000 
	 loss: 27.2860, MinusLogProbMetric: 27.2860, val_loss: 27.5102, val_MinusLogProbMetric: 27.5102

Epoch 486: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2860 - MinusLogProbMetric: 27.2860 - val_loss: 27.5102 - val_MinusLogProbMetric: 27.5102 - lr: 6.2500e-05 - 10s/epoch - 53ms/step
Epoch 487/1000
2023-10-05 10:51:56.854 
Epoch 487/1000 
	 loss: 27.2857, MinusLogProbMetric: 27.2857, val_loss: 27.5106, val_MinusLogProbMetric: 27.5106

Epoch 487: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2857 - MinusLogProbMetric: 27.2857 - val_loss: 27.5106 - val_MinusLogProbMetric: 27.5106 - lr: 6.2500e-05 - 10s/epoch - 53ms/step
Epoch 488/1000
2023-10-05 10:52:07.039 
Epoch 488/1000 
	 loss: 27.2854, MinusLogProbMetric: 27.2854, val_loss: 27.5113, val_MinusLogProbMetric: 27.5113

Epoch 488: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2854 - MinusLogProbMetric: 27.2854 - val_loss: 27.5113 - val_MinusLogProbMetric: 27.5113 - lr: 6.2500e-05 - 10s/epoch - 52ms/step
Epoch 489/1000
2023-10-05 10:52:17.206 
Epoch 489/1000 
	 loss: 27.2859, MinusLogProbMetric: 27.2859, val_loss: 27.5108, val_MinusLogProbMetric: 27.5108

Epoch 489: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2859 - MinusLogProbMetric: 27.2859 - val_loss: 27.5108 - val_MinusLogProbMetric: 27.5108 - lr: 6.2500e-05 - 10s/epoch - 52ms/step
Epoch 490/1000
2023-10-05 10:52:27.438 
Epoch 490/1000 
	 loss: 27.2850, MinusLogProbMetric: 27.2850, val_loss: 27.5113, val_MinusLogProbMetric: 27.5113

Epoch 490: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2850 - MinusLogProbMetric: 27.2850 - val_loss: 27.5113 - val_MinusLogProbMetric: 27.5113 - lr: 6.2500e-05 - 10s/epoch - 52ms/step
Epoch 491/1000
2023-10-05 10:52:37.581 
Epoch 491/1000 
	 loss: 27.2851, MinusLogProbMetric: 27.2851, val_loss: 27.5125, val_MinusLogProbMetric: 27.5125

Epoch 491: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2851 - MinusLogProbMetric: 27.2851 - val_loss: 27.5125 - val_MinusLogProbMetric: 27.5125 - lr: 6.2500e-05 - 10s/epoch - 52ms/step
Epoch 492/1000
2023-10-05 10:52:47.652 
Epoch 492/1000 
	 loss: 27.2848, MinusLogProbMetric: 27.2848, val_loss: 27.5122, val_MinusLogProbMetric: 27.5122

Epoch 492: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2848 - MinusLogProbMetric: 27.2848 - val_loss: 27.5122 - val_MinusLogProbMetric: 27.5122 - lr: 6.2500e-05 - 10s/epoch - 51ms/step
Epoch 493/1000
2023-10-05 10:52:57.802 
Epoch 493/1000 
	 loss: 27.2859, MinusLogProbMetric: 27.2859, val_loss: 27.5108, val_MinusLogProbMetric: 27.5108

Epoch 493: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2859 - MinusLogProbMetric: 27.2859 - val_loss: 27.5108 - val_MinusLogProbMetric: 27.5108 - lr: 6.2500e-05 - 10s/epoch - 52ms/step
Epoch 494/1000
2023-10-05 10:53:07.953 
Epoch 494/1000 
	 loss: 27.2856, MinusLogProbMetric: 27.2856, val_loss: 27.5142, val_MinusLogProbMetric: 27.5142

Epoch 494: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2856 - MinusLogProbMetric: 27.2856 - val_loss: 27.5142 - val_MinusLogProbMetric: 27.5142 - lr: 6.2500e-05 - 10s/epoch - 52ms/step
Epoch 495/1000
2023-10-05 10:53:18.098 
Epoch 495/1000 
	 loss: 27.2858, MinusLogProbMetric: 27.2858, val_loss: 27.5133, val_MinusLogProbMetric: 27.5133

Epoch 495: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2858 - MinusLogProbMetric: 27.2858 - val_loss: 27.5133 - val_MinusLogProbMetric: 27.5133 - lr: 6.2500e-05 - 10s/epoch - 52ms/step
Epoch 496/1000
2023-10-05 10:53:28.279 
Epoch 496/1000 
	 loss: 27.2856, MinusLogProbMetric: 27.2856, val_loss: 27.5119, val_MinusLogProbMetric: 27.5119

Epoch 496: val_loss did not improve from 27.50747
196/196 - 10s - loss: 27.2856 - MinusLogProbMetric: 27.2856 - val_loss: 27.5119 - val_MinusLogProbMetric: 27.5119 - lr: 6.2500e-05 - 10s/epoch - 52ms/step
Epoch 497/1000
2023-10-05 10:53:39.390 
Epoch 497/1000 
	 loss: 27.2854, MinusLogProbMetric: 27.2854, val_loss: 27.5132, val_MinusLogProbMetric: 27.5132

Epoch 497: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2854 - MinusLogProbMetric: 27.2854 - val_loss: 27.5132 - val_MinusLogProbMetric: 27.5132 - lr: 6.2500e-05 - 11s/epoch - 57ms/step
Epoch 498/1000
2023-10-05 10:53:50.828 
Epoch 498/1000 
	 loss: 27.2855, MinusLogProbMetric: 27.2855, val_loss: 27.5111, val_MinusLogProbMetric: 27.5111

Epoch 498: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2855 - MinusLogProbMetric: 27.2855 - val_loss: 27.5111 - val_MinusLogProbMetric: 27.5111 - lr: 6.2500e-05 - 11s/epoch - 58ms/step
Epoch 499/1000
2023-10-05 10:54:02.229 
Epoch 499/1000 
	 loss: 27.2843, MinusLogProbMetric: 27.2843, val_loss: 27.5123, val_MinusLogProbMetric: 27.5123

Epoch 499: val_loss did not improve from 27.50747
196/196 - 11s - loss: 27.2843 - MinusLogProbMetric: 27.2843 - val_loss: 27.5123 - val_MinusLogProbMetric: 27.5123 - lr: 6.2500e-05 - 11s/epoch - 58ms/step
Epoch 500/1000
2023-10-05 10:54:14.807 
Epoch 500/1000 
	 loss: 27.2851, MinusLogProbMetric: 27.2851, val_loss: 27.5140, val_MinusLogProbMetric: 27.5140

Epoch 500: val_loss did not improve from 27.50747
196/196 - 13s - loss: 27.2851 - MinusLogProbMetric: 27.2851 - val_loss: 27.5140 - val_MinusLogProbMetric: 27.5140 - lr: 6.2500e-05 - 13s/epoch - 64ms/step
Epoch 501/1000
2023-10-05 10:54:27.377 
Epoch 501/1000 
	 loss: 27.2850, MinusLogProbMetric: 27.2850, val_loss: 27.5158, val_MinusLogProbMetric: 27.5158

Epoch 501: val_loss did not improve from 27.50747
196/196 - 13s - loss: 27.2850 - MinusLogProbMetric: 27.2850 - val_loss: 27.5158 - val_MinusLogProbMetric: 27.5158 - lr: 6.2500e-05 - 13s/epoch - 64ms/step
Epoch 502/1000
2023-10-05 10:54:39.664 
Epoch 502/1000 
	 loss: 27.2849, MinusLogProbMetric: 27.2849, val_loss: 27.5116, val_MinusLogProbMetric: 27.5116

Epoch 502: val_loss did not improve from 27.50747
196/196 - 12s - loss: 27.2849 - MinusLogProbMetric: 27.2849 - val_loss: 27.5116 - val_MinusLogProbMetric: 27.5116 - lr: 6.2500e-05 - 12s/epoch - 63ms/step
Epoch 503/1000
2023-10-05 10:54:52.054 
Epoch 503/1000 
	 loss: 27.2850, MinusLogProbMetric: 27.2850, val_loss: 27.5100, val_MinusLogProbMetric: 27.5100

Epoch 503: val_loss did not improve from 27.50747
196/196 - 12s - loss: 27.2850 - MinusLogProbMetric: 27.2850 - val_loss: 27.5100 - val_MinusLogProbMetric: 27.5100 - lr: 6.2500e-05 - 12s/epoch - 63ms/step
Epoch 504/1000
2023-10-05 10:55:04.216 
Epoch 504/1000 
	 loss: 27.2800, MinusLogProbMetric: 27.2800, val_loss: 27.5089, val_MinusLogProbMetric: 27.5089

Epoch 504: val_loss did not improve from 27.50747
196/196 - 12s - loss: 27.2800 - MinusLogProbMetric: 27.2800 - val_loss: 27.5089 - val_MinusLogProbMetric: 27.5089 - lr: 3.1250e-05 - 12s/epoch - 62ms/step
Epoch 505/1000
2023-10-05 10:55:16.680 
Epoch 505/1000 
	 loss: 27.2798, MinusLogProbMetric: 27.2798, val_loss: 27.5093, val_MinusLogProbMetric: 27.5093

Epoch 505: val_loss did not improve from 27.50747
196/196 - 12s - loss: 27.2798 - MinusLogProbMetric: 27.2798 - val_loss: 27.5093 - val_MinusLogProbMetric: 27.5093 - lr: 3.1250e-05 - 12s/epoch - 64ms/step
Epoch 506/1000
2023-10-05 10:55:29.277 
Epoch 506/1000 
	 loss: 27.2796, MinusLogProbMetric: 27.2796, val_loss: 27.5070, val_MinusLogProbMetric: 27.5070

Epoch 506: val_loss improved from 27.50747 to 27.50705, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 13s - loss: 27.2796 - MinusLogProbMetric: 27.2796 - val_loss: 27.5070 - val_MinusLogProbMetric: 27.5070 - lr: 3.1250e-05 - 13s/epoch - 65ms/step
Epoch 507/1000
2023-10-05 10:55:41.626 
Epoch 507/1000 
	 loss: 27.2801, MinusLogProbMetric: 27.2801, val_loss: 27.5096, val_MinusLogProbMetric: 27.5096

Epoch 507: val_loss did not improve from 27.50705
196/196 - 12s - loss: 27.2801 - MinusLogProbMetric: 27.2801 - val_loss: 27.5096 - val_MinusLogProbMetric: 27.5096 - lr: 3.1250e-05 - 12s/epoch - 62ms/step
Epoch 508/1000
2023-10-05 10:55:53.780 
Epoch 508/1000 
	 loss: 27.2798, MinusLogProbMetric: 27.2798, val_loss: 27.5087, val_MinusLogProbMetric: 27.5087

Epoch 508: val_loss did not improve from 27.50705
196/196 - 12s - loss: 27.2798 - MinusLogProbMetric: 27.2798 - val_loss: 27.5087 - val_MinusLogProbMetric: 27.5087 - lr: 3.1250e-05 - 12s/epoch - 62ms/step
Epoch 509/1000
2023-10-05 10:56:05.697 
Epoch 509/1000 
	 loss: 27.2797, MinusLogProbMetric: 27.2797, val_loss: 27.5088, val_MinusLogProbMetric: 27.5088

Epoch 509: val_loss did not improve from 27.50705
196/196 - 12s - loss: 27.2797 - MinusLogProbMetric: 27.2797 - val_loss: 27.5088 - val_MinusLogProbMetric: 27.5088 - lr: 3.1250e-05 - 12s/epoch - 61ms/step
Epoch 510/1000
2023-10-05 10:56:16.824 
Epoch 510/1000 
	 loss: 27.2800, MinusLogProbMetric: 27.2800, val_loss: 27.5087, val_MinusLogProbMetric: 27.5087

Epoch 510: val_loss did not improve from 27.50705
196/196 - 11s - loss: 27.2800 - MinusLogProbMetric: 27.2800 - val_loss: 27.5087 - val_MinusLogProbMetric: 27.5087 - lr: 3.1250e-05 - 11s/epoch - 57ms/step
Epoch 511/1000
2023-10-05 10:56:30.153 
Epoch 511/1000 
	 loss: 27.2799, MinusLogProbMetric: 27.2799, val_loss: 27.5066, val_MinusLogProbMetric: 27.5066

Epoch 511: val_loss improved from 27.50705 to 27.50662, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_167/weights/best_weights.h5
196/196 - 14s - loss: 27.2799 - MinusLogProbMetric: 27.2799 - val_loss: 27.5066 - val_MinusLogProbMetric: 27.5066 - lr: 3.1250e-05 - 14s/epoch - 69ms/step
Epoch 512/1000
2023-10-05 10:56:43.801 
Epoch 512/1000 
	 loss: 27.2797, MinusLogProbMetric: 27.2797, val_loss: 27.5096, val_MinusLogProbMetric: 27.5096

Epoch 512: val_loss did not improve from 27.50662
196/196 - 13s - loss: 27.2797 - MinusLogProbMetric: 27.2797 - val_loss: 27.5096 - val_MinusLogProbMetric: 27.5096 - lr: 3.1250e-05 - 13s/epoch - 69ms/step
Epoch 513/1000
2023-10-05 10:56:55.177 
Epoch 513/1000 
	 loss: 27.2797, MinusLogProbMetric: 27.2797, val_loss: 27.5084, val_MinusLogProbMetric: 27.5084

Epoch 513: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2797 - MinusLogProbMetric: 27.2797 - val_loss: 27.5084 - val_MinusLogProbMetric: 27.5084 - lr: 3.1250e-05 - 11s/epoch - 58ms/step
Epoch 514/1000
2023-10-05 10:57:05.990 
Epoch 514/1000 
	 loss: 27.2798, MinusLogProbMetric: 27.2798, val_loss: 27.5081, val_MinusLogProbMetric: 27.5081

Epoch 514: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2798 - MinusLogProbMetric: 27.2798 - val_loss: 27.5081 - val_MinusLogProbMetric: 27.5081 - lr: 3.1250e-05 - 11s/epoch - 55ms/step
Epoch 515/1000
2023-10-05 10:57:16.879 
Epoch 515/1000 
	 loss: 27.2797, MinusLogProbMetric: 27.2797, val_loss: 27.5107, val_MinusLogProbMetric: 27.5107

Epoch 515: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2797 - MinusLogProbMetric: 27.2797 - val_loss: 27.5107 - val_MinusLogProbMetric: 27.5107 - lr: 3.1250e-05 - 11s/epoch - 56ms/step
Epoch 516/1000
2023-10-05 10:57:26.792 
Epoch 516/1000 
	 loss: 27.2797, MinusLogProbMetric: 27.2797, val_loss: 27.5082, val_MinusLogProbMetric: 27.5082

Epoch 516: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2797 - MinusLogProbMetric: 27.2797 - val_loss: 27.5082 - val_MinusLogProbMetric: 27.5082 - lr: 3.1250e-05 - 10s/epoch - 51ms/step
Epoch 517/1000
2023-10-05 10:57:37.371 
Epoch 517/1000 
	 loss: 27.2798, MinusLogProbMetric: 27.2798, val_loss: 27.5106, val_MinusLogProbMetric: 27.5106

Epoch 517: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2798 - MinusLogProbMetric: 27.2798 - val_loss: 27.5106 - val_MinusLogProbMetric: 27.5106 - lr: 3.1250e-05 - 11s/epoch - 54ms/step
Epoch 518/1000
2023-10-05 10:57:48.044 
Epoch 518/1000 
	 loss: 27.2796, MinusLogProbMetric: 27.2796, val_loss: 27.5100, val_MinusLogProbMetric: 27.5100

Epoch 518: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2796 - MinusLogProbMetric: 27.2796 - val_loss: 27.5100 - val_MinusLogProbMetric: 27.5100 - lr: 3.1250e-05 - 11s/epoch - 54ms/step
Epoch 519/1000
2023-10-05 10:57:58.452 
Epoch 519/1000 
	 loss: 27.2795, MinusLogProbMetric: 27.2795, val_loss: 27.5087, val_MinusLogProbMetric: 27.5087

Epoch 519: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2795 - MinusLogProbMetric: 27.2795 - val_loss: 27.5087 - val_MinusLogProbMetric: 27.5087 - lr: 3.1250e-05 - 10s/epoch - 53ms/step
Epoch 520/1000
2023-10-05 10:58:09.069 
Epoch 520/1000 
	 loss: 27.2791, MinusLogProbMetric: 27.2791, val_loss: 27.5092, val_MinusLogProbMetric: 27.5092

Epoch 520: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2791 - MinusLogProbMetric: 27.2791 - val_loss: 27.5092 - val_MinusLogProbMetric: 27.5092 - lr: 3.1250e-05 - 11s/epoch - 54ms/step
Epoch 521/1000
2023-10-05 10:58:19.940 
Epoch 521/1000 
	 loss: 27.2796, MinusLogProbMetric: 27.2796, val_loss: 27.5087, val_MinusLogProbMetric: 27.5087

Epoch 521: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2796 - MinusLogProbMetric: 27.2796 - val_loss: 27.5087 - val_MinusLogProbMetric: 27.5087 - lr: 3.1250e-05 - 11s/epoch - 55ms/step
Epoch 522/1000
2023-10-05 10:58:30.779 
Epoch 522/1000 
	 loss: 27.2797, MinusLogProbMetric: 27.2797, val_loss: 27.5096, val_MinusLogProbMetric: 27.5096

Epoch 522: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2797 - MinusLogProbMetric: 27.2797 - val_loss: 27.5096 - val_MinusLogProbMetric: 27.5096 - lr: 3.1250e-05 - 11s/epoch - 55ms/step
Epoch 523/1000
2023-10-05 10:58:41.696 
Epoch 523/1000 
	 loss: 27.2795, MinusLogProbMetric: 27.2795, val_loss: 27.5096, val_MinusLogProbMetric: 27.5096

Epoch 523: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2795 - MinusLogProbMetric: 27.2795 - val_loss: 27.5096 - val_MinusLogProbMetric: 27.5096 - lr: 3.1250e-05 - 11s/epoch - 56ms/step
Epoch 524/1000
2023-10-05 10:58:52.667 
Epoch 524/1000 
	 loss: 27.2792, MinusLogProbMetric: 27.2792, val_loss: 27.5086, val_MinusLogProbMetric: 27.5086

Epoch 524: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2792 - MinusLogProbMetric: 27.2792 - val_loss: 27.5086 - val_MinusLogProbMetric: 27.5086 - lr: 3.1250e-05 - 11s/epoch - 56ms/step
Epoch 525/1000
2023-10-05 10:59:03.635 
Epoch 525/1000 
	 loss: 27.2794, MinusLogProbMetric: 27.2794, val_loss: 27.5105, val_MinusLogProbMetric: 27.5105

Epoch 525: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2794 - MinusLogProbMetric: 27.2794 - val_loss: 27.5105 - val_MinusLogProbMetric: 27.5105 - lr: 3.1250e-05 - 11s/epoch - 57ms/step
Epoch 526/1000
2023-10-05 10:59:14.846 
Epoch 526/1000 
	 loss: 27.2794, MinusLogProbMetric: 27.2794, val_loss: 27.5089, val_MinusLogProbMetric: 27.5089

Epoch 526: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2794 - MinusLogProbMetric: 27.2794 - val_loss: 27.5089 - val_MinusLogProbMetric: 27.5089 - lr: 3.1250e-05 - 11s/epoch - 56ms/step
Epoch 527/1000
2023-10-05 10:59:25.621 
Epoch 527/1000 
	 loss: 27.2796, MinusLogProbMetric: 27.2796, val_loss: 27.5086, val_MinusLogProbMetric: 27.5086

Epoch 527: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2796 - MinusLogProbMetric: 27.2796 - val_loss: 27.5086 - val_MinusLogProbMetric: 27.5086 - lr: 3.1250e-05 - 11s/epoch - 55ms/step
Epoch 528/1000
2023-10-05 10:59:36.156 
Epoch 528/1000 
	 loss: 27.2796, MinusLogProbMetric: 27.2796, val_loss: 27.5080, val_MinusLogProbMetric: 27.5080

Epoch 528: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2796 - MinusLogProbMetric: 27.2796 - val_loss: 27.5080 - val_MinusLogProbMetric: 27.5080 - lr: 3.1250e-05 - 11s/epoch - 54ms/step
Epoch 529/1000
2023-10-05 10:59:46.515 
Epoch 529/1000 
	 loss: 27.2795, MinusLogProbMetric: 27.2795, val_loss: 27.5075, val_MinusLogProbMetric: 27.5075

Epoch 529: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2795 - MinusLogProbMetric: 27.2795 - val_loss: 27.5075 - val_MinusLogProbMetric: 27.5075 - lr: 3.1250e-05 - 10s/epoch - 53ms/step
Epoch 530/1000
2023-10-05 10:59:56.810 
Epoch 530/1000 
	 loss: 27.2796, MinusLogProbMetric: 27.2796, val_loss: 27.5080, val_MinusLogProbMetric: 27.5080

Epoch 530: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2796 - MinusLogProbMetric: 27.2796 - val_loss: 27.5080 - val_MinusLogProbMetric: 27.5080 - lr: 3.1250e-05 - 10s/epoch - 53ms/step
Epoch 531/1000
2023-10-05 11:00:07.133 
Epoch 531/1000 
	 loss: 27.2793, MinusLogProbMetric: 27.2793, val_loss: 27.5094, val_MinusLogProbMetric: 27.5094

Epoch 531: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2793 - MinusLogProbMetric: 27.2793 - val_loss: 27.5094 - val_MinusLogProbMetric: 27.5094 - lr: 3.1250e-05 - 10s/epoch - 53ms/step
Epoch 532/1000
2023-10-05 11:00:17.333 
Epoch 532/1000 
	 loss: 27.2796, MinusLogProbMetric: 27.2796, val_loss: 27.5097, val_MinusLogProbMetric: 27.5097

Epoch 532: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2796 - MinusLogProbMetric: 27.2796 - val_loss: 27.5097 - val_MinusLogProbMetric: 27.5097 - lr: 3.1250e-05 - 10s/epoch - 52ms/step
Epoch 533/1000
2023-10-05 11:00:27.613 
Epoch 533/1000 
	 loss: 27.2795, MinusLogProbMetric: 27.2795, val_loss: 27.5084, val_MinusLogProbMetric: 27.5084

Epoch 533: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2795 - MinusLogProbMetric: 27.2795 - val_loss: 27.5084 - val_MinusLogProbMetric: 27.5084 - lr: 3.1250e-05 - 10s/epoch - 52ms/step
Epoch 534/1000
2023-10-05 11:00:37.972 
Epoch 534/1000 
	 loss: 27.2795, MinusLogProbMetric: 27.2795, val_loss: 27.5073, val_MinusLogProbMetric: 27.5073

Epoch 534: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2795 - MinusLogProbMetric: 27.2795 - val_loss: 27.5073 - val_MinusLogProbMetric: 27.5073 - lr: 3.1250e-05 - 10s/epoch - 53ms/step
Epoch 535/1000
2023-10-05 11:00:48.282 
Epoch 535/1000 
	 loss: 27.2794, MinusLogProbMetric: 27.2794, val_loss: 27.5077, val_MinusLogProbMetric: 27.5077

Epoch 535: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2794 - MinusLogProbMetric: 27.2794 - val_loss: 27.5077 - val_MinusLogProbMetric: 27.5077 - lr: 3.1250e-05 - 10s/epoch - 53ms/step
Epoch 536/1000
2023-10-05 11:00:58.725 
Epoch 536/1000 
	 loss: 27.2794, MinusLogProbMetric: 27.2794, val_loss: 27.5094, val_MinusLogProbMetric: 27.5094

Epoch 536: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2794 - MinusLogProbMetric: 27.2794 - val_loss: 27.5094 - val_MinusLogProbMetric: 27.5094 - lr: 3.1250e-05 - 10s/epoch - 53ms/step
Epoch 537/1000
2023-10-05 11:01:09.141 
Epoch 537/1000 
	 loss: 27.2790, MinusLogProbMetric: 27.2790, val_loss: 27.5108, val_MinusLogProbMetric: 27.5108

Epoch 537: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2790 - MinusLogProbMetric: 27.2790 - val_loss: 27.5108 - val_MinusLogProbMetric: 27.5108 - lr: 3.1250e-05 - 10s/epoch - 53ms/step
Epoch 538/1000
2023-10-05 11:01:19.707 
Epoch 538/1000 
	 loss: 27.2789, MinusLogProbMetric: 27.2789, val_loss: 27.5092, val_MinusLogProbMetric: 27.5092

Epoch 538: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2789 - MinusLogProbMetric: 27.2789 - val_loss: 27.5092 - val_MinusLogProbMetric: 27.5092 - lr: 3.1250e-05 - 11s/epoch - 54ms/step
Epoch 539/1000
2023-10-05 11:01:30.502 
Epoch 539/1000 
	 loss: 27.2793, MinusLogProbMetric: 27.2793, val_loss: 27.5093, val_MinusLogProbMetric: 27.5093

Epoch 539: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2793 - MinusLogProbMetric: 27.2793 - val_loss: 27.5093 - val_MinusLogProbMetric: 27.5093 - lr: 3.1250e-05 - 11s/epoch - 55ms/step
Epoch 540/1000
2023-10-05 11:01:41.386 
Epoch 540/1000 
	 loss: 27.2795, MinusLogProbMetric: 27.2795, val_loss: 27.5095, val_MinusLogProbMetric: 27.5095

Epoch 540: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2795 - MinusLogProbMetric: 27.2795 - val_loss: 27.5095 - val_MinusLogProbMetric: 27.5095 - lr: 3.1250e-05 - 11s/epoch - 55ms/step
Epoch 541/1000
2023-10-05 11:01:52.444 
Epoch 541/1000 
	 loss: 27.2792, MinusLogProbMetric: 27.2792, val_loss: 27.5097, val_MinusLogProbMetric: 27.5097

Epoch 541: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2792 - MinusLogProbMetric: 27.2792 - val_loss: 27.5097 - val_MinusLogProbMetric: 27.5097 - lr: 3.1250e-05 - 11s/epoch - 56ms/step
Epoch 542/1000
2023-10-05 11:02:02.996 
Epoch 542/1000 
	 loss: 27.2793, MinusLogProbMetric: 27.2793, val_loss: 27.5074, val_MinusLogProbMetric: 27.5074

Epoch 542: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2793 - MinusLogProbMetric: 27.2793 - val_loss: 27.5074 - val_MinusLogProbMetric: 27.5074 - lr: 3.1250e-05 - 11s/epoch - 54ms/step
Epoch 543/1000
2023-10-05 11:02:13.580 
Epoch 543/1000 
	 loss: 27.2790, MinusLogProbMetric: 27.2790, val_loss: 27.5084, val_MinusLogProbMetric: 27.5084

Epoch 543: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2790 - MinusLogProbMetric: 27.2790 - val_loss: 27.5084 - val_MinusLogProbMetric: 27.5084 - lr: 3.1250e-05 - 11s/epoch - 54ms/step
Epoch 544/1000
2023-10-05 11:02:24.152 
Epoch 544/1000 
	 loss: 27.2796, MinusLogProbMetric: 27.2796, val_loss: 27.5105, val_MinusLogProbMetric: 27.5105

Epoch 544: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2796 - MinusLogProbMetric: 27.2796 - val_loss: 27.5105 - val_MinusLogProbMetric: 27.5105 - lr: 3.1250e-05 - 11s/epoch - 54ms/step
Epoch 545/1000
2023-10-05 11:02:34.583 
Epoch 545/1000 
	 loss: 27.2790, MinusLogProbMetric: 27.2790, val_loss: 27.5086, val_MinusLogProbMetric: 27.5086

Epoch 545: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2790 - MinusLogProbMetric: 27.2790 - val_loss: 27.5086 - val_MinusLogProbMetric: 27.5086 - lr: 3.1250e-05 - 11s/epoch - 54ms/step
Epoch 546/1000
2023-10-05 11:02:45.381 
Epoch 546/1000 
	 loss: 27.2792, MinusLogProbMetric: 27.2792, val_loss: 27.5106, val_MinusLogProbMetric: 27.5106

Epoch 546: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2792 - MinusLogProbMetric: 27.2792 - val_loss: 27.5106 - val_MinusLogProbMetric: 27.5106 - lr: 3.1250e-05 - 11s/epoch - 54ms/step
Epoch 547/1000
2023-10-05 11:02:55.749 
Epoch 547/1000 
	 loss: 27.2796, MinusLogProbMetric: 27.2796, val_loss: 27.5095, val_MinusLogProbMetric: 27.5095

Epoch 547: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2796 - MinusLogProbMetric: 27.2796 - val_loss: 27.5095 - val_MinusLogProbMetric: 27.5095 - lr: 3.1250e-05 - 10s/epoch - 53ms/step
Epoch 548/1000
2023-10-05 11:03:06.404 
Epoch 548/1000 
	 loss: 27.2789, MinusLogProbMetric: 27.2789, val_loss: 27.5101, val_MinusLogProbMetric: 27.5101

Epoch 548: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2789 - MinusLogProbMetric: 27.2789 - val_loss: 27.5101 - val_MinusLogProbMetric: 27.5101 - lr: 3.1250e-05 - 11s/epoch - 55ms/step
Epoch 549/1000
2023-10-05 11:03:17.052 
Epoch 549/1000 
	 loss: 27.2791, MinusLogProbMetric: 27.2791, val_loss: 27.5095, val_MinusLogProbMetric: 27.5095

Epoch 549: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2791 - MinusLogProbMetric: 27.2791 - val_loss: 27.5095 - val_MinusLogProbMetric: 27.5095 - lr: 3.1250e-05 - 10s/epoch - 54ms/step
Epoch 550/1000
2023-10-05 11:03:27.446 
Epoch 550/1000 
	 loss: 27.2792, MinusLogProbMetric: 27.2792, val_loss: 27.5084, val_MinusLogProbMetric: 27.5084

Epoch 550: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2792 - MinusLogProbMetric: 27.2792 - val_loss: 27.5084 - val_MinusLogProbMetric: 27.5084 - lr: 3.1250e-05 - 10s/epoch - 53ms/step
Epoch 551/1000
2023-10-05 11:03:37.908 
Epoch 551/1000 
	 loss: 27.2789, MinusLogProbMetric: 27.2789, val_loss: 27.5098, val_MinusLogProbMetric: 27.5098

Epoch 551: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2789 - MinusLogProbMetric: 27.2789 - val_loss: 27.5098 - val_MinusLogProbMetric: 27.5098 - lr: 3.1250e-05 - 10s/epoch - 53ms/step
Epoch 552/1000
2023-10-05 11:03:48.241 
Epoch 552/1000 
	 loss: 27.2793, MinusLogProbMetric: 27.2793, val_loss: 27.5090, val_MinusLogProbMetric: 27.5090

Epoch 552: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2793 - MinusLogProbMetric: 27.2793 - val_loss: 27.5090 - val_MinusLogProbMetric: 27.5090 - lr: 3.1250e-05 - 10s/epoch - 53ms/step
Epoch 553/1000
2023-10-05 11:03:58.614 
Epoch 553/1000 
	 loss: 27.2788, MinusLogProbMetric: 27.2788, val_loss: 27.5097, val_MinusLogProbMetric: 27.5097

Epoch 553: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2788 - MinusLogProbMetric: 27.2788 - val_loss: 27.5097 - val_MinusLogProbMetric: 27.5097 - lr: 3.1250e-05 - 10s/epoch - 53ms/step
Epoch 554/1000
2023-10-05 11:04:08.962 
Epoch 554/1000 
	 loss: 27.2790, MinusLogProbMetric: 27.2790, val_loss: 27.5090, val_MinusLogProbMetric: 27.5090

Epoch 554: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2790 - MinusLogProbMetric: 27.2790 - val_loss: 27.5090 - val_MinusLogProbMetric: 27.5090 - lr: 3.1250e-05 - 10s/epoch - 53ms/step
Epoch 555/1000
2023-10-05 11:04:19.083 
Epoch 555/1000 
	 loss: 27.2788, MinusLogProbMetric: 27.2788, val_loss: 27.5084, val_MinusLogProbMetric: 27.5084

Epoch 555: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2788 - MinusLogProbMetric: 27.2788 - val_loss: 27.5084 - val_MinusLogProbMetric: 27.5084 - lr: 3.1250e-05 - 10s/epoch - 52ms/step
Epoch 556/1000
2023-10-05 11:04:29.257 
Epoch 556/1000 
	 loss: 27.2789, MinusLogProbMetric: 27.2789, val_loss: 27.5103, val_MinusLogProbMetric: 27.5103

Epoch 556: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2789 - MinusLogProbMetric: 27.2789 - val_loss: 27.5103 - val_MinusLogProbMetric: 27.5103 - lr: 3.1250e-05 - 10s/epoch - 52ms/step
Epoch 557/1000
2023-10-05 11:04:39.636 
Epoch 557/1000 
	 loss: 27.2789, MinusLogProbMetric: 27.2789, val_loss: 27.5123, val_MinusLogProbMetric: 27.5123

Epoch 557: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2789 - MinusLogProbMetric: 27.2789 - val_loss: 27.5123 - val_MinusLogProbMetric: 27.5123 - lr: 3.1250e-05 - 10s/epoch - 53ms/step
Epoch 558/1000
2023-10-05 11:04:50.239 
Epoch 558/1000 
	 loss: 27.2791, MinusLogProbMetric: 27.2791, val_loss: 27.5118, val_MinusLogProbMetric: 27.5118

Epoch 558: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2791 - MinusLogProbMetric: 27.2791 - val_loss: 27.5118 - val_MinusLogProbMetric: 27.5118 - lr: 3.1250e-05 - 11s/epoch - 55ms/step
Epoch 559/1000
2023-10-05 11:05:00.954 
Epoch 559/1000 
	 loss: 27.2790, MinusLogProbMetric: 27.2790, val_loss: 27.5086, val_MinusLogProbMetric: 27.5086

Epoch 559: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2790 - MinusLogProbMetric: 27.2790 - val_loss: 27.5086 - val_MinusLogProbMetric: 27.5086 - lr: 3.1250e-05 - 11s/epoch - 54ms/step
Epoch 560/1000
2023-10-05 11:05:11.387 
Epoch 560/1000 
	 loss: 27.2790, MinusLogProbMetric: 27.2790, val_loss: 27.5103, val_MinusLogProbMetric: 27.5103

Epoch 560: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2790 - MinusLogProbMetric: 27.2790 - val_loss: 27.5103 - val_MinusLogProbMetric: 27.5103 - lr: 3.1250e-05 - 10s/epoch - 53ms/step
Epoch 561/1000
2023-10-05 11:05:21.839 
Epoch 561/1000 
	 loss: 27.2789, MinusLogProbMetric: 27.2789, val_loss: 27.5106, val_MinusLogProbMetric: 27.5106

Epoch 561: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2789 - MinusLogProbMetric: 27.2789 - val_loss: 27.5106 - val_MinusLogProbMetric: 27.5106 - lr: 3.1250e-05 - 10s/epoch - 53ms/step
Epoch 562/1000
2023-10-05 11:05:32.180 
Epoch 562/1000 
	 loss: 27.2766, MinusLogProbMetric: 27.2766, val_loss: 27.5095, val_MinusLogProbMetric: 27.5095

Epoch 562: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2766 - MinusLogProbMetric: 27.2766 - val_loss: 27.5095 - val_MinusLogProbMetric: 27.5095 - lr: 1.5625e-05 - 10s/epoch - 53ms/step
Epoch 563/1000
2023-10-05 11:05:42.586 
Epoch 563/1000 
	 loss: 27.2762, MinusLogProbMetric: 27.2762, val_loss: 27.5083, val_MinusLogProbMetric: 27.5083

Epoch 563: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2762 - MinusLogProbMetric: 27.2762 - val_loss: 27.5083 - val_MinusLogProbMetric: 27.5083 - lr: 1.5625e-05 - 11s/epoch - 54ms/step
Epoch 564/1000
2023-10-05 11:05:53.363 
Epoch 564/1000 
	 loss: 27.2761, MinusLogProbMetric: 27.2761, val_loss: 27.5087, val_MinusLogProbMetric: 27.5087

Epoch 564: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2761 - MinusLogProbMetric: 27.2761 - val_loss: 27.5087 - val_MinusLogProbMetric: 27.5087 - lr: 1.5625e-05 - 11s/epoch - 55ms/step
Epoch 565/1000
2023-10-05 11:06:03.824 
Epoch 565/1000 
	 loss: 27.2761, MinusLogProbMetric: 27.2761, val_loss: 27.5088, val_MinusLogProbMetric: 27.5088

Epoch 565: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2761 - MinusLogProbMetric: 27.2761 - val_loss: 27.5088 - val_MinusLogProbMetric: 27.5088 - lr: 1.5625e-05 - 10s/epoch - 53ms/step
Epoch 566/1000
2023-10-05 11:06:14.364 
Epoch 566/1000 
	 loss: 27.2761, MinusLogProbMetric: 27.2761, val_loss: 27.5083, val_MinusLogProbMetric: 27.5083

Epoch 566: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2761 - MinusLogProbMetric: 27.2761 - val_loss: 27.5083 - val_MinusLogProbMetric: 27.5083 - lr: 1.5625e-05 - 11s/epoch - 54ms/step
Epoch 567/1000
2023-10-05 11:06:24.855 
Epoch 567/1000 
	 loss: 27.2760, MinusLogProbMetric: 27.2760, val_loss: 27.5086, val_MinusLogProbMetric: 27.5086

Epoch 567: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2760 - MinusLogProbMetric: 27.2760 - val_loss: 27.5086 - val_MinusLogProbMetric: 27.5086 - lr: 1.5625e-05 - 10s/epoch - 53ms/step
Epoch 568/1000
2023-10-05 11:06:35.171 
Epoch 568/1000 
	 loss: 27.2763, MinusLogProbMetric: 27.2763, val_loss: 27.5088, val_MinusLogProbMetric: 27.5088

Epoch 568: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2763 - MinusLogProbMetric: 27.2763 - val_loss: 27.5088 - val_MinusLogProbMetric: 27.5088 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 569/1000
2023-10-05 11:06:45.551 
Epoch 569/1000 
	 loss: 27.2760, MinusLogProbMetric: 27.2760, val_loss: 27.5094, val_MinusLogProbMetric: 27.5094

Epoch 569: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2760 - MinusLogProbMetric: 27.2760 - val_loss: 27.5094 - val_MinusLogProbMetric: 27.5094 - lr: 1.5625e-05 - 10s/epoch - 53ms/step
Epoch 570/1000
2023-10-05 11:06:55.948 
Epoch 570/1000 
	 loss: 27.2760, MinusLogProbMetric: 27.2760, val_loss: 27.5088, val_MinusLogProbMetric: 27.5088

Epoch 570: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2760 - MinusLogProbMetric: 27.2760 - val_loss: 27.5088 - val_MinusLogProbMetric: 27.5088 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 571/1000
2023-10-05 11:07:06.243 
Epoch 571/1000 
	 loss: 27.2761, MinusLogProbMetric: 27.2761, val_loss: 27.5087, val_MinusLogProbMetric: 27.5087

Epoch 571: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2761 - MinusLogProbMetric: 27.2761 - val_loss: 27.5087 - val_MinusLogProbMetric: 27.5087 - lr: 1.5625e-05 - 10s/epoch - 53ms/step
Epoch 572/1000
2023-10-05 11:07:16.516 
Epoch 572/1000 
	 loss: 27.2760, MinusLogProbMetric: 27.2760, val_loss: 27.5085, val_MinusLogProbMetric: 27.5085

Epoch 572: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2760 - MinusLogProbMetric: 27.2760 - val_loss: 27.5085 - val_MinusLogProbMetric: 27.5085 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 573/1000
2023-10-05 11:07:26.784 
Epoch 573/1000 
	 loss: 27.2761, MinusLogProbMetric: 27.2761, val_loss: 27.5086, val_MinusLogProbMetric: 27.5086

Epoch 573: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2761 - MinusLogProbMetric: 27.2761 - val_loss: 27.5086 - val_MinusLogProbMetric: 27.5086 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 574/1000
2023-10-05 11:07:37.060 
Epoch 574/1000 
	 loss: 27.2761, MinusLogProbMetric: 27.2761, val_loss: 27.5087, val_MinusLogProbMetric: 27.5087

Epoch 574: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2761 - MinusLogProbMetric: 27.2761 - val_loss: 27.5087 - val_MinusLogProbMetric: 27.5087 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 575/1000
2023-10-05 11:07:47.195 
Epoch 575/1000 
	 loss: 27.2760, MinusLogProbMetric: 27.2760, val_loss: 27.5084, val_MinusLogProbMetric: 27.5084

Epoch 575: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2760 - MinusLogProbMetric: 27.2760 - val_loss: 27.5084 - val_MinusLogProbMetric: 27.5084 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 576/1000
2023-10-05 11:07:57.395 
Epoch 576/1000 
	 loss: 27.2760, MinusLogProbMetric: 27.2760, val_loss: 27.5093, val_MinusLogProbMetric: 27.5093

Epoch 576: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2760 - MinusLogProbMetric: 27.2760 - val_loss: 27.5093 - val_MinusLogProbMetric: 27.5093 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 577/1000
2023-10-05 11:08:07.551 
Epoch 577/1000 
	 loss: 27.2761, MinusLogProbMetric: 27.2761, val_loss: 27.5092, val_MinusLogProbMetric: 27.5092

Epoch 577: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2761 - MinusLogProbMetric: 27.2761 - val_loss: 27.5092 - val_MinusLogProbMetric: 27.5092 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 578/1000
2023-10-05 11:08:17.917 
Epoch 578/1000 
	 loss: 27.2759, MinusLogProbMetric: 27.2759, val_loss: 27.5082, val_MinusLogProbMetric: 27.5082

Epoch 578: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2759 - MinusLogProbMetric: 27.2759 - val_loss: 27.5082 - val_MinusLogProbMetric: 27.5082 - lr: 1.5625e-05 - 10s/epoch - 53ms/step
Epoch 579/1000
2023-10-05 11:08:28.182 
Epoch 579/1000 
	 loss: 27.2761, MinusLogProbMetric: 27.2761, val_loss: 27.5091, val_MinusLogProbMetric: 27.5091

Epoch 579: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2761 - MinusLogProbMetric: 27.2761 - val_loss: 27.5091 - val_MinusLogProbMetric: 27.5091 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 580/1000
2023-10-05 11:08:38.464 
Epoch 580/1000 
	 loss: 27.2759, MinusLogProbMetric: 27.2759, val_loss: 27.5083, val_MinusLogProbMetric: 27.5083

Epoch 580: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2759 - MinusLogProbMetric: 27.2759 - val_loss: 27.5083 - val_MinusLogProbMetric: 27.5083 - lr: 1.5625e-05 - 10s/epoch - 53ms/step
Epoch 581/1000
2023-10-05 11:08:48.961 
Epoch 581/1000 
	 loss: 27.2759, MinusLogProbMetric: 27.2759, val_loss: 27.5089, val_MinusLogProbMetric: 27.5089

Epoch 581: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2759 - MinusLogProbMetric: 27.2759 - val_loss: 27.5089 - val_MinusLogProbMetric: 27.5089 - lr: 1.5625e-05 - 10s/epoch - 54ms/step
Epoch 582/1000
2023-10-05 11:08:59.215 
Epoch 582/1000 
	 loss: 27.2760, MinusLogProbMetric: 27.2760, val_loss: 27.5089, val_MinusLogProbMetric: 27.5089

Epoch 582: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2760 - MinusLogProbMetric: 27.2760 - val_loss: 27.5089 - val_MinusLogProbMetric: 27.5089 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 583/1000
2023-10-05 11:09:09.414 
Epoch 583/1000 
	 loss: 27.2762, MinusLogProbMetric: 27.2762, val_loss: 27.5085, val_MinusLogProbMetric: 27.5085

Epoch 583: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2762 - MinusLogProbMetric: 27.2762 - val_loss: 27.5085 - val_MinusLogProbMetric: 27.5085 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 584/1000
2023-10-05 11:09:19.567 
Epoch 584/1000 
	 loss: 27.2759, MinusLogProbMetric: 27.2759, val_loss: 27.5094, val_MinusLogProbMetric: 27.5094

Epoch 584: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2759 - MinusLogProbMetric: 27.2759 - val_loss: 27.5094 - val_MinusLogProbMetric: 27.5094 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 585/1000
2023-10-05 11:09:29.759 
Epoch 585/1000 
	 loss: 27.2759, MinusLogProbMetric: 27.2759, val_loss: 27.5098, val_MinusLogProbMetric: 27.5098

Epoch 585: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2759 - MinusLogProbMetric: 27.2759 - val_loss: 27.5098 - val_MinusLogProbMetric: 27.5098 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 586/1000
2023-10-05 11:09:40.474 
Epoch 586/1000 
	 loss: 27.2761, MinusLogProbMetric: 27.2761, val_loss: 27.5087, val_MinusLogProbMetric: 27.5087

Epoch 586: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2761 - MinusLogProbMetric: 27.2761 - val_loss: 27.5087 - val_MinusLogProbMetric: 27.5087 - lr: 1.5625e-05 - 11s/epoch - 54ms/step
Epoch 587/1000
2023-10-05 11:09:50.813 
Epoch 587/1000 
	 loss: 27.2761, MinusLogProbMetric: 27.2761, val_loss: 27.5087, val_MinusLogProbMetric: 27.5087

Epoch 587: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2761 - MinusLogProbMetric: 27.2761 - val_loss: 27.5087 - val_MinusLogProbMetric: 27.5087 - lr: 1.5625e-05 - 10s/epoch - 53ms/step
Epoch 588/1000
2023-10-05 11:10:01.109 
Epoch 588/1000 
	 loss: 27.2758, MinusLogProbMetric: 27.2758, val_loss: 27.5096, val_MinusLogProbMetric: 27.5096

Epoch 588: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2758 - MinusLogProbMetric: 27.2758 - val_loss: 27.5096 - val_MinusLogProbMetric: 27.5096 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 589/1000
2023-10-05 11:10:11.409 
Epoch 589/1000 
	 loss: 27.2761, MinusLogProbMetric: 27.2761, val_loss: 27.5093, val_MinusLogProbMetric: 27.5093

Epoch 589: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2761 - MinusLogProbMetric: 27.2761 - val_loss: 27.5093 - val_MinusLogProbMetric: 27.5093 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 590/1000
2023-10-05 11:10:21.571 
Epoch 590/1000 
	 loss: 27.2760, MinusLogProbMetric: 27.2760, val_loss: 27.5085, val_MinusLogProbMetric: 27.5085

Epoch 590: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2760 - MinusLogProbMetric: 27.2760 - val_loss: 27.5085 - val_MinusLogProbMetric: 27.5085 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 591/1000
2023-10-05 11:10:31.750 
Epoch 591/1000 
	 loss: 27.2759, MinusLogProbMetric: 27.2759, val_loss: 27.5086, val_MinusLogProbMetric: 27.5086

Epoch 591: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2759 - MinusLogProbMetric: 27.2759 - val_loss: 27.5086 - val_MinusLogProbMetric: 27.5086 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 592/1000
2023-10-05 11:10:41.955 
Epoch 592/1000 
	 loss: 27.2760, MinusLogProbMetric: 27.2760, val_loss: 27.5085, val_MinusLogProbMetric: 27.5085

Epoch 592: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2760 - MinusLogProbMetric: 27.2760 - val_loss: 27.5085 - val_MinusLogProbMetric: 27.5085 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 593/1000
2023-10-05 11:10:52.221 
Epoch 593/1000 
	 loss: 27.2757, MinusLogProbMetric: 27.2757, val_loss: 27.5085, val_MinusLogProbMetric: 27.5085

Epoch 593: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2757 - MinusLogProbMetric: 27.2757 - val_loss: 27.5085 - val_MinusLogProbMetric: 27.5085 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 594/1000
2023-10-05 11:11:02.431 
Epoch 594/1000 
	 loss: 27.2759, MinusLogProbMetric: 27.2759, val_loss: 27.5090, val_MinusLogProbMetric: 27.5090

Epoch 594: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2759 - MinusLogProbMetric: 27.2759 - val_loss: 27.5090 - val_MinusLogProbMetric: 27.5090 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 595/1000
2023-10-05 11:11:12.590 
Epoch 595/1000 
	 loss: 27.2759, MinusLogProbMetric: 27.2759, val_loss: 27.5097, val_MinusLogProbMetric: 27.5097

Epoch 595: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2759 - MinusLogProbMetric: 27.2759 - val_loss: 27.5097 - val_MinusLogProbMetric: 27.5097 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 596/1000
2023-10-05 11:11:22.773 
Epoch 596/1000 
	 loss: 27.2759, MinusLogProbMetric: 27.2759, val_loss: 27.5091, val_MinusLogProbMetric: 27.5091

Epoch 596: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2759 - MinusLogProbMetric: 27.2759 - val_loss: 27.5091 - val_MinusLogProbMetric: 27.5091 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 597/1000
2023-10-05 11:11:33.088 
Epoch 597/1000 
	 loss: 27.2758, MinusLogProbMetric: 27.2758, val_loss: 27.5094, val_MinusLogProbMetric: 27.5094

Epoch 597: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2758 - MinusLogProbMetric: 27.2758 - val_loss: 27.5094 - val_MinusLogProbMetric: 27.5094 - lr: 1.5625e-05 - 10s/epoch - 53ms/step
Epoch 598/1000
2023-10-05 11:11:43.592 
Epoch 598/1000 
	 loss: 27.2759, MinusLogProbMetric: 27.2759, val_loss: 27.5086, val_MinusLogProbMetric: 27.5086

Epoch 598: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2759 - MinusLogProbMetric: 27.2759 - val_loss: 27.5086 - val_MinusLogProbMetric: 27.5086 - lr: 1.5625e-05 - 11s/epoch - 54ms/step
Epoch 599/1000
2023-10-05 11:11:54.219 
Epoch 599/1000 
	 loss: 27.2760, MinusLogProbMetric: 27.2760, val_loss: 27.5094, val_MinusLogProbMetric: 27.5094

Epoch 599: val_loss did not improve from 27.50662
196/196 - 11s - loss: 27.2760 - MinusLogProbMetric: 27.2760 - val_loss: 27.5094 - val_MinusLogProbMetric: 27.5094 - lr: 1.5625e-05 - 11s/epoch - 54ms/step
Epoch 600/1000
2023-10-05 11:12:04.514 
Epoch 600/1000 
	 loss: 27.2758, MinusLogProbMetric: 27.2758, val_loss: 27.5094, val_MinusLogProbMetric: 27.5094

Epoch 600: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2758 - MinusLogProbMetric: 27.2758 - val_loss: 27.5094 - val_MinusLogProbMetric: 27.5094 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 601/1000
2023-10-05 11:12:14.822 
Epoch 601/1000 
	 loss: 27.2757, MinusLogProbMetric: 27.2757, val_loss: 27.5085, val_MinusLogProbMetric: 27.5085

Epoch 601: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2757 - MinusLogProbMetric: 27.2757 - val_loss: 27.5085 - val_MinusLogProbMetric: 27.5085 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 602/1000
2023-10-05 11:12:25.165 
Epoch 602/1000 
	 loss: 27.2758, MinusLogProbMetric: 27.2758, val_loss: 27.5085, val_MinusLogProbMetric: 27.5085

Epoch 602: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2758 - MinusLogProbMetric: 27.2758 - val_loss: 27.5085 - val_MinusLogProbMetric: 27.5085 - lr: 1.5625e-05 - 10s/epoch - 53ms/step
Epoch 603/1000
2023-10-05 11:12:35.544 
Epoch 603/1000 
	 loss: 27.2757, MinusLogProbMetric: 27.2757, val_loss: 27.5095, val_MinusLogProbMetric: 27.5095

Epoch 603: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2757 - MinusLogProbMetric: 27.2757 - val_loss: 27.5095 - val_MinusLogProbMetric: 27.5095 - lr: 1.5625e-05 - 10s/epoch - 53ms/step
Epoch 604/1000
2023-10-05 11:12:45.817 
Epoch 604/1000 
	 loss: 27.2757, MinusLogProbMetric: 27.2757, val_loss: 27.5101, val_MinusLogProbMetric: 27.5101

Epoch 604: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2757 - MinusLogProbMetric: 27.2757 - val_loss: 27.5101 - val_MinusLogProbMetric: 27.5101 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 605/1000
2023-10-05 11:12:56.082 
Epoch 605/1000 
	 loss: 27.2758, MinusLogProbMetric: 27.2758, val_loss: 27.5088, val_MinusLogProbMetric: 27.5088

Epoch 605: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2758 - MinusLogProbMetric: 27.2758 - val_loss: 27.5088 - val_MinusLogProbMetric: 27.5088 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 606/1000
2023-10-05 11:13:06.446 
Epoch 606/1000 
	 loss: 27.2757, MinusLogProbMetric: 27.2757, val_loss: 27.5096, val_MinusLogProbMetric: 27.5096

Epoch 606: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2757 - MinusLogProbMetric: 27.2757 - val_loss: 27.5096 - val_MinusLogProbMetric: 27.5096 - lr: 1.5625e-05 - 10s/epoch - 53ms/step
Epoch 607/1000
2023-10-05 11:13:16.724 
Epoch 607/1000 
	 loss: 27.2759, MinusLogProbMetric: 27.2759, val_loss: 27.5090, val_MinusLogProbMetric: 27.5090

Epoch 607: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2759 - MinusLogProbMetric: 27.2759 - val_loss: 27.5090 - val_MinusLogProbMetric: 27.5090 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 608/1000
2023-10-05 11:13:26.920 
Epoch 608/1000 
	 loss: 27.2758, MinusLogProbMetric: 27.2758, val_loss: 27.5091, val_MinusLogProbMetric: 27.5091

Epoch 608: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2758 - MinusLogProbMetric: 27.2758 - val_loss: 27.5091 - val_MinusLogProbMetric: 27.5091 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 609/1000
2023-10-05 11:13:37.090 
Epoch 609/1000 
	 loss: 27.2756, MinusLogProbMetric: 27.2756, val_loss: 27.5091, val_MinusLogProbMetric: 27.5091

Epoch 609: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2756 - MinusLogProbMetric: 27.2756 - val_loss: 27.5091 - val_MinusLogProbMetric: 27.5091 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 610/1000
2023-10-05 11:13:47.211 
Epoch 610/1000 
	 loss: 27.2757, MinusLogProbMetric: 27.2757, val_loss: 27.5092, val_MinusLogProbMetric: 27.5092

Epoch 610: val_loss did not improve from 27.50662
196/196 - 10s - loss: 27.2757 - MinusLogProbMetric: 27.2757 - val_loss: 27.5092 - val_MinusLogProbMetric: 27.5092 - lr: 1.5625e-05 - 10s/epoch - 51ms/step
Epoch 611/1000
2023-10-05 11:13:57.342 
Epoch 611/1000 
	 loss: 27.2757, MinusLogProbMetric: 27.2757, val_loss: 27.5087, val_MinusLogProbMetric: 27.5087

Epoch 611: val_loss did not improve from 27.50662
Restoring model weights from the end of the best epoch: 511.
196/196 - 10s - loss: 27.2757 - MinusLogProbMetric: 27.2757 - val_loss: 27.5087 - val_MinusLogProbMetric: 27.5087 - lr: 1.5625e-05 - 10s/epoch - 52ms/step
Epoch 611: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
LR metric calculation completed in 173.527243596036 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
nchunks = 10
Iterating from 0 to 1 out of 10 .
Iterating from 1 to 2 out of 10 .
Iterating from 2 to 3 out of 10 .
Iterating from 3 to 4 out of 10 .
Iterating from 4 to 5 out of 10 .
Iterating from 5 to 6 out of 10 .
Iterating from 6 to 7 out of 10 .
Iterating from 7 to 8 out of 10 .
Iterating from 8 to 9 out of 10 .
Iterating from 9 to 10 out of 10 .
KS tests calculation completed in 170.82185897091404 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
SWD metric calculation completed in 167.7033484969288 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
nchunks = 10
Iterating from 0 to 1 out of 10 .
Iterating from 1 to 2 out of 10 .
Iterating from 2 to 3 out of 10 .
Iterating from 3 to 4 out of 10 .
Iterating from 4 to 5 out of 10 .
Iterating from 5 to 6 out of 10 .
Iterating from 6 to 7 out of 10 .
Iterating from 7 to 8 out of 10 .
Iterating from 8 to 9 out of 10 .
Iterating from 9 to 10 out of 10 .
FN metric calculation completed in 166.90852499601897 seconds.
Training succeeded with seed 187.
Model trained in 7059.89 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 683.58 s.
                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/c_Main_MsplineN.py , Line : 468, Func.Name : prediction_function, Message : Plotters.cornerplotter(X_data_test.numpy(),X_data_nf.numpy(),path_to_results,ndims,norm=True) # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 684.43 s.
===========
Run 167/360 done in 7746.58 s.
===========

Directory ../../results/MsplineN_new/run_168/ already exists.
Skipping it.
===========
Run 168/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_169/ already exists.
Skipping it.
===========
Run 169/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_170/ already exists.
Skipping it.
===========
Run 170/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_171/ already exists.
Skipping it.
===========
Run 171/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_172/ already exists.
Skipping it.
===========
Run 172/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_173/ already exists.
Skipping it.
===========
Run 173/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_174/ already exists.
Skipping it.
===========
Run 174/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_175/ already exists.
Skipping it.
===========
Run 175/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_176/ already exists.
Skipping it.
===========
Run 176/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_177/ already exists.
Skipping it.
===========
Run 177/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_178/ already exists.
Skipping it.
===========
Run 178/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_179/ already exists.
Skipping it.
===========
Run 179/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_180/ already exists.
Skipping it.
===========
Run 180/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_181/ already exists.
Skipping it.
===========
Run 181/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_182/ already exists.
Skipping it.
===========
Run 182/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_183/ already exists.
Skipping it.
===========
Run 183/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_184/ already exists.
Skipping it.
===========
Run 184/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_185/ already exists.
Skipping it.
===========
Run 185/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_186/ already exists.
Skipping it.
===========
Run 186/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_187/ already exists.
Skipping it.
===========
Run 187/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_188/ already exists.
Skipping it.
===========
Run 188/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_189/ already exists.
Skipping it.
===========
Run 189/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_190/ already exists.
Skipping it.
===========
Run 190/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_191/ already exists.
Skipping it.
===========
Run 191/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_192/ already exists.
Skipping it.
===========
Run 192/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_193/ already exists.
Skipping it.
===========
Run 193/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_194/ already exists.
Skipping it.
===========
Run 194/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_195/ already exists.
Skipping it.
===========
Run 195/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_196/ already exists.
Skipping it.
===========
Run 196/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_197/ already exists.
Skipping it.
===========
Run 197/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_198/ already exists.
Skipping it.
===========
Run 198/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_199/ already exists.
Skipping it.
===========
Run 199/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_200/ already exists.
Skipping it.
===========
Run 200/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_201/ already exists.
Skipping it.
===========
Run 201/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_202/ already exists.
Skipping it.
===========
Run 202/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_203/ already exists.
Skipping it.
===========
Run 203/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_204/ already exists.
Skipping it.
===========
Run 204/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_205/ already exists.
Skipping it.
===========
Run 205/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_206/ already exists.
Skipping it.
===========
Run 206/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_207/ already exists.
Skipping it.
===========
Run 207/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_208/ already exists.
Skipping it.
===========
Run 208/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_209/ already exists.
Skipping it.
===========
Run 209/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_210/ already exists.
Skipping it.
===========
Run 210/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_211/ already exists.
Skipping it.
===========
Run 211/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_212/ already exists.
Skipping it.
===========
Run 212/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_213/ already exists.
Skipping it.
===========
Run 213/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_214/ already exists.
Skipping it.
===========
Run 214/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_215/ already exists.
Skipping it.
===========
Run 215/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_216/ already exists.
Skipping it.
===========
Run 216/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_217/ already exists.
Skipping it.
===========
Run 217/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_218/ already exists.
Skipping it.
===========
Run 218/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_219/ already exists.
Skipping it.
===========
Run 219/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_220/ already exists.
Skipping it.
===========
Run 220/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_221/ already exists.
Skipping it.
===========
Run 221/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_222/ already exists.
Skipping it.
===========
Run 222/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_223/ already exists.
Skipping it.
===========
Run 223/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_224/ already exists.
Skipping it.
===========
Run 224/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_225/ already exists.
Skipping it.
===========
Run 225/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_226/ already exists.
Skipping it.
===========
Run 226/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_227/ already exists.
Skipping it.
===========
Run 227/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_228/ already exists.
Skipping it.
===========
Run 228/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_229/ already exists.
Skipping it.
===========
Run 229/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_230/ already exists.
Skipping it.
===========
Run 230/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_231/ already exists.
Skipping it.
===========
Run 231/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_232/ already exists.
Skipping it.
===========
Run 232/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_233/ already exists.
Skipping it.
===========
Run 233/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_234/ already exists.
Skipping it.
===========
Run 234/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_235/ already exists.
Skipping it.
===========
Run 235/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_236/ already exists.
Skipping it.
===========
Run 236/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_237/ already exists.
Skipping it.
===========
Run 237/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_238/ already exists.
Skipping it.
===========
Run 238/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_239/ already exists.
Skipping it.
===========
Run 239/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_240/ already exists.
Skipping it.
===========
Run 240/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_241/ already exists.
Skipping it.
===========
Run 241/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_242/ already exists.
Skipping it.
===========
Run 242/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_243/ already exists.
Skipping it.
===========
Run 243/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_244/ already exists.
Skipping it.
===========
Run 244/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_245/ already exists.
Skipping it.
===========
Run 245/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_246/ already exists.
Skipping it.
===========
Run 246/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_247/ already exists.
Skipping it.
===========
Run 247/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_248/ already exists.
Skipping it.
===========
Run 248/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_249/ already exists.
Skipping it.
===========
Run 249/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_250/ already exists.
Skipping it.
===========
Run 250/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_251/ already exists.
Skipping it.
===========
Run 251/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_252/ already exists.
Skipping it.
===========
Run 252/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_253/ already exists.
Skipping it.
===========
Run 253/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_254/ already exists.
Skipping it.
===========
Run 254/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_255/ already exists.
Skipping it.
===========
Run 255/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_256/ already exists.
Skipping it.
===========
Run 256/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_257/ already exists.
Skipping it.
===========
Run 257/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_258/ already exists.
Skipping it.
===========
Run 258/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_259/ already exists.
Skipping it.
===========
Run 259/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_260/ already exists.
Skipping it.
===========
Run 260/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_261/ already exists.
Skipping it.
===========
Run 261/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_262/ already exists.
Skipping it.
===========
Run 262/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_263/ already exists.
Skipping it.
===========
Run 263/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_264/ already exists.
Skipping it.
===========
Run 264/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_265/ already exists.
Skipping it.
===========
Run 265/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_266/ already exists.
Skipping it.
===========
Run 266/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_267/ already exists.
Skipping it.
===========
Run 267/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_268/ already exists.
Skipping it.
===========
Run 268/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_269/ already exists.
Skipping it.
===========
Run 269/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_270/ already exists.
Skipping it.
===========
Run 270/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_271/ already exists.
Skipping it.
===========
Run 271/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_272/ already exists.
Skipping it.
===========
Run 272/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_273/ already exists.
Skipping it.
===========
Run 273/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_274/ already exists.
Skipping it.
===========
Run 274/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_275/ already exists.
Skipping it.
===========
Run 275/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_276/ already exists.
Skipping it.
===========
Run 276/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_277/ already exists.
Skipping it.
===========
Run 277/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_278/ already exists.
Skipping it.
===========
Run 278/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_279/ already exists.
Skipping it.
===========
Run 279/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_280/ already exists.
Skipping it.
===========
Run 280/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_281/ already exists.
Skipping it.
===========
Run 281/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_282/ already exists.
Skipping it.
===========
Run 282/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_283/ already exists.
Skipping it.
===========
Run 283/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_284/ already exists.
Skipping it.
===========
Run 284/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_285/ already exists.
Skipping it.
===========
Run 285/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_286/ already exists.
Skipping it.
===========
Run 286/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_287/ already exists.
Skipping it.
===========
Run 287/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_288/ already exists.
Skipping it.
===========
Run 288/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_289/ already exists.
Skipping it.
===========
Run 289/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_290/ already exists.
Skipping it.
===========
Run 290/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_291/ already exists.
Skipping it.
===========
Run 291/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_292/ already exists.
Skipping it.
===========
Run 292/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_293/ already exists.
Skipping it.
===========
Run 293/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_294/ already exists.
Skipping it.
===========
Run 294/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_295/ already exists.
Skipping it.
===========
Run 295/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_296/ already exists.
Skipping it.
===========
Run 296/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_297/ already exists.
Skipping it.
===========
Run 297/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_298/ already exists.
Skipping it.
===========
Run 298/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_299/ already exists.
Skipping it.
===========
Run 299/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_300/ already exists.
Skipping it.
===========
Run 300/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_301/ already exists.
Skipping it.
===========
Run 301/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_302/ already exists.
Skipping it.
===========
Run 302/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_303/ already exists.
Skipping it.
===========
Run 303/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_304/ already exists.
Skipping it.
===========
Run 304/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_305/ already exists.
Skipping it.
===========
Run 305/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_306/ already exists.
Skipping it.
===========
Run 306/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_307/ already exists.
Skipping it.
===========
Run 307/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_308/ already exists.
Skipping it.
===========
Run 308/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_309/ already exists.
Skipping it.
===========
Run 309/360 already exists. Skipping it.
===========

===========
Generating train data for run 310.
===========
Train data generated in 0.47 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[400], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 400)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_310/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 869}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_310/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 4.958481 ,  7.185559 ,  5.2691135, ...,  2.2815313, -0.778629 ,
         1.838389 ],
       [ 5.6181526,  7.16129  ,  4.80875  , ...,  2.5667636,  1.2025442,
         1.772511 ],
       [ 5.6036563,  6.387541 ,  7.460415 , ...,  2.7951665, -0.5726781,
         1.8691473],
       ...,
       [ 4.4865627,  9.730911 ,  1.6274097, ...,  2.6767344,  2.3187554,
         5.185367 ],
       [ 5.421912 ,  8.0552   ,  5.8100533, ...,  4.3451815, -1.3246787,
         1.7943339],
       [ 4.8276386,  7.225754 ,  7.454408 , ...,  4.0019584,  1.7594593,
         1.9465172]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[400], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[400], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_310/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_310
self.data_kwargs: {'seed': 869}
self.x_data: [[ 5.564473    5.964719    5.442881   ...  4.2789574   0.42959195
   1.9512737 ]
 [ 3.898483    9.561785    1.0025021  ...  2.8539047   2.2991526
   4.1931987 ]
 [ 5.19114     7.2764535   6.8194084  ...  4.571225   -1.0834298
   1.7557602 ]
 ...
 [ 3.9283736   9.18209     0.52922547 ...  2.3498971   2.2025552
   3.7278938 ]
 [ 5.3986945   5.5772276   5.7054524  ...  4.2691116   0.44027776
   1.672469  ]
 [ 5.824199    6.0575733   6.9229517  ...  2.790286   -0.18190761
   2.0085988 ]]
self.y_data: []
self.ndims: 400
Model defined.
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        [(None, 400)]             0         
                                                                 
 log_prob_layer_1 (LogProbLa  (None,)                  5197280   
 yer)                                                            
                                                                 
=================================================================
Total params: 5,197,280
Trainable params: 5,197,280
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_1/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_1'")
self.model: <keras.engine.functional.Functional object at 0x7f37a1f647f0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7f37a1b27b80>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7f37a1b27b80>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7f37a1f64100>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7f37a1abdcf0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7f37a1abe260>, <keras.callbacks.ModelCheckpoint object at 0x7f37a1abe320>, <keras.callbacks.EarlyStopping object at 0x7f37a1abe590>, <keras.callbacks.ReduceLROnPlateau object at 0x7f37a1abe5c0>, <keras.callbacks.TerminateOnNaN object at 0x7f37a1abe200>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 4.958481 ,  7.185559 ,  5.2691135, ...,  2.2815313, -0.778629 ,
         1.838389 ],
       [ 5.6181526,  7.16129  ,  4.80875  , ...,  2.5667636,  1.2025442,
         1.772511 ],
       [ 5.6036563,  6.387541 ,  7.460415 , ...,  2.7951665, -0.5726781,
         1.8691473],
       ...,
       [ 4.4865627,  9.730911 ,  1.6274097, ...,  2.6767344,  2.3187554,
         5.185367 ],
       [ 5.421912 ,  8.0552   ,  5.8100533, ...,  4.3451815, -1.3246787,
         1.7943339],
       [ 4.8276386,  7.225754 ,  7.454408 , ...,  4.0019584,  1.7594593,
         1.9465172]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_310/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 310/360 with hyperparameters:
timestamp = 2023-10-05 11:25:27.418216
ndims = 400
seed_train = 869
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 8
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 5197280
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 5.5644732e+00  5.9647188e+00  5.4428811e+00  3.9577458e+00
  3.0179524e+00  6.1647692e+00  4.2089882e+00  7.9654708e+00
  9.4179373e+00  3.7585826e+00  7.9273734e+00  5.5586958e+00
  6.7501726e+00  9.2974787e+00  4.8001468e-01  1.2172394e+00
  1.0081589e-01  8.4297094e+00  8.1617374e+00  9.2360516e+00
  9.6743031e+00  8.7472935e+00  4.6498642e+00  7.8264141e+00
  8.5118628e-01  6.3854818e+00  1.5208231e+00  9.4902525e+00
  5.2141681e+00  4.5499167e+00  2.7460706e+00  7.6669340e+00
  4.5326633e+00  5.5555077e+00  1.7942755e-01  5.8154359e+00
  6.3558588e+00  6.3473015e+00  9.4286709e+00  6.9009266e+00
  3.3508213e+00  4.5059600e+00  8.6057320e+00  8.4116054e-01
  5.4284921e+00  7.0877514e+00  2.6609249e+00  2.0939958e+00
  2.7867985e+00  3.5950177e+00  5.8090401e+00  5.0730381e+00
  1.0149550e+01  1.0946103e+00  2.3387823e+00  1.7575771e+00
  6.4593601e+00  3.0161257e+00  4.7968550e+00  2.8741136e+00
  1.5774881e+00  2.2630596e+00  6.7312951e+00  1.0040274e+00
  1.4217609e+00  4.8913841e+00  8.3270550e+00  7.2194958e-01
  8.9426384e+00  1.0678217e+00  1.0096296e+01  4.6515751e+00
  8.2459908e+00  6.1420493e+00  8.4806290e+00 -1.1691749e-03
  3.4647141e+00  7.9819608e-01  2.9313142e+00  7.6457512e-01
  2.6114082e+00  3.3926206e+00  6.3204336e-01  6.9472232e+00
  6.1767802e+00  1.7232375e+00  5.2088680e+00  6.7266166e-01
  5.8520455e+00  9.2741919e+00  3.3221593e+00  6.5970306e+00
  1.3103381e+00  6.8199043e+00  2.9266403e+00  4.2567813e-01
  6.9772291e+00  2.5234514e-01  9.1087856e+00 -1.1639075e-01
  6.3724360e+00  1.9607766e+00  7.5801768e+00  8.5791264e+00
  2.2578557e+00  7.5813990e+00  6.4804850e+00  5.8132205e+00
  2.1088514e+00  1.0999339e+01  5.4197254e+00  8.3633041e+00
  7.1461926e+00  3.0918367e+00  8.0308876e+00  3.8536227e+00
  1.0430374e+01  5.6626177e+00  8.1247635e+00  8.6208382e+00
  7.1810780e+00  5.1034966e+00  9.5615063e+00  6.7382231e+00
  4.6961942e+00  6.1229806e+00  2.3970871e-01  3.0389297e+00
  6.5725913e+00  1.8930186e+00  6.0706911e+00  4.8668084e+00
  7.2900695e-01  2.7427726e+00  6.2901268e+00  5.3226457e+00
  6.4436941e+00  6.3124623e+00  6.5496554e+00  3.7559834e+00
  8.7001657e+00  3.7271805e+00  3.8051229e+00  8.6121111e+00
  7.9988327e+00  8.0225945e+00  1.2260035e+00  9.4835634e+00
  6.7190905e+00  1.1107555e+01  1.7306167e+00  8.9052773e+00
  1.0469657e+00  5.3587871e+00  4.8209906e-02  8.4675579e+00
  8.0731897e+00  5.4796133e+00  5.1478128e+00  7.9991090e-01
  7.2909007e+00  5.4361420e+00  6.9195671e+00  9.0617733e+00
  9.8714008e+00  9.2150116e+00  9.9882595e-02  4.0313225e+00
  8.1073208e+00  2.1348555e+00  4.9532614e+00  1.1814938e+00
  8.2748628e-01  2.2591886e-01  7.9481497e+00  3.7439425e+00
  3.4663754e+00  8.5179749e+00  7.2716212e+00  5.2001154e-01
  8.4139794e-01  6.2331824e+00  4.3589931e+00  2.0797641e+00
  9.6821423e+00  7.0645223e+00  4.4966307e+00  5.6680598e+00
  7.3415375e+00  3.5300772e+00  4.2633262e+00  1.8567795e+00
  2.1430013e+00  8.7593298e+00  5.9687657e+00  5.3629761e+00
  2.4785576e+00  2.6607697e+00  1.3090696e+00  4.8614373e+00
  3.0679677e+00  7.7780356e+00  4.2973862e+00  2.0292830e+00
  8.6426532e-01 -9.6826899e-01  6.6356387e+00  4.5498505e+00
  6.4922161e+00  8.3934307e+00  9.9302053e+00  3.1980631e+00
  6.7549562e+00  2.5491276e+00  9.8962471e-02  7.5182462e+00
  3.2976124e+00  3.5520930e+00  5.7718983e+00  8.9637823e+00
  6.2356396e+00  8.8487635e+00  2.5871990e+00  8.3640232e+00
  1.9508564e+00  9.9790535e+00  8.2423458e+00  1.5020468e+00
  9.4301147e+00  8.5344362e+00  2.5804756e+00  1.9531720e+00
  5.8337846e+00  8.7513995e-01  1.9036969e+00  4.0885725e+00
  3.2597775e+00  5.4588337e+00  3.7165027e+00  6.5091848e+00
  9.1366730e+00  1.1218386e+00  5.5315199e+00  1.6425103e+00
  6.9227962e+00  3.8944986e+00  6.5958529e+00  2.7533178e+00
  1.0201238e+00  4.7558842e+00  2.5354340e+00  8.6109276e+00
  8.7848501e+00  6.9936213e+00  9.4159269e+00  1.2381315e+00
  5.0839267e+00  6.4841466e+00  8.7124062e+00  3.4702032e+00
  2.4535975e+00  2.2145528e-01  4.9332717e-01  9.6155348e+00
  6.6220002e+00  8.6177359e+00  2.8209510e+00  6.0984297e+00
  5.1170254e-01  5.0358410e+00  9.7963343e+00  9.1100302e+00
  3.3173375e+00  1.0093975e+01  2.1636114e+00  9.6137924e+00
  8.5213242e+00  7.7084403e+00  4.9318528e+00  7.2097282e+00
  2.9828334e+00  8.1237202e+00  6.1372480e+00  6.9740668e-02
  4.5652747e+00  2.6813500e+00  1.0121011e+01  4.5073867e+00
  5.3750186e+00  6.4560575e+00  3.6601653e+00  5.2769214e-01
  8.4301453e+00  1.9634770e+00  6.3079758e+00  2.2661259e+00
  9.2980838e-01  8.3633375e+00  9.7871046e+00  9.6099081e+00
  9.3740044e+00  8.7310429e+00  3.2533665e+00  6.5555799e-01
  4.2784367e+00  1.7472155e+00  2.6335521e+00  7.9057425e-01
  8.1307993e+00  5.1638454e-01  7.7403736e+00  1.2915041e+00
  9.1701037e-01  4.5069432e-01  5.8971043e+00  1.9417634e+00
  3.8502593e+00  5.0155010e+00  8.0462313e+00  7.2887397e+00
  3.1584864e+00  1.8443762e+00  3.9476866e-01  2.5119877e+00
  4.0305524e+00  4.4092383e+00  6.5799918e+00  7.8337493e+00
  3.3282962e+00  3.3075032e+00  1.6791583e+00  8.2602863e+00
  6.5185136e-01  6.8482847e+00  7.3727760e+00  8.4360771e+00
  2.0570569e+00  3.2551155e+00  6.2362885e+00  2.1132956e+00
  3.7721217e+00  1.6363618e+00  4.4879384e+00  1.5592048e-01
  8.7436781e+00  3.2695165e-01  5.0355420e+00  2.4176400e+00
  5.8541756e+00  1.1064837e+01  5.7690058e+00  2.0451261e-01
  4.0661583e+00  5.2560072e+00  5.3713546e+00  7.9772549e+00
  2.7795429e+00  1.5028974e+00  4.2679973e+00  9.1248150e+00
  1.5850805e+00  8.7205067e+00  5.4285793e+00  4.9169712e+00
  1.0060825e+01  3.8250780e+00  7.1650805e+00  4.0729742e+00
  8.9841719e+00  6.9391742e+00  7.8083930e+00  3.9812775e+00
  7.8273044e+00  6.4795074e+00  2.4150946e+00  1.6428995e+00
  8.3115578e+00  9.9696436e+00  7.0351176e+00  6.0687480e+00
  8.3650837e+00  4.6081719e+00  1.0135881e+01  5.7391953e+00
  8.8811264e+00  1.0321923e+01  7.5924931e+00  1.5841845e+00
  6.1072383e+00  3.7689674e+00 -4.1580003e-01  5.3280330e+00
  2.2242229e+00  8.2317858e+00  3.7272879e-01  7.9410253e+00
  2.8971622e+00  4.2789574e+00  4.2959195e-01  1.9512737e+00]
Epoch 1/1000
2023-10-05 11:26:06.971 
Epoch 1/1000 
	 loss: 459.5399, MinusLogProbMetric: 459.5399, val_loss: 218.0045, val_MinusLogProbMetric: 218.0045

Epoch 1: val_loss improved from inf to 218.00453, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 40s - loss: 459.5399 - MinusLogProbMetric: 459.5399 - val_loss: 218.0045 - val_MinusLogProbMetric: 218.0045 - lr: 0.0010 - 40s/epoch - 204ms/step
Epoch 2/1000
2023-10-05 11:26:21.653 
Epoch 2/1000 
	 loss: 205.5455, MinusLogProbMetric: 205.5455, val_loss: 200.4911, val_MinusLogProbMetric: 200.4911

Epoch 2: val_loss improved from 218.00453 to 200.49115, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 205.5455 - MinusLogProbMetric: 205.5455 - val_loss: 200.4911 - val_MinusLogProbMetric: 200.4911 - lr: 0.0010 - 15s/epoch - 76ms/step
Epoch 3/1000
2023-10-05 11:26:36.488 
Epoch 3/1000 
	 loss: 196.1239, MinusLogProbMetric: 196.1239, val_loss: 193.7013, val_MinusLogProbMetric: 193.7013

Epoch 3: val_loss improved from 200.49115 to 193.70129, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 196.1239 - MinusLogProbMetric: 196.1239 - val_loss: 193.7013 - val_MinusLogProbMetric: 193.7013 - lr: 0.0010 - 15s/epoch - 76ms/step
Epoch 4/1000
2023-10-05 11:26:51.387 
Epoch 4/1000 
	 loss: 193.1128, MinusLogProbMetric: 193.1128, val_loss: 191.8294, val_MinusLogProbMetric: 191.8294

Epoch 4: val_loss improved from 193.70129 to 191.82936, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 193.1128 - MinusLogProbMetric: 193.1128 - val_loss: 191.8294 - val_MinusLogProbMetric: 191.8294 - lr: 0.0010 - 15s/epoch - 76ms/step
Epoch 5/1000
2023-10-05 11:27:06.285 
Epoch 5/1000 
	 loss: 191.1505, MinusLogProbMetric: 191.1505, val_loss: 191.0237, val_MinusLogProbMetric: 191.0237

Epoch 5: val_loss improved from 191.82936 to 191.02368, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 191.1505 - MinusLogProbMetric: 191.1505 - val_loss: 191.0237 - val_MinusLogProbMetric: 191.0237 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 6/1000
2023-10-05 11:27:20.903 
Epoch 6/1000 
	 loss: 189.9512, MinusLogProbMetric: 189.9512, val_loss: 189.6931, val_MinusLogProbMetric: 189.6931

Epoch 6: val_loss improved from 191.02368 to 189.69305, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 189.9512 - MinusLogProbMetric: 189.9512 - val_loss: 189.6931 - val_MinusLogProbMetric: 189.6931 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 7/1000
2023-10-05 11:27:35.475 
Epoch 7/1000 
	 loss: 188.8991, MinusLogProbMetric: 188.8991, val_loss: 188.3486, val_MinusLogProbMetric: 188.3486

Epoch 7: val_loss improved from 189.69305 to 188.34856, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 14s - loss: 188.8991 - MinusLogProbMetric: 188.8991 - val_loss: 188.3486 - val_MinusLogProbMetric: 188.3486 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 8/1000
2023-10-05 11:27:49.784 
Epoch 8/1000 
	 loss: 188.8060, MinusLogProbMetric: 188.8060, val_loss: 188.2765, val_MinusLogProbMetric: 188.2765

Epoch 8: val_loss improved from 188.34856 to 188.27649, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 188.8060 - MinusLogProbMetric: 188.8060 - val_loss: 188.2765 - val_MinusLogProbMetric: 188.2765 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 9/1000
2023-10-05 11:28:04.575 
Epoch 9/1000 
	 loss: 187.3919, MinusLogProbMetric: 187.3919, val_loss: 188.4438, val_MinusLogProbMetric: 188.4438

Epoch 9: val_loss did not improve from 188.27649
196/196 - 14s - loss: 187.3919 - MinusLogProbMetric: 187.3919 - val_loss: 188.4438 - val_MinusLogProbMetric: 188.4438 - lr: 0.0010 - 14s/epoch - 72ms/step
Epoch 10/1000
2023-10-05 11:28:18.802 
Epoch 10/1000 
	 loss: 187.2644, MinusLogProbMetric: 187.2644, val_loss: 187.1776, val_MinusLogProbMetric: 187.1776

Epoch 10: val_loss improved from 188.27649 to 187.17757, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 14s - loss: 187.2644 - MinusLogProbMetric: 187.2644 - val_loss: 187.1776 - val_MinusLogProbMetric: 187.1776 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 11/1000
2023-10-05 11:28:33.397 
Epoch 11/1000 
	 loss: 187.0913, MinusLogProbMetric: 187.0913, val_loss: 187.9312, val_MinusLogProbMetric: 187.9312

Epoch 11: val_loss did not improve from 187.17757
196/196 - 14s - loss: 187.0913 - MinusLogProbMetric: 187.0913 - val_loss: 187.9312 - val_MinusLogProbMetric: 187.9312 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 12/1000
2023-10-05 11:28:47.809 
Epoch 12/1000 
	 loss: 186.2809, MinusLogProbMetric: 186.2809, val_loss: 188.5257, val_MinusLogProbMetric: 188.5257

Epoch 12: val_loss did not improve from 187.17757
196/196 - 14s - loss: 186.2809 - MinusLogProbMetric: 186.2809 - val_loss: 188.5257 - val_MinusLogProbMetric: 188.5257 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 13/1000
2023-10-05 11:29:02.117 
Epoch 13/1000 
	 loss: 186.0354, MinusLogProbMetric: 186.0354, val_loss: 185.3013, val_MinusLogProbMetric: 185.3013

Epoch 13: val_loss improved from 187.17757 to 185.30132, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 14s - loss: 186.0354 - MinusLogProbMetric: 186.0354 - val_loss: 185.3013 - val_MinusLogProbMetric: 185.3013 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 14/1000
2023-10-05 11:29:16.761 
Epoch 14/1000 
	 loss: 185.7062, MinusLogProbMetric: 185.7062, val_loss: 187.8057, val_MinusLogProbMetric: 187.8057

Epoch 14: val_loss did not improve from 185.30132
196/196 - 14s - loss: 185.7062 - MinusLogProbMetric: 185.7062 - val_loss: 187.8057 - val_MinusLogProbMetric: 187.8057 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 15/1000
2023-10-05 11:29:31.205 
Epoch 15/1000 
	 loss: 185.4167, MinusLogProbMetric: 185.4167, val_loss: 187.9447, val_MinusLogProbMetric: 187.9447

Epoch 15: val_loss did not improve from 185.30132
196/196 - 14s - loss: 185.4167 - MinusLogProbMetric: 185.4167 - val_loss: 187.9447 - val_MinusLogProbMetric: 187.9447 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 16/1000
2023-10-05 11:29:45.721 
Epoch 16/1000 
	 loss: 184.9723, MinusLogProbMetric: 184.9723, val_loss: 187.5308, val_MinusLogProbMetric: 187.5308

Epoch 16: val_loss did not improve from 185.30132
196/196 - 15s - loss: 184.9723 - MinusLogProbMetric: 184.9723 - val_loss: 187.5308 - val_MinusLogProbMetric: 187.5308 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 17/1000
2023-10-05 11:30:00.244 
Epoch 17/1000 
	 loss: 185.3601, MinusLogProbMetric: 185.3601, val_loss: 185.6634, val_MinusLogProbMetric: 185.6634

Epoch 17: val_loss did not improve from 185.30132
196/196 - 15s - loss: 185.3601 - MinusLogProbMetric: 185.3601 - val_loss: 185.6634 - val_MinusLogProbMetric: 185.6634 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 18/1000
2023-10-05 11:30:14.725 
Epoch 18/1000 
	 loss: 184.6486, MinusLogProbMetric: 184.6486, val_loss: 188.4022, val_MinusLogProbMetric: 188.4022

Epoch 18: val_loss did not improve from 185.30132
196/196 - 14s - loss: 184.6486 - MinusLogProbMetric: 184.6486 - val_loss: 188.4022 - val_MinusLogProbMetric: 188.4022 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 19/1000
2023-10-05 11:30:29.191 
Epoch 19/1000 
	 loss: 184.6060, MinusLogProbMetric: 184.6060, val_loss: 185.1150, val_MinusLogProbMetric: 185.1150

Epoch 19: val_loss improved from 185.30132 to 185.11499, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 184.6060 - MinusLogProbMetric: 184.6060 - val_loss: 185.1150 - val_MinusLogProbMetric: 185.1150 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 20/1000
2023-10-05 11:30:44.213 
Epoch 20/1000 
	 loss: 184.4888, MinusLogProbMetric: 184.4888, val_loss: 184.3666, val_MinusLogProbMetric: 184.3666

Epoch 20: val_loss improved from 185.11499 to 184.36656, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 184.4888 - MinusLogProbMetric: 184.4888 - val_loss: 184.3666 - val_MinusLogProbMetric: 184.3666 - lr: 0.0010 - 15s/epoch - 76ms/step
Epoch 21/1000
2023-10-05 11:30:58.862 
Epoch 21/1000 
	 loss: 184.3760, MinusLogProbMetric: 184.3760, val_loss: 184.2025, val_MinusLogProbMetric: 184.2025

Epoch 21: val_loss improved from 184.36656 to 184.20245, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 184.3760 - MinusLogProbMetric: 184.3760 - val_loss: 184.2025 - val_MinusLogProbMetric: 184.2025 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 22/1000
2023-10-05 11:31:13.537 
Epoch 22/1000 
	 loss: 183.8911, MinusLogProbMetric: 183.8911, val_loss: 185.1264, val_MinusLogProbMetric: 185.1264

Epoch 22: val_loss did not improve from 184.20245
196/196 - 14s - loss: 183.8911 - MinusLogProbMetric: 183.8911 - val_loss: 185.1264 - val_MinusLogProbMetric: 185.1264 - lr: 0.0010 - 14s/epoch - 72ms/step
Epoch 23/1000
2023-10-05 11:31:27.899 
Epoch 23/1000 
	 loss: 183.9608, MinusLogProbMetric: 183.9608, val_loss: 184.3837, val_MinusLogProbMetric: 184.3837

Epoch 23: val_loss did not improve from 184.20245
196/196 - 14s - loss: 183.9608 - MinusLogProbMetric: 183.9608 - val_loss: 184.3837 - val_MinusLogProbMetric: 184.3837 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 24/1000
2023-10-05 11:31:42.225 
Epoch 24/1000 
	 loss: 183.7516, MinusLogProbMetric: 183.7516, val_loss: 184.4462, val_MinusLogProbMetric: 184.4462

Epoch 24: val_loss did not improve from 184.20245
196/196 - 14s - loss: 183.7516 - MinusLogProbMetric: 183.7516 - val_loss: 184.4462 - val_MinusLogProbMetric: 184.4462 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 25/1000
2023-10-05 11:31:56.660 
Epoch 25/1000 
	 loss: 183.5910, MinusLogProbMetric: 183.5910, val_loss: 183.3020, val_MinusLogProbMetric: 183.3020

Epoch 25: val_loss improved from 184.20245 to 183.30202, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 183.5910 - MinusLogProbMetric: 183.5910 - val_loss: 183.3020 - val_MinusLogProbMetric: 183.3020 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 26/1000
2023-10-05 11:32:11.137 
Epoch 26/1000 
	 loss: 183.4723, MinusLogProbMetric: 183.4723, val_loss: 183.1828, val_MinusLogProbMetric: 183.1828

Epoch 26: val_loss improved from 183.30202 to 183.18277, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 183.4723 - MinusLogProbMetric: 183.4723 - val_loss: 183.1828 - val_MinusLogProbMetric: 183.1828 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 27/1000
2023-10-05 11:32:25.908 
Epoch 27/1000 
	 loss: 183.4417, MinusLogProbMetric: 183.4417, val_loss: 184.1649, val_MinusLogProbMetric: 184.1649

Epoch 27: val_loss did not improve from 183.18277
196/196 - 14s - loss: 183.4417 - MinusLogProbMetric: 183.4417 - val_loss: 184.1649 - val_MinusLogProbMetric: 184.1649 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 28/1000
2023-10-05 11:32:40.445 
Epoch 28/1000 
	 loss: 183.1477, MinusLogProbMetric: 183.1477, val_loss: 183.1578, val_MinusLogProbMetric: 183.1578

Epoch 28: val_loss improved from 183.18277 to 183.15782, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 183.1477 - MinusLogProbMetric: 183.1477 - val_loss: 183.1578 - val_MinusLogProbMetric: 183.1578 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 29/1000
2023-10-05 11:32:54.841 
Epoch 29/1000 
	 loss: 183.4643, MinusLogProbMetric: 183.4643, val_loss: 184.2965, val_MinusLogProbMetric: 184.2965

Epoch 29: val_loss did not improve from 183.15782
196/196 - 14s - loss: 183.4643 - MinusLogProbMetric: 183.4643 - val_loss: 184.2965 - val_MinusLogProbMetric: 184.2965 - lr: 0.0010 - 14s/epoch - 72ms/step
Epoch 30/1000
2023-10-05 11:33:09.231 
Epoch 30/1000 
	 loss: 183.2955, MinusLogProbMetric: 183.2955, val_loss: 183.2155, val_MinusLogProbMetric: 183.2155

Epoch 30: val_loss did not improve from 183.15782
196/196 - 14s - loss: 183.2955 - MinusLogProbMetric: 183.2955 - val_loss: 183.2155 - val_MinusLogProbMetric: 183.2155 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 31/1000
2023-10-05 11:33:23.626 
Epoch 31/1000 
	 loss: 183.0682, MinusLogProbMetric: 183.0682, val_loss: 183.6622, val_MinusLogProbMetric: 183.6622

Epoch 31: val_loss did not improve from 183.15782
196/196 - 14s - loss: 183.0682 - MinusLogProbMetric: 183.0682 - val_loss: 183.6622 - val_MinusLogProbMetric: 183.6622 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 32/1000
2023-10-05 11:33:38.051 
Epoch 32/1000 
	 loss: 182.9748, MinusLogProbMetric: 182.9748, val_loss: 184.3073, val_MinusLogProbMetric: 184.3073

Epoch 32: val_loss did not improve from 183.15782
196/196 - 14s - loss: 182.9748 - MinusLogProbMetric: 182.9748 - val_loss: 184.3073 - val_MinusLogProbMetric: 184.3073 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 33/1000
2023-10-05 11:33:52.386 
Epoch 33/1000 
	 loss: 182.9243, MinusLogProbMetric: 182.9243, val_loss: 183.9122, val_MinusLogProbMetric: 183.9122

Epoch 33: val_loss did not improve from 183.15782
196/196 - 14s - loss: 182.9243 - MinusLogProbMetric: 182.9243 - val_loss: 183.9122 - val_MinusLogProbMetric: 183.9122 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 34/1000
2023-10-05 11:34:06.744 
Epoch 34/1000 
	 loss: 183.2105, MinusLogProbMetric: 183.2105, val_loss: 183.1923, val_MinusLogProbMetric: 183.1923

Epoch 34: val_loss did not improve from 183.15782
196/196 - 14s - loss: 183.2105 - MinusLogProbMetric: 183.2105 - val_loss: 183.1923 - val_MinusLogProbMetric: 183.1923 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 35/1000
2023-10-05 11:34:21.021 
Epoch 35/1000 
	 loss: 182.8024, MinusLogProbMetric: 182.8024, val_loss: 184.2905, val_MinusLogProbMetric: 184.2905

Epoch 35: val_loss did not improve from 183.15782
196/196 - 14s - loss: 182.8024 - MinusLogProbMetric: 182.8024 - val_loss: 184.2905 - val_MinusLogProbMetric: 184.2905 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 36/1000
2023-10-05 11:34:35.655 
Epoch 36/1000 
	 loss: 182.6158, MinusLogProbMetric: 182.6158, val_loss: 182.9467, val_MinusLogProbMetric: 182.9467

Epoch 36: val_loss improved from 183.15782 to 182.94673, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 16s - loss: 182.6158 - MinusLogProbMetric: 182.6158 - val_loss: 182.9467 - val_MinusLogProbMetric: 182.9467 - lr: 0.0010 - 16s/epoch - 79ms/step
Epoch 37/1000
2023-10-05 11:34:51.040 
Epoch 37/1000 
	 loss: 182.9752, MinusLogProbMetric: 182.9752, val_loss: 183.3032, val_MinusLogProbMetric: 183.3032

Epoch 37: val_loss did not improve from 182.94673
196/196 - 14s - loss: 182.9752 - MinusLogProbMetric: 182.9752 - val_loss: 183.3032 - val_MinusLogProbMetric: 183.3032 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 38/1000
2023-10-05 11:35:05.692 
Epoch 38/1000 
	 loss: 182.5061, MinusLogProbMetric: 182.5061, val_loss: 182.8583, val_MinusLogProbMetric: 182.8583

Epoch 38: val_loss improved from 182.94673 to 182.85834, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 182.5061 - MinusLogProbMetric: 182.5061 - val_loss: 182.8583 - val_MinusLogProbMetric: 182.8583 - lr: 0.0010 - 15s/epoch - 76ms/step
Epoch 39/1000
2023-10-05 11:35:20.409 
Epoch 39/1000 
	 loss: 182.7442, MinusLogProbMetric: 182.7442, val_loss: 182.8002, val_MinusLogProbMetric: 182.8002

Epoch 39: val_loss improved from 182.85834 to 182.80023, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 182.7442 - MinusLogProbMetric: 182.7442 - val_loss: 182.8002 - val_MinusLogProbMetric: 182.8002 - lr: 0.0010 - 15s/epoch - 76ms/step
Epoch 40/1000
2023-10-05 11:35:35.172 
Epoch 40/1000 
	 loss: 182.3583, MinusLogProbMetric: 182.3583, val_loss: 182.7920, val_MinusLogProbMetric: 182.7920

Epoch 40: val_loss improved from 182.80023 to 182.79201, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 182.3583 - MinusLogProbMetric: 182.3583 - val_loss: 182.7920 - val_MinusLogProbMetric: 182.7920 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 41/1000
2023-10-05 11:35:50.184 
Epoch 41/1000 
	 loss: 182.3788, MinusLogProbMetric: 182.3788, val_loss: 183.5592, val_MinusLogProbMetric: 183.5592

Epoch 41: val_loss did not improve from 182.79201
196/196 - 14s - loss: 182.3788 - MinusLogProbMetric: 182.3788 - val_loss: 183.5592 - val_MinusLogProbMetric: 183.5592 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 42/1000
2023-10-05 11:36:04.785 
Epoch 42/1000 
	 loss: 182.2524, MinusLogProbMetric: 182.2524, val_loss: 183.7017, val_MinusLogProbMetric: 183.7017

Epoch 42: val_loss did not improve from 182.79201
196/196 - 15s - loss: 182.2524 - MinusLogProbMetric: 182.2524 - val_loss: 183.7017 - val_MinusLogProbMetric: 183.7017 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 43/1000
2023-10-05 11:36:19.314 
Epoch 43/1000 
	 loss: 182.6266, MinusLogProbMetric: 182.6266, val_loss: 182.8429, val_MinusLogProbMetric: 182.8429

Epoch 43: val_loss did not improve from 182.79201
196/196 - 15s - loss: 182.6266 - MinusLogProbMetric: 182.6266 - val_loss: 182.8429 - val_MinusLogProbMetric: 182.8429 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 44/1000
2023-10-05 11:36:33.921 
Epoch 44/1000 
	 loss: 182.2998, MinusLogProbMetric: 182.2998, val_loss: 183.2020, val_MinusLogProbMetric: 183.2020

Epoch 44: val_loss did not improve from 182.79201
196/196 - 15s - loss: 182.2998 - MinusLogProbMetric: 182.2998 - val_loss: 183.2020 - val_MinusLogProbMetric: 183.2020 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 45/1000
2023-10-05 11:36:48.412 
Epoch 45/1000 
	 loss: 182.1141, MinusLogProbMetric: 182.1141, val_loss: 182.6929, val_MinusLogProbMetric: 182.6929

Epoch 45: val_loss improved from 182.79201 to 182.69290, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 182.1141 - MinusLogProbMetric: 182.1141 - val_loss: 182.6929 - val_MinusLogProbMetric: 182.6929 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 46/1000
2023-10-05 11:37:03.303 
Epoch 46/1000 
	 loss: 182.3382, MinusLogProbMetric: 182.3382, val_loss: 182.7208, val_MinusLogProbMetric: 182.7208

Epoch 46: val_loss did not improve from 182.69290
196/196 - 15s - loss: 182.3382 - MinusLogProbMetric: 182.3382 - val_loss: 182.7208 - val_MinusLogProbMetric: 182.7208 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 47/1000
2023-10-05 11:37:17.709 
Epoch 47/1000 
	 loss: 181.9841, MinusLogProbMetric: 181.9841, val_loss: 183.5525, val_MinusLogProbMetric: 183.5525

Epoch 47: val_loss did not improve from 182.69290
196/196 - 14s - loss: 181.9841 - MinusLogProbMetric: 181.9841 - val_loss: 183.5525 - val_MinusLogProbMetric: 183.5525 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 48/1000
2023-10-05 11:37:32.115 
Epoch 48/1000 
	 loss: 182.1518, MinusLogProbMetric: 182.1518, val_loss: 182.4086, val_MinusLogProbMetric: 182.4086

Epoch 48: val_loss improved from 182.69290 to 182.40855, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 182.1518 - MinusLogProbMetric: 182.1518 - val_loss: 182.4086 - val_MinusLogProbMetric: 182.4086 - lr: 0.0010 - 15s/epoch - 76ms/step
Epoch 49/1000
2023-10-05 11:37:47.269 
Epoch 49/1000 
	 loss: 181.9451, MinusLogProbMetric: 181.9451, val_loss: 182.2061, val_MinusLogProbMetric: 182.2061

Epoch 49: val_loss improved from 182.40855 to 182.20605, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 181.9451 - MinusLogProbMetric: 181.9451 - val_loss: 182.2061 - val_MinusLogProbMetric: 182.2061 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 50/1000
2023-10-05 11:38:02.297 
Epoch 50/1000 
	 loss: 182.0294, MinusLogProbMetric: 182.0294, val_loss: 182.1326, val_MinusLogProbMetric: 182.1326

Epoch 50: val_loss improved from 182.20605 to 182.13264, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 182.0294 - MinusLogProbMetric: 182.0294 - val_loss: 182.1326 - val_MinusLogProbMetric: 182.1326 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 51/1000
2023-10-05 11:38:17.251 
Epoch 51/1000 
	 loss: 182.0351, MinusLogProbMetric: 182.0351, val_loss: 183.1406, val_MinusLogProbMetric: 183.1406

Epoch 51: val_loss did not improve from 182.13264
196/196 - 15s - loss: 182.0351 - MinusLogProbMetric: 182.0351 - val_loss: 183.1406 - val_MinusLogProbMetric: 183.1406 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 52/1000
2023-10-05 11:38:32.056 
Epoch 52/1000 
	 loss: 181.8323, MinusLogProbMetric: 181.8323, val_loss: 183.7728, val_MinusLogProbMetric: 183.7728

Epoch 52: val_loss did not improve from 182.13264
196/196 - 15s - loss: 181.8323 - MinusLogProbMetric: 181.8323 - val_loss: 183.7728 - val_MinusLogProbMetric: 183.7728 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 53/1000
2023-10-05 11:38:46.282 
Epoch 53/1000 
	 loss: 182.1817, MinusLogProbMetric: 182.1817, val_loss: 182.7861, val_MinusLogProbMetric: 182.7861

Epoch 53: val_loss did not improve from 182.13264
196/196 - 14s - loss: 182.1817 - MinusLogProbMetric: 182.1817 - val_loss: 182.7861 - val_MinusLogProbMetric: 182.7861 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 54/1000
2023-10-05 11:39:00.811 
Epoch 54/1000 
	 loss: 181.9134, MinusLogProbMetric: 181.9134, val_loss: 182.2927, val_MinusLogProbMetric: 182.2927

Epoch 54: val_loss did not improve from 182.13264
196/196 - 14s - loss: 181.9134 - MinusLogProbMetric: 181.9134 - val_loss: 182.2927 - val_MinusLogProbMetric: 182.2927 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 55/1000
2023-10-05 11:39:15.275 
Epoch 55/1000 
	 loss: 181.8086, MinusLogProbMetric: 181.8086, val_loss: 186.9625, val_MinusLogProbMetric: 186.9625

Epoch 55: val_loss did not improve from 182.13264
196/196 - 14s - loss: 181.8086 - MinusLogProbMetric: 181.8086 - val_loss: 186.9625 - val_MinusLogProbMetric: 186.9625 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 56/1000
2023-10-05 11:39:29.820 
Epoch 56/1000 
	 loss: 181.7327, MinusLogProbMetric: 181.7327, val_loss: 181.8357, val_MinusLogProbMetric: 181.8357

Epoch 56: val_loss improved from 182.13264 to 181.83574, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 181.7327 - MinusLogProbMetric: 181.7327 - val_loss: 181.8357 - val_MinusLogProbMetric: 181.8357 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 57/1000
2023-10-05 11:39:44.948 
Epoch 57/1000 
	 loss: 181.9007, MinusLogProbMetric: 181.9007, val_loss: 182.8186, val_MinusLogProbMetric: 182.8186

Epoch 57: val_loss did not improve from 181.83574
196/196 - 15s - loss: 181.9007 - MinusLogProbMetric: 181.9007 - val_loss: 182.8186 - val_MinusLogProbMetric: 182.8186 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 58/1000
2023-10-05 11:39:59.569 
Epoch 58/1000 
	 loss: 181.7668, MinusLogProbMetric: 181.7668, val_loss: 182.6079, val_MinusLogProbMetric: 182.6079

Epoch 58: val_loss did not improve from 181.83574
196/196 - 15s - loss: 181.7668 - MinusLogProbMetric: 181.7668 - val_loss: 182.6079 - val_MinusLogProbMetric: 182.6079 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 59/1000
2023-10-05 11:40:13.985 
Epoch 59/1000 
	 loss: 181.7365, MinusLogProbMetric: 181.7365, val_loss: 182.7900, val_MinusLogProbMetric: 182.7900

Epoch 59: val_loss did not improve from 181.83574
196/196 - 14s - loss: 181.7365 - MinusLogProbMetric: 181.7365 - val_loss: 182.7900 - val_MinusLogProbMetric: 182.7900 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 60/1000
2023-10-05 11:40:28.444 
Epoch 60/1000 
	 loss: 181.6477, MinusLogProbMetric: 181.6477, val_loss: 181.9617, val_MinusLogProbMetric: 181.9617

Epoch 60: val_loss did not improve from 181.83574
196/196 - 15s - loss: 181.6477 - MinusLogProbMetric: 181.6477 - val_loss: 181.9617 - val_MinusLogProbMetric: 181.9617 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 61/1000
2023-10-05 11:40:42.823 
Epoch 61/1000 
	 loss: 181.6134, MinusLogProbMetric: 181.6134, val_loss: 184.1679, val_MinusLogProbMetric: 184.1679

Epoch 61: val_loss did not improve from 181.83574
196/196 - 14s - loss: 181.6134 - MinusLogProbMetric: 181.6134 - val_loss: 184.1679 - val_MinusLogProbMetric: 184.1679 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 62/1000
2023-10-05 11:40:57.406 
Epoch 62/1000 
	 loss: 181.4857, MinusLogProbMetric: 181.4857, val_loss: 182.0748, val_MinusLogProbMetric: 182.0748

Epoch 62: val_loss did not improve from 181.83574
196/196 - 15s - loss: 181.4857 - MinusLogProbMetric: 181.4857 - val_loss: 182.0748 - val_MinusLogProbMetric: 182.0748 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 63/1000
2023-10-05 11:41:11.980 
Epoch 63/1000 
	 loss: 181.5802, MinusLogProbMetric: 181.5802, val_loss: 182.1648, val_MinusLogProbMetric: 182.1648

Epoch 63: val_loss did not improve from 181.83574
196/196 - 15s - loss: 181.5802 - MinusLogProbMetric: 181.5802 - val_loss: 182.1648 - val_MinusLogProbMetric: 182.1648 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 64/1000
2023-10-05 11:41:26.447 
Epoch 64/1000 
	 loss: 181.5105, MinusLogProbMetric: 181.5105, val_loss: 181.8245, val_MinusLogProbMetric: 181.8245

Epoch 64: val_loss improved from 181.83574 to 181.82452, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 181.5105 - MinusLogProbMetric: 181.5105 - val_loss: 181.8245 - val_MinusLogProbMetric: 181.8245 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 65/1000
2023-10-05 11:41:41.038 
Epoch 65/1000 
	 loss: 181.5968, MinusLogProbMetric: 181.5968, val_loss: 182.0583, val_MinusLogProbMetric: 182.0583

Epoch 65: val_loss did not improve from 181.82452
196/196 - 14s - loss: 181.5968 - MinusLogProbMetric: 181.5968 - val_loss: 182.0583 - val_MinusLogProbMetric: 182.0583 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 66/1000
2023-10-05 11:41:55.510 
Epoch 66/1000 
	 loss: 181.6271, MinusLogProbMetric: 181.6271, val_loss: 182.2228, val_MinusLogProbMetric: 182.2228

Epoch 66: val_loss did not improve from 181.82452
196/196 - 14s - loss: 181.6271 - MinusLogProbMetric: 181.6271 - val_loss: 182.2228 - val_MinusLogProbMetric: 182.2228 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 67/1000
2023-10-05 11:42:09.956 
Epoch 67/1000 
	 loss: 181.3820, MinusLogProbMetric: 181.3820, val_loss: 181.7011, val_MinusLogProbMetric: 181.7011

Epoch 67: val_loss improved from 181.82452 to 181.70111, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 181.3820 - MinusLogProbMetric: 181.3820 - val_loss: 181.7011 - val_MinusLogProbMetric: 181.7011 - lr: 0.0010 - 15s/epoch - 76ms/step
Epoch 68/1000
2023-10-05 11:42:24.875 
Epoch 68/1000 
	 loss: 181.4311, MinusLogProbMetric: 181.4311, val_loss: 182.0572, val_MinusLogProbMetric: 182.0572

Epoch 68: val_loss did not improve from 181.70111
196/196 - 15s - loss: 181.4311 - MinusLogProbMetric: 181.4311 - val_loss: 182.0572 - val_MinusLogProbMetric: 182.0572 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 69/1000
2023-10-05 11:42:39.490 
Epoch 69/1000 
	 loss: 181.3970, MinusLogProbMetric: 181.3970, val_loss: 181.5293, val_MinusLogProbMetric: 181.5293

Epoch 69: val_loss improved from 181.70111 to 181.52934, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 181.3970 - MinusLogProbMetric: 181.3970 - val_loss: 181.5293 - val_MinusLogProbMetric: 181.5293 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 70/1000
2023-10-05 11:42:54.560 
Epoch 70/1000 
	 loss: 181.4655, MinusLogProbMetric: 181.4655, val_loss: 182.2035, val_MinusLogProbMetric: 182.2035

Epoch 70: val_loss did not improve from 181.52934
196/196 - 15s - loss: 181.4655 - MinusLogProbMetric: 181.4655 - val_loss: 182.2035 - val_MinusLogProbMetric: 182.2035 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 71/1000
2023-10-05 11:43:08.994 
Epoch 71/1000 
	 loss: 181.4329, MinusLogProbMetric: 181.4329, val_loss: 182.1251, val_MinusLogProbMetric: 182.1251

Epoch 71: val_loss did not improve from 181.52934
196/196 - 14s - loss: 181.4329 - MinusLogProbMetric: 181.4329 - val_loss: 182.1251 - val_MinusLogProbMetric: 182.1251 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 72/1000
2023-10-05 11:43:23.225 
Epoch 72/1000 
	 loss: 181.1862, MinusLogProbMetric: 181.1862, val_loss: 181.8470, val_MinusLogProbMetric: 181.8470

Epoch 72: val_loss did not improve from 181.52934
196/196 - 14s - loss: 181.1862 - MinusLogProbMetric: 181.1862 - val_loss: 181.8470 - val_MinusLogProbMetric: 181.8470 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 73/1000
2023-10-05 11:43:37.636 
Epoch 73/1000 
	 loss: 181.4096, MinusLogProbMetric: 181.4096, val_loss: 181.8324, val_MinusLogProbMetric: 181.8324

Epoch 73: val_loss did not improve from 181.52934
196/196 - 14s - loss: 181.4096 - MinusLogProbMetric: 181.4096 - val_loss: 181.8324 - val_MinusLogProbMetric: 181.8324 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 74/1000
2023-10-05 11:43:52.126 
Epoch 74/1000 
	 loss: 181.2925, MinusLogProbMetric: 181.2925, val_loss: 182.5255, val_MinusLogProbMetric: 182.5255

Epoch 74: val_loss did not improve from 181.52934
196/196 - 14s - loss: 181.2925 - MinusLogProbMetric: 181.2925 - val_loss: 182.5255 - val_MinusLogProbMetric: 182.5255 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 75/1000
2023-10-05 11:44:06.666 
Epoch 75/1000 
	 loss: 181.2823, MinusLogProbMetric: 181.2823, val_loss: 182.0788, val_MinusLogProbMetric: 182.0788

Epoch 75: val_loss did not improve from 181.52934
196/196 - 15s - loss: 181.2823 - MinusLogProbMetric: 181.2823 - val_loss: 182.0788 - val_MinusLogProbMetric: 182.0788 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 76/1000
2023-10-05 11:44:21.209 
Epoch 76/1000 
	 loss: 181.3352, MinusLogProbMetric: 181.3352, val_loss: 181.6292, val_MinusLogProbMetric: 181.6292

Epoch 76: val_loss did not improve from 181.52934
196/196 - 15s - loss: 181.3352 - MinusLogProbMetric: 181.3352 - val_loss: 181.6292 - val_MinusLogProbMetric: 181.6292 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 77/1000
2023-10-05 11:44:35.721 
Epoch 77/1000 
	 loss: 181.1704, MinusLogProbMetric: 181.1704, val_loss: 181.6915, val_MinusLogProbMetric: 181.6915

Epoch 77: val_loss did not improve from 181.52934
196/196 - 15s - loss: 181.1704 - MinusLogProbMetric: 181.1704 - val_loss: 181.6915 - val_MinusLogProbMetric: 181.6915 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 78/1000
2023-10-05 11:44:50.215 
Epoch 78/1000 
	 loss: 181.2457, MinusLogProbMetric: 181.2457, val_loss: 181.7507, val_MinusLogProbMetric: 181.7507

Epoch 78: val_loss did not improve from 181.52934
196/196 - 14s - loss: 181.2457 - MinusLogProbMetric: 181.2457 - val_loss: 181.7507 - val_MinusLogProbMetric: 181.7507 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 79/1000
2023-10-05 11:45:04.734 
Epoch 79/1000 
	 loss: 181.4145, MinusLogProbMetric: 181.4145, val_loss: 181.6435, val_MinusLogProbMetric: 181.6435

Epoch 79: val_loss did not improve from 181.52934
196/196 - 15s - loss: 181.4145 - MinusLogProbMetric: 181.4145 - val_loss: 181.6435 - val_MinusLogProbMetric: 181.6435 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 80/1000
2023-10-05 11:45:18.923 
Epoch 80/1000 
	 loss: 181.0226, MinusLogProbMetric: 181.0226, val_loss: 183.4232, val_MinusLogProbMetric: 183.4232

Epoch 80: val_loss did not improve from 181.52934
196/196 - 14s - loss: 181.0226 - MinusLogProbMetric: 181.0226 - val_loss: 183.4232 - val_MinusLogProbMetric: 183.4232 - lr: 0.0010 - 14s/epoch - 72ms/step
Epoch 81/1000
2023-10-05 11:45:33.734 
Epoch 81/1000 
	 loss: 181.2537, MinusLogProbMetric: 181.2537, val_loss: 181.5454, val_MinusLogProbMetric: 181.5454

Epoch 81: val_loss did not improve from 181.52934
196/196 - 15s - loss: 181.2537 - MinusLogProbMetric: 181.2537 - val_loss: 181.5454 - val_MinusLogProbMetric: 181.5454 - lr: 0.0010 - 15s/epoch - 76ms/step
Epoch 82/1000
2023-10-05 11:45:48.165 
Epoch 82/1000 
	 loss: 181.0197, MinusLogProbMetric: 181.0197, val_loss: 182.2171, val_MinusLogProbMetric: 182.2171

Epoch 82: val_loss did not improve from 181.52934
196/196 - 14s - loss: 181.0197 - MinusLogProbMetric: 181.0197 - val_loss: 182.2171 - val_MinusLogProbMetric: 182.2171 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 83/1000
2023-10-05 11:46:02.632 
Epoch 83/1000 
	 loss: 180.9963, MinusLogProbMetric: 180.9963, val_loss: 181.4192, val_MinusLogProbMetric: 181.4192

Epoch 83: val_loss improved from 181.52934 to 181.41917, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 180.9963 - MinusLogProbMetric: 180.9963 - val_loss: 181.4192 - val_MinusLogProbMetric: 181.4192 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 84/1000
2023-10-05 11:46:17.316 
Epoch 84/1000 
	 loss: 181.0531, MinusLogProbMetric: 181.0531, val_loss: 181.9759, val_MinusLogProbMetric: 181.9759

Epoch 84: val_loss did not improve from 181.41917
196/196 - 14s - loss: 181.0531 - MinusLogProbMetric: 181.0531 - val_loss: 181.9759 - val_MinusLogProbMetric: 181.9759 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 85/1000
2023-10-05 11:46:31.636 
Epoch 85/1000 
	 loss: 181.0162, MinusLogProbMetric: 181.0162, val_loss: 183.4910, val_MinusLogProbMetric: 183.4910

Epoch 85: val_loss did not improve from 181.41917
196/196 - 14s - loss: 181.0162 - MinusLogProbMetric: 181.0162 - val_loss: 183.4910 - val_MinusLogProbMetric: 183.4910 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 86/1000
2023-10-05 11:46:45.917 
Epoch 86/1000 
	 loss: 181.2708, MinusLogProbMetric: 181.2708, val_loss: 182.5608, val_MinusLogProbMetric: 182.5608

Epoch 86: val_loss did not improve from 181.41917
196/196 - 14s - loss: 181.2708 - MinusLogProbMetric: 181.2708 - val_loss: 182.5608 - val_MinusLogProbMetric: 182.5608 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 87/1000
2023-10-05 11:47:00.377 
Epoch 87/1000 
	 loss: 180.9747, MinusLogProbMetric: 180.9747, val_loss: 181.5707, val_MinusLogProbMetric: 181.5707

Epoch 87: val_loss did not improve from 181.41917
196/196 - 14s - loss: 180.9747 - MinusLogProbMetric: 180.9747 - val_loss: 181.5707 - val_MinusLogProbMetric: 181.5707 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 88/1000
2023-10-05 11:47:14.904 
Epoch 88/1000 
	 loss: 180.9415, MinusLogProbMetric: 180.9415, val_loss: 181.8965, val_MinusLogProbMetric: 181.8965

Epoch 88: val_loss did not improve from 181.41917
196/196 - 15s - loss: 180.9415 - MinusLogProbMetric: 180.9415 - val_loss: 181.8965 - val_MinusLogProbMetric: 181.8965 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 89/1000
2023-10-05 11:47:29.390 
Epoch 89/1000 
	 loss: 181.2593, MinusLogProbMetric: 181.2593, val_loss: 181.3928, val_MinusLogProbMetric: 181.3928

Epoch 89: val_loss improved from 181.41917 to 181.39282, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 181.2593 - MinusLogProbMetric: 181.2593 - val_loss: 181.3928 - val_MinusLogProbMetric: 181.3928 - lr: 0.0010 - 15s/epoch - 76ms/step
Epoch 90/1000
2023-10-05 11:47:44.362 
Epoch 90/1000 
	 loss: 181.0128, MinusLogProbMetric: 181.0128, val_loss: 181.5264, val_MinusLogProbMetric: 181.5264

Epoch 90: val_loss did not improve from 181.39282
196/196 - 15s - loss: 181.0128 - MinusLogProbMetric: 181.0128 - val_loss: 181.5264 - val_MinusLogProbMetric: 181.5264 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 91/1000
2023-10-05 11:47:58.851 
Epoch 91/1000 
	 loss: 181.0032, MinusLogProbMetric: 181.0032, val_loss: 181.6864, val_MinusLogProbMetric: 181.6864

Epoch 91: val_loss did not improve from 181.39282
196/196 - 14s - loss: 181.0032 - MinusLogProbMetric: 181.0032 - val_loss: 181.6864 - val_MinusLogProbMetric: 181.6864 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 92/1000
2023-10-05 11:48:13.234 
Epoch 92/1000 
	 loss: 180.8419, MinusLogProbMetric: 180.8419, val_loss: 181.2852, val_MinusLogProbMetric: 181.2852

Epoch 92: val_loss improved from 181.39282 to 181.28516, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 180.8419 - MinusLogProbMetric: 180.8419 - val_loss: 181.2852 - val_MinusLogProbMetric: 181.2852 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 93/1000
2023-10-05 11:48:28.044 
Epoch 93/1000 
	 loss: 180.9387, MinusLogProbMetric: 180.9387, val_loss: 181.4433, val_MinusLogProbMetric: 181.4433

Epoch 93: val_loss did not improve from 181.28516
196/196 - 14s - loss: 180.9387 - MinusLogProbMetric: 180.9387 - val_loss: 181.4433 - val_MinusLogProbMetric: 181.4433 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 94/1000
2023-10-05 11:48:42.388 
Epoch 94/1000 
	 loss: 180.8098, MinusLogProbMetric: 180.8098, val_loss: 181.3738, val_MinusLogProbMetric: 181.3738

Epoch 94: val_loss did not improve from 181.28516
196/196 - 14s - loss: 180.8098 - MinusLogProbMetric: 180.8098 - val_loss: 181.3738 - val_MinusLogProbMetric: 181.3738 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 95/1000
2023-10-05 11:48:56.776 
Epoch 95/1000 
	 loss: 180.8201, MinusLogProbMetric: 180.8201, val_loss: 182.7789, val_MinusLogProbMetric: 182.7789

Epoch 95: val_loss did not improve from 181.28516
196/196 - 14s - loss: 180.8201 - MinusLogProbMetric: 180.8201 - val_loss: 182.7789 - val_MinusLogProbMetric: 182.7789 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 96/1000
2023-10-05 11:49:11.075 
Epoch 96/1000 
	 loss: 180.9378, MinusLogProbMetric: 180.9378, val_loss: 183.2514, val_MinusLogProbMetric: 183.2514

Epoch 96: val_loss did not improve from 181.28516
196/196 - 14s - loss: 180.9378 - MinusLogProbMetric: 180.9378 - val_loss: 183.2514 - val_MinusLogProbMetric: 183.2514 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 97/1000
2023-10-05 11:49:25.476 
Epoch 97/1000 
	 loss: 181.2996, MinusLogProbMetric: 181.2996, val_loss: 181.5056, val_MinusLogProbMetric: 181.5056

Epoch 97: val_loss did not improve from 181.28516
196/196 - 14s - loss: 181.2996 - MinusLogProbMetric: 181.2996 - val_loss: 181.5056 - val_MinusLogProbMetric: 181.5056 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 98/1000
2023-10-05 11:49:40.347 
Epoch 98/1000 
	 loss: 180.7402, MinusLogProbMetric: 180.7402, val_loss: 181.4071, val_MinusLogProbMetric: 181.4071

Epoch 98: val_loss did not improve from 181.28516
196/196 - 15s - loss: 180.7402 - MinusLogProbMetric: 180.7402 - val_loss: 181.4071 - val_MinusLogProbMetric: 181.4071 - lr: 0.0010 - 15s/epoch - 76ms/step
Epoch 99/1000
2023-10-05 11:49:54.764 
Epoch 99/1000 
	 loss: 180.8335, MinusLogProbMetric: 180.8335, val_loss: 181.8461, val_MinusLogProbMetric: 181.8461

Epoch 99: val_loss did not improve from 181.28516
196/196 - 14s - loss: 180.8335 - MinusLogProbMetric: 180.8335 - val_loss: 181.8461 - val_MinusLogProbMetric: 181.8461 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 100/1000
2023-10-05 11:50:09.376 
Epoch 100/1000 
	 loss: 180.7105, MinusLogProbMetric: 180.7105, val_loss: 181.8732, val_MinusLogProbMetric: 181.8732

Epoch 100: val_loss did not improve from 181.28516
196/196 - 15s - loss: 180.7105 - MinusLogProbMetric: 180.7105 - val_loss: 181.8732 - val_MinusLogProbMetric: 181.8732 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 101/1000
2023-10-05 11:50:23.762 
Epoch 101/1000 
	 loss: 181.0099, MinusLogProbMetric: 181.0099, val_loss: 183.3564, val_MinusLogProbMetric: 183.3564

Epoch 101: val_loss did not improve from 181.28516
196/196 - 14s - loss: 181.0099 - MinusLogProbMetric: 181.0099 - val_loss: 183.3564 - val_MinusLogProbMetric: 183.3564 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 102/1000
2023-10-05 11:50:38.197 
Epoch 102/1000 
	 loss: 180.8378, MinusLogProbMetric: 180.8378, val_loss: 181.4408, val_MinusLogProbMetric: 181.4408

Epoch 102: val_loss did not improve from 181.28516
196/196 - 14s - loss: 180.8378 - MinusLogProbMetric: 180.8378 - val_loss: 181.4408 - val_MinusLogProbMetric: 181.4408 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 103/1000
2023-10-05 11:50:52.519 
Epoch 103/1000 
	 loss: 180.6805, MinusLogProbMetric: 180.6805, val_loss: 181.7834, val_MinusLogProbMetric: 181.7834

Epoch 103: val_loss did not improve from 181.28516
196/196 - 14s - loss: 180.6805 - MinusLogProbMetric: 180.6805 - val_loss: 181.7834 - val_MinusLogProbMetric: 181.7834 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 104/1000
2023-10-05 11:51:07.014 
Epoch 104/1000 
	 loss: 180.6505, MinusLogProbMetric: 180.6505, val_loss: 181.4213, val_MinusLogProbMetric: 181.4213

Epoch 104: val_loss did not improve from 181.28516
196/196 - 14s - loss: 180.6505 - MinusLogProbMetric: 180.6505 - val_loss: 181.4213 - val_MinusLogProbMetric: 181.4213 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 105/1000
2023-10-05 11:51:21.444 
Epoch 105/1000 
	 loss: 180.8761, MinusLogProbMetric: 180.8761, val_loss: 182.0511, val_MinusLogProbMetric: 182.0511

Epoch 105: val_loss did not improve from 181.28516
196/196 - 14s - loss: 180.8761 - MinusLogProbMetric: 180.8761 - val_loss: 182.0511 - val_MinusLogProbMetric: 182.0511 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 106/1000
2023-10-05 11:51:36.013 
Epoch 106/1000 
	 loss: 180.7595, MinusLogProbMetric: 180.7595, val_loss: 181.8552, val_MinusLogProbMetric: 181.8552

Epoch 106: val_loss did not improve from 181.28516
196/196 - 15s - loss: 180.7595 - MinusLogProbMetric: 180.7595 - val_loss: 181.8552 - val_MinusLogProbMetric: 181.8552 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 107/1000
2023-10-05 11:51:50.504 
Epoch 107/1000 
	 loss: 180.7972, MinusLogProbMetric: 180.7972, val_loss: 181.7578, val_MinusLogProbMetric: 181.7578

Epoch 107: val_loss did not improve from 181.28516
196/196 - 14s - loss: 180.7972 - MinusLogProbMetric: 180.7972 - val_loss: 181.7578 - val_MinusLogProbMetric: 181.7578 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 108/1000
2023-10-05 11:52:05.035 
Epoch 108/1000 
	 loss: 180.5938, MinusLogProbMetric: 180.5938, val_loss: 181.3151, val_MinusLogProbMetric: 181.3151

Epoch 108: val_loss did not improve from 181.28516
196/196 - 15s - loss: 180.5938 - MinusLogProbMetric: 180.5938 - val_loss: 181.3151 - val_MinusLogProbMetric: 181.3151 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 109/1000
2023-10-05 11:52:19.624 
Epoch 109/1000 
	 loss: 180.8737, MinusLogProbMetric: 180.8737, val_loss: 181.9511, val_MinusLogProbMetric: 181.9511

Epoch 109: val_loss did not improve from 181.28516
196/196 - 15s - loss: 180.8737 - MinusLogProbMetric: 180.8737 - val_loss: 181.9511 - val_MinusLogProbMetric: 181.9511 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 110/1000
2023-10-05 11:52:34.170 
Epoch 110/1000 
	 loss: 180.7501, MinusLogProbMetric: 180.7501, val_loss: 181.6780, val_MinusLogProbMetric: 181.6780

Epoch 110: val_loss did not improve from 181.28516
196/196 - 15s - loss: 180.7501 - MinusLogProbMetric: 180.7501 - val_loss: 181.6780 - val_MinusLogProbMetric: 181.6780 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 111/1000
2023-10-05 11:52:48.596 
Epoch 111/1000 
	 loss: 180.6204, MinusLogProbMetric: 180.6204, val_loss: 181.6606, val_MinusLogProbMetric: 181.6606

Epoch 111: val_loss did not improve from 181.28516
196/196 - 14s - loss: 180.6204 - MinusLogProbMetric: 180.6204 - val_loss: 181.6606 - val_MinusLogProbMetric: 181.6606 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 112/1000
2023-10-05 11:53:03.158 
Epoch 112/1000 
	 loss: 180.7080, MinusLogProbMetric: 180.7080, val_loss: 189.9543, val_MinusLogProbMetric: 189.9543

Epoch 112: val_loss did not improve from 181.28516
196/196 - 15s - loss: 180.7080 - MinusLogProbMetric: 180.7080 - val_loss: 189.9543 - val_MinusLogProbMetric: 189.9543 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 113/1000
2023-10-05 11:53:17.670 
Epoch 113/1000 
	 loss: 181.0633, MinusLogProbMetric: 181.0633, val_loss: 181.4586, val_MinusLogProbMetric: 181.4586

Epoch 113: val_loss did not improve from 181.28516
196/196 - 15s - loss: 181.0633 - MinusLogProbMetric: 181.0633 - val_loss: 181.4586 - val_MinusLogProbMetric: 181.4586 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 114/1000
2023-10-05 11:53:32.157 
Epoch 114/1000 
	 loss: 180.6376, MinusLogProbMetric: 180.6376, val_loss: 181.4664, val_MinusLogProbMetric: 181.4664

Epoch 114: val_loss did not improve from 181.28516
196/196 - 14s - loss: 180.6376 - MinusLogProbMetric: 180.6376 - val_loss: 181.4664 - val_MinusLogProbMetric: 181.4664 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 115/1000
2023-10-05 11:53:46.728 
Epoch 115/1000 
	 loss: 180.6824, MinusLogProbMetric: 180.6824, val_loss: 181.3239, val_MinusLogProbMetric: 181.3239

Epoch 115: val_loss did not improve from 181.28516
196/196 - 15s - loss: 180.6824 - MinusLogProbMetric: 180.6824 - val_loss: 181.3239 - val_MinusLogProbMetric: 181.3239 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 116/1000
2023-10-05 11:54:01.299 
Epoch 116/1000 
	 loss: 180.7388, MinusLogProbMetric: 180.7388, val_loss: 181.7638, val_MinusLogProbMetric: 181.7638

Epoch 116: val_loss did not improve from 181.28516
196/196 - 15s - loss: 180.7388 - MinusLogProbMetric: 180.7388 - val_loss: 181.7638 - val_MinusLogProbMetric: 181.7638 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 117/1000
2023-10-05 11:54:15.784 
Epoch 117/1000 
	 loss: 180.6037, MinusLogProbMetric: 180.6037, val_loss: 181.5081, val_MinusLogProbMetric: 181.5081

Epoch 117: val_loss did not improve from 181.28516
196/196 - 14s - loss: 180.6037 - MinusLogProbMetric: 180.6037 - val_loss: 181.5081 - val_MinusLogProbMetric: 181.5081 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 118/1000
2023-10-05 11:54:30.263 
Epoch 118/1000 
	 loss: 180.5250, MinusLogProbMetric: 180.5250, val_loss: 182.1002, val_MinusLogProbMetric: 182.1002

Epoch 118: val_loss did not improve from 181.28516
196/196 - 14s - loss: 180.5250 - MinusLogProbMetric: 180.5250 - val_loss: 182.1002 - val_MinusLogProbMetric: 182.1002 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 119/1000
2023-10-05 11:54:44.780 
Epoch 119/1000 
	 loss: 180.5548, MinusLogProbMetric: 180.5548, val_loss: 183.3057, val_MinusLogProbMetric: 183.3057

Epoch 119: val_loss did not improve from 181.28516
196/196 - 15s - loss: 180.5548 - MinusLogProbMetric: 180.5548 - val_loss: 183.3057 - val_MinusLogProbMetric: 183.3057 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 120/1000
2023-10-05 11:54:59.299 
Epoch 120/1000 
	 loss: 180.6298, MinusLogProbMetric: 180.6298, val_loss: 181.3549, val_MinusLogProbMetric: 181.3549

Epoch 120: val_loss did not improve from 181.28516
196/196 - 15s - loss: 180.6298 - MinusLogProbMetric: 180.6298 - val_loss: 181.3549 - val_MinusLogProbMetric: 181.3549 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 121/1000
2023-10-05 11:55:13.581 
Epoch 121/1000 
	 loss: 180.5222, MinusLogProbMetric: 180.5222, val_loss: 181.2737, val_MinusLogProbMetric: 181.2737

Epoch 121: val_loss improved from 181.28516 to 181.27367, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 180.5222 - MinusLogProbMetric: 180.5222 - val_loss: 181.2737 - val_MinusLogProbMetric: 181.2737 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 122/1000
2023-10-05 11:55:28.585 
Epoch 122/1000 
	 loss: 180.5410, MinusLogProbMetric: 180.5410, val_loss: 181.5214, val_MinusLogProbMetric: 181.5214

Epoch 122: val_loss did not improve from 181.27367
196/196 - 14s - loss: 180.5410 - MinusLogProbMetric: 180.5410 - val_loss: 181.5214 - val_MinusLogProbMetric: 181.5214 - lr: 0.0010 - 14s/epoch - 72ms/step
Epoch 123/1000
2023-10-05 11:55:42.889 
Epoch 123/1000 
	 loss: 180.4901, MinusLogProbMetric: 180.4901, val_loss: 181.4524, val_MinusLogProbMetric: 181.4524

Epoch 123: val_loss did not improve from 181.27367
196/196 - 14s - loss: 180.4901 - MinusLogProbMetric: 180.4901 - val_loss: 181.4524 - val_MinusLogProbMetric: 181.4524 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 124/1000
2023-10-05 11:55:57.327 
Epoch 124/1000 
	 loss: 180.5279, MinusLogProbMetric: 180.5279, val_loss: 181.6595, val_MinusLogProbMetric: 181.6595

Epoch 124: val_loss did not improve from 181.27367
196/196 - 14s - loss: 180.5279 - MinusLogProbMetric: 180.5279 - val_loss: 181.6595 - val_MinusLogProbMetric: 181.6595 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 125/1000
2023-10-05 11:56:11.882 
Epoch 125/1000 
	 loss: 180.6271, MinusLogProbMetric: 180.6271, val_loss: 181.5184, val_MinusLogProbMetric: 181.5184

Epoch 125: val_loss did not improve from 181.27367
196/196 - 15s - loss: 180.6271 - MinusLogProbMetric: 180.6271 - val_loss: 181.5184 - val_MinusLogProbMetric: 181.5184 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 126/1000
2023-10-05 11:56:26.323 
Epoch 126/1000 
	 loss: 180.9276, MinusLogProbMetric: 180.9276, val_loss: 181.3368, val_MinusLogProbMetric: 181.3368

Epoch 126: val_loss did not improve from 181.27367
196/196 - 14s - loss: 180.9276 - MinusLogProbMetric: 180.9276 - val_loss: 181.3368 - val_MinusLogProbMetric: 181.3368 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 127/1000
2023-10-05 11:56:40.716 
Epoch 127/1000 
	 loss: 180.3215, MinusLogProbMetric: 180.3215, val_loss: 181.3598, val_MinusLogProbMetric: 181.3598

Epoch 127: val_loss did not improve from 181.27367
196/196 - 14s - loss: 180.3215 - MinusLogProbMetric: 180.3215 - val_loss: 181.3598 - val_MinusLogProbMetric: 181.3598 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 128/1000
2023-10-05 11:56:55.338 
Epoch 128/1000 
	 loss: 180.6494, MinusLogProbMetric: 180.6494, val_loss: 181.4600, val_MinusLogProbMetric: 181.4600

Epoch 128: val_loss did not improve from 181.27367
196/196 - 15s - loss: 180.6494 - MinusLogProbMetric: 180.6494 - val_loss: 181.4600 - val_MinusLogProbMetric: 181.4600 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 129/1000
2023-10-05 11:57:09.847 
Epoch 129/1000 
	 loss: 180.3909, MinusLogProbMetric: 180.3909, val_loss: 182.2372, val_MinusLogProbMetric: 182.2372

Epoch 129: val_loss did not improve from 181.27367
196/196 - 15s - loss: 180.3909 - MinusLogProbMetric: 180.3909 - val_loss: 182.2372 - val_MinusLogProbMetric: 182.2372 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 130/1000
2023-10-05 11:57:24.452 
Epoch 130/1000 
	 loss: 180.4188, MinusLogProbMetric: 180.4188, val_loss: 181.2755, val_MinusLogProbMetric: 181.2755

Epoch 130: val_loss did not improve from 181.27367
196/196 - 15s - loss: 180.4188 - MinusLogProbMetric: 180.4188 - val_loss: 181.2755 - val_MinusLogProbMetric: 181.2755 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 131/1000
2023-10-05 11:57:38.657 
Epoch 131/1000 
	 loss: 180.5081, MinusLogProbMetric: 180.5081, val_loss: 181.6954, val_MinusLogProbMetric: 181.6954

Epoch 131: val_loss did not improve from 181.27367
196/196 - 14s - loss: 180.5081 - MinusLogProbMetric: 180.5081 - val_loss: 181.6954 - val_MinusLogProbMetric: 181.6954 - lr: 0.0010 - 14s/epoch - 72ms/step
Epoch 132/1000
2023-10-05 11:57:53.077 
Epoch 132/1000 
	 loss: 180.5000, MinusLogProbMetric: 180.5000, val_loss: 181.2116, val_MinusLogProbMetric: 181.2116

Epoch 132: val_loss improved from 181.27367 to 181.21164, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 180.5000 - MinusLogProbMetric: 180.5000 - val_loss: 181.2116 - val_MinusLogProbMetric: 181.2116 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 133/1000
2023-10-05 11:58:07.800 
Epoch 133/1000 
	 loss: 180.2998, MinusLogProbMetric: 180.2998, val_loss: 182.1443, val_MinusLogProbMetric: 182.1443

Epoch 133: val_loss did not improve from 181.21164
196/196 - 14s - loss: 180.2998 - MinusLogProbMetric: 180.2998 - val_loss: 182.1443 - val_MinusLogProbMetric: 182.1443 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 134/1000
2023-10-05 11:58:21.912 
Epoch 134/1000 
	 loss: 180.4633, MinusLogProbMetric: 180.4633, val_loss: 181.3637, val_MinusLogProbMetric: 181.3637

Epoch 134: val_loss did not improve from 181.21164
196/196 - 14s - loss: 180.4633 - MinusLogProbMetric: 180.4633 - val_loss: 181.3637 - val_MinusLogProbMetric: 181.3637 - lr: 0.0010 - 14s/epoch - 72ms/step
Epoch 135/1000
2023-10-05 11:58:36.158 
Epoch 135/1000 
	 loss: 180.4495, MinusLogProbMetric: 180.4495, val_loss: 181.2183, val_MinusLogProbMetric: 181.2183

Epoch 135: val_loss did not improve from 181.21164
196/196 - 14s - loss: 180.4495 - MinusLogProbMetric: 180.4495 - val_loss: 181.2183 - val_MinusLogProbMetric: 181.2183 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 136/1000
2023-10-05 11:58:50.527 
Epoch 136/1000 
	 loss: 180.3004, MinusLogProbMetric: 180.3004, val_loss: 183.2092, val_MinusLogProbMetric: 183.2092

Epoch 136: val_loss did not improve from 181.21164
196/196 - 14s - loss: 180.3004 - MinusLogProbMetric: 180.3004 - val_loss: 183.2092 - val_MinusLogProbMetric: 183.2092 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 137/1000
2023-10-05 11:59:04.915 
Epoch 137/1000 
	 loss: 180.3337, MinusLogProbMetric: 180.3337, val_loss: 181.0001, val_MinusLogProbMetric: 181.0001

Epoch 137: val_loss improved from 181.21164 to 181.00006, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 180.3337 - MinusLogProbMetric: 180.3337 - val_loss: 181.0001 - val_MinusLogProbMetric: 181.0001 - lr: 0.0010 - 15s/epoch - 76ms/step
Epoch 138/1000
2023-10-05 11:59:19.809 
Epoch 138/1000 
	 loss: 180.4080, MinusLogProbMetric: 180.4080, val_loss: 181.1661, val_MinusLogProbMetric: 181.1661

Epoch 138: val_loss did not improve from 181.00006
196/196 - 14s - loss: 180.4080 - MinusLogProbMetric: 180.4080 - val_loss: 181.1661 - val_MinusLogProbMetric: 181.1661 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 139/1000
2023-10-05 11:59:34.364 
Epoch 139/1000 
	 loss: 180.8851, MinusLogProbMetric: 180.8851, val_loss: 181.4255, val_MinusLogProbMetric: 181.4255

Epoch 139: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.8851 - MinusLogProbMetric: 180.8851 - val_loss: 181.4255 - val_MinusLogProbMetric: 181.4255 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 140/1000
2023-10-05 11:59:48.840 
Epoch 140/1000 
	 loss: 180.4173, MinusLogProbMetric: 180.4173, val_loss: 181.4690, val_MinusLogProbMetric: 181.4690

Epoch 140: val_loss did not improve from 181.00006
196/196 - 14s - loss: 180.4173 - MinusLogProbMetric: 180.4173 - val_loss: 181.4690 - val_MinusLogProbMetric: 181.4690 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 141/1000
2023-10-05 12:00:03.270 
Epoch 141/1000 
	 loss: 180.3090, MinusLogProbMetric: 180.3090, val_loss: 181.3072, val_MinusLogProbMetric: 181.3072

Epoch 141: val_loss did not improve from 181.00006
196/196 - 14s - loss: 180.3090 - MinusLogProbMetric: 180.3090 - val_loss: 181.3072 - val_MinusLogProbMetric: 181.3072 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 142/1000
2023-10-05 12:00:17.752 
Epoch 142/1000 
	 loss: 180.4612, MinusLogProbMetric: 180.4612, val_loss: 181.5377, val_MinusLogProbMetric: 181.5377

Epoch 142: val_loss did not improve from 181.00006
196/196 - 14s - loss: 180.4612 - MinusLogProbMetric: 180.4612 - val_loss: 181.5377 - val_MinusLogProbMetric: 181.5377 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 143/1000
2023-10-05 12:00:32.148 
Epoch 143/1000 
	 loss: 180.3105, MinusLogProbMetric: 180.3105, val_loss: 181.2687, val_MinusLogProbMetric: 181.2687

Epoch 143: val_loss did not improve from 181.00006
196/196 - 14s - loss: 180.3105 - MinusLogProbMetric: 180.3105 - val_loss: 181.2687 - val_MinusLogProbMetric: 181.2687 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 144/1000
2023-10-05 12:00:46.751 
Epoch 144/1000 
	 loss: 180.2453, MinusLogProbMetric: 180.2453, val_loss: 181.8822, val_MinusLogProbMetric: 181.8822

Epoch 144: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.2453 - MinusLogProbMetric: 180.2453 - val_loss: 181.8822 - val_MinusLogProbMetric: 181.8822 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 145/1000
2023-10-05 12:01:01.364 
Epoch 145/1000 
	 loss: 180.4619, MinusLogProbMetric: 180.4619, val_loss: 181.2334, val_MinusLogProbMetric: 181.2334

Epoch 145: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.4619 - MinusLogProbMetric: 180.4619 - val_loss: 181.2334 - val_MinusLogProbMetric: 181.2334 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 146/1000
2023-10-05 12:01:15.925 
Epoch 146/1000 
	 loss: 180.1843, MinusLogProbMetric: 180.1843, val_loss: 181.2838, val_MinusLogProbMetric: 181.2838

Epoch 146: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.1843 - MinusLogProbMetric: 180.1843 - val_loss: 181.2838 - val_MinusLogProbMetric: 181.2838 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 147/1000
2023-10-05 12:01:30.449 
Epoch 147/1000 
	 loss: 180.3181, MinusLogProbMetric: 180.3181, val_loss: 181.6328, val_MinusLogProbMetric: 181.6328

Epoch 147: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.3181 - MinusLogProbMetric: 180.3181 - val_loss: 181.6328 - val_MinusLogProbMetric: 181.6328 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 148/1000
2023-10-05 12:01:44.929 
Epoch 148/1000 
	 loss: 180.3292, MinusLogProbMetric: 180.3292, val_loss: 181.3852, val_MinusLogProbMetric: 181.3852

Epoch 148: val_loss did not improve from 181.00006
196/196 - 14s - loss: 180.3292 - MinusLogProbMetric: 180.3292 - val_loss: 181.3852 - val_MinusLogProbMetric: 181.3852 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 149/1000
2023-10-05 12:01:59.459 
Epoch 149/1000 
	 loss: 180.2375, MinusLogProbMetric: 180.2375, val_loss: 181.8489, val_MinusLogProbMetric: 181.8489

Epoch 149: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.2375 - MinusLogProbMetric: 180.2375 - val_loss: 181.8489 - val_MinusLogProbMetric: 181.8489 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 150/1000
2023-10-05 12:02:13.643 
Epoch 150/1000 
	 loss: 180.2403, MinusLogProbMetric: 180.2403, val_loss: 181.3447, val_MinusLogProbMetric: 181.3447

Epoch 150: val_loss did not improve from 181.00006
196/196 - 14s - loss: 180.2403 - MinusLogProbMetric: 180.2403 - val_loss: 181.3447 - val_MinusLogProbMetric: 181.3447 - lr: 0.0010 - 14s/epoch - 72ms/step
Epoch 151/1000
2023-10-05 12:02:27.986 
Epoch 151/1000 
	 loss: 180.2253, MinusLogProbMetric: 180.2253, val_loss: 182.3573, val_MinusLogProbMetric: 182.3573

Epoch 151: val_loss did not improve from 181.00006
196/196 - 14s - loss: 180.2253 - MinusLogProbMetric: 180.2253 - val_loss: 182.3573 - val_MinusLogProbMetric: 182.3573 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 152/1000
2023-10-05 12:02:42.697 
Epoch 152/1000 
	 loss: 180.2388, MinusLogProbMetric: 180.2388, val_loss: 181.5552, val_MinusLogProbMetric: 181.5552

Epoch 152: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.2388 - MinusLogProbMetric: 180.2388 - val_loss: 181.5552 - val_MinusLogProbMetric: 181.5552 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 153/1000
2023-10-05 12:02:57.251 
Epoch 153/1000 
	 loss: 180.3378, MinusLogProbMetric: 180.3378, val_loss: 181.1121, val_MinusLogProbMetric: 181.1121

Epoch 153: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.3378 - MinusLogProbMetric: 180.3378 - val_loss: 181.1121 - val_MinusLogProbMetric: 181.1121 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 154/1000
2023-10-05 12:03:11.629 
Epoch 154/1000 
	 loss: 180.2295, MinusLogProbMetric: 180.2295, val_loss: 181.4412, val_MinusLogProbMetric: 181.4412

Epoch 154: val_loss did not improve from 181.00006
196/196 - 14s - loss: 180.2295 - MinusLogProbMetric: 180.2295 - val_loss: 181.4412 - val_MinusLogProbMetric: 181.4412 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 155/1000
2023-10-05 12:03:26.188 
Epoch 155/1000 
	 loss: 180.1302, MinusLogProbMetric: 180.1302, val_loss: 181.4243, val_MinusLogProbMetric: 181.4243

Epoch 155: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.1302 - MinusLogProbMetric: 180.1302 - val_loss: 181.4243 - val_MinusLogProbMetric: 181.4243 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 156/1000
2023-10-05 12:03:40.560 
Epoch 156/1000 
	 loss: 180.2973, MinusLogProbMetric: 180.2973, val_loss: 181.6177, val_MinusLogProbMetric: 181.6177

Epoch 156: val_loss did not improve from 181.00006
196/196 - 14s - loss: 180.2973 - MinusLogProbMetric: 180.2973 - val_loss: 181.6177 - val_MinusLogProbMetric: 181.6177 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 157/1000
2023-10-05 12:03:55.104 
Epoch 157/1000 
	 loss: 180.2063, MinusLogProbMetric: 180.2063, val_loss: 181.7193, val_MinusLogProbMetric: 181.7193

Epoch 157: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.2063 - MinusLogProbMetric: 180.2063 - val_loss: 181.7193 - val_MinusLogProbMetric: 181.7193 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 158/1000
2023-10-05 12:04:09.688 
Epoch 158/1000 
	 loss: 180.1355, MinusLogProbMetric: 180.1355, val_loss: 181.0490, val_MinusLogProbMetric: 181.0490

Epoch 158: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.1355 - MinusLogProbMetric: 180.1355 - val_loss: 181.0490 - val_MinusLogProbMetric: 181.0490 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 159/1000
2023-10-05 12:04:24.181 
Epoch 159/1000 
	 loss: 180.8483, MinusLogProbMetric: 180.8483, val_loss: 181.4130, val_MinusLogProbMetric: 181.4130

Epoch 159: val_loss did not improve from 181.00006
196/196 - 14s - loss: 180.8483 - MinusLogProbMetric: 180.8483 - val_loss: 181.4130 - val_MinusLogProbMetric: 181.4130 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 160/1000
2023-10-05 12:04:38.662 
Epoch 160/1000 
	 loss: 179.9913, MinusLogProbMetric: 179.9913, val_loss: 181.2122, val_MinusLogProbMetric: 181.2122

Epoch 160: val_loss did not improve from 181.00006
196/196 - 14s - loss: 179.9913 - MinusLogProbMetric: 179.9913 - val_loss: 181.2122 - val_MinusLogProbMetric: 181.2122 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 161/1000
2023-10-05 12:04:53.193 
Epoch 161/1000 
	 loss: 180.1155, MinusLogProbMetric: 180.1155, val_loss: 181.8418, val_MinusLogProbMetric: 181.8418

Epoch 161: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.1155 - MinusLogProbMetric: 180.1155 - val_loss: 181.8418 - val_MinusLogProbMetric: 181.8418 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 162/1000
2023-10-05 12:05:07.744 
Epoch 162/1000 
	 loss: 180.1695, MinusLogProbMetric: 180.1695, val_loss: 182.4902, val_MinusLogProbMetric: 182.4902

Epoch 162: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.1695 - MinusLogProbMetric: 180.1695 - val_loss: 182.4902 - val_MinusLogProbMetric: 182.4902 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 163/1000
2023-10-05 12:05:22.320 
Epoch 163/1000 
	 loss: 180.1765, MinusLogProbMetric: 180.1765, val_loss: 181.4023, val_MinusLogProbMetric: 181.4023

Epoch 163: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.1765 - MinusLogProbMetric: 180.1765 - val_loss: 181.4023 - val_MinusLogProbMetric: 181.4023 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 164/1000
2023-10-05 12:05:36.885 
Epoch 164/1000 
	 loss: 180.0385, MinusLogProbMetric: 180.0385, val_loss: 181.8059, val_MinusLogProbMetric: 181.8059

Epoch 164: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.0385 - MinusLogProbMetric: 180.0385 - val_loss: 181.8059 - val_MinusLogProbMetric: 181.8059 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 165/1000
2023-10-05 12:05:51.522 
Epoch 165/1000 
	 loss: 180.1051, MinusLogProbMetric: 180.1051, val_loss: 181.3422, val_MinusLogProbMetric: 181.3422

Epoch 165: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.1051 - MinusLogProbMetric: 180.1051 - val_loss: 181.3422 - val_MinusLogProbMetric: 181.3422 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 166/1000
2023-10-05 12:06:06.124 
Epoch 166/1000 
	 loss: 180.6607, MinusLogProbMetric: 180.6607, val_loss: 181.5507, val_MinusLogProbMetric: 181.5507

Epoch 166: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.6607 - MinusLogProbMetric: 180.6607 - val_loss: 181.5507 - val_MinusLogProbMetric: 181.5507 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 167/1000
2023-10-05 12:06:20.659 
Epoch 167/1000 
	 loss: 180.0123, MinusLogProbMetric: 180.0123, val_loss: 181.3900, val_MinusLogProbMetric: 181.3900

Epoch 167: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.0123 - MinusLogProbMetric: 180.0123 - val_loss: 181.3900 - val_MinusLogProbMetric: 181.3900 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 168/1000
2023-10-05 12:06:34.819 
Epoch 168/1000 
	 loss: 180.0668, MinusLogProbMetric: 180.0668, val_loss: 181.4032, val_MinusLogProbMetric: 181.4032

Epoch 168: val_loss did not improve from 181.00006
196/196 - 14s - loss: 180.0668 - MinusLogProbMetric: 180.0668 - val_loss: 181.4032 - val_MinusLogProbMetric: 181.4032 - lr: 0.0010 - 14s/epoch - 72ms/step
Epoch 169/1000
2023-10-05 12:06:49.053 
Epoch 169/1000 
	 loss: 180.0521, MinusLogProbMetric: 180.0521, val_loss: 181.5613, val_MinusLogProbMetric: 181.5613

Epoch 169: val_loss did not improve from 181.00006
196/196 - 14s - loss: 180.0521 - MinusLogProbMetric: 180.0521 - val_loss: 181.5613 - val_MinusLogProbMetric: 181.5613 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 170/1000
2023-10-05 12:07:01.307 
Epoch 170/1000 
	 loss: 180.0505, MinusLogProbMetric: 180.0505, val_loss: 181.5204, val_MinusLogProbMetric: 181.5204

Epoch 170: val_loss did not improve from 181.00006
196/196 - 12s - loss: 180.0505 - MinusLogProbMetric: 180.0505 - val_loss: 181.5204 - val_MinusLogProbMetric: 181.5204 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 171/1000
2023-10-05 12:07:15.849 
Epoch 171/1000 
	 loss: 180.2146, MinusLogProbMetric: 180.2146, val_loss: 181.0276, val_MinusLogProbMetric: 181.0276

Epoch 171: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.2146 - MinusLogProbMetric: 180.2146 - val_loss: 181.0276 - val_MinusLogProbMetric: 181.0276 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 172/1000
2023-10-05 12:07:30.299 
Epoch 172/1000 
	 loss: 180.0062, MinusLogProbMetric: 180.0062, val_loss: 181.2742, val_MinusLogProbMetric: 181.2742

Epoch 172: val_loss did not improve from 181.00006
196/196 - 14s - loss: 180.0062 - MinusLogProbMetric: 180.0062 - val_loss: 181.2742 - val_MinusLogProbMetric: 181.2742 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 173/1000
2023-10-05 12:07:44.878 
Epoch 173/1000 
	 loss: 180.0084, MinusLogProbMetric: 180.0084, val_loss: 181.1862, val_MinusLogProbMetric: 181.1862

Epoch 173: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.0084 - MinusLogProbMetric: 180.0084 - val_loss: 181.1862 - val_MinusLogProbMetric: 181.1862 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 174/1000
2023-10-05 12:07:59.383 
Epoch 174/1000 
	 loss: 180.0643, MinusLogProbMetric: 180.0643, val_loss: 181.3234, val_MinusLogProbMetric: 181.3234

Epoch 174: val_loss did not improve from 181.00006
196/196 - 14s - loss: 180.0643 - MinusLogProbMetric: 180.0643 - val_loss: 181.3234 - val_MinusLogProbMetric: 181.3234 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 175/1000
2023-10-05 12:08:13.850 
Epoch 175/1000 
	 loss: 180.1586, MinusLogProbMetric: 180.1586, val_loss: 181.6893, val_MinusLogProbMetric: 181.6893

Epoch 175: val_loss did not improve from 181.00006
196/196 - 14s - loss: 180.1586 - MinusLogProbMetric: 180.1586 - val_loss: 181.6893 - val_MinusLogProbMetric: 181.6893 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 176/1000
2023-10-05 12:08:28.410 
Epoch 176/1000 
	 loss: 179.9626, MinusLogProbMetric: 179.9626, val_loss: 181.5652, val_MinusLogProbMetric: 181.5652

Epoch 176: val_loss did not improve from 181.00006
196/196 - 15s - loss: 179.9626 - MinusLogProbMetric: 179.9626 - val_loss: 181.5652 - val_MinusLogProbMetric: 181.5652 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 177/1000
2023-10-05 12:08:42.998 
Epoch 177/1000 
	 loss: 180.0985, MinusLogProbMetric: 180.0985, val_loss: 181.3039, val_MinusLogProbMetric: 181.3039

Epoch 177: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.0985 - MinusLogProbMetric: 180.0985 - val_loss: 181.3039 - val_MinusLogProbMetric: 181.3039 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 178/1000
2023-10-05 12:08:57.559 
Epoch 178/1000 
	 loss: 180.0650, MinusLogProbMetric: 180.0650, val_loss: 181.2070, val_MinusLogProbMetric: 181.2070

Epoch 178: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.0650 - MinusLogProbMetric: 180.0650 - val_loss: 181.2070 - val_MinusLogProbMetric: 181.2070 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 179/1000
2023-10-05 12:09:12.285 
Epoch 179/1000 
	 loss: 180.0990, MinusLogProbMetric: 180.0990, val_loss: 181.1931, val_MinusLogProbMetric: 181.1931

Epoch 179: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.0990 - MinusLogProbMetric: 180.0990 - val_loss: 181.1931 - val_MinusLogProbMetric: 181.1931 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 180/1000
2023-10-05 12:09:26.883 
Epoch 180/1000 
	 loss: 180.0276, MinusLogProbMetric: 180.0276, val_loss: 182.6485, val_MinusLogProbMetric: 182.6485

Epoch 180: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.0276 - MinusLogProbMetric: 180.0276 - val_loss: 182.6485 - val_MinusLogProbMetric: 182.6485 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 181/1000
2023-10-05 12:09:41.409 
Epoch 181/1000 
	 loss: 180.1310, MinusLogProbMetric: 180.1310, val_loss: 181.2465, val_MinusLogProbMetric: 181.2465

Epoch 181: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.1310 - MinusLogProbMetric: 180.1310 - val_loss: 181.2465 - val_MinusLogProbMetric: 181.2465 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 182/1000
2023-10-05 12:09:55.884 
Epoch 182/1000 
	 loss: 180.0066, MinusLogProbMetric: 180.0066, val_loss: 181.3679, val_MinusLogProbMetric: 181.3679

Epoch 182: val_loss did not improve from 181.00006
196/196 - 14s - loss: 180.0066 - MinusLogProbMetric: 180.0066 - val_loss: 181.3679 - val_MinusLogProbMetric: 181.3679 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 183/1000
2023-10-05 12:10:10.400 
Epoch 183/1000 
	 loss: 180.1027, MinusLogProbMetric: 180.1027, val_loss: 181.5710, val_MinusLogProbMetric: 181.5710

Epoch 183: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.1027 - MinusLogProbMetric: 180.1027 - val_loss: 181.5710 - val_MinusLogProbMetric: 181.5710 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 184/1000
2023-10-05 12:10:24.892 
Epoch 184/1000 
	 loss: 180.0691, MinusLogProbMetric: 180.0691, val_loss: 183.7923, val_MinusLogProbMetric: 183.7923

Epoch 184: val_loss did not improve from 181.00006
196/196 - 14s - loss: 180.0691 - MinusLogProbMetric: 180.0691 - val_loss: 183.7923 - val_MinusLogProbMetric: 183.7923 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 185/1000
2023-10-05 12:10:39.428 
Epoch 185/1000 
	 loss: 179.9168, MinusLogProbMetric: 179.9168, val_loss: 182.0131, val_MinusLogProbMetric: 182.0131

Epoch 185: val_loss did not improve from 181.00006
196/196 - 15s - loss: 179.9168 - MinusLogProbMetric: 179.9168 - val_loss: 182.0131 - val_MinusLogProbMetric: 182.0131 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 186/1000
2023-10-05 12:10:53.937 
Epoch 186/1000 
	 loss: 180.1212, MinusLogProbMetric: 180.1212, val_loss: 181.2927, val_MinusLogProbMetric: 181.2927

Epoch 186: val_loss did not improve from 181.00006
196/196 - 15s - loss: 180.1212 - MinusLogProbMetric: 180.1212 - val_loss: 181.2927 - val_MinusLogProbMetric: 181.2927 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 187/1000
2023-10-05 12:11:08.490 
Epoch 187/1000 
	 loss: 179.8792, MinusLogProbMetric: 179.8792, val_loss: 181.5121, val_MinusLogProbMetric: 181.5121

Epoch 187: val_loss did not improve from 181.00006
196/196 - 15s - loss: 179.8792 - MinusLogProbMetric: 179.8792 - val_loss: 181.5121 - val_MinusLogProbMetric: 181.5121 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 188/1000
2023-10-05 12:11:23.042 
Epoch 188/1000 
	 loss: 179.1027, MinusLogProbMetric: 179.1027, val_loss: 180.6407, val_MinusLogProbMetric: 180.6407

Epoch 188: val_loss improved from 181.00006 to 180.64069, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 16s - loss: 179.1027 - MinusLogProbMetric: 179.1027 - val_loss: 180.6407 - val_MinusLogProbMetric: 180.6407 - lr: 5.0000e-04 - 16s/epoch - 80ms/step
Epoch 189/1000
2023-10-05 12:11:38.750 
Epoch 189/1000 
	 loss: 179.2423, MinusLogProbMetric: 179.2423, val_loss: 180.6955, val_MinusLogProbMetric: 180.6955

Epoch 189: val_loss did not improve from 180.64069
196/196 - 15s - loss: 179.2423 - MinusLogProbMetric: 179.2423 - val_loss: 180.6955 - val_MinusLogProbMetric: 180.6955 - lr: 5.0000e-04 - 15s/epoch - 75ms/step
Epoch 190/1000
2023-10-05 12:11:53.369 
Epoch 190/1000 
	 loss: 179.1041, MinusLogProbMetric: 179.1041, val_loss: 180.8981, val_MinusLogProbMetric: 180.8981

Epoch 190: val_loss did not improve from 180.64069
196/196 - 15s - loss: 179.1041 - MinusLogProbMetric: 179.1041 - val_loss: 180.8981 - val_MinusLogProbMetric: 180.8981 - lr: 5.0000e-04 - 15s/epoch - 75ms/step
Epoch 191/1000
2023-10-05 12:12:07.994 
Epoch 191/1000 
	 loss: 179.2401, MinusLogProbMetric: 179.2401, val_loss: 180.6912, val_MinusLogProbMetric: 180.6912

Epoch 191: val_loss did not improve from 180.64069
196/196 - 15s - loss: 179.2401 - MinusLogProbMetric: 179.2401 - val_loss: 180.6912 - val_MinusLogProbMetric: 180.6912 - lr: 5.0000e-04 - 15s/epoch - 75ms/step
Epoch 192/1000
2023-10-05 12:12:22.591 
Epoch 192/1000 
	 loss: 179.0736, MinusLogProbMetric: 179.0736, val_loss: 180.5558, val_MinusLogProbMetric: 180.5558

Epoch 192: val_loss improved from 180.64069 to 180.55580, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 179.0736 - MinusLogProbMetric: 179.0736 - val_loss: 180.5558 - val_MinusLogProbMetric: 180.5558 - lr: 5.0000e-04 - 15s/epoch - 77ms/step
Epoch 193/1000
2023-10-05 12:12:37.458 
Epoch 193/1000 
	 loss: 179.1836, MinusLogProbMetric: 179.1836, val_loss: 180.4870, val_MinusLogProbMetric: 180.4870

Epoch 193: val_loss improved from 180.55580 to 180.48701, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 179.1836 - MinusLogProbMetric: 179.1836 - val_loss: 180.4870 - val_MinusLogProbMetric: 180.4870 - lr: 5.0000e-04 - 15s/epoch - 75ms/step
Epoch 194/1000
2023-10-05 12:12:52.245 
Epoch 194/1000 
	 loss: 179.2095, MinusLogProbMetric: 179.2095, val_loss: 180.5349, val_MinusLogProbMetric: 180.5349

Epoch 194: val_loss did not improve from 180.48701
196/196 - 14s - loss: 179.2095 - MinusLogProbMetric: 179.2095 - val_loss: 180.5349 - val_MinusLogProbMetric: 180.5349 - lr: 5.0000e-04 - 14s/epoch - 74ms/step
Epoch 195/1000
2023-10-05 12:13:06.792 
Epoch 195/1000 
	 loss: 179.2097, MinusLogProbMetric: 179.2097, val_loss: 180.5061, val_MinusLogProbMetric: 180.5061

Epoch 195: val_loss did not improve from 180.48701
196/196 - 15s - loss: 179.2097 - MinusLogProbMetric: 179.2097 - val_loss: 180.5061 - val_MinusLogProbMetric: 180.5061 - lr: 5.0000e-04 - 15s/epoch - 74ms/step
Epoch 196/1000
2023-10-05 12:13:21.396 
Epoch 196/1000 
	 loss: 179.1738, MinusLogProbMetric: 179.1738, val_loss: 180.5772, val_MinusLogProbMetric: 180.5772

Epoch 196: val_loss did not improve from 180.48701
196/196 - 15s - loss: 179.1738 - MinusLogProbMetric: 179.1738 - val_loss: 180.5772 - val_MinusLogProbMetric: 180.5772 - lr: 5.0000e-04 - 15s/epoch - 74ms/step
Epoch 197/1000
2023-10-05 12:13:35.934 
Epoch 197/1000 
	 loss: 179.0590, MinusLogProbMetric: 179.0590, val_loss: 180.9114, val_MinusLogProbMetric: 180.9114

Epoch 197: val_loss did not improve from 180.48701
196/196 - 15s - loss: 179.0590 - MinusLogProbMetric: 179.0590 - val_loss: 180.9114 - val_MinusLogProbMetric: 180.9114 - lr: 5.0000e-04 - 15s/epoch - 74ms/step
Epoch 198/1000
2023-10-05 12:13:50.430 
Epoch 198/1000 
	 loss: 179.0939, MinusLogProbMetric: 179.0939, val_loss: 180.6084, val_MinusLogProbMetric: 180.6084

Epoch 198: val_loss did not improve from 180.48701
196/196 - 14s - loss: 179.0939 - MinusLogProbMetric: 179.0939 - val_loss: 180.6084 - val_MinusLogProbMetric: 180.6084 - lr: 5.0000e-04 - 14s/epoch - 74ms/step
Epoch 199/1000
2023-10-05 12:14:04.976 
Epoch 199/1000 
	 loss: 179.3547, MinusLogProbMetric: 179.3547, val_loss: 180.7375, val_MinusLogProbMetric: 180.7375

Epoch 199: val_loss did not improve from 180.48701
196/196 - 15s - loss: 179.3547 - MinusLogProbMetric: 179.3547 - val_loss: 180.7375 - val_MinusLogProbMetric: 180.7375 - lr: 5.0000e-04 - 15s/epoch - 74ms/step
Epoch 200/1000
2023-10-05 12:14:19.596 
Epoch 200/1000 
	 loss: 178.9755, MinusLogProbMetric: 178.9755, val_loss: 180.5202, val_MinusLogProbMetric: 180.5202

Epoch 200: val_loss did not improve from 180.48701
196/196 - 15s - loss: 178.9755 - MinusLogProbMetric: 178.9755 - val_loss: 180.5202 - val_MinusLogProbMetric: 180.5202 - lr: 5.0000e-04 - 15s/epoch - 75ms/step
Epoch 201/1000
2023-10-05 12:14:34.128 
Epoch 201/1000 
	 loss: 179.3880, MinusLogProbMetric: 179.3880, val_loss: 184.2407, val_MinusLogProbMetric: 184.2407

Epoch 201: val_loss did not improve from 180.48701
196/196 - 15s - loss: 179.3880 - MinusLogProbMetric: 179.3880 - val_loss: 184.2407 - val_MinusLogProbMetric: 184.2407 - lr: 5.0000e-04 - 15s/epoch - 74ms/step
Epoch 202/1000
2023-10-05 12:14:48.582 
Epoch 202/1000 
	 loss: 179.1838, MinusLogProbMetric: 179.1838, val_loss: 180.6282, val_MinusLogProbMetric: 180.6282

Epoch 202: val_loss did not improve from 180.48701
196/196 - 14s - loss: 179.1838 - MinusLogProbMetric: 179.1838 - val_loss: 180.6282 - val_MinusLogProbMetric: 180.6282 - lr: 5.0000e-04 - 14s/epoch - 74ms/step
Epoch 203/1000
2023-10-05 12:15:03.138 
Epoch 203/1000 
	 loss: 178.9797, MinusLogProbMetric: 178.9797, val_loss: 180.5576, val_MinusLogProbMetric: 180.5576

Epoch 203: val_loss did not improve from 180.48701
196/196 - 15s - loss: 178.9797 - MinusLogProbMetric: 178.9797 - val_loss: 180.5576 - val_MinusLogProbMetric: 180.5576 - lr: 5.0000e-04 - 15s/epoch - 74ms/step
Epoch 204/1000
2023-10-05 12:15:17.696 
Epoch 204/1000 
	 loss: 179.1726, MinusLogProbMetric: 179.1726, val_loss: 180.5068, val_MinusLogProbMetric: 180.5068

Epoch 204: val_loss did not improve from 180.48701
196/196 - 15s - loss: 179.1726 - MinusLogProbMetric: 179.1726 - val_loss: 180.5068 - val_MinusLogProbMetric: 180.5068 - lr: 5.0000e-04 - 15s/epoch - 74ms/step
Epoch 205/1000
2023-10-05 12:15:32.131 
Epoch 205/1000 
	 loss: 179.0370, MinusLogProbMetric: 179.0370, val_loss: 180.7146, val_MinusLogProbMetric: 180.7146

Epoch 205: val_loss did not improve from 180.48701
196/196 - 14s - loss: 179.0370 - MinusLogProbMetric: 179.0370 - val_loss: 180.7146 - val_MinusLogProbMetric: 180.7146 - lr: 5.0000e-04 - 14s/epoch - 74ms/step
Epoch 206/1000
2023-10-05 12:15:46.734 
Epoch 206/1000 
	 loss: 179.0481, MinusLogProbMetric: 179.0481, val_loss: 180.5786, val_MinusLogProbMetric: 180.5786

Epoch 206: val_loss did not improve from 180.48701
196/196 - 15s - loss: 179.0481 - MinusLogProbMetric: 179.0481 - val_loss: 180.5786 - val_MinusLogProbMetric: 180.5786 - lr: 5.0000e-04 - 15s/epoch - 74ms/step
Epoch 207/1000
2023-10-05 12:16:00.882 
Epoch 207/1000 
	 loss: 179.0716, MinusLogProbMetric: 179.0716, val_loss: 180.6898, val_MinusLogProbMetric: 180.6898

Epoch 207: val_loss did not improve from 180.48701
196/196 - 14s - loss: 179.0716 - MinusLogProbMetric: 179.0716 - val_loss: 180.6898 - val_MinusLogProbMetric: 180.6898 - lr: 5.0000e-04 - 14s/epoch - 72ms/step
Epoch 208/1000
2023-10-05 12:16:15.019 
Epoch 208/1000 
	 loss: 179.1136, MinusLogProbMetric: 179.1136, val_loss: 180.8674, val_MinusLogProbMetric: 180.8674

Epoch 208: val_loss did not improve from 180.48701
196/196 - 14s - loss: 179.1136 - MinusLogProbMetric: 179.1136 - val_loss: 180.8674 - val_MinusLogProbMetric: 180.8674 - lr: 5.0000e-04 - 14s/epoch - 72ms/step
Epoch 209/1000
2023-10-05 12:16:29.221 
Epoch 209/1000 
	 loss: 179.0252, MinusLogProbMetric: 179.0252, val_loss: 180.5210, val_MinusLogProbMetric: 180.5210

Epoch 209: val_loss did not improve from 180.48701
196/196 - 14s - loss: 179.0252 - MinusLogProbMetric: 179.0252 - val_loss: 180.5210 - val_MinusLogProbMetric: 180.5210 - lr: 5.0000e-04 - 14s/epoch - 72ms/step
Epoch 210/1000
2023-10-05 12:16:43.673 
Epoch 210/1000 
	 loss: 179.0239, MinusLogProbMetric: 179.0239, val_loss: 180.6935, val_MinusLogProbMetric: 180.6935

Epoch 210: val_loss did not improve from 180.48701
196/196 - 14s - loss: 179.0239 - MinusLogProbMetric: 179.0239 - val_loss: 180.6935 - val_MinusLogProbMetric: 180.6935 - lr: 5.0000e-04 - 14s/epoch - 74ms/step
Epoch 211/1000
2023-10-05 12:16:58.280 
Epoch 211/1000 
	 loss: 179.0314, MinusLogProbMetric: 179.0314, val_loss: 180.7095, val_MinusLogProbMetric: 180.7095

Epoch 211: val_loss did not improve from 180.48701
196/196 - 15s - loss: 179.0314 - MinusLogProbMetric: 179.0314 - val_loss: 180.7095 - val_MinusLogProbMetric: 180.7095 - lr: 5.0000e-04 - 15s/epoch - 75ms/step
Epoch 212/1000
2023-10-05 12:17:12.963 
Epoch 212/1000 
	 loss: 179.0120, MinusLogProbMetric: 179.0120, val_loss: 180.8410, val_MinusLogProbMetric: 180.8410

Epoch 212: val_loss did not improve from 180.48701
196/196 - 15s - loss: 179.0120 - MinusLogProbMetric: 179.0120 - val_loss: 180.8410 - val_MinusLogProbMetric: 180.8410 - lr: 5.0000e-04 - 15s/epoch - 75ms/step
Epoch 213/1000
2023-10-05 12:17:27.627 
Epoch 213/1000 
	 loss: 179.0118, MinusLogProbMetric: 179.0118, val_loss: 180.6752, val_MinusLogProbMetric: 180.6752

Epoch 213: val_loss did not improve from 180.48701
196/196 - 15s - loss: 179.0118 - MinusLogProbMetric: 179.0118 - val_loss: 180.6752 - val_MinusLogProbMetric: 180.6752 - lr: 5.0000e-04 - 15s/epoch - 75ms/step
Epoch 214/1000
2023-10-05 12:17:42.187 
Epoch 214/1000 
	 loss: 179.1869, MinusLogProbMetric: 179.1869, val_loss: 180.7705, val_MinusLogProbMetric: 180.7705

Epoch 214: val_loss did not improve from 180.48701
196/196 - 15s - loss: 179.1869 - MinusLogProbMetric: 179.1869 - val_loss: 180.7705 - val_MinusLogProbMetric: 180.7705 - lr: 5.0000e-04 - 15s/epoch - 74ms/step
Epoch 215/1000
2023-10-05 12:17:57.193 
Epoch 215/1000 
	 loss: 178.9122, MinusLogProbMetric: 178.9122, val_loss: 181.4320, val_MinusLogProbMetric: 181.4320

Epoch 215: val_loss did not improve from 180.48701
196/196 - 15s - loss: 178.9122 - MinusLogProbMetric: 178.9122 - val_loss: 181.4320 - val_MinusLogProbMetric: 181.4320 - lr: 5.0000e-04 - 15s/epoch - 77ms/step
Epoch 216/1000
2023-10-05 12:18:12.674 
Epoch 216/1000 
	 loss: 179.1673, MinusLogProbMetric: 179.1673, val_loss: 180.5708, val_MinusLogProbMetric: 180.5708

Epoch 216: val_loss did not improve from 180.48701
196/196 - 15s - loss: 179.1673 - MinusLogProbMetric: 179.1673 - val_loss: 180.5708 - val_MinusLogProbMetric: 180.5708 - lr: 5.0000e-04 - 15s/epoch - 79ms/step
Epoch 217/1000
2023-10-05 12:18:27.049 
Epoch 217/1000 
	 loss: 179.2223, MinusLogProbMetric: 179.2223, val_loss: 180.7656, val_MinusLogProbMetric: 180.7656

Epoch 217: val_loss did not improve from 180.48701
196/196 - 14s - loss: 179.2223 - MinusLogProbMetric: 179.2223 - val_loss: 180.7656 - val_MinusLogProbMetric: 180.7656 - lr: 5.0000e-04 - 14s/epoch - 73ms/step
Epoch 218/1000
2023-10-05 12:18:41.533 
Epoch 218/1000 
	 loss: 178.9141, MinusLogProbMetric: 178.9141, val_loss: 180.6094, val_MinusLogProbMetric: 180.6094

Epoch 218: val_loss did not improve from 180.48701
196/196 - 14s - loss: 178.9141 - MinusLogProbMetric: 178.9141 - val_loss: 180.6094 - val_MinusLogProbMetric: 180.6094 - lr: 5.0000e-04 - 14s/epoch - 74ms/step
Epoch 219/1000
2023-10-05 12:18:55.997 
Epoch 219/1000 
	 loss: 179.0391, MinusLogProbMetric: 179.0391, val_loss: 180.6151, val_MinusLogProbMetric: 180.6151

Epoch 219: val_loss did not improve from 180.48701
196/196 - 14s - loss: 179.0391 - MinusLogProbMetric: 179.0391 - val_loss: 180.6151 - val_MinusLogProbMetric: 180.6151 - lr: 5.0000e-04 - 14s/epoch - 74ms/step
Epoch 220/1000
2023-10-05 12:19:10.605 
Epoch 220/1000 
	 loss: 178.9028, MinusLogProbMetric: 178.9028, val_loss: 180.6899, val_MinusLogProbMetric: 180.6899

Epoch 220: val_loss did not improve from 180.48701
196/196 - 15s - loss: 178.9028 - MinusLogProbMetric: 178.9028 - val_loss: 180.6899 - val_MinusLogProbMetric: 180.6899 - lr: 5.0000e-04 - 15s/epoch - 75ms/step
Epoch 221/1000
2023-10-05 12:19:25.072 
Epoch 221/1000 
	 loss: 179.0004, MinusLogProbMetric: 179.0004, val_loss: 181.0053, val_MinusLogProbMetric: 181.0053

Epoch 221: val_loss did not improve from 180.48701
196/196 - 14s - loss: 179.0004 - MinusLogProbMetric: 179.0004 - val_loss: 181.0053 - val_MinusLogProbMetric: 181.0053 - lr: 5.0000e-04 - 14s/epoch - 74ms/step
Epoch 222/1000
2023-10-05 12:19:39.095 
Epoch 222/1000 
	 loss: 178.9761, MinusLogProbMetric: 178.9761, val_loss: 180.8064, val_MinusLogProbMetric: 180.8064

Epoch 222: val_loss did not improve from 180.48701
196/196 - 14s - loss: 178.9761 - MinusLogProbMetric: 178.9761 - val_loss: 180.8064 - val_MinusLogProbMetric: 180.8064 - lr: 5.0000e-04 - 14s/epoch - 72ms/step
Epoch 223/1000
2023-10-05 12:19:53.477 
Epoch 223/1000 
	 loss: 178.9946, MinusLogProbMetric: 178.9946, val_loss: 180.6123, val_MinusLogProbMetric: 180.6123

Epoch 223: val_loss did not improve from 180.48701
196/196 - 14s - loss: 178.9946 - MinusLogProbMetric: 178.9946 - val_loss: 180.6123 - val_MinusLogProbMetric: 180.6123 - lr: 5.0000e-04 - 14s/epoch - 73ms/step
Epoch 224/1000
2023-10-05 12:20:07.701 
Epoch 224/1000 
	 loss: 178.9605, MinusLogProbMetric: 178.9605, val_loss: 180.7260, val_MinusLogProbMetric: 180.7260

Epoch 224: val_loss did not improve from 180.48701
196/196 - 14s - loss: 178.9605 - MinusLogProbMetric: 178.9605 - val_loss: 180.7260 - val_MinusLogProbMetric: 180.7260 - lr: 5.0000e-04 - 14s/epoch - 72ms/step
Epoch 225/1000
2023-10-05 12:20:22.242 
Epoch 225/1000 
	 loss: 179.0773, MinusLogProbMetric: 179.0773, val_loss: 180.5882, val_MinusLogProbMetric: 180.5882

Epoch 225: val_loss did not improve from 180.48701
196/196 - 15s - loss: 179.0773 - MinusLogProbMetric: 179.0773 - val_loss: 180.5882 - val_MinusLogProbMetric: 180.5882 - lr: 5.0000e-04 - 15s/epoch - 74ms/step
Epoch 226/1000
2023-10-05 12:20:36.672 
Epoch 226/1000 
	 loss: 179.0178, MinusLogProbMetric: 179.0178, val_loss: 180.6606, val_MinusLogProbMetric: 180.6606

Epoch 226: val_loss did not improve from 180.48701
196/196 - 14s - loss: 179.0178 - MinusLogProbMetric: 179.0178 - val_loss: 180.6606 - val_MinusLogProbMetric: 180.6606 - lr: 5.0000e-04 - 14s/epoch - 74ms/step
Epoch 227/1000
2023-10-05 12:20:51.252 
Epoch 227/1000 
	 loss: 179.2438, MinusLogProbMetric: 179.2438, val_loss: 180.7710, val_MinusLogProbMetric: 180.7710

Epoch 227: val_loss did not improve from 180.48701
196/196 - 15s - loss: 179.2438 - MinusLogProbMetric: 179.2438 - val_loss: 180.7710 - val_MinusLogProbMetric: 180.7710 - lr: 5.0000e-04 - 15s/epoch - 74ms/step
Epoch 228/1000
2023-10-05 12:21:05.783 
Epoch 228/1000 
	 loss: 178.9125, MinusLogProbMetric: 178.9125, val_loss: 180.7510, val_MinusLogProbMetric: 180.7510

Epoch 228: val_loss did not improve from 180.48701
196/196 - 15s - loss: 178.9125 - MinusLogProbMetric: 178.9125 - val_loss: 180.7510 - val_MinusLogProbMetric: 180.7510 - lr: 5.0000e-04 - 15s/epoch - 74ms/step
Epoch 229/1000
2023-10-05 12:21:20.171 
Epoch 229/1000 
	 loss: 179.0620, MinusLogProbMetric: 179.0620, val_loss: 180.8152, val_MinusLogProbMetric: 180.8152

Epoch 229: val_loss did not improve from 180.48701
196/196 - 14s - loss: 179.0620 - MinusLogProbMetric: 179.0620 - val_loss: 180.8152 - val_MinusLogProbMetric: 180.8152 - lr: 5.0000e-04 - 14s/epoch - 73ms/step
Epoch 230/1000
2023-10-05 12:21:34.712 
Epoch 230/1000 
	 loss: 178.9455, MinusLogProbMetric: 178.9455, val_loss: 180.6207, val_MinusLogProbMetric: 180.6207

Epoch 230: val_loss did not improve from 180.48701
196/196 - 15s - loss: 178.9455 - MinusLogProbMetric: 178.9455 - val_loss: 180.6207 - val_MinusLogProbMetric: 180.6207 - lr: 5.0000e-04 - 15s/epoch - 74ms/step
Epoch 231/1000
2023-10-05 12:21:49.308 
Epoch 231/1000 
	 loss: 179.1026, MinusLogProbMetric: 179.1026, val_loss: 180.6232, val_MinusLogProbMetric: 180.6232

Epoch 231: val_loss did not improve from 180.48701
196/196 - 15s - loss: 179.1026 - MinusLogProbMetric: 179.1026 - val_loss: 180.6232 - val_MinusLogProbMetric: 180.6232 - lr: 5.0000e-04 - 15s/epoch - 74ms/step
Epoch 232/1000
2023-10-05 12:22:03.801 
Epoch 232/1000 
	 loss: 178.8864, MinusLogProbMetric: 178.8864, val_loss: 180.5816, val_MinusLogProbMetric: 180.5816

Epoch 232: val_loss did not improve from 180.48701
196/196 - 14s - loss: 178.8864 - MinusLogProbMetric: 178.8864 - val_loss: 180.5816 - val_MinusLogProbMetric: 180.5816 - lr: 5.0000e-04 - 14s/epoch - 74ms/step
Epoch 233/1000
2023-10-05 12:22:18.247 
Epoch 233/1000 
	 loss: 179.1719, MinusLogProbMetric: 179.1719, val_loss: 180.7706, val_MinusLogProbMetric: 180.7706

Epoch 233: val_loss did not improve from 180.48701
196/196 - 14s - loss: 179.1719 - MinusLogProbMetric: 179.1719 - val_loss: 180.7706 - val_MinusLogProbMetric: 180.7706 - lr: 5.0000e-04 - 14s/epoch - 74ms/step
Epoch 234/1000
2023-10-05 12:22:32.932 
Epoch 234/1000 
	 loss: 179.0172, MinusLogProbMetric: 179.0172, val_loss: 180.6741, val_MinusLogProbMetric: 180.6741

Epoch 234: val_loss did not improve from 180.48701
196/196 - 15s - loss: 179.0172 - MinusLogProbMetric: 179.0172 - val_loss: 180.6741 - val_MinusLogProbMetric: 180.6741 - lr: 5.0000e-04 - 15s/epoch - 75ms/step
Epoch 235/1000
2023-10-05 12:22:47.464 
Epoch 235/1000 
	 loss: 178.8788, MinusLogProbMetric: 178.8788, val_loss: 181.5445, val_MinusLogProbMetric: 181.5445

Epoch 235: val_loss did not improve from 180.48701
196/196 - 15s - loss: 178.8788 - MinusLogProbMetric: 178.8788 - val_loss: 181.5445 - val_MinusLogProbMetric: 181.5445 - lr: 5.0000e-04 - 15s/epoch - 74ms/step
Epoch 236/1000
2023-10-05 12:23:02.018 
Epoch 236/1000 
	 loss: 179.0468, MinusLogProbMetric: 179.0468, val_loss: 180.6562, val_MinusLogProbMetric: 180.6562

Epoch 236: val_loss did not improve from 180.48701
196/196 - 15s - loss: 179.0468 - MinusLogProbMetric: 179.0468 - val_loss: 180.6562 - val_MinusLogProbMetric: 180.6562 - lr: 5.0000e-04 - 15s/epoch - 74ms/step
Epoch 237/1000
2023-10-05 12:23:16.457 
Epoch 237/1000 
	 loss: 178.8766, MinusLogProbMetric: 178.8766, val_loss: 180.8589, val_MinusLogProbMetric: 180.8589

Epoch 237: val_loss did not improve from 180.48701
196/196 - 14s - loss: 178.8766 - MinusLogProbMetric: 178.8766 - val_loss: 180.8589 - val_MinusLogProbMetric: 180.8589 - lr: 5.0000e-04 - 14s/epoch - 74ms/step
Epoch 238/1000
2023-10-05 12:23:30.955 
Epoch 238/1000 
	 loss: 179.2322, MinusLogProbMetric: 179.2322, val_loss: 180.6461, val_MinusLogProbMetric: 180.6461

Epoch 238: val_loss did not improve from 180.48701
196/196 - 14s - loss: 179.2322 - MinusLogProbMetric: 179.2322 - val_loss: 180.6461 - val_MinusLogProbMetric: 180.6461 - lr: 5.0000e-04 - 14s/epoch - 74ms/step
Epoch 239/1000
2023-10-05 12:23:45.569 
Epoch 239/1000 
	 loss: 178.8472, MinusLogProbMetric: 178.8472, val_loss: 180.7146, val_MinusLogProbMetric: 180.7146

Epoch 239: val_loss did not improve from 180.48701
196/196 - 15s - loss: 178.8472 - MinusLogProbMetric: 178.8472 - val_loss: 180.7146 - val_MinusLogProbMetric: 180.7146 - lr: 5.0000e-04 - 15s/epoch - 75ms/step
Epoch 240/1000
2023-10-05 12:24:00.249 
Epoch 240/1000 
	 loss: 179.0397, MinusLogProbMetric: 179.0397, val_loss: 180.8912, val_MinusLogProbMetric: 180.8912

Epoch 240: val_loss did not improve from 180.48701
196/196 - 15s - loss: 179.0397 - MinusLogProbMetric: 179.0397 - val_loss: 180.8912 - val_MinusLogProbMetric: 180.8912 - lr: 5.0000e-04 - 15s/epoch - 75ms/step
Epoch 241/1000
2023-10-05 12:24:14.690 
Epoch 241/1000 
	 loss: 178.8782, MinusLogProbMetric: 178.8782, val_loss: 180.5719, val_MinusLogProbMetric: 180.5719

Epoch 241: val_loss did not improve from 180.48701
196/196 - 14s - loss: 178.8782 - MinusLogProbMetric: 178.8782 - val_loss: 180.5719 - val_MinusLogProbMetric: 180.5719 - lr: 5.0000e-04 - 14s/epoch - 74ms/step
Epoch 242/1000
2023-10-05 12:24:29.282 
Epoch 242/1000 
	 loss: 179.0387, MinusLogProbMetric: 179.0387, val_loss: 180.6391, val_MinusLogProbMetric: 180.6391

Epoch 242: val_loss did not improve from 180.48701
196/196 - 15s - loss: 179.0387 - MinusLogProbMetric: 179.0387 - val_loss: 180.6391 - val_MinusLogProbMetric: 180.6391 - lr: 5.0000e-04 - 15s/epoch - 74ms/step
Epoch 243/1000
2023-10-05 12:24:44.005 
Epoch 243/1000 
	 loss: 178.8690, MinusLogProbMetric: 178.8690, val_loss: 180.9190, val_MinusLogProbMetric: 180.9190

Epoch 243: val_loss did not improve from 180.48701
196/196 - 15s - loss: 178.8690 - MinusLogProbMetric: 178.8690 - val_loss: 180.9190 - val_MinusLogProbMetric: 180.9190 - lr: 5.0000e-04 - 15s/epoch - 75ms/step
Epoch 244/1000
2023-10-05 12:24:58.574 
Epoch 244/1000 
	 loss: 178.4981, MinusLogProbMetric: 178.4981, val_loss: 180.2838, val_MinusLogProbMetric: 180.2838

Epoch 244: val_loss improved from 180.48701 to 180.28380, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 178.4981 - MinusLogProbMetric: 178.4981 - val_loss: 180.2838 - val_MinusLogProbMetric: 180.2838 - lr: 2.5000e-04 - 15s/epoch - 77ms/step
Epoch 245/1000
2023-10-05 12:25:13.732 
Epoch 245/1000 
	 loss: 178.4675, MinusLogProbMetric: 178.4675, val_loss: 180.4361, val_MinusLogProbMetric: 180.4361

Epoch 245: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.4675 - MinusLogProbMetric: 178.4675 - val_loss: 180.4361 - val_MinusLogProbMetric: 180.4361 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 246/1000
2023-10-05 12:25:28.285 
Epoch 246/1000 
	 loss: 178.5432, MinusLogProbMetric: 178.5432, val_loss: 180.4214, val_MinusLogProbMetric: 180.4214

Epoch 246: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.5432 - MinusLogProbMetric: 178.5432 - val_loss: 180.4214 - val_MinusLogProbMetric: 180.4214 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 247/1000
2023-10-05 12:25:42.825 
Epoch 247/1000 
	 loss: 178.5626, MinusLogProbMetric: 178.5626, val_loss: 180.6111, val_MinusLogProbMetric: 180.6111

Epoch 247: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.5626 - MinusLogProbMetric: 178.5626 - val_loss: 180.6111 - val_MinusLogProbMetric: 180.6111 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 248/1000
2023-10-05 12:25:57.347 
Epoch 248/1000 
	 loss: 178.4532, MinusLogProbMetric: 178.4532, val_loss: 180.3304, val_MinusLogProbMetric: 180.3304

Epoch 248: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.4532 - MinusLogProbMetric: 178.4532 - val_loss: 180.3304 - val_MinusLogProbMetric: 180.3304 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 249/1000
2023-10-05 12:26:11.981 
Epoch 249/1000 
	 loss: 178.5826, MinusLogProbMetric: 178.5826, val_loss: 180.2967, val_MinusLogProbMetric: 180.2967

Epoch 249: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.5826 - MinusLogProbMetric: 178.5826 - val_loss: 180.2967 - val_MinusLogProbMetric: 180.2967 - lr: 2.5000e-04 - 15s/epoch - 75ms/step
Epoch 250/1000
2023-10-05 12:26:26.586 
Epoch 250/1000 
	 loss: 178.5652, MinusLogProbMetric: 178.5652, val_loss: 180.4037, val_MinusLogProbMetric: 180.4037

Epoch 250: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.5652 - MinusLogProbMetric: 178.5652 - val_loss: 180.4037 - val_MinusLogProbMetric: 180.4037 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 251/1000
2023-10-05 12:26:41.222 
Epoch 251/1000 
	 loss: 178.4380, MinusLogProbMetric: 178.4380, val_loss: 180.3936, val_MinusLogProbMetric: 180.3936

Epoch 251: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.4380 - MinusLogProbMetric: 178.4380 - val_loss: 180.3936 - val_MinusLogProbMetric: 180.3936 - lr: 2.5000e-04 - 15s/epoch - 75ms/step
Epoch 252/1000
2023-10-05 12:26:55.840 
Epoch 252/1000 
	 loss: 178.5670, MinusLogProbMetric: 178.5670, val_loss: 180.3210, val_MinusLogProbMetric: 180.3210

Epoch 252: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.5670 - MinusLogProbMetric: 178.5670 - val_loss: 180.3210 - val_MinusLogProbMetric: 180.3210 - lr: 2.5000e-04 - 15s/epoch - 75ms/step
Epoch 253/1000
2023-10-05 12:27:10.430 
Epoch 253/1000 
	 loss: 178.5100, MinusLogProbMetric: 178.5100, val_loss: 180.3143, val_MinusLogProbMetric: 180.3143

Epoch 253: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.5100 - MinusLogProbMetric: 178.5100 - val_loss: 180.3143 - val_MinusLogProbMetric: 180.3143 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 254/1000
2023-10-05 12:27:25.026 
Epoch 254/1000 
	 loss: 178.5655, MinusLogProbMetric: 178.5655, val_loss: 180.3805, val_MinusLogProbMetric: 180.3805

Epoch 254: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.5655 - MinusLogProbMetric: 178.5655 - val_loss: 180.3805 - val_MinusLogProbMetric: 180.3805 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 255/1000
2023-10-05 12:27:39.613 
Epoch 255/1000 
	 loss: 178.4621, MinusLogProbMetric: 178.4621, val_loss: 180.3075, val_MinusLogProbMetric: 180.3075

Epoch 255: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.4621 - MinusLogProbMetric: 178.4621 - val_loss: 180.3075 - val_MinusLogProbMetric: 180.3075 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 256/1000
2023-10-05 12:27:54.206 
Epoch 256/1000 
	 loss: 178.6121, MinusLogProbMetric: 178.6121, val_loss: 180.4154, val_MinusLogProbMetric: 180.4154

Epoch 256: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.6121 - MinusLogProbMetric: 178.6121 - val_loss: 180.4154 - val_MinusLogProbMetric: 180.4154 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 257/1000
2023-10-05 12:28:08.833 
Epoch 257/1000 
	 loss: 178.4464, MinusLogProbMetric: 178.4464, val_loss: 180.3526, val_MinusLogProbMetric: 180.3526

Epoch 257: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.4464 - MinusLogProbMetric: 178.4464 - val_loss: 180.3526 - val_MinusLogProbMetric: 180.3526 - lr: 2.5000e-04 - 15s/epoch - 75ms/step
Epoch 258/1000
2023-10-05 12:28:23.432 
Epoch 258/1000 
	 loss: 178.5675, MinusLogProbMetric: 178.5675, val_loss: 180.3227, val_MinusLogProbMetric: 180.3227

Epoch 258: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.5675 - MinusLogProbMetric: 178.5675 - val_loss: 180.3227 - val_MinusLogProbMetric: 180.3227 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 259/1000
2023-10-05 12:28:37.983 
Epoch 259/1000 
	 loss: 178.5670, MinusLogProbMetric: 178.5670, val_loss: 180.3421, val_MinusLogProbMetric: 180.3421

Epoch 259: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.5670 - MinusLogProbMetric: 178.5670 - val_loss: 180.3421 - val_MinusLogProbMetric: 180.3421 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 260/1000
2023-10-05 12:28:52.618 
Epoch 260/1000 
	 loss: 178.4240, MinusLogProbMetric: 178.4240, val_loss: 180.5034, val_MinusLogProbMetric: 180.5034

Epoch 260: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.4240 - MinusLogProbMetric: 178.4240 - val_loss: 180.5034 - val_MinusLogProbMetric: 180.5034 - lr: 2.5000e-04 - 15s/epoch - 75ms/step
Epoch 261/1000
2023-10-05 12:29:07.198 
Epoch 261/1000 
	 loss: 178.5724, MinusLogProbMetric: 178.5724, val_loss: 180.3765, val_MinusLogProbMetric: 180.3765

Epoch 261: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.5724 - MinusLogProbMetric: 178.5724 - val_loss: 180.3765 - val_MinusLogProbMetric: 180.3765 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 262/1000
2023-10-05 12:29:21.826 
Epoch 262/1000 
	 loss: 178.5893, MinusLogProbMetric: 178.5893, val_loss: 180.3574, val_MinusLogProbMetric: 180.3574

Epoch 262: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.5893 - MinusLogProbMetric: 178.5893 - val_loss: 180.3574 - val_MinusLogProbMetric: 180.3574 - lr: 2.5000e-04 - 15s/epoch - 75ms/step
Epoch 263/1000
2023-10-05 12:29:36.410 
Epoch 263/1000 
	 loss: 178.4531, MinusLogProbMetric: 178.4531, val_loss: 180.3450, val_MinusLogProbMetric: 180.3450

Epoch 263: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.4531 - MinusLogProbMetric: 178.4531 - val_loss: 180.3450 - val_MinusLogProbMetric: 180.3450 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 264/1000
2023-10-05 12:29:51.009 
Epoch 264/1000 
	 loss: 178.4104, MinusLogProbMetric: 178.4104, val_loss: 181.0305, val_MinusLogProbMetric: 181.0305

Epoch 264: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.4104 - MinusLogProbMetric: 178.4104 - val_loss: 181.0305 - val_MinusLogProbMetric: 181.0305 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 265/1000
2023-10-05 12:30:06.236 
Epoch 265/1000 
	 loss: 178.5911, MinusLogProbMetric: 178.5911, val_loss: 180.3640, val_MinusLogProbMetric: 180.3640

Epoch 265: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.5911 - MinusLogProbMetric: 178.5911 - val_loss: 180.3640 - val_MinusLogProbMetric: 180.3640 - lr: 2.5000e-04 - 15s/epoch - 78ms/step
Epoch 266/1000
2023-10-05 12:30:20.762 
Epoch 266/1000 
	 loss: 178.4922, MinusLogProbMetric: 178.4922, val_loss: 180.3967, val_MinusLogProbMetric: 180.3967

Epoch 266: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.4922 - MinusLogProbMetric: 178.4922 - val_loss: 180.3967 - val_MinusLogProbMetric: 180.3967 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 267/1000
2023-10-05 12:30:35.306 
Epoch 267/1000 
	 loss: 178.5333, MinusLogProbMetric: 178.5333, val_loss: 180.3349, val_MinusLogProbMetric: 180.3349

Epoch 267: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.5333 - MinusLogProbMetric: 178.5333 - val_loss: 180.3349 - val_MinusLogProbMetric: 180.3349 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 268/1000
2023-10-05 12:30:49.836 
Epoch 268/1000 
	 loss: 178.4258, MinusLogProbMetric: 178.4258, val_loss: 180.5387, val_MinusLogProbMetric: 180.5387

Epoch 268: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.4258 - MinusLogProbMetric: 178.4258 - val_loss: 180.5387 - val_MinusLogProbMetric: 180.5387 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 269/1000
2023-10-05 12:31:04.352 
Epoch 269/1000 
	 loss: 178.5201, MinusLogProbMetric: 178.5201, val_loss: 180.3966, val_MinusLogProbMetric: 180.3966

Epoch 269: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.5201 - MinusLogProbMetric: 178.5201 - val_loss: 180.3966 - val_MinusLogProbMetric: 180.3966 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 270/1000
2023-10-05 12:31:18.878 
Epoch 270/1000 
	 loss: 178.5653, MinusLogProbMetric: 178.5653, val_loss: 180.3462, val_MinusLogProbMetric: 180.3463

Epoch 270: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.5653 - MinusLogProbMetric: 178.5653 - val_loss: 180.3462 - val_MinusLogProbMetric: 180.3463 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 271/1000
2023-10-05 12:31:33.578 
Epoch 271/1000 
	 loss: 178.4571, MinusLogProbMetric: 178.4571, val_loss: 180.8675, val_MinusLogProbMetric: 180.8675

Epoch 271: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.4571 - MinusLogProbMetric: 178.4571 - val_loss: 180.8675 - val_MinusLogProbMetric: 180.8675 - lr: 2.5000e-04 - 15s/epoch - 75ms/step
Epoch 272/1000
2023-10-05 12:31:48.093 
Epoch 272/1000 
	 loss: 178.4648, MinusLogProbMetric: 178.4648, val_loss: 180.6318, val_MinusLogProbMetric: 180.6318

Epoch 272: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.4648 - MinusLogProbMetric: 178.4648 - val_loss: 180.6318 - val_MinusLogProbMetric: 180.6318 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 273/1000
2023-10-05 12:32:02.172 
Epoch 273/1000 
	 loss: 178.5399, MinusLogProbMetric: 178.5399, val_loss: 180.4386, val_MinusLogProbMetric: 180.4386

Epoch 273: val_loss did not improve from 180.28380
196/196 - 14s - loss: 178.5399 - MinusLogProbMetric: 178.5399 - val_loss: 180.4386 - val_MinusLogProbMetric: 180.4386 - lr: 2.5000e-04 - 14s/epoch - 72ms/step
Epoch 274/1000
2023-10-05 12:32:16.339 
Epoch 274/1000 
	 loss: 178.4257, MinusLogProbMetric: 178.4257, val_loss: 180.4766, val_MinusLogProbMetric: 180.4766

Epoch 274: val_loss did not improve from 180.28380
196/196 - 14s - loss: 178.4257 - MinusLogProbMetric: 178.4257 - val_loss: 180.4766 - val_MinusLogProbMetric: 180.4766 - lr: 2.5000e-04 - 14s/epoch - 72ms/step
Epoch 275/1000
2023-10-05 12:32:30.735 
Epoch 275/1000 
	 loss: 178.5173, MinusLogProbMetric: 178.5173, val_loss: 180.4585, val_MinusLogProbMetric: 180.4585

Epoch 275: val_loss did not improve from 180.28380
196/196 - 14s - loss: 178.5173 - MinusLogProbMetric: 178.5173 - val_loss: 180.4585 - val_MinusLogProbMetric: 180.4585 - lr: 2.5000e-04 - 14s/epoch - 73ms/step
Epoch 276/1000
2023-10-05 12:32:45.170 
Epoch 276/1000 
	 loss: 178.4884, MinusLogProbMetric: 178.4884, val_loss: 180.3986, val_MinusLogProbMetric: 180.3986

Epoch 276: val_loss did not improve from 180.28380
196/196 - 14s - loss: 178.4884 - MinusLogProbMetric: 178.4884 - val_loss: 180.3986 - val_MinusLogProbMetric: 180.3986 - lr: 2.5000e-04 - 14s/epoch - 74ms/step
Epoch 277/1000
2023-10-05 12:32:59.735 
Epoch 277/1000 
	 loss: 178.5434, MinusLogProbMetric: 178.5434, val_loss: 180.9169, val_MinusLogProbMetric: 180.9169

Epoch 277: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.5434 - MinusLogProbMetric: 178.5434 - val_loss: 180.9169 - val_MinusLogProbMetric: 180.9169 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 278/1000
2023-10-05 12:33:14.328 
Epoch 278/1000 
	 loss: 178.3982, MinusLogProbMetric: 178.3982, val_loss: 180.3189, val_MinusLogProbMetric: 180.3189

Epoch 278: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.3982 - MinusLogProbMetric: 178.3982 - val_loss: 180.3189 - val_MinusLogProbMetric: 180.3189 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 279/1000
2023-10-05 12:33:28.877 
Epoch 279/1000 
	 loss: 178.4915, MinusLogProbMetric: 178.4915, val_loss: 180.3624, val_MinusLogProbMetric: 180.3624

Epoch 279: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.4915 - MinusLogProbMetric: 178.4915 - val_loss: 180.3624 - val_MinusLogProbMetric: 180.3624 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 280/1000
2023-10-05 12:33:43.467 
Epoch 280/1000 
	 loss: 178.4777, MinusLogProbMetric: 178.4777, val_loss: 180.3510, val_MinusLogProbMetric: 180.3510

Epoch 280: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.4777 - MinusLogProbMetric: 178.4777 - val_loss: 180.3510 - val_MinusLogProbMetric: 180.3510 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 281/1000
2023-10-05 12:33:57.905 
Epoch 281/1000 
	 loss: 178.4698, MinusLogProbMetric: 178.4698, val_loss: 180.9989, val_MinusLogProbMetric: 180.9989

Epoch 281: val_loss did not improve from 180.28380
196/196 - 14s - loss: 178.4698 - MinusLogProbMetric: 178.4698 - val_loss: 180.9989 - val_MinusLogProbMetric: 180.9989 - lr: 2.5000e-04 - 14s/epoch - 74ms/step
Epoch 282/1000
2023-10-05 12:34:12.649 
Epoch 282/1000 
	 loss: 178.4852, MinusLogProbMetric: 178.4852, val_loss: 180.8801, val_MinusLogProbMetric: 180.8801

Epoch 282: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.4852 - MinusLogProbMetric: 178.4852 - val_loss: 180.8801 - val_MinusLogProbMetric: 180.8801 - lr: 2.5000e-04 - 15s/epoch - 75ms/step
Epoch 283/1000
2023-10-05 12:34:27.346 
Epoch 283/1000 
	 loss: 178.4623, MinusLogProbMetric: 178.4623, val_loss: 180.5551, val_MinusLogProbMetric: 180.5551

Epoch 283: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.4623 - MinusLogProbMetric: 178.4623 - val_loss: 180.5551 - val_MinusLogProbMetric: 180.5551 - lr: 2.5000e-04 - 15s/epoch - 75ms/step
Epoch 284/1000
2023-10-05 12:34:42.007 
Epoch 284/1000 
	 loss: 178.4815, MinusLogProbMetric: 178.4815, val_loss: 180.3945, val_MinusLogProbMetric: 180.3945

Epoch 284: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.4815 - MinusLogProbMetric: 178.4815 - val_loss: 180.3945 - val_MinusLogProbMetric: 180.3945 - lr: 2.5000e-04 - 15s/epoch - 75ms/step
Epoch 285/1000
2023-10-05 12:34:56.620 
Epoch 285/1000 
	 loss: 178.3750, MinusLogProbMetric: 178.3750, val_loss: 180.3399, val_MinusLogProbMetric: 180.3399

Epoch 285: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.3750 - MinusLogProbMetric: 178.3750 - val_loss: 180.3399 - val_MinusLogProbMetric: 180.3399 - lr: 2.5000e-04 - 15s/epoch - 75ms/step
Epoch 286/1000
2023-10-05 12:35:11.162 
Epoch 286/1000 
	 loss: 178.5132, MinusLogProbMetric: 178.5132, val_loss: 180.6422, val_MinusLogProbMetric: 180.6422

Epoch 286: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.5132 - MinusLogProbMetric: 178.5132 - val_loss: 180.6422 - val_MinusLogProbMetric: 180.6422 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 287/1000
2023-10-05 12:35:25.777 
Epoch 287/1000 
	 loss: 178.4914, MinusLogProbMetric: 178.4914, val_loss: 180.3848, val_MinusLogProbMetric: 180.3848

Epoch 287: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.4914 - MinusLogProbMetric: 178.4914 - val_loss: 180.3848 - val_MinusLogProbMetric: 180.3848 - lr: 2.5000e-04 - 15s/epoch - 75ms/step
Epoch 288/1000
2023-10-05 12:35:40.379 
Epoch 288/1000 
	 loss: 178.5269, MinusLogProbMetric: 178.5269, val_loss: 180.4535, val_MinusLogProbMetric: 180.4535

Epoch 288: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.5269 - MinusLogProbMetric: 178.5269 - val_loss: 180.4535 - val_MinusLogProbMetric: 180.4535 - lr: 2.5000e-04 - 15s/epoch - 74ms/step
Epoch 289/1000
2023-10-05 12:35:54.879 
Epoch 289/1000 
	 loss: 178.5000, MinusLogProbMetric: 178.5000, val_loss: 181.3992, val_MinusLogProbMetric: 181.3992

Epoch 289: val_loss did not improve from 180.28380
196/196 - 14s - loss: 178.5000 - MinusLogProbMetric: 178.5000 - val_loss: 181.3992 - val_MinusLogProbMetric: 181.3992 - lr: 2.5000e-04 - 14s/epoch - 74ms/step
Epoch 290/1000
2023-10-05 12:36:09.035 
Epoch 290/1000 
	 loss: 178.4227, MinusLogProbMetric: 178.4227, val_loss: 180.6297, val_MinusLogProbMetric: 180.6297

Epoch 290: val_loss did not improve from 180.28380
196/196 - 14s - loss: 178.4227 - MinusLogProbMetric: 178.4227 - val_loss: 180.6297 - val_MinusLogProbMetric: 180.6297 - lr: 2.5000e-04 - 14s/epoch - 72ms/step
Epoch 291/1000
2023-10-05 12:36:23.767 
Epoch 291/1000 
	 loss: 178.4432, MinusLogProbMetric: 178.4432, val_loss: 180.7788, val_MinusLogProbMetric: 180.7788

Epoch 291: val_loss did not improve from 180.28380
196/196 - 15s - loss: 178.4432 - MinusLogProbMetric: 178.4432 - val_loss: 180.7788 - val_MinusLogProbMetric: 180.7788 - lr: 2.5000e-04 - 15s/epoch - 75ms/step
Epoch 292/1000
2023-10-05 12:36:38.257 
Epoch 292/1000 
	 loss: 178.4413, MinusLogProbMetric: 178.4413, val_loss: 180.3676, val_MinusLogProbMetric: 180.3676

Epoch 292: val_loss did not improve from 180.28380
196/196 - 14s - loss: 178.4413 - MinusLogProbMetric: 178.4413 - val_loss: 180.3676 - val_MinusLogProbMetric: 180.3676 - lr: 2.5000e-04 - 14s/epoch - 74ms/step
Epoch 293/1000
2023-10-05 12:36:52.622 
Epoch 293/1000 
	 loss: 178.4990, MinusLogProbMetric: 178.4990, val_loss: 180.4518, val_MinusLogProbMetric: 180.4518

Epoch 293: val_loss did not improve from 180.28380
196/196 - 14s - loss: 178.4990 - MinusLogProbMetric: 178.4990 - val_loss: 180.4518 - val_MinusLogProbMetric: 180.4518 - lr: 2.5000e-04 - 14s/epoch - 73ms/step
Epoch 294/1000
2023-10-05 12:37:06.650 
Epoch 294/1000 
	 loss: 178.4217, MinusLogProbMetric: 178.4217, val_loss: 180.3883, val_MinusLogProbMetric: 180.3883

Epoch 294: val_loss did not improve from 180.28380
196/196 - 14s - loss: 178.4217 - MinusLogProbMetric: 178.4217 - val_loss: 180.3883 - val_MinusLogProbMetric: 180.3883 - lr: 2.5000e-04 - 14s/epoch - 72ms/step
Epoch 295/1000
2023-10-05 12:37:20.652 
Epoch 295/1000 
	 loss: 178.2171, MinusLogProbMetric: 178.2171, val_loss: 180.2678, val_MinusLogProbMetric: 180.2678

Epoch 295: val_loss improved from 180.28380 to 180.26778, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 14s - loss: 178.2171 - MinusLogProbMetric: 178.2171 - val_loss: 180.2678 - val_MinusLogProbMetric: 180.2678 - lr: 1.2500e-04 - 14s/epoch - 73ms/step
Epoch 296/1000
2023-10-05 12:37:35.824 
Epoch 296/1000 
	 loss: 178.2035, MinusLogProbMetric: 178.2035, val_loss: 180.2553, val_MinusLogProbMetric: 180.2553

Epoch 296: val_loss improved from 180.26778 to 180.25531, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 178.2035 - MinusLogProbMetric: 178.2035 - val_loss: 180.2553 - val_MinusLogProbMetric: 180.2553 - lr: 1.2500e-04 - 15s/epoch - 78ms/step
Epoch 297/1000
2023-10-05 12:37:50.307 
Epoch 297/1000 
	 loss: 178.2058, MinusLogProbMetric: 178.2058, val_loss: 180.2818, val_MinusLogProbMetric: 180.2818

Epoch 297: val_loss did not improve from 180.25531
196/196 - 14s - loss: 178.2058 - MinusLogProbMetric: 178.2058 - val_loss: 180.2818 - val_MinusLogProbMetric: 180.2818 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 298/1000
2023-10-05 12:38:04.476 
Epoch 298/1000 
	 loss: 178.1888, MinusLogProbMetric: 178.1888, val_loss: 180.3045, val_MinusLogProbMetric: 180.3045

Epoch 298: val_loss did not improve from 180.25531
196/196 - 14s - loss: 178.1888 - MinusLogProbMetric: 178.1888 - val_loss: 180.3045 - val_MinusLogProbMetric: 180.3045 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 299/1000
2023-10-05 12:38:18.772 
Epoch 299/1000 
	 loss: 178.1917, MinusLogProbMetric: 178.1917, val_loss: 180.2704, val_MinusLogProbMetric: 180.2704

Epoch 299: val_loss did not improve from 180.25531
196/196 - 14s - loss: 178.1917 - MinusLogProbMetric: 178.1917 - val_loss: 180.2704 - val_MinusLogProbMetric: 180.2704 - lr: 1.2500e-04 - 14s/epoch - 73ms/step
Epoch 300/1000
2023-10-05 12:38:33.135 
Epoch 300/1000 
	 loss: 178.1907, MinusLogProbMetric: 178.1907, val_loss: 180.3084, val_MinusLogProbMetric: 180.3084

Epoch 300: val_loss did not improve from 180.25531
196/196 - 14s - loss: 178.1907 - MinusLogProbMetric: 178.1907 - val_loss: 180.3084 - val_MinusLogProbMetric: 180.3084 - lr: 1.2500e-04 - 14s/epoch - 73ms/step
Epoch 301/1000
2023-10-05 12:38:47.311 
Epoch 301/1000 
	 loss: 178.1878, MinusLogProbMetric: 178.1878, val_loss: 180.2530, val_MinusLogProbMetric: 180.2530

Epoch 301: val_loss improved from 180.25531 to 180.25301, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 14s - loss: 178.1878 - MinusLogProbMetric: 178.1878 - val_loss: 180.2530 - val_MinusLogProbMetric: 180.2530 - lr: 1.2500e-04 - 14s/epoch - 74ms/step
Epoch 302/1000
2023-10-05 12:39:01.894 
Epoch 302/1000 
	 loss: 178.1925, MinusLogProbMetric: 178.1925, val_loss: 180.2620, val_MinusLogProbMetric: 180.2620

Epoch 302: val_loss did not improve from 180.25301
196/196 - 14s - loss: 178.1925 - MinusLogProbMetric: 178.1925 - val_loss: 180.2620 - val_MinusLogProbMetric: 180.2620 - lr: 1.2500e-04 - 14s/epoch - 73ms/step
Epoch 303/1000
2023-10-05 12:39:16.203 
Epoch 303/1000 
	 loss: 178.1781, MinusLogProbMetric: 178.1781, val_loss: 180.2810, val_MinusLogProbMetric: 180.2810

Epoch 303: val_loss did not improve from 180.25301
196/196 - 14s - loss: 178.1781 - MinusLogProbMetric: 178.1781 - val_loss: 180.2810 - val_MinusLogProbMetric: 180.2810 - lr: 1.2500e-04 - 14s/epoch - 73ms/step
Epoch 304/1000
2023-10-05 12:39:30.466 
Epoch 304/1000 
	 loss: 178.1949, MinusLogProbMetric: 178.1949, val_loss: 180.2764, val_MinusLogProbMetric: 180.2764

Epoch 304: val_loss did not improve from 180.25301
196/196 - 14s - loss: 178.1949 - MinusLogProbMetric: 178.1949 - val_loss: 180.2764 - val_MinusLogProbMetric: 180.2764 - lr: 1.2500e-04 - 14s/epoch - 73ms/step
Epoch 305/1000
2023-10-05 12:39:44.973 
Epoch 305/1000 
	 loss: 178.1921, MinusLogProbMetric: 178.1921, val_loss: 180.2655, val_MinusLogProbMetric: 180.2655

Epoch 305: val_loss did not improve from 180.25301
196/196 - 14s - loss: 178.1921 - MinusLogProbMetric: 178.1921 - val_loss: 180.2655 - val_MinusLogProbMetric: 180.2655 - lr: 1.2500e-04 - 14s/epoch - 74ms/step
Epoch 306/1000
2023-10-05 12:39:59.354 
Epoch 306/1000 
	 loss: 178.1890, MinusLogProbMetric: 178.1890, val_loss: 180.2655, val_MinusLogProbMetric: 180.2655

Epoch 306: val_loss did not improve from 180.25301
196/196 - 14s - loss: 178.1890 - MinusLogProbMetric: 178.1890 - val_loss: 180.2655 - val_MinusLogProbMetric: 180.2655 - lr: 1.2500e-04 - 14s/epoch - 73ms/step
Epoch 307/1000
2023-10-05 12:40:13.636 
Epoch 307/1000 
	 loss: 178.1857, MinusLogProbMetric: 178.1857, val_loss: 180.2602, val_MinusLogProbMetric: 180.2602

Epoch 307: val_loss did not improve from 180.25301
196/196 - 14s - loss: 178.1857 - MinusLogProbMetric: 178.1857 - val_loss: 180.2602 - val_MinusLogProbMetric: 180.2602 - lr: 1.2500e-04 - 14s/epoch - 73ms/step
Epoch 308/1000
2023-10-05 12:40:27.860 
Epoch 308/1000 
	 loss: 178.1841, MinusLogProbMetric: 178.1841, val_loss: 180.2548, val_MinusLogProbMetric: 180.2548

Epoch 308: val_loss did not improve from 180.25301
196/196 - 14s - loss: 178.1841 - MinusLogProbMetric: 178.1841 - val_loss: 180.2548 - val_MinusLogProbMetric: 180.2548 - lr: 1.2500e-04 - 14s/epoch - 73ms/step
Epoch 309/1000
2023-10-05 12:40:42.055 
Epoch 309/1000 
	 loss: 178.1811, MinusLogProbMetric: 178.1811, val_loss: 180.2811, val_MinusLogProbMetric: 180.2811

Epoch 309: val_loss did not improve from 180.25301
196/196 - 14s - loss: 178.1811 - MinusLogProbMetric: 178.1811 - val_loss: 180.2811 - val_MinusLogProbMetric: 180.2811 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 310/1000
2023-10-05 12:40:56.122 
Epoch 310/1000 
	 loss: 178.1795, MinusLogProbMetric: 178.1795, val_loss: 180.4028, val_MinusLogProbMetric: 180.4028

Epoch 310: val_loss did not improve from 180.25301
196/196 - 14s - loss: 178.1795 - MinusLogProbMetric: 178.1795 - val_loss: 180.4028 - val_MinusLogProbMetric: 180.4028 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 311/1000
2023-10-05 12:41:10.110 
Epoch 311/1000 
	 loss: 178.2047, MinusLogProbMetric: 178.2047, val_loss: 180.2603, val_MinusLogProbMetric: 180.2603

Epoch 311: val_loss did not improve from 180.25301
196/196 - 14s - loss: 178.2047 - MinusLogProbMetric: 178.2047 - val_loss: 180.2603 - val_MinusLogProbMetric: 180.2603 - lr: 1.2500e-04 - 14s/epoch - 71ms/step
Epoch 312/1000
2023-10-05 12:41:24.390 
Epoch 312/1000 
	 loss: 178.1881, MinusLogProbMetric: 178.1881, val_loss: 180.2550, val_MinusLogProbMetric: 180.2550

Epoch 312: val_loss did not improve from 180.25301
196/196 - 14s - loss: 178.1881 - MinusLogProbMetric: 178.1881 - val_loss: 180.2550 - val_MinusLogProbMetric: 180.2550 - lr: 1.2500e-04 - 14s/epoch - 73ms/step
Epoch 313/1000
2023-10-05 12:41:38.659 
Epoch 313/1000 
	 loss: 178.1693, MinusLogProbMetric: 178.1693, val_loss: 180.2527, val_MinusLogProbMetric: 180.2527

Epoch 313: val_loss improved from 180.25301 to 180.25266, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_310/weights/best_weights.h5
196/196 - 15s - loss: 178.1693 - MinusLogProbMetric: 178.1693 - val_loss: 180.2527 - val_MinusLogProbMetric: 180.2527 - lr: 1.2500e-04 - 15s/epoch - 76ms/step
Epoch 314/1000
2023-10-05 12:41:53.430 
Epoch 314/1000 
	 loss: 178.1760, MinusLogProbMetric: 178.1760, val_loss: 180.3184, val_MinusLogProbMetric: 180.3184

Epoch 314: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1760 - MinusLogProbMetric: 178.1760 - val_loss: 180.3184 - val_MinusLogProbMetric: 180.3184 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 315/1000
2023-10-05 12:42:07.504 
Epoch 315/1000 
	 loss: 178.1846, MinusLogProbMetric: 178.1846, val_loss: 180.2814, val_MinusLogProbMetric: 180.2814

Epoch 315: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1846 - MinusLogProbMetric: 178.1846 - val_loss: 180.2814 - val_MinusLogProbMetric: 180.2814 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 316/1000
2023-10-05 12:42:21.577 
Epoch 316/1000 
	 loss: 178.1839, MinusLogProbMetric: 178.1839, val_loss: 180.3261, val_MinusLogProbMetric: 180.3261

Epoch 316: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1839 - MinusLogProbMetric: 178.1839 - val_loss: 180.3261 - val_MinusLogProbMetric: 180.3261 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 317/1000
2023-10-05 12:42:35.635 
Epoch 317/1000 
	 loss: 178.1749, MinusLogProbMetric: 178.1749, val_loss: 180.3621, val_MinusLogProbMetric: 180.3621

Epoch 317: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1749 - MinusLogProbMetric: 178.1749 - val_loss: 180.3621 - val_MinusLogProbMetric: 180.3621 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 318/1000
2023-10-05 12:42:50.011 
Epoch 318/1000 
	 loss: 178.1762, MinusLogProbMetric: 178.1762, val_loss: 180.2939, val_MinusLogProbMetric: 180.2939

Epoch 318: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1762 - MinusLogProbMetric: 178.1762 - val_loss: 180.2939 - val_MinusLogProbMetric: 180.2939 - lr: 1.2500e-04 - 14s/epoch - 73ms/step
Epoch 319/1000
2023-10-05 12:43:04.279 
Epoch 319/1000 
	 loss: 178.1843, MinusLogProbMetric: 178.1843, val_loss: 180.3906, val_MinusLogProbMetric: 180.3906

Epoch 319: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1843 - MinusLogProbMetric: 178.1843 - val_loss: 180.3906 - val_MinusLogProbMetric: 180.3906 - lr: 1.2500e-04 - 14s/epoch - 73ms/step
Epoch 320/1000
2023-10-05 12:43:18.571 
Epoch 320/1000 
	 loss: 178.1834, MinusLogProbMetric: 178.1834, val_loss: 180.3355, val_MinusLogProbMetric: 180.3355

Epoch 320: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1834 - MinusLogProbMetric: 178.1834 - val_loss: 180.3355 - val_MinusLogProbMetric: 180.3355 - lr: 1.2500e-04 - 14s/epoch - 73ms/step
Epoch 321/1000
2023-10-05 12:43:32.873 
Epoch 321/1000 
	 loss: 178.1774, MinusLogProbMetric: 178.1774, val_loss: 180.2700, val_MinusLogProbMetric: 180.2700

Epoch 321: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1774 - MinusLogProbMetric: 178.1774 - val_loss: 180.2700 - val_MinusLogProbMetric: 180.2700 - lr: 1.2500e-04 - 14s/epoch - 73ms/step
Epoch 322/1000
2023-10-05 12:43:47.293 
Epoch 322/1000 
	 loss: 178.1719, MinusLogProbMetric: 178.1719, val_loss: 180.2787, val_MinusLogProbMetric: 180.2787

Epoch 322: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1719 - MinusLogProbMetric: 178.1719 - val_loss: 180.2787 - val_MinusLogProbMetric: 180.2787 - lr: 1.2500e-04 - 14s/epoch - 74ms/step
Epoch 323/1000
2023-10-05 12:44:01.419 
Epoch 323/1000 
	 loss: 178.1711, MinusLogProbMetric: 178.1711, val_loss: 180.3114, val_MinusLogProbMetric: 180.3114

Epoch 323: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1711 - MinusLogProbMetric: 178.1711 - val_loss: 180.3114 - val_MinusLogProbMetric: 180.3114 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 324/1000
2023-10-05 12:44:15.612 
Epoch 324/1000 
	 loss: 178.1737, MinusLogProbMetric: 178.1737, val_loss: 180.3017, val_MinusLogProbMetric: 180.3017

Epoch 324: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1737 - MinusLogProbMetric: 178.1737 - val_loss: 180.3017 - val_MinusLogProbMetric: 180.3017 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 325/1000
2023-10-05 12:44:29.810 
Epoch 325/1000 
	 loss: 178.1835, MinusLogProbMetric: 178.1835, val_loss: 180.2889, val_MinusLogProbMetric: 180.2889

Epoch 325: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1835 - MinusLogProbMetric: 178.1835 - val_loss: 180.2889 - val_MinusLogProbMetric: 180.2889 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 326/1000
2023-10-05 12:44:43.898 
Epoch 326/1000 
	 loss: 178.1895, MinusLogProbMetric: 178.1895, val_loss: 180.3338, val_MinusLogProbMetric: 180.3338

Epoch 326: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1895 - MinusLogProbMetric: 178.1895 - val_loss: 180.3338 - val_MinusLogProbMetric: 180.3338 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 327/1000
2023-10-05 12:44:58.015 
Epoch 327/1000 
	 loss: 178.1819, MinusLogProbMetric: 178.1819, val_loss: 180.3158, val_MinusLogProbMetric: 180.3158

Epoch 327: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1819 - MinusLogProbMetric: 178.1819 - val_loss: 180.3158 - val_MinusLogProbMetric: 180.3158 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 328/1000
2023-10-05 12:45:12.156 
Epoch 328/1000 
	 loss: 178.1722, MinusLogProbMetric: 178.1722, val_loss: 180.4510, val_MinusLogProbMetric: 180.4510

Epoch 328: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1722 - MinusLogProbMetric: 178.1722 - val_loss: 180.4510 - val_MinusLogProbMetric: 180.4510 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 329/1000
2023-10-05 12:45:26.086 
Epoch 329/1000 
	 loss: 178.1810, MinusLogProbMetric: 178.1810, val_loss: 180.3501, val_MinusLogProbMetric: 180.3501

Epoch 329: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1810 - MinusLogProbMetric: 178.1810 - val_loss: 180.3501 - val_MinusLogProbMetric: 180.3501 - lr: 1.2500e-04 - 14s/epoch - 71ms/step
Epoch 330/1000
2023-10-05 12:45:40.032 
Epoch 330/1000 
	 loss: 178.1954, MinusLogProbMetric: 178.1954, val_loss: 180.4366, val_MinusLogProbMetric: 180.4366

Epoch 330: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1954 - MinusLogProbMetric: 178.1954 - val_loss: 180.4366 - val_MinusLogProbMetric: 180.4366 - lr: 1.2500e-04 - 14s/epoch - 71ms/step
Epoch 331/1000
2023-10-05 12:45:54.150 
Epoch 331/1000 
	 loss: 178.1901, MinusLogProbMetric: 178.1901, val_loss: 180.3785, val_MinusLogProbMetric: 180.3785

Epoch 331: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1901 - MinusLogProbMetric: 178.1901 - val_loss: 180.3785 - val_MinusLogProbMetric: 180.3785 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 332/1000
2023-10-05 12:46:08.240 
Epoch 332/1000 
	 loss: 178.1677, MinusLogProbMetric: 178.1677, val_loss: 180.3506, val_MinusLogProbMetric: 180.3506

Epoch 332: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1677 - MinusLogProbMetric: 178.1677 - val_loss: 180.3506 - val_MinusLogProbMetric: 180.3506 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 333/1000
2023-10-05 12:46:22.184 
Epoch 333/1000 
	 loss: 178.1631, MinusLogProbMetric: 178.1631, val_loss: 180.3381, val_MinusLogProbMetric: 180.3381

Epoch 333: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1631 - MinusLogProbMetric: 178.1631 - val_loss: 180.3381 - val_MinusLogProbMetric: 180.3381 - lr: 1.2500e-04 - 14s/epoch - 71ms/step
Epoch 334/1000
2023-10-05 12:46:36.263 
Epoch 334/1000 
	 loss: 178.1843, MinusLogProbMetric: 178.1843, val_loss: 180.3706, val_MinusLogProbMetric: 180.3706

Epoch 334: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1843 - MinusLogProbMetric: 178.1843 - val_loss: 180.3706 - val_MinusLogProbMetric: 180.3706 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 335/1000
2023-10-05 12:46:50.399 
Epoch 335/1000 
	 loss: 178.1767, MinusLogProbMetric: 178.1767, val_loss: 180.3048, val_MinusLogProbMetric: 180.3048

Epoch 335: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1767 - MinusLogProbMetric: 178.1767 - val_loss: 180.3048 - val_MinusLogProbMetric: 180.3048 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 336/1000
2023-10-05 12:47:04.490 
Epoch 336/1000 
	 loss: 178.1521, MinusLogProbMetric: 178.1521, val_loss: 180.3023, val_MinusLogProbMetric: 180.3023

Epoch 336: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1521 - MinusLogProbMetric: 178.1521 - val_loss: 180.3023 - val_MinusLogProbMetric: 180.3023 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 337/1000
2023-10-05 12:47:18.518 
Epoch 337/1000 
	 loss: 178.1668, MinusLogProbMetric: 178.1668, val_loss: 180.2981, val_MinusLogProbMetric: 180.2981

Epoch 337: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1668 - MinusLogProbMetric: 178.1668 - val_loss: 180.2981 - val_MinusLogProbMetric: 180.2981 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 338/1000
2023-10-05 12:47:32.643 
Epoch 338/1000 
	 loss: 178.1523, MinusLogProbMetric: 178.1523, val_loss: 180.2815, val_MinusLogProbMetric: 180.2815

Epoch 338: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1523 - MinusLogProbMetric: 178.1523 - val_loss: 180.2815 - val_MinusLogProbMetric: 180.2815 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 339/1000
2023-10-05 12:47:46.787 
Epoch 339/1000 
	 loss: 178.1653, MinusLogProbMetric: 178.1653, val_loss: 180.3063, val_MinusLogProbMetric: 180.3063

Epoch 339: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1653 - MinusLogProbMetric: 178.1653 - val_loss: 180.3063 - val_MinusLogProbMetric: 180.3063 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 340/1000
2023-10-05 12:48:00.856 
Epoch 340/1000 
	 loss: 178.1633, MinusLogProbMetric: 178.1633, val_loss: 180.2863, val_MinusLogProbMetric: 180.2863

Epoch 340: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1633 - MinusLogProbMetric: 178.1633 - val_loss: 180.2863 - val_MinusLogProbMetric: 180.2863 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 341/1000
2023-10-05 12:48:14.821 
Epoch 341/1000 
	 loss: 178.1570, MinusLogProbMetric: 178.1570, val_loss: 180.3287, val_MinusLogProbMetric: 180.3287

Epoch 341: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1570 - MinusLogProbMetric: 178.1570 - val_loss: 180.3287 - val_MinusLogProbMetric: 180.3287 - lr: 1.2500e-04 - 14s/epoch - 71ms/step
Epoch 342/1000
2023-10-05 12:48:28.884 
Epoch 342/1000 
	 loss: 178.2000, MinusLogProbMetric: 178.2000, val_loss: 180.3517, val_MinusLogProbMetric: 180.3517

Epoch 342: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.2000 - MinusLogProbMetric: 178.2000 - val_loss: 180.3517 - val_MinusLogProbMetric: 180.3517 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 343/1000
2023-10-05 12:48:43.005 
Epoch 343/1000 
	 loss: 178.1628, MinusLogProbMetric: 178.1628, val_loss: 180.3122, val_MinusLogProbMetric: 180.3122

Epoch 343: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1628 - MinusLogProbMetric: 178.1628 - val_loss: 180.3122 - val_MinusLogProbMetric: 180.3122 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 344/1000
2023-10-05 12:48:57.081 
Epoch 344/1000 
	 loss: 178.1480, MinusLogProbMetric: 178.1480, val_loss: 180.3085, val_MinusLogProbMetric: 180.3085

Epoch 344: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1480 - MinusLogProbMetric: 178.1480 - val_loss: 180.3085 - val_MinusLogProbMetric: 180.3085 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 345/1000
2023-10-05 12:49:11.046 
Epoch 345/1000 
	 loss: 178.1586, MinusLogProbMetric: 178.1586, val_loss: 180.3100, val_MinusLogProbMetric: 180.3100

Epoch 345: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1586 - MinusLogProbMetric: 178.1586 - val_loss: 180.3100 - val_MinusLogProbMetric: 180.3100 - lr: 1.2500e-04 - 14s/epoch - 71ms/step
Epoch 346/1000
2023-10-05 12:49:25.049 
Epoch 346/1000 
	 loss: 178.1663, MinusLogProbMetric: 178.1663, val_loss: 180.3728, val_MinusLogProbMetric: 180.3728

Epoch 346: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1663 - MinusLogProbMetric: 178.1663 - val_loss: 180.3728 - val_MinusLogProbMetric: 180.3728 - lr: 1.2500e-04 - 14s/epoch - 71ms/step
Epoch 347/1000
2023-10-05 12:49:38.994 
Epoch 347/1000 
	 loss: 178.1440, MinusLogProbMetric: 178.1440, val_loss: 180.5098, val_MinusLogProbMetric: 180.5098

Epoch 347: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1440 - MinusLogProbMetric: 178.1440 - val_loss: 180.5098 - val_MinusLogProbMetric: 180.5098 - lr: 1.2500e-04 - 14s/epoch - 71ms/step
Epoch 348/1000
2023-10-05 12:49:53.035 
Epoch 348/1000 
	 loss: 178.1711, MinusLogProbMetric: 178.1711, val_loss: 180.3385, val_MinusLogProbMetric: 180.3385

Epoch 348: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1711 - MinusLogProbMetric: 178.1711 - val_loss: 180.3385 - val_MinusLogProbMetric: 180.3385 - lr: 1.2500e-04 - 14s/epoch - 71ms/step
Epoch 349/1000
2023-10-05 12:50:07.041 
Epoch 349/1000 
	 loss: 178.1609, MinusLogProbMetric: 178.1609, val_loss: 180.4314, val_MinusLogProbMetric: 180.4314

Epoch 349: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1609 - MinusLogProbMetric: 178.1609 - val_loss: 180.4314 - val_MinusLogProbMetric: 180.4314 - lr: 1.2500e-04 - 14s/epoch - 71ms/step
Epoch 350/1000
2023-10-05 12:50:21.673 
Epoch 350/1000 
	 loss: 178.1668, MinusLogProbMetric: 178.1668, val_loss: 180.3780, val_MinusLogProbMetric: 180.3780

Epoch 350: val_loss did not improve from 180.25266
196/196 - 15s - loss: 178.1668 - MinusLogProbMetric: 178.1668 - val_loss: 180.3780 - val_MinusLogProbMetric: 180.3780 - lr: 1.2500e-04 - 15s/epoch - 75ms/step
Epoch 351/1000
2023-10-05 12:50:35.780 
Epoch 351/1000 
	 loss: 178.1528, MinusLogProbMetric: 178.1528, val_loss: 180.3450, val_MinusLogProbMetric: 180.3450

Epoch 351: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1528 - MinusLogProbMetric: 178.1528 - val_loss: 180.3450 - val_MinusLogProbMetric: 180.3450 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 352/1000
2023-10-05 12:50:49.990 
Epoch 352/1000 
	 loss: 178.1434, MinusLogProbMetric: 178.1434, val_loss: 180.3548, val_MinusLogProbMetric: 180.3548

Epoch 352: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1434 - MinusLogProbMetric: 178.1434 - val_loss: 180.3548 - val_MinusLogProbMetric: 180.3548 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 353/1000
2023-10-05 12:51:04.028 
Epoch 353/1000 
	 loss: 178.1616, MinusLogProbMetric: 178.1616, val_loss: 180.3173, val_MinusLogProbMetric: 180.3173

Epoch 353: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1616 - MinusLogProbMetric: 178.1616 - val_loss: 180.3173 - val_MinusLogProbMetric: 180.3173 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 354/1000
2023-10-05 12:51:18.091 
Epoch 354/1000 
	 loss: 178.1501, MinusLogProbMetric: 178.1501, val_loss: 180.2799, val_MinusLogProbMetric: 180.2799

Epoch 354: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1501 - MinusLogProbMetric: 178.1501 - val_loss: 180.2799 - val_MinusLogProbMetric: 180.2799 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 355/1000
2023-10-05 12:51:32.054 
Epoch 355/1000 
	 loss: 178.1549, MinusLogProbMetric: 178.1549, val_loss: 180.3217, val_MinusLogProbMetric: 180.3217

Epoch 355: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1549 - MinusLogProbMetric: 178.1549 - val_loss: 180.3217 - val_MinusLogProbMetric: 180.3217 - lr: 1.2500e-04 - 14s/epoch - 71ms/step
Epoch 356/1000
2023-10-05 12:51:46.179 
Epoch 356/1000 
	 loss: 178.1516, MinusLogProbMetric: 178.1516, val_loss: 180.3214, val_MinusLogProbMetric: 180.3214

Epoch 356: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1516 - MinusLogProbMetric: 178.1516 - val_loss: 180.3214 - val_MinusLogProbMetric: 180.3214 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 357/1000
2023-10-05 12:52:00.297 
Epoch 357/1000 
	 loss: 178.1782, MinusLogProbMetric: 178.1782, val_loss: 180.4853, val_MinusLogProbMetric: 180.4853

Epoch 357: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1782 - MinusLogProbMetric: 178.1782 - val_loss: 180.4853 - val_MinusLogProbMetric: 180.4853 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 358/1000
2023-10-05 12:52:14.443 
Epoch 358/1000 
	 loss: 178.1713, MinusLogProbMetric: 178.1713, val_loss: 180.4207, val_MinusLogProbMetric: 180.4207

Epoch 358: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1713 - MinusLogProbMetric: 178.1713 - val_loss: 180.4207 - val_MinusLogProbMetric: 180.4207 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 359/1000
2023-10-05 12:52:28.311 
Epoch 359/1000 
	 loss: 178.1628, MinusLogProbMetric: 178.1628, val_loss: 180.5040, val_MinusLogProbMetric: 180.5040

Epoch 359: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1628 - MinusLogProbMetric: 178.1628 - val_loss: 180.5040 - val_MinusLogProbMetric: 180.5040 - lr: 1.2500e-04 - 14s/epoch - 71ms/step
Epoch 360/1000
2023-10-05 12:52:42.425 
Epoch 360/1000 
	 loss: 178.1427, MinusLogProbMetric: 178.1427, val_loss: 180.3721, val_MinusLogProbMetric: 180.3721

Epoch 360: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1427 - MinusLogProbMetric: 178.1427 - val_loss: 180.3721 - val_MinusLogProbMetric: 180.3721 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 361/1000
2023-10-05 12:52:56.451 
Epoch 361/1000 
	 loss: 178.1521, MinusLogProbMetric: 178.1521, val_loss: 180.4035, val_MinusLogProbMetric: 180.4035

Epoch 361: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1521 - MinusLogProbMetric: 178.1521 - val_loss: 180.4035 - val_MinusLogProbMetric: 180.4035 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 362/1000
2023-10-05 12:53:10.531 
Epoch 362/1000 
	 loss: 178.1578, MinusLogProbMetric: 178.1578, val_loss: 180.2987, val_MinusLogProbMetric: 180.2987

Epoch 362: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1578 - MinusLogProbMetric: 178.1578 - val_loss: 180.2987 - val_MinusLogProbMetric: 180.2987 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 363/1000
2023-10-05 12:53:24.712 
Epoch 363/1000 
	 loss: 178.1509, MinusLogProbMetric: 178.1509, val_loss: 180.4978, val_MinusLogProbMetric: 180.4978

Epoch 363: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.1509 - MinusLogProbMetric: 178.1509 - val_loss: 180.4978 - val_MinusLogProbMetric: 180.4978 - lr: 1.2500e-04 - 14s/epoch - 72ms/step
Epoch 364/1000
2023-10-05 12:53:38.844 
Epoch 364/1000 
	 loss: 178.0704, MinusLogProbMetric: 178.0704, val_loss: 180.2908, val_MinusLogProbMetric: 180.2908

Epoch 364: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0704 - MinusLogProbMetric: 178.0704 - val_loss: 180.2908 - val_MinusLogProbMetric: 180.2908 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 365/1000
2023-10-05 12:53:53.014 
Epoch 365/1000 
	 loss: 178.0626, MinusLogProbMetric: 178.0626, val_loss: 180.2539, val_MinusLogProbMetric: 180.2539

Epoch 365: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0626 - MinusLogProbMetric: 178.0626 - val_loss: 180.2539 - val_MinusLogProbMetric: 180.2539 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 366/1000
2023-10-05 12:54:07.179 
Epoch 366/1000 
	 loss: 178.0586, MinusLogProbMetric: 178.0586, val_loss: 180.2729, val_MinusLogProbMetric: 180.2729

Epoch 366: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0586 - MinusLogProbMetric: 178.0586 - val_loss: 180.2729 - val_MinusLogProbMetric: 180.2729 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 367/1000
2023-10-05 12:54:21.337 
Epoch 367/1000 
	 loss: 178.0668, MinusLogProbMetric: 178.0668, val_loss: 180.2856, val_MinusLogProbMetric: 180.2856

Epoch 367: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0668 - MinusLogProbMetric: 178.0668 - val_loss: 180.2856 - val_MinusLogProbMetric: 180.2856 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 368/1000
2023-10-05 12:54:35.439 
Epoch 368/1000 
	 loss: 178.0603, MinusLogProbMetric: 178.0603, val_loss: 180.2787, val_MinusLogProbMetric: 180.2787

Epoch 368: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0603 - MinusLogProbMetric: 178.0603 - val_loss: 180.2787 - val_MinusLogProbMetric: 180.2787 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 369/1000
2023-10-05 12:54:49.509 
Epoch 369/1000 
	 loss: 178.0580, MinusLogProbMetric: 178.0580, val_loss: 180.2845, val_MinusLogProbMetric: 180.2845

Epoch 369: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0580 - MinusLogProbMetric: 178.0580 - val_loss: 180.2845 - val_MinusLogProbMetric: 180.2845 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 370/1000
2023-10-05 12:55:03.613 
Epoch 370/1000 
	 loss: 178.0549, MinusLogProbMetric: 178.0549, val_loss: 180.3142, val_MinusLogProbMetric: 180.3142

Epoch 370: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0549 - MinusLogProbMetric: 178.0549 - val_loss: 180.3142 - val_MinusLogProbMetric: 180.3142 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 371/1000
2023-10-05 12:55:17.858 
Epoch 371/1000 
	 loss: 178.0583, MinusLogProbMetric: 178.0583, val_loss: 180.2605, val_MinusLogProbMetric: 180.2605

Epoch 371: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0583 - MinusLogProbMetric: 178.0583 - val_loss: 180.2605 - val_MinusLogProbMetric: 180.2605 - lr: 6.2500e-05 - 14s/epoch - 73ms/step
Epoch 372/1000
2023-10-05 12:55:32.075 
Epoch 372/1000 
	 loss: 178.0548, MinusLogProbMetric: 178.0548, val_loss: 180.2764, val_MinusLogProbMetric: 180.2764

Epoch 372: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0548 - MinusLogProbMetric: 178.0548 - val_loss: 180.2764 - val_MinusLogProbMetric: 180.2764 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 373/1000
2023-10-05 12:55:46.200 
Epoch 373/1000 
	 loss: 178.0594, MinusLogProbMetric: 178.0594, val_loss: 180.2832, val_MinusLogProbMetric: 180.2832

Epoch 373: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0594 - MinusLogProbMetric: 178.0594 - val_loss: 180.2832 - val_MinusLogProbMetric: 180.2832 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 374/1000
2023-10-05 12:56:00.383 
Epoch 374/1000 
	 loss: 178.0563, MinusLogProbMetric: 178.0563, val_loss: 180.2697, val_MinusLogProbMetric: 180.2697

Epoch 374: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0563 - MinusLogProbMetric: 178.0563 - val_loss: 180.2697 - val_MinusLogProbMetric: 180.2697 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 375/1000
2023-10-05 12:56:14.352 
Epoch 375/1000 
	 loss: 178.0479, MinusLogProbMetric: 178.0479, val_loss: 180.2805, val_MinusLogProbMetric: 180.2805

Epoch 375: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0479 - MinusLogProbMetric: 178.0479 - val_loss: 180.2805 - val_MinusLogProbMetric: 180.2805 - lr: 6.2500e-05 - 14s/epoch - 71ms/step
Epoch 376/1000
2023-10-05 12:56:28.474 
Epoch 376/1000 
	 loss: 178.0597, MinusLogProbMetric: 178.0597, val_loss: 180.2951, val_MinusLogProbMetric: 180.2951

Epoch 376: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0597 - MinusLogProbMetric: 178.0597 - val_loss: 180.2951 - val_MinusLogProbMetric: 180.2951 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 377/1000
2023-10-05 12:56:42.461 
Epoch 377/1000 
	 loss: 178.0570, MinusLogProbMetric: 178.0570, val_loss: 180.2744, val_MinusLogProbMetric: 180.2744

Epoch 377: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0570 - MinusLogProbMetric: 178.0570 - val_loss: 180.2744 - val_MinusLogProbMetric: 180.2744 - lr: 6.2500e-05 - 14s/epoch - 71ms/step
Epoch 378/1000
2023-10-05 12:56:56.579 
Epoch 378/1000 
	 loss: 178.0506, MinusLogProbMetric: 178.0506, val_loss: 180.2931, val_MinusLogProbMetric: 180.2931

Epoch 378: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0506 - MinusLogProbMetric: 178.0506 - val_loss: 180.2931 - val_MinusLogProbMetric: 180.2931 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 379/1000
2023-10-05 12:57:10.720 
Epoch 379/1000 
	 loss: 178.0506, MinusLogProbMetric: 178.0506, val_loss: 180.2667, val_MinusLogProbMetric: 180.2667

Epoch 379: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0506 - MinusLogProbMetric: 178.0506 - val_loss: 180.2667 - val_MinusLogProbMetric: 180.2667 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 380/1000
2023-10-05 12:57:24.848 
Epoch 380/1000 
	 loss: 178.0504, MinusLogProbMetric: 178.0504, val_loss: 180.2924, val_MinusLogProbMetric: 180.2924

Epoch 380: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0504 - MinusLogProbMetric: 178.0504 - val_loss: 180.2924 - val_MinusLogProbMetric: 180.2924 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 381/1000
2023-10-05 12:57:39.071 
Epoch 381/1000 
	 loss: 178.0491, MinusLogProbMetric: 178.0491, val_loss: 180.2968, val_MinusLogProbMetric: 180.2968

Epoch 381: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0491 - MinusLogProbMetric: 178.0491 - val_loss: 180.2968 - val_MinusLogProbMetric: 180.2968 - lr: 6.2500e-05 - 14s/epoch - 73ms/step
Epoch 382/1000
2023-10-05 12:57:53.158 
Epoch 382/1000 
	 loss: 178.0481, MinusLogProbMetric: 178.0481, val_loss: 180.2726, val_MinusLogProbMetric: 180.2726

Epoch 382: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0481 - MinusLogProbMetric: 178.0481 - val_loss: 180.2726 - val_MinusLogProbMetric: 180.2726 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 383/1000
2023-10-05 12:58:07.209 
Epoch 383/1000 
	 loss: 178.0478, MinusLogProbMetric: 178.0478, val_loss: 180.2995, val_MinusLogProbMetric: 180.2995

Epoch 383: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0478 - MinusLogProbMetric: 178.0478 - val_loss: 180.2995 - val_MinusLogProbMetric: 180.2995 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 384/1000
2023-10-05 12:58:21.441 
Epoch 384/1000 
	 loss: 178.0512, MinusLogProbMetric: 178.0512, val_loss: 180.3104, val_MinusLogProbMetric: 180.3104

Epoch 384: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0512 - MinusLogProbMetric: 178.0512 - val_loss: 180.3104 - val_MinusLogProbMetric: 180.3104 - lr: 6.2500e-05 - 14s/epoch - 73ms/step
Epoch 385/1000
2023-10-05 12:58:35.739 
Epoch 385/1000 
	 loss: 178.0460, MinusLogProbMetric: 178.0460, val_loss: 180.2738, val_MinusLogProbMetric: 180.2738

Epoch 385: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0460 - MinusLogProbMetric: 178.0460 - val_loss: 180.2738 - val_MinusLogProbMetric: 180.2738 - lr: 6.2500e-05 - 14s/epoch - 73ms/step
Epoch 386/1000
2023-10-05 12:58:49.899 
Epoch 386/1000 
	 loss: 178.0493, MinusLogProbMetric: 178.0493, val_loss: 180.2812, val_MinusLogProbMetric: 180.2812

Epoch 386: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0493 - MinusLogProbMetric: 178.0493 - val_loss: 180.2812 - val_MinusLogProbMetric: 180.2812 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 387/1000
2023-10-05 12:59:03.983 
Epoch 387/1000 
	 loss: 178.0520, MinusLogProbMetric: 178.0520, val_loss: 180.2894, val_MinusLogProbMetric: 180.2894

Epoch 387: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0520 - MinusLogProbMetric: 178.0520 - val_loss: 180.2894 - val_MinusLogProbMetric: 180.2894 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 388/1000
2023-10-05 12:59:18.112 
Epoch 388/1000 
	 loss: 178.0498, MinusLogProbMetric: 178.0498, val_loss: 180.2914, val_MinusLogProbMetric: 180.2914

Epoch 388: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0498 - MinusLogProbMetric: 178.0498 - val_loss: 180.2914 - val_MinusLogProbMetric: 180.2914 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 389/1000
2023-10-05 12:59:32.243 
Epoch 389/1000 
	 loss: 178.0496, MinusLogProbMetric: 178.0496, val_loss: 180.2889, val_MinusLogProbMetric: 180.2889

Epoch 389: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0496 - MinusLogProbMetric: 178.0496 - val_loss: 180.2889 - val_MinusLogProbMetric: 180.2889 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 390/1000
2023-10-05 12:59:46.467 
Epoch 390/1000 
	 loss: 178.0524, MinusLogProbMetric: 178.0524, val_loss: 180.3183, val_MinusLogProbMetric: 180.3183

Epoch 390: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0524 - MinusLogProbMetric: 178.0524 - val_loss: 180.3183 - val_MinusLogProbMetric: 180.3183 - lr: 6.2500e-05 - 14s/epoch - 73ms/step
Epoch 391/1000
2023-10-05 13:00:00.749 
Epoch 391/1000 
	 loss: 178.0527, MinusLogProbMetric: 178.0527, val_loss: 180.2659, val_MinusLogProbMetric: 180.2659

Epoch 391: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0527 - MinusLogProbMetric: 178.0527 - val_loss: 180.2659 - val_MinusLogProbMetric: 180.2659 - lr: 6.2500e-05 - 14s/epoch - 73ms/step
Epoch 392/1000
2023-10-05 13:00:14.911 
Epoch 392/1000 
	 loss: 178.0503, MinusLogProbMetric: 178.0503, val_loss: 180.2906, val_MinusLogProbMetric: 180.2906

Epoch 392: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0503 - MinusLogProbMetric: 178.0503 - val_loss: 180.2906 - val_MinusLogProbMetric: 180.2906 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 393/1000
2023-10-05 13:00:29.075 
Epoch 393/1000 
	 loss: 178.0444, MinusLogProbMetric: 178.0444, val_loss: 180.2776, val_MinusLogProbMetric: 180.2776

Epoch 393: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0444 - MinusLogProbMetric: 178.0444 - val_loss: 180.2776 - val_MinusLogProbMetric: 180.2776 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 394/1000
2023-10-05 13:00:43.167 
Epoch 394/1000 
	 loss: 178.0431, MinusLogProbMetric: 178.0431, val_loss: 180.2924, val_MinusLogProbMetric: 180.2924

Epoch 394: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0431 - MinusLogProbMetric: 178.0431 - val_loss: 180.2924 - val_MinusLogProbMetric: 180.2924 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 395/1000
2023-10-05 13:00:57.205 
Epoch 395/1000 
	 loss: 178.0495, MinusLogProbMetric: 178.0495, val_loss: 180.3283, val_MinusLogProbMetric: 180.3283

Epoch 395: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0495 - MinusLogProbMetric: 178.0495 - val_loss: 180.3283 - val_MinusLogProbMetric: 180.3283 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 396/1000
2023-10-05 13:01:11.312 
Epoch 396/1000 
	 loss: 178.0400, MinusLogProbMetric: 178.0400, val_loss: 180.3063, val_MinusLogProbMetric: 180.3063

Epoch 396: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0400 - MinusLogProbMetric: 178.0400 - val_loss: 180.3063 - val_MinusLogProbMetric: 180.3063 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 397/1000
2023-10-05 13:01:25.521 
Epoch 397/1000 
	 loss: 178.0506, MinusLogProbMetric: 178.0506, val_loss: 180.2856, val_MinusLogProbMetric: 180.2856

Epoch 397: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0506 - MinusLogProbMetric: 178.0506 - val_loss: 180.2856 - val_MinusLogProbMetric: 180.2856 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 398/1000
2023-10-05 13:01:39.680 
Epoch 398/1000 
	 loss: 178.0391, MinusLogProbMetric: 178.0391, val_loss: 180.3057, val_MinusLogProbMetric: 180.3057

Epoch 398: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0391 - MinusLogProbMetric: 178.0391 - val_loss: 180.3057 - val_MinusLogProbMetric: 180.3057 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 399/1000
2023-10-05 13:01:53.901 
Epoch 399/1000 
	 loss: 178.0395, MinusLogProbMetric: 178.0395, val_loss: 180.2731, val_MinusLogProbMetric: 180.2731

Epoch 399: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0395 - MinusLogProbMetric: 178.0395 - val_loss: 180.2731 - val_MinusLogProbMetric: 180.2731 - lr: 6.2500e-05 - 14s/epoch - 73ms/step
Epoch 400/1000
2023-10-05 13:02:08.103 
Epoch 400/1000 
	 loss: 178.0547, MinusLogProbMetric: 178.0547, val_loss: 180.2837, val_MinusLogProbMetric: 180.2837

Epoch 400: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0547 - MinusLogProbMetric: 178.0547 - val_loss: 180.2837 - val_MinusLogProbMetric: 180.2837 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 401/1000
2023-10-05 13:02:22.334 
Epoch 401/1000 
	 loss: 178.0456, MinusLogProbMetric: 178.0456, val_loss: 180.2824, val_MinusLogProbMetric: 180.2824

Epoch 401: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0456 - MinusLogProbMetric: 178.0456 - val_loss: 180.2824 - val_MinusLogProbMetric: 180.2824 - lr: 6.2500e-05 - 14s/epoch - 73ms/step
Epoch 402/1000
2023-10-05 13:02:36.629 
Epoch 402/1000 
	 loss: 178.0416, MinusLogProbMetric: 178.0416, val_loss: 180.2938, val_MinusLogProbMetric: 180.2938

Epoch 402: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0416 - MinusLogProbMetric: 178.0416 - val_loss: 180.2938 - val_MinusLogProbMetric: 180.2938 - lr: 6.2500e-05 - 14s/epoch - 73ms/step
Epoch 403/1000
2023-10-05 13:02:51.012 
Epoch 403/1000 
	 loss: 178.0452, MinusLogProbMetric: 178.0452, val_loss: 180.2820, val_MinusLogProbMetric: 180.2820

Epoch 403: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0452 - MinusLogProbMetric: 178.0452 - val_loss: 180.2820 - val_MinusLogProbMetric: 180.2820 - lr: 6.2500e-05 - 14s/epoch - 73ms/step
Epoch 404/1000
2023-10-05 13:03:05.270 
Epoch 404/1000 
	 loss: 178.0464, MinusLogProbMetric: 178.0464, val_loss: 180.3030, val_MinusLogProbMetric: 180.3030

Epoch 404: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0464 - MinusLogProbMetric: 178.0464 - val_loss: 180.3030 - val_MinusLogProbMetric: 180.3030 - lr: 6.2500e-05 - 14s/epoch - 73ms/step
Epoch 405/1000
2023-10-05 13:03:19.451 
Epoch 405/1000 
	 loss: 178.0431, MinusLogProbMetric: 178.0431, val_loss: 180.2919, val_MinusLogProbMetric: 180.2919

Epoch 405: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0431 - MinusLogProbMetric: 178.0431 - val_loss: 180.2919 - val_MinusLogProbMetric: 180.2919 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 406/1000
2023-10-05 13:03:33.807 
Epoch 406/1000 
	 loss: 178.0410, MinusLogProbMetric: 178.0410, val_loss: 180.2914, val_MinusLogProbMetric: 180.2914

Epoch 406: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0410 - MinusLogProbMetric: 178.0410 - val_loss: 180.2914 - val_MinusLogProbMetric: 180.2914 - lr: 6.2500e-05 - 14s/epoch - 73ms/step
Epoch 407/1000
2023-10-05 13:03:47.999 
Epoch 407/1000 
	 loss: 178.0403, MinusLogProbMetric: 178.0403, val_loss: 180.3028, val_MinusLogProbMetric: 180.3028

Epoch 407: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0403 - MinusLogProbMetric: 178.0403 - val_loss: 180.3028 - val_MinusLogProbMetric: 180.3028 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 408/1000
2023-10-05 13:04:02.303 
Epoch 408/1000 
	 loss: 178.0460, MinusLogProbMetric: 178.0460, val_loss: 180.2991, val_MinusLogProbMetric: 180.2991

Epoch 408: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0460 - MinusLogProbMetric: 178.0460 - val_loss: 180.2991 - val_MinusLogProbMetric: 180.2991 - lr: 6.2500e-05 - 14s/epoch - 73ms/step
Epoch 409/1000
2023-10-05 13:04:16.643 
Epoch 409/1000 
	 loss: 178.0376, MinusLogProbMetric: 178.0376, val_loss: 180.3651, val_MinusLogProbMetric: 180.3651

Epoch 409: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0376 - MinusLogProbMetric: 178.0376 - val_loss: 180.3651 - val_MinusLogProbMetric: 180.3651 - lr: 6.2500e-05 - 14s/epoch - 73ms/step
Epoch 410/1000
2023-10-05 13:04:30.763 
Epoch 410/1000 
	 loss: 178.0366, MinusLogProbMetric: 178.0366, val_loss: 180.3006, val_MinusLogProbMetric: 180.3006

Epoch 410: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0366 - MinusLogProbMetric: 178.0366 - val_loss: 180.3006 - val_MinusLogProbMetric: 180.3006 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 411/1000
2023-10-05 13:04:44.992 
Epoch 411/1000 
	 loss: 178.0363, MinusLogProbMetric: 178.0363, val_loss: 180.2937, val_MinusLogProbMetric: 180.2937

Epoch 411: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0363 - MinusLogProbMetric: 178.0363 - val_loss: 180.2937 - val_MinusLogProbMetric: 180.2937 - lr: 6.2500e-05 - 14s/epoch - 73ms/step
Epoch 412/1000
2023-10-05 13:04:59.189 
Epoch 412/1000 
	 loss: 178.0426, MinusLogProbMetric: 178.0426, val_loss: 180.3502, val_MinusLogProbMetric: 180.3502

Epoch 412: val_loss did not improve from 180.25266
196/196 - 14s - loss: 178.0426 - MinusLogProbMetric: 178.0426 - val_loss: 180.3502 - val_MinusLogProbMetric: 180.3502 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 413/1000
2023-10-05 13:05:13.168 
Epoch 413/1000 
	 loss: 178.0334, MinusLogProbMetric: 178.0334, val_loss: 180.3219, val_MinusLogProbMetric: 180.3219

Epoch 413: val_loss did not improve from 180.25266
Restoring model weights from the end of the best epoch: 313.
196/196 - 14s - loss: 178.0334 - MinusLogProbMetric: 178.0334 - val_loss: 180.3219 - val_MinusLogProbMetric: 180.3219 - lr: 6.2500e-05 - 14s/epoch - 72ms/step
Epoch 413: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
LR metric calculation completed in 45610.01999892504 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
nchunks = 10
Iterating from 0 to 1 out of 10 .
Iterating from 1 to 2 out of 10 .
Iterating from 2 to 3 out of 10 .
Iterating from 3 to 4 out of 10 .
Iterating from 4 to 5 out of 10 .
Iterating from 5 to 6 out of 10 .
Iterating from 6 to 7 out of 10 .
Iterating from 7 to 8 out of 10 .
Iterating from 8 to 9 out of 10 .
Iterating from 9 to 10 out of 10 .
KS tests calculation completed in 45795.79175420408 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
SWD metric calculation completed in 45726.40185272205 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
nchunks = 10
Iterating from 0 to 1 out of 10 .
Iterating from 1 to 2 out of 10 .
Iterating from 2 to 3 out of 10 .
Iterating from 3 to 4 out of 10 .
Iterating from 4 to 5 out of 10 .
Iterating from 5 to 6 out of 10 .
Iterating from 6 to 7 out of 10 .
Iterating from 7 to 8 out of 10 .
Iterating from 8 to 9 out of 10 .
Iterating from 9 to 10 out of 10 .
FN metric calculation completed in 45244.0287845789 seconds.
Training succeeded with seed 869.
Model trained in 5985.81 s.

===========
Computing predictions
===========

Computing metrics...
===========
Failed on GPU, re-trying on CPU
===========

Computing metrics...
Metrics computed in 182388.65 s.
                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/c_Main_MsplineN.py , Line : 468, Func.Name : prediction_function, Message : Plotters.cornerplotter(X_data_test.numpy(),X_data_nf.numpy(),path_to_results,ndims,norm=True) # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 182448.41 s.
===========
Run 310/360 done in 188436.42 s.
===========

Directory ../../results/MsplineN_new/run_311/ already exists.
Skipping it.
===========
Run 311/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_312/ already exists.
Skipping it.
===========
Run 312/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_313/ already exists.
Skipping it.
===========
Run 313/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_314/ already exists.
Skipping it.
===========
Run 314/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_315/ already exists.
Skipping it.
===========
Run 315/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_316/ already exists.
Skipping it.
===========
Run 316/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_317/ already exists.
Skipping it.
===========
Run 317/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_318/ already exists.
Skipping it.
===========
Run 318/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_319/ already exists.
Skipping it.
===========
Run 319/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_320/ already exists.
Skipping it.
===========
Run 320/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_321/ already exists.
Skipping it.
===========
Run 321/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_322/ already exists.
Skipping it.
===========
Run 322/360 already exists. Skipping it.
===========

===========
Generating train data for run 323.
===========
Train data generated in 0.36 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 1000)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_323/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 0}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_323/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[6.277253 , 6.974316 , 5.431759 , ..., 8.818214 , 1.8372726,
        6.879843 ],
       [8.248872 , 4.6043487, 5.1827307, ..., 2.8883853, 8.569977 ,
        6.566897 ],
       [7.511346 , 4.894093 , 5.228927 , ..., 2.959833 , 8.1193695,
        7.606636 ],
       ...,
       [5.4142895, 7.32243  , 7.81261  , ..., 9.441056 , 0.9493766,
        6.7277093],
       [5.4575763, 6.765944 , 6.234851 , ..., 9.695062 , 1.5681067,
        6.672586 ],
       [5.466369 , 6.341171 , 6.2548084, ..., 9.017296 , 2.8553374,
        6.70359  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_323/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_323
self.data_kwargs: {'seed': 0}
self.x_data: [[8.210789   4.3589015  5.1949253  ... 2.1186912  8.28666    6.44192   ]
 [5.776202   0.0413513  4.6274076  ... 4.7782993  6.688914   5.570342  ]
 [5.7263374  6.2561994  5.7377024  ... 8.820506   0.58727944 6.515802  ]
 ...
 [5.7884197  0.56533414 4.7867274  ... 4.878848   6.0022035  4.9900055 ]
 [5.9892163  0.222366   4.8566475  ... 4.5662537  6.433208   4.1020565 ]
 [7.8653784  4.6189337  5.157348   ... 2.6189103  7.542449   6.328924  ]]
self.y_data: []
self.ndims: 1000
Model defined.
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_7 (InputLayer)        [(None, 1000)]            0         
                                                                 
 log_prob_layer_2 (LogProbLa  (None,)                  9352304   
 yer)                                                            
                                                                 
=================================================================
Total params: 9,352,304
Trainable params: 9,352,304
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_2/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_2'")
self.model: <keras.engine.functional.Functional object at 0x7f37a1eea1d0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7f33383f3ee0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7f33383f3ee0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7f335843d540>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7f33586809a0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_323/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7f3358680f10>, <keras.callbacks.ModelCheckpoint object at 0x7f3358680fd0>, <keras.callbacks.EarlyStopping object at 0x7f3358681240>, <keras.callbacks.ReduceLROnPlateau object at 0x7f3358681270>, <keras.callbacks.TerminateOnNaN object at 0x7f3358680eb0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[6.277253 , 6.974316 , 5.431759 , ..., 8.818214 , 1.8372726,
        6.879843 ],
       [8.248872 , 4.6043487, 5.1827307, ..., 2.8883853, 8.569977 ,
        6.566897 ],
       [7.511346 , 4.894093 , 5.228927 , ..., 2.959833 , 8.1193695,
        7.606636 ],
       ...,
       [5.4142895, 7.32243  , 7.81261  , ..., 9.441056 , 0.9493766,
        6.7277093],
       [5.4575763, 6.765944 , 6.234851 , ..., 9.695062 , 1.5681067,
        6.672586 ],
       [5.466369 , 6.341171 , 6.2548084, ..., 9.017296 , 2.8553374,
        6.70359  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_323/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 323/360 with hyperparameters:
timestamp = 2023-10-07 15:46:03.030112
ndims = 1000
seed_train = 0
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 9352304
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 8.21078873e+00  4.35890150e+00  5.19492531e+00  2.84795880e+00
  6.23694658e+00  2.48332572e+00  6.01452780e+00  1.49544990e+00
  1.56305087e+00  4.33542109e+00  3.63919592e+00  2.33469009e+00
  7.12970674e-01  4.46248204e-01  1.55621916e-01  3.05101776e+00
  4.20721769e+00  7.49161625e+00  3.96869850e+00  9.05481625e+00
  4.47121114e-01  2.05655861e+00  3.52404070e+00  5.90453529e+00
  8.73787975e+00  3.53096032e+00  2.76253247e+00  6.50554955e-01
  8.03491688e+00  3.65929008e+00  4.93096781e+00  1.00386086e+01
  5.29845119e-01  1.22730446e+00  7.25914860e+00  7.58729315e+00
  7.71210337e+00  5.14168453e+00  9.58227444e+00  4.79759741e+00
  6.05360174e+00 -3.22920084e-03  4.30121565e+00  7.28324509e+00
  2.30840397e+00  9.72805214e+00  7.01551247e+00  3.15825868e+00
  7.77309942e+00  1.27091324e+00  9.88113785e+00  5.76226175e-01
  9.93493366e+00  6.19022250e-01  7.72215176e+00  1.45727849e+00
  2.63241100e+00  7.56394577e+00  4.26764488e+00  1.30306756e+00
  4.47696209e+00  4.10884666e+00  6.25260830e+00  7.17153311e+00
  7.79660606e+00  4.86149597e+00  4.01030636e+00  1.48931491e+00
  8.25993347e+00  6.99169493e+00  4.15396929e+00  5.40362930e+00
  6.69921494e+00  1.80113685e+00 -2.28963286e-01  3.53704309e+00
  5.97519684e+00  5.03495884e+00  5.96093559e+00  8.27530861e+00
  5.11110401e+00  1.71916723e-01  1.00485516e+01  5.39971399e+00
  6.97965956e+00  6.67698717e+00  9.53224850e+00  2.60424829e+00
  6.92656088e+00  2.48836160e+00  1.50950837e+00  3.11806774e+00
  3.62086797e+00  9.48242664e+00  2.35715413e+00  1.47683930e+00
  6.57032585e+00  2.31288910e+00  5.07415724e+00  8.22896194e+00
  2.67307043e+00  4.70531940e+00  5.81045723e+00  3.97613907e+00
  1.00836468e+01  6.80917358e+00  7.91102648e+00  9.83973694e+00
  3.97975469e+00  2.81087971e+00  6.61194921e-01  2.09042239e+00
  1.80242181e+00  2.45311332e+00  7.75794411e+00  5.35263777e+00
  6.36038160e+00  8.03104973e+00  2.23086929e+00  3.26186609e+00
  7.10611820e+00  4.36860800e+00  5.38674593e-01  5.03258133e+00
  8.79059315e+00  4.12663126e+00  2.96597481e+00  9.92143154e+00
  6.63155603e+00  2.29087067e+00  9.67418194e-01  8.54019165e+00
  7.32748413e+00  9.67831326e+00  3.08930302e+00  1.43350685e+00
  7.23957300e+00  2.06572795e+00  1.31994998e+00  2.38906145e+00
  8.15470123e+00  4.92610788e+00  4.60461289e-01  4.69264269e+00
  7.11180496e+00  6.15540504e+00  5.58532810e+00  1.97622848e+00
  8.55810928e+00  5.60682297e+00  6.50732088e+00  9.74595356e+00
  3.70203424e+00  8.65994740e+00  3.66820455e-01 -1.19887441e-01
  5.62859249e+00  3.21332264e+00  2.41353798e+00  2.97626567e+00
  3.33519387e+00  7.60388327e+00  5.94638872e+00  7.90076303e+00
  8.14614868e+00  8.43794918e+00  5.11629820e+00  4.45509529e+00
  8.96594524e+00  6.83408117e+00  5.29020429e-01  5.47313118e+00
  3.56114149e+00  9.86122417e+00 -8.47060025e-01  5.97660685e+00
  7.56903505e+00  3.27315211e+00  9.39664459e+00  9.18616390e+00
  9.16251087e+00  3.12576860e-01  5.81769562e+00  2.36430216e+00
  8.91152668e+00  6.80723286e+00  5.49286032e+00  1.25512540e+00
  6.51518726e+00  6.32031965e+00  9.03301430e+00  5.99218893e+00
  9.68340588e+00  9.75206280e+00  6.48233700e+00  5.02287769e+00
  4.40520668e+00  8.71606636e+00  1.15936518e-01  1.15061617e+00
  1.13465822e+00  7.72926044e+00  3.59013176e+00  6.88610840e+00
  6.62146950e+00  3.82466817e+00  5.06336927e+00  6.39645910e+00
  9.77296638e+00  6.23589993e+00  6.13958120e+00  6.46353066e-01
  7.98168039e+00  5.24744987e+00  8.84934807e+00  7.04309762e-01
  4.59585285e+00  2.57471061e+00  2.76045990e+00  7.58923578e+00
  6.31161690e+00  3.93680930e+00  3.41281295e-03  9.66006947e+00
  9.57943439e+00  2.44953036e+00  7.60993719e-01  5.62422276e+00
  9.45851040e+00  9.12294960e+00  5.39434481e+00  2.33969688e+00
  3.87983751e+00  8.94526768e+00  4.94882011e+00  7.46908426e-01
  3.23506546e+00  2.77883267e+00  1.57590222e+00  5.10829020e+00
  9.52500534e+00  6.17966223e+00  1.10281193e+00  5.18856943e-01
  2.46926522e+00  3.78143835e+00  6.96128178e+00  1.00144138e+01
  3.66667557e+00  5.97449923e+00  9.95713520e+00  7.44061518e+00
  6.02692795e+00  7.26248920e-01  3.43354082e+00  1.11553822e+01
  1.09044552e+00  8.32242012e+00  7.46725512e+00  3.50707126e+00
  4.66837549e+00  6.27135944e+00  7.01602077e+00  4.99376917e+00
  1.22947979e+00  6.21938133e+00  4.57749987e+00  9.84504700e+00
  3.30335212e+00  2.10937715e+00  8.59310150e-01  5.95748758e+00
  7.51813459e+00  1.18187451e+00  3.30510187e+00  6.36148548e+00
  4.50776958e+00  4.50498581e+00  1.05220985e+01  9.05682564e+00
  6.02789402e+00  7.13881588e+00  7.25975084e+00  6.13174152e+00
  2.50386310e+00  6.21227741e+00  6.38945484e+00  8.56712151e+00
  3.63186836e-01  9.32480907e+00  5.54315186e+00 -3.98739636e-01
  3.37429929e+00  7.95210361e+00  5.01406813e+00  9.63213921e+00
  3.99637389e+00  2.97415352e+00  8.29203606e+00  6.00829792e+00
  6.21376610e+00  7.23727989e+00  6.71069527e+00  5.01448536e+00
  9.13507938e-01  6.87569332e+00  9.86827469e+00  4.45279694e+00
  8.80540848e+00  5.50182295e+00  6.56988764e+00  8.22664070e+00
  6.11226082e+00  9.90539372e-01  8.70905399e+00  2.35227823e+00
  6.95939922e+00  4.88893890e+00  4.05508137e+00  1.27094746e+00
  7.41610336e+00  9.57014084e-01  1.03208637e+01  8.77536011e+00
  5.40437126e+00  3.66490221e+00  1.92103791e+00  5.05432844e+00
  6.88084650e+00  2.36994123e+00  4.34519386e+00  1.71688604e+00
  3.39162683e+00  1.85334861e+00  9.56473351e+00  6.55594063e+00
  7.24569368e+00  9.57989931e-01  3.30405354e+00  8.91251564e+00
  9.43958402e-01  2.91835928e+00  6.76908159e+00  6.41434669e+00
  8.02711487e+00  8.37068748e+00  1.76286387e+00  2.83487058e+00
  4.26155806e+00 -1.64624956e-02  5.80787063e-02  2.90215087e+00
  4.82958937e+00  2.67308688e+00  8.74459743e+00  3.35418940e+00
  9.50176620e+00  9.24923992e+00  5.82722712e+00  3.35397267e+00
  3.11244607e+00  7.65114069e+00  2.58552289e+00  3.75996971e+00
  5.17049551e+00  5.17774963e+00  9.58946896e+00  2.46264791e+00
  4.03688717e+00  2.72447777e+00  2.75106120e+00  1.24247396e+00
  2.18880701e+00  8.80450439e+00  2.16815996e+00  4.50869846e+00
  9.47779369e+00  6.92755127e+00  5.21426487e+00  7.63384438e+00
  1.33627713e+00  5.05314064e+00  8.01588058e-01  2.33411765e+00
  2.04597259e+00  3.71735334e+00  3.99399781e+00  9.83961201e+00
  2.91163659e+00  3.73780441e+00  7.86999273e+00  7.62870979e+00
  7.85087109e+00  2.87814641e+00  5.46488953e+00  1.44017196e+00
  2.16978312e+00  4.34651899e+00  7.40160513e+00  5.01842690e+00
  8.79978561e+00  8.01273918e+00  6.23900414e-01  5.34396315e+00
  5.84303570e+00  9.49287987e+00 -2.03253716e-01  5.55819988e+00
  2.56452465e+00  5.52358687e-01  5.80285740e+00  8.33415508e+00
  8.18197632e+00 -8.59678984e-02  3.97874522e+00  4.08348382e-01
  2.77977419e+00  2.01314735e+00  2.23359156e+00  3.15110850e+00
  3.16415262e+00  9.69314194e+00  3.46537042e+00  8.90620518e+00
  1.80000591e+00  6.60689974e+00 -7.20865309e-01  4.78756142e+00
 -1.09752685e-01  9.03241920e+00  8.91885853e+00  6.74625039e-01
  9.64687729e+00  5.28304863e+00  3.44711399e+00  9.08611012e+00
  3.02275133e+00  4.11477327e+00  1.01315606e+00  7.55140066e+00
  7.66734123e-01  4.76552486e+00  6.70099640e+00  7.79399300e+00
  1.63697755e+00  6.94904470e+00  6.56399965e+00  4.96204281e+00
  5.89378309e+00  5.83356380e-01  6.12774992e+00  4.05969334e+00
  8.60876942e+00  3.77930760e+00  5.77260780e+00  4.28877592e+00
  9.17067528e+00  2.55027103e+00  1.33500242e+00  8.23266697e+00
  4.27657557e+00  5.92882109e+00  3.65143597e-01  1.05127277e+01
  9.12497520e+00  4.73808956e+00  1.15415120e+00  4.24439526e+00
  9.80254364e+00  7.13764381e+00  2.21075535e+00  4.46259594e+00
  9.60248947e+00  6.37608194e+00  3.89600515e-01  6.30370569e+00
  2.47006059e+00  9.89494145e-01  4.10520649e+00  5.44608831e+00
  5.12012959e-01  4.04597473e+00  5.92461109e+00  8.09785938e+00
  5.32709646e+00  5.15376234e+00  7.13395691e+00  8.32365990e+00
  4.20349646e+00  6.05286407e+00  6.26060724e+00  6.60055876e-03
  8.09364128e+00  3.49219418e+00  7.10890245e+00  4.91867685e+00
  7.30661583e+00  6.67151976e+00  2.00603342e+00  6.53424406e+00
  8.17309189e+00  2.37493563e+00  7.19742537e+00  6.21698093e+00
  1.02654848e+01  4.02459478e+00  2.00096679e+00  3.60146332e+00
  2.72641587e+00  7.55267096e+00  7.33097744e+00  6.48247480e+00
  1.84161115e+00  8.67273045e+00  1.03891554e+01  5.11711931e+00
  6.14349842e+00  4.63130045e+00  1.04338384e+00  3.16097307e+00
  2.48957181e+00  2.08219433e+00  9.02428818e+00  7.58692598e+00
  3.53382182e+00  2.87967825e+00  9.43597221e+00  1.85656917e+00
  5.57112312e+00  9.00374889e-01  1.43457806e+00  5.70213127e+00
  6.18463993e+00  5.21287870e+00  8.30662155e+00  9.78884792e+00
  8.07082462e+00  4.94385624e+00  9.57595062e+00  4.81561422e-01
  5.93677044e+00  6.03051233e+00  1.27146268e+00  9.59977341e+00
  3.53188229e+00  5.92599010e+00  8.90297794e+00  5.73115826e+00
  8.29036653e-01  6.28442287e+00  4.10012245e+00  8.16020679e+00
  9.57242489e+00  8.73237801e+00  3.82743692e+00  7.33982182e+00
  9.39437389e+00  5.32039928e+00  4.49351358e+00  7.41679072e-01
  7.33104944e+00  8.68616486e+00  2.54391122e+00  2.88136458e+00
  5.05854321e+00  4.12581384e-01  7.20838428e-01  4.39249325e+00
  2.12579203e+00  5.69973421e+00  3.94032979e+00  1.01283722e+01
  9.79717064e+00  2.52009940e+00  8.86107635e+00  8.79512429e-01
  4.84236622e+00  1.72291732e+00  3.82897258e+00  6.94665861e+00
  4.18651247e+00  8.54575062e+00  7.19269276e+00  9.72444630e+00
  5.51988173e+00  8.01771069e+00  3.28205919e+00  3.97813463e+00
  4.18136644e+00  5.16412115e+00  1.75697100e+00  5.15417719e+00
  1.50469279e+00  9.25226021e+00  4.35976595e-01  4.19854736e+00
  3.64054823e+00  1.06782198e-01  8.30288601e+00  7.06305122e+00
  1.87979758e+00  6.35672998e+00  8.16109753e+00  6.51096630e+00
  5.61127961e-01  6.76316595e+00  6.57550716e+00  7.76742983e+00
  5.40051842e+00  4.99695921e+00  1.05247574e+01  7.60159779e+00
  5.60209799e+00  3.34395909e+00  9.19912910e+00  4.68194294e+00
  1.00466835e+00  5.51672554e+00  8.06357193e+00  4.60604143e+00
  7.99039245e-01  6.11217165e+00  9.98776340e+00  7.64210176e+00
  6.11796856e+00  9.89960003e+00  7.96584511e+00  6.26075697e+00
  4.63107634e+00  7.38753414e+00  6.49842548e+00  7.23403335e-01
  7.84123564e+00  3.43258095e+00  5.87750053e+00  8.16937256e+00
  4.84820747e+00  1.59829724e+00  4.18775225e+00  1.30482543e+00
  6.89824677e+00  9.70094967e+00  7.83443594e+00  4.79529858e+00
  6.26568747e+00  3.08977580e+00  5.72115278e+00  2.92952847e+00
  7.45006084e+00  2.38916183e+00  9.71957111e+00  6.54768562e+00
  6.25139415e-01 -2.21325979e-02  1.01162004e+01  1.64097524e+00
  3.30466270e+00  2.32712507e+00  9.82605267e+00  5.42485619e+00
  4.57557726e+00  5.65397930e+00  2.95226574e+00  6.00716829e+00
  4.69566488e+00  1.86493647e+00  5.55787706e+00  4.29599905e+00
  8.97355652e+00  4.49551582e+00  5.21416712e+00  7.87060261e+00
  4.67125940e+00  9.76075363e+00  8.19973755e+00  8.41541100e+00
  9.90537739e+00  2.93996453e+00  5.85271358e+00  7.30432892e+00
  7.22648525e+00  9.17044544e+00  2.83920431e+00  3.20150447e+00
  8.31029034e+00  7.78128242e+00  2.25734663e+00  5.91900253e+00
  7.87056684e+00  3.05571938e+00  3.93086529e+00  5.76315022e+00
  5.30861235e+00  7.55313301e+00 -1.47460684e-01  4.09288597e+00
  1.74171937e+00  4.78674221e+00  7.88887119e+00  7.54741371e-01
  1.54648781e+00  7.28928089e+00  7.57703447e+00  5.61207056e+00
  9.85756111e+00  4.10112953e+00  1.57129598e+00  6.85865021e+00
  6.33887672e+00  6.33726215e+00  5.35512924e+00  8.78589249e+00
  8.93958569e-01 -1.22548640e-01  1.54779208e+00  2.83668208e+00
  5.92615891e+00  5.92532015e+00  2.29801345e+00  4.49938583e+00
  4.36498499e+00  5.37602377e+00  8.03752041e+00  5.66677046e+00
  8.83142376e+00  1.65858328e+00  5.42761660e+00  8.26859760e+00
  1.79626775e+00  4.40248251e+00  5.96399355e+00  2.07387352e+00
  7.58685493e+00  6.19924068e-01  9.63695049e+00  4.80245113e+00
  2.84362292e+00  1.11408031e+00  4.65407324e+00  6.60547924e+00
  1.22691751e+00  3.05578947e+00  1.09281607e+01  6.40130091e+00
  2.10371280e+00  1.27200794e+00  8.89848232e+00  2.80182910e+00
  2.19280529e+00  1.05606747e+01  2.94065785e+00  1.69049454e+00
  5.48146868e+00  4.31994724e+00  9.06744099e+00  1.15592277e+00
 -7.79310703e-01  1.04373407e+00  8.86706924e+00  4.28514481e+00
  1.81781006e+00  5.78969526e+00  5.54994345e+00  2.30405951e+00
  5.54053879e+00  2.74468279e+00  2.27062321e+00  4.07878542e+00
  2.84625888e+00  2.04214787e+00  8.94879723e+00  6.88817441e-01
  2.71495771e+00  3.84625363e+00  2.55016398e+00  2.09636283e+00
  7.99209976e+00  3.07564521e+00  1.11745620e+00  5.30355263e+00
  9.93744850e-01  2.74349833e+00  8.41612911e+00  4.34795761e+00
  6.55439472e+00  6.15104818e+00  5.19303381e-01  6.36637783e+00
  8.49066544e+00  8.24014544e-01  6.90668011e+00  7.08179665e+00
  9.01312637e+00  3.36554408e+00  2.87336349e+00  6.86589861e+00
 -2.01100767e-01  7.31349230e+00  8.66450596e+00  4.29815626e+00
  3.38823771e+00  3.01338983e+00  8.08154404e-01  1.78297210e+00
  9.61242580e+00  8.81327534e+00  2.97019339e+00  8.63016319e+00
  3.02107668e+00  2.72670150e+00  2.13139439e+00  8.94742870e+00
  9.83511925e+00  3.19685555e+00  6.81030130e+00  3.50014639e+00
  1.05297625e+00  4.07330465e+00  5.53509521e+00  1.18256664e+00
  8.23826122e+00  5.53470898e+00  2.24809480e+00  5.40734196e+00
  7.84483671e+00  2.75392199e+00  7.62425852e+00  4.27786589e+00
  9.72611332e+00  8.83753872e+00  3.43726850e+00  1.27960294e-01
  7.29834032e+00  2.04023504e+00  1.30689442e+00  9.04135704e+00
  1.00866823e+01  2.58009624e+00  3.01804805e+00  1.68803823e+00
  4.80738878e+00  8.68211079e+00  6.73749733e+00  8.63989162e+00
  2.21114421e+00  7.04848576e+00  9.34753704e+00  2.76184368e+00
  6.90854836e+00  4.05415773e+00  3.81649780e+00  9.40583229e+00
  4.05083704e+00  8.92635822e-01  3.82358503e+00  4.43289518e+00
  7.26910877e+00  8.82122993e+00  8.22476578e+00  9.33980370e+00
  4.71105146e+00  6.95373154e+00  3.06833911e+00 -4.22824502e-01
  3.65492988e+00  6.86570597e+00  2.05108023e+00  8.74809170e+00
  8.31052685e+00  1.87380075e+00  2.81262565e+00  8.66123104e+00
  3.31760716e+00  3.31471944e+00  3.48811197e+00  7.28613329e+00
 -9.66772735e-02 -7.69796014e-01  6.32836771e+00  3.86802888e+00
  5.99920893e+00  2.40654874e+00  9.12174988e+00  8.34914875e+00
  7.07096219e-01  7.57762194e+00  9.58280849e+00  8.65084171e+00
  6.67687321e+00  1.21811235e+00  5.86707783e+00  3.30112028e+00
  1.01402960e+01  7.17766523e+00  5.74374008e+00  6.99432039e+00
  4.40368319e+00  2.86542940e+00  9.42987251e+00  3.30265784e+00
  3.83230895e-01  4.20491457e+00  8.71614361e+00  7.57816601e+00
  9.77553654e+00  6.46106720e-01  9.44217777e+00  4.46305180e+00
  4.83198547e+00  3.06845570e+00  1.06641746e+00  4.49923372e+00
  7.57343435e+00  5.86748123e-03  1.58664107e+00  5.31323195e-01
  8.55088329e+00  6.48872995e+00  1.54820132e+00  7.71537733e+00
  8.20388412e+00  9.80402565e+00  9.79537868e+00 -8.38677704e-01
  5.94942427e+00  2.88661289e+00  5.26643085e+00  3.18921828e+00
  7.79481411e-01  4.42821693e+00  5.33531380e+00  9.32881355e+00
  2.65765786e-02  3.08747840e+00  8.52437019e+00  6.85948515e+00
  8.21984768e+00  6.24451685e+00  7.30141687e+00  4.90936804e+00
  2.20824790e+00  8.48395348e+00  5.67844057e+00  1.24840343e+00
  8.05260468e+00  9.64081573e+00  3.07099938e+00  3.18240905e+00
  9.12044704e-01  5.96499348e+00  9.19813156e+00  3.36040854e-01
  4.73263264e+00  1.30067658e+00  5.19609153e-01  6.70743704e+00
  8.23411751e+00  3.52812862e+00  8.22581482e+00  1.19572031e+00
  2.63071656e+00  9.79853821e+00  4.98861170e+00  6.00117397e+00
  3.19664389e-01  1.32244027e+00  6.05848253e-01  7.35753870e+00
  1.13696325e+00  8.69066429e+00  3.58892393e+00  7.88068628e+00
  3.04448676e+00  2.65313506e+00  9.56735551e-01  2.75976801e+00
  4.98727465e+00  7.08365965e+00  5.05365181e+00  9.17652988e+00
  5.92350817e+00  1.26345801e+00  3.95679140e+00  7.46081781e+00
  2.64605379e+00  6.97033882e+00  5.93741179e+00  1.01776525e-01
  7.47330189e+00  5.93837404e+00  8.12254488e-01  3.60206747e+00
  3.23938537e+00  8.24193764e+00  3.56294060e+00  9.41426849e+00
  5.64243269e+00  2.11869121e+00  8.28666019e+00  6.44191980e+00]
Epoch 1/1000
2023-10-07 15:46:40.920 
Epoch 1/1000 
	 loss: 1225.7050, MinusLogProbMetric: 1225.7050, val_loss: 517.5692, val_MinusLogProbMetric: 517.5692

Epoch 1: val_loss improved from inf to 517.56921, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_323/weights/best_weights.h5
196/196 - 38s - loss: 1225.7050 - MinusLogProbMetric: 1225.7050 - val_loss: 517.5692 - val_MinusLogProbMetric: 517.5692 - lr: 0.0010 - 38s/epoch - 194ms/step
Epoch 2/1000
2023-10-07 15:46:55.458 
Epoch 2/1000 
	 loss: 484.2717, MinusLogProbMetric: 484.2717, val_loss: 458.5713, val_MinusLogProbMetric: 458.5713

Epoch 2: val_loss improved from 517.56921 to 458.57126, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_323/weights/best_weights.h5
196/196 - 15s - loss: 484.2717 - MinusLogProbMetric: 484.2717 - val_loss: 458.5713 - val_MinusLogProbMetric: 458.5713 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 3/1000
2023-10-07 15:47:10.093 
Epoch 3/1000 
	 loss: 452.1089, MinusLogProbMetric: 452.1089, val_loss: 448.0248, val_MinusLogProbMetric: 448.0248

Epoch 3: val_loss improved from 458.57126 to 448.02484, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_323/weights/best_weights.h5
196/196 - 15s - loss: 452.1089 - MinusLogProbMetric: 452.1089 - val_loss: 448.0248 - val_MinusLogProbMetric: 448.0248 - lr: 0.0010 - 15s/epoch - 74ms/step
Epoch 4/1000
2023-10-07 15:47:25.028 
Epoch 4/1000 
	 loss: 437.5374, MinusLogProbMetric: 437.5374, val_loss: 436.7461, val_MinusLogProbMetric: 436.7461

Epoch 4: val_loss improved from 448.02484 to 436.74609, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_323/weights/best_weights.h5
196/196 - 15s - loss: 437.5374 - MinusLogProbMetric: 437.5374 - val_loss: 436.7461 - val_MinusLogProbMetric: 436.7461 - lr: 0.0010 - 15s/epoch - 76ms/step
Epoch 5/1000
2023-10-07 15:47:40.053 
Epoch 5/1000 
	 loss: 430.0466, MinusLogProbMetric: 430.0466, val_loss: 430.0927, val_MinusLogProbMetric: 430.0927

Epoch 5: val_loss improved from 436.74609 to 430.09271, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_323/weights/best_weights.h5
196/196 - 15s - loss: 430.0466 - MinusLogProbMetric: 430.0466 - val_loss: 430.0927 - val_MinusLogProbMetric: 430.0927 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 6/1000
2023-10-07 15:47:55.162 
Epoch 6/1000 
	 loss: 425.2737, MinusLogProbMetric: 425.2737, val_loss: 423.4817, val_MinusLogProbMetric: 423.4817

Epoch 6: val_loss improved from 430.09271 to 423.48169, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_323/weights/best_weights.h5
196/196 - 15s - loss: 425.2737 - MinusLogProbMetric: 425.2737 - val_loss: 423.4817 - val_MinusLogProbMetric: 423.4817 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 7/1000
2023-10-07 15:48:10.308 
Epoch 7/1000 
	 loss: 421.9130, MinusLogProbMetric: 421.9130, val_loss: 422.3397, val_MinusLogProbMetric: 422.3397

Epoch 7: val_loss improved from 423.48169 to 422.33966, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_323/weights/best_weights.h5
196/196 - 15s - loss: 421.9130 - MinusLogProbMetric: 421.9130 - val_loss: 422.3397 - val_MinusLogProbMetric: 422.3397 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 8/1000
2023-10-07 15:48:25.289 
Epoch 8/1000 
	 loss: 419.6749, MinusLogProbMetric: 419.6749, val_loss: 418.5736, val_MinusLogProbMetric: 418.5736

Epoch 8: val_loss improved from 422.33966 to 418.57358, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_323/weights/best_weights.h5
196/196 - 15s - loss: 419.6749 - MinusLogProbMetric: 419.6749 - val_loss: 418.5736 - val_MinusLogProbMetric: 418.5736 - lr: 0.0010 - 15s/epoch - 76ms/step
Epoch 9/1000
2023-10-07 15:48:40.318 
Epoch 9/1000 
	 loss: 417.4412, MinusLogProbMetric: 417.4412, val_loss: 416.0061, val_MinusLogProbMetric: 416.0061

Epoch 9: val_loss improved from 418.57358 to 416.00610, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_323/weights/best_weights.h5
196/196 - 15s - loss: 417.4412 - MinusLogProbMetric: 417.4412 - val_loss: 416.0061 - val_MinusLogProbMetric: 416.0061 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 10/1000
2023-10-07 15:48:55.507 
Epoch 10/1000 
	 loss: 415.1724, MinusLogProbMetric: 415.1724, val_loss: 424.1719, val_MinusLogProbMetric: 424.1719

Epoch 10: val_loss did not improve from 416.00610
196/196 - 15s - loss: 415.1724 - MinusLogProbMetric: 415.1724 - val_loss: 424.1719 - val_MinusLogProbMetric: 424.1719 - lr: 0.0010 - 15s/epoch - 76ms/step
Epoch 11/1000
2023-10-07 15:49:10.500 
Epoch 11/1000 
	 loss: 413.8076, MinusLogProbMetric: 413.8076, val_loss: 412.1235, val_MinusLogProbMetric: 412.1235

Epoch 11: val_loss improved from 416.00610 to 412.12350, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_323/weights/best_weights.h5
196/196 - 15s - loss: 413.8076 - MinusLogProbMetric: 413.8076 - val_loss: 412.1235 - val_MinusLogProbMetric: 412.1235 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 12/1000
2023-10-07 15:49:25.674 
Epoch 12/1000 
	 loss: 412.3948, MinusLogProbMetric: 412.3948, val_loss: 410.4521, val_MinusLogProbMetric: 410.4521

Epoch 12: val_loss improved from 412.12350 to 410.45206, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_323/weights/best_weights.h5
196/196 - 15s - loss: 412.3948 - MinusLogProbMetric: 412.3948 - val_loss: 410.4521 - val_MinusLogProbMetric: 410.4521 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 13/1000
2023-10-07 15:49:40.835 
Epoch 13/1000 
	 loss: 411.3942, MinusLogProbMetric: 411.3942, val_loss: 412.3964, val_MinusLogProbMetric: 412.3964

Epoch 13: val_loss did not improve from 410.45206
196/196 - 15s - loss: 411.3942 - MinusLogProbMetric: 411.3942 - val_loss: 412.3964 - val_MinusLogProbMetric: 412.3964 - lr: 0.0010 - 15s/epoch - 76ms/step
Epoch 14/1000
2023-10-07 15:49:55.872 
Epoch 14/1000 
	 loss: 409.7394, MinusLogProbMetric: 409.7394, val_loss: 414.9979, val_MinusLogProbMetric: 414.9979

Epoch 14: val_loss did not improve from 410.45206
196/196 - 15s - loss: 409.7394 - MinusLogProbMetric: 409.7394 - val_loss: 414.9979 - val_MinusLogProbMetric: 414.9979 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 15/1000
2023-10-07 15:50:10.903 
Epoch 15/1000 
	 loss: 409.1862, MinusLogProbMetric: 409.1862, val_loss: 416.4221, val_MinusLogProbMetric: 416.4221

Epoch 15: val_loss did not improve from 410.45206
196/196 - 15s - loss: 409.1862 - MinusLogProbMetric: 409.1862 - val_loss: 416.4221 - val_MinusLogProbMetric: 416.4221 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 16/1000
2023-10-07 15:50:26.029 
Epoch 16/1000 
	 loss: 423.6919, MinusLogProbMetric: 423.6919, val_loss: 489.9863, val_MinusLogProbMetric: 489.9863

Epoch 16: val_loss did not improve from 410.45206
196/196 - 15s - loss: 423.6919 - MinusLogProbMetric: 423.6919 - val_loss: 489.9863 - val_MinusLogProbMetric: 489.9863 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 17/1000
2023-10-07 15:50:41.061 
Epoch 17/1000 
	 loss: 416.2226, MinusLogProbMetric: 416.2226, val_loss: 408.2634, val_MinusLogProbMetric: 408.2634

Epoch 17: val_loss improved from 410.45206 to 408.26337, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_323/weights/best_weights.h5
196/196 - 15s - loss: 416.2226 - MinusLogProbMetric: 416.2226 - val_loss: 408.2634 - val_MinusLogProbMetric: 408.2634 - lr: 0.0010 - 15s/epoch - 78ms/step
Epoch 18/1000
2023-10-07 15:50:56.390 
Epoch 18/1000 
	 loss: 407.1418, MinusLogProbMetric: 407.1418, val_loss: 410.1873, val_MinusLogProbMetric: 410.1873

Epoch 18: val_loss did not improve from 408.26337
196/196 - 15s - loss: 407.1418 - MinusLogProbMetric: 407.1418 - val_loss: 410.1873 - val_MinusLogProbMetric: 410.1873 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 19/1000
2023-10-07 15:51:11.446 
Epoch 19/1000 
	 loss: 406.1317, MinusLogProbMetric: 406.1317, val_loss: 407.5880, val_MinusLogProbMetric: 407.5880

Epoch 19: val_loss improved from 408.26337 to 407.58804, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_323/weights/best_weights.h5
196/196 - 15s - loss: 406.1317 - MinusLogProbMetric: 406.1317 - val_loss: 407.5880 - val_MinusLogProbMetric: 407.5880 - lr: 0.0010 - 15s/epoch - 78ms/step
Epoch 20/1000
2023-10-07 15:51:26.635 
Epoch 20/1000 
	 loss: 405.2036, MinusLogProbMetric: 405.2036, val_loss: 405.4979, val_MinusLogProbMetric: 405.4979

Epoch 20: val_loss improved from 407.58804 to 405.49789, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_323/weights/best_weights.h5
196/196 - 15s - loss: 405.2036 - MinusLogProbMetric: 405.2036 - val_loss: 405.4979 - val_MinusLogProbMetric: 405.4979 - lr: 0.0010 - 15s/epoch - 78ms/step
Epoch 21/1000
2023-10-07 15:51:41.841 
Epoch 21/1000 
	 loss: 404.9393, MinusLogProbMetric: 404.9393, val_loss: 405.5921, val_MinusLogProbMetric: 405.5921

Epoch 21: val_loss did not improve from 405.49789
196/196 - 15s - loss: 404.9393 - MinusLogProbMetric: 404.9393 - val_loss: 405.5921 - val_MinusLogProbMetric: 405.5921 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 22/1000
2023-10-07 15:51:56.832 
Epoch 22/1000 
	 loss: 404.1720, MinusLogProbMetric: 404.1720, val_loss: 405.1268, val_MinusLogProbMetric: 405.1268

Epoch 22: val_loss improved from 405.49789 to 405.12677, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_323/weights/best_weights.h5
196/196 - 15s - loss: 404.1720 - MinusLogProbMetric: 404.1720 - val_loss: 405.1268 - val_MinusLogProbMetric: 405.1268 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 23/1000
2023-10-07 15:52:12.114 
Epoch 23/1000 
	 loss: 403.6379, MinusLogProbMetric: 403.6379, val_loss: 405.6681, val_MinusLogProbMetric: 405.6681

Epoch 23: val_loss did not improve from 405.12677
196/196 - 15s - loss: 403.6379 - MinusLogProbMetric: 403.6379 - val_loss: 405.6681 - val_MinusLogProbMetric: 405.6681 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 24/1000
2023-10-07 15:52:27.080 
Epoch 24/1000 
	 loss: 402.6476, MinusLogProbMetric: 402.6476, val_loss: 402.4158, val_MinusLogProbMetric: 402.4158

Epoch 24: val_loss improved from 405.12677 to 402.41583, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_323/weights/best_weights.h5
196/196 - 15s - loss: 402.6476 - MinusLogProbMetric: 402.6476 - val_loss: 402.4158 - val_MinusLogProbMetric: 402.4158 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 25/1000
2023-10-07 15:52:42.161 
Epoch 25/1000 
	 loss: 403.8196, MinusLogProbMetric: 403.8196, val_loss: 403.4690, val_MinusLogProbMetric: 403.4690

Epoch 25: val_loss did not improve from 402.41583
196/196 - 15s - loss: 403.8196 - MinusLogProbMetric: 403.8196 - val_loss: 403.4690 - val_MinusLogProbMetric: 403.4690 - lr: 0.0010 - 15s/epoch - 76ms/step
Epoch 26/1000
